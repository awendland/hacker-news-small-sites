<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 28 Sep 2020 04:25:34 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 28 Sep 2020 04:25:34 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[On not choosing WordPress for the W3C redesign project]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24596769">thread link</a>) | @ziodave
<br/>
September 25, 2020 | https://w3c.studio24.net/updates/on-not-choosing-wordpress/ | <a href="https://web.archive.org/web/*/https://w3c.studio24.net/updates/on-not-choosing-wordpress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="0"> <div>  <div class="page"> <div id="main-content" role="main">  <p> <span>Updates</span> <span>CMS</span> </p>  <hr> <p>The W3C redesign project is an incredibly exciting one for us at Studio 24, it’s an honour to be working with an organisation we have looked up to for our whole career. But it’s also challenging, with many aspects coming under more scrutiny than we’re normally used to. It’s also made harder in this time of pandemic, with increased anxiety and challenges working effectively during this “new normal” we’re all living in.</p> <p>We’re happy to rise to this challenge. Yesterday a well written article was published by WordPress Tavern on <a href="https://wptavern.com/w3c-drops-wordpress-from-consideration-for-redesign-narrows-cms-shortlist-to-statamic-and-craft">W3C dropping WordPress from consideration</a> which I’d like to respond to.</p> <h2 id="in-context-of-the-project"> <a href="#in-context-of-the-project"></a> In context of the project </h2> <p>We’ve tackled a huge variety of work so far from initial Discovery, User Research, Information Architecture, Content Design and UX Design that has helped move the project forward.</p> <p>The CMS platform decision is just part of this and for the end website is one of the less visible aspects. As you can read from <a href="https://w3c.studio24.net/docs/cms-selection-report/">Marie’s report on the work we did to choose Craft CMS</a> you can see the steps we went through to help shortlist and choose a CMS.</p> <p>For us, and the requirements from W3C, the delivery of accessible HTML/CSS pages that meet user needs is the most important part of this project - and where we are focussing our time. All in, we spent around 15 days on the CMS platform choice. Enough to help evaluate a limited number of options, but not enough to do a thorough review of the state of accessibility in a wide range of CMSs.</p> <p>We were surprised by the accessibility issues that cropped up in CMS platforms after our <a href="https://w3c.studio24.net/docs/w3c-cms-selection-process-update/">initial CMS review</a>. This prompted us to prioritise accessibility above other requirements due to the <a href="https://www.w3.org/Consortium/mission#principles">principles and values of W3C</a>.</p> <h2 id="challenges-of-gutenberg-for-now"> <a href="#challenges-of-gutenberg-for-now"></a> Challenges of Gutenberg (for now) </h2> <p><a href="https://www.studio24.net/">Studio 24</a> is a firm supporter of open source software and we use <a href="https://www.wordpress.org/">WordPress</a> extensively for our client work. For this project we had committed to not selecting a CMS until we’d had the chance to better understand client requirements.</p> <p>An important consideration for WordPress was accessibility concerns with the new Gutenberg editor. Many have written about the <a href="https://www.marcozehe.de/my-thoughts-on-gutenberg-accessibility/">accessibility issues</a> the project has had as well as the positive <a href="https://www.marcozehe.de/whats-new-for-accessibility-in-gutenberg-7-2/">steps to improve accessibility in Gutenberg</a>.</p> <p>Gutenberg is an exciting and really interesting development. Many CMS vendors are looking at ways to allow editors to create more flexible content from compontents or blocks. However, this comes with huge challenges on how to make innovative user interfaces accessible. WordPress decided to use the JavaScript framework <a href="https://reactjs.org/">React</a> to meet these needs.</p> <p>We <a href="https://medium.com/studio24/we-tried-converting-a-bespoke-website-design-in-wordpress-with-gutenberg-42e11986b05a">tested Gutenberg</a> six months before it was released in WordPress 5. Recently we worked on a project for the University of Cambridge creating a site for their <a href="https://magazine.alumni.cam.ac.uk/">Alumni magazine</a>. This launched in April 2020 and uses Gutenberg to manage content. This gave us a good idea of how Gutenberg works. In June, we reviewed the current accessibility issue backlog (<a href="https://github.com/WordPress/gutenberg/labels/Accessibility%20%28a11y%29">issues</a>, <a href="https://github.com/WordPress/gutenberg/projects/25">a11y project</a>) and had some feedback from users with accessibility needs who had difficulties using the current user interface. This was a contributing factor in our decision that WordPress was not a good fit for this project.</p> <p>Given the importance the WordPress project has put on Gutenberg as the future of WordPress we did not feel it was reasonable to recommend using the Classic Editor if there is a good chance this will not be supported in the future. At present <a href="https://make.wordpress.org/core/2018/11/07/classic-editor-plugin-support-window/">Classic Editor is slated for end of life in Dec 2021</a>.</p> <p>We look forward to the continued development of Gutenberg and applaud efforts to make it more accessible. We appreciate improvements have been made since our review and we’re very glad to see the <a href="https://wpaccessibilityday.org/">WordPress Accessibility Day</a> on 2nd October.</p> <h2 id="front-end-complexity"> <a href="#front-end-complexity"></a> Front-end complexity </h2> <p>From a business perspective I also believe Gutenberg creates a complexity issue that makes it challenging for use by many agencies who create custom websites for clients; where we have a need to create lots of bespoke blocks and page elements for individual client projects.</p> <p>The use of React complicates front-end build. We have very talented front-end developers, however, they are not React experts - nor should they need to be. I believe front-end should be built as standards-compliant HTML/CSS with JavaScript used to enrich functionality where necessary and appropriate.</p> <p>As of yet, we have not found a satisfactory (and profitable) way to build custom Gutenberg blocks for commercial projects. We won’t stop trying though and plan to do more R&amp;D with Gutenberg in the future. The W3C project, however, did not feel like the right place to do this. On a project as wide-ranging as this one, development time does become a factor.</p> <p>Drupal also has this complexity issue which makes developing sites harder than it needs to be, and is why we didn’t consider that platform either. I’ve talked to <a href="https://torchbox.com/blog/torchbox-has-dropped-drupal/">other agencies who have decided to drop Drupal</a> due to its complexity.</p> <h2 id="the-question-of-open-source"> <a href="#the-question-of-open-source"></a> The question of open source </h2> <p>The W3C embraces and supports the open web. However, as an agency we also have to be practical when it comes to the tools we use to build sites. From our review, which was focussed on PHP-based CMSs, Craft and Statamic came out as meeting all the key requirements and are both very developer-friendly platforms. An important consideration for a tool that we need to hand over to W3C to maintain in the future.</p> <p>While their <a href="https://github.com/craftcms/cms">source code</a> is open, they do have commercial licenses and cost money (though a modest sum). Charging money enables small teams to develop good software, so we’re not ideologically against this business model. Both platforms are well respected in the community and well-used by professionals, running sites such as <a href="https://media.netflix.com/en/">Netflix</a> and <a href="https://www.bigcommerce.com/">Big Commerce</a> in Craft, <a href="https://www.spiegel.de/plus/">Spiegel Plus</a> and <a href="https://www.freshbooks.com/">FreshBooks</a> in Statamic.</p> <p>We are using open source technology in the majority of this project (HTML/CSS, JavaScript, PHP, Symfony). While Craft is a proprietary CMS, this has given us the advantage of direct access to the team developing the CMS which has helped improve accessibility in these CMSs. We hope this helps move accessibility forward in the CMS industry.</p> <p>Open tools will continue to be used to publish the standards of the web. The <a href="https://www.w3.org/TR/">Technical Reports</a> page is powered by <a href="https://symfony.com/">Symfony</a> and specifications will continue to be published to <a href="https://github.com/w3c">GitHub</a> to facilitate open discussion. Nothing’s changing with how the W3C work in the open.</p> <h2 id="a-note-on-front-end-delivery"> <a href="#a-note-on-front-end-delivery"></a> A note on front-end delivery </h2> <p>One final note. We are currently considering a <a href="https://www.studio24.net/blog/what-is-a-headless-cms/">Headless CMS</a> option for front-end page delivery. This means using the CMS in a decoupled way to manage content but use a separate system to deliver front-end pages. Please note this solution would not be reliant on JavaScript (e.g. a single page app which is common with headless). Under this option we’d use Symfony to deliver front-end pages which is an established technology W3C already use across a lot of the site.</p> <p>This may give W3C better flexibility for the future, though comes at a cost of added complexity. The W3C site is already made up of a lot of different systems, the CMS is just one part of the what makes up the varied content on <a href="https://www.w3.org/">w3.org</a>.</p> <p>I hope this helps explain the thought process behind our decision a little more and addresses some of the valid concerns highlighted in the WordPress Tavern post.</p> <hr>  </div> </div> </div> </div></div>]]>
            </description>
            <link>https://w3c.studio24.net/updates/on-not-choosing-wordpress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596769</guid>
            <pubDate>Sat, 26 Sep 2020 06:05:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's talk about safety of Pinephone]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24596248">thread link</a>) | @lostmsu
<br/>
September 25, 2020 | https://xnux.eu/log/#017 | <a href="https://web.archive.org/web/*/https://xnux.eu/log/#017">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<ul>
	<li><a href="#019">2020–09–20: Downsizing the multi-boot image</a></li>
	<li><a href="#018">2020–09–20: Some ways to improve Pinephone safety</a></li>
	<li><a href="#017">2020–09–18: Let's talk about safety of Pinephone</a></li>
	<li><a href="#016">2020–09–17: Video acceleration experiments with PinePhone</a></li>
	<li><a href="#015">2020–09–16: PineBook Pro and Levinboot again</a></li>
	<li><a href="#014">2020–09–14: Putting 13 PinePhone distributions on a 8GiB uSD card</a></li>
	<li><a href="#013">2020–09–11: Adding postmarket OS to multi-distro image</a></li>
	<li><a href="#012">2020–09–11: Ways to help improve Pinephone kernel</a></li>
	<li><a href="#011">2020–09–11: PinePhone multi-boot image deduplication tool complete</a></li>
	<li><a href="#010">2020–09–10: PinePhone multi-boot image deduplication</a></li>
	<li><a href="#009">2020–09–08: PinePhone multi-boot finishing touches / modem improvements</a></li>
	<li><a href="#008">2020–09–08: PinePhone multi-boot image optimizations</a></li>
	<li><a href="#007">2020–09–07: PinePhone multi-boot image boot testing</a></li>
	<li><a href="#006">2020–09–05: PinePhone multi-boot image</a></li>
	<li><a href="#005">2020–09–04: Pinebook Pro and Levinboot</a></li>
	<li><a href="#004">2020–09–02: Progress on the multi-boot image</a></li>
	<li><a href="#003">2020–09–01: More p-boot cleanups and an example configuration</a></li>
	<li><a href="#002">2020–08–31: Releasing p-boot GUI bootloader</a></li>
	<li><a href="#001">2020–08–31: Getting started</a></li>
</ul>

<article id="019">
<h2 id="toc-2020-09-20-downsizing-the-multi-boot-image">2020–09–20:
Downsizing the multi-boot image</h2>

<p>If the multi-boot image doesn't fit your 8GiB uSD card, because it's&nbsp;a tad
too big, you can downsize it a bit by using this script:</p>

<pre><span>#!/bin/bash</span>

<span>set -e -x</span>

<span>mkdir</span> <span>-p</span> m
L<span>=</span><span>`losetup -P --show -f multi.img`</span>
mount <span>-o</span> <span>compress</span><span>-force</span><span>=</span>zstd <span>${L}</span>p2 m
btrfs filesystem resize <span>7000</span>M m
<span>echo</span> <span>",7000M"</span> <span>|</span> sfdisk <span>-N</span> <span>2</span> <span>${L}</span>
umount m
losetup <span>-d</span> <span>"</span><span>$L</span><span>"</span>

truncate <span>-s</span> <span>$((128+7000)</span><span>)</span>M multi.img
</pre>

<p>If something fails in the middle, you may need to recover by calling
<code>umount</code> and <code>losetup -d</code> yourself.
<code>losetup -l</code> can tell you if the image is still exported as a loop
device, and which&nbsp;one.</p>

<p>The image will have the size of 7128&nbsp;MiB after resize and this should fit
more „8“ giga something uSD cards, as there are obviously some other giga
units than gigabyte and gigibyte used by some manufacturers.</p>
</article>

<article id="018">
<h2 id="toc-2020-09-20-some-ways-to-improve-pinephone-safety">2020–09–20:
Some ways to improve Pinephone safety</h2>

<p>This is a follow up on some issues from the previous article. On surface,
solutions to some of the previously presented issues can seem simple. Toggle a
few registers in PMIC, and we're mostly done. Trouble is that safety mechanisms
are barely ever triggered, by definition. Safety events occur rarely. That means
that the mechanisms are not regularly tested, and it is not known that
they&nbsp;work.</p>

<p>Also it's&nbsp;not clear which code's&nbsp;responsibility fixing the issues should
be. Bootloader, or kernel, or userspace? Finally, there are a bunch of devils in
the details, that complicate the upstreamability of any solution. And having
fixes upstream is necessary to make sure they reach the most&nbsp;users.</p>

<h3 id="toc-necessary-minimum">Necessary minimum</h3>

<p>Nevertheless, at least enabling some pre-existing PMIC functionality blindly
is better than nothing, so that's&nbsp;precisely what I&nbsp;decided to do <a href="https://megous.com/git/p-boot/commit/?id=db73ff85c60944207b7f7368e554003494148a05">in
p-boot</a>. It's&nbsp;the easiest place to start resolving these issues for me
personally, and for other p-boot&nbsp;users.</p>

<p>I&nbsp;fixed two issues:</p>

<ul>
	<li>I&nbsp;enabled the battery temperature monitoring and charging regulation based
	on temperature thresholds defined in the Pinephone battery specification.</li>

	<li>I&nbsp;enabled emergency shutdown when crossing the critical temperature
	of&nbsp;PMIC.</li>
</ul>

<p>I&nbsp;didn't measure the 3kOhm NTC used in Pinephone battery and third party
batteries I&nbsp;bought. I&nbsp;just used a table from some random 3kOhm NTC spec on The
Internet, that seemed like it could match. Hopefully it's&nbsp;close enough.</p>

<p>Trouble with the second fix is that it's&nbsp;a hard power cut-off, so data loss
may occur when PMIC overheats. There are three fixed temperature levels in
AXP803. On level 1&nbsp;the charging is limited, on level 2&nbsp;the interrupt is sent
to SoC, on level 3&nbsp;the PMIC shuts down if configured to do so (by default it
keeps running, and this is what my p-boot fix changes). Ideally, the crossing of
level 2&nbsp;would be handled by Linux to make it safely shut down the system, and
level 3&nbsp;forced power cut-off would never happen. Arguably, if charging was
source of the heating, crossing level 1&nbsp;will lead to resolving the issue, so
the next level will not be reached.</p>

<h3 id="toc-suggested-fixes-elsewhere">Suggested fixes elsewhere</h3>

<p>These fixes will reach a very limited audience. It would be nice to have
these fixes in U-Boot too, but that's&nbsp;not possible at the moment, because
U-Boot doesn't have access to&nbsp;PMIC.</p>

<p>Other places to put the fix is to ATF or Linux kernel. That can reach more
people faster, but there would have to be some generic mechanism to make the fix
upstreamable, otherwise it will not reach people using the mainline Linux kernel
or mainline&nbsp;ATF.</p>

<p>There are some ways to approach this:</p>

<ul>
	<li>Use battery description in DT from <a href="https://github.com/ARM-software/arm-trusted-firmware">ATF</a> to set up
	thresholds in PMIC (ATF has access to&nbsp;PMIC).</li>

	<li>Use battery description in DT from Linux's&nbsp;battery charger driver for
	AXP803 to set up thresholds in PMIC and stop disabling temperature
	monitoring.</li>

	<li>Use <a href="https://elixir.bootlin.com/linux/latest/source/Documentation/devicetree/bindings/power/supply/charger-manager.txt">charger
	manager</a> in Linux, but that looks like it's&nbsp;a completely software solution,
	that will be inferior to PMIC handling the regulation. And it seems it would not
	work in system suspend, anyway, because Linux is not running&nbsp;then.</li>

	<li>Detect Pinephone compatible string in either ATF or Linux and set up the
	thresholds to ad-hoc values for 3kOhm NTC. (easiest, unlikely to be acceptable
	upstream)</li>
</ul>

<p>First, the most generic solution would be to have a description of the
battery in DT describing the Pinephone. Sadly, the <a href="https://elixir.bootlin.com/linux/v5.9-rc5/source/Documentation/devicetree/bindings/power/supply/battery.yaml">current
bindings</a> don't include battery temperature limits.</p>

<p>Also converting from temperature to NTC resistance (which is necessary to
determine the code word from ADC for the limits used by the temperature monitor
logic in PMIC) is not straightforward. It is usually defined in NTC datasheet as
a table. Do I&nbsp;have NTC datasheet? No. I&nbsp;bought the batteries online from some
mobile phone service&nbsp;shop.</p>

<p>There are also equations that approximate the temperature&nbsp;– resistance
relationship for the NTC, which could be used instead of a fixed table, if one
knows the relevant coefficients. These can be calculated after measuring the
NTC's&nbsp;resistance at a few temperature points when we lack the datasheet.</p>

<p>So generic solution may look like this:</p>

<ul>
	<li>DT contains battery temperature limits from the battery&nbsp;spec</li>

	<li>DT contains NTC coefficients (perhaps also on the battery&nbsp;node)</li>

	<li>some routine would use all this info from DT to calculate code words used by
	AXP803 ADC and program them to PMIC (either in ATF, or&nbsp;Linux)</li>
</ul>

<p>Kernel also has support for NTC devices, so maybe NTC can be described
outside of the battery node (even though it's&nbsp;part of the battery).</p>

<p>This may all fail to be upstreamed on one thing: the battery is user
swappable, so it's&nbsp;arguably not part of the Pinephone, and describing it inside
the pinephone DT will not be appropriate.</p>

<p>I&nbsp;don't have any plans implementing any of the above, atm. Maybe with the
exception of adding a 4th approach to the fix to my Linux kernel (the easiest
one ;)). I'd like to work on my multi-boot image. So these are mostly pointers
for somebody else who'd like to tackle&nbsp;this.</p>

<h3 id="toc-other-issues">Other issues</h3>

<p>Fast charging is not necesary in many situations, so having it as a default
is not great. User should be able to decide if he wants to trade off slower,
safer charging and battery longetivity over speed. This tradeoff can be realized
in many&nbsp;ways.</p>

<p>All this is already controllable from userspace via sysfs. Ideally there
would be some charging monitoring daemon that would take into account
users's&nbsp;wishes and select proper strategy for charging, based on preference for
battery longetivity or&nbsp;speed.</p>

<p>There are several trade offs the deamon would be able to handle:</p>

<ul>
	<li>0.2C charging all the way (slow, but safer)</li>

	<li>0.5C charging to 40% and 0.2C charging to 100% (middle ground)</li>

	<li>0.5C charging all the way to 100%</li>
</ul>

<p>All this is decision making that doesn't belong to the kernel.</p>

<p>Similar daemon could monitor power usage of the phone and try to limit it to
safer levels, or warn the user if that's&nbsp;not possible.</p>
</article>

<article id="017">
<h2 id="toc-2020-09-18-let-s-talk-about-safety-of-pinephone">2020–09–18:
Let's&nbsp;talk about safety of Pinephone</h2>

<p>My gf read me some articles about exploding phones today. :) I&nbsp;think there
needs to be some serious conversation about Pinephone safety. Safety needs to
become an important concern now, when more and more people are getting their
Pinephones every month. It's&nbsp;just a matter of time before the first major
safety incident hits this community, and it may be more than just a hacked
store. It's&nbsp;just a numbers&nbsp;game.</p>

<p>Pinephone is an interesting device in one way. You can run whatever software
you like on it (and you do!), and this software comes almost universally with
<strong>zero</strong> guarantees. Read the license to any of the program you run
on your Pinephone and it will almost certainly tell&nbsp;you:</p>

<blockquote>
	<p>THIS SOFTWARE IS PROVIDED ``AS IS'' AND WITHOUT ANY EXPRESS OR IMPLIED
	WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
	MERCHANTABILITY AND FITNESS FOR A&nbsp;PARTICULAR PURPOSE.</p>
</blockquote>

<p>or</p>

<blockquote>
	<p>THIS SOFTWARE IS PROVIDED BY &lt;COPYRIGHT HOLDER&gt; AS IS AND ANY EXPRESS
	OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
	MERCHANTABILITY AND FITNESS FOR A&nbsp;PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
	EVENT SHALL &lt;COPYRIGHT HOLDER&gt; BE LIABLE FOR ANY DIRECT, INDIRECT,
	INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES</p>
</blockquote>

<p>or</p>

<blockquote>
	<p>This program is distributed in the hope that it will be useful, but WITHOUT
	ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
	FOR A&nbsp;PARTICULAR PURPOSE. See the GNU General Public License for more
	details.</p>
</blockquote>

<p>etc.</p>

<p>In case of Pinephone you have to take these warnings <strong>very
seriously</strong>, because this software is not provided by the manufacturer
(Pine64), and as far as I&nbsp;know, there's&nbsp;no software related safety testing
going on at&nbsp;all.</p>

<h3 id="toc-some-skeletons-hiding-at-the-lower-levels">Some skeletons, hiding at
the lower levels…</h3>

<p>I'll give you a few reasons why things may not be so rosy, when it comes to
safety.</p>

<p>There's&nbsp;no unchangeable well tested guardian angel management engine that
safely manages battery, power supplies, thermal behavior, that is provided by
the manufacturer, and that is independent of the operating system.</p>

<p>Pinephone's&nbsp;SoC is quite bare when it comes to software/firmware
(that's&nbsp;why FOSS enthusiasts like it, no blobs, you know!). This has a dark</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xnux.eu/log/#017">https://xnux.eu/log/#017</a></em></p>]]>
            </description>
            <link>https://xnux.eu/log/#017</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596248</guid>
            <pubDate>Sat, 26 Sep 2020 03:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculus in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24594833">thread link</a>) | @Lukas1994
<br/>
September 25, 2020 | https://www.causal.app/blog/calculus-in-saas | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/calculus-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a>‍</p><p>I have been studying the SaaS model in depth for almost 7 years now. Since the day <a href="https://alexoppenheimer.substack.com/p/harry-2d5d1af6bf">Harry Weller</a> walked into my office with a stack of materials and told me to study it and then SaaS build models and bring them to portfolio companies, I don't think a day has gone by where I have not thought about the conceptual and operational nuances of the recurring revenue business model.</p><p>Somewhere around mid 2015 I had my "aha" moment in my research when I tied my academic training in mechanical engineering to the startup business models I was building: it's all calculus. The integral-derivative relationship applies incredibly well to the ARR and Recognized Revenue relationship. Making this connection between engineering math and financial math gave me a feeling that only a true nerd could appreciate: the joy of putting integral symbols and accounting terms on the same slide.</p><p>The simplest way to illustrate this mathematical parallel is with a car:</p><figure id="w-node-2abd43418357-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b33c9e3271323643b3d_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F42d5ef92-52d9-49fe-8be7-16028bee1ff4_884x306.png" alt=""></p></figure><p>If a car is moving at 60mph, then in one hour it will travel 60 miles (assuming its speed does not change). That is the definition of "miles per hour." ARR is very similar: if a company is "moving" at $10M ARR, then in one year it will recognize $10M of revenue (assuming everything stays consistent). Recognized revenue is the distance, ARR is the speed. It's critical to recognize that ARR is a rate at a specific point in time used to imply something (here, expected recognized revenue in the future period).</p><p>For the more accounting oriented, another analogy can be made to the balance sheet:</p><figure id="w-node-9fc87f218c80-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b3392b0138c4e64006b_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F6c06ddcc-de3e-4d96-960a-22b4b39e334e_842x455.png" alt=""></p></figure><p>While revenue is the top line metric on the income statement, ARR works more like a balance sheet metric: it is taken at a single point in time rather than over a period of time. This can make income statements confusing and misaligned - another example of the divergence of accounting in economics in subscription businesses.</p><p>Now back to calculus... if the ARR function was actually a mathematical equation, you could integrate it. If y = 10x where y = ARR and x = time in months, then after two months ARR = $20. After 12 months, ARR = $120 (assuming we start from $0 of ARR). So at the end of a year, the business has grown from $0 to $120 in ARR. But what is the recognized revenue? The complex answer is that it's the integral of 10x from 0 to 12 months. (Apologies in advance if this triggers a high school calculus flashback.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b337d3c7911d7362b81_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Ff7fcb57f-644b-490c-bfa8-6d0c986d2fda_305x80.png" alt=""></p></figure><p>You could also chart this out and see that it is a right triangle with the area of 1/2*base*height. Where the base is 12 months and the height is $120: $1,440/2 = $720).</p><p>Pretty cool relationship and calculation conceptually, but in real businesses ARR growth doesn't fit a simple equation (or any equation at all), so it's not inherently practical to start breaking out the power rule and your old textbooks to predict ARR growth.</p><p>If we switch back to the car analogy, it takes on a little more of a nuanced meaning. Just like a business doesn't grow on a smooth curve, car speeds do not either. Just like the gas pedal makes the car go faster and the brake pedal &amp; friction make it go slower, so too in a SaaS company, <a href="https://alexoppenheimer.substack.com/p/thin-slicing-arr">the new sales are making the speed/ARR increase and the churned customers are making the speed/ARR decrease</a>. I will dive into more details in later posts, but the goal in a car is to go as far and fast as you can while burning the least amount of fuel. So too in a SaaS company, the goal is to have the highest ARR you can, recognize the most revenue and burn the least cash. You can think about SaaS Magic Number like the fuel efficiency of a SaaS business - looking forward to diving into why this is actually helpful in building a company.</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/calculus-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594833</guid>
            <pubDate>Fri, 25 Sep 2020 22:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers for Assange Open Letter to the UK Prime Minister et al.]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594374">thread link</a>) | @jstanley
<br/>
September 25, 2020 | https://www.lawyersforassange.org/en/open-letter.html | <a href="https://web.archive.org/web/*/https://www.lawyersforassange.org/en/open-letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>14 August 2020</strong></p>



<p><strong>Dear Prime Minister, </strong></p>

<p><strong>Dear Lord Chancellor and Secretary of State for Justice,</strong></p>

<p><strong>Dear Secretary of State for Foreign Affairs,</strong></p>

<p><strong>Dear Home Secretary,</strong></p>





<p>We write to you as legal practitioners and legal academics to express our collective concerns about the violations of Mr. Julian Assange’s fundamental human, civil and political rights and the precedent his persecution is setting.</p>



<p>We call on you to act in accordance with national and international law, human rights and the rule of law by bringing an end to the ongoing extradition proceedings and granting Mr. Assange his long overdue freedom – freedom from torture, arbitrary detention and deprivation of liberty, and political persecution.</p>



<ol>
	<li><strong>ILLEGALITY OF POTENTIAL EXTRADITION TO THE UNITED STATES</strong></li>
</ol>



<p><strong>Extradition of Mr. Assange from the UK to the US would be illegal on the following grounds: </strong></p>



<ol>
	<li><strong>Risk of being subjected to an unfair trial in the US</strong></li>
</ol>



<p>Extradition would be unlawful owing to failure to ensure the protection of Mr. Assange’s fundamental trial rights in the US. Mr. Assange faces show trial at the infamous “Espionage court” of the Eastern District of Virginia, before which no national security defendant has ever succeeded. Here, he faces secret proceedings before a jury picked from a population in which most of the individuals eligible for jury selection work for, or are connected to, the CIA, NSA, DOD or DOS.<a href="#_edn1" name="_ednref1" title=""><sup><sup>[i]</sup></sup></a></p>



<p>Furthermore, Mr. Assange’s<strong> </strong>legal privilege, a right enshrined in Art. 8 European Convention on Human Rights (ECHR) and long recognised under English common law, was grossly violated through<strong> </strong>constant and criminal video and audio surveillance at the Ecuadorian embassy carried out by the Spanish security firm, UC Global. This surveillance was, according to witness testimony, ordered by the CIA and has triggered an investigation into the owner of UC Global, David Morales, by Spain’s High Court, the Audiencia Nacional.<a href="#_edn2" name="_ednref2" title="">[ii]</a> The surveillance resulted in all of Mr. Assange’s meetings and conversations being recorded, including those with his lawyers. The Council of Bar and Law Societies of Europe, which represents more than a million European lawyers, has expressed its concerns that these illegal recordings may be used – openly or secretly – in proceedings against Mr. Assange in the event of successful extradition to the US. The Council states that if the information merely became known to the prosecutors, this would present an irremediable breach of Mr. Assange’s fundamental rights to a fair trial under Art. 6 of the ECHR and due process under the US Constitution.<a href="#_edn3" name="_ednref3" title=""><sup><sup>[iii]</sup></sup></a> Furthermore, the prosecuting state obtained the totality of Mr. Assange’s legal papers after their unlawful seizure in the Embassy. Upon hearing that the Government of Ecuador was planning to seize and hand over personal belongings of Mr. Assange, including documents, telephones, electronic devices, memory drives, etc. to the US, the UN Special Rapporteur on Privacy, Joseph Cannataci, expressed his serious concern to the Ecuadorian government and twice formally requested it to return Mr. Assange's personal effects to his lawyers, to no avail.<a href="#_edn4" name="_ednref4" title=""><sup><sup>[iv]</sup></sup></a> <strong>The UN Model Treaty on Extradition prohibits extradition if the person has not received, or would not receive, the minimum guarantees in criminal proceedings, as enshrined in Art. 14 of the International Covenant on Civil and Political Rights (ICCPR).</strong><a href="#_edn5" name="_ednref5" title=""><sup><sup>[v]</sup></sup></a></p>



<ol start="2">
	<li><strong>The political nature of the offence prohibits extradition</strong></li>
</ol>



<p>The US superseding indictment issued against Mr. Assange on the 24 June 2020 charges him with 18 counts all related solely to the 2010 publications of US government documents. The publications, comprising information about the wars in Iraq and Afghanistan, US diplomatic cables and Guantanamo Bay, revealed evidence of war crimes, corruption and governmental malfeasance.<a href="#_edn6" name="_ednref6" title=""><sup><sup>[vi]</sup></sup></a></p>



<p>Charges 1-17 are brought under the Espionage Act 1917, which, in name alone, reveals the political and antiquated nature of the charges.<a href="#_edn7" name="_ednref7" title=""><sup><sup>[vii]</sup></sup></a><strong> </strong>Furthermore, the essence of the 18 charges concerns Mr. Assange’s alleged intention to obtain or disclose US state “secrets” in a manner that was damaging to the strategic and national security interests of the US state, to the capability of its armed forces, the work of the security and intelligence services of the US, and to the interests of the US abroad. Thus, the conduct, motivation and purpose attributed to Mr. Assange confirm the political character of the 17 charges brought under the Espionage Act (‘pure political’ offences) and of the hacking charge (a ‘relative political’ offence). In addition, several US government officials have at various times ascribed motives “hostile” to the US to Mr. Assange, an Australian citizen.<a href="#_edn8" name="_ednref8" title=""><sup><sup>[viii]</sup></sup></a> <strong>The UK-US Extradition Treaty, which provides the very basis of the extradition request, specifically prohibits extradition for political offences in Art. 4(1). </strong>Yet the presiding judge and prosecution wish to simply disregard this article by referring to the Extradition Act 2003 (“EA”) instead, which does not include the political offence exception. This blatantly ignores the fact that the EA is merely an enabling act that creates the minimum statutory safeguards, but it does not preclude stronger protections from extradition as expressly provided in subsequently ratified treaties such as the UK-US Extradition Treaty. <strong>Furthermore, there is broad international consensus that political offences should not be the basis of extradition.<a href="#_edn9" name="_ednref9" title=""><sup><strong><sup>[ix]</sup></strong></sup></a> This is reflected in Art. 3 of the 1957 European Convention on Extradition, Art. 3 ECHR, Art. 3(a) of the UN Model Treaty on Extradition, the Interpol Constitution and every bilateral treaty ratified by the US for over a century.</strong></p>



<ol start="3">
	<li><strong>Risk of torture or other cruel, inhuman or degrading treatment or punishment in the US</strong></li>
</ol>



<p>The United Nations Special Rapporteur on Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (“the UN Rapporteur on Torture”), Professor Nils Melzer, has expressed with certainty that, if extradited to the US, Mr. Assange will be exposed to torture or other cruel, inhuman or degrading treatment or punishment. Similar concerns have also been raised by the UN Working Group on Arbitrary Detention, and Amnesty International has recently restated its concerns in relation to the unacceptable risk of mistreatment.<a href="#_edn10" name="_ednref10" title=""><sup><sup>[x]</sup></sup></a></p>



<p>The detention conditions, and the draconian punishment of 175 years, in a maximum security prison, which Mr. Assange faces under the US indictment, would constitute torture or other cruel, inhuman or degrading treatment or punishment, according to the current UN Rapporteur on Torture and according to the<strong> </strong>consistently expressed opinion of his predecessor, as well as of NGOs and legal authorities.<a href="#_edn11" name="_ednref11" title=""><sup><sup>[xi]</sup></sup></a></p>



<p>If extradited, Mr. Assange would, by the US government’s own admission, likely be placed under Special Administrative Measures. These measures prohibit prisoners from contact or communication with all but a few approved individuals, and any approved individuals would not be permitted to report information concerning the prisoner’s treatment to the public, thereby shielding potential torture from public scrutiny and government from accountability.<a href="#_edn12" name="_ednref12" title=""><sup><sup>[xii]</sup></sup></a></p>



<p><strong>Under the principle of non-refoulement, it is not permissible to extradite a person to a country in which there are substantial grounds for</strong> <strong>believing that they would be subjected to torture. This principle is enshrined in the 1951 UN Convention Relating to the Status of Refugees, specifically Art. 33(1) from which no derogations are permitted. Also relevant are Art. 3(1) UN Declaration on Territorial Asylum 1967, Art. 3 of the Convention against Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (CAT)</strong>,<strong> and Art. 2 of the Resolution on Asylum to Persons in Danger of Persecution, adopted by the Committee of Ministers of the Council of Europe in 1967. As an obligation arising from the prohibition of torture, the principle of non-refoulement in this area is absolute and also takes on the character of a peremptory norm of customary international law, i.e. jus cogens.<a href="#_edn13" name="_ednref13" title=""><sup><strong><sup>[xiii]</sup></strong></sup></a></strong></p>



<p><strong>Mr. Assange, who was accepted as a political asylee by the Ecuadorian government owing to what have proved to have been wholly legitimate fears of political persecution and torture in the US, should clearly have been accorded protection of this principle, firstly by Ecuador and secondly by the UK. Ecuador violated its human rights obligations by summarily rescinding Mr. Assange’s asylum in direct contradiction of the ‘Latin American tradition of asylum’<a href="#_edn14" name="_ednref14" title=""><sup><strong><sup>[xiv]</sup></strong></sup></a> and the Advisory Opinion </strong><strong>OC-25/18 of 30 May 2018 of the Inter-American Court of Human Rights affirming the principle of non-refoulement in cases of persons who have entered an embassy for protection.<a href="#_edn15" name="_ednref15" title=""><sup><strong><sup>[xv]</sup></strong></sup></a> The entry of the Ecuadorian Embassy by UK police and the arrest of Mr. Assange were thus based on an illegal revocation of his nationality and asylum, which can only be rectified by the UK upholding its own duty to protect the principle of non-refoulement by denying extradition to the US.</strong></p>



<p><strong>B) VIOLATIONS OF THE FREEDOM OF THE PRESS AND THE RIGHT TO KNOW</strong></p>



<p>Counts 1-17 of the indictment under the Espionage Act violate the right to freedom of expression, the right to freedom of the press and the right to know. These counts present standard and necessary investigative journalistic practices as criminal.<a href="#_edn16" name="_ednref16" title=""><sup><sup>[xvi]</sup></sup></a> Such practices include indicating availability to receive information, indicating what information is of interest, encouraging the provision of information, receipt of information for the purpose of publication, and publication of information in the public interest.</p>



<p>Under the charge of conspiracy to commit computer intrusion, the initial indictment criminalised also Mr. Assange’s alleged attempt at helping his source to maintain their anonymity while providing the documents in question, which falls squarely under the standard journalistic practice and duty of protecting the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lawyersforassange.org/en/open-letter.html">https://www.lawyersforassange.org/en/open-letter.html</a></em></p>]]>
            </description>
            <link>https://www.lawyersforassange.org/en/open-letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594374</guid>
            <pubDate>Fri, 25 Sep 2020 21:37:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Deafening Silence of the Royal Society Open Science Journal]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24593465">thread link</a>) | @mathgenius
<br/>
September 25, 2020 | https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/ | <a href="https://web.archive.org/web/*/https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Florin Moldoveanu researches the foundation of quantum mechanics with emphasis on quantum mechanics reconstruction and solving the measurement problem. After getting his PhD in theoretical physics at the University of Maryland at College Park in 1999, he pursued a career in industry. Three years ago he started the transition back from industry to academia and became an adjunct professor at George Mason University. His earlier graduate student research papers in theoretical physics received 267 citations to date.</p><hr><p>More than two years ago, on February 26<sup>th</sup> 2018, I was contacted by the <strong>Royal Society Open Science Journal</strong> to referee a submitted manuscript. Two prior referees had accepted the paper and two had rejected it, and I was the tiebreaker. The manuscript, <em>Quantum Correlations are Weaved by the Spinors of the Euclidean Primitives</em> by Joy Christian, basically claims that Bell’s theorem is incorrect. If true, this would be a game changer in the foundation of quantum mechanics. Bell’s theorem shows that it is impossible to construct a local realistic model of the theory.</p><p>Bell’s result is an impossibility proof; it attracts such passion as the impossibility of perpetual motion machines that were so popular some 100 years ago. A manuscript claiming the invention of a working perpetual motion device, proof that Earth is flat (yes, there is such a thing as an annual conference of Flat-Earth-ers), or that the sun circles Earth would be rejected by any respectable journal right away.</p><p>So, what if someone managed to “disprove” Bell’s theorem and, better yet, to publish that “discovery”? This would create lots of debates and excitement – certainly, notoriety and free publicity for the journal who published your claim. In other words, good business.</p><p>But who is claiming to have “disproven” Bell theorem? Enter Joy Christian, who has been asserting this claim for 13 years. It was debunked by many scientists and scientific panels over the years, yet Christian is not having any of it. Basically, he alleges to have found a method for obtaining the quantum correlation of a Bell pair of particles, by using a Bell “loophole”. In the no-mans-land at the intersection of physics, mathematics, and philosophy, experts in all three fields are scarce. Christian’s ‘method’ is based on a mathematical error, which is ultimately adding apples and oranges, but the error is hard to spot if you are not a genuine expert in geometric algebra. Add to this the language and structure of a well-written physics paper and you might convince an unsuspecting referee to approve your manuscript.</p><p>I had found Christian’s mistake again in the manuscript and I recommended to reject the paper. Certain that it would never be published, I went about my daily business. Imagine my surprise when I heard Christian had somehow managed to publish his nonsense. I thought this impossible; the vote had been 3 to 2 for rejection. I checked and found that indeed, the paper had gotten accepted after submitting a revision. <strong>However,</strong><strong>I was not contacted by the journal to review the revision. </strong>I started contacting colleagues who had to deal with Joy’s claims before, and together with Philippe Grangier, Richard Gill, Howard Wiseman, Brukner Časlav, Gregor Weihs, and Scott Aaronson, in a letter to the journal on July 28<sup>th</sup> 2018, we asked that the article be withdrawn:</p><p><em>Dear Editor-in-Chief,</em></p><p><em>We are writing to you about the publication of the paper “Quantum Correlations are weaved by the spinors of the Euclidean primitives” by Joy Christian in your journal on May 30 2018&nbsp;</em><a href="http://rsos.royalsocietypublishing.org/content/5/5/180526" target="_blank"><em>http://rsos.royalsocietypublishing.org/content/5/5/180526</em></a></p><p><em>The result of this paper conflicts with an established scientific fact (Bell’s theorem) well known in the foundations of quantum physics and a basis of modern quantum information science; moreover, the subject of recent high-profile experiments (“loophole free tests of Bell’s theorem”). The paper contains numerous errors in elementary algebra, calculus, and logic. The manuscript was rejected by three of the five reviewers,&nbsp;but the editorial process as stated to the reviewers by your journal was not followed:&nbsp;the manuscript was accepted without informing the reviewers&nbsp;and giving them a chance to rebut the misleading statements made by the author (see review history on the link above).</em></p><p><em>The claims made by the author are well known from 2007 and they were disproven in the past (</em><a href="https://fqxi.org/community/forum/topic/1577" target="_blank"><em>https://fqxi.org/community/forum/topic/1577</em></a><em>&nbsp;). From time to time Joy Christian attempts to publish his faulty claims and recently a similar paper was withdrawn by Annals of Physics&nbsp;</em><a href="https://www.sciencedirect.com/science/article/pii/S0003491616300975" target="_blank"><em>https://www.sciencedirect.com/science/article/pii/S0003491616300975</em></a></p><p><em>The journal did extend an invitation to write a rebuttal paper but stated that Joy Christian would be a reviewer to the rebuttal. This is not an acceptable course of action from an ethical point of view because it legitimizes scientific dishonesty on behalf of Joy Christian who is well aware of the issues with his arguments for more than 10 years and yet continues to obfuscate the truth.</em></p><p><em>Considering this, we are respectfully asking your journal to withdraw the paper.</em></p><p><em>Sincerely,</em></p><p><em>Florin Moldoveanu&nbsp;- George Mason University (reviewer 5)</em></p><p><em>Richard Gill – Leiden University</em></p><p><em>Howard Wiseman – Griffith University (reviewer 3)</em></p><p><em>Scott Aaronson - University of Texas</em></p><p><em>Philippe Grangier - Institute of Optics, Charles Fabry Laboratory</em></p><p><em>Brukner Caslav - IQOQI - Institute for Quantum Optics and Quantum Information Vienna</em></p><p><em>Gregor Weihs – Innsbruck University</em></p><p>This was about two years ago. We kept asking for updates, and when not stonewalling us, the journal kept pushing one roadblock after another.</p><p>The <strong>Royal Society Open Science Journal had more than two years to get their act together. By now, their silence speaks louder than words.</strong></p><p>It is unconscionable that instead of putting extra checks in place for authors with a history of inaccurate publications, the journal violated their own peer review policy and chose to maintain a faulty paper instead of withdrawing it.</p><p>We gave the journal the benefit of the doubt for two years. The passing of time made it clear that the decision to maintain the faulty paper is no accident and no mistake.</p><p>Perhaps this is a symptom of a larger systemic problem with open journals who are paid by the authors to get their papers (usually rejected elsewhere) published. When your salary and livelihood depend on the people you are supposed to enforce rules upon, the temptation to bend those rules is high.</p><p>I grew up in a former communist country of the eastern bloc. At the time of communism, a rule supposed to be enforced by the traffic police was that if you pay for a traffic ticket on the spot, you will be charged with half the fine. You might guess that most officers pocketed that money. The rule only solidified endemic corruption.</p><p>In our case, the author is well known for making the same incorrect argument over and over again. However, <strong>the root of the problem seems to be with the journal</strong>. After all, had they followed their own policy, the problem would not have arisen in the first place. And in case the mistake was genuine (as sometimes mistakes do happen), is two years enough time to get the record straight? It makes me wonder: just how often did the editors turn a blind eye to publication issues to secure revenue? <strong>Is it really a good idea that those in charge of rule enforcement are financially dependent on the rule violators? </strong></p></div></div>]]>
            </description>
            <link>https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593465</guid>
            <pubDate>Fri, 25 Sep 2020 19:51:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists developed a technology for printing neuroprostheses on 3D bioprinter]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24593123">thread link</a>) | @rbanffy
<br/>
September 25, 2020 | https://english.spbu.ru/news/3891-scientists-developed-a-technology-for-printing-customised-neuroprostheses-on-a-3d-bioprinter | <a href="https://web.archive.org/web/*/https://english.spbu.ru/news/3891-scientists-developed-a-technology-for-printing-customised-neuroprostheses-on-a-3d-bioprinter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        
        
        
        
                        <div id="main-content">
       
            <section id="main">
                             	
            	
<div itemscope="" itemtype="https://schema.org/Article">
	<meta itemprop="inLanguage" content="en-GB">
	
		
			
					
		
						<dl>

		
			<dt>
									Details							</dt>

			
			
			
			
										<dd>
				
				<time datetime="2020-09-23T19:37:21+03:00" itemprop="datePublished">
					Published: 23 September 2020				</time>
			</dd>			
		
					
			
										<dd>
					
					<meta itemprop="interactionCount" content="UserPageVisits:92">
					Hits: 92			</dd>						</dl>
	
			
			
	
		
								<div itemprop="articleBody">
		<p>Researchers from St&nbsp;Petersburg University have developed the NeuroPrint soft neuroprosthesis 3D&nbsp;printing technology. In&nbsp;the long term, this can help paralyzed people after spinal cord injury. The new development has already shown its effectiveness in&nbsp;studies on&nbsp;mammals and zebrafish. The results are published in&nbsp;<!--noindex--><a href="https://www.nature.com/articles/s41551-020-00615-7" target="_blank" rel="1">Nature Biomedical Engineering</a><!--/noindex-->.</p>
<p>According to&nbsp;the World Health Organization, more than a&nbsp;billion people, that&nbsp;is, about&nbsp;15% of&nbsp;the world’s population, have various forms of&nbsp;disability. Every year, up&nbsp;to&nbsp;half a&nbsp;million people receive spinal cord injuries, which are often accompanied by&nbsp;paralysis, and disorders of&nbsp;autonomic functions. To&nbsp;find ways to&nbsp;restore health to&nbsp;people with disabilities, researchers are developing invasive neuroprostheses that can transmit electrical signals to&nbsp;the spinal cord and brain and recover lost functions.</p>
<p>One of&nbsp;the main challenges faced by&nbsp;doctors and scientists is&nbsp;the adjustment of&nbsp;neuroprostheses to&nbsp;the surrounding nerve tissues of&nbsp;a&nbsp;person. Despite the biocompatible elastic materials, it&nbsp;is&nbsp;not always possible to&nbsp;adapt quickly the device to&nbsp;the anatomical and age characteristics of&nbsp;the patient. The solution to&nbsp;this problem has been proposed by&nbsp;a&nbsp;research team headed by&nbsp;Professor Pavel Musienko from the Institute of&nbsp;Translational Biomedicine at&nbsp;St&nbsp;Petersburg University and Professor Ivan Minev from the University of&nbsp;Sheffield (the Department of&nbsp;Automatic Control and Systems Engineering, the University of&nbsp;Sheffield). They have developed a&nbsp;new 3D&nbsp;printing technology that makes it&nbsp;possible to&nbsp;rapidly customise muscular and neural implants for monitoring and restoring of&nbsp;motor and autonomic functions.</p>
<p>This patient-specific approach is&nbsp;now possible thanks to&nbsp;NeuroPrint hybrid 3D&nbsp;printing technology. First, the printer creates the geometry of&nbsp;the future implant made of&nbsp;silicone, which also serves as&nbsp;an&nbsp;insulating material. Then microparticles of&nbsp;platinum or&nbsp;another electrically conductive element of&nbsp;the implant are applied to&nbsp;the framework. Then the surface is&nbsp;activated by&nbsp;cold plasma. Moreover, the number and configuration of&nbsp;electrodes in&nbsp;the neural implant can be&nbsp;changed, producing devices for implantation in&nbsp;the tissue of&nbsp;the spinal cord, brain or&nbsp;muscles. The average production time from project creation to&nbsp;prototyping can be&nbsp;just 24&nbsp;hours.</p>
<p>‘By the developed technology, the process of&nbsp;creating implants can become a&nbsp;lot faster and cheaper,’ said Professor Pavel Musienko, Head of&nbsp;the Laboratory of&nbsp;Neuroprosthetics at&nbsp;the Institute of&nbsp;Translational Biomedicine, St&nbsp;Petersburg University. ‘Considering the compactness of&nbsp;the equipment and the versatility of&nbsp;the approach, it&nbsp;is&nbsp;quite likely that in&nbsp;the future it&nbsp;will be&nbsp;possible to&nbsp;produce patient-specific neural implants right in&nbsp;the hospital. This follows the principles of&nbsp;personalized medicine and will minimise the cost and delivery time as&nbsp;much as&nbsp;possible.’</p>
<p>Neuroscientists have already exploited the NeuroPrint technology to&nbsp;carry out research on&nbsp;various model objects&nbsp;— mammals and zebrafish. It&nbsp;has shown that the new neural implants have a&nbsp;high level of&nbsp;biointegration and functional stability. Also, they are as&nbsp;good as&nbsp;their counterparts when they are used to&nbsp;restore motor functions of&nbsp;the limbs and monitor the bladder activity. Additionally, the scientists have been able to&nbsp;print soft implants similar in&nbsp;shape and mechanical characteristics to&nbsp;the dura mater&nbsp;— outer connective tissue membrane of&nbsp;the brain. This is&nbsp;an&nbsp;important achievement, since many scientific experiments cannot be&nbsp;carried out due to&nbsp;too rigid neuronal implants that are not suitable for the soft structures of&nbsp;the nervous tissue. Moreover, this limits their use in&nbsp;clinical practice.</p>
<p>‘We have tested our development in&nbsp;experiments on&nbsp;freely moving rats for chronic recording of&nbsp;the electrocortical signals of&nbsp;the cerebral cortex, that is&nbsp;a&nbsp;necessary element of&nbsp;the brain-computer interface,’ said Pavel Musienko. ‘The experiments on&nbsp;paralysed animals have shown that electrical stimulation of&nbsp;neural networks effectively restores locomotor function. Thus, the NeuroPrint technology opens up&nbsp;new opportunities both for basic research into the central nervous system and for neuroprosthetics when people suffer from various diseases and injuries.’</p>
<p>Among the participants of&nbsp;the research are scientists from: St&nbsp;Petersburg University; Pavlov Institute of&nbsp;Physiology of&nbsp;the Russian Academy of&nbsp;Sciences; Granov Russian Research Centre of&nbsp;Radiology and Surgical Technologies; St&nbsp;Petersburg State Research Institute of&nbsp;Phthisiopulmonology of&nbsp;the Ministry of&nbsp;Health of&nbsp;the Russian Federation; Ural Federal University; Technische Universität Dresden (Germany); and the University of&nbsp;Sheffield (the UK).</p>
<p><strong>For reference:</strong></p>
<p>The research has been supported by&nbsp;grants from: St&nbsp;Petersburg University; European Research Council; Technische Universität Dresden; the Russian Foundation for Basic Research; the German Research Foundation (the Deutsche Forschungsgemeinschaft); and Volkswagen Foundation.</p> 	</div>

	
							</div>

                                     
            </section>                 
              
        
                  
        </div>
                                
    </div></div>]]>
            </description>
            <link>https://english.spbu.ru/news/3891-scientists-developed-a-technology-for-printing-customised-neuroprostheses-on-a-3d-bioprinter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593123</guid>
            <pubDate>Fri, 25 Sep 2020 19:11:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anecdotes from Donald Knuth and Robert Tarjan]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24591454">thread link</a>) | @furcyd
<br/>
September 25, 2020 | https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/ | <a href="https://web.archive.org/web/*/https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"> <figure id="attachment_7848" aria-describedby="caption-attachment-7848"><a href="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png"> <img alt="" width="342" height="114" srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-1024x341.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-768x256.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png 1291w" sizes="(max-width: 342px) 100vw, 342px" data-srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-1024x341.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-768x256.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png 1291w" data-src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png" src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png"></a><figcaption id="caption-attachment-7848">Donald Knuth and Robert Tarjan chat during the virtual HLF</figcaption></figure> <p><span>On day two of the Virtual </span><a href="https://www.heidelberg-laureate-forum.org/"><span>Heidelberg Laureate Forum</span></a><span> (HLF) 2020, Robert Endre Tarjan and Donald Ervin Knuth engaged in a freewheeling conversation about mathematics, computer science, and art.&nbsp;</span></p> <p><a href="https://www.heidelberg-laureate-forum.org/laureate/donald-ervin-knuth.html"><span>Donald Knuth</span></a><span> was the 1974 </span><a href="https://amturing.acm.org/"><span>ACM A.M. Turing Award</span></a><span> winner for “for his major contributions to the analysis of algorithms and the design of programming languages, and in particular for his contributions to the “art of computer programming” through his well-known books in a continuous series by this title,” while </span><a href="https://www.heidelberg-laureate-forum.org/laureate/robert-endre-tarjan.html"><span>Robert Tarjan</span></a><span>, won the </span><a href="https://www.mathunion.org/imu-awards/rolf-nevanlinna-prize"><span>Nevanlinna Prize</span></a><span> in 1982 “for devising near-optimal algorithms for many graph-theoretic and geometric problems for the development and exploitation of data structures supporting efficient algorithms, and for contributing several algorithmic analyses of striking profundity and elegance” and the Turing Award in 1986 “with </span><a href="https://en.wikipedia.org/wiki/John_Hopcroft"><span>John E. Hopcroft</span></a><span>, for fundamental achievements in the design and analysis of algorithms and data structures.”</span></p> <p><span>Tarjan was a student of Knuth’s at Stanford, and their history together was on display in their dynamic banter. The conversation produced a number of entertaining anecdotes, such as Knuth’s concern for Tarjan’s health when he was an assistant professor. Knuth said of Tarjan, “as I sort of remember…I was very worried about you because you were proving theorems in your head as you were driving the freeways and I was afraid you would get into a wreck.” Remember kids, don’t do math and drive.&nbsp;</span></p> <p><span>Knuth also discussed his time as the manager of the </span><a href="https://ohiohistorycentral.org/w/Case_Institute_of_Technology"><span>Case Institute of Technology</span></a><span> basketball team while he was an undergraduate. During his junior year he created a process to keep better statistics on each basketball player during practices and games. Then, using punch cards, he fed this data into an </span><a href="https://en.wikipedia.org/wiki/IBM_650"><span>IBM 650</span></a><span> to generate strategic recommendations for the coach of the team. This system seems to have been a success — Case won more games the year they began to use Knuth’s system than they did the year before. IBM even recorded a short film about Knuth’s system called </span><i><span>The Electronic Coach</span></i><span>, which you can watch on Youtube </span><a href="https://www.youtube.com/watch?v=dhh8Ao4yweQ"><span>here</span></a><span>.&nbsp;</span></p> <p><span>Knuth was ahead of his time — modern NBA teams rely on detailed data analytics to better understand their players and the competition; in fact during the 2013-2014 season the NBA </span><a href="https://www.engadget.com/2013-09-07-nba-stats-llc-motion-tracking-sportvu.html"><span>installed SportVu motion tracking cameras</span></a><span> in every NBA stadium. These SportVu cameras monitor the movements of every player and the basketball at 25 frames per second, generating data about everything that happens in every basketball game. NBA teams, </span><a href="https://digital.hbs.edu/platform-digit/submission/moreyball-the-houston-rockets-and-analytics/"><span>most famously the Houston Rockets</span></a><span>, have used these analytics to redefine how the game is played. While three point shots are the toughest shot to make, they have a higher expected value than a long two point shot (because the difference in shooting percentage between the two is marginal), increase the spacing between players (which makes it harder to play defense), and increases the likelihood of getting an offensive rebound (because missed three point shots tend to bounce further away from the basket). Realizing this, NBA teams consistently shoot more and more threes every season. In the 1979-1980 season, the first year the three point line was introduced to the NBA, the San Diego Clippers </span><a href="https://www.basketball-reference.com/leagues/NBA_1980.html"><span>led the league</span></a><span> with 6.6 three point attempts (3PA) per game. Last year the Houston Rockets smashed that number, attempting the most threes in NBA history with </span><a href="https://www.basketball-reference.com/leagues/NBA_2019.html"><span>45.4 attempts per game</span></a><span>.&nbsp;</span></p> <p><span>This is all to say that Knuth was really onto something when he had the novel idea of using a computer to better understand a basketball game. You can learn more about the work of a NBA modern data scientist in this video from </span><a href="https://www.youtube.com/watch?v=MpLHMKTolVw"><span>Bloomberg</span></a><span> that profiles </span><a href="https://www.linkedin.com/in/ivana-seric-503b4731/"><span>Ivana Seric</span></a><span>, a senior researcher with the Philadelphia 76ers.&nbsp;</span></p> <figure id="attachment_7851" aria-describedby="caption-attachment-7851"><a href="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM.png"> <img alt="" width="300" height="154" srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1024x524.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-768x393.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1536x786.png 1536w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-2048x1048.png 2048w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1024x524.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-768x393.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1536x786.png 1536w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-2048x1048.png 2048w" data-src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png" src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png"></a><figcaption id="caption-attachment-7851">Typeset score from Chapter 1 of Fantasia Apocalyptica</figcaption></figure> <p><span>Knuth’s application of math and computer science to other fields doesn’t stop there. Knuth is also an accomplished pipe organ player and a few years ago he composed, </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fant.html"><i><span>Fantasia Apocalyptica</span></i></a><span>, a multimedia work for pipe organ. In </span><i><span>Apocalyptica </span></i><span>Knuth used a few mathematical and algorithmic methods to generate melodies. </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fant.html"><span>On his webpage</span></a><span> Knuth says:</span></p> <p><span>“At one point I thought I might have time to understand music theory well enough that I could try to teach that theory to a computer. But eventually I concluded that it would be better to create this piece almost entirely by hand, using my desktop machine only to help organize the work. Thus it’s definitely </span><i><span>not</span></i><span> “computer music”, although I do profess to be a computer scientist.</span></p> <p><span>On the other hand, I did apply some algorithms manually in a few places. For example, a haunting melody, taken from one of the earliest surviving instances of ancient Greek music, occurs ten times. I harmonized it differently each time, using the algorithm of David Kraehenbuehl that’s described in Chapter 22 of </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fg.html"><span>Selected Papers on Fun &amp; Games</span></a><span>. (See </span><a href="https://www-cs-faculty.stanford.edu/~knuth/papers/randomness.ps.gz"><span>“Randomness in Music”</span></a><span>.)</span></p> <p><span>Mathematical methods were also used to generate the changeringing patterns that appear briefly, as well as certain melodies used for the twelve tribes of Israel and for the twelve precious jewels below the “pearly gates” of the New Jerusalem. If those methods hadn’t been successful, I would have changed the results by hand. Fortunately, I didn’t have to do that; the algorithmic approach did give a pleasing result in those cases.”</span></p> <p><span>Knuth’s diverse interests led Tarjan to ask a compelling question: “It’s been said that any field that has science in its name is not a science, so I might ask you is computer science a science, a branch of engineering, a branch of mathematics, an art — but let me ask it in a more personal way….do you see yourself as an artist, a scientist, a mathematician, an engineer, a philosopher, some combination?”&nbsp;</span></p> <p><span>Knuth replied that he realized art stands not only for fine art but also for things that are artificial or made by human beings (as opposed to nature). He defined science as “what we understand well enough to explain to a computer” while “art is everything else.” He went on to say that as we learn more science about something our brains “keep a few jumps ahead, and that’s the art.”&nbsp;</span></p> <p><span>Finally, Knuth was asked if he had advice for students. Knuth’s response was to echo the </span><a href="https://scilogs.spektrum.de/hlf/have-fun-life-and-career-advice-from-sir-c-antony-r-hoare-and-leslie-lamport/"><span>advice of Leslie Lamport</span></a><span> from earlier in HLF, which was to write often. However, Knuth cautioned to not be “too influenced by trendy stuff. Don’t write a paper because you have to write a paper or because you think you have to impress people about something that you aren’t personally really interested in…that’s the worst reason to write a paper.”&nbsp;</span></p> <p><span>Tarjan added to this and said, “You have to figure out what your own path is and follow it. The best students I’ve had came in with or ended up with their own idea that they developed.” Clearly both men have had success finding and following their own path. </span><b>Watch the full conversation between Tarjan and Knuth on Youtube </b><a href="https://www.youtube.com/watch?v=O5g4Zl8ppQA"><b>here</b></a><b>. </b></p>  </div></div>]]>
            </description>
            <link>https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591454</guid>
            <pubDate>Fri, 25 Sep 2020 16:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It? Part II]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24591216">thread link</a>) | @parsecs
<br/>
September 25, 2020 | https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we continue our four-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, II, III, IV) look at pre-modern iron and steel production.  Last week we prospected our iron ore and extracted it from the ground and did some initial mechanical processing (washing, sorting, crushing).  This week, we’re going to make our way from just rocks to an actual mass of <em>metal</em> rather than just some metal-bearing ore.  As we’ll see, we are going to do this by applying <em>heat</em> and (more importantly) <em><strong>chemistry</strong></em>:</p>



<figure><img data-attachment-id="4618" data-permalink="https://acoup.blog/fuel-use-in-iron-production-1/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png" data-orig-size="1024,372" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fuel-use-in-iron-production-1" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png 1024w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Note that this week is going to be spent <strong>just</strong> getting our iron ore into being an <strong>iron bloom</strong>, the first two steps.</figcaption></figure>



<p>Warning: Many, <em><strong>many</strong></em> trees were harmed in the making of this iron.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<p>But let’s start with the <strong>single largest input</strong> for our entire process, measured in either mass or volume – quite literally the largest input resource <em>by an order of magnitude</em>.  That’s right, it’s…</p>



<h2>Trees</h2>



<figure><img data-attachment-id="4597" data-permalink="https://acoup.blog/a_route_through_pine_forest/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg" data-orig-size="5184,3456" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 60D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1402052182&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;18&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="a_route_through_pine_forest" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The reader may be pardoned for having gotten to this point expecting to begin with exciting furnaces, bellowing roaring flames and melting all and sundry.  <strong>The thing is, all of that energy has to come from somewhere and that somewhere is, by and large, wood</strong>.  Now it is absolutely true that there are other common fuels which were probably frequently experimented with and sometimes used, but don’t seem to have been used widely.  Manure, used as cooking and heating fuel in many areas of the world where trees were scarce, doesn’t – to my understanding – reach sufficient temperatures for use in iron-working.  Peat seems to have similar problems, although my understanding is it can be reduced to charcoal like wood; I haven’t seen any clear evidence this was often done, although one assumes it must have been tried.</p>



<p>Instead, the fuel I gather most people <em>assume</em> was used (to the point that it is what many video-game crafting systems set for) was coal.  The problem with coal is that it has to go through a process of <em>coking</em> in order to create a pure mass of carbon (called ‘coke’) which is suitable for use.  Without that conversion, the coal itself both does not burn hot enough, but also is apt to contain lots of sulfur, which will ruin the metal being made with it, as the iron will absorb the sulfur and produce an inferior alloy (sulfur makes the metal brittle, causing it to break rather than bend, and makes it harder to weld too).  Indeed, the reason we <em>know</em> that the Romans in Britain experimented with using local coal this way is that analysis of iron produced at Wilderspool, Cheshire during the Roman period revealed the presence of sulfur in the metal which was likely from the coal on the site.</p>



<p>We have records of early experiments with methods of coking coal in Europe beginning in the late 1500s, but the first truly successful effort was that of Abraham Darby in 1709.  Prior to that, it seems that the use of coal in iron-production in Europe was minimal (though coal might be used as a fuel for other things like cooking and home heating).  In China, development was more rapid and there is evidence that iron-working was being done with coke as early as the eleventh century.  But apart from that, by and large the fuel to create all of the heat we’re going to need is going to come from <strong>trees</strong>.</p>



<p><strong>And, as we’ll see, really quite a lot of trees.  Indeed, a <em>staggering</em> number of trees, if iron production is to be done on a major scale</strong>.  The good news is we needn’t be <em>too </em>picky about what trees we use;  ancient writers go on at length about the very specific best woods for ships, spears, shields, or pikes (fir, cornel, poplar or willow, and ash respectively, for the curious), but are far less picky about fuel-woods.  Pinewood seems to have been a consistent preference, both Pliny (<em>NH</em> 33.30) and Theophrastus (<em>HP</em> 5.9.1-3) note it as the easiest to use and Buckwald (<em>op cit</em>.) notes its use in medieval Scandinavia as well.  But we are also told that chestnut and fir also work well, and we see a fair bit of birch in the archaeological record.  So we have our trees, more or less.</p>



<h2>Forests and Fellers</h2>



<p>The bad news is that while ancient sources are often <em>very</em> interested in trees (entire books about them, in fact), they are generally interested in trees used to make things like ships, buildings, furniture and weapons; essentially, elite products.  They are <em>not</em> interested in trees used as fuel.  Indeed, Latin marks this distinction, where wood for building was <em>materia</em> whereas wood for burning (but also, it seems, bulk wood being transported overseas) was <em>lignum</em>; our sources care greatly about the former and only minimally about the latter.  And so as soon as we get very far into the question of the harvesting and preparation of fuel woods, our evidence just about drops away entirely, save for a few poor mentions of this or that tree being good for charcoaling (a crucial process we’ll get to in a moment).</p>



<figure><img data-attachment-id="4598" data-permalink="https://acoup.blog/1024px-transport_cedar_dur_sharrukin_louvre_ao19891/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg" data-orig-size="1024,833" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-transport_cedar_dur_sharrukin_louvre_ao19891" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://commons.wikimedia.org/wiki/Dur_Sharrukin#/media/File:Transport_cedar_Dur_Sharrukin_Louvre_AO19891.jpg">Via Wikipedia</a>, a detail of an Assyrian relief from the palace of Sargon II (r. 722-705) at Dur-Sharrukin, now in the Louvre, Paris, showing the transport of Lebanese cedars; in this case, clearly building timber.</figcaption></figure>



<p>Consequently, our ability to see the fellows felling the forests (say <em>that</em> five times fast) is limited.  Medieval ‘foresters’ are often more visible, but much like we noted last time that when Georgius Agricola says ‘miner’ he means ‘mine owner,’ my understanding is that foresters in the Middle Ages were something closer to <em>administrators</em> of the forest (responsible for letting out contracts, catching poachers, etc.; essentially a sheriff but in the woods) rather than simple tree-fellers.</p>



<p>So who did the actual tree-cutting?  I must confess, I have found relatively little evidence for the social standing of ancient tree-fellers. <strong> In quite a lot of cases, they must not have been meaningfully distinct from the local peasantry or other sources of unskilled rural labor.</strong>  Clearly a lot of woodcutting was done by the rural population that bordered the forests to clear spaces for fields, gather fuel and firewood and so on, and consequently it seems like the basic skills of tree-felling may have been relatively common. The Latin word for a wood-cutter was a <em>lignator</em> (or sometimes a <em>caesor</em>, which meant ‘cutter’ but could mean of wood (<em>lignorum caesores</em>) or of stone), but that word most often appears in military contexts to mean soldiers tasked with cutting wood for fuel, not full-time lumberjacks.  Evidence for the medieval period is somewhat better and also generally suggests that the local peasantry was employed in the wood-cutting itself (for this, note J. Birrell, “Peasant Craftsmen in the Medieval Forest” <em>Agricultural History Review</em> 17.2 (1969): 91-107).  <strong>As we will see below, often wood cut for charcoaling was cut by the colliers themselves</strong>, who we will discuss below.  It seems hard to imagine that there wasn’t some division of labor in larger operations (like on Elba or at Populonia), but how that might have been structured is not clear from the limited evidence.</p>



<p>Not all timber works were so easily acquired, of course.  While ancient wood-cutters are hard to see in the evidence, ancient sawyers and carpenters are more visible; records from building programs in Athens and Delphi suggest that skilled sawyers (seemingly always assisted by at least one unskilled worker) were paid at least as well as citizen oarsmen in the Athenian navy and in some cases rather better.  The presence of English surnames like Carpenter, Cooper, Fletcher, Bowyer, Turner, Sawyer and Wheeler speak to the fact that these were specialized crafts in medieval England; the absence of wood-<em>cutting</em> surnames further suggests that the bulk labor of felling was mostly done by the local rural workforce.  <strong>Consequently, the social status of the average timber-cutter seems to have been about the same as that of a local peasant, serf or small-farmer, because by and large these seem to have been the same people</strong>; while the work done once the tree was down and barked might be done by specialists (but is far less important for trees that are going to be charcoaled).  There were also clearly specialist timber merchants, even in the ancient world, and the degree of their visibility, especially in timber-rich regions suggests that they could do quite well for themselves (although, <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">like most merchants</a>, we effectively never see them penetrate into the ruling class), but again, these merchants were likely working with building timbers because, as we’ll see, charcoal wood doesn’t tend to travel very far.</p>



<figure><img data-attachment-id="4600" data-permalink="https://acoup.blog/800px-transport_cedar_dur_sharrukin_louvre_ao19890/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg" data-orig-size="800,1008" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="800px-transport_cedar_dur_sharrukin_louvre_ao19890" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=238" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=800" src="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=800" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg 800w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=119 119w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=238 238w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption><a href="https://commons.wikimedia.org/wiki/Dur_Sharrukin#/media/File:Transport_cedar_Dur_Sharrukin_Louvre_AO19890.jpg">Via Wikipedia</a>, a detail of an Assyrian relief from the palace of Sargon II (r. 722-705) at Dur-Sharrukin, now in the Louvre, Paris, showing the shipment of timber, in this case likely down the Tigris to the Assyrian heartland.  High quality building timbers or ship timbers do seem to have been valuable enough to be worth shipping long distances (Athens famously imported its ship-timber from Macedon), but fuel timbers tended to come from closer to hand.  But I <strong>had</strong> this picture and I wanted to use it.</figcaption></figure>



<p><strong>The largest stock of forest-land was typically owned by the state, but private landholders owning their own forests also played a role, albeit generally a small one</strong>.  In Macedon, the king owned the forests and controlled the supply of lumber, granting or revoking the authority for communities within his territory to take advantage of woodland resources; the practice seems to have been the same, Meiggs (<em>op cit</em>.) notes, in the Near East.  In Roman Italy, a large amount of the forest-land was held by the state and contracted out for timber-cutting;<em> </em>Meiggs supposes that figures called <em>saltuarii</em> may have been responsible for making sure that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591216</guid>
            <pubDate>Fri, 25 Sep 2020 16:02:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardcore Year: from 0 to $100k ARR]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24590965">thread link</a>) | @a007mr
<br/>
September 25, 2020 | https://usefocus.co/blog/hard-core-year/ | <a href="https://web.archive.org/web/*/https://usefocus.co/blog/hard-core-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><img src="https://0.gravatar.com/avatar/0fade99d9d6b780de315f66b5036c890?s=96" alt="Anton Cherkasov"></p><h4>Anton Cherkasov</h4>
        
        <p>Anton is a founder of Focus, which is a team management platform. He is also a writer in HackerNoon, The Startup, Good Audience, and other media. Previously Anton has worked in Wildberries (#1 eCommerce store in Russia). He is falling in love with growth hacking, product management, and football.</p>
        <hr>
        <p><strong>LATEST POSTS</strong></p><p><a href="https://usefocus.co/blog/how-to-stay-focused/">How to Stay Focused for Product Teams</a><span> 10th July, 2020</span></p><p><a href="https://usefocus.co/blog/20-hr-okr-examples/">20 Human Resources (HR) OKR Examples</a><span> 24th June, 2020</span></p>    </div><section>

				<article id="post-566">

					
	<header>
		<h2>
			<a href="https://usefocus.co/blog/category/founders-journey/">Founder's Journey</a>		</h2>
		
		<span>
			Posted 
			on <i></i> <time datetime="2020-09-15">September 15th, 2020</time>.
		</span>
	</header>


					<section>
						
<figure><img src="https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-1024x614.png" alt="Hard Core Year Focus" srcset="https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-1024x614.png 1024w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-300x180.png 300w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-768x461.png 768w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-1240x744.png 1240w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-860x516.png 860w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-680x408.png 680w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-500x300.png 500w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-400x240.png 400w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-200x120.png 200w, https://usefocus.co/blog/wp-content/uploads/2020/09/Hard-Core-Year-Focus-50x30.png 50w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>I created several startups and one of them is profitable. My last one was a blockchain platform for the recruitment industry. We wanted to change recruitment and become a unicorn. It was a marketplace where we didn’t manage to acquire two types of target audiences – companies and job seekers. It was a very challenging time. However, I decided to move forward and focus only on the B2B market.&nbsp;</p>



<p>After a long time, I decided to create a new product for team management space and now everything will be different. First, it’s an open startup. Second, I will publish our journey and share all pitfalls and challenges we overcome. That’s why it’s time for Hardcore Year.</p>



<p>Our goal is <strong>$100k ARR in 1 year</strong>. 2020 is a really unusual year and as they said crisis is the best time for the new opportunities. Let’s check it out. </p>



<h2><strong>What’s Hardcore Year?</strong></h2>



<p>Kick ass challenge to get out of the comfort zone. Hardcore Year is the public and ambitious goal with sharing all key details during the journey. You will see the main problems we solve (or not) and of course data (probably, the most interesting for you :)). I am going to publish results at the end of each month.</p>



<p>I was inspired by great entrepreneurs who have already had their Hardcore Years. Here are the few of them:</p>



<ul><li><a rel="noreferrer noopener" aria-label="Andrei Azimov (opens in a new tab)" href="https://twitter.com/AndreyAzimov/status/1134472394091814912" target="_blank">Andrei Azimov</a> (Completed)&nbsp;</li><li><a rel="noreferrer noopener" aria-label="Reilly Chaze (opens in a new tab)" href="https://rchase.com/hardcore-year/" target="_blank">Reilly Chaze</a> (Completed)&nbsp;</li><li><a rel="noreferrer noopener" aria-label="Jon Yongfook (opens in a new tab)" href="https://twitter.com/yongfook/status/1303861152603017223" target="_blank">Jon Yongfook</a>&nbsp;</li><li><a href="https://www.groovehq.com/blog/founders-journey/" target="_blank" rel="noreferrer noopener" aria-label="Alex Turnbull (opens in a new tab)">Alex Turnbull</a> from Groove (Completed)</li></ul>



<h2><strong>Why $100k ARR?</strong></h2>



<p>$100k ARR is a great milestone to validate an idea of the startup. It means ~8.3k MRR, which allows us to live and to develop the business. I want to build a profitable business that earns money without venture investments and has enough growth to make a successful company.&nbsp;</p>



<p>There is a decent amount of interesting entrepreneurs who tell their story. Groove, Andrei Azimov, Reilly Chaze, and others. They have already had great results and some of them completed their Hardcore Year. This blog might be interested for you as I start from scratch now. I will share pitfalls, mistakes, and insights I get as a founder of the early-stage startup. I will show how we make a startup in 2020.&nbsp;&nbsp;</p>



<p>Each month I publish an update with key metrics. I hope it will help others to start their journey and make something valuable for the world.&nbsp;</p>



<h2><strong>What is Focus?</strong></h2>



<p>My passion is simplifying complex things. We have a lot of different stuff every day. Different tools for work, challenges, goals, channels, news, and so on. That’s why I want to build a tool that helps companies to manage their team in a much better way than they have it now. To cut everything that is not important and focus on what really matters.</p>



<p>Focus is a team management software that helps to connect strategy with daily operations. It allows to get employees feedback and set the objectives. It’s not a usual project management tool. Because task managers don’t solve the real problem of management. They allow to do good task lists. However, many companies struggle with leadership and management. Employees don’t know how they affect the company’s goals. They even don’t know what are the main company’s goals in most cases. These issues and unskillful management directly impacts employees’ happiness and engagement. According the Gallup <a href="https://www.forbes.com/sites/georgenehuang/2019/04/26/most-employees-dont-hate-their-jobs/#59aa72ed573d">survey</a>, 66% of employees are disengaged in their job. I want to fix it and make it better by giving companies the best tool to manage their teams. </p>



<h2><strong>What’s next?</strong></h2>



<p>I will publish updates at the end of a month. Subscribe to the newsletter to get the latest news about our journey. Also, connect with me on <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://twitter.com/_antoncherkasov" target="_blank">Twitter</a>&nbsp;and <a href="https://www.linkedin.com/in/anton-cherkasov/" target="_blank" rel="noreferrer noopener" aria-label="LinkedIn (opens in a new tab)">LinkedIn</a>.</p>





											</section>

					
    

					
    <div>
        <p><img src="https://0.gravatar.com/avatar/0fade99d9d6b780de315f66b5036c890?s=96" alt="Anton Cherkasov"></p><div>
            <h4>Anton Cherkasov</h4>
            <p><a href="https://usefocus.co/" target="_blank">https://usefocus.co/</a></p><p>Anton is a founder of Focus, which is a team management platform. He is also a writer in HackerNoon, The Startup, Good Audience, and other media. Previously Anton has worked in Wildberries (#1 eCommerce store in Russia). He is falling in love with growth hacking, product management, and football.</p>
            
        </div>
    </div>

					

				</article>

				
    

			</section></div>]]>
            </description>
            <link>https://usefocus.co/blog/hard-core-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590965</guid>
            <pubDate>Fri, 25 Sep 2020 15:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Live server push without JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24590687">thread link</a>) | @lawik
<br/>
September 25, 2020 | https://underjord.io/live-server-push-without-js.html | <a href="https://web.archive.org/web/*/https://underjord.io/live-server-push-without-js.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-09-25</small><!-- RSS:2020-09-25T17:00:00Z -->
<p>
    So in my post <a href="https://underjord.io/is-this-evil.html">Is this evil?</a> I covered a way of tracking users with CSS. While
    thinking about those weird ways of using the web I also started thinking about pushing live data to clients
    without JS. Or at least maintaining a connection.
    So WebSockets requires JS. WebRTC requires JS. Even HLS (video streaming), which would otherwise
    be super cool, with captions for accessibility. But no. Or rather, maybe on Apple platforms. Eh. Not good enough.
</p>
<p>And then it hit me. From some old Nerves projects I'd seen, that there is a standard for just sending a stream of
    JPEG frames as a video. MJPEG. Did you know about MJPEG? Lots of people don't. It is used by lots of webcams and
    security cameras. Common option for Raspberry Pi hacks as well. MJPEG is super simple which is its big advantage.
</p>
<p>But video is what we expect. I was going for something else. So this could be used for a CI status light, showing
    any amount of visual status information. I use it for this:</p>
<p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>
<p>That's live. Or dead if my server falls over.</p>
<p>So how does MJPEG work. Well, you take an <code>&lt;img&gt;</code> tag and you shove an MJPEG URL into it. Done.</p>
<p>Okay, that's how you use it. Not how it works. I implemented it in Elixir, Elixir is quite good at keeping state and
    serving updates. Links are below. But basically the browser opens the connection, receives some headers and some
    chunks of data and then realizes it is dealing with MJPEG. It wil then just expect the chunks to keep coming.
    Indefinitely. Because this is live video. Frame by frame of JPEG.</p>
<p>The basic code for the MJPEG headers and chunking was lifted from a pi camera repo made by the Nerves team. It had a
    lot of Frank Hunleth and Connor Rigby in it so kudos to those guys as always. This is what I did with it: <a href="https://github.com/lawik/mjpeg/blob/master/lib/mjpeg.ex">lawik/mjpeg</a></p>
<p>My server implementation is here and uses the above code: <a href="https://github.com/lawik/mjpeg_example/blob/master/lib/mjpeg_example.ex">lawik/mjpeg_example</a></p>
<p>So I receive the connection and then that calls my MjpegExample GenServer to persist the connection and keep track of
    how to notify that connection about new data. It also triggers an update to notify everyone already connected.</p>
<p>This is not polished, it is hammered together and I'm curious to see if it falls over the next time I get a decent
    amount of traffic.</p>
<p>I really like this approach because it is a fun hack that simply happens to work across browsers and quite well at
    that. I like how it is just an img element and no frills. I added lazy loading because that works more nicely with
    things like Google Lighthouse scores and the loading experience (your browser doesn't spend a few seconds thinking
    about loading the image).</p>
<p>Unfortunately it is absolutely a poor choice to actually use aside from fun and hacky stuff. There is no good way of
    doing accessibility with it. You can update the pixels and that is it. Unless you can chunk-stream a txt-file in an
    iframe.
    Haven't tried that yet...</p>
<p>So, don't use it. But isn't it pretty neat?</p>
<p>Of course, much like the CSS tracking, this can be used for evilish things. You can absolutely keep track of how long
    someone keeps receiving your frames and use that for your analytics. I also find it neat that it lets me know
    concurrent users. I just log the number along with sending it out because I want to know at what number it breaks
    and out of curiosity but you can probably do some mildly untoward things with this. Oh.. Wait. You could serve
    rotating ads with this. You know what the last frame you sent was so if you get a click on it you can direct that
    particular user to the right thing. New title: Ad placement entirely without JS, ugh, no thanks. Moving on.</p>
<p>If you know how to make this more dirty, hacky and fun or even more useful or accessible feel free to get in touch at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on
    Twitter where I'm <a href="https://twitter.com/lawik">@lawik</a>.</p><p><img alt="live visual readership indicator" loading="lazy" src="https://count.underjord.io/"></p>

</div></div>]]>
            </description>
            <link>https://underjord.io/live-server-push-without-js.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24590687</guid>
            <pubDate>Fri, 25 Sep 2020 15:17:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MakAir: Covid-19 ventilator with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24589853">thread link</a>) | @telecoteco
<br/>
September 25, 2020 | https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>During the covid-19 crisis, The birth of the first open source data enabled ventilator. </p><article>
      
<p>Back to March 20, 2020. <a href="https://twitter.com/waxzce" target="_blank" rel="noreferrer noopener">Quentin Adam</a>, with some friends living in Nantes, is trying to build a ventilator prototype with 3D printing and Arduino, in response to a shortage of equipment. </p>



<p><strong>Project MakAir is started</strong>. </p>



<p>Quentin, a software expert, is struggling with the electronics part and looking for electronics engineers. Among his friends is Mathias, SenX CTO. That is how Mathias asked me to review the electronics part of the project. My first call with Quentin was to help him connect an old pressure sensor to an Arduino, during the late evening of March 20.</p>



<p><strong>The goal was clear: to mass-produce an open-source medical ventilator</strong>. Crazy! Looking at the project that day, it looked like an "amateur" project. So I did the first real schematics, the first BOM, the first Radiospares, and Farnell reference list during the weekend, discussing with more and more people on the MakAir Slack. </p>



<figure></figure>



<h3>Amateur? Not really...</h3>



<p>Next Thursday, I understood that the small "amateur" project is quickly getting big. Two electronics companies detached people, and a whole regulatory team was up. In this team, there were some experts in medical devices. We also knew that we were in a shortlist of projects that the French government is looking at closely.</p>



<p>I soon realized that in Nantes, there is no one able to actually make the prototypes. <a href="https://blog.senx.io/connecting-a-beertender-to-warp-10-using-mqtt-on-lorawan-with-thethingsnetwork/" target="_blank" rel="noreferrer noopener">Engineers with prototyping knowledge</a> are scarce, I just know a few of them like me. So, on the 25th during the evening, in a few minutes, I convinced Cherine, a former Renault Sport colleague living near Paris who has the same knowledge of prototyping as me, to join the project as well.</p>



<p><strong>On the 26th, I joined the MakAir core team, choosing to confine myself with 17 other people to make project MakAir a reality</strong>. Cherine came from Paris the same day I came from Brest. At the same time in France, 100 people were already helping us remotely. </p>



<p>I brought with me all my personal tools, from soldering iron to oscilloscope, and tons of components. </p>



<figure><blockquote><p>If I had been told this would last 25 days, I would have brought more than 3 days of clothing!</p></blockquote></figure>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" alt="working in the Palace, Nantes" width="509" height="339" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w" sizes="(max-width: 509px) 100vw, 509px"><figcaption>One sleepless night later, the first functional prototype was up.</figcaption></figure></div>







<p>Three days later, <strong>the <a href="http://www.cea.fr/" target="_blank" rel="noreferrer noopener">CEA</a></strong> (french government agency for atomic energy) is now supporting us. On the 31<sup>st</sup> of March, we all moved from Nantes to Grenoble CEA facility, traveling on a nearly empty motorway.</p>



<p>The first prototype had basic electronics: STM32 Nucleo, a small 4 lines screen, a few buttons, a good precision pressure sensor, and several servo outputs. <strong>This first prototype allows us to make a pig breath for 4 hours</strong> on the 3rd of April, only 2 weeks after the project started.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" alt="" data-id="11640" data-link="https://blog.senx.io/?attachment_id=11640" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The first prototype board...</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" alt="" data-id="11641" data-link="https://blog.senx.io/?attachment_id=11641" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Stacking a Nucleo F411 with pressure sensor, keyboard, screen.</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="768" src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" alt="" data-id="11748" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-link="https://blog.senx.io/?attachment_id=11748" srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>First wood prototype</figcaption></figure></li></ul></figure>



<h2>Enters the Raspberry Pi</h2>



<p>What we learned from the first test on a pig:</p>



<ul><li>The ventilator did the job. The pig was alive and woke up correctly.</li><li><strong>There is a huge UX problem.</strong></li><li>The air flow measurement is really helpful.</li></ul>



<p>The experts from the medical world are now used to high-tech screens displaying curves with not only pressure, but real-time air volume blown into the patient lungs. Even in crisis time, we understand that our product does not meet their minimum UI/UX needs.</p>



<figure><img loading="lazy" width="1024" height="418" src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" alt="difference of UX between first MakAir screen and a recent ventilator" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Makair prototype on the left, a recent ventilator on the right. <br>Both can save life, but UX gap is huge!</figcaption></figure>



<p>Always listen to the users. Even if we succeed in mass production of an open-source ventilator, if doctors want curves and measure of the number of air liters entering the lungs, we must do it. </p>



<p>Since the beginning, this project is time driven. We never consider the price, but we always look at worldwide stocks. In a time where lots of plants are closed in Europe, <strong>the supply chain is leading the project.</strong></p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" alt="inside the v1 of the MakAir" width="522" height="347" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w" sizes="(max-width: 522px) 100vw, 522px"><figcaption>Scooter lead-acid batteries. Because these are the most available batteries in the word.</figcaption></figure></div>



<p>So, what is the world's most available touch screen? </p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" alt="farnell stocks" width="616" height="217" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w" sizes="(max-width: 616px) 100vw, 616px"><figcaption>(and 18000 more at radiospares)</figcaption></figure></div>



<p>As I just said, the supply chain rules the project. MakAir will have a raspberry to display curves. Nice coincidence for an open-source project!</p>



<p>By the way, the mass flow meter sensor was a huge problem. Since the beginning, MakAir did not want to disturb the production of existing ventilators. But this component is on the air way, it should be approved for medical use. In April, it was impossible to source any Sensirion or Honeywell mass flow sensors... Anyway, the next test will be done with a raspberry connected to the STM32. </p>







<h2>Enter Warp&nbsp;10</h2>



<p>On the 17th of April, the first batch of ventilators built in the CEA clean-rooms was ready. This batch was used for the 1st clinical tests. </p>



<p><strong>The pressure switches from the technical team to the regulatory team, remotely working on the project since the beginning. </strong></p>



<p>To prepare the next batch, we came back to Nantes. After 25 days, we switched from commando mode (18h/day, 7 days a week) to a more standard week (14h/day, the weekends with the family).</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" alt="MakAir team in the CEA cleanroom with prototypes" width="521" height="390" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w" sizes="(max-width: 521px) 100vw, 521px"><figcaption>Tyvek sterile clothing in a cleanroom. Could not be better for medical device assembly. Thanks to the CEA.</figcaption></figure></div>



<p>On the 30<sup>th</sup> of April, the prototype with a raspberry pi is ready for the next animal test. Two people had to fly to Grenoble CEA with this prototype, but the rest of us, and all the people remotely working on the project wanted to follow the experience. </p>



<p>So, the night before the test, I quickly deployed Warp&nbsp;10 on the raspberry and wrote a small script to copy data every 10s to another Warp&nbsp;10 server.</p>



<p>What is <a href="https://www.warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a>? It is a time series platform. But unlike other TSDB (Time Series Database), there is a full analysis environment behind, and even a task scheduler. Compress time series, replicate to another server while managing network outage is really easy. Same tooling on the server and the connected object, that what I call easy IoT. To stream data, you just need a few WarpScript functions among <a href="https://www.warp10.io/doc/functionList" target="_blank" rel="noreferrer noopener">the thousand available</a>.</p>



<p>Basically, the WarpScript pseudo code is:</p>



<pre><code>- Read the last value of makair.lastupload GTS
- take the last tick as start
- take now as end
- fetch locally all the makair GTS from start to end
- WRAP all the GTS
- build a script that UNWRAP and UPDATE the data
- do a remote execution of the script with REXEC 
- if the REXEC was a success, store end in makair.lastupload</code></pre>



<p>You can follow the <a href="https://www.warp10.io/content/04_Tutorials/01_WarpScript/30_Server_to_Server" target="_blank" rel="noreferrer noopener">server to server tutorial</a> to implement such a WarpScript, then save it as $WARP10HOME/warpscripts/makair/10000/upload_data.mc2 to schedule an execution every 10s.</p>



<p>To display data in real-time, <a href="http://studio.senx.io/" target="_blank" rel="noreferrer noopener">WarpStudio</a> did the job easily too. Autorefresh of the DataViz every 10s is a built-in function:</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" alt="autorefresh settings of the MakAir test" width="522" height="385" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w" sizes="(max-width: 522px) 100vw, 522px"><figcaption>In the dataviz tab of WarpStudio.</figcaption></figure></div>







<p>Around 30 lines of code to allow all the MakAir team to follow the pressure inside the pig lungs in real-time!</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" alt="real time display" width="516" height="343" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w" sizes="(max-width: 516px) 100vw, 516px"><figcaption>WarpStudio on a 60" 4k display, that's a nice dashboard.</figcaption></figure></div>







<h2>Next steps</h2>



<p>MakAir ventilators are designed to store everything in the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a> time series database. They also have built-in WiFi and LoRa. All these features are not yet available, because the priority is still to make an open-source approved ventilator. </p>



<figure><ul><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg" alt="" data-id="11728" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11728" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w" sizes="(max-width: 225px) 100vw, 225px"><figcaption>Revision 3 has a Raspberry screen on top of the small screen.</figcaption></figure></li><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg" alt="" data-id="11727" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11727" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w" sizes="(max-width: 225px) 100vw, 225px"><figcaption>The Raspberry Pi connected to the mainboard</figcaption></figure></li></ul></figure>



<p>Connected features + open-source software is an enabler for doctors and researchers to perform extensive data collection and try new algorithms in the machine. Warp&nbsp;10 is the best open source time series database to <a href="https://blog.senx.io/warp-10-for-iot-gdpr-compliant-before-gdpr-even-existed/" target="_blank" rel="noreferrer noopener">securely</a> store medical data and analyze it. It's not a walled garden.</p>



<p>If you need to connect medical devices to a time series database, <a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">just ask us</a>.</p>



<p>MakAir is now entering the second phase of clinical tests. We can consider we are half way to the goal. Keep in mind that among all the projects of ventilators announced by big companies, MakAir is the only one to reach the clinical tests step. <a href="https://makair.life/" target="_blank" rel="noreferrer noopener">200 people, backed up by CEA and a few french companies</a> are about to make a commercially available open source ventilator... </p>



<p>That's crazy when you think about it!</p>




<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589853</guid>
            <pubDate>Fri, 25 Sep 2020 14:08:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube Channels to Level Up Your Programming Skills]]>
            </title>
            <description>
<![CDATA[
Score 257 | Comments 118 (<a href="https://news.ycombinator.com/item?id=24589474">thread link</a>) | @spiderjako22
<br/>
September 25, 2020 | https://blog.codegiant.io/programming-skills-d77d4abdf255 | <a href="https://web.archive.org/web/*/https://blog.codegiant.io/programming-skills-d77d4abdf255">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.codegiant.io/@codegiant?source=post_page-----d77d4abdf255--------------------------------" rel="noopener"><img alt="Team Codegiant" src="https://miro.medium.com/fit/c/96/96/2*iU0oAI5CSMp5LPuEKOqNuQ.png" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2740/1*Xx2YxTWIGNI3ExVLq1meoA.png" width="1370" height="992" srcset="https://miro.medium.com/max/552/1*Xx2YxTWIGNI3ExVLq1meoA.png 276w, https://miro.medium.com/max/1104/1*Xx2YxTWIGNI3ExVLq1meoA.png 552w, https://miro.medium.com/max/1280/1*Xx2YxTWIGNI3ExVLq1meoA.png 640w, https://miro.medium.com/max/1400/1*Xx2YxTWIGNI3ExVLq1meoA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Xx2YxTWIGNI3ExVLq1meoA.png?q=20"></p></div></div></div></figure><p id="d6a2"><strong>From the desk of a brilliant weirdo #1:</strong></p><p id="e270"><em>Thank you for taking the time to check out this article. It doesn’t matter where you’re coming from (Codegiant, Hacker News, Reddit, or some other place), I always appreciate every reader who lands on my articles.</em></p><p id="0d0f">Now that I’ve coaxed you into reading this article, let’s get down to brass tacks.</p><p id="fb09">Whenever you’re just starting out with <a rel="noopener" href="https://blog.codegiant.io/software-development-life-cycle-the-ultimate-guide-2020-153d17bb20fb">software development</a> or simply want to uplevel your programming skills, you’ll need the right info resources to achieve your goals.</p><p id="3284">In this article, I’ve listed 22 of the best YouTube channels for improving your programming skills. Some are geared towards beginners while others focus on advanced topics.</p><p id="993e">So, if you consider yourself an experienced programmer, you can jump over to the last section where you’ll find all the 22 YouTube channels.</p><p id="2c67">If you are a beginner developer, however, I recommend that you go through each section of this article as we’ll talk about coding in general, programming skills, your computer programming resume, job opportunities, and some of the most in-demand programming languages.</p><p id="65e3">Without further ado:</p><p id="359c">Coding is the end result of a specific set of actions triggered to create a tangible result, whether it is a web page, an app, a video, or just an image on your screen.</p><p id="c92e">The great thing about computer coding (or programming) is that you can have a big idea and actually code it out into reality. And it doesn’t cost much, barring some time and effort on your side.</p><p id="3e5a">Many non-tech people consider the definition of a computer programmer to be someone who just makes programs. Although that’s partly true, partly not, it’s a mistake. Managers believe that the more lines of code a programmer can produce a month, the more creative he will be — another mistake. You can’t put a <a rel="noopener" href="https://blog.codegiant.io/software-developer-vs-software-engineer-31e873e787bc">developer</a> into a cubicle, set a deadline, ask him to work for 8–9 hours straight, and expect a top-notch quality software at the end.</p><p id="9e66">Instead of thinking about the programs a developer composes, one should consider the possible computations evoked by the developed program. “Designing a set of computations” is a more accurate description of what programmers actually do.</p><p id="5647">One can also imagine programmers as writers that have to think and write carefully, because the readers (the computers) take what the programmers write literally.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2330/0*al-_-Anr6m8BIIIi" width="1165" height="805" srcset="https://miro.medium.com/max/552/0*al-_-Anr6m8BIIIi 276w, https://miro.medium.com/max/1104/0*al-_-Anr6m8BIIIi 552w, https://miro.medium.com/max/1280/0*al-_-Anr6m8BIIIi 640w, https://miro.medium.com/max/1400/0*al-_-Anr6m8BIIIi 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*al-_-Anr6m8BIIIi?q=20"></p></div></div></div></figure><p id="f506">Many non-tech folks believe that programming is all about acquiring technical skills. I believe that being a developer requires more than just knowing how to code. To make it in the software development world, you’ll need to dig up some creativity and inject it into your coding skills. The ability to think analytically is highly valued among developers as well.</p><p id="1779">One of the most essential skills a developer can have isn’t actually technical, it’s social, and that is empathy. Lack of empathy inevitably leads to poor communication (barring you are a narcissist, sociopath, or psychopath and therefore can be charming as hell). On the other hand, being able to put empathy into practice will, without doubt, boost your career opportunities.</p><p id="9732">When it comes to <strong>planning software</strong>, developers should know how to use models and flowcharts to convey instructions clearly.</p><p id="c39f"><strong>Designing and creating applications</strong>. Depending on the project, this can take from a couple of weeks to months and sometimes even years to complete.</p><p id="9b77"><strong>Writing programs</strong>. As simple as that.</p><p id="9220"><strong>Update and expand existing programs</strong>. Most times, you’ll need to modify and update existing programs with extra features.</p><p id="e7df"><strong>Debugging code</strong>. Yup.</p><p id="5ef0"><strong>Simplify programming</strong>. Developers may also use software tools to automate a part of their development process in order to simplify and speed up the workflow.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2564/0*tJ40Go85DKYBw5cS" width="1282" height="869" srcset="https://miro.medium.com/max/552/0*tJ40Go85DKYBw5cS 276w, https://miro.medium.com/max/1104/0*tJ40Go85DKYBw5cS 552w, https://miro.medium.com/max/1280/0*tJ40Go85DKYBw5cS 640w, https://miro.medium.com/max/1400/0*tJ40Go85DKYBw5cS 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*tJ40Go85DKYBw5cS?q=20"></p></div></div></div></figure><p id="8ced">Showing up and practicing your programming skills seem to be the main ingredients to getting better at programming and coding. You gotta be programming in your spare time; you gotta be obsessed with it. Load yourself with patience because becoming a skilled coder takes years. And anyone who is telling you that you can learn and become good at coding in a month is probably trying to sell you something.</p><p id="8e25">Senior developers have all adopted common traits and basic coding skills that have helped them to rise in the hierarchy during their programming careers. Here are some valuable skills needed for you to be a senior developer:</p><p id="3a2c">One, being able to easily explain tech stuff to non-technical people.</p><p id="b60e">Two, being able to come up with accurate estimates.</p><p id="8cdb">Three, willingness to roll up their sleeves and do some grunt work.</p><p id="49a8">Four, knowing when to raise an issue to upper management.</p><p id="ff3f">Five, the ability to mentor junior developers.</p><p id="eb41">Six, vast knowledge of the technicalities for their domain.</p><h2 id="5ec1">Understand how the language works</h2><p id="e035">Focus on one language while learning. Having your focus split between two or three languages will discombobulate you.</p><p id="c797">It becomes obvious when a programmer doesn’t have a good understanding of the programming language he’s using. He’ll try to solve problems by following the logic of other languages and thus litter the code with unnecessary statements that can otherwise be reduced to fewer lines.</p><p id="094c">Also, you must know how to organize code into a system that makes sense. Creating rigid classes, schemas, and hierarchies require you to first think them through. Design can be a broad topic so I won’t cover much, but if you wish to read more, head over <a href="https://en.wikipedia.org/wiki/Fred_Brooks" rel="noopener">here</a>.</p><p id="e256">Poorly designed software lacks well-defined concepts, and its responsibilities are vague. Good software, on the other hand, comes with clear concepts and responsibilities. Take a look at mathematicians and physicists. They spend a huge amount of time trying to develop a clear definition of something because that will allow them to understand the truth about it. Developers should take a similar approach and spend a considerable amount of time brainstorming before writing code. Yes, this might be controversial to Agile but you gotta do what you gotta do.</p><p id="8ecf">It’s better to sit down with the dev team initially and outline all the required tasks than to go through 10 rounds of code reviews later.</p><p id="ea9f">Perhaps the best way to learn about design is to write and study many programs written by experienced programmers. As you gain more coding experience, you’ll, without doubt, enhance your design skills and expand your knowledge.</p><p id="0729">Good programmers ask questions like:</p><ul><li id="ff87">What’s the goal of this function?</li><li id="ee63">How can I explain this data structure to my teammates?</li><li id="771f">Can this function represent two standalone tasks?</li><li id="0e31">What’s the responsibility of this snippet of code?</li><li id="0f32">What should I include in the public interface?</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2648/0*uR00-riTaFDc4QFt" width="1324" height="919" srcset="https://miro.medium.com/max/552/0*uR00-riTaFDc4QFt 276w, https://miro.medium.com/max/1104/0*uR00-riTaFDc4QFt 552w, https://miro.medium.com/max/1280/0*uR00-riTaFDc4QFt 640w, https://miro.medium.com/max/1400/0*uR00-riTaFDc4QFt 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*uR00-riTaFDc4QFt?q=20"></p></div></div></div></figure><p id="d2d4">Most people think that you need a diploma from Harvard or universities alike to be considered for a job in big tech companies. Although that may be partially true (<a href="https://www.cnbc.com/2018/08/16/15-companies-that-no-longer-require-employees-to-have-a-college-degree.html" rel="noopener">not always though, it seems Apple and Google no longer require you to have a college degree</a>), some companies prefer the opposite, or at least don’t want you to be coming for Harvard, Oxford, Stanford, etc.</p><p id="3c6c">There are CEOs out there looking for developers that are qualified but not overly qualified… hard workers, being on time, but also leaving at the stroke of 5. Such CEOs consider Ivy League schools to be a red flag. Big resumes are also a red flag. That’s because developers coming from such schools can’t get off their high horse, question whether every decision is optimal, and are always hungry for praise, recognition, and “interesting work.”</p><p id="c97a">Instead, these CEOs are looking for loyal people who know how to take orders without questioning, and are ready to do the work, day in and day out, because they need the paycheck at the end of the month.</p><p id="6749">At a glance, this might seem quite controversial. Yet, there are developers out there who don’t want to become millionaire CTOs at the age of 30. Instead, they are satisfied with what they have on their plate: a steady job, fair pay, and that’s about it. Some companies with that kind of culture say that they have produced a 100% employee retention rate which means developers are happy with their work environment.</p><h2 id="11a4">Let’s talk about your resume now.</h2><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1964/0*P0TDzRLC7SaDQKzK" width="982" height="911" srcset="https://miro.medium.com/max/552/0*P0TDzRLC7SaDQKzK 276w, https://miro.medium.com/max/1104/0*P0TDzRLC7SaDQKzK 552w, https://miro.medium.com/max/1280/0*P0TDzRLC7SaDQKzK 640w, https://miro.medium.com/max/1400/0*P0TDzRLC7SaDQKzK 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*P0TDzRLC7SaDQKzK?q=20"></p></div></div></div></figure><p id="2aa7">So, what should you list on your resume?</p><p id="8bab">Proficiency in programming languages is, ostensibly, a vital thing to include. Always remember that companies are getting tens, hundreds, even thousands of applications a month. All of which say “I can do X.” The thing is skill level varies between each applicant. You should describe your coding experience and give examples of successful projects you’ve completed.</p><p id="dbb6">When listing your most valuable programming skills, there are a couple of things you need to know in order to have a fully optimized programming resume.</p><ol><li id="72b7">Before sending your resume, always go through the job description a couple of times and try to understand what is relevant to the job you are applying for. Then make yourself relevant to the job.</li><li id="dd11">Always be honest with yourself. Don’t list programming languages you don’t know because they are mentioned in the job description. Don’t tell them you have 5 years of experience when you only have 4 years and 1 month.</li><li id="1642">Place your programming skills (languages) right at the top, below the header.</li><li id="a384">List your most advanced coding skills first, then in the middle list the ones you are least experienced with, and at the end, list the programming skills you have a decent experience with.</li><li id="44ae">Create horizontal categories instead of vertical ones. This eliminates the blank space on your resume while remaining aesthetically pleasing.</li></ol><p id="1230">In your resume, except for talking about what you bring to the table, you can also mention what you’re looking for in an employer. You’ll thus earn the respect you are looking for if you get the job.</p><p id="48b7">Also, avoid using phrases that everybody else is using. Don’t be afraid to infuse your CV with some personality. You’ll thus stand out. Not everybody will like your personality, but those that do will adore you. Try to be specific in your writing. Instead of “extensive experience,” say “5 years and 6 months of experience.” Instead of saying “Y number of successful projects,” say “Y amount of successful projects that helped us achieve A, …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codegiant.io/programming-skills-d77d4abdf255">https://blog.codegiant.io/programming-skills-d77d4abdf255</a></em></p>]]>
            </description>
            <link>https://blog.codegiant.io/programming-skills-d77d4abdf255</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589474</guid>
            <pubDate>Fri, 25 Sep 2020 13:30:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacOS-like Fonts on Manjaro/Arch Linux]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 146 (<a href="https://news.ycombinator.com/item?id=24588947">thread link</a>) | @aswinmohanme
<br/>
September 25, 2020 | https://aswinmohan.me/posts/better-fonts-on-linux/ | <a href="https://web.archive.org/web/*/https://aswinmohan.me/posts/better-fonts-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Either you love gorgeous typography or just don’t care. If you are the former read ahead on how to make the font rendering on your Linux look just as awesome as that on macOS, else read on to find out what beauty you have been missing.</p>
<p>I switched to a hackintosh for a while and fell in love with how beautiful the typography was. After returning to Linux and some fiddiling around I came across a not so ugly setup that looked close enough to macOS. So if you want to make your Linux Distro a tad bit typographically better, follow along.</p>
<h3 id="results">Results</h3>
<p>This is how the fonts look on the default installation of Manjaro Linux.
</p><figure>
    <img src="https://aswinmohan.me/images/before_macosfont.png"> <figcaption>
            <h4>Search before font change</h4>
        </figcaption>
</figure>

<figure>
    <img src="https://aswinmohan.me/images/wikipedia_beforefonts.png"> <figcaption>
            <h4>Wikipedia before font change</h4>
        </figcaption>
</figure>

<p>This is how they would look after we are done.
</p><figure>
    <img src="https://aswinmohan.me/images/after_macos.png"> <figcaption>
            <h4>Search after font change</h4>
        </figcaption>
</figure>

<figure>
    <img src="https://aswinmohan.me/images/wikipedia_afterfonts.png"> <figcaption>
            <h4>Wikipedia after font change</h4>
        </figcaption>
</figure>

<h3 id="some-pointers">Some Pointers</h3>
<p>Rather than copy pasting everything on here, let’s try to understand why the fonts on macOS looks better than the ones we have on Linux.</p>
<p>Fonts belong to certain types.</p>
<ul>
<li><code>sans-serif</code> : Well the sans fonts on your computer. The regular plain fonts.</li>
<li><code>serif</code> : The fonts that look like they came out of a 14th century Bible. You know with the curves and they look like showoffs.</li>
<li><code>monospace</code> : The typical code font. The ones where every character is the same width.</li>
</ul>
<p>The reason fonts look way better on macOS is because Steve Jobs loved typography, and he went the extra mile and licensed some great typefaces for each font type, and recently Apple put in the extra effort to make their custom fonts even better. Well fret not Linux has some free fonts that are metric compatible(means they look awfully similar), and better that we can substitute for fonts.</p>
<h3 id="installation">Installation</h3>
<p>Step one is installing the fonts that look similar or better than the ones on macOS.
All the fonts that are used here can be found on the Arch Repositories, and on Google Fonts. You are free to replace everything with the ones you find great.</p>
<ul>
<li><code>sans-serif</code> : tex-gyre-fonts, free alternative to Helvetica and Arial and looks really really similar</li>
<li><code>serif</code> : Libertinus Serif, suprisingly looks really great</li>
<li><code>monospace</code> : DM Mono from Google Fonts, for monospace fonts that look great</li>
<li><code>emoji</code> : noto-fonts-emoji, get some colorful emojis</li>
</ul>
<p>If you are using Manjaro or Arch here is the command to get all fonts in one go.</p>
<div><pre><code data-lang="fallback">yay -S tex-gyre-fonts otf-libertinus noto-fonts-emoji
</code></pre></div><h3 id="font-setup">Font Setup</h3>
<p>Everything about fonts can be configured from a single file located at <code>/etc/fonts/local.conf</code> if the file doesn’t exist create it. You do require <code>sudo</code> for it.</p>
<div><pre><code data-lang="fallback">sudo nvim /et/fonts/local.conf
</code></pre></div><p>After you are editing the file copy paste everything here.</p>
<div><pre><code data-lang="fallback">&lt;?xml version='1.0'?&gt;
&lt;!DOCTYPE fontconfig SYSTEM 'fonts.dtd'&gt;
&lt;fontconfig&gt;

&lt;match target="font"&gt;
  &lt;edit name="autohint" mode="assign"&gt;
    &lt;bool&gt;true&lt;/bool&gt;
  &lt;/edit&gt;
  &lt;edit name="hinting" mode="assign"&gt;
    &lt;bool&gt;true&lt;/bool&gt;
  &lt;/edit&gt;
  &lt;edit mode="assign" name="hintstyle"&gt;
    &lt;const&gt;hintslight&lt;/const&gt;
  &lt;/edit&gt;
  &lt;edit mode="assign" name="lcdfilter"&gt;
   &lt;const&gt;lcddefault&lt;/const&gt;
 &lt;/edit&gt;
&lt;/match&gt;


&lt;!-- Default sans-serif font --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;-apple-system&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Helvetica Neue&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Helvetica&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;arial&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;sans-serif&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;
 
&lt;!-- Default serif fonts --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;serif&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Libertinus Serif&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Noto Serif&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Noto Color Emoji&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAPMincho&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;HanaMinA&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

&lt;!-- Default monospace fonts --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;SFMono-Regular&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Menlo&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;monospace&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

&lt;!-- Fallback fonts preference order --&gt;
 &lt;alias&gt;
  &lt;family&gt;sans-serif&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Sans&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Open Sans&lt;/family&gt;
   &lt;family&gt;Droid Sans&lt;/family&gt;
   &lt;family&gt;Ubuntu&lt;/family&gt;
   &lt;family&gt;Roboto&lt;/family&gt;
   &lt;family&gt;NotoSansCJK&lt;/family&gt;
   &lt;family&gt;Source Han Sans JP&lt;/family&gt;
   &lt;family&gt;IPAPGothic&lt;/family&gt;
   &lt;family&gt;VL PGothic&lt;/family&gt;
   &lt;family&gt;Koruri&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;
 &lt;alias&gt;
  &lt;family&gt;serif&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Serif&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Droid Serif&lt;/family&gt;
   &lt;family&gt;Roboto Slab&lt;/family&gt;
   &lt;family&gt;IPAPMincho&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;
 &lt;alias&gt;
  &lt;family&gt;monospace&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Sans Mono&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Inconsolatazi4&lt;/family&gt;
   &lt;family&gt;Ubuntu Mono&lt;/family&gt;
   &lt;family&gt;Droid Sans Mono&lt;/family&gt;
   &lt;family&gt;Roboto Mono&lt;/family&gt;
   &lt;family&gt;IPAGothic&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;

&lt;/fontconfig&gt;
</code></pre></div><p>What this file does that is it creates aliases for the common fonts used on the web and uses the metric compatible fonts that we have. That way we have way better looking fonts.</p>
<p>After you have done all this, restart your computer to see the changes.</p>
<h3 id="chrome">Chrome</h3>
<p>If you are using chrome, you can do something more too.</p>
<ul>
<li>Goto Settings</li>
<li>Select Customize Fonts under Appearences</li>
<li>Set Standard to <code>Libertinus Serif</code></li>
<li>Set Serif to <code>Libertinus Serif</code></li>
<li>Set Sans-serif to <code>TeX Gyre Heros</code></li>
<li>Set Fixed-width to <code>Monospace</code></li>
</ul>
<h3 id="interface-text">Interface Text</h3>
<p>For Desktop Environments like Gnome and KDE, you could use Tex-Gyre-Heros for the overall Helvetica look. I use Gnome 3.36 and use <code>TeX Gyre Heros Regular 10</code> as my interface text.</p>
<p>That’s all set, and keep in mind this guide will be improved.</p>

			</div></div>]]>
            </description>
            <link>https://aswinmohan.me/posts/better-fonts-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588947</guid>
            <pubDate>Fri, 25 Sep 2020 12:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What makes a good REPL? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24588453">thread link</a>) | @diggan
<br/>
September 25, 2020 | https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html | <a href="https://web.archive.org/web/*/https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <ol><li><a href="#what_does_a_good_repl_give_you?">What does a good REPL give you?</a></li><ol><li><a href="#a_smooth_transition_from_manual_to_automated">A smooth transition from manual to automated</a></li><li><a href="#a_repl_lets_you_improvise">A REPL lets you improvise</a></li><li><a href="#a_repl_lets_you_write_fewer_tests,_faster">A REPL lets you write fewer tests, faster</a></li><li><a href="#a_repl_makes_you_write_accessible_code">A REPL makes you write accessible code</a></li></ol><li><a href="#what_makes_a_good_repl?">What makes a good REPL?</a></li><li><a href="#what_makes_a_programming_language_repl-friendly?">What makes a programming language REPL-friendly?</a></li><li><a href="#conclusion">Conclusion</a></li></ol>
    <p> <i>Dear Reader: although this post mentions Clojure as an example, it is not specifically about Clojure; please do not make it part of a language war. If you know other configurations which allow for a productive REPL experience, please describe them in the comments!</i></p><p> <img src="https://vvvvalvalval.github.io/img/repl.gif" width="100%"></p><p>Most comparisons I see of Clojure to other programming languages are in terms of its programming language <em>semantics</em>:  immutability, homoiconicity, data-orientation, dynamic typing, first-class functions, polymorphism 'à la carte'...  All of these are interesting and valuable features, but what actually gets me to <em>choose</em> Clojure for projects is its interactive  development story, enabled by <em>the REPL</em> (Read-Eval-Print Loop), which lets you evaluate Clojure expressions in an interactive  shell (including expressions which let you modify the state or behaviour of a running program).  </p><p>If you're not familiar with Clojure, you may be surprised that I describe the REPL as Clojure's most differentiating feature:   after all, most industrial programming languages come with REPLs or 'shells' these days (including Python, Ruby, Javascript, PHP, Scala,  Haskell, ...). However, I've never managed to reproduced the productive REPL workflow I had in Clojure with those languages;  the truth is that <strong>not all REPLs are created equal</strong>.</p><p>In this post, I'll try to describe what a 'good' REPL gives you, then list some technical characteristics which make some REPLs   qualify as 'good'. Finally, I'll try to reflect on what programming language features give REPLs the most leverage.</p><h2 id="what_does_a_good_repl_give_you?">What does a good REPL give you?</h2><p>The short answer is: by providing a <i>tight feedback loop</i>, and making your programs <i>tangible</i>,  a REPL helps you deliver programs with significantly higher productivity and quality.  If you're wondering why a tight feedback loop is important for creative activities such as programming, I recommend you watch  <a href="https://www.vimeo.com/36579366">this talk by Bret Victor</a>.</p><p>If you have no idea what REPL-based development looks like, I suggest you watch a few minutes of  <a href="https://vimeo.com/230220635" target="_blank">the following video</a>:</p><p><iframe src="https://player.vimeo.com/video/230220635" width="640" height="359" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p><p>Now, here's the long answer: <i>A good REPL gives you...</i></p><h3 id="a_smooth_transition_from_manual_to_automated">A smooth transition from manual to automated</h3><p>The vast majority of the programs we write essentially automate tasks that humans can do themselves.  Ideally, to automate a complex task, we should be able to break it down into smaller sub-tasks, then gradually automate each of the subtasks until reaching a fully-automated solution.  If you were to build a sophisticated machine like a computer from scratch, you would want to make sure you understand how the individual components work before putting them together, right?  Unfortunately, this is not what we get with the typical write/(compile)/run/watch-stdout workflow, in which we essentially put all the pieces together blindly and pray it works the first time we hit 'run'.  The story is different with a REPL: you will have played with each piece of code in isolation before running the whole program,  which makes you quite confident that each of the sub-tasks is well implemented.</p><p>This is also true in the other direction: when a fully-automated program breaks, in order to debug it,  you will want to re-play some of the sub-tasks manually.</p><p>Finally, not all programs need be fully automated - sometimes the middle ground between manual and automated is exactly what you want.  For instance, a REPL is a great environment to run ad hoc queries to your database, or perform ad hoc data analysis, while leveraging  all of the automated code you have already written for your project - much better than working with database clients, especially when  you need to query several data stores or reproduce advanced business logic to access the data.</p><p>How's life without a REPL? Here's a list of things that we do to cope with these issues when we don't have a REPL:</p><ul><li>Experiment with interactive tools such as cURL or database clients, then reproduce what we did in code.  Problem: you can't connect these in any way with your existing codebase. These tools are good at experimenting manually,  but then you have to code all the way to bridge the gap between making it work with these tools and having it work in your project.</li><li>Run scripts which call our codebase to print to standard output our files. Problem: you need to know exactly what to output before writing the script; you can't hold on to program state and <em>improvise</em> from there, as we'll discuss in the next section.</li><li>Use unit tests (possibly with auto-reloading), which have a number of limitations in this regard, as we'll see later in this post.</li></ul><h3 id="a_repl_lets_you_improvise">A REPL lets you improvise</h3><p>Software programming is primarily and <i>exploratory</i> activity.  If we had a precise idea of how our programs should work before writing them, we'd be <i>using</i> code, not writing it.</p><p>Therefore, we should be able to write our programs incrementally, one expression at a time, figuring out what to do next at each step,  <i>walking the machine through</i> our current thinking. This is simply not what the  compile/run-the-whole-thing/look-at-the-logs workflow gives you.</p><p>In particular, one situation where this ability is critical is fixing bugs in an emergency.  When you have to reproduce the problem, isolate the cause, simulate the fix and finally apply it, a REPL is often the  difference between minutes and hours.</p><p>Fun fact: maybe the most spectacular occurrence of this situation was the fixing of a bug  of the <a href="https://www.youtube.com/watch?v=_gZK0tW8EhQ">Deep Space 1</a> probe in 1999,  which fortunately happened to run a Common Lisp REPL while drifting off course several light-minutes away from Earth.</p><h3 id="a_repl_lets_you_write_fewer_tests,_faster">A REPL lets you write fewer tests, faster</h3><p>Automated tests are very useful for expressing what your code is supposed to do,  and giving you confidence that it works and keeps working correctly.</p><p>However, when I see some TDD codebases, it seems to me that a lot of unit tests are mostly here to make the code more tangible while developing, which is the same value proposition as using a REPL. However, using unit tests for this purpose comes with its lot of issues:</p><ol><li>Having too many unit tests makes your codebase harder to evolve. You ideally want to have as few tests as possible capture as many properties of your domain as possible.</li><li>Tests can only ever answer close-ended questions: "does this work?", but not "how does this work?", "what does this look like?" etc.</li><li>Tests typically won't run in real-world conditions: they'll use simple, artificial data and mocks of services such as databases or API clients. As a result, they don't typically help you understand a problem that only happens on real-life data, nor do they give you confidence that the real-life implementations of the services they emulate do work.</li></ol><p>So it seems to me a lot of unit tests get written for lack of a better solution for interactivity,  even though they don't really pull their weight as unit tests.  When you have a REPL, you can make the choice to only write the tests that matter.</p><p>What's more, the REPL <i>helps you</i> write these tests. Once you have explored from the REPL, you can just copy and paste  some of the REPL history to get both example data and expected output. You can even use the REPL to assist you in writing  the fixture data for your tests by generating it programmatically (everyone who has written comprehensive fixture datasets  by hand knows how tedious this can get). Finally, when writing the tests require implementing some non-trivial logic  (as is the case when doing Property-Based Testing), the productivity benefits of the REPL for writing code applies to writing tests as well.</p><p>Again, do <i>not</i> take from this that a REPL is a replacements for tests. Please do write tests, and let the REPL help you  write the right tests effectively.</p><h3 id="a_repl_makes_you_write_accessible_code">A REPL makes you write accessible code</h3><p>A REPL-based workflow encourages you to write programs which manipulate values that are <strong><i>easy to fabricate.</i></strong>  If you need to set up a complex graph of objects before you can make a single method call, you won't be very inclined to use the REPL.  </p><p>As a result, you'll tend to write <strong><i>accessible code</i></strong> - with few dependencies, little environmental coupling, high modularity,   and tangible inputs and outputs.  This is likely to make your code more clear, easy to test, and easy to debug.  </p><p>To be clear, this <i>is</i> an additional constraint on your code (it requires some upfront thinking to make your code REPL-friendly,  just likes it requires some upfront thinking to make your code easy to test) - but I believe it's a very beneficial constraint.  When my car engine breaks, I'm glad I can just lift the hood and access all the parts - and making this possible  has certainly put more work on the plate of car designers.</p><p>Another way a REPL makes code more accessible is that it makes it easier to learn, by providing a rich playground for beginners to experiment.  This applies to both learning languages and onboarding existing projects.</p><h2 id="what_makes_a_good_repl?">What makes a good REPL?</h2><p>As I said above, not all REPLs give you the same power.  Having experimented with REPLs in various configurations of language and tooling,  this is the list of the main things I believe a REPL should enable you to do to give you the most leverage:</p><ol><li><strong>Defining new behaviour / modify existing behaviour.</strong> For instance, in a procedural language, this means defining new functions, and modify the implementation of existing functions.</li><li><strong>Saving state in-memory.</strong> If you can't hold on to the data you manipulate, you will waster a ton of effort re-obtaining it - it's like doing your paperwork without a desk.</li><li><strong>Outputting values which can easily be translated to code.</strong> This means that the textual representation the REPL outputs is suitable for being embedded in code.</li><li><strong>Giving you access to your whole project code.</strong> You should be able to call any piece of code written in your project of its dependencies. As an execution …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html">https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html</a></em></p>]]>
            </description>
            <link>https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588453</guid>
            <pubDate>Fri, 25 Sep 2020 10:38:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Elixir's Phoenix Framework Does Right]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24588122">thread link</a>) | @dinomad
<br/>
September 25, 2020 | https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>I dabbled in Phoenix for a while now, but never <em>really</em> got my hands dirty with it right up until now. Apart from the whole framework being surprisingly well thought through, there are a few things that strike me as being done <em>exceptionally</em> well in Phoenix, compared to the rest of modern web frameworks.</p><p><img src="https://scorpil.com/img/phoenix.png" alt="Phoenix Framework Logo"></p><h3 id="1-striking-a-balance-between-flexibility-and-strictness">1. Striking a balance between flexibility and strictness</h3><p>Modern web frameworks can be roughly divided into two camps:</p><ul><li>Flexible “DIY” frameworks are a little more than a set of utilities for the most common web-related tasks. Most Go frameworks are like this, as well as ExpressJS. They enforce little to no rules for the structure of your applications and rely on the community to come up with the extensions and best practices. As a result, they are very flexible; those with a large community have extensions to perform any task imaginable. On the flip side, apps built on such a foundation can, given poor governance, slowly evolve into an unsupportable mess of incompatible plugins and mismatched coding styles.</li><li>Strict “batteries included” frameworks bring with them a complete set of tools to perform common web development tasks, as well as a set of conventions to go with it. They guide the developer into optimal code structure and typically strive to provide a single favored way of doing things. Of course, these kinds of frameworks are also extendable, but built-in tools often get embedded so deep into the project that they are almost irreplaceable. In this category, the most popular examples are Django and Ruby on Rails.</li></ul><p>Of course, most frameworks are not on an extreme end of the scale, but the distinction is there. Worth noting that neither group is strictly better than the other – each has its usecases.</p><p>Phoenix Framework, in my mind, holds very close to the middle of this scale for these reasons:</p><ul><li>it builds upon Elixir’s functional philosophy, so it has a very clear idea how things <em>should</em> work (single request context passed around as the first argument to all components that participate in a response generation, avoiding side effects where possible, MVC-inspired architecture, etc.)</li><li>it does not hide its internal details in a “black box”, quite the opposite - it encourages you to understand internal conventions to write your own code in the same fashion. When you get comfortable using a framework, you can probably read its code without too much trouble.</li><li>by default Phoenix comes with a huge pack of tools and utils (ORM, routing, test suit, HTML rendering, metrics dashboard (sic!)…), but in most cases, there’s a trivial way to swap them out or turn them off.</li></ul><h3 id="2-reactiveness">2. Reactiveness</h3><p>When an app requires bi-directional communication between client and server, you usually either
integrate a 3rd party library into the framework, which means writing a pile of glue code, or
use a specialized framework like Tornado, which (caution, personal opinion here) kind of an awkward choice for those parts of the web app that do not concern themselves with WebSockets.</p><p>Phoenix is great for classical HTTP, but persistent communication is where it <em>really</em> shines. Primitives it gives you with channels, PubSub and Presence are just enough to avoid boilerplate without sacrificing flexibility. Recent live view release is a whole new way of building dynamic apps. I wouldn’t go as far as to call it revolutionary, but it is definitely an intriguing attempt of bridging the gap between frontend and backend.</p><h3 id="3-performance">3. Performance</h3><p>Phoenix’s performance has surprisingly little to do with the framework itself. It inherited its impressive concurrence characteristics from Elixir, which got it from Erlang, which got it thanks to the primitives of the BEAM virtual machine and the architectural patterns of OTP. The main principle at work to achieve concurrency is to schedule lightweight threads of execution to run each independent piece of work concurrently. You might have seen this approach in other languages (goroutines, python’s greenlets, etc.), that’s because it works great to organize concurrent code execution without performance hit and with a minimal headache for a developer. However, BEAM gives this concept support on a VM level, which means it can be optimized even on a hardware level.</p><p>While lightweight processes help you perform well on your IO-bound tasks, Elixir being a compiled language means that CPU bound tasks won’t bottleneck easily as well, and perform on less computing resources than most alternatives. While I can’t be 100% sure that it will be faster for your application than Go or Rust in terms of CPU usage, I’m reasonably sure that it will be more than fast enough in a context of a typical web app.</p><p><em><strong>Update:</strong> correction based on discussion in here and on other platforms: Elixir is slower than Go/Rust on purely CPU-bound tasks, mainly because BEAM interrupts running threads for task scheduling. Also, Elixir/Erlang compiles to bytecode, not directly to the machine code (although BeamAsm, JIT compiler for Erlang’s VM, has <a href="https://github.com/erlang/otp/pull/2745">landed in master 4 days ago</a>, so this should change in the next OTP release).</em></p><h3 id="4-failure-tolerance-and-cluster-awareness">4. Failure tolerance and cluster-awareness</h3><p>You might have heard Phoenix being called a “monolithic framework”. This is true to some extent: Phoenix <em>does</em> encourage you to put your frontend, backend, and background tasks in the same app. However, it also provides facilities to ensure that failure in a single component of the app will not affect other independent components. To explain in short, the app is divided into processes that communicate with each other via kind-of event messages. Each component is supervised, the supervisor will catch unhandled failures and restart the process in an attempt to fix them. It’s somewhat reminiscent of a microservice architecture, just on a lower level.</p><p>Unlike most frameworks, Phoenix understands that it will most likely run on more than one node. It provides a way to communicate over the network in exactly the same way you communicate between the processes within your app.</p><p>This does not mean that Phoenix is a bad choice for microservices, it just means that framework itself can handle some of the same concerns microservices are designed to handle. A smaller app might benefit from that by avoiding some of the complexities of building up your own microservices architecture. Bigger apps, and those that are already built as microservices, can still incorporate Phoenix effectively.</p><h3 id="are-there-any-drawbacks">Are there any drawbacks?</h3><p>Elixir, and functional programming in general, is still a long way away from the mainstream. If you don’t know your way around closures, immutable data structures, and functional thinking it will take you a while before getting to feel comfortable with Phoenix. The good news is that functional programming is on an upwards trend, and with applications growing more parallel and distributed, I don’t think this trend will reverse any time soon. So the knowledge you acquire in the process will serve you well going forward, independent from what the future holds for Phoenix.</p><p>The included tooling is great, but you might miss some 3rd party SDK’s when you need them. That’s definitely something to consider when starting a project. To give you an example: <a href="https://aws.amazon.com/getting-started/tools-sdks/">AWS</a> at the time of writing does not provide an official elixir client library.</p><p>Phoenix Framework a rock-solid, production-ready tool with a variety of usecases. It feels fresh and well thought through. I won’t be surprised if Phoenixes popularity continues to grow to reach the level of „Top tier“ frameworks in the next few years.</p></div></article></div></div></div></div>]]>
            </description>
            <link>https://scorpil.com/post/things-elixirs-phoenix-framework-does-right/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588122</guid>
            <pubDate>Fri, 25 Sep 2020 09:29:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Throw away code]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24587934">thread link</a>) | @lukastyrychtr
<br/>
September 25, 2020 | https://vorner.github.io/2020/09/20/throw-away-code.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/09/20/throw-away-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>There’s an ongoing discussion about what makes Python better prototyping
language than Rust (with Python being probably just the archetype of some
scripted weakly-typed language). The thing is, I prefer doing my prototypes in
Rust over Python. Apparently, I’m not the only one. So I wanted to share few
things about what makes Rust viable for these kinds of throw-away coding
sprints, at least for me.</p>

<h2 id="our-goals">Our goals</h2>

<p>Sometimes, our goal isn’t really to write perfect code that is performant,
correct, handles all kinds of errors sanely, has great UX and is maintainable.
These projects are what we are proud of, sure. We pin them on github profiles.
We write blog posts about them. We write whole handbooks of best practices how
to do them.</p>

<p>But sometimes we just need to throw something together really fast and don’t
care about the quality as much. That kind of bit of cardboard and huge amount of
duck tape thing. These include:</p>

<ul>
  <li>Single-use debugging tools („I need to throw 10k of these weird requests at
the server to see if it triggers the bug. It didn’t? Ok, let’s try something
else…“)</li>
  <li>Searching for a counter-example to a claim in a scientific paper („I can prove
it’s a counter example once I have it, so I won’t need the code any more“)</li>
  <li>Processing bunch of data just once („I wonder how many of these <code>.txt</code> files
have broken unicode in them“)</li>
  <li>Figuring if something has any chance to fly at all, before committing to it
(„Could I distribute the changes as compressed binary diffs, or would that be
too large?“)</li>
  <li>Demonstration purposes („We would like to build something in lines of this,
but, you know, actually working“)</li>
</ul>

<p>Of course, there’s a lot more. I’m not even sure if there’s more of the „proper“
coding or of this „throw away“ coding. Except that we don’t really brag about
our throw-away code („Look what terrible monster I’ve stitched together during
the lunch break“), we don’t write tutorials how to write them much, etc. So this
is exactly the kind of blog post we don’t write 😈.</p>

<p>Instead of writing something proper this time, we are going to talk about
how to write terrible code, but fast. We have decided to make an explicitly
sloppy job of this one and admit it to ourselves not to feel ashamed of it
later:</p>

<ul>
  <li>We want to spend as little time on it as possible. Just do it, throw the code
away after it had its use and move on. This one is going to be over by lunch
time.</li>
  <li>We don’t care about performance that much (as long as it finishes running
before the lunch too).</li>
  <li>We don’t care about handling all corner cases, only the ones we actually
encounter in the data.</li>
  <li>We don’t care about documentation or readability.</li>
  <li>We don’t care about tests, provided we are confident enough the answers are
accurate enough.</li>
  <li>Actually, we don’t really care at all…</li>
</ul>

<p><em>Note: make sure not to let anyone put this into production 😇. If you don’t
delete it, make sure there’s a comment on a prominent place warning people not
to use it.</em></p>

<h2 id="why-do-people-think-python-fits-here-better-than-rust">Why do people think Python fits here better than Rust</h2>

<p>The thing is, Rust <em>makes us</em> care. That’s one of the points of Rust. It’ll
complain that our code is not production quality and that we need to do better
to save on the pain down the line. Its type system can be a real prick in
insisting on little details, like that ints and strings are not really the same
thing and that there’s a difference between owned and borrowed thing and… Well,
you know, all that stuff. Rust wants you to make good, proper, maintainable
code.</p>

<p>On the other hand, Python doesn’t really insist on anything. Therefore, it is
easier to not care in Python.</p>

<h2 id="my-own-experience">My own experience</h2>

<p>I know a bunch of programming languages and reach for the one that I hope would
suit me best in the given time. So, for some really simple things I simply put
together few lines of shell (and some slightly less simple ones ‒ I’m ashamed to
admit that some 1000 lines long shell monster kept running in real production
for years ‒ but it <em>did run</em>). If it can be done by 2 or 3 ugly pipelines, it’s
fine.</p>

<p>Over the years, I’ve used Perl a lot (that one doesn’t care if it’s int or
string… no, correction, in Perl everything is a string, ints just don’t exist.
Well, kind of). It’s probably <em>the</em> language designed for throw away coding.
I’ve done some Python too (that’s like Perl, but with proper objects in it, and
everything is a dictionary there).</p>

<p>But recently I’ve noticed that if I try to do a similar thing, I do it faster in
Rust. Not that it runs faster (well, that usually too, but that’s not the
point), but that I’m done with the task at hand sooner and with slightly smaller
amount of cursing.</p>

<p>This certainly is in part because I’m more proficient in Rust than in Python.
It’s also because the Rust mental model is closer to how my brain works than the
Python one. <strong>Your mileage will vary</strong> ‒ if you’re a Python matador who’s been
coding in it for decades and are just learning Rust, you’ll certainly do it
faster in Python.</p>

<p>But also, there are some tricks you might employ to do these things in Rust
faster (that is, faster than you do now, not necessarily faster than in
<code>$OTHER_LANGUAGE</code>).</p>

<h2 id="tricks-for-faster-coding">Tricks for faster coding</h2>

<h3 id="compile-times">Compile times</h3>

<p>Rust is known for its slow compile times. Python has <em>no</em> compile times. If you
have to wait every time for the compilation just to have a bunch of errors
thrown into your face, it’s going to slow you down. Especially because Rust
<em>likes to</em> throw bunch of errors at you every time you try to compile it. Rust
is known for its great error messages, so it wants to brag how good they are by
using them <em>a lot</em>.</p>

<p>You can, however, notice that you don’t really need to <em>build and run</em> every
time. That you often just want to check everything is on the right path. For
Python, you do need to actually run the thing (because Python doesn’t really
have much of a compile time so it likes to throw the bunch of errors into your
face at <em>run time</em>), but Rust is the language that „if
it compiles, it’s correct“. And by complies, I actually mean mostly type-checks.</p>

<p>What does this all mean? You can check out:</p>

<ul>
  <li>The <code>rust-analyzer</code> language server. You’ll be getting red squiggles in the
editor instead of having to compile. It’s not perfect (sometimes the list of
errors is different, sometimes it just gives up on that particular project),
but it’s getting better and it points out most of the errors without any
compilation at all.</li>
  <li><code>cargo check</code> performs just the first stages of compilation and will stop
before codegen. It means it doesn’t produce anything that could be run, but
it is so much faster and provides the bunch of errors we so much want to have.</li>
  <li>You can let <code>cargo watch</code> keep recompiling the code asynchronously in another
terminal. I just glance at it to check if there are any errors around, but I
don’t wait for it ‒ at worst, the list of errors is one iteration outdated. It
can be used for other things, like keeping the documentation of the current
crate up to date, or having a head start at compiling the executable, or even
having all the tests being re-run on each save (I’m getting off topic here; we
are being sloppy here on purpose, so what tests are we talking about?)</li>
</ul>

<p>These don’t make the compile times shorter, but it eliminates the <em>waiting</em> for
them from the hot coding path. It still takes some time to compile (especially
if you have a lot of dependencies and do a clean release build), but that
doesn’t mean it has to slow you down.</p>

<h3 id="embrace-the-type-system-and-borrow-checker-and-all-of-these-things">Embrace the type system (and borrow checker and all of these things)</h3>

<p>After some time working with Rust, one learns to lean onto them instead of
fighting them.</p>

<p>This is where most of my own speed up comes from and what I miss about Python.
When I want to know if my code is working, I actually have to run the Python
thing and feed it with data. Which means I either need to set up a smaller input
or wait for the whole thing to get crunched, only to have it explode on some
typo or switched order of parameters after 5 minutes of running. After 10
iterations of running the Python code (each crashing later and later in the
code), it finally finishes. By that time, I’m no longer confident it does what
it should, after all these retries, so I go back and have to figure a way to
double-check it.</p>

<p>In Rust not only I don’t have to run the code until it is almost finished and
even when I feed it the whole input (which I usually do), it’s usually faster
and it runs to completion the first time. I also can move through the code much
faster. With Python, I stop to check the documentation, think about what type
goes where, etc, exactly because it’s so painful to find out only at runtime. I
need to be careful while writing the code.
With Rust, I just type the code, get the red squiggly, fix it and move on. I
outsource that effort of checking if these things click together in any
meaningful way to the compiler.</p>

<p>This is kind of in the theme of „hurry slowly“ approach. By making sure
everything has the right types and aligns well, it makes each iteration slower.
But it also makes it possible to have much fewer iterations before the whole
thing works well enough.</p>

<p>Also, don’t fall for the impression that throwing <code>unsafe</code> in there to bypass
some of the checking will save you time. It won’t. It’s a trap. If you don’t
know for sure that you need it, then you probably don’t and doing <code>unsafe</code> right
is a lot of work. Doing it wrong is easy, maybe easier than doing it safely, but
you’ll pay for it later on, when trying to figure out why the thing does
something arcanely weird. If you put any non-trivial <code>unsafe</code> in the code,
you’re risking spending days and nights in front of a debugger. The checks are
there for a reason.</p>

<h3 id="take-the-easy-way-out">Take the easy way out</h3>

<p>I don’t say to clone everything. Even in prototyping code, I often take <code>&amp;str</code>
as parameter if it’s just „looking at it“. But I do so in the obvious, trivial
cases. The ones I don’t really need to think about any more.</p>

<p>But if you ever find yourself thinking about writing any kind of
<code>-&gt; impl Iterator&lt;Item = &amp;impl Display&gt; + '_</code>, just stop and throw a
<code>Vec&lt;String…</code></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/09/20/throw-away-code.html">https://vorner.github.io/2020/09/20/throw-away-code.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/09/20/throw-away-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587934</guid>
            <pubDate>Fri, 25 Sep 2020 08:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Zone Bugs I Ran Into]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24586991">thread link</a>) | @Sandeepg33k
<br/>
September 24, 2020 | https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into | <a href="https://web.archive.org/web/*/https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600871234687/et6yX6Wlb.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>Software development is hard. Time zones are hard. Dealing with time zones in software development?  Yeah, <strong>harder</strong>.</p>
<p>Here are <strong>4</strong> places where time zones might differ; and 4 personal bug stories for each case. I'll be referring to the same app for each story, the one I work with and maintain in my day-to-day job. This app works with Mexico's City time zone.</p>

<h2 id="time-zone-of-your-app">Time zone of your app</h2>
<p>Your app runs with a default time zone. It's usually the time zone of the server it runs on, but it can be different.</p>
<p>In Java, you can define the time zone of the whole application when it boots. If for some reason you don't want to work with your server's timezone, this is the place to change it.</p>
<h3 id="the-bug-time-in-chile-off-by-one-hour">The bug - Time in Chile off by one hour</h3>
<p>The app shows the date of creation of an object in many places. Three of these places were showing different times; <strong>two incorrect and one correct</strong>.</p>
<p>One error was because I forgot to pass the user's timezone to the date formatter. Quick fix.</p>
<p>The second error was weird. I couldn't identify why, so I compared it with the correct one.</p>
<p>But the third case was only right because the date had been double parsed! Once on the server and a second time on the client (browser).</p>
<p>So none of the three dates were actually correct. <strong>WTF?</strong></p>
<p>After some headaches, I learned that each version of Java comes with a time zone data file. This file includes the latest information on the world's time zones, and the <a target="_blank" href="https://www.iana.org/time-zones">Internet Assigned Numbers Authority (IANA)</a> manages it. </p>
<p>Time zone changes happen when governments decide to apply or not to apply daylight saving times (DST). </p>
<p>In 2015, Chile decided to move from seasonal DST to permanent DST, and some JRE releases included this change. But then, in 2016 Chile decided to revert to how it was before; seasonal DST instead of permanent. <strong>What was the issue?</strong> The app was using one of these JRE releases with an outdated time zone data file.</p>
<p>You can read more about these <a target="_blank" href="https://hi.service-now.com/kb_view.do?sysparm_article=KB0622033">DST issues with Java here</a>.</p>

<h2 id="time-zone-of-your-server">Time zone of your server</h2>
<p>The operative system defines your server's time zone. I've always used Linux for production servers, and they come with UTC as the default time zone.</p>
<p>If you need to change this time zone, make sure to do it before your application starts or it won't reflect the change.</p>
<h3 id="the-bug-app-using-the-wrong-default-time-zone-from-the-server">The bug - App using the wrong default time zone from the server</h3>
<p>I was migrating some processes in our build and deployment pipeline. From configuring the app with every deploy to a pre-built AWS Amazon Machine Image (AMI) with HashiCorp's Packer.</p>
<p>One step of the initial configuration was to change the server's time zone to America/Mexico_City, and I was aware of it. So I created a bash script that changed the time zone on the AMI we were going to use. The script worked well when I tested it on a Linux instance. No problem there.</p>
<p>I proceeded to use this AMI in our staging environment and neither I nor my teammates noticed something off. So, to production!</p>
<p>Customer's questions and complaints about dates behaving weird arrived minutes later 😥</p>
<p><strong>The issue?</strong> The script that updated the server's time zone was failing silently and I missed double-checking it in the staging environment. The app wasn't using an explicit time zone, so it took the server's. And the server's time zone was UTC by default, and we needed America/Mexico_City. I fixed the script and, to make sure, updated the app's default time zone to the expected one.</p>

<h2 id="time-zone-of-your-database">Time zone of your database</h2>
<p>You can also change your database's time zone. I use AWS Relational Database Service (RDS) and the default time zone is UTC. You can update it from the parameter group of your cluster or individual instance.</p>
<h3 id="the-bug-wrong-database-time-zone">The bug - Wrong database time zone</h3>
<p>Now I was doing a migration of our database. I anticipated myself by changing the database's time zone to America/Mexico_City because the app and server had it. Every part of the system should be in the same page, right? <strong>Wrong!</strong></p>
<p>The database was perfectly okay being in UTC while the app and server were in America/Mexico_City. That's how it worked. </p>
<p>This bug was not as critical as the previous ones because I caught it in our staging environment. </p>

<h2 id="time-zone-of-your-users">Time zone of your users</h2>
<p>If it wasn't enough, each one of your users can have a different time zone, and you have to take that into consideration when showing time sensitive-data.</p>
<h3 id="the-bug-many-of-them">The bug - Many of them!</h3>
<p>I've encountered many bugs related to user's time zones:</p>
<ul>
<li>Missing time zone in date formatter.</li>
<li>Incorrect time zone selection from the user.</li>
<li>Missing DST time zone options for users to select.</li>
<li>Storing dates with time zone modifications that get parsed again when retrieved.</li>
</ul>
<hr>
<p>Time zones are one of the most complicated topics you'll find while developing software. They're complex by themselves, and even more when you throw some code into the mix.</p>
<p>I hope these short stories can help you avoid my mistakes in the future 🙌🏼</p>
<p><strong>Thanks for reading me! 💙</strong></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586991</guid>
            <pubDate>Fri, 25 Sep 2020 06:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Iranian diaspora is using old-school tech to fight internet shutdown at home]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 35 (<a href="https://news.ycombinator.com/item?id=24585986">thread link</a>) | @rfreytag
<br/>
September 24, 2020 | https://restofworld.org/2020/cat-and-mouse-censorship/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cat-and-mouse-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>One November morning last year, Mehdi Yahyanejad listened to a voicemail in his Los Angeles office: “I’m contacting you from the city of Tehran,” said the voice. “This was the first time I’ve experienced an internet shutdown. … It feels like I’m in a prison.”</p>



<p>A few weeks earlier, Iran’s largest mobile networks and internet providers went offline. Amid weeks of growing anti-regime protests, Iranian authorities imposed <a href="https://edition.cnn.com/2019/11/18/middleeast/iran-protests-explained-intl/index.html">the longest internet shutdown</a> in the country’s history, effectively cutting off external communication for over 80 million Iranians. In an unprecedented crackdown, regime forces <a href="https://www.amnesty.org/en/latest/news/2020/05/iran-details-released-of-304-deaths-during-protests-six-months-after-security-forces-killing-spree/">killed more than 300 protesters</a> and arrested <a href="https://www.amnesty.org/en/latest/news/2019/12/iran-thousands-arbitrarily-detained-and-at-risk-of-torture-in-chilling-post-protest-crackdown/">over 7,000 people</a>. When access was finally restored on November 23, nearly half the country was still unable to come online.</p>



<p>Nine months after the November blackout, Iranians still live in fear of another all-out shutdown. As authorities tighten their hold on internet access, diaspora-led companies are filling the gap for Iranians who are seeking a way to bypass censors. The circumvention tools, created largely by diaspora entrepreneurs, are becoming increasingly critical as they face a crackdown at home and the bite of American-led sanctions online.</p>



<p>On November 15, as Iranian authorities first moved to induce the digital blackout, 44-year-old Yahyanejad raced against the clock in Los Angeles to make sure that people back home had downloaded his satellite file-casting application <a href="https://www.toosheh.org/">Toosheh</a>.<em> </em>“It was a very small window,” says Yahyanejad. “Once they were fully disconnected, I wasn’t sure they’d be able to download the software.”&nbsp;</p>



<p>Launched by Yahyanejad in 2016, the technology aggregates uncensored content, like news articles, YouTube videos, and podcasts, and sends it to Iranian homes directly via satellite TV. When Yahyanejad first began developing Toosheh in 2013, an estimated 70% of Iranian households owned a satellite dish, while around 20% had access to the internet. Even as internet access has grown, state censorship means Toosheh’s satellite technology is a much more reliable source for uncensored content. Iranians can install Toosheh’s satellite channel and receive a daily dispatch in the form of a file package of up to 8 gigabytes. Once a user downloads the app, the satellite transfers circumvent the internet entirely.&nbsp;</p>



<p>Yahyanejad says Toosheh gained nearly 100,000 new Iranians users in November 2019. In the absence of an internet connection, it became the only way for many users to access news from the outside world. The voice on Toosheh’s voicemail belonged to one such user, a 34-year-old high school principal in Tehran who downloaded emergency VPN and proxy tools delivered to him through the satellite service.&nbsp;</p>



<p>Having navigated extensive cyber censorship for over a decade, Iranians are tech savvy and <a href="https://www.bbc.com/news/blogs-trending-42612546">adept at nimbly crossing firewalls</a>, using proxies and foreign circumvention tools. “It’s a constant cat-and-mouse game,” says Fereidoon Bashar, executive director of ASL19, a Canadian organization working to help Iranians bypass internet censorship. The group often works in tandem with Yahyanejad to distribute proxy tools.&nbsp;</p>



<p>Bashar says Iranians adapt quickly to ever-changing institutionalized control online. But the last five years of Iranian president Hassan Rouhani’s rule have seen <a href="https://www.cnet.com/news/irans-president-plans-to-cut-countrys-internet-off-from-the-rest-of-the-world/">a tighter grip on internet connections</a>. Site blocking and calculated internet outages have become easier to enforce: the regime has reduced Iran’s dependence on global networks by pushing a local intranet, with the <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">aim to keep online traffic</a> inside the country. With strict American sanctions that threaten hefty fines for companies interfacing with Iran, foreign tech companies limit ordinary Iranians’ ability to purchase reliable proxies <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">out of an abundance of caution</a>. Riddled with insecurity, the local VPN black market is not a reliable option for those trying to avoid government attention.</p>



<p>But even as internet access grew incrementally difficult over the years, no one saw the November blackout coming. “An internet shutdown was previously viewed as a kind of dystopian political campaign,” says Kaveh Azarhoosh, an internet policy researcher. In November, the worst-case scenario for Iran’s censorship suddenly became a reality.&nbsp;&nbsp;</p>



<p>In the early days of the protest, Toosheh created a special “Protest News Package.” Every night, after aggregating content from over 200 publications, Toosheh delivered digital bundles containing clips of protests occuring in different cities: Tabriz, Qom, Shiraz, Mashhad, and others. It also contained slides about how to stay safe during a protest; crucial news coverage from banned sites, like the <em>New York Times</em>, Voice of America Persian, and Deutsche Welle; and a curated compilation of tweets from Iranian politicians. These packages weren’t just bringing news of the outside world to Iran: they kept Iranians informed about what was happening inside their own country too.</p>



<p>Yahyanejad, a physicist by training, left Iran in 1997 to pursue a Ph.D. from the Massachusetts Institute of Technology. “I’ve lived in Iran, and I’ve gone to school and college there,” he explains. “I know that this repressive government exists because they are able to control the flow of information.” He says he’s always had an interest in limiting their control. “I want,” he says, “to see democracy in Iran in my lifetime.”&nbsp;</p>



<p>In 2006, Yahyanejad launched a Reddit-like forum called <a href="https://www.balatarin.com/">Balatarin</a>. “Its popularity surprised me,” he says. The site posted a translated rumor about the supreme leader’s death, after he hadn’t been seen in public for two months, and was swiftly blocked by Iran shortly after. The moment was a turning point for Yahyanejad, who says, “I made a conscious decision to keep the platform open at a personal cost.”&nbsp;</p>



<p>The Iranian blocks on Balatarin inspired Yahyanejad to explore censorship circumvention. He launched the satellite app Toosheh in 2016. “I <a href="https://www.youtube.com/watch?v=FWfwF8Gx6VA">went on BBC Persian’s ‘Newshour</a>,’ and as soon as I talked about it, people started downloading and testing it immediately,” he says.&nbsp;</p>



<p>Yahyanjad finds himself among a cohort of diaspora Iranians working to fight the regime’s censors. ASL19, the Canadian technology group, collaborated with him to deliver proxy tools to over half a million Iranians during November’s shutdown. ASL19’s Bashar, who left Iran in the early 2000s before <a href="https://opennet.net/blog/2013/02/after-green-movement-internet-controls-iran-2009-2012">the tumultuous Green Movement</a>, says diaspora Iranians are stepping into the field because Iranians “risk harsh conditions, imprisonment, and long sentences” if they’re caught creating circumvention tools inside the country.&nbsp;&nbsp;</p>



<p>But even outside of Iran, outspoken diaspora activists like Bashar and Yahyanejad face immense risks. In June, it was reported that an Iranian activist named Ruhollah Zam was <a href="https://www.bbc.com/news/world-middle-east-53238000">sentenced to death </a>in Iran after creating a popular anti-government Telegram news channel that he operated while living in exile in France. The channel, with 1.4 million followers, was shut down shortly after. For Yahyanejad, who knew of Ruhollah through the diaspora community, the ordeal was a shot across the bow. “I can never go back to Iran,” Yahyanejad admits. “But I see myself as part of the movement.”&nbsp;</p>



<p>Yahyanejad’s work has become crucial for Iranians, even after November’s shutdown. On July 14, following news that Iran’s Supreme Court had upheld the death sentences of three young anti-regime protesters, Iranians took to banned social media sites in an unprecedented protest, with over 6 million posts under the hashtag #DontExecute. Hours after #DontExecute began trending online, digital rights organization NetBlocks <a href="https://twitter.com/netblocks/status/1283106806332620801?s=20">monitored disruptions in the network</a>. Panicked users, still reeling from November’s shutdown, speculated another block was imminent. Luckily, an all-out ban didn’t occur, but the renewed threat of one was enough to increase Toosheh’s usage by more than 50% in the days that followed.&nbsp;</p>



<p>For Yahyanejad, who has been actively fighting the Iranian regime’s censorship for over a decade, the past year is proof that his work is even more necessary. “Internet shutdowns are psychological tools designed to terrify populations, to convince them that they are voiceless,” he says. “Fighting shutdowns is important so that you can show people that they are not alone and that there are others.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cat-and-mouse-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585986</guid>
            <pubDate>Fri, 25 Sep 2020 02:26:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simple WireGuard Docker network setup]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24583512">thread link</a>) | @bjoko
<br/>
September 24, 2020 | https://www.eisfunke.com/article/docker-wireguard-systemd.html | <a href="https://web.archive.org/web/*/https://www.eisfunke.com/article/docker-wireguard-systemd.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.eisfunke.com/article/docker-wireguard-systemd.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24583512</guid>
            <pubDate>Thu, 24 Sep 2020 20:54:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consume less, produce more]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24582837">thread link</a>) | @hecticjeff
<br/>
September 24, 2020 | https://www.chrismytton.com/2020/09/24/consume-less-produce-more/ | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/2020/09/24/consume-less-produce-more/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<p>If you have too many inputs then your brain gets overwhelmed. Every piece of information you consume takes up some brain cycles.</p>

<p>If you’re not producing enough output to match your inputs then it can get clogged up in your brain. You end up with too many strands of thought. Too many lines of enquiry.</p>

<h2 id="excess-consumption-causes-anxiety">Excess consumption causes anxiety</h2>

<p>This can often be a cause of anxiety, stress and depression. Just increasing the amount you produce allows your brain to work through your anxieties.</p>

<p>Perhaps this is why mental health issues are on the rise. There are just so many inputs for our brain in the modern world that we don’t have time to process them all into coherent outputs, so that we can understand the information we’re being presented with.</p>

<h2 id="reduce-consumption">Reduce consumption</h2>

<p>Reduce the number of inputs in your daily life.</p>

<ul>
  <li>Stop reading the news</li>
  <li>Spend less time on social media</li>
  <li>Reduce the number of websites you visit daily</li>
  <li>Delete unused apps from your phone</li>
  <li>Eliminate unnecessary calendar appointments</li>
  <li>Spend less time watching TV series</li>
</ul>

<p>Generally stimulate your brain less.</p>

<h2 id="increase-production">Increase production</h2>

<p>Increase the number of productive outputs in your life.</p>

<ul>
  <li>Create something with your hands</li>
  <li>Draw or paint pictures (doesn’t matter if you’re good or not)</li>
  <li>Write more, keep a journal or a blog</li>
  <li>Increase your daily step count</li>
  <li>Explore new places</li>
  <li>Exercise regularly</li>
  <li>Cook for yourself, rather than eating out</li>
</ul>

<p>These are things that allow you to express yourself. Express the ideas in your brain. Work through the inputs in your life.</p>

<p>Not everything has to have a point, sometimes you just need to <a href="https://www.chrismytton.com/2019/09/24/do-things-for-fun/">do things for fun</a>.</p>

<p><img src="https://www.chrismytton.com/assets/images/chelt-paint-fest-2020.jpg" alt="Cheltenham Paint Festival 2020 at Cheltenham Spa station"></p>

<h2 id="express-yourself">Express yourself</h2>

<p>It’s by expressing the ideas in your brain that you can actually think clearly. Because the more you express them the more you can see them. Then you can visualise the ideas. Then you can better structure and organise them and compartmentalize them.</p>

<p>Now stop consuming these words and go and produce something. Express yourself.</p>

  </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/2020/09/24/consume-less-produce-more/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582837</guid>
            <pubDate>Thu, 24 Sep 2020 19:53:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to remember what you learn]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24582571">thread link</a>) | @flreln
<br/>
September 24, 2020 | https://vasilishynkarenka.com/learning/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://vasilishynkarenka.com/content/images/size/w300/2020/09/IMG_1517.jpg 300w,
                            https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_1517.jpg 600w,
                            https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_1517.jpg 1000w,
                            https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://vasilishynkarenka.com/content/images/size/w2000/2020/09/IMG_1517.jpg" alt="How to remember what you learn">
            </figure>

            <section>
                <div>
                    <p><em>“I don’t remember a damn thing.”</em></p><p>The book I hold my hands was full of highlights. It seemed like I’ve got all colors of the rainbow on a page. Apparently, this didn’t help. When I tried recalling ideas from the book, I didn’t hear a thing. Just. Silence.</p><p>Terrified, I started questioning how much I <em>really</em> know. If I forget everything I read, I can’t apply my knowledge to the problem at hand. I can’t transfer it. And without transfer, knowledge is very much like music for deaf ears.</p><p>I quickly did the math. I was planning to invest in learning a few hours a day for the next ~75 years of my life. Staring at the number of potentially wasted hours, I knew exactly what I had to do.</p><hr><p>In the past six months, I’ve devoured dozens of books, research papers, and studies on how people learn. As a result, I’ve designed a learning process that works for me. It’s not perfect, but an order of magnitude better than what I had before. </p><p>In this work, I outline my workflow so that you can try it out. It applies to any subject or discipline, from programming to economics. If you stumble upon something where it doesn’t work, let me know.</p><blockquote><em>Make it time-based, take regular breaks, and learn what you’re curious about.</em></blockquote><p>The most important thing is that my learning is time-based, not goal-based. Setting learning goals such as “read X pages today” is a way to fail because you set up the wrong incentives. When you plan to read X pages by lunch, you can’t help but begin optimizing for the goal, which leads to focusing on speed instead of understanding. And when you don’t have those “aha” moments, it is hard to remember what you learn.</p><p>It’s also important to not overload yourself and take breaks. I do 3h learning sessions every day split into 30 min intervals with 5 min breaks. Breaks help to fall back into the diffuse mode of thinking and get access to a broader set of neural networks in my head. They also warm up my body, and I feel better after moving around for a few minutes.</p><p>As for material, I learn what I’m interested in. First, because life is <a href="http://www.paulgraham.com/vb.html">too short</a> to do things that you don’t love. Second, I’ve found that studying stuff I genuinely like awakens my curiosity. And curiosity is essential to develop mastery because mastery is about depth and breadth of knowledge. </p><p>For example, if you’re learning JavaScript and you’re curious about it, you’ll go and figure out how JS runtime environment works in Chrome even though the tutorial doesn’t cover it. Just because you’re interested. But if you’re not curious, then you’ll just memorize the tutorial, and your knowledge will be shallow.</p><h2 id="how-my-learning-session-works">How my learning session works</h2><blockquote>Clean up working memory, apply metacognition, and "siege" the thing with questions to improve understanding.</blockquote><p>When I learn, I always have two devices on my desk. I have my laptop with the study material (ie, a book, a video, an article) on the right, and I have my iPad with a text editor open on the left.</p><p>This is how my current setup looks like:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_2658.jpg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_2658.jpg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_2658.jpg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_2658.jpg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_2658.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Morning learning session.</figcaption></figure><p>When I begin learning, I set a timer for 30 minutes and create three files in Drafts:</p><ol><li>A file with a timestamp where my random thoughts go.</li><li>A file with a timestamp where I think about the subject.</li><li>A file with questions.</li></ol><p><strong>The first file is a mind dump.</strong> When I start learning, I immediately begin thinking about things. It’s almost as if my brain wakes up and starts throwing ideas, tasks, and memories at me. I suspect this comes from the associative memory because I present myself with many triggers when I’m learning; words and sentences that bear special meaning to me and invoke these ideas.</p><p>But here’s the problem. If I don’t write thoughts down, I can’t focus. My working memory is overloaded with todos, ideas, and emotions. You’ve probably experienced this for yourself – your mind is running too fast, and you can’t really concentrate on what you’re learning. Having this “dump” file is immensely useful to a) free up my working memory to focus on my learning instead of thinking about these things, and b) store these thoughts somewhere safe to go back to them later and take action.</p><p><strong>The second file is where I write about what I’m learning.</strong> Folks in the kitchen call it metacognition, which means thinking about thinking. Metacognition is the single best trick I’ve found to improve understanding, and I will write more about it in the future. Whenever I don’t understand something or see that my understanding is shallow, I begin writing in the first person. It looks like this: “So Peter explains that there are four characteristics of a monopoly, but I don’t really understand why branding is one of them; why so?”</p><p>It’s also important to note that I don’t write in a usual sentence-paragraph manner. Instead, I write every thought on a new line. I don’t even put dots at the end of the sentences. This helps me to focus on understanding instead of nitty-gritty styling and typos. The “enter” key on a keyboard serves as the “end of thought” symbol and helps formulate ideas more clearly.</p><p>Another important idea is that my editor is plain text. I’ve found it incredibly liberating to operate in a plain text environment where you don’t have incentives to color, underline, bold, italicize, or do some other weird things with the text you’re writing. Instead of choosing the right font for my heading, I can focus on meaning instead. Also, my plain text app is way faster than all feature-rich text editors, and I’ve found it essential for a thought input environment to be fast. Otherwise, I can't think.</p><p>Here’s a fragment from my learning of React yesterday:</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_D7F6BD12F133-1.jpeg" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_D7F6BD12F133-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_D7F6BD12F133-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_D7F6BD12F133-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_D7F6BD12F133-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Metacognition notes from studying React.js.</figcaption></figure><p>You’re probably thinking that it’s quite a bit of writing. It is. For an hour-long learning session, I usually do about 500-1000 words in this file. But it’s worth every character, and here’s why:</p><ul><li>When I apply metacognition, I understand things <em>way</em> better than when I don’t. I’ve tested many different learning modes and found metacognition to perform at least 2x better based on my later ability to recall and transfer knowledge. Also, there’s <a href="https://academicpublishingplatforms.com/downloads/pdfs/ati/volume18/201607070302_09_ATI_Vol11_Issue2_2015_Todorova_and_Karamanska_Study_motivation_satisfaction_students_e-learning_pp.82-89.pdf">some</a> <a href="http://www.csun.edu/science/ref/reasoning/how-students-learn/1.html">research</a> on metacognition as well.</li><li>Having a file with my thinking about the subject keeps my working memory clean. I don’t feel overloaded as I usually feel after reading many articles at one go. You’ve probably experienced this yourself; your brain is almost melting after an hour of scrolling through the web. That’s because you present yourself with too much information without really making sense of it. After a few months of applying metacognitive practices, I realized that I can’t go back. It just feels so strange to experience that cognitive load again.</li><li>Metacognition improves remembering through elaboration and interleaving. When I’m writing my thoughts in the file, I can’t help but begin connecting them with other ideas on that topic because of associative memory. And interleaving leads to mastery.</li><li>(Speculation) Training metacognition improves my ability to transform vague notions and thoughts that I have during the day into specific words that I can write down for later analysis. This one is particularly interesting to me, but there’s no evidence besides my own experiments. And I might be biased because I’ve come up with this method.</li></ul><p>Moreover, I type 2-3x faster than most people because I use <a href="https://barehands.substack.com/p/how-to-type-3x-faster">shortcuts</a>. So it’s not that bad.</p><p><strong>The third file is questions. </strong>Whenever I stumble upon something that I don’t understand, I try to break it down into a set of simple questions. Each question in the group takes on a small part of the problem. If the concept is particularly challenging, I try to “siege” it with questions from many many different angles and break it down even further.</p><p>When I’m beginning a new session, I always start from the previous one’s questions file. I only look at questions and answer them before I’m beginning new learning. This doesn’t sound like very much fun, but it’s actually pretty interesting to explain stuff to yourself if you do it out loud. Answering questions improves my understanding and helps to connect ideas together. And yes, answering questions counts as learning – probably the most efficient learning you could be doing.</p><p><em>I'm not going into much detail on questions because Michael Nielsen has done a phenomenal job describing it <a href="http://augmentingcognition.com/ltm.html">here</a>.</em></p><h2 id="what-happens-after-the-session">What happens after the session</h2><blockquote>Write a dense summary, provoke elaboration, interleaving, and transfer, and choose what to never forget.</blockquote><p>After the session is done, and my three files are full of information, I begin the recap process.</p><p><strong>First, I write a three to five sentence-long summary of what I’ve just studied.</strong> Here I try to distill the material’s core idea and compress the whole thing into a maximally dense chunk. When I’m summarizing, my laptop is closed. Not looking at the text helps to “compress” the idea to its core and make a small “hook” to my memory to later see what the whole book was about.</p><p>Here’s how my summary note looks like: </p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/IMG_9771D059CFD1-1.jpeg" alt="Recap of studying React.js." srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/IMG_9771D059CFD1-1.jpeg 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/IMG_9771D059CFD1-1.jpeg 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/IMG_9771D059CFD1-1.jpeg 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/IMG_9771D059CFD1-1.jpeg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Recap of studying React.js.</figcaption></figure><p>Very often, what I’m writing in the summary section is not what the text was about, but what it means to me. In other words, if both of us read this text and wrote a summary of it, mine would be very different than yours.</p><p>After I’m done with the summary, I write down the answers to three questions:</p><ol><li>What are the key ideas? </li><li>How can I apply this knowledge that I learned? </li><li>How do these ideas relate to what I already know?</li></ol><p><strong>The first question speaks for itself.</strong> I try to remember what I just read and write down as many ideas as I can bring back. When I began applying the metacognition trick that I mentioned earlier, I noticed a 3x increase in the number of concepts I could recall. And as I speculate that long-term memory recall is influenced by initial interleaving and recall, this might actually help to improve your long-term memory.</p><p><strong>The second question is about transfer.</strong> The sole purpose of learning is to apply the knowledge that we learn. Without application, …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/learning/">https://vasilishynkarenka.com/learning/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24582571</guid>
            <pubDate>Thu, 24 Sep 2020 19:31:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Work on What Matters]]>
            </title>
            <description>
<![CDATA[
Score 470 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24581810">thread link</a>) | @wholien
<br/>
September 24, 2020 | https://staffeng.com/guides/work-on-what-matters | <a href="https://web.archive.org/web/*/https://staffeng.com/guides/work-on-what-matters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><h4><a href="https://staffeng.com/guides">Guides</a> / <a href="https://staffeng.com/guides/work-on-what-matters">Work on what matters</a></h4><div><p>We all have a finite amount of time to live, and within that mortal countdown we devote some fraction towards our work. Even for the most career-focused, your life will be filled by many things beyond work: supporting your family, children, exercise, being a mentor and a mentee, hobbies, and so the list goes on. This is the sign of a rich life, but one side-effect is that time to do your work will become increasingly scarce as you get deeper into your career.</p>
<p>If you’re continuing to advance in your career, then even as your time available for work shrinks, the expectations around your impact will keep growing. For a while you can try sleeping less or depriving yourself of the non-work activities you need to feel whole, but you’ll inevitably find that your work maintains an aloof indifference to your sacrifice rather than rewarding it. Only through <a href="https://lethain.com/forty-year-career/">pacing your career to your life</a> can you sustain yourself for the long-term.</p>
<p>Indeed, pacing yourself becomes the central challenge of a sustained, successful career: increasingly senior roles require that you accomplish more and more, and do it in less and less time. The ledge between these two constraints gets narrower the further you go, but it remains walkable if you take a deliberate approach.</p>
<p>First a discussion on a few common ways to get tripped up: <em>snacking</em>, <em>preening</em>, and <em>chasing ghosts</em>. Then we’ll get into the good stuff: how <em>do</em> you work on what really matters?</p>
<h2>Avoid snacking</h2>
<p>Hunter Walk recommends that folks <a href="https://hunterwalk.com/2016/06/18/the-best-startups-resists-snacks-im-not-talking-about-food/">avoid “snacking”</a> when they prioritize work. If you’re in a well-run organization, at some point you’re going to run out of things that are both high-impact and easy. This leaves you with a choice between shifting right to hard and high-impact or shifting down to easy and low-impact. The latter choice--easy and low-impact--is what Walk refers to as <em>snacking</em>.</p>
<p>When you’re busy, these snacks give a sense of accomplishment that makes them psychologically rewarding but you’re unlikely to learn much from doing them, others are likely equally capable of completing them (<em>and</em> for some of them it might be a good development opportunity), and there’s a tremendous opportunity cost versus doing something higher impact.</p>
<p>It’s ok to spend some of your time on snacks to keep yourself motivated between bigger accomplishments, but you have to keep yourself honest about how much time you’re spending on high-impact work versus low-impact work. In senior roles, you’re more likely to self-determine your work and if you’re not deliberately tracking your work, it’s easy to catch yourself doing little to no high-impact work.</p>
<h2>Stop preening</h2>
<p>Where “snacking” is the broad category of doing easy and low-impact work, there’s a particularly seductive subset of snacking that I call “preening.” Preening is doing low-impact, high-visibility work. Many companies conflate high-visibility and high-impact so strongly that they can’t distinguish between preening and impact, which is why it’s not uncommon to see some companies’ senior-most engineers spend the majority of their time doing work of dubious value but that is frequently recognized in company meetings.</p>
<p>If you’re taking a short-term look at <a href="https://yenkel.dev/posts/how-to-achieve-career-growth-opportunities-skills-sponsors">career growth</a>, then optimizing for your current organization’s pathologies in evaluating impact is the optimal path: go forth and preen gloriously. However, if you’re thinking about developing yourself to succeed as your <a href="https://lethain.com/growing-with-your-company/">current role grows in complexity</a> or across multiple organizations, then it’s far more important to strike a balance between valued work and self-growth.</p>
<p>This is also an important factor to consider when choosing a company to work at! Dig into what a company values and ensure it aligns with your intended personal growth. If a company’s leadership is entirely folks who focus their energy on performant urgency or acts of fealty, don’t be surprised when your success in the company depends on those activities.</p>
<p>Worse, to be a successful preener requires a near invulnerability to criticism of your actual impact, and your true work <em>will</em> suffer if your energy is diverted to preening. Typically this means you need to be a vanity hire of a senior leader or to present yourself in the way a company believes leaders look and act. If that isn’t you, then your attempt to exchange your good judgement for company success will end up failing anyway: you’ll get held accountable for the lack of true impact where others who match the company’s expectation of how a leader appears will somehow slip upward.</p>
<h2>Stop chasing ghosts</h2>
<p>Many folks would assume that companies, rational optimizers that they are, avoid spending much time on low-impact high-effort projects. Unfortunately that isn’t consistently the case. It’s surprisingly common for a new senior leader to join a company and immediately drive <a href="https://lethain.com/grand-migration/">a strategy shift that fundamentally misunderstands the challenges at hand</a>. The ghosts of their previous situation hold such a firm grasp on their understanding of the new company that they misjudge the familiar as the essential.</p>
<p>As a senior leader, you have to maintain a hold on your ego to avoid investing into meaningless work at a grand scale. This can be surprisingly challenging when during your hiring process you’ve been repeatedly told that you’ve been hired to fix something deeply broken -- you’re the newly-hired savior, of course your instincts are right! Taking the time to understand the status quo before shifting it will always repay diligence with results.</p>
<p>I had a recent discussion with someone who argued that new senior leaders <em>deliberately</em> push for major changes even though they suspect the efforts will fail. Such changes make the organization increasingly dependent on the new leader, and also ensures anything that <em>does</em> go well gets attributed to the new leader directly rather than their team. If this is your approach to leadership, please know that you’re awful and take the time to work on yourself until the well-being and success of an entire company matters to you more than being perceived as essential.</p>
<h2>Existential issues</h2>
<p>Now that you’re done snacking, preening and chasing ghosts, the first place to look for work that matters is exploring whether your company is experiencing an existential risk. Companies operate in an eternal <a href="https://lethain.com/iterative-elimination-tournaments/">iterative elimination tournament</a>, balancing future success against surviving until that future becomes the present. If you’re about to lose one of those rounds, then always focus there.</p>
<p>Running out of money, <a href="https://lethain.com/digg-v4/">like my experience at Digg</a>, can be the most obvious issue, but not every existential issue is financial, like <a href="https://www.theatlantic.com/technology/archive/2015/01/the-story-behind-twitters-fail-whale/384313/">Twitter’s fail whale stability challenges</a> or adapting to the shifts caused by the Covid-19 pandemic.</p>
<p>If something dire is happening at your company, then that’s the place to be engaged. Nothing else will matter if it doesn’t get addressed.</p>
<h2>Work where there’s room <em>and</em> attention</h2>
<p>Existential issues are usually <em>not</em> the most efficient place to add your efforts, but efficiency isn’t a priority when the walls are crashing down around you. You <em>should</em> swarm to existential problems, but if a problem isn’t existential then you should be skeptical of adding your efforts where everyone’s already focused. Folks often chase leadership’s top priority, but with so many folks looking to make their impact there, it’s often challenging to have a meaningful impact.</p>
<p>Instead, the most effective places to work are those that matter to your company but still have enough room to actually do work. What are priorities that will become critical in the future, where you can do great work ahead of time? Where are areas that are doing <em>ok</em> but could be doing <em>great</em> with your support?</p>
<p>Sometimes you’ll find work that’s <em>worthy</em> of attention, but which an organization is incapable of paying attention to, usually because its leadership doesn’t value that work. In some companies this is developer tooling work, in others it’s inclusion work, and in most companies it’s <a href="https://noidea.dog/glue">glue work</a>.</p>
<p>There is almost always a great deal of room to do this sort of work that no one is paying attention to, so you’ll be able to make rapid initial progress on it, which <em>feels</em> like a good opportunity to invest. At some point, though, you’ll find that the work needs support, and it’s quite challenging to get support for work that a company is built to ignore or devalue. Your early wins will slowly get eroded by indifference and misalignment, and your initial impact will be reclaimed by the sands of time.</p>
<p>Does this mean you shouldn’t do inclusion work? No, that’s not the conclusion I want you to take away from this. Sometimes an area that an organization doesn’t pay attention to is so important that you’re going to want to advocate for it to start paying attention. Teaching a company to value something it doesn’t care about is considerably the hardest sort of work you can do, and it often fails, so you should do as little of it as you can, but no less. As a senior leader, you have an ethical obligation that goes beyond maximizing your company-perceived impact, but it’s important to recognize what you’re up against and time your efforts accordingly.</p>
<h2>Foster growth</h2>
<p>One area that’s often underinvested in (e.g. lots of room to work in) while also being highly leveraged is growing the team around you. <em>Hiring</em> has a lot of folks involved in it, usually in terms of optimizing the <a href="https://lethain.com/hiring-funnel/">hiring funnel</a>, but onboarding, mentoring and coaching are wholly neglected at many companies despite being <em>at least</em> <a href="https://lethain.com/productivity-in-the-age-of-hypergrowth/">as impactful as hiring to your company’s engineering velocity</a>.</p>
<p>If you start dedicating even a couple hours a week to developing the team around you, it’s quite likely that will become your legacy long after your tech specs and pull requests are forgotten.</p>
<h2>Edit</h2>
<p>A surprising number of projects are one small change away from succeeding, one quick modification that unlocks a new opportunity, or one conversation away from consensus. I think of making those small changes, quick modifications and short conversations as <em>editing</em> your team’s …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://staffeng.com/guides/work-on-what-matters">https://staffeng.com/guides/work-on-what-matters</a></em></p>]]>
            </description>
            <link>https://staffeng.com/guides/work-on-what-matters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581810</guid>
            <pubDate>Thu, 24 Sep 2020 18:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We cancelled standups and let the team build]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 252 (<a href="https://news.ycombinator.com/item?id=24581360">thread link</a>) | @thellimist
<br/>
September 24, 2020 | https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>👋 I'm Julian, the Cofounder of <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a>. We're building dashboards and alerts that plug into Github - helping engineering leaders build happier, healthier, more productive teams. </p><p>We wanted to share a quick story on why "we cancelled standups and just let the team build". </p><p>It's not as crazy as it sounds so let's dive an and see what happened..</p><p>‍</p><h2>So.. why did we do this?</h2><p>‍</p><h4>At first we were doing great</h4><p>At first the team was moving at (what seemed to be) the speed of light. We were handling issues, fixing bugs, launching features. We even tackled our biggest, nagging pieces of technical debt. Dream come true, right? As a team of technical founders, we patted ourselves on the back for a job well done. It felt like we couldn't be stopped.</p><p>‍</p><h4>But things quickly turned around on us..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f593cc6238ba8f66e10c539_Screenshot_2020-09-08_at_10.22.47_PM.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‍</p><h4>And we noticed an odd pattern happening daily..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc18e8a5d4f630d45d4f2_2.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‍</p><h4>We brought this data to the team and uncovered a few issues.. Here are some notes from our retro</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6ccdaf16b35490656f58c6_retro-summary.png" loading="lazy" alt=""></p></figure><p>‍</p><h2>So.. What did we do?</h2><p>‍</p><h4>We asked for suggestions. Here are the results..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd0bbf86c9040f44cc92b_retro-votes.png" loading="lazy" alt=""></p></figure><p>‍</p><h4>Top Votes:&nbsp;</h4><ol start="" role="list"><li>Cancel Standup</li><li>Work on 'Fun Projects'</li></ol><p>‍</p><p>Might seem crazy but we like to empower the team to improve themselves. &nbsp;We take pride in our ability to iterate our process as often as possible. </p><p>Plus we've got Haystack to see if our changes are working.</p><p>So why not?&nbsp;Let's try it for a week. Revert back if it isn't working out.</p><p>‍</p><h2>We cancelled standup and let the team 'just build'.</h2><p>‍</p><h4>We did agree on some ground rules though..</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd49e16b35472506f74b8_fun-sprint-etiquette.png" loading="lazy" alt=""></p></figure><p>‍</p><h4>And with those rules in place we were off 💨🚣‍♀️</h4><p>Without hesitation we kicked off. Very surprised to see how many 'fun projects' the team already had in mind. It didn't take much prompting at all.</p><p>‍</p><h2>And.. We had our most productive week EVER:</h2><p>‍</p><h4>We recovered our Throughput!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc209c0fe2df87e4583c0_3.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‍</p><h4>Improved our Cycle Time (reversing the trend)!</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc20f1523b25682b1fe92_4.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‍</p><h4>Got our 'deep work' back.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2169b6b491e6744cd11_5.png" loading="lazy" alt=""></p><figcaption>Source:&nbsp;<a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a></figcaption></figure><p>‍</p><h4>And tackled projects we've wanted to do for MONTHS.</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc2313f047785e14bf727_11.png" loading="lazy" alt=""></p></figure><p>‍</p><h4>Most Importantly..We DECREASED BURNOUT</h4><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cd71016b35499cd6f7f8d_before.png" loading="lazy" alt=""></p></figure><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f6cc24b1523b2af6fb20099_13.png" loading="lazy" alt=""></p></figure><p>‍</p><p>‍</p><h2>It was a HUGE success.</h2><p>The experiment went better than we could have hoped. By removing standups and letting the team work on new, exciting projects we were able to get out of the funk we found ourselves in. Without skipping a beat our team is refreshed, recovered, and excited.</p><p>‍</p><p>‍</p><h2>Does this mean no more stand-ups or roadmaps?</h2><p>Well.. No. But we are considering it. </p><p>‍</p><p>We'll continue to experiment until we find the right balance. Today, we do 2-3 in-person standups per week with async standups on Slack the other days. We carefully document our work in Notion everyday and have Weekly Kick-Off meetings every Monday.</p><p>‍</p><p>The new process is working well so far - plus we have Haystack to help us check-in and make changes if needed.</p><p>‍</p><p>‍</p><h2>So.. how often do YOU experiment with process?</h2><p>The 'right' process is a constantly moving target. What works one day might not work the next. It's important to empower your team to make changes when necessary and improve their day-to-day experience. </p><p>‍</p><p>If you want to experiment like a mad man(woman) on your process. AGGRESSIVELY enable improvement. Empower your team to improve their own work environment - then come check out <a href="https://www.usehaystack.io/?utm_source=Blog&amp;utm_medium=internal%20link&amp;utm_campaign=image%20source">Haystack</a> and we'll show you how to implement a culture of continuous improvement.</p><p>‍</p><p>Either way, hope our story got your wheels turning!</p><p>‍</p><p>‍</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5f5123c19bb423a1492c778d_Haystack_Designed_Presentation.png" loading="lazy" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Haystack</a> helps engineering leaders identify blockers and trends. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get insights in your inbox every morning. Plus a dashboard to track improvements over time.</p><p>‍</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=subscription-sequence&amp;utm_campaign=3-ways-to-identify-blockers">Try it for free</a></p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/we-cancelled-standups-and-let-the-team-build-heres-what-happened</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581360</guid>
            <pubDate>Thu, 24 Sep 2020 17:52:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Consensus Algorithms at Scale – Part 3]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24581091">thread link</a>) | @sougou
<br/>
September 24, 2020 | https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases | <a href="https://web.archive.org/web/*/https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><figure id="w-node-9c5fe811ec3e-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bda6f1d50dc20271ab64d_part3-07.png" loading="lazy" alt=""></p></figure><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‍</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p><h2>Recap</h2><p>Here is a recap of what we covered in the last blog:</p><ul role="list"><li>Durability is the main reason why we want to use a consensus system.</li><li>Since Durability is use-case dependent, we made it an abstract requirement requiring the consensus algorithms to assume nothing about the durability requirements.</li><li>We started off with the original properties of a consensus system as defined by <a href="https://en.wikipedia.org/wiki/Paxos_(computer_science)">Paxos</a> and modified it to make it usable in practical scenarios: instead of converging on a value, we changed the system to accept a series of requests.</li><li>We narrowed our scope down to single leader systems.</li><li>We came up with a new set of rules that are agnostic of durability. The essential claim is that a system that follows these rules will be able to satisfy the requirements of a consensus system. Specifically, we excluded some requirements like majority quorum that have previously been used as core building blocks in consensus algorithms.</li></ul><h2>Consensus Use Cases</h2><p>If there was no need to worry about a majority quorum, we would have the flexibility to deploy any number of nodes we require. We can designate any subset of those nodes to be eligible leaders, and we can make durability decisions without being influenced by the above two decisions. This is exactly what many users have done with <a href="https://vitess.io/">Vitess</a>. The following use cases are loosely derived from real production workloads:</p><ul role="list"><li>We have a large number of replicas spread over many data centers. Of these, we have fifteen leader capable nodes spread over three data centers. We don’t expect two nodes to go down at the same time. Network partitions can happen, but only between two data centers; a data center will never be totally isolated. A data center can be taken down for planned maintenance.</li><li>We have four zones with one node in each zone. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have six nodes spread over three zones. Any node can fail. A zone can go down without notice. A partition can happen between any two zones.</li><li>We have two regions, each region has two zones. We don’t expect more than one zone to go down. A region can be taken down for maintenance, in which case we want to proactively transfer writes to the other region.</li></ul><p>I have not seen anyone ask for a durability requirement of more than two nodes. But this may be due to difficulties dealing with corner cases that MySQL introduces due to its semi-sync behavior. On the other hand, these settings have served the users well so far. So, why become more conservative?</p><p>These configurations are all uncomfortable for a majority based consensus system. More importantly, these flexibilities will encourage users to experiment with even more creative combinations and allow them to achieve better trade-offs.</p><h2>Reasoning about Flexible Consensus</h2><p>The configurations in the previous section seem to be all over the place. How do we design a system that satisfies all of them, and how do we future-proof ourselves against newer requirements?</p><p>There is a way to reason about why this flexibility is possible. This is because the two cooperating algorithms (Request and Election) share a common view of the durability requirements, but can otherwise operate independently.</p><p>For example, let us consider the five node system. If a user does not expect more than one node to fail at any given time, then they would specify their durability requirement as two nodes.</p><p>The leader can use this constraint to make requests durable: as soon as the data has reached one other node, it has become durable. We can return success to the client.</p><p>On the election side, if there is a failure, we know that no more than one node could have failed. This means that four nodes will be reachable. At least one of those will have the data for all successful requests. This will allow the election process to propagate that data to other nodes and continue accepting new requests after a new leader is elected.</p><p>In other words, a single durability constraint dictates both sides of the behavior; if we can find a formal way to describe the requirements, then a request has to fulfil those requirements. On the other hand, an election needs to reach enough nodes to intersect with the same requirements.</p><figure id="w-node-f2e13589f425-ca993012"><p><img src="https://assets-global.website-files.com/5ef5a4d4da0d67ccda9b5588/5f6bdb8ae991420d4c1c808f_request-election-01.jpg" loading="lazy" alt=""></p></figure><p>For example, if durability is achieved with 2/5 nodes, then the election algorithm needs to reach 4/5 nodes to intersect with the durability criteria. In the case of a majority quorum, both of these are 3/5. But our generalization will work for any arbitrary property.</p><h2>Worst Case Scenario</h2><p>In the above five node case, if two nodes fail, the failure tolerance has been exceeded. We can only reach three nodes. If we don’t know about the state of the other two nodes, we will have to assume the worst case scenario that a durable request could have been accepted by the two unreachable nodes. This will cause the election process to stall.</p><p>If this were to happen, the system has to allow for a compromise: abandon the two nodes and move forward. Otherwise, the loss of availability may become more expensive than the potential loss of that data.</p><h2>Practical Balance</h2><p>A two-node durability does not always mean that the system will stall or lose data. A very specific sequence of failures have to happen:</p><ul role="list"><li>Leader accepts a request</li><li>Leader attempts to send the request to multiple recipients</li><li>Only one recipient receives and acknowledges the request</li><li>Leader returns a success to the client</li><li>Both the leader and that recipient crash</li></ul><p>This type of failure can happen if the leader and the recipient node are network partitioned from the rest of the cluster. We can mitigate this failure by requiring the ackers to live across network boundaries.</p><p>The likelihood of a replica node in one cell failing after an acknowledgment, and a master node failing in the other cell after returning success, is much lower. This failure mode is rare enough that many users treat this level of risk as acceptable.</p><h2>Orders of Magnitude</h2><p>The most common operation performed by a consensus system is the completion of requests. In contrast, a leader election generally happens in two cases: taking nodes down for maintenance, or upon failure.</p><p>Even in a dynamic cloud environment like Kubernetes, it would be surprising to see more than one election per day for a cluster, whereas such a system could be serving hundreds of requests per second. That amounts to many orders of magnitude in difference between a request being fulfilled and a leader election.</p><p>This means that we must do whatever it takes to fine tune the part that executes requests, whereas leader elections can be more elaborate and slower. This is the reason why we have a bias towards reducing the durability settings to the bare minimum. Expanding this number can adversely affect performance, especially the tail latency.</p><p>At <a href="https://youtube.com/">YouTube</a>, although the quorum size was big, a single ack from a replica was sufficient for a request to be deemed completed. On the other hand, the leader election process had to chase down all possible nodes that could have acknowledged the last transaction. We did consciously trade off on the number of ackers to avoid going on a total wild goose chase.</p><p>In the next blog, we will take a short detour. Shlomi Noach will talk about how some of these approaches work with MySQL and semi-sync replication. Following this, we will continue pushing forward on the implementation details of these algorithms.</p><p>‍</p><p><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-1"><em>Consensus Algorithms at Scale - Part 1 <br>‍</em></a><em>Read </em><a href="https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-2"><em>Consensus Algorithms at Scale - Part 2</em></a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.planetscale.com/blog/blog-series-consensus-algorithms-at-scale-part-3-use-cases</link>
            <guid isPermaLink="false">hacker-news-small-sites-24581091</guid>
            <pubDate>Thu, 24 Sep 2020 17:29:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping the Dark Forest]]>
            </title>
            <description>
<![CDATA[
Score 315 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24580879">thread link</a>) | @CyrusL
<br/>
September 24, 2020 | https://samczsun.com/escaping-the-dark-forest/ | <a href="https://web.archive.org/web/*/https://samczsun.com/escaping-the-dark-forest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://samczsun.com/content/images/size/w300/2020/09/109768371_xl.jpg 300w,
                            https://samczsun.com/content/images/size/w600/2020/09/109768371_xl.jpg 600w,
                            https://samczsun.com/content/images/size/w1000/2020/09/109768371_xl.jpg 1000w,
                            https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://samczsun.com/content/images/size/w2000/2020/09/109768371_xl.jpg" alt="Escaping the Dark Forest">
</figure>
<section>
<div>
<p><em>On September 15, 2020, a small group of people worked through the night to rescue over 9.6MM USD from a vulnerable smart contract. This is our story.</em></p><p>I was about to wrap up for the night when I decided to take another look at some smart contracts.</p><p>I wasn’t expecting anything interesting, of course. Over the past few weeks I had seen countless yield farming clones launch with the exact same pitch: stake your tokens with us and you could be the next cryptocurrency millionaire. Most were simply forks of well-audited code although some tweaked bits and pieces, sometimes with catastrophic results.</p><p>But amidst all of the noise there was some code I hadn’t seen before. The contract held over 25,000 Ether, worth over 9,600,000 USD at the time, and would be a very juicy payday for anyone who managed to find a bug in its logic.</p><p>I quickly looked through the code for where Ether is transferred out and found two hits. One of them transferred the Ether to a hardcoded token address, so that could be ignored. The second was a burn function that transferred Ether to the sender. After tracing the usage of this function, I discovered that it would be trivial for anyone to mint tokens to themselves for free, but then burn them in exchange for all of the Ether in the contract. My heart jumped. Suddenly, things had become serious.</p><p>Some digging revealed that the contract I had found was part of <a href="https://lien.finance/">Lien Finance</a>’s protocol. Unfortunately, their team was anonymous! The only IM platform they supported was Telegram, and I couldn’t be sure that the admins of that channel were actually protocol developers or just a few early supporters. The last thing I wanted to do was accidentally leak the exploit to the wrong person.</p><p>After browsing their website a little while longer, I noticed that they had worked with ConsenSys Diligence and CertiK for an audit. This seemed like a good avenue, since both ConsenSys and CertiK must have interacted with the developers during their audits. I quickly pinged <a href="https://twitter.com/maurelian_">maurelian</a> on Telegram.</p><figure><img src="https://samczsun.com/content/images/2020/09/image.png" alt=""><figcaption>You never want to be on the receiving end of this message</figcaption></figure><p>Unfortunately, time ticked on, my heart kept pounding, but there was no response from maurelian. It seemed like he had already gone to sleep. Desperate, I sent a message to the ETHSecurity Telegram channel.</p><figure><img src="https://samczsun.com/content/images/2020/09/image-1.png" alt=""><figcaption>Artist's rendering of the message, since I deleted the original</figcaption></figure><p>Within minutes, I got a message from someone I’d worked with quite a few times in the past - <a href="https://twitter.com/wadealexc">Alex Wade</a>.</p><hr><p>My head had just hit the pillow when I got a knock on my door. It was my roommate: “Sam’s in the ETHSec Telegram asking for anyone from Diligence.”</p><figure><img src="https://samczsun.com/content/images/2020/09/image-2.png" alt=""><figcaption>It was, in fact, a long night</figcaption></figure><p>Knowing Sam, this couldn’t be good. I found a channel we’d set up with Lien a few months ago and an email address. Better than nothing, given their team was anon.</p><p>I was still half asleep. Sam, not wanting to commit details to text, asked for a Zoom call. Groggily wishing I was back in bed, I attempted to gauge the severity of the situation:</p><figure><img src="https://samczsun.com/content/images/2020/09/image-4.png" alt=""><figcaption>Five minutes later, it was clear that the situation called for coffee</figcaption></figure><p>Sam and I reviewed the code together. By this point, Sam had already prepared a sample exploit and was able to confirm the issue on his machine. The conversation quickly turned to discussing options:</p><ol><li>Attempt to exploit the issue ourselves.</li><li>Reach out to Lien and have them go public, urging users to withdraw.</li></ol><p>Neither of these were appealing options. The first was risky because, as discussed in <a href="https://medium.com/@danrobinson/ethereum-is-a-dark-forest-ecc5f0505dff">Ethereum is a Dark Forest</a> by <a href="https://twitter.com/danrobinson">Dan Robinson</a> and <a href="https://twitter.com/gakonst/">Georgios Konstantopoulos</a>, the possibility of our transactions getting frontrun was very real. The second option was similarly risky, as a public announcement would draw attention to the problem and create a window of opportunity for attackers. We needed a third option.</p><p>Recalling a section from <em>Ethereum is a Dark Forest</em>, Sam reached out to <a href="https://twitter.com/epheph">Scott Bigelow</a>:</p><blockquote>If you find yourself in a situation like this, we suggest you reach out to Scott Bigelow, a security researcher who has been studying this topic and has a prototype implementation for a better obfuscator.</blockquote><hr><p>After participating in the recovery attempt from <em>Ethereum is a Dark Forest, </em>which ultimately lost to front-runners, I was hungry for a re-match. I’ve spent time monitoring front-running and designing a simple system that seemed able to fool generalized front-runners, at least for the $200 I’d been able to test it with. When Sam reached out to me in the late evening with the innocent-sounding “mind staying up for another hour or so”, I couldn’t wait to try it out! I was already working it out: how I’d make a few tweaks, stay up a couple hours, feel a sense of accomplishment having helped rescue and return a few thousand dollars of user funds, and get a good night’s sleep.</p><p>Those plans immediately fell apart when Sam shared the contract with me: ~25,000 ETH, valued at $9.6M, at stake. For as much as I wanted that rematch, $9.6M was way outside my humble script’s weight class.</p><p><br>For the past few months, I had been trying to establish contacts with miners for this very purpose: white-hat transaction cooperation. If ever there was a time to appeal to a miner to include a transaction without giving front-runners the chance to steal it, it was now. Luckily, <a href="https://twitter.com/tzhen">Tina</a> and I have worked together over the past few months on establishing this cooperation. It seemed like a slim chance at the time, but it was worth a shot: let’s bring Tina into the rescue attempt to work with a mining pool to mine a private transaction.</p><hr><p>I had just evacuated from the Bobcat forest fire and was sipping on unknown beachy drinks zoning out to the monotonic sound of dark Pacific waves, when a Telegram DM from Sam buzzed me back to a darker reality: “funds at risk, frontrunnable”. Over the last few weeks, I had been collaborating with Sam and Scott on a research project on MEV and could already guess their ask before they sent it: a direct channel to shield a whitehat tx from getting sniped by the “advanced predators” in the mempool’s “dark forest”.</p><p>Since this was a risky move that entailed exposing our strategy to miners, we decided we should first try to get the greenlight from the anonymous Lien team. While Alex was trying to get in contact via ConsenSys-internal channels, we tried to loop in CertiK as well.</p><p>I realized it may take another 4 hours before Certik's US-based auditors would wake up, yet the clock was ticking. &nbsp;Knowing nothing much about CertiK beyond the fact it had serviced quite a few Asian projects, I tried to reach the CertiK China team to arbitrage the time zone difference. I blasted a casual sounding message in “DeFi the World” and “Yellow Hats” WeChat groups. Four leads slid into my DMs independently within 30 minutes, confirming the WeChat ID that I connected with was indeed the real Zhaozhong Ni, CTO of CertiK. I was added to a WeChat group with 5 CertiK team members, yet at this point I was still not in a position to disclose the project nor the vulnerability. To minimize the exposure and potential liability, we could only invite one member from Certik to join our whitehat operation. After passing a final verification via official email, Georgios Delkos, the engineering lead at CertiK joined our call.</p><p>With Georgios’s help, Alex was able to quickly get in contact with the Lien team and verify their identity. We brought them up-to-speed on the current situation and asked for their permission to try working directly with a mining pool to rescue the vulnerable funds. After some deliberation, the Lien team agreed that the risk from trying to rescue the funds directly or publishing a warning was too high, and gave the go-ahead to continue.</p><p>Now we needed to identify a mining pool that had the infrastructure ready in place and would be willing to cooperate with us ASAP. Which mining pool should we tap? Which contact from the pool would be in a position to make technical decisions swiftly that help us beat the clock?</p><p>SparkPool came to mind, as I knew they had been working on a piece of public infrastructure called Taichi Network that could easily offer what we needed. I decided to ping Shaoping Zhang, SparkPool’s co-founder, who had helped me investigate mempool events in the past.</p><p>Half an hour later, Shaoping responded: “You mean do we have a whitelist service for transactions? Sorry, we don’t.” Oops, something was lost in translation, “whitehat” and “whitelist” sounded similar in Chinese.</p><p>“There’s 10mn dollar worth of funds at risk. samczsun is on the line.” I tried again to communicate the situation without revealing any specifics.</p><figure><img src="https://samczsun.com/content/images/2020/09/photo5145442418169063579.png" alt="" srcset="https://samczsun.com/content/images/size/w600/2020/09/photo5145442418169063579.png 600w, https://samczsun.com/content/images/size/w1000/2020/09/photo5145442418169063579.png 1000w, https://samczsun.com/content/images/size/w1600/2020/09/photo5145442418169063579.png 1600w, https://samczsun.com/content/images/2020/09/photo5145442418169063579.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>“Are you guys saving the world again? Do you need help from our mining pool?” To my surprise and great relief, Shaoping jokingly extended an offer to help. After official email verification, Shaoping popped into our marathon Zoom call with the support of a roomful of SparkPool devs.</p><hr><p>After lunch, just when I was about to take a nap, I received a message from Tina: “Has SparkPool ever helped with whitehat transactions??” I mistook it for whitelisting a transaction at first. No whitehats had approached us before, and we were not familiar with what “whitehat transactions” entailed. After Tina explained it in more details, I realized that what they needed was a private transaction service, i.e. the whitehats wanted to send transactions to save a DeFi contract, but in order to prevent getting front-runned, they needed a mining pool to include the transaction without broadcasting it.</p><p>We had been working on a “private transaction” feature on our Taichi Network, which was still under development and had not been tested. I brought the whitehats’ request to our development team, and explained the urgency: our private transaction feature needed to be in production within a few hours. Our devs said they could try their best to finish in time, and we immediately got to work. We finished development of the private transaction feature in 2 hours, and then spent some time fixing bugs.</p><p>After we completed our internal testing, we sent the <em>whitehat.taichi.network</em> endpoint to …</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://samczsun.com/escaping-the-dark-forest/">https://samczsun.com/escaping-the-dark-forest/</a></em></p>]]>
            </description>
            <link>https://samczsun.com/escaping-the-dark-forest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580879</guid>
            <pubDate>Thu, 24 Sep 2020 17:09:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fintech Is Not New]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24580770">thread link</a>) | @mattmarcus
<br/>
September 24, 2020 | https://www.moderntreasury.com/journal/fintech-is-not-new | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/fintech-is-not-new">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>There’s a myth going around now that fintech is a new industry, poised to take over, and that now that it’s here, every company will be a fintech company. The myth continues: some of the most promising new tech is of a new, different, novel flavor called “fintech.”</p><p>In reality, though, fintech is just as old as "tech." For as long as engineers and entrepreneurs have been coming up with new technology amongst the hills of Cupertino and the orange groves of Mountain View, there have been fintech entrepreneurs right amongst them. And in many instances, the two groups have utilized the same technology advances to push the world forward.</p><h5>1956</h5><p>In 1956, the same year that William Shockley founded the Shockley Semiconductor Laboratory in Palo Alto, Bill Fair and Earl Isaac set up Fair, Isaac, &amp; Company, better known today as <a href="https://www.fico.com/">FICO</a>.&nbsp;</p><p>Bill Fair and Earl Isaac met at the Stanford Research Institute in Menlo Park and worked on a project as data heavy as it gets: the mathematics and statistics behind credit scoring tools for lenders. In 1956 they moved up north, invested $400 each in their new company, and set off to sell credit assessment systems to lenders. The FICO score as we know it today, set on a scale between 300 and 850, was not formulated until the 1980s, but the <a href="https://www.fico.com/en/about-us#history%20(edited)" target="_blank">FICO concept</a> started simultaneously with the semiconductor. Today we’d describe what they were doing as “data science.”&nbsp;</p><p>‍</p><h5>1957</h5><p>The very next year, in 1957, as Arthur Rock was making one of the first venture capital investments in Fairchild Semiconductor, Bank of America’s team in San Francisco was coming up with the BankAmericard program, which launched in 1958. The famous “Fresno drop,” <a href="#1">[1]</a> in which BofA mailed credit cards to everyone in Fresno, became <a href="https://usa.visa.com/">Visa</a>. Like many consumer fintech startups, it was riddled with fraud at first. But it turned a profit in 1961 and the rest is <a href="https://usa.visa.com/about-visa/our_business/history-of-visa.html" target="_blank">history</a>. Visa, in its pursuit of the perfect payment experience at a store or restaurant, drove some of the most demanding requirements on data center reliability, redundancy, and latency in the 1970s. Today we’d describe these as “cloud services.”&nbsp;</p><p>‍</p><h5>1968</h5><p>In 1968, Robert Noyce, Gordon Moore, Andy Grove, and several other high profile Fairchild employees left Fairchild to start Intel. They too turned to Arthur Rock for seed funding. That was the year Ross Perot’s Electronic Data Systems IPO’d on the strength of multimillion dollar contracts building early software necessary to enable Medicare and Medicaid. EDS <a href="https://www.dxc.technology/about_us/ds/140019-our_history" target="_blank">built</a> the backends of ATMs, electronic funds transfer, and point-of-sale terminals for banks and credit unions. Today we’d probably describe EDS as a “banking core” or, at the very least, a “systems integrator” for banks—systems that eventually came to run on Intel chips.&nbsp;</p><p>‍</p><h5>1972</h5><p>In 1972, the year Steve Jobs graduated from high school, Charles Schwab’s new startup began offering brokerage services.<a href="#1">[1]</a> The company grew and expanded, and in 1979 Schwab spent a fortune on the “BETA” system, which stood for “Brokerage Execution and Transaction Analysis.” That was the same year Bill Gates and Paul Allen moved their fledgling startup from Albuquerque to Seattle, and renamed it Microsoft from the previous, awkward “Micro-Soft.” Steve Ballmer joined Microsoft the following year, the year that Schwab used its now-stable BETA system to offer 24 hour stock price quotes.&nbsp;</p><p>‍</p><h5>1984</h5><p>In 1984, Apple released the Macintosh. That same year, a group of entrepreneurs started a startup bank aimed at serving the tech industry that the traditional banks didn’t want to serve. When they opened their first branch in Mountain View, they needed something to attract PR, and they decided to <a href="https://www.computerhistory.org/collections/catalog/102739976" target="_blank">borrow</a> bunny suits from their first customers, which were semiconductor companies. The grand opening landed them in the local papers as the Valley wondered what was going on with this upstart bank with “bankers” dressed in bunny suits, but the message was clear. That bank is now the familiar banking institution we know today as <a href="https://www.svb.com/">Silicon Valley Bank</a>. Their strategy, of focusing on startups, was radical, but it worked.&nbsp;</p><p>‍</p><h5>Today</h5><p>There may be no better time to build fintech companies. </p><p>There’s no good reason for payments to take three days to settle in 2020. There’s no good reason for the most sophisticated companies in the world to pay workers on a rigid bimonthly schedule. There’s no good reason why predatory payday lenders are the best option for millions to turn to in economic hardship. There’s no good reason for the government to disburse stimulus funds by paper check delivered via the postal service. Each of these is an opportunity to build a product of real consequence.&nbsp;</p><p>But this industry is not new. If anything, today’s companies are just an extension of a long tradition. Square, Stripe, Adyen, Plaid, Brex, Modern Treasury, and others all stand on the shoulders of giants. We benefit from FICO’s pioneering work in instant decision making, Visa’s mastery of electronic payment networks, and SVB’s startup-focused business model. </p><p>If we study the lessons of history, we will build products with more impact.<br></p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/fintech-is-not-new</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580770</guid>
            <pubDate>Thu, 24 Sep 2020 16:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The missing harm of manual dispatch in Julia]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 37 (<a href="https://news.ycombinator.com/item?id=24580479">thread link</a>) | @amkkma
<br/>
September 24, 2020 | https://andreaskroepelin.de/blog/manual_dispatch/ | <a href="https://web.archive.org/web/*/https://andreaskroepelin.de/blog/manual_dispatch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Just a short one today:
New users of Julia coming from other dynamically typed languages might write functions like</p>
<div><pre><code data-lang="julia"><span>function</span> <span>foo</span><span>(</span><span>x</span><span>)</span>
    <span>if</span> <span>x</span> <span>isa</span> <span>Int</span>
        <span>x</span> <span>+</span> <span>x</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>Float64</span>
        <span>x</span> <span>/</span> <span>2.0</span>
    <span>elseif</span> <span>x</span> <span>isa</span> <span>String</span>
        <span>length</span><span>(</span><span>x</span><span>)</span>
    <span>else</span>
        <span>1</span>
    <span>end</span>
<span>end</span>
</code></pre></div><p>This is clearly unidiomatic and should be written as</p>
<div><pre><code data-lang="julia"><span>bar</span><span>(</span><span>x</span><span>::</span><span>Int</span><span>)</span> <span>=</span> <span>x</span> <span>+</span> <span>x</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>Float64</span><span>)</span> <span>=</span> <span>x</span> <span>/</span> <span>2.0</span>
<span>bar</span><span>(</span><span>x</span><span>::</span><span>String</span><span>)</span> <span>=</span> <span>length</span><span>(</span><span>x</span><span>)</span>
<span>bar</span><span>(</span><span>x</span><span>)</span> <span>=</span> <span>1</span> <span># or bar(x::Any), to be explicit</span>
</code></pre></div><p>because it is nicer to read and very easy to extend for other types of <code>x</code>.
Well, you technically can extend <code>foo</code> the same way as <code>bar</code>, but reading the definition of <code>foo</code> one would expect to then know its complete behavior, so it would be misleading.</p>
<p><em>However</em>, my point is that there is actually (maybe surprisingly) no harm at runtime for code as in <code>foo</code>!
The Julia compiler isn’t tricked that easily and will still produce optimal machine code for each type of the argument:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1</span><span>)</span>
    <span>.</span><span>text</span>
    <span>leaq</span>	<span>(</span><span>%</span><span>rdi</span><span>,</span><span>%</span><span>rdi</span><span>),</span> <span>%</span><span>rax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div><p>Both functions basically compile down to a single adding instruction (<code>leaq</code>; <code>retq</code> is for returning from the function and <code>nopw</code> is an operation that does nothing and is there for <a href="https://en.wikipedia.org/wiki/NOP_%28code%29%23Machine_language_instructions">technical reasons</a>).
Think about it this way:
When Julia compiles <code>foo(1)</code>, it knows that <code>1</code> is of type <code>Int</code>, can evaluate the <code>x isa Int</code> expression at compile time to <code>true</code>, and discard everything but the <code>x + x</code> without a problem.</p>
<h2 id="appendix">“Appendix”</h2>
<p>For completeness, here is what’s produced in the other cases:</p>
<div><pre><code data-lang="julia"><span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530607976</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A168</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>1.0</span><span>)</span>
    <span>.</span><span>text</span>
    <span>movabsq</span>	<span>$</span><span>140581530608088</span><span>,</span> <span>%</span><span>rax</span>  <span># imm = 0x7FDBB031A1D8</span>
    <span>vmulsd</span>	<span>(</span><span>%</span><span>rax</span><span>),</span> <span>%</span><span>xmm0</span><span>,</span> <span>%</span><span>xmm0</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>(</span><span>"abc"</span><span>)</span>
    <span>.</span><span>text</span>
    <span>pushq</span>	<span>%</span><span>rax</span>
    <span>movabsq</span>	<span>$</span><span>"ncodeunits;"</span><span>,</span> <span>%</span><span>rax</span>
    <span>callq</span>	<span>*%</span><span>rax</span>
    <span>popq</span>	<span>%</span><span>rcx</span>
    <span>retq</span>
    <span>nop</span>


<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>bar</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>

<span>julia</span><span>&gt;</span> <span>@code_native</span> <span>debuginfo</span><span>=:</span><span>none</span> <span>foo</span><span>([])</span>
    <span>.</span><span>text</span>
    <span>movl</span>	<span>$</span><span>1</span><span>,</span> <span>%</span><span>eax</span>
    <span>retq</span>
    <span>nopw</span>	<span>%</span><span>cs</span><span>:</span><span>(</span><span>%</span><span>rax</span><span>,</span><span>%</span><span>rax</span><span>)</span>
</code></pre></div>
        </div></div>]]>
            </description>
            <link>https://andreaskroepelin.de/blog/manual_dispatch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580479</guid>
            <pubDate>Thu, 24 Sep 2020 16:36:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp: Reader]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24580453">thread link</a>) | @azhenley
<br/>
September 24, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-6/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-5/">previous</a></em></p>

<p>Welcome back to the “Compiling a Lisp” series. This time I want to take a break
from compiling and finally add a <em>reader</em>. I’m finally getting frustrated
manually entering increasinly complicated ASTs, so I figure it is time. After
this post, we’ll be able to type in programs like:</p>



<p>and have our compiler make ASTs for us! Magic. This will also add some nice
debugging tools for us. For example, imagine an interactive command line
utility in which we can enter Lisp expressions and the compiler prints out
human-readable assembly (and hex? maybe?). It could even run the code, too.
Check out this imaginary demo:</p>

<div><div><pre><code>lisp&gt; 1
; mov rax, 0x4
=&gt; 1
lisp&gt; (add1 1)
; mov rax, 0x4
; add rax, 0x4
=&gt; 2
lisp&gt;
</code></pre></div></div>

<p>Wow, what a thought.</p>

<h3 id="the-reader-interface">The Reader interface</h3>

<p>To make this interface as simple and testable as possible, I want the reader
interface to take in a C string and return an <code>ASTNode *</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>);</span>
</code></pre></div></div>

<p>We can add interfaces later to support reading from a <code>FILE*</code> or file
descriptor or something, but for now we’ll just use strings and line-based
input.</p>

<p>On success, we’ll return a fully-formed <code>ASTNode*</code>. But on error, well, hold
on. We can’t just return <code>NULL</code>. On many platforms, <code>NULL</code> is defined to be
<code>0</code>, which is how we encode the integer <code>0</code>. On others, it could be defined to
be <code>0x55555555</code><sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> or something equally silly. Regardless, its value might
overlap with our type encoding scheme in some unintended way.</p>

<p>This means that we have to go ahead and add another immediate object: an
<code>Error</code> object. We have some open immediate tag bits, so sure, why not. We can
also use this to signal runtime errors and other fun things. It’ll probably be
useful.</p>

<h3 id="the-error-object">The Error object</h3>

<p>Back to the object tag diagram. Below I have reproduced the tag diagram from
previous posts, but now with a new entry (denoted by <code>&lt;-</code>). This new entry
shows the encoding for the canonical <code>Error</code> object.</p>

<div><div><pre><code>High							     Low
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX00  Integer
0000000000000000000000000000000000000000000000000XXXXXXX00001111  Character
00000000000000000000000000000000000000000000000000000000X0011111  Boolean
0000000000000000000000000000000000000000000000000000000000101111  Nil
0000000000000000000000000000000000000000000000000000000000111111  Error &lt;-
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX001  Pair
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX010  Vector
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX011  String
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX101  Symbol
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX110  Closure
</code></pre></div></div>

<p>If we wanted to, we could even add additional tag bits to the (currently all 0)
payload, to signal different kinds of errors. Maybe later. For now, we add a
tag constant and associated <code>Object</code> and <code>AST</code> functions:</p>

<div><div><pre><code><span>const</span> <span>unsigned</span> <span>int</span> <span>kErrorTag</span> <span>=</span> <span>0x3f</span><span>;</span> <span>// 0b111111</span>
<span>uword</span> <span>Object_error</span><span>()</span> <span>{</span> <span>return</span> <span>kErrorTag</span><span>;</span> <span>}</span>

<span>bool</span> <span>AST_is_error</span><span>(</span><span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span> <span>return</span> <span>(</span><span>uword</span><span>)</span><span>node</span> <span>==</span> <span>Object_error</span><span>();</span> <span>}</span>
<span>ASTNode</span> <span>*</span><span>AST_error</span><span>()</span> <span>{</span> <span>return</span> <span>(</span><span>ASTNode</span> <span>*</span><span>)</span><span>Object_error</span><span>();</span> <span>}</span>
</code></pre></div></div>

<p>That should be enough to get us going for now. Perhaps we could even convert
our <code>Compile_</code> suite of functions to use this object instead of an <code>int</code>. It
would certainly be more informative. Maybe in a future post.</p>

<h3 id="language-syntax">Language syntax</h3>

<p>Let’s get back to business and think about what we want our language to look
like. This is a Lisp series but really you could adapt your reader to read any
sort of syntax. No need for parentheses if you’re allergic.</p>

<p>I’m going to use this simple Lisp reader because it’s short and simple, so
we’ll have some parens.</p>

<p>First, our integers will look like integers in most languages — <code>0</code>, <code>123</code>,
<code>-123</code>.</p>

<p>You can add support for other bases if you like, but I don’t plan on it here.</p>

<p>Second, our characters will look like C characters — <code>'a'</code>, <code>'b'</code>, etc. Some
implementations opt for <code>#'a</code> but that has always looked funky to me.</p>

<p>Third, our booleans will be <code>#t</code> and <code>#f</code>. You’re also welcome to go ahead and
use symbols to represent the names, avoid special syntax, and have those
symbols evaluate to truthy and falsey values.</p>

<p>Fourth, the nil object will be <code>()</code>. We can also later bind the symbol <code>nil</code> to
mean <code>()</code>, too.</p>

<p>I’m going to skip error objects, because they don’t yet have any sort of
user-land meaning yet — they’re just used in compiler infrastructure right
now.</p>

<p>Fifth, pairs will look like <code>(1 2 3)</code>, meaning <code>(cons 1 (cons 2 (cons 3
nil)))</code>. I don’t plan on adding support for dotted pair syntax. Whitespace will
be insignificant.</p>

<p>Sixth, symbols will look like any old ASCII identifier: <code>hello</code>, <code>world</code>,
<code>fooBar</code>. I’ll also include some punctuation in there, too, so we can use <code>+</code>
and <code>-</code> as symbols, for example. Or we could even go full Lisp and use
<code>train-case</code> identifiers.</p>

<p>I’m going to skip closures, since they don’t have a syntactic representation
— they are just objects known to the runtime. Vectors and strings don’t have
any implementation right now so we’ll add those to the reader later.</p>

<p>That’s it! Key points are: mind your plus and minus signs since they can appear
in both integers and symbols; don’t read off the end; have fun.</p>

<h3 id="the-reader-implementation">The Reader implementation</h3>

<p>Now that we’ve rather informally specified what our language looks like, we can
write a small reader. We’ll start with the <code>Reader_read</code> function from above.</p>

<p>This function will just be a shell around an internal function with some more
parameters.</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>Reader_read</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>)</span> <span>{</span>
  <span>word</span> <span>pos</span> <span>=</span> <span>0</span><span>;</span>
  <span>return</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>&amp;</span><span>pos</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This is because we need to carry around some more state to read through this
string. We need to know how far into the string we are. I chose to use an
additional <code>word</code> for the index. Some might prefer a <code>char**</code> instead. Up to
you.</p>

<p>With any recursive reader invocation, we should advance through all the
whitespace, because it doesn’t mean anything to us. For this reason, we have a
handy-dandy <code>skip_whitespace</code> function that reads through all the whitespace
and then returns the next non-whitespace character.</p>

<div><div><pre><code><span>void</span> <span>advance</span><span>(</span><span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span> <span>++*</span><span>pos</span><span>;</span> <span>}</span>

<span>char</span> <span>next</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
<span>}</span>

<span>char</span> <span>skip_whitespace</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>for</span> <span>(</span><span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isspace</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>;</span>
  <span>}</span>
  <span>return</span> <span>c</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>We can use <code>skip_whitespace</code> in the <code>read_rec</code> function to fetch the next
non-whitespace character. Then we’ll use that character (and sometimes the
following one, too) to determine what structure we’re about to read.</p>

<div><div><pre><code><span>bool</span> <span>starts_symbol</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>switch</span> <span>(</span><span>c</span><span>)</span> <span>{</span>
  <span>case</span> <span>'+'</span><span>:</span>
  <span>case</span> <span>'-'</span><span>:</span>
  <span>case</span> <span>'*'</span><span>:</span>
  <span>case</span> <span>'&gt;'</span><span>:</span>
  <span>case</span> <span>'='</span><span>:</span>
  <span>case</span> <span>'?'</span><span>:</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>default:</span>
    <span>return</span> <span>isalpha</span><span>(</span><span>c</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_rec</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>isdigit</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'+'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '+'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'-'</span> <span>&amp;&amp;</span> <span>isdigit</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]))</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '-'</span>
    <span>return</span> <span>read_integer</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>,</span> <span>/*sign=*/</span><span>-</span><span>1</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>starts_symbol</span><span>(</span><span>c</span><span>))</span> <span>{</span>
    <span>return</span> <span>read_symbol</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '\''</span>
    <span>return</span> <span>read_char</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'t'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 't'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>true</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'#'</span> <span>&amp;&amp;</span> <span>input</span><span>[</span><span>*</span><span>pos</span> <span>+</span> <span>1</span><span>]</span> <span>==</span> <span>'f'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '#'</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip 'f'</span>
    <span>return</span> <span>AST_new_bool</span><span>(</span><span>false</span><span>);</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'('</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span> <span>// skip '('</span>
    <span>return</span> <span>read_list</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>}</span>
  <span>return</span> <span>AST_error</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>Note that I put the integer cases above the symbol case because we want to
catch <code>-123</code> as an integer instead of a symbol, and <code>-a123</code> as a symbol instead
of an integer.</p>

<p>We’ll probably add more entries to <code>starts_symbol</code> later, but those should
cover the names we’ve used so far.</p>

<p>For each type of subcase (integer, symbol, list), the basic idea is the same:
while we’re still inside the subcase, add on to it.</p>

<p>For integers, this means multiplying and adding (concatenating digits, so to
speak):</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_integer</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>,</span> <span>int</span> <span>sign</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>word</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span> <span>c</span> <span>=</span> <span>next</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>))</span> <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>c</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>AST_new_integer</span><span>(</span><span>sign</span> <span>*</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>It also takes a sign parameter so if we see an explicit <code>-</code>, we can negate the
integer.</p>

<p>For symbols, this means reading characters into a C string buffer:</p>

<div><div><pre><code><span>const</span> <span>word</span> <span>ATOM_MAX</span> <span>=</span> <span>32</span><span>;</span>

<span>bool</span> <span>is_symbol_char</span><span>(</span><span>char</span> <span>c</span><span>)</span> <span>{</span>
  <span>return</span> <span>starts_symbol</span><span>(</span><span>c</span><span>)</span> <span>||</span> <span>isdigit</span><span>(</span><span>c</span><span>);</span>
<span>}</span>

<span>ASTNode</span> <span>*</span><span>read_symbol</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>buf</span><span>[</span><span>ATOM_MAX</span> <span>+</span> <span>1</span><span>];</span> <span>// +1 for NUL</span>
  <span>word</span> <span>length</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span> <span>(</span><span>length</span> <span>=</span> <span>0</span><span>;</span> <span>length</span> <span>&lt;</span> <span>ATOM_MAX</span> <span>&amp;&amp;</span> <span>is_symbol_char</span><span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]);</span> <span>length</span><span>++</span><span>)</span> <span>{</span>
    <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>}</span>
  <span>buf</span><span>[</span><span>length</span><span>]</span> <span>=</span> <span>'\0'</span><span>;</span>
  <span>return</span> <span>AST_new_symbol</span><span>(</span><span>buf</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>For simplicity’s sake, I avoided dynamic resizing. We only get at most symbols
of size 32. Oh well.</p>

<p>Note that symbols can also have trailing numbers in them, just not at the front
— like <code>add1</code>.</p>

<p>For characters, we only have three potential input characters to look at:
quote, char, quote. No need for a loop:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_char</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>input</span><span>[</span><span>*</span><span>pos</span><span>];</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>input</span><span>[</span><span>*</span><span>pos</span><span>]</span> <span>!=</span> <span>'\''</span><span>)</span> <span>{</span>
    <span>return</span> <span>AST_error</span><span>();</span>
  <span>}</span>
  <span>advance</span><span>(</span><span>pos</span><span>);</span>
  <span>return</span> <span>AST_new_char</span><span>(</span><span>c</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This means that input like <code>''</code> or <code>'aa'</code> will be an error.</p>

<p>For booleans, we can tackle those inline because there’s only two cases and
they’re both trivial. Check for <code>#t</code> and <code>#f</code>. Done.</p>

<p>And last, for lists, it means we recursively build up pairs until we get to
<code>nil</code>:</p>

<div><div><pre><code><span>ASTNode</span> <span>*</span><span>read_list</span><span>(</span><span>char</span> <span>*</span><span>input</span><span>,</span> <span>word</span> <span>*</span><span>pos</span><span>)</span> <span>{</span>
  <span>char</span> <span>c</span> <span>=</span> <span>skip_whitespace</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>if</span> <span>(</span><span>c</span> <span>==</span> <span>')'</span><span>)</span> <span>{</span>
    <span>advance</span><span>(</span><span>pos</span><span>);</span>
    <span>return</span> <span>AST_nil</span><span>();</span>
  <span>}</span>
  <span>ASTNode</span> <span>*</span><span>car</span> <span>=</span> <span>read_rec</span><span>(</span><span>input</span><span>,</span> <span>pos</span><span>);</span>
  <span>assert</span><span>(</span><span>car</span> <span>!=</span> <span>AST_error</span><span>());</span>
  <span>ASTNode</span> <span>*</span><span>cdr</span> <span>=</span> <span>read_l…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">https://bernsteinbear.com/blog/compiling-a-lisp-6/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580453</guid>
            <pubDate>Thu, 24 Sep 2020 16:35:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a runtime reflection system for Rust (Part 1)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24580273">thread link</a>) | @samjs
<br/>
September 24, 2020 | https://www.osohq.com/post/rust-reflection-pt-1 | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/rust-reflection-pt-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Part 1: <code>dyn Class</code></h2>
<h3>Introduction</h3>
<p>We're building oso, an open source policy engine for authorization. You can use oso to separate authorization logic from application code by writing policies in our declarative language, called Polar. oso is built to be <em>embedded</em> directly in the application, which means you can pass in application objects, check types, lookup attributes, and call methods. To do this, it relies on each host language's support for runtime reflection.</p>
<p>This is trivial for languages like Python, for instance, where getting the type from an object is as simple as <code>type(obj)</code>, and accessing arbitrary attributes and methods is just <code>getattr(obj, "attr")</code>. We first shipped oso with support for Python, Ruby and Java, followed by JavaScript.</p>
<p>When we set out to build support for oso in Rust applications, we had to solve this problem ourselves because Rust doesn't have any out-of-the box support for runtime reflection. It does, however, have some low-level building blocks that we can assemble to create something similar.</p>
<p>This is the first part of a three-part series in which we describe how we implemented a runtime reflection system in Rust for oso.</p>
<p>In this post, we look at how dynamic type checks work in Rust, and explain how our team built a simple class system that we use as the foundation for the rest of the reflection system and the rest of the series.</p>
<h3>Introduction to <code>std::any::Any</code></h3>
<p>The main way to achieve dynamic dispatch in Rust is through the trait system. And the <a href="https://doc.rust-lang.org/book/ch17-03-oo-design-patterns.html#summary">Rust book has this quote</a> for us in design patterns:</p>
<blockquote>
<p>No matter whether or not you think Rust is an object-oriented language after reading this chapter, you now know that you can use trait objects to get some object-oriented features in Rust. Dynamic dispatch can give your code some flexibility in exchange for a bit of runtime performance</p>
</blockquote>
<p>In some ways, the Mother of all Traits is <a href="https://doc.rust-lang.org/std/any/trait.Any.html"><em>std::any::Any</em></a>, which the documentation describes as "A trait to emulate dynamic typing."</p>
<p>This lets us erase a thing's concrete type, and pass around its "trait object" instead:</p>
<pre><code>let s: String = "Hello, World".to_string();
let any: Box&lt;dyn Any&gt; = Box::new(s);

// `any` doesn't have a type, running:
//    println!("{}", any);
// would fail with:
//     error[E0277]: `dyn std::any::Any` doesn't implement `std::fmt::Display`

let mut recovered: Box&lt;String&gt; = any.downcast().expect("failed conversion");
recovered.make_ascii_uppercase();
println!("{}", recovered);
</code></pre>

<p>In case you're interested: profiling the bottom code takes 18ns versus approx. 16ns for the version without downcasting. You can see in the assembly there's some 20-30 instructions needed for the conversion: <a href="https://godbolt.org/z/Ph6q3b">https://godbolt.org/z/Ph6q3b</a>.</p>
<p>A few layers beneath the surface of the <code>Any</code> trait, and what makes the above possible, is <a href="https://doc.rust-lang.org/std/any/struct.TypeId.html#method.of"><code>TypeId::of::&lt;T&gt;</code></a>. This method uses a compiler intrinsic to inspect the object's type. The important part is that the original object still has a concrete type, even though that type has temporarily been "lost" to the current scope.</p>
<p>With this one small piece of intrinsic Rust, we begin to build our fully dynamic system.</p>
<h2>What is oso?</h2>
<p>As mentioned at the beginning, oso is a policy engine for authorization. It reads in policies – written in the Polar language – and makes authorization decisions by evaluating the rules against the provided inputs. Polar is a variant of Prolog, and encodes logic as rules. The syntax looks like this:</p>
<pre><code># True for all inputs that are of type Foo
is_a_foo(input: Foo);

# True if the x attribute of the input is equal to 1
x_is_one(input) if input.x = 1;
</code></pre>

<p>The important parts are (a) <code>input: Foo</code> which checks that the input parameter is of type <code>Foo</code>, and where <code>Foo</code> is a type defined in the application; and (b) <code>input.x</code> which is a lookup on <code>input</code> of the attribute <code>x</code> , even if <code>input</code> is an application object. These are the types of use cases that our dynamic system needs to support.</p>
<h3>Implementing <code>Class</code> and <code>Instance</code></h3>
<p>We lay the foundation of our runtime reflection system by wrapping types up in classes, and wrapping objects as instances. Starting with just the pieces we've seen so far, the initial implementations for these look like this:</p>
<pre><code>/// Class definition
struct Class {
   /// The name of the class
   name: String,
   /// The corresponding Rust type
   type_id: TypeId,
}

impl Class {
    /// Create a new class definition for the type `T`
    fn new&lt;T&gt;() -&gt; Self {
        Self {
            name: std::any::type_name::&lt;T&gt;(),
            type_id: TypeId::of::&lt;T&gt;(),
        }
    }
}

/// An instance of a class
struct Instance {
    inner: Arc&lt;dyn Any&gt;, // `Arc` because we don't need/want mutability
}

impl Instance {
    /// Construct a new `Instance` from a type that
    /// implements `Any` (i.e. any sized type).
    fn new(obj: impl Any) -&gt; Self {
        Self {
            inner: Arc::new(obj)
        }
    }
}
</code></pre>

<p>With just this in place, we have our simple runtime class system!</p>
<h3>Dynamic type checking</h3>
<p>As shown in the brief snippet of Polar earlier, we want to be able to type-check using the syntax <code>input: Foo</code>. This translates into our class system as: "is <code>input</code> an instance of the <code>Foo</code> class"?</p>
<p>We could track what type the object had when we created it by storing the <code>TypeId</code>, but it's actually even simpler to recover the <code>TypeId</code> of the inner object stored on our <code>Instance</code> using the <code>Any::type_id</code> trait method:</p>
<pre><code>impl Instance {
    /// Check whether this is an instance of the provided class
    fn instance_of(&amp;self, class: &amp;Class) -&gt; bool {
        self.inner.as_ref().type_id() == class.type_id
    }
}
</code></pre>

<p>Not bad!</p>
<p>Note one important detail: when writing this example I initially wrote <code>self.inner.type_id() == class.type_id</code> . This <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=51ca79b94b834e0696cd619b7c51634c">is not the same thing</a> as the code above, because <code>Arc&lt;dyn Any&gt;</code> <em>also</em> implements <code>std::any::Any</code>, and thus has a type ID. To avoid making these kinds of mistakes, we've found that the best practice is to restrict the number of places directly accessing the <code>dyn Any</code> object to as few as possible, providing helper functions for even the simplest of methods.</p>
<p>To test that this is working:</p>
<pre><code>#[test]
fn test_instance_of() {
    struct Foo {}
    struct Bar {}

    let foo_class: Class = Class::new::&lt;Foo&gt;();
    let bar_class: Class = Class::new::&lt;Bar&gt;();
    let foo_instance: Instance = Instance::new(Foo {});

    assert!(foo_instance.instance_of(&amp;foo_class));
    assert!(!foo_instance.instance_of(&amp;bar_class));
}
</code></pre>

<p>And there we have it –&nbsp;we were able to successfully determine <strong>at runtime</strong> the class of the <code>Instance</code>!</p>
<h3>Future extension: traits as interfaces</h3>
<p>Now that we have our class system up and running, what else can we do with it? One pattern used in oso policies is using inheritance to write rules over multiple objects. For example, we might model "vets can treat all pets," as <code>can_treat("vet", pet: Pet)</code>, but "only doctors can treat a human" as <code>can_treat("doctor", human: Human)</code>.</p>
<p>Rust doesn't <em>really</em> have any notion of subtypes (except for lifetimes, which are out of scope for this post) but it does have traits. And traits are like interfaces. So perhaps we should be able to use traits again in some way?</p>
<p>Revisiting the docs for <code>std::any::Any</code> we find:</p>
<blockquote>
<p>Note that &amp;dyn Any is limited to testing whether a value is of a specified concrete type, and cannot be used to test whether a type implements a trait.</p>
</blockquote>
<p>Well, then.</p>
<p>Not all hope is lost, there are some interesting approaches out there to do <em>just what we need</em>. The most prominent approach I could find is <a href="https://github.com/Diggsey/query_interface"><code>query_interface</code></a>. Or <a href="http://idubrov.name/rust/2018/06/16/dynamic-casting-traits.html">this blog post</a> on dynamic casting for traits.</p>
<p>Digging into how <code>query_interface</code> works: there's a fair amount of unsafety and casting pointers and vtable manipulation. All fun stuff, but the disappointing part (for us) is that the "check whether a type implements a trait" is really handled at compile-time by the macro. There are lines like:</p>
<pre><code>let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
</code></pre>

<p>Which will error at compile-time if <code>Foo</code> doesn't implement <code>MyTrait</code>:</p>
<pre><code>138 |     let x = ::std::ptr::null::&lt;Foo&gt;() as *const dyn MyTrait;
    |             ^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `MyTrait` is not implemented for `Foo`
</code></pre>

<p>It's doing the wildly unsafe casting-trait-objects-to-other-trait-objects-at-runtime, but the checks are all done at compile-time. And the trait bounds are explicitly "registered" through use of the macro: <code>interfaces!(Foo: dyn MyTrait)</code>.</p>
<p>Given that we're not <em>yet</em> interested in using trait implementations, rather just checking whether a type implements a trait or not, this approach doesn't help us get any closer to making our runtime reflection system support traits as interfaces.</p>
<p>If instead we scope the task to registering trait implementations as part of a macro, we can get there with something more straightforward:</p>
<pre><code>trait HasInterface {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool;
}

impl HasInterface for Foo {
    fn has_interface&lt;T: 'static + ?Sized&gt;() -&gt; bool
    {
        // compile-time assertions
        static_assertions::assert_impl_all!(Foo: MyTrait);

        // runtime check
        match std::any::TypeId::of::&lt;T&gt;() {
            x if x == std::any::TypeId::of::&lt;dyn MyTrait&gt;() =&gt; true,
              // ... etc
              _ =&gt; false,
        }
    }
}
</code></pre>

<p>The above code is safe, and can easily be automated through a macro. However, it does have the same limitation as <code>query_interface</code> –&nbsp;the traits need to be <a href="https://doc.rust-lang.org/1.26.2/book/second-edition/ch17-02-trait-objects.html#object-safety-is-required-for-trait-objects"><em>object safe</em></a>.</p>
<h3>Conclusion</h3>
<p>We've built the foundation of our runtime reflection system through classes and instances, and we've shown some simple dynamic type checking using the built in <code>Any</code> trait.</p>
<p>Up next, things start getting a bit more complicated as we attempt to replicate Python's <code>getattr</code> magic method, and make it possible to look up <em>attributes</em> on Rust structs dynamically at runtime.</p>
<ul>
<li>Subscribe to our newsletter below to get the next installment of this
  series.</li>
<li>Interested in learning more about oso? Check out our
  <a href="https://docs.osohq.com/">docs</a>.</li>
<li>If you have any feedback, or want to chat about Rust, come join us in
  <a href="https://join-slack.osohq.com/">Slack</a>.</li>
</ul></div></div></div>]]>
            </description>
            <link>https://www.osohq.com/post/rust-reflection-pt-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24580273</guid>
            <pubDate>Thu, 24 Sep 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Pragmatic Approach to Live Collaboration]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579935">thread link</a>) | @maclockard
<br/>
September 24, 2020 | https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration | <a href="https://web.archive.org/web/*/https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>At <a href="https://hex.tech/" target="_blank" rel="nofollow">Hex</a>, we're all about making data workflows more collaborative. Our product allows users to connect to data, build analyses with Python and SQL, and turn them into interactive apps anyone can use.</p><p>The backing "Logic View" of a Hex project is powered by a notebook-style interface, similar in spirit to products like Mathematica or Jupyter. From early on, we wanted to support live multi-user editing in this Logic View so users can review or assist each other with their work.</p><figure>
    <span>
      <span></span>
  <img alt="Our Logic view: a notebook-style interface" title="Our Logic view: a notebook-style interface" src="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png" srcset="https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ccb66/hex_logic_view.png 185w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/3ac6e/hex_logic_view.png 370w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/b38af/hex_logic_view.png 740w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/ffc38/hex_logic_view.png 1110w, https://hex.tech/static/a2beb2e7deaf89901a98f9e4d52b225c/0ff2a/hex_logic_view.png 1138w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span>
    <figcaption>Our Logic view: a notebook-style interface</figcaption>
  </figure><p>Our team evaluated several options, and wound up pursuing a pragmatic approach which we were able to implement for our entire application in less than six weeks. We are excited to share some details for others who might be thinking through similar decisions.</p><h2>State of the Art</h2><p>There are two dominant approaches to multi-user collaboration today: <strong>Operational Transforms</strong> and <strong>Conflict-free Replicated Data Types</strong>. Both are powerful, although they come with trade-offs that make implementation challenging, particularly for smaller teams like ours. There is also a lesser-known hybrid approach—originally pioneered by Figma—geared towards ease of implementation.</p><h3>Operational Transforms</h3><p><a href="https://en.wikipedia.org/wiki/Operational_transformation" target="_blank" rel="nofollow">Operational Transforms</a> (OT) has been around for years. This technology is famously used to back Google Docs, and there are a number of reference implementations available on the web.</p><div><div><p><strong>The basic idea of OT</strong> is to decompose all state mutations to specific operations.</p><p>As an example, let's say we want two editors to simultaneously edit the string <code>ello</code>. Editor 1 sends an operation that inserts <code>!</code> at position 4 (or <code>[!, 4]</code> for short) and Editor 2 sends another operation that inserts <code>H</code> at position 0 (or <code>[H, 0]</code>).</p><p>If received in this order, a client can process these operations as they are and get the desired text <code>Hello!</code>. However, if a client were to receive <code>[H, 0]</code> first and <code>[!, 4]</code> second, the resulting string would be the incorrect <code>Hell!o</code>. OT implementations need to account for this, and implement a transformation to correct or "transform" the second operation to <code>[!, 5]</code> in order to preserve the user's intent and get <code>Hello!</code>.</p></div></div><p>In order to properly broker operations between clients, OT requires a centralized server, which may not be acceptable for all use cases.</p><p>OT offers a lot of control to the developer over how user actions are de-conflicted, making it easy to preserve user intent and context.</p><p>The "transform" part, however, can be quite tricky and error-prone since an implementor needs to account for each pair of operations. The number of possible combinations grows quadratically with the number of operations, meaning even with extensive testing it's possible to miss an edge case. This combinatorial complexity means an application gets harder and harder to reason about over time. <sup id="fnref-1"><a href="#fn-1">1</a></sup></p><h3>Conflict-free Replicated Data Types</h3><p><a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type" target="_blank" rel="nofollow">Conflict-free Replicated Data Types</a> (CRDTs) are a newer alternative that sidesteps much of the complexity that burdens OT.</p><div><div><p><strong>The basic idea of CRDT</strong> is to use data structures that are inherently (you guessed it) conflict-free.</p><p>There are <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#portfolio-of-basic-crdts" target="_blank" rel="nofollow">several different CRDTs</a>, each with their own implementation details. An example CRDT is a <a href="https://www.baeldung.com/java-conflict-free-replicated-data-types#grow-only-set" target="_blank" rel="nofollow">Grow Only Set</a>, which can only have elements added to it, but never removed. Conflicts are avoided since it is impossible to add/remove an item at the same time.</p><p>A multiplayer application can compose different types of CRDTs to create more complex structures for modeling its state.</p></div></div><p>CRDTs avoid the combinatorial complexity that comes along with OT, and also enable direct client-to-client communication, removing the need for a central server. Despite these advantages, they still have major trade-offs.</p><p>While CRDTs are correct from a mathematical standpoint, they might not have the correct semantics for a specific application. For example, the result of a state mutation is always consistent, but it may not be exactly what was expected since it's possible to lose user intent. <sup id="fnref-2"><a href="#fn-2">2</a></sup></p><p>CRDTs also trade off the complexity of resolving conflicts for a more challenging initial implementation, due to their reliance on algorithms like <a href="https://en.wikipedia.org/wiki/Vector_clock" target="_blank" rel="nofollow">vector clocks</a>. They also incur a fair amount of storage overhead—while there is <a href="https://www.youtube.com/watch?v=x7drE24geUw&amp;feature=youtu.be&amp;t=3198" target="_blank" rel="nofollow">progress being made</a>, avoiding this problem requires foresight and cleverness. And since CRDTs are newer, there are fewer reference implementations. <sup id="fnref-3"><a href="#fn-3">3</a></sup></p><h3>Figma's Hybrid Approach</h3><p>While at first we considered OT and CRDTs as our two main options, we were intrigued by <a href="https://www.figma.com/blog/how-figmas-multiplayer-technology-works/" target="_blank" rel="nofollow">the pragmatic approach taken by Figma</a>. They borrowed some ideas from CRDTs, like a <a href="https://github.com/pfrazee/crdt_notes/tree/68c5fe81ade109446a9f4c24e03290ec5493031f#last-writer-wins-register-lww-register" target="_blank" rel="nofollow">last-writer-wins data register</a>. Instead of using vector clocks to provide an ordering guarantee, however, they used a central authority, similar to OT.</p><p>By using the best parts of both OT and CRDTs, Figma avoided challenges with de-conflicting operations and difficulty of implementation. The main trade-off is that certain functionality, such as multi-user editable text strings, is not easily supported.</p><p>Figma's hybrid technique resonated with us as being both practical and elegant, although it was surprising that we couldn't find examples of others pursuing a similar approach. <sup id="fnref-4"><a href="#fn-4">4</a></sup></p><p>
  <video src="https://hex.tech/images/blog/figma-multiplayer.mp4" preload="auto" muted="" loop="" playsinline="" webkit-playsinline="" x5-playsinline="" autoplay="">
  </video>
<figcaption>From Figma's Blog Post</figcaption></p><h2>Choosing a Path</h2><p>As we assessed our options, we weighed a few key factors:</p><h3>Taking it step by step</h3><p>It was important to us that our solution was <a href="https://hex.tech/blog/incremental-shipping" target="_blank" rel="nofollow">shippable incrementally</a> and completable within a reasonable time frame. Any solution that required rewriting significant parts of our code base all at once, or a "big bang" cutover, would have not been acceptable.</p><h3>Our current stack</h3><p>Some existing multiplayer frameworks, such as <a href="https://github.com/share/sharedb" target="_blank" rel="nofollow">ShareDB</a>, require storing the model in a specific format and shape, or that the frontend connects to the model in a particular way.</p><p>We wanted to avoid major changes like this. An ideal solution would need to work well with our current tools, including:</p><ul>
<li><a href="https://www.apollographql.com/docs/" target="_blank" rel="nofollow">Apollo + GraphQL</a> to build an API schema shared by our frontend and backend services</li>
<li><a href="https://graphql-code-generator.com/" target="_blank" rel="nofollow">GraphQL Code Generator</a> and Typescript to ensure type safety across the entire stack</li>
<li><a href="https://www.apollographql.com/docs/react/" target="_blank" rel="nofollow">Apollo Client</a> on the frontend to store requested data in a normalized object cache that allows React to intelligently subscribe to changes</li>
<li>PostgreSQL and relational database patterns/features like normalization, constraints, and transactions to help guarantee data consistency and correctness</li>
</ul><p>This stack strikes a good balance between feature velocity and stability, and we wanted to build on top of it—not replace it.</p><h3>Controlling our destiny</h3><p>As we considered these approaches, we evaluated a number of open source libraries. We're generally enthusiastic about adopting and contributing to OSS, and originally thought to do so here.</p><p>While there are some great projects out there, like <a href="https://github.com/automerge/automerge" target="_blank" rel="nofollow">Automerge</a> and <a href="https://github.com/yjs/yjs" target="_blank" rel="nofollow">Y.js</a>, it can be risky to outsource something as core as our application state. Even really promising projects can lose momentum: <a href="https://github.com/Operational-Transformation/ot.js/" target="_blank" rel="nofollow">ot.js</a>, for example, is an Operational Transform library with over 1.2k stars on Github, but is no longer under active development and is looking for a maintainer.</p><h2>Atomic Operations</h2><p>After considering our options, we pursued an approach inspired by Figma's hybrid solution. We call it <strong>Atomic Operations (AO),</strong> as all edits to application state are broken down to their smallest <em>atomic</em> parts.</p><p>For us, this technique struck the right balance between ease of implementation, compatibility with our stack, and control over the application foundations.</p><p><span>
      <span></span>
  <img alt="splitting atom" title="splitting atom" src="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png" srcset="https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/ccb66/splitting-atom.png 185w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/3ac6e/splitting-atom.png 370w, https://hex.tech/static/6f23e527d113a4b225b481e26dff0926/b38af/splitting-atom.png 740w" sizes="(max-width: 740px) 100vw, 740px" loading="lazy">
    </span></p><h3>Splitting the Atom</h3><p>AO mutations exist at the single property update level, such that <strong>two operations of different types cannot conflict with each other.</strong></p><p>It is, however, still possible for two operations of the <em>same type</em> to conflict. This is determined by an operation's <code>conflictId</code>, which is a concatenation of its type and the ID of the object being edited. <sup id="fnref-5"><a href="#fn-5">5</a></sup> Since we use last-writer-wins semantics, we don't merge conflicts, we just pick a winner.</p><p>For determining which operation is "last", the server keeps track of a monotonically increasing counter per object that increments with each write. Upon acknowledging an operation, the server includes the latest value of this counter. To determine which operation is a winner, the client simply chooses the operation with the higher value. A central authority is required to implement this monotonic counter, prohibiting any distributed implementations.</p><p>As an example, take a hypothetical object type "foobar":</p><div data-language="typescript"><pre><code><span>interface</span> <span>Foobar</span> <span>{</span>
  id<span>:</span> <span>string</span>
  name<span>:</span> <span>string</span>
  color<span>:</span> <span>string</span>
<span>}</span></code></pre></div><p>Here are some examples of atomic operations for creating and editing a foobar:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"CREATE_FOOBAR"</span><span>,</span>
  conflictId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    name<span>:</span> <span>"My new foobar"</span><span>,</span>
    color<span>:</span> <span>"#DE1738"</span>
  <span>}</span>
<span>}</span>

<span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_COLOR"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_COLOR-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newColor<span>:</span> <span>"#0B6623"</span>
  <span>}</span>
<span>}</span></code></pre></div><p>Again: by breaking down all edits to a foobar object to changing individual properties, we remove the need to worry about how different operations might merge—<strong>at this level of granularity, only one write <em>can</em> win.</strong></p><p>A nice benefit of this decomposition is that all mutations to state are described by plain objects. A keen eye might note some parallels with how <a href="https://redux.js.org/basics/actions" target="_blank" rel="nofollow">Redux defines actions</a>, and indeed AO similarly benefits from making state mutations predictable, transparent, and easily testable.</p><p>Finally, we implemented undo / redo by requiring all atomic operation to include an additional operation that can undo the change. As an example:</p><div data-language="typescript"><pre><code><span>{</span>
  <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
  conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
  creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
  payload<span>:</span> <span>{</span>
    id<span>:</span> <span>"123ABC"</span><span>,</span>
    newName<span>:</span> <span>"My slightly less new foobar"</span>
  <span>}</span><span>,</span>
  undo<span>:</span> <span>{</span>
    <span>type</span><span>:</span> <span>"SET_FOOBAR_NAME"</span><span>,</span>
    conflictId<span>:</span> <span>"SET_FOOBAR_NAME-123ABC"</span><span>,</span>
    creationId<span>:</span> <span>"CREATE_FOOBAR-123ABC"</span><span>,</span>
    payload<span>:</span> <span>{</span>
      id<span>:</span> <span>"123ABC"</span><span>,</span>
      newName<span>:</span> <span>"My new foobar"</span> 
    <span>}</span><span>,</span>
  <span>}</span>
<span>}</span></code></pre></div><h3>Getting fractional</h3><p>A drawback of AO is that certain types of mutations can be difficult to express as simple last-writer-wins operations.</p><p>One such case is ordered collections. With classic integer indexing of a collection, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration">https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</a></em></p>]]>
            </description>
            <link>https://hex.tech/blog/a-pragmatic-approach-to-live-collaboration</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579935</guid>
            <pubDate>Thu, 24 Sep 2020 16:00:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Hat releases 2.0.0 of Odo, a Kubernetes and OpenShift dev tool]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579814">thread link</a>) | @twelvenmonkeys
<br/>
September 24, 2020 | https://odo.dev/blog/odo-200-ga-release/ | <a href="https://web.archive.org/web/*/https://odo.dev/blog/odo-200-ga-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<div>
							<p><code>2.0.0</code> of odo has been released!</p>



<h4 id="changes-to-the-default-deployment-method">Changes to the default deployment method</h4>

<p><a href="ihttps://devfile.github.io/devfile/index.html">Devfile</a> is a file format that is used as odo’s new deployment engine. Starting from <code>2.0.0</code> onwards, Source-to-Image (S2I) is no longer the default deployment method. S2I is still supported and can now be accessed with the <code>--s2i</code> flag from the command-line.</p>

<p>Learn how to deploy your first devfile using devfiles from our <a href="https://odo.dev/docs/deploying-a-devfile-using-odo/">Devfile tutorial</a>.</p>

<p>Example on how to download a starter project and deploy a devfile:</p>

<div><div><pre><code><span>$ </span>odo create nodejs <span>--starter</span>
Validation
 ✓  Checking devfile existence <span>[</span>22411ns]
 ✓  Checking devfile compatibility <span>[</span>22492ns]
 ✓  Creating a devfile component from registry: DefaultDevfileRegistry <span>[</span>24341ns]
 ✓  Validating devfile component <span>[</span>74471ns]

Starter Project
 ✓  Downloading starter project nodejs-starter from https://github.com/odo-devfiles/nodejs-ex.git <span>[</span>479ms]

Please use <span>`</span>odo push<span>`</span> <span>command </span>to create the component with <span>source </span>deployed

<span>$ </span>odo push

Validation
 ✓  Validating the devfile <span>[</span>132092ns]

Creating Kubernetes resources <span>for </span>component nodejs
 ✓  Waiting <span>for </span>component to start <span>[</span>5s]

Applying URL changes
 ✓  URL http-3000: http://http-3000-nodejs-foobar.myproject.example.com/ created

Syncing to component nodejs
 ✓  Checking files <span>for </span>pushing <span>[</span>1ms]
 ✓  Syncing files to the component <span>[</span>868ms]

Executing devfile commands <span>for </span>component nodejs
 ✓  Executing <span>install command</span> <span>"npm install"</span> <span>[</span>4s]
 ✓  Executing run <span>command</span> <span>"npm start"</span> <span>[</span>2s]

Pushing devfile component nodejs
 ✓  Changes successfully pushed to component
</code></pre></div></div>

<h4 id="deploying-a-custom-kubernetes-controller-with-odo">Deploying a custom Kubernetes controller with odo</h4>

<p>With the release of <code>2.0.0</code> deploying operators is now out of experimental mode.</p>

<p>Learn how to deploy your first Kubernetes custom controller from our <a href="https://odo.dev/docs/operator-hub/">Operator documentation</a>.</p>

<p>Example on how to deploy your first Operator:</p>

<div><div><pre><code><span>$ </span>odo catalog list services
  Operators available <span>in </span>the cluster
  NAME                          CRDs
  etcdoperator.v0.9.4           EtcdCluster, EtcdBackup, EtcdRestore

<span>$ </span>odo service create etcdoperator.v0.9.4/EtcdCluster
</code></pre></div></div>

<h4 id="odo-debug-is-no-longer-in-technical-preview"><code>odo debug</code> is no longer in technical preview</h4>

<p>The <code>odo debug</code> command is no longer in technical preview.</p>

<p><a href="https://odo.dev/docs/debugging-using-devfile/">Learn how to debug your component via the CLI or VSCode</a>.</p>



<h2 id="installing-odo-on-linux">Installing odo on Linux</h2>

<h3 id="binary-installation">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-linux-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-macos">Installing odo on macOS</h2>

<h3 id="binary-installation-1">Binary installation</h3>

<div><div><pre><code># curl -L https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-darwin-amd64 -o /usr/local/bin/odo
# chmod +x /usr/local/bin/odo
</code></pre></div></div>

<h2 id="installing-odo-on-windows">Installing odo on Windows</h2>

<h3 id="binary-installation-2">Binary installation</h3>

<ol>
  <li>
    <p>Download the latest  <a href="https://mirror.openshift.com/pub/openshift-v4/clients/odo/latest/odo-windows-amd64.exe"><code>odo.exe</code></a>   file.</p>
  </li>
  <li>
    <p>Add the location of your <code>odo.exe</code> to your <code>GOPATH/bin</code> directory.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-10">Setting the <code>PATH</code> variable for Windows 10</h3>

<p>Edit <code>Environment Variables</code> using search:</p>

<ol>
  <li>
    <p>Click <strong>Search</strong> and type <code>env</code> or <code>environment</code>.</p>
  </li>
  <li>
    <p>Select <strong>Edit environment variables for your account</strong>.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>

<h3 id="setting-the-path-variable-for-windows-78">Setting the <code>PATH</code> variable for Windows 7/8</h3>

<p>The following example demonstrates how to set up a path variable. Your binaries can be located in any location, but this example uses C:\go-bin as the location.</p>

<ol>
  <li>
    <p>Create a folder at <code>C:\go-bin</code>.</p>
  </li>
  <li>
    <p>Right click <strong>Start</strong> and click <strong>Control Panel</strong>.</p>
  </li>
  <li>
    <p>Select <strong>System and Security</strong> and then click <strong>System</strong>.</p>
  </li>
  <li>
    <p>From the menu on the left, select the <strong>Advanced systems settings</strong>  and click the <strong>Environment Variables</strong> button at the bottom.</p>
  </li>
  <li>
    <p>Select <strong>Path</strong> from the <strong>Variable</strong> section and click <strong>Edit</strong>.</p>
  </li>
  <li>
    <p>Click <strong>New</strong> and type <code>C:\go-bin</code> into the field or click    <strong>Browse</strong> and select the directory, and click <strong>OK</strong>.</p>
  </li>
</ol>



<p><strong>New features:</strong></p>

<ul>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/issues/3644">#3644</a></li>
  <li>Release 2.0.0 <a href="https://github.com/openshift/odo/pull/4021">#4021</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Move Operator Hub out of experimental mode <a href="https://github.com/openshift/odo/pull/3938">#3938</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Implement clonePath, update source code sync location <a href="https://github.com/openshift/odo/pull/3907">#3907</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Code Refactoring:</strong></p>

<ul>
  <li>“odo link” help message should not check for ClusterServiceVersion support <a href="https://github.com/openshift/odo/issues/4008">#4008</a></li>
  <li>API version and schema version tests should be migrated to devfileV2 <a href="https://github.com/openshift/odo/issues/3794">#3794</a></li>
  <li>Do not check for CSV when initializing odo link command <a href="https://github.com/openshift/odo/pull/4010">#4010</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Update odo debug –help screen <a href="https://github.com/openshift/odo/pull/3963">#3963</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Clarify description of the force-build flag in help text for odo push <a href="https://github.com/openshift/odo/pull/3958">#3958</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Switch to use project instead of namespace in env <a href="https://github.com/openshift/odo/pull/3951">#3951</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Remove the namespace flag from odo <a href="https://github.com/openshift/odo/pull/3949">#3949</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Migrate devfile cmd validation to validate pkg <a href="https://github.com/openshift/odo/pull/3912">#3912</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Remove command group type init <a href="https://github.com/openshift/odo/pull/3898">#3898</a> (<a href="https://github.com/adisky">adisky</a>)</li>
</ul>

<p><strong>Bugs:</strong></p>

<ul>
  <li>“odo link -h” shows same message for 3.x &amp; 4.x clusters <a href="https://github.com/openshift/odo/issues/3992">#3992</a></li>
  <li>make goget-tools fails due to go mod dependency <a href="https://github.com/openshift/odo/issues/3983">#3983</a></li>
  <li>Handle edge case when index file is commented in .gitignore <a href="https://github.com/openshift/odo/issues/3961">#3961</a></li>
  <li>Java component build execution requires pom.xml <a href="https://github.com/openshift/odo/issues/3943">#3943</a></li>
  <li>default registry not initialized when user already has a preference.yaml file <a href="https://github.com/openshift/odo/issues/3940">#3940</a></li>
  <li><code>odo url create</code> shouldn’t require a port if only one port exists in the devfile <a href="https://github.com/openshift/odo/issues/3923">#3923</a></li>
  <li><code>odo push</code> with alternate –run-command should push complete file set upon new pod creation <a href="https://github.com/openshift/odo/issues/3918">#3918</a></li>
  <li>converting s2i items to devfile items does not set the Endpoint’s name properly <a href="https://github.com/openshift/odo/issues/3910">#3910</a></li>
  <li>Unexpected EOF during watch stream event decoding, watch channel was closed. <a href="https://github.com/openshift/odo/issues/3905">#3905</a></li>
  <li>odo debug serial tests script panic out <a href="https://github.com/openshift/odo/issues/3897">#3897</a></li>
  <li>Default URL does not propagate to <code>.odo/env/env.yaml</code> and you cannot delete it. <a href="https://github.com/openshift/odo/issues/3893">#3893</a></li>
  <li>Breaking component create without exposing port <a href="https://github.com/openshift/odo/issues/3882">#3882</a></li>
  <li>odo registry list causes panic if preference has not been setup <a href="https://github.com/openshift/odo/issues/3842">#3842</a></li>
  <li>odo watch goes into infinite push loop if ignore flag is used <a href="https://github.com/openshift/odo/issues/3819">#3819</a></li>
  <li>‘odo create’ should properly validate devfiles <a href="https://github.com/openshift/odo/issues/3778">#3778</a></li>
  <li>context flag does not work with devfile url create <a href="https://github.com/openshift/odo/issues/3767">#3767</a></li>
  <li>odo log is unusable for multi container components <a href="https://github.com/openshift/odo/issues/3711">#3711</a></li>
  <li>“odo registry add” adds registry for invalid url in devfileV2 <a href="https://github.com/openshift/odo/issues/3451">#3451</a></li>
  <li>Prints help message based on backend cluster <a href="https://github.com/openshift/odo/pull/3993">#3993</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>s2i component fix: use Config instead of ContainerConfig for port detection <a href="https://github.com/openshift/odo/pull/3957">#3957</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>3923- url creation with optional port flag <a href="https://github.com/openshift/odo/pull/3950">#3950</a> (<a href="https://github.com/yangcao77">yangcao77</a>)</li>
  <li>Add mandatory file ignores when using –ignore flag <a href="https://github.com/openshift/odo/pull/3942">#3942</a> (<a href="https://github.com/maysunfaisal">maysunfaisal</a>)</li>
  <li>Fix default registry support <a href="https://github.com/openshift/odo/pull/3941">#3941</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>Update s2i image from library for ppc64le <a href="https://github.com/openshift/odo/pull/3939">#3939</a> (<a href="https://github.com/sarveshtamba">sarveshtamba</a>)</li>
  <li>update s2i to devfile conversion as per new url design <a href="https://github.com/openshift/odo/pull/3930">#3930</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Add test-case for validating devfiles on component create <a href="https://github.com/openshift/odo/pull/3908">#3908</a> (<a href="https://github.com/johnmcollier">johnmcollier</a>)</li>
  <li>Improve URL format validation <a href="https://github.com/openshift/odo/pull/3900">#3900</a> (<a href="https://github.com/GeekArthur">GeekArthur</a>)</li>
  <li>implement odo describe for devfile <a href="https://github.com/openshift/odo/pull/3843">#3843</a> (<a href="https://github.com/metacosm">metacosm</a>)</li>
</ul>

<p><strong>Tests:</strong></p>

<ul>
  <li>Test failures while running <code>test-cmd-push</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3539">#3539</a></li>
  <li>Test failures while running <code>test-cmd-storage</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3531">#3531</a></li>
</ul>

<p><strong>Documentation &amp; Discussions:</strong></p>

<ul>
  <li>Update installation page to include instructions for VSCode / IDE’s <a href="https://github.com/openshift/odo/issues/3970">#3970</a></li>
  <li>Update docs according to schema changes in the command and component struct <a href="https://github.com/openshift/odo/issues/3925">#3925</a></li>
  <li>Help for <code>odo push -f</code> should explain that the full set of project source is pushed to the container <a href="https://github.com/openshift/odo/issues/3919">#3919</a></li>
  <li>Make the <code>odo.dev</code> front page documentation simpler <a href="https://github.com/openshift/odo/issues/3887">#3887</a></li>
  <li>Add debug examples for “odo debug -h” <a href="https://github.com/openshift/odo/issues/3871">#3871</a></li>
  <li>Remove technology preview feature for debug command <a href="https://github.com/openshift/odo/issues/3869">#3869</a></li>
  <li>Update devfile “odo.dev” doc <a href="https://github.com/openshift/odo/issues/3868">#3868</a></li>
  <li>Documentation for Operator Hub integration in v2 <a href="https://github.com/openshift/odo/issues/3810">#3810</a></li>
  <li>Document on converting s2i to devfile <a href="https://github.com/openshift/odo/issues/3749">#3749</a></li>
  <li>Adds a blog folder <a href="https://github.com/openshift/odo/pull/4003">#4003</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Document odo and Operator Hub integration <a href="https://github.com/openshift/odo/pull/3982">#3982</a> (<a href="https://github.com/dharmit">dharmit</a>)</li>
  <li>Add instructions on how to install VSCode plugin <a href="https://github.com/openshift/odo/pull/3977">#3977</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Update installation page to indicate beta-1 <a href="https://github.com/openshift/odo/pull/3960">#3960</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Remove references to Docker support <a href="https://github.com/openshift/odo/pull/3954">#3954</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
  <li>Updates docs to use the new schema changes for commands and components <a href="https://github.com/openshift/odo/pull/3928">#3928</a> (<a href="https://github.com/mik-dass">mik-dass</a>)</li>
  <li>Update commands ouputs in docs. <a href="https://github.com/openshift/odo/pull/3927">#3927</a> (<a href="https://github.com/boczkowska">boczkowska</a>)</li>
</ul>

<p><strong>Closed issues:</strong></p>

<ul>
  <li>Determine if we want to keep Docker support in experimental mode, or disable it <a href="https://github.com/openshift/odo/issues/3955">#3955</a></li>
  <li>rename –namespace flag in odo push to –project <a href="https://github.com/openshift/odo/issues/3948">#3948</a></li>
  <li>rename odo env variable namespace to project <a href="https://github.com/openshift/odo/issues/3947">#3947</a></li>
  <li>Test failures while running <code>test-integration</code>  and <code>test-e2e-all</code> test suite on ppc64le <a href="https://github.com/openshift/odo/issues/3945">#3945</a></li>
  <li>“unknown flag: –s2i” while running odo test suite ‘test-generic’ on ppc64le <a href="https://github.com/openshift/odo/issues/3934">#3934</a></li>
  <li>odo <code>make</code> commands fail on ppc64le after latest changes. <a href="https://github.com/openshift/odo/issues/3891">#3891</a></li>
  <li>Downstream release of the odo cli <a href="https://github.com/openshift/odo/issues/3852">#3852</a></li>
  <li>clonePath should be supported in odo <a href="https://github.com/openshift/odo/issues/3729">#3729</a></li>
  <li>Move devfile command validation to validate pkg <a href="https://github.com/openshift/odo/issues/3703">#3703</a></li>
  <li><code>make test</code> throws “Errorf format %w has unknown verb w” error on ppc64le with latest master <a href="https://github.com/openshift/odo/issues/3607">#3607</a></li>
  <li>Move Operator Hub integration out of Experimental mode <a href="https://github.com/openshift/odo/issues/3595">#3595</a></li>
  <li>Move container image used in springboot devfile to some odo owned image repository <a href="https://github.com/openshift/odo/issues/3578">#3578</a></li>
  <li>Move the devfile feature set out of the experimental mode <a href="https://github.com/openshift/odo/issues/3550">#3550</a></li>
  <li>JSON  / machine output support for Devfile Components <a href="https://github.com/openshift/odo/issues/3521">#3521</a></li>
  <li>Component push throws error of “Waiting for component to start” on ppc64le <a href="https://github.com/openshift/odo/issues/3497">#3497</a></li>
  <li>odo project create throws error of connection refused on ppc64le <a href="https://github.com/openshift/odo/issues/3491">#3491</a></li>
  <li>Tests for devfiles in odo devfile registry <a href="https://github.com/openshift/odo/issues/3378">#3378</a></li>
</ul>

<p><strong>Merged pull requests:</strong></p>

<ul>
  <li>vendor: switch location of goautoneg to github <a href="https://github.com/openshift/odo/pull/3984">#3984</a> (<a href="https://github.com/kadel">kadel</a>)</li>
  <li>Remove url describe command <a href="https://github.com/openshift/odo/pull/3981">#3981</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>odo list follow up implementation <a href="https://github.com/openshift/odo/pull/3964">#3964</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Fix test failure caused by updating springboot devfile <a href="https://github.com/openshift/odo/pull/3946">#3946</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>apiVersion test migrated to devfileV2 <a href="https://github.com/openshift/odo/pull/3920">#3920</a> (<a href="https://github.com/anandrkskd">anandrkskd</a>)</li>
  <li>add test for odo url create –context flag <a href="https://github.com/openshift/odo/pull/3917">#3917</a> (<a href="https://github.com/girishramnani">girishramnani</a>)</li>
  <li>Update springboot devfile <a href="https://github.com/openshift/odo/pull/3799">#3799</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Fix odo log for multi containers devfile <a href="https://github.com/openshift/odo/pull/3735">#3735</a> (<a href="https://github.com/adisky">adisky</a>)</li>
  <li>Make Devfile the default deployment mechanism <a href="https://github.com/openshift/odo/pull/3705">#3705</a> (<a href="https://github.com/cdrage">cdrage</a>)</li>
</ul>

						</div><!-- /.content -->
					</div></div>]]>
            </description>
            <link>https://odo.dev/blog/odo-200-ga-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579814</guid>
            <pubDate>Thu, 24 Sep 2020 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handshake – A Namespace for the Decentralized Web]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 86 (<a href="https://news.ycombinator.com/item?id=24579284">thread link</a>) | @rasengan
<br/>
September 24, 2020 | https://meowis.ms/handshake.html | <a href="https://web.archive.org/web/*/https://meowis.ms/handshake.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://meowis.ms/"> &lt; </a>




<!-- <div class="subtitle"></div> -->

<p>Names are fundamental to human existence and how we relate to everything in the world. At the heart of all interactions lies the ability for all the parties to match names to the respective entities they stand for.</p>

<p>Names are so integral to the human experience that a strong argument can be made that if <em>something doesnâ€™t have a name, it does not exist.</em></p>

<p>Correspondingly, names on the internet are critical to our online existence. Users, apps, or machines locate a resource on the internet via its name. The name needs to not only be understood by humans but also needs to be uniquely identifiable by machines amongst the billions of potential destinations.</p>

<p>Given that the act of matching a name to the eventual resource is the starting point of trillions of internet transactions that happen daily,  it is no surprise that out of the three core layers of internet stack - naming (DNS), transportation (TCP/IP) and application (HTTP), naming is at the very start of the stack.</p>

<p>Naming needs a single source of truth as the names within the namespaces have to be unique across the whole system. Hence, an effective naming system cannot merely be a standard or a protocol, it has to meet all the other aspects of running an internet-scale namespace - including enforcement of unique names, the management of the naming records, scaling to internet traffic, while remaining fully accessible to anyone, anywhere.</p>

<h2 id="namespaces">Namespaces</h2>

<p>Names are the most valuable assets on the internet, but we donâ€™t own our own names. All of the crucial namespaces belong to centralized entities who control the namespaces and take that control away from you. This is true for all significant namespaces today - the ICANN namespace, Facebook, Twitter, and Google.</p>

<p>As a result, your name on the internet does not belong to you, but rather to the owners of these centralized namespaces.  With a stroke of the keyboard, they can remove anyone from existence.  If your name lives on a centralized namespace, your right to exist effectively belongs to someone else.</p>

<p>Centralized namespaces also determine much more than a userâ€™s ability to exist. They also decree a userâ€™s ability to search, match, and communicate with others. They unilaterally set the framework for what protocols can be used, which use cases are permitted, and what information can flow.</p>

<p>The power to enforce monopolies with little consequence also makes these centralized namespaces some of the most valuable properties on the internet today. Verisign makes billions a year controlling .com with practically zero innovation, while ICANN has the power to arbitrarily raise price caps of entire TLDs with their pet cartel companies. Facebook and Twitter controls exactly how users can use their names/accounts, and can heedlessly cancel pages and remove identities for barely specified reasons.</p>

<p>Everywhere we see, we are seeing the serious dangers of depending on centralized entities to exist and be found by others. The Internet is supposed to be kingless, but the ability to strike away oneâ€™s existence and control exactly how the name is to be used makes the owners of these namespaces the de-facto kings/governors of the internet.</p>

<h2 id="the-world-needs-a-decentralized-namespace">The World Needs a Decentralized Namespace</h2>

<p>Of course, the ability of these centralized namespace owners to control digital existence, lockout access, and enforce monopolistic economics is the complete opposite goal of the decentralized web, which is the ability to exist, innovate, and create their own business models without the need for centralized control or systems.</p>

<p>Whether itâ€™s decentralized currencies, decentralized file systems, or decentralized servers - if these decentralized entities do not live on a widely used namespace, they simply do not exist to the vast majority of users on the internet.</p>

<p><em>Without a decentralized namespace widely readable by humans and resolvable by machines, it is impossible for the decentralized world to be widely adopted by users</em>.</p>

<p><strong>Criteria for a Decentralized Naming System</strong></p>

<p>Naming systems play a crucial role in discovery, connection and identification. As one of the most fundamental and long-lasting components of the internet backbone infrastructure, the bar needs to be set very high in terms of longevity, stability, and technical scalability.</p>

<p>For a decentralized naming system to become the legitimate namespace for the decentralized world, the bar is even higher. Without a centralized body in charge, the world has to trust that this naming system will exist in a stable state for a long time to come and stay relevant regardless of potential upheavals and technological progress.</p>

<p>As such, this naming systemâ€™s fundamental construction needs to have certain key technical, social, and governance requirements:</p>

<ol>
  <li><strong>Be truly decentralized</strong>: what is the point of a decentralized naming system if it remains controlled by a small set of people?</li>
  <li><strong>Main key focus as a naming system</strong>: naming systems need to be extremely focused and fast. Can you imagine the DNS system operating reliably if it was also designed for delivering 4K video?</li>
  <li><strong>Be as accessible yet trustless as possible</strong>: anyone should be able to access the namespace directly in a fully trustless manner without intensive resources</li>
  <li><strong>Compatible with the rest of the internet</strong>: allowing for seamless usage with the rest of the application, user, and technical stack</li>
  <li><strong>Stability and upgradability at the protocol level</strong>: allowing for innovation moving forward without disrupting regular operations</li>
</ol>

<h2 id="handshake-design">Handshake Design</h2>

<p>Given these objectives, and with the general goal of the decentralized root zone and certificate authority, Handshake is the only naming system that is fundamentally suitable to be the namespace for decentralized web.</p>

<h3 id="1-focus-as-a-naming-system">1. Focus as a Naming System</h3>

<p>Letâ€™s consider the inherent complexity of an internet-scale naming system. For reference, the naming layer (DNS), unlike the other layers of the internet stack, is the only layer that is a system and not a protocol - the key difference between the two is that a protocol cannot enforce uniqueness of names, which is essential to a functioning namespace. Itâ€™s also arguably by far the most complex layer with many competing technical, political, and economical demands.</p>

<p>As a standalone blockchain, Handshake has room to grow all on its own and govern itself without interfering with other projects or having to compete with different priorities with other use cases (like gaming or DeFi) trying to run in parallel on the same network. In addition, there are several fundamental constraints in other blockchains - for example, Bitcoin limited OP sizes and Ethereumâ€™s notoriously hard to sync blockchain.</p>

<p>If Handshake is built on another blockchain, the instability caused by these competing priorities for use cases and political interests also eliminates one of the core requirements for a decentralized naming infrastructure - which is stability. A naming infrastructure needs to be highly stable - remember - both users, hosts and developers need to be confident that the names will be around for a long time in the same format. For instance, Ethereumâ€™s sky high gas prices due to DeFi and the complex migration to ETH2 are both creating high levels of certainty around how apps will work in the future, and whether retail users will be able to have the same level of access as large ticket users.</p>

<p>Lastly, creating a native auction system is complicated and requires highly specific primitives, such as making coins unspendable for certain periods, and increases the complexity of the system if HNS is a non-native token.</p>

<h3 id="2-decentralization">2. Decentralization</h3>

<p>The other critical consideration is decentralization. <em>Remember, the goal here is to achieve a truly decentralized, uncensorable namespace independent of centralized control and policies. Anything less than will be completely redundant.</em></p>

<p>Ethereum is the most decentralized smart contract platform of date, but itâ€™s still insufficient as a base layer blockchain for a truly decentralized naming system. A system based on Ethereum either would have to be strictly immutable or engineer a governance mechanism with a single or multiple signers. For example, the ENS system on Ethereum has a 7-part multisig making it either censorable and shutting it off to any future innovations or upgrades. These mechanisms either risk shutting off future innovations or donâ€™t meet the decentralized requirement.</p>

<p>How about sidechains? Sidechains mostly rely on the main chainâ€™s security, which makes them completely subject to the same concerns above in terms of sharing priorities with the main chain. In addition, there is currently no such thing as a decentralized side-chain on Bitcoin. Counterparty is a one-way system, Liquid requires a small federated multisig, and Rootstock is currently federated waiting on Drivechain support from Bitcoin.</p>

<p>For all of PoWâ€™s issues, namely with the limited number of miners, it is built on competition which is inherently decentralized as well as clear separation of concerns between developers, users, and miners. This is in contrast to PoS which encourages stakeholders to collude and centralize, creating a largely plutocratic environment.</p>

<p>As such, true naming decentralization with the ability to upgrade is likely best achieved on a standalone PoW chain with robust hash power, a strong ecosystem, and miner confidence in the value of the blockchain.</p>

<h3 id="3-ease-of-trustless-resolution">3. Ease of Trustless Resolution</h3>

<p>Compared to other naming blockchains, _the entire Handshake stack is engineered for the use case of creating a human readable, truly decentralized, fully accessible and secure namespace. _</p>

<p>The naming data in Handshake is stored in a novel data structure called an Urkel Tree,  which was designed specifically for this purpose. The proofs are small and verify quickly, allowing name resolution to happen with very little computation.</p>

<p>Secondly, a highly unique application called HNSD written in C only handles the DNS functions of Handshake (avoiding …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meowis.ms/handshake.html">https://meowis.ms/handshake.html</a></em></p>]]>
            </description>
            <link>https://meowis.ms/handshake.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579284</guid>
            <pubDate>Thu, 24 Sep 2020 15:05:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do Musical Scales Have Certain Numbers of Notes?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24579111">thread link</a>) | @lucaspauker
<br/>
September 24, 2020 | https://www.lucaspauker.ml/articles/16 | <a href="https://web.archive.org/web/*/https://www.lucaspauker.ml/articles/16">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.lucaspauker.ml/articles/16</link>
            <guid isPermaLink="false">hacker-news-small-sites-24579111</guid>
            <pubDate>Thu, 24 Sep 2020 14:48:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IPFS 0.7.0, the SECIO retirement edition]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24578953">thread link</a>) | @georgyo
<br/>
September 24, 2020 | https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/ | <a href="https://web.archive.org/web/*/https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    


    <div>
      
      <p>by Jacob Heun &amp; Adin Schmahmann on 2020-09-24</p>

      

      

<p>In August we announced the <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">deprecation of the SECIO security transport</a>. In this release we have disabled SECIO by default, which will have an impact on older nodes on the network. The best way to mitigate the impact of this change is to <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrade your IPFS nodes</a> as soon as possible! Not only will upgrading ensure you’re using the latest security transports, you’ll get access to all of the <a href="https://blog.ipfs.io/2020-07-20-dht-deep-dive/">performance improvements</a> we’ve made this year to content routing.</p>

<p>With this release you will also start seeing more Peer IDs and IPNS Keys on the network that start with <code>1</code> instead of the typical <code>Qm</code>. This is due to a switch to ed25519 keys being used by default over RSA keys, which you can read more about in the highlights below.</p>

<p>🚨 For those of you using plugins with IPFS there is a breaking change detailed below to the build process.</p>



<h2 id="secio-is-now-disabled-by-default">🔒 SECIO is now disabled by default</h2>

<p>As part of deprecating and removing support for the SECIO security transport, we have disabled it by default. TLS1.3 will remain the default security transport with fallback to Noise. You can read more about the deprecation in the blog post, <a href="https://blog.ipfs.io/2020-08-07-deprecating-secio/">https://blog.ipfs.io/2020-08-07-deprecating-secio/</a>. If you’re running Go IPFS older than 0.5 or JS IPFS older than 0.47, this may start to impact your performance on the public network, so we strongly encourage you to upgrade today!</p>

<h2 id="ed25519-keys-are-now-used-by-default">🗝️ Ed25519 keys are now used by default</h2>

<p>Previously go-ipfs generated 2048 bit RSA keys for new nodes, but it will now use ed25519 keys by default. This will not affect any existing keys, but newly created keys will be ed25519 by default. The main benefit of using ed25519 keys over RSA is that ed25519 keys have an inline public key. This means that someone only needs your PeerId to verify things you’ve signed, such as your Peer Records or in the future Signed Provider Records, which means we don’t have to worry about storing bulky RSA public keys.</p>

<h3 id="rotating-keys">Rotating keys</h3>

<p>Along with switching the default key type, we’ve added support for rotating Identity keys. If you would like to change the key type of your IPFS node, you can now do so with the rotate command. <strong>NOTE: This will affect your Peer Id, so be sure you want to do this!</strong> Your existing identity key will be backed up in the Keystore so that it can still be referenced for things like IPNS records.</p>

<pre><code>$ ipfs key rotate -o my-old-key -t ed25519
</code></pre>

<h2 id="key-export-import">📦 Key export/import</h2>

<p>Speaking of backing up keys, we’ve added commands to allow you to export and import keys from the IPFS Keystore to a local .key file. This does not currently apply to the IPFS identity key, <code>self</code>, which is housed in the configuration file.</p>

<pre><code>$ ipfs key gen mykey
$ ipfs key export -o mykey.key mykey # ./&lt;name&gt;.key is the default path
$ ipfs key import mykey mykey.key # on another node
</code></pre>

<h2 id="ipns-paths-now-encode-the-key-name-as-a-base36-cidv1-by-default">#️⃣ IPNS paths now encode the key name as a base36 CIDv1 by default</h2>

<p>Previously go-ipfs encoded the key names for IPNS paths as base58btc multihashes (e.g. <code>Qmabc...</code>). We now encode them as base36 encoded CIDv1s as defined in the <a href="https://github.com/libp2p/specs/blob/master/peer-ids/peer-ids.md#string-representation">peerID spec</a> (e.g. <code>k51xyz...</code>) which also deals with the encoding of public keys. This is nice because it means that IPNS keys will by default be case-insensitive and that they will fit into DNS labels (e.g. <code>k51xyz...ipns.localhost</code>) and therefore that subdomain gateway redirections (e.g. from <code>localhost:8080/ipns/{key}</code> to <code>{key}.ipns.localhost</code>) will look better to users in the default case.</p>

<p>Many commands will accept a <code>--ipns-base</code> option that allows changing command outputs to use a particular encoding (i.e.  base58btc multihash, or CIDv1 encoded in any supported base):</p>

<pre><code>$ ipfs key list -l --ipns-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK self
$ ipfs key list -l --ipns-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2 self
</code></pre>

<h2 id="multiaddresses-now-accept-peerids-encoded-as-cidv1">📮 Multiaddresses now accept PeerIDs encoded as CIDv1</h2>

<p>In preparation for eventually changing the default PeerID representation multiaddresses can now contain strings like <code>/p2p/k51xyz...</code> in addition to the default <code>/p2p/Qmabc...</code>. There is a corresponding <code>--peerid-base</code> option to many functions that output peerIDs:</p>

<pre><code>$ ipfs id --format "&lt;id&gt;" --peerid-base b58mh
12D3KooWCjhz69LskTZEC5vFWs8eDpHo7kYbGzrC5EjU75BHSmVK
$ ipfs id --format "&lt;id&gt;" --peerid-base base36
k51qzi5uqu5dh9ihj4p2v5sl3hxvv27ryx2w0xrsv6jmmqi91t9xp8p9kaipc2
</code></pre>

<h2 id="dag-stat-command">🧮 <code>dag stat</code> command</h2>

<p>Initial support has been added for the <code>ipfs dag stat</code> command. Running this command will traverse the DAG for the given root CID and report statistics. By default, progress will be shown as the DAG is traversed. Supported statistics currently include DAG size and number of blocks.</p>

<pre><code>$ ipfs dag stat bafybeihpetclqvwb4qnmumvcn7nh4pxrtugrlpw4jgjpqicdxsv7opdm6e # the IPFS webui
Size: 30362191, NumBlocks: 346
</code></pre>

<h2 id="plugin-build-changes">🚨 Plugin build changes 🚨</h2>

<p>We have changed the build flags used by the official binary distributions on <a href="https://dist.ipfs.io/">dist.ipfs.io</a> (or <code>/ipns/dist.ipfs.io</code>) to use the simpler and more reliable <code>-trimpath</code> flag instead of the more complicated and brittle <code>-asmflags=all=-trimpath="$(GOPATH)" -gcflags=all=-trimpath="$(GOPATH)"</code> flags, however the build flags used by default in go-ipfs remain the same.</p>

<p>The scripts in <a href="https://github.com/ipfs/go-ipfs-example-plugin">go-ipfs-example-plugin</a> have been updated to reflect this change. This is a <strong>breaking change</strong> to how people have been building plugins against the dist.ipfs.io binary of go-ipfs and plugins should update their build processes accordingly. See <a href="https://github.com/ipfs/go-ipfs-example-plugin/pull/9">go-ipfs-example-plugin/pull/9</a> for details.</p>

<h2 id="the-changelog">The Changelog</h2>

<p>For a full list of updates included in this release you can review the Changelog at <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22">https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#v070-2020-09-22</a>.</p>

<h2 id="thank-you-contributors">Thank you contributors!</h2>

<p>A huge thank you to <a href="https://github.com/ipfs/go-ipfs/blob/v0.7.0/CHANGELOG.md#contributors">everyone who contributed</a> patches and improvements in this release, all <strong>53</strong> of you! We couldn’t have made this happen without your help and feedback. ❤</p>

<h2 id="install-upgrade-and-join-us">Install, upgrade, and join us!</h2>

<p>You can get started by <a href="https://dist.ipfs.io/#go-ipfs">installing go-ipfs</a> or <a href="https://docs.ipfs.io/recent-releases/go-ipfs-0-7/update-procedure">upgrading to go-ipfs 0.7</a>.</p>

<p>There are many ways to get involved with IPFS based on your skill set, interest, and availability.  Please check out <a href="https://github.com/ipfs/community/blob/master/CONTRIBUTING.md">our contribution page</a> on GitHub for guidance and next steps.</p>

<p>This is an exciting time for IPFS and the web in general. Join us!</p>


      
          
          
          
      
    </div>
  </div></div>]]>
            </description>
            <link>https://blog.ipfs.io/2020-09-24-go-ipfs-0-7-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578953</guid>
            <pubDate>Thu, 24 Sep 2020 14:33:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ready-Made CRM, Project and Content Management on Notion]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24578943">thread link</a>) | @saviorand
<br/>
September 24, 2020 | https://optemization.com/preconceived | <a href="https://web.archive.org/web/*/https://optemization.com/preconceived">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="/preconceived"><div id="/df2631fcf3ab4d74bfb32255cee6151d"><div id="/f3a8a7556e534222be5e49e6fb2c9ef6"><blockquote id="/7100cd2e553b454ab5102d49c9c9c48f"><span><span>Functional Notion workspaces take hours to create. To setup yourself and your team, you'd have to learn, ideate, build, iterate, and train. Let Optemization take care of this.

</span><span><strong>In two weeks flat.</strong></span></span></blockquote></div></div><h3><span id="/8dc73654f3b645b18006ee25d1bb0cfc"></span><span><span>📦 Components</span></span></h3><div id="/74c3d09ab64f4127abaeac25d78eed42"><div id="/a9f4c8f2706a40b19028c89ec97026e8"><p><span><span><strong>Foundational Databases</strong></span></span></p><p><span><span>→ Eleven databases with properties and templates pre-built</span></span></p><ul><li id="/b56f8c313d22445ba331a9c56073cbed"><span><span>Project management suite with for task, calendar, project databases</span></span></li><li id="/7a82c37bf18a42cab68dadea85212342"><span><span>CRM suite with company, people, industry, geography databases</span></span></li><li id="/fd5f5c66de8f4986a9a784efdd6e8e39"><span><span>Resources suite with for content, topic databases</span></span></li><li id="/8ea94eb3df3c4ffa99ca78e24503cdfe"><span><span>Workspace hierarchy with three top-level pages</span></span></li><li id="/d44e005dffc84274af7dcf2f68ec130f"><span><span>Eleven database templates</span></span></li><li id="/e819d910acab47168608f868293a6a83"><span><span>$1000 credit</span></span></li><li id="/8cfdf53823ed4f6199f85397682457af"><span><span>1 hour onboarding meeting</span></span></li></ul></div></div><div id="/ce69d2f7689448ce8af6af68c6950bb9"><div id="/9987596c4d4e4e7099539209c83d70a7"><p><span><span><strong>Personalized Dashboards</strong></span></span></p><p><span><span>→ Three customizable dashboards</span></span></p><ul><li id="/1bcf8781b59b47dbb85e426df06d2455"><span><span>Personal dashboard</span></span></li><li id="/b567781f9eb94096a4981739aa8bf700"><span><span>Vertical project dashboard</span></span></li><li id="/ea8517dbc1f34b49acc9333437539481"><span><span>Horizontal project dashboard</span></span></li><li id="/ecd1c7606e4c4229909eb2a4e5d786f5"><span><span>Dashboard component library</span></span></li><li id="/fe950994c03143f9b89b0f2adc7b44d0"><span><span>1 hour personalization meeting</span></span></li></ul></div></div><div id="/c43afe7bd97e4eb69e857db6c0b2abde"><div id="/d6f53f22277e4f6a9728ae71f6f03d77"><p><span><span><strong>Bonus Support</strong></span></span></p><ul><li id="/504337f059c94e02b38782626b35c482"><span><span>Shared Slack Connect channel</span><span><span>*</span></span></span></li><li id="/4b53e407064046d1b105399317f9e88c"><span><span>Curated Notion updates and content</span></span></li><li id="/fed65626c7414f0da78c7eeec6e5d222"><span><span>Discounts on future services and tools </span></span></li></ul><p><span><span>*Requires Standard Plan</span></span></p></div></div><h3><span id="/0b78decb95c24aa8b8771b3041080f4d"></span><span><span>🖥️ Demo</span></span></h3><h3><span id="/56d6370823f34ff6bf3d2f2ddbfea3d5"></span><span><span>📆 Timeline</span></span></h3><p><span><span><strong>Six steps including two meetings (example dates).</strong></span></span></p><div id="/0de5b0f2af9944039b1a02342f8d0cd8"><div id="/5ea01ed9dfb244ae829b371d5c8a7ef9"><p><span><span><strong>🗿Start Installation</strong></span></span></p><p><span><span>💬</span><span><strong>Onboarding Meeting</strong></span></span></p><p><span><span>📦</span><span><strong>Ship Databases</strong></span></span></p><p><span><span>💬</span><span><strong>Customization Meeting</strong></span></span></p><p><span><span>📦</span><span><strong>Ship Dashboards</strong></span></span></p><p><span><span><strong>🗿Completion Installation</strong></span></span></p></div><div id="/20f078e837764769ac3290a5f4ba6221"><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 5, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 12, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span>Oct 19, 2020</span></span></p><p><span><span><strong>14 days</strong></span></span></p></div></div><h3><span id="/fdd2e4c53e3848a7ade37b394d8b9430"></span><span><span>💳 Pricing</span></span></h3><p><span><span><strong>$3,000. Split up as follows</strong></span></span></p><div id="/24038df326844c6693e5f7ecf3dcc093"><div id="/9ed4fc58aaec46cb9f76ca91e51408b5"><p><span><span>🧾</span><span><strong>Deposit Payment</strong></span></span></p><p><span><span><strong>📦Add Credit</strong></span></span></p><p><span><span>🧾</span><span><strong>Final Payment</strong></span></span></p></div></div><h3><span id="/6d214b8077b04c56a2b46d400dc03207"></span><span><span>🔒 Checkout</span></span></h3><p><span><span><strong>You will not be charged immediately.</strong></span></span></p></article></div></div>]]>
            </description>
            <link>https://optemization.com/preconceived</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578943</guid>
            <pubDate>Thu, 24 Sep 2020 14:32:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: MP3 to Text]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24578053">thread link</a>) | @sabbakeynejad
<br/>
September 24, 2020 | https://www.veed.io/tools/mp3-to-text#hn | <a href="https://web.archive.org/web/*/https://www.veed.io/tools/mp3-to-text#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="Intro"><div><div id="w-node-be84c295ef36-ccc0cf0b"><h2><strong>Turn your MP3 into text files, online</strong></h2><p>Do you want to transcribe the speech from your MP3 into a text file? Well, now you can, with VEED! VEED’s online auto transcription tool is fast, free, and easy to use. Compatible not just with MP3s, but with WAVs, AACs, OGGs, M4As, and even video files - you can convert to text with the click of a button</p></div><p><img alt="" loading="lazy" src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5f2ab08f19e2546287724ff1_Transcribe%20Audio%20Files%20Automatically%2C%20Online2.png 1280w"></p></div><div><div id="w-node-be84c295ef39-ccc0cf0b"><h3><strong>MP3 to Text, Online</strong></h3><p>With VEED you can upload your MP3 files in your browser, no software required, and have a text transcription ready in no time</p></div><div id="w-node-be84c295ef3a-ccc0cf0b"><h3><strong>Automatic</strong></h3><p>No longer do you have to sit and listen, typing along to your MP3 files. Now VEED transcribes your MP3s automatically</p></div><div id="w-node-be84c295ef3b-ccc0cf0b"><h3><strong>Fast</strong></h3><p>Our super-fast, cloud-based servers will have your audio files uploaded, transcribed, and converted into text files in a matter of seconds. It’s so easy!</p></div><div id="w-node-be84c295ef3c-ccc0cf0b"><h3><strong>Edit</strong></h3><p>If you want to change anything, or add a note or comment, just click on a line of transcription and start typing!</p></div><div id="w-node-be84c295ef3d-ccc0cf0b"><h3><strong>Different Languages</strong></h3><p>VEED is able to recognise and transcribe languages from all over the world - English, Spanish, French, Chinese, and many more</p></div><div id="w-node-be84c295ef3e-ccc0cf0b"><h3><strong>Video Transcription</strong></h3><p>You can also upload video files (in multiple formats) and create transcriptions, add subtitles, or download subtitle (.srt) files</p></div></div></div><div id="How-to"><div><h2>How to transcribe MP3 to text:</h2><p>Transcribe your MP3 in 3 easy steps</p></div><div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7b5d102969e0f443e9_cloud.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>1. Upload</strong></h3><p>Upload your MP3 files to VEED. VEED is all online, no software required</p><p>‍</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7a7679911e1f802d1d_scissors.png" loading="lazy" width="32" alt=""></p><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9ba6edbc7fd0db328f8f_line.png" loading="lazy" width="2" alt=""></p></div><div><h3><strong>2. Convert to text</strong></h3><p>Under ‘Subtitles’, click ‘Auto Subtitles’, choose your language, and that’s it! Your MP3 transcript is generated</p><p>‍</p></div></div><div><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3f9b7afbaf558411481ae3_Share.png" loading="lazy" width="32" alt=""></p></div><div><h3><strong>3. Download</strong></h3><p>You can now download in multiple formats - .txt, .vtt, .srt - whatever you need</p></div></div></div><div><div><p><h4>How to use VEED - Make social media video content online</h4><h5>591 views</h5></p></div></div></div><div id="use-cases"><div><h2>Why use our MP3 to Text tool?</h2><p>Turn your MP3s into text files, automatically</p></div><div><div><h3><strong>Quick</strong></h3><p>No need to download any software, you don't even need an account. Get started right away, with our super-fast MP3 to Text tool</p></div><div><h3><strong>Easy</strong></h3><p>You can create transcriptions of your MP3 with a single click, and make line-by-line edits with ease</p></div><div><h3><strong>Versatile</strong></h3><p>You can export your MP3 transcription as a text file, subtitle file, whatever you need</p></div></div></div><div id="testimonials"><div><p><img src="https://uploads-ssl.webflow.com/5ea7ec2f0fe2ee14fc247bf0/5f3fcd9f6ea642218575ff6d_quote.png" loading="lazy" width="28" alt=""></p><h2>What they say about <span>VEED</span></h2></div><div><div data-animation="slide" data-duration="500" data-infinite="1"><div><div><div><div><p>Veed is a great piece of browser software with the best team I've ever seen.</p><p>‍</p><p>Veed allows for subtitling, editing, effect/text encoding, and many more advanced features that other editors just can't compete with. The free version is wonderful, but the Pro version is beyond perfect. Keep in mind that this a browser editor we're talking about and the level of quality that Veed allows is stunning and a complete game changer at worst.</p></div><p><strong>Chris Y.</strong></p></div></div><div><div><div><p>I love using VEED&nbsp;as the speech to subtitles transcription is the most accurate I've seen on the market.</p><p>‍</p><p>It has enabled me to edit my videos in just a few minutes and bring my video content to the next level</p></div><p><strong>Laura Haleydt</strong> - Brand Marketing Manager, Carlsberg Importers</p></div></div><div><div><div><p>The Best &amp; Most Easy to Use Simple Video Editing Software!</p><p>‍</p><p>I had tried tons of other online editors on the market and been disappointed. With VEED I haven't experienced any issues with the videos I create on there.</p><p>‍</p><p>It has everything I need in one place such as the progress bar for my 1-minute clips, auto transcriptions for all my video content, and custom fonts for consistency in my visual branding.</p></div><p><strong>Diana B - </strong>Social Media Strategist, Self Employed</p></div></div></div></div></div></div><div id="more-things"><div><div><h2><strong>More than just an MP3 to Text tool</strong></h2><p>VEED is so much more than just an MP3 to Text converter - you can edit and create all kinds of video and audio. Create YouTube video intros, auto-generate subtitles, create Instagram Stories with links and stickers, add sound effects to your audio, join MP3 files together, and so much more!</p></div><p><img src="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png" alt="" sizes="100vw" srcset="https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-500.png 500w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-800.png 800w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1)-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ea7ef450fe2ee1a3524891b/5efcc39090c5db4fed168b7a_ezgif.com-webp-to-png%20(1).png 1600w"></p></div></div></div></div>]]>
            </description>
            <link>https://www.veed.io/tools/mp3-to-text#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24578053</guid>
            <pubDate>Thu, 24 Sep 2020 12:44:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important non-programming skills for programmers]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24577876">thread link</a>) | @IncRnd
<br/>
September 24, 2020 | https://welearncode.com/most-important-nonprogramming/ | <a href="https://web.archive.org/web/*/https://welearncode.com/most-important-nonprogramming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><a href="https://welearncode.com/">← Home</a></p><p>When I think about who I would like to work with as a programmer, I think so much more about non-technical skills than technical skills that make somebody a good co-worker. In fact, all of the skills that are in this post contribute to writing good code that improves technical projects. Most of them are really helpful for careers outside of programming too, but I'm going to focus on why they're useful for programmers specifically.</p><h2>Empathy</h2><p>To build a great product, you must put yourself in the shoes of your users. How will they be using your product? What features will be helpful for them? How can your program help them or improve their lives? And -- conversely -- how could it harm them or negatively impact their lives? What are the ethical implications of your application?</p><p>Empathy is essential for so many pieces of your programs -- if they aren't secure then your user's information could be used negatively by a third party. If they aren't accessible, then you are limiting the number of people that can use your project. If they run slowly or needs huge amounts of bandwidth to run, then users will leave and people in areas with slow internet or mobile users won't be able to run them. It seems like every day an article comes out with some harmful algorithm a company has implemented, like the <a href="https://www.theguardian.com/media/2018/sep/18/report-youtubes-alternative-influence-network-breeds-rightwing-radicalisation">YouTube algorithm radicalizing the alt-right</a>, <a href="https://www.inc.com/guadalupe-gonzalez/amazon-artificial-intelligence-ai-hiring-tool-hr.html">Amazon creating a sexist hiring algorithm (which they didn't end up using)</a>, or <a href="https://www.youtube.com/watch?v=QxuyfWoVV98">AI misgendering black women</a>. Think about everybody when you are writing your code!</p><p>Also, empathy is helpful for being a team member and a mentor. Put yourself in your manager or another developer's shoes. Why are they making their decisions? What can you do to help them? Having empathy will definitely improve your ability to be an effective teammate. If you're an employer, you can retain your employees for longer, and they will be more effective workers if you display empathy <a href="https://www.forbes.com/sites/karenhigginbottom/2018/05/31/why-empathy-matters-in-the-workplace/#386ca65d1130">(src)</a>.</p><p>Have patience for other programmers, especially ones that are learning new things. Remind yourself of something that was really hard for you to learn and how that felt. They probably feel similarly. Being rude to them, diminishing their progress, or being pedantic will only be harmful and make that process harder for them.</p><p><strong>Your words and actions have real consequences -- you can use that to enact positive change or hurt somebody. That doesn't end with in-person communication -- online communication counts too. You may think you're being funny or just letting off steam, but you may actually causing a very negative impact on someone's life. It's up to you to decide how to act, and how to apologize if you hurt someone to undo some of that harm.</strong></p><h2>Problem Solving</h2><p>When I teach people to code, I see a lot more people struggling with problem-solving than the code itself. The ability to break a problem into smaller ones and then solve all of those smaller problems takes a lot of practice. Getting good at problem-solving can help you become a much stronger programmer.</p><p>Also, for most problems, there will be more than one solution. A large part of our jobs as software developers is to think through those different solutions and choose the one that is best. Is one faster to implement? Or does it run more efficiently? Or will it be less expensive? All of these are important questions, and picking the correct solution is a challenging but important part of software development.</p><h2>Collaboration</h2><p>Chances are very high that you with other people as a programmer. You will have to work with other developers, business people, managers, open source contributors, stakeholders, and countless other people even if you are a freelancer or entrepreneur. Learning how to work well with different people and their personalities is critical.</p><p>There are so many things that contribute to good collaboration. The first is knowing that one person can't do everything, or at least do everything well. Different people have different skills, points of view, and life experiences that are more powerful in combination than isolation. Don't feel like you always need to "put the team on your back" or be everything to everybody. You can be a lot better if you allow other people to contribute too.</p><p>Ask other people for help, and be willing to help people in return. You don't need to be an expert in everything, and different people will be experts in different things. Rely on other people, and if you are stuck on something make sure to ask for help so that you don't stay stuck for too long. When somebody asks you for help, be willing to help them. You can learn a lot by explaining things well, and you will be able to reinforce your knowledge of the topic. If you're in a management position, make sure to give people time for mentorship and effective collaboration!</p><p>Along the same lines, don't talk over people or immediately dismiss their viewpoints. They will probably be much less likely to contribute in the future if their opinions aren't valued or taken into account. Actively listen when people share their ideas -- instead of thinking about your response or why your idea is better while they are talking, try to think about why their approach is also good or how it could be implemented.</p><p>Then, once you implement their awesome ideas, give them credit for those ideas. Nothing has made me less effective as an employee as being on a team where my ideas were dismissed, under-valued, and un-credited by other people on my team.</p><h2>Communication</h2><p>When you are working with other people, whether those people are co-workers, clients, the people who use your projects, managers, or people you manage, good communication is crucial. Give honest updates on how things are going, where projects currently stand, and your opinions on things honestly but kindly. People will be less receptive to feedback if you are rude or unconstructive. But, if you are dishonest or sugar-coat the truth, then you may not see a positive change. There's definitely a fine line here.</p><p>One real life example from my life: I had somebody who read one of my blog posts write a very long letter about how dumb I sound because of the tone I take. I usually use a lot of exclamation points and try to sound exciting in my posts -- and that's very intentional to try and make topics that can be intimidating or boring more fun. The person got pretty sexist in this email and said some pretty hurtful things. That being said, I probably could scale back on the exclamation points and still get people excited about programming. I would have been a lot more receptive to that point if the person had framed the criticism more constructively.</p><p>If things are not going well, make sure to say so. Be honest about needing a deadline pushed back, or how something isn't going well at work. You will have a much better chance at changing it and making the environment better for yourself if you speak up.</p><h2>Inclusiveness</h2><p>I used to work as a rock climbing instructor and counselor at a summer camp, and the age group I worked with most were middle school girls. They were some of my favorite people I've ever worked with, but, that being said, middle schoolers aren't usually the most accepting of difference or that clique-adverse. We used to run a game where we started out in one large circle, and then one counselor would tell people they were "out of the circle", and they would have to leave the game based on some characteristic that they weren't informed of and couldn't control. The people still inside the circle would play a game, and the people outside of the circle were excluded and just had to watch from afar.</p><p>This activity was super effective in showing these girls what it was like to be left out for reasons outside of your control, and I still think back on it a lot. As adults, we still leave people out of the circle and exclude them based on certain characteristics outside their control, but if we let them back into the circle and allow them to contribute then our products draw on more diverse experiences and are better. <strong>There's <a href="https://hbr.org/2016/11/why-diverse-teams-are-smarter">a lot of research</a> on more diverse teams performing better, but from an individual perspective, think about what it feels like to be left out of the circle and try to make your circle larger, not smaller.</strong> Chances are, a lot of your users may be people that have traditionally been left out of the circle in tech. I can tell you from my own experience, that it's really difficult to be the only person like you on a team as someone who's been on a team with another woman for ~5% of my programming career.</p><p>This also links into empathy -- make sure that you are making your programs for a wide variety of users. Not just the able-bodied or those with cutting-edge internet or technologies. You will be able to reach more people.</p><h2>Patience</h2><p>The first person that you need to have patience with when you are programming is yourself. <strong>Programming is hard</strong> and sometimes you will have bugs or difficult problems to overcome. If it's always easy, then you aren't challenging yourself, and you aren't growing as a programmer. Have the tenacity to keep working through a problem and not give up when it gets hard. But, also, know that you can take a break and come back to the problem in a little while. Maybe taking a break will help you solve the problem more efficiently or to see it differently when you come back to it.</p><p>Also, be patient with other people. Things can take a while to learn and people are not perfect. Making mistakes and failing can be some of the most important experiences in the learning process, so allow for that instead of creating an environment where it isn't safe to take risks or grow. Understand that different things click more easily for different people, and know that learning can take a while.</p><h2>Creativity</h2><p>My favorite thing about being a programmer is that I get to use my creative energy to build things that other people can then benefit from. You get to think outside of the box to create really cool things.</p><p>Having creative ideas is important for coming up with …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://welearncode.com/most-important-nonprogramming/">https://welearncode.com/most-important-nonprogramming/</a></em></p>]]>
            </description>
            <link>https://welearncode.com/most-important-nonprogramming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577876</guid>
            <pubDate>Thu, 24 Sep 2020 12:21:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smart Cow Collars]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24577468">thread link</a>) | @troydavis
<br/>
September 24, 2020 | https://halterhq.com/smart-cow-collars | <a href="https://web.archive.org/web/*/https://halterhq.com/smart-cow-collars">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ca2563ba93dc6cf1ddae"><div><p>Shift, manage and monitor your herd remotely - we’ve summed it up fairly concisely, but how we do that may require a little more paper and a sharpening of the pencil. How are we able to shift a cow to and from the milk shed with the click of a button? Essentially, we train cows to respond to sensory cues which help them understand where they can and cannot go, a method based on the theory of Pavlovian Conditioning. Now, it’s likely your list of questions is long, so we’ve brought in our Head of Rural, Chris, who oversees all on farm training to give you some answers.</p><p><strong>You say that you use sensory cues to guide cows… how does that work?</strong></p><p>Like any animal, cows learn behaviours through the use of positive and negative reinforcement. This technique is commonly known as Pavlovian Conditioning, whereby certain stimuli such as sounds, touches and smells are paired with a conditioned response in order to elicit a desired behaviour.</p><p>If you think about the way we farm today, farmers use a multitude of different cues to shift cows or keep them in a particular zone. To put it really simply, Halter replicates these cues and places them on a collar in the form of sound and vibration. </p><p>Vibration can be seen as a positive reinforcer, enabling us to shift cows around the farm as well as indicating to a cow that she is moving in the right direction. You might like to think of vibration as a farmer walking behind their cows to shift them up to the shed! Sound on the other hand helps a cow understand she is moving in the wrong direction or outside of the allocated zone. Currently on the farm an electric fence is the only real means available for farmers to keep their cows within a particular boundary; we instead use sound to replicate a fence line with a pulse used during the initial training period to help a cow understand the meaning of sound. Once the girls are trained we combine sound cues with vibration and we have the ability to guide cows around a farm, keep them out of waterways and set up virtual paddocks and break fences.</p><p><strong>How quick is the training process? Do all cows learn or do some just not get it?&nbsp;</strong></p><p>Cows are extremely quick to respond to sound, within a couple hours of wearing a collar cows learn to stay within a static boundary. It takes a little longer for them to associate vibration with positive cues, however we are currently seeing this happen within a week. In general onboarding takes a week, however this process is continually being modified and improved.</p><p>To date we haven’t come across any cows that we couldn’t train! Some learn faster than others but due to the fact that cows are herd animals, the slower ones tend to follow and learn from the faster cows.</p><p><strong>How do you ensure that the training is safe and ethical?</strong></p><p>We’ve been working with animal ethics committees from the start and continue to work closely with them, along with vets and professors in this domain. Welfare is our top priority and our founding vision is to unlock the connection between animals and humans to create a better world, with the hope of not only improving the welfare of cows but other animals in the future. </p><p>We are employing a number of systems to ensure our technology is never harmful to a cow, for instance we have hardcoded mechanisms in place that will shut down a collar should anything out of the ordinary happen, for example a cow getting spooked. We have also considered the training process itself and will begin training softly until a cow becomes more comfortable. </p><p>We want to dramatically improve the welfare of cows and will never compromise their wellbeing.</p><p><strong>Will Halter work on other livestock like sheep and beef cattle? And what about calves?</strong></p><p>Absolutely. Beef cattle would be simple - it just requires a slight change in use case. Sheep would require a collar redesign to fit their small fluffy necks and, no, they are not too stupid! I am confident that the fundamental techniques will work on pretty much any mammal. Pavlovian conditioning is a concept that appeals to very basic animalistic instincts that all mammals, and most likely many other types of animals share.</p><p>In terms of calves there is no reason that Halter wouldn’t work for them, we’d just need collars small enough! Although we are currently focused on dairy cattle I see no reason why Halter wouldn’t work on other livestock in the future!</p><p>Setting up a virtual break fence, shifting cows automatically or drafting a single cow with the touch of a button sounds like a rather crazy concept, but we hope this has given you a touch of background and understanding to it all. We’ll leave you to train your dogs, but trust us when we say - we’ve got the cows covered.</p></div></div></div>]]>
            </description>
            <link>https://halterhq.com/smart-cow-collars</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577468</guid>
            <pubDate>Thu, 24 Sep 2020 11:20:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Most Dangerous Cult of Our Times: QAnon's Inexorable Spread Beyond the U.S.]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24577419">thread link</a>) | @nabla9
<br/>
September 24, 2020 | https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<p>The path into the parallel world follows rural roads snaking through the hills of Baden-Wurttemberg to a house located on the edge of a village with a bright white façade, well-swept driveway and carefully trimmed lawn. The conspiracy has long since eaten its way into the southern German idyll. A friendly man opens the door - muscular, burly, he does a lot of lifting.</p>


<div>
<p>It was not easy to set up a meeting. He has a deep aversion to journalists and other members of a supposed elite, whom he believes are covering up a worldwide plot to oppress humanity. Over the phone, he said that he hopes to open the reporter’s eyes. "Maybe I can wake you up.” He requested that his real name not be used, so we'll call him Martin Schmidt.</p><p>"The goal of the elites is to stay powerful, to stay rich and to enslave the world,” he says.</p><p>Schmidt is 27, works as an electrician and has been living with his parents again since the beginning of the pandemic. He leads the way into the living room, with its bright tile floor and woodchip wallpaper, and says he has been thinking about the big questions for a long time. The death of John F. Kennedy, the attacks of September 11, the coronavirus pandemic: He believes they have all been faked as part of a giant plan.</p>
</div>

<p>His father nods next to him. He also believes people are being systematically deceived by politicians and members of the media. Schmidt says: "This elite, they are various men and women who work on Wall Street, to whom the banks belong, all these people.” He believes businesspeople like George Soros, Bill Gates and Mark Zuckerberg are among them, as well as the Rockefellers and the Rothschilds.</p>

<section data-area="contentbox">
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;113e04ed-6f97-4955-b6e0-c8c1e98da13a&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>He takes out his smartphone. "I’ll show you how the rich and beautiful party.” He shows a photo of performance artist Marina Abramović&nbsp;with the singer Lady Gaga at a charity event. In the picture, they are standing next to a naked female body covered with a red liquid. For Schmidt, the photo is proof of how morally degenerate the leaders of society have become, and that even the so-called elite aren’t afraid of killing people - even if, in this case, the photo is of an art performance. He says the situation is alarming. "I have awoken.”</p>

<p>Martin Schmidt is part of a growing number of QAnon sympathizers, one of tens of thousands in Germany. Followers of this right-wing conspiracy theory are convinced that an influential group of Satanist pedophiles is kidnapping boys and girls and using their blood to produce a drug. They believe that the coronavirus was developed in a Chinese lab – possibly with the help of Barack Obama – in order to hurt Donald Trump and prevent his reelection, a claim that is as absurd as it is false. And they believe Donald Trump is a hero fighting against the "deep state,” and that he wants to protect the world from the demonic group.</p>

<p>"He is trying to save humanity,” says Schmidt. "He will take away the elites’ power.”</p>
<div>
<p>One could dismiss QAnon as crazed paranoia, like the false claims that the moon landing was faked or that the attacks of September 11th were planned by the U.S. government. But what makes the movement unique and, especially, dangerous, is its ideas.</p><p>QAnon’s followers spread disturbingly familiar themes: a supposed conspiracy of rich elites, including many Jewish businesspeople, targeting the rest of the world; a supposed group of corrupt left-wing politicians infiltrating democracies; journalists who spread propaganda as accomplices to the powerful. These centuries-old fictions from the right-wing, anti-Semitic fringe have been spread into the international public sphere via 21st-century media - part Dreyfus Affair, part Dan Brown.</p><p>"It is no exaggeration to view QAnon as a potential threat to national security,” says extremism researcher Julia Ebner from the London-based think tank Institute for Strategic Dialogue. Ebner has been researching online radicalization for years and is watching with concern as the German Q movement is becoming more independent and itself trying to recruit new followers.</p><p>Indeed, QAnon is on its way to becoming the most dangerous cult in the world – the first ideology to come from the digital realm and to emerge from an online niche into real life, aided by Donald Trump-supporters and right-wing demagogues. The "Q” cult is fueled by one or several anonymous users who regularly post to the web and who claim to have access to top-secret U.S. government documents – a claim that is more than questionable.</p><p>Just as disturbing is how QAnon builds on age-old anti-Semitic conspiracy theories that, centuries ago, claimed Jews drink the blood of Christians and seek to control the world. At the same time, the movement’s potential for violence is also becoming clearer. In March 2019, a QAnon believer shot an alleged mafia boss in New York because he believed the man was a member of the "deep state.” In April, U.S. police officers took a woman into custody who had threatened Hillary Clinton on Facebook because she had allegedly abused a child. In 2018, a man in Florida sent mail bombs to prominent Democrats whom he believed to be members of a "deep state" conspiracy.</p><p>The gunman in the central German city of Hanau who killed 10 people and then himself in February alluded to topics circulating in the QAnon cosmos. In a YouTube video, he argued that there were subterranean military installations in the U.S. where children are abused and killed and where the devil is worshipped.</p><p>QAnon followers also played a role in the storming of the Reichstag, the seat of German parliament, in Berlin in late August by a group protesting the authorities’ measures to control COVID-19. Naturopath Tamara Kirschbaum, who called on people to run up the building’s stairs to the entrance, is identified online as a "freelance employee” of Qlobal-Change, a portal of QAnon followers. She describes herself as "the voice” of the "X22 Report,” a YouTube show about QAnon-related topics that is also translated into German. The Office for the Protection of the Constitution, the German domestic intelligence agency, in the western German state of North Rhine-Westphalia classifies her as a member of the Reichsbürger (or "citizens of the Reich”) scene, a group that does not believe in the legitimacy of the modern German state.</p><p>Large U.S. tech companies have played a decisive role in the dissemination of the ideology. QAnon would not have been able to spread as fast and far around the world without YouTube, Facebook, Twitter and other social networks. During the coronavirus pandemic and in the first lockdowns in February, the ideology spread even more rapidly, especially in Germany. QAnon has been like a second virus spreading around the world, but this one is very definitely man-made.</p>
</div>

<div>
<p>It is no accident that Trump’s campaign team has recognized QAnon disciples as an important part of his base and is catering to them. Indeed, several Republican candidates for Congress have professed their affiliation to the movement.</p><p>The QAnon ideology, the first to emerge in the 21st century, is like a blend of video game and online treasure hunt, and emerged on a rather noxious platform that caters largely to young men: 4chan, a simple web forum that was founded in 2003 by a 15-year-old programmer from New York.</p><p><strong>4chan is essentially</strong> a giant digital pinboard with virtually no oversight. Anyone can write and post pretty much anything they want, always anonymously. Only very few things are not allowed and are then deleted. Its offerings include hardcore pornography, as well as tasteless, insulting or right-wing extremist speech. It has given birth to both good and repulsive ideas, which are then commented on and discussed - before immediately being overwhelmed by new posts and ideas.</p><p>4chan’s roots are in the Japanese manga scene. First-time visitors to the platform will struggle to make sense of its hundreds of discussion groups, manga photos and inside jokes. There are hundreds of thousands of entries every day, supposedly 27 million visitors per month. A unique language has emerged almost without any oversight that, like the jokes, is incomprehensible to outsiders. Thus far, there have been 3.5 billion entries. Users are bound together by the belief that they are part of one of the last bastions of free speech and opinion.</p><p>On October 28, 2017, an anonymous user on 4chan posted the following message: "Hillary Clinton will be arrested between 7:45 AM – 8:30 AM EST on Monday – the morning of Oct 30, 2017." The author signed later entries with the letter "Q.” It was the movement's Big Bang, launched by a false prediction. Clinton wasn’t arrested on October 30th, nor has she been arrested since, but the curiosity of users was piqued.</p><p>Author and conspiracy-theory researcher Timothy Melley at the University of Miami says many Americans are familiar with the elements of the QAnon movement. "It is like a detective novel, where you always inch closer to the truth.” Q has been posting increasingly complex entries since fall 2017, called "drops” by followers. These entries contain so-called "breadcrumbs” that must be followed to reach the goal. Which is ultimately unattainable.</p><p>Q’s breadcrumbs are like seeds, out of which the stories about the alleged elite conspiracy grow almost by themselves. Q is asking his or her (or their) followers to do their own research if they do not believe the media, turning conspiracy theorists into investigators. Melley argues that the desire to be a part of a revelation keeps them going, even if they never prove anything, and merely keep finding new breadcrumbs.</p>
</div>
<section>
<div data-component="HTMLEmbed">

<p>Illustration: Iris Kuhlmann / DER SPIEGEL; Fotos: Getty Images (3); klaput.blogspot.com; Twitter; wilkowmajority.com; YouTube.</p>
</div>
</section>
<div>
<p>The participatory nature of the ideology is what makes it so attractive. Melley argues that QAnon blends two big conspiracy theories together: a belief that the Illuminati, or someone else, rules the world and that there is a "deep state” within the government that is …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170">https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/world/the-most-dangerous-cult-of-our-times-qanon-s-inexorable-spread-beyond-the-u-s-a-e2b13c80-246a-43e5-945b-80ad7767a170</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577419</guid>
            <pubDate>Thu, 24 Sep 2020 11:13:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Database Version Control with Liquibase]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24577239">thread link</a>) | @asafg6
<br/>
September 24, 2020 | https://www.turtle-techies.com/database-version-controler-with-liquibase/ | <a href="https://web.archive.org/web/*/https://www.turtle-techies.com/database-version-controler-with-liquibase/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
        
        <h4>Introduction to managing DB shcema changes with Liquibase</h4>
                <h6>
                    By Suresh Regmi, Published 2020-09-06
                </h6>
    </p><div itemprop="articleBody"><h2 id="motivation">Motivation</h2>
<p>Let me give you a scenario,<br>
You have a project with multiple database instances in different environments (Dev, QA, Production) and you need to manage the database schema changes that are done against those environments.
Let’s assume that you are managing those changes by creating a git project or a shared file on a drive and adding a new SQL file for each database changes you are doing.
To implement your changes in that database, for each SQL file, you need to run the changes in each environment manually and add a flag or note to indicate which change is run on which environment.<br>
Would it be able to complete your task?
Yes, Yet, is it a decent method to manage schema changes?<br>
Of Course Not.</p>
<h2 id="here-are-some-of-the-many-problems-you-might-face-while-doing-so">Here are some of the many problems you might face while doing so</h2>
<ol>
<li>Hard to synchronize database and application code changes in different environments</li>
<li>The tedious process to run each change manually in different environments</li>
<li>Collaboration across the development team on what change is deployed and what is not</li>
<li>Hard to roll-back to the previous version of the database</li>
<li>Possibility of data loss</li>
</ol>
<h2 id="here-comes-liquibase">Here comes Liquibase</h2>
<p>Liquibase is an open-source library for tracking and managing database schema changes that can be used for any database with a JDBC driver.<br>
It is a platform-independent database migration tool that allows the database changes referred to as ‘changesets’ to be written in various formats including XML, JSON, YAML, and SQL.</p>
<h2 id="features">Features</h2>
<ol>
<li>Supports almost all databases that have a JDBC driver.</li>
<li>Changesets can be written in different formats like XML, JSON, YAML, and SQL.</li>
<li>Can be used to automatically generate changesets for an existing database</li>
<li>Easy to integrate with build tools like Jenkins, Maven etc</li>
<li>Supports database rollbacks</li>
<li>Supports context-dependent logic allowing us to use global context and preconditions</li>
<li>Can be executed via command line, Apache Maven, Apache Ant, Spring Framework</li>
<li>Has feature to generate changeset from an existing database and can also generate schema difference as changesets</li>
</ol>
<h2 id="different-ways-to-run-liquibase">Different ways to run liquibase</h2>
<ol>
<li><strong>Embed liquibase with your app:</strong> Embedding liquibase with your application code will automatically deploy liquibase on the app startup.</li>
<li><strong>Run liquibase using build tools:</strong> Integrate liquibase into your build process (with build tools like Jenkins, Ant, Maven, and Gradle) and update them without being tied up with the application.</li>
<li><strong>Generate the SQL and run it manually:</strong> Using update SQL, Liquibase provides the SQL generated from the changeset along with the database changes required to keep the tracking tables up to date. DBA will then inspect the SQL and run them against the database.</li>
</ol>
<h2 id="installation-process">Installation Process</h2>
<p><strong>Prerequisites:</strong> Liquibase requires Java 8+</p>
<p>There are two ways to install Liquibase, Manual installation and using liquibase installer.</p>
<p>If you set up liquibase using the liquibase installer, dependencies, directories, config and properties files will all be in place already.
It also provides some examples which will provide you with the core concepts required to understand the changesets.</p>
<p>In the case of manual installation, you need to download the compressed liquibase file and extract it in your workspace.<br>
For windows users, you need to add a new <code>PATH</code> variable in the <code>Environment Variables</code>.<br>
For macOS users, the path should be added to the <code>bash.profile</code> file.</p>
<p>For detailed instruction on Installation please follow this <a href="https://docs.liquibase.com/concepts/installation/home.html" target="_blank"> document </a>.</p>
<h2 id="core-concepts">Core Concepts</h2>
<ol>
<li><strong>liquibase.properties:</strong> The file <code>liquibase.properties</code> is a text-based file that stores common properties like database connection parameters, driver details, classpath parameters, global changelog parameters etc.
If you install liquibase using liquibase installer, it will provide pre-written <code>liquibase.properties</code> file while in case of manual installation, you need to create <code>liquibase.properties</code> file using a sample file provided.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image01.png" alt="Sample liquibase.properties file for Oracle"></a></p>
<ol start="2">
<li><strong>DatabaseChangeLog:</strong> Databasechangelog is a file where all changesets go. Each database changelog can include one or more changesets.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image02.png" alt="Example of an empty DatabaseChangeLog file
"></a></p>
<ol start="3">
<li><strong>Changeset:</strong> In liquibase, a changeset is represented as an atomic change to the database. Each changeset should be uniquely identified using author and id fields.
The database handles each changeset as a single transaction.
Changesets can be written in JSON, XML, SQL and YAML formats.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image03.png" alt="Example of a changeset in XML format"></a></p>
<ol start="4">
<li><strong>DATABASECHANGELOG &amp; DATABASECHANGELOGLOCK:</strong> These two tables are created by liquibase to track the changes that are run against the database and to make sure that no other migrations age going on.</li>
</ol>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image04.png" alt="DATABASECHANGELOG table structure"></a></p>
<p><a href="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" target="_blank"><img src="https://www.turtle-techies.com/database-version-controler-with-liquibase/image05.png" alt="DATABASECHANGELOGLOCK table structure"></a></p>
<h2 id="what-if-i-dont-like-liquibase">What if I don’t like Liquibase?</h2>
<p>If you told me that you don’t like liquibase and are looking for alternatives, I would ask why not Liquibase first.<br>
Liquibase is a sophisticated tool for database migration that has all features that you need for professional database refactoring and versioning.</p>
<p>But still, if you don’t want to use liquibase, here are some alternatives.</p>
<ol>
<li>
<p><strong>Flyway:</strong> Flyway is an open-source Apache licenced tool for database migration where you can write migrations in database-specific SQL or using Java code. For more details on Flyway, you can refer to this website. <a href="https://flywaydb.org/">https://flywaydb.org/</a></p>
</li>
<li>
<p><strong>YUNIQL:</strong> YUNIQL is also an open-source schema versioning and database migration engine that uses plain SQL scripts which can be integrated with CI/CD pipelines. If you want to check out YUNIQL, you can refer to this website. <a href="https://yuniql.io/">https://yuniql.io/</a></p>
</li>
</ol>
</div></div>]]>
            </description>
            <link>https://www.turtle-techies.com/database-version-controler-with-liquibase/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24577239</guid>
            <pubDate>Thu, 24 Sep 2020 10:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust programming language exploit mitigations]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24575844">thread link</a>) | @DyslexicAtheist
<br/>
September 23, 2020 | https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/ | <a href="https://web.archive.org/web/*/https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>By  on <time itemprop="datePublished" datetime="2020-09-16T00:00:00-07:00">September 16, 2020</time>. <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/#disqus_thread" data-disqus-identifier="/2020/09/16/rust-lang-exploit-mitigations/"></a></p><div itemprop="articleBody">
    <p>The Rust programming language provides memory[1] and thread[2] safety
guarantees via its ownership[3], references and borrowing[4], and slice
types[5] features. However, Unsafe Rust[6] introduces unsafe blocks, unsafe
functions and methods, unsafe traits, and new types that are not subject to
the borrowing rules.</p>

<p>Parts of the Rust standard library are implemented as safe abstractions over
unsafe code (and historically have been vulnerable to memory corruption[7]).
Furthermore, the Rust code and documentation encourage creating safe
abstractions over unsafe code. This can cause a false sense of security if
unsafe code is not properly reviewed and tested.</p>

<p>Unsafe Rust disables some of the features that provide memory and thread
safety guarantees. This causes programs or libraries to be susceptible to
memory corruption (CWE-119)[8] and concurrency issues (CWE-557)[9]. Modern C
and C++ compilers provide exploit mitigations to increase the difficulty to
exploit vulnerabilities resulting from these issues. Therefore, the Rust
compiler must also support these exploit mitigations in order to mitigate
vulnerabilities resulting from the use of Unsafe Rust. This post is going to
document these exploit mitigations and how they apply to Rust.</p>

<h2 id="exploit-mitigations">Exploit mitigations</h2>

<p>This section documents the exploit mitigations applicable to the Rust
compiler when building programs for the Linux operating system on the AMD64
architecture and equivalent.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> All examples in this section were
built using the Rust compiler version 1.40.0 (2019-12-19) on Debian testing
(Bullseye).</p>

<p>The Rust Programming Language currently has no specification. The Rust
compiler (i.e., rustc) is the language reference implementation. All
references to “the Rust compiler” in this post refer to the language
reference implementation.</p>

<p>Table I <br>
Summary of exploit mitigations supported by the Rust compiler when building
programs for the Linux operating system on the AMD64 architecture and
equivalent.</p>
<table>
  <tbody><tr>
   <td><strong>Exploit mitigation</strong>
   </td>
   <td><strong>Supported and enabled by default</strong>
   </td>
   <td><strong>Since</strong>
   </td>
  </tr>
  <tr>
   <td>Position-independent executable
   </td>
   <td>Yes
   </td>
   <td>0.12.0 (2014-10-09)
   </td>
  </tr>
  <tr>
   <td>Integer overflow checks
   </td>
   <td>Supported but enabled by default when debug assertions are enabled only.
   </td>
   <td>1.1.0 (2015-06-25)
   </td>
  </tr>
  <tr>
   <td>Non-executable memory regions
   </td>
   <td>Yes
   </td>
   <td>1.8.0 (2016-04-14)
   </td>
  </tr>
  <tr>
   <td>Stack clashing protection
   </td>
   <td>Yes
   </td>
   <td>1.20.0 (2017-08-31)
   </td>
  </tr>
  <tr>
   <td>Read-only relocations and immediate binding
   </td>
   <td>Yes
   </td>
   <td>1.21.0 (2017-10-12)
   </td>
  </tr>
  <tr>
   <td>Heap corruption protection
   </td>
   <td>Yes
   </td>
   <td>1.32.0 (2019-01-17) via OS default or specified allocator
   </td>
  </tr>
  <tr>
   <td>Stack smashing protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Forward-edge control flow protection
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
  <tr>
   <td>Backward-edge control flow protection (e.g., shadow and safe stack)
   </td>
   <td>No
   </td>
   <td>
   </td>
  </tr>
</tbody></table>

<p id="fn:1">1. See
<a href="https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec">https://github.com/rust-lang/rust/tree/master/compiler/rustc_target/src/spec</a>
for a list of targets and their default options. <a href="#fnref:1" role="doc-backlink">↩</a></p>

<h3 id="position-independent-executable">Position-independent executable</h3>

<p>Position-independent executable increases the difficulty of the use of code
reuse exploitation techniques, such as return-oriented programming (ROP) and
variants, by generating position-independent code for the executable, and
instructing the dynamic linker to load it similarly to a shared object at a
random load address, thus also benefiting from address-space layout
randomization (ASLR). This is also referred to as “full ASLR”.</p>

<p>The Rust compiler supports position-independent executable and enables it by
default since version 0.12.0 (2014-10-09)[10]–[13].</p>

<div><div><pre><code>$ readelf -h target/release/hello-rust | grep Type:
  Type:                              DYN (Shared object file)
</code></pre></div></div>
<p>Fig. 1. Checking if an executable is a position-independent executable.</p>

<p>An executable with an object type of <code>ET_DYN</code> (i.e., shared object) and not
<code>ET_EXEC</code> (i.e., executable) is a position-independent executable (see Fig.
1).</p>

<h3 id="integer-overflow-checks">Integer overflow checks</h3>

<p>Integer overflow checks protects programs from undefined and unintended
behavior (which may cause vulnerabilities) by checking for results of signed
and unsigned integer computations that cannot be represented in their type,
resulting in an overflow or wraparound.</p>

<p>The Rust compiler supports integer overflow checks, and enables it when
debug assertions are enabled since version 1.0.0 (2015-05-15)[14]–[17], but
support for it was not completed until version 1.1.0 (2015-06-25)[16]. An
option to control integer overflow checks was later stabilized in version
1.17.0 (2017-04-27)[18]–[20].</p>

<div><div><pre><code><span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>u</span><span>:</span> <span>u8</span> <span>=</span> <span>255</span><span>;</span>
    <span>println!</span><span>(</span><span>"u: {}"</span><span>,</span> <span>u</span> <span>+</span> <span>1</span><span>);</span>
<span>}</span>
</code></pre></div></div>
<p>Fig. 2. hello-rust-integer program.</p>

<div><div><pre><code>$ cargo run
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished dev [unoptimized + debuginfo] target(s) in 0.23s
     Running `target/debug/hello-rust-integer`
thread 'main' panicked at 'attempt to add with overflow', src/main.rs:3:23
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace.
</code></pre></div></div>
<p>Fig. 3. Build and execution of hello-rust-integer with debug assertions
enabled.</p>

<div><div><pre><code>$ cargo run --release
   Compiling hello-rust-integer v0.1.0 (/home/rcvalle/hello-rust-integer)
    Finished release [optimized] target(s) in 0.23s
     Running `target/release/hello-rust-integer`
u: 0
</code></pre></div></div>
<p>Fig. 4. Build and execution of hello-rust-integer with debug assertions
disabled.</p>

<p>Integer overflow checks are enabled when debug assertions are enabled (see
Fig. 3), and disabled when debug assertions are disabled (see Fig. 4). To
enable integer overflow checks independently, use the option to control
integer overflow checks, scoped attributes, or explicit checking methods
such as <code>checked_add</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>It is recommended that explicit wrapping methods such as <code>wrapping_add</code> be
used when wrapping semantics are intended, and that explicit checking and
wrapping methods always be used when using Unsafe Rust.</p>

<p id="fn:2">2. See <a href="https://doc.rust-lang.org/std/primitive.u32.html">https://doc.rust-lang.org/std/primitive.u32.html</a> for more
information on the checked, overflowing, saturating, and wrapping methods
(using u32 as an example). <a href="#fnref:2" role="doc-backlink">↩</a></p>

<h3 id="non-executable-memory-regions">Non-executable memory regions</h3>

<p>Non-executable memory regions increase the difficulty of exploitation by
limiting the memory regions that can be used to execute arbitrary code. Most
modern processors provide support for the operating system to mark memory
regions as non executable, but it was previously emulated by software, such
as in grsecurity/PaX
<a href="https://pax.grsecurity.net/docs/pageexec.txt">PAGEEXEC</a> and
<a href="https://pax.grsecurity.net/docs/segmexec.txt">SEGMEXEC</a>, on processors that
did not provide support for it. This is also known as “No Execute (NX) Bit”,
“Execute Disable (XD) Bit”, “Execute Never (XN) Bit”, and others.</p>

<p>The Rust compiler supports non-executable memory regions, and enables it by
default since its initial release, version 0.1 (2012-01-20)[21], [22], but
has regressed since then[23]–[25], and enforced by default since version
1.8.0 (2016-04-14)[25].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep -A 1 GNU_STACK
  GNU_STACK      0x0000000000000000 0x0000000000000000 0x0000000000000000
                 0x0000000000000000 0x0000000000000000  RW     0x10
</code></pre></div></div>
<p>Fig. 5. Checking if non-executable memory regions are enabled for a given
binary.</p>

<p>The presence of an element of type <code>PT_GNU_STACK</code> in the program header
table with the <code>PF_X</code> (i.e., executable) flag unset indicates non-executable
memory regions<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> are enabled for a given binary (see Fig. 5).
Conversely, the presence of an element of type <code>PT_GNU_STACK</code> in the program
header table with the <code>PF_X</code> flag set or the absence of an element of type
<code>PT_GNU_STACK</code> in the program header table indicates non-executable memory
regions are not enabled for a given binary.</p>

<p id="fn:3">3. See the Appendix section for more information on why it affects other
memory regions besides the stack. <a href="#fnref:3" role="doc-backlink">↩</a></p>

<h3 id="stack-clashing-protection">Stack clashing protection</h3>

<p>Stack clashing protection protects the stack from overlapping with another
memory region—allowing arbitrary data in both to be overwritten using each
other—by reading from the stack pages as the stack grows to cause a page
fault when attempting to read from the guard page/region. This is also
referred to as “stack probes” or “stack probing”.</p>

<p>The Rust compiler supports stack clashing protection via stack probing, and
enables it by default since version 1.20.0 (2017-08-31)[26]–[29].</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image1.png" alt="Screenshot listing cross references to __rust_probestack in hello-rust." title="Cross references to __rust_probestack in hello-rust.">
Fig. 6. Cross references to <code>__rust_probestack</code> in hello-rust.</p>

<div><div><pre><code><span>fn</span> <span>hello</span><span>()</span> <span>{</span>
    <span>println!</span><span>(</span><span>"Hello, world!"</span><span>);</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>_</span><span>:</span> <span>[</span><span>u64</span><span>;</span> <span>1024</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>;</span> <span>1024</span><span>];</span>
    <span>hello</span><span>();</span>
<span>}</span>
</code></pre></div></div>
<p>Fig 7. Modified hello-rust.</p>

<p><img src="https://rcvalle.blog/assets/2020/09/16/rust-lang-exploit-mitigations/image2.png" alt="Screenshot listing cross references to __rust_probestack in modified hello-rust." title="Cross references to __rust_probestack in modified hello-rust.">
Fig. 8. Cross references to <code>__rust_probestack</code> in modified hello-rust.</p>

<p>To check if stack clashing protection is enabled for a given binary, search
for cross references to <code>__rust_probestack</code>. The <code>__rust_probestack</code> is
called in the prologue of functions whose stack size is larger than a page
size (see Fig. 6), and can be forced for illustration purposes by modifying
the hello-rust example as seen in Fig. 7 and Fig. 8.</p>

<h3 id="read-only-relocations-and-immediate-binding">Read-only relocations and immediate binding</h3>

<p><strong>Read-only relocations</strong> protect segments containing relocations and
relocation information (i.e., <code>.init_array</code>, <code>.fini_array</code>, <code>.dynamic</code>, and
<code>.got</code>) from being overwritten by marking these segments read only. This is
also referred to as “partial RELRO”.</p>

<p>The Rust compiler supports read-only relocations, and enables it by default
since version 1.21.0 (2017-10-12)[30], [31].</p>

<div><div><pre><code>$ readelf -l target/release/hello-rust | grep GNU_RELRO
  GNU_RELRO      0x000000000002ee00 0x000000000002fe00 0x000000000002fe00
</code></pre></div></div>
<p>Fig. 9. Checking if read-only relocations is enabled for a given binary.</p>

<p>The presence of an element of type <code>PT_GNU_RELRO</code> in the program header
table indicates read-only relocations are enabled for a given binary (see
Fig. 9). Conversely, the absence of an element of type <code>PT_GNU_RELRO</code> in the
program header table indicates read-only relocations are not enabled for a
given binary.</p>

<p><strong>Immediate binding</strong> protects additional segments containing relocations
(i.e., <code>.got.plt</code>) from being overwritten by instructing the dynamic linker
to perform all relocations before transferring control to the program during
startup so all segments containing relocations can be marked read only (when
combined with read-only …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/">https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</a></em></p>]]>
            </description>
            <link>https://rcvalle.blog/2020/09/16/rust-lang-exploit-mitigations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575844</guid>
            <pubDate>Thu, 24 Sep 2020 06:25:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Google Grant for Libcurl Work]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24575819">thread link</a>) | @gilad
<br/>
September 23, 2020 | https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Earlier this year I was the recipient of a monetary <a rel="noreferrer noopener" href="https://www.google.com/about/appsecurity/patch-rewards/" target="_blank">Google patch grant</a> with the expressed purpose of <strong>improving security in libcurl</strong>.</p>



<p>This was an upfront payout under this Google program describing itself as “an experimental program that rewards proactive security improvements to select open-source projects”.</p>



<p>I accepted this grant for the curl project and <strong>I intend to keep working fiercely on securing curl</strong>. I recognize the importance of curl security as curl remains one of the most widely used software components in the world, and even one that is doing network data transfers which typically is a risky business. curl is responsible for a <a href="https://daniel.haxx.se/blog/2019/12/04/daily-web-traffic/">measurable share</a> of all Internet transfers done over the Internet an average day. My job is to make sure those transfers are done as safe and secure as possible. It isn’t my <em>only</em> responsibility of course, as I have other tasks to attend to as well, but still.</p>



<h2>Do more</h2>



<p>Security is already and always a top priority in the curl project and for myself personally. This grant will of course further my efforts to strengthen curl and by association, all the many users of it.</p>



<h2>What I will not do</h2>



<p>When security comes up in relation to curl, some people like to mention and propagate for other programming languages, But <strong>curl will not be rewritten in another language</strong>. Instead we will increase our efforts in writing good C and detecting problems in our code earlier and better.</p>



<h2>Proactive counter-measures</h2>



<p>Things we have done lately and working on to enforce everywhere:</p>



<p><strong>String and buffer size limits</strong> – all string inputs and all buffers in libcurl that are allowed to grow now have a maximum allowed size, that makes sense. This stops malicious uses that could make things grow out of control and it helps detecting programming mistakes that would lead to the same problems. Also, by making sure strings and buffers are never ridiculously large, we avoid a whole class of integer overflow risks better.</p>



<p><strong>Unified dynamic buffer functions</strong> – by reducing the number of different implementations that handle “growing buffers” we reduce the risk of a bug in one of them, even if it is used rarely or the spot is hard to reach with and “exercise” by the fuzzers. The “dynbuf” internal API first shipped in curl 7.71.0 (June 2020).</p>



<p><strong>Realloc buffer growth unification</strong> – pretty much the same point as the previous, but we have earlier in our history had several issues when we had silly realloc() treatment that could lead to bad things. By limiting string sizes and unifying the buffer functions, we have reduced the number of places we use realloc and thus we reduce the number of places risking new realloc mistakes. The realloc mistakes were usually in combination with integer overflows.</p>



<p><strong>Code style</strong> – we’ve gradually improved our code style checker (<code>checksrc.pl</code>) over time and we’ve also gradually made our code style more strict, leading to less variations in code, in white spacing and in naming. I’m a firm believer this makes the code look more coherent and therefore become more readable which leads to fewer bugs and easier to debug code. It also makes it easier to grep and search for code as you have fewer variations to scan for.</p>



<p><strong>More code analyzers</strong> – we run every commit and PR through a large number of code analyzers to help us catch mistakes early, and we always remove detected problems. Analyzers used at the time of this writing: lgtm.com, Codacy, Deepcode AI, Monocle AI, clang tidy, scan-build, CodeQL, Muse and Coverity. That’s of course in addition to the regular run-time tools such as valgrind and sanitizer builds that run the entire test suite.</p>



<p><strong>Memory-safe components</strong> – curl already supports getting built with a plethora of different libraries and “backends” to cater for users’ needs and desires. By properly supporting and offering users to build with components that are written in for example rust – or other languages that help developers avoid pitfalls – future curl and libcurl builds could potentially avoid a whole section of risks. (Stay tuned for more on this topic in a near future.)</p>



<h2>Reactive measures</h2>



<p>Recognizing that whatever we do and however tight ship we run, <strong>we will continue to slip every once in a while</strong>, is important and we should make sure we find and fix such slip-ups as good and early as possible.</p>



<p><strong>Raising bounty rewards</strong>. While not directly fixing things, offering more money in <a href="https://hackerone.com/curl">our bug-bounty program</a> helps us get more attention from security researchers. Our ambition is to gently drive up the reward amounts progressively to perhaps multi-thousand dollars per flaw, as long as we have funds to pay for them and we mange keep the security vulnerabilities at a reasonably low frequency.</p>



<p><strong>More fuzzing</strong>. I’ve said it before but let me say it again: fuzzing is really the top method to find problems in curl once we’ve fixed all flaws that the static analyzers we use have pointed out.  The primary fuzzing for curl is done by OSS-Fuzz, that tirelessly keeps hammering on the most recent curl code.</p>



<p>Good fuzzing needs a certain degree of “hand-holding” to allow it to really test all the APIs and dig into the dustiest corners, and we should work on adding more “probes” and entry-points into libcurl for the fuzzer to make it exercise more code paths to potentially detect more mistakes.</p>



<p>See also my presentation <a href="https://daniel.haxx.se/blog/2020/07/02/video-testing-curl-for-security/">testing curl for security</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/09/23/a-google-grant-for-libcurl-work/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24575819</guid>
            <pubDate>Thu, 24 Sep 2020 06:20:53 GMT</pubDate>
        </item>
    </channel>
</rss>
