<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 12 Dec 2020 08:34:04 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 12 Dec 2020 08:34:04 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Digital Twins, a Requirement for Industrial AI]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25371343">thread link</a>) | @MorganeR
<br/>
December 10, 2020 | https://blog.senx.io/digital-twins-requirement-for-industrial-ai/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/digital-twins-requirement-for-industrial-ai/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Using AI to make industrial assets more efficient and reduce their downtime is on many agendas. Learn how digital twins and time series data play a major role in this plan.</p><article>
      
<p><strong>When interviewed, CEOs across industries all state that AI is part of their top priorities.</strong> But when it comes to actual implementation AI projects are not very glamorous. Past simple proofs of concept and the hiring of a team of data scientists, there is usually no sign of the highly anticipated digital transformation wished by the CEOs.</p>



<p>There are multiple reasons for this disenchantment, far too many to list here. But among those, some are directly related to what we focus on at <a href="https://senx.io/" target="_blank" rel="noreferrer noopener">SenX</a>, data, and the way industries introduce them in their environment.</p>



<h2>No digital transformation without data</h2>



<p>The willingness to transform is genuine in many organizations, driven by ambitious visions or just the consciousness that the competitive landscape is evolving.</p>



<p>The next step is usually for those businesses to pick some quick wins to prove that the transformation can be initiated and comfort everyone that it does not mean changing teams or radically modifying their way of working.</p>



<p>Those short projects aim at demonstrating the methodology for transforming limited operational perimeters. They often involve solving a problem with approaches to leveraging new technologies. Those technologies, 100% digital, need fuel to work, and that fuel is data. <strong>So the first step is to ensure data are available</strong>.</p>



<p>The firms hired to help in building those quick wins will then wander among departments. They will harvest datasets here and there until they have sufficient matter for implementing their solutions.</p>



<p>This step can sometimes take time if the data is not well identified and distributed across the organization. But it is a mandatory path to follow as without data no digital transformation will happen.</p>



<figure></figure>



<h2>No AI without big data</h2>



<p>Past the simple quick wins done to bootstrap the transformation comes a time when more ambitious projects are brought on the table, and that is when AI (Artificial Intelligence) comes into the conversation. The hype around AI is so strong that projects around AI and ML (Machine Learning) cannot be neglected.</p>



<p>The problem with the current hype is that very few people really understand what AI actually implies. <strong>For many</strong>,<strong> you buy an AI like you buy a Microsoft Office 365 subscription</strong>, this is just not true. The promise of AI is to bring new, automatic, ways to use data to help in or even completely assume the decision process. This promise can only be fulfilled if the actual AI put to work, otherwise called the model, is actually trained on the data in your very own organization, and this requires once again the same digital transformation fuel, data. The difference is that this time you need more of it. You are no longer trying to light a fondue burner but a rocket engine!</p>



<p>Training a model does indeed require a lot of data covering the various aspects of your business operations you want the model to focus on, also covering a long period of time so trend and seasonality can be modeled. </p>



<h4>This has several impacts</h4>



<ul><li>The first is that you cannot expect to train a model and efficiently introduce AI in your operations until you actually have collected enough meaningful data. And if your organization has not done so so far you need to start as soon as possible. </li><li>The second impact is that this data collection process is not a one time job. It does not stop once you have enough data for training a model. It needs to go on and on so you keep on accumulating signals on how your business operates to retrain your models in the future if their performance starts to degrade. This means that prior to your journey into the core of AI you need to plan for big data to be collected, stored and made available to teams across your organization so they can start looking at the data and imagine possible uses and models.</li></ul>



<h2>No industrial AI without Digital Twins</h2>



<p>Among verticals, industrial organizations face the hardest problems of data collection. Industries whose data mainly relates to users using their services are lucky. In the end, their data are not that massive. Sure we have all heard stories of banks or retailers hoarding piles of data. But we are talking about a few thousand interactions per year per user. So even with a billion users, which not that many banks or retailers have, we are talking a few trillion events per year.</p>



<p>In the industrial world, things are different, the assets producing data do not eat or sleep. They work day and night and sometimes produce thousands of measurements per second.</p>



<h3>For example...</h3>



<p>Take for example the CERN experiments at the LHC. They produced 600 million events per second during the campaigns for the quest of the Higgs boson. That is 51 trillion events per day. Luckily for the CERN, not all events needed to be retained. With highly efficient AI-based detectors, which needed to be trained with massive data themselves, they were able to limit the production to 100 000 events per second sent for digital reconstruction and ultimately 200 events persisted per second. </p>



<p>But other sectors need to retain more data. Synchro phasors (or PMUs, phase monitoring units) monitoring electrical grids, for example. They each produce several 1000s measures per second, and there are thousands of those at the scale of a country like France. This means millions of C37.118.2 messages sent every second, not to mention the IEC61850 messages sent to supervise the substations. </p>



<p>Same thing in aeronautics where aircraft typically produce 5 000 to 15 000 data points per second they are operating, or industrial assets whose PLC (Programmable Logic Controllers) track the state of many sensors and actuators.</p>



<p>The use of AI in those verticals requires that those truly massive data be collected and organized. Since they are data related to physical assets, it is wise to use an approach which mimics these assets in a digital form, this approach is called Digital Twins. </p>



<figure></figure>



<h3>What are Digital Twins?</h3>



<p>The Digital Twin of an asset is the set of measures coming from its sensors and actuators. Those measures need to be tracked in time to catch the dynamics of the assets' operations. And the technology of choice to do so is a <a href="https://blog.senx.io/which-time-series-database-suited-to-your-needs/" target="_blank" rel="noreferrer noopener">Time Series Database</a>. Indeed Digital Twins are nothing else than time series, some for the sensors, some for the actuators with their states. And if you want more advanced digital twins, some with the control commands sent to the assets to modify how it behaves.</p>



<p>Once you start collecting the data from your assets in a Time Series Database, you can easily access the state of those assets at any point in time. More importantly, you can start extracting features to train models to detect anomalies and perform predictive maintenance.</p>



<h2>Takeaways</h2>



<p>AI is on every business' agenda, but the importance of data is too often overlooked. <strong>When it comes to industrial AI, the first step towards a successful implementation is the collection of all sensor data to build Digital Twins of the physical assets involved.</strong> This approach needs to leverage a Time Series Database, the kind of database SenX offers with the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp 10 Time Series Platform</a>.</p>



<p><a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">Contact us</a> to learn how SenX and its technologies can help you master your industrial AI adventure.</p>








<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/digital-twins-requirement-for-industrial-ai/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25371343</guid>
            <pubDate>Thu, 10 Dec 2020 08:45:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Filmbox – Physically accurate motion picture film emulation]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25367371">thread link</a>) | @wilg
<br/>
December 9, 2020 | https://videovillage.co/filmbox/ | <a href="https://web.archive.org/web/*/https://videovillage.co/filmbox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://videovillage.co/images/filmbox/hero-ee5486c3.jpg" alt="Hero"></p><p><h2>A complete reproduction of photochemical motion picture imaging.</h2><h2>Driven by empirical data and tailored to specific digital sensors.</h2><h2>Built for high-end production. Right in DaVinci Resolve.</h2></p><div><div><p><h2>The look and feel of motion picture film defines a century of art.</h2><h2>As we move beyond the photochemical process, we need not leave behind its aesthetic quality.</h2></p><div><div><div><p><h2>Film negative has a unique response to light intensity and wavelength. Filmbox reproduces this behavior using rich empirical datasets to transform digital sensor values to exhibit the same non-linearities.</h2></p></div></div></div><div><div><div><p><h2>As light strikes color film negative, different wavelengths scatter to different degrees within the layers of emulsion and affect neighboring image regions. Filmbox convolves the digital image data to recreate the soft yet detailed quality of the negative.</h2></p></div></div></div><div><div><div><p><h2>The perceptual intensity of film grain varies with the density of the developed negative. Filmbox reproduces the quality and tonal distribution of grain as well as other subtle effects of the development process.</h2></p></div></div></div><div><div><div><p><h2>Film camera transport mechanisms are not perfectly stable, and labs are not perfectly clean. If desired, Filmbox can model the subtle instability of real 35mm and 16mm cameras, and procedurally place samples of real dust.</h2></p></div></div></div><div><div><div><p><h2>The look of projected film is the combination of the characteristics of the negative and the print.</h2><h2>Filmbox maps the emulated negative to the light output of the digital display using a characterization of the combined photometric response of an actual contact printed negative.</h2></p></div></div></div></div></div><div><div><video autoplay="" data-sources="W3sic3JjIjoiL2ltYWdlcy9maWxtYm94L3ZpZGVvL2NvbXBhcmlzb24vdmlk
ZW8ubXA0IiwidHlwZSI6InZpZGVvL21wNDsgY29kZWNzPVwiYXZjMVwiIn1d
" loop="" muted="" playsinline="" poster="https://videovillage.co/images/filmbox/video/comparison/poster-c124bf44.jpg"><img alt="Comparison of Filmbox and actual film" src="https://videovillage.co/images/filmbox/video/comparison/poster-c124bf44.jpg"></video></div></div><div><div><p><h2>Built for simplicity, no tweaking necessary.</h2><h2>Consistent, predictable, understandable by the whole creative team.</h2><h2>Plenty of knobs under the hood if you want to tinker.</h2></p><div><p><img src="https://videovillage.co/images/filmbox/features/default-17385d13.jpeg" alt="Default"></p></div></div></div><div><div><p><img src="https://videovillage.co/images/filmbox/workflow_fb-f68b50df.jpg" alt="Workflow fb"></p><p>Pro Workflows</p><div><p>Profiled for Alexa, Venice, RED, Varicam, Blackmagic URSA, C300II</p><p>Work in the camera's native space, Resolve Intermediate, or ACES</p><p>Set looks between the Negative and Print to simulate DI and printer lights</p><p>Output as negative, or as print to standard display spaces or ACES</p></div></div><div><p><img src="https://videovillage.co/images/scatter/gpu-52db23e1.jpg" alt="Gpu"></p><p>Fast</p><div><p>Built for DaVinci Resolve using GPU acceleration</p><p>Realtime performance at DCI 4K</p></div></div></div><section><div><p><img width="128" height="128" src="https://videovillage.co/images/filmbox-6cdfa86d.png" alt="Filmbox"></p><p>Filmbox</p><p>Really good film emulation</p></div><div><div><p>Filmbox is still in early access so we can make sure it works great.</p>

<p>Plugin for DaVinci Resolve. Requires macOS 10.15 or later and DaVinci Resolve 16 or later.</p>
</div></div></section><section id="footer"><p>© &amp; ™ 2014-2020 Video Village, LLC</p><p>Made in California by <a href="http://gregcotten.com/">Greg Cotten</a> &amp; <a href="http://wilgieseler.com/">Wil Gieseler</a> &amp; <a href="http://afinch.com/">Andrew Finch</a>.</p></section></div></div>]]>
            </description>
            <link>https://videovillage.co/filmbox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25367371</guid>
            <pubDate>Wed, 09 Dec 2020 23:57:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Common Problems in Financial Services Reconciliation]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25363650">thread link</a>) | @kunle
<br/>
December 9, 2020 | https://kunle.app/dec-2020-financial-reconciliation.html | <a href="https://web.archive.org/web/*/https://kunle.app/dec-2020-financial-reconciliation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  				
  				 <p>December 2020</p>

<p>If your product moves money on behalf of customers, and you manage the ledger, you need reconciliation. You can think of recon as the process of making sure every transaction in your system matches one in the external world. For every dollar you’ve moved, an external entity agrees with the amount and direction, and has provided “documentation” to that effect.</p>
<p>I’ve seen a few performant recon systems that came under stress as they scaled, and I’ve worked with startups at early enough stages that getting recon right was not existential. I’ve also never built a recon system from scratch. Everything I'll say here is from the perspective of a user of recon systems rather than a maker of them. I’ve been a customer of a couple, and their performance impacted my output so I have strong opinions about what I wish would exist. Since I'm not sure what a perfect recon system would look like, I'm writing this to flesh out the thought, and to smoke out anyone who already knows.</p>
<p>I’ve interacted with reconciliation systems aimed at two types of problems:</p>
<h2>Reconciliation of transactions</h2>
<p>Transaction oriented recon makes sure that some external party agrees with every money movement in your ledger. I saw this philosophy in the recon systems I interacted with at Cash App &amp; Square in general. In this model, the objective is to make sure that every money movement action matches your intention. This means the state of the transaction, the direction, and the amount are what you expect. A secondary objective is ensuring the timing matches your intention. This is secondary because in a lot of cases, the actual precise timing doesn't matter as long as it happens&nbsp; "soon", and as long as the underlying accounts aren’t run at a $0 balance. In this case reconciliation solves an accounting problem, ensuring money movements are correct. It also helps ensure that the company's receivables and payables are complete, is useful for regulatory &amp; financial audits, and empowers your treasury team to make good cash management decisions. I suspect most acquirers (Stripe, Square, Adyen, etc.) at least start by pursuing transaction oriented recon.</p>
<p>Typically in an acquiring world, you construct the “internal” ledger from the settlement/capture messages generated by the card networks. This is what product teams look at to inform customer facing features. You construct the “external” ledger from settlement files generated by the acquiring bank. Accounting teams look at the external ledger (technically accounting teams look at both ledgers, but product teams rarely look at the external ledger on an ongoing basis).</p>
<p>A recon system often includes an engineering team paired with an operations team, working together. In cases where the internal and external ledgers disagree, a human (on the ops team) reviews the data. They determine what’s causing the exception, whether it's systematic, how frequently it occurs, and what to do to fix it. The eng team continually optimizes the process to reduce the exception rate over time. Transaction oriented recon primarily solves accounting problems. You’re typically working towards SLAs designed for monthly/quarterly earnings close, and your outputs feed into income/cash flow statements.</p>
<h2>Reconciliation of balances</h2>
<p>Balance oriented recon ensures precise amounts in bank or customer accounts on a periodic basis. You use the same internal and external ledgers as in transaction oriented recon. However, you're comparing not only the amounts, state and direction of a transaction, but also its timing. This type of recon system can be useful for accounting, but is ideal for building systems that report a balance at a point in time. One example is a banking system of record. In the case of a system of record, a balance oriented recon system informs customer-facing balances and FDIC insurance.</p>
<p>Balance oriented recon systems are required for organizations that issue instruments and are the final source of truth for their own ledger. Most financial technology companies today rely on the ledgers managed by their infrastructure providers. For instance, if you issue cards, the banking as a service platform typically connects to the bank’s core, and most traditional bank cores have a balance oriented recon framework built in.</p>
<p>For context - in order to provide FDIC insurance to customers, banks are required to provide an auditable record of customer balances at any point in time. This is usually solved by being able to provide a daily snapshot of customer balances. This function is one of several provided by core processors, and as a result most core processors have a balance oriented recon process built in by default.</p>
<p>However if you’re the rare card issuer managing your own ledger (or really building any kind of financial product where you’re responsible for your own ledger, such as a digital wallet where you own the money transmission licenses), you’ll need to build a balance oriented recon system eventually. It's the way you’ll be sure you have the money that you’re telling customers you have.</p>
<h2>Common Problems in Recon</h2>
<h3>Adding a new money movement type to a single balance</h3>
<p>One overarching problem that affects all recon systems is what happens when new types of money movement impact a balance. For instance, imagine you run a digital wallet where your primary funding and cash-out transaction types are ACH debits and credits. Also, imagine you’ve built a perfect reconciliation system, with the combination of technology and human process that allows you to tie out balances and payments with zero failures (this is super unlikely). The moment you add payment cards as funding/cash out instruments, you now have a different external ledger to integrate with. It will have different edges than you're used to. You'll deal with potentially different organizations, who have different processes for resolving exceptions. No matter what you do, this will take time to get right, and long after your new feature is launched, you’ll probably discover new, undocumented quirks. Some of these quirks will only be clear when you’re processing money movements at scale. I’ve seen cases where the incorrect MID set with a card network resulted in hundreds of millions of dollars routed to the wrong (internal) account. Survivable error as the transactions were reconciled in aggregate, but bad for accounting and distraction caused to cross functional team members pulled in to swarm the problem.</p>
<h3>Timing differences between authorization and settlement</h3>
<p>For balance oriented reconciliation systems in particular, solving timing problems is critical. Timing problems typically occur when a) the payment authorization time and the settlement time are different, and your system’s not necessarily aware, b) you’re dealing with payment types where the settlement amount can be adjusted multiple times c) your ledger updates customers balances when a new payment authorization comes in, rather than a settlement message. In all these cases you’re grappling with a few questions (I don’t actually know the right answers to these):</p>
<ul>
<li>When should you update a customer’s balance? When you know there is a transaction (when the auth comes in) or when amount is finalized (when the settlement comes in)</li>
<li>When the authorization and settlement amounts are different, do you retroactively adjust the balance for the day the authorization came in? Or do you fix that in place and only adjust the balance with the delta on the day the settlement arrives?</li>
<li>Is your snapshot on a particular day immutable (i.e. it can never be adjusted) and if so, how do you handle changes in amounts between the authorization and the settlement?</li>
<li>Traditional core systems will have an available balance (which is how much you can access, with pending transaction amounts removed), and an account balance (which includes pending transactions, and is typically higher than the available balance).</li>
</ul>
<h3>Relying on aged systems for exception handling</h3>
<p>Very often you work with a wholesale bank whose systems are seasoned and handle the majority of exceptions using manual workflows. This can be frustrating; you’re faced with either adopting their manual processes, which bind your cost structure to theirs, or accepting a higher exception rate temporarily while you build technical systems around their process. There’s no easy trade-off here.</p>
<h3>Early prototyping and float problems</h3>
<p>In the course of product development you’ll often prototype by adding new money movement types to your ledger. A lot of these prototypes (as should happen) will be discarded. Despite this, they will have moved real money and affected your real ledger, and (at least for your accounting team's sanity) you’ll need a stateful way to reconcile the money that moved to your ledger. While at Cash I once spent a year integrating into 6 card issuer processor systems while prototyping the Cash Card. With each integration we needed a float (depositing funds with the card issuer so we could test transactions in the real world) which meant our accounting team now had 6 new banking relationships to monitor, 4 of which lasted less than 6 months, but all of which required material floats amounts. In a few cases, the issuer processor didn’t actually enable us to manage our own ledger, so we’d have a parallel ledger (one on our databases and a mirror on theirs) that we’d have to keep in sync. There was at least one integration that we ultimately discarded, which took us several months to reconcile, long after we’d walked away from the partnership. How you handle these cases will depend on what’s financially “material” for your organization. In our cases, prototype floats were all sub $100k, so survivable at our scale. But tracking these down repeatedly was an insane level of tedium.</p>
<h3>Managing ledgers across many internal bank accounts</h3>
<p>Sometimes you’ll contract with multiple banks for different financial services. For instance one bank for merchant acquiring and another for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kunle.app/dec-2020-financial-reconciliation.html">https://kunle.app/dec-2020-financial-reconciliation.html</a></em></p>]]>
            </description>
            <link>https://kunle.app/dec-2020-financial-reconciliation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363650</guid>
            <pubDate>Wed, 09 Dec 2020 19:50:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open source Internet-less IRC using LoRa, for disaster resilience]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25363427">thread link</a>) | @spiritplumber
<br/>
December 9, 2020 | http://f3.to/cellsol/ | <a href="https://web.archive.org/web/*/http://f3.to/cellsol/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
    


    








    <article>
        
        



    



<p>Welcome to CellSol!</p>
<p>This website and its associated project are now in beta! Come take a look at our <a href="https://github.com/RbtsEvrwhr-Riley/CellSol/">GitHub</a></p>
<p><img src="http://f3.to/cellsol/media/cellsol_large_236.png" alt="CellSol Logo - Large"></p>

<div><hr>
<h2 id="lastmod-2020-11-24">publishdate: 2019-11-17
lastmod: 2020-11-24</h2>

<p>What if the internet and cell phone towers went down for more than a few hours - or during an emergency situation? No communication could lead to lost lives.</p>

<p>The end goal of the project is to have a widespread network able to handle low-bandwidth traffic (text, compressed images) for a large number of users, to fill gaps when the larger Internet is unavailable.</p>
<p>In the event of an emergency, the CellSol network, much like the Internet, can be used as a knowledge base, as well as a rally point, giving people a tool to use to coordinate and organize even if 
other communication systems go down. We intend to scale the design, with long-haul routing capabilities, so that regional networks can intercommunicate and interoperate, allowing for a wider breadth of use cases.</p>

<p>The overall design is a <a href="https://en.wikipedia.org/wiki/Mesh_networking">mesh network</a> of <a href="https://www.semtech.com/lora/what-is-lora">LoRa</a> devices, called “Pylons”
that act as repeaters (extending the range of the network). Terminals (devices that users access the network with) also repeat packets, so that a network
made up entirely of end users is possible.</p>
<p>The two basic types of pylons are the ESP32 WiFi Pylon (a terminal device) and the Ardunio Repeater Pylon (a pure repeater, but can have bluetooth to use as a terminal).</p>
<p>Pylons with more specialized uses, such as data repositories for local emergency resources (phone numbers, shelter locations, etc.) and knowledge bases (such as a Wikipedia mirror) are also intended to be
developed in the future, to add to the overall usefulness of the network.</p>
</div>



    </article>

                








    
    

    







            </div></div>]]>
            </description>
            <link>http://f3.to/cellsol/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25363427</guid>
            <pubDate>Wed, 09 Dec 2020 19:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Native JavaScript Document API for Cassandra]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25362944">thread link</a>) | @Gulthor
<br/>
December 9, 2020 | https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html | <a href="https://web.archive.org/web/*/https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
        
        <h4>Level-up your app dev with fast and easy data APIs for the world’s most battle tested database.</h4>
      </p>
    </div><div>
      <div>
        <p><img data-src="/assets/images/stargate-profile.png" alt="Denise Gosnell" width="32" height="32" src="https://stargate.io/assets/images/stargate-profile.png">
          <span>By <span>Denise Gosnell</span></span>
          •
          <span>Dec 9, 2020</span>
        </p>
      </div>
    </div><div>
      <div>
        <div>
          <p>It is a really great time to be a developer.</p>

<p>We have tons of APIs integrated within great tools for building dynamic, full stack apps. If you are a developer, you probably are using technologies like schemaless data stores, serverless architectures, JSON APIs, and/or the GraphQL language.</p>

<p>Further, there are a bunch of cool frameworks like the <strong>Jam</strong>stack (<strong>J</strong>avaScript, <strong>A</strong>PIs, and <strong>M</strong>arkup) and services like Netlify to make it fast to deploy a serverless app.</p>

<p>And now, for the first time ever, Apache Cassandra is a part of this stack because <a href="https://astra.datastax.com/">Stargate is now live on Astra</a> as the official data API.</p>

<p>The modern apps we build need data APIs which integrate into our toolset and work with native data shapes (JSON, REST, GraphQL, etc). These data APIs need to support schemaless JSON, while simultaneously providing speed and scalability.</p>

<p>Most importantly, it better only take a few minutes for us to use them within our project.</p>

<p>DataStax built <a href="https://stargate.io/">Stargate</a> into Astra to give us, app developers, a natural data API stack which meshes with the Jamstack (or serverless stack of your choice). Stargate in Astra is built on the rock solid NoSQL data engine (Apache Cassandra) which powers Netflix, Instagram, Yelp, iCloud and other apps we all use everyday.</p>

<h2 id="what-exactly-is-stargate">What exactly is Stargate?</h2>
<p>Stargate is an <a href="https://stargate.io/2020/09/14/init-stargate.html">open source data gateway</a> that sits between your app server and your databases. Stargate brings together an API platform and data request coordination code into one OSS project.</p>

<p>Multiple successful app companies - like Netflix and Yelp - built their own data gateways to help internal app developers create features using simple APIs, without needing to learn the underlying database or mess with schema.</p>

<p>DataStax integrated Stargate into Astra to give you the same power and ease of access to your data.</p>

<p>What does this mean for you?</p>

<ul>
  <li>No upfront data modelling needed for Documents.</li>
  <li>Less custom code to maintain.</li>
  <li>More time to build what you care about.</li>
</ul>

<p><img alt="" data-src="/assets/images/stargate-astra/stargate-astra.png" src="https://stargate.io/assets/images/stargate-astra/stargate-astra.png"></p>

<p>You can work with your data the way you want – JSON via schemaless document APIs or database schema aware GraphQL and RESTful APIs – while Stargate serves as the proxy that coordinates these requests to different flavors of Cassandra.</p>

<p>To see it in action, let’s see how this works by using JSON with Stargate’s schemaless Document API in a TikTok clone. Because, if Instagram and Snapchat have a TikTok clone, we should have one, too. Right?</p>

<h2 id="real-quick-note-first">Real Quick Note First</h2>

<p>Slinging JSON to and from Apache Cassandra without data modeling is just too much fun. You gotta <a href="http://astra.datastax.com/">try this out in Astra for yourself</a>. You can get <a href="https://www.datastax.com/dev/documents-api">hands on with it right away</a> or check out our <a href="https://astra.datastax.com/sample-app-gallery">sample app gallery</a> to see schemaless Cassandra in action.</p>

<p>We are stoked to have engineers from Netflix, Burberry, Macquarie Bank, USAA, and Yelp creating Stargate with us. They are already hard at work battletesting the APIs and collaborating on new features.</p>

<p>Ok, onto the code!</p>

<h2 id="posts-in-tiktok">Posts in TikTok</h2>

<p>We are going to walk through using Stargate’s APIs in Astra for creating and updating posts within a TikTok clone. We’re walking through examples that are ready to be pasted into your latest Jamstack app.</p>

<p>To use Stargate in Astra in your app, first install and set up our <a href="https://www.npmjs.com/package/@astrajs/collections">JavaScript SDK</a>. You can learn about storing environment <a href="https://www.youtube.com/watch?v=vSmzEGZQI5A">variables in your .env file here</a>.</p>

<p>Let’s start with a basic TikTok post: a video with a caption, like:</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>postData</span> <span>=</span> <span>{</span>
  <span>"</span><span>postId</span><span>"</span><span>:</span> <span>0</span><span>,</span>
  <span>"</span><span>video</span><span>"</span><span>:</span> <span>"</span><span>https://i.imgur.com/FTBP02Y.mp4</span><span>"</span><span>,</span>
  <span>"</span><span>caption</span><span>"</span><span>:</span> <span>"</span><span>These ducks are cute</span><span>"</span><span>,</span>
  <span>"</span><span>timestamp</span><span>"</span><span>:</span> <span>"</span><span>2020-12-09T09:08:31.020Z</span><span>"</span><span>,</span>
  <span>"</span><span>likes</span><span>"</span><span>:</span> <span>0</span><span>,</span>
<span>}</span></code></pre></figure>

<p>After connecting to Stargate in Astra with a nodejs client, let’s create a new collection in our app and add the post with:</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>postsCollection</span> <span>=</span> <span>astraClient</span><span>.</span><span>namespace</span><span>(</span><span>"</span><span>tikTokClone</span><span>"</span><span>).</span>
  <span>collection</span><span>(</span><span>"</span><span>posts</span><span>"</span><span>);</span>

<span>const</span> <span>post</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>create</span><span>(</span><span>postData</span><span>);</span></code></pre></figure>

<p>If you’ve ever used Cassandra before, you know this is amazing. Look at what we didn’t do: no data modeling, no table creation, no configuration code, no partition keys, no clustering columns. I think you get my drift.</p>

<p>Stargate in Astra allows you to add data to Apache Cassandra in one line of code.</p>

<p>This level of ease of use hasn’t previously been possible with Cassandra. Insert JSON and move on.</p>

<p>Next up, let’s say you want to find all posts about ducks. You can do that via:</p>

<figure><pre><code data-lang="javascript"><span>// find all posts about ducks</span>
<span>const</span> <span>posts</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>find</span><span>({</span> <span>caption</span><span>:</span> 
  <span>{</span> <span>$in</span><span>:</span>  <span>[</span><span>"</span><span>ducks</span><span>"</span><span>]</span> <span>}</span> <span>});</span></code></pre></figure>

<p>And boom. Now you have your ducks channel all set up for your users. Because who doesn’t want a stream fully dedicated to ducks?</p>

<p>Now, your app isn’t going to <a href="https://www.newsweek.com/twitter-fleets-reactions-memes-edit-button-1548037">be like Twitter</a>. We can edit stuff here. Let’s show how to edit your post’s caption. Stories tho? That’s on you</p>

<figure><pre><code data-lang="javascript"><span>// update the post’s caption</span>
<span>const</span> <span>post</span> <span>=</span> <span>await</span> <span>postsCollection</span><span>.</span><span>update</span><span>(</span><span>post</span><span>.</span><span>documentId</span><span>,</span> <span>{</span>
  <span>caption</span><span>:</span> <span>"</span><span>These ducks are MEGA cute</span><span>"</span><span>,</span>
<span>});</span></code></pre></figure>

<p>The above was just a quick tour on how to do a few data API calls for a basic TikTok clone. Want to see the full thing? Check out <a href="https://www.youtube.com/watch?v=IATOicvih5A">Ania Kubow</a>’s tutorial to see how to wire this up into a full React app with Netlify.</p>

<h2 id="whats-next">What’s next?</h2>

<p>For more examples, we have hands-on tutorials for using <a href="https://www.datastax.com/dev/rest">Stargate’s REST</a>, <a href="https://www.datastax.com/dev/documents-api">Document</a> and <a href="https://www.datastax.com/dev/graphql">GraphQL APIs</a>. Check ‘em out and let us know what you think.</p>

<p>Have an app idea or want to join the fun? <a href="https://discord.gg/2Xt8QNyFZA">You can join the Stargate community, too</a>.</p>

<p>We would love to see how you customize your TikTok clone to show off more ways to feature data in your app. Or, you can create your own non-TikTok example. We would love to showcase your example in our <a href="https://astra.datastax.com/sample-app-gallery">sample app gallery</a>, so tell us about it in <a href="https://discord.gg/33mKDHHFUE">our contribute channel</a>.</p>

<h2 id="so-you-are-down-here-looking-for-a-few-more-details">So, you are down here looking for a few more details</h2>
<p>If you came down here, maybe you are looking for a few more lines of code.</p>

<p>No problem.</p>

<p>Let’s show how to set up the node JS client and a few more data API calls. For starters, let’s take a look at how to set up your client to connect to Stargate in Astra.</p>

<figure><pre><code data-lang="javascript"><span>// npm install @astrajs/collections</span>
<span>const</span> <span>{</span> <span>createClient</span> <span>}</span> <span>=</span> <span>require</span><span>(</span><span>"</span><span>@astrajs/collections</span><span>"</span><span>);</span>

<span>// create an Astra client</span>
<span>const</span> <span>astraClient</span> <span>=</span> <span>await</span> <span>createClient</span><span>(</span>
<span>{</span>   <span>astraDatabaseId</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_ID</span><span>,</span>
    <span>astraDatabaseRegion</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_REGION</span><span>,</span>
    <span>username</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_USERNAME</span><span>,</span>
    <span>password</span><span>:</span> <span>process</span><span>.</span><span>env</span><span>.</span><span>ASTRA_DB_PASSWORD</span><span>,</span>
<span>});</span></code></pre></figure>

<p>Easy enough.</p>

<p>Then, let’s create a users collection in our database to store documents about our TikTok users:</p>

<figure><pre><code data-lang="javascript"><span>// create the users collection in the app</span>
<span>const</span> <span>usersCollection</span> <span>=</span> <span>astraClient</span><span>.</span><span>namespace</span><span>(</span><span>"</span><span>tikTokClone</span><span>"</span><span>).</span><span>collection</span><span>(</span><span>"</span><span>users</span><span>"</span><span>);</span></code></pre></figure>

<p>A TikTok user in our app will have the basics: a unique id, a name, username, etc.</p>

<figure><pre><code data-lang="javascript"><span>const</span> <span>userData</span> <span>=</span> <span>{</span>
  <span>"</span><span>id_3</span><span>"</span><span>:</span> <span>"</span><span>0</span><span>"</span><span>,</span>
  <span>"</span><span>name</span><span>"</span><span>:</span> <span>"</span><span>Mo Farooq</span><span>"</span><span>,</span>
  <span>"</span><span>username</span><span>"</span><span>:</span> <span>"</span><span>mofarooq32</span><span>"</span><span>,</span>
  <span>"</span><span>avatar</span><span>"</span><span>:</span> <span>"</span><span>https://i.imgur.com/9KYq7VG.png</span><span>"</span>
<span>};</span></code></pre></figure>

<p>So, let’s add our user into our collection:</p>

<figure><pre><code data-lang="javascript"><span>// create a new user</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>create</span><span>(</span><span>userData</span><span>);</span></code></pre></figure>

<p>You can check to make sure your user was stored in the database by reading the user back by any of their properties, like their username.</p>

<figure><pre><code data-lang="javascript"><span>// find our user by username</span>
<span>const</span> <span>users</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>find</span><span>({</span> <span>username</span><span>:</span> <span>{</span> <span>$eq</span><span>:</span> 
  <span>"</span><span>mofarooq32</span><span>"</span> <span>}</span> <span>});</span></code></pre></figure>

<p>Or, you can lookup a user by their <strong>documentId</strong>:</p>

<figure><pre><code data-lang="javascript"><span>// get the user by document id</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>get</span><span>(</span><span>user</span><span>.</span><span>documentId</span><span>);</span></code></pre></figure>

<p>And, lastly, if you need to delete that user:</p>

<figure><pre><code data-lang="javascript"><span>// delete the post</span>
<span>const</span> <span>user</span> <span>=</span> <span>await</span> <span>usersCollection</span><span>.</span><span>delete</span><span>(</span><span>user</span><span>.</span><span>documentId</span><span>);</span></code></pre></figure>

<p>Want to see the full code? Check out <a href="https://github.com/kubowania/stargate-tik-tok">Ania Kubow’s app</a> to get all the goodness and start customizing it on your own. Let me know when you have stories up and I can subscribe to your ducks channel.</p>

<p>Thank you for following along all the way down here.</p>

<p>Happy building!</p>


        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://stargate.io/2020/12/09/announcing-stargate-10-ga-rest-graphql-schemaless-json-for-your-cassandra-development.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362944</guid>
            <pubDate>Wed, 09 Dec 2020 19:11:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Code Review Best Practices – Lessons from the Trenches]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25362375">thread link</a>) | @eric_cartman
<br/>
December 9, 2020 | https://blogboard.io/blog/code-review-best-practices | <a href="https://web.archive.org/web/*/https://blogboard.io/blog/code-review-best-practices">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1516259762381-22954d7d3ad2?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDd8fGNvZGV8ZW58MHx8fA&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Code Review Best Practices - Lessons from the Trenches">
            </figure>

            <section>
                <div>
                    <p>There's a ton of resources scattered around the web dealing with code review fundamentals, best practices, tools, etc. In this article we'll summarize the lessons from a dozen of official company engineering blogs. You can find links to the original articles in <a href="http://localhost:8080/blog/code-reviews"></a><a href="https://blogboard.io/search?searchQuery=code%20review">this blogboard search</a>.</p><h2 id="what-s-in-this-article">What's in this article?</h2><p>We'll cover several topics:</p><ol><li>Why do code reviews?<br>Besides the obvious, quality assurance, there are other benefits to code reviews</li><li>Code reviews as quality assurance<br>We'll cover the general recommendations on what to look for in a code review, why having a review checklist is beneficial, and you'll get a fairly long checklist that you can use as a base for your own list</li><li>Code reviews as a team improvement tool<br>If you've done more than a few code reviews, you know they're useful for more than just preventing bugs. We'll summarize common views on how reviews are beneficial as a learning and team bonding tool</li><li>Preparing a pull request for review<br>Lessons for pull request authors. There are rules of thumb consistently pointed out that help to prepare a PR for a smooth review</li><li>Reviewing code - Be human!<br>Lessons for reviewers on how wording and tone of your comments can make a huge difference in effectiveness of the whole review effort.</li></ol><p>The topics are covered fairly independently, so if you're curious about a particular topic feel free to skip ahead.</p><h2 id="why-do-code-reviews">Why do code reviews?</h2><p>It should be obvious that the primary purpose of code review is to assess quality of the changes being introduced. I mean, the dictionary definition of <em>review </em>says precisely that</p><blockquote><strong>review</strong> <em>(noun) - </em>a formal assessment of something with the intention of instituting change if necessary.</blockquote><p>Of course, code being code, there's a lot of things that can be checked and tested automatically, so there's nuance to what actually needs to be checked in an actual code review. We cover that in the next section.</p><p>On the other hand, code review is a form of communication between the <em><strong>author</strong> </em>of the change (these days usually <em>a pull request</em>) and one or several <em><strong>reviewers</strong>. </em>So it has side effects that go beyond preventing bugs from slipping in or keeping the codebase consistent in terms of style and architecture. </p><p>When done well, code reviews help accelerate learning across the team, create psychological safety for all team members, help establish and communicate best practices, teach proper communication and improve team dynamics. When done poorly, they can help deteriorate all of the above.</p><h2 id="code-reviews-as-quality-assurance">Code reviews as quality assurance </h2><p>There are a bunch of ways in which code reviews help maintain the quality bar for the codebase and the product. In the end it comes down to catching mistakes at the level which can hardly be automatically tested, such as architectural inconsistencies. Also, the code for automated tests should be reviewed, so there's a meta level at which reviews help with QA. </p><p>In <a href="https://engineering.gusto.com/high-leverage-code-reviews/">Giving High Leverage Code Reviews</a>, Casey Rollins advocates for having a checklist with all the usual things that need attention. </p><blockquote>When I’m reviewing a pull request, I often do multiple “passes” where I focus on one attribute at a time. I start at the beginning and review the pull request with a single attribute in mind before moving on to the next. When I’ve worked through the checklist, I submit the review.<p>This checklist moves from general to specific checks because it’s important to focus on the high-level attributes first. It doesn’t make sense to offer a variable name suggestion if you’re also suggesting that an entire class or function be refactored.</p></blockquote><p>You can have your own checklist or make it a shared list for the team or a project. There's a ton of material written on the usefulness of checklists. In <em><a href="https://en.wikipedia.org/wiki/Getting_Things_Done">Getting Things Done</a>, </em>David Allen puts forward a simple idea -<em> </em>our minds are great at processing information, but terrible at storing and recalling it. That's why checklists are a great way of externally storing and breaking down a planned or repetitive task.</p><p>Compiled from several articles (<a href="https://medium.com/paypal-engineering/effective-code-reviews-53d62a203b2f">1</a>, <a href="https://engineering.gusto.com/high-leverage-code-reviews/">2</a>, <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">3</a>) here's a high-level list of things to be concerned about when reviewing a code change:</p><ul><li>Story alignment - does the change meet the requirements of the task at all; ie. does the code implement any and all of the specified functionalities?</li><li>Consistency across the codebase</li><li>Architectural considerations - how does the new piece of code fit the existing architecture. Can the new feature architecture be improved, is it too generic or not extensible enough?</li><li>Simplicity/over-engineering</li><li>Performance concerns - are there specific cases (eg. peak load times) when the code will break? Do the queries pull more data than necessary? Could new queries benefit from adding new indexes to the database?</li><li>Accidental errors such as typos or errors in math formulas - these can be either obvious or really tricky to notice, especially with math heavy code</li><li>Compliance with laws and regulations - depending on the business this might be the most important thing</li><li>Security concerns - are there any exploitable pieces of code being introduced? Are any secrets being shared or stored unsafely?</li><li>Readability and style - a seemingly perfect piece of code might not be immediately understandable and readable to a different pair of eyes. Is it possible to understand the changes without the author explaining them?</li><li>Best practices - programming languages usually have their best practices - are they met in the pull request? Also, with time any project, team and company will evolve their own set of best practices - code reviews are a way to enforce and spread knowledge about them</li><li>Localization - are all language dependent resources localized properly?</li><li>Dependencies - are there external libraries or APIs being introduced? Are there other simpler/faster/better ways to do this with different dependencies or without any?</li><li>Interactions and side effects - how does the new piece of code interact with the rest of the codebase; does the new function implementation break any existing functionality; are all relevant unit tests updated/added</li><li>Logging - it's practically impossible to debug server code properly without good logging. Is everything logged/traced correctly</li><li>Error handling - how are the errors handled on the backend; how are they communicated to the user; are fallbacks activated where possible?</li><li>Testability/Test coverage - is the new piece of code covered with automated tests? Have all the suspicious test cases been checked either automatically or manually? Is the code written in a way that's suitable for unit testing?</li><li>External documentation - in case it's necessary is the external documentation updated to reflect the change?</li></ul><p>It's a pretty long list. In addition to it, a recurring piece of advice is not to use code reviews in place of static code analysis tools. If your review is mostly about code formatting, variable naming and alphabetical ordering, it might be a good time to include an automated code analysis tool into your development workflow.</p><p>In <em><a href="https://medium.com/paypal-engineering/effective-code-reviews-53d62a203b2f">Effective Code Reviews: Bettering Products, Teams, and Engineers</a> </em>from PayPal engineering<em>, </em>Gabriel McAdams points out several important benefits of code reviews related to team dynamics:</p><ul><li>Team cohesion - by making everyone's code subject to peer review, code review process promotes <em>individual accountability, healthy conflict</em> and the idea that everyone's<em> working together</em> to make the product better. As said in <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">Code Review Best Practices</a>: <em>Code reviews are classless: being the most senior person on the team does not imply that your code does not need review.</em><br>In summary, McAdams puts it nicely: <em>Trust + healthy conflict + individual accountability + working together to better the team = team cohesion.</em></li><li>Free career improvement training - simply by virtue of reviewing other people's code you become more skilled at reading and understanding new code. I've heard it said that one of the foremost traits of great engineers is the ability to dive into and dissect a completely unfamiliar piece of code. Over time you learn how to spot common practices, little tricks, pieces of syntactic sugar, architectural abstractions and how to appreciate different mental models used to solve the same problem.</li></ul><p>In <a href="https://medium.com/palantir/code-review-best-practices-19e02780015f">Code Review Best Practices</a> from the Palantir Blog, Robert Fink lists several ways in which knowledge sharing and social side-effects happen via code reviews:</p><ul><li>Authors are motivated by the peer review process to do all the necessary pre-checks, tighten the loose ends and generally tidy up the code before sending to review</li><li>A code review explicitly communicates changes made to product functionality to team members</li><li>The author maybe used a technique, abstraction or an algorithm that reviewers are unfamiliar with. The opposite can also be the case - reviewers might be aware of a more appropriate way to solve a given problem</li><li>Positive communication strengthens social bonds within the team (might especially be true for remote teams)</li></ul><h2 id="preparing-a-pull-request-for-review-help-the-reviewer">Preparing a pull request for review - help the reviewer</h2><p>Code reviews should be seen as a team effort. Once you view them that way it becomes clear that both sides - the author and the reviewers - have their distinct sets of responsibilities.</p><p>In <a href="https://medium.engineering/the-code-review-mindset-3280a4af0a89">this short post</a> on Medium Engineering blog, Xiao Ma describes how a different perspective changes the way code reviews are done, how feedback is taken and how people on each side benefit by adopting a <em>positive mindset</em> about code reviews.</p><p>When we talk about the responsibilities of the pull request author, there are several key things recurring in all code review guides.</p><ol><li><strong>Make pull requests as atomic as possible</strong><br><a href="https://shopify.engineering/great-code-reviews">At Shopify</a> they advise to keep <em>your pull requests small </em>- it helps the reviewer dive into it and finish it as an atomic piece of work in their workday. In practice this can mean keeping your pull requests limited to <em>a single concern. </em>A single concern here means a single bug fix, a feature, an API change etc. Don't mix refactoring that doesn't alter behavior with bug fixes or new features. This is …</li></ol></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blogboard.io/blog/code-review-best-practices">https://blogboard.io/blog/code-review-best-practices</a></em></p>]]>
            </description>
            <link>https://blogboard.io/blog/code-review-best-practices</link>
            <guid isPermaLink="false">hacker-news-small-sites-25362375</guid>
            <pubDate>Wed, 09 Dec 2020 18:45:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New York Times Best Seller Business Book]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25361439">thread link</a>) | @dubeyaayush07
<br/>
December 9, 2020 | https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/ | <a href="https://web.archive.org/web/*/https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>December 08, 2020</p></header><section itemprop="articleBody"><h3>Oversimplified, Overgeneralized Rules to Make <del>Me</del> You Rich</h3>
<ul>
<li>It is good to be a contrarian but do you know what is even better? To be a contrarian contrarian and since according to an unrelated mathematical rule inverse of an inverse is equal to the same thing you should do what everyone is doing, that is buying my book.</li>
<li>Steve Jobs, Elon musk.</li>
<li><strong>PASSION</strong>, Do what you want, Quit your Job.</li>
<li>Case studies of why I am right based on misinterpretations of what really happened.</li>
<li>Correlation == Causation.</li>
<li>Cliched  general advice: Exercise, Brush Your teeth before bed, work hard to succeed, clean your room, etc.</li>
<li>Filler                 </li>
<li>Confirmation Bias, Anecdotal evidence.</li>
<li>Graphs, Plots(Who needs axes and scales), Math is on my side.</li>
<li>Random Philosophy detour which has nothing to do with my thesis</li>
<li>Arguments that look logical on paper but are just superficial overgeneralizations  targeted towards inexperienced individuals.</li>
<li>My life and how I applied these principles to get rich. People disagreed with me. I succeeded and now I am rich.</li>
</ul>
<hr>
<p>I wrote this post as a result of my frustration with popular business books and with non-fiction books in general. I am not saying every book is like this, some books are insightful and bring new ideas and perspectives to the table. But I have noticed that some authors have an idea and without fleshing it out and properly researching it they decide to write a book about it. Throw in cognitive dissonance, confirmation bias and an incompetent publishers and you have got yourself a popular non-fiction book. There is no peer review and if you sensationalize things you can earn a lot of money. </p>
<p>You cannot even trust books by experts in the field. I bought into the hype of the book Why We Sleep  by Matthew Walker the author seemed legit and well respected within his field. He even appeared on the Joe Rogan Experience. After reading the book I  began espousing the benefits of 8 hour sleep until I read <a href="https://guzey.com/books/why-we-sleep/">this</a> wonderful article by Alexey Guzey. So who should you trust? Should you stop reading non-fiction altogether? I suggest doing the opposite, read as much as you can and be wary of any broad sweeping statements. Even though some books might get something wrong, the good ideas are still valuable. And as with business you can only get better at it (i.e. filtering signal) by exposing yourself to more of it.</p></section><hr></article></div>]]>
            </description>
            <link>https://dubeyaayush07.github.io/deliberate-mistakes/new-york-times-best-seller-business-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25361439</guid>
            <pubDate>Wed, 09 Dec 2020 17:57:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief Goodbye to CentOS]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 151 (<a href="https://news.ycombinator.com/item?id=25359951">thread link</a>) | @notadeveloper
<br/>
December 9, 2020 | https://www.clementchiew.me/blog/blog-013 | <a href="https://web.archive.org/web/*/https://www.clementchiew.me/blog/blog-013">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<hr>
<header>
		
</header>

<p>The traditional CentOS Linux distribution as we know it is dead. Here is another drop in the ocean of opinion pieces that follow the news of its death. After cooling down from the initial rush of blood to my head, here is my take on this event.</p>

<h2>Why Did This Probably Happen</h2>
<p>With the advent of DevOps and SRE, businesses and startups are moving away from the old-school concept of traditional server clusters to running their applications on disposable containers. The trend is clear and true. Developers are increasingly less reliant on a tried-and-true Linux distribution that lasts for a decade. With containers, developers can develop, test, deploy, and rollback with blazing fast velocity.

</p><h2>How It Will Affect All of Us</h2>
<p>Without a doubt one of the most popular Linux distributions to ever exist, CentOS was prevalent among all kinds of computing systems ranging from simple database servers to billion-dollar computer clusters. There are countless organizations have made the business decision to keep using the traditional model, or organizations that do not require microservices at all. With CentOS drawn from below their feet, a lot of organizations will be forced to migrate to another option, or fork out a pretty penny for RHEL. Besides, on-prem deployment of any container orchestration tool still requires a stable Linux distribution.</p>

<p>The second ripple effect it will have is towards the skilled professionals who have spend decades on CentOS. Not every company is willing to pay up for RHEL or risk using CentOS Stream. For those who migrate to Debian or OpenSUSE, they will have to retrain and adapt with different tools.</p>

<h2>Questioning IBM/Red Hat Decisions</h2>
<p>The most obvious of them all was, was it necessary for CentOS to die? With CentOS Stream to track ahead of RHEL, it is still possible for CentOS to remain functional and serve its purpose. This is clearly a business decision to increase profits. It used to be that developers wanted to write for RHEL but did not want pay for it; CentOS filled that need. What also happened was that some companies decided that they wanted the free experience all the way. Red Hat now provides free use of the Red Hat Universal Base Image for developers. With this, companies no longer have an excuse.</p>

<p>Secondly, why the PR disaster? In hindsight, there is no way to deliver this news gently to the public. However, I felt that Red Hat gave the bird to the open source community, especially those who contributed to CentOS, by pulling the plug on Centos 8 towards the end of 2021. There wasn't even a courtesy to end it later then CentOS 7's EOL date, June 30th 2024. A raw-dogged "Pay up, now" to everyone. </p>

<p>Last of all, what is the next move from Red Hat/IBM? With CentOS gone, there is a huge vacuum for another to take its place. RHEL sources are still available and can still be repackaged. While Red Hat currently has massive influence over Linux in general, is this a arrogant statement proclaiming "Hey, you can't live without me"? Another ominuous take with conspiratorial undertones would be that Red Hat plans to eventually scrap the FOSS model, but I would have to wear my tin hat for this one.

</p><h2>So, What Happens Now?</h2>
<p>Almost immediately after the release, all the attention is now directed to towards filling the space that CentOS will leave behind. Undoubtedly, Ubuntu and SUSE would try to assert their presence with their open source alternatives. Debian, the largest behemoth of them all, hopefully will receive funding and participation like never before. A silver lining of this event would perhaps be the buzzing excitement of what will be and can be. It is time to be excited about Linux again. I, for one, have to begin migrating my CentOS containers and virtual machines to Debian.</p>

<p>CentOS's founder, Gregory Kurtzer, is working with the community to establish Rocky Linux. Join them at https://webchat.freenode.net/#rockylinux .</p>
<hr>
<blockquote>
I doubt that the imagination can be suppressed. If you truly eradicated it in a child, he would grow up to be an eggplant.
<br>
- Ursula K. Le Guin
</blockquote>
</div>]]>
            </description>
            <link>https://www.clementchiew.me/blog/blog-013</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359951</guid>
            <pubDate>Wed, 09 Dec 2020 15:58:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DAML: A Haskell-Based Language for Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25359249">thread link</a>) | @NaeosPsy
<br/>
December 9, 2020 | https://serokell.io/blog/daml-interview | <a href="https://web.archive.org/web/*/https://serokell.io/blog/daml-interview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Digital Asset is a fintech company that helps companies design and run the next generation of business applications. One of their products is <a href="https://daml.com/">DAML</a>, a functional smart contract language.</p><p>While we have already covered Digital Asset in our <a href="https://serokell.io/blog/functional-programming-in-fintech">functional programming in fintech overview</a>, I recently got a chance to talk with Anthony Lusardi, a developer advocate at DAML, and delve deeper into the product. In the interview, we talk about DAML, the benefits and downsides of functional programming languages, and their practical experience while building DAML.</p><p><strong>Hi! Could you shortly explain what DAML is?</strong></p><p>Sure! DAML is an open-source smart contract language with roots firmly planted in Haskell. It’s designed so multiple parties/business entities can perform workflows with high assurances and consistency between parties. So you have this transactional language that is atomic with every update, high level, portable across data persistence backends, and with strongly enforced permissions over who can update data when.</p><p>In more practical terms, imagine you’re managing an operationally complex workflow where multiple different stakeholders (ie. parties) need to see and interact with different parts of the workflow, definitely should not see other parts, and have a complex tree of dependencies. Today implementing such a thing is truly hard to manage with complex access control schemes implemented at a level outside of your program, and substantial difficulties maintaining data privacy. DAML treats these concerns as first-class elements of every class (what DAML calls templates) and thus makes it much easier to implement and manage these types of workflows.</p><p><strong>Why should customers choose DAML over building their project on Ethereum, Tezos, or other public blockchains?</strong></p><p>This really boils down to their needs. If you’re building something that truly needs permissionless, censorship-resistant, and entirely public transactions, then a public blockchain might be a good fit despite what would be substantial tradeoffs for most real-world applications in terms of low data storage, poor privacy, and high cost. DAML, on the other hand, won’t give you a permissionless architecture but will allow you to have high data storage, strong privacy, and significantly lower costs.</p><p>In practice, very few use cases actually need the properties of a permissionless public blockchain. The one that comes to mind for me where a public blockchain is a better fit would be Bitcoin for permissionless value storage/transfer.</p><p>While I think there are some interesting projects on Ethereum, I’m not personally convinced most use cases need Ethereum’s architecture as, with a few exceptions, most have components that in practice are replaceable and centrally administered by their development team. In such cases, these teams are trading off ease of operation for decentralized architectures and really getting neither. That is, of course, open for extensive theoretical debate that is well beyond the scope of this interview :)</p><p><strong>What’s the main thing that separates DAML from other enterprise blockchain platforms like Corda and Hyperledger Fabric?</strong></p><p>DAML applications can be written once and deployed on any supported platform without changing a single line of code. In this way, your code written in DAML is decoupled from the underlying backend allowing for much greater architectural flexibility.</p><p>In fact, DAML actually runs on these platforms (and many others) with a runtime that runs alongside them and uses them for data persistence and consensus. It’ll even run on PostgreSQL. It’s truly platform-agnostic.</p><p><strong>What’s the benefit of basing DAML on functional programming languages like Haskell and Scala?</strong></p><p>Simple. Functional programmers are the best programmers.</p><p>More seriously, though, the language is based on Haskell but has conventions and differences that make it uniquely its own language. The general benefits are a high degree of composability, as anyone who writes in functional languages knows, when your types match your functions and components can easily work together and extend each other. Functional languages are also beneficial for the more distributed applications that DAML is designed for because they reduce bugs and allow for better ensuring that operations will or won’t complete; both of which are big concerns whenever you’re writing a distributed application.</p><p><strong>Are there any features of the language that really help smart contract language development?</strong></p><p>Most definitely. DAML has two features that really help. The first is that all data concerns are laid out in templates and strongly typed. In a lot of ways, these templates are much like classes in imperative languages <strong><em>but</em></strong> they will always do what you expect them to.</p><p>The other feature (and this is really smart-contract specific) is that DAML treats permissions as first-class citizens, so we have observers, signatories, and choices which you can consider respectively akin to UNIX’s <code>rwx </code>permissions. Every template specifies ahead of time who has the authority to read, write, and execute functions on a given instance of that template (what we call a contract in DAML).</p><p><strong>Have you seen any non-technical benefits? ( e.g. is it easier to hire good developers, etc.)</strong></p><p>Reductions in codebase size and operational complexity are definitely benefits. It’s really designed from the ground up to allow developers to focus solely on business logic without having to worry about the backend. These factors, in turn, make DAML applications cheaper to maintain and easier to extend. Basically, all the benefits functional programmers have been touting for a long time.</p><p>One other great benefit is readability. While it takes a programmer to write DAML, many non-programmers can comprehend much of a DAML contract with just a little bit of familiarization. This really comes as a direct consequence of how explicit DAML is about data concerns and permissions. You can check out an example of this readability at <a href="https://beer.woah.xyz/">https://beer.woah.xyz</a>.</p><p><strong>What about downsides? Are there any downsides to choosing a programming language for your project that is not that popular?</strong></p><p>There certainly are, but if you’re reading this blog post, then you probably already use non-mainstream programming languages that are still wonderful and let you get your work done in effective ways that mainstream languages don’t support. Innovation happens at the edges so I think DAML’s benefits in the smart contract space and its enthusiastic and supportive engineers on our forum more than outweigh the tradeoffs.</p><p>Really the biggest concern people have is essentially “if I choose to invest time in learning this language, will it still be there next year?” and for that, the answer is yes. DAML is an open-source language maintained by Digital Asset, which is a company of 140+ people currently and growing. DAML will be here for years to come.</p><p><strong>Do you feel happy about your choice to create an FP language for your project?</strong></p><p>I don’t think you could build a non-functional language that accomplished what DAML does. It’s really a prerequisite for the rest of the stack. So in that sense, yes, and also the decision was made well before I joined Digital Asset.</p><p><strong>If you had to give one tip to customers looking to come into the blockchain/DLT space, what would it be?</strong></p><p>If the app needs you to first buy a token to use it, then run away.</p><hr><p>I would like to thank Anthony for the interview and wish DAML the best of luck in conquering the private blockchain market!</p><p>If you wish to get more details on DAML, go straight to their <a href="https://daml.com/">homepage</a>. You can also follow DAML on <a href="https://twitter.com/damldriven">Twitter</a> for updates and cool blog articles.</p><p>For more interviews with interesting projects in the functional programming space, be sure to check out the <a href="https://serokell.io/blog/interviews">interview</a> section of our blog.</p></div></div>]]>
            </description>
            <link>https://serokell.io/blog/daml-interview</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359249</guid>
            <pubDate>Wed, 09 Dec 2020 15:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube to remove content that alleges widespread election fraud]]>
            </title>
            <description>
<![CDATA[
Score 972 | Comments 2562 (<a href="https://news.ycombinator.com/item?id=25359003">thread link</a>) | @1cvmask
<br/>
December 9, 2020 | https://blog.youtube/news-and-events/supporting-the-2020-us-election | <a href="https://web.archive.org/web/*/https://blog.youtube/news-and-events/supporting-the-2020-us-election">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="-1">
            
  <article>
    
    


<div>

<section>
    
    <div>
      
      
      <p>
        <article>
          Updates to our work supporting the integrity of the 2020 U.S. election.
        </article>
      </p>
    </div>
  </section>
</div>


    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><p>Over the past weeks and months, we’ve seen people coming to YouTube to learn more about where and how to vote or learning more about a candidate or an issue. We’ve seen news organizations grow their audience. And we’ve seen people turn to YouTube for the latest election results or simply to follow an historic event with the highest voting turnout in over a century in the U.S.&nbsp;&nbsp;</p><p>Our main goal going into the election season was to make sure we’re connecting people with authoritative information, while also limiting the reach of misinformation and removing harmful content. The work here is ongoing and we wanted to provide an update.&nbsp;&nbsp;</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="paragraph">
  <div>
    
    <div>
      <div>
        <div><h2>Removing content that violates our policies</h2><p>Our <a href="https://www.youtube.com/howyoutubeworks/policies/community-guidelines/">Community Guidelines</a> prohibit spam, scams, or other manipulated media, coordinated influence operations, and any content that seeks to incite violence. Since September, we've terminated over 8000 channels and thousands of harmful and misleading elections-related videos for violating our existing policies. Over 77% of those removed videos were taken down before they had 100 views.&nbsp;</p><p>We also work to make sure that the line between what is removed and what is allowed is drawn in the right place. Our policies prohibit misleading viewers about where and how to vote. We also disallow content alleging widespread fraud or errors changed the outcome of a historical U.S. Presidential election. However in some cases, that has meant allowing controversial views on the outcome or process of counting votes of a current election as election officials have worked to finalize counts.&nbsp;</p><p>Yesterday was the safe harbor deadline for the U.S. Presidential election and enough states have certified their election results to determine a President-elect. Given that, we will start removing any piece of content uploaded today (or anytime after) that misleads people by alleging that widespread fraud or errors changed the outcome of the 2020 U.S. Presidential election, in line with our approach towards historical U.S. Presidential elections. For example, we will remove videos claiming that a Presidential candidate won the election due to widespread software glitches or counting errors. We will begin enforcing this policy today, and will ramp up in the weeks to come. As always, news coverage and commentary on these issues can remain on our site if there’s sufficient <a href="https://blog.youtube/inside-youtube/look-how-we-treat-educational-documentary-scientific-and-artistic-content-youtube/">education, documentary, scientific or artistic</a> context.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/MostViewed-Elections-Blog_Lists_AddedBorder.png" alt="most viewed u.s. election-related content">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><h2>Connecting people to authoritative information</h2><p>While only a small portion of watch time is election-related content, YouTube continues to be an important source of election news. On average 88% of the videos in top 10 search results related to elections came from authoritative news sources (amongst the rest are things like newsy late-night shows, creator videos and commentary). And the most viewed channels and videos are from news channels like NBC and CBS.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Election_Results_Blog_437_x_879_1.gif" alt="election results gif">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>We also showed information panels linking both to Google’s election results feature, which sources election results from The Associated Press, and to the Cybersecurity &amp; Infrastructure Security Agency’s (CISA) “Rumor Control” page for debunking election integrity misinformation, alongside these and over 200,000 other election-related videos. Collectively, these information panels have been shown over 4.5 billion times. Starting today, we will update this information panel, linking to the “2020 Electoral College Results” page from the Office of the Federal Register, noting that as of December 8, states have certified Presidential election results, with Joe Biden as the President-elect. It will also continue to include a link to CISA, explaining that states certify results after ensuring ballots are properly counted and correcting irregularities and errors.</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Fact_Check_Dominion_voting__Michigan_recount.png" alt="fact check">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>Additionally, since Election Day, relevant <a href="https://blog.youtube/news-and-events/expanding-fact-checks-on-youtube-to-united-states">fact check information panels</a>, from third party fact checkers, were triggered over 200,000 times above relevant election-related search results, including for voter fraud narratives such as “Dominion voting machines” and “Michigan recount.”</p></div>
      </div>
      
    </div>
  </div>
</section>

      
    
      
        



<section data-component="yt-paragraph-media" data-media-type="image_paragraph">
  <div>
    <div>
      
        <div>
          
              <p><img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Recommended-Elections-Blog_Lists_AddedBorder.png" alt="most recommended u.s. election-related content">
                
              
              </p>
          
          

          
        </div>
        
      
    </div>
    <div>
      <div>
        <div><p>Now let’s look at recommendations, one of the main ways our viewers find content. Limiting the reach of borderline content and prominently surfacing authoritative information are important ways we protect people from problematic content that doesn’t violate our Community Guidelines. Over 70% of recommendations on election-related topics came from authoritative news sources and the top recommended videos and channels for election-related content were primarily authoritative news. In fact, the top 10 authoritative news channels were recommended over 14X more than the top 10 non-authoritative channels on election-related content.&nbsp;</p><p>Despite these encouraging results, we recognize there's always more to do. For example, while problematic misinformation represents a fraction of 1% of what's watched on YouTube in the U.S., we know we can bring that number down even more. And some videos, while not recommended prominently on YouTube, continue to get high views, sometimes coming from other sites. We're continuing to consider this and other new challenges as we make ongoing improvements.&nbsp;</p><p>We understand the need for intense scrutiny on our elections-related work. Our teams work hard to ensure we are striking a balance between allowing for a broad range of political speech and making sure our platform isn't abused to incite real-world harm or broadly spread harmful misinformation. We welcome ongoing debate and discussion and will keep engaging with experts, researchers and organizations to ensure that our policies and products are meeting that goal. And as always, we'll apply learnings from this election to our ongoing efforts to protect the integrity of elections around the world.<br></p></div>
      </div>
      
    </div>
  </div>
</section>

      
    

    


<section>
  <article>
    
  </article>
</section>


    
    
  


  </article>


        </div></div>]]>
            </description>
            <link>https://blog.youtube/news-and-events/supporting-the-2020-us-election</link>
            <guid isPermaLink="false">hacker-news-small-sites-25359003</guid>
            <pubDate>Wed, 09 Dec 2020 14:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prisma Migrate is now ready]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25357937">thread link</a>) | @sorenbs
<br/>
December 9, 2020 | https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a | <a href="https://web.archive.org/web/*/https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><h2 id="contents"><a href="#contents" aria-label="contents permalink"></a>Contents</h2><ul><li><a href="#schema-migrations-with-prisma-migrate">Schema migrations with Prisma Migrate</a></li><li><a href="#how-does-prisma-migrate-work">How does Prisma Migrate work?</a></li><li><a href="#what-has-changed-since-the-experimental-version">What has changed since the Experimental version?</a></li><li><a href="#whats-next">What's next</a></li><li><a href="#try-prisma-migrate-and-share-your-feedback">Try Prisma Migrate and share your feedback</a></li></ul><h2 id="schema-migrations-with-prisma-migrate"><a href="#schema-migrations-with-prisma-migrate" aria-label="schema migrations with prisma migrate permalink"></a>Schema migrations with Prisma Migrate</h2><p>Today we're excited to share the new version of Prisma Migrate! 🎊</p><p>Prisma Migrate is a data modeling and migrations tool that simplifies evolving the database schema with the application in-tandem. Migrate is based on the <a href="https://www.prisma.io/docs/concepts/components/prisma-schema#example">Prisma schema</a> – a declarative data model definition that codifies your database schema.</p><p>This Preview release is the evolution of the Experimental version of Migrate that we released last year. Since then, we've been gathering feedback from the community and incorporating it into Prisma Migrate.</p><h3 id="making-schema-migrations-predictable"><a href="#making-schema-migrations-predictable" aria-label="making schema migrations predictable permalink"></a>Making schema migrations predictable</h3><p>Database schema migrations play a crucial role in software development workflows and affect the most critical component in your application – the database. We've built Migrate to be predictable while allowing you to control how database schema changes are carried out.</p><p>Prisma Migrate generates migrations as plain SQL files based on changes in your Prisma schema. These SQL files are fully customizable and allow you to use any feature of the underlying database, such as manipulating data supporting a migration, setting up triggers, stored procedures, and views.</p><p>Prisma Migrate treads the balance between productivity and control by automating the repetitive and error-prone aspects of writing database migrations while giving you the final say over how they are executed.</p><h3 id="integration-with-prisma-client"><a href="#integration-with-prisma-client" aria-label="integration with prisma client permalink"></a>Integration with Prisma Client</h3><p>Prisma Migrate integrates with Prisma Client using the Prisma schema as their shared source of truth. In other words, both Prisma Client and migrations are generated based on the Prisma schema. This makes synchronizing and verifying database schema changes in your application code easier by leveraging Prisma Client's type safety.</p><h3 id="prisma-migrate-is-ready-for-broader-testing"><a href="#prisma-migrate-is-ready-for-broader-testing" aria-label="prisma migrate is ready for broader testing permalink"></a>Prisma Migrate is ready for broader testing</h3><p>Prisma Migrate has passed rigorous testing internally and is now ready for broader testing by the community. You can use it with PostgreSQL, MySQL, SQLite, and SQL Server. <strong>However, as a Preview feature, it is not fully production-ready yet.</strong> To read more about what Preview means, check out the <a href="https://www.prisma.io/docs/more/releases#preview">maturity levels</a> in the Prisma docs.</p><p>Thus, we're inviting you to try it out and <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">give us feedback</a> so we can bring Prisma Migrate to General Availability. 🚢</p><p>Your feedback and suggestions will help us shape the future of Prisma Migrate. 🙌</p><hr><h2 id="how-does-prisma-migrate-work"><a href="#how-does-prisma-migrate-work" aria-label="how does prisma migrate work permalink"></a>How does Prisma Migrate work?</h2><p>Prisma Migrate is based on the <a href="https://www.prisma.io/docs/reference/tools-and-interfaces/prisma-schema">Prisma schema</a> and works by generating <code>.sql</code> migration files that are executed against your database.</p><p>The Prisma schema is the starting point for schema migrations and provides an overview of your desired end-state of the database. Prisma Migrate inspects changes in the Prisma schema and generates the necessary <code>.sql</code> migration files to apply.</p><p>Applying migrations looks very different depending on the stage of development. For example, during development, there are scenarios where resetting the database can be tolerated for quicker prototyping, while in production, great care must be taken to avoid data loss and breaking changes.</p><p>Prisma Migrate accommodates for this with workflows for local development and applying migrations in production.</p><h3 id="evolving-the-schema-in-development"><a href="#evolving-the-schema-in-development" aria-label="evolving the schema in development permalink"></a>Evolving the schema in development</h3><p>To use the new version of Prisma Migrate, you should have at least version <code>2.13.0</code> of the <a href="https://www.prisma.io/docs/concepts/components/prisma-cli/installation"><code>@prisma/cli</code></a> package installed.</p><p>During development, you first define the Prisma schema and then run the <code>prisma migrate dev --preview-feature</code> command, which generates the migration, applies it, and generates Prisma Client:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/9dee8cc50b930a017447904d95e15e0e82f9a3bf/426d4/blog/posts/2020-12-migrate-development-workflow.png" alt="Development workflow"><span>Development workflow</span></span></p><p>Here is an example showing it in action:</p><p><strong>1. Define your desired database schema using the Prisma schema:</strong></p><pre><code><span>datasource</span> <span>db</span> <span>{</span>
  provider <span>=</span> <span>"postgresql"</span>
  url      <span>=</span> <span>env</span><span>(</span><span>"DATABASE_URL"</span><span>)</span>
<span>}</span>

<span>model</span> <span>User</span> <span>{</span>
  id    <span>Int</span>      <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  name  <span>String</span>
  posts <span>Post</span><span>[</span><span>]</span>
<span>}</span>

<span>model</span> <span>Post</span> <span>{</span>
  id        <span>Int</span>     <span>@id</span> <span>@default</span><span>(</span><span>autoincrement</span><span>(</span><span>)</span><span>)</span>
  title     <span>String</span>
  published <span>Boolean</span> <span>@default</span><span>(</span><span>true</span><span>)</span>
  authorId  <span>Int</span>
  author    <span>User</span>    <span>@relation</span><span>(</span><span>fields:</span> <span>[</span>authorId<span>]</span><span>,</span> <span>references:</span> <span>[</span>id<span>]</span><span>)</span>
<span>}</span>
</code></pre><p><strong>2. Run <code>prisma migrate dev --preview-feature</code> to create and execute the migration.</strong></p><div><div><svg width="6" height="9" viewBox="0 0 6 9" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M7.3273 0C7.88605 0 8.20036 0.653318 7.85732 1.1017L4.53001 5.45076C4.26119 5.80213 3.73881 5.80213 3.46999 5.45076L0.142684 1.1017C-0.200356 0.653318 0.113948 0 0.672698 0H7.3273Z" transform="rotate(-90 4.5 4.357)" fill="#8FA6B2"></path></svg><p><label for="tab-1">Expand to view the SQL contents of the generated migration</label></p><div><pre><code>
<span>CREATE</span> <span>TABLE</span> <span>"User"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"name"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>CREATE</span> <span>TABLE</span> <span>"Post"</span> <span>(</span>
  <span>"id"</span> <span>SERIAL</span><span>,</span>
  <span>"title"</span> <span>TEXT</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>"published"</span> <span>BOOLEAN</span> <span>NOT</span> <span>NULL</span> <span>DEFAULT</span> <span>true</span><span>,</span>
  <span>"authorId"</span> <span>INTEGER</span> <span>NOT</span> <span>NULL</span><span>,</span>
  <span>PRIMARY</span> <span>KEY</span> <span>(</span><span>"id"</span><span>)</span>
<span>)</span><span>;</span>

<span>ALTER</span> <span>TABLE</span> <span>"Post"</span> <span>ADD</span> <span>FOREIGN</span> <span>KEY</span><span>(</span><span>"authorId"</span><span>)</span><span>REFERENCES</span> <span>"User"</span><span>(</span><span>"id"</span><span>)</span> <span>ON</span> <span>DELETE</span> <span>CASCADE</span> <span>ON</span> <span>UPDATE</span> <span>CASCADE</span><span>;</span>
</code></pre></div></div></div><p>After the migration has been executed, the migration files are typically committed to the repository so that the migration can be applied in other environments.</p><p>Further changes to the database schema follow the same workflow and begin with updating the Prisma schema.</p><h3 id="customizing-sql-migrations"><a href="#customizing-sql-migrations" aria-label="customizing sql migrations permalink"></a>Customizing SQL migrations</h3><p>You can customize the migration SQL with the following workflow:</p><ol><li>Run <strong><code>prisma migrate dev --create-only --preview-feature</code></strong> to create the SQL migration without applying it.</li><li>Edit the migration SQL.</li><li>Run <strong><code>prisma migrate dev --preview-feature</code></strong> to apply it.</li></ol><h3 id="applying-migrations-in-production-and-other-environments"><a href="#applying-migrations-in-production-and-other-environments" aria-label="applying migrations in production and other environments permalink"></a>Applying migrations in production and other environments</h3><p>To apply migrations to other environments such as production, you pull changes to the repository containing the migrations and run the <code>prisma migrate deploy</code> command:</p><p><span><img src="https://d33wubrfki0l68.cloudfront.net/5d9831941c87b7e24646bca3d96f91d4b799af6a/b7004/blog/posts/2020-12-migrate-production-workflow.png" alt="Production workflow"><span>Production workflow</span></span></p><hr><h2 id="what-has-changed-since-the-experimental-version"><a href="#what-has-changed-since-the-experimental-version" aria-label="what has changed since the experimental version permalink"></a>What has changed since the Experimental version?</h2><p>The most significant change since the Experimental version is the use of SQL as the format for migrations, making migrations <strong>deterministic</strong>. In other words, the exact steps of the migration are determined when the migration is created, allowing you to inspect the SQL (and make changes if necessary) before running.</p><p>This approach has the following benefits:</p><ul><li>The generated SQL is editable, thereby allowing you to control the exact schema changes.</li><li>The migration is predictable with the exact SQL that will be applied.</li><li>You don't need to write SQL unless you want to change a migration.</li><li>You can perform data migrations using SQL as part of a migration.</li></ul><p>Editable SQL for migrations is useful in scenarios where there are multiple ways to map changes in the Prisma schema to the database, and the desired path cannot be automatically determined.</p><p>For example, when you rename a field in the Prisma schema, that can be interpreted as either deleting the column and adding an unrelated new one or as you renaming the column. By allowing you to inspect and edit the migration SQL, you can decide whether to rename the column (and retain the data in the column) or drop it and add a new one.</p><p>If you're upgrading Prisma Migrate from the Experimental version, check out the <a href="https://www.prisma.io/docs/guides/prisma-guides/prisma-migrate-guides/add-prisma-migrate-to-a-project">upgrade guide</a>.</p><hr><h2 id="whats-next"><a href="#whats-next" aria-label="whats next permalink"></a>What's next</h2><p>This Preview version of Prisma Migrate lays the foundations for the upcoming General Availability release. Some of the improvements we are considering are improved support for native database types, seeding functionality, and finding a way to make database resets in development less disruptive.</p><h3 id="native-database-types"><a href="#native-database-types" aria-label="native database types permalink"></a>Native database types</h3><p>One of the most requested features in Prisma is support for the database's native types. This release is a step closer to that – however, there's still more work to be done for native types to be fully supported.</p><p>Currently, the Prisma schema can only represent a limited set of types: <code>String</code>, <code>Int</code>, <code>Float</code>, <code>Boolean</code>, <code>DateTime</code>, and <code>Json</code>. Each of these types has a default mapping to an underlying database type that's specified for each database connector (see the mappings for <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a>).</p><p>In version <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/releases/tag/2.11.0">2.11.0</a>, we released the <code>nativeTypes</code> Preview feature – the ability to annotate fields in the Prisma schema with the specific native database type that it should be mapped to. <strong>However, the native types preview feature doesn't work with Prisma Migrate yet</strong>.</p><p>Even so, you can still change the types of columns in the generated SQL as long as they are supported, as documented in the <a href="https://www.prisma.io/docs/concepts/database-connectors/postgresql#prisma-migrate">PostgreSQL</a> and <a href="https://www.prisma.io/docs/concepts/database-connectors/mysql#prisma-migrate">MySQL</a> connector docs.</p><hr><p>We built Prisma Migrate for you and are keen to hear your feedback.</p><p>We want to understand how Prisma Migrate fits into your development workflow and how we can help you stay productive and confident while building and evolving data-centric applications.</p><p>🐛 Tried it out and found that it's missing something or stumbled upon a bug? Please <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/new/choose">file an issue</a> so we can look into it.</p><p>🏗 Share your feedback about how the new Prisma Migrate is working out for you on <a target="_blank" rel="noopener noreferrer" href="https://github.com/prisma/prisma/issues/4531">GitHub</a>.</p><p>🌍 Join us on our <a target="_blank" rel="noopener noreferrer" href="https://slack.prisma.io/">Slack</a> in the <a target="_blank" rel="noopener noreferrer" href="https://app.slack.com/client/T0MQBS8JG/C01ACF1DJ1M"><code>#prisma-migrate</code></a> channel for help.</p><p>👷‍♀️ We are thrilled to finally share the Preview version of Prisma Migrate and can't wait to see what you all build with it.</p></div></div></article></div>]]>
            </description>
            <link>https://www.prisma.io/blog/prisma-migrate-preview-b5eno5g08d0b?a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357937</guid>
            <pubDate>Wed, 09 Dec 2020 12:47:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games people play with cash flow]]>
            </title>
            <description>
<![CDATA[
Score 329 | Comments 126 (<a href="https://news.ycombinator.com/item?id=25357669">thread link</a>) | @kalonis
<br/>
December 9, 2020 | https://commoncog.com/blog/cash-flow-games/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/cash-flow-games/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <p>In my <a href="https://commoncog.com/blog/how-first-principles-thinking-fails/">last post</a> I examined how first principles thinking fails. This post is going to be about a single, concrete example — about an argument that started me down this path in the first place.</p><p>A couple of months ago, a friend sent me a blog post titled <em><a href="https://ensorial.com/2020/dont-raise-money/">Startups Shouldn’t Raise Money</a></em>, over at a website called ensorial.com. I thought that the post was tightly argued and reasonably put together, with each proposition leading logically and coherently to the next. I also noticed that the author had taken the time to construct their argument from first principles … which meant it was difficult to refute any individual clause in their chain of reasoning.</p><p>But I also thought it was wrong. I told my friend as much.</p><p>“How is it wrong?” he immediately challenged.</p><p>“Well …” I began. And then I stopped. I realised I didn’t have a good argument for <em>why</em> it was wrong. Every axiom and intermediate proposition were ideas that I agreed with. And it wasn’t so simple as the conclusion being flat out mistaken — you <em>could</em> probably run a small, successful internet business using the ideas laid out in the posts’s argument (internet-based businesses tend to be simpler to manage, and there are many niches you can occupy).</p><p>But I felt uneasy because I thought the framing wasn’t as <em>useful</em>. This was a more complex thing to debunk.</p><h2 id="the-setup">The Setup</h2><p>It’s easy to think that arguments have just three terminal truth values: right, maybe, and wrong. In practice, arguments (and in particular, the sort of argument that we use to justify actions) have many possible truth values. These include things like ‘got the details wrong, but is by-and-large correct’, or ‘is correct but for a <a href="https://commoncog.com/blog/the-right-level-of-abstraction/">different level of abstraction</a>; doesn’t apply here’, or ‘is partially correct, but isn’t as useful compared to a different framing of things.’ The ensorial.com piece is interesting because I think it is an instance of that last one. It was what pushed me to start thinking about all the various ways first principles thinking could go wrong.</p><p>The author’s argument unfolds as follows:</p><ol><li>Startups are risky.</li><li>Raising capital to do a startup reduces skin in the game (you’re spending other people’s money, after all).</li><li>Once you have less skin in the game, it is easier to make bad decisions. The author argues this is due to a) having a capital buffer to cushion you, and b) having more time to waste.</li><li>The alternative is to forego raising venture capital and to create a sustainable business from the beginning, ‘growing linearly with the number of people that give you money for your product.’</li><li>This aligns incentives: you grow only by solving customer problems that they would pay you for. And you’ll pick the shortest path, because you don’t have the luxury of time given to you by an infusion of other people’s money.</li><li>Therefore: startups shouldn’t raise money.</li></ol><p>At first glance, there doesn’t seem to be anything that’s explicitly <em>wrong</em> with this argument. I agree with all the base ideas, and I found myself nodding to the intermediate propositions. The logical correctness of the argument wasn’t a problem. No, my unease stemmed from experience: I <em>knew</em> this wasn’t the right way to think about raising capital. But I couldn’t begin to construct an argument that went against it.</p><figure><img src="https://commoncog.com/blog/content/images/2020/12/argument_chain.f369ba07141442ea959636c21f56e207.png" alt=""></figure><p>My friend and I spent no more than 10 minutes discussing this piece. But in the months after our conversation, I continued to return to the author’s argument. I thought it was interesting because it represented a type of thinking error that you and I are likely to encounter in our lives. The form of the error is subtle, and therefore more difficult to detect; the best description I have for it is: ‘perfectly rational, logically constructed, and not really <em>wrong</em> — but not as useful or as powerful as some other framing.’</p><p>Of course, my obsession was for instrumental reasons: how might you recognise a better framing when you found one? I’ll admit that I was a little naive here: I thought that if I could generalise the structure of this argument, I would be better able to recognise similar errors in the future. Alas, I have not been able to do this to my satisfaction.</p><p>(In practice, most of the older entrepreneurs I know seem to understand the problems with such sensemaking. Plausible arguments are dealt with in a simple manner: you try the recommendations that unfold from the analysis, but you remain alert to see if they give you exactly the results you want. If they don’t, you keep the frame for the time being, but you continue to look out for a better explanation. And how would you know if you have found a better way of thinking about your situation? Simple: you listen carefully. In the words of Malaysian magnate Robert Kuok, “you learn to distill wisdom from the air.”)</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>The most I’ve been able to do is to articulate <em>how</em> the author messed up — and therefore how first principles thinking may fail — something that I <a href="https://commoncog.com/blog/how-first-principles-thinking-fails/">explored in my previous post</a>. The core idea is simple: I believe the author started from a limited set of axioms. If you start from a wrong set of axioms, you would eventually end up with a flawed conclusion. In this case, I think the ensorial.com author started from a deficient understanding of business.</p><p>To generalise a little, people with limited understanding of business think that business is all about making profits. But those who actually run businesses know that running a business is all about managing cash flows.</p><p>And the ensorial.com author’s argument fails because he doesn’t appear to understand this.</p><h2 id="john-malone-and-the-invention-of-ebitda">John Malone and the Invention of EBITDA</h2><p>In 1972, a 32 year old man named John Malone was offered the top job at Tele-Communications Inc (TCI), a cable company. He took charge on April Fool’s Day, 1973.</p><p>At the time of his hiring, Malone was president of Jerrold Electronics, a division of General Instrument that supplied cable boxes and credit to the cable systems companies. He had been offered the Jerrold Electronics job when he was 29 years old, just two years earlier. Before JE, he was at McKinsey Consulting. And before McKinsey, he had a job at AT&amp;T’s famed Bell Labs, where he applied operations research to find optimal company strategies in monopoly markets. Malone concluded that AT&amp;T should increase its debt load and aggressively reduce its equity base through share repurchases — a highly unorthodox recommendation at the time. His advice was delivered to AT&amp;T’s board and then promptly ignored.</p><p>Malone had been thinking about the interplay between debt, profit, cash flow, and corporate taxes for some time. In 1972, when he was first offered the TCI job, he had already noticed a number of structural properties in the cable industry that piqued his interest:</p><ol><li>The cable industry had highly predictable subscription revenues. Cable television customers in the 60s — especially those in rural communities — were eager to upgrade to cable for better TV reception. These subscribers paid monthly fees and rarely cancelled.</li><li>Cable franchises were essentially a legal right to a local monopoly, which meant that cable system operators had limited competition once it established itself in a given locale.</li><li>The industry itself had very favourable tax characteristics — smart cable operators could shelter their cash flow from taxes by using debt to build new systems, and by aggressively depreciating the costs of construction. Once the depreciation ran out on particular systems, they could then sell them to another operator, where the depreciation clock would start anew.</li><li>Most importantly, the entire market was growing like a weed: over the course of the 60s and into the start of the 70s, subscriber counts had grown over twentyfold.</li></ol><p>Of course, Malone didn’t have much time to reflect on these observations. He landed at TCI and found the company at the brink of bankruptcy.</p><p>Bob Magness, the founder of TCI, had grown the company over the course of two decades using a ridiculous pile of debt — about 17 times revenues, at the time of Malone’s hiring. Malone spent his first couple of years at TCI fighting to keep the company alive. He flew into New York every couple of weeks, hat in hand, renegotiating <a href="https://www.investopedia.com/terms/c/covenant.asp">covenants</a> and asking for extensions on debt repayments. At one point during a meeting with TCI’s bankers, Malone threw his keys on the table and threatened to walk, leaving the company to the banks. The bankers capitulated, granting TCI a much needed extension.</p><p>Malone and Magness also had to worry about hostile takeovers, given TCI’s low stock price in the early 70s. They executed a series of complicated financial manoeuvres a year or so after Malone took over, placing a large chunk of stock in a holding company to grant them majority control. Later, they created a separate class of voting stock. These moves gave them hard control of the company, allowing Malone the freedom to focus on righting its finances.</p><p>After three years of hell, TCI was finally pulled back from the brink of financial disaster. And then Malone got to work.</p><p>Malone understood a few things about the cable industry that many outsiders didn’t. First, he understood that cable was like real estate: incredibly high fixed costs up front as you built or bought the systems, and then highly predictable, monopoly cash flows for a long time afterwards. He understood that if he used debt to finance acquisitions, he could keep growing the company, and use the depreciation on acquired systems (plus the write-offs from the loans itself) to delay paying taxes on that cash flow. Third, Malone understood that untaxed cash flows from all of those cable subscribers could be used to a) service the debt, b) pay down some of those loans — only when necessary; Malone wanted to keep the debt-to-earnings ratio at a five-to-one level — but more importantly c) demonstrate to creditors that TCI was a worthy debtor. And finally, Malone understood the benefits of size: the larger TCI got, the lower the cost of acquiring programming (i.e. shows and programs), because it could amortise those costs across its entire subscriber …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/cash-flow-games/">https://commoncog.com/blog/cash-flow-games/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/cash-flow-games/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357669</guid>
            <pubDate>Wed, 09 Dec 2020 11:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is the Google Cloud UI so slow?]]>
            </title>
            <description>
<![CDATA[
Score 468 | Comments 370 (<a href="https://news.ycombinator.com/item?id=25357409">thread link</a>) | @mostlystatic
<br/>
December 9, 2020 | https://www.debugbear.com/blog/slow-google-cloud-ui | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/slow-google-cloud-ui">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>Opening a page in the Google Cloud Console always takes a long time.</p>
<p>Here are some metrics I collected on a high-end 2018 MacBook Pro on a UK-based Gigabit internet connection.</p>

<div id="slow-gcp-table">
<table>
<thead>
<tr>
<th>Page</th>
<th>Download</th>
<th>JavaScript</th>
<th>CPU Time</th>
<th>Main Content</th>
<th>Fully Loaded</th>
</tr>
</thead>
<tbody>
<tr>
<td>Cloud Functions</td>
<td>4.2 MB</td>
<td>15.7 MB</td>
<td>5.3s</td>
<td>6.7s</td>
<td>8.1s</td>
</tr>
<tr>
<td>Compute Engine</td>
<td>4.5 MB</td>
<td>15.1 MB</td>
<td>6.5s</td>
<td>6.7s</td>
<td>8.1s</td>
</tr>
<tr>
<td>Cloud Storage</td>
<td>4.3 MB</td>
<td>16.2 MB</td>
<td>6.2s</td>
<td>6.5s</td>
<td>8.2s</td>
</tr>
</tbody>
</table>
</div>
<p>Download size is the compressed size, JavaScript size is uncompressed. Main Content is the time when e.g. the Cloud Functions become visible, Fully Loaded is when no more changes are made to the UI.</p>

<p>We can see that each page loads over 15 MB of JavaScript code. A look at the performance timeline in Chrome DevTools confirms that running this code is the primary cause of the poor page performance.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/timeline.png" alt="DevTools CPU timeline showing a large amount of JavaScript work"></p>
<p>This article will take a closer look at the page load process of the Google Cloud Functions page, and examine how it could be sped up.</p>
<p>You can use these strategies to investigate and improve the performance of the apps you're working on.</p>
<h2 id="loading-the-html-document">Loading the HTML document</h2>
<p>The initial HTML request is very fast and only takes about 150ms. It contains an embedded SVG spinner that shows while the first chunk of JavaScript code is loading.</p>
<video autoplay="" muted="" loop="" playsinline="">
    <source src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/gcp-spinner.mp4" type="video/mp4">
</video>
<h2 id="loading-the-initial-java-script-bundles">Loading the initial JavaScript bundles</h2>
<p>These are the first two JavaScript bundles the page starts loading.</p>
<ul>
<li><strong>routemap</strong> 21 KB (103 KB uncompressed)</li>
<li><strong>core,pm_ng1_bootstrap</strong> 1.3 MB (4.8 MB uncompressed)</li>
</ul>
<p>These files don't take too long to download, but running the code freezes the UI for a while. The spinner SVG becomes stuck at this point, until it's replaced by a skeleton UI for Google Cloud Console page.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/gcp-initial-load.png" alt="Filmstrip showing initial rendering of the GCP page"></p>
<p>Here's what happens when the browser wants to run some JavaScript code.</p>
<ol>
<li><strong>Parsing</strong> (done lazily at first, and then as needed later on)</li>
<li><strong>Compilation</strong> (also happens lazily)</li>
<li><strong>Initialization</strong> –&nbsp;the browser runs module initialization code, i.e. code that runs when loading a module rather than when calling one of its functions</li>
<li><strong>Running core app code</strong> – renders the application using the initialized modules</li>
</ol>
<p>For the whole Google Cloud page, just parsing the source code takes 250ms, and compilation takes another 750ms (not including the 113 ms spent on "Compile Script").</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/devtools-profile.png" alt="DevTools profile showing a breakdown of CPU activity"></p>
<p>The initial render of the Angular app takes about 1s.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/initial-bundle.png" alt="JavaScript execution flamechart"></p>
<p>Eventually we start to see a new spinner.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/second-spinner.png" alt="Page frame and new spinner"></p>
<h2 id="loading-page-bundles">Loading page bundles</h2>
<p>Once the generic Google Cloud UI is rendered the page starts loading 18 additional JavaScript files with an overall size of 1.5 MB.</p>
<p>Making a lot of separate requests isn't actually a problem though – it can improve performance by increasing the likelinhood of cache hits, and splitting up bundles makes it easy to load only necessary code.</p>
<p>After loading the first set up bundles the app starts making fetch requests and loads 3 more bundles at a total size of 6 MB.</p>
<p>When loading the page on my normal network the requests all kind of blurred together and it was hard to see which requests were sequential. So this screenshot shows the request chart on a throttled connection.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/more-page-bundles.png" alt="Request waterfall showing three sets of JavaScript being loaded sequentially"></p>
<h2 id="loading-the-list-of-cloud-functions">Loading the list of Cloud Functions</h2>
<p>The request loading the list of Cloud Functions takes about 700ms. But it doesn't start as soon as the bundles are loaded, in part because there's a <code>testIamPermissions</code> request that needs to finish first.</p>
<p>As a result the CPU ends up being idle for half a second –&nbsp;this time could be used better if the request started sooner.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/loading-functions.png" alt="Waterfall showing requests made to load the list of cloud functions"></p>
<p>Finally the app re-renders and we get the list of Cloud Functions we wanted to see.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/cloud-functions.png" alt="Page showing GCP Cloud Functions"></p>

<p>Chrome DevTools has a code coverage tool tracks which parts of the code actually run on the current page. This can help identify code that doesn't have to be loaded.</p>
<p>The Cloud Functions page runs 53% of the JavaScript code it downloads. This is actually a bit disappointing, as it means that even if only necessary code is loaded it would still only cut the total JavaScript size of the page in half.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/code-coverage.png" alt="Chrome DevTools Code Coverage tool"></p>
<h2 id="moving-configuration-into-json">Moving configuration into JSON</h2>
<p>A good amount of the code actually consists of configuration objects. For example, this 200 KB object with 4997 keys.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/configuration.png" alt="Configuration object in a JavaScript bundle"></p>
<p>Loading this as a JSON string with <code>JSON.parse</code> could be faster, as JSON is simpler to parse than a JavaScript object. This would be easy to do, but might not result in a huge performance improvement.</p>
<p>Ideally the app wouldn't need to load the full list on the client, but this would be harder to implement.</p>
<h2 id="reduce-code-duplication">Reduce code duplication</h2>
<p>The 200KB JSON object above is actually included in two of the JavaScript bundles. Breaking it out and reusing it would save download and processing time.</p>
<p>The same seems to apply to a bunch of UI components, like this one.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/code-duplication.png" alt="Duplicate code in DevTools code search"></p>
<h2 id="prioritize-primary-content">Prioritize primary content</h2>
<p>The Google Cloud page loads a large initial JavaScript bundle. The longer it takes to load and initialize this code, the longer it takes to load page-specific code and to render the list of Cloud Functions the user wants to see.</p>
<p>But the initial bundle also contains secondary content, like the complex navigation sidebar. This menu becomes functional before the main page content is loaded, but it should only be loaded after the primary content.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/prioritize-primary-content.png" alt="Sidebar menu is open while main content is still loading"></p>
<p>Google Cloud already does this in some cases. For example, the page initially renders a simpler version of the header and then loads more complex features later on.</p>
<p><img src="https://www.debugbear.com/public/blog/slow-google-cloud-ui/header.png" alt="Header doesn't show project dropdown at first and then shows it later"></p>
<h2 id="conclusion">Conclusion</h2>
<p>While the performance of static pages tends to be dominated by render-blocking network requests, single-page apps are often blocked by JavaScript execution or loading account data.</p>
<p>Downloading large amounts of code can hurt performance on slow connections, but due to compression and caching CPU processing often has a greater impact.</p>
<p>If you want to track the performance of your website, including logged-in pages, <a href="https://www.debugbear.com/">give DebugBear a try</a>.</p>
<blockquote><p lang="en" dir="ltr">Why is the Google Cloud UI so slow? This article looks at the performance of a large JavaScript application and explores how it could be made faster.<a href="https://t.co/HSHhCXYQCi">https://t.co/HSHhCXYQCi</a></p>— DebugBear (@DebugBear) <a href="https://twitter.com/DebugBear/status/1336621651669213186?ref_src=twsrc%5Etfw">December 9, 2020</a></blockquote> 

        

        
        <div>
            <div>
                <p>
                    DebugBear is a website monitoring tool built for front-end teams.
                    Track performance metrics and Lighthouse scores in CI and production.
                    <a href="https://www.debugbear.com/?noredirect&amp;from_blog">Learn more</a>.
                </p>
                
            </div>
        </div>
        <div>
        
                    <!-- Begin Mailchimp Signup Form -->
            
            
            <div>
                <div>
                    
                    <div>
                        
                        <h2>Get new articles on web performance <!-- and debugging --> by email.</h2>
                    </div>
                </div>
                
            </div>
        
            
        
        </div>      </div>
    </div>
  </div>
</div></div>]]>
            </description>
            <link>https://www.debugbear.com/blog/slow-google-cloud-ui</link>
            <guid isPermaLink="false">hacker-news-small-sites-25357409</guid>
            <pubDate>Wed, 09 Dec 2020 11:08:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AsyncAPI partners with Postman to boost development of Asynchronous APIs]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25356677">thread link</a>) | @derberg
<br/>
December 9, 2020 | https://www.asyncapi.com/blog/asyncapi-partners-with-postman | <a href="https://web.archive.org/web/*/https://www.asyncapi.com/blog/asyncapi-partners-with-postman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><img src="https://www.asyncapi.com/img/posts/asyncapi-partners-with-postman.png" alt="Post cover image"><p>I'm proud and honored to let you know that we're partnering with <a href="https://www.postman.com/">Postman</a><undefined> to boost the development of Asynchronous APIs to a new level <span role="img" aria-label="rocket">🚀</span></undefined></p><p>Since the very beginning, I knew the duty we had at hand was challenging. And still is! The specification was just the trigger of a snowball effect. What's the spec for if you can't do anything with it? Tooling is as important as the specification. However, tooling is a number of times more complex than the specification. We engineers don't want to abandon our favorite programming language and framework, therefore, it's AsyncAPI's responsibility to integrate with the existing tools in the market. <strong>The specification (and tools) should work for the user, not the other way around.</strong> Partnering with Postman allows us to boost the development of more and better tools to help engineers create and maintain Asynchronous APIs while using their favorite programming languages and frameworks.</p><p><strong>Our goal is to make Asynchronous APIs as successful and mature as REST APIs.</strong> We are aware this is a long journey but, with Postman's help, we'll be able to grow the team and continue working on the AsyncAPI specification and all the necessary tools to create a delightful developer experience. The AsyncAPI Initiative team is fully committed to open source software (OSS), and the partnership with Postman will help us keep doing our job with freedom and independence.</p><h2 id="next-steps">Next steps</h2><p>We want to make the AsyncAPI Initiative a neutral and independent place for collaborating on defining the future of Asynchronous APIs. Next step for us is to host the project in a neutral foundation to guarantee the long-term success of the initiative. We're currently in conversations with different actors of the OSS world to make sure the initiative remains independent.</p><p>Also, we want you to work with us. <a href="https://www.asyncapi.com/jobs">We are hiring</a> at Postman to work full-time on AsyncAPI. In the first half of 2021, we'll open a bunch of positions, including Software Engineers, Graphic Designers, Technical Writers, and more. Make sure you don't miss them!</p><div><h3>Receive an email when we publish a new job offer:</h3><p>We respect your inbox. No spam, promise ✌️</p></div><p>Before I finish, I would love to thank <a href="https://twitter.com/kinlane/">Kin Lane</a> and <a href="https://twitter.com/a85">Abhinav Asthana</a> for being so supportive. And of course, a huge shout out to <a href="https://twitter.com/derberq">Łukasz Gornicki</a> and <a href="https://twitter.com/e_morcillo">Eva Morcillo</a> for their tireless support. None of these would be possible without their help.</p><p>There's a bright future ahead for Asynchronous APIs. 2021 will be the year of AsyncAPI, the year of you, our beloved open-source community.</p><p><undefined>Cheers! <span role="img" aria-label="clinking beer mugs">🍻</span></undefined></p></article></div>]]>
            </description>
            <link>https://www.asyncapi.com/blog/asyncapi-partners-with-postman</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356677</guid>
            <pubDate>Wed, 09 Dec 2020 08:57:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Progress Over Perfection]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25356266">thread link</a>) | @phughes1980
<br/>
December 8, 2020 | https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/ | <a href="https://web.archive.org/web/*/https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main><article aria-label="My New Side Hustle Mantra: Progress Over Perfection"><div><figure><img loading="lazy" width="1880" height="1249" src="https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1880%2C1249&amp;ssl=1" alt="traffic red blue sign" srcset="https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?w=1880&amp;ssl=1 1880w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=300%2C199&amp;ssl=1 300w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1024%2C680&amp;ssl=1 1024w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=768%2C510&amp;ssl=1 768w, https://i1.wp.com/www.thedailymba.com/wp-content/uploads/2020/12/pexels-photo-117602.jpeg?resize=1536%2C1020&amp;ssl=1 1536w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"><figcaption>Photo by Mabel Amber on <a href="https://www.pexels.com/photo/traffic-red-blue-sign-117602/" rel="nofollow">Pexels.com</a></figcaption></figure><p>A Guest Post by Phil Hughes</p><p>“Progress over perfection”. I’ve written this on the whiteboard next to my standing desk in the home office/guitar studio/mancave/junk room.&nbsp;</p><p>I heard this statement earlier on in the year. Must have been around May or June, it instantly struck a chord with me.</p><p>Working full time and trying to get no less than 3 side hustles and a podcast off the ground is a big ask.&nbsp;</p><p>I have used the progress over perfection mantra before. It was worded slightly differently; I can’t remember the exact statement.</p><p>However, I hadn’t fully embraced the concept.&nbsp;</p><p>When it came to my core skill of software development, I could easily apply this principle.&nbsp;</p><p>Every other part of the side hustle lifestyle was still “I got to make sure this is the best it can be”.</p><h2 id="h-already-integrated-into-my-9-5"><span id="Already_Integrated_into_My_95"></span>Already Integrated into My 9-5<span></span></h2><p>Like I’ve just touched on. I’ve used progress over perfection, day to day with my software development ‘hat’ on.</p><p>I’m going to sound arrogant now. Having spent 14+ years developing software, I’m confident in my skills and the fact I can get stuff done and out the door, quicker than a lot of my “development” peers.</p><p>By using this principle, I can get the feature ‘X’ out to the world. Start feature ‘Y’ and deliver that in rapid time. Same too with Feature ‘Z’</p><p>Then go back to feature ‘X’ and make it better. Progress over perfection in action.</p><h3 id="h-progress-over-perfection-a-real-world-app-example"><span id="Progress_Over_Perfection_%E2%80%93_A_Real_World_App_Example"></span>Progress Over Perfection – A Real World App Example<span></span></h3><p>I’m writing this post towards the end of 2020, having gone through the Coronavirus pandemic.</p><p>At the start of lockdown, I had more spare time and I came up with a <a href="https://baitcamp.net/">mobile app idea for a hobby of mine, fishing</a>.&nbsp;</p><p>After doing a bit of product validation and finding out what other fishermen would like to see in the app. I sketched out the features I was going to include in version 1 of the app.</p><p>One of the features was to allow the user to upload photos to the app, linking them to a fishing trip.</p><p>Having never done anything like this before, it was a learning curve, to say the least. I decided to use the “progress over perfection” mantra by making sure the uploading, editing, removing, and retrieving of the photos, from a functionality point of view, was “perfect”</p><p>However, the way the user uploaded the photos and then viewing them was shocking, “perfect” was just a dot on the horizon.&nbsp;</p><p>That said, I went with it as I wanted to get the app published on both the <a href="https://apps.apple.com/us/app/id1519992229">Apple App Store</a> and <a href="https://play.google.com/store/apps/details?id=uk.co.phhdigital.baitcamp">Google Play</a> as quickly as possible.&nbsp;</p><p>5 months after the initial idea came to me, I had published the app on both platforms. WAHOO!</p><p>After feedback from people testing version 1. And the fact I wasn’t happy with the photo upload/viewing features. I have been able to start work on version 1.1 to sort this problem out.</p><p>Another day or two and I will have a slick way of managing the photos. Be able to release an update very quickly. As well as ironing out a few bugs that have come to light.</p><p>I genuinely believe if I had kept on working on the app until I was entirely happy with the photo functionality, I wouldn’t have it published or have people downloading the app and using it.</p><p>The key here was “progress over perfection” to get something live that was usable, then go from there.</p><h2 id="h-side-hustling-and-what-you-need-to-learn"><span id="Side_Hustling_and_What_You_Need_To_Learn"></span>Side Hustling and What You Need To Learn<span></span></h2><p>When it comes to other aspects of side hustling, I’m still “newborn” in a lot of the skills you need.&nbsp;</p><p>Writing blog posts, writing social media posts, copywriting, creating nice-looking webpages, building sales funnels, creating ads, shooting walkthroughs for YouTube, recording video sales letters, editing videos, coming up with offers, researching, scheming and plotting, creating eBooks, creating eBook covers, creating eBook mock-ups, recording podcasts, editing podcasts.</p><p>How did I come up with that list of things to do? I looked at my planner at what tasks I wanted to achieve over the last 2 weeks.&nbsp;</p><p>That’s on top of coding 3 software products by myself. Working 8-4 Monday through Thursday. And, having a life, like spending time with my wife, playing guitar, and going fishing.</p><p>It can be very overwhelming.&nbsp;</p><p>You see how great other people are at all these other things and want your stuff to be as “perfect” as theirs</p><p>That’s why this new mantra has been a bit of a breakthrough for me.</p><h2 id="h-progress-over-perfection-and-switching-your-mindset"><span id="Progress_Over_Perfection_and_Switching_Your_Mindset"></span>Progress Over Perfection and Switching Your Mindset<span></span></h2><p>As I’ve touched upon. For certain aspects of my day to day I would apply “progress over perfection”. Not all aspects though.</p><p>Hearing this really got me thinking about what I wanted to achieve.&nbsp;</p><p>One thing it also did was remove some fear I had around things.&nbsp;</p><p>For example, I had started digging deep into the concept of creating online sales funnels to promote my products and reach my “golden goose” of 350 paying customers.</p><p>My dream is to work for myself running a software product. After a bit of number crunching, I worked out I would need 350 monthly subscribers for me to realize my dream.&nbsp;</p><p>Sales funnels could help me achieve this.</p><h3 id="h-sales-funnel-progress-over-perfection"><span id="Sales_Funnel_Progress_Over_Perfection"></span>Sales Funnel Progress Over Perfection<span></span></h3><p>This is where the fear kicked in. I was worried that I would create a sales funnel, it would completely bomb, and I would feel like a failure.&nbsp;</p><p>I wanted my sales funnels to be successful as soon as I start driving traffic to it. If this were a software product, I wouldn’t think like that. I know they will be some bugs and users would probably want something different than what I had built.</p><p>After consuming a lot of content around the sales funnel process and how even the most experienced “funnel hackers” can’t get their funnel to work out of the gate.&nbsp;</p><p>I decided that I just need to get it out there and see what “feedback” I get.</p><p>So, I continued to put it together as best I could, giving myself a time constraint that it must be done by the end of that week. Then the week after I could drive some paid traffic to it.</p><p>I got the opt-in page up and running, where someone could submit their details and in return get a free eBook user guide.</p><p>Next, I spent most of my time working on the sales page and putting together an offer and pricing.&nbsp;</p><p>Thirdly, I added a “One Time Offer” that the person would be shown if they subscribed to the product I was promoting on the sales page.</p><p>Finally, I put together an email sequence that would be sent to anyone who opted in for the free eBook, as a follow up to get them to revisit my funnel.</p><p>The next week I created a Facebook ad campaign and got loads of people into the funnel. Guess how many sales I made?</p><p>ZERO.</p><h3 id="h-analyzing-the-results"><span id="Analyzing_the_Results"></span>Analyzing the Results<span></span></h3><p>Sounds terrible right? It was, but I wasn’t downhearted.&nbsp;</p><p>Looking into the stats, the opt-in page was working. I was getting almost 45% of the visitors to put in their email address and request a copy of the eBook.</p><p>Yes, no one bought from me. I knew that part of my sales funnel did work. However, I was building an email list of people that I could keep in contact with, which I hadn’t be able to do before.</p><p>“Progress over perfection”.</p><p>I ended up scrapping this funnel as I still didn’t ‘convert’ after a few attempts at rewriting parts of the sales page.</p><p>Taking the learnings from the opt-in success, I created a brand-new funnel. This targeted a different group of people. Again, this funnel wasn’t the success I wanted. My opt-in rate was still high, 35% and I got my first ever paying customer.</p><p>Someone signed up and subscribed to <a href="https://outflash.xyz/">my software product called Outflash</a>. They even took my up one-time offer.</p><p>I was blown away. Yes, it wasn’t the riches you pray for, but I had made progress on this skill.</p><p>Progress! Progress towards what I deem successful.</p><h2 id="h-podcasting-and-getting-yourself-out-there"><span id="Podcasting_and_Getting_Yourself_Out_There"></span>Podcasting and Getting Yourself Out There<span></span></h2><p>A problem with being a developer, is you think it will be like the movie Field of Dreams. “Build it and they will come”. With a software product, this NEVER happens.</p><p>Someone said if you want to get yourself out there to promote your products and services. Use a platform or media that you enjoy yourself. For me this was podcasting.</p><p>I’m an avid podcast listener. Whether it be working out, going for a run, listening while coding. I even put a podcast on while cooking a Sunday Dinner.</p><p>Starting a podcast can be scary though. What do I talk about? Do I have enough content to get past the first 10 episodes? How do I even publish a podcast? Which platforms do I publish to?</p><h3 id="h-excuses-excuses-just-do-it"><span id="Excuses,_Excuses,_Just_Do_It"></span>Excuses, Excuses, Just Do It<span></span></h3><p>Having mild success with the sales funnels gave me a lot of belief in the saying “Just Do It”.</p><p>One of the podcasts I listen to is by two guys that have launched their own podcasting hosting and publishing platform. I know, a bit Inception right!</p><p>So, I decided to use their platform to publish and host <a href="https://www.philliphughes.co.uk/podcast/">my podcast</a>. Which platforms to publish to? Their service had guides on how to publish to <a href="https://podcasts.apple.com/gb/podcast/find-your-side-hustle/id1523991465">Apple</a> and <a href="https://podcasts.google.com/feed/aHR0cHM6Ly9mZWVkcy50cmFuc2lzdG9yLmZtL2ZpbmQteW91ci1zaWRlLWh1c3RsZQ?sa=X&amp;ved=0CBUQ27cFahcKEwiIrMe2-eLqAhUAAAAAHQAAAAAQAQ">Google podcasts</a>, <a href="https://open.spotify.com/show/19pwsqTl75RSGrhhrsFIWW">Spotify</a>, and <a href="https://www.stitcher.com/podcast/find-your-side-hustle">Stitcher</a>. I didn’t overthink it, I registered with those 4 providers first and thought, “progress over perfection”, I can publish to more platforms later.</p><p>People also think they need a mass of equipment to record and edit a podcast. I was on a roll; nothing was stopping me from getting my first episode out to the world.&nbsp;</p><p>Quickly opening Amazon and searching for “cheap podcast mic”. I bought the 3<sup>rd</sup> one I saw for £20, with Amazon Prime it was delivered the next day.</p><p>In another quick search for “free podcast editing software,” I found a piece of software that I could do basic audio editing with, like snipping or increasing the volume.&nbsp;</p><h3 id="h-other-people-skills-to-progress-over-perfection"><span id="Other_People_Skills_To_Progress_Over_Perfection"></span>Other People Skills To Progress Over Perfection<span></span></h3><p>The last two pieces of the podcasting puzzle were that I needed a logo/header for the podcast that will be unique to me and my chosen topic.</p><p>I have used Fiverr in the past and thought it would be a good place to find someone to do it for me, quickly.&nbsp;</p><p>If I didn’t like it, I could always change it a few months down the line. I found someone who had a decent portfolio of similar work, that wasn’t too pricy. I put the order in, with a description of what I was looking for, and forgot about it for the rest of the evening.</p><p>While the logo was being designed, I needed to get together a list of episode ideas so I could record a least a handful to get me started.</p><p>This time I turned to Evernote, created …</p></div></article></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/">https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/</a></em></p>]]>
            </description>
            <link>https://www.thedailymba.com/2020/12/08/my-new-side-hustle-mantra-progress-over-perfection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25356266</guid>
            <pubDate>Wed, 09 Dec 2020 07:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Survey 2020 Results]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25354551">thread link</a>) | @pama
<br/>
December 8, 2020 | https://emacssurvey.org/2020/ | <a href="https://web.archive.org/web/*/https://emacssurvey.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2>Questions</h2>
      <p>For reference, this was <a href="https://emacssurvey.org/2020/emacs-user-survey-2020.org">the survey questions</a> in org-mode format.</p>
      <h2>Data</h2>
      <ul>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-raw.csv">Raw data</a>
          <ul>
            <li>the reconciled data from both webform and email submissions</li>
            <li>absolutely no change made aside from a few instances where PII and email addresses were redacted</li>
          </ul>
        </li>
        <li>
          <a href="https://emacssurvey.org/2020/Emacs-User-Survey-2020-clean.csv">Cleaned up data</a><br>
          It might get updated in the future, but right now it was derived from the raw data in a best-effort attempt:
          <ul>
            <li>removed negative years in "For how many years have you been using Emacs?"</li>
            <li>unified responses for "How did you hear about this survey?" as Hacker News, Emacs China and Emacs News weren't part of the options</li>
            <li>unified responses for "Which theme do you use?", especially around spelling</li>
            <li>general cleanup and unified of responses which only differed by punctuation and casing</li>
          </ul>
        </li>
      </ul>
      <h2>Statistics about the survey</h2>
      
      <h2>Analysis</h2>
      <p>There is a lot of data to look at in many different ways. For now, I performed a simple question-by-question analysis using a <a href="https://github.com/abrochard/emacs-survey/blob/main/2020/Emacs%20User%20Survey%202020.ipynb">Jupyter Notebook</a>.</p>
      <p>Also, since free text was available for most questions, it can be hard to categorize some of the results. For multiple choice questions, I did a best effort attempt to bundle responses with low cardinality into an "other" section, which can get quite big in some cases! I also did not attempt to graph anything for pure free text questions. I encourage anyone who is curious to inspect the full responses, either in the notebook or looking at the data directly. The omitted free text questions are:
        </p><ul>
          <li>If you use org-mode, for what purpose?</li>
          <li>Do you use a language server with lsp-mode or eglot? With what languages?</li>
          <li>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</li>
          <li>What are some of the Emacs improvements you are the most interested in?</li>
          <li>What do you think are Emacs' greatest strengths?</li>
          <li>Can you recall any difficulties you faced initially learning Emacs?</li>
          <li>What is the one thing you would like Emacs to do differently?</li>
          <li>If there is another survey in 2021, would you be opposed to it containing optional &amp; general demographics questions?</li>
          <li>Do you have a preferred platform for filling out the survey in the future?</li>
          <li>Do you have general feedback about the survey process?</li>
        </ul>
      

      <p>Also if you have some cool analysis and want to share it, please <a href="mailto:contact@emacssurvey.org">let us know</a> and we can link to you.</p>
      <p><img src="https://emacssurvey.org/2020/how-would-you-characterize-your-use-of-emacs.png">
      <img src="https://emacssurvey.org/2020/what-do-you-use-emacs-for.png">
      <img src="https://emacssurvey.org/2020/for-how-many-years-have-you-been-using-emacs.png">
      <img src="https://emacssurvey.org/2020/which-version-of-emacs-do-you-primarily-use.png">
      <img src="https://emacssurvey.org/2020/which-os-do-you-primarily-use-emacs-on.png">
      <img src="https://emacssurvey.org/2020/how-do-you-run-emacs.png">
      <img src="https://emacssurvey.org/2020/how-do-you-use-emacs.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-gui-do-you-disable-any-of-the-graphical-elements.png">
      <img src="https://emacssurvey.org/2020/is-your-configuration-based-on-any-starter-kit.png">
      <img src="https://emacssurvey.org/2020/what-keybindings-do-you-use-now.png">
      <img src="https://emacssurvey.org/2020/when-you-started-using-emacs-what-keybindings-did-you-use-then.png">
      <img src="https://emacssurvey.org/2020/prior-to-using-emacs-what-was-your-primary-editor.png">
      <img src="https://emacssurvey.org/2020/describe-your-org-mode-usage.png"></p><!-- <p>If you use org-mode, for what purpose?</p> -->
      <p><img src="https://emacssurvey.org/2020/which-completionselection-framework-do-you-use.png">
      <img src="https://emacssurvey.org/2020/how-do-you-manage-third-party-elisp.png">
      <img src="https://emacssurvey.org/2020/how-do-you-get-emacs-packagesif-applicable.png">
      <img src="https://emacssurvey.org/2020/can-you-list-some-of-your-favorite-packages.png">
      <img src="https://emacssurvey.org/2020/which-theme-do-you-use.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-error-checking.png">
      <img src="https://emacssurvey.org/2020/do-you-use-tramp.png">
      <img src="https://emacssurvey.org/2020/do-you-use-magit.png">
      <img src="https://emacssurvey.org/2020/what-package-do-you-use-for-project-management.png">
      <img src="https://emacssurvey.org/2020/do-you-use-a-shellterminal-emulator-in-emacs.png">
      <img src="https://emacssurvey.org/2020/do-you-use-an-email-client-in-emacs.png">
      <img src="https://emacssurvey.org/2020/what-is-your-elisp-proficiency.png">
      <img src="https://emacssurvey.org/2020/if-you-use-emacs-for-programming-which-languages-do-you-program-in.png"></p><!-- <p>Do you use a language server with lsp-mode or eglot? With what languages?</p>
           <p>Do you use an Emacs debugger interface? What do you use? (Gdb, dap-mode etc)</p> -->
      <p><img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-gnu-emacs-coreelpa.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-to-melpa-package.png">
      <img src="https://emacssurvey.org/2020/have-you-ever-contributed-financially-to-emacs-development-either-via-fsf-or-directly.png">
      <img src="https://emacssurvey.org/2020/what-emacs-community-forums-have-you-visited-in-the-past-year.png"></p><!-- <p>What are some of the Emacs improvements you are the most interested in?</p>
           <p>What do you think are Emacs' greatest strengths?</p>
           <p>Can you recall any difficulties you faced initially learning Emacs?</p>
           <p>What is the one thing you would like Emacs to do differently?</p> -->
      <p><img src="https://emacssurvey.org/2020/how-did-you-hear-about-this-survey.png"></p><!-- <p>If there is another survey in 2021, would you be opposed to it containing optional & general demographics questions?</p>
           <p>Do you have a preferred platform for filling out the survey in the future?</p>
           <p>Do you have general feedback about the survey process?</p> -->
    </div></div>]]>
            </description>
            <link>https://emacssurvey.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25354551</guid>
            <pubDate>Wed, 09 Dec 2020 02:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kite Power for Mauritius]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25353559">thread link</a>) | @usrusr
<br/>
December 8, 2020 | https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius | <a href="https://web.archive.org/web/*/https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://skysails-power.com/index.html?artikel=Kite-Power-For-Mauritius</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353559</guid>
            <pubDate>Wed, 09 Dec 2020 00:16:37 GMT</pubDate>
        </item>
    </channel>
</rss>
