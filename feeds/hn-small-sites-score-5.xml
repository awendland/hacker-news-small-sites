<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 08 Mar 2021 04:37:48 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 08 Mar 2021 04:37:48 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[How to Build a Community: Starting with “Why?”]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26363709">thread link</a>) | @alexdean
<br/>
March 5, 2021 | https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html | <a href="https://web.archive.org/web/*/https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="my-origin-story">My origin story</h2>

<p>In November 2018, I moved from Sydney to the US to take on a role managing the dbt community. I’d been a member of the community for the two years prior, and in that time had gone from a data analyst who knew enough SQL to be dangerous, to someone who understood the data space deeply enough that I wanted a new challenge. And I’d learned almost everything about data from the dbt community.</p>

<p>Over the last few years, the dbt community has been incredibly successful — since I started, we’ve grown from 1000 members to over 10 000. In December, we hosted a conference that had 5 000 registrants, and received incredibly positive feedback. Late last year, when our eventual Series-B investors reached out to a dozen community members and asked for their NPS, we received an average score of 10.2/10 — no, this is not a typo, apparently someone gave us as 12/10. (If this was you: you should know better as a data person! You’re really messing up my numbers here!). Most of these community members cited the community as a reason for their high score.</p>

<p>Finally, around once a week I get around one DM a week saying thanks for everything we’ve built!</p>

<p><img src="https://clrcrl.com/assets/img/posts/tickled-pink.png"></p>



<p>If you had asked me when I joined in November 2018 what our community would look like at 10k members, I would have guessed that it would have become like most other online communities: full of unkind people and extractive behavior (after all, <a href="http://blog.vickiboykis.com/2017/05/10/good-things-don't-scale/">good things don’t scale</a>). I would have been scared of that day.</p>

<p>Yet somehow, despite my worst fears of growth (or perhaps because of them), people still find being a part of the dbt community to be a net-positive experience. Sure, it’s not perfect, but it’s still pretty good!</p>

<p>As a result, other companies in the industry are noticing, leading to a number of “can I pick your brain?” meeting requests¹ over the past few months. Most days, I feel wholly unqualified to give an opinion on why, or how, we’ve been so successful, I’ve just been making it up as I go along. But when I look at what we’ve achieved, when I talk to new starters at our company, or when I <em>do</em> let someone pick my brain, I realise that I do know <em>something</em> about this whole community building thing, and perhaps that thing is worth writing about.</p>

<p>So, this is the first of who-knows-how-many posts on <em>How to Build a Community</em>.</p>



<p>Often folks end up in my inbox because their CEO has heard that community building is the latest hotness, and they’re scrambling to figure out what that means, and how they should do this.</p>

<p>My first question is always “why do you want to build a community?”. Here’s some common answers:</p>
<ul>
  <li>“Well, it must be fantastic at increasing your top of funnel for sales and marketing.”</li>
  <li>“It just feels like your community creates incredible hype around your product.”</li>
  <li>“I guess we’ll be able to understand our users’ needs better, and get more product feedback.”</li>
  <li>“After all, you get free content, and get to outsource a ton of other work.”</li>
</ul>

<p>These are pretty reasonable answers on the surface, especially if you’re looking at our community as a model of success — after all, we do in fact get all of these benefits.</p>

<p>But if these are the primary motivators for <em>why</em> you’re building a community, I’m skeptical that you’ll succeed. These reasons put the benefit of the company ahead of the community member, and I’m pretty sure that any of our community members would see right through these motivations.</p>

<h2 id="building-mission-driven-communities">Building mission-driven communities</h2>

<p>So if those answers aren’t quite right, what <em>is</em> a good answer? Here’s my two step process to identifying why community might be right for you:</p>

<ol>
  <li>Find for your company mission, and</li>
  <li>Ask yourself “does building a community help us achieve this mission?”. If yes, then that’s your “why”.</li>
</ol>

<p>Let’s take the mission of company I work for, Fishtown Analytics, as an example:</p>
<blockquote>
  <p>Fishtown Analytics is on a mission to empower analysts.</p>
</blockquote>

<p>(OK there’s actually a little bit more in the mission, but this is the part that I like most).</p>

<p>Another great example is <a href="https://www.animalz.co/about/">Animalz</a>:</p>
<blockquote>
  <p><strong>Set a new bar for quality content marketing</strong>. <br> We envision a world where the internet is dominated by content that’s informative, insightful and entertaining.</p>
</blockquote>

<p>In both of these examples, it’s so clear that community is a tool for the company to achieve this mission — yes, a company can provide software and services in pursuit of this mission, but to <em>really</em> achieve it, one needs to be thinking bigger than this.</p>

<h2 id="how-does-this-play-out">How does this play out?</h2>

<p>For the last two and a half years, I’ve approached community-management from the perspective of trying to achieve our mission of empowering more analysts. Often, this leads us to make decisions that look different to other companies in our space.</p>

<ul>
  <li>On creating events:
    <ul>
      <li><strong>Other companies:</strong> I recently saw the info sheet for an event that a vendor wanted us to participate in. At the top of the sheet was the goal for the event: “Create $X of sales opportunities”. Most of the talks were a thinly-veiled sales pitch for their product. I didn’t feel like I’d learned anything by attending, and I won’t be attending next year.</li>
      <li><strong>My take:</strong> When planning our inaugural conference, Coalesce, our goal was to create an event that advanced the practice of analytics engineering. When selecting talks, we chose the ones that we felt helped data teams be more impactful.</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On speaking at conferences:
    <ul>
      <li><strong>Other companies:</strong> It’s not uncommon to have Developer Advocates whose role it is to speak at conferences.</li>
      <li><strong>My take:</strong> In comparison, I prefer to work with our community members so that they give the best conference talks possible (note: I have spoken at the odd-conference here and there – it’s a great way for to make sure that I’m well placed to give community members advice on how to make talks great!).</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On getting product feedback:
    <ul>
      <li><strong>Other companies:</strong> If I had an Amazon gift card for every time a company sent me an email asking me to do a product survey (in exchange for… an Amazon gift card). Some times, it’s up to the community team to bring feedback back to the company.</li>
      <li><strong>My take:</strong> I think more about how I can bring our team <em>into</em> the community — I’m very lucky in that all of our product team are data people themselves, so have a shared context with our community. But even our non-data teammates are building connections in the community — everyone on our team is great at what they do, and our community members often enjoy getting the chance to speak to a fantastic product designer and learn from them.</li>
    </ul>
  </li>
</ul>



<ul>
  <li>On recognizing community members:
    <ul>
      <li><strong>Other companies:</strong> Ever been to a conference that had a points system for swag? Or seen a community that had a leaderboard? In these cases a company is trying to incentivize someone to give them something.</li>
      <li><strong>My take:</strong> If someone does something wonderfully kind, I’ll try to say thanks with a small gift. As much as possible, I’m trying to recognize, rather than incentivize.</li>
    </ul>
  </li>
</ul>



<p>I think part of this is also just treating our community members with respect. Our community is full of incredibly bright, curious, and kind human beings&nbsp;— they’d see right through us if our motivations were related to dollars.</p>

<p>The <em>incredible</em> thing about this approach is that we do end up getting all of those benefits that I listed above — yes, we have a great sales funnel; yes, we have huge reach; yes, we stay in touch with our user needs; yes, we have people contribute work that we could not do ourselves. But we only get to sustain the good vibes (even with our growth) because we stay true to our mission.</p>


<p>That’s okay! But I think you need to be realistic with what you’re going to achieve if you try to build a community. Maybe your team isn’t going to build <em>the</em> <code>&lt;insert field of practice&gt;</code> community, but perhaps there’s ways you can generate goodwill by contributing to adjacent communities.</p>

<p>A lot of this mindset also applies to other interactions with your users, crossing over into the world of “developer experience” (i.e. how easy it is for a developer to be successful with your product) — by putting your user first, you’ll still create a lot of virtuous cycles.</p>

<p>No matter what your mission is, I encourage you to ask not what your community can do for you, but what you can do for your community.</p>



<p>We’ll see, this is my first time writing about community, and I have no idea how it will land.</p>

<p>Here’s a few topics I’m thinking about:</p>
<ul>
  <li>Managing the growth of a community</li>
  <li>Measuring the success of community</li>
  <li>Assessing community-market fit (or: when community isn’t the right strategy)</li>
  <li>What to look for in an early hire</li>
</ul>

<p>If one of these appeals to you, let me know via <a href="https://twitter.com/clairebcarroll/status/1365679922585468931">the bird site</a> or <a href="mailto:hello@clrcrl.com">email</a>.</p>

<hr>

<p>¹If you are reading this, and you have sent an email to someone in the past asking to “pick their brain” via a 30 minute meeting with no agenda, please don’t do this. Instead, send an email that includes the specific questions you are interested in, and don’t assume that the best way to get them answered is via a call.</p>

        </div></div>]]>
            </description>
            <link>https://clrcrl.com/2021/03/03/how-to-build-a-community-why.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26363709</guid>
            <pubDate>Fri, 05 Mar 2021 23:39:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FizzBuzz Mario World: Learning Assembly Language and Having Some Fun]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26362739">thread link</a>) | @vga805
<br/>
March 5, 2021 | https://computebeauty.com/posts/fbmw/index.html | <a href="https://web.archive.org/web/*/https://computebeauty.com/posts/fbmw/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I've wanted to learn <a href="https://en.wikipedia.org/wiki/Assembly_language" target="_blank">Assembly language (ASM)</a> programming for a long time. I finally found the perfect project to do it: hacking Super Mario World (SMW). It was a lot of fun so I thought I'd document the process.</p><p>The SMW <a href="https://en.wikipedia.org/wiki/ROM_hacking" target="_blank">ROM hacking</a> community is vibrant. It's an impressively talented and creative community that makes a lot of awesome games with custom graphics, music, level design, and game physics. Stumbling upon <a href="https://www.youtube.com/results?search_query=super+mario+world+rom+hack" target="_blank">these hacks</a> on YouTube started me down this rabbit hole.</p><p>TLDR: the code and a list of the resources mentioned in this post can be found on <a href="https://github.com/thoughtbyte/super-fizzbuzz-world" target="_blank">GitHub</a>.</p><h2>FizzBuzz Mario</h2><p><a href="https://en.wikipedia.org/wiki/Fizz_buzz" target="_blank">FizzBuzz</a> is a common problem that beginner programmers solve for practice. The objective is to loop from 1 to 100 and:</p><ul><li>for every number divisible by 3, print 'fizz'</li><li>for every number divisible by 5, print 'buzz'</li><li>for every number divisible by 3 and 5, print 'fizz buzz'</li><li>otherwise print the number</li></ul><p>The goal of this project is to solve a problem similar to FizzBuzz by writing custom ASM that can be patched, or inserted, into the SMW code. The perfect context for FizzBuzz in SMW is the coin count. At any one time the player can have between 0 and 99 coins. Additionally, Mario can have 1 of 4 power-up statuses: small, big, cape, and fire. Here's the behavior we'll hack into our version of SMW:</p><ul><li>when coin count is divisible by 3, set status to big</li><li>when coin count is divisible by 5, set status to cape</li><li>when coin count is divisible by 3 and 5, set status to fire</li><li>otherwise set status to small</li></ul><p>Here's game-play of the finished product:</p><p><iframe title="FizzBuzz Mario World Demo" src="https://www.youtube.com/embed/APwAE0wiGF8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h2>Getting Started</h2><p>After a few minutes of searching the web I found the source of most of the information I'll be sharing: <a href="https://www.smwcentral.net/" target="_blank">SWM Central</a>. You can find a full list of resources at the end of this article but the guides I found most helpful were Ersanio's <a href="https://ersanio.gitbook.io/assembly-for-the-snes/" target="_blank">Assembly for the SNES</a> and <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=15073" target="_black">Assembly for Super Mario World</a>. The former assumes no knowledge of ASM. The latter refreshes the ASM information from the former and then goes into how to apply a simple patch similar to the one we'll be writing. Both are quick reads and I recommend them to any programmer that wants to know what ASM programming feels like.</p><h3>Memory</h3><p>ASM is a low-level language with which you deal directly with individual bytes of memory. SNES games are comprised of read-only memory (ROM) and random-access memory (RAM). You can think of the ROM as the game cartridge itself. Instead of an actual cartridge and SNES, the ROM for present purposes is a computer file that you can play on a <a href="http://www.snes9x.com/" target="_blank">SNES emulator</a>. The ROM is where all the code for how the game works is stored. This memory, as the name implies, is usually only ever read from. Our goal is to hack this ROM by overwriting a small part of it thus changing how the game behaves.</p><p>The RAM is on the SNES itself and it's where values are stored that will change while the game is played. The coin counter value needs to live in RAM because it changes often. The same goes for the player's power-up status.</p><p>In both ROM and RAM, memory is a long list of addresses where values can be stored. These addresses are represented in <a href="https://en.wikipedia.org/wiki/Hexadecimal" target="_blank">hexadecimal (hex)</a>. For our purposes we'll need to figure out the memory addresses for three things: the value of the coin count, the value of the power-up status, and where to insert some custom code.</p><p>Fortunately, people have completely disassembled SMW and mapped the RAM and ROM, so finding what we need is a simple web search. The RAM map can be found on <a href="https://www.smwcentral.net/?p=memorymap&amp;game=smw&amp;u=0&amp;address=&amp;sizeOperation=%3D&amp;sizeValue=&amp;region[]=ram&amp;type=*&amp;description=" target="_blank">SMW Central</a>. The RAM begins at address <code>$7E0000</code> and ends at <code>$7FC800</code>. The <code>$</code> indicates hex. By searching a few relevant keywords I found that the coin count is stored at address <code>$7E0019</code> and the power-up status is stored at address <code>$7E0DBF</code>. The entry for power-up status also indicates the 4 possible values for this address and what they mean: 1 for big Mario, 2 for cape Mario, 3 for fire Mario, and 0 for small Mario.</p><p>This gives us a basic idea of what our ASM code will need to do, in pseudocode:</p><pre><code>every time the coin count increases:
  get the value of RAM address $7E0019 (coin count)
  if that value is divisible by 15
    store 3 in RAM address $7E0DBF (power-up status)
  else if that value is divisible by 5
    store 2 in RAM address $7E0DBF
  else if that value is divisible by 3
    store 1 in RAM address $7E0DBF
  else store 0 in RAM address $7E0DBF</code></pre><p>Now we need to figure out where to insert our code. I want this code to run whenever the player gets a coin so I searched for "coin count" within the ROM map and found <code>$008F1D</code>, a 30 byte piece of code that "handles actually increasing the player's coin count and giving a life from 100 coins." This is a good start, but we can't just insert code into 30 bytes of ROM without seeing what it does. We will break everything if we're not careful. Unfortunately the ROM map on SWM Central doesn't have the actual code stored at this address. But then I found <a href="https://www.smwcentral.net/?p=section&amp;a=details&amp;id=21822" target="_blank">All.log++</a>: a complete disassembly of the SMW source code, in ASM, with extensive comments and labels.</p><p>Inspecting the disassembled SMW source code at this coin count code address, I noticed that the address where the coin count is actually increased is <code>$008F25</code>. That is, this is the memory address of ROM that stores the instruction that literally adds 1 to the coin count every single time the player receives 1 coin. But instead of just increasing the coin count by 1, I want to patch the ROM so that when the code at this address gets executed, the SNES <i>also</i> runs my FizzBuzz code.</p><p>Now we have all of the relevant memory addresses that we need, and we have the pseudocode that we need to run at the coin count increase ROM address. Now we assemble.</p><h2>Writing the Code</h2><p>Our first two lines are easy:</p><pre><code>!PowerUpStatus = $0019
!CoinCount = $0DBF</code></pre><p>We simply set the RAM memory addresses that we need for the coin count and power-up status to some labels so they'll be easier to refer to in the code. Notice that we dropped the <code>7E</code> from both addresses. We don't need it. These lines don't actually get patched into the ROM. All occurrences of the labels in the code that we will write will get replaced with the addresses by the assembler. The assembler is the thing that will take our code and insert it into the ROM.</p><h3>Hijacking the Coin Count Increase Code</h3><p>We know where we want to insert our code: the ROM address where the coin count is increased. But we can't insert <i>all</i> of our code into this address, we'll overwrite a lot of stuff and break the game. We can only insert a few bytes, and we have to make sure the bytes that we overwrite are executed by us in our own code so that everything that the original code was supposed to do still happens. So what we'll do is insert one instruction in the ROM at the coin count increase address that tells the processor to <i>jump</i> to the rest of our code. Then we'll tell the assembler to insert our code in some free space so we don't overwrite anything. Here's what that looks like:</p><pre><code>ORG $008F25
JSL FizzBuzz
NOP
NOP

freecode</code></pre><p><code>ORG $008F25</code> instructs the assembler to insert the following instruction, <code>JSL FizzBuzz</code>, into the ROM address where the coin count is increased. What <code>JSL FizzBuzz</code> means is: <b>J</b>ump to the <b>S</b>ubroutine code labeled <code>FizzBuzz</code>. Most ASM operation codes, or opcodes, are menumonic. The J and S are for Jump and Subroutine. We can ignore the L, it's beyond the scope of this.</p><p>What's with the <code>NOP</code>s? As it turns out, the code we've chosen to overwrite, the coin count increase instruction, is 3 bytes long (we know this because All.log++ tells us that). The code we insert, <code>JSL FizzBuzz</code>, is 4 bytes long. So in our attempt to overwrite 1 3 byte long instruction, we overwrote the first byte of a second instruction.</p><p>The fix for this is that we need remember to execute <i>both instructions that we overwrote</i> in the code <i>we</i> write. The second instruction we overwrite, like the first, is 3 bytes long, for a total of 6 bytes. But again, the code we inserted is only 4 bytes: there are still 2 dangling bytes that were previously part of that second instruction. That's not good. Random, partially overwritten bytes in the code will break the game. So, we include 2 <code>NOP</code> instructions. These are <b>N</b>o <b>OP</b>erations. We do nothing for 2 bytes to fill up the space not filled up by the previous 4 bytes of code we inserted. To recap, we overwrote 6 bytes of 2 instructions with 6 bytes of our own instruction that jumps to our custom code.</p><p><code>freecode</code> just means find some free space in the ROM to put the rest of our custom ASM code.</p><h3>The FizzBuzz Subroutine</h3><p>The following code is the beginning of the <code>FizzBuzz</code> subroutine that we referenced above.</p><pre><code>FizzBuzz:
INC !CoinCount
LDA #$0F
STA $00
LDA !CoinCount
JSR Mod</code></pre><p>The first line is the label. The second, <code>INC !CoinCount</code>, means <b>INC</b>rement the value in the memory address for the coin count by 1. This is what the first instruction of the code we overwrote was supposed to do, so we do it here ourselves.</p><p>In ASM, one of the most important things is the <a href="https://en.wikipedia.org/wiki/Accumulator_(computing)" target="_blank">accumulator</a>. Essentially, the accumulator (A) is the memory address where the microprocessor stores its results from math and logic operations. We can also store stuff there for use in math operations. <code>LDA #$0F</code> does just that. It <b>L</b>oa<b>D</b>s into the <b>A</b>ccumulator the value 15. 0F is hex for the decimal value 15, and the # means we want the value 15 itself, not what's stored at the memory address 15.</p><p>We then run <code>STA $00</code>, this <b>ST</b>ores the value of the <b>A</b>ccumulator into memory address <code>$00</code>. This memory address is "scratch" memory that has no assigned purpose other than as a place to store temporary values. We couldn't just store a value directly into <code>$00</code>, instead it was a two-step process: load a value into A, then store the value of A in <code>$00</code>. Next, <code>LDA !CoinCount</code> loads the value of the coin count into A.</p><p>So now we have two values stored in memory: the coin count, stored in A, and 15, stored in <code>$00</code>. To check if something is divisible by 3 and 5, we can divide it by 15 and check if there's a remainder. Many programming languages have a modulo operator that gives you the remainder of 1 number divided by another. For example, 47 modulo 15 is 2. <code>JSR Mod</code> means <b>J</b>ump to the <b>S</b>ub<b>R</b>outine labeled <code>Mod</code>.…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://computebeauty.com/posts/fbmw/index.html">https://computebeauty.com/posts/fbmw/index.html</a></em></p>]]>
            </description>
            <link>https://computebeauty.com/posts/fbmw/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26362739</guid>
            <pubDate>Fri, 05 Mar 2021 22:04:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SVG Tetris]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26360716">thread link</a>) | @marcodiego
<br/>
March 5, 2021 | https://www.xul.fr/svgtetris.svg | <a href="https://web.archive.org/web/*/https://www.xul.fr/svgtetris.svg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.xul.fr/svgtetris.svg</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360716</guid>
            <pubDate>Fri, 05 Mar 2021 19:07:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Canadian government switches to support for first doses first]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26360556">thread link</a>) | @monkeypizza
<br/>
March 5, 2021 | https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html | <a href="https://web.archive.org/web/*/https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


    
    <h2>On this page</h2>
<ul>
	<li><a href="#a1">Preamble</a></li>
	<li><a href="#a2">Summary</a></li>
	<li><a href="#a3">Introduction</a></li>
	<li><a href="#a4">Methods</a></li>
	<li><a href="#a5">Recommendations</a></li>
	<li><a href="#a6">Summary of rationale</a></li>
	<li><a href="#a7">Acknowledgments</a></li>
</ul>
<h2 id="a1">Preamble</h2>
<p>The National Advisory Committee on Immunization (NACI) is an External Advisory Body that provides the Public Health Agency of Canada (PHAC) with independent, ongoing and timely medical, scientific, and public health advice in response to questions from PHAC relating to immunization.</p>
<p>In addition to burden of disease and vaccine characteristics, PHAC has expanded the mandate of NACI to include the systematic consideration of programmatic factors in developing evidence-based recommendations to facilitate timely decision-making for publicly funded vaccine programs at provincial and territorial levels.</p>
<p>The additional factors to be systematically considered by NACI include: economics, ethics, equity, feasibility, and acceptability. Not all NACI Statements will require in-depth analyses of all programmatic factors. While systematic consideration of programmatic factors will be conducted using evidence-informed tools to identify distinct issues that could impact decision-making for recommendation development, only distinct issues identified as being specific to the vaccine or vaccine-preventable disease will be included.</p>
<p>This statement contains NACI's independent advice and recommendations, which are based upon the best current available scientific knowledge.</p>
<p>This document is being disseminated for information purposes. People administering the vaccine should also be aware of the contents of the relevant product monograph(s). Recommendations for use and other information set out herein may differ from that set out in the product monograph(s) of the Canadian manufacturer(s) of the vaccines. Manufacturer(s) have sought approval of the vaccines and provided evidence as to its safety and efficacy only when it is used in accordance with the product monographs. NACI members and liaison members conduct themselves within the context of PHAC's Policy on Conflict of Interest, including yearly declaration of potential conflict of interest.</p>
<h2 id="a2">Summary</h2>
<ul>
	<li>NACI has considered evidence from recent scientific studies on efficacy and effectiveness of COVID-19 vaccines in preventing various health outcomes such as infection, symptomatic disease, hospitalizations and death from COVID-19.</li>
	<li>While studies have not yet collected four months of data on vaccine effectiveness after the first dose, the first two months of real world effectiveness are showing sustained high levels of protection.</li>
	<li>Short term sustained protection is consistent with immunological principles and vaccine science where it is not expected to see rapid waning of a highly effective vaccine in adults over a relatively short period of time.&nbsp;Extending the interval between doses was shown to be a good strategy through modelling, even in scenarios considering a six month interval and in theoretical scenarios where waning protection was considered.</li>
	<li>NACI recommends that in the context of limited COVID-19 vaccine supply, jurisdictions should maximize the number of individuals benefiting from the first dose of vaccine by extending the interval for the second dose of vaccine to four months.</li>
	<li>Extending the dose interval to four months allows NACI to create opportunities for protection of the entire adult population within a short timeframe. This will not only achieve protection of the adult population, but will also contribute to health equity,</li>
	<li>NACI will continue to monitor the evidence on effectiveness of extended dose intervals and will adjust recommendations as needed.</li>
</ul>
<h2 id="a3">Introduction</h2>
<p>Since COVID-19 vaccines were first authorised in Canada in December 2020, the National Advisory Committee on Immunization (NACI) has been providing evidence-informed guidance on the recommended interval between vaccine doses. In the most recent update, January 12, 2021, NACI provided advice on extending intervals for mRNA vaccines to six weeks. In February 2021 the Public Health Agency of Canada (PHAC) asked NACI to address the following context and question: Due to limited vaccine supply and logistical challenges, jurisdictions need to implement COVID-19 mRNA vaccine intervals beyond six weeks. Given emerging evidence as mRNA vaccines are rolled out to populations in Canada and elsewhere in the world, what extended interval would be recommended in order to balance individual protection and population impact? Are extended intervals a particular concern for any key populations?</p>
<h3 id="a3.1">Guidance objective</h3>
<p>The objective of this bulletin is to provide guidance for the equitable, ethical, and efficient allocation of authorized COVID-19 vaccines in the context of staggered arrival of vaccine supply. This guidance builds on the foundational framework of NACI's <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>. The goal of Canada's pandemic response is to minimize serious illness and death while minimizing societal disruption as a result of the COVID-19 pandemic.</p>
<h2 id="a4">Methods</h2>
<p>NACI reviewed available evidence in full Committee meetings (February 8, 2021; February 24-25, 2021) and Working Group meetings (February 19, 2021) on extended intervals for COVID-19 vaccines. This included evidence available from published peer-review studies, pre-prints, and data available from population-based assessments from within and outside of Canada. On March 1, 2021, NACI voted on and approved the revised recommendations by majority. Due to the urgency for provinces and territories to consider implementing extended dose intervals, NACI is providing an abridged rationale in this document. The complete analysis, including more detailed evidence summaries and references, will be provided in coming weeks as the NACI evergreen guideline is updated online in the <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>.</p>
<h2 id="a5">Recommendations</h2>
<p>Based on emerging evidence of the protection provided by the first dose of a two dose series for COVID-19 vaccines currently authorized in Canada, NACI recommends that in the context of limited COVID-19 vaccine supply jurisdictions should maximize the number of individuals benefiting from the first dose of vaccine by extending the second dose of COVID-19 vaccine up to four months after the first. NACI will continue to monitor the evidence on effectiveness of an extended dose interval and will adjust recommendations as needed. <strong>(Strong NACI Recommendation)</strong></p>
<ul>
	<li>In addition to emerging population-based data, this recommendation is based on expert opinion and the public health principles of equity, ethics, accessibility, feasibility, immunological vaccine principles, and the perspective that, within a global pandemic setting, reducing the risk of severe disease outcomes at the population-level will have the greatest impact. Current evidence suggests high vaccine effectiveness against symptomatic disease and hospitalization for several weeks after the first dose, including among older populations.</li>
	<li>This recommendation applies to all COVID-19 vaccines currently authorized for use in Canada.</li>
	<li>In situations where informed consent included assumptions about second dose timing, jurisdictions may consider offering second doses at shorter intervals for those who provided consent for the vaccine series prior to this recommendation.</li>
	<li>The vaccine effectiveness of the first dose will be monitored closely and the decision to delay the second dose will be continuously assessed based on surveillance and effectiveness data and post-implementation study designs. Effectiveness against variants of concern will also be monitored closely, and recommendations may need to be revised.</li>
</ul>
<p>Please note:</p>
<ul>
	<li>A&nbsp;<strong>strong recommendation</strong>&nbsp;applies to most populations/individuals and should be followed unless a clear and compelling rationale for an alternative approach is present.</li>
	<li>A&nbsp;<strong>discretionary recommendation</strong>&nbsp;may be offered for some populations/individuals in some circumstances. Alternative approaches may be reasonable.</li>
</ul>
<h2 id="a6">Summary of rationale</h2>
<p>Due to the urgency for provinces and territories to consider implementing extended dose intervals, NACI is providing an abridged rationale in this document. The complete analysis, including more detailed evidence summaries and references, will be provided in coming weeks as the NACI evergreen guideline is updated online in the <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/recommendations-use-covid-19-vaccines.html">Recommendations on the use of COVID-19 vaccines</a>.</p>
<h3 id="a6.1">Protecting individuals</h3>
<ul>
	<li>By implementing an extended four month interval strategy, Canada will be able to provide access to first doses of highly efficacious vaccines to more individuals earlier which is expected to increase health equity faster. Canada has secured enough vaccines to ensure that a second dose will be available to every adult.</li>
	<li>As a general vaccination principle, interruption of a vaccine series resulting in an extended interval between doses does not require restarting the vaccine series. Principles of immunology, vaccine science, and historical examples demonstrate that delays between doses do not result in a reduction in final antibody concentrations nor a reduction in durability of memory response for most multi-dose products.</li>
	<li><strong>Assessment of available data on efficacy and effectiveness</strong> of a single dose of mRNA vaccine was a critical factor in assessing the impact of a delayed second dose at this time. The two available clinical trials for mRNA vaccines (Pfizer-BioNTech and Moderna) provide evidence that indicates that efficacy against symptomatic disease begins as early as 12 to 14 days after the first dose of the mRNA vaccine. Excluding the first 14 days before vaccines are expected to offer protection, both vaccines showed an efficacy of 92% up until the second dose (most second doses were administered at 19-42 days in the trials). Recently, real world vaccine effectiveness data presented to or reviewed by NACI assessing PCR-positive COVID-19 disease and/or infection from Quebec, British Columbia, Israel, the United Kingdom and the United States support good effectiveness (generally 70-80%, depending on the methodology used and outcomes assessed) from a …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html">https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html</a></em></p>]]>
            </description>
            <link>https://www.canada.ca/en/public-health/services/immunization/national-advisory-committee-on-immunization-naci/rapid-response-extended-dose-intervals-covid-19-vaccines-early-rollout-population-protection.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360556</guid>
            <pubDate>Fri, 05 Mar 2021 18:58:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TikTok Popularity Growth or New Feature Increasing DNS Queries?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26360222">thread link</a>) | @serenadns
<br/>
March 5, 2021 | https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news | <a href="https://web.archive.org/web/*/https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>TikTok has been <a href="https://brandastic.com/blog/what-is-tiktok-and-why-is-it-so-popular/#:~:text=The%20TikTok%20app%20has%20been,123%20million%20from%20the%20U.S.&amp;text=Bytedance%20the%20company%20that%20owns,the%20world's%20most%20valuable%20startup%20.">growing in popularity</a> steadily since 2019 despite <a href="https://threatpost.com/tik-tok-ban-security-experts-dangers/159362/#:~:text=In%20fact%2C%20Comparitech%20evaluated%20TikTok,advocate%20with%20Comparitech%2C%20told%20Threatpost.">concerns over its security</a> in the US. It’s been <a href="https://www.oberlo.com/blog/tiktok-statistics#:~:text=The%20TikTok%20app%20has%20been,more%20than%2033%20million%20downloads.">downloaded over <strong>2 billion times</strong></a> and hit <a href="https://wallaroomedia.com/blog/social-media/tiktok-statistics/#:~:text=Monthly%20Active%20Users%20%E2%80%93%20TikTok%20has,of%20now%20(February%202021).">1 billion active monthly users</a> as of February 2021. For context, competitor app Instagram (owned by Facebook) had 1 billion active monthly users <a href="https://www.statista.com/statistics/253577/number-of-monthly-active-instagram-users/">back in 2018</a>. And TikTok seems poised to take the No. 1 spot in 2021.<br></p><p>We’ve been monitoring the growth of TikTok popularity on our network, as we’re curious about the app’s increased usage. DNSFilter is a product used primarily by other businesses, so we’ve been surprised by the use of TikTok on corporate networks.&nbsp;<br></p><p>In March 2020, TikTok DNS queries accounted for under .5% of our entire network traffic. By the end of July, it made up 1.3% of our network traffic—that was a 7x increase when looking at the number of queries. To put this into perspective, the entire <strong><em>category</em></strong> of shopping sites on our network at the end of July 2020 made up <strong>2% of our entire network</strong>.<br></p><p>I should note: There are over 14,000 companies that route their traffic through DNSFilter and we see roughly 12 billion DNS queries daily. So while our network does not allow us to view internet traffic as a whole, we <em>are</em> able to see overall trends.&nbsp;<br></p><p>In early February 2021, we noticed another major spike in traffic to TikTok:</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/604123432b07fa4bdec5385d_001h98GlCeJ2zwmnM1537Jf45q3Nty7WJCs91SYRWk34DgJuzYh9ssiI2mWZujOvTtGJAgxN7g0BfP809muA0Xrn3NxavqgdCR8qQxaBvGrYR8TvMtSB9LcDF4oFL87TMsRv9jsy.png" alt=""></p></figure><p>Prior to February 3, our network was resolving around 6.3 million TikTok queries daily (that number had held relatively steady since July 2020). The day of the spike, we saw 11.96 million queries. And as of February 25, we’ve seen as high as <em>15.15 million queries</em> in a day.<br></p><p>This made us ask the question: Did TikTok <em>really</em> see a 100% increase in traffic overnight? Or is there something else happening?</p><h2>Many domains, one application</h2><p>Before we go any further, I want to explain why one application is usually comprised of more than one domain. Applications like TikTok don’t use a single domain for all of the content on their service. Under the TikTok umbrella, there might be <em>hundreds</em> of domains.<br></p><p>The reason for all of these domains varies. One domain might be responsible for the TikTok site content, as in tiktok.com. Another domain might be a Content Delivery Network (CDN), a place to host files (such as the video content users host) that the application then “calls” for when someone wants to view that content. And then there might be service domains to host API endpoints.&nbsp;<br></p><p>Depending on their setup, they may use different hostnames for geographic scaling or simply as a method of distributing load. Not all applications do it this way, but it is one possibility. Doing it this way would mean those 1.5 billion TikTok users are served different domains based on their geolocation.</p><p>The ability to block and allow entire applications (as opposed to individual domains) is actually something we’re working on at DNSFilter and part of why we were able to identify this TikTok growth in the first place. <a href="https://dnsfilter.canny.io/feature-requests/p/additional-quick-lists-for-easy-blocking-of-popular-services">Keep an eye on our roadmap for updates</a>.</p><h2>Researching TikTok’s domain growth: Real or not?</h2><p>There is no doubt that starting February 3 there were more DNS queries accessing TikTok. The question is: What is the purpose of these queries?<br></p><p>Were these additional queries generated by users who are just using the site more? Were these queries initiated by <strong><em>TikTok </em></strong>or another service that uses them?&nbsp;<br></p><p>So with that, Domain Intelligence Lead Peter Lowe and I started digging into these questions.<br></p><p>Before looking into the actual queries, we first wanted to rule out any changes to <strong>caching</strong> or <strong>TTL</strong> (time to live). TTL is the lifespan of how long a domain name record is cached for. If the TTL has a shorter time out period, it will look like there are more requests to a domain. However, this didn’t seem to be the case for TikTok.<br></p><p>Next, we looked at the queries themselves. Of the domains under the umbrella of the TikTok application, which ones were requested the most?<br></p><p>Here, we got a clear answer: tiktokcdn[dot]com was responsible for this large spike in traffic. Here’s a comparison of the main TikTok domain to the tiktokcdn domain:</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/60412343fa7329ac84611b92_MQn0NsNR2PuWFBiRM-XJzDCc3BL3ZO-NEUMAc4D8nNJA986opKzDc18v9RHs8gORhORGui3sKjAU0RfJxW1NkCHX8W0g5oZeZbAbM9moIHDcqPkyOwNR7pjGlXXkft3ZqV690HDy.png" alt=""></p></figure><p>This domain was <strong><em>single handedly</em></strong> responsible for the spike in DNS queries.<br></p><p>Now that we knew the main domain making these queries, we could do a comparison between February 3 (the day of the spike) and January 27 (one week before). The reason we’d look at one week before as opposed to the day before is that domain queries generally tend to follow a pattern based on the day of the week. This way, we’re comparing apples to apples (or Wednesdays to Wednesdays).&nbsp;<br></p><p>We compared the total number of organizations and networks that accessed TikTok during this time—the numbers were essentially the same. In fact, January 27 actually had a few <em>more</em> organizations (and networks) connecting to TikTok than February 3.<br></p><p>Definitively, this spike was <em>not</em> based on new usage. It is based on new <em>queries</em>.<br></p><p>That this domain literally includes “CDN” in its name tells us it’s very likely a CDN domain. Though we can’t rule out that TikTok’s domain naming convention is purposefully meant to conceal the actual goal of the domain—but I promise we won’t get into conspiracy theories today.<br></p><p>Going with the assumption that this tiktokcdn[dot]com domain is <em>actually</em> a CDN domain where static files are hosted by TikTok, this still doesn’t answer the question of <em>who</em> is initiating these queries. An increase in CDN queries could mean users are suddenly requesting the same content as before (just more often), that the app itself is requesting content more frequently, or that another service (possibly owned by TikTok) is now using TikTok domains to serve content.<br></p><p>If you’re wondering how that third option would work, I’ll use the app <a href="https://www.goodreads.com/">Goodreads</a> as an example. Goodreads is owned by Amazon. When I open up my Goodreads app and then look in DNSFilter’s query log, I’ll see that I’ve accessed domains containing both “goodreads” and “amazon” in the domain names. In fact, in just a few minutes of clicking through my Goodreads history within the app, the application generates roughly 40 DNS queries: 32 of them include “Amazon” in the domain or subdomain name and only 8 actually include “Goodreads.”&nbsp;</p><h2>What happened on February 3?</h2><p>Our CEO, Ken Carnesi, is the one who first noticed the TikTok spike. He also found that on February 3 TikTok released an update. The only context he could find in the release notes for <a href="https://appmagic.rocks/ipad/tiktok/835599320/info?metrics=top_free">TikTok version 18.5.0</a> was a single line: “Share your favorite effects with friends.”<br></p><p>Could the purpose of these new queries be tied to this new “share your favorite effects” feature?&nbsp;<br></p><p>But there was another TikTok update on the same day that got a little more attention. <a href="https://newsroom.tiktok.com/en-us/new-prompts-to-help-people-consider-before-they-share">This&nbsp; particular update</a> was all about flagging unsubstantiated content to help fight fake news—something that’s been plaguing social platforms in recent years. According to TikTok, sometimes fact checks on videos that are flagged as misinformation are inconclusive. Rather than take the content down the content in question, TikTok released a new banner that would appear on possibly misleading information with the warning: “Caution: Video flagged for unverified content.”</p><figure><p><img src="https://assets.website-files.com/5fda06d4fe4b4ba14ad334dc/60412343d9397424fe443e00_g8ju0AT2WmSJHO86y1urHGBRES50rZV7NcUEdM6rZf-6lY8o8yL0OYtzXgRTVGwEaalgrtYi8MWla8Wan9YODAoH04-4cudgcinKRNTto50XztKz41lRTqiHM_QqfWMWuVhjAuLw.png" alt=""></p></figure><p>This new feature would alert content creators who receive a warning label on their video, load a warning label over said video, and if a user were to share a video they would be prompted with a message asking “Are you sure you want to share this video?”<br></p><p>All of these changes within the app would likely be served by a CDN. Next up was to test our hypothesis that one of these updates was linked to the increase in DNS queries.</p><h2>How many queries does TikTok generate?</h2><p>Applications generate a lot of queries.&nbsp;<br></p><p>Browsing on Instagram for 5 minutes can generate upwards of 300 queries—especially if you’re searching for new content. Applications like Fitbit run in the background and send queries regularly. While browsing Instagram for 5 minutes, Fitbit will likely send 4 DNS queries. And after just a minute of using the Fitbit app, I found nearly 100 queries in the DNSFilter query log.<br></p><p>Fitbit generates more queries than Instagram because it’s using DNS to lookup server IPs it's constantly sending data to, from my Fitbit device and app. Instagram might need to communicate with servers where files are hosted, but otherwise it’s not sending DNS queries to external devices.<br></p><p>Between 1:30 - 4:00, I had TikTok downloaded on my phone. In that time, I generated nearly 2,000 DNS queries—76% of them included “CDN” in the domain name.<br></p><p>But this isn’t that rare. Of the Fitbit queries I mentioned earlier, 73% of them were CDN domains. And 77% of the Instagram domain queries were CDN domains.<br></p><p>To dive into where these CDN queries were most active, I tracked usage across the app and would spent a period of time performing a single action. These were:<br></p><ul role="list"><li>Scrolled through recommended videos</li><li>Used the search feature</li><li>Flagged videos as misinformation</li><li>Clicked on videos with some type of warning</li><li>Favorited effects<br></li></ul><p>Of all of these actions, favoriting filters and sounds connected to CDN domains more than the rest—92% of queries during the period I favorited those items were CDN domains. Surprisingly, flagging misinformation and clicking on videos with warning resulted in the lowest number of CDN queries.</p><h2>What could be driving TikTok queries?</h2><p>Based on the CDN usage of just <em>favoriting</em> effects, it seems reasonable that sharing the effect would generate a large number of DNS queries. Considering there was an update on February 3, it’s possible that update is causing this prolonged spike in queries because it needs to communicate with CDN servers more often.<br></p><p>But we still have other theories.<br></p><p>Because the total number of DNS queries generated by TikTok and its competitor Instagram are similar (browsing TikTok for 5 minutes generated 196 queries while browsing Instagram generated 258), I think it’s possible that there is an <em>external</em> application using the tiktokcdn[dot]com domain. This could be a sister app of TikTok’s, like <a href="https://www.douyin.com/">Douyin</a>, or it could be another service that’s enabling users to post TikTok videos. In both cases, they’d need to refer to TikTok’s CDN servers.<br></p><p>Peter …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news">https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news</a></em></p>]]>
            </description>
            <link>https://www.dnsfilter.com/blog/tiktok-popularity-or-fake-news</link>
            <guid isPermaLink="false">hacker-news-small-sites-26360222</guid>
            <pubDate>Fri, 05 Mar 2021 18:36:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do What Makes the Best Story]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 53 (<a href="https://news.ycombinator.com/item?id=26359378">thread link</a>) | @tosh
<br/>
March 5, 2021 | https://amasad.me/story | <a href="https://web.archive.org/web/*/https://amasad.me/story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Kids are always telling themselves stories. Try to remember yourself as a child lying in bed, anticipating an exciting day tomorrow, and you'll probably remember telling yourself a story about how cool it's going to be, who's going to be there, and how much fun you'll have. Self storytelling might be more pronounced in kids -- they like to say it out loud -- but it never goes away and only subsides to the background in adults. Self storytelling is so essential for people that one of the most effective <a href="https://en.wikipedia.org/wiki/Cognitive_behavioral_therapy">techniques</a> for treating depression and anxiety boils down to "tell yourself better stories." </p>
<p>Life is also a form of self storytelling. We're continually retelling ourselves our life story, but very few people think of themselves as authors of their story, not mere subjects. People with extraordinary high-agency realize this early in life and start maximizing the interestingness of their life story.</p>
<p>Having a fascinating life story is not just an exercise in vanity -- it has a real impact on your success in life. You'll have an easier time attracting friends as well as life and business partners. It'll also make it much easier to sell yourself or your products. It has a kind of compounding <a href="https://en.wikipedia.org/wiki/Halo_effect">halo effect</a>.</p>
<p>Startups also have to be good stories. A good business idea or market is not enough to endure the pain and have the motivation to get a startup off the ground. Without an interesting story about the founding of the company and the vision, you'll have a hard time attracting talent and money. Notice how the most successful startups in the world all have remarkable genesis stories. </p>
<p>So next time you're faced with a tough decision, consider the path that makes a more interesting story. If it turned out to be the wrong decision to have made, you'd at least be fun at dinner parties.</p>

          </div></div>]]>
            </description>
            <link>https://amasad.me/story</link>
            <guid isPermaLink="false">hacker-news-small-sites-26359378</guid>
            <pubDate>Fri, 05 Mar 2021 17:26:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The reason Okta spent $6.5B on Auth0]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 138 (<a href="https://news.ycombinator.com/item?id=26358309">thread link</a>) | @advaitruia
<br/>
March 5, 2021 | https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0 | <a href="https://web.archive.org/web/*/https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png" loading="lazy" width="680" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" alt="Express session vs SuperTokens" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/okta_merged-14.png 2835w"></p><p>March 05, 2021</p>

<p>Okta acquired <a href="https://www.okta.com/press-room/press-releases/okta-signs-agreement-to-acquire-auth0/">Auth0 for $6.5B</a> in an all stock deal (Okta was valued at ~$35B in the few days preceding the
announcement).<br></p>
<p>In July last year, Auth0 <a href="https://auth0.com/blog/auth0-announces-120m-seriesf-funding/">raised $120M</a> in private financing at a valuation of $1.9B. The round was led by Salesforce
Ventures with participation from DTCP and other existing investors.<br></p>
<p><strong>The acquisition is a ~3.5X jump in Auth0â€™s valuation from last year.Â&nbsp;</strong><br></p>
<h2 id="Security">Why acquire Auth0 for $6.5B?</h2>

<ol role="list">
<li>
<p><span>Complementary product and revenue streamâ€¨<br></span>Oktaâ€™s
core strength is workforce identity and it used to be almost all of their revenue. In the last few years,
revenues from their customer identity product has grown to 25% of total revenues from almost nothing. Auth0
core strength is customer identity. With Auth0, Okta has the best product for both use cases.<br></p>
</li>
<li>
<p><span>Increasing addressable marketâ€¨<br></span>According to Todd,
the founder of Okta, workforce identity is a $30B market and customer identity is $25B. The customer identity
space effectively doubles Oktaâ€™s addressable market. In return, Okta is paying 20% of its market cap for that
opportunity.<br></p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png" loading="lazy" sizes="(max-width: 479px) 280px, (max-width: 767px) 500px, 640px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/marketing_okta.png 1582w" alt="">
</li>
<li>
<p><span>Competition and pricing power<br></span>Auth0 is the most
prominent alternative that customers consider when evaluating Okta. The acquisition of Auth0 eliminates that
threat and grants Okta pricing power as a result.<br></p>
</li>
<li>
<p><span>Go To Market (GTM) strategy<br></span>Okta is built as a top
down sales organisation whereas Auth0 is built with a developer first bottoms up acquisition strategy. This
allows Okta to get the best of both worlds.<br></p>
<p>In the words of the Founder and CEO of Auth0, â€œWe have a large thriving developer
community, which provides powerful grassroot support for Auth0 within SMB and enterprise that we leverage in
our sales motion. Our developer-led adoption fosters rapid customer growthâ€�<br></p>
</li>
<li>
<p><span>Strategic acquisition<br></span>There were rumours that
Salesforce was interested in acquiring Auth0. Given that Salesforce has made several key acquisitions (Slack,
Mulesoft, and others) and led Auth0â€™s last round, this is a well founded theory. It is possible that Okta had
to make a preemptive move. Weâ€™ve heard anecdotally that Salesforceâ€™s and Oracleâ€™s identity solution were both
performing badly and they were looking to do something about it. Auth0 was the perfect candidate for and was
also supposedly being shopped around.<br></p>
</li>
</ol>
<p>Finally, â€¨there was a Hackernews comment along the lines of: â€œ$6,500,000,000.00 for a company
providing authentication APIs?â€� and the sentiment has been echoed by others too.<br></p>
<p>The thing to note is that Okta isn't just acquiring an API or a product. Itâ€™s acquiring
$200M in recurring revenue thatâ€™s probably growing at 50%. As soon as Okta acquires its largest competitor, it can
also refactor Auth0â€™s (and itâ€™s own) pricing to increase revenue even further. So it's paying a lot upfront
for what it hopes will be even more in the future.Â&nbsp;<br></p>
<p>Now that we have some clarity on the acquisition, weâ€™ll be looking at how the (stock) market,
users and employees reacted to the news (largely drawn from Reddit, Hackernews and some personal
conversations)<br></p>
<h2><strong>Reactions (and what this means)</strong><br></h2>

<p><span>Market<br></span>Oktaâ€™s will acquire Auth0 in an all stock deal
and dilute existing shareholders by 20%. The 10% fall in the stock price (equivalent to a decrease in $3-4B)
immediately post the announcement means that investors are valuing Auth0 at half the price what Okta paid for
it.<br></p>
<p>Okta will issue shares to Auth0 shareholders at share price of $276.21, close to 20% less
than the current share price (at the time of writing).<br></p><p><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png" loading="lazy" sizes="(max-width: 479px) 320px, (max-width: 767px) 540px, 680px" srcset="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-500.png 500w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-800.png 800w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1080.png 1080w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19-p-1600.png 1600w, https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Screenshot-2021-03-05-at-17.35.19.png 1830w" alt=""></p><p><strong>Users<br>â€�</strong>In general, the developer community has had an unpleasant
experience with Okta. This is perhaps expected given that it is not a â€œdeveloper firstâ€� company. Below are some
excerpts taken from Hackernews.<br></p>
<p>â€œWe moved from Okta a few years ago after we basically received almost no actual real support
for a bunch of issues, even though we were paying a premium cost. Nobody cares about issues on their Githubâ€�. â€œWe
ended up switching to Auth0â€�, â€œshaved a decent amount off our costsâ€�. â€œIn the end we were much happier.â€�<br></p>
<p>â€œOkta requires you to "contact support" to turn on basic features like email
customization, and even though I'm a paying customer, I was given a multi-week estimate (after waiting a week
or two) for how long it would take to enable this featureâ€�<br></p>
<p>â€œWe use Okta for multiple AWS accounts and they "ran a bad migration" that deleted
half our permissions and took a month to resolve. On top of that, nothing appeared in the audit logs.â€�<br></p>
<p>â€œOkta as a business are a pain to deal with, and unless you meet their minimum spend
requirements (which are not told to you up-front) you're screwed.â€�<br></p>
<p><strong>Employees<br>â€�</strong>Similarly, employees were worried about Auth0, given their
experience with Oktaâ€™s culture and hiring process.<br></p>
<p>â€œI interviewed with both, and the process at Auth0 had me walk away with respect, while
contrasted with Okta that left me reminded that tech hiring is broken.â€�<br></p>
<p>â€œThe two companies couldn't be more different, with Auth0 embracing a remote-first-class
culture with creative interview processes, and Okta (pre-covid) being very much the opposite.â€�<br></p>
<p>I used to work on the Okta team.. As far as I could tell, Okta is a sales company. The
salespeople got the fancy events, the high floors with nice views, all the budgetâ€¦ Enterprise customers are the
only ones that mattered.. I got to know some people who came into Okta via acquisitions and letâ€™s just say itâ€™s
not a fun ride.â€�<br></p>
<h2><strong>What next for Auth0?</strong><br></h2>

<p>â€¨Officially the statement is that the â€œCompany will operate as an independent unit inside of
Okta as they look for paths to integration in the coming monthsâ€�.<br></p>
<h2><strong>What is the opportunity for SuperTokens?â€¨</strong><br></h2>

<ol role="list">
<li>
<p>The incumbents in the space are Okta, Auth0, Firebase and AWS Cognito. However, they are all closed source,
proprietary companies. We have a strong belief in our open source approach as it benefits all stakeholders -
customers, the community and us as a company. There are a few others who are taking this approach and there is
a strong possibility for a project like SuperTokens to reach the scale that matches the incumbents.<br></p>
</li>
<li>
<p>Consolidation typically creates small vacuums. It is our job, as the project creators, to understand which
vacuum (niche) is the strongest.Â&nbsp;<br></p>
</li>
<li>
<div><p>We claim to be truly developer friendly. <b>But what does that really mean?</b> How do we demonstrate
that?
</p><ul>
<li>First is <b>our open source approach</b> - we place developers and the community above all else.</li>Â&nbsp;
<li>Second is the <b>modular architecture of SuperTokens</b>. This enables developers to pick features
they need
for their use
case and forget about the complexity associated with everything else (for example, if you do not need SSO,
no
need worry about OAuth flows). It allows you to add authentication functionality as your product and
company
scale.
<strong>We even have different docs based on your feature set and use case.<br>â€�</strong>
</li>
<li>Finally, our
frontend
UI is the most customizable weâ€™ve seen of any of the alternatives. While Auth0 provides a ready made
frontend
or exposes the backend APIs to build your own frontend, we provide ready made frontends and make it far
easier
to build your own theme or customize existing ones.<br></li>
</ul>
</div>
</li>
</ol>
<p>Hope this added some insight into this massive development. Weâ€™re excited about the space and
are here to serve developers everyday.<br></p>
<p>Written by the Folks at <a href="https://supertokens.io/" aria-current="page">SuperTokens</a> â€” hope you enjoyed! We are always available on our Discord server.
Join us if you have any questions or need any help.<br></p>
<p><a rel="noopener" href="https://supertokens.io/discord" target="_blank"><img src="https://supertokens.io/static/webflow/blog/auth0-acquisition/images/Image-93x.png" loading="lazy" width="200" alt=""></a>
</p></div></div>]]>
            </description>
            <link>https://supertokens.io/blog/the-real-reason-okta-spent-on-auth0</link>
            <guid isPermaLink="false">hacker-news-small-sites-26358309</guid>
            <pubDate>Fri, 05 Mar 2021 16:02:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Two Classes of Software Engineer]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 61 (<a href="https://news.ycombinator.com/item?id=26356976">thread link</a>) | @wagslane
<br/>
March 5, 2021 | https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/ | <a href="https://web.archive.org/web/*/https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://qvault.io/2021/03/05/the-two-classes-of-software-engineer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356976</guid>
            <pubDate>Fri, 05 Mar 2021 14:06:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating ePub from LaTeX]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26356903">thread link</a>) | @ivan_ah
<br/>
March 5, 2021 | https://minireference.com/blog/generating-epub-from-latex/ | <a href="https://web.archive.org/web/*/https://minireference.com/blog/generating-epub-from-latex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://minireference.com/blog/generating-epub-from-latex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356903</guid>
            <pubDate>Fri, 05 Mar 2021 13:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rejuvenating WordPress Through GraphQL]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26356546">thread link</a>) | @jun-e
<br/>
March 5, 2021 | https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/ | <a href="https://web.archive.org/web/*/https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>WordPress is a legacy CMS: having been invented over 17 years ago, it's filled with PHP code that, given a new chance, it would be coded in a different way.</p><p>GraphQL is a modern interface to access data. Please notice the word "interface": it doesn't care how the underlying data system is implemented, but only how to expose the data.</p><p>What happens when we put these two together? How should we design the GraphQL interface to access data from WordPress?</p><p>There are a couple of obvious strategies that we can put in place:</p><ol><li><p>Respect tradition, and provide a mapping that keeps the WordPress data model as is, including the technical debt it accumulated during the years</p></li><li><p>Fix the technical debt, providing an interface exposing data in an abstract, not-necessarily-fixed-to-WordPress way</p></li></ol><p>Both approaches have benefits and drawbacks, and there is no right or wrong. It's just opinionatedness, prioritizing some behavior over another.</p><p>For plugin <a href="https://graphql-api.com/">GraphQL API for WordPress</a> I have chosen the latter approach, attempting to create a GraphQL schema that, even though it is based on WordPress and works for WordPress, it is not tied to WordPress (for instance, by removing inconsistent names and relationships).</p><p>The result is that GraphQL rejuvenates WordPress: while we still have WordPress as our underlying CMS, with its legacy PHP code, its data layer can be created anew, based on common sense, not tradition. The data layer goes back from being an adolescent, to become a toddler again.</p><p><img src="https://graphql-api.com/images/own-good-together-best.jpg" alt="GraphQL + WordPress rock" loading="lazy" width="577" height="433"></p><p>The result is <a href="https://newapi.getpop.org/graphql-interactive/">this GraphQL schema, representing the WordPress data model</a>, and also <a href="https://newapi.getpop.org/graphql-interactive/?mutation_scheme=nested">supporting nested mutations</a>.</p><p>Let's check out it was carried out.</p><h2 id="heading-the-wordpress-data-model">The WordPress data model<a href="#heading-the-wordpress-data-model"><span> permalink</span></a></h2><p>WordPress has the following entities:</p><ul><li>posts</li><li>pages</li><li>custom posts</li><li>media elements</li><li>users</li><li>user roles</li><li>tags</li><li>categories</li><li>comments</li><li>blocks</li><li>meta properties</li><li>others (options, plugins, themes, etc)</li></ul><p>These entities can have a hierarchy. For instance, post, page and media elements are both custom post types, and tags and categories are both taxonomies.</p><p>This is the WordPress database diagram, showing how data for all entities is stored:</p><figure><a href="https://graphql-api.com/assets/guides/query/wp-data-model.png" target="_blank"><img src="https://graphql-api.com/assets/guides/query/wp-data-model.png" alt="The WordPress database diagram" loading="lazy" width="793" height="1118"></a><figcaption>The WordPress database diagram</figcaption></figure><h2 id="heading-is-the-mapping-an-exact-replica-of-the-db-diagram">Is the mapping an exact replica of the DB diagram?<a href="#heading-is-the-mapping-an-exact-replica-of-the-db-diagram"><span> permalink</span></a></h2><p>When mapping the WordPress database into a GraphQL schema, is the same diagrame above respected 1 to 1?</p><p>No, it is not. While the database diagram is an actual implementation, GraphQL is an interface to access the data from the client. These two are related, but they can be different. GraphQL doesn't care about the database: it doesn't think in SQL commands, or know there are database tables called <code>wp_posts</code> and <code>wp_users</code>.</p><p>So we don't need to worry too much about the database diagram when creating the GraphQL schema for WordPress. That means that we can produce a GraphQL schema that fixes some of the technical debt from the WordPress data model.</p><h2 id="heading-mapping-the-wordpress-data-model-as-a-graphql-schema">Mapping the WordPress data model as a GraphQL schema<a href="#heading-mapping-the-wordpress-data-model-as-a-graphql-schema"><span> permalink</span></a></h2><p>Let's do the mapping. First, we map the original entities as types, as much as possible. From the list of entities in the WordPress data model, we produce the following types for the GraphQL schema:</p><ul><li><code>Post</code></li><li><code>Page</code></li><li><code>Media</code></li><li><code>User</code></li><li><code>UserRole</code></li><li><code>PostTag</code></li><li><code>PostCategory</code></li><li><code>Comment</code></li></ul><p>Then, we add all the expected fields to every type. To represent the schema, we can use the SDL, or Schema Definition Language. (This is used for documentation purposes only; the plugin itself does not use SDL to codify the schema: it's all PHP code).</p><p>These are the fields (among many others) for a <code>Post</code>:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span></code></pre><p>These are the fields (among many others) for a <code>User</code>:</p><pre><code><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>name</span><span>:</span> String</span><br><span>  <span>email</span><span>:</span> String<span>!</span></span><br><span><span>}</span></span></code></pre><p>We also create the corresponding connections, which are fields that return another entity (instead of a scalar, such as a number or a string). For instance, we represent a post having an author, and a user owning posts:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>author</span><span>:</span> User<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>posts</span><span>:</span> <span>[</span>Post<span>]</span></span><br><span><span>}</span></span></code></pre><p>Fields and connections can also accept arguments. For instance, we enable <code>Post.date</code> to be formatted, and <code>User.posts</code> to search entries and limit their number:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>posts</span><span>(</span><span>limit</span><span>:</span> Int<span>,</span> <span>search</span><span>:</span> String<span>)</span><span>:</span> <span>[</span>Post<span>]</span></span><br><span><span>}</span></span></code></pre><p>We keep doing this for all entities in the WordPress data model. Once we are done, we'll arrive at the GraphQL schema for WordPress, as visible using the Voyager client (available as "Interactive Schema" on the plugin's menu):</p><figure><a href="https://graphql-api.com/assets/guides/interactive-schema.png" target="_blank"><img src="https://graphql-api.com/assets/guides/interactive-schema.png" alt="The GraphQL schema for WordPress" loading="lazy" width="1680" height="976"></a><figcaption>The GraphQL schema for WordPress</figcaption></figure><p>This schema has similarities to the WordPress database diagram, but also many differences. Let's analyse them.</p><h3 id="heading-operations-without-entity-are-mapped-as-root-fields">Operations without entity are mapped as Root fields<a href="#heading-operations-without-entity-are-mapped-as-root-fields"><span> permalink</span></a></h3><p>In the WordPress database diagram represents how data is stored, so there is no "beginning". GraphQL, though, is an interface to retrieve data, hence there must be an initial stage from which to execute the query.</p><p>This initial stage is the <code>Root</code> type, or, to be more precise, the <code>QueryRoot</code> and <code>MutationRoot</code> types (to deal with queries and mutations, respectively).</p><p>In these two types, we map all operations that do not depend on an entity, such as when executing <code>get_posts()</code>, <code>get_users()</code> or <code>wp_signon()</code>:</p><pre><code><span><span>type</span> <span>QueryRoot</span> <span>{</span></span><br><span>  <span>posts</span><span>:</span> <span>[</span>Post<span>]</span><span>!</span></span><br><span>  <span>users</span><span>:</span> <span>[</span>User<span>]</span><span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>MutationRoot</span> <span>{</span></span><br><span>  <span>logUserIn</span><span>(</span><span>username</span><span>:</span> String<span>,</span> <span>password</span><span>:</span> String<span>)</span><span>:</span> User</span><br><span><span>}</span></span></code></pre><p>The fields do not need to have the same name or signature as the operation they represent. For instance, calling field <code>logUserIn</code> can be considered more suitable than <code>signOn</code>.</p><h3 id="heading-all-mutations-go-under-mutationroot">All mutations go under MutationRoot<a href="#heading-all-mutations-go-under-mutationroot"><span> permalink</span></a></h3><p>There are operations which do depend on an entity, such as <code>wp_update_post()</code>, which is applied on some post. The corresponding mutation on the GraphQL schema must be added to the <code>MutationRoot</code> type, because that's how GraphQL works.</p><p>Then, this operation is mapped like this:</p><pre><code><span><span>type</span> <span>MutationRoot</span> <span>{</span></span><br><span>  <span>updatePost</span><span>(</span><span>postID</span><span>:</span> ID<span>!</span><span>,</span> <span>newTitle</span><span>:</span> String<span>,</span> <span>newContent</span><span>:</span> String<span>)</span><span>:</span> Post</span><br><span><span>}</span></span></code></pre><p>This plugin also supports nested mutations, which are offered as an opt-in feature (because this is not standad GraphQL behavior). Then, mutations can also be added under any type, not just <code>MutationRoot</code>. In this case, we obtain:</p><pre><code><span><span>type</span> <span>Post</span> <span>{</span></span><br><span>  <span>update</span><span>(</span><span>newTitle</span><span>:</span> String<span>,</span> <span>newContent</span><span>:</span> String<span>)</span><span>:</span> Post<span>!</span></span><br><span><span>}</span></span></code></pre><h3 id="heading-dealing-with-custom-posts">Dealing with custom posts<a href="#heading-dealing-with-custom-posts"><span> permalink</span></a></h3><p>There is no type inheritance in GraphQL. Hence, we can't have a type <code>CustomPost</code>, and declare that <code>Post</code> and <code>Page</code> extend it.</p><p>GraphQL offers two resources to compensate for this lack: interfaces and union types.</p><p>For the first one, we create an interface <code>IsCustomPost</code> for the schema, declaring all the fields expected from a custom post, and we define types <code>Post</code> and <code>Page</code> to implement the interface:</p><pre><code><span><span>interface</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Post</span> <span>implements</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Page</span> <span>implements</span> <span>IsCustomPost</span> <span>{</span></span><br><span>  <span>title</span><span>:</span> String</span><br><span>  <span>content</span><span>:</span> String</span><br><span>  <span>excerpt</span><span>:</span> String</span><br><span>  <span>date</span><span>(</span><span>format</span><span>:</span> String<span>)</span><span>:</span> Date<span>!</span></span><br><span><span>}</span></span></code></pre><p>For the second one, we create a <code>CustomPostUnion</code> type for the schema returning all the custom post types:</p><pre><code><span><span>union</span> <span>CustomPostUnion</span> <span>=</span> Post <span>|</span> Page</span></code></pre><p>And have fields return this type whenever appropriate:</p><pre><code><span><span>type</span> <span>QueryRoot</span> <span>{</span></span><br><span>  <span>customPost</span><span>(</span><span>id</span><span>:</span> ID<span>)</span><span>:</span> CustomPostUnion</span><br><span>  <span>customPosts</span><span>:</span> <span>[</span>CustomPostUnion<span>]</span><span>!</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>User</span> <span>{</span></span><br><span>  <span>customPosts</span><span>:</span> <span>[</span>CustomPostUnion<span>]</span></span><br><span><span>}</span></span><br><span></span><br><span><span>type</span> <span>Comment</span> <span>{</span></span><br><span>  <span>customPost</span><span>:</span> CustomPostUnion<span>!</span></span><br><span><span>}</span></span></code></pre><p>As it can be observed, in the GraphQL schema we need to explicitly assert when we are dealing with posts, and when with custom posts, since they are not the same! Calling these two interchangeably is technical debt from WordPress, which we can fix.</p><p>For this reason, a custom post is always called <code>CustomPost</code> and not <code>Post</code>, a field dealing with custom posts is always called <code>customPosts</code> and not <code>posts</code>, and a field argument receiving the ID for a custom post is called <code>customPostID</code> and not <code>postID</code> (even though that's how it's called in the mapped WordPress function).</p><p>Then, the expectation is always clear:</p><ul><li>field <code>User.customPosts</code> can return a list of any custom post, including posts and pages, and <code>User.posts</code> only returns posts</li><li>field <code>Root.setFeaturedImageOnCustomPost</code> can add a featured image to any custom post, that's why it's not called <code>setFeaturedImageOnPost</code></li></ul><h3 id="heading-not-grouping-tags-(and-categories)-under-a-single-type">Not grouping tags (and categories) under a single type<a href="#heading-not-grouping-tags-(and-categories)-under-a-single-type"><span> permalink</span></a></h3><p>Why is type <code>PostTag</code> (and same for <code>PostCategory</code>) called like that, instead of just <code>Tag</code>?</p><p>Because, when executing this query (where a product is a CPT), the results from field <code>tags</code> for posts and products will always be different, non-overlapping:</p><pre><code><span><span>query</span> <span>{</span></span><br><span>  posts <span>{</span></span><br><span>    tags <span>{</span></span><br><span>      id</span><br><span>      name</span><br><span>    <span>}</span></span><br><span>  <span>}</span></span><br><span>  products <span>{</span></span><br><span>    tags <span>{</span></span><br><span>      id</span><br><span>      name</span><br><span>    <span>}</span></span><br><span>  <span>}</span></span><br><span><span>}</span></span></code></pre><p>Tags added to posts will not show up when retrieving tags for products, and the other way around (unless a product also uses the <code>post_tag</code> taxonomy, but then it can also be represented with the <code>PostTag</code> type). This does not represent a big deal in WordPress, since these items can be considered different rows from the same database table. But it does matter for GraphQL, which is strongly typed.</p><p>Then, it's a good design decision to keep these entities separate, under their own types, and have tags for posts returned under the <code>PostTag</code> type and, if a custom plugin implements its own product CPT, it must use the <code>ProductTag</code> type for its tags.</p><h3 id="heading-giving-media-items-their-own-identity">Giving media items their own identity<a href="#heading-giving-media-items-their-own-identity"><span> permalink</span></a></h3><p>Media entities in WordPress are custom post types, only because it was convenient from an implementation point of view. However, the GraphQL schema can avoid this technical debt, and model media elements as a distinct entity, not as custom posts.</p><p>This implies the following decisions for the GraphQL schema:</p><ul><li>When querying field <code>customPosts</code>, it will not fetch media elements</li><li>The <code>Media</code> type does not implement the <code>IsCustomPost</code> interface, and won't be part of the <code>CustomPostUnion</code> type</li><li>The <code>Media</code> type doesn't have many fields expected from a custom post type, such as <code>excerpt</code>, <code>date</code> and <code>status</code>. Instead, it only has those fields expected from a media element:</li></ul><pre><code><span><span>type</span> <span>Media</span> <span>{</span></span><br><span>  <span>id</span><span>:</span> ID<span>!</span></span><br><span>  <span>src</span><span>:</span> String<span>!</span></span><br><span>  <span>width</span><span>:</span> Int</span><br><span>  <span>height</span><span>:</span> Int</span><br><span><span>}</span></span></code></pre><h3 id="heading-identifying-and-mapping-enums">Identifying and mapping enums<a href="#heading-identifying-and-mapping-enums"><span> permalink</span></a></h3><p>In some situations, WordPress uses fixed values from a given set. For instance, the status of a post can only be <code>"publish…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/">https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/</a></em></p>]]>
            </description>
            <link>https://graphql-api.com/blog/rejuvenating-wordpress-through-graphql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356546</guid>
            <pubDate>Fri, 05 Mar 2021 13:22:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Case for building Client-First web apps  (2020)]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26356391">thread link</a>) | @EGreg
<br/>
March 5, 2021 | https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/ | <a href="https://web.archive.org/web/*/https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Now that 2020 is here, let’s look at what we can expect from the next decade in software. As Web developers, our solutions can help shape the organizations we work for. The tools we build and the architectural decisions we make have a compounding effect on society at large. What are the new trends, and will they help empower or enslave people?</p>
<h2>The Old Trends</h2>
<p>The trends in the last 10-20 years have led to more and more&nbsp;<a href="https://qbix.com/blog/2017/08/20/centralization-and-open-source/">centralization of the Web</a>, consolidation of power in the hands of the largest services (Facebook, Google, Amazon, Reddit) and their extended ecosystems. Between these and the large publications, the “independent Web” has suffered a tremendous setback. Most people and organizations trust large corporations with proprietary algorithms to manage their data, identity and brand. This has led to&nbsp;<a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">massive new issues for individuals and society</a>, involving governments and corporations, and how we all relate to one another. Attempts to resolve these issues have spawned some projects to&nbsp;<a href="https://qbix.com/blog/2017/08/30/the-future-of-decentralization/">decentralize the Web</a>.</p>
<p>When the Web was born, browsers rendered HTML documents, and there was very little support for client-side programming. Whatever Javascript support was introduced over the next decade was inconsistent because of the&nbsp;<a href="https://en.wikipedia.org/wiki/Browser_wars">browser wars</a>, and led to&nbsp;<a href="http://www.jqueryvsmootools.com/">Javascript libraries</a> to bridge the gap, of which jQuery emerged as the winner. The last 10 years saw the rise of&nbsp;<a href="https://angular.io/">Angular</a> and&nbsp;<a href="https://reactjs.org/">React</a>, new versions of&nbsp;<a href="https://developer.mozilla.org/en-US/docs/Web/Guide/HTML/HTML5">Javascript</a> and&nbsp;<a href="https://developer.mozilla.org/en-US/docs/Web/API">HTML5 Web APIs</a>, which finally made front-end Web programming a powerful proposition on the most widely deployed platform in the world.</p>
<h2>Client-First Web Apps</h2>
<p>As Javascript was maturing, a conventional wisdom has developed among most Web developers, that you should render the HTML on the client side, and then progressively enhance it with Javascript. This was considered best practice and recommended by pretty much every authority from&nbsp;<a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2009</a> to&nbsp;<a href="https://www.freecodecamp.org/news/what-is-progressive-enhancement-and-why-it-matters-e80c7aaf834a/">2018</a>.</p>
<p>In this decade, Web developers will turn this conventional wisdom on its head, and start to consider progressive enhancement to go the other way:</p>
<ol>
<li>First, develop static HTML, CSS and Javascript</li>
<li>Make Javascript fetch data from servers, render it on the client</li>
<li>Progressively enhance the site for older environments (Server-rendered HTML)</li>
</ol>
<p>What follows are multiple reasons for why this is the better approach going forward.&nbsp;This one shift in how we approach Web development will have profound technological and societal implications.</p>
<h2 id="distributing-software">Distributing Software</h2>
<p><strong>1. Separation of concerns.</strong> It pays to decouple the rendering of an interface from the delivery of code / markup. That way we are not tied to one type of app delivery — that of a server on the web sending our executable code. We are able to&nbsp;<a href="https://en.wikipedia.org/wiki/Sideloading">sideload apps</a>, download them from&nbsp;<a href="https://developer.apple.com/documentation/bundleresources">app stores</a>, and update specific files when they have changed. And we use one language for each task, too: JS is the code. HTML / Handlebars / etc. can be used for templates / markup. CSS is used for presentation. JSON or XML is used for data. After you have done this, if you want to pre-render HTML on a server for AJAX, you can, but will start to feel “dirty” as you’ll be coupling things unnecessarily again. Things are going this way as&nbsp;<a href="https://www.gatsbyjs.org/blog/2019-10-15-free-headless-cms/">headless CMSes</a> are making an appearance, while&nbsp;<a href="https://cordova.apache.org/">Cordova</a>,&nbsp;<a href="https://ionicframework.com/">Ionic</a> and&nbsp;<a href="https://facebook.github.io/react-native/">React Native</a> represent other ways of delivering code through app stores.</p>
<p><strong>2. Trust. </strong>You can’t trust what code is running remotely (although Signal&nbsp;<a href="https://signal.org/blog/private-contact-discovery/">has been experimenting</a> with using&nbsp;<a href="https://software.intel.com/en-us/articles/innovative-technology-for-cpu-based-attestation-and-sealing">Software Guard Extensions</a> by CPU makers, originally designed for DRM, to go the other way and ensure what code runs on a server). But even if you can, you have no guarantee some other process won’t steal or corrupt your data. The&nbsp;<a href="https://en.wikipedia.org/wiki/Trusted_computing_base">Trusted Computing Base</a> should not include arbitrary amounts of remote sites shipping code at any time. Decoupling how the code is loaded (see point #1) onto your client allows you or your user agent to verify checksums and certify that it is indeed the code you think it is. And it is that code that should be managing your data and using the personal keys on your device. Package managers and app stores will be able to distribute code that has been audited by third-party security firms, and people will be able to trust them.</p>
<p><strong>3. Decentralization of Code.</strong> As the next decade unfolds, we will find that&nbsp;code bases don’t necessarily have to live shrink-wrapped on a specific server. Rather, clients can use multiple interoperable software modules and versions and can have multiple app stores and distributors in the future helping maintain repos and package managers for end-users and organizations. We will probably see automated package management become more user friendly in the 2020s, as we already have a docker container culture, we have browser based package managers etc.</p>
<h2 id="data-ownership">Data Ownership</h2>
<p><strong>4. Decentralization of Data.</strong> This is the big one in terms of effect on society. By having web servers render your webpage, you are implicitly locking yourself and your organization into the type of model where the servers store and access the data in a private database. They have enough data to render everything, apply access control rules to manage what you can read and write, and so on. Instead, we as a society need to empower people and their client side apps, and push the logic of fetching data, caching it and assembling it to the&nbsp;<a href="https://continuations.com/post/108271329110/tedxnewyork-big-and-bot-policy-proposals">user agents</a>. We can use&nbsp;<a href="https://en.wikipedia.org/wiki/Capability-based_security">capabilities</a> /&nbsp;<a href="https://www.oauth.com/oauth2-servers/access-tokens/">access tokens</a> for data instead of a centralized site rendering HTML.&nbsp;In this way, always inverting the progressive enhancement is an&nbsp;<em>activist</em> position to change society against the abuses of power&nbsp;<a href="https://qbix.com/blog/2019/03/08/how-qbix-platform-can-change-the-world/">like the ones listed here</a>.</p>
<p><strong>5. Reliability</strong> After the 2015 ISIS attacks in Paris, countries around the world expressed solidarity with the French people. French colors were flown, but similar-sized attacks at the same time by ISIS in&nbsp;<a href="https://www.nytimes.com/2015/11/16/world/middleeast/beirut-lebanon-attacks-paris.html?smid=tw-nytimesworld&amp;smtyp=cur&amp;_r=0">Beirut</a> were totally forgotten. Facebook rolled out a feature to customize one’s profile with the French flag superimposed, but only the French flag. So we used the Qbix Platform to quickly build a small app called&nbsp;<a href="https://customizemypic.com/">customizemypic.com</a> to allow anyone to change their profile picture to a flag of their choice. The goal was to make a statement and express solidarity with people in Beirut, Baghdad and other areas hard hit by terrorism. Today, that same app is no longer able to do its core function because Facebook&nbsp;<a href="https://developers.facebook.com/blog/post/2018/04/24/new-facebook-platform-product-changes-policy-updates/">removed any way for users to give permissions to apps</a> to upload a photo on their behalf. This is what happens when you rely on third parties to announce what you can and cannot do with your own profile picture. The most extreme reliability is achieved by an&nbsp;<a href="http://offlinefirst.org/">offline-first</a> approach, which is a close cousin of the client-first trend that will grow in the 2020s.</p>
<p><strong>6. End to End Encryption.</strong> Server-side rendering perpetuates a culture where the server has all the data unencrypted. Even if the data is encrypted at rest, the served holds all the decryption keys and is one central target for hackers, government agencies, and advertisers. Rendering things client-side goes hand-in-hand with a culture of people storing their own keys on devices of their choice, and letting key management and password management be the domain of operating systems and trusted computing bases, not random websites.</p>
<h2 id="Data Delivery">Data Delivery</h2>
<p><strong>7. Bandwidth.</strong> Ever since&nbsp;<a href="https://www.youtube.com/watch?v=rm8FAHGJB3M">Steve Jobs presented WebObjects</a>, we have wanted sites to render dynamically. Well, that often involves looping through various items and rendering each one. It is extremely wasteful to send the HTML results of rendering hundreds of items to a client, when you could have just sent the data, which would then be “hydrated” into 5. templates by the client. However, I can understand pre-rendering just the items above the fold (if one could estimate this number, not knowing the size of the window on the first request).</p>
<p><strong>8. Caching Issues.</strong> Often, you have subtle and pervasive changes on every page when a person is logged in vs out. (I should remark that “logging in” into a site itself is an artifact of “centralized” thinking, but I digress.) Their avatar might be rendered in various places. New links are shown that might not be available otherwise. And new information may be shown that access control and discovery suggestions determines they can see. If you render everything on the served, there is no way to cache most of the fragments of the page, because they are changing. If you render client-side, all this comes for free.</p>
<h2 id="next-steps">Next Steps for Web Developers</h2>
<p>So by now you may be convinced that “client-first” is a good design pattern and progressive enhancement can be implemented later, by “speeding up” the first render, and by making it available to “dumb” crawlers and user agents who don’t execute Javascript in 2020. Here is how that would actually look, in actionable terms:</p>
<p><strong>9. Preloading. </strong>Okay, now that you are rendering everything client-side, you can implement a mechanism to preload data from the server. Perhaps put all the JSON in one file and send it over on the first render. Which — remember — happens only when you use a Web Browser to visit a page directly, a very specific scenario. Every other request besides that, including subsequent requests from a web browser, don’t need this preload. It’s an extra flair you can add for that specific use case. So the preloaded data comes and your Javascript will already have it and will render the HTML synchronously and quickly.</p>
<p><strong>10. Static Site Generation. </strong>The most popular static site generators today are still pretty narrow in their use-case. They help with blogs and publishing, eg&nbsp;<a href="https://jekyllrb.com/">Jekyll</a>,&nbsp;<a href="https://gohugo.io/">Hugo</a>, etc. But if you already have a dynamic site, you can sort of transform it into a static site by having a server-side script request some (dynamically specified) set of pages and render them to some related static html documents, and then begin sending 301 redirects on the dynamic pages to permanently tell browsers to go to the static pages in the future. (Because rewriting all links in your site may be infeasible). This approach runs into problems I described in point 5 — so a naive approach would only work for publicly accessible pages …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/">https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</a></em></p>]]>
            </description>
            <link>https://qbix.com/blog/2020/01/02/the-case-for-building-client-first-web-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356391</guid>
            <pubDate>Fri, 05 Mar 2021 13:05:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure from a Schemer's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 62 (<a href="https://news.ycombinator.com/item?id=26356367">thread link</a>) | @todsacerdoti
<br/>
March 5, 2021 | https://www.more-magic.net/posts/thoughts-on-clojure.html | <a href="https://web.archive.org/web/*/https://www.more-magic.net/posts/thoughts-on-clojure.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Recently I joined <a href="https://www.bevuta.com/">bevuta IT</a>, where I am now working on a big project written in <a href="https://www.clojure.org/">Clojure</a>.  I'm very fortunate to be working in a Lisp for my day job!</p>
<p>As I've mostly worked with Scheme and have used other Lisps here and there, I would like to share my perspective on the language.</p><a href="#overall-design">
<h2 id="overall-design">Overall design</h2></a>
<p>From a first view, it is pretty clear that Clojure has been designed from scratch by (mostly) one person who is experienced with Lisps and as a language designer.  It is quite clean and has <a href="https://download.clojure.org/papers/clojure-hopl-iv-final.pdf">a clear vision</a>. Most of the standard library has a very consistent API.  It's also nice that it's a <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">Lisp-1</a>, which obviously appeals to me as a Schemer.</p>
<p>My favourite aspect of the language is that everything is designed with a functional-first mindset.  This means I can program in the same functional style as I tend to do in Scheme.  Actually, it's even more functional, because for example its maps (what would be hash tables in Scheme) are much less clunky to deal with.  In Scheme, SRFI-69 hash tables are quite imperative, with <tt>hash-table-set!</tt> and <tt>hash-table-update!</tt> being the ways to insert new entries, which of course mutate the existing object.  Similarly, vectors can easily be extended (on either end!) functionally.</p>
<p>The underlying design of Clojure's data structures must be different. It needs to efficiently support functional updates; you don't want to fully copy a hash table or vector whenever you add a new entry. I am not sure how efficient everything is, because the system I'm working on isn't in production yet.  A quick look <a href="https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/PersistentArrayMap.java">at the code</a> implies that various data structures are used under the hood for what looks like one data structure in the language.  That's a lot of complexity!  I'm not sure that's a tradeoff I'd be happy to make.  It makes it harder to reason about performance.  You might just be using a completely different underlying data structure than expected, depending on which operations you've performed.</p><a href="#non-lispiness">
<h2 id="non-lispiness">(non) Lispiness</h2></a>
<p>To a seasoned Lisp or Scheme programmer, Clojure can appear positively <i>bizarre</i>.  For example, while there is a <tt>cons</tt> function, there are no cons cells, and <tt>car</tt> and <tt>cdr</tt> don't exist.  Instead, it has <tt>first</tt> and <tt>rest</tt>, which are definitely saner names for a language designed from scratch.  It has "persistent lists", which are immutable lists, but in most day to day programming you will not even be <b>using</b> lists, as weird as that sounds!</p><a href="#symbols-and-keywords">
<h3 id="symbols-and-keywords">Symbols and keywords</h3></a>
<p>One thing that really surprised me is that symbols are not interned. This means that two symbols which are constructed on the fly, or when read from the same REPL, are not identical (as in <tt>eq</tt> or <tt>eq?</tt>) to one another:</p>
<pre><tt>user&gt; <span>(<span>= 'foo 'foo</span>)</span>
true
user&gt; <span>(<span>identical? 'foo 'foo</span>)</span>
false</tt></pre>
<p>Keywords seem to fulfil most "symbolic programming" use cases.  For example, they're almost always used as "keys" in maps or when specifying options for functions.  Keywords <i>are</i> interned:</p>
<pre><tt>user&gt; <span>(<span>= <span>:foo</span> <span>:foo</span></span>)</span>
true
user&gt; <span>(<span>identical? <span>:foo</span> <span>:foo</span></span>)</span>
true</tt></pre>
<p>Code is still (mostly) expressed as lists of symbols, though.  When you're writing macros you'll deal with them a lot.  But in "regular" code you will deal more with keywords, maps and vectors than lists and symbols.</p><a href="#numeric-tower">
<h3 id="numeric-tower">Numeric tower</h3></a>
<p>A favorite gotcha of mine is that integers <a href="https://clojure.org/reference/data_structures#Numbers">are not automatically promoted to bignums</a> like in most Lisps that support bignums.  If you need bignums, you have to use special-purpose operators like <tt>+'</tt> and <tt>-'</tt>:</p>
<pre><tt>user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
Execution error <span>(<span>ArithmeticException</span>)</span> at user/eval51159 <span>(<span>REPL:263</span>)</span>.
integer overflow
user&gt; <span>(<span>*' <span>(<span>bit-shift-left 1 62</span>)</span> 2</span>)</span>
9223372036854775808N

user&gt; <span>(<span>* <span>(<span>bit-shift-left 1 62</span>)</span> 2N</span>)</span> 9223372036854775808N
user&gt; <span>(<span>* 1N 1</span>)</span> 1N</tt></pre>
<p>This could lead to better performance at the cost of more headaches when dealing with the accidental large numbers in code that was not prepared for them.</p>
<p>What about rationals, you ask?  Well, those are just treated as "the unusual, slow case".  So even though they <i>do</i> normalize to regular integers when simplifying, operations on those always return BigInts:</p>
<pre><tt>user&gt; <span>(<span>+ 1/2 1/4</span>)</span>
3/4
user&gt; <span>(<span>+ 1/2 1/2</span>)</span>
1N
user&gt; <span>(<span>/ 1 2</span>)</span> 1/2
user&gt; <span>(<span>/ 4 2</span>)</span> 2</tt></pre>
<p>The sad part is, bitwise operators do not support bignums, <i>at all</i>:</p>
<pre><tt>user&gt; <span>(<span>bit-shift-right 9223372036854775808N 62</span>)</span>
Execution error <span>(<span>IllegalArgumentException</span>)</span> at user/eval51167 <span>(<span>REPL:273</span>)</span>.
bit operation not supported for: class clojure.lang.BigInt
user&gt; <span>(<span>bit-shift-right' 9223372036854775808N 62</span>)</span> Syntax error compiling at <span>(<span>*cider-repl test:localhost:46543<span>(<span>clj</span>)</span>*:276:7</span>)</span>.
Unable to resolve symbol: bit-shift-right' in this context</tt></pre>
<p>There's one benefit to all of this: if you know the types of something going into numeric operators, you will typically know the type that comes out, because there is no automatic coercion.  Like I mentioned, this may provide a performance benefit, but it also simplifies reasoning about types.  Unfortunately, this does not work as well as you would hope because division may change the type, depending on whether the result divides cleanly or not.</p><a href="#syntax">
<h3 id="syntax">Syntax</h3></a>
<p>For many Lispers, this is the elephant in the room.  Clojure certainly qualifies as a Lisp, but it is much heavier on syntax than most other Lisps.  Let's look at a small contrived example:</p>
<pre><tt><span>(<span><i><span>let</span></i> [foo-value <span>(<span>+ 1 2</span>)</span>
      bar-value <span>(<span>* 3 4</span>)</span>]
  {<span>:foo</span> foo-value
   <span>:bar</span> bar-value}</span>)</span></tt></pre>
<p>This is a <tt>let</tt> just like in Common Lisp or Scheme.  The bindings are put inside square brackets, which is literal syntax for <i>vectors</i>.  Inside this vector, key-value pairs are interleaved, like in a Common Lisp <a href="http://www.lispworks.com/documentation/lw50/CLHS/Body/26_glo_p.htm#property_list">property list</a>.</p>
<p>The lack of extra sets of "grouping" parentheses is a bit jarring at first, but you get used to it rather quickly.  I still mess up occasionally when I accidentally get an odd number of entries in a binding vector.  Now, the <tt>{:foo foo-value :bar bar-value</tt>} syntax is a <i>map</i>, which acts like a hash table (more on that below).</p>
<p>There doesn't seem to be a good rationale about why vectors are used instead of regular lists, though.  What I <i>do</i> really like is that all the binding forms (even function signatures!) support <a href="https://clojure.org/guides/destructuring">destructuring</a>.  The syntax for destructuring maps is a bit ugly, but having it available is super convenient.</p>
<p>What I regard as a design mistake is the fact that Clojure allows for optional commas in lists and function calls.  Commas are just whitespace to the reader.  For example:</p>
<pre><tt><span>(<span>= [1, 2, 3, 4] [1 2 3 4]</span>)</span> =&gt; true
<span>(<span>= '<span>(<span>1, 2, 3, 4</span>)</span> '<span>(<span>1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= {<span>:foo</span> 1, <span>:bar</span> 2, <span>:qux</span> 3} {<span>:foo</span> 1 <span>:bar</span> 2 <span>:qux</span> 3}</span>)</span> =&gt; true
<span>(<span>= <span>(<span>foo 1, 2, 3, 4</span>)</span> <span>(<span>foo 1 2 3 4</span>)</span></span>)</span> =&gt; true
<span>(<span>= [,,,,,,1,,,2,3,4,,,,,,] [1 2 3 4]</span>)</span> =&gt; true</tt></pre>
<p>Maybe this is to make up for removing the extra grouping parentheses in <tt>let</tt>, <tt>cond</tt> and map literal syntax?  With commas you can add back some clarity about which items belong together.  Rarely anybody uses commas in real code, though.  And since it's optional it doesn't make much sense.</p>
<p>This has an annoying ripple effect on quasiquotation.  Due to this decision, a different character has to be used for <tt>unquote</tt>, because the comma was already taken:</p>
<pre><tt>`<span>(<span>1 2 ~<span>(<span>+ 1 2</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3</span>)</span>
`<span>(<span>1 2 ~@<span>(<span>list 3 4</span>)</span></span>)</span> =&gt; <span>(<span>1 2 3 4</span>)</span></tt></pre>
<p>This might seem like a small issue, but it is an unnecessary and stupid distraction.</p><a href="#minimalism">
<h2 id="minimalism">Minimalism</h2></a>
<p>One of the main reasons I enjoy Scheme so much is its goal of minimalism.  This is achieved through elegant building blocks.  This is embodied by the <a href="https://schemers.org/Documents/Standards/R5RS/HTML/r5rs-Z-H-3.html#%_chap_Temp_3">Prime Clingerism</a>:</p>
<pre><tt>  Programming languages should be designed not by piling feature on
  top of feature, but by removing the weaknesses and restrictions
  that make additional features appear necessary.</tt></pre>
<p>Let's check the size of the <tt>clojure.core</tt> library.  It clocks in at 640 identifiers (v1.10.1), which is a lot more than R5RS Scheme's 218 identifiers.  It's not an entirely fair comparison as Scheme without SRFI-1 or SRFI-43 or an FFI has much less functionality as well. Therefore, I think Clojure's core library is fairly small but not exactly an exercise in minimalism.</p>
<p>Clojure reduces its API size considerably by having a "<a href="https://clojure.org/reference/sequences">sequence</a> abstraction". This is similar to Common Lisp's sequences: you can call <tt>map</tt>, <tt>filter</tt> or <tt>length</tt> on any sequence-type object: lists, vectors, strings and even maps (which are treated as key/value pairs). However, it is less hacky than in Common Lisp because for example with <tt>map</tt> you don't need to specify which kind of sequence you want to get back.  I get the impression that in Common Lisp this abstraction is not very prominent or used often but in Clojure <i>everything</i> uses sequences.  What I also liked is that sequences can be <i>lazy</i>, which removes the need for special operators as well.</p>
<p>If you compare this to Scheme, you have special-purpose procedures for every concrete type: <tt>length</tt>, <tt>vector-length</tt>, <tt>string-length</tt> etc.  And there's no <tt>vector-map</tt> in the standard, so you need <a href="https://srfi.schemers.org/srfi-43/srfi-43.html#vector-map"><tt>vector-map</tt> from SRFI 43</a>.  Lazy lists are a <a href="https://srfi.schemers.org/srfi-41/srfi-41.html">separate type</a> with its own set of specialized operators.  And so on and so forth.  Using concrete types everywhere provides for less abstract and confusing code and the performance characteristics of an algorithm tend to be clearer, but it also leads to a massive growth in library size.</p>
<p>After a while I really started noticing mistakes that make additional features appear necessary: for example, there's a special macro called <tt>loop</tt> to make tail recursive calls.  This uses a keyword <tt>recur</tt> to call back into the loop.  In Scheme, you would do that with a named <tt>let</tt> where you can choose your own identifier to recur.  It's also not possible to nest such Clojure loops, because the identifier is hardcoded.  So, this called for adding <a href="https://archive.clojure.org/design-wiki/display/design/Named%2Bloops%2Bwith%2Brecur-to.html">another feature</a>, which is currently in proposal.  Speaking of <tt>recur</tt>, it is also used for tail recursive self-calls.  It relies on the programmer rather than the compiler to mark calls as tail recursive. I find this a bit of a cop-out, especially in a language that is so heavily functional.  Especially since this doesn't work for mutually tail-recursive functions.  The <a href="https://www.windley.com/archives/2008/11/tail_optimized_mutual_recursion_in_clojure.shtml">official way to do those</a> is even more of a crutch.</p>
<p>I find the special syntax for one-off lambdas <tt>#(foo %)</tt> just as misguided as <a href="https://srfi.schemers.org/srfi-26/srfi-26.html">SRFI 26</a> (<tt>cut</tt> and <tt>cute</tt>).  You often end up needing to tweak the code in such a way that you have …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.more-magic.net/posts/thoughts-on-clojure.html">https://www.more-magic.net/posts/thoughts-on-clojure.html</a></em></p>]]>
            </description>
            <link>https://www.more-magic.net/posts/thoughts-on-clojure.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26356367</guid>
            <pubDate>Fri, 05 Mar 2021 13:01:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bring Your Own Client]]>
            </title>
            <description>
<![CDATA[
Score 496 | Comments 224 (<a href="https://news.ycombinator.com/item?id=26355779">thread link</a>) | @pcr910303
<br/>
March 5, 2021 | https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html | <a href="https://web.archive.org/web/*/https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Just a little note about the main problem I'm pondering these days...</p><div><p>It’s delightful to have the freedom to <strong>Bring Your Own Client (BYOC)</strong>: to choose your favorite application to interact with some data.</p>

<p>For example, I can program with Sublime Text, while my teammate uses vim, and we don’t need to fight to the death to pick one editor between us. There are dozens of text editors to choose from, and no lock-in from proprietary file formats.</p>

<p>Contrast this with Google Docs: in order to live collaborate with each other, we all need to use the same editor. For someone who spends their whole working day in Google Docs, this can be a serious limitation. I personally hate doing substantial writing in Google Docs.</p>

<p>In cloud apps, the live collaboration logic is usually coupled to a specific editor; even if Google wanted to expose an API for editing Google Docs in third-party editors, it would probably be very challenging. The situation is nicer with text editors and git, because editing is decoupled from collaboration logic. Our team only needs to agree on a version control solution, which exposes a simple API (local text files) that many editors can interact with.</p>

<p>To be fair, local vs cloud isn’t the only factor here—even in local software, collaborators are often forced to converge on a single proprietary client (Microsoft Office, Adobe suite); conversely, a cloud service can support a third-party client ecosystem with the right APIs and attitude. Still, cloud apps exacerbate the problem. With local files, there’s some default openness built in; even proprietary file formats can be reverse-engineered. With cloud apps, the default is a single official client, unless the service actively exposes an API (and doesn’t shut it down—looking at you, Twitter).</p>

<p>It seems like local-first software is a good foundation for promoting Bring Your Own Client more broadly. What would it look like to have a thriving ecosystem of third-party clients for Google Docs style word processing, which can all interoperate with each other, even supporting realtime collaboration?</p>

<h2 id="concrete-examples">Concrete examples</h2>

<p>Some successful existing examples of client ecosystems built around open standards:</p>

<ul>
<li>text editors / IDE</li>
<li>RSS readers</li>
<li>email clients</li>
<li>web browsers</li>
</ul>

<p>Places where I want to have BYOC:</p>

<ul>
<li>Google Docs. I wish I could write this very doc in my preferred editor, locally, but have also support for inline comments and live collaboration. Might it be possible to build a VSCode extension that edits Google Docs live? (Tricky, because Google doesn’t have a nice API to integrate with, but maybe doable)</li>
<li>Google Slides</li>
<li>Figma</li>
<li>Notion</li>
<li>Trello / Asana / shared todo lists</li>
<li>multiplayer code editor: live collaboration as in repl.it</li>
</ul>

<h2 id="finer-granularity">Finer granularity</h2>

<p>Today we generally think about BYOC at the “app” level. But can we go finer-grained than that, picking individual interface elements?</p>

<p>Instead of needing to pick a single email client, can I compose my favorite email client out of an inbox, a compose window, and a spam filter?</p>

<h2 id="problems-questions">Problems / questions</h2>

<ul>
<li><strong>Schema compatibility</strong>: do all the editors need to agree on a single rigidly specified format? If there are reconcilable differences between formats, can we build “live converters” that convert between them on every change? (Essentially, imagine collaborating between Pages and Microsoft Word, running a file export in both directions on every keystroke from either app) This problem is closely related to the problem of schema versioning within a single editor, but BYOC can complicate things much further.</li>
<li><strong>Preserving intent</strong>: the decoupling of git + text editors has a downside: the text format fails to capture the intent of edits, so git can’t be very smart about merging conflicts. Is this something fundamental to decoupling editors from collaboration? Or are there ways to design APIs that preserve intent better, while also supporting an open client ecosystem? (It seems like deciding on how you store your data in a CRDT is the key question here?)</li>
<li><strong>Additional editor-specific metadata</strong>: Some editors need to store additional data that isn’t part of the “core data model.” Eg, Sublime Text stores my <code>.sublime-workspace</code> file alongside the code source. How does this work smoothly without polluting the data being used by other editors?</li>
<li><strong>Code distribution</strong>: Traditionally code distribution happens through centralized means, but could code be distributed in a decentralized way alongside documents? If we’re collaborating together in a doc, can I directly share a little editor widget/tool that I’m using, without needing to send you a Github link? This might be overcomplicating things / orthogonal to the general idea here… (This idea inspired by <a href="https://webstrates.net/">Webstrates</a>, linked below)</li>
<li><strong>Innovation</strong>: Unfortunately stable open formats can limit product innovation—eg, email clients are tied down by adherence to the email standard. Can we mitigate that effect? I think web browsers have struck a good balance between progress and openness, despite frustrations in both directions.</li>
</ul>

<h2 id="addendum-faq">Addendum: FAQ</h2>

<p><em>Edited 2020-03-05: This post unexpectedly got popular on HN. As I drink my morning coffee, I’ll briefly respond to a few themes from the comments here.</em></p>

<p><strong>Q: Don’t standards make it harder to innovate?</strong></p>

<p>A: Yes, that’s a major challenge. For example, email and IRC have lagged behind Slack and Reddit, because it’s hard to change standards. We discussed this problem a bit in the <a href="https://www.inkandswitch.com/cambria.html#mastodon-protocol-evolution">Cambria paper, re: Mastodon</a>.</p>

<p>I think the key is to aim for more flexible and extensible standards: a useful 80% compatibility, rather than a perfect 100%.</p>

<p>Of course, once you abandon an exact standard, it’s easy to rack up tons of complexity. (I think the Semantic Web struggled with this problem trying to provide schema flexibility.) So we also need better tools to make partial compatibility easy to reason about, for both developers and users.</p>

<p><strong>Q: Hmm. 80% compatibility sounds like kind of a buggy mess? Word and OpenOffice don’t interop very well.</strong></p>

<p>A: I think with the right foundational tech for helping devs build maximally compatible formats, we can avoid the worst problems of incorrect format conversions. In the Cambria paper we sketched <a href="https://www.inkandswitch.com/cambria.html#lenses-in-action">a few examples</a> of partial compatibility, where Cambria guaranteed type safety and helped us easily avoid bugs.</p>

<p>That does leave a substantial design problem, though: even if everything works correctly, what do you show the <em>user</em> when two pieces of software aren’t fully compatible? How do you tell a user that their actions might show up differently for collaborators using different apps? I’m thinking a lot about these questions…</p>

<p><strong>Q: Cloud business models are so entrenched. Can this actually happen without government intervention?</strong></p>

<p>A:  It’s true that business incentives are a major challenge. Maybe some form of government intervention could help, but ultimately it’ll be fighting a headwind unless users and devs are excited for the change.</p>

<p>I think the most sustainable way to make progress is to make BYOC the most convenient option, for the typical user and the typical developer. On the desktop, it’s convenient for a developer to work with the user’s existing filesystem. On the web today, there’s no user-controlled filesystem, so it’s usually easiest to just put the data in a database, and add a ticket to the backlog for someday building a public-facing API. How would that change if we had a convenient user-controlled place to put data?</p>

<p>See the <a href="https://www.inkandswitch.com/local-first.html">local-first software</a> article by Ink &amp; Switch for some ideas on how new data architectures can make the right thing the easy thing, for both users and devs.</p>

<h2 id="prior-art">Prior Art</h2>

<ul>
<li><a href="https://webstrates.net/">Webstrates</a> has some great demos of this philosophy. It uses a centralized server for the live sync.</li>
<li>Webstrates descends from Michel Beaudouin-Lafon’s work on <a href="https://youtu.be/ntaudUum06E?t=727">instrumental interfaces</a>—"polymorphic" tools that can operate in different applications. For example, a color picker that I can use in any app.</li>
<li>The <a href="https://solidproject.org/">SOLID</a> decentralized web project has some closely related ideas: <a href="https://ruben.verborgh.org/blog/2017/12/20/paradigm-shifts-for-the-decentralized-web/#apps-become-views">“apps become views”</a>, creating a competitive marketplace of clients decoupled from data silos. In turn it’s heavily inspired by ideas from the Semantic Web.</li>
<li><a href="https://mashable.com/2009/05/28/google-wave-guide/">Google Wave</a> had some related ideas… A platform for realtime collaboration, with a rich open <a href="https://youtu.be/v_UyVmITiYQ?t=4207">extension API</a> intended for people to build various collaboration clients on top of. Seems like the common wisdom on why it failed is that it was <a href="https://gizmodo.com/what-in-the-hell-was-google-wave-trying-to-be-anyway-1835038967">too complicated</a> and tried to do too much.</li>
<li><a href="https://braid.news/">Braid</a> is exploring ways to extend HTTP to support collaborative editing across diverse clients.</li>
</ul>



<ul>
<li>I believe one piece of the puzzle here is declarative schema mapping, for example the <a href="https://www.inkandswitch.com/cambria.html">Cambria</a> project I worked on recently.</li>
<li>Granular BYOC starts to look like <a href="https://www.geoffreylitt.com/2020/07/19/tools-over-apps-for-personal-notetaking.html">software as curation</a>: assembling software out of smaller “extensions”</li>
<li>Also relates to document-centric computing ideas like OpenDoc. Some <a href="https://twitter.com/geoffreylitt/status/1362779218241855494">recent notes</a> I took on why that failed…</li>
<li>Part of the solution may involve extracting and synchronizing data from cloud services without going through official APIs, as demonstrated in my <a href="https://www.geoffreylitt.com/wildcard">Wildcard</a> project.</li>
</ul>

<h2 id="im-working-on-this">I’m working on this!</h2>

<p>I’m currently pursuing a PhD at MIT doing research on this topic. Lots of challenges and open questions ahead, but I have some ideas for how to make progress. I’m particularly excited about clever ways to incrementally nudge us from the status quo to a BYOC world, rather than reinventing everything.</p>

<p>If you want to follow along with future updates, you can subscribe via the links below.</p>

<p>And if you have ideas about this topic or want to chat, feel free to <a href="mailto:gklitt@gmail.com">get in touch</a>.</p>

<h2 id="ps-idea-incubation">PS: idea incubation</h2>

<p>I actually wrote this note 10 months ago and had totally forgotten about it.</p>

<p>An hour ago, I randomly came across it and was quite amused. It includes some ideas which I <em>thought</em> I had started thinking about only recently. But it turns out they’ve been incubating in my mind for a long time. Funny how that works!</p>
</div></div>]]>
            </description>
            <link>https://www.geoffreylitt.com/2021/03/05/bring-your-own-client.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355779</guid>
            <pubDate>Fri, 05 Mar 2021 11:47:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free SVG Wave Generator]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26355584">thread link</a>) | @narekb
<br/>
March 5, 2021 | https://www.softr.io/tools/svg-wave-generator | <a href="https://web.archive.org/web/*/https://www.softr.io/tools/svg-wave-generator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-appid="8f7af9fb-a550-425d-b327-48195c193a5f"><nav id="header"><div><!-- Logo --><p><a href="https://www.softr.io/"><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/9774cc17-156a-4cc2-99cc-ce21bcd4d459.svg" alt="Publish your designed things."></a></p><!-- mobile toggle --></div></nav><section id="custom-code1"></section><section id="feature-grid3"><div><!-- Header --><!-- Subheader --><div><p>A free design tool to create colorful, multilayer, random, unique, and organic-looking SVG waves.</p></div><div><div><h6>Customize</h6><p>Change the number of waves, complexity, height, colors and gradient  to create different types of organic SVG waves</p></div><div><h6>Randomize</h6><p>Press the randomize button until you find a SVG wave you like</p></div><div><h6>Download</h6><p>Get the wave as an SVG, PNG or copy the code directly into your clipboard</p></div></div></div></section><section id="cta2"></section><header id="hero1"><div><div><div><p>SVG Wave Generator is a free tool made by Softr for creating random wave-like shapes that you can use in your landing page designs, social media images, product feature showcase, and so on. If you are not proficient with professional design tools but think you might need something like that for your website or for some other purpose, you can use the tool to generate random waves in a few seconds and download them as .png or .svg. There’s also an option to switch between curvy and sharp-edged waves as well as add a gradient to make the waves look even cooler. In addition, you can combine multiple waves to produce a more complex image at once. The image on the right is an example of a shape generated with SVG Wave Generator. It uses sharp edges, gradients, and a combination of 4 wave shapes.</p></div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/2c65eb38-1235-44d8-bc2a-ecb6d2ab4dd8.png" alt="Image alt"></p></div></div></header><header id="hero2"><div><div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/c2c2d625-1d31-4b25-9ed9-9c8585a04a01.png" alt="Image alt"></p><div><p>Wave-like shapes are really commonplace in today’s web design. The image shows a few examples of wave usage in websites. As you can see, they can be used in mobile apps, as a landing page background, site navigation bar background, and so on. With SVG Wave Generator, you can create similar shapes in just a few seconds and apply them in your designs.</p></div></div></div></header><header id="hero3"><div><div><div><p>To show how it can be applied in real life, let’s consider an example using our no-code website and web app builder – Softr. In Softr, you have the option of uploading a custom background image to almost all the building blocks that are used to construct a web app or a website. The image shows one of our hero area layouts, where an .svg generated by the Wave Generator has been added as a background image.

Thus, generating designs for your site with SVG Wave Generator is really easy and fun. Go ahead and try it yourself!</p></div><p><img src="https://softr-prod.imgix.net/applications/8f7af9fb-a550-425d-b327-48195c193a5f/assets/983e6e1d-aaad-4841-b49f-97ccd62e105b.png" alt="Image alt"></p></div></div></header><section id="cta1"><div><div><div><h2>The website you are reading now is built on Softr.</h2><p>Want to create yours?</p></div></div></div></section></div></div>]]>
            </description>
            <link>https://www.softr.io/tools/svg-wave-generator</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355584</guid>
            <pubDate>Fri, 05 Mar 2021 11:23:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clothing, How Did They Make It? Part I: High Fiber]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26355046">thread link</a>) | @CapitalistCartr
<br/>
March 5, 2021 | https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we are starting the first of a four (?) part look at pre-modern textile production.  As with our series on <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farming </a>and <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">iron</a>, we are going to follow the sequence of production from the growing of fibers all the way to the finished object, with a focus not merely on the methods of production but also <em>on the people doing the producing</em> at each stage of production.  Now while I have titled this series, “Clothing, How Did They Make It?” it is worth noting that textiles were used for a lot more than just clothing.  All sorts of household goods were produced this way.  In addition, of course, clothing was sometimes made out of non-textile materials (although, <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">as we’ve discussed</a>, far less often than is portrayed in popular culture; in Eurasia, by and large, clothing meant textiles).  <strong>But what we are going to focus on here is really <em>textiles</em></strong> and (of course) the people that make them.  Leather working will have to wait for another day.</p>



<p>That said, even within textiles, to try to keep the scope manageable<strong> I am going to narrow things down further, by focusing on just two major fibers: wool and flax</strong> (which makes linen) and thus <strong>mostly focus on how this worked in the Mediterranean</strong>, broadly construed (so the Near East, North Africa and Europe).  I am choosing these two fibers because they dominate in locally produced textiles in the Near East and Europe for much of the pre-modern period.  Cotton, another important fiber, only seems to have been cultivated in Egypt in the Roman period (though, as far as I can tell, at some point Egyptian cotton cultivation seems to have largely dropped off, only to boom again in the Early Modern though this is a point about which I can express little confidence in my knowledge) and for much of Europe remained an expensive import fiber through the Middle Ages, transported from South Asia.  Likewise, silk remained in the pre-modern period almost entirely an expensive import good from far to the East of the Mediterranean.  Of course any import good must be local somewhere, but my expertise in pre-modern textile production does not extend so far into South or East Asia, so the task of laying that out must fall to someone else.  We will talk a <em>bit</em> about these fibers as they arrive in the Mediterranean as trade goods, but mostly stay focused on wool and flax.</p>



<p>The very rarity of these goods in the Near East and Europe confined them to the upper-classes, while wool and linen often remained the everyday fibers (though even the very wealthy used textiles of high quality wool and linen as well) and so saw a lot more use.  More importantly to our investigation here, for the ancient Mediterranean (where my knowledge is best) wool and linen were <em>by far</em> the fibers most involved in the household textile production.  Of course other fibers were used locally in the Mediterranean as well – hemp, nettle and even tree-bast, but the vast majority of<strong> textiles being produced in the broader Mediterranean world were wool and linen and so we are going to focus on that.</strong></p>



<figure><img data-attachment-id="6453" data-permalink="https://acoup.blog/616302001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg" data-orig-size="2218,1817" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="616302001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/03/616302001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/G_1814-0704-573">From the British Museum</a>, a fourth century bell krater depicting the Judgement of Paris (which in turn leads to the Trojan War).  Paris, at the time, was living in exile as a shepherd – the occupation notable because of its lowly status.  Here he is seen seated with his shepherd’s crook (the standing male figure is Hermes); the animal below Paris is a sheep (you can see the twisted horns; to the right is a dog, presumably assisting in the herding.</figcaption></figure>



<p>Worry not, we will have more than enough to talk about with just those two fibers.  This week, we’re going to focus just on producing the raw fibers – how flax is farmed and how wool is produced from sheep.  Next week, we’ll look at the long process of taking those raw fibers, processing them and spinning them into thread.  The week after that, we’ll look at weaving as well as dying, bleaching and other color treatments treatments.  Then finally in the last week, we’ll look at finally sewing but also at markets and trade. <strong> As always, we’ll try to direct attention not only to the processes, but also to the workers who <em>performed</em> those processes and their place in the broader society.</strong></p>



<p>And that brings us to the second reason to discuss textile production, which is that in the broader pre-modern Mediterranean <strong>much of the textile production</strong> <strong>was done within the household and nearly all of that household production was done by women</strong>.  Now as we’ll see, household spinning, weaving and sewing is by no means the only jobs involved in the production of the clothes that say an Egyptian, Babylonian, Roman or early Medieval European family would wear and some important stages of production here were also generally done by men.  As I have mentioned before, the literary sources for the pre-modern world generally prefer to talk about individuals who are rich, male, and free, but as we will see, the workers involved in each stage of textile production are almost never rich, frequently not male and sometimes not free.  Nevertheless investigating textile production gives us a chance to peer into parts of the lives of some historical subjects that we very rarely hear about: women (rich and poor, slave and free), along with enslaved or poor men doing work that left them well outside of the ‘polite society’ of our literary sources.</p>



<p>I should note at the beginning that while I am going to try to keep this discussion general and at points cover technological or regional variations in how textiles in wool and linen were made, in practice a lot of what I am going to write here is going to reflect in particular practice during the Roman period (especially the period of the Republic) and even more specifically than that in Roman Italy, simply because that is where my own specialist knowledge is best.  Consult your friendly neighborhood primary sources when looking to apply these systems on a wider basis either geographically or chronologically!</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>(<strong>Bibliography Note:</strong> For the sake of keeping these posts readable, especially since I don’t have a footnote function here, I am not going to laboriously cite everything at each point of reference, but instead I’m going to include a short selected bibliography here up front for the whole series.  For the beginner looking to get their feet under themselves when it comes to pre-modern textile production, E.W. Barber, <em>Women’s Work: The First 20,000 Years, Women, Cloth and Society in Early Times</em> (1994) is the standard starting point.  Also note E.W. Barber, <em>Prehistoric Textiles: The Development of Cloth in the Neolithic and Bronze Ages with Special Reference to the Aegean</em> (1991).  More specific to the Romans, M. Gleba, <em>Textile Production in Pre-Roman Italy</em> (2008) is an indispensable book which gathers together a lot of the quite technical investigation – often done by archaeologists rather than historians because the literary record on textile production can be quite disappointing – in a fairly easy to read location.  Several of the essays in M. Gleba and J. Pásztókai-Szeöke <em>Making Textiles in Pre-Roman Times and Roman Times: People, Places, Identities</em> (2013), while more technical in nature, were also useful here, especially on the question of who did this sort of thing.  Also on this point, L. L. Lovén, <em>The Imagery of Textile Making: Gender and Status in the Funerary Iconography of Textile Manufacture in Roman Italy and Gaul</em> (2002).  On textile production for soldiers, note in the Greek context G.S. Aldrete, S. Bartel and A. Aldrete, <em>Reconstructing Ancient Linen Body Armor: Unraveling the Linothorax Mystery</em>(2013) which also has some very useful time-labor study data; for Roman soldiers note the essays in M.L. Nosch ed., <em>Wearing the Cloak: Dressing the Soldier in Roman Times</em> (2012) and G. Sumner, <em>Roman Military Dress </em>(2009).  On the cloth trade in medieval Europe, I’ve relied heavily on J.S. Lee, <em>The Medieval Clothier</em> (2018).</p>



<p>If it sounds like pre-modern textile production is one of those fields that is only now, somewhat belatedly receiving the attention it has long deserved, that is by and large correct!  As you can see, compared to the discussion of farming or iron-working, the key references here are often decades younger (one is left to assume that it is something to do with the fact that this work was largely done by women that led to it being so late to receive its due study).  Fortunately, archaeology is giving us a lot of the evidence that our literary sources don’t, especially for the ancient world, which has enabled a lot of this work.  May it continue!)</p>



<h2>Meet the Fibers! Flax and Linen</h2>



<p>Linen fabrics are produced from the fibers of the flax plant, <em>Linum usitatissimum</em>.  This common flax plant is the domesticated version of the wild <em>Linum bienne</em>, domesticated in the northern part of the fertile crescent no later than 7,000 BC, although wild flax fibers were being used to produce textiles even earlier than that. Consequently the use of linen fibers goes <em><strong>way </strong></em>back. In fact, the oldest known textiles are made from flax, including finds of fibers at Nahal Hemar (7th millennium BC), Çayönü (c. 7000 BC), and Çatalhöyük (c. 6000 BC). Evidence for the cultivation of flax goes back even further, with linseed from Tell Asward in Syria dating to the 8th millennium BC. Flax was being cultivated in Central Europe no later than the second half of the 7th millennium BC.</p>



<figure><img data-attachment-id="6451" data-permalink="https://acoup.blog/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg" data-orig-size="439,591" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223" data-large-file="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" src="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=439" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg 439w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=111 111w, https://acoupdotblog.files.wordpress.com/2021/03/linum_usitatissimum_-_kohlere28093s_medizinal-pflanzen-088.jpg?w=223 223w" sizes="(max-width: 439px) 100vw, 439px"><figcaption><a href="https://en.wikipedia.org/wiki/Flax">Via Wikipedia</a>, the flax plant, showing the seeds and – more importantly for our purpose – the stalk which, when fully grown contains the bast fibers used to make linen.</figcaption></figure>



<p>Flax is a productive little plant that produces two main …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/">https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/03/05/collections-clothing-how-did-they-make-it-part-i-high-fiber/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26355046</guid>
            <pubDate>Fri, 05 Mar 2021 10:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stability of Fixed Points of High Dimensional Dynamical Systems]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26352308">thread link</a>) | @adipandas
<br/>
March 4, 2021 | https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/ | <a href="https://web.archive.org/web/*/https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><p> 5 minute read</p><p><strong> Published:</strong> <time datetime="2021-03-04T00:00:00-08:00">March 04, 2021</time></p></header><section itemprop="text"><p>In the <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a>, I discussed the basics regarding the stability of fixed points of a dynamical system and explained it with a simple continuous-time one-dimensional example. In this post, I will discuss fixed points for a general case of a continuous-time $n$-dimensional system.</p><h4 id="fixed-point">Fixed point</h4><p>Just to reiterate, if the ordinary differential equation (ODE) in $\eqref{eq:1}$ represents a dynamical system:</p>\[\dot x = f(x) \label{eq:1}\]<p>Fixed points of this system are given by the roots of the equation $\eqref{eq:2}$:</p>\[\begin{equation} \dot x = f(x) = 0 \label{eq:2} \end{equation}\]<h2 id="fixed-points-of-multi-dimensional-system">Fixed points of Multi-dimensional system</h2><p>My <a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">previous post</a> only explained the definition of fixed point and provided an example with a scalar-valued dynamical system. Now, lets discuss a case of multi-dimensional ODE.</p><p>We will start with the system given by equation $\eqref{eq:3}$:</p>\[\mathbf{\dot x} = \mathbf{f(x)} \label{eq:3}\]<p>where $\mathbf{f}$ is a vector-valued function, $\mathbf{x}$ and $\mathbf{\dot x}$ are $n$-dimensional vectors:</p>\[\mathbf{x, \dot x} \in \mathcal{R}^{n} \label{eq:4}\]<p>We find the fixed points (a.k.a. equilibrium states) of the system by following $\eqref{eq:2}$:</p>\[\mathbf{\dot x_{eq}} = \mathbf{f}(\mathbf{x_{eq}}) = \mathbf{0} \label{eq:5}\]<p>The roots of $\eqref{eq:5}$ will give us the value of $\mathbf{x_{eq}}$, i.e., fixed points of our multi-dimensional system.</p><h2 id="stable-and-unstable-fixed-points">Stable and Unstable Fixed Points</h2><p>We analyzed the system in a one-dimensional case (<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">here</a>) using a small perturbation $\delta$ at the equilibrium condition of the system. We will follow the similar procedure here as well.</p><p>We evaluated $\mathbf{f}^{\prime}\mathbf{(x)}$ at $\mathbf{x_{eq}}$ to see if our fixed point is stable or unstable. In case of one-dimensional system, it was easy since $f^{\prime}(x_{eq})&gt;0$ is unstable fixed point $x_{eq}$ while it is stable when $f^{\prime}(x_{eq})&lt;0$. In case of high-dimensional system, we cannot do this.</p><p>To analyze the behavior of our $n$-dimensional system at $\mathbf{x_{eq}}$, we will introduce the perturbation $\mathbf{\delta x}$ at $\mathbf{x_{eq}}$. Thus, we end up with the following:</p>\[\begin{align} \mathbf{\dot x_{eq} + \dot {\delta x}} &amp;= \mathbf{f(x_{eq}+\delta x)} \label{eq:6} \end{align}\]<p>Using Taylor expansion on $\eqref{eq:6}$:</p>\[\begin{align} \mathbf{\dot x_{eq} + \delta \dot x = f(x_{eq}) + f^{\prime}(x_{eq}) \delta x + f^{\prime \prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \label{eq:7} \end{align}\]<p>But, we know at fixed points, equation $\eqref{eq:5}$ holds and thus, $\eqref{eq:7}$ reduces to $\eqref{eq:8}$.</p>\[\begin{align} \mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + f^{\prime\prime}(x_{eq}) \frac{\delta x^2}{2!} + \dots} \end{align}\] \[\mathbf{ \delta \dot x = f^{\prime}(x_{eq}) \delta x + H.O.T. \label{eq:8}}\]<p>We can ignore the higher order terms $\mathbf{H.O.T.}$ for values of $\mathbf{\delta{x}}$ close to $\mathbf{0}$, resulting in equation $\eqref{eq:9}$.</p>\[\begin{align} \mathbf{\delta \dot x = f^{\prime}(x_{eq}) \delta x \label{eq:9}} \end{align}\]<p>$\mathbf{f}^{\prime}\mathbf{(x)}$ is the Jacobian of $\mathbf{f(x)}$ at $\mathbf{x_{eq}}$, i.e., a <strong>linear approximation</strong> of our dynamical system $\mathbf{f(x)}$ near $\mathbf{x_{eq}}$ (you can refer <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/#jacobian-aka-derivative-of-vector-valued-function">this</a> for further details on Jacobian).</p>\[\begin{align} \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \left[ \frac{\partial\mathbf{f}}{\partial x_{1}}, \frac{\partial\mathbf{f}}{\partial x_{2}}, \dots, \frac{\partial\mathbf{f}}{\partial x_{n}} \right] \label{eq:11}\\ \mathbf{f}^{\prime}\mathbf{(x)} &amp;= \begin{bmatrix} \frac{\partial{f_{1}}}{\partial x_{1}} &amp; \frac{\partial{f_{2}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \vdots &amp; \ddots &amp; \ddots &amp; \vdots \\ \frac{\partial{f_{n}}}{\partial x_{1}} &amp; \frac{\partial{f_{n}}}{\partial x_{2}} &amp; \dots &amp; \frac{\partial{f_{n}}}{\partial x_{n}}\\ \end{bmatrix} \label{eq:12} \end{align}\]<p>Using this Jacobian, equation $\eqref{eq:12}$, at our fixed point $\mathbf{x_{eq}}$ for the dynamical system under consideration, we can calculate its <a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors"><strong>eigenvalues</strong></a> and interpret the results of the fixed point.</p><p>Therefore, we find the eigenvalues for equation $\eqref{eq:13}$,</p>\[\begin{align} \mathbf{f}^{\prime}(\mathbf{x_{eq}}) \mathbf{x_{eq}} = \lambda \mathbf{x_{eq}} \label{eq:13} \end{align}\]<p>Here, $\lambda$ denotes the eigenvalue of the system. The roots of $\eqref{eq:13}$ are the eigenvalues the dynamical system at the fixed point $\mathbf{x}=\mathbf{x_{eq}}$.</p><h3 id="eigenvalue-interpretation-">Eigenvalue interpretation <a name="eigen_value_interpretation"></a></h3><p>For a continuous-time nonlinear dynamical system given by $\eqref{eq:3}$, the eigenvalues $\lambda$ that are found as roots of equation $\eqref{eq:13}$ can be interpreted as:</p><ul><li>If any of the eigenvalues have a real part $Re(\lambda)&gt;0$: $\mathbf{x_{eq}}$ is an unstable fixed point.</li><li>If all $Re(\lambda)&lt;0$: $\mathbf{x_{eq}}$ is a stable fixed point.</li><li>If $\lambda=0$: $\mathbf{x_{eq}}$ is a neutral fixed point.</li><li>If eigenvalues $\lambda$ are complex conjugates, i.e., $Im(\lambda) \ne 0$: The dynamical system has oscillatory behavior around the fixed point.</li></ul><h3 id="important-points-to-note-regarding-this-article">Important points to note regarding this article</h3><p>In this post, we discussed a general case of interpreting the fixed points of a dynamical system. By general, I mean $\mathbf{f(x)}$ is a non-linear, continuous-time vector-valued function representing a dynamical system. Below are certain points one should note about any non-linear dynamical system:</p><ul><li>We assumed that the system is non-linear and linearized it using Taylor series expansion near its fixed point (a.k.a. equilibrium).</li><li>We evaluated the stability of a fixed point <strong>near</strong> the equilibrium condition by perturbing the system ($\mathbf{x_{eq}}+\mathbf{\delta x}$).</li><li>This approach of interpreting the stability of the system by linearizing it near the equilibrium <strong>does not tell much</strong> about a system’s asymptotic behavior at large.<ul><li>We only understand how the system behaves <strong>locally</strong> or <strong>in the neighborhood of the fixed points</strong>.</li></ul></li><li>In practical or real-world systems, it may not be possible to interpret the global stability characteristics of the system. Thus, the stability analysis around the neighborhood of the fixed point is useful for many practical applications such as sustaining a non-linear system’s state near or at the fixed point.</li><li>In general, global asymptotic behaviors of any non-linear dynamical system can be complex and there are no systematic methods to predict and analyze such behaviors.</li></ul><h3 id="references-and-further-readings">References and Further Readings:</h3><ul><li>Deshpande, A. M. Stablility of Fixed Point of a Dynamical System. [<a href="https://adipandas.github.io/posts/2020/02/stable-unstable-fixed-point/">web</a>]</li><li>Strogatz, Steven H. Nonlinear dynamics and chaos with student solutions manual: With applications to physics, biology, chemistry, and engineering. CRC press, 2018.</li><li>Khalil, Hassan K. “Lyapunov stability.” <em>Control Systems, Robotics and AutomatioN–Volume XII: Nonlinear, Distributed, and Time Delay Systems-I</em> (2009): 115.</li><li>Bomze, Immanuel M., and Jörgen W. Weibull. “Does neutral stability imply Lyapunov stability?.” <em>Games and Economic Behavior</em> 11.2 (1995): 173-192.</li><li>Fixed point. [<a href="https://mathworld.wolfram.com/FixedPoint.html">web</a>]</li><li>Jacobian matrix [<a href="https://www.youtube.com/watch?v=bohL918kXQk">video</a>]</li><li>Stability Theory. [<a href="https://en.wikipedia.org/wiki/Stability_theory">web</a>]</li><li>Lyapunov Stability. [<a href="https://en.wikipedia.org/wiki/Lyapunov_stability">web</a>]</li></ul></section><!--<nav class="pagination"> <a href="https://adipandas.github.io/posts/2020/03/vector-calculus/" class="pagination--pager" title="Notes on Vector Calculus ">Previous</a> <a href="https://adipandas.github.io/posts/2021/03/biasvariancetradeoff/" class="pagination--pager" title="Bias, Variance and Trade-off ">Next</a></nav>--></div></div>]]>
            </description>
            <link>https://adipandas.github.io/posts/2021/03/fixed-point-high-dim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352308</guid>
            <pubDate>Fri, 05 Mar 2021 03:38:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silence – GPL-Licensed Encrypted SMS/MMS for Android]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26352086">thread link</a>) | @jhabdas
<br/>
March 4, 2021 | https://git.silence.dev/Silence/Silence-Android/ | <a href="https://web.archive.org/web/*/https://git.silence.dev/Silence/Silence-Android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p data-sourcepos="1:1-1:46" dir="auto">A fork of Signal with only SMS/MMS encryption.</p>
</div>

</div></div>]]>
            </description>
            <link>https://git.silence.dev/Silence/Silence-Android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26352086</guid>
            <pubDate>Fri, 05 Mar 2021 03:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Production Machine Learning Fails – and How to Fix It]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26350953">thread link</a>) | @rkearns
<br/>
March 4, 2021 | https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/ | <a href="https://web.archive.org/web/*/https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          
<p><em>Machine learning has emerged as a must-have tool for any serious data team: augmenting processes, generating smarter and more accurate predictions, and generally improving our ability to make use of data.</em></p>



<p><em>However, discussing applications of ML in theory is much different than actually applying ML models at scale in production. In this article, we walk through common challenges and corresponding solutions to making ML a force multiplier for your data organization.&nbsp;</em></p>



<p>From generating your weekend bike route on Google Maps to helping you discover your next binge-worthy show on Netflix, machine learning (ML) has evolved well beyond a theoretical buzzword into a powerful technology that most of us use every day.&nbsp;</p>



<p>For the modern business, the appetite for ML has never been stronger. But while certain industries have been transformed by the automation made possible by ML—think <a href="https://www.businessinsider.com/ai-in-banking-report" target="_blank" rel="noopener">fraud detection</a> in finance and <a href="https://customerthink.com/explained-working-and-advantages-of-a-recommendation-engine/" target="_blank" rel="noopener">personalized product recommendations</a> in e-commerce—the hard truth is that many ML projects fail before they ever see the light of day.&nbsp;</p>



<p>In October 2020, <a href="https://www.gartner.com/en/newsroom/press-releases/2020-10-19-gartner-identifies-the-top-strategic-technology-trends-for-2021#:~:text=Gartner%20research%20shows%20only%2053,a%20production%2Dgrade%20AI%20pipeline." target="_blank" rel="noopener">Gartner reported</a> that only 53% of projects make it from prototype to production—and that’s at organizations with some level of AI experience. For companies still working to develop a data-driven culture, that number is likely far higher, with <a href="https://venturebeat.com/2019/07/19/why-do-87-of-data-science-projects-never-make-it-into-production/" target="_blank" rel="noopener">some failure-rate estimates</a> soaring to nearly 90%.&nbsp;</p>



<p>Data-first tech companies like Google, Facebook, and Amazon are transforming our daily lives with ML, while many other well-funded and highly talented teams are still struggling to get their initiatives off the ground. But why does this happen? And how can we fix it?</p>



<p><strong>We share the four biggest challenges modern data teams face when adopting ML at scale— and how to overcome them.&nbsp;</strong></p>



<h3>Misalignment between actual business needs and ML objectives</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1024x683.jpg" alt="" width="768" height="512" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1024x683.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-300x200.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-768x512.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-1536x1024.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/charles-deluvio-pjAH2Ax4uWk-unsplash-1-2048x1365.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>When your business objectives and ML goals are misaligned, all of your best laid plans are bound to fail, just like that model you trained with stale data. Image courtesy of <a href="https://unsplash.com/photos/pjAH2Ax4uWk" target="_blank" rel="noopener">Charles Deluvio</a> on <a href="https://unsplash.com/s/photos/machine-learning" target="_blank" rel="noopener">Unsplash</a>.</figcaption></figure></div>



<p>The first challenge is strategic, not technical: starting with a solution instead of a clearly defined problem.&nbsp;</p>



<p>As companies race to incorporate ML into their organizations, leaders may hire data scientists and ML practitioners to automate or improve processes without a mature understanding of <a href="https://developers.google.com/machine-learning/problem-framing/good" target="_blank" rel="noopener"><strong>which problems are actually suitable for ML</strong></a> to solve. And even when the business problem is a good fit for ML, without a shared definition of what success looks like, projects can languish in experimentation mode for months while stakeholders wait for an idealized level of machine-like perfection that can never be reached.&nbsp;</p>



<p>Machine learning is not magic, it will not solve every problem perfectly, and should, by nature, continue to evolve over time. Sometimes, a model merely achieving the same results as humans is a worthy project—errors and all.&nbsp;</p>



<p>Before starting any project, ask your team or your stakeholders: <em>What business problem are we trying to solve? Why do we believe that ML is the right path? What is the measurable threshold of business value this project is trying to reach? What does “good enough” look like?&nbsp;</em></p>



<p>Without these clear, shared definitions articulated at the outset, many worthy ML projects will never reach production and valuable resources will be wasted. Solve a business problem using ML and not just embark on a ML project for checking off the ML box.</p>



<h3>Model training that doesn’t generalize</h3>



<p>With a clearly defined business problem and targeted success metrics, your potential pitfalls get more technical. During the model training stage, issues related to your training data or model fit are the likeliest culprit for future failure.&nbsp;</p>



<p>The goal of <a href="https://elitedatascience.com/model-training" target="_blank" rel="noopener"><strong>model training</strong></a> is to develop a model that can generalize, or make accurate predictions when given new data because it understands the relationships between data points and can identify trends. Your training dataset should be clean, sizable, and representative of the real-time data your model is expected to process once in production. No where has one seen clean data in a production environment. Expect to spend considerable time cleaning, labeling&nbsp; and feature engineering just to get the data ready.</p>



<p>Representative training data is also key: If your training data doesn’t reflect the actual datasets your model will encounter, you may end up with a model that won’t perform once you’ve reached testing or production.&nbsp;</p>



<p>Another issue that can occur during training is overfitting and underfitting. Overfitting happens when a model learns <em>too much </em>and produces outputs that fit too closely with your training data.</p>



<p>Underfitting is simply the opposite—your model doesn’t learn enough to make useful predictions on even the training data itself, let alone new data it will encounter in testing or production.</p>



<h3>Testing and validation issues</h3>



<p>As you test and validate your models, new challenges can arise from merging multiple data streams and making updates to improve performance. Changes to data sources, model parameters, and <a href="https://en.wikipedia.org/wiki/Feature_engineering" target="_blank" rel="noopener"><strong>feature engineering</strong></a> all introduce room for error.&nbsp;</p>



<p>This may also be the stage when you detect overfitting or underfitting in your model—a model that performed wonderfully during training but fails to produce useful results during testing may be overfit.&nbsp;</p>



<p>Even at companies like Google, where ML engineers abound, <a href="https://www.technologyreview.com/2020/04/27/1000658/google-medical-ai-accurate-lab-real-life-clinic-covid-diabetes-retina-disease/" target="_blank" rel="noopener">surprises</a> in your product models can—and will—arise.&nbsp;</p>



<h3>Deployment and serving hurdles</h3>



<p>Deploying ML projects is rarely simple, and teams typically can’t use consistent workflows to do so—since ML projects solve a wide range of business problems, there’s a similarly wide range of ways to host and deploy them. For example, some projects require batched predictions on a regular basis, while others need to generate and deliver predictions on-demand when an application makes an API request to predict using the model. (This is part of why it’s challenging to make models apply to different use cases, no matter how appealing it may sound to executives who may view ML models as more magic than narrowly focused functions.)</p>



<p>Additionally, some ML projects can require a lot of resources, and cross-functional teams need to agree upon priorities of deployment. Engineers only have so many things they can productionalize, and as we’ve discussed, ML projects are much more than models and algorithms: most will need infrastructure, alerting, maintenance, and more to be successfully deployed.&nbsp;</p>



<p>This is why it’s so important to articulate the business problem clearly at the outset, agree upon what success looks like, design an end-to-end solution, and have a shared understanding of your ML project’s value compared to other priorities. Without this strategic plan, your project may never receive the engineering resources it needs to finally reach production.&nbsp;</p>



<p>For just one example, Netflix never productionalized its <a href="https://www.wired.com/2012/04/netflix-prize-costs/" target="_blank" rel="noopener">million-dollar prize-winning recommendation algorithm</a> due to the winning model’s complexity to implement—instead choosing another submission that was simpler to integrate.&nbsp;&nbsp;</p>



<h3>Tactics for scalable ML in production</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1024x687.jpg" alt="" width="768" height="515" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1024x687.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-300x201.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-768x515.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-1536x1030.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/kobu-agency-67L18R4tW_w-unsplash-2048x1373.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Machine learning isn’t magic, but it is powerful—and often misunderstood.&nbsp; Sort of like this paper stick figure. Image courtesy of <a href="https://unsplash.com/photos/67L18R4tW_w" target="_blank" rel="noopener">Kobu Agency</a> on <a href="http://www.unsplash.com/" target="_blank" rel="noopener">Unsplash.</a></figcaption></figure></div>



<p>Beyond strategic planning and staffing, there are concrete steps you can take to help scale your ML production.&nbsp;</p>



<h4>Lean into the cloud</h4>



<p>If your teams are working locally instead of in the cloud, it’s time to shift. Working in the cloud is the “glue” that keeps model training and deployment workflows in lockstep. Most vendors and open-source tools are developed for the cloud, and once there, it’s much easier to automate processes. Testing, training, validation and model deployment needs to be a repeatable process, it should not go from local Python code to a production environment.</p>



<h4>Leverage a DevOps approach</h4>



<p>Just as we’ve talked about applying DevOps practices to data, like <a href="https://www.montecarlodata.com/how-to-make-your-data-pipelines-more-reliable-with-slas/"><strong>setting data SLAs</strong></a> and measuring data health along <a href="https://www.montecarlodata.com/introducing-the-5-pillars-of-data-observability/">observability pillars</a>, ML teams can follow in DevOps’ footsteps by implementing the <strong><a href="https://www.infoworld.com/article/3271126/what-is-cicd-continuous-integration-and-continuous-delivery-explained.html" target="_blank" rel="noopener">Continuous Integration (CI) and Continuous Delivery (CD)</a> model</strong>, while introducing <a href="https://cloud.google.com/solutions/machine-learning/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning" target="_blank" rel="noopener">Continuous Training (CT)</a>. By setting up agile build cycles and tools, ML teams can more rapidly deliver changes into the codebase and improve overall performance.&nbsp;</p>



<p>Similar to DevOps best practices, ML teams should use containerization to consistently run software across any type of device and make it simpler for engineers to productionalize their work. Keeping a consistent and visible build process that deploys smaller changes more frequently allows the team to work more smoothly and have more insight into what’s working well, and what’s not. Visibility also helps would-be code “gatekeepers” trust the build process and speed up the ML team’s workflow.&nbsp;</p>



<p>Investing time to build a strategic MLOps team and processes will help by reducing the likelihood of a project stalling out before production, and making continuous improvements feasible—setting every project up for long-term success.</p>



<h4>Invest in observability and monitoring&nbsp;</h4>



<p>Finally, the primary rule of machine learning is that your outcomes will only be as good as your inputs. Healthy data is absolutely essential to ML. Without clean data and working pipelines, models won’t be able to perform to their fullest potential and may fail to make accurate predictions.&nbsp;</p>



<p>And when you’re relying on ML to make important business decisions, you don’t want to find out about a broken pipeline or inaccurate data after those outputs have already been delivered.&nbsp;</p>



<p>That’s why <a href="https://www.montecarlodata.com/introducing-the-5-pillars-of-data-observability/"><strong>data observability</strong></a>, which provides a full understanding and comprehensive monitoring of data health—and can prevent bad data from reaching your ML models in the first place—is well worth the investment.&nbsp;</p>



<h3>Achieving ML production at scale</h3>



<div><figure><img loading="lazy" src="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1024x683.jpg" alt="" width="768" height="512" srcset="https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1024x683.jpg 1024w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-300x200.jpg 300w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-768x512.jpg 768w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-1536x1024.jpg 1536w, https://314eeh1sonxi1dnazoipvkl6-wpengine.netdna-ssl.com/wp-content/uploads/2021/03/matthew-henry-fPxOowbR6ls-unsplash-2048x1365.jpg 2048w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>You don’t need to design the next motion-activated security camera to make an …</figcaption></figure></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/">https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/</a></em></p>]]>
            </description>
            <link>https://www.montecarlodata.com/why-production-machine-learning-fails-and-how-to-fix-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26350953</guid>
            <pubDate>Fri, 05 Mar 2021 00:58:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Postgres Notify for Real Time Dashboards]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26350862">thread link</a>) | @epberry
<br/>
March 4, 2021 | https://blog.arctype.com/postgres-notify-for-real-time-dashboards/ | <a href="https://web.archive.org/web/*/https://blog.arctype.com/postgres-notify-for-real-time-dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>We’re going to take a look how I used a Postgres feature, <code>pg_notify</code>, to power a work schedule for a manufacturing company. This particular product went through a dozen or so stages of manufacture, and each time a product advanced to its next stage the worker would record that progress from their workstation. The app we will build in this post displayed this schedule and allowed everyone to see the day’s progress.</p><h3 id="the-observer-pattern-in-sql">The Observer Pattern in SQL</h3><p>If you’re only used to using the standards of SQL in Postgres, the <code>NOTIFY</code> and <code>LISTEN</code> commands might not be familiar. But with these two commands you can implement something akin to the Observer pattern, but in your SQL engine!</p><p>The Observer pattern allows one class of object to “listen” for incoming events and another class to send events to those listeners. This pattern is commonly used for instances where data is being updated or changed, and several possibly unrelated objects need to react to those changes.</p><h3 id="observer-examples">Observer Examples</h3><p>Listening to state changes from a Redux store from inside of a React component is a common example of this pattern. Many React components listen to a single part of the Redux store. Android’s LiveData is another great example of this pattern, where observers can be created to watch for changes and immediately update the state and UI of an app.</p><h3 id="observing-in-postgresql">Observing in PostgreSQL</h3><figure><img src="https://blog.arctype.com/content/images/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 1000w, https://blog.arctype.com/content/images/2021/03/Screen-Shot-2021-02-03-at-19.18.43.png 1600w" sizes="(min-width: 720px) 720px"><figcaption>System architecture with pg_notify as the event bus.</figcaption></figure><p><code>NOTIFY</code> and <code>LISTEN</code> work together to allow you to implement this design within your Postgres database. Generally, <code>NOTIFY</code> will be called inside of a SQL query, oftentimes within a trigger. <a href="https://blog.arctype.com/learn-sql-triggers/">Triggers and event-based models go together well.</a> </p><!--kg-card-begin: html--><p>
    <h3>Looking for a collaborative SQL Editor?</h3>
    
</p><!--kg-card-end: html--><p><code>LISTEN</code> is called from your Postgres client. When an event is triggered by <code>NOTIFY</code> the client will be notified. The event contains a payload so the client can tell what event was triggered (this can also contain metadata or actual data from the database). How your client receives this notification and how you are able to process it from there varies from client to client. In our example, the client will use WebSockets to update each connected schedule client after it receives the signal from <code>pg_notify</code>.</p><h2 id="building-the-work-schedule-app">Building the Work Schedule App</h2><h3 id="schema-design">Schema Design</h3><p>Let’s begin on the Postgres side. We are modeling items that are being manufactured. Items in production will be represented by the <code>production_item</code> table. Each <code>production_item</code> has an associated <code>product_id</code> &nbsp;and a current stage of production. </p><figure><img src="https://blog.arctype.com/content/images/2021/03/Frame-27--1-.png" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/Frame-27--1-.png 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/Frame-27--1-.png 1000w, https://blog.arctype.com/content/images/2021/03/Frame-27--1-.png 1498w" sizes="(min-width: 720px) 720px"><figcaption>ERD Diagram made with <a href="https://blog.arctype.com/erd-builder/">Arctype's Free Figma template</a>.</figcaption></figure><p>We could store the current production stage as a column in the <code>production_item</code> table, but that would only allow us to see what stage the item is in currently. Instead, we’ll use a <code>production_item_wip</code> (work-in-progress) table where each row will contain a timestamp as the item progresses through the stages of production. Let’s also create a table that stores all the possible stages of production, <code>production_stage</code>. <code>production_stage</code> will have an <code>idx</code> integer column to store the order in which the stages occur. The query below creates the <code>production_item_wip</code> table, as an example.</p><pre><code>create table production_item_wip (  
  id serial primary key,  
  insert_time timestamp default NOW(),  
  production_item_id int references production_item(id),  
  production_stage_id int references production_stage(id),  
  employee_id int references employee(id)  
); </code></pre><p>PROTIP: You may notice I’ve included <code>insert_time</code> on every table. We will not need to use this column on every table for this particular example right now, but I’ve found that it often proves useful in the future. I spend a significant amount of time building queries and extracting useful statistics, and countless times I’ve been unable to use data because it lacked an <code>insert_time</code>. I would err on the side of adding it when designing database schema in general, if you’re unsure whether or not you should.</p><h3 id="postgres-notify-syntax">Postgres NOTIFY Syntax</h3><p>Using NOTIFY to send an event is dead simple! Here is a trigger procedure that sends a notification to the order_progress_event channel.</p><pre><code>create
or replace function fn_production_stage_modified() returns trigger as $psql$
begin
  perform pg_notify(
    'order_progress_event',
    'Time to refresh those screens!'
  );return new;
end;$psql$ language plpgsql;</code></pre><p><code>pg_notify</code> lends itself well to being used within a trigger when used to deliver real-time data streaming. However, you could just as easily call <code>pg_notify</code> from a regular SQL query: <code>select pg_notify('order_progress_event', 'Hello world!');</code></p><p>Inside of a PL/pgSQL procedure, you cannot <code>SELECT</code> a function, like <code>pg_notify</code>, that returns void. Doing so will cause a Postgres error. That’s why in the first example we use <code>perform</code>, while in the second we can simply use <code>select</code>.</p><p>With that procedure created, let’s add the actual trigger so that whenever an item moves along in the production process, and thus another row is inserted for <code>production_item_wip</code>, the procedure above is called.</p><pre><code>create trigger production_stage before
insert
  on production_item_wip for each row execute procedure fn_production_stage_modified();</code></pre><!--kg-card-begin: html--><p>
    <h3>The Collaborative SQL Editor</h3>
    
</p><!--kg-card-end: html--><p>That’s it! In this example the payload is the same each time. You could send actual data rather than just an alert, but in this example I prefer to send a basic notification so the client application can receive it and then in turn, select <em>exactly</em> what it needs in a separate query.</p><p>Encoding data within a notification, whether it’s a push notification or one from something like <code>pg_notify</code>, requires you to abstract away the source of the notification, assuming the data is normally delivered via an HTTP API. Using notifications as a “hint” for your software to reach out and get fresh data from an HTTP API simplifies the process and helps you reduce the number of different data sources you need to maintain.</p><h3 id="postgres-listen-syntax">Postgres LISTEN Syntax</h3><p>Listening to a channel is even simpler: <code>LISTEN order_progress_event;</code> </p><p>That really is all.</p><p>When this event is called, we’ll want to select the latest production data for the day. Here’s a view that will show how many products have progressed through each production stage today:</p><pre><code>create view view_daily_production_stats as
select
  count(1) as stage_count,
  ps.name as stage_namefrom production_item_wip piw
  join production_stage ps on ps.id = piw.production_stage_idwhere date(piw.insert_time) = date(now())
group by
  ps.id</code></pre><p>Now that your client is listening, how can you react to events it receives? This varies by client, since the featuresets of programming languages that serve async events vary heavily. We are using JavaScript’s <code>pg</code> client in this example. JavaScript is commonly used for asynchronous web programming.</p><pre><code>var clients = [];
function eventCallback(event) {
  query('select * from view_daily_production_stats', (data) =&gt; {
    clients.map(c =&gt; {
      c.send(data);
    });
  });
}
client.connect(function(err, client) {
  var query = client.query("LISTEN order_progress_event");
  client.on("notification", eventCallback);
});
;  </code></pre><p>Whenever a new event is received by the PostgreSQL client, the function <code>eventCallback</code> will be called with the payload from <code>NOTIFY</code>. The callback then queries the view we wrote earlier to select the most recent production stage data, and loops through to send the new data to all of the listening clients (Raspberry Pis). The clients receive the data and render HTML.</p><h3 id="putting-it-all-together">Putting it all Together</h3><figure><img src="https://blog.arctype.com/content/images/2021/03/IMG_0744.JPG" alt="" srcset="https://blog.arctype.com/content/images/size/w600/2021/03/IMG_0744.JPG 600w, https://blog.arctype.com/content/images/size/w1000/2021/03/IMG_0744.JPG 1000w, https://blog.arctype.com/content/images/2021/03/IMG_0744.JPG 1600w" sizes="(min-width: 720px) 720px"></figure><p><code>pg_notify</code> is simple, built-in to PostgreSQL feature that has tons of different potential use cases. If you need a simple, real-time notification of just a few specific events, consider checking it out! <a href="https://blog.arctype.com/p/a2b910df-311c-4f7f-b902-7953de122f4b/www.arctype.com/">Arctype</a>, with its functions for running Javascript alongside SQL, is built for developers who want to build applications like this.</p><!--kg-card-begin: html--><p>
    <h3>The Collaborative SQL Editor</h3>
    
</p><!--kg-card-end: html-->
          </div></div>]]>
            </description>
            <link>https://blog.arctype.com/postgres-notify-for-real-time-dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26350862</guid>
            <pubDate>Fri, 05 Mar 2021 00:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maps of Matter]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26349725">thread link</a>) | @danohuiginn
<br/>
March 4, 2021 | https://futureofmatter.com/maps_of_matter.html | <a href="https://web.archive.org/web/*/https://futureofmatter.com/maps_of_matter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
    <p>
      <strong>Status:</strong> <em>Rough working notes – me
      thinking aloud. Speculative, and likely contains errors,
      misconceptions, and omissions; thoughtful, informed comments are
      welcome. Intended for a general scientifically curious audience,
      not requiring much detailed specialist background.</em>
    </p>
    
    <p>
      It is sometimes said physics is nearing its end – closing
      in on a “theory of everything” – because we
      understand so much about the basic rules governing the particles
      and forces in our universe. This is like asserting that computer
      science ended in 1936 with the Turing machine, computing's
      “theory of everything”. Of course, that's not what
      happened. Rather, the invention of the Turing machine opened a
      new creative frontier, enabling an extraordinary profusion of
      new ideas.
    </p>

    <p>
      Science is going through a similarly exciting transition
      today. Until recently humanity worked with matter much like we
      did computing prior to Turing, using a patchwork of bespoke
      tools and ideas. But now we understand the fundamentals of how
      matter works: we have a fantastic theory describing the
      elementary particles and forces, and we're getting increasingly
      good at manipulating matter. And so we're beginning to ask: what
      can we build, <em>in principle</em>? Not just in a practical
      sense, with the tools that happen to be at hand, but in a
      fundamental sense: what is allowed by the laws of physics?
    </p>

    <p>
      Of course, this implies a whole world of questions: What
      qualities are possible in matter? Can we do for matter what
      Turing and company did for computation? Can we invent new
      high-level abstractions and design principles for matter,
      similar to what people like John McCarthy and Alan Kay did for
      computing?  What design space is opened up when we control
      matter as well as we control pixels on a computer screen? What
      beautiful new design ideas are possible?
    </p>

    <p>
      Most of the matter in our everyday experience is constructed
      from just three particles: protons, electrons, and
      neutrons. These can be used to build an astonishing array of
      different things: diamonds; human beings; galaxies; black holes;
      iPhones. With sufficiently good tweezers and a lot of patience
      you could reassemble a human being into a bicycle of comparable
      mass; and vice versa.
    </p>

    <p>
      So, what else can we build from protons, electrons, and
      neutrons*<span>* Martin Rees has pointed out
      that we humans tend to engage in particle chauvinism, often
      assuming that what we think of as “ordinary matter”
      is all there is to matter. Indeed, I've engaged in just such a
      chauvinism in asserting above that “we understand the
      fundamentals of how matter works”.  However, based on what
      we currently suspect about dark matter, so-called
      “ordinary matter” may actually be rather unusual,
      the exception rather than the rule. Nonetheless, in the absence
      of a good understanding of dark matter I shall continue to
      engage in particle chauvinism, and restrict myself in this essay
      to ordinary matter. Indeed, I shall go further and restrict the
      discussion (mostly) to protons, electrons, and neutrons.
      </span>?
    </p>

    <p>
      It seems likely we can build things that would astonish us,
      things going radically beyond anything we can even conceive of
      today, much less build.
    </p>

    <p>
      Consider that ten million years ago conscious minds were absent
      from the earth, except in quite primitive forms. Might there be
      forms of matter possible which are as different from anything
      familiar to us today as consciousness is from a
      rock*<span>* Some people don't believe
      consciousness is a property of matter. There are limited senses
      in which that is reasonable: certainly, matter is a substrate,
      and aspects of consciousness may be independent of the details
      of that substrate, in a matter analogous to the way an algorithm
      has an existence independent of the computer it runs
      on. Nonetheless, I don't think there is much serious reason to
      doubt that consciousness is a property that emerges out of
      ordinary matter.</span>?
    </p>
    
    <p>
      What might those forms be?
    </p>

    <p>
      One way to explore the “what can we build?” question
      is to look at different <em>maps of matter</em>. Probably the
      best known such map is the periodic table, showing all the
      different types of atoms which make up most of the matter in the
      world around us. But there's many other maps of matter. There's
      phylogenetic trees, which show the relationship between
      different types of life. There's maps of the different types of
      stars, of the different phases of matter, of all the proteins
      we've found. And many more.
    </p>

    <p>
      In these notes we'll go on safari through several such maps of
      matter. We won't go too deep into any individual map –
      everything I discuss could be (often has been) the subject of
      PhD theses, or even an entire field. Instead, we're going to
      look rapidly at several different ways we explore matter. The
      purpose is to discern some general principles that can help us
      explore in generative ways.
    </p>

    <p>
      When I began writing these notes I had a whimsical question in
      mind: is there a single, unified map we can use to understand
      all of matter? I hoped the attempt to make such a unified map
      would give me some insight into the question “what can we
      build, in principle?” And so, as I wrote the notes I toyed
      with multiple ways of making a unified map. Eventually, I
      realized matter is too rich and variegated for a really good
      unified map to be possible. What's more, to do even a passing
      job these notes would need to be a hundred times longer!
      Nonetheless, I found the attempt stimulating. And so at the end
      of the notes I show a single diagram which encapsulates many of
      the ideas for exploration developed in these notes. It's grossly
      incomplete, but hopefully interesting and generative.
    </p>

    <h2>The strangest places in the periodic table</h2>

    <p>
      The physicist John Wheeler once stated a useful principle to
      guide research: “In any field, find the strangest thing
      and explore it”. One great thing about maps is that they
      suggest strange things. This is true even when the map itself is
      familiar, like the periodic table. We can ask ourselves: where
      are the strangest “places” in the periodic table?
      And then challenge ourselves to explore those places.
    </p>

    <p>
      One candidate for the strangest place in the periodic table is
      the most recently discovered chemical element, oganesson. It's
      the heaviest known element, with an atomic number of 118. It's
      highlighted below with a red circle in the bottom
      right*<span>* Image adapted from images due
      to users “Double sharp” and “Offnfopt”
      on <a href="https://commons.wikimedia.org/wiki/File:Simple_Periodic_Table_Chart-blocks.svg">Wikipedia</a>.</span>:
    </p>

    <center>
    <img src="https://futureofmatter.com/assets/periodic_table.svg" width="100%">
    </center>
    
    <p>
      Oganesson was discovered in 2002 by a team of scientists headed
      by Yuri Oganessian, after being predicted in 1895 by Hans Peter
      Jørgen Julius Thomsen. It was made by using calcium ions to
      bombard a target of californium atoms, at very high speed. Only
      a handful of oganesson atoms have ever been observed –
      around a half dozen, with several of those observations regarded
      as unconfirmed.
    </p>

    <p>
      We don't know much for sure about oganesson – the handful
      of atoms observed decayed too quickly to get much idea of what
      oganesson does. Despite this, intensive theoretical studies have
      been done, and some surprising predictions made. Oganesson is in
      the final column of the periodic table, and these are of course
      the “noble gases”, highly non-reactive gases like
      helium and argon.
    </p>

    <p>
      At least, that's the story we learn in high school chemistry. In
      fact, oganesson confounds these expectations. Theoretical
      calculations suggest oganesson is likely to be a solid
      semiconductor at standard temperature and pressure, not a
      gas. Furthermore, it may be significantly reactive, unlike the
      other noble gases*<span>* Clinton
      S. Nash, <a href="https://pubs.acs.org/doi/10.1021/jp050736o">Atomic
      and Molecular Properties of Elements 112, 114, and 118</a>
      (2005). Note that the other noble gases <em>are</em> at least
      somewhat reactive (disodium helide, anyone?)
      – <a href="https://en.wikipedia.org/wiki/Noble_gas_compound">Wikipedia's
      discussion is a good place to start</a> – but oganesson is
      predicted to be significantly moreso.</span>.
    </p>

    <p>
      There is a standard argument for why noble gases are
      non-reactive gases – the gist is to understand the
      electron orbital shell structure, the number of electrons in
      each, and why full shells are particularly stable and lead to
      non-reactive elements. What you learn from oganesson is that
      some of the principles underlying that argument can't be quite
      right. I must admit, I haven't worked through the details of how
      the standard argument breaks down (beyond quickly skimming the
      above paper); nonetheless, it's extremely useful to have a
      little flag in my head saying that the standard argument about
      electron orbitals and noble gases actually breaks down for some
      elements.  That argument is often presented as being based on
      universal principles, but those principles are not, in fact,
      universal.
    </p>

    
    <p>
      And so one benefit of exploring oganesson is that it improves
      other parts of your understanding of matter, even if only by
      informing you of limits to that understanding. And it pokes at
      you: the periodic table has the shape it does <em>because</em>
      of those underlying principles. If …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://futureofmatter.com/maps_of_matter.html">https://futureofmatter.com/maps_of_matter.html</a></em></p>]]>
            </description>
            <link>https://futureofmatter.com/maps_of_matter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26349725</guid>
            <pubDate>Thu, 04 Mar 2021 22:59:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compensation as a Reflection of Values]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 91 (<a href="https://news.ycombinator.com/item?id=26348836">thread link</a>) | @timf
<br/>
March 4, 2021 | https://oxide.computer/blog/compensation-as-a-reflection-of-values/ | <a href="https://web.archive.org/web/*/https://oxide.computer/blog/compensation-as-a-reflection-of-values/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Compensation: the word alone is enough to trigger a fight-or-flight reaction in many. But we in technology have the good fortune of being in a well-compensated domain, so why does this issue induce such anxiety when our basic needs are clearly covered? If it needs to be said, it's because compensation isn't merely about the currency we redeem in exchange for our labors, but rather it is a proxy for how we are <em>valued</em> in a larger organization. This, in turn, brings us to our largest possible questions for ourselves, around things like meaning and self-worth.</p><p>So when we started Oxide -- as in any new endeavor -- compensation was an issue we had to deal with directly. First, there was the thorny issue of how we founders would compensate ourselves. Then, of course, came the team we wished to hire: hybrid local and remote, largely experienced to start (on account of <a href="https://www.youtube.com/watch?v=vvZA9n3e5pc">Oxide's outrageously ambitious mission</a>), and coming from a diverse set of backgrounds and experiences. How would we pay people in different geographies? How could we responsibly recruit experienced folks, many of whom have families and other financial obligations that can't be addressed with stock options? How could we avoid bringing people's compensation history -- often a reflection of race, gender, class, and other factors rather than capability -- with them?</p><p>We decided to do something outlandishly simple: take the salary that Steve, Jess, and I were going to pay ourselves, and pay that to everyone. The three of us live in the San Francisco Bay Area, and Steve and I each have three kids; we knew that the dollar figure that would allow us to live without financial distress -- which we put at $175,000 a year -- would be at least universally adequate for the team we wanted to build. And we mean everyone literally: as of this writing we have 23 employees, and that's what we all make.</p><p>Now, because compensation is the hottest of all hot buttons, it can be fairly expected that many people will have a reaction to this. Assuming you've made it to this sentence it means you are not already lighting us up in your local comments section (thank you!), and I want to promise in return that we know some likely objections, and we'll address those. But before we do, we want to talk about the benefits of transparent uniform compensation, because they are, in a word, profound.</p><p>Broadly, our compensation model embodies our <a href="https://oxide.computer/about/">mission, principles, and values</a>. First and foremost, we believe that our compensation model reflects our principles of <b>honesty</b>, <b>integrity</b>, and <b>decency</b>. To flip it around: sadly, we have seen extant comp structures in the industry become breeding grounds for dishonesty, deceit, and indecency. Beyond our principles, our comp model is a tangible expression of several of our values in particular:</p><ul><li><p>It has set the tone with respect to <b>teamwork</b>. In my experience, the need to "quantify" one's performance in exchange for justifying changes to individual compensation are at the root of much of what's wrong in the tech industry. Instead of incentivizing people to achieve together as a team, they are incentivized to advance themselves -- usually with sophisticated-sounding jargon like OKRs or MBOs, or perhaps reasonable-sounding (but ultimately misguided) mantras like "measure everything." Even at their very best, these individual incentives represent a drag on a team, as their infrequent calibration can prevent a team from a necessary change in its direction. And at worst, they leave individuals perversely incentivized and operating in direct opposition to the team's best interest. When comp is taken out of the picture, everyone can just focus on what we need to focus on: getting this outlandish thing built, and loving and serving the customers who are taking a chance on it.</p></li><li><p>It is an expression of our <b>empathy</b>. Our approach to compensation reflects our belief in treating other people the way that we ourselves want to be treated. There are several different dimensions for this, but one is particularly visceral: because we have not talked about this publicly, candidates who have applied to Oxide have done so assuming that we have a traditional comp model, and have braced themselves for the combat of a salary negotiation. But we have spoken about it relatively upfront with candidates (before they talk to the team, for example), and (as the one who has often had this discussion) the relief is often palpable. As one recent candidate phrased it to me: "if I had known about this earlier, I wouldn't have wasted time stressing out about it!"</p></li><li><p>It is (obviously?) proof-positive of our <b>transparency</b>. Transparency is essential for building <i>trust</i>, itself one of the most important elements of doing something bold together. One of the interesting pieces of advice we got early on from someone who has had outsized, repeated success: modulo private personnel meetings, make sure that every meeting is open to everyone. For those accustomed to more opaque environments, our level of transparency can be refreshing: for example, new Oxide employees have been pleasantly surprised that we always go through our board decks with everyone -- but we can't imagine doing it any other way. Transparent compensation takes this to an unusual (but not unprecedented) extreme, and we have found it to underscore how seriously we take transparency in general.</p></li><li><p>It has allowed whole new levels of <b>candor</b>. When everyone can talk about their salary, other things become easier to discuss directly. This candor is in all directions; without comp to worry about, we can all be candid with respect to our own struggles -- which in turn allows us to address them directly. And we can be candid too when giving public positive feedback; we don't need to be afraid that by calling attention to someone's progress, someone else will feel shorted.</p></li></ul><p>These are (some of!) the overwhelming positives; what about those objections?</p><ul><li><p>Some will say that this salary is too low. While cash compensation gets exaggerated all of the time, it's unquestionable that salaries in our privileged domain have gotten much higher than our $175,000 (and indeed, many at Oxide have taken a cut in pay to work here). But it's also true that $175,000 per year puts us each in the top 5% of US individual earners -- and it certainly puts a roof over our families' heads and food in their bellies. Put more viscerally: this is enough to not fret when your kids toss the organic raspberries into the shopping cart -- or when they devour them before you've managed to get the grocery bags out of the car! And speaking of those families: nothing is more anxiety-producing than having a healthcare issue compounded by financial distress due to inadequate insurance; Oxide not only offers the best healthcare plans we could find, but we also pay 100% of monthly premiums -- a significant benefit for those with dependents.</p></li><li><p>Some will say that we should be paying people differently based on different geographical locations. I know there are thoughtful people who pay folks differently based on their zip code, but (respectfully), we disagree with this approach. Companies spin this by explaining they are merely paying people based on their cost of living, but this is absurd: do we increase someone's salary when their spouse loses their job or when their kid goes to college? Do we slash it when they inherit money from their deceased parent or move in with someone? The answer to all of these is no, of course not: we pay people based on their work, not their costs. The truth is that companies pay people less in other geographies for a simple reason: because they can. We at Oxide just don't agree with this; we pay people the same regardless of where they pick up their mail.</p></li><li><p>Some will say that this doesn't scale. This is, at some level, surely correct: it's hard to envision a multi-thousand employee Oxide where everyone makes the same salary -- but it has also been (rightly) said that startups should do things that don't scale. And while it seems true that the uniformity won't necessarily scale, we believe that the values behind it very much will!</p></li><li><p>Some will say that this makes us unlikely to hire folks just starting out in their career. There is truth to this too, but the nature of our problem at Oxide (namely, technically very broad and very deep), the size of our team (very small), and the stage of our company (still pretty early!) already means that engineers at the earliest stages of their career are unlikely to be a fit for us right now. That said, we don't think this is impossible; and if we felt that we had someone much earlier in their career who was a fit -- that is, if we saw them contributing to the company as much as anyone else -- why wouldn't we reflect that by paying them the same as everyone else?</p></li><li><p>Some will say that this narrows the kind of roles that we can hire for. In particular, different roles can have very different comp models (sales often has a significant commission component in exchange for a lower base, for example). There is truth to this too -- but for the moment we're going to put this in the "but-this-can't-scale" bucket.</p></li><li><p>Some will say that this doesn't offer a career ladder. Uniform compensation causes us to ask some deeper questions: namely, what <em>is</em> a career ladder, anyway? To me, the true objective for all of us should be to always be taking on new challenges -- to be unafraid to learn and develop. I have found traditional ladders to not serve these ends particularly well, because they focus us on competition rather than collaboration. By eliminating the rung of compensation, we can put the focus on career development where it belongs: on supporting one another in our self-improvement, and working together to do things that are beyond any one of us.</p></li><li><p>Some will say that we should be talking about equity, not cash compensation. While it's true that startup equity is important, it's also true that startup equity doesn't pay the orthodontist's bill or get the basement …</p></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://oxide.computer/blog/compensation-as-a-reflection-of-values/">https://oxide.computer/blog/compensation-as-a-reflection-of-values/</a></em></p>]]>
            </description>
            <link>https://oxide.computer/blog/compensation-as-a-reflection-of-values/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26348836</guid>
            <pubDate>Thu, 04 Mar 2021 21:44:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse-engineering Rosetta 2 Part 1: Analyzing AoT files and the runtime]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26346980">thread link</a>) | @my123
<br/>
March 4, 2021 | https://ffri.github.io/ProjectChampollion/part1/ | <a href="https://web.archive.org/web/*/https://ffri.github.io/ProjectChampollion/part1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
              
            
            
              
              
            
          
          <div>
            <article>
              
                
                  <a href="https://github.com/FFRI/ProjectChampollion/edit/master/docs/part1.md" title="Edit this page">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
                  </a>
                
                
                
<p>date: 2021/2/19</p>
<p>author: Koh M. Nakagawa</p>
<h2 id="introduction">Introduction</h2>
<p>Apple announced that it would be moving from Intel processors to Arm-based Apple Silicon CPUs for Macs at WWDC 2020.
The Apple Silicon-based Mac Book Air and Pro were released in October 2020 with great fanfare.</p>
<p>One of the issues that arise with the CPU transition is application compatibility.
Since Apple Silicon is an Arm-based processor, applications built for Intel-based Macs will no longer work.
To solve this problem, Apple offers the following two technologies:</p>
<ul>
<li>Universal Binary 2</li>
<li>Rosetta 2</li>
</ul>
<p>Universal Binary 2 is a mechanism to encapsulate binaries built for multiple architectures into a single binary, which is also called Fat Binary.
Apple has been using this technology for a long time to maintain backward compatibility.
A Mach-O loader selects the binary with the best architecture for the machine it is running on, then loads only that binary into memory to run the program.
Most macOS Big Sur system binaries are currently Fat Binaries, containing binaries built for both Arm and Intel architectures.</p>
<p>Rosetta 2 is a technology that translates Intel-based binaries or JIT-generated code into Arm-based binaries or code.
It is the successor to Rosetta, which was also used in the past processor transition.
There is not much information officially released by Apple.
Of course, there is no source code available, unlike the XNU kernel.
Also, at the time of writing this article, there seems to be no article that examines it in detail.</p>
<p>In this article, I introduce some reverse engineering results of Rosetta 2.</p>
<p>Why I take a closer look at Rosetta 2?</p>
<p>The reason is that I'm interested in translated binaries in Rosetta 2 and examining the possibility of exploiting them.
I presented <a href="https://www.blackhat.com/eu-20/briefings/schedule/index.html#jack-in-the-cache-a-new-code-injection-technique-through-modifying-x-to-arm-translation-cache-21324">a new code injection technique in Windows 10 on Arm at Black Hat EU</a> last December.
The code injection is achieved by modifying x86 to Arm (XTA) binary translation cache files.
This research encourages me to examine whether similar code injection techniques can be achieved with Rosetta 2.</p>
<p>In this part, I will cover the following points:</p>
<ul>
<li>The executables associated with Rosetta 2 and their roles</li>
<li>Analysis results of the translated binaries</li>
<li>JIT binary translation capabilities of Rosetta 2 (mainly focusing on x86_64 machine code decoding process)</li>
</ul>
<p>In the following, I will follow Apple's terminology when referring to architecture.</p>
<ul>
<li>arm64: The architecture specified when generating binaries to run on an Apple Silicon Mac</li>
<li>x86_64: The architecture specified when generating binaries to run on an Intel-based Mac</li>
</ul>
<h2 id="setting-up-the-analysis-environment">Setting up the analysis environment</h2>
<p>First, I show you how to set up the analysis environment.</p>
<p>Rosetta 2 is not installed by default on an Apple Silicon Mac.
So, you need to install it following the pop-up that appears when you run an x86_64 code for the first time.</p>
<figure>
    <img src="https://ffri.github.io/ProjectChampollion/assets/macos-big-sur-software-update-rosetta-alert.jpg">
    <figcaption>Figure 1 Rosetta 2 installation popup (https://support.apple.com/en-us/HT211861).</figcaption>
</figure>

<p>After the installation, a folder named <code>/Library/Apple/usr/libexec/oah/</code> (hereinafter referred to as the oah folder) is created, and you can see the following binaries installed.</p>
<figure>
    <img src="https://ffri.github.io/ProjectChampollion/assets/rosetta_binaries.png">
    <figcaption>Figure 2 Binaries installed after Rosetta 2 installation.</figcaption>
</figure>

<p>The role of each binary will be explained later.</p>
<p>The next step is to disable System Integrity Protection (SIP).
This is because the folder that contains the translated binaries is protected by SIP and cannot be accessed by default even with administrative privileges.</p>
<p>Please follow the steps below to disable SIP.</p>
<ul>
<li>Restart the OS</li>
<li>Press and hold Touch ID to boot in the recovery mode</li>
<li>Select Terminal from "Utilities" at the top of the screen</li>
<li>Type <code>csrutil disable</code> and execute</li>
<li>Restart the OS again</li>
</ul>
<p>In addition to this, please install Xcode and Command Line Tools for Xcode to use Clang and LLDB.</p>
<h2 id="roles-of-oahd-and-oahd-helper">Roles of <code>oahd</code> and <code>oahd-helper</code></h2>
<p>First, let's create a command line application built for x86_64 and monitor system events (e.g., process creation, file-system activities, and memory mapping) when the x86_64 application runs.</p>
<pre><code>$ cat hello.c
#include &lt;stdio.h&gt;
int main() {
    puts("Hello World");
    return 0;
}
$ clang -arch x86_64 hello.c -o hello.out # specify x86_64 as the target architecture
$ file hello.out
hello.out: Mach-O 64-bit executable x86_64
</code></pre>
<p>To obtain several system events, I used EventMonitor created using the <a href="https://developer.apple.com/documentation/endpointsecurity">Endpoint Security Framework</a>.
I will release EventMonitor as an OSS soon.</p>
<p>Start EventMonitor and run <code>hello.out</code>.
The following jsonl file contains logs obtained by EventMonitor. The only events related to Rosetta 2 are extracted.</p>
<p><a href="https://ffri.github.io/ProjectChampollion/assets/event.jsonl">event.jsonl</a></p>
<p>When you look at the first line of the logs, you can see an event where <code>/bin/zsh</code> executes <code>hello.out</code>.</p>
<pre><code>{"event":{"log":{"args":[".\/hello.out"],"cwd":{"path":"\/Users\/konakagawa.ffri","path_truncated":false},"last_fd":4,"target":{"executable_path":"\/Users\/konakagawa.ffri\/hello.out","group_id":54132,"pid":54132,"ppid":48492,"session_id":48491}},"type":"exec"},"target_process":{"executable_path":"\/bin\/zsh","group_id":54132,"pid":54132,"ppid":48492,"session_id":48491}}
</code></pre>
<p>After the exec system call, <code>oahd</code> daemon checks for the file <code>/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0/hello.out.aot</code>.</p>
<pre><code>... (the oahd checks for the AOT file)
{"event":{"log":{"relative_target":"var\/db\/oah\/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00\/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0\/hello.out.aot","source_dir":{"path":"\/","path_truncated":false}},"type":"lookup"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}
</code></pre>
<p>The file with the extension <code>.aot</code> contains the result of the translation from x86_64 to arm64.
We refer to this file as the AOT file.
The name <code>.aot</code> comes from Ahead-Of-Time, which means that the translation is performed before a thread actually starts.
The <code>oahd</code> is the management daemon for the AOT files.</p>
<p>Since this is the first time we run <code>hello.out</code>, the <code>oahd</code> cannot find the corresponding AOT file. So, it creates a new AOT file.
If the same binary in the same path has already been executed and the AOT file has been created, the <code>oahd</code> uses it.</p>
<p>You can see the folder named <code>/var/db/oah</code> in the above logs.
This folder has a <code>Oah.version</code> file at the top, which is supposed to contain the version information for Rosetta 2.
Also, this folder has <code>16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00</code> folder.
We can see that multiple folders are containing AOT files in it.
The names of these folders are SHA-256 hash values that are calculated from both the contents of the file in x86_64 code and the path where it was executed.</p>
<pre><code># /var/db/oah contains the Oah.version file and 16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00 folder
$ ls -l /var/db/oah
total 8
drwxr-xr-x  6528 _oahd  _oahd  208896  2 13 22:22 16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00
-rw-------     1 _oahd  _oahd      32  1 27 14:44 Oah.version
# show some AOT files
$ ls -l /var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/* | head -n 10
/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/00088a4116103832383ae2866e61d745d3d0013c5073ed032dabf6a785611db9:
total 40
-rwxr-xr-x  1 _oahd  _oahd  17656  1 27 14:45 FlashlightModule.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/0008a5059fda4b8aee7110b04a3e65f175a80ea55a64129a7660c7d3ed77a9d5:
total 56
-rwxr-xr-x  1 _oahd  _oahd  25928  1 27 14:47 libswiftAccelerate.dylib.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/00091f4ca51a770fa7a398f4320efe920fa8c3fc611247dcf55ca025f22301d4:
total 600
-rwxr-xr-x  1 _oahd  _oahd  304536  1 27 14:45 AirPlayRoutePrediction.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/000a1ab017d7e24b25cd58739ae01120b8a6d3a9cff37235156dced0123f2c3c:
total 24
-rwxr-xr-x  1 _oahd  _oahd  12280  1 27 14:46 NanoNewsComplications.aot

/var/db/oah/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00/001dac33f82e558695268fb4a4285f47e9806766e7398e377d9dff59235399f5:
total 1192
-rwxr-xr-x  1 _oahd  _oahd  606347  1 27 14:46 TSCoreSOS.aot
</code></pre>
<p>Note that the folders and files under <code>/var/db/oah</code> are protected by SIP, so we cannot access even with admin privileges.
After disabling SIP, we can access these folders and files with admin privileges.</p>
<p>Now, back to the analysis of the logs.
<code>oahd</code> checks for the AOT file, and if not found, it runs <code>oahd-helper</code> to create a new AOT file.</p>
<pre><code>... (oahd creates hello.out.aot.in_progress file)
{"event":{"log":{"dest_path":{"path":"\/private\/var\/db\/oah\/16c6785d8fdab5ee2435f23dc2962ceda2e76042ea2ad1517687c5bb7358bf00\/065b3f057e68a5474d378306e41d8b1e3e8e612b9cf9010b76449e02b607d7f0\/hello.out.aot.in_progress","path_truncated":false},"dest_type":0,"filename":null},"type":"create"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}
... (creates a child process)
{"event":{"log":{"child":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":54133,"ppid":426,"session_id":426}},"type":"fork"},"target_process":{"executable_path":"\/Library\/Apple\/usr\/libexec\/oah\/oahd","group_id":426,"pid":426,"ppid":1,"session_id":426}}</code></pre></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ffri.github.io/ProjectChampollion/part1/">https://ffri.github.io/ProjectChampollion/part1/</a></em></p>]]>
            </description>
            <link>https://ffri.github.io/ProjectChampollion/part1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26346980</guid>
            <pubDate>Thu, 04 Mar 2021 19:27:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Serverless Rust Testing]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26345597">thread link</a>) | @timf
<br/>
March 4, 2021 | https://www.peakscale.com/serverless-rust/ | <a href="https://web.archive.org/web/*/https://www.peakscale.com/serverless-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>In the system I'm building there are a significant amount of SQS messages that need to be processed asynchronously and Lambda is a really good fit for that. It is perfect for spiky workloads. You can control max parallelism easily. And it now has a native integration where Lambda functions are invoked with pending SQS messages without any extra work on your part.</p>
<p>Lambda's great. I think it's time to declare it boring. In the "choose boring technology" sense. As in it's a robust and well-worn solution.</p>
<p>But a significant problem I had was that most of my code is Rust. The Lambda experience with the major languages (e.g. Python) is categorically better. There are fewer gotchas, many more examples, and it seems especially true when trying to use the higher level tooling out there which I will get into in a minute.</p>
<p>Re-writing the pieces in another language like Python was not tempting as these Lambda functions are handling all the same data structures, re-using business logic, and calling the same dependencies as the main code base. It could be done, of course. But having multiple pieces of code doing the same things can be a giant hassle/waste (for small teams especially). And Rust is just far more maintainable to me.</p>
<p>Those reasons to stick with Rust outweighed any deployment inconveniences or performance arguments. </p>
<p>Performance-wise, Rust is surely faster than my main other candidate Python. So, maybe I'd pay significantly less money in the long run? Especially now that Lambda is billing at 1ms increments? I love that this happened but it's not really a significant factor in this case. The actual processing time is dominated by calling SQS, gRPC services, and/or DynamoDB.</p>
<p>Cost decisions all depend on the use case and expected load, of course, but the difference I projected is a not significant problem to me in the real dollars it would translate to. Something like Python would be completely fine here. I projected it would only increase the 30-40ms average runtime by around 10%. Waiting around is pretty efficient in any language. The great news recently was Lambda moving from 100ms billing increments to 1ms: a boon here regardless of the programming language. Very cool.</p>
<p>On a related note, I'm about to create something with Cloudflare Workers (using Rust/wasm) and that's quite a different billing model. Unlike Lambda, if you're awaiting subrequests, it doesn't actively count against your CPU time for that invocation. Sweet. It comes with trade-offs, of course. I'll probably write about what I learn in the future. I bet I'm adopting it for the directly customer-facing layer as my experiments so far on that platform have been pretty positive.</p>
<p>For Lambda and Rust, I ended up trying a number of the higher level frameworks and tools. The biggest factors in the decision were the deployment and testing support. I don't mind some setup pain if there are safe deployment mechanisms and fast, local testing that very closely approximates the real environment.</p>
<p><a href="https://www.serverless.com/">Serverless</a> and <a href="https://aws.amazon.com/serverless/sam/">AWS SAM</a> are the two big ones that work with Rust and provide some local testing capability. There are a lot of other Python-centric ones. If you take local/mock testing out of the requirements, there are also some good infrastructure-as-code options: I'm eventually going to investigate CDK, Terraform, and Pulumi (which I use elsewhere). I have limited time and can't research a comprehensive survey of all of the options, unfortunately. I wish I could.</p>
<p>Fast iteration while developing is really important to me but none of those frameworks were fast for testing. The CLIs themselves take multiple seconds to respond for even simple tasks. Once Rust is involved, you're now into cross-compiling (to <a href="https://doc.rust-lang.org/edition-guide/rust-2018/platform-and-target-support/musl-support-for-fully-static-binaries.html">musl</a>) and on top of that delay the frameworks are building/using Docker containers behind the scenes to run the tests. For a week or so, I was just running the lambci Docker image directly in automated integration tests, but that was not cutting it either. Still all too slow, the cross-compilation especially.</p>
<p>I ended up eschewing the frameworks altogether for local testing which is what I mainly want to write about.</p>
<p>There's now a thin layer that intakes SQS messages and parses the JSON payload into a strongly typed Rust data structure. This is in the <code>bootstrap</code> binary that Lambda runs. It reads environment variables for configuration. Locally, there's a completely separate binary that reads configurations from a dynamically generated file and polls for messages from a Redis queue (using LPOP/BLPOP). In both cases, the parsed queue payload is pushed into the 'real' code base which is identical in both cases. A classic "shim":</p>
<p><img src="https://www.peakscale.com/serverless-rust.png"></p><p>It's worked out well. I folded it into the same test framework that I wrote for traditional services. Redis is just another process that is launched from a group blueprint. The framework can launch groups of arbitrary binaries (either my own artifacts or system binaries like Redis) and Docker containers. Unique ports are reserved on the fly (via a SQLite database that is unique to each node) and written into the dynamically created configuration files. The processes can discover each other by role name so that you don't have to test one process at a time and mock dependencies - they can work together just as they would in the real system. The integration test itself can look up the same configurations and feed the test messages into Redis.</p>
<p>Importantly, many groups can be launched simultaneously, i.e., each integration test can launch its own group of processes. I can have hundreds of these running thousands of Unix processes even on my laptop. The Unix process model works quite well. Use it!</p>
<p>And that means cross-compiling to musl only happens for real deployments to Lambda. Anything I'm in the middle of coding is incrementally compiled and local (either OSX or Linux). The tests can be run nearly instantly. Both Redis and Rust binaries are extremely fast to execute and get to an operational state. The actual process wrangling is handled by the extremely fast <a href="http://smarden.org/runit/">runit</a> set of tools which the group management code triggers. No more waiting on those Lambda testing framework's slow local testing or, worse, actually deploying to Lambda to get basic iterative feedback.</p>
<p>It's just unacceptable to me to wait more than a few seconds. Anything that requires more time tends to mean you get sucked into some distraction. When I'm coding I want to stay in the flow of it. Getting instant feedback from testing is awesome. Getting instant feedback from tests that are running exactly the same thing as production? That is just perfect. Unfortunately in this case, unlike my web services, it required faking something out (substituting Redis in for SQS) but I think it's low risk.</p>
<p>Even so, before final deployment I still choose to run the test suite against something with almost exact parity as production (basically only differing from production in stored database data). There could always be some difference. On teams I've been on, we've caught a few problems in those stages.</p>
<p>I also believe in the 'testing in production' ideas out there, to an extent. As long as we're not talking about <em>only</em> testing in production which usually makes no sense. There are still a number of problems you can catch ahead of time with a stage right before production that matches the infrastructure. In my case it's going to add around 10 minutes per actual deployment and I'm just fine with that given that it's automated and the potential value from avoiding an outage. But everyone has their own trade-offs to think about (<a href="https://www.peakscale.com/context/">context</a> matters).</p>
<p>Meanwhile both my local development flow and the longer full integration test suite were both sped up massively.</p>
<hr>
<p>Update: wrote a separate post going into more detail about process group launches and runit <a href="https://www.peakscale.com/process-groups-runit/">here</a>.</p>
<hr>

    </div></div>]]>
            </description>
            <link>https://www.peakscale.com/serverless-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26345597</guid>
            <pubDate>Thu, 04 Mar 2021 17:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Female Founder Secrets: Fertility]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 715 (<a href="https://news.ycombinator.com/item?id=26345226">thread link</a>) | @femfosec
<br/>
March 4, 2021 | https://femfosec.com/fertility/ | <a href="https://web.archive.org/web/*/https://femfosec.com/fertility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Because of our biological clocks, women need to consider the timing of children a lot more urgently than men.</p><p>Startups take much longer than you’d think before they become successful. You should have a 5-10 year horizon, at least.</p><p>And the period between when you start the startup and when you can relax a little is grueling and all-consuming. The focus that’s required at first will probably force you to cut back on almost everything in your life, making a healthy work/life balance nearly impossible.</p><p>Startups are also unpredictable. In the early stages, you can’t plan too far in the future and arrange your life neatly around your plans, as you might with a job as an employee in the corporate world.</p><p>So you are working around the clock—so busy that you can’t focus on much outside of work, not knowing what startup disaster is around the corner, and maybe with no end in sight for years. But you know you want a family someday, either with your current partner or someone you haven’t even had the time to meet yet.</p><p>Because startups can cause you to neglect much of your own life, women founders need to be really proactive about their fertility. Especially if you want to buy more time before the window shuts on your childbearing years.</p><p>My advice: Freeze your eggs/embryos.</p><p>I wish I had. Life with my company whizzed by and it wasn’t until my late 30s when I had a child. After a year, I started working on baby #2. Three miscarriages later, I finally woke up to the urgency of the situation and went to a fertility doctor.</p><p>The next few years were consumed by IVF cycles. My obsession to have another baby grew with each failed cycle. I’d be on an emotional roller coaster waiting for the various results, praying that this time was the magical one. It never was. My eggs were just too old, I think. After 8 rounds with not one viable embryo to transfer, I decided I had to move on, to focus on my kid and all the really great things in my life. But the what-ifs still haunt me, privately.</p><p>Aspects of getting your eggs retrieved and/or frozen can be really awful. It’s extremely expensive if not covered by your medical insurance. The drugs can wreak havoc on moods and emotions. Between all the doctor’s appointments and the various shots (which cause serious bruising) you have to give yourself several times each day, it’s quite time consuming. &nbsp;And it’s stressful. At least it was for me. The stakes feel so high.</p><p>But nothing is as awful as it not working out. It’s a type of depressing that’s difficult to describe concisely.</p><p>It might seem weird or somehow frivolous to freeze your eggs—and especially to freeze embryos if you’re already married. (Though it’s becoming more mainstream as companies offer egg freezing as an employee benefit.) But freezing is worth it simply because it gives you more options as you get older.</p><p>Until they go through it themselves, few people realize how hard Mother Nature can be in the fertility department. The older you are, the tougher the blows. So if you want a biological child, the best thing you can do is prepare. You don’t want to be like me and wake up one day and it’s too late.</p>
			</section></div>]]>
            </description>
            <link>https://femfosec.com/fertility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26345226</guid>
            <pubDate>Thu, 04 Mar 2021 17:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Search for a Perfect Access Control System]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26344870">thread link</a>) | @aberoham
<br/>
March 4, 2021 | https://goteleport.com/blog/access-controls/ | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/access-controls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/access/controls.png" width="100%" alt="Access controls overview"></p>

<h2 id="evergreen-challenge">Evergreen Challenge</h2>

<p>Every cloud has its own identity and access management system. AWS and Google use a bunch
of JSON files specifying various rules. Open source projects like Kubernetes support
three concurrent access control models - attribute-based, role-based and
a webhook access control, all expressed using YAML. Some teams are going as far as
inventing their own programming language to solve this evergreen problem.</p>

<p>As many engineers before us, we faced the challenge of choosing the
design and the tooling from the kaleidoscope of JSON, YAML and custom languages
for our own software’s access controls. Which system is the best, and can there be one language to rule them all?
What are the properties of a good access control system, and what mistakes of the past should we avoid?</p>

<h2 id="time-sharing-and-first-pen-testers">Time Sharing and First Pen-testers</h2>

<p>In the early 1960s one computer could be accessed by one person, program and team at a time.
Computers were quite expensive; a PDP-1, for example, would cost you a whopping $120,000.
That’s close to $1M adjusted for inflation in 2021.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/pdp-1.jpg" width="100%" alt="PDP-1 in a computer history museum"></p>

<p><em>DEC PDP-1 in a computer history museum</em></p>

<p>You could securely use the computer for different applications as long as the files and data for
different projects were kept separate. That was a serious bottleneck, and by the mid-sixties manufacturers offered time-sharing systems
that allowed many folks to use computers at the same time.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/time-sharing.jpg" width="100%" alt="Fernando Corbató with MIT's IBM 7090"></p>

<p><em>Fernando Corbató - researcher working on time sharing with MIT’s IBM 7090</em></p>

<p>The arrival of time sharing made folks at the U.S. Air Force worried.
There could be two programs residing in the storage and sharing compute and memory at the same time.
What if a program working on a lower privilege level hacked the system and gained access to sensitive data of another program?</p>

<p>To assess the scope of the problem, USAF formed a special task force to
figure out the impact of such hacks and come up with a solution.
The team came back with some bad news: operating systems at the time were not designed
at all to protect from a malicious program. The executable had almost unrestricted
capability to reference any main and auxiliary memory locations.
The task force concluded that a new approach was needed [1]:</p>

<blockquote>
<p>The operating systems were not designed to be secure, provide a malicious user
with any number of opportunities to subvert the operating system itself.</p>

<p>…</p>

<p>A system designed to be secure, containing;</p>

<p>A) An adequate system access control mechanism</p>

<p>B) An authorization mechanism</p>

<p>…</p>
</blockquote>

<h2 id="bell-la-padula-security-model">Bell-La Padula Security Model</h2>

<p>In 1972, two computer scientists were assigned with the task of designing such a system [2].</p>

<blockquote>
<p>In the summer of 1972, The MITRE Corporation initiated its task to produce a report titled “Secure Computer Systems.”
The modeling task fell to Len La Padula and me. David E Bell.</p>
</blockquote>

<p>In 1972-1974 David E. Bell and Leonard J. La Padula came up with the theoretical foundations of access control systems [3]
and then worked with programmers to implement that in the most promising O.S. at the time — Multics [4].
In the Multics paper, they defined elements of both models still used to this day — subjects,
objects and access control lists.</p>

<ul>
<li><code>subjects</code> are actors, like processes and programs in execution.</li>
<li><code>objects</code> are passive things, like data, files, programs, subjects.</li>
</ul>

<p><img src="https://goteleport.com/blog/images/2021/access/subjects-objects.png" width="100%" alt="Subjects accessing objects"></p>

<p><em>Subjects accessing objects. Here and below are the original figures from the paper.</em></p>

<p>Subjects can access objects. These access modes are governed by access <code>attributes</code>:</p>

<ul>
<li><code>e</code> - no access, <code>r</code> - read-only, <code>a</code> - can write, but not read, <code>w</code> - can read and write.</li>
</ul>

<p>They defined access of subject to object with a triple:</p>
<pre><code>(subject, object, attribute)</code></pre>
<p>Objects are organized in a tree-like structure, forming a hierarchy.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/object-structure.png" width="100%" alt="Object structure"></p>

<p><em>Object structure</em></p>

<p>An access matrix specifies access modes (<code>e</code>, <code>r</code>, <code>a</code>, <code>w</code>) in which subjects can access objects.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/access-matrix.png" width="100%" alt="Access Matrix"></p>

<p>Because MITRE corporation’s research was funded by the military, you would find a couple of parts unfamiliar to
most Unix users — category and classification levels for the U.S. Military — “unclassified”, “confidential”, “secret”, “top secret”.
Categories are general topics such as “Nuclear”, “NATO” or “Crypto”.</p>

<p>Security level assigned to an individual and object is a pair:</p>
<pre><code>(classification, set of categories)</code></pre>
<p>A user can access a document if their security level “dominates” the document level:</p>
<pre><code>(class 1, category-set 1) dominates (class 2, category-set 2) if and only if

class 1&gt;= class 2 and category-set 1 includes category-set 2 as a subset</code></pre>
<p><strong>Simple Security Property</strong></p>

<p>The researchers have defined a first property, as a simple security property:</p>

<p>For a triplet <code>(subject, object, read)</code> the security level of a subject always “dominates” security level of an object.
In other words, subjects can only read objects with the same or lower security level.
This property is also sometimes called “Read down” or “ss-property”.</p>

<p><strong>Star Property</strong></p>

<p>Bell and La Padula noticed that “simple security property” is not enough to protect classified
information. A malicious program could pass classified information along by reading the classified
docs on one level and writing on lower level:</p>

<p><img src="https://goteleport.com/blog/images/2021/access/star-property.png" width="100%" alt="Star property"></p>

<p>They called it “*-property”:</p>

<blockquote>
<p>in any state, if a subject has simultaneous “observe” access to object-1 and “alter”
access to object-2, then level (object-1) is dominated by level (object-2)</p>
</blockquote>

<p>In other words, you cannot read objects at higher security level and write
to objects at lower security level. Some folks call this property “Write Up”.
With this rule in place, any system drifts towards higher and higher clearance level
documents and it creates a practical problem — what if you still need to communicate the
level “down”? They defined “trusted subjects”, exceptions to the “*-property”
rule to communicate some information down and lower clearance of the documents.</p>

<p><strong>Discretionary and Mandatory</strong></p>

<p>To conform to military regulations, the researchers defined a “mandatory” or “non-discretionary” security policy —
an individual may not exercise their judgment to violate access standard, and the enforcement
is mandatory.</p>

<p>Two systems have emerged: Mandatory Access Controls (MAC), in which individuals
have no say in whether to set up their access levels, and Discretionary Access Control (DAC), in which folks
have some say who can access what.</p>

<p>Discretionary security is defined by access matrix above and specified as “ds-property”:</p>

<blockquote>
<p>if (subject-i, object-j, attribute-x) is a current access … then attribute-x is recorded
in the (subject-i, object-j) component of M …</p>
</blockquote>

<p>In other words, subjects can access objects if there is a matching access attribute
in the matrix.</p>

<p><strong>Basic Security Theorem</strong></p>

<p>Bell and La Padula defined “Basic security theorem” as a combination of
“ss-property”, “*-property” and “ds-property’.</p>

<p>In their assessment, the system is secure if:</p>

<ul>
<li>Users can only read resources at lower or equal security levels (Read Down)</li>
<li>Subjects cannot read objects at higher level and write to objects at lower level (Write Up)</li>
<li>System enforces access attributes on any subject-object access.</li>
</ul>

<p>The researchers were excited about “inductive nature” of the Basic Security Theorem — the system
will stay secure through all transitions as long as these three rules are enforced.</p>

<p>In the security world, this is also called security invariant — a property that system
keeps true at all times despite all the changes.</p>

<p><strong>Multics</strong></p>

<p><img src="https://goteleport.com/blog/images/2021/access/multics.jpg" width="100%" alt="Visicalc on Multics"></p>

<p><em>Visicalc running on Multics</em></p>

<p>Based on this paper, Multics engineers introduced access control lists — <code>ACL</code>.
Multics “ACLs” were composed of <code>(process, ring bracket)</code> pairs, where process is analogue of
the paper’s subject and ring bracket is a clearance level.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/acls.png" width="100%" alt="Multics ACLs"></p>

<p><em>Multics ACLs. Multics Paper</em></p>

<p>Objects could be “directory segments”, data segments, certain I/O devices, certain
address spaces and sockets.</p>

<p>Multics stored ACLs in the parent directory of an object and manipulated them
by altering the directory properties. Control over an object was represented
by write permission on an object’s directory.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/segment.png" width="100%" alt="Adding Segment to DIR"></p>

<p><em>Adding Segment to DIR. Multics Paper</em></p>

<p>A request to give access to an object is allowed only if the requesting subject
has current <code>w</code> access to the parent of the object.</p>

<p>Imagine a situation when a user created unclassified folder <code>Or</code>, then in it,
created a secret folder <code>O1</code> and placed unclassified file <code>O2</code> in it.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/compatibility.png" width="100%" alt="A need for compatibility"></p>

<p><em>A need for compatibility. Multics Paper</em></p>

<p>An unclassified user can’t access the file <code>O2</code> because they can’t access the secret folder <code>O1</code>.
This would have violated the ss-property — because unclassified users can’t read the
secret data and *-property, where users can’t read secret data and write to non-secret files
at the same time. They called it “The need for compatibility” — a child’s object
security levels should be higher than the parent’s object security levels.</p>

<h3 id="modern-day-descendants-of-bell-la-padula-model">Modern-Day Descendants of Bell-La-Padula Model</h3>

<p>Chances are, you are using discretionary access control implementation of the Bell-La-Padula
model every time you access a file on your system.</p>

<p><strong>Discretionary Access Controls</strong></p>

<p>Unix devs were frustrated with Multics’ complexity. Even Unix itself is a pun on Multics —
“Uniplex information and computing service”,  compared to Multics’  “Multiplex information and computer services”.
They dropped most of the complex stuff and kept only the discretionary part securing access to files with permissions.</p>

<p><img src="https://goteleport.com/blog/images/2021/access/ken-dennis.jpg" width="100%" alt="Ken Thompson and Dennis Ritchie"></p>

<p><em>Ken Thompson and Dennis Ritchie hacking on PDP-11 and probably ranting about Multics complexity</em></p>

<p>DAC defines an owner of a resource, for example a file. A file owner specifies what others
can do to this file. Linux access control list system defines a set of permissions - read <code>(r)</code>, write <code>(w)</code> and execute <code>(x)</code>.
Users are divided into three classes: owners, groups and other. Every Linux file has a list of
access controls defined for every user class. Here is, for example an ACL for a file “animals.pl” on my computer:</p>
<div><pre><code data-lang="bash">$ ls -l animals.pl
-rw-r--r-- <span>1</span> sasha admins <span>187</span> Nov <span>28</span> 15:14 animals.pl</code></pre></div>
<p>This ACL says that user <code>sasha</code> is allowed to read and write …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://goteleport.com/blog/access-controls/">https://goteleport.com/blog/access-controls/</a></em></p>]]>
            </description>
            <link>https://goteleport.com/blog/access-controls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26344870</guid>
            <pubDate>Thu, 04 Mar 2021 16:59:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data Engineering at Wikimedia]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26344518">thread link</a>) | @javisantana
<br/>
March 4, 2021 | https://www.speedwins.tech/posts/some-words-with-nuria-ruiz | <a href="https://web.archive.org/web/*/https://www.speedwins.tech/posts/some-words-with-nuria-ruiz">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h6>What is the company about? What are you building?</h6><p>The data engineering team at Wikimedia maintains what would be a traditional data pipeline for product teams to gather data to aid in product execution. What is different in the open knowledge ecosystem is that much of the metadata about Wikipedia is also public. This means that you can get a <a href="https://dumps.wikimedia.org/">myriad of datasets</a> with <a href="http://stats.wikimedia.org/">pageviews for every article</a>, unique devices, editors per country, etc.<br></p><p>All this data is delivered every hour and has been so for more than 15 years. It is not an overstatement to say that Wikipedia's open datasets have played a <a href="https://commons.m.wikimedia.org/wiki/File:The_role_of_Wikipedia_on_AI_(Wikimania,_2019).pdf">key role in the development of many technologie</a>s we take for granted, like NLP. Maintaining all the pipelines for data delivery for a system that <a href="https://grafana.wikimedia.org/d/000000500/varnish-caching?viewPanel=5&amp;orgId=1&amp;refresh=15m">at peak gets 200,000 requests </a>per second is needless to say, quite a task.&nbsp;&nbsp;</p><p>‍</p><blockquote>It is not an overstatement to say that Wikipedia's open datasets have played a <a href="https://commons.m.wikimedia.org/wiki/File:The_role_of_Wikipedia_on_AI_(Wikimania,_2019).pdf">key role in the development of many technologie</a>s we take for granted, like NLP<br></blockquote><h6>Can you describe the high level data architecture? Wikipedia is pretty open and I know you use Cassandra, Druid, Kafka, how those work together. In other words, what’s the data path from a GET request to a wikipedia page to something you can render on a graph.</h6><p>Something that is not well-known is that the whole puppet repo that describes Wikipedia's is public and you can take a look at it on<a href="https://github.com/wikimedia/puppet"> github</a>. To this day I find this impressive, that every single piece of infra of all Wikipedia's systems is described there. We also provide <a href="https://meta.wikimedia.org/wiki/Wikimedia_servers#/media/File:Wikipedia_webrequest_flow_2020.png">pretty pictures of the stack.</a><br></p><p>The data stack is very standard. As you mentioned we have Kafka for data intake, Hadoop as a persistent storage and from those two data gets ingested into Cassandra or Druid. There are different pipelines with different bells and whistles, some of them have a JSON <a href="https://schema.wikimedia.org/#!/">schema registry</a> and some others parse data out of the HTTP requests directly.&nbsp; In Wikipedia, 97% of requests at all times are cached and thus served from the CDN via Varnish. So, in order to gather all this data, we need Varnish to be able to talk to Kafka, we have a custom piece called varnishkafka that is a source of joy (#not) for our SRE team. The migration to Apache Traffic Service will eventually render this piece of infra obsolete.&nbsp;<br></p><p>There are two distinct sources of data: data from <strong>readers </strong>and <strong>editors</strong>. While data for readers is very high volume is quite "simple". It can be thought as simple pageviews. Edit data is however a lot more complicated and in order to harvest it properly we developed a <a href="https://en.wikipedia.org/wiki/Lambda_architecture">Lambda-ish architecture</a>. We source this data two ways, once a month from the MediaWiki database directly and via Spark, after 2 days of processing in a ~60 nodes hadoop cluster we create large <a href="https://wikitech.wikimedia.org/wiki/Analytics/Data_Lake/Edits">denormalized tables</a>.&nbsp; And at the same time we have event streams of data that publish every edit event to wikipedia as a json blob real time and those also get persisted on hadoop. We made a very conscious decision to use <a href="https://techblog.wikimedia.org/2020/09/10/wikimedias-event-data-platform-or-json-is-ok-too/">JSON versus AVRO</a> in most of our data pipelines and, since then, the Kafka ecosystem has moved more towards being a lot more friendly towards JSON. Makes sense, because JSON is a lot easier to debug.&nbsp;<br></p><p>The visualization layer is Superset, a nifty UI tool that can be used against druid but also <a href="https://prestodb.io/">Presto</a>, a very fast data query engine developed by Facebook that can be deployed on top of hadoop and it is fully ANSI SQL compliant.</p><h6>Wikipedia does not use any cloud provider, how does that change the way architecture is designed?</h6><p>Everything is developed from the ground up so we favor open source solutions tried and tested at scale. Much of the data pipeline of Wikipedia exists thanks to Facebook and LinkedIn open source efforts.</p><p>‍<br></p><h6>Also, you only use open source software, how do you pick the right tool for the job? Are software licenses a limitation? Could you use Mongo or Elastic for example?</h6><p>If we need a piece of software that, for example, pulls data from Kafka we survey the ecosystem and look at what exists that is tried and tested and fully open source. We do couple small prototypes and evaluate results. See for example our recent spike on <a href="https://wikitech.wikimedia.org/wiki/Analytics/Systems/Cluster/Workflow_management_tools_study">Airflow and others</a>.&nbsp; Licenses that do not provide the same level of freedom as <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a> are a problem. We cannot, for example,&nbsp; use the licenses for Kafka Connect which are too restrictive. We <a href="https://diff.wikimedia.org/2014/01/06/wikimedia-moving-to-elasticsearch/">have been using Elastic since 2014</a> but that, with their new license, might need to change.&nbsp;</p><p>‍<br></p><h6>What are some of the hardest data problems you’ve had to solve so far?</h6><p>Something that I have learned in these 20 years of work is that most of the real hard problems have to do with people, rather than technology.</p><p>Now, I would say the hardest problems in the data realm on 2021 have to do with Privacy. At Wikipedia Privacy is paramount (there cannot be truly free access to knowledge without a guarantee of privacy) and we had to "invent" methods to calculate in privacy-conscious ways metrics that are the norm for web properties, like Monthly Active Users. You can see <a href="https://diff.wikimedia.org/2016/03/30/unique-devices-dataset/">how we did it.</a> Still, the hardest problem was probably communicating effectively how much we care about Privacy.</p><p>‍</p><h6>What are the hard ones still unsolved?</h6><p>Data quality issues are kind of a "<a href="https://en.wikipedia.org/wiki/Fractal">fractal</a>" problem, you are never done eliminating those completely. <a href="https://phabricator.wikimedia.org/T211833">Here</a> is an example of a problem with data quality that was invisible to data throughput alarms and here is the first idea we had on how to partially solve issues like these (spoiler: entropy counts). Now, these examples make apparent how other quality issues of more complex nature would slip by.&nbsp;</p><h6>How did the architecture change during your 6 years at wikipedia?</h6><p>I would say it is recently that streaming or event-based architectures&nbsp; have become an achievable reality, little by little we are moving towards a world with more <a href="https://diff.wikimedia.org/2017/03/20/eventstreams/">streaming services.</a>&nbsp;</p><h6>Tell us some interesting numbers (traffic, rows, gigabytes you store, process, infra costs and so on)</h6><p>Wikipedia's <a href="https://wikimediafoundation.org/about/financial-reports/">budget is public</a>, the site and the 400 people on staff plus a number of projects and chapters are run with a budget of about $100 million dollars per year. The whole data stack hardware costs are minimal, less than a million dollars per year for about 3PB of data. We process and aggregate a lot of data but also, according to our privacy policy, a lot of it is discarded.</p><h6>What’s the most interesting use case solved with data. I know you have <a href="https://techblog.wikimedia.org/2021/01/15/censorship-outages-and-internet-shutdowns-monitoring-wikipedias-accessibility-around-the-world/">pretty interesting blog posts</a> about it.</h6><p>My two favorite projects are more data scienc-y than data engineer-y and in both I collaborated with our team of Researchers which are the ones that really came into gauge whether the engineering ideas are mathematically sound.<br></p><p><strong>Bot detection</strong>: It took us a bit but we finally were able to flag a lot of the automated traffic that Wikipedia gets and tag it as such on our data releases and internal reports. Some of this traffic is benign (in the sense of it only using resources). An <a href="https://phabricator.wikimedia.org/T273741">example</a>.&nbsp; Other traffic, however, is not so innocuous. There are many attempts to manipulate Wikipedia's top pageview lists, for example. Most recently someone was trying to add a bunch of obscene terms to the top pageview list of Hungarian Wikipedia.</p><p>While on first instance, this seems like a simple classification problem, getting a labeled dataset to do prediction is actually not that simple. It&nbsp; requires building pseudo-sessions on top of data that has no common identifiers to know that two requests came from the same entity. We ended up using heuristics rather than ML and things worked out pretty well. You can read about the details of it <a href="https://techblog.wikimedia.org/2020/10/05/bot-or-not-identifying-fake-traffic-on-wikipedia/">here</a>.<br></p><p><strong>Censorship Alarms: </strong>We wanted to identify events in which active censorship of Wikipedia sites is ongoing. Wikipedia was blocked in Turkey for years and it is today blocked in Mainland China. Besides these countries like Iran block Wikipedia on and off. Looking at that problem in detail we realized that it had a lot in common with problems with data quality so we used some of the same techniques to alarm when "it seemed" a country had an anomalous traffic pattern. Again, this is less easy than it seems at first sight because you do not want to alarm unnecessarily and uniform traffic drops do not constitute an event. Anomalous traffic drops do. See how we did it <a href="https://techblog.wikimedia.org/2021/01/15/censorship-outages-and-internet-shutdowns-monitoring-wikipedias-accessibility-around-the-world/">here</a>.&nbsp;&nbsp;</p><p>‍<br></p><h6>What are the most interesting, unexpected, or challenging lessons that you have learned? I guess there are plenty of them related to user privacy. How that changes in comparison to a “regular company”, what things you need to be careful when dealing with data.</h6><p>Lessons learned are many: in environments where the work is principle-based rather than profit based defining metrics is not easy.&nbsp; When everyone cares a lot about the larger mission of their work there is going to be a lot of strong discussions, once consensus is reached execution is fast with zero management oversight. Also, principles are very useful when choices are needed so in a way, working on a strong principle based organization makes some choices easy (ex: only use open source, preserve the right to fork) even if those choices imply a lot of work.</p><h6>How was your team organized: people, roles. What was your objective as a team? I guess one of them would be to create internal tools but I know you have some external tools and data.</h6><p>The larger Technology team reports to the CTO, there are several parallel teams: Security, SRE, Data Engineering, Performance... Those teams work independently but coordinate among themselves.&nbsp;The mission of the Data Engineering team is to serve internal customers but also the large external community. I think for a team in an organization as large in impact as Wikimedia is crucial to have a mission statement, otherwise it is easy to get lost in the many (infinite, really) requests for work. Our mission was to "empower and support data informed decision making across the Foundation <strong>and</strong> the Community". We make Wikimedia related data available for querying and <strong>analysis</strong> to both Wikimedia employees and the different Wiki communities and stakeholders."<br>This mission, notice, involves serving a large group of stakeholders, the community of editors that do not …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.speedwins.tech/posts/some-words-with-nuria-ruiz">https://www.speedwins.tech/posts/some-words-with-nuria-ruiz</a></em></p>]]>
            </description>
            <link>https://www.speedwins.tech/posts/some-words-with-nuria-ruiz</link>
            <guid isPermaLink="false">hacker-news-small-sites-26344518</guid>
            <pubDate>Thu, 04 Mar 2021 16:33:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DataOps: Principles to develop data intensive projects]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26343319">thread link</a>) | @javisantana
<br/>
March 4, 2021 | https://blog.tinybird.co/2021/02/27/dataops-principles/ | <a href="https://web.archive.org/web/*/https://blog.tinybird.co/2021/02/27/dataops-principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content"> <div> <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div id="post-content" itemprop="articleBody"> <p>These are 10 of the principles of <a href="https://blog.tinybird.co/2021/02/27/dataops/">DataOps</a> that we make available to data teams.</p> <p>While we always challenge our assumptions, this new paradigm guides the way we are building Tinybird, deeply focused on simplicity, speed and developer experience.</p> <h3 id="1-the-data-project"> 1. The Data Project <a href="#1-the-data-project">¶</a> </h3> <p>This is like your framework (<em>think of MVC for web development</em>). It describes how your data should be stored, processed, and exposed through APIs.</p> <p>You put there your <a href="https://docs.tinybird.co/cli.html#data-projects-title">know-how</a>, abstractions and the focus on the problem you are solving.</p> <h3 id="2-serialization"> 2. Serialization <a href="#2-serialization">¶</a> </h3> <p>All your table schemas, transformations and endpoints need to be serializable. Keep <a href="https://docs.tinybird.co/cli.html#datafile-reference-title">the format</a> simple for humans to read and write. If possible, map every resource to a text file.</p> <h3 id="3-version-control"> 3. Version Control <a href="#3-version-control">¶</a> </h3> <p>This is a consequence of having a data project and a file format. Treat your data project as regular source code, and <a href="https://blog.tinybird.co/2021/01/22/tech-product-design-how-we-integrate-with-git/">push it to a source version control system</a> (e.g. git)</p> <p>From there you get traceability over changes, collaboration, peer reviews, automations and the very same workflow and best practices you are used to as a development team.</p> <h3 id="4-continuous-integration-and-deployment"> 4. Continuous Integration and Deployment <a href="#4-continuous-integration-and-deployment">¶</a> </h3> <p>The key for most of the things developers do is speed. Innovation is iteration and if you are fast you can learn faster and iterate faster.</p> <p>This means making an assumption, running an experiment, learn and repeat, ensuring quality.</p> <p>Your system should allow you to easily create testing environments and use fixtures, so you can build, test and measure your data pipelines and endpoints on every change.</p> <h3 id="5-lead-time"> 5. Lead Time <a href="#5-lead-time">¶</a> </h3> <ul> <li>Deploying to production should be seconds (<em>not minutes or hours</em>)</li> <li>Fixing a bug should be minutes (<em>not hours or days</em>)</li> <li>Developing a new feature should be hours (<em>not days or weeks</em>)</li> </ul> <h3 id="6-data-quality-assurance"> 6. Data Quality Assurance <a href="#6-data-quality-assurance">¶</a> </h3> <p>So you are a data engineer working for a Fortune 500 company, are you confident enough (<em>or even allowed</em>) to make a change in any of your data pipelines and push it to production right away in a matter of minutes?</p> <p>How do you ensure data quality in your data product?</p> <p><strong><a href="https://guides.tinybird.co/guide/implementing-test-strategies">Data needs tests</a>, even more than code.</strong></p> <h3 id="7-tools"> 7. Tools <a href="#7-tools">¶</a> </h3> <p>Pick tools based on your goals, but as a starting point, your tools should make it easy for your team to access, share, and analyze data.</p> <p>You should be able to <a href="https://docs.tinybird.co/cli.html">work from your terminal</a> or IDE without leaving your data project context.</p> <p>Avoid steep learning curves, use a familiar syntax, short and clear so you can run and automate stuff quickly.</p> <p>When it comes to data exploration and problem-solution discovery, you need instant feedback.</p> <h3 id="8-observability"> 8. Observability <a href="#8-observability">¶</a> </h3> <p>You need to run and understand <a href="https://docs.tinybird.co/api-reference/service-datasources.html">your data in production</a> and quickly learn if it’s solving your business problems.</p> <p>Automate <a href="https://guides.tinybird.co/guide/on-the-fly-health-checks">health checks</a>, monitor performance, allow runtime traceability and implement an alerting system.</p> <h3 id="9-recipes-and-building-blocks"> 9. Recipes and building blocks <a href="#9-recipes-and-building-blocks">¶</a> </h3> <p>The data development experience should be as close as the experience you actually have working with some library that you will import and use in any language.</p> <p>Your analysis should be idempotent, composable and immutable. Wrap them and make them reusable right away.</p> <p>Wrap your analyses into <a href="https://github.com/tinybirdco/log_parsing_template">reusable data projects</a>.</p> <h3 id="10-fine-tuning"> 10. Fine Tuning <a href="#10-fine-tuning">¶</a> </h3> <p>Query optimization is a never ending process. You should monitor queries and transformations to build a system that helps <a href="https://blog.tinybird.co/2020/12/15/eating-our-own-dog-food-how-we-investigate-performance-bottlenecks-using-our-product-and-google-sheets/">fine tuning your data products</a>.</p> <h3 id="bonus-track-publication-and-documentation"> Bonus track: publication and documentation <a href="#bonus-track-publication-and-documentation">¶</a> </h3> <p><strong>Data and development teams work together</strong>. Your data are exposed as <a href="https://blog.tinybird.co/2020/08/11/badass-api-endpoint/">auto-documented APIs</a>, so it can be integrated anywhere.</p> <p>Don’t forget about not so cool tools such as <a href="https://blog.tinybird.co/2020/12/15/eating-our-own-dog-food-how-we-investigate-performance-bottlenecks-using-our-product-and-google-sheets/#visualizing-the-correlation-matrix-in-google-sheets">spreadsheets</a> and traditional BI.</p> <p><strong><em>What are your main challenges when dealing with large quantities of data?</em></strong> <a href="https://www.tinybird.co/survey">Tell us about them</a> and get started solving them with Tinybird right away.</p> </div>  </article>  </div> </div></div>]]>
            </description>
            <link>https://blog.tinybird.co/2021/02/27/dataops-principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26343319</guid>
            <pubDate>Thu, 04 Mar 2021 15:08:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft, Google and OWASP walk into a bar]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26342568">thread link</a>) | @Hacman123
<br/>
March 4, 2021 | http://www.fuzzcon.eu/web-security | <a href="https://web.archive.org/web/*/http://www.fuzzcon.eu/web-security">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="cell" data-x="0" data-w="12">

<div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<p><span id="hs_cos_wrapper_module_1591198618882700_" data-hs-cos-general-type="widget" data-hs-cos-type="rich_text"><h2><span><strong>What Is Fuzzing?</strong></span></h2>
<p>In recent years, feedback-based fuzzing (or coverage-guided fuzzing) has experienced an unmatched success story. For example, over 27,000 bugs have been found in Chrome and several open-source projects and Google stated that it finds around 80% of its bugs with modern fuzzing techniques. However, fuzzing is not only reserved for big tech companies: It is gradually finding its way into the wide world.</p>
<p><span>Fuzzing is used for security and stability testing of the codebase. The application under test is fed with a series of inputs, which are smartly mutated in the testing process. The testing tool gets feedback about the code covered during the execution of inputs. Unlike traditional or black-box fuzzing, feedback-based fuzzing explores the program state efficiently and discovers bugs hidden deep in the code. If you want to learn more in detail about the underlying technology, we recommend you to read our blog post <a href="https://blog.code-intelligence.com/the-magic-behind-feedback-based-fuzzing?hsLang=en"><span>The Magic Behind Feedback-based Fuzzing.</span></a>&nbsp;</span></p></span></p>

</div><!--end widget-span -->
</div><!--end row-->
</div><!--end row-wrapper -->

</div><!--end widget-span -->
</div><!--end row-->
</div></div>]]>
            </description>
            <link>http://www.fuzzcon.eu/web-security</link>
            <guid isPermaLink="false">hacker-news-small-sites-26342568</guid>
            <pubDate>Thu, 04 Mar 2021 14:05:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI-powered, privacy-preserving ads at IMGZ]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26342232">thread link</a>) | @StavrosK
<br/>
March 4, 2021 | https://imgz.org/blog/2021/03/04/yeah-right/ | <a href="https://web.archive.org/web/*/https://imgz.org/blog/2021/03/04/yeah-right/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
Posted on
<time itemprop="datePublished" datetime="2021-03-04">March 04, 2021</time>.
</p><div itemprop="articleBody"><p>After a <a href="https://imgz.org/blog/2020/12/23/haha-suckers/">massively successful hiring campaign</a>, which was propagated far and wide in social media, we had our pick of the litter (or, in US English, "trash") for our Chief of Artificial Intelligence Science Officer position.
After filtering candidates based on relevant traits such as age, marital status and naivety, we finally settled on our new CAISO!</p>
<p>He came in with some fresh new ideas, most of which were rejected outright, and we quickly got him working on the next big thing.
IMGZ has been <a href="https://imgz.org/blog/2020/12/23/haha-suckers/">growing exponentially</a>, and, despite all the problems that come with growth, our focus is LASER-focused on one thing:
Money.
We want to make lots and lots of money, as much as possible, as fast as possible.
Our motto is "At IMGZ, images come first, after money".</p>
<p>Given this imperative, we got our finger on the pulse of the webiverse, and realized that, if we were going to make money, we couldn't rely on people paying us money for services.
That's just not the way the web operates.
We needed to take a page from the book of Facebook, Google, Amazon and AltaVista and innovate, so we sat down with our new CAISO and thought long and hard about how AI could aid us in our monetization strategy, and finally came up with a radical new monetization model:</p>
<p>Ads.</p>
<h2>Ads</h2>
<p>Ads on the internet are not new.
They've been around for at least two years, and people are getting tired of them already.
They aren't so much getting tired of <em>seeing</em> ads, which are always relevant and nigh-magical in their pinpointing of the exact thing you're wanting to buy at any given time, but they're getting tired of the sacrifices needed to achieve this accuracy.</p>
<p>They're getting tired of the constant invasion of privacy by internet giants, who impinge on people's rights to sell them exactly the right thing at exactly the right time.</p>
<p>At IMGZ, we believe that AI can help.
Help the users preserve their privacy, help the advertisers present their products in a respectful manner, but, most importantly, help us make lots of money.</p>
<p>We present to you:</p>
<p>Privacy-preserving ads.</p>
<h2>Privacy-preserving ads</h2>
<p>Privacy-preserving ads is a brand-new technology, from the innovative free-thinkers of IMGZ.
We dared to ask the question "how can we monetize the free trial?".
The obvious answer was "ads".</p>
<p>However, tracking the user and placing some relevant ads next to the images as they viewed them was too invasive, and protecting our users' privacy is the third most important priority for us.</p>
<p>We thought long and hard, and, leveraging our latest hire, we quickly came up with a design for an ML-powered pipeline:</p>
<ul>
<li>The uploading frontend ingests images and sends them to a Kafka queue.</li>
<li>If the image belongs to a user on the free trial, Kafka forwards the images to a distributed worker pool for deep learning processing with a custom Keras model.</li>
<li>The Keras model performs saliency detection to find the most important parts of the image.</li>
<li>Once the most important parts of the image are identified, we send the image back to Kafka for forwarding to the next step in the pipeline, categorization.</li>
<li>A second Keras model performs label extraction on the image, to find a few categories that the image belongs to (such as "woman, dress, smiling").</li>
<li>The next step processes the image, selecting the best ad for the category and stitching it into the salient parts of the image.</li>
<li>The image is stored and forwarded to the CDN for serving.</li>
</ul>
<p>After lots of back and forth, we finalized this plan and realized we couldn't be bothered to do any of this and just wrote three lines of OpenCV to detect faces and slap our logo on them:</p>
<p><a href="https://imgz.org/i7GXsVuM/"><img src="https://imgz.org/i7GXsVuM-1280.jpg" alt=""></a></p>
<p>You will notice that you can't tell who this guy is, perfectly preserving his privacy.
In fact, we're sure you didn't even notice this is actually <em>a girl</em>.</p>
<p><strong>That</strong> is the power of AI.</p>
<h2>The power of AI</h2>
<p>With the help of our engineers, we managed to take this solution from an average of 68 seconds per image to near <em>real-time</em>.
As the free-trial user uploads an image, detection and advertization runs in a few milliseconds, ruining the image nearly instantly and resulting in happy advertisers and users who retained their privacy.</p>
<p>For example, try to recognize even one person in this photo, where the photographer did not obtain model releases:</p>
<p><a href="https://imgz.org/i3yjnGcF/"><img src="https://imgz.org/i3yjnGcF-1280.jpg" alt=""></a></p>
<p>You'll find that you can't!
You may, however, get an inexplicable urge to sign up for IMGZ, which is exactly the intended effect of the subtle advertising.</p>
<p>Of course, while trial users enjoy the full suite of privacy-preserving tools IMGZ has to offer, paid users will be subject to no such annoyance.
Their images will be uploaded and served entirely unchanged, as a thank-you from us to their money.</p>
<h2>Epilogue</h2>
<p>Of course, none of this would be possible without the help of one man:</p>
<p><a href="https://imgz.org/ipFmfjaJ/"><img src="https://imgz.org/ipFmfjaJ-1280.jpg" alt=""></a></p>
<p>He's still on the trial account, as he hasn't paid for an IMGZ account yet, but he'll have to when his trial expires.</p>
<p>We hope that this short article has given you some insight in the pioneering research that goes on at IMGZ in the fields of both privacy and monetization, and maybe you'll implement some of these ideas in your own companies, for only a modest fee to us.</p>
<p>Enjoy, and don't forget, <a href="https://imgz.org/#login">the signup link is here</a>.</p>
</div></div>]]>
            </description>
            <link>https://imgz.org/blog/2021/03/04/yeah-right/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26342232</guid>
            <pubDate>Thu, 04 Mar 2021 13:41:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commercial Only LTS Qt 5.15.3 Released]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26342231">thread link</a>) | @turrini
<br/>
March 4, 2021 | https://www.qt.io/blog/commercial-lts-qt-5.15.3-released | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/commercial-lts-qt-5.15.3-released">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>We <a href="https://www.qt.io/blog/qt-offering-changes-2020" rel="noopener" target="_blank">announced</a> a bit over one year ago that the long-term supported releases of Qt 5.15 will be available only for commercial license holders. Today we have released Qt 5.15.3 LTS, the first commercial only patch release to Qt 5.15 LTS series. As a patch release, Qt 5.15.3 does not add any new functionality but provides bug fixes and other improvements.</p>
<!--more-->
<p>Compared to Qt 5.15.2, the new Qt 5.15.3 contains close to 250 bug fixes. All the applicable bug fixes are also part of the upcoming <a href="https://wiki.qt.io/Qt_6.1_Release" rel="noopener" target="_blank">Qt 6.1</a> release targeted to be released in April.</p>
<p>We have adjusted the process of change files and instead of separate changelog for each module you can check the overview of all important changes and bug fixes in the Qt 5.15.3 from <a href="https://account.qt.io/" rel="noopener" target="_blank">the release note found in the Qt Account portal</a>.</p>
<p>Qt 5.15.3 is automatically visible for all commercial license holders in the online installer (maintenance tool). The source packages of Qt 5.15.3 are available via the online installer as well as the Qt Account. The offline packages for Qt 5.15.3 are available from the Qt Account portal.</p>
<p>If you want to access the source code repository, it can be done via the <a href="https://codereview.qt-project.org/" rel="noopener" target="_blank">Codereview</a>&nbsp;system. Just log in with a Qt Account that has a valid commercial license, and you will be able to access the LTS repositories. For more details, please check <a href="https://wiki.qt.io/Qt_5.15_Release#Getting_Source_Codes" rel="noopener" target="_blank">the instructions for accessing the commercial LTS repositories</a>.</p>
<p>Qt for Device Creation images are also available for Qt 5.15.3 LTS. If you want to build yourself with yocto, use the meta-qt5 layer from the Qt repository. We have updated the yocto meta-qt5 layer of Qt 5.15.3 to point to the commercial LTS repositories. For more details, please check <a href="https://doc.qt.io/QtForDeviceCreation-5.15/qtee-meta-qt5.html" rel="noopener" target="_blank">the instructions on using yocto with access to the commercial LTS repositories</a>.</p>
<p>If you have any problems with the commercial LTS releases, please contact Qt Support. You can also create bugs to <a href="https://bugreports.qt.io/" rel="noopener" target="_blank">https://bugreports.qt.io</a>, but in addition it is recommended to notify the support team about it.</p>
<p>Next commercial-only LTS patch release, Qt 5.15.4 is planned to be released at the end of April.</p></span></p></div>]]>
            </description>
            <link>https://www.qt.io/blog/commercial-lts-qt-5.15.3-released</link>
            <guid isPermaLink="false">hacker-news-small-sites-26342231</guid>
            <pubDate>Thu, 04 Mar 2021 13:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tips for Shipping Data Products Fast]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26341032">thread link</a>) | @oedmarap
<br/>
March 4, 2021 | https://shopify.engineering/shipping-data-products-fast | <a href="https://web.archive.org/web/*/https://shopify.engineering/shipping-data-products-fast">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Shipping a new product is hard. Doing so under tight time constraints is even harder. It’s no different for data-centric products. Whether it’s a forecast, a classification tool, or a dashboard, you may find yourself in a situation where you need to ship a new data product in a seemingly impossible timeline.&nbsp;</p>
<p>Shopify’s Data Science team has certainly found itself in this situation more than a few times over the years. Our team focuses on creating data products that support our merchants’ entrepreneurial journeys, from their initial interaction with Shopify, to their first sale, and throughout their growth journey on the platform. Commerce is a fast changing industry, which means we have to build and ship fast to ensure we’re providing our merchants with the best tools to help them succeed.</p>
<p>Along the way, our team learned a few key lessons for shipping data products quickly, while maintaining focus and getting things done efficiently—<em>but also done right.</em> Below are four tips that are proven to help you ship new products fast.&nbsp;</p>

<p>Investing time in a design sprint pays off down the line as you approach deadlines. The design sprint (created by <a href="https://www.gv.com/sprint/" target="_blank" title="Google Ventures" rel="nofollow noopener noreferrer">Google Ventures</a>) is “a process for answering critical business questions through design, prototyping and testing ideas with customers.” Sprints are great for getting a new data product off the ground quickly because they carve out specific time blocks and resources for you and your team to work on a problem. The Shopify Data Science teams make sprints a common practice, especially when we’re under a tight deadline. When setting up new sprints, here are the steps we like to take:</p>
<ol>
<li>
<strong><em>Choose an impactful problem to tackle. </em></strong>We focus on solving problems for our merchants, but in order to do that, we first have to uncover what those problems are by asking questions. <em>What</em> is the problem we’re trying to solve? <em>Why </em>are we solving this problem? Asking questions empowers you to find a problem worth tackling, identify the right technical solution and ultimately drive impact.</li>
<li>
<strong><em>Assemble a small sprint team</em></strong>: Critical to the success of any sprint is assembling a small team (no more than 6 or 7) of highly motivated individuals. Why a small team? It’s easier to stay aligned in a smaller group due to better communication and transparency, which means it’s easier to move fast.</li>
<li>
<strong><em>Choose a sprint Champion:</em></strong> This individual should be responsible for driving the direction of the project and making decisions when needed (should we use solution A or B?). Assigning a Champion helps remove ambiguity and allow the rest of the team to focus their energy on solving the problem in front of them.</li>
<li>
<strong><em>Set your sprint dates:</em></strong> Timeboxing is one of the main reasons why sprints are so effective. By setting fixed dates, you're committing your team to focus on shipping on a precise timeline. Typically, a sprint lasts up to five days. However, the timeline can be shortened based on the size of the project (for example, three days is likely enough time for creating the first version of a dashboard that follows the impact of COVID-19 on the business’s acquisition funnel).</li>
</ol>
<p>With your problem identified, your team set up, and your dates blocked off, it’s now time to sprint. Keep in mind while exploring solutions that solving a data-centric problem with a non-data focused approach can sometimes be simple and time efficient. For instance, asking a user for its preferred location rather than inferring it using a complex heuristic.</p>

<p>Speed is critical! The first iterations of a brand new product often go through many changes. Prototypes allow for quick and cheap learning cycles. They also help prevent the sunk cost fallacy (when a past investment becomes a rationale for continuing).&nbsp;</p>
<p>In the data world, a good rule of thumb is to leverage spreadsheets for building a prototype. Spreadsheets are a versatile tool that help accelerate build times, yet are often underutilized by data scientists and engineers. By design, spreadsheets allow the user to make sense of data in messy contexts, with just a few clicks. The built-in functions cover most basic use cases:&nbsp;</p>
<ul>
<li>cleaning data by hand rapidly</li>
<li>displaying graphs</li>
<li>computing basic ranking indices</li>
<li>formatting output data.</li>
</ul>
<p>While creating a robust system is desirable, it often comes at the expense of longer building times. When releasing a brand new data product under a tight timeline, the focus should be on developing prototypes fast.&nbsp;</p>
<figure><img alt="A sample Google Sheet dashboard evaluating Inbound Leads.  The dashboard consists of 6 charts.  The 3 line charts on the left measure Lead Count, Qualification Rate %, and Time to Qualification in Minutes.  The 3 bar charts on the right  measure Leads by Channel, Leads by Country, and Leads by Last Source Touched." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/google-sheets-dashboard-prototype_8e7a900e-b66d-4618-a4d0-fdb26359a44b.jpg?v=1614705455" src="https://cdn.shopify.com/s/files/1/0779/4361/files/google-sheets-dashboard-prototype_8e7a900e-b66d-4618-a4d0-fdb26359a44b.jpg?v=1614705455">
<figcaption>An example of a dashboard prototype created within Google Sheets.</figcaption>
</figure>
<p>Despite a strong emphasis on speed, a prototype should still look and feel professional. For example, the first iteration of the <a href="https://www.shopify.my/blog/marketing-attribution" target="_blank" title="Marketing Attribution: Seeing the Customer Journey More Clearly" rel="noopener noreferrer">Marketing attribution tool</a> developed for Shopify’s Revenue team was a collection of SQL queries automated by a bash script. The output was then formatted in a spreadsheet. This allowed us to quickly make changes to the prototype and compare it to out-of-the-box tools. We avoided any wasted effort spinning up dashboards, production code, as well as any sentimental attachment to the work, which made it easier for the best solution to win.</p>

<p>When building a new data product, it’s tempting to spend lots of time on a flashy machine learning algorithm. This is especially true if the product is supposed to be “smart”. Building a machine learning model for your first iteration can cost a lot of time. For example, when sprinting to build a lead scoring system for our Sales Representatives, our team spent 80% of the sprint gathering features and training a model. This left little time to integrate the product with the existing <a href="https://en.wikipedia.org/wiki/Customer_relationship_management" target="_blank" title="Customer Relationship Management on Wikipedia" rel="nofollow noopener noreferrer">customer relationship management</a> (CRM) infrastructure, polish it, and ask for feedback. A simple ranking using a proxy metric would be much faster to implement for the first iteration. The time gained would allow for more conversations with the users about the impact, use and engagement with the tool.&nbsp;</p>
<p>We took that lesson to heart in our next project when we built a sales forecasting tool. We started with a linear regression using only two input variables that allowed us to have a prototype ready in a couple of hours. Using a simple model allowed us to ship fast and quickly learn whether it solved our user’s problem. Knowing we were on the right track, we then built a more complex model using machine learning.</p>
<p>Focus on building models that solve problems and can be shipped quickly. Once you’ve proven that your product is effective and delivers impact, then you can focus your time and resources on building more complex models.&nbsp;</p>

<p>Shipping fast also means shipping the right product. In order to stay on track, gathering feedback from users is invaluable! It allows you to build the right solution for the problem you’re tackling. Take the time to talk to your users, before, during, and after each build iteration. Shadowing them, or even doing the task yourself is a great return on investment.</p>
<p>Gathering feedback is an art. Entire books and research papers are dedicated to it. Here are the two tips we use at Shopify that increased the value of feedback we’ve received:</p>
<ul>
<li>
<em>Ask specific questions.</em> Asking, “Do you have any feedback?” doesn’t help the user direct their thoughts. Questions like, “How do you feel about the speed at which the dashboard loads?” or “Are you able to locate the insights you need on this dashboard to report on top of funnel performance?” are more targeted and will yield richer feedback.</li>
</ul>
<ul>
<li>
<em>Select a diverse group of users for feedback</em>. Let’s suppose that you are building a dashboard that’s going to be used by three regional teams. It’s more effective to send a request for feedback to one person in each team rather than five people in a single team.</li>
</ul>
<figure><img alt="A sample Google Form that measures Prototype A's Scoring.  The form consists of 2 questions. The first question is &quot;Is the score easy to parse and interpret? It is scored using a ranking from 1 - 5 with 1 = Very Hard and 5 = Very Easy. The 2nd question is &quot;Additional Comments&quot; and has a text field for the answer." data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/sample-google-form.jpg?v=1614705664" src="https://cdn.shopify.com/s/files/1/0779/4361/files/sample-google-form.jpg?v=1614705664">
<figcaption>Feedback our team asked for the scoring system we created. When asking for feedback, you want to ask specific questions so you can yield better feedback.</figcaption>
</figure>
<p>We implemented the two tips when requesting feedback from users of the sales forecasting tool highlighted in the previous section. We asked a diverse group specific questions about our product, and learned that displaying a numerical score (0 - 100) was confusing. The difference between scores wasn’t clear to the users. Instead, it was suggested to display grades (A, B, C) which turned out to be much quicker to interpret and led to a better user experience.</p>
<p>At Shopify, following these tips has provided the team with a clearer path for launching brand new data products under tight time constraints. More importantly, it helped us avoid common pitfalls like getting stuck during neverending design phases, overengineering complex machine learning systems, or building data products that users don’t use.&nbsp;</p>
<p>Next time you’re under a tight timeline to ship a new data product, remember to:</p>
<ol>
<li>
<strong><em>Utilize design sprints</em></strong> to help focus your team’s efforts and remove the stress of the ticking clock</li>
<li>
<strong><em>Don’t skip on prototyping,</em></strong> it’s a great way to fail early</li>
<li>
<strong><em>Avoid machine learning</em></strong> (for first iterations) to avoid being slowed down by unnecessary complexity</li>
<li>
<strong><em>Talk to your users</em></strong> so you can get a better sense of what problem they’re facing and what they need in a product</li>
</ol>
<p>If you’d like to read more about shipping new products fast, we recommend checking out <a href="https://www.thesprintbook.com/" target="_blank" title="Sprint (How to Solve Big Problems and Test New Ideas in Just Five Days)" rel="nofollow noopener noreferrer">The Design Sprint</a> book, by Jake Knapp et al. which provides a complete framework for testing new ideas.</p>
<hr>
<p>If you’re interested in helping us ship great data products, quickly, we’re looking for talented data scientists to <a href="https://www.shopify.com/careers/teams/data?itcat=EngBlog&amp;itterm=Post&amp;shpxid=73b80879-3076-43E8-7604-FE14CE1EBEED" target="_blank">join our team</a>.</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/shipping-data-products-fast</link>
            <guid isPermaLink="false">hacker-news-small-sites-26341032</guid>
            <pubDate>Thu, 04 Mar 2021 11:13:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Went Passwordless]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26340357">thread link</a>) | @varlogix
<br/>
March 4, 2021 | https://spike.sh/blog/why-we-went-passwordless/ | <a href="https://web.archive.org/web/*/https://spike.sh/blog/why-we-went-passwordless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        


<main id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://spike.sh/blog/content/images/2021/03/Blog-image.png 300w,
                            https://spike.sh/blog/content/images/2021/03/Blog-image.png 600w,
                            https://spike.sh/blog/content/images/2021/03/Blog-image.png 1000w,
                            https://spike.sh/blog/content/images/2021/03/Blog-image.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://spike.sh/blog/content/images/2021/03/Blog-image.png" alt="Why we went passwordless on our new product">
            </figure>

            <section>
                <div>
                    <p>Passwords are dying. The cost of creating and maintaining passwords is becoming untenable. Which can be seen in the rise of users logging in with social products and developers outsourcing their pain to Auth0 and the likes. We decided to sidestep the password based authentication and went passwordless on our new product. Read on to see how you can go passwordless too.</p><p><strong>The cost of passwords</strong></p><p>Passwords create too much friction for users. It’s becoming difficult to come up with passwords that satisfy the ever growing password strength requirements - minimum 9 characters, 1 number, 1 upper case, 1 special character etc. And with the rise of data breaches where hackers steal and sell password data on the internet, passwords are only really effective when you don’t repeat them across different services. Which means you have to remember unique passwords or use a password manager.</p><p>Passwords are even more painful for developers to build and maintain. Imagine the work - 4 forms (signup, login, reset password, send forgot password link), storing passwords securely, managing email service providers for deliverability and spam scores. All this work just for the auth, which is not your core product and not what users come to you for. </p><p><strong>Magic links, the solution to the password problem</strong></p><p>An elegant solution to this mess is authenticating users using magic links sent on email. We all use email anyway as a core part of our online identity and authentication. So instead of logging in with email and password, you enter your email and get a login link sent to you. You might have seen Slack do this.</p><figure><img src="https://lh3.googleusercontent.com/2Yx1vwl0CygQi3k1aT9iKXiAETGQmsfaNuE2uA4-KsTWrGKN-WjwAGQv_XwPOpv3zainHdNZ29jbxiJYBIbVo-iKPAE9BMHIkVlKZQgVFzJK0dxaoaoJmQ6a-k5UuKDmNecYiqZY"><figcaption>Slack popularised magic links for logging in</figcaption></figure><p><strong>How we went passwordless with magic link</strong></p><p>When we were building our new product, we didn’t want to spend time building full blown password auth, so we decided on using magic links. And although the work involved building a magic link system is less than traditional auth, it is still valuable developer time spent on non-core plumbing. After some research, we found <a href="https://magic.link/">Magic</a> which provides magic links as a service. We loved the focus on security (the founders have built a security product in the past), the good design and the developer friendly docs. </p><p>The implementation involves a client SDK (for web and mobile) for showing the Magic overlay (screenshots below) and server code for managing sessions. We used the sample code provided to implement this. </p><p><strong>The user experience of magic links</strong></p><p>Login form</p><figure><img src="https://lh6.googleusercontent.com/87Sh7Be5B83QExzyE2bF12OGsrTom6Lpw-haLYteMvUUaoFyZbe9FLozGgE1bcMgB7x0NyTThb0fj-uqwanGADb3OpA9x5srYvNqVGlKSvPoy9XvYR4xjDwEcKNKInFDNC8JUAqD"><figcaption>Sign up and Log in form</figcaption></figure><p>Email</p><figure><img src="https://lh5.googleusercontent.com/EtAzDiIBqb7SpaSTW6W3qRB5J7E7uq-ThWLXWPczkdIKIXXbhRK74OlQkFMrcTIkWXI5YJC7blPMl5qblW4wF5mM_JpFOicTIXy_rr0R9Ijn0dsSJv4O-a0xfFBJRs38F0MYlxfk"><figcaption>Magic link email</figcaption></figure><p>You can <a href="https://incidents.sh/">try out the experience for yourself</a> on our new product. It’s a free timer for developers to keep track of major software incidents, built by the team who also built the simple <a href="https://spike.sh/">incident alerting</a> product for developers.</p><p><strong>Conclusion</strong></p><p>After using magic links as a developer and as a user, I loved the experience. There are still some hiccups as with any new technology, but overall this looks like the future. And I am quite excited to watch it unfold!</p>
                </div>
            </section>



        </article>

    </div>
</main>



</div></div>]]>
            </description>
            <link>https://spike.sh/blog/why-we-went-passwordless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26340357</guid>
            <pubDate>Thu, 04 Mar 2021 09:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t blindly prefer emplace_back to push_back]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 140 (<a href="https://news.ycombinator.com/item?id=26339893">thread link</a>) | @todsacerdoti
<br/>
March 4, 2021 | https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/ | <a href="https://web.archive.org/web/*/https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In one of my recent training courses, a student informed me that both clang-tidy
and PVS-Studio were complaining about some code of the form</p>

<div><div><pre><code>std::vector&lt;Widget&gt; widgets;
~~~
widgets.push_back(Widget(foo, bar, baz));
</code></pre></div></div>

<p>Both tools flagged this line as “bad style.”
clang-tidy even offered a (SARCASM ALERT) helpful fixit:</p>

<div><div><pre><code>warning: use emplace_back instead of push_back [modernize-use-emplace]
    widgets.push_back(Widget(foo, bar, baz));
            ^~~~~~~~~~~~~~~~~             ~
            emplace_back(
</code></pre></div></div>

<p>The student dutifully changed the line, and both tools reported their
satisfaction with the replacement:</p>

<div><div><pre><code>widgets.emplace_back(Widget(foo, bar, baz));
</code></pre></div></div>

<p>The original line materializes a temporary <code>Widget</code> object on the stack;
takes an rvalue reference to it; and passes that reference to
<code>vector&lt;Widget&gt;::push_back(Widget&amp;&amp;)</code>, which move-constructs a <code>Widget</code>
into the vector. Then we destroy the temporary.</p>

<p>The student’s replacement materializes a temporary <code>Widget</code> object on the stack;
takes an rvalue reference to it; and passes that reference to
<code>vector&lt;Widget&gt;::emplace_back&lt;Widget&gt;(Widget&amp;&amp;)</code>, which move-constructs
a <code>Widget</code> into the vector. Then we destroy the temporary.</p>

<p><em>Absolutely no difference.</em></p>

<p>The change clang-tidy meant to suggest — and in fact <em>did</em> suggest,
if you pay very close attention to the underlining in the fixit — was actually this:</p>

<div><div><pre><code>widgets.emplace_back(foo, bar, baz);
</code></pre></div></div>

<p>This version does <em>not</em> materialize any <code>Widget</code> temporaries. It simply
passes <code>foo, bar, baz</code> to <code>vector&lt;Widget&gt;::emplace_back&lt;Foo&amp;, Bar&amp;, Baz&amp;&gt;(Foo&amp;, Bar&amp;, Baz&amp;)</code>,
which constructs a <code>Widget</code> into the vector using whatever
constructor of <code>Widget</code> best matches that bunch of arguments.</p>

<h2 id="emplace_back-is-not-magic-c11-pixie-dust"><code>emplace_back</code> is not magic C++11 pixie dust</h2>

<p>Even a decade after C++11 was released, I still sometimes see programmers assume
that <code>emplace_back</code> is somehow related to move semantics. (In the same way that
some programmers assume lambdas are somehow the same thing as <code>std::function</code>,
you know?) For example, they’ll rightly observe that this code makes an
unnecessary copy:</p>

<div><div><pre><code>void example() {
    auto w = Widget(1,2,3);
    widgets.push_back(w);  // Copy-constructor alert!
}
</code></pre></div></div>

<p>So they’ll change it to this:</p>

<div><div><pre><code>void example() {
    auto w = Widget(1,2,3);
    widgets.emplace_back(w);  // Fixed? Nope!
}
</code></pre></div></div>

<p>The original line constructs a <code>Widget</code> object into <code>w</code>, then
passes <code>w</code> by reference to <code>vector&lt;Widget&gt;::push_back(const Widget&amp;)</code>,
which copy-constructs a <code>Widget</code> into the vector.</p>

<p>The replacement constructs a <code>Widget</code> object into <code>w</code>, then
passes <code>w</code> by reference to <code>vector&lt;Widget&gt;::emplace_back&lt;Widget&amp;&gt;(Widget&amp;)</code>,
which copy-constructs a <code>Widget</code> into the vector.</p>

<p><em>Absolutely no difference.</em></p>

<p>What the student should have done is ask the compiler to make an
<em>rvalue</em> reference to <code>w</code>, by saying either</p>

<div><div><pre><code>widgets.push_back(std::move(w));
</code></pre></div></div>

<p>or</p>

<div><div><pre><code>widgets.emplace_back(std::move(w));
</code></pre></div></div>

<p>It doesn’t matter which verb you use; what matters is the value category of
<code>w</code>. You must explicitly mention <code>std::move</code>, so that the language (and the
human reader) understand that you’re done using <code>w</code> and it’s okay for
<code>widgets</code> to pilfer its guts.</p>

<p><code>emplace_back</code> was added to the language at the same time as <code>std::move</code> — just
like lambdas were added at the same time as <code>std::function</code> — but that doesn’t
make them the same thing. <code>emplace_back</code> may “look more C++11-ish,” but it’s
not magic move-enabling pixie dust and it will never insert a move in a place
you don’t explicitly request one.</p>

<h2 id="when-all-else-is-equal-prefer-push_back-to-emplace_back">When all else is equal, prefer <code>push_back</code> to <code>emplace_back</code></h2>

<p>So, given that these two lines do the same thing and are equally efficient
at runtime, which should I prefer, stylistically?</p>

<div><div><pre><code>widgets.push_back(std::move(w));
widgets.emplace_back(std::move(w));
</code></pre></div></div>

<p>I recommend sticking with <code>push_back</code> for day-to-day use. You should definitely
use <code>emplace_back</code> when you need its particular set of skills — for example, <code>emplace_back</code>
is your only option when dealing with a <code>deque&lt;mutex&gt;</code> or other non-movable type —
but <code>push_back</code> is the appropriate default.</p>

<p>One reason is that <code>emplace_back</code> is more work for the compiler.
<code>push_back</code> is an overload set of two non-template member functions.
<code>emplace_back</code> is a single variadic template.</p>

<div><div><pre><code>void push_back(const Widget&amp;);
void push_back(Widget&amp;&amp;);

template&lt;class... Ts&gt;
reference emplace_back(Ts&amp;&amp;...);
</code></pre></div></div>

<p>When you call <code>push_back</code>, the compiler must do overload resolution, but that’s all.
When you call <code>emplace_back</code>, the compiler must do template type deduction, followed
by (easy-peasy) overload resolution, followed by function template instantiation and
code generation. That’s a much larger amount of work for the compiler.</p>

<h2 id="the-benchmark-program">The benchmark program</h2>

<p>I wrote a simple test program to demonstrate the difference in compiler workload.
Of course <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a> applies:
my benchmark displays a massive difference because it’s doing <em>nothing but</em>
instantiating <code>emplace_back</code>, whereas any production codebase will be doing vastly
more other stuff relative to the number of times it instantiates <code>emplace_back</code>.
Still, I hope this benchmark gives you a sense of why I recommend “<code>push_back</code> over
<code>emplace_back</code>” and not vice versa.</p>

<p>This Python 3 script generates the benchmark:</p>

<div><div><pre><code>import sys
print('#include &lt;vector&gt;')
print('#include &lt;string&gt;')
print('extern std::vector&lt;std::string&gt; v;')
for i in range(1000):
    print('void test%d() {' % i)
    print('    v.%s_back("%s");' % (sys.argv[1], 'A' * i))
    print('}')
</code></pre></div></div>

<p>Generate like this:</p>

<div><div><pre><code>python generate.py push &gt;push.cpp
python generate.py emplace &gt;emplace.cpp
time g++ -c push.cpp
time g++ -c emplace.cpp
</code></pre></div></div>

<p>With Clang trunk on my laptop, I get consistently about 1.0s for the <code>push</code> version,
and 4.2s for the <code>emplace</code> version. This big difference is due to the fact that the
<code>push</code> version is merely code-generating a thousand <code>test</code> functions, whereas
the <code>emplace</code> version is code-generating that same thousand <code>test</code> functions <em>and</em>
another thousand template instantiations of <code>emplace_back</code> with different parameter
types:</p>

<div><div><pre><code>vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[1]&gt;(const char (&amp;)[1])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[2]&gt;(const char (&amp;)[2])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[3]&gt;(const char (&amp;)[3])
vector&lt;string&gt;::emplace_back&lt;const char(&amp;)[4]&gt;(const char (&amp;)[4])
~~~
</code></pre></div></div>

<p>See, <code>push_back</code> knows that it expects a <code>string&amp;&amp;</code>, and so it knows to call the
non-explicit constructor <code>string(const char *)</code> on the caller’s side. The same
constructor is called in each case, and the temporary <code>string</code> is passed to
the same overload of <code>push_back</code> in each case. <code>emplace_back</code>, on the other hand,
is a dumb perfect-forwarding template: it doesn’t know that the relevant constructor
overload will end up being <code>string(const char *)</code> in each case. So it takes
an lvalue reference to the specific <em>array type</em> being passed by the caller.
Perfect-forwarding has no special cases for <code>const char *</code>!</p>

<p>If we change <code>vector&lt;string&gt;</code> to <code>vector&lt;const char *&gt;</code>, the compile-time-performance
gap widens: now it’s 0.7s for <code>push</code>, 3.8s for <code>emplace</code>. This is because we’ve cut
out some of the work that was common to both versions (constructing <code>std::string</code> objects)
without affecting the source of the gap (that one version instantiates a
thousand copies of <code>emplace_back</code> and the other doesn’t). Amdahl’s Law in action!</p>

<p>My conclusions:</p>

<blockquote>
  <p>Use <code>push_back</code> by default.</p>
</blockquote>

<blockquote>
  <p>Use <code>emplace_back</code> where it is semantically significant to your algorithm
(such as when the element type’s move-constructor is absent or has been
benchmarked as expensive).</p>
</blockquote>

<blockquote>
  <p>Avoid mixing string literals and perfect-forwarding templates,
especially in repetitive machine-generated code.</p>
</blockquote>

<hr>

<p>Previously on this blog:</p>

<ul>
  <li><a href="https://quuxplusone.github.io/blog/2018/06/26/cost-of-static-lifetime-constructors/">“The surprisingly high cost of static-lifetime constructors”</a> (2018-06-26)</li>
</ul>

  </div></div>]]>
            </description>
            <link>https://quuxplusone.github.io/blog/2021/03/03/push-back-emplace-back/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26339893</guid>
            <pubDate>Thu, 04 Mar 2021 08:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Human Interface Guidelines (1995)[pdf]]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26339159">thread link</a>) | @neilpanchal
<br/>
March 3, 2021 | https://apps.hci.rwth-aachen.de/borchers-old/cs377a/handouts/HIGuidelines.pdf | <a href="https://web.archive.org/web/*/https://apps.hci.rwth-aachen.de/borchers-old/cs377a/handouts/HIGuidelines.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>^¸
œ4L²œ/mTÑŒQK\7ÎRÚY�%&lt;7
ã`Þ3Èc$.1Í,ÁCFQ¤ˆ7�ã\:ÃÕÏ•ÏšÂØ$Å	M�dÄÒAtèè:Í–•}Z´£¤‡7h�Q4Að�n�ãÓ‚ÌœcbÆ4èÑ¢hÚEÅfiCž˜4é×¾ÿ©Z¦¬©Fp—#ªÌ0–±¹lvÆ•0K›½½-Ðï�CGÜ&gt;å¥CZ5´9B]YRV½+7ÓÛùÜ6mî&amp;³EQØN´ú	£õz�ãžiZ]OÀç‡¶˜ˆ\˜â—+çt&gt;×[ów?�~á1¹dÀ°8AâÍÈø3Hr…ÐÜ:Œ¾þ²!Ž½|y¢5b‚
A¨4,g°'ìÜ�&nbsp;0´õƒc“A‚G@¬M–¼5’ßÒ3ì\ÇÑÂ†óÝ‚€D+)è²·ÌpP.ÍW¬¹Âbb
f®
†P¦§ÕÜ4záQ÷?ÙÙúã+æQIUò¡ãïüÕ„€òëâL&gt;
‘$¤ÎBºínlíŸ·¾ôŸL00¡€åOÒÖ]‡èÕ¼WŽ—Tm¡±dÄÒ¢ì$|êÄ°Ü˜y3‘&nbsp;ÔÆ¥ŠØú{-) ‡ ÖÈXBûRPÔú¼ØÖ÷€.WL|3£CðÇÚzøp±/æ !¤lýDp@­ªõM\ØG¥HBl-P7…H
\ºAròBE¹?v�ò^/!øÁ	ãP
áÜÒ„'$jÂˆuG!¬"'ÀïOØRBá`HôÖBšu4Š0š´ú˜!à8-ÌÓ‚‡é<gœo3²!'È©Šä|ak+…áieÒ}æbï?±~ ¢dc="" oh¦±‡t¶Ÿä‡•“i-…7lüfÑgÇÔÏ"Ó½�’­…q':s°msrhË¯ºë|5aÝ©ä€�’!�wru;+´Á)b†k°0¨`Ôs@sx="" ™ÜËrÏ-ètb!#e§ÿ�krl”žÈæk="" Àg="" Á„„tÔ[kÐˆf\#'Å8ñcy¥s*®z‰'Ò{ o•”5Òhmw="" u="" *p©ná:c3áÊœq…¿\ªÄ}—Á±="" #Ät¡èÚlgi‰�²Š‡'—e�°É&h)*Éjdu+†-·-©*Šƒpyb…tyŠf§Ðrt‰_Æ×�7c="" ß‰w1…="" š½gt¬¡–²="">Æé‹™&lt;‰´õPOëa@h$’6"¶¥dì­£GÕZ=ËˆÄB&nbsp;Ch0‡`ÀbGhJ±WÚÿjYµG™Ö
ÚùaW	­?ºõ`Ä&gt;Dú­ib�7+ÑN]@n½–f
…iÁy­­z¿·nÀ`½�í[áµ¦]páè•ˆ.Z¡O{¢¨‰A@SdqÍ‚àÊ´›¼E!Õ£E‹(`À ”ËÚ	]LpÀØ,«L@Ã{)K*$lnOÊ	C!Å““&nbsp;R�©½7 4ñ•sÆˆi‚+§
	eÀnbA¹Q9'höxÄHM¾"³&lt;ŒÀR
A'@²xN|ú$¿ô*4f…ºf4‚s‚�E
0 „0ŠB.�É¦4¸*B`LWÆ°&amp;ê0“¡40)ÑEhÀ©­Âž�ÒAP$�ƒ¦Ë^žÇ7F]`»ÂpC	�T"�œõ¦¶×mIhyç¯4^�Ø@#i0¤ÂF¾œ!�£°¬“	Ú#_œBžÁÁ&lt;)i�f*ð)&nbsp;)@¯ÂUÔ›öRp&nbsp;B�P	áL"ÃMB4‚
šãk‰ÄüJ×úGx™p¨ÁNÚÙgG…ÀPA€\&lt;{K[À³¾‚�O	¥H$^i88ß%?rìN}¿HGÚÚÃYê¢f7vÿâ&nbsp; ñN…Ñ9æÆ^\ç�„&gt;Ÿo‘­<g8"¿&þ´~˜zà�o¡"&“lÔtuq=-;§ãa~j‹l gÏ¶`kß§”mí¸w†Èîðw~="" b5Õq+�¿f�xe¾÷~„p±ä7ÆÇ¼^7@í ˆjÂ¿›ñÛà(^¼t¹fÄë[pËìÀ�³‚bï="" ›(û‹àq–˜|'e„?�28h(ÕŸtù7á»7w¿ø="">7z…Mï¾fO�ÒÉO¡pôÿø¬#…kÅåÄ8—C½Wi#Â¢×OœÃS@Qì¶¶÷Ï­0ž	�
:dOØØÀYBžÓ-â²	àª5nŒüï˜ê&nbsp;Š
N,çÎª
`ªÐM®uBÅ-R×î.
MŒ	m0Ø.N5�vzÖÅÊÞo„ø�JøãRì
XÕÄã&nbsp;œåŠ
ÐBÐÍÜÖM..ü	Ž|N|Ð
Ù	RÙ.ðRMöß­ªÔ.¼œ
¡
¯\þFõ&nbsp;†Ò¯rèM­à‰-×/m"â�{0ÀÖo’„M˜ïýíd?M&nbsp;Œç.vÑ�©ÊÐ¶Ò
úéo†äŒ5�†Ø­ŽwÆäÿMžÔ[ÂF	î0Lzp
p[§
$pmÐ<j„`d®fŒ¬ŠÉhÕ`\ìh+ Ü="" |ÑðÔ-pÚ¯â€©="" ïa0¦àÏî="" 0@Ÿ="" 0âï<Ú@ª="" `“Ðã¯’Ð�Š="" ­ÈÓ="" bÖ`žèÀ¤="" cvßŽ˜Òï©�¯€¨ão0<ô°ô�k@ˆc¦,öˆ,”m…Ø¬="" ÜŠë q±$d€Þ="" Ê3¦¤©�Â4ebm�ô`'bh*ò´†="" ¤ª="" # ="">tÃ#ÝÅ$&nbsp;ð4„ü[å„PàÈœ¥¾gGB@îEf`mÉÁ[Cº
c@3¤¶Ê1èEhPé†ì“#@Æ
Š-$dõ‘z;¤pP	S(`dgnfRPO¤x`ÄôGÂQ@P'zRäxîoF”^¦ÒOEhc@â~…êod ÂŠå4æE
¸}*`ÞCF.deÁ±ù'’|[ÇRH$‡&amp;òÞ¾£6HgB%&nbsp;C&nbsp;¨î’NRRHi:CD%0Àë`æg$.lf.¯ÆÒn„!-iÞ$§å*
’Úí€Ã.’ÞXŠõ3Æì§„rf„ÖECA-‰R3§C&amp;cHË´#@Db
Ì&nbsp;ÌBl&amp;ìÊ's„X+3ŒÎp"‚v#&nbsp;Ž# Ò@	@@#&nbsp;Õ;cxt*§Î¶¢:“‚ ó˜³œ(‚ß93Ò ¢f-£+ÇÊ&amp;@i&gt;†.&nbsp;¦Ìâ–)£:¢v/³¶þ ¬ä0‚ÐÎƒˆ€f9c�&nbsp;l1 hÏÂÄØÀ„Ò@`£"‹`b�ÀkˆÂ,B¢&amp;@@!#Î4r&nbsp;„('àj3òb?-èìvZ^fÆX.S.dîH¥ËÔr8Œ²¢+Lä!b!â"'",#Ð)¢ž/BvB*ôµ9ƒ+”2bÂ#¢6;ÂÏI"WJ¢�@@K´¸!3–Ó¢ô+ÔÅA`Pã¦ÔKù@¢;&gt;LãL
\T+BÆ;*D£&amp;2¯ï‹ê¯J,`&amp;&nbsp;î‡.°¥8¦ìgÔHÅ`PÔN¬p�äV„%+B&amp;`ó'¦"`mH‘€®Bš<tù<b¯<@gaa”Î)t—wt"4 !´¤"óü6µdÍui@³Ä0ž<ôè,2`Ærs r(´pwõ®tb=""> é[`n0áZâ†€@ÉZàs\*’FU®@î«£’=iæ	µÈ(`P
u®*&nbsp;dJ`i]³Ø#C•ÿ_¤?M  
endstream
endobj
17 0 obj
&lt;&lt;
/ProcSet [/PDF /Text]
/ColorSpace &lt;&gt;
/Font &lt;&lt;
/F3 5 0 R
/F5 6 0 R
/F6 7 0 R
/F7 8 0 R
/F9 18 0 R
/F11 19 0 R
&gt;&gt;
&gt;&gt;
endobj
21 0 obj
&lt;&lt;
/Length 1683
/Filter /LZWDecode
&gt;&gt;
stream
€A£À€n8£q°€Z7†FPi\@n�ˆàÑ„r2
†2|~%#J1˜ØÈa	HcH(´g ‰ƒLÀÒP/#
DRv1ŽÒhqØ$E6Ç(§ h&nbsp;@)*ªQ±¨È\4Iõè)P‰U4Úk¢,ú‰ÇFÃ˜(Òc‘Gg3»Œ†è »I×¨¤î{?#Ch”`hÊJÇ%ÓÄt©QŽÆÅ3y¸èeÏíp:U2:2Ó¡9z­^³‹µ"ÑˆÔ\2jlÕ"¡Ü[�&amp;s©ÈR1Š§1„Üd¢ŠG#A„ÄlåŠE²á€ÀPx´šE%Ò¡(m–Tˆñ“NH@JGM_½ïKD²ìtÈ¯¡¨rÔ°+ÂN�@ì†ª!ªº…(hØŠiâ|&nbsp;*#£¨ŠT2hêÕ³ÓZÑ¶Á¤‡!°\…¡­ØP("c0Â1Œ­bÇ¾*†mR¡µéoÅ�˜\°µk8ZIqjŠß8Ä7Ž£¢Š4
.cµ…Þ7�oÊÄ1J*ŽÒ¿›SÈj³FpsE“¨e («;¾ð4m¢¼Ç(M¤í&gt;7l´¨
ã@Þ
tpê6:�Ê0º¤¸æLS#´î;ÃÅò&lt;Èí
 ·n0Ž‚ân¹‚pÊû�#sóÖ£&nbsp;Þ9��:�®p@$³Ã(åGŒã9@Þ6ªá˜l#€àìSîíBð<u *j¬­,km1="" Ã`ki(a’¼†7só\­!Ì_»w{s="">·á@š0�u¨ÏaËWøÇ\×cE²îÏëU¼&nbsp;M,ci{Q]ÜÙ_q•æ�ÅÉ#%ã+=T4U•v*æV²ÜºS³+·ma¶ìÎ¢T÷ã�M¹`Â9�#@(Kƒev7Ž@ó…ÛxtÏp_¹Å‡bØñ¾r"»k@:4Y~Q&lt;33Í¦J¶³@2
#Ã³­i:SÌÚE�uQ‘°R†�Dº:Œ#`@!Ž®X@*Žc+¡”ÓY^[¤f9“Ìô-ðK‡,î¡«ßh,ó,'
°ðÄ55 pì{†ˆLàÖ32"´È"IÐüŒd(#”´ÇQâ˜„†“zžÖNR(c#¡.ßaöÓðŒ:¹ã¬Ïo-_ÆDËï2¡@¼¤¾#¼ÊÍ¦J?1ýÓÃÊ j¢uq+5�É[¥
¶ÈBË?y àgÃ‘Cw¨õß�§TðÊ‹Å^‰@¤ƒ¶�Qjñ*ªý`«e‰C9FŠÕƒ­s²kØ�Ct…"€jA_‹®©¯–ä
úˆOÀÍ@�@\eI#Ç0É¦††sXÐdC–pÕ´
Ðtì5•@
£^#,ÕT¯àÊE
áÊ'3¢·›(�¥f�ÊØ)Î
!ÁIªÀÒg\@5ŠQ„)†PÊNpd¡@7«—
ãšá8p73Àægâ[Gm¢@F	£ÈS	!\,„p@c$\«4,�#¨–„vXg1UÉ³“'NšÎ&nbsp;€#Åp¸
\@8�+õÀ,fögC¤eYÁ±Ä™fp4v�‰†³šsâ(io!¼3ËÙ~pbÙÇ9!œ4‡c@râë)&lt;(,i¤
ÄÕpJB, ÒHt‘Q=Þ7@Pï$rý',:CàèÏZyŸáÊtÎ¶a;[¬ðir&lt;&amp;†ðÈbhs
ÓaÄ8¤Û"£p!‘²Os:Þeso§1]Ky
h9Æ‘`Æ-æhñÛzý	a¸7‡s°;9
á˜«ÉÉ=*&nbsp;)ZKP:¶C@Ž(m%&nbsp;sÈ1£€æÏ'4è�T6/¦w°\
bÒrF	ï¸êHPŸ!C�óºŒú¡¦)…Á¤'X‰&nbsp;Q�6F&nbsp;‡Br¾
2±f(‡‰‚A…5¤¤$¸C‘RvAèÊVÐ°åF"3&lt;êÚB3ÊCŒëÖ+P…õ¦ÈH¾ëÛô6Èìšƒg—'|r5çmãº’k¡âª¦ñmJz@ÎLàmº¤ÏÚ
¢•'mÌØÍ©0èqhÃr•-æ�ÐÙPÎ–ib]Tk�Š©]&amp;ÑØ l�AÃ!…G&nbsp;�ÔàŒqr¤P‹Š½t¡–4àÁ ’
Î
£­2ÁŽž'(ä@d;@Í­0é~ËÞ¿àµÔ·[ôP2nÓÕOƒS¼’ø9ÂKøí`PPËŠA¨Š4ï9†Öñè%d
endstream
endobj
22 0 obj
&lt;&lt;
/ProcSet [/PDF /Text]
/ColorSpace &lt;&gt;
/Font &lt;&lt;
/F5 6 0 R
/F6 7 0 R
/F7 8 0 R
/F11 19 0 R
/F13 23 0 R
&gt;&gt;
&gt;&gt;
endobj
25 0 obj
&lt;&lt;
/Length 1521
/Filter /LZWDecode
&gt;&gt;
stream
€A£À€n8£q°€Z7†FPi\@n�ˆàÑ„r2
†2|~%#J1˜ØÚ:6�
&amp;á˜ÞN
3HE@h¼Œ5DIÈÆ;G&nbsp;ÇFò&lt;$¨mŽPÎ@Ñ@€RT5TcbÑˆºIKÓb¡¨i;Uë$Yå
[/ÁfRIv'8�O'ÐÚHŽÑ&nbsp;Ô
m¡UµV¯âáÌ8s^±ÐìÑÒ¡Ü[&amp;ã9ÔÂg2ˆ†“0¤b7Œ§-6&nbsp;Ên1™Nb‘hÈa·A%Ò¡*£\òYqAPR9Š§ƒ¦ˆÒs8'‘lÉCãòy|Ò)�Òt4ç6›mÀÄs»ÞƒJ‚®!Êf0�MœÑHÌl( ›
&amp;sq·^æ�ã0@$�Ã£Vø6!Š6¯ô
Ù¶­¸`6ÏC|õ¸‚XÊ&lt;ŒCxÂÖ4á@É&lt;�˜dBÏSØÌÃ|ñÂP&nbsp;g«ˆrºá,&nbsp;hZÁ€f&nbsp;2® ª7-
Xæ0��‚1¶#œI†A¤R¡8Ã&amp;¡²ÌÀ&nbsp;2�î‹B+…!¨h;ãCª
@ò9�#�çHãÒýƒÌ`ÜA¬SKRä¼LÈ:LÃ@+L3žÏI-ã9»ó´#<omä …Ü»pmb„@Ë¼#<à0Îs¥%Â�´÷lssýep“8¦8="" £(Ç3="" ã�@Í3ŒóasÕ4Œïõ{‰xÓ•�?[="" £hô:Ä="" tá^µ±wcÂ–m-j‘»†ÌcxØéc£�ÂðÍ="" Ê6Ž«Àñrvd§87qr¶="" xÜ="" Õè@'Ð�x@*Žr5¸s1„`ÂhÈÿ�"àfûmÏ]…á¶üøüi��ç4kdæ2´|ñŽ½8ø 0ÉÃ½±Äx[Ï�s%×c­€ä<ŽÕÿ€×Â�ujx×¨p†u÷cáÞ6Ž²&24ÅÙt'¦iÔs¢éÔ¡©z–«•„˜éu´0e�Ûšæpâjz¬Ûuì6tË�àµöz;="" ;4]šÖ–éÂpÊ:fc�ÖìÈqu="" Î„?lµãw†|e¾Ÿ*ú¢¨jgbƒ&Ì*žª*ÊÅÀlj�zû8!Êœ³_c@Ã àÑŸ\¡="2)HC" Ö1!°\øvØ2p$£k7À°8Ã½Ócøê�Î¾Æ÷]£d»Âu«zÚ�*":24„="" �”#£wè¯(º’="" ¡�¶hèd¤¸c„\Èq="" .äæb@tª'€¤Ì6�Ð¦^ièftîŒ�¼èp^="" ue@Ž‘³ëŽÌ!&ÔÇƒpfaqÊ™a½&›7\^Ê="" c(¦ýƒ‚Þc®�à†‚Ðhwa³8m-ß˜†="" Á¤++ æ%#“0÷oÚÿ="ÁŒçµ‡*ÜR’ß\+æ+€Œ¨Ã¢Ôs" �æ¸b:�5†·É#xs�h„Ùf�×\{zÁ="" ˜&æ&Üt«-sp4ˆšÚ!6- )®eå¤b4Œixâg@ÜgÛ="" ïkÁá¤ªÄ~½Òªúa="" „(8="" ÎÙ™en�óg©`Üaj‘*\â•àƒ$¬–ªx="" ×="" mdÒø“†`"œÃ^wŒãb‘¯a$[‹,7Òm}y¿Ã oq$6‹ŸÓáÔ4±3ô£ëj…í8!nÀØuÑtÒ434ç¯5l�&¬×n,ÞeÔ\Å“Éô="">Çá'E�@âŸÔæwN^²9Â‚¥ sŸÌ1¥táhNrÁ¶&amp;z!5Ò	Ah4ÿµ#âÆƒ¨s
ŽlÜFš·Ñ¬©Œ¨;.g4X€rdg†}#eC¥jÙ†Œ‰nDyP¸‘Ê;G&nbsp;Ä†¤®X±öž€,��PÖ¡V6Çà:�ç36UNnfQ,Ÿ‰?LÃÑ¡8Ç 3Öá«U3Õ9�z’ˆC|áNªâ¼"†æfxba!Év°{aj|d,Æb¹�¥þÚƒ(pdm©N€êèÚ†¨4rÅ‡fðÆëJ3[å°�
endstream
endobj
26 0 obj
&lt;&lt;
/ProcSet [/PDF /Text]
/ColorSpace &lt;&gt;
/Font &lt;&lt;
/F5 6 0 R
/F6 7 0 R
/F11 19 0 R
&gt;&gt;
&gt;&gt;
endobj
28 0 obj
&lt;&lt;
/Length 1249
/Filter /LZWDecode
&gt;&gt;
stream
€A£À€n8£q°€Z7†FPi\@n�ˆàÑ„r2
†2|~%#J1˜ØÈa	HcH(´g ‰ƒLÀÒP/#
DRv1ŽÒhqÑÌv	*c”S�4P •
U8ØÐj.
!0ñ�º
T"UŽÕšÙ}D�Ód#˜(Òc‘Gg3¸é2iH	Bé«.PŽô±4@[.ÇL€Û�Ú »I!·¼¤w,3T†£Y|@l”ç“êÆ‰D£@è”­p€s&nbsp;§ÑjQØÝ^Ø
Œ1}´q`
è¶˜éPïV(NGLüc	ÚBG0ÝÍF­X­Fâá¿^ñfyub¡&nbsp;Ê $›Ž†S‘˜Âc÷‘M†Si—ä9·ërXÎ¤!š:Ì¯	:u&amp;/SDÒ$!“ÔÔ5Iê~#6­‚ŽÙ°Š^)Ì»¼Þ;íû‚)¯PZ†ar†­
°†4#ƒæ93³±¼ÊCq*MóÂñ†O4VáÎKÖ	¯ðë&lt;*
 jR:¤)nS» ¼
Øb¯©ª$VE›A…&nbsp;sÌ@a13,Î´‹aCÚ÷É£pêN�R¥ÑPÒ"è¨%*qX]9�³¬ó=ˆC,h;
#xå?Ð!…Ð´8*Tl™'Óøÿ�SA¨qNÑ…õÑÕ ’ù�¡œ0¿µU3AÕô5PTB=.†á@Þ:ŽHÜ3¾ÀæYÌl�_U�@lVýCZÏAˆ4Òƒ#élPI�»¡Ó�:Šc&nbsp;Â7“õ��fé&gt;ñ½§yß"&nbsp;R†!@Ê&lt;:—ˆòýÚƒu­=]ÒÃnÖWxQŒ£Ö6ºC]ÿz\Cæ÷Zv­ˆÛA¥»bN³½J6
ƒHà9�6�ö9_¯¦‡ÉôÅ²äåvøP …!¨h«Üuàß�	¸îv:=ÊÀfhc€á˜ŒcéJáÔ~}A&lt;º
E¢`�@ì7�7È�¥Žw•é{Y7Îš9cÙÞO¯ÓA¸e±e¸ƒá#¦2äºí¯¼%×ŠÖ“¶ýeã;÷¹VÖ—Ó–½Q
c�d�ù…�hnõ^Á`ÓÙ`P$
/¦àc@Ó¬�™æPÍ|×T(
ã€Z*Ž·o|×ÞuëÏßyßxMM¾ùÇÈP&lt;Ž(ZøùÝïàôµþ	ÅÝµŸ‘Çl£/^‰ã0S{ŒÝ°A€yÃö:&gt;yB&gt;ÅK`Oµ÷¿æ²_«å[&amp;Ýë�öÿ\AÛ}
)‹/ëÛ‘÷YÁÐ7²7¤ù�B±€'­ƒfPŽr¢eÁ«0Äÿ	Õz‚0„ŒÁGCË�Î	®ãÖsNzuÁ¥†5ç¦
Ë¹SÏ:€œC¼‰K
¡÷ºœAH/\!†È:bÈ0x®¥¡0Â£G)©Ý*K	Ê,Aš4‚Ê
@6záH2Æƒ§^´m*p¥:�Î{Â˜e‹0.3]a£»PnFÈøÔ$‹B
!Ô4Ã¹/ÎL…MD"†I:Ï#&nbsp;”Lµ¨ÅÖe`ÄYh­-´`Qäu
«Ð7‚øø|²–ÑmM8¸dò¿–²Ð©¨ÙCw¡æaLÅ[Yóš²Þf¨8¸~Óôj–sq¼­Ô@@
endstream
endobj
29 0 obj
&lt;&lt;
/ProcSet [/PDF /Text]
/ColorSpace &lt;&gt;
/Font &lt;&lt;
/F5 6 0 R
/F6 7 0 R
/F11 19 0 R
&gt;&gt;
&gt;&gt;
endobj
31 0 obj
&lt;&lt;
/Length 1328
/Filter /LZWDecode
&gt;&gt;
stream
€A£À€n8£q°€Z7†FPi\@n�ˆàÑ„r2
†2|~%#J1˜ØÚ:6�
&amp;á˜ÞN
3HE@h¼Œ5DIÈÆ;G&nbsp;ÇhÃ˜4"†mŽPÎ@Ñ@€RT5TcbÑ&nbsp;º™‡i±P‰T;jõ’,ò…-—Ž`³)$Š;œN§“èm
‰¤R©R:l$©PªÚë@ÑÀºH9ÇY(vqhÀ\0Ð
‡pilPS2›¦3&nbsp;€‚l6
E£!†´P1�FšñHÀP7—J„ªˆ´b.äê9¼î|Ðo;ˆfÃIÀÄo0œ…#¸&nbsp;È/$L†^W3�Ðéu:Ú­f»a²×î7[Â&nbsp;«ŠCðõL¦§p&nbsp;u1sfƒ)È¸†-ƒVÖ¶Ï;fØ6ÏSv½®(¦ücä4ŒNà¨‡!ˆP7¶¡Cÿ¼�#hô �Ì³Ï»ò4¿oè_ŒPŒ'
ŽAž8ƒHÞ7püòÀ­Œ‡3xß!Íû‚³8¢£øÑÛJ&amp;Œ£pë¼Íd�=Ìôœî
cHôîJ’´±†A”·ø@)ŽƒËDL²¼,†“\»6ÉâCB8N’¬í 5á�k=I²x–2�.{¢éº£%3NóEõË€k*Ë³*9/Iâà89ƒé
Ê°ZÌ…¬ÏBÁR:„ß8:â3Ô]ðR°@"Ž#¨Ò;-Ü:uzG"ÓjX¨ˆèÈÒ$P@Ž�V»&nbsp;9*4èbê:2©p@(jè‡!«Âss]
&nbsp;Í78r&nbsp;
€h¦½'¢4&nbsp;¨j*„¤_ð
ƒ°Ê‚:�±*Å4®‡!‚¿CÁ¸j‚É�@†41Ãú…1AŠ‚!0
m„)ê¢­‡+¡€oYµŒpgŒ,á@®4�Ã#‘dáËæ¿ÛØ"”(YC•d+rƒ¡Á“ê_1Hx\² µ&nbsp;s¨É”Û0ÍSù´„gÓ“Q˜ä0�ÃËesÍ1YÉUµ&lt;âˆƒxÆ:�²«J+ì{+�åJOŒ66Y4®§¹DóØª9»ƒxÍÂ
ƒ|kœÑÁüM³4C&lt;*Ç.dãÌð9Îw¸V4ÖéZÉŒ÷4Ùó�„2ã‹O-ÏD]s-õò[(Ëkû½@î-%†î5Ugg²uC¾áßÓmo°Æò®p3õß£Þ&lt;Á£aêÏ~j"E• Â&lt;ÆÜ3¶éqYgÑl^öÌ
xæ4Ç1ßÀ�I“ÀI.À³¼p@(f!Ô6Wòþßê©G`€0¦÷¶œÂšW¡•*¬&nbsp;hëSbn�*@çôÿ@ ‚a6œØ1�G�yf8ÖðV(o{�7‡ˆ(ÎJ°3À&nbsp;ÓŸÓK!ô…ùeP`–ÒB´xG½Ê¿°Ü÷ «æz155&gt;CŠCyiŠðQî»H¶üM“ôcm°3½°@zaLp©ÉÅ—RÙ¢h6~�eÃóQ£³ö96›Ç‚pŒô|W±ø6;c¢ÿÍ{�pÀêÈÈÜù£„oŽ2QÃÈÐS¢ r�®uegç¤Lœ’ÑŽL‰4w;k}’~!„|å+Œ=‰îE)V÷ì�¬3ÆØÇª5ÚË—èC¨t
áµS†4ß2ŽdW”±éLEêìSáÜA¾iÌÈ|Û”Z~îÝÜ£§àçÁ´…S2%R?Äsäf�ÄÄöçâ›²Žî(6Ã¹;º�îôÅØlg‚xnLÔÒ¶”jÐ›~TèíeyN‚Öq
endstream
endobj
32 0 obj
&lt;&lt;
/ProcSet [/PDF /Text]
/ColorSpace &lt;&gt;
/Font &lt;&lt;
/F5 6 0 R
/F6 7 0 R
/F11 19 0 R
&gt;&gt;
&gt;&gt;
endobj
34 0 obj
&lt;&lt;
/Length 1378
/Filter /LZWDecode
&gt;&gt;
stream
€A£À€n8£q°€Z7†FPi\@n�ˆàÑ„r2
†2|~%#J1˜ØÈa	HcH(´g ‰ƒLÀÒP/#
DRv1ŽÒhqÙÎ
¢›c”S�4P •
U8ØÐb.
Ç0á¸È]**ÇcI¦³["Ï¨‘±Ìtl9‚�&amp;0évs;Ž‘ã&amp;‘€” Žš±á•ïKD²ìtÈ
ºÈj©$6ÿ˜»)Õ!¨Ö@6Ñ
€Òœò}@Ñ(”h•±¡Œ¡°xIR¥�ÕíàÙ¶0oNŽ,-ª:T;Õˆfƒ	Àèe9HxcNÞ#±ï*5jÅh5áwË8ÂÇi«
&amp;a¼Î !ÏSŸ€†¶j:”¦)�šœñ7Ï#¶½+Ò…Á¬æªÁˆn¸aj�ÆAÐÐ\Âo€¶	£xÈ2��àæ&gt;O£ìü?OàR¥Á€`BÁÀR.Š‚R3)ÑIETXù¾¯»ò&lt;+˜l#€à2Œ#�Â7c,gÆð°sÇ&nbsp;h¨±KÅ#œWÉ1„˜!®¢Ø7ŽOìiK¡Àc0GÊ$�
LÃ(Ü:¿¬›'ˆ#³5KsÄq=O“ÉÑ2Ë¬4�Ï»§+ŒïàAL#"M3\‘ÉtlmG†TŒÇ2…Þ6ŽHéLSU˜Û+Œ“´¹G†”Œh‡+ò
Õ3
ã°Â1E5ÈúHñt•×Ôr	G“íˆôÐ•f¶u¡6UÕ(JR¤­,KS½V‚Õu'oYvlÏqÔöœß8Œ3œëUO!½#?X¶è›AP‚ÉÒ…`~l¸‰&amp;!^ãe£6Éq•Ý&lt;ÇX¦	nc5ñiM×&lt;£)Ê²¼³ˆ†+­åXc8ÝË}ÎCLéjÝáÌ÷‘[v6i„P®ÎDaôf?gÙœF)ŽƒÆ5×5r_Xõ˜Õ¸¥‡?ÈBR9“vµkDƒnìNÆË%åWN[vfÍƒŠUáh`RŠèÄbpÞë„nÈ¬&amp;Á¨QŽç’îí§V#ë[�ãw±ì±›ÕÅÚ›­±0Õúxè7Ž¾ÝÄs|fëxëÙ„çðXÂ9�#m}`Â&lt;�üŸWÈ	c(ò1
ò¨S @'_£HÎ0òœµA¬lÜn™�ôŸ©¸`óPÃNúÙŒ¿¼^z…yãyPŒ4Ù¾ß;¥Æ¼€§~Ü4Ý3Ohò‡17b)v~˜K‰,4€ƒ„gá''P�“Hi&nbsp;!/5F°×ðŒn	µ1n7äoÈÒ
&lt;À´7Æ|C�&nbsp;3ÄŒÙ–¥bu±Ø ÇlîÁÃ¾È,„Enƒs¸C�1gOHQX¹Pèƒxl?§˜ÿ”2Š€&nbsp;Ú(`Ð�C£„y�Œ*+Éø ÈRÐ�A.he#p‡‘BtOœ9<pnòj()gÀ 7Ä—ˆ“�nˆñº:d§úkÛs`xî-Éº0Üõ‰swl.¹n„) åoÂü_ÑýÏ£çc!¤†ya„6¶uvk�bacm­!="" ÂÑø‘òþ”‡="" tÃ+sŽòyÆ`r="" a¢8xr1!g˜öò"j+pm”)‡t¤�»Ê="" aä@Ð¸bkrsŒ9†ˆãã¨lŽò¶e-©¬˜l="" (�¿¸ÌÛÓ|oÇaxÀÓ&vhaq¶`y="" e="" –lŽÁx÷'8ƒrá="" €¤�p�š™m2µì#ég7Ño™ÐÈ"¢™;‘xfn€€*‡8dcÑØjof†h="" ès="" ¡á²„xô¦cëe="" öv¾7³8ô�ñ&€yÜÃ¤ˆ%Êf��="" endstream="" endobj="" 35="" 0="" obj="" <<="" procset="" [="" pdf="" text]="" colorspace="" defaultrgb="" 1="" r="">&gt;
/Font &lt;&lt;
/F5 6 0 R
/F6 7 0 R
/F11 19 0 R
&gt;&gt;
&gt;&gt;
endobj
39 0 obj
&lt;&lt;
/Length 1463
/Filter /LZWDecode
&gt;&gt;
stream
€A£À€n8£q°€Z7†FPi\@n�ˆàÑ„r2
†2|~%#J1˜ØÚ:6�
&amp;á˜ÞN
3HE@h¼Œ5DIÈÆ;G&nbsp;ÇF#HLT6Ç(g h&nbsp;@)*ªQ±hà]	‡Œ…Ã�´Ø¨Dª��6ºÅh‹&lt;¡Keã˜,ÊI"ŽÄç"<dÒ �„Óv="" \2 é"h€¶]Ž™²é="" av‡cosœ Øp3tf£){@l”çsÉðÆ…b¢@èt�ui6§pê1ØÝzÚ="" ‡‹‡#Ì:¼6²ÐíÒ¡Þªc4nc)È@8ßÒð}¾ÐÄkÜÔ*µzÌ="" \7ífÖ="">'*ªI1›ÍÇ=üú°¢Ò)T¡­7,ñ7Ï(na¢€‡!pj´:ªÒmøZÀ�2¸PcÜ-…¸Ð&lt;„ƒä9„¸R†!@Þ9
aHZˆPÒ�Hº*	J�[A«D8&amp;
#hÒ:#&nbsp;Ó„xÍ¾/œ]FM oGh¨°àˆ2ŽcHÎ7
#pÎ£0R†á@Ì2Œr0ì2É‘Ÿ†˜dÊ‘Ê…À�pZÁ€f&nbsp;9²ÈP*Žs€‚8”Ï4�ôhÓ"Îu	£,ˆ8
[éÎ“´ñÇ2º¥BÃ‚&nbsp;Ñ0�j¸fÄ7Ž£¤KÅ1XØ2ãHÉ8cxÚ8H£HÄ4�’ó9Ê!˜a&lt;ÊÒÄ8 ×@ì7×Êª2�´Ã8ÉÕ›gÔ–�
-Ë²ø@3Eaè4NhÂ1Ì#&nbsp;Þ9�ˆ4Žc€Ø0Ùwêa�¡SC”Dà0„ç~:ƒum ãEl)Ö”tÐc-™�†a–i{§ �#Ôáv:ÔxP,Ú¸ÍµS:ãSHÏM_Wåý€cñžC‘Ð×•ê0Ûøf.Žx�l+/èQ~£ÙWVXà2Œ#�Â7c¡’7*÷*ICaDE²Ã„6`2†AÜ±|/&gt;ÁØMpLƒ`Ê6Œ¸”I¥âé¸h8&amp;é*Ç{¼{CUS€�0×î¶Öm»~ãPà‘­Ë„V;'/tKÛ ¡œÅXèçOîZm¢C‚þ1�an¾2°ô‡8m}g8»þI`�—o{Äø„÷´o;T›†�þ(åßJ!¥É*ù{Ä|r:ÅcFoÛç‰vŠt×ëvD¶3ëÃ%ŠùI2]ß`z?&amp;xÕõˆÇÔ^ñ š|’ž|ìá(gÊß“jGlŠd1�ÀÃjë]¯�Ë$×¨ÀÁ¤J®‚
˜CeY)ˆÆ&amp;È¿ ‹,zIpAtf
u{.=i± ÒB
É)u1&gt;w…</dò></pnòj()gà 7ä—ˆ“�nˆñº:d§úkûs`xî-éº0üõ‰swl.¹n„)></omä></u></tù<b¯<@gaa”î)t—wt"4 !´¤"óü6µdíui@³ä0ž<ôè,2`ærs></j„`d®fœ¬šéhõ`\ìh+></g8"¿&þ´~˜zà�o¡"&“lôtuq=-;§ãa~j‹l></gœo3²!'è©šä|ak+…áieò}æbï?±~></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://apps.hci.rwth-aachen.de/borchers-old/cs377a/handouts/HIGuidelines.pdf">https://apps.hci.rwth-aachen.de/borchers-old/cs377a/handouts/HIGuidelines.pdf</a></em></p>]]>
            </description>
            <link>https://apps.hci.rwth-aachen.de/borchers-old/cs377a/handouts/HIGuidelines.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26339159</guid>
            <pubDate>Thu, 04 Mar 2021 06:01:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ship Investor game: Practise your bet sizing intuition]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26338744">thread link</a>) | @kqr
<br/>
March 3, 2021 | https://static.loop54.com/ship-investor.html | <a href="https://web.archive.org/web/*/https://static.loop54.com/ship-investor.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2>History</h2>
            <p>The year is 1721. You are a rich person, and you want to put your
                wealth to use. You are approached by various people who buy goods in
                one part of the world, and sell them in another. They want you to
                finance some of their initial purchase and transportation costs, in
                exchange for a share of the revenue.</p>
            <p>Unfortunately, this being 1721, a significant fraction of shipments
                end up on the sea floor, or stolen by pirates, or gets lost to
                corrupt locals.</p>
            <p>You will be presented with a few shipments to finance, of varying
                value, ordered from low to high. They all have the same return
                relative to financing cost – your job is just to pick the most
                attractively sized suggestion.</p>
            <p>All proposed shipments have one thing in common: they will need to
                pass through a specific strait. This is critical information for
                your decision: different straits have different probabilities of
                losing the goods.</p>

            <p>You will have to consider three straits. Their true probability of
                success is unknown (and varies whenever you restart the game) but
                you get an estimation for each as a hint.</p>
            <ul>
                <li><strong>Bering</strong>: Very dangerous. Probability of success
                    is around 50&nbsp;%. Shipments through Bering strait
                    often have a high payoff as a result.</li>
                <li><strong>Malacca</strong>: Somewhat unsafe. Probability of
                    success is estimated to be between 60&nbsp;% and 80&nbsp;%.</li>
                <li><strong>Gibraltar</strong>: Very safe. Probability of success
                    unknown, but it seems to be over 90&nbsp;%, maybe even as high
                    as 100&nbsp;%. These shipments have relatively low payoff.</li>
            </ul>
        </div><p>I've been lazy with dependencies. Please wait while
            a gazillion HTTP requests are being performed under the hood.</p></div>]]>
            </description>
            <link>https://static.loop54.com/ship-investor.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26338744</guid>
            <pubDate>Thu, 04 Mar 2021 04:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bitsquatting Windows.com]]>
            </title>
            <description>
<![CDATA[
Score 252 | Comments 71 (<a href="https://news.ycombinator.com/item?id=26338244">thread link</a>) | @vikrum
<br/>
March 3, 2021 | https://remyhax.xyz/posts/bitsquatting-windows/ | <a href="https://web.archive.org/web/*/https://remyhax.xyz/posts/bitsquatting-windows/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://remyhax.xyz/image/dns.jpg"></figure><p>Earlier this month, I came back around to seriously considering an attempt at <a href="http://dinaburg.org/bitsquatting.html">bitsquatting</a>. While the prior link goes into great depth on the topic, I will attempt to give a <em>very</em> high level overview here:</p><p>If this sort of thing interests you: I tend to do stuff like this weekly. Give me a follow <a href="https://twitter.com/_mattata">@_mattata</a></p><p>When you try to access a site by it’s domain, that domain is stored in the memory of your computer, device, whatever… in a structure that looks something like this.</p><table><thead><tr><th>01110111</th><th>01101001</th><th>01101110</th><th>01100100</th><th>01101111</th><th>01110111</th><th>01110011</th></tr></thead><tbody><tr><td>w</td><td>i</td><td>n</td><td>d</td><td>o</td><td>w</td><td>s</td></tr></tbody></table><p>Now let’s say that the computer is running too hot, a solar flare is happening, or a cosmic ray (very real thing) flips a bit on the computer.</p><table><thead><tr><th>01110111</th><th>01101000</th><th>01101110</th><th>01100100</th><th>01101111</th><th>01110111</th><th>01110011</th></tr></thead><tbody><tr><td>w</td><td><strong>h</strong></td><td>n</td><td>d</td><td>o</td><td>w</td><td>s</td></tr></tbody></table><p>Oh no! Now the value stored in memory is w<strong>h</strong>ndows.com instead of windows.com! When the time comes to make a connection to that domain, what happens?</p><blockquote><p>nslookup whndows.com</p></blockquote><blockquote><p>*** can’t find whndows.com: Non-existent domain</p></blockquote><p>The domain doesn’t resolve to an IP!</p><hr><p>In fact, out of the 32 valid domain names that are 1-bitflip away from windows.com 14 were available for purchase! This is a rather odd occurance as usually these are bought up by a company like Microsoft to prevent their use for phishing attempts. So I bought them. All of them. For ~$126.</p><p>(<em>If you’re a verifiably responsible party, I’m more than happy to transfer ownership of the domains. Otherwise, I’ll just hold on to them and continue to sinkhole.</em>)</p><blockquote><p>windnws.com
windo7s.com
windkws.com
windmws.com
winlows.com
windgws.com
wildows.com
wintows.com
wijdows.com
wiodows.com
wifdows.com
whndows.com
wkndows.com
wmndows.com</p></blockquote><p>Now we need to point these domains somewhere. So I rent a VPS and configure IPv4/IPv6, and create wildcard DNS entries to point to them.</p><p>Wildcard DNS works so that if I create a record saying that whndows.com points to 123.123.123.123 and someone requests abs.xyz.whndows.com, they will still get the same 123.123.123.123 DNS record as a reply. Due to the nature of this research dealing with bits being flipped, this allows me to capture any DNS lookup for a subdomain of windows.com where multiple bits have flipped.</p><p>Once we have DNS configured, we use <a href="https://www.wireshark.org/docs/man-pages/tshark.html">tshark</a> to perform a packet capture on the public interface of our VPS and wait for something interesting to happen.</p><p>Below is a short snippet of some interesting things that can be shared without uniquely indentifying any users.</p><p>Usage of <strong><a href="https://greynoise.io/tech">GreyNoise.io</a></strong> was key in helping to differentiate between opportunistic scanning and actual bitflip scenarios. Great product!</p><h2 id="ntp-udp-port-123-timewindowscom">NTP UDP port 123 time.windows.com</h2><p>UDP packets destined for port 123 attempting to set their computer clock using the Network Time Protocol (NTP).
time.windows.com is the default NTP server configured for all Windows machines and they check for the time regularly. If they don’t succeed in getting the time, they try again, and again, and again.</p><p>In total, over the course of 14 days, my server recieved <strong>199,180 NTP Client connections from 626 unique IP addresses.</strong></p><p>The NTP client for windows OS has no inherent verification of authenticity, so there is nothing stopping a malicious person from telling all these computers that it’s after <a href="https://en.wikipedia.org/wiki/Year_2038_problem">03:14:07 on Tuesday, 19 January 2038</a> and wreaking unknown havoc as the memory storing the signed 32-bit integer for time overflows.</p><p>As it turns out though, for ~30% of these computers doing that would make little to no difference at all to those users because their clock is already <em>broken</em>.</p><p>Using the tshark filter “ntp.xmt” we can extract the Transmit Timestamp, which is the time that the computer thinks it is when it asks to update the time.</p><blockquote><p>tshark -r capture.pcap -T fields -e ntp.xmt -2 -R ntp.xmt | sort -u</p></blockquote><pre><code>Sep 28, 1984 19:41:12.638290998 EDT
Sep 28, 2012 11:59:42.976403314 EDT
Sep 28, 2029 21:50:47.552079831 EDT
Sep 28, 2100 18:13:09.180229791 EST
Sep 29, 1975 08:36:52.200231052 EDT
Sep 29, 1980 23:44:14.142299217 EDT
Sep 29, 2036 11:54:11.410350275 EDT
Sep 29, 2038 06:18:34.082394858 EDT
Sep 29, 2046 16:00:00.102963544 EST
Sep 29, 2050 06:39:18.880921186 EST
Sep 29, 2074 07:31:58.701524704 EST
Sep 30, 1999 00:29:32.120677896 EDT
Sep 30, 2009 02:54:33.318870579 EDT
Sep 30, 2049 00:14:59.396552253 EST
Sep 30, 2075 13:56:14.492526678 EST
Sep 30, 2081 01:56:58.477295064 EST
</code></pre><h2 id="http-tcp-port-80-sg2pwswindowscom">HTTP TCP port 80 sg2p.w.s.windows.com</h2><p>No active DNS record exists for the correct domain sg2p.w.s.windows.com</p><p>However, the User-Agent and timing of requests suggest that this activity is directly linked to the same application that generated the traffic shown below for client.wns.windows.com and skydrive.wns.windows.com</p><pre><code>GET / HTTP/1.1
Host: sg2p.w.s.windo7s.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-clientwnswindowscom">HTTP TCP port 80 client.wns.windows.com</h2><p>These appear to be directly related to <a href="https://docs.microsoft.com/en-us/windows/uwp/design/shell/tiles-and-notifications/windows-push-notification-services--wns--overview">Windows Push Notification Services (WNS)</a> enable third-party developers to send toast, tile, badge, and raw updates from their own cloud service. DNS record is a CNAME to wns.notify.trafficmanager.net</p><p>DNS Records:</p><pre><code>client.wns.windows.com.        IN    CNAME   wns.notify.trafficmanager.net.
wns.notify.trafficmanager.net. IN    A       52.177.166.224
</code></pre><p>HTTP Request:</p><pre><code>GET / HTTP/1.1
Host: client.wns.wkndows.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-skydrivewnswindowscom">HTTP TCP port 80 skydrive.wns.windows.com</h2><p>Skydrive is what <a href="https://www.microsoft.com/en-us/microsoft-365/onedrive/online-cloud-storage">OneDrive</a> was called before it’s name change.</p><p>DNS Records:</p><pre><code>skydrive.wns.windows.com.      IN      CNAME   client.wns.windows.com.
client.wns.windows.com.        IN      CNAME   wns.notify.trafficmanager.net.
wns.notify.trafficmanager.net. IN      A       52.179.224.121
</code></pre><p>HTTP Request:</p><pre><code>GET / HTTP/1.1
Host: skydrive.wns.windo7s.com
User-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.109 Safari/537.36
Accept: */*
</code></pre><h2 id="http-tcp-port-80-timewindowscom">HTTP TCP port 80 time.windows.com</h2><p>I have no idea where the hell this request came from or why they were fetching HTTP on a server that should be an NTP server. WHOIS for the IP that made this request shown below:</p><pre><code>inetnum:        123.112.0.0 - 123.127.255.255
netname:        UNICOM-BJ
descr:          China Unicom Beijing province network
descr:          China Unicom
country:        CN
admin-c:        CH1302-AP
tech-c:         SY21-AP
mnt-by:         APNIC-HM
mnt-lower:      MAINT-CNCGROUP-BJ
mnt-routes:     MAINT-CNCGROUP-RR
mnt-irt:        IRT-CU-CN

GET / HTTP/1.1
Host: time.wiodows.com
Connection: close
User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/48.0.2564.116 Safari/537.36
Accept-Encoding: gzip
Accept-Language: zh-cn,zh-tw
Accept: */*
</code></pre><p><strong>Even stranger, shortly after the above request occurred, this happened!</strong> Baidu is one of China’s largest search engines. Keep in mind that I configured my DNS servers to resolve in wildcard mode. There is only a small number of ways Baiduspider could know that time.wiodows.com existed. Especially considering that only a single request had ever been made for this domain previously (seen above).</p><pre><code>GET / HTTP/1.1
Host: time.wiodows.com
Connection: close
User-Agent: Mozilla/5.0 (compatible; Baiduspider/2.0; +http://www.baidu.com/search/spider.html)
Accept-Encoding: gzip
Accept-Language: zh-cn,zh-tw
Accept: */*
</code></pre><h2 id="http-tcp-port-80-windowscomstopcode">HTTP tcp port 80 windows.com/stopcode</h2><p>When you get a blue screen of death on Windows, you are prompted to visit <a href="https://www.windows.com/stopcode">https://www.windows.com/stopcode</a>
Naturally, as the computer has crashed, they can’t just open the link. Most people would probably just scan the QR code, but those who misspell things ended up here.
<img src="https://remyhax.xyz/bitsquatting/bsod.png" alt="stopcode)"></p><pre><code>GET /stopcode HTTP/1.1
Host: wildows.com
Connection: keep-alive
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Linux; Android 5.0.1; ALE-L21) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.111 Mobile Safari/537.36
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: en-US,en;q=0.9
</code></pre><p>The following request was particularly interesting. Due to the nature of the request, I’m going to be very general with some details or censor entirely because it’s not exactly clear what’s going on.</p><p>An IP from somewhere in the range 113.96.0.0 - 113.111.255.255 (CHINANET-GD) makes a request from an android phone.</p><pre><code>GET /topode HTTP/1.1
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (Linux; Android 7.1.2; M6 Note Build/N2G47H; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/77.0.3865.120 MQQBrowser/6.2 TBS/045223 Mobile Safari/537.36 MMWEBID/9551 MicroMessenger/7.0.14.1660(0x27000E37) Process/tools NetType/4G Language/zh_CN ABI/arm64 WeChat/arm64 wechatdevtools
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9
Accept-Encoding: gzip, deflate
Accept-Language: en-US
Host: wintows.com
Via: 1.1 TENCENT64.site (squid/3.5.20)
X-Forwarded-For: &lt;Department of Defence IP&gt;
Cache-Control: max-age=259200
Connection: keep-alive
</code></pre><p>It would appear the some user in China is using <a href="http://www.squid-cache.org/">squid</a> to inject HTTP headers in every request originating in their network, including their mobile phone. Their computer gets a BSOD, so they try to look up the stopcode at windows.com/stopcode on their phone. They mis-type the url and end up at my server where we can see that they’re injecting an HTTP header for <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For">X-Forwarded-For</a> that attempts to make the request appear as if it originated from an IP belonging to the US Department of Defense.</p><p>When I looked up the source IP on <a href="https://greynoise.io/">GreyNoise</a> it showed that “This IP address has been opportunistically scanning the Internet, and has completed a full TCP connection. Reported activity could not be spoofed. This IP address has been observed by GreyNoise scanning the Internet on the following ports: 443 / TCP”</p><p>Seeing as how my traffic was recieved on 80 / TCP, this seems like it may be something they did not intend to do.</p><h2 id="http-tcp-port-80-windowscomfbclid">HTTP TCP port 80 …</h2></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://remyhax.xyz/posts/bitsquatting-windows/">https://remyhax.xyz/posts/bitsquatting-windows/</a></em></p>]]>
            </description>
            <link>https://remyhax.xyz/posts/bitsquatting-windows/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26338244</guid>
            <pubDate>Thu, 04 Mar 2021 03:24:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An app that gives you a random contact to text]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26337276">thread link</a>) | @hithereitsbrett
<br/>
March 3, 2021 | https://brettbejcek.com/out-of-the-blue | <a href="https://web.archive.org/web/*/https://brettbejcek.com/out-of-the-blue">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I am a <span data-period="4000" data-type="[ &quot; data scientist.&quot;, &quot; mind mapping enthusiast.&quot;, &quot; terrible singer.&quot;, &quot; scuba school dropout.&quot;, &quot; morning alarm snoozer.&quot;, &quot; cold brew addict.&quot;, &quot; pro at Wii bowling.&quot;]"><span></span></span></p><p><span>I live by my top values of <em><b> zest, curiosity </b></em> and <em><b> creativity</b></em>. At work, I develop predictive models, encode meaning into visualizations, and find insightful ways to blend qualitative with quantitative. Outside of work, I am an avid journaler, a side project connoisseur, and a coffee chat enthusiast. All thoughts are my own and do not represent clients or employers.</span></p></div></div>]]>
            </description>
            <link>https://brettbejcek.com/out-of-the-blue</link>
            <guid isPermaLink="false">hacker-news-small-sites-26337276</guid>
            <pubDate>Thu, 04 Mar 2021 01:08:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It Can Happen to You]]>
            </title>
            <description>
<![CDATA[
Score 1650 | Comments 401 (<a href="https://news.ycombinator.com/item?id=26337046">thread link</a>) | @mooreds
<br/>
March 3, 2021 | https://www.mattkeeter.com/blog/2021-03-01-happen/ | <a href="https://web.archive.org/web/*/https://www.mattkeeter.com/blog/2021-03-01-happen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<!-- End header -->



<h2>It Can Happen to You</h2>
<p>A few days ago, a <a href="https://nee.lv/2021/02/28/How-I-cut-GTA-Online-loading-times-by-70/">fascinating article</a>
about Grand Theft Auto Online
made the rounds of the tech news ecosystem.</p>
<p>I'd encourage you to read the whole thing, but in short,
GTA Online had <a href="https://accidentallyquadratic.tumblr.com/">accidentally quadratic</a>
performance when parsing a large JSON blob
(due to repeated calls to <code>strlen</code>);
fixing this improved loading time by almost 70%.</p>
<p>This sparked a <a href="https://news.ycombinator.com/item?id=26296339">great deal</a> of discussion:
Was this C's fault?
Perhaps <a href="https://twitter.com/Jonathan_Blow/status/1366452792563359744">"web shit"</a>?
<a href="https://twitter.com/fasterthanlime/status/1366187333507293184">Capitalism and incentives</a>?</p>
<p>Still, folks in the comments section generally agreed:
<em>they</em> wouldn't write anything that silly.</p>
<p>(<em>do you feel the foreshadowing?</em>)</p>
<hr>
<p>One of my side projects is a high-performance 3D viewer named <a href="https://www.mattkeeter.com/projects/erizo">Erizo</a>.</p>
<p><img src="https://www.mattkeeter.com/blog/2021-03-01-happen/porsche.png" alt="Porsche"></p>
<p>Thanks to a lot of careful programming, it will open a 97 MB binary STL
file in about 165 milliseconds flat, on a <em>2013</em> Macbook Pro.
This is <strong>blinding</strong> fast.</p>
<p>In the interest of compatibility, I wrote a small parser for
<a href="https://en.wikipedia.org/wiki/STL_(file_format)#ASCII_STL">ASCII STLs</a> as well.</p>
<p>ASCII STLs are a poorly-specified plain-text format that looks like this:</p>
<pre><code>solid cube_corner
          facet normal 0.0 -1.0 0.0
            outer loop
              vertex 0.0 0.0 0.0
              vertex 1.0 0.0 0.0
              vertex 0.0 0.0 1.0
            endloop
          endfacet
          facet normal 0.0 0.0 -1.0
            outer loop
              vertex 0.0 0.0 0.0
              vertex 0.0 1.0 0.0
              vertex 1.0 0.0 0.0
            endloop
          endfacet
          ...
endsolid
</code></pre>
<p>I wrote an extremely <a href="https://en.wikipedia.org/wiki/Robustness_principle">robust</a>
parser, described in a comment as</p>
<pre><code>/*  The most liberal ASCII STL parser:  Ignore everything except
 *  the word 'vertex', then read three floats after each one. */
</code></pre>
<p>Loading ASCII STLs always seemed a little slow, but I assumed
that's what you get for using an inefficient textual format.</p>
<p>(<em>foreshadowing intensifies</em>)</p>
<hr>
<p>Over the course of a few days, several things happened:</p>
<ul>
<li>I revisited Erizo for the first time in a few years to fix a <a href="https://github.com/mkeeter/erizo/commit/d4683f94a4aa0b674bdde0fa53fb6f92d6e1979c">focus issue on macOS</a></li>
<li>The GTA Online article was published</li>
<li>In a follow-up discussion, I learned that
<a href="https://news.ycombinator.com/item?id=26302744">parsing could be quadratic due to repeated calls to <code>sscanf</code></a></li>
<li>I noticed that ASCII STL loading was <em>really quite</em> slow.</li>
</ul>
<p>Here's the timestamped logs (in seconds), loading a 1.5 MB ASCII STL:</p>
<pre><code>[erizo] (0.000000) main.c:10      | Startup!
[erizo] (0.162895) window.c:91    | Created window
[erizo] (0.162900) window.c:95    | Made context current
[erizo] (0.168715) window.c:103   | Initialized GLEW
[erizo] (0.178329) window.c:91    | Created window
[erizo] (0.178333) window.c:95    | Made context current
[erizo] (1.818734) loader.c:109   | Parsed ASCII STL
[erizo] (1.819471) loader.c:227   | Workers have deduplicated vertices
[erizo] (1.819480) loader.c:237   | Got 5146 vertices (7982 triangles)
[erizo] (1.819530) loader.c:240   | Waiting for buffer...
[erizo] (1.819624) loader.c:326   | Allocated buffer
[erizo] (1.819691) loader.c:253   | Sent buffers to worker threads
[erizo] (1.819883) loader.c:258   | Joined worker threads
[erizo] (1.819887) loader.c:279   | Loader thread done
[erizo] (1.821291) instance.c:32  | Showed window
</code></pre>
<p>From startup to showing the window, it took over 1.8 seconds!</p>
<p>Looking at the ASCII parser with fresh eyes, the cause was glaringly obvious:</p>
<pre><code>    /*  The most liberal ASCII STL parser:  Ignore everything except
     *  the word 'vertex', then read three floats after each one. */
    const char VERTEX_STR[] = "vertex ";
    while (1) {
        data = strstr(data, VERTEX_STR);
        if (!data) {
            break;
        }

        /* Skip to the first character after 'vertex' */
        data += strlen(VERTEX_STR);

        for (unsigned i=0; i &lt; 3; ++i) {
            SKIP_WHILE(isspace);
            float f;
            const int r = sscanf(data, "%f", &amp;f);
            ABORT_IF(r == 0 || r == EOF, "Failed to parse float");
            if (buf_size == buf_count) {
                buf_size *= 2;
                buffer = (float*)realloc(buffer, buf_size * sizeof(float));
            }
            buffer[buf_count++] = f;

            SKIP_WHILE(!isspace);
        }
    }
</code></pre>
<p>You may notice <code>sscanf</code>, happily sitting there, reading a single float off
the front of the data stream and <strong>checking the length of the whole string each time</strong>.</p>
<p>Yes, I had made the exact same mistake as the programmers working on GTA Online:
I had an accidentally quadratic parser!</p>
<p>Replacing the <code>sscanf</code> call with <code>strtof</code> improved startup by nearly a factor of
10: from 1.8 seconds to 199 milliseconds.</p>
<pre><code>[erizo] (0.000000) main.c:10      | Startup!
[erizo] (0.178082) window.c:91    | Created window
[erizo] (0.178086) window.c:95    | Made context current
[erizo] (0.184226) window.c:103   | Initialized GLEW
[erizo] (0.194469) window.c:91    | Created window
[erizo] (0.194472) window.c:95    | Made context current
[erizo] (0.196126) loader.c:109   | Parsed ASCII STL
[erizo] (0.196866) loader.c:227   | Workers have deduplicated vertices
[erizo] (0.196871) loader.c:237   | Got 5146 vertices (7982 triangles)
[erizo] (0.196921) loader.c:240   | Waiting for buffer...
[erizo] (0.197013) loader.c:326   | Allocated buffer
[erizo] (0.197082) loader.c:253   | Sent buffers to worker threads
[erizo] (0.197303) loader.c:258   | Joined worker threads
[erizo] (0.197306) loader.c:279   | Loader thread done
[erizo] (0.199328) instance.c:32  | Showed window
</code></pre>
<p>This is back down in the noise of
"how long does the OS take to give us an OpenGL context",
which is a great place for a high-performance tool.</p>
<hr>
<p>As someone that has been programming for many years,
this was a perfectly-timed reminder that there are <em>always</em> pitfalls out there.
The <a href="https://en.cppreference.com/mwiki/index.php?title=cpp/io/c/fscanf&amp;oldid=125683">documentation for <code>sscanf</code></a>
does not include a time complexity,
so this is particularly tricky <a href="https://en.wiktionary.org/wiki/footgun">footgun</a>,
and I'm sure it's not the only one lurking in the darkness.</p>
<p>You may not get such a perfectly-timed reminder, but it's worth remembering –
next time you read a fascinating story about bad programming –
that it <em>can</em> happen to you!</p>
<p>(Obviously, the moral of the story is to not use <code>sscanf</code> to repeatedly
parse single tokens off the front of a string; I'm sure you'll do <em>fine</em>
if you can just avoid <strong>that</strong>)</p>
<hr>
<h2>Follow-up and related discussions</h2>
<ul>
<li><a href="https://news.ycombinator.com/item?id=26337046">Hacker News</a> (lots of discussion)</li>
<li><a href="https://lobste.rs/s/0obriy/it_can_happen_you">Lobste.rs</a>, including an <a href="https://lobste.rs/s/0obriy/it_can_happen_you#c_giuxfq">interesting survey</a> across different C libraries</li>
<li><a href="https://reviews.freebsd.org/D29007">Relevant FreeBSD patch</a></li>
<li><a href="https://sourceware.org/bugzilla/show_bug.cgi?id=17577"><code>glibc</code> bug tracker</a></li>
<li>The <a href="https://en.cppreference.com/w/cpp/io/c/fscanf">cppreference.com page for <code>sscanf</code></a> now mentions this pitfall</li>
</ul>

<!-- Begin footer -->
</div></div>]]>
            </description>
            <link>https://www.mattkeeter.com/blog/2021-03-01-happen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26337046</guid>
            <pubDate>Thu, 04 Mar 2021 00:37:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacker rewrote complex backend with Postgres and cron, CEO fired 40% of devs]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26336750">thread link</a>) | @samokhvalov
<br/>
March 3, 2021 | https://www.theolognion.com/hacker-hacks-into-startup-rewrites-complex-backend-with-postgresql-and-cron-forces-ceo-to-fire-40-of-devs-and-devops/ | <a href="https://web.archive.org/web/*/https://www.theolognion.com/hacker-hacks-into-startup-rewrites-complex-backend-with-postgresql-and-cron-forces-ceo-to-fire-40-of-devs-and-devops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://images.unsplash.com/photo-1562813733-b31f71025d54?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDR8fGhhY2tlcnxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 300w,
                            https://images.unsplash.com/photo-1562813733-b31f71025d54?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDR8fGhhY2tlcnxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 600w,
                            https://images.unsplash.com/photo-1562813733-b31f71025d54?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDR8fGhhY2tlcnxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 1000w,
                            https://images.unsplash.com/photo-1562813733-b31f71025d54?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDR8fGhhY2tlcnxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1562813733-b31f71025d54?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDR8fGhhY2tlcnxlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Hacker hacks into startup, rewrites complex backend with PostgreSQL and cron, forces CEO to fire 40% of devs and devops">
</figure>
<section>
<div>
<p>A hacker of unknown origins hacked into servers of Complify, a rapidly growing VC-funded startup. When Complify's security specialists noticed the breach, it was too late. However, unexpectedly, the hacker's actions did not seem to have been destructive in nature.</p><p>Apparently, the hacker rewrote complex backend architecture with a simple, single-node PostgreSQL instance and a bunch of cron jobs. This made the whole cluster of orchestrated containerized systems obsolete in one night. As a result, the CEO and the board of directors had no other choice but to let go 583 tech employees (nearly 40% of the workforce), as they now have literally nothing to do.</p><p>Alarmed, other startups in the industry are hiring more security specialists in order to reduce the risk of so-called <strong>"green-hat hacker"</strong> attacks.</p>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://www.theolognion.com/hacker-hacks-into-startup-rewrites-complex-backend-with-postgresql-and-cron-forces-ceo-to-fire-40-of-devs-and-devops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26336750</guid>
            <pubDate>Thu, 04 Mar 2021 00:06:55 GMT</pubDate>
        </item>
    </channel>
</rss>
