<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 10 Nov 2020 12:24:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 10 Nov 2020 12:24:50 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Migrating My Blog to Zola]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25024170">thread link</a>) | @todsacerdoti
<br/>
November 8, 2020 | https://mrkaran.dev/posts/migrating-to-zola/ | <a href="https://web.archive.org/web/*/https://mrkaran.dev/posts/migrating-to-zola/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<section>
    
    <article>
        <p>I've been writing on this blog for about 2 years now. This has been the longest I've stuck on to the same <em>technology stack</em> for my blog. I've previously jumped from a Jekyll based static site to a Medium blog before finally settling for <a href="https://gohugo.io/">Hugo</a>.</p>
<p>I've been using Hugo since 2018 but I don't recall as to <em>why</em> I went ahead with it. Maybe it was increasingly popular at that time and everyone touted Hugo as <em>the</em> solution to Static Site Generator (referred to as SSG from here on). There are 1000s of SSGs and at least a dozen of websites which lists all the SSGs out there. This is crazy by any standards. Hugo started as a generic blog generator but over the years it has become a <em>website generator</em>. It's no longer aimed at people who just want to have a small little static website/blog but supports all the use cases for people building full-fledged static websites. IMHO these two goals are overarching however this has resulted in a simple project to become incredibly complex over time.</p>
<h3 id="tipping-point">Tipping Point</h3>
<p>Anyway, so I wanted to change the look of the homepage on my website so I decided to look at Hugo's documentation. Hugo's documentation is great for someone who knows what exactly are they looking for. The documentation is so huge that you simply cannot grok it in one evening. I had zero ideas on how to customise the damn homepage of my blog and after spending hours buried in the documentation I was able to kind of figure the solution but it was unintuitive, to say the least. Apparently, to override any template from the theme, you have to mirror the directory structure of the theme in your root directory. Which meant, I needed to look at the source code of the theme, figure out the project structure, copy-paste all the folder names and put my override of <code>index.html</code> there. Which, BTW <strong>magically</strong> overrides it. This whole magic thing is BS and I am being strongly opinionated here.</p>
<p>There is more than one way to do something in Hugo. Different theme authors use different styles, which makes the whole thing even more complex. It also means for my customisations to work across themes, well you guessed it right: <strong>it's impossible</strong>.</p>
<p>Recently I discovered that I was unable to preview my Hugo website locally without internet because I had a Twitter <a href="https://gohugo.io/content-management/shortcodes/#tweet">shortcode</a> in one of my blog post (which makes an API call to Twitter to render a nice card preview). The site completely failed to render instead of just logging a warning. Bollocks.</p>
<p>The tipping point for me, however, was when the theme I was using stopped working with the latest version of Hugo at that point. So, picture this -- You make dozens of custom changes and then one update just <em>breaks</em> your website. Now not only you have to fix your shit but the theme you were using, you've to make upstream changes to the theme or maintain your own fork. And no, this is not a one-off experience. Hugo upgrades are a joke, they are known to break very very often.</p>
<p>I was done at this point. I didn't want to deal with this BS of continuously fighting the generator for my blog.</p>
<h3 id="a-fresh-change">A fresh change</h3>
<p>Being a practitioner of <a href="https://projects.csail.mit.edu/gsb/old-archive/gsb-archive/gsb2000-02-11.html">Yak Shaving</a>, I discussed the idea of a "tinyhugo" with <a href="https://nadh.in/">Kailash</a> and <a href="https://www.saratchandra.in/">Sarat</a>. We'd arrived at a spec and I started writing some code to pander to my NIH syndrome.</p>
<p>However, I was still not convinced that a simpler solution doesn't exist. I spent countless hours exploring other alternatives. I'd used <a href="https://www.getlektor.com/">Lektor</a>, <a href="https://blog.getpelican.com/">Pelican</a>, <a href="https://www.11ty.dev/">Eleventy</a> before finally stumbling upon <a href="https://www.getzola.org/">Zola</a> from HN/Lobster discussions. I've got to say, the landing page gave a <em>fresh</em> feeling - one that I've not seen with any other alternatives. In fact quite opposite to the Eleventy landing page which looks like an over-engineered piece of software to generate websites (Not hating on it, there might be use cases for it, but the JS tooling and dependency system is something that I would not want to touch with a 10ft pole).</p>
<p>Zola's primary appeal to me was that like Hugo it's extremely fast and comes as a single binary no dependency package. I looked at the docs the first impression was they are concise enough to get a basic idea. Zola is strongly opinionated, even to the extent of dictating a project structure and sometimes filenames too. I actually preferred this over the <em>magic</em> Hugo does. In less than 2 hours I was able to port the home page of my blog (and tweak it to my liking) in Zola. I decided to abandon my own <code>tinyhugo</code> attempt because for the very fact Zola fits my needs very well.</p>
<p>The thing that I really loved about Zola is how it enforces a separation between <a href="https://www.getzola.org/documentation/content/section/">Section</a> and <a href="https://www.getzola.org/documentation/content/page/">Pages</a>. The section represents a "collection" of posts. So a <em>blog</em> can be a section, and I can have another section called "Book Reviews". I could easily tell Zola where to look for the templates by specifying the same in <code>content/book_reviews/_index.md</code>. I don't have to read Hugo docs or do <em>Google-fu</em> to figure this out, it's right there in the docs and very apparent.</p>
<p>For the record, I still don't know how to customise different templates for different sections in Hugo, but I couldn't care less.</p>
<h3 id="migration">Migration</h3>
<p>The migration was pretty straightforward -- I had to copy the <code>content folder</code>s of my blog (which are just a bunch of <code>.md</code> fikes) and replace <code>YAML</code> frontmatter to <code>TOML</code>. There were a few variable changes that I needed to do manually but since they were a manageable 20-25 posts, I did it by hand. I could potentially automate but then rabbit deep in the rabbit hole of Yak Shaving. The good part was that I was able to retain the same URL structure for my new blog because the URL scheme was based on the file paths.</p>
<p>I spent some time porting <a href="https://github.com/knadh/hugo-ink">hugo-ink</a> to Zola and did minor CSS tweaks to it. Zola uses the Terra language for templating and it's much more pleasing to eyes than the Go Template syntax. Zola comes with pretty neat features like Search, RSS/Atom Feeds, Syntax Highlighting and SASS-&gt;CSS Processors.</p>
<p>What took me time however was to figure out how to get <code>opengraph</code> tags in each page. Hugo provides nifty <a href="https://github.com/gohugoio/hugo/blob/master/tpl/tplimpl/embedded/templates/opengraph.html">template</a> for this use case but Zola is pretty barebones like that. People who care a lot about SEO need to spend some extra efforts here.</p>
<h3 id="future">Future</h3>
<p>Zola is still a pretty new kid on the block but the author shares the same frustration about Hugo:</p>
<blockquote>
<p>it personally drives me insane, to the point of writing my own template engine and static site generator. Yes, this is a bit biased. -- <a href="https://github.com/getzola/zola#-explanations">Source</a></p>
</blockquote>
<p>This also reflects in the issues/PRs I've seen for Zola and the author is opinionated about not adding features which would make Zola complicated. Overall I am very happy with the switch and it was long due. I feel more confident in tweaking certain sections of my website. I plan to open-source the current theme in the next few days.</p>
<p>You can read the <a href="https://git.mrkaran.dev/karan/website">Source Code</a> of this website if you'd like to explore how this website is built.</p>
<p>Fin!</p>

    </article>
</section>
</article></div>]]>
            </description>
            <link>https://mrkaran.dev/posts/migrating-to-zola/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25024170</guid>
            <pubDate>Sun, 08 Nov 2020 08:39:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parsing the Infamous Japanese Postal CSV]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25023673">thread link</a>) | @polm23
<br/>
November 7, 2020 | https://www.dampfkraft.com/posuto.html | <a href="https://web.archive.org/web/*/https://www.dampfkraft.com/posuto.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Late last year I released <a href="https://github.com/polm/posuto">posuto</a>, a package presenting Japanese postal code
data in an easy-to-use format. It's based on <a href="https://www.post.japanpost.jp/zipcode/dl/kogaki-zip.html">data released by Japan
Post</a>, which is infamous for being widely used but hard to parse.</p>
<figure><a href="https://www.dampfkraft.com/by-id/806ae69c/postcharacter.png"><img src="https://www.dampfkraft.com/by-id/806ae69c/img/postcharacter.png.l.png"></a><figcaption>This adorable character by <a href="https://www.irasutoya.com/2019/08/blog-post_590.html">Irasutoya</a> is cute, but the raw postal CSV data is not.
</figcaption></figure>
<p>I first became aware of the postal data when I entered my postal code in an
online form and it auto-completed my address as "XXX-borough (except the
following buildings)". I had no idea what that parenthetical was referring to,
so I looked for a common source of postal data, found the CSV, and found the
issue.  It turns out the CSV file contains parenthetical notes for anyone
reading the CSV file and makes reference to the order of the rows.</p>
<p>This causes problems. The data is mainly useful one row at a time, where the
parenthetical is meaningless. Since CSV is a field-delimited format, there's
also no need for parentheticals - you could just add a note field.</p>
<p>This is only one of many issues with <code>ken_all.csv</code>. You can find people
complaining about it regularly <a href="https://twitter.com/search?q=ken_all.csv&amp;src=typed_query&amp;f=live">on Twitter</a>, and there was
even briefly <a href="http://ken-all.hatenadiary.com/">a blog</a> just collecting posts from all over the web
about it. A <a href="https://twitter.com/bulkneets/status/1259457777862184966">particularly amusing tweet</a> describes people who expect
computers to bend to the will of humans being punished in Hell by having to
parse <code>ken_all.csv</code> forever.</p>
<p>The <a href="https://www.post.japanpost.jp/zipcode/dl/readme.html">README</a> for the file explains that lines with overly long fields will be
broken up into multiple lines. Specifically, if the neighborhood name is over
38 characters, or if the half-width katakana (<em>half-width katakana</em>)
pronunciation field is over 76 characters, the line will be split into two
lines. The overly-long neighborhood field will be continued and all other
fields will be duplicated. This is an abbreviated sample of what that looks
like:</p>
<pre><code>12345,Tokyo,Minato,This place name is really
12345,Tokyo,Minato,very long it didn't fit in
12345,Tokyo,Minato,a single line so we had to 
12345,Tokyo,Minato,split it
</code></pre>
<p>The motivation for this is not explained. Maybe there was a fixed-width buffer
for storing a line somewhere thirty years ago. I used to process CSV and other
files from hundreds of different providers at an old job and I saw many
horrors, but I've never seen this particular formatting choice anywhere else.
It should also be noted that while the length limits are as stated, the
location where line breaks are inserted in long lines appears random, occurring
neither at the character limit nor at normal word boundaries.</p>
<p>It's worth noting not all the issues with the CSV are inherently technical;
postal codes are always complicated. The postal code with the most rows in the
CSV - a stunning 66 - is 〒452-0961, which refers to the <a href="https://ja.wikipedia.org/wiki/%E6%98%A5%E6%97%A5%E7%94%BA_(%E6%84%9B%E7%9F%A5%E7%9C%8C)">Haruhi region</a> of
Kiyosu City in Aichi Prefecture. This has that many lines because every
neighborhood gets a separate line. (This particular case may be related to Haruhi
having been the smallest town by area in Japan from 2006 until 2009, when it
was incorporated into Kiyosu City.)</p>
<p>In contrast, the longest <em>continued</em> line, using the line break rules above, is
the entry for 〒602-8368 or 〒602-8374, both with eight lines. These are both in
one of a few areas in Kyoto that uses <a href="https://en.wikipedia.org/wiki/Japanese_addressing_system#Kyoto">a unique, bizarre system of
intersection-based addressing</a>. The entry looks a bit like this:</p>
<pre><code>12345,Kyoto,Kyoto,"North Town (Up Lower Godsroad from"
12345,Kyoto,Kyoto,"the West, Down Turtle Street from the"
12345,Kyoto,Kyoto,"East, Up Old Temple Road from the"
12345,Kyoto,Kyoto,"West)"
</code></pre>
<p>I have used quoted fields here, but the actual CSV doesn't quote fields and
instead uses a different kind of comma.</p>
<p>There are other issues. There are catch-all postal codes for many areas, where
the neighborhood is given as "except the following", and the only thing to do
is look for that exact string and exclude it. There's a variety of similar
strings, and it's hard to be sure I've caught them all.</p>
<p>An example of another comment is 一円. Normally this would mean "one yen", but
it also means "the area surrounding", and is a note in the CSV that should be
removed from neighborhood names, <em>except</em> for exactly one neighborhood in Shiga where
that's actually the name (〒522-0317).</p>
<p>There's also a <a href="https://www.post.japanpost.jp/zipcode/dl/roman.html">separate romaji file</a> offered by JP Post. It's updated
less frequently than the main files, is often out of sync, and the provided
romaji are extremely low quality. For the moment I'm still providing the data
in posuto in the name of consistency, but honestly you should just use
<a href="https://www.dampfkraft.com/nlp/cutlet-python-romaji-converter.html">cutlet</a>. To give an example of bad romaji:</p>
<pre><code>大手町 JAビル
OTEMACHI JIEIEIBIRU
</code></pre>
<p>What's happening here is that "JA" is being converted to the phonetic reading
in Japanese, "ジェイエイ". Then ジェ, which is written "large ji small e" but
pronounced "je", is being converted to "jie" by treating the small character as
though it were large, and the other characters are translated as-is, turning
something already in the latin alphabet into alphabet soup. For contrast,
cutlet has no problem converting "JAビル" into "JA building" (case handling
admittedly needs some work still). Similar issues turn "Roppongi Hills" into
"Roppongihiruzu", and "Sweden Hills" into "Suedenhiruzu".</p>
<p>Anyway, dealing with the file was a humbling lesson in the amount of complexity
it's possible to pack into one place. I've glossed over many details, but you
can find them covered in posuto's README.</p>
<p>You can use <a href="https://github.com/polm/posuto">posuto</a> as a library, or if you're not using Python, just
download the pre-processed JSON and make use of that. If you find a good use
for it I'd be delighted to hear about it.</p>
<p>Oh, and if you need a Win3.1 or DOS program to copy the data onto an IBM H
floppy disk, just check the bottom of <a href="https://www.post.japanpost.jp/zipcode/dl/kogaki-zip.html">JP Post's page</a> - they've
got you covered. Ψ</p>
</div></div>]]>
            </description>
            <link>https://www.dampfkraft.com/posuto.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25023673</guid>
            <pubDate>Sun, 08 Nov 2020 06:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QR Codes Aren't Magic]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25022738">thread link</a>) | @allending
<br/>
November 7, 2020 | https://blog.snappymob.com/qr-codes-arent-actually-magic | <a href="https://web.archive.org/web/*/https://blog.snappymob.com/qr-codes-arent-actually-magic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Especially after COVID-19 began plaguing the planet, QR codes have been a big part of our daily lives. In this day and age, it’s quite impossible for one to have never seen a QR code, or used one. Even before the pandemic, QR codes had been around us for a while, but many of us — having grown up in the Digital Age — simply accept new technology into our lives without wondering too much about how they work. For most of us, QR codes just look like... square pixelated versions of the alien heptapod symbols in Arrival (2016), that somehow, magically (and really quickly) bring us to a different screen when we scan them.</p>
<!--more-->
<p>So what are these cryptic codes? Are they magic? Clearly they’re not, but how do they work? Before we take you in for the ride, let’s get the basics down.&nbsp;</p>
<p>QR stands for <em>Quick Response</em>, and a QR code is pretty much a barcode (which has been around since the 1950s) except two-dimensional. Because it’s 2D, it can contain more data than a barcode. It can encode over 7000 characters, which is a vast improvement from the standard barcode with a limited capacity of about 20 alphanumeric characters.</p>
<h2>How did they come about?&nbsp;</h2>
<p>In Japan circa 1990s, Denso Wave Incorporated was contacted by manufacturing sites and asked if it was possible to come up with a faster barcode scanning system. This presented a problem as barcodes had a limited capacity, which made the scanning process time consuming for workers no matter how efficient the scanner was. To tackle this, Denso Wave began developing a compact code that can contain more data, including Kanji and Kana characters. The launch of the QR code was later announced in 1994.</p>
<h2>What are they used for?</h2>
<p>The QR code was first used by the auto industry to track parts and products shipped around the globe. Then, gradually, other industries all over the world began joining in. Today, QR codes are used by nearly every physical and digital establishment for quick check-ins, displaying geolocation or contact info, redirecting customers to their websites, etc.</p>
<h2>How do they work?</h2>
<p>Grasping how a QR code works would require understanding the functions of its different parts. With the help of the labelled diagram, we hope to make this palatable for the layman. Let’s break it down.</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=715&amp;name=QR%20Structure.png" alt="QR Structure, modules, separators, alignment, timing, format info, version, labels, black and white" width="715" srcset="https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=358&amp;name=QR%20Structure.png 358w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=715&amp;name=QR%20Structure.png 715w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=1073&amp;name=QR%20Structure.png 1073w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=1430&amp;name=QR%20Structure.png 1430w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=1788&amp;name=QR%20Structure.png 1788w, https://blog.snappymob.com/hs-fs/hubfs/QR%20Structure.png?width=2145&amp;name=QR%20Structure.png 2145w" sizes="(max-width: 715px) 100vw, 715px"></p>
<p>(Image Source: techspot.com)</p>
<p>The tiny squares in a QR code are called <em><strong>modules</strong></em> - black squares would be considered foreground modules, and white ones would be background modules. They don’t always have to be black and white, though, they could be in color too. Most QR codes are in black and white only so decoder softwares easily distinguish the contrast between the background and foreground. If you want your QR code to be colorful, you just have to make sure that the contrast is retained when it is in grayscale / black and white.</p>
<p>The bigger the code, the more rows and columns of modules it will contain. Yup, just like humankind, QR codes come in different shapes, sizes and colors (although there are standards to follow).</p>
<p>There are 40 preset sizes (or, <em><strong>versions</strong></em>) to choose from. Version 1 being the smallest type with 21 rows and 21 columns, and Version 40 being the largest with 177 rows and 177 columns. When a generator produces a code for you, it will determine the suitable QR code version number for you depending on the amount of data you are encoding.</p>
<p>The 3 big squares on 3 corners of the QR code are <em><strong>finder patterns</strong></em>, which help your device camera determine the boundaries of the code and its correct orientation. This is so if the code is rotated, or upside-down, decoders would still be able to read it. These finder patterns are surrounded by a single-module spacing called <em><strong>separators</strong></em> which help decoders separate the finder patterns from the code data.</p>
<p>Connecting each finder pattern are <em><strong>timing patterns</strong></em> that alternate between black and white. These lines tell your decoder software how big the data cells are within the code.</p>
<p>The smaller square (that is distinctively not a finder pattern) on the fourth corner is an <em><strong>alignment pattern</strong></em> that helps the decoder prevent image distortions. Level 1 QR codes (the smallest size of QR codes) do not contain alignment patterns. The bigger the code, however, the more alignment patterns are added.&nbsp;</p>
<p>The 15 bits beside the separators are <em><strong>format and version strings</strong></em> which contain information on the code’s error correction level and the chosen mask pattern for the particular code. Hold on… information on the what and what?</p>
<p><em><strong>Error correction</strong></em> code makes sure that the code is still readable if up to 30% of the code is corrupt. Designers or generators of a code can decide how many levels of error correction they want to include in the code. The higher the level of error correction, the higher percentage of corruption a decoder can read past. However, the higher the level of error correction, the more space it takes up on the QR code, leaving less space for data. In other words, the more space the error correction code takes up, the lower the max numerical characters a QR code can fit. How much error correction a QR code needs probably will depend on where it will be displayed. E.g. A QR code on a paper flyer would need higher error correction than one on a laminated poster placed indoors, and a digital QR code could do with none because it is unlikely to be damaged.</p>
<p>The code is also overlaid by a <em><strong>mask pattern</strong></em>, inverting and retaining certain data areas to “mix it up” / conceal it. Decoder softwares detect the mask type from the format information and demask the QR code before reading the rest of the data. Of course this happens in a matter of milliseconds.</p>
<p><em><strong>Encoded characters </strong></em>- The black and white modules read in a fixed zigzaggy direction (as shown in the image), starting from the bottom right corner, gives the decoder a sequence of data bits that goes something like 001010111…&nbsp;&nbsp;&nbsp;</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=447&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png" alt="QR code, zigzag sequence, binary sequence, pattern" width="447" srcset="https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=224&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 224w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=447&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 447w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=671&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 671w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=894&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 894w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=1118&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 1118w, https://blog.snappymob.com/hs-fs/hubfs/Google%20Drive%20Integration/Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png?width=1341&amp;name=Copy%20of%20(Writeup)%20QR%20codes%20arent%20actually%20magic-2.png 1341w" sizes="(max-width: 447px) 100vw, 447px"><br>(Image Source: nayuki.io)</p>
<p>Different binary sequences represent different codewords, which include symbols, lowercase letters, uppercase letters, etc. For example, the binary sequence 01110111 represents the letter ‘w’, 00100001 represents the exclamation point ‘!’, and 00100000 represents a space.</p>
<h2><strong>How can you make a QR code?</strong></h2>
<p><span><img src="https://lh3.googleusercontent.com/Mi8ate-UiC0ZpKEoRFn8EUpe5bZDS5O6ggTSK96wPR1OTHx_zoKu_dbS5NvJDpPRsDAt9qdHXkQdfo1sm8Jun4Id0dpS3JjSnmOO51mXv6NT1ql7rb5P0DJc01k-kuw9RYw5vMF2" alt="QR code, generated QR code, snappymob website" width="297"></span></p>
<p>Here’s a QR code generated with <a href="http://www.qr-code-generator.com/"><span>www.qr-code-generator.com</span></a>. Do the patterns make a lot more sense to you now? If you can’t answer in confidence, that’s okay. You’re not going to have to make one by hand, ever. (Unless you want to.)&nbsp;</p>
<p>There are plenty of offline and online QR code generators free for use. All you have to do is key in what you want to encode in the QR code, be it a link to a coupon redemption page, a YouTube video, your social media sites, your contact details, or simply a website homepage.&nbsp;</p>
<p>Most free QR code generators, though, require you to sign up or subscribe to a plan to gain access to more design options and features, such as error correction levels and insights tracking.&nbsp;</p>
<h2><strong>How can QR codes help you?</strong></h2>
<p>Whether you own a business or simply have a web page to share, a QR code could help people reach you easily and quickly. In case you were looking for ideas, here are some of the ways in which using a QR code could greatly benefit you:</p>
<h4><strong>Webpages and Location</strong></h4>
<p>Your customers can get to your website, social media platforms, or map location in a matter of seconds. They don’t have to manually type your website URL, usernames, or addresses into their browsers or maps. They simply need to whip out their phones and scan the QR code to be redirected to you.</p>
<h4><strong>Payment</strong></h4>
<p>Payment is also made easy with QR codes. Most stores enable QR codes for quick payment via e-wallets so customers don’t have to fumble through their wallets for cash and keep others waiting. Some good examples would be GrabPay or ShopeePay, which are enabled at many on and offline merchants in Malaysia.</p>
<p><img src="https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=648&amp;name=grabpayshopeepay.jpg" alt="grabpay, shopeepay, qr code, merchant, scan to pay, app" width="648" srcset="https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=324&amp;name=grabpayshopeepay.jpg 324w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=648&amp;name=grabpayshopeepay.jpg 648w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=972&amp;name=grabpayshopeepay.jpg 972w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=1296&amp;name=grabpayshopeepay.jpg 1296w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=1620&amp;name=grabpayshopeepay.jpg 1620w, https://blog.snappymob.com/hs-fs/hubfs/grabpayshopeepay.jpg?width=1944&amp;name=grabpayshopeepay.jpg 1944w" sizes="(max-width: 648px) 100vw, 648px"><br>(Image Source: help.shopee.com.my, grab.com)</p>
<h4><strong>Email and Direct Messaging</strong></h4>
<p>You can embed URL links that lead straight to a ‘compose email’ or ‘compose direct message’ page (for instance, <a href="mailto:hello@snappymob.com">mailto:hello@snappymob.com</a>) into your QR code. For email, this saves your customers up to 10 seconds because it helps them skip the process of opening their email app, tapping on compose email, and typing your email address manually into the recipient bar. For social media, this saves them the effort of opening the app, typing your username into the search bar, and tapping on the message button. This might literally be “a matter of seconds” which seems small, but it keeps people who are interested in your services or products, well, interested. Making things quicker and easier for your patrons is always a good move.</p></span></p><p><label>app insights</label></p>
        
      </div></div>]]>
            </description>
            <link>https://blog.snappymob.com/qr-codes-arent-actually-magic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022738</guid>
            <pubDate>Sun, 08 Nov 2020 03:48:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stack Videos Horizontally, Vertically, in a Grid With FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25022665">thread link</a>) | @rrao84
<br/>
November 7, 2020 | https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" alt="stack videos using ffmpeg" title="stacking-videos" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/11/stacking-videos.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>Often times, when you want to compare two videos side-by-side or you want to create an effect during post-processing, you might want to stack videos together. It can get expensive if you end up buying a tool to do this, but, guess what? </p>



<p><strong>FFmpeg offers a variety of tools to help stack videos together – horizontally, vertically, or in a grid fashion. In this tutorial, let’s learn about FFmpeg’s <code>hstack</code> and <code>vstack</code> filters for stacking videos. </strong></p>



<hr>




<h2><span id="How_to_Stack_Videos_Horizontally_using_FFmpeg"></span><strong>How to Stack Videos Horizontally using FFmpeg?</strong><span></span></h2>



<p>“Horizontally stacking videos” refers to placing videos side-by-side (one on the left and the other on the right). </p>



<p>Before you do this, there are a couple of points that you need to consider. </p>



<ol><li>The videos that you want to stack need to have the same height. </li><li> The videos need to have the same pixel format. </li></ol>



<p>The command line is shown below where we try and stack two <code>mp4</code> videos. </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex hstack=inputs=2 horizontal-stacked-output.mp4</code></pre>



<p>The <code>hstack</code> filter has a simple format. You need to specify the number of inputs and it parses that from the beginning portion of the commandline. The order of stacking follows the order of inputs. </p>



<p>Here is a screenshot of what it looks like. </p>



<figure><img src="https://lh6.googleusercontent.com/4FwbqByqDpDpOGTNvpSWSOh6RVE9yzesrQyAyGvaOF1ZjVsycKOlQUjrTmdJRFJWblHjC9gF6zMds0s5w2Yy2w6CVXXme-H-zF8nYoJ496khN0aHXHaWbnwEe41BYmu6c2mdoQb8" alt="stack videos using ffmpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>And, here is a video! </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731721" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>







<p>Here is another use case. Companies or teams working on video compression often like to compare videos side-by-side in the lab or showcase their work in conferences. FFmpeg’s horizontal stacking is an easy way to do this and achieve a very good result. </p>



<p>Below are two videos encoded at different video quality settings and stacked horizontally. Comparison made simple, right? <em>(note: Vimeo’s choise of bitrate might mess with the comparison, but, when done offline (downloaded), the <code>hstack</code> filter makes comparisons easy!)</em></p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/476095363" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Stacking_Videos_Vertically_using_FFmpeg"></span><strong>Stacking Videos Vertically using FFmpeg</strong><span></span></h2>



<p>“Vertically stacked videos” results in placing videos one below the other. Unlike in horizontal stacking, inputs need to be having the same width. The command is as shown.&nbsp;</p>



<p>For vertical stacking, we need to use the <code>vstack</code> filter whose syntax is similar to the <code>hstack</code> filter we used in the previous horizontal stacking example.</p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4&nbsp;-filter_complex vstack=inputs=2 vertical-stack-output.mp4</code></pre>



<figure><img src="https://lh5.googleusercontent.com/qtyxioWFR54pqwZhX7jgX6HkSG7gCw840GdK78HGHHP7X3sv3fr3Pou9hOMFu2O-e6O7nmCith3U6CM1SpDanhwmIFIBzZUQyaG4T0BJaF9QCdMIPrmMmH0qc9WTK5f-5Nf4-92y" alt="stack videos using ffmpeg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>Both functions pretty much use the same commands with a simple distinction, the <a href="https://ffmpeg.org/ffmpeg-filters.html#hstack" target="_blank" rel="noopener"><code>hstack</code></a> and the <a href="https://ffmpeg.org/ffmpeg-filters.html#vstack" target="_blank" rel="noopener"><code>vstack</code></a> under the <code>-filter_complex</code> argument.&nbsp;</p>



<p>Here’s a video of stacking two videos vertically using FFmpeg. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731607" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Stacking_Videos_of_Different_Lengths"></span><strong>Stacking Videos of Different Lengths</strong><span></span></h2>



<p>Well, there’s a really nifty ability for both of these to prioritize the length of the shortest video. And as luck would have it the parameter is named <code>shortest</code>, and it’s applicable to both the horizontal and vertical stacking filters. Using <code>shortest=1</code> ensures the shortest length is used. </p>



<p>For example – </p>



<pre><code>ffmpeg -i input0.mp4 -i input1.mp4 -filter_complex hstack=inputs=2:shortest=1 shortest-output.mp4</code></pre>



<p>As a <b>side note</b>, if you run into an error that claims frames are being duplicated, the easiest workaround is to slip the <code>vsync 2</code> parameter into your command, and it worked like a charm.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_Without_the_shortest_parameter"></span>Stacking Videos of Different Lengths Without the <code>shortest</code> parameter<span></span></h3>



<p>To test what happens in this situation, let’s stack two videos vertically – a 10 second clip and an 18 second clip. You’ll see that the shorter clip just stops after it completes, but the output video continues till the longest of the input clips complete.  </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731684" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>











<p>If you want to truncate the clips to the length of the shortest clip, then you need to use the <code>shortest=1</code> parameter. Let’s look at that in the next section.</p>



<h3><span id="Stacking_Videos_of_Different_Lengths_With_the_shortest=1_parameter"></span>Stacking Videos of Different Lengths With the <code>shortest=1</code> parameter<span></span></h3>



<p>In this example, we use the <code>shortest=1</code> command-line parameter and as you can see, the length of the final video is truncated to the length of the shortest of the inputs. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475731643" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="2%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong><strong>2×2 Grid of Videos using FFmpeg</strong></strong><span></span></h2>



<p>We can achieve a 2×2 grid of videos using a combination of the <code>hstack</code> and <code>vstack</code> filters. Let’s start by looking at the command-line and then break it down. It’s actually pretty simple! </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 -i input2.mp4 -i input3.mp4 \
-filter_complex \
"[0:v][1:v]hstack=inputs=2[top]; \
[2:v][3:v]hstack=inputs=2[bottom]; \
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>



<p>What’s happening here?</p>



<ul><li>firstly, you need to provide 4 input videos with the same height and width</li><li>next, you stack the first two videos horizontally and call it “top” i.e. <code>[0:v][1:v]hstack=inputs=2[top]</code></li><li>then, you you stack the next two videos horizontally and call it “bottom” i.e. <code>[2:v][3:v]hstack=inputs=2[bottom]</code></li><li>then, you stack <code>top</code> and <code>bottom</code> vertically to create a 2×2 grid. — <code>[top][bottom]vstack=inputs=2[v]</code></li><li>then using the <code>map</code> command, we can extract and push the video track to the output container. </li></ul>



<p>Here is what the video looks like. </p>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475771172" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="3%C3%972_Grid_of_Videos_using_FFmpeg"></span><strong>3×2 Grid of Videos using FFmpeg</strong><span></span></h2>



<p>Along the same lines, here is a 3×2 grid of videos using <code>hstack</code> and <code>vstack</code> filters. </p>



<pre><code>ffmpeg \
-i input0.mp4 -i input1.mp4 \
-i input2.mp4 -i input3.mp4 \
-i input4.mp4 -i input5.mp4 \
-filter_complex \
"[0:v][1:v][2:v]hstack=inputs=3[top];\
[3:v][4:v][5:v]hstack=inputs=3[bottom];\
[top][bottom]vstack=inputs=2[v]" \
-map "[v]" \
finalOutput.mp4</code></pre>



<p><iframe frameborder="0" allow="autoplay; fullscreen" allowfullscreen="" data-src="https://player.vimeo.com/video/475780643" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>



<hr>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>That’s it folks. Now you know how to stack videos together horizontally, vertically, and in a grid. This is very useful in comparing videos and also creating fun effects along the way! </p>



<p>If you enjoyed this post, do check out the rest of<a href="https://ottverse.com/category/ffmpeg/"> <strong>OTTVerse’s FFmpeg tutorials</strong></a> to learn more about this amazing media editing and compression software!  </p>

	</div></div>]]>
            </description>
            <link>https://ottverse.com/stack-videos-horizontally-vertically-grid-with-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25022665</guid>
            <pubDate>Sun, 08 Nov 2020 03:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remote Work: How the alternative has become the new norm]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25021471">thread link</a>) | @martin_crd
<br/>
November 7, 2020 | https://remoteworkers.net/blog/remote-work-how-alternative-has-become-new-norm | <a href="https://web.archive.org/web/*/https://remoteworkers.net/blog/remote-work-how-alternative-has-become-new-norm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The debate on the impact telework has on employee productivity &amp; morale is one that has slowly aged with the improvement of technology, but never so important to discuss than in the current global pandemic state the world is faced with.</p><p>For decades the working class has enjoyed, and even thrived in the conventional 9-to-5 office workday with very little contention. In fact, most of the well-known productivity techniques are centered around the premise that employees can only maximize team cohesion &amp; communication when working in a controlled work environment like the office.</p><p>But with the rise of the digital age and need to travel, the world has started to realize the value and need for remote work and set in place internal measures to promote alternative work methods that benefit the workforce.<br>
&nbsp;</p><h2>Reimagining the 9-to-5 workday could improve productivity</h2><p>The contemporary 9-to-5, eight-hour workday was imagined by American labor unions in the 1800s and normalized by Henry Ford in the 1920s. Most employees today simply accept this narrative because it’s what they have gotten so acquainted with. But despite the growing popularity in the demand for remote and flexible work, the need for a change in work culture has been met with much skepticism from managers. A recent study conducted by Remote Workplace Study explores the prime obstacles to implementing a flexible workplace policy:&nbsp;</p><ul><li>Company’s long-standing resistance to change &nbsp;</li><li>Privacy</li><li>Lack of understanding about the benefits of remote work</li><li>Fear of how it will impact the overall company culture</li><li>Technology requirements</li><li>Data security</li></ul><p>Understandably, managers have reservations about changing traditional work culture. Most concerns center around losing control of assessing team cohesiveness and potential reduction in employee productivity &amp; focus. But despite this, change is inevitable. In fact, most studies confirm an increase in productivity, working “smarter” and willingness to work over-time when employees are given the flexibility to choose when and how to work.&nbsp;</p><h2>Millennials are driving the demand for flexible and remote work&nbsp;</h2><p>As of today, millennials (those born between 1981 and 1996) account for almost 50% of the global workforce and are expected to grow to 75% by 2025. This means that the need for companies to adopt flexible and remote work policies is more compelling today than ever before in order to attract and retain a younger, skilled workforce.&nbsp;</p><h2>There are equal benefits to jumping on the remote-work bandwagon for both companies and employees:</h2><p>There are equal benefits to jumping on the remote-work bandwagon for both companies and employees:</p><h3>For Companies</h3><ul><li>Cost savings (office &amp; overhead costs)</li><li>Increase in productivity</li><li>Employee retention &amp; reduced turnover</li><li>Profitability (companies save avg. $11, 000 &nbsp;per part-time telecommuter)</li><li>Environmental benefits (less commuting to work reduces carbon footprint)</li><li>Improved inclusivity and diversity (easier reach and accessibility to skilled talent from different demographics, races, and people with disabilities from all over the world)</li></ul><h3>For Employees</h3><ul><li>Improved work-life balance</li><li>Flexible schedule</li><li>No commute (time and cost savings)</li><li>Location independence (work from home/travel while working)</li><li>More time to spend with family</li><li>Expense savings (transportation, gas, &amp; freedom &nbsp;to live in low-cost cities) &nbsp;</li></ul><h2>The world’s largest firms have endorsed remote working policies in the wake of Covid19</h2><p>It’s no secret that the novel Coronavirus pandemic has played an integral role in the sudden surge of remote work policies implemented across companies worldwide. Big corporations such as Twitter, Facebook, Google, Amazon, &amp; Microsoft have adopted such changes with Twitter and Square CEO Jack Dorsey announcing that his employees can work remotely indefinitely.&nbsp;</p><blockquote><p>“... the work-from-home revolution is shaping the future of the workplace.”</p></blockquote><p>Improved inclusivity and diversity (easier reach and accessibility to skilled talent from different demographics, races, and people with disabilities from all over the world)</p><p>In closing, albeit reservations from conservative and outdated work practices, the future of the work environment is remote and flexible work. In the age of the internet, connecting with skilled professionals has become easier and accessible. Thanks to online professional platforms like remoteworkers.net, companies have access to a wider pool of highly experienced talent and job-seekers can find their ideal remote jobs. Companies would be wise to evolve with the growth in remote work trends in order to become more competitive &amp; improve productivity.</p><h2>Looking for a remote job?</h2><p>Thanks to the internet, connecting skilled professionals with remote-friendly companies has never been easier. Whether you’re an experienced professional looking for your dream remote job or a remote-friendly company looking to hire the best talent, join <a href="https://remoteworkers.net/signup">Remote Workers</a>&nbsp;today!&nbsp;</p></div></div>]]>
            </description>
            <link>https://remoteworkers.net/blog/remote-work-how-alternative-has-become-new-norm</link>
            <guid isPermaLink="false">hacker-news-small-sites-25021471</guid>
            <pubDate>Sun, 08 Nov 2020 00:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A prerecorded message from Richard Stallman]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25020937">thread link</a>) | @billyjobob
<br/>
November 7, 2020 | https://peertube.qtg.fr/videos/watch/d4aab174-50ca-4455-bb32-ed463982e943 | <a href="https://web.archive.org/web/*/https://peertube.qtg.fr/videos/watch/d4aab174-50ca-4455-bb32-ed463982e943">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://peertube.qtg.fr/videos/watch/d4aab174-50ca-4455-bb32-ed463982e943</link>
            <guid isPermaLink="false">hacker-news-small-sites-25020937</guid>
            <pubDate>Sat, 07 Nov 2020 23:37:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Get Good at Chess, Fast (2013)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25020036">thread link</a>) | @spekcular
<br/>
November 7, 2020 | https://www.gautamnarula.com/how-to-get-good-at-chess-fast/ | <a href="https://web.archive.org/web/*/https://www.gautamnarula.com/how-to-get-good-at-chess-fast/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Edit: This article on chess improvement was unexpectedly popular, reaching #2 on Hacker News and being linked to on LifeHacker. Thanks for your patience as I work through all the comments and emails I receive.<br>
</em></p>
<p>Last updated: October 1, 2020</p>
<p>There are many misconceptions about rapid chess improvement. In this post I’m going to lay out a simple but effective way to get good at chess, fast.</p>
<p>This system is based on lessons learned from my own chess improvement and from coaching others. The good news is that you can become better than the vast majority of other players with minimal but targeted effort.</p>
<p><b>What does it mean to be “good” at chess? </b></p>
<p><span><span><a href="https://en.wikipedia.org/wiki/Magnus_Carlsen">Magnus Carlsen’s</a></span></span> meteoric rise to the top ranked player in the world (at age 19), the highest chess rating in history (age 22), and as of a few days ago, the title of World Chess Champion (age 22) has brought with it a renewed interest in chess. This is exciting, because Carlsen represents the first real hope of renewing chess’s mass appeal since the days of <span><span><a href="https://en.wikipedia.org/wiki/Bobby_Fischer">Bobby Fischer</a></span></span><sup>1</sup>.</p>
<p>In the context of discussions about Magnus Carlsen, many people mentioned that they enjoyed playing chess but quit because of the sheer time commitment it took to get “good.”</p>
<p>I define “good” as the 90<sup>th</sup> percentile among the player pool you’re competing against. In competitive chess in the United States, that means a United States Chess Federation (USCF) <span><span><a href="https://en.wikipedia.org/wiki/Elo_rating">Elo rating</a></span></span> of about 1800<sup>2</sup>. If you’re a casual player playing against your friends, my guess is that 90<sup>th</sup> percentile is around 900. Even though I was only rated 1100 when I first began playing competitively, I was already able to beat the vast majority of non-competitive players.</p>
<p>The goal here is to help you get good, fast, with minimal effort.</p>
<p><b>Results with this system</b></p>
<p>I actively trained for a period of about 3.5 years using a (much, much less disciplined) version of this system, during which my rating increased from 1100 to 1950, a 135 fold increase I strength<sup>3</sup>. In one 12 month period I improved from 1198 to 1639. I improved even faster with my quick rating (games with less than 30 minutes per side), where I went from 1001 to 1740 in 15 months (75 fold increase in playing strength).</p>
<p>My first experience using these ideas with other players was in high school, when I began coaching the lowest ranked player in our chess club. Within a few months he had improved so rapidly that he represented the school in the state championships and won every single game in the tournament.</p>
<p>Given that I managed to do this despite my own inexperience and mistakes with studying chess and my own laziness, I’m convinced others can improve much more quickly if they follow this system strictly<sup>4</sup>.</p>
<p><b>The system</b></p>
<p>Since this article is meant for both casual and competitive players, I specify minimum rating requirements when appropriate. If you’re a casual player and this is overkill for your goals, skip to the footnotes for a much simpler system<sup>5</sup>.</p>
<p><span>Playing</span></p>
<p>To improve quickly you need to play often. If you are (or aspire to be) a competitive player, play as many over-the-board (OTB) tournaments as possible. In my heyday I played 3-4 tournaments per month. Online is not enough! Use online games (15 minutes per side or slower) to practice openings or for practice if there is no tournament for a while. If you’re a casual player, play OTB chess with your friends as much as you can, and play online if nobody wants to play with you.</p>
<p>Since I first wrote this post, I’ve received a fair number of questions asking why OTB chess is so important and why online-only is insufficient. IM Andras Toth has <a href="https://www.youtube.com/watch?v=_kmdFbyWiTY">an excellent discussion</a> of this topic that explains it better than I could&nbsp; (his channel is also chronically underrated–I highly recommend checking his other videos out!).</p>
<p><span>Tactics</span></p>
<p>I did two types of tactics training. The first was “Chess Vision” and “Knight Sight” exercises, as described in <span><a href="http://www.masschess.org/Chess_Horizons/Articles/2001-01_Sample_400_Points_Part_1.pdf">this article</a></span>. They may sound stupid, but they work. I did these exercises every day for two weeks initially, and then would do them the day of a tournament and once in a while as a refresher.</p>
<p>My primary method of tactics training was using <a href="https://www.amazon.com/gp/product/B004U0YZ0M/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B004U0YZ0M&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=Y76EOXPI5OJF2DV4">Chess Tactics for Beginners</a>, which is absolutely fantastic. Since it may have compatibility issues with modern OSes, a good alternative is CT Art 4.0 available for both <a href="https://play.google.com/store/apps/details?id=com.chessking.android.learn.ctart4&amp;hl=en_US">Android</a> and <a href="https://apps.apple.com/us/app/ct-art-4-0-chess-tactics/id1132601225">iOS</a>.</p>
<p><a href="https://www.amazon.com/gp/product/B004U0YZ0M/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B004U0YZ0M&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=J7V5XFOTBIDIIG2C" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i1.wp.com/ecx.images-amazon.com/images/I/6105Zn3iBeL._SL1000_.jpg?resize=278%2C278&amp;ssl=1" alt="" width="278" height="278" data-recalc-dims="1"></a></p>
<p>If you only buy one thing to help your chess game, this should be it. I did 50 puzzles per day, every day, and once I finished the entire CD I repeated the process six more times. Online tactics sites usually don’t cut it, because they aren’t structured so that you learn based off previous ideas and many don’t incorporate the pedagogical features of Chess Tactics for Beginners/CT Art 4.0. Trust me, paying for the software is worth it.</p>
<p>If I had to recommend a book to accompany such study (which is helpful, since the above software doesn’t actually have any explanatory text), I’d recommend <a href="https://www.amazon.com/gp/product/1889323276?ie=UTF8&amp;camp=1789&amp;creativeASIN=1889323276&amp;linkCode=xm2&amp;tag=gautnaru-20" target="_blank" rel="noopener noreferrer">Chess Tactics for the Tournament Player </a>for intermediate players, and <a href="https://www.amazon.com/gp/product/1857443861/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1857443861&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=7ALJB5A3ECUHWDEW" target="_blank" rel="noopener noreferrer">Winning Chess Tactics</a> for less experienced players.</p>
<p><a href="https://www.amazon.com/gp/product/1889323276?ie=UTF8&amp;camp=1789&amp;creativeASIN=1889323276&amp;linkCode=xm2&amp;tag=gautnaru-20">&nbsp;&nbsp;&nbsp; </a><a href="https://www.amazon.com/gp/product/1889323276?ie=UTF8&amp;camp=1789&amp;creativeASIN=1889323276&amp;linkCode=xm2&amp;tag=gautnaru-20" target="_blank" rel="noopener noreferrer"><img loading="lazy" id="imgBlkFront" src="https://i1.wp.com/ecx.images-amazon.com/images/I/51zU34AQ%2BOL._SX323_BO1,204,203,200_.jpg?resize=290%2C445&amp;ssl=1" alt="" width="290" height="445" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51zU34AQ%2BOL._SY344_BO1,204,203,200_.jpg&quot;:[226,346],&quot;http://ecx.images-amazon.com/images/I/51zU34AQ%2BOL._SX323_BO1,204,203,200_.jpg&quot;:[325,499]}" data-recalc-dims="1"></a><a href="https://www.amazon.com/gp/product/1857443861/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1857443861&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=7ALJB5A3ECUHWDEW" target="_blank" rel="noopener noreferrer"> &nbsp; &nbsp;&nbsp; <img loading="lazy" id="imgBlkFront" src="https://i0.wp.com/ecx.images-amazon.com/images/I/51ISp9Y-ATL._SX398_BO1,204,203,200_.jpg?resize=322%2C403&amp;ssl=1" alt="" width="322" height="403" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51ISp9Y-ATL._SX258_BO1,204,203,200_.jpg&quot;:[260,325],&quot;http://ecx.images-amazon.com/images/I/51ISp9Y-ATL._SX398_BO1,204,203,200_.jpg&quot;:[400,500]}" data-recalc-dims="1"></a></p>
<p>I’ll admit, there is a bit of a leap between solving tactics puzzles and applying it to real games–obviously nobody’s going to tell you when a tactic is available, and you won’t be “primed” to find tactics the way you would be when solving a bunch of puzzles. To counteract this I created a binder of puzzles taken from tactics I missed in my games, and reviewed them from time to time.</p>
<p><span>Analysis</span></p>
<p>Analysis is by far the most undervalued part of chess training. As a kid I barely analyzed my games after tournaments, because I was lazy. This was a huge mistake—your games are worth their weight in gold! Learn <span><span><a href="https://en.wikipedia.org/wiki/Algebraic_notation_(chess)">algebraic chess notation</a></span></span> so you can write down your moves, and analyze your games using the method outlined in <span><span><a href="https://www.chess.com/blog/CharlyAZ/a-hardcore-guide-to-analyze-your-chess-games">this article</a></span></span>. Use the analysis phase to brush up on your openings and endgames and practice your strategic play. If possible, have a stronger player go over your games with you after you’ve done your own analysis.</p>
<p>One big mistake is to rely heavily on computers for chess analysis. Too often, players use computers as a crutch to replace their own study of the game. Working through games on your own and trying to find the best moves and ideas is highly instructive. Computer analysis should be done only after you analyze the game on your own, so you can compare your analysis to the computer’s and unearth any mistakes you made in assessing critical positions in the game.</p>
<p><span>Openings</span><b> </b></p>
<p>One of the biggest mistakes players make is to devote massive amounts of time to openings. This is because openings tend to be very concrete, and beginners think that simply memorizing an opening will give them an unassailable advantage over their opponents<sup>6</sup>.</p>
<p>Don’t bother spending any time studying openings outside of analyzing your games. Just make sure you know the basic opening principles. I teach my beginning students simple openings like the <span><span><a href="https://en.wikipedia.org/wiki/London_System">London System </a></span></span>as white, and a kingside fianchetto system as black<sup>7</sup>. These openings are simple, solid, can be played against virtually anything.</p>
<p>Once you hit 1600, get a good opening book that gives you both specific moves and the ideas behind the opening. Don’t mindlessly memorize!</p>
<p><em>Openings for White</em></p>
<p>If you’re a d4 player, I highly recommend Cox’s <a href="https://www.amazon.com/gp/product/1857444175/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857444175&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=STJDQXBM7GK6XYNM" target="_blank" rel="noopener noreferrer">Starting Out: 1. d4!</a><sup>8</sup>. An offbeat alternative is Summerscale’s <a href="https://amzn.to/36pGkPS">A Killer Chess Opening Repertoire</a>.</p>
<p>If you’re an e4 player it gets a bit trickier. The truth is, e4 is simply harder to play than d4 because it’s a lot easier to get in trouble if you don’t play precisely. This makes finding a single volume repertoire book a bit more challening, but here are some options:</p>
<ul>
<li>Alburt’s<a href="https://www.amazon.com/gp/product/1889323209/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1889323209&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=AF3LPY4VTPCU6ID3"> Chess Openings for White, Explained.</a> I haven’t personally used it, and I’ve heard some reasonable criticism around some of the lines chosen, but I think for most players it’ll probably be a good starting point.</li>
<li>Emms’s <a href="https://www.amazon.com/gp/product/B00ZA2DM12/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=B00ZA2DM12&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=dcee712605ab0911a0fafd2bf00b1532">Attacking with 1. e4</a> is a book I have used and enjoyed during my forays as an e4 player.</li>
</ul>
<p>If you’re a c4 player, you’ll have to do some research on your own to find a good repertoire book. Being a hipster has its downsides.</p>
<p><em>Openings for Black</em></p>
<ul>
<li>Alburt’s <a href="https://www.amazon.com/gp/product/1889323187/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1889323187&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=PBISMJGJT42NGJX6">Chess Openings for Black, Explained</a> is a great book.</li>
</ul>
<p><a href="https://www.amazon.com/gp/product/1857444175/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857444175&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=STJDQXBM7GK6XYNM"> &nbsp;&nbsp; </a><a href="https://www.amazon.com/gp/product/1857444175/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857444175&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=STJDQXBM7GK6XYNM" target="_blank" rel="noopener noreferrer"><img loading="lazy" id="imgBlkFront" src="https://i1.wp.com/ecx.images-amazon.com/images/I/51qe4nRkrzL._SX329_BO1,204,203,200_.jpg?resize=300%2C452&amp;ssl=1" alt="" width="300" height="452" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51qe4nRkrzL._SX329_BO1,204,203,200_.jpg&quot;:[331,499],&quot;http://ecx.images-amazon.com/images/I/51qe4nRkrzL._SY344_BO1,204,203,200_.jpg&quot;:[230,346]}" data-recalc-dims="1"></a><a href="https://www.amazon.com/gp/product/1889323187/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1889323187&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=PBISMJGJT42NGJX6"> &nbsp;&nbsp; &nbsp; &nbsp; </a><a href="https://www.amazon.com/gp/product/1889323187/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1889323187&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=PBISMJGJT42NGJX6" target="_blank" rel="noopener noreferrer"><img loading="lazy" id="imgBlkFront" src="https://i1.wp.com/ecx.images-amazon.com/images/I/515HExt56YL._SX331_BO1,204,203,200_.jpg?resize=306%2C459&amp;ssl=1" alt="" width="306" height="459" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/515HExt56YL._SX331_BO1,204,203,200_.jpg&quot;:[333,499],&quot;http://ecx.images-amazon.com/images/I/515HExt56YL._SY344_BO1,204,203,200_.jpg&quot;:[231,346]}" data-recalc-dims="1"></a></p>
<p>Obviously this depends on your opening preferences. Even here openings should not be your main focus. I only consult these books when analyzing my games to see where I deviated from established opening theory, occasionally supplemented by a chess database if there’s a line not covered in the book or I’d like to go more in-depth.</p>
<p>And if your first thought is, “Gautam, one of those books was published in 2006! I’ll be using outdated opening theory!” then I’m afraid you’re missing the point. If you’re below master or even International Master level, playing what world champions played in 2006 rather than what they played in 2020 will <em>never</em> be the reason you lose a game. Ever. That simply is not your bottleneck, and the time invested to try to constantly keep up with the latest won’t result in any rating gains.</p>
<p><span>Strategy<br>
</span></p>
<p>Until you hit 1400-1500, you should be picking up strategic play from analyzing your games and going over annotated games. Once you hit that level, I recommend Silman’s <a href="https://www.amazon.com/gp/product/1890085022/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1890085022&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=5GKXCF6U4LWI7Y24" target="_blank" rel="noopener noreferrer">The Amateur’s Mind</a> and Seirawan’s <a href="https://www.amazon.com/gp/product/1857443853/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857443853&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=V5IEYHJJ5PL3FC6Q" target="_blank" rel="noopener noreferrer">Winning Chess Strategies.&nbsp;</a></p>
<p><a href="https://www.amazon.com/gp/product/1890085022/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1890085022&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=5GKXCF6U4LWI7Y24">&nbsp;&nbsp; </a><a href="https://www.amazon.com/gp/product/1890085022/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1890085022&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=5GKXCF6U4LWI7Y24" target="_blank" rel="noopener noreferrer"><img loading="lazy" id="imgBlkFront" src="https://i0.wp.com/ecx.images-amazon.com/images/I/51EZ9QBPN9L._SX340_BO1,204,203,200_.jpg?resize=284%2C415&amp;ssl=1" alt="" width="284" height="415" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51EZ9QBPN9L._SY344_BO1,204,203,200_.jpg&quot;:[237,346],&quot;http://ecx.images-amazon.com/images/I/51EZ9QBPN9L._SX340_BO1,204,203,200_.jpg&quot;:[342,499]}" data-recalc-dims="1"></a><a href="https://www.amazon.com/gp/product/1857443853/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857443853&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=V5IEYHJJ5PL3FC6Q" target="_blank" rel="noopener noreferrer">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img loading="lazy" id="imgBlkFront" src="https://i2.wp.com/ecx.images-amazon.com/images/I/51O9bBRKCzL._SX392_BO1,204,203,200_.jpg?resize=324%2C410&amp;ssl=1" alt="" width="324" height="410" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51O9bBRKCzL._SX258_BO1,204,203,200_.jpg&quot;:[260,329],&quot;http://ecx.images-amazon.com/images/I/51O9bBRKCzL._SX392_BO1,204,203,200_.jpg&quot;:[394,499]}" data-recalc-dims="1"></a></p>
<p>Once you hit 1800, <a href="https://www.amazon.com/gp/product/1890085138/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1890085138&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=2TUB27GQ6MOMAYRT" target="_blank" rel="noopener noreferrer">Silman’s Reassess Your Chess, Fourth Edition</a>.</p>
<p><a href="https://www.amazon.com/gp/product/1890085138/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1890085138&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=2TUB27GQ6MOMAYRT" target="_blank" rel="noopener noreferrer"><img loading="lazy" id="imgBlkFront" src="https://i2.wp.com/ecx.images-amazon.com/images/I/51luxFAgz6L._SX348_BO1,204,203,200_.jpg?resize=350%2C499&amp;ssl=1" alt="" width="350" height="499" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51luxFAgz6L._SX348_BO1,204,203,200_.jpg&quot;:[350,499],&quot;http://ecx.images-amazon.com/images/I/51luxFAgz6L._SY344_BO1,204,203,200_.jpg&quot;:[243,346]}" data-recalc-dims="1"></a></p>
<p><span>Endgame</span></p>
<p>After learning the basic checkmates (King and Queen vs. King, King and Rook vs. King, etc.), <a href="https://www.amazon.com/gp/product/1890085103/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1890085103&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=B7XX3NKSQ3PENDNU" target="_blank" rel="noopener noreferrer">Silman’s Complete Endgame Course</a> is the only book you need. Study the appropriate section based on your rating, and only come back to it if it’s clear that you keep messing up endgames.</p>
<p><a href="https://www.amazon.com/gp/product/1890085103/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1890085103&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=B7XX3NKSQ3PENDNU" target="_blank" rel="noopener noreferrer"><img loading="lazy" src="https://i0.wp.com/d.gr-assets.com/books/1348296214l/83337.jpg?resize=280%2C400&amp;ssl=1" alt="" width="280" height="400" data-recalc-dims="1"></a></p>
<p><span>Annotated Games</span></p>
<p>Go over at least one annotated game a week (and more frequently if you’re a serious competitive player). A good annotated game book is <a href="https://www.amazon.com/gp/product/1857443470/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857443470&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=SWT4HHD4X4F3H2XB" target="_blank" rel="noopener noreferrer">Winning Chess Brilliancies</a> by Seirawan. I hear the <a href="https://www.amazon.com/gp/product/0762439955/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0762439955&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=MOTVUMZGF5OZXYD5" target="_blank" rel="noopener noreferrer">Mammoth Book of the World’s Greatest Chess Games</a> is pretty good too, but I can’t personally vouch for it.</p>
<p><a href="https://www.amazon.com/gp/product/1857443470/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857443470&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=SWT4HHD4X4F3H2XB">&nbsp; &nbsp; &nbsp; </a><a href="https://www.amazon.com/gp/product/1857443470/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=1857443470&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=SWT4HHD4X4F3H2XB" target="_blank" rel="noopener noreferrer"><img loading="lazy" id="imgBlkFront" src="https://i1.wp.com/ecx.images-amazon.com/images/I/51s0ZaO0WDL._SX399_BO1,204,203,200_.jpg?resize=310%2C387&amp;ssl=1" alt="" width="310" height="387" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51s0ZaO0WDL._SX258_BO1,204,203,200_.jpg&quot;:[260,324],&quot;http://ecx.images-amazon.com/images/I/51s0ZaO0WDL._SX399_BO1,204,203,200_.jpg&quot;:[401,500]}" data-recalc-dims="1"></a><a href="https://www.amazon.com/gp/product/0762439955/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0762439955&amp;linkCode=as2&amp;tag=gautnaru-20&amp;linkId=MOTVUMZGF5OZXYD5" target="_blank" rel="noopener noreferrer">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <img loading="lazy" id="imgBlkFront" src="https://i1.wp.com/ecx.images-amazon.com/images/I/51FE6WIn3aL._SX328_BO1,204,203,200_.jpg?resize=269%2C407&amp;ssl=1" alt="" width="269" height="407" data-a-dynamic-image="{&quot;http://ecx.images-amazon.com/images/I/51FE6WIn3aL._SX328_BO1,204,203,200_.jpg&quot;:[330,499],&quot;http://ecx.images-amazon.com/images/I/51FE6WIn3aL._SY344_BO1,204,203,200_.jpg&quot;:[229,346]}" data-recalc-dims="1"></a></p>
<p><span>Psychology</span></p>
<p>Magnus Carlsen is my favorite chess player. In equal positions where many …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.gautamnarula.com/how-to-get-good-at-chess-fast/">https://www.gautamnarula.com/how-to-get-good-at-chess-fast/</a></em></p>]]>
            </description>
            <link>https://www.gautamnarula.com/how-to-get-good-at-chess-fast/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25020036</guid>
            <pubDate>Sat, 07 Nov 2020 22:08:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Going from $0 to $2M ARR in 2 years]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25019737">thread link</a>) | @gatsby
<br/>
November 7, 2020 | https://laskie.co/playbooks/bootstrapping-b2b-sales | <a href="https://web.archive.org/web/*/https://laskie.co/playbooks/bootstrapping-b2b-sales">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Welcome! You're probably here because you read <a href="https://twitter.com/ChrisJBakke/status/1309197276061945857" target="_blank">this tweet</a> and then signed up to hear the longer-form version of how we ran founder-led sales to grow from $0 to $2m ARR in under 2 years.</p><p><strong>This guide is for founders who have a B2B company that is just starting out, where you're selling a product that is $250/mo or more.</strong></p><p>You might also find value in certain sections if you're running an agency, or a B2C company, or are selling a product &lt;$250/mo. You might find value if you're a B2B sales leader, or an account executive, or are just trying to learn more about sales.</p><p>Like many other things - sales, marketing, pricing, and onboarding are all really case-dependent. This isn't meant to be advice, or "go do this," but rather, "here's the playbook that worked well for us, with a specific product, at a specific moment in time."</p><h2 id="why-founder-led-sales-is-important"><a href="#why-founder-led-sales-is-important" aria-label="why founder led sales is important permalink" target="_blank"></a>Why founder-led sales is important</h2><p><strong>Sales should to be driven by at least one founder until you stop learning new things about your customers, the problem you are solving, and how to position your solution.</strong></p><p>At our last company, we had all three founders involved in sales at some level for almost 2 years.</p><p>No one is going to understand the product and problem it solves better than the founders. If that's not the case, you have bigger problems than sales.</p><p><strong>Sales conversations are also your most important feedback loop.</strong> As a founder, you need a front row seat to drive product, pricing and marketing decisions.</p><h2 id="why-i-wrote-this"><a href="#why-i-wrote-this" aria-label="why i wrote this permalink" target="_blank"></a>Why I wrote this</h2><p>I've done a lot of sales. I've worked at, built, founded, and sold a couple companies. Everything about a startup is sales: you're selling a product or service to a customer, you're pitching the best people to join your team, you're pitching investors, you're selling a vision to your team, you're striking a critical partnership.</p><p><strong>Everything is sales, so we might as well get good at it.</strong></p><p>I didn't write this alone. Our team at my new company <a href="https://laskie.co/" target="_blank">Laskie</a> encouraged me to write this, and helped out a lot.</p><p><strong>Please reach out with questions: <a href="mailto:chris@laskie.co" target="_blank">chris@laskie.co</a>.</strong></p><hr></div></div></div>]]>
            </description>
            <link>https://laskie.co/playbooks/bootstrapping-b2b-sales</link>
            <guid isPermaLink="false">hacker-news-small-sites-25019737</guid>
            <pubDate>Sat, 07 Nov 2020 21:38:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux – A Survival Guide for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25019381">thread link</a>) | @URfejk
<br/>
November 7, 2020 | https://www.jacobgoldstein.tk/linux-survival-guide/ | <a href="https://web.archive.org/web/*/https://www.jacobgoldstein.tk/linux-survival-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                



<p>I survived the transition to Linux—and you can too</p>

<p><img src="https://cdn-images-1.medium.com/max/12032/1*XXI-kg18liPn4XcfZmoqQQ.jpeg" alt="Photo by [Chris Ried](https://unsplash.com/@cdr6934?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText) on [Unsplash](https://unsplash.com/search/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText)"><em>Photo by <a href="https://unsplash.com/@cdr6934?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Chris Ried</a> on <a href="https://unsplash.com/search/photos/code?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Unsplash</a></em></p>

<p>Switching from Windows to <a href="https://www.linux.org/" target="_blank">Linux</a> can be really scary. But if you can survive the first few months, the eventual returns are exponential. Here’s how I survived.</p>

<h2 id="tldr">TLDR</h2>

<ol>
<li><p>Though I am just an amateur in Linux, I was able to survive the transition and indeed benefitted from it. So these are my notes for somebody facing a similar situation.</p></li>

<li><p>Pick <a href="https://ubuntu.com/" target="_blank">Ubuntu</a> to start with. Choose other flavours once you know better and can decide for yourself.</p></li>

<li><p>Get comfortable with following commands ssh, pwd, ls, cd, mv, cp, scp, grep, find, rm. Tip: you can use <a href="https://tldr.ostera.io/cp" target="_blank">https://tldr.ostera.io/cp</a> to get the list of most frequently used options of these commands.</p></li>

<li><p>Learn to use the | symbol. Using this symbol, you can pass the output of one command as an input to the next command.</p></li>
</ol>

<h2 id="the-long-version">The Long Version</h2>

<p>In my first company, we were using Windows extensively, whether it was desktop machines we used for development or the servers on which we deployed our code. But when I moved to my <a href="http://azrisolutions.com/?source=gokulnk" target="_blank">second company</a>, it was all in on OSS and hence using Linux was mandatory there. It became a herculean task for me. For the first month or so it was a nightmare.</p>

<p>Having gone through that nightmare and survived it, I am making this list to help others like me who are trying to make this transition.</p>

<h2 id="new-environments">New Environments</h2>

<p>Transitions are hard in general. New environments can be scary. If you’re a Windows user who has never used the command line, then transition to Linux can get really scary. Don’t fret because that is generally the experience of many people who are making this transition. Knowing that others also find it difficult can be really consoling at times.</p>

<p>According to me, the two main reasons that make transitions difficult are: <strong>lack of familiarity</strong> and <strong>fear of screwing up.</strong></p>

<h3 id="lack-of-familiarity">Lack of familiarity</h3>

<p>To address the issue of familiarity, I started using Linux on my office laptop as well as my personal laptop. I started reading blogs about Linux and followed some interesting Linux-related accounts on Twitter. I reached out to people who were good at Linux. I would walk up to their cubicles and ask them to show me their command history. I learned a lot more from this than from reading the blogs. Most of the times, since it’s just muscle memory, the programmers can’t explain it. But their history is a treasure trove.</p>

<p>I would recommend running the following command. You will get many insights into the commands your Linux heroes use frequently.</p>
<div><pre><code data-lang="bash">history | awk ‘<span>{</span> $1<span>=</span>””; print $0 <span>}</span>’ | sort | uniq -c | sort -nr | head -20</code></pre></div>
<p>Run the command on the terminals of the Linux gurus in your office. Ask them about the commands you are not familiar with and you should be able to learn a lot more than what a couple of books could teach you. Don’t forget that these are battle-tested commands and hence much more valuable than standard examples in blogs. If you cannot understand what the above command does, don’t worry—I’ll explain it later on in the piece.</p>

<h3 id="fear-of-screwing-up">Fear of screwing up</h3>

<p>I have been using Linux for a couple of years but I still have this fear. This fear was multi-fold when I started. One thing that helped me a lot was, I spoke to Linux pros in my company and made a blacklist—a list of commands that I should never use or use with caution. sudo rm -rf was the top of the list. If you are anxious like me you can use <a href="https://github.com/nivekuil/rip" target="_blank">https://github.com/nivekuil/rip</a> on your local machine.</p>

<p>When I was going through the stage of being afraid of screwing up this Youtube user was of great help: <a href="https://www.jacobgoldstein.tk/linux-survival-guide/youtube.com/c/ChrisTitusTech/" target="_blank">ChrisTitus</a>. I wish I had spent more time watching him and learnt a couple more of his tricks. Find your angels and they will help you face your fears.</p>

<p>Now that your fears are addressed, let’s get started.</p>

<h2 id="why-you-should-learn-linux">Why You Should Learn Linux</h2>

<p>There are countless reasons why you should learn Linux. A google search will fetch you thousands of articles about why you should learn Linux, such as “<a href="https://www.quora.com/What-are-the-benefits-of-learning-Linux" target="_blank">What are the benefits of learning Linux</a>,” “<a href="https://fossbytes.com/10-reasons-switch-linux-os-right-now/" target="_blank">Why you should switch to Linux</a>” and “<a href="https://www.reddit.com/r/learnprogramming/comments/38zytg/is_it_worth_my_time_to_learn_linux_while_learning/" target="_blank">Is it worth my time to learn Linux while learning programming</a>?” Those three articles are worth a read, but here are my top two reasons why you should learn:</p>

<ol>
<li><p><strong>Linux is ubiquitous</strong>: Linux is everywhere. So with or without your knowledge there is a high probability that you are already using or benefitting from Linux. Understanding the basics of Linux can therefore come in handy in many situations. If you are a programmer then that chance is fairly high. A fair number of applications are deployed on Linux servers. So learning it can be a lifesaver.</p></li>

<li><p><strong>Linux is versatile</strong>: <a href="https://askubuntu.com/a/11396/217036" target="_blank">Both Linux and MAC are built on UNIX.</a> So if you are comfortable with the Linux terminal you should be able to use most of the commands in MAC terminal as well. <a href="https://unix.stackexchange.com/questions/25463/does-android-really-use-the-same-kernel-as-linux" target="_blank">Android uses the Linux kernel. </a><a href="https://www.raspberrypi.org/documentation/linux/kernel/building.md" target="_blank">Raspberry Pi uses Linux.</a> <a href="https://en.wikipedia.org/wiki/Linux#Embedded_devices" target="_blank">Many embedded devices use Linux.</a></p></li>
</ol>

<h2 id="why-did-you-start-learning-linux">Why Did You Start Learning Linux?</h2>

<p>As we’ve seen, there are many reasons for you to learn Linux. But if you are a programmer, there’s a fair chance that you fall into one of the two following categories:</p>

<ol>
<li><p>You read up about the cool things that Linux can do or you heard from a friend who just can’t stop raving about Linux.</p></li>

<li><p>Your laptop or desktop has a non-Unix OS. But your application or website is deployed on a Linux server.</p></li>
</ol>

<p>If you fall under the first category, you have all the time in the world. So take your sweet little time. If you fall under the second category, then there is a fair chance that you are running against a deadline. So finish the next parts and get your hands dirty.</p>

<h2 id="man-command-is-your-friend-or-is-it">Man Command Is Your Friend. Or Is It?</h2>

<p>One of the first tips you get when you want to learn Linux is “Use man command, it is your friend.” While there is a certain truth to it, it can be overwhelming for many first-time users. All you generally need are the options for the most frequently used scenarios of the command—and that is what is precisely missing from man pages. Luckily for you, there’s a project called <a href="https://tldr.sh/" target="_blank">TLDR </a>which is trying to fix exactly that.</p>

<p>Just compare the outputs of these two commands to see what I mean.</p>

<p><strong>First, output from man pages.</strong></p>

<p><img src="https://cdn-images-1.medium.com/max/2302/1*0QXjvacgzf1OHvziiX9s2w.png" alt=""></p>

<p>Now the output from TLDR project.</p>

<p><img src="https://cdn-images-1.medium.com/max/2000/1*ZrSUDueSxi2uezlLqoq1iQ.png" alt=""></p>

<p>Do you see the difference?</p>

<p>TLDR is like the notes about commands I would have written for myself. I find it very handy. I installed the TLDR using <a href="https://nodejs.org/" target="_blank">nodejs</a> command sudo npm i -g tldr. If you have not installed nodejs I suggest you do it, as there are many node packages that are very handy. You can install nodejs using <a href="https://www.digitalocean.com/community/tutorials/how-to-install-node-js-on-ubuntu-18-04" target="_blank">this installation manual by Digitial Ocean.</a></p>

<p>I thought of sharing my notes on all the commands in this post, but then I came across a post by Andrew where he covers 101 bash commands:
<a href="https://dev.to/awwsmm/101-bash-commands-and-tips-for-beginners-to-experts-30je#whereis-which-whatis" target="_blank"><strong>101 Bash Commands and Tips for Beginners to Experts</strong>
*Andrew Jan 13 ・39 min readThe commands below are laid out in a more-or-less narrative style, so if you’re just getting…*dev.to</a></p>

<p>He has categorised all the commands and has good examples as well, and I can’t do a better job than that.</p>

<h2 id="learn-about-bash-profiles">Learn About Bash Profiles</h2>

<p>I found bash config files or bash profiles to be handy, so it helps to <a href="https://stackoverflow.com/a/415444/493742" target="_blank">learn the differences and how they work</a>.</p>

<p>One rule of thumb I follow is to add all my configs to .bash_profile and also make sure to load .bashrc within the .bash_profile file. I add my favourite aliases to this file. I keep a basic version of my .bash_profile in my private gist and I download the raw version of that on the servers where I need these.</p>



<h2 id="learn-to-use-emacs">Learn to Use Emacs</h2>

<p>One thing that I look for these days is commonality. This has helped me leverage what I know in multiple scenarios. For example, we are pushing a lot of Javascript in our team as we can use it in multiple scenarios, like our website front end, in browser console to scrape things quickly, debug our front end or learn from other websites, for joining collections in mongodb, and in nodejs for server side.</p>

<p>Stressing commonality helps us “Learn Once, Benefit Multiple Times”—a much greater ROI.</p>

<p>Coming back to Linux, I wanted to decide on a command line editor. I had the options of choosing Nano, Vim, or Emacs. I chose <a href="https://www.gnu.org/software/emacs/emacs.html" target="_blank">Emacs</a>.</p>

<p>Most of the commands used in Emacs can also be used in Linux shell. For example, you can use CTRL/CMD+A to go to the beginning of the line on both shell and Emacs. There are many such commands which work in both shell and Emacs. I think this is a huge advantage.</p>

<p>Since it is a command line editor, you can install it easily on any server. On every server where I am root I generally install Emacs. I am not sure if this is a good practice, but I generally find it very convenient. Yes I have decided not to learn Nano or Vim. Roast me for it if you want to.</p>

<h2 id="pipe-it">PIPE It</h2>

<p>Pipe command in Linux lets you use the output of one command as the input of the next command. This can be really helpful once you get the hang of a few Linux commands like grep, sort, awk, uniq, head, and tail. Piping along with these commands is immensely powerful. For example, I never remember what the options are in ls for showing only text files (and I don’t think you should either). I just run the following command.</p>

<pre><code>ls -l | grep txt
</code></pre>

<p>I know this is quick and dirty but it works in most scenarios.</p>

<p>For example, if we look at the history processing command we used in the first section:</p>

<pre><code>history | awk ‘{ $1=””; print $0 }’ | sort | uniq -c | sort -nr | head -20
</code></pre>

<p>We are taking the output of the history command, and we are passing it to awk to remove the line numbers at the beginning of each line from the output. Then we are passing the output to the sort command so that we can sort it. Then we are passing the output uniq command to retain only unique lines along with the number of occurrences. Then we are passing it to sort command to sort it in reverse order. Then we are passing it to head command to list only the top 20 most frequently used commands that are present in our history.</p>

<p>How cool is that?</p>

<h2 id="grep-it">GREP it</h2>

<p>If you are used to SDKs and GUI editors, GREP might seem little limited. But most of the time, the differentiator is that you can chain the output of the grep …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jacobgoldstein.tk/linux-survival-guide/">https://www.jacobgoldstein.tk/linux-survival-guide/</a></em></p>]]>
            </description>
            <link>https://www.jacobgoldstein.tk/linux-survival-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25019381</guid>
            <pubDate>Sat, 07 Nov 2020 21:07:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Marketers are addicted to bad data]]>
            </title>
            <description>
<![CDATA[
Score 303 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25016532">thread link</a>) | @iamacyborg
<br/>
November 7, 2020 | https://www.jacquescorbytuech.com/writing/marketers-addicted-bad-data | <a href="https://web.archive.org/web/*/https://www.jacquescorbytuech.com/writing/marketers-addicted-bad-data">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
<article>
<header>

</header>
<p><small><time datetime="2020-11-07T15:45:00+00:00">
      Sat 07 November 2020
    </time></small>
</p>
<div>
<p>Modern marketing is all about data and however hard you might try, you can't spend any time around marketers online without <a href="https://blog.marketo.com/2013/11/prove-your-worth10-kpis-for-marketers.html">being</a> <a href="https://www.searchenginejournal.com/paid-owned-earned-content/242075/">subjected</a> <a href="https://blogs.oracle.com/oracledatacloud/effectively-measuring-advertising-performance-your-guide-to-success">to</a> <a href="https://searchengineland.com/using-auction-insights-for-better-ppc-competitor-analysis-343264">endless</a> <a href="https://www.searchenginewatch.com/2020/07/28/10-reasons-why-marketers-use-data-to-make-budgeting-decisions/">think</a> <a href="https://www.oberlo.co.uk/blog/spent-200000-facebook-ads-heres-learned">pieces</a>, how-to guides, ebooks or other dreck about how we need to track and measure and count every little thing.</p>
<p>We've got click rates, impressions, conversion rates, open rates, ROAS, pageviews, bounces rates, ROI, CPM, CPC, impression share, average position, sessions, channels, landing pages, KPI after never ending KPI.</p>
<p>That'd be fine if all this shit meant something and we knew how to interpret it. But <em>it doesn't</em> and <strong>we don't</strong>. </p>
<p>The reality is much simpler, and therefore much more complex.  Most of us don't understand how data is collected, how these mechanisms work and most importantly where and how they <em>don't</em> work.</p>
<ul>
<li><a href="https://www.statista.com/statistics/874736/ad-blocker-usage-in-united-kingdom/">36% percent of people in the UK</a> use an adblocker, which means your javascript based website tracking is meaningless</li>
<li>Email open rates <a href="https://developermedia.com/email-open-rates-misleading-metrics-best-practices-2/">don't <em>actually</em> indicate that an email was opened</a>, merely that a request was made to a server</li>
<li>The black boxes inside Facebook and other ad exchanges give you <a href="https://www.etcentric.org/facebook-agrees-to-40-million-fine-for-incorrect-ad-metrics/">flat out wrong</a> data about how your ads are performing</li>
<li>The audiences you're targeting on Google, Bing, etc <a href="https://www.forbes.com/sites/augustinefou/2020/11/02/got-large-budgets-you-need-to-spend-fraudsters-will-help-you-spend-it/?sh=54b93f867a9f">are fraudulent</a> and don't even exist</li>
<li>The exchanges you're purchasing media space from are <a href="https://www.adexchanger.com/mobile/is-ubers-new-ad-fraud-lawsuit-futile-or-game-changing/">cheating you</a></li>
</ul>
<p>And even if we know how the data is collected, what it means and what it's actually tracking, most of us don't have the technical chops to analyse the data we've collected<sup id="fnref:1"><a href="#fn:1">1</a></sup>. I don't mean to rag on anyone by saying this, but we do need a reality check.</p>
<p>And look. I get it. Having tangible data allows us to demonstrate that we're doing our job and we're trying to measure and improve what we're doing. But as Bob Hoffman rightly points out - <a href="http://adcontrarian.blogspot.com/2020/09/the-mystery-of-modern-media.html">that's not how brands are built</a>. </p>
<p>The numbers are often all we have to prove our case, to get more budget and in extreme cases, to continue to stay employed. We'll remain in this mess until we can separate marketing from short sighted and poorly informed decision making. Until leaders can lead on the strength of their conviction and experience instead of second guessing themselves and their staff based on the inadequacy of data.</p>
<p>I don't know what the way out of this mess is, or what the path to success looks like. All I know is this.</p>
<p><em>We're addicted to bad data</em>.</p>

<p>Cheers,</p>
<p><img src="https://www.jacquescorbytuech.com/images/jacques.png">
</p></div>
<div>
<h4>Subscribe for updates</h4>

<p>Updates, whenever I've got something valuable to say.</p>
</div>
</article>
</section></div>]]>
            </description>
            <link>https://www.jacquescorbytuech.com/writing/marketers-addicted-bad-data</link>
            <guid isPermaLink="false">hacker-news-small-sites-25016532</guid>
            <pubDate>Sat, 07 Nov 2020 17:27:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fosshost launches ARMv8 64-bit eMAG]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25016045">thread link</a>) | @fosshost
<br/>
November 7, 2020 | https://fosshost.org/about | <a href="https://web.archive.org/web/*/https://fosshost.org/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-30c5a225=""><div data-v-257fbba2=""><div data-v-257fbba2=""><p data-v-257fbba2="">The fosshost project is a non-profit organisation that exists to serve the hosting needs of the global open source community.</p>
<p data-v-257fbba2="">We're on a mission to empower and support every free and open source software project. To go further, together. Our work never stops. </p>
<p data-v-257fbba2="">Today, we help provide world-class hosting services to more than seventy open source projects.</p>
<p data-v-257fbba2="">We operate several nodes which are usually donated by our hosting sponsors, and manage the infrastructure donated to us, on behalf of the projects we help.  You can read more about the projects we help <a href="https://fosshost.org/projects">here</a>. </p>
<p data-v-257fbba2="">Those open source projects eligible for our services, typically apply for a virtual private server (VPS).  This is typically provided with the following specification, but can be increased, upon request.</p>
<ul data-v-257fbba2="">
<li data-v-257fbba2="">6 vCPU</li>
<li data-v-257fbba2="">8GB Memory</li>
<li data-v-257fbba2="">400GB Storage</li>
<li data-v-257fbba2="">IPv4 / IPv6 connectivity</li>
<li data-v-257fbba2="">Full Remote SSH Access</li>
</ul>
<p data-v-257fbba2="">We support most operating systems including CentOS, Debian, Ubuntu, Gentoo, ArchLinux, Fedora and FreeBSD. We support custom OS.</p>
<p data-v-257fbba2="">Other services we provide include web, email, database, communication, domain, DNS and storage hosting.  You can apply for all of our services via the <a href="https://fosshost.org/apply">application</a> form, or read more about the services we offer <a href="https://docs.fosshost.org/" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">here</a>.</p>
<h2 id="our-network" data-v-257fbba2="">Our network</h2>
<p data-v-257fbba2="">The project operates a large and global infrastructure across multiple continents in world-class facilities.  Projects can select which region they want their services deploying on.</p>
<p data-v-257fbba2="">Maidenhead, United Kingdom (Node 1):<br data-v-257fbba2="">
Facility: iomart DC5 Maidenhead<br data-v-257fbba2="">
Dual Xeon 2630, 64GB RAM and 8x2TB SATA (RAID 10)<br data-v-257fbba2="">
IPv4 only supported<br data-v-257fbba2="">
Network Connectivity: 1000Mbps<br data-v-257fbba2="">
Test IP: 185.35.79.69<br data-v-257fbba2="">
Network Info:&nbsp;<a href="https://ipinfo.io/185.35.79.69" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/185.35.79.69</a></p>
<p data-v-257fbba2="">Newark, United Kingdom (Node 2):<br data-v-257fbba2="">
Facility: Timico Newark<br data-v-257fbba2="">
Dual Xeon 2136, 64GB RAM and 2x1TB SSD (RAID 1)<br data-v-257fbba2="">
IPv4 only supported<br data-v-257fbba2="">
Network Connectivity: 100Mbps<br data-v-257fbba2="">
Test IP: 37.61.232.244<br data-v-257fbba2="">
Network Info:&nbsp;<a href="https://ipinfo.io/37.61.232.244" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/37.61.232.244</a></p>
<p data-v-257fbba2="">Chicago, United States (Node 3):<br data-v-257fbba2="">
Facility: zColo Chicago<br data-v-257fbba2="">
Dual Xeon 5520, 72GB RAM and 4x3TB SATA (RAID 10)<br data-v-257fbba2="">
IPv4 and IPv6 supported<br data-v-257fbba2="">
Network Connectivity: 1000Mbps<br data-v-257fbba2="">
Test IP: 192.240.104.4<br data-v-257fbba2="">
Network Info:&nbsp;<a href="https://ipinfo.io/192.240.104.4" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/192.240.104.4</a></p>
<p data-v-257fbba2="">Los Angeles, United States (Node 4 and 5):<br data-v-257fbba2="">
Facility: zColo Los Angeles<br data-v-257fbba2="">
Dual Xeon 5520, 72GB RAM and 4x3TB SATA (RAID 10)<br data-v-257fbba2="">
IPv4 and IPv6 supported<br data-v-257fbba2="">
Network Connectivity: 1000Mbps<br data-v-257fbba2="">
Test IP: 192.240.120.250<br data-v-257fbba2="">
Network Info:&nbsp;<a href="https://ipinfo.io/192.240.120.250" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/192.240.120.250</a></p>
<p data-v-257fbba2="">Warsaw, Poland (Node 6):<br data-v-257fbba2="">
Facility: LIM Warsaw<br data-v-257fbba2="">
Dual Xeon 5620, 48GB RAM and 2x900GB SAS (RAID 1)<br data-v-257fbba2="">
IPv4 only supported<br data-v-257fbba2="">
Network Connectivity: 1000Mbps<br data-v-257fbba2="">
Test IP: 109.232.240.226<br data-v-257fbba2="">
Network Info:&nbsp;<a href="https://ipinfo.io/109.232.240.226" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/109.232.240.226</a></p>
<p data-v-257fbba2="">Meppel, Netherlands (Node 7)<br data-v-257fbba2="">
Facility: Serverius SDC2<br data-v-257fbba2="">
Dual Xeon 2620, 32GB RAM and 4x3TB (RAID 1)<br data-v-257fbba2="">
IPv4 only supported<br data-v-257fbba2="">
Network Connectivity: 100Mbps<br data-v-257fbba2="">
Test IP: 146.0.73.72<br data-v-257fbba2="">
Network Info:&nbsp;<a href="https://ipinfo.io/146.0.73.72" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/146.0.73.72</a></p>
<p data-v-257fbba2="">Meppel, Netherlands (Node 8)<br data-v-257fbba2="">
Facility: Serverius SDC2<br data-v-257fbba2="">
Dual Xeon 2620, 62GB RAM and 4x3TB (RAID 1)<br data-v-257fbba2="">
IPv4 only supported<br data-v-257fbba2="">
Network Connectivity: 1000Mbps<br data-v-257fbba2="">
Test IP: 5.255.91.1<br data-v-257fbba2="">
Network Info:&nbsp;<a href="https://ipinfo.io/5.255.91.1" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/5.255.91.1</a></p>
<p data-v-257fbba2="">North Dallas, United States (Node 9 and 10)<br data-v-257fbba2="">
Facility: DataBank DFW2<br data-v-257fbba2="">
Dual Xeon 2620, 128GB RAM and x2 480GB SSD, x1 128GB SSD, x12 2TB<br data-v-257fbba2="">
IPv4 and IPv6 supported<br data-v-257fbba2="">
Network Connectivity: x2 10Gbps (Bonded)<br data-v-257fbba2="">
Test IP: 139.178.85.253<br data-v-257fbba2="">
Network Info: <a href="https://ipinfo.io/139.178.85.253" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/139.178.85.253</a></p>
<p data-v-257fbba2="">Oregon, United States (Node 11)<br data-v-257fbba2="">
Facility: OSUOSL Corvallis<br data-v-257fbba2="">
Dual Xeon 5690, 64GB RAM and x6 2TB (RAID6)<br data-v-257fbba2="">
IPv4 and IPv6 supported<br data-v-257fbba2="">
Network Connectivity: 1000Mbps<br data-v-257fbba2="">
Test IP: 140.211.9.133<br data-v-257fbba2="">
Network Info: <a href="https://ipinfo.io/140.211.9.133" rel="nofollow noopener noreferrer" target="_blank" data-v-257fbba2="">https://ipinfo.io/140.211.9.133</a></p></div></div></div></div>]]>
            </description>
            <link>https://fosshost.org/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-25016045</guid>
            <pubDate>Sat, 07 Nov 2020 16:36:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn how to design and defend an embedded Linux device]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25015821">thread link</a>) | @sprado
<br/>
November 7, 2020 | https://embeddedbits.org/introduction-embedded-linux-security-part-1/ | <a href="https://web.archive.org/web/*/https://embeddedbits.org/introduction-embedded-linux-security-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p>This article is going to be an introduction to <strong>embedded Linux security</strong>.</p>
<p>Since this topic is quite extensive, I divided into two parts. In this first part, we will have a small introduction to security concepts and threat modeling and then focus on some mitigation techniques to improve the security of an embedded Linux device, including secure boot, code/data encryption and secure key storage.</p>
<p>If you prefer a one hour talk instead of reading this article, you can also watch the webinar <a href="https://www.youtube.com/watch?v=QcUKAgVKSxQ">“Introduction to embedded Linux security”</a> I recorded for <a href="https://www.toradex.com/">Toradex</a>. I also gave the same talk at Embedded Linux Conference North America 2020, but as I write this article it was not yet published on YouTube.</p>
<p>Let’s first start with some concepts…</p>
<h2 id="security-concepts">Security concepts</h2>
<p>Security is all about risk mitigation.</p>
<p>On the one hand, we have <strong>owners</strong>, those who benefit from a product or service (user, manufacturer, business owner, etc). And owners want to protect <strong>assets</strong>, anything that has some value in the product or service (data, code, reputation, etc).</p>
<p>On the other hand, we have <strong>threat actors</strong>, a person or thing (malicious hacker, government, etc) that can manifest a <strong>threat</strong>, anything that is capable of acting against an asset in a manner that can result in harm.</p>
<p>To manifest a threat, the threat actor will explore <strong>vulnerabilities</strong> (weakness in the system) via an <strong>attack vector</strong>, a method or pathway used by the threat actor to access or penetrate the target system.</p>
<p>The diagram below express very well all those concepts:</p>
<p><a href="https://www.enisa.europa.eu/publications/hardware-threat-landscape/at_download/fullReport"><img src="https://embeddedbits.org/images/20200906-security-concepts.png" alt="Security Concepts"></a></p>
<p>In the end, is a cat-and-mouse game between owners and threat actors. How far will the owner go to protect the assets? How far will the threat actor go to compromise the assets? It really depends on the value of the assets. Indeed, the perception of value may not be the same for owners and threat actors.</p>
<p>Identifying assets (and their value) to mitigate the risks of being compromised can be done in a process called <strong>threat modeling</strong>.</p>
<h2 id="threat-modeling">Threat modeling</h2>
<p>Threat modeling is a process where potential threats can be identified, enumerated, and mitigations can be prioritized. It is basically a risk assessment process where you evaluate the value of your assets and the cost to protect them. The result of a threat modeling is the <strong>threat model</strong> of your product.</p>
<p><img src="https://embeddedbits.org/images/20200906-threat-modeling.png" alt="Threat modeling"></p>
<p>There are several techniques and methodologies that can help during threat modeling, including STRIDE, DREAD, VAST, OCTAVE, and many others.</p>
<p>To have a very basic introduction to the topic, let’s talk about STRIDE and DREAD.</p>
<p>The <a href="https://en.wikipedia.org/wiki/STRIDE_(security)">STRIDE model</a> is a very useful tool to help classify threats. It was developed by Microsoft and the name is an acronym for the six main types of threats: <strong>S</strong>poofing, <strong>T</strong>ampering, <strong>R</strong>epudiation, <strong>I</strong>nformation disclosure, <strong>D</strong>enial of service and <strong>E</strong>scalation of privileges. STRIDE can be used to identify all threats the assets of a system could be exposed to.</p>
<p><a href="https://allabouttesting.org/stride-acronym-of-threat-modeling-system/"><img src="https://embeddedbits.org/images/20200906-stride.png" alt="STRIDE"></a></p>
<p>The <a href="https://en.wikipedia.org/wiki/DREAD_(risk_assessment_model)">DREAD methodology</a> is a tool for risk-assessing computer security threats. The name is an acronym for five categories of security threats: <strong>D</strong>amage (how bad would an attack be), <strong>R</strong>eproducibility (how easy is it to reproduce the attack), <strong>E</strong>xploitability (how much work is it to launch the attack), <strong>A</strong>ffected users (how many people would be impacted) and <strong>D</strong>iscoverability (how easy is it to discover the threat).</p>
<p><a href="https://www.slideshare.net/SecurityInnovation/threat-modeling-to-reduce-software-security-risk"><img src="https://embeddedbits.org/images/20200906-dread.png" alt="DREAD"></a></p>
<p>While the STRIDE model helps to identify the threats, the DREAD methodology helps to rank them. For each threat in the system, you would go over each threat category and classify it in low (1 point), medium (2 points), or high (3 points). In the end, you would have a ranked list of threats and mitigation strategies. Example:</p>
<p><img src="https://embeddedbits.org/images/20200906-threat-modeling-example.png" alt="Threat modeling example"></p>
<p>We can see that threat modeling will provide a very clear view of what we want to protect, how we plan to protect it, and associated costs. This is part of the <strong>threat model</strong> of the product, which needs to be re-evaluated for every development cycle. As a result, the threat model will provide a prioritized list of threats to work on, so we can focus on implementing the mitigations to improve the security of the product.</p>
<p>How to protect the integrity and authenticity of your code? How to ensure the privacy of the data? Where to store cryptographic keys? How to minimize the risks of an application to be exploited? Let’s try to answer all of those questions and many more, starting with secure boot!</p>
<h2 id="secure-boot">Secure Boot</h2>
<p>How to make sure the code you are running was built by a trustworthy person or company? Implementing a <strong>secure boot</strong> process.</p>
<p>The objective of a secure boot process is to protect the integrity and authenticity of the code.</p>
<p>Secure boot is usually based on the verification of digital signatures. An embedded Linux system normally has three major components: bootloader, kernel and root filesystem (rootfs). All these components are signed and the signatures are checked during boot.</p>
<p>For example, some hardware mechanism can be used to check the signature of the bootloader, that will check the signature of the kernel, that will use a ramdisk image to check the signature of the root filesystem. Since we have one component checking the signature of the next one in the boot chain, this process is often called a <strong>chain-of-trust</strong>.</p>
<p><img src="https://embeddedbits.org/images/20200906-secure-boot-1.png" alt="Secure boot"></p>
<p>Let’s take a look at a real example on an <a href="https://www.nxp.com/imx6">NXP iMX6</a> device.</p>
<p>Everything starts in the ROM code inside the SoC. On NXP iMX6, there is a hardware component called High Assurance Boot (HAB) that it is able to validate the signature of the first stage bootloader, making it possible to implement a secure boot process. The High Assurance Boot inside iMX6 devices can also be called the <strong>Root of Trust</strong>, since if it is compromised, all the secure boot process is also compromised.</p>
<p>The ROM code inside the iMX6 SoC, using the HAB component, will check the signature of the bootloader. For that, it is necessary to generate a pair of keys (public and private), sign the bootloader with the private key and store the public key inside the SoC. On iMX6, OTP fuses are used to store the keys. Actually, to make it less expensive, only the hash of the public key is stored in the SoC.</p>
<p>When the bootloader boots (e.g. <a href="https://www.denx.de/wiki/U-Boot">U-Boot</a>), it will have to check the signature of the Linux kernel. For that, it is common to use an image format called <strong>FIT image</strong>. The FIT image is a container for multiple binaries with hashing and signature support, and usually contains the Linux kernel image, device tree files and an initial ramdisk. After generating a pair of keys, we need to sign the binaries inside the FIT image with the private key e configure U-Boot to use the public key to check the signature of the FIT image.</p>
<p>After the kernel boots, it will run the <em>init</em> program from the ramdisk image. The ramdisk will have the logic to verify the integrity of the final root filesystem before mounting it. There are some options to implement this. One common option is using the device-mapper verity (<a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/verity.html">dm-verity</a>) kernel module. The <strong>dm-verity</strong> kernel module provides integrity checking of block devices and requires a read-only rootfs (squashfs can be a good solution). Other approaches would be <a href="https://wiki.gentoo.org/wiki/Integrity_Measurement_Architecture">IMA</a> or <a href="https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/dm-integrity.html">dm-integrity</a> if you want a read-write root filesystem.</p>
<p>Here is a diagram of the complete secure boot process:</p>
<p><img src="https://embeddedbits.org/images/20200906-secure-boot-2.png" alt="Secure boot on NXP iMX6"></p>
<p>This is only one example of a secure boot implementation, although it could be applied to a different set of boards and ARM SoCs.</p>
<p>Yet nothing is 100% secure!</p>
<p>Secure boot vulnerabilities in the ROM code of several NXP devices (i.MX6, i.MX50, i.MX53, i.MX7, i.MX28 and Vybrid families) were <a href="https://blog.quarkslab.com/vulnerabilities-in-high-assurance-boot-of-nxp-imx-microprocessors.html">publicly disclosed</a> on July 17th, 2017. And if your chain of trust is compromised, everything is compromised! So we need to be aware of these types of vulnerabilities (in this case, they were fixed with new silicon).</p>
<p>While secure boot ensures authenticity and integrity, it does not protect the device from being counterfeited or threat actors from extracting code/data from the device. So if you want to protect your intellectual property or ensure data confidentiality, you will need to use encryption.</p>
<h2 id="code-and-data-encryption">Code and data encryption</h2>
<p>You may want to encrypt data or code in an embedded Linux device.</p>
<p>Data encryption is a common approach when you need to protect the privacy and confidentiality of the users. Data is any information generated during the executing of the device, including databases, configuration files, and so on.</p>
<p>Code encryption depends on the situation, and encrypting the full root filesystem is not that common. Usually, most of the components are free and open source software, so there is nothing to hide. There is also the issue of GPLv3 and Tivoization (using any GPLv3 software will force you to provide a mechanism for the user to update the software, and that would make it more difficult if you are encrypting it). A more common use case is to encrypt only the applications you developed for the device. It’s usually where your intellectual property is.</p>
<p>There are basically two main approaches to encryption in Linux: <strong>full disk encryption</strong> and <strong>file-based encryption</strong>.</p>
<p>Full disk encryption provides encryption at the block level and the whole disk or a disk partition is encrypted. For that, we can use <a href="https://en.wikipedia.org/wiki/Dm-crypt">dm-crypt</a>, the Linux kernel’s device mapper crypto target.</p>
<p>File-based encryption provides encryption at the file system level, where each directory may be separately and optionally encrypted with a different key. The two most common implementations of file-based encryption are <a href="https://wiki.archlinux.org/index.php/Fscrypt">fscrypt</a> and <a href="https://wiki.archlinux.org/index.php/ECryptfs">eCryptFS</a>. fscrypt is an API available on some filesystems like EXT4, UBIFS and F2FS, and eCryptFS is a more generic solution implemented as a layer that stacks on top of an existing filesystem.</p>
<p>But what about the keys used for encryption?</p>
<h2 id="encryption-keys">Encryption keys</h2>
<p>Since an asymmetric key algorithm is too slow to be used in encryption, usually a symmetric-key algorithm is used in encryption. That means the same key is used for encryption and decryption, and the key should be available somewhere in the filesystem so the encrypted code/data can be decrypted.</p>
<p>But we can’t just leave the key lying around in the filesystem, right?</p>
<p>There are several cases where companies …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://embeddedbits.org/introduction-embedded-linux-security-part-1/">https://embeddedbits.org/introduction-embedded-linux-security-part-1/</a></em></p>]]>
            </description>
            <link>https://embeddedbits.org/introduction-embedded-linux-security-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25015821</guid>
            <pubDate>Sat, 07 Nov 2020 16:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting the most out of your Intel integrated GPU on Linux]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25015327">thread link</a>) | @joseluisq
<br/>
November 7, 2020 | http://jason-blog.jlekstrand.net/2020/05/getting-most-out-of-your-intel.html | <a href="https://web.archive.org/web/*/http://jason-blog.jlekstrand.net/2020/05/getting-most-out-of-your-intel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-6228875266477811300">
<p>About a year ago ago, I got a new laptop: a late 2019 Razer Blade Stealth 13.&nbsp; It sports an Intel i7-1065G7 with the best Intel's Ice Lake graphics along with an NVIDIA GeForce GTX 1650.&nbsp; Apart from needing an ACPI lid quirk and the power management issues described here, it’s been a great laptop so far and the Linux experience has been very smooth.</p><p>

Unfortunately, the out-of-the-box integrated graphics performance of my new laptop was less than stellar.&nbsp; My first task with the new laptop was to debug a rendering issue in the Linux port of Shadow of the Tomb Raider which turned out to be a bug in the game.&nbsp; In the process, I discovered that the performance of the game’s built-in benchmark was almost half of Windows.&nbsp; We’ve had some performance issues with Mesa from time to time on some games but half seemed a bit extreme.&nbsp; Looking at system-level performance data with gputop revealed that GPU clock rate was unable to get above about 60-70% of the maximum in spite of the GPU being busy the whole time.&nbsp; Why?&nbsp; The GPU wasn’t able to get enough power.&nbsp; Once I sorted out my power management problems, the benchmark went from about 50-60% the speed of Windows to more like 104% the speed of windows (yes, that’s more than 100%).</p><p>

This blog post is intended to serve as a bit of a guide to understanding memory throughput and power management issues and configuring your system properly to get the most out of your Intel integrated GPU.&nbsp; Not everything in this post will affect all laptops so you may have to do some experimentation with your system to see what does and does not matter.&nbsp; I also make no claim that this post is in any way complete; there are almost certainly other configuration issues of which I'm not aware or which I've forgotten.</p><h2>
Update your drivers</h2><p>
This should go without saying but if you want the best performance out of your hardware, running the latest drivers is always recommended.&nbsp; This is especially true for hardware that has just been released.&nbsp; Generally, for graphics, most of the big performance improvements are going to be in Mesa but your Linux kernel version can matter as well.&nbsp; In the case of Intel Ice Lake processors, some of the power management features aren’t enabled until Linux 5.4.</p><p>

I’m not going to give a complete guide to updating your drivers here.&nbsp; If you’re running a distro like Arch, chances are that you’re already running something fairly close to the latest available.&nbsp; If you’re on Ubuntu, the padoka PPA provides versions of the userspace components (Mesa, X11, etc.) that are usually no more than about a week out-of-date but upgrading your kernel is more complicated.&nbsp; Other distros may have something similar but I’ll leave as an exercise to the reader.</p><p>

This doesn’t mean that you need to be obsessive about updating kernels and drivers.&nbsp; If you’re happy with the performance and stability of your system, go ahead and leave it alone.&nbsp; However, if you have brand new hardware and want to make sure you have new enough drivers, it may be worth attempting an update.&nbsp; Or, if you have the patience, you can just wait 6 months for the next distro release cycle and hope to pick up with a distro update.</p><h2>
Make sure you have dual-channel RAM</h2><p>
One of the big bottleneck points in 3D rendering applications is memory bandwidth.&nbsp; Most standard monitors run at a resolution of 1920x1080 and a refresh rate of 60 Hz.&nbsp; A 1920x1080 RGBA (32bpp) image is just shy of 8 MiB in size and, if the GPU is rendering at 60 FPS, that adds up to about 474 MiB/s of memory bandwidth to write out the image every frame.&nbsp; If you're running a 4K monitor, multiply by 4 and you get about 1.8 GiB/s.&nbsp; Those numbers are only for the final color image, assume we write every pixel of the image exactly once, and don't take into account any other memory access.&nbsp; Even in a simple 3D scene, there are other images than just the color image being written such as depth buffers or auxiliary gbuffers, each pixel typically gets written more than once depending on app over-draw, and shading typically involves reading from uniform buffers and textures.&nbsp; Modern 3D applications typically also have things such as depth pre-passes, lighting passes, and post-processing filters for depth-of-field and/or motion blur.&nbsp; The result of this is that actual memory bandwidth for rendering a 3D scene can be 10-100x the bandwidth required to simply write the color image.</p><p>

Because of the incredible amount of bandwidth required for 3D rendering, discrete GPUs use memories which are optimized for bandwidth above all else.&nbsp; These go by different names such as GDDR6 or HBM2 (current as of the writing of this post) but they all use extremely wide buses and access many bits of memory in parallel to get the highest throughput they can.&nbsp; CPU memory, on the other hand, is typically DDR4 (current as of the writing of this post) which runs on a narrower 64-bit bus and so the over-all maximum memory bandwidth is lower.&nbsp; However, as with anything in engineering, there is a trade-off being made here.&nbsp; While narrower buses have lower over-all throughput, they are much better at random access which is necessary for good CPU memory performance when crawling complex data structures and doing other normal CPU tasks.&nbsp; When 3D rendering, on the other hand, the vast majority of your memory bandwidth is consumed in reading/writing large contiguous blocks of memory and so the trade-off falls in favor of wider buses.</p><p>

With integrated graphics, the GPU uses the same DDR RAM as the CPU so it can't get as much raw memory throughput as a discrete GPU.&nbsp; Some of the memory bottlenecks can be mitigated via large caches inside the GPU but caching can only do so much.&nbsp; At the end of the day, if you're fetching 2 GiB of memory to draw a scene, you're going to blow out your caches and load most of that from main memory.</p><p>

The good news is that most motherboards support a dual-channel ram configurations where, if your DDR units are installed in identical pairs, the memory controller will split memory access between the two DDR units in the pair.&nbsp; This has similar benefits to running on a 128-bit bus but without some of the drawbacks.&nbsp; The result is about a 2x improvement in over-all memory throughput.&nbsp; While this may not affect your CPU performance significantly outside of some very special cases, it makes a huge difference to your integrated GPU which cares far more about total throughput than random access.&nbsp; If you are unsure how your computer's RAM is configured, you can run “dmidecode -t memory” and see if you have two identical devices reported in different channels.</p><h2>
Power management 101</h2><p>
Before getting into the details of how to fix power management issues, I should explain a bit about how power management works and, more importantly, how it doesn’t.&nbsp; If you don’t care to learn about power management and are just here for the system configuration tips, feel free to skip this section.</p><p>

Why is power management important?&nbsp; Because the clock rate (and therefore the speed) of your CPU or GPU is heavily dependent on how much power is available to the system.&nbsp; If it’s unable to get enough power for some reason, it will run at a lower clock rate and you’ll see that as processes taking more time or lower frame rates in the case of graphics.&nbsp; There are some things that you, as the user, cannot control such as the physical limitations of the chip or the way the OEM has configured things on your particular laptop.&nbsp; However, there are some things which you can do from a system configuration perspective which can greatly affect power management and your performance.</p><p>

First, we need to talk about thermal design power or TDP.&nbsp; There is a lot of misunderstanding on the internet about TDP and we need to clear some of them up.&nbsp; Wikipedia defines TDP as “the maximum amount of heat generated by a computer chip or component that the cooling system in a computer is designed to dissipate under any workload.”&nbsp; The Intel Product Specifications site defines TDP as follows:</p><p>

Thermal Design Power (TDP) represents the average power, in watts, the processor dissipates when operating at Base Frequency with all cores active under an Intel-defined, high-complexity workload. Refer to Datasheet for thermal solution requirements.</p><p>

In other words, the TDP value provided on the Intel spec sheet is a pretty good design target for OEMs but doesn’t provide nearly as many guarantees as one might hope.&nbsp; In particular, there are several things that the TDP value on the spec sheet is not:</p><ul>
<li>It’s not the exact maximum power.&nbsp; It’s a “average power”.</li>
<li>It may not match any particular workload.&nbsp; It’s based on “an Intel-defined, high-complexity workload”.&nbsp; Power consumption on any other workload is likely to be slightly different.</li>
<li>It’s not the actual maximum.&nbsp; It’s based on when the processor is “operating at Base Frequency with all cores active.” Technologies such as Turbo Boost can cause the CPU to operate at a higher power for short periods of time.</li>
</ul><p>
If you look at the&nbsp; Intel Product Specifications page for the i7-1065G7, you’ll see three TDP values: the nominal TDP of 15W, a configurable TDP-up value of 25W and a configurable TDP-down value of 12W.&nbsp; The nominal TDP (simply called “TDP”) is the base TDP which is enough for the CPU to run all of its cores at the base frequency which, given sufficient cooling, it can do in the steady state.&nbsp; The TDP-up and TDP-down values provide configurability that gives the OEM options when they go to make a laptop based on the i7-1065G7.&nbsp; If they’re making a performance laptop like Razer and are willing to put in enough cooling, they can configure it to 25W and get more performance.&nbsp; On the other hand, if they’re going for battery life, they can put the exact same chip in the laptop but configure it to run as low as 12W.&nbsp; They can also configure the chip to run at 12W or 15W and then ship software with the computer which will bump it to 25W once Windows boots up.&nbsp; We’ll talk more about this reconfiguration …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jason-blog.jlekstrand.net/2020/05/getting-most-out-of-your-intel.html">http://jason-blog.jlekstrand.net/2020/05/getting-most-out-of-your-intel.html</a></em></p>]]>
            </description>
            <link>http://jason-blog.jlekstrand.net/2020/05/getting-most-out-of-your-intel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25015327</guid>
            <pubDate>Sat, 07 Nov 2020 14:44:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: eBook with hundreds of Perl one-liners]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25014639">thread link</a>) | @asicsp
<br/>
November 7, 2020 | https://learnbyexample.github.io/learn_perl_oneliners/one-liner-introduction.html | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/learn_perl_oneliners/one-liner-introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav id="sidebar" aria-label="Table of contents"></nav><div id="page-wrapper"><div class="page"><div id="content"><main><p>This chapter will give an overview of <code>perl</code> syntax for command line usage and some examples to show what kind of problems are typically suited for one-liners.</p><h2><a href="#why-use-perl-for-one-liners" id="why-use-perl-for-one-liners">Why use Perl for one-liners?</a></h2><p>I assume you are already familiar with use cases where command line is more productive compared to GUI. See also this series of articles titled <a href="https://sanctum.geek.nz/arabesque/series/unix-as-ide/">Unix as IDE</a>.</p><p>A shell utility like <code>bash</code> provides built-in commands and scripting features to easily solve and automate various tasks. External *nix commands like <code>grep</code>, <code>sed</code>, <code>awk</code>, <code>sort</code>, <code>find</code>, <code>parallel</code>, etc can be combined to work with each other. Depending upon your familiarity with those tools, you can either use <code>perl</code> as a single replacement or complement them for specific use cases.</p><p>Here's some one-liners (options will be explained later):</p><ul><li><code>perl -pe 's/(?:\x27;\x27|";")(*SKIP)(*F)|;/#/g'</code> — change <code>;</code> to <code>#</code> but don't change <code>;</code> within single or double quotes</li><li><code>perl -MList::Util=uniq -e 'print uniq &lt;&gt;'</code> — retain only first copy of duplicated lines, uses built-in module <code>List::Util</code></li><li><code>perl -MRegexp::Common=net -nE 'say join "\n", //g if /$RE{net}{IPv4}/'</code> — extract only IPv4 addresses, using a third-party <a href="https://metacpan.org/pod/Regexp::Common">Regexp::Common</a> module</li><li>Some stackoverflow Q&amp;A that I've answered over the years with simpler <code>perl</code> solution compared to other cli tools <ul><li><a href="https://stackoverflow.com/questions/42554684/shell-replace-string-with-incrementing-value">replace string with incrementing value</a></li><li><a href="https://stackoverflow.com/questions/48920626/sort-rows-in-csv-file-without-header-first-column">sort rows in csv file without header &amp; first column</a></li><li><a href="https://stackoverflow.com/questions/63681983/sed-reverse-matched-pattern">reverse matched pattern</a></li><li><a href="https://stackoverflow.com/questions/49765879/append-zeros-to-list">append zeros to list</a></li><li><a href="https://stackoverflow.com/questions/62241101/arithmetic-replacement-in-a-text-file">arithmetic replacement in a text file</a></li><li><a href="https://stackoverflow.com/questions/45571828/execute-bash-command-inside-awk-and-print-command-output">reverse complement DNA sequence for a specific field</a></li></ul></li></ul><p>The selling point of <code>perl</code> over tools like <code>grep</code>, <code>sed</code> and <code>awk</code> includes feature rich regular expression engine and standard/third-party modules. If you don't already know the syntax and idioms for <code>sed</code> and <code>awk</code>, learning command line options for <code>perl</code> would be the easier option. Another advantage is that <code>perl</code> is more portable compared to GNU, BSD and Mac implementations of cli tools. The main disadvantage is that <code>perl</code> is likely to be slower for features that are supported out of the box by those tools.</p><blockquote><p><img src="https://learnbyexample.github.io/learn_perl_oneliners/images/info.svg" alt="info"> See also <a href="https://unix.stackexchange.com/questions/303044/when-to-use-grep-less-awk-sed">unix.stackexchange: when to use grep, sed, awk, perl, etc</a></p></blockquote><h2><a href="#installation-and-documentation" id="installation-and-documentation">Installation and Documentation</a></h2><p>If you are on a Unix like system, you are most likely to already have some version of Perl installed. See <a href="https://www.cpan.org/src/README.html">cpan: Perl Source</a> for instructions to install the latest <code>perl</code> version from source. <code>perl v5.32.0</code> is used for all the examples shown in this book.</p><p>You can use <code>perldoc</code> command to access documentation from the command line. You can visit <a href="https://perldoc.perl.org/">https://perldoc.perl.org/</a> if you wish to read it online, which also has a handy search feature. Here's some useful links to get started:</p><ul><li><a href="https://perldoc.perl.org/perl#Overview">perldoc: overview</a></li><li><a href="https://perldoc.perl.org/perlintro">perldoc: perlintro</a></li><li><a href="https://perldoc.perl.org/perlfaq">perldoc: faqs</a></li></ul><h2><a href="#command-line-options" id="command-line-options">Command line options</a></h2><p><code>perl -h</code> gives the list of all command line options, along with a brief description. See <a href="https://perldoc.perl.org/perlrun">perldoc: perlrun</a> for documentation on these command switches.</p><table><thead><tr><th><strong>Option</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td><code>-0[octal]</code></td><td>specify record separator (<code>\0</code>, if no argument)</td></tr><tr><td><code>-a</code></td><td>autosplit mode with <code>-n</code> or <code>-p</code> (splits <code>$_</code> into <code>@F</code>)</td></tr><tr><td><code>-C[number/list]</code></td><td>enables the listed Unicode features</td></tr><tr><td><code>-c</code></td><td>check syntax only (runs <code>BEGIN</code> and <code>CHECK</code> blocks)</td></tr><tr><td><code>-d[:debugger]</code></td><td>run program under debugger</td></tr><tr><td><code>-D[number/list]</code></td><td>set debugging flags (argument is a bit mask or alphabets)</td></tr><tr><td><code>-e program</code></td><td>one line of program (several <code>-e</code>'s allowed, omit programfile)</td></tr><tr><td><code>-E program</code></td><td>like <code>-e</code>, but enables all optional features</td></tr><tr><td><code>-f</code></td><td>don't do <code>$sitelib/sitecustomize.pl</code> at startup</td></tr><tr><td><code>-F/pattern/</code></td><td><code>split()</code> pattern for <code>-a</code> switch (<code>//</code>'s are optional)</td></tr><tr><td><code>-i[extension]</code></td><td>edit <code>&lt;&gt;</code> files in place (makes backup if extension supplied)</td></tr><tr><td><code>-Idirectory</code></td><td>specify <code>@INC/#include</code> directory (several <code>-I</code>'s allowed)</td></tr><tr><td><code>-l[octal]</code></td><td>enable line ending processing, specifies line terminator</td></tr><tr><td><code>-[mM][-]module</code></td><td>execute <code>use/no module...</code> before executing program</td></tr><tr><td><code>-n</code></td><td>assume <code>while (&lt;&gt;) { ... }</code> loop around program</td></tr><tr><td><code>-p</code></td><td>assume loop like <code>-n</code> but <code>print</code> line also, like <code>sed</code></td></tr><tr><td><code>-s</code></td><td>enable rudimentary parsing for switches after programfile</td></tr><tr><td><code>-S</code></td><td>look for programfile using <code>PATH</code> environment variable</td></tr><tr><td><code>-t</code></td><td>enable tainting warnings</td></tr><tr><td><code>-T</code></td><td>enable tainting checks</td></tr><tr><td><code>-u</code></td><td>dump core after parsing program</td></tr><tr><td><code>-U</code></td><td>allow unsafe operations</td></tr><tr><td><code>-v</code></td><td>print version, patchlevel and license</td></tr><tr><td><code>-V[:variable]</code></td><td>print configuration summary (or a single <code>Config.pm</code> variable)</td></tr><tr><td><code>-w</code></td><td>enable many useful warnings</td></tr><tr><td><code>-W</code></td><td>enable all warnings</td></tr><tr><td><code>-x[directory]</code></td><td>ignore text before <code>#!perl</code> line (optionally <code>cd</code> to directory)</td></tr><tr><td><code>-X</code></td><td>disable all warnings</td></tr></tbody></table><p>This chapter will show examples with <code>-e</code>, <code>-l</code>, <code>-n</code>, <code>-p</code> and <code>-a</code> options. Some more options will be covered in later chapters, but not all of them are discussed in this book.</p><h2><a href="#executing-perl-code" id="executing-perl-code">Executing Perl code</a></h2><p>If you want to execute a <code>perl</code> program file, one way is to pass the filename as argument to the <code>perl</code> command.</p><pre><code>$ echo 'print "Hello Perl\n"' &gt; hello.pl
$ perl hello.pl
Hello Perl
</code></pre><p>For short programs, you can also directly pass the code as an argument to the <code>-e</code> or <code>-E</code> options. See <a href="https://perldoc.perl.org/feature">perldoc: feature</a> for details about the features enabled by the <code>-E</code> option.</p><pre><code>$ perl -e 'print "Hello Perl\n"'
Hello Perl

$ # multiple statements can be issued separated by ;
$ # -l option will be covered in detail later, appends \n to 'print' here
$ perl -le '$x=25; $y=12; print $x**$y'
59604644775390625
$ # or, use -E and 'say' instead of -l and 'print'
$ perl -E '$x=25; $y=12; say $x**$y'
59604644775390625
</code></pre><h2><a href="#filtering" id="filtering">Filtering</a></h2><p><code>perl</code> one-liners can be used for filtering lines matched by a regexp, similar to <code>grep</code>, <code>sed</code> and <code>awk</code>. And similar to many command line utilities, <code>perl</code> can accept input from both <code>stdin</code> and file arguments.</p><pre><code>$ # sample stdin data
$ printf 'gate\napple\nwhat\nkite\n'
gate
apple
what
kite

$ # print all lines containing 'at'
$ # same as: grep 'at' and sed -n '/at/p' and awk '/at/'
$ printf 'gate\napple\nwhat\nkite\n' | perl -ne 'print if /at/'
gate
what

$ # print all lines NOT containing 'e'
$ # same as: grep -v 'e' and sed -n '/e/!p' and awk '!/e/'
$ printf 'gate\napple\nwhat\nkite\n' | perl -ne 'print if !/e/'
what
</code></pre><p>By default, <code>grep</code>, <code>sed</code> and <code>awk</code> will automatically loop over input content line by line (with <code>\n</code> as the line distinguishing character). The <code>-n</code> or <code>-p</code> option will enable this feature for <code>perl</code>. <a href="https://learnbyexample.github.io/learn_perl_oneliners/using-modules.html#convert-one-liners-to-pretty-formatted-scripts">O module</a> section shows the code Perl runs with these options.</p><p>As seen before, the <code>-e</code> option accepts code as command line argument. Many shortcuts are available to reduce the amount of typing needed. In the above examples, a regular expression (defined by the pattern between a pair of forward slashes) has been used to filter the input. When the input string isn't specified, the test is performed against special variable <code>$_</code>, which has the contents of the current input line here (the correct term would be input <strong>record</strong>, see <a href="https://learnbyexample.github.io/learn_perl_oneliners/record-separators.html#record-separators">Record separators</a> chapter). <code>$_</code> is also the default argument for many functions like <code>print</code> and <code>say</code>. To summarize:</p><ul><li><code>/REGEXP/FLAGS</code> is a shortcut for <code>$_ =~ m/REGEXP/FLAGS</code></li><li><code>!/REGEXP/FLAGS</code> is a shortcut for <code>$_ !~ m/REGEXP/FLAGS</code></li></ul><blockquote><p><img src="https://learnbyexample.github.io/learn_perl_oneliners/images/info.svg" alt="info"> See <a href="https://perldoc.perl.org/perlop#m/PATTERN/msixpodualngc">perldoc: match</a> for help on <code>m</code> operator. See <a href="https://perldoc.perl.org/perlvar#SPECIAL-VARIABLES">perldoc: special variables</a> for documentation on <code>$_</code>, <code>$&amp;</code>, etc.</p></blockquote><p>Here's an example with file input instead of <code>stdin</code>.</p><pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14

$ perl -nE 'say $&amp; if /(?&lt;!-)\d+$/' table.txt
42
14

$ # if the condition isn't required, capture groups can be used
$ perl -nE 'say /(\d+)$/' table.txt
42
7
14
</code></pre><blockquote><p><img src="https://learnbyexample.github.io/learn_perl_oneliners/images/info.svg" alt="info"> The <a href="https://github.com/learnbyexample/learn_perl_oneliners/tree/main/example_files">learn_perl_oneliners repo</a> has all the files used in examples (like <code>table.txt</code> in the above example).</p></blockquote><h2><a href="#substitution" id="substitution">Substitution</a></h2><p>Use <code>s</code> operator for search and replace requirements. By default, this operates on <code>$_</code> when the input string isn't provided. For these examples, <code>-p</code> option is used instead of <code>-n</code> option, so that the value of <code>$_</code> is automatically printed after processing each input line. See <a href="https://perldoc.perl.org/perlop#s/PATTERN/REPLACEMENT/msixpodualngcer">perldoc: search and replace</a> for documentation and examples.</p><pre><code>$ # for each input line, change only first ':' to '-'
$ # same as: sed 's/:/-/' and awk '{sub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | perl -pe 's/:/-/'
1-2:3:4
a-b:c:d

$ # for each input line, change all ':' to '-'
$ # same as: sed 's/:/-/g' and awk '{gsub(/:/, "-")} 1'
$ printf '1:2:3:4\na:b:c:d\n' | perl -pe 's/:/-/g'
1-2-3-4
a-b-c-d
</code></pre><blockquote><p><img src="https://learnbyexample.github.io/learn_perl_oneliners/images/info.svg" alt="info"> The <code>s</code> operator modifies the input string it is acting upon if the pattern matches. In addition, it will return number of substitutions made if successful, otherwise returns a <em>false</em> value (empty string or <code>0</code>). You can use <code>r</code> flag to return string after substitution instead of in-place modification. As mentioned before, this book assumes you are already familiar with <code>perl</code> regular expressions. If not, see <a href="https://perldoc.perl.org/perlretut">perldoc: perlretut</a> to get started.</p></blockquote><h2><a href="#field-processing" id="field-processing">Field processing</a></h2><p>Consider the sample input file shown below with fields separated by a single space character.</p><pre><code>$ cat table.txt
brown bread mat hair 42
blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre><p>Here's some examples that is based on specific field rather than the entire line. The <code>-a</code> option will cause the input line to be split based on whitespaces and the field contents can be accessed using <code>@F</code> special array variable. Leading and trailing whitespaces will be suppressed, so there's no possibility of empty fields. More details is discussed in <a href="https://learnbyexample.github.io/learn_perl_oneliners/field-separators.html#default-field-separation">Default field separation</a> section.</p><pre><code>$ # print the second field of each input line
$ # same as: awk '{print $2}' table.txt
$ perl -lane 'print $F[1]' table.txt
bread
cake
banana

$ # print lines only if last field is a negative number
$ # same as: awk '$NF&lt;0' table.txt
$ perl -lane 'print if $F[-1] &lt; 0' table.txt
blue cake mug shirt -7

$ # change 'b' to 'B' only for the first field
$ # same as: awk '{gsub(/b/, "B", $1)} 1' table.txt
$ perl -lane '$F[0] =~ s/b/B/g; print "@F"' table.txt
Brown bread mat hair 42
Blue cake mug shirt -7
yellow banana window shoes 3.14
</code></pre><p>See <a href="https://learnbyexample.github.io/learn_perl_oneliners/field-separators.html#output-field-separator">Output field separator</a> section for details on using array variable inside double quotes.</p><h2><a href="#begin-and-end" id="begin-and-end">BEGIN and END</a></h2><p>You can use a <code>BEGIN{}</code> block when you need to execute something before input is read and a <code>END{}</code> block to execute something after all of the input has been processed.</p><pre><code>$ # same as: awk 'BEGIN{print "---"} 1; END{print "%%%"}'
$ seq 4 | perl -pE 'BEGIN{say "---"} END{say "%%%"}'
---
1
2
3
4
%%%
</code></pre><h2><a href="#env-hash" id="env-hash">ENV hash</a></h2><p>When it comes to automation and scripting, you'd often need to construct commands that can accept input from user, file, output of a shell command, etc. As mentioned before, this book assumes <code>bash</code> as the shell being used. …</p></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://learnbyexample.github.io/learn_perl_oneliners/one-liner-introduction.html">https://learnbyexample.github.io/learn_perl_oneliners/one-liner-introduction.html</a></em></p>]]>
            </description>
            <link>https://learnbyexample.github.io/learn_perl_oneliners/one-liner-introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014639</guid>
            <pubDate>Sat, 07 Nov 2020 12:16:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why not use GraphQL?]]>
            </title>
            <description>
<![CDATA[
Score 410 | Comments 380 (<a href="https://news.ycombinator.com/item?id=25014582">thread link</a>) | @jensneuse
<br/>
November 7, 2020 | https://wundergraph.com/blog/why_not_use_graphql | <a href="https://web.archive.org/web/*/https://wundergraph.com/blog/why_not_use_graphql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I think GraphQL will change the world. There will be a future where you can query any system in the world using GraphQL. I'm building this future. So why would I argue against using GraphQL? My personal pet peeve is when the community keeps advertising benefits of GraphQL that are very generic and really have nothing to do with GraphQL. If we want to drive adoption, we should be honest and take off the rose-tinted glasses. This post is a response to "Why use GraphQL" by Kyle Schrade (<a href="https://www.apollographql.com/blog/why-use-graphql/" target="_blank" rel="noopener noreferrer">https://www.apollographql.com/blog/why-use-graphql/</a>). It’s not meant to be direct criticism. The article is just an excellent base to work with as it represents opinions I keep hearing a lot in the community. If you read the whole article, it’ll take some time, you’ll fully understand why I think Kyle’s article should be named “Why use Apollo”.</p><p>If you haven't read Kyles's article already, I think it makes most sense if you read it first: <a href="https://www.apollographql.com/blog/why-use-graphql/" target="_blank" rel="noopener noreferrer">https://www.apollographql.com/blog/why-use-graphql/</a></p><p>The author states that REST APIs come with a set of downsides and how GraphQL solves all of them:
Over-fetching
Multiple requests for multiple resources
Waterfall network requests on nested data
Each client need to know the location of each service</p><p>The first three issues could be solved by writing another REST API as a facade for a specific user interface. Take Next.JS as an example. Next lets you define APIs with a very lightweight syntax. Instead of making multiple requests from the client, you can wrap those calls into an API and make them server-side. Over and underfetching can be solved with this approach too, as you can manipulate the data before sending it back to the client. The pattern described is named "backend for frontend" (BFF). It's not limited to full stack frameworks like Next.JS. You can build a BFF for your mobile apps as well.</p><p>With the BFF pattern, the client itself doesn't have to know the location of each service. However, the developer who implements the BFF needs to understand the service landscape. Hopefully you have Open API Specifications for all your services, nicely presented in a developer portal. If that's the case, it should be easy to write a BFF.</p><p>With GraphQL, there still needs to be a developer who implements the resolvers. Implementing the resolvers is more or less the same task as building a BFF, the logic is very similar. So, what's the real difference?</p><p>The BFF is easier to implement as there's a lot more tooling available. E.g. if you use a framework like Next.JS in combination with swr hooks (stale while revalidate) you get automatic caching with Etags and cache invalidation out of the box. This reduces the amount of data sent between server and client. It's even less data than GraphQL, because you're not sending query payloads and the server responds with 304 (Not Modified) if the response is still valid. Additionally, you don't have to use a heavyweight client like Apollo. The library swr by Vercel is small and very easy to use. It comes with support for pagination, hooks, and helps to navigate back and forth very efficiently.</p><p>GraphQL has persisted queries but it comes with additional overhead to implement this. If you don't use a client like Relay, which persists Queries by default, you have to do it on your own or use some third party library to implement it. Compared to the BFF approach using e.g. Next.JS there's a lot more complexity involved in getting to the same results on the frontend. How would you implement Etags with GraphQL? How do you make your GraphQL server return 304 status codes if nothing changed? Don't you first have to turn all Queries into GET requests? If so, does your GraphQL client and server easily support this?</p><p>When it comes to user experience and ease of development, the BFF is the clear winner. Less data transfer between client and server. Easier to implement. Smaller client, less moving parts.</p><p>But there's a catch. You have to build a BFF for each individual frontend. If you have many of them this can be a lot of work. You have to maintain all the BFFs. You have to operate them. You have to secure them.</p><p>Wouldn't it be nice if you could have the benefits of both without making tradeoffs? This is exactly what WunderGraph is. A framework to build BFFs using GraphQL.</p><p>In the next paragraph, Kyle goes on with the problems involved with versioned APIs. He's absolutely right that having too many versions of an API makes it very hard to keep track of. He then concludes that in GraphQL, there's only one version of the graph and changes can be tracked in a schema registry, a paid feature of Apollo. For that reason you won’t have any problems with versioning, he says.</p><p>I have problems coming to the same conclusion. Just because GraphQL schemas don’t support versioning natively doesn’t mean the problem goes away. You get the same effect if you just don’t version your REST APIs. In fact, many experts say that you should always try to not introduce versions of an API if you don’t have to. That being said, what holds you off running two versions of your GraphQL schema? Not that I think this is a good idea but it's technically possible.</p><p>If having too many versions of your REST APIs is a problem in your organization, before throwing a new tool like GraphQL at the problem, maybe you should have a look at the organization first. What are the reasons for having so many versions? Maybe the change of a process or new team structures can help? GraphQL does absolutely nothing to solve your versioning problems. Instead I think it actually makes the situation worse.</p><p>Do you have to support mobile applications? You should be aware that shipping native apps takes time. You have to wait for app store approval and you can expect many of your users to never (or slowly) install the new version. What if you want to introduce a breaking change in this scenario without breaking a client? It's impossible. You have to introduce this change in a non-breaking way. It would be interesting to hear from Facebook how they avoided breaking clients.</p><p>Evolving your schema in the case of GraphQL would mean, you deprecate the old field and add a new one. New clients use the new field while you hope that the number of clients using the old field will get less and less. Hopefully, you have a system in place that forces your users to download a new version at some point in time. Otherwise, you might be forced to support the deprecated field indefinitely. If that's the case, the deprecation model of GraphQL doesn't help you at all.</p><p>With REST you could create a new endpoint or another version of an existing one. The problem is the same, the solution just looks a bit different.</p><p>To make it clear, if you cannot control your clients you really want some kind of versioning. If all you have is a single web application you won’t need this feature. But then again GraphQL might be overkill as well.</p><p>In this paragraph, the author states that RESTful APIs don't allow partial responses.</p><p>This is just wrong. Here's an example:</p><div><div><div tabindex="0"><div><p><span>GET /users?fields=results(gender,name)</span></p></div></div></div></div><p>What does the author actually mean? I'm pretty sure he's aware of partial responses. I guess what he's trying to say is that someone needs to implement partial responses. Actually, it looks very familiar to GraphQL as you're selecting subfields from a resource. With GraphQL we have this feature out of the box.</p><p>On the other hand, with the BFF approach, you don't need this. Just return exactly the data you need. Again, a full-stack framework like Next.JS makes it simpler to implement this, makes caching easier and gives you Etag based cache invalidation for free.</p><p>To sum this section up, GraphQL gives you exactly the data you need. Partial responses can achieve the same result. BFFs come with the additional cost of implementation and maintenance but have a better UX &amp; DX.</p><p>In this paragraph, Kyle addresses the issues of REST APIs not being strictly typed. He talks about the problems with APIs where it's not clear if you get an array of posts or something different and how query parameters complicate the situation. He also states that GraphQL, because of its strict type system, doesn't have this problem.</p><p>I think what Kyle is talking about is an organizational problem for which you need an organizational solution.</p><p>You have the kind of problems he describes, when you allow developers to deploy REST APIs without publishing Open API Specifications (OAS) or similar. With OAS all resources can be described very easily. OAS also allows you to describe OAuth2 flows and required scopes per endpoint. Additionally, you can describe the exact types and validation rules for query parameters, a feature that GraphQL is lacking.</p><p>Looking at GraphQL, there's no way to describe Authentication, Authorization and input validation. GraphQL is lacking these features because the inventors at Facebook solved this problem at a different layer. There was no need for them to add these features to GraphQL. You can add custom directives to your schema to achieve similar results like OAS but this would be a custom implementation which you have to maintain yourself.</p><p>You might be thinking that OAS doesn't guarantee the response of an API to be compliant with the specification. You would be right. But how does a GraphQL schema guarantee anything?</p><p>GraphQL introspection is the act of sending a specific GraphQL query to the server to get information about the GraphQL schema. The GraphQL server is free to answer with whatever types it wants to. If you send a Query, the server can answer with a response that doesn't adhere to the GraphQL schema from the introspection response. Take Apollo Federation as an example. You upload your schema into a schema registry and then, by error, deploy the wrong version of your GraphQL server. If you change the type of a field, the client might be confused.</p><p>When we talk about type safety in GraphQL, what we actually mean is that we trust in a GraphQL server to behave exactly as advertised by the introspection Query …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wundergraph.com/blog/why_not_use_graphql">https://wundergraph.com/blog/why_not_use_graphql</a></em></p>]]>
            </description>
            <link>https://wundergraph.com/blog/why_not_use_graphql</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014582</guid>
            <pubDate>Sat, 07 Nov 2020 11:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Advanced Join Patterns for the Actor Model Based on CEP Techniques]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25014513">thread link</a>) | @mpweiher
<br/>
November 7, 2020 | https://programming-journal.org/2021/5/10/ | <a href="https://web.archive.org/web/*/https://programming-journal.org/2021/5/10/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            


            
            
            <p>Humberto Rodriguez Avila<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>, Joeri De Koster<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>, and Wolfgang De Meuter<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></p>

<p>The Art, Science, and Engineering of Programming, 2021, Vol. 5, Issue 2, Article 10</p>

<p>Submission date: 2020-02-06<br>
Publication date: 2020-11-02<br>
DOI: <a href="https://doi.org/10.22152/programming-journal.org/2021/5/10">https://doi.org/10.22152/programming-journal.org/2021/5/10</a><br>
Full text: <a href="https://arxiv.org/pdf/2010.16301v1">PDF</a></p>

<h3 id="abstract">Abstract</h3>
<p>Context: Actor-based programming languages offer many essential features for developing modern distributed reactive systems. These systems exploit the actor model’s isolation property to fulfill their performance and scalability demands. Unfortunately, the reliance of the model on isolation as its most fundamental property requires programmers to express complex interaction patterns between their actors to be expressed manually in terms of complex combinations of messages sent between the isolated actors.</p>

<p>Inquiry: In the last three decades, several language design proposals have been introduced to reduce the complexity that emerges from describing said interaction and coordination of actors. We argue that none of these proposals is satisfactory in order to express the many complex interaction patterns between actors found in modern reactive distributed systems.</p>

<p>Approach:  We describe seven smart home automation scenarios (in which an actor represents every smart home appliance) to motivate the support by actor languages for five radically different types of message synchronization patterns, which are lacking in modern distributed actor-based languages. Fortunately, these five types of synchronisation patterns have been studied extensively by the Complex Event Processing (CEP) community. Our paper describes how such CEP patterns are elegantly added to an actor-based programming language.</p>

<p>Knowledge: Based on our findings, we propose an extension of the single-message matching paradigm of contemporary actor-based languages in order to support a multiple-message matching way of thinking in the same way as proposed by CEP languages. Our proposal thus enriches the actor-model by ways of declaratively describing complex message combinations to which an actor can respond.</p>

<p>Grounding: We base the problem-statement of the paper on an online poll in the home automation community that has motivated the real need for the CEP-based synchronisation operators between actors proposed in the paper. Furthermore, we implemented a DSL —— called Sparrow —— that supports said operators and we argue quantitatively (in terms of LOC and in terms of a reduction of the concerns that have to be handled by programmers) that the DSL outperforms existing approaches.</p>

<p>Importance: This work aims to provide a set of synchronization operators that help actor-based languages to handle the complex interaction required by modern reactive distributed systems. To the best of our knowledge, our proposal is the first one to add advanced CEP synchronization operators to the —— relatively simplistic single-message based matching —— mechanisms of most actor-based languages.</p>



          </section></div>]]>
            </description>
            <link>https://programming-journal.org/2021/5/10/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014513</guid>
            <pubDate>Sat, 07 Nov 2020 11:36:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arch Conf 2020]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 34 (<a href="https://news.ycombinator.com/item?id=25014421">thread link</a>) | @todsacerdoti
<br/>
November 7, 2020 | https://media.ccc.de/c/arch-conf-2020 | <a href="https://web.archive.org/web/*/https://media.ccc.de/c/arch-conf-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://media.ccc.de/c/arch-conf-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014421</guid>
            <pubDate>Sat, 07 Nov 2020 11:09:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 400 – First Impressions]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 138 (<a href="https://news.ycombinator.com/item?id=25014025">thread link</a>) | @martinpeck
<br/>
November 7, 2020 | https://martinpeck.com/blog/2020/11/06/Raspberry-Pi-400/ | <a href="https://web.archive.org/web/*/https://martinpeck.com/blog/2020/11/06/Raspberry-Pi-400/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>I grew up programming on my TV, with a Sinclair ZX81 followed by a ZX Spectum. Computers built into keyboards, that you can easily plug into a TV, are part of my DNA. So, given this, how could I resist buying the new <a href="https://www.raspberrypi.org/products/raspberry-pi-400/">Raspberry Pi 400</a>!?</p>

<p>The following are my initial thoughts on the hardware, and on using it for light weight development.</p>

<p>TL;DR: I like it :)</p>

<h2 id="tech-specs">Tech Specs</h2>

<p>The Raspberry Pi 400 is, essentially, a Raspberry Pi 4 housed within a keyboard. You can read much better descriptions elseewhere, but the main points from the tech specs are:</p>

<ul>
  <li>Broadcom BCM2711 quad-core Cortex-A72 (ARM v8) 64-bit SoC @ 1.8GHz</li>
  <li>4GB LPDDR4-3200</li>
  <li>Dual-band (2.4GHz and 5.0GHz) IEEE 802.11b/g/n/ac wireless LAN</li>
  <li>Bluetooth 5.0, BLE</li>
  <li>Gigabit Ethernet</li>
  <li>2 × USB 3.0</li>
  <li>1 × USB 2.0 ports</li>
  <li>Horizontal 40-pin GPIO header</li>
  <li>2 × micro HDMI ports (supports up to 4Kp60)</li>
  <li>MicroSD card slot for operating system and data storage</li>
  <li>79-key compact keyboard</li>
</ul>

<p>(full specs can be found <a href="https://www.raspberrypi.org/products/raspberry-pi-400/specifications/">here</a>)</p>

<p>The 400 comes with a 16GB SD card pre-installed with Raspbian, and a host of apps (LibreOffice), dev tools (Geany, Mathematica, Scratch), utilities (Chromium, VLC Media Player), and games (Minecraft).</p>

<h2 id="first-impressions-on-the-hardware">First Impressions on the Hardware</h2>

<p>It was <em>very</em> easy to plug the 400 in and get it up and running. It’s a neat device, with a good collection of ports and connectors at the back. The keyboard is…ok. The device is £67 in the UK. I bought the kit (which includes a mouse, power supply, HDMI cable, and official guide) for £94. Given the price point the keyboard is absolutely fine, but it does feel a tiny bit “plasticy”.</p>

<p>The 400 doesn’t have an audio-out. Audio is delivered via the HDMI output. For me, that’s a problem because my monitor doesn’t have speakers. It’s not a BIG problem, but it’s something I hadn’t considered.</p>

<p>The other thing the 400 doesn’t have is the connector for the Raspberry Pi camera module. Again, this isn’t a big deal for me but if you were expecting to build any camera projects then the 400 isn’t the right choice.</p>

<p>The 400has the GPIO header at the back, so with a ribbon cable you can build electronics projects very easily. I have an <a href="https://www.adafruit.com/product/2028">Adafruit T-Cobbler Plus</a> which makes it very easy to connect the 400 to a breadboard and build…stuff!</p>

<p><img src="https://martinpeck.com/images/rpi400/gpio.jpg" alt="GPIO"></p>

<p>The 400 starts up quickly, and is very capable as a general purpose desktop device. I’ve spent most of today browsing the web on it, while also installing apps, running docker containers, and building code, and it’s felt fast/snappy pretty much most of the time.</p>

<p>Overall, the hardware is pretty good and I love the form factor. I can see schools/code clubs purchasing these devices and using the in their computing labs.</p>

<h2 id="developer-experience">Developer Experience</h2>

<p>I’ve spent the day setting my Raspberry Pi 400 up, and I’m pretty impressed. My setup has included:</p>

<ul>
  <li>Set up Chromium, and installed the <a href="https://1password.com/">1Password extension</a></li>
  <li>Installed <a href="https://code.visualstudio.com/">Visual Studio Code</a> using <a href="https://pimylifeup.com/raspberry-pi-visual-studio-code/">these instructions</a></li>
  <li>Installed the <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers">VS Code Remote Containers extension</a> so that I can use Docker dev containers to develop code within</li>
</ul>

<p>On the whole, this setup was easy. So easy it was almost boring! I had a couple of issues, but on the whole it was very easy to set my Raspberry Pi 400 up so that I can write code, use Docker, and push changes to GitHub. For example, I’m currently writing this blog post within VS Code, building it using <a href="https://jekyllrb.com/">Jekyll</a> within a Docker container.</p>

<p>The only issue that I hit is the ARM support for various Docker images. The default Ruby dev container image wouldn’t build because it had some dependencies that didn’t have ARM variants. In the end I took the Ruby 2.7 docker image as a base, and copy/pasted into my own <code>Dockerfile</code> the parts of the defintion I needed (removing Node, Zsh, Oh my Zsh and a few other things). I’m not sure exactly what it was that was failng to build, so I need to go back and work it out, but it’s worth remembering that if the Rasberry Pi is ARM based, and not all development tools have ARM builds.</p>

<p>Having installed tools, and played around, I’ve built some very basic Rust code (with build times comparible to my MacBook!), I’ve written some <a href="https://gpiozero.readthedocs.io/en/stable/">GPIOZero</a> based Python 3 code (controlling butons and LEDs), and I’ve set up a Jekyll/Ruby dev container and built/updated my blog.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I own several Raspberry Pi computers (1, 2 and 3). Most of them are the Model B format, but I have couple of Zeros too. All of them sit in a box, unused. I’ve played with them, then put them away. Part of that is because the performance hasn’t been that great, but the form factor is a major factor. It feels like the Raspberry Pi 400 has the power I need (for casual projects), and comes in a form factor that I can happily leave plugged in on my desk.</p>

<p>On top of that…it gives me a massive nostalgia rush using it!</p>

<p><img src="https://martinpeck.com/images/rpi400/desktop.jpg" alt="GPIO"></p>

<p>In the picture below I have two instances of VS Code (both running dev containers), plus I’m browsing. It takes it all in its stride.</p>

<p><img src="https://martinpeck.com/images/rpi400/pi-400-desktop.png" alt="GPIO"></p>

<p>I’ve not tried building anything huge…but that’s not what it’s for. It’s for having fun…</p>

<p>…and I’m <strong>absolutely having fun</strong>!</p>

			</div></div>]]>
            </description>
            <link>https://martinpeck.com/blog/2020/11/06/Raspberry-Pi-400/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25014025</guid>
            <pubDate>Sat, 07 Nov 2020 09:19:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Government Continues Encryption War]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 84 (<a href="https://news.ycombinator.com/item?id=25013802">thread link</a>) | @freddyym
<br/>
November 7, 2020 | https://blog.privacytools.io/us-government-continues-encryption-war/ | <a href="https://web.archive.org/web/*/https://blog.privacytools.io/us-government-continues-encryption-war/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.privacytools.io/content/images/size/w300/2020/10/binarycrypto.png 300w,
                            https://blog.privacytools.io/content/images/size/w600/2020/10/binarycrypto.png 600w,
                            https://blog.privacytools.io/content/images/size/w1000/2020/10/binarycrypto.png 1000w,
                            https://blog.privacytools.io/content/images/size/w2000/2020/10/binarycrypto.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.privacytools.io/content/images/size/w2000/2020/10/binarycrypto.png" alt="US Government Continues Encryption War">
            </figure>

            <section>
                <div>
                    <p>Wars can be fought in the real world but there is also a virtual battlefield - and it is just as harmful. The <a href="https://www.judiciary.senate.gov/press/rep/releases/graham-cotton-blackburn-introduce-balanced-solution-to-bolster-national-security-end-use-of-warrant-proof-encryption-that-shields-criminal-activity">Lawful Access to Encrypted Data Act</a> is the latest attempt to access people's encrypted data and it serves as another reinforcement.</p><blockquote>This type of “warrant-proof” encryption adds little to the security of the communications of the ordinary user, but it is a serious benefit for those who use the internet for illicit purposes.</blockquote><p>This statement is plainly false. Encryption has as much benefit, if not more, for ordinary users. Encryption is used in every website that has the padlock sign (HTTP<strong>S</strong>), in every iPhone app since 2016, in every Android app since 2018 and in almost every modern application - and for good reason. Encryption helps protect sensitive information (such as that shared with your bank, or any time you use a password on a website). It may also help protect files which are not in use (at rest), or in the event the server is accessed by an unauthorised person (such as a criminal attempting to siphon off important data).</p><p>In 2016, Bruce Schneier wrote an article on <a href="https://www.schneier.com/essays/archives/2016/04/the_value_of_encrypt.html">the value of encryption</a> clearly outlining why encryption is needed. Schneier went on to say that when the US Government was <a href="https://blog.privacytools.io/us-government-wages-war-on-encryption/">previously</a> <a href="https://en.wikipedia.org/wiki/Crypto_Wars">fighting cryptography</a>, he wondered if they were aware how much they relied on it themselves. No-one is above the law, so if you ban strong encryption, the FBI should not use it either. Attorney General Barr, <a href="https://www.theregister.com/2019/07/23/us_encryption_backdoor/">gives the impression</a> that the government, along with certain large companies, should have an exception to the law. Barr recognises that there are some things that are secret, but he doesn't recognise that regular citizens might also want to enjoy privacy as well.</p><blockquote>“We are not talking about protecting the nation’s nuclear launch codes,” Barr told the International Conference on Cyber Security at Fordham University.</blockquote><blockquote>“Nor are we necessarily talking about the customized encryption used by large business enterprises to protect their operations. We are talking about consumer products and services such as messaging, smart phones, email, and voice and data applications."</blockquote><p>Somehow, because your average Joe does not have government level secrets, he is no longer entitled to encryption. We are all humans, and we all need privacy. By taking away encryption, you are taking away privacy online.</p><p>This act is aimed at Section 230, which ensures that no interactive computer service provider shall be treated as the publisher or speaker of content published by their users - an essential part of the survival of all search engines, social media platforms and video sharing sites. Without it, the internet would become a self-censored platform – one that is more concerned with fending off lawsuits than providing a medium for ideas and innovation as it originally was.</p><p>It is easy to sympathise with an act that is being pushed through on the grounds that terrorists, paedophiles and drug-dealers all use encryption. Reading the <a href="https://www.nytimes.com/interactive/2019/09/28/us/child-sex-abuse.html">New York Times</a>' <a href="https://www.nytimes.com/2020/02/19/podcasts/the-daily/child-sex-abuse.html">reporting</a> on online images of &nbsp;sexual abuse would leave some wondering why this sort of Act has not been passed already. Equally, if no-one had encryption then it would certainly be easier to catch above mentioned crooks and fellons.</p><p>Encryption, however, did not create these problems; these crimes were around long before it came into existence. In addition, those who partake in illicit activity will always find loopholes and ways to do so, such as using products or encryption tools that don't have backdoors. Criminals do not obey laws by definition. Furthermore, many innocent people use similar encryption to these criminals, but only to protect privacy, not hide any illegalities and yet they could still be subject to some kind of prosecution. It is assumed the use or possession of non-backdoored software would also become an offence if too many people used that instead. Statistically, it's agreed there are many more innocent people in society than criminals; those innocent people would be punished as a result of the bad actions of a few.</p><p>It is not feasible for a government to make a law of this sort that can apply outside of it's own country. Governments around the world would almost certainly disagree on which countries should be allowed access to the backdoor. As a result, this backdoor would most certainly lead to every unauthorised party having access, as the key to decrypt the data would be discovered by third parties, this would result in completely broken encryption for all. In federated networks, such as Matrix, it's not even possible to add a backdoor to every homeserver. Federation decentralises trust, which means that the person deploying the server isn't necessarily the same entity who makes the client software or server software. Matrix has even written a <a href="https://matrix.org/blog/2020/10/19/combating-abuse-in-matrix-without-backdoors">thorough article</a> on how to combat this sort of abuse without backdoors. </p><p>Weakening encryption will only result in criminals using strong encryption anyway, without fighting any of the problems that the the law claims to solve. There is no easy solution, and it is down to politicians to provide one. Yes, encryption can be used by people with bad intentions, but it is also used by so many ordinary people who would never think to use it in a malicious way. Nearly every tool in life can be used for nefarious purposes, but does not mean it should be unavailable for legitimate non-criminal uses. You could hit someone with a hammer, but it doesn't mean hammers should be made out of foam, because if they were, people would just use knives instead. Weakening encryption will not solve these issues, and that's probably because they were not the the focus of the Act. Instead, it seems that this law seeks to criminalises strong encryption that does not have backdoors, even though the government knows full well that this will not stop criminals. The US Government should stop devising new ways to breach its citizens privacy, and focus on combating the issues that this Act fails to.</p><p>In 1988, Timothy May <a href="https://activism.net/cypherpunk/crypto-anarchy.html">predicted</a> that “the State will of course try to slow or halt the spread of [encryption], citing national security concerns, use of the technology by drug dealers and tax evaders, and fears of societal disintegration”. He was spot on.</p><p><em>Cover artwork by <a href="https://setofprinciples.com/">Zan</a></em></p>
                </div>
            </section>


            

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.privacytools.io/us-government-continues-encryption-war/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25013802</guid>
            <pubDate>Sat, 07 Nov 2020 08:22:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Browser – WorldWideWeb Next Application]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25013103">thread link</a>) | @mpweiher
<br/>
November 6, 2020 | https://worldwideweb.cern.ch/worldwideweb/ | <a href="https://web.archive.org/web/*/https://worldwideweb.cern.ch/worldwideweb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    
<section>
	<h2>WorldWideWeb</h2>
	<div>
		<p>The idea of hypertext preceded the World Wide Web by decades. But nearly all hypertext systems worked on local files. Tim Berners-Lee wanted to create a system that would work across networks so that people could link from a file on one machine to another file on another machine.</p>
		<p>WorldWideWeb wasn't just a programme for browsing files. It was a browser and editor. The introductory text reads:</p>
		<blockquote>HyperMedia Browser/Editor, An excercise in global information availability by Tim Berners-Lee</blockquote>
		<p>Today it's hard to imagine that web browsers might also be used to create web pages. It turned out that people were quite happy to write HTML by hand—something that Tim Berners-Lee and colleagues never expected. They thought that some kind of user interface would be needed for making web pages and links. That's what the WorldWideWeb browser provided. You could open a document in one window and "mark" it. Then, in a document in another window, you could create a link to the marked page.</p>
		<p>You'll notice as you use the WorldWideWeb browser that you need to double-click links to open them. That's because a single click was used for editing.</p>
	</div>
</section>

<section>
	<h2>Browsing</h2>
	<div>
		<p>The user interface of the WorldWideWeb browser somewhat blurred the lines between documents on your own computer and documents out on the network. To "browse" directly to a document out on the network, you need to know its URL. But you can't simply type that URL into an address bar; there is no address bar. Instead you have to follow a sequence of steps:</p>
		<ol>
			<li>From the "WorldWideWeb" menu, select "Document".</li>
			<li>Now from the newly-opened "Document" menu, select "Open from full document reference".</li>
			<li>Type the URL into the field marked "reference".</li>
			<li>Press the "Open" button</li>
		</ol>
		<p>Once you've got a web-based document (or web page, as we would say today) open in WorldWideWeb, you can navigate by double-clicking on links. Every link you double-click will open in a new window.</p>
	</div>
</section>

<section>
	<h2>Linking</h2>
	<div>
		<p>At its heart, WorldWideWeb is a word processor …but with links. And just as you <em>can</em> use a word processor purely for reading documents, the real fun comes when you write your own. Especially when you throw hyperlinks into the mix.</p>
		<p>To create a document:</p>
		<ol>
			<li>From the "WorldWideWeb" menu, select "New File..."</li>
			<li>Type the name of the file you want to create e.g. example.html</li>
			<li>In the boilerplate document, click on the heading to edit. Same with the text.</li>
		</ol>
		<p>Once you've got a document written, it's time to turn from regular text into <em>hyper</em>text:</p>
		<ol>
			<li>From the "WorldWideWeb" menu, select "Links"</li>
			<li>To link to another document, you need to have that other document open in another window. Click on its title bar to focus it.</li>
			<li>With that document in focus, select "Mark all" from the "Links" menu.</li>
			<li>Now switch back to your example.html document and highlight the text you want to be a link.</li>
			<li>From the "Links" menu, select "Link to marked".</li>
		</ol>
		<p>You can even save your new document on to your hard drive. Click on "Save a copy offline" under the "Documents" menu.</p>
		<p>Once you've downloaded the file to your computer, you can open it up with a text editor to see what the HTML would have looked like.</p>
	</div>
</section>

<section>
<h2>Editing</h2>
<div>
	<p>To edit any document, whether it's one you created, or a page on the world wide web:</p>
	<ol>
		<li>Click on the text you want edit.</li>
		<li>Edit it.</li>
	</ol>
	<p>That's it.</p>
	<p>If you want to keep a copy of the edited document, choose "Save a copy offline" from the "Documents" menu.</p>
	</div>
</section>

<section>
	<h2>Components</h2>
	<p>Here is a collection of HTML-based components recreating the original NeXT interface. Feel free to grab, view-source, etc, to use for your own projects. </p>
	<section>
		<h3 id="#palette-section">Color Palette</h3>

		
	</section>

	<section>
		<h3 id="form-section">Form Elements</h3>

		<h4>Inputs</h4>
		<p><label>A label </label></p>
		<h4>Fieldsets</h4>
		
	</section>

	<section>
		<h3 id="buttons-section">Buttons</h3>
		<p>In the case of buttons, there's no standard for paddings. The button must
				match the width/height of the parent, so all buttons of the same group are of the
				same width/height.</p>

		<h4>Simple button</h4>
		
		<h4>Image Buttons</h4>
		
	</section>

	<section>
		<h3 id="panels-section">Panels</h3>
		<p>Width and height properties must be defined locally.</p>
		<div>
			<div>
				
				<p>Content goes here; it can be a webview, group of buttons, forms...</p>
			</div>

			<div>
				
				<p>Content goes here; it can be a webview, group of buttons, forms...</p>
			</div>
		</div>
	</section>

	<section>
		<h3 id="webview-section">WebView</h3>
		<p>Width and height properties must be defined locally.</p>
		<div>
			<div>
				<div>
					<div>
						<p><a href="#">Omnia sol temperat</a>
								Purus et subtilis<br>
								Novo mundo reserat<br>
								Faciem Aprilis<br>
								Ad amorem properat<br>
								Animus herilis<br>
								Et iocundis imperat<br>
								Deus puerilis<br>
								Et iocundis imperat<br>
								Deus puerilis</p>
							<p>Ama me fideliter<br>
								Fidem meam nota<br>
								De corde totaliter<br>
								Et Ex mente tota<br>
								Ama me fideliter<br>
								Fidem meam nota<br>
								De corde totaliter<br>
								Et Ex mente tota</p>

							<p>Rerum tanta novitas<br>
								In sollmenti vere<br>
								Et veris auctoritas<br>
								Iubet nos gaudere<br>
								Vices prebet solitas<br>
								Et in tuo vere<br>
								Fides est et probitas<br>
								Tuum retinere<br>
								Fides est et probitas<br>
								Tuum retinere</p>
					</div>
				</div>
				</div>
		</div>
	</section>

	<section>
		<h3 id="nav-section">Floating Menus</h3>
		
	</section>

	<section>
		<h3 id="general-section">General UI Elements</h3>
		<h4>Divisions</h4>
		
	</section>

	<section>
		<h3 id="open-url-section">Open URL</h3>
		<div>
			<div id="open-url">
				<div>
					<h3>Open using hypertext reference</h3>
					</div>
				
			</div>
		</div>
	</section>

	<section>
			<h3 id="navigation-section">Browser Navigation</h3>
			
	</section>

	<section>
			<h3 id="info-section">Info Dialog</h3>
			<div>
				<div id="browser-info">
					
					<div>
						<header>
							<p><img src="https://worldwideweb.cern.ch/images/ui-patterns/wwwicon.png" alt=""></p>
							<div>
								<h4>HyperMedia Browser/Editor</h4>
								<p>An excercise in global information availability</p>
							</div>
							<p>Version 1.0<br>Alpha only</p>
							<address>by Tim Berners-Lee</address>
						</header>
						<hr>
						<div>
							<p>Copyright 1990, 91
									<span>Distribution restricted: ask for terms.</span>
									<span>TEST VERSION ONLY</span></p>
							<dl>
								<p>
									<dt>HyperText:</dt>
									<dd>Text which is not constrained to be linear.</dd>
								</p>
								<p>
									<dt>HyperMedia:</dt>
									<dd>Information which is not constrained linear... or to be text.</dd>
								</p>
							</dl>
						</div>
						<div>
							<div>
								<div>
									<div>
									<p>This is the first version of the NextStep WorldWideWeb application
								 like the libWWW Library. <br>
								 It can pick up hypertext information from files in a number of formats, from local files, from remote files using NFS 
								 or anonymous FTP, from hypertext servers by name or keyword search, and from internet news.<br>
								 Hypertext files may be edited, and links made from hypertext files to other files or any other information.
								 <br>
								 </p><p>For more help, use "Help" from the menu. If that doesn't work, then your application has been incompletely installed.
								 </p><p>If you have any comments or have bugs, please mail timbl@info.cern.ch quoting the version number
								 (above).</p>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</div>
		</section>

	<section>
		<h3 id="style-editor-section">Style Editor</h3>
		
	</section>
</section>

<!--

<section>

No images. Three levels of grey.


</section>

<section>
<img src="/images/screenshots/image2.png" alt="A style editor from the NeXT Cube computer" />
<img src="/images/screenshots/image7.png" alt="A style editor from the NeXT Cube computer" />
<img src="/images/screenshots/image11.png" alt="Document inspector from the NeXT Cube computer" />
<img src="/images/screenshots/image15.png" alt="Info Window for NeXT Cube computer's Hypermedia browser / editor with a Nexus" />
<img src="/images/screenshots/image21.png" alt="Reading news from the NeXT Cube computer's Nexus browser" />
</section>
-->


  </div></div>]]>
            </description>
            <link>https://worldwideweb.cern.ch/worldwideweb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25013103</guid>
            <pubDate>Sat, 07 Nov 2020 03:50:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use a Conversational Hook When Networking with Strangers]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25012993">thread link</a>) | @mooreds
<br/>
November 6, 2020 | https://letterstoanewdeveloper.com/2019/02/25/use-a-conversational-hook-when-networking-with-strangers/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2019/02/25/use-a-conversational-hook-when-networking-with-strangers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-136">
			<!-- .entry-header -->		<!-- .entry-meta -->
	
	<div>
		<p>Dear new developer,</p>
<p>Work on your network. It will help you in numerous ways as you progress in your career. Whatever you are looking for: a new job, to hire someone, to get a mentor, to learn about a new technology, having a list of people that you know and/or have worked with that you can reach out to will help you accomplish your goals.</p>
<p>But it can be tough, especially if you are awkward around people. I am awkward around people and learned how to be less awkward. My main technique is to both give and ask for a “hook” in any conversation I start.</p>
<p>Here’s a typical “networking” conversation of which I’ve had many:</p>
<p>Dan: Hi, I’m Dan.</p>
<p>Jan: Hi, I’m Jan.</p>
<p>Dan: Where do you work?</p>
<p>Jan: I work at Company X. Where do you work?</p>
<p>Dan: Company Y.</p>
<p>&lt;crickets&gt;</p>
<p>Compare that with this conversation:</p>
<p>Dan: Hi, I’m Dan.</p>
<p>Jan: Hi, I’m Jan.</p>
<p>Dan: Where do you work?</p>
<p>Jan: I work at Company X. Where do you work?</p>
<p>Dan: Company Y. We recently launched website Z and are evaluating technology ABC. What has your company recently rolled out?</p>
<p>See the difference? Dan has provided Jan with two avenues for conversation–one is asking further about technology ABC or website Z, and the other is talking about Company X. Jan can decide where to take the conversation, but Dan has provided the start of it.</p>
<p>Learning this trick, which comes naturally to many many people, changed the way I network. Another thing that mattered was my realization that everyone, every single person, has an interesting story or anecdote to tell, and that I can learn something. That understanding has made conversation much more fun.</p>
<p>Sincerely,</p>
<p>Dan</p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	<div>
			<!-- .entry-auhtor -->
		<p><strong>Published</strong>
			<time datetime="2019-02-25T12:04:06-07:00">February 25, 2019</time><time datetime="2019-02-03T12:04:26-07:00">February 3, 2019</time>		</p><!-- .site-posted-on -->
	</div>
</article></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2019/02/25/use-a-conversational-hook-when-networking-with-strangers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25012993</guid>
            <pubDate>Sat, 07 Nov 2020 03:14:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is this Mahler? This sounds like Mahler]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25012900">thread link</a>) | @luu
<br/>
November 6, 2020 | http://sarabee.github.io/2020/09/13/is-this-mahler/ | <a href="https://web.archive.org/web/*/http://sarabee.github.io/2020/09/13/is-this-mahler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="http://sarabee.github.io/images/whatnow-crop.jpg" width="180">
One of the most delightful parts of being a software engineer and hardware
tinkerer is having the ability to solve my own specific (and often niche)
problems. In this post, the particular problem I’ll be solving is the burning
need to know what is currently playing on <a href="https://www.wqxr.org/">WQXR</a>, NYC’s classical radio station.</p>

<p>A typical Saturday for me looks like this: I wake up and make a coffee, bring
it to the couch in the living room, pick up my knitting, and turn on the radio. Maybe midway through the morning
a halfway-familiar piece comes on, but I’ve left my phone in the other room and won’t be
able to go check the WQXR website without disentangling myself from my
knitting and missing a bit of the piece that has captured my attention.</p>

<p>Or how about a weekday: I’m working on a project, elbows deep in the code, with the WQXR livestream open in one of my million
browser tabs. I feel a glimmer of recognition, but I’m fully focused on my
work and don’t want to break my concentration to go hunt down the livestream
player and find out what it is.</p>

<p>To solve this particular problem, I needed two things: a way to find out what
was on the radio, and a place to display it.</p>

<p>There are a couple of different ways you could find out what’s playing,
including music identification services like Shazam. But those rely on already
having a recording in their database to match against, and I’m listening to
classical music where I could be hearing any one of dozens of different
recordings (and even live performances) for any given piece, making it
unlikely that such a service would be able to find a match. So I started with
the source I was already using to get this information: the WQXR website.</p>

<p>If you leave the website open long enough, you’ll notice that it automatically
updates to reflect what’s currently playing. This was great news for me,
because it meant that somewhere in the page a script is periodically making
ajax requests to get that information, requests that I could also make myself.
To find out what these requests were, I eavesdropped on my browser’s network
calls using the developer console.</p>

<p><img src="http://sarabee.github.io/images/wqxr-network.jpg" width="500"></p>

<p>There are two calls being made here, one to an endpoint called streams,
and one to something very promisingly named <code>whats_on</code>. Making a request to
that second endpoint, we get a beautiful json response containing information
about what’s playing on New York Public Radio’s various livestreams. Great!
This is exactly what I need to satisfy the first piece of this project.</p>

<p>(I honestly can’t remember how I figured this out, but you can append the call
letters for the particular station you’re interested in to the URI to just get
information for that stream, but the full response would also have worked just
fine.)</p>

<p>Okay, cool, so I have the data. How do I get this information in front of my
eyeballs when I’m listening to the radio?</p>

<p>You already know from the teaser photo at the top of the post that
I ultimately put it on my mantel, but I took an iterative approach to getting
there.</p>

<p>I use tmux to manage my terminal sessions, and it occurred to me that the
status bar, always there along the bottom of my terminal, might be a nice
place to have information about what’s currently playing. I wrote some
lightweight python classes for fetching and parsing the radio’s API response,
and a tiny script, <code>tmux.py</code> that outputs the information in the format I want for this
purpose.</p>

<p>Adding something to the tmux status bar is just a matter of adding a couple of
lines to <code>.tmux.conf</code>:</p>

<figure><pre><code data-lang="bash"><span>set</span> <span>-g</span> status-right-length 200
<span>set</span> <span>-g</span> status-right <span>'#[bg=#d7ff5f] #(python3
/home/sarabee/development/nowplaying/tmux.py)  |  [%H:%M] '</span></code></pre></figure>

<p>This overwrote the clock that was there by default, so I added one back in. By
default, scripts run in <code>.tmux.conf</code> are executed once every 15 seconds, which
was more than fast enough for my purpose. My status bar then looks like this:</p>

<p><img src="http://sarabee.github.io/images/now-playing.jpg"></p>

<p>This fixed the problem of not wanting to leave my terminal to find out what
I’m listening to, but what about when I’m in the living room? I knew I wanted
a display, that I wanted it to update automatically, like the tmux status bar,
that I wanted it to be constantly running, like an indoor thermometer readout,
and that I wanted it to be readable from any position in the room, with good
view angles and readability under a variety of lighting conditions.  This all
sounded to me like the <em>perfect</em> excuse to work with e-paper.</p>

<p><a href="http://shop.pimoroni.com/">Pimoroni</a> was having a sale, so I picked up two e-ink displays: the smaller inkypHAT, and the
larger inkywHAT. I also got a couple of Raspberry Pi Zero Ws to pop them on
top of (quick aside: these things cost $10 and have wifi and bluetooth, wowww).</p>

<p>Starting with the inkypHAT and the code I’d already written for handling radio
data, I prototyped my idea, creating a tiny display that sits on top of my
monitor. I set the Pi Zeroes up the way I set up my larger Raspberry Pi 3,
with Raspbian Lite. Without worrying too much about styling the display
aesthetically, I learned how to work with the
<a href="https://github.com/pimoroni/inky">Inky</a> and
<a href="https://pillow.readthedocs.io/en/stable/">Pillow</a> libraries and
wrote a script to get the composer and title chopped up to fit across multiple
lines on the screen:</p>

<p><img src="http://sarabee.github.io/images/wqxr-phat.jpg" width="500"></p>

<p>I have it running once a minute on a cron, and to avoid refreshing the e-ink
display unnecessarily, I keep the last piece written to the display in memory and
update only if I’ve gotten something new back from WQXR.</p>

<p>Reworking this script for the larger inkywHAT display wasn’t difficult; it
mostly involved tweaking font size to take advantage of the larger screen. But
since this is meant to live on my mantel and be highly visible in my living
room, I wanted to make it look a bit nicer than just throwing the text on
there. I found a clip-art scrollwork frame, and using only the MacOS Preview
app and ImageMagick, got it into the right size and format
for the e-ink display.</p>

<p>In Preview, I grabbed a corner of the frame and pasted it in again three more
times, rotated 90 degrees each time, and carefully bumped each corner around
until they were lined up and could be scaled down reasonably to the right
dimensions (400x300px). Even though the image appeared to be entirely black
and white, a closer look shows this wasn’t true at all! It’s actually full of
many different shades of gray:</p>

<p><img src="http://sarabee.github.io/images/whatnow-corner.png" width="300"></p>

<p>To get the image into the right format and flatten it down to just two colors,
I used the <a href="https://imagemagick.org/script/command-line-processing.php">ImageMagick command-line
tools</a>. While <a href="http://www.imagemagick.org/Usage/quantize/#two_color">this
extremely thorough page</a> in the IM docs goes pretty far in-depth with the
various ways you can convert an image to black and white, I ultimately ended
up going with:</p>

<figure><pre><code data-lang="bash">magick input.png <span>-colorspace</span> gray <span>-colors</span> 2 <span>-normalize</span> PNG8:output.png</code></pre></figure>

<p>Which produces a frame that looks like this:</p>

<p><img src="http://sarabee.github.io/images/whatnow-frame.png"></p>

<p>It’s a little rough when you see it on a relatively high resolution monitor, but looks great on the 400x300 e-ink
display! After that, adding the text was pretty straightforward;
earlier when only displaying text, I was still actually using Pillow to create an empty
image in the correct dimensions that I drew the text onto:</p>

<figure><pre><code data-lang="python"><span>img</span> <span>=</span> <span>Image</span><span>.</span><span>new</span><span>(</span><span>"P"</span><span>,</span> <span>(</span><span>inky_display</span><span>.</span><span>WIDTH</span><span>,</span> <span>inky_display</span><span>.</span><span>HEIGHT</span><span>))</span></code></pre></figure>

<p>To use the frame, I simply started with the frame image instead:</p>

<figure><pre><code data-lang="python"><span>img</span> <span>=</span> <span>Image</span><span>.</span><span>open</span><span>(</span><span>os</span><span>.</span><span>path</span><span>.</span><span>join</span><span>(</span><span>current_dir</span><span>,</span>
<span>"whatnow.png"</span><span>)).</span><span>resize</span><span>(</span><span>inky_display</span><span>.</span><span>resolution</span><span>)</span></code></pre></figure>

<p>The last little bit of clean-up work involved getting the text centered in the
frame, and setting the margins in my script so that the line breaks were
a comfortable distance from its edges.</p>

<p><img src="http://sarabee.github.io/images/whatnow-closeup.jpg" width="500"></p>

<p>I’m happy with where this project is at; the text is clear and legible from
anywhere in my living room, and my Saturday morning listening experience has
been greatly improved. Eventually, it’ll get custom wooden housing, which will
be its own post, I’m sure! Feel free to dig around in <a href="https://github.com/SaraBee/nowplaying">the project’s repo on
GitHub</a> to get an even better idea of how this all works.</p>
</div></div>]]>
            </description>
            <link>http://sarabee.github.io/2020/09/13/is-this-mahler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25012900</guid>
            <pubDate>Sat, 07 Nov 2020 02:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Personal OKR Template Built in Notion]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25012687">thread link</a>) | @gogo61
<br/>
November 6, 2020 | https://rohitgupta.site/OKR-2021-f4c8acc86da24b278048b02158eafc32 | <a href="https://web.archive.org/web/*/https://rohitgupta.site/OKR-2021-f4c8acc86da24b278048b02158eafc32">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://rohitgupta.site/OKR-2021-f4c8acc86da24b278048b02158eafc32</link>
            <guid isPermaLink="false">hacker-news-small-sites-25012687</guid>
            <pubDate>Sat, 07 Nov 2020 01:47:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Etherify – bringing the ether back to ethernet]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25012469">thread link</a>) | @vitplister
<br/>
November 6, 2020 | https://lipkowski.com/etherify/ | <a href="https://web.archive.org/web/*/https://lipkowski.com/etherify/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="content">

<div>
	<div id="primary">
		<main id="main" role="main">

			
<article id="post-69" class="page">
	<!-- .entry-header -->
	<div>
		<p>Leaking data via out of unconnected devices (both connected and unconnected) is a very interesting topic, often called “soft tempest”. Often this is the realm of absurdly costly lab equipment, source code isn’t published etc.&nbsp; Here i would like to demonstrate this using the simplest equipment and means, and make it very easy to reproduce.</p>
<p>To transmit an elecromagnetic wave one needs to have a conductor driven by a high frequency source. Various busses are used: monitor cables, pci buses etc. Here i propose the use of ethernet.</p>
<p>An ethernet cable consists of 4 twisted pair lines with 100ohm impedance., which carries RF signals in the tens to hundredths MHz range. Any imperfections in the cable (asymetry etc) or in the interface will cause radio signals to be radiated.</p>
<p>Signals can be modulated using different methods. Here i will use morse code for simplicity. This also allows one to judge the signal to noise ratio by just listening. It is also possible to decode it by ear without additional devices if one knows morse code, if not there is a lot of software that can do it (although usually with much worse performance than an experienced human operator).</p>
<p>Transmission is implemented via very simple shell scripts. Only bash, ethtool and ping is needed. This enables the script to be used easily on embedded devices and other platforms where shipping binaries, installing a python environment etc might be a problem.</p>
<p>The proof-of-concept scripts are avaliable at <a href="https://github.com/sq5bpf/etherify">https://github.com/sq5bpf/etherify</a></p>
<p><strong>Etherify 1 – transmitting by switching speed</strong></p>
<p>Various ethernet speeds have different modulation speeds, types and encoding. By switching between we can modulate the RF signal leaking from the wires.</p>
<p>10base-T uses manchester encoding with 10MHz symbol rate. This is used as the space signal (logical 0).</p>
<p>100base-T uses 4B5B encoding with NRZI at 125MHz symbol rate . This results in an easy to receive signal around 125MHz, this is used as the mark signal (logical 1).</p>
<p>Ethernet transmits an idle sequence when no packets are carried, so the signal is constant. No packets have to be transmitted for the signal to be present, on the speed of the interface has to be changed.</p>
<p>The transmission is implemented by a simple bash script, which sends the content of a short text file given as the argument, or “etherify demo” if none is given. The signal can be received as morse code around 125MHz, please use USB or CW mode in the receiver and use a narrow filter.</p>
<p>Demo:</p>
<p>Ensure that the two raspberry PIs are connected and that there is an ethernet link between them (signalled via the LEDs).</p>
<p>Run as root:</p>
<p>./etherify1</p>
<p>to transmit “etherify demo” or to exfiltrate the contents of /tmp/secret.txt</p>
<p>./etherify1 /tmp/secret.txt</p>
<p>Listen to the signal at 125MHz as described below.</p>
<p><iframe title="Etherify 1 demo receiving via SDR and decoding via fldigi" width="525" height="295" src="https://www.youtube.com/embed/ueC4SLPrtNg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>The is decodable by ear with a simple Moxon directional antenna and a ham radio receiver (SDR could be used too).</p>
<p>This results in a strong signal at 15m distance:</p>
<p><iframe title="Etherify 1 at 15m" width="525" height="295" src="https://www.youtube.com/embed/MK15ofaWS_U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>The results at 100m distance (weak signal, please use headphones):</p>
<p><iframe title="Etherify 1 at 100m" width="525" height="295" src="https://www.youtube.com/embed/1hdmZOwssGM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>If in doubt let an experienced amateur radio operator decode it. I was not able to decode the signal at 100m with software.</p>
<p><strong>Etherify 2 – transmitting by sending data</strong></p>
<p>Sending a stream of data at 1Gbps also produces a detectable signal change at 125MHz. There may be other frequencies where the signals were more readable, but equipment was avaliable to receive at 125MHz. This probably works by loading the supply voltage when the packets are generated. A change of voltage probably changes the frequency of some clock slightly, thus generating FSK (F1A to be exact). Note that this doesn’t work with all hardware, which could be explained by the hypothesis about the frequency being modulated by the interface load.</p>
<p>A large volume of traffic represents a logical 1, while no traffic represents logical 0.</p>
<p>The transmission is implemented as a simple bash script, which sends the content of a short text file given as the argument, or “etherify demo” if none is given. The signal can be received as morse code around 125MHz, please use USB or CW mode in the receiver and use a narrow filter, also AM mode can be used.</p>
<p>Demo:</p>
<p>Ensure that the two raspberry PIs are connected and that there is an ethernet link between them (signalled via the LEDs). Set one raspberry PI to 192.168.1.1/24 and the other to 192.168.1.2/24 (the IP address can be changed in the etherify2 script). Ensure that the two raspberry PIs have IP connectivity and can ping each other, and that he interface rate is 1Gbps.</p>
<p>On the 192.168.1.2 raspberry PI run as root:</p>
<p>./etherify2</p>
<p>to transmit “etherify demo” or to exfiltrate the contents of /tmp/secret.txt</p>
<p>./etherify2 /tmp/secret.txt</p>
<p>Listen to the signal at 125MHz as described below.</p>
<p>The signal was decodable by ear at a distance of 30m with a simple Moxon directional antenna and a ham radio receiver.</p>
<p>This results in a strong signal at 15m distance:</p>
<p><iframe title="Etherify 2 at 15m" width="525" height="295" src="https://www.youtube.com/embed/9zKCrdAY1oQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>And a readable signal at 30m:</p>
<p><iframe title="Etherify 2 at 30m" width="525" height="295" src="https://www.youtube.com/embed/CCttAsAU_IU?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><strong>Equipment used and experiment description</strong></p>
<p>The RF radiation differs with different equipment and ethernet cable type being used. In order to make this demo reproducible i used two Raspberry PI 4, because it makes it easy for everyone to obtain the exact hardware that was used for this experiment. The raspberry PIs were connected using the ethernet cable supplied with the official Raspberry PI 4 starter kit. The stock Raspbian 10 operating system, which was supplied on the SD cards&nbsp; in the Starter Kit, was used. The devices were accessed via the serial console.</p>
<p>Power was provided via powerbanks. This was to avoid a connection to the mains voltage, because the powerline could be an unintentional radiator.</p>
<p>The Raspberry PIs were laid on a wooden bench about 1.4m from each other.</p>
<p>The experiment was conducted in an electromagnetically quiet area.</p>
<figure id="attachment_83" aria-describedby="caption-attachment-83"><img loading="lazy" src="https://lipkowski.com/wp-content/uploads/2020/11/rpi_etherify.jpg" alt="" width="843" height="355"><figcaption id="caption-attachment-83">Raspberry PI etherify demo</figcaption></figure>
<p>The signal was received via a Moxon antenna built for 125MHz and a Yaesu FT-817 transceiver with a 500Hz CW filter. Morse code was received and decoded by ear.</p>
<p>The experiments can be repeated with other devices with ethernet ports, for example two laptops, running any linux distribution and the required tools installed (most will come with them out of the box). The devices should be able to establish an ethernet link very quickly upon switching speed. An SDR receiver can be used for reception, with any antenna that can receive 125MHz (test first at close range). Morse code decoding can be done via software, for example fldigi [3].</p>
<p>The easiest receive setup would probably be gqrx with an rtl-sdr dongle, and fldigi for deciding the signals. If the signal is not decoded, it should be played to someone who can receive morse code by ear. Often such person will be able to decode it with ease.</p>
<p>The experiment should be first conducted in an electromagnetically quiet area, nearby ethernet networks will generate a lot of interference. If testing in the vicinity of other ethernet networks move the antenna closer, and reduce the receiver gain as much as possible.</p>
<p><strong>How to replicate with your own hardware</strong></p>
<p>This can be replicated with other ethernet hardware, but with varying results.</p>
<p>The speed at which the ethernet hardware can renegotiate different speed sets the maximum speed of etherify 1 transmission. The&nbsp; ethernet port on the raspberry pi 4 can change speed very quickly. Other hardware will have a delay when chaging speed, for example on an Dell Latitude 5310 running with Debian bullseye (e1000e 3.2.6-k driver) it takes about 5 seconds to change speed. Lower modulation speed means lower datarate, but also better signal/noise when decoding.</p>
<p>The clock frequency modulation under packet load observed on the raspberry pi 4 (etherify 2) is specific to the raspberry pi 4. However loading the interface with packets often has effects on the electromagnetic spectrum on different hardware.</p>
<p>To check your hardware:</p>
<ul>
<li>look at the spectrum around 125MHz</li>
<li>ensure that the interface is up</li>
<li>change speed with ethtool to 10Mbps, 100Mbps, 1Gbps and observe the spectrum</li>
<li>try enabling/disabling eee (energy efficient ethernet), observe the effects at different speeds</li>
<li>try loading the interface with packets, observe the effects at different speeds</li>
<li>look at different ethtool settings and module options, especially those concerning power saving, carrier delay etc.</li>
<li>allow a few seconds after changing each parameter, on some interfaces it takes some time to change parameters</li>
<li>keep in mind that both ends of the ethernet link have an effect on he transmission. For experiments it’s best to use the same hardware on both ends.</li>
</ul>
<p>If you find something interesting, then please send me an email.</p>
<p><strong>Discussion</strong></p>
<p>The signal was shown to be decodable by ear at 100m for etherify 1, and 30m for etherify 2. This was done via a simple antenna and modest receiver. An antenna with more gain and better receiver would surely yield better range.</p>
<p>Nearby ethernet networks will generate a lot of interference at the same frequencies. The 125MHz frequency falls in the 108-137MHz air band, and one can expect interference from strong signals on nearby frequencies from nearby airplanes and airports. Therefore first tests should be conducted in areas with less interference, such as outdoor areas or underground parking lots.</p>
<p>The 125MHz frequency was chosen because of avaliable equipment. It would be hard for one person to hold and operate an antenna, laptop and SDR receiver. Other frequencies may be better.</p>
<p>Etherify 1 yields better range, however etherify 2 may enable to use a device located somewhere else in the network as the transmitter. This device may be physically closer to the receiver or may have greater leakage from the ethernet cable. Etherify 2 can be exploited as a non-root user by flooding the network with UDP datagrams or possibly other data.</p>
<p>The “software” side is intentionally a very primitive silly hack.</p>
<p>I haven’t done an extensive search for similar prior publications, but a few quick searches didn’t yield any results. If you know of any, please let me know.</p>
<p>If you cite this, …</p></div></article></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lipkowski.com/etherify/">https://lipkowski.com/etherify/</a></em></p>]]>
            </description>
            <link>https://lipkowski.com/etherify/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25012469</guid>
            <pubDate>Sat, 07 Nov 2020 00:49:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prop 24 Puts Anonymized Data at Greater Risk of Re-Identification]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25012366">thread link</a>) | @icoe
<br/>
November 6, 2020 | https://www.tonic.ai/post/prop-24-anonymized-data-greater-risk-re-identification | <a href="https://web.archive.org/web/*/https://www.tonic.ai/post/prop-24-anonymized-data-greater-risk-re-identification">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Californians voted Yes on <a href="https://vig.cdn.sos.ca.gov/2020/general/pdf/topl-prop24.pdf">Prop 24</a>, approving extensive amendments to the <a href="https://leginfo.legislature.ca.gov/faces/billTextClient.xhtml?bill_id=201720180SB1121">California Consumer Privacy Act</a> with the mindset of strengthening the U.S.’s most comprehensive data privacy regulation to date. But one of its provisions undermines that goal in a way that puts both individual privacy and corporate security at a heightened risk.<br></p><p>Specifically, a collection of amendments grants service providers expanded powers to combine consumer datasets obtained from different sources (see Secs. 1798.140(ag)(1) and 1798.185(e)(10)).<strong> In the world of data anonymization, the risks of combining datasets </strong><a href="https://www.nature.com/articles/s41467-019-10933-3/"><strong>are</strong></a><strong> </strong><a href="https://techcrunch.com/2019/07/24/researchers-spotlight-the-lie-of-anonymous-data/"><strong>well</strong></a><strong> </strong><a href="https://www.sciencedaily.com/releases/2018/12/181207144403.htm"><strong>known</strong></a><strong>.</strong> When paired with additional data, individuals in many anonymized datasets are surprisingly easy to re-identify. This can be due to uneven approaches in anonymization, as well as the simple benefit of added data points. Real-world instances include <a href="https://fpf.org/wp-content/uploads/The-Re-identification-of-Governor-Welds-Medical-Information-Daniel-Barth-Jones.pdf">anonymized medical records</a> being re-identified when pooled with voter databases; the infamous <a href="https://arxiv.org/abs/cs/0610105">Netflix user re-identification</a> achieved by combining anonymized Netflix data with IMDB user movie ratings; and <a href="https://www.forbes.com/sites/simonchandler/2019/09/04/researchers-use-big-data-and-ai-to-remove-legal-confidentiality/?sh=24ba16ec15f6">anonymized Swiss Supreme Court cases</a> involving pharmaceutical companies being re-identified using publicly available databases.<br></p><p>We’ve talked previously about how the <a href="https://www.tonic.ai/post/ccpa-will-hit-your-dev-team-harder-than-gdpr">CCPA impacts dev teams</a> thanks to its extremely broad definition of the types of data requiring protection. Today, we’ll look at how Prop 24 throws that data under the bus by loosening its restrictions on data pooling.<br></p><h3>A practical example<br></h3><p>Imagine there’s a handful of companies in the same industry, say EdTech, all working with the same third-party service provider to debug software, perform testing, or develop apps. Each of these companies anonymizes their users’ data prior to sharing it with the service provider. Thanks to Prop 24, the service provider pools those datasets to maximize their work. Then the service provider experiences a breach. Individually, those anonymized user datasets may have been safe from re-identification. But combined, they make it much easier to connect the dots and re-identify users with as much as a <a href="https://www.nature.com/articles/s41467-019-10933-3/">99.9% rate of accuracy</a>.<br></p><p>The end result? Multiple companies grappling with crisis management thanks to a single data leak of “anonymized” data. The inclusion of this provision in the newly-passed Prop 24 significantly weakens the individual privacy protections that the CCPA otherwise aims to safeguard. What’s more, it weakens a company’s ability to ensure the privacy of their data when working with third parties.</p><figure><p><img src="https://uploads-ssl.webflow.com/5f0ae1534d32e5a91598eb9c/5fa5e8d498f39f28e061d229_wpTaqICtlYpRVLx4exhENOlsJh4wo898y97N_2Hhc6DJKYk06ryDg5nZj1yv5gBOa0s9DHtrJhQYE8CEg8WAzHkT_NqrcOsbFFUp_m75LDSJTiJVx742PBA69hqfJQSgvMrT25dm.png" alt=""></p></figure><h3><strong>What to do about it</strong><br></h3><p>More and more companies are relying on third-party providers to expand their development teams, outsource QA testing, or engage in other ways that rely on shared datasets. Where the law opens the door to data pooling, concerned companies should specify in their contracts if they want that door kept firmly shut.<br></p><p>But maybe a company stands to benefit from the provider having a larger pool of data to work with. In that case, here are two approaches that allow for reaping the benefits of working with third-parties without upping the risks to data security.<br></p><h4>Ironclad data de-identification</h4><p>Simple redaction, pseudonymization, and sampling aren’t going to cut it. Advanced subsetting paired with full database obfuscation? Now we’re talking. Data beyond what the law defines as “sensitive personal information” and “unique identifiers” could be used to re-identify individuals when combined with other datasets. Taking a more comprehensive approach to data de-identification provides the safeguards needed against re-identification due to data pooling. And with tools like those available in <a href="https://www.tonic.ai/product">Tonic</a> to link columns and preserve relationships in the protected output dataset, companies can strengthen their data security without sacrificing their data’s utility.</p><h4>Data synthesis with differential privacy&nbsp;</h4><p>For the strongest in data security, data synthesis performed with differential privacy at its core not only provides mathematical guarantees for data protection, it also allows for scaling up datasets to any size to equip developers with the amount of realistic, yet wholly fictitious, data they need to do their best work. Here, too, Tonic is <a href="https://www.tonic.ai/post/differential-privacy-comes-to-tonic">leading the charge</a>.<br></p><h3>Why companies should act<br></h3><p>Two additional components of Prop 24 and the CPPA are worth highlighting. First, Prop 24 establishes the California Privacy Protection Agency, expanding the resources available to implement and enforce the CCPA (see Sec. 1798.199.10). This strengthens the state’s ability to take legal action against companies that violate privacy rights.<br></p><p>Second, Prop 24 missed an opportunity to bring the CCPA in line with GDPR in requiring that companies have <a href="https://iapp.org/news/a/yes-how-opt-in-consent-really-works/">users opt into data collection</a>, as opposed to leaving the burden with users to opt out. Essentially what this means is that under the CCPA privacy is not the default. And most consumers won’t take the time to click through pop-ups, on/off forms, or privacy settings to make the opt-out change.<br></p><p>This leaves the onus on companies to do right by the data they're collecting by default in order to avoid the legal ramifications that are now easier to enforce.<br></p><p>CCPA and Prop 24 are designed to protect consumers. In the best of worlds, protecting consumers also means protecting businesses from the fallout of poor data practices. Despite its best intentions, Prop 24 stumbles in achieving these goals. Enabling service providers to combine datasets makes companies who work with third-parties more vulnerable to data leaks, despite the protections those companies may have put in place through data anonymization.</p><p>Where Prop 24 does succeed is in paving a clear path for taking legal action against companies who misuse or fail to protect their users’ data. It’s up to companies to implement strong data protection practices regardless of the law’s lax requirements, to avoid costly fines and damaging leaks.<br></p></div><div><h2>What’s a Rich Text element?</h2><p>The rich text element allows you to create and format headings, paragraphs, blockquotes, images, and video all in one place instead of having to add and format them individually. Just double-click and easily create content.</p><h5>Static and dynamic content editing</h5><blockquote>Static and dynamic content editing</blockquote><p>‍</p><h6>Static and dynamic content editing</h6><p>A rich text element can be used with static or dynamic content. For static content, just drop it into any page and begin editing. For dynamic content, add a rich text field to any collection and then <strong>connect</strong> a rich text element to that field in the settings panel. Voila!</p><h4>How to customize formatting for each rich text</h4><p>Headings, paragraphs, blockquotes, figures, images, and figure captions can all be styled after a class is added to the rich text element using the "When inside of" nested selector system.</p></div></div>]]>
            </description>
            <link>https://www.tonic.ai/post/prop-24-anonymized-data-greater-risk-re-identification</link>
            <guid isPermaLink="false">hacker-news-small-sites-25012366</guid>
            <pubDate>Sat, 07 Nov 2020 00:27:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you need to know about UX/UI at a high-level]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25012270">thread link</a>) | @Whiskeyjck
<br/>
November 6, 2020 | http://www.kickassux.com/vault | <a href="https://web.archive.org/web/*/http://www.kickassux.com/vault">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.kickassux.com/vault</link>
            <guid isPermaLink="false">hacker-news-small-sites-25012270</guid>
            <pubDate>Sat, 07 Nov 2020 00:03:05 GMT</pubDate>
        </item>
    </channel>
</rss>
