<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 17 Jan 2021 05:08:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 17 Jan 2021 05:08:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Food on the table while giving away source code]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25788122">thread link</a>) | @nixcraft
<br/>
January 14, 2021 | https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I founded the curl project early 1998 but had already then been working on the code since <a href="https://daniel.haxx.se/blog/2021/01/03/age-is-just-a-number-or-two/" data-type="post" data-id="15434">November 1996</a>. The source code was always open, free and available to the world. The term “open source” actually wasn’t even coined until early 1998,  just weeks before curl was born.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png" alt="" width="125" height="108" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png 789w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-200x175.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-450x394.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-768x672.png 768w" sizes="(max-width: 125px) 100vw, 125px"></figure></div>



<p>In the beginning of course, the first few years or so, this project wasn’t seen or discovered by many and just grew slowly and silently in a dusty corner of the Internet.</p>



<p>Already when I shipped the first versions I wanted the code to be open and freely available. For years I had seen the cool free software put out the in the world by others and I wanted my work to help build this communal treasure trove.</p>



<h2>License</h2>



<p>When I started this journey I didn’t really know what I wanted with curl’s license and exactly what rights and freedoms I wanted to give away and it took a few years and attempts before it landed.</p>



<p>The early versions were <a href="https://opensource.org/licenses/GPL-2.0">GPL licensed</a>, but as I learned about resistance from proprietary companies and thought about it further, I changed the license to be more commercially friendly and to match my conviction better. I ended up with <a href="https://opensource.org/licenses/MIT">MIT</a> after a brief experimental time using <a href="https://opensource.org/licenses/MPL-1.1">MPL</a>. (It was easy to change the license back then because I owned all the copyrights at that point.)</p>



<p>To be exact: we actually have a <a href="https://curl.se/docs/copyright.html">slightly modified MIT license</a> with some very subtle differences. The reason for the changes have been forgotten and we didn’t get those commits logged in the “big transition” to Sourceforge that we did in late 1999…  The end result is that this is now often recognized as “the curl license”, even though it is in effect the MIT license.</p>



<p>The license says everyone can use the code for whatever purpose and nobody is required to ship any source code to anyone, but they cannot claim they wrote it themselves and the license/use of the code should be mentioned in documentation or another relevant location.</p>



<p>As licenses go, this has to be one of the most frictionless ones there is.</p>



<h2>Copyright</h2>



<p>Open source relies on a solid copyright law and the copyright owners of the code are the only ones who can license it away. For a long time I was the sole copyright owner in the project. But as I had decided to stick to the license, I saw no particular downsides with allowing code and contributors (of significant contributions) to retain their copyrights on the parts they brought. To not use that as a fence to make contributions harder.</p>



<p>Today, in early 2021, I count 1441 copyright strings in the curl source code git repository. 94.9% of them have my name.</p>



<p>I never liked how some projects require copyright assignments or license agreements etc to be able to submit code or patches. Partly because of the huge administrative burden it adds to the project, but also for the significant friction and barrier to entry they create for new contributors and the unbalance it creates; some get more rights than others. I’ve always worked on making it easy and smooth for newcomers to start contributing to curl. It doesn’t happen by accident.</p>



<h2>Spare time</h2>



<p>In many ways, running a spare time open source project is easy. You just need a steady income from a “real” job and sufficient spare time, and maybe a server to host stuff on for the online presence.</p>



<p>The challenge is of course to keep developing it, adding things people want, to help users with problems and to address issues timely. Especially if you happen to be lucky and the user amount increases and the project grows in popularity.</p>



<p>I ran curl as a spare time project for decades. Over the years it became more and more common that users who submitted bug reports or asked for help about things were actually doing that during their <em>paid</em> work hours because they used  curl in a commercial surrounding – which sometimes made the situation almost absurd. The ones who actually got paid to work with curl were asking the unpaid developers to help them out.</p>



<p>I changed employers several times. I started my own company and worked as my own boss for a while. I worked for Mozilla on network stuff in Firefox for five years. But curl remained a spare time project because I couldn’t figure out how to turn it into a job without risking the project or my economy.</p>



<h2>Earning a living</h2>



<p>For many years it was a pipe dream for me to be able to work on curl as a real job. But how do I actually take the step from a spare time project to doing it full time? I give away all the code for free, and it is a solid and reliable product.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="186" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 186px) 100vw, 186px"></a></figure></div>



<p>The initial seeds were planted when I met and got to know Larry (wolfSSL CEO) and some of the other good people at <a href="https://www.wolfssl.com/">wolfSSL</a> back in the early 2010s. This, because wolfSSL is a company that write open source libraries and offer commercial support for them – proving that it can work as a business model. Larry always told me he thought there was a possibility waiting here for me with curl.</p>



<p>Apart from the business angle, if I would be able to work more on curl it could really benefit the curl project, and then of course indirectly everyone who uses it.</p>



<p>It was still a step to take. When <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/" data-type="post" data-id="11748">I gave up on Mozilla</a> in 2018, it just took a little thinking before I decided to try it. <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">I joined wolfSSL</a> to work on curl full time. A dream came true and finally curl was not just something I did “on the side”. It only took 21 years from first curl release to reach that point…</p>



<p>I’m living the open source dream, working on the project I created myself.</p>



<h2>Food for free code</h2>



<p>We sell commercial support for curl and libcurl. Companies and users that need a helping hand or swift assistance with their problems can get it from us – and with me here I dare to claim that there’s no company anywhere else with the same ability. We can offload engineering teams with their curl issues. Up to 24/7 level!</p>



<p>We also offer custom curl development, debugging help, porting to new platforms and basically any other curl related activity you need. See more on the <a href="https://www.wolfssl.com/products/curl/">curl product page</a> on the wolfSSL site.</p>



<p>curl (mostly in the shape of libcurl) runs in <strong>ten billion installations</strong>: some five, six billion mobile phones and tablets – used by several of the most downloaded apps in existence, in virtually every website and Internet server. In a billion computer games, a billion Windows machines, half a billion TVs, half a billion game consoles and in a few hundred million cars… curl has been made to run on 82 operating systems on 22 CPU architectures. Very few software components can claim a wider use.</p>



<p><em>“Isn’t it easier to list companies that are <strong>not</strong> using curl?”</em></p>



<p>Wide use and being recognized does not bring food on the table. curl is also totally free to download, build and use. It is very solid and stable. It performs well, is documented, well tested and “battle hardened”. It “just works” for most users.</p>



<h2>Pay for support!</h2>



<p>How to convince companies that they should get a curl support contract with me?</p>



<p>Paying customers get to influence what I work on next. Not only distant road-mapping but also how to prioritize short term bug-fixes etc. We have a guaranteed response-time.</p>



<p>You get your issues first in line to get fixed. Customers also won’t risk getting their issues added the known bugs document and put in the attic to be forgotten. We can help customers make sure their application use libcurl correctly and in the best possible way.</p>



<p>I try to emphasize that by getting support from us, customers can  take away some of those tasks from their own engineers and because we are  faster and better on curl related issues, that is a pure net gain economically. For all of us.</p>



<p><strong>This is not an easy sell.</strong></p>



<p>Sure, curl is used by thousands of companies everywhere, but most of them do it because it’s free (in all meanings of the word), functional and available. There’s a real challenge in identifying those that actually use it enough and  value the functionality enough that they realize they want to improve their curl foo.</p>



<p>Most of our curl customers purchased support first when they faced a complicated issue or problem they couldn’t fix themselves –  this fact gives me this weird (to the wider curl community) incentive to <em>not</em> fix some problems too fast, because it then makes it work against my ability to gain new customers!</p>



<p>We need paying customers for this to be sustainable. When wolfSSL has a sustainable curl business, I get paid and the work I do in curl benefits all the curl users; paying as well as non-paying.</p>



<h2>Dual license</h2>



<p>There’s clearly business in releasing open source under a strong copyleft license such as GPL, and as long as you keep the copyrights, offer customers to purchase that same code under another more proprietary- friendly  license. The code is still open source and anyone doing totally open things can still use it freely and at no cost.</p>



<p>We’ve shipped <a href="https://curl.se/tiny/">tiny-curl</a> to the world licensed under GPLv3. Tiny-curl is a curl branch with a strong focus on the<em><strong> </strong></em><strong>tiny</strong> part: the idea is to provide a libcurl more suitable for smaller systems, the ones that can’t even run a full Linux but rather use an RTOS.</p>



<p>Consider it a sort of experiment. Are users interested in getting a smaller curl onto their products and are they interested in paying for licensing. So far, tiny-curl supports two separate RTOSes for which we haven’t ported the “normal” curl to.</p>



<h2>Keeping things separate</h2>



<p>Maybe you don’t realize this, but I work hard to keep separate things compartmentalized. I am not curl, curl is not wolfSSL and wolfSSL is not me.  But we  all overlap greatly!</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/01/curl-circles.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/01/curl-circles.jpg" alt="" width="599" height="562"></a><figcaption>The Daniel + curl + wolfSSL trinity</figcaption></figure>



<p>I work for wolfSSL. I work on curl. wolfSSL offers commercial curl support.</p>



<h2>Reserved features</h2>



<p>One idea that we haven’t explored much yet is the ability to make and offer “reserved features” to paying customers only. This of course as another motivation for companies to become curl support customers.</p>



<p>Such reserved features would still have to be sensible for the curl project …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/">https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788122</guid>
            <pubDate>Fri, 15 Jan 2021 07:49:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Insurrections, Ancient and Modern (and Also Meet the Academicats)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25787594">thread link</a>) | @parsecs
<br/>
January 14, 2021 | https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>So this week I want to talk about how what I know a historian influences how I am interpreting what I am going to call the Capitol Insurrection that happened on Wednesday, January 6 instead of taking the week off as I had originally planned. Since that is a really heavy topic, I am also going to do what I was <em>originally </em>planning to do this week,<strong> which was to share pictures of the two adorable little cats the Pedant-Household has adopted.</strong></p>



<p>They are named Oliver and Percival (Oliver after the knight from <em>The Song of Roland</em> and Percival after the knight from Arthurian legends, particularly Chretien de Troyes), and they are super-friendly and also oppose insurrectionists.</p>



<figure><img data-attachment-id="5936" data-permalink="https://acoup.blog/pxl_20210114_215722402/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610643442&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1117&quot;,&quot;shutter_speed&quot;:&quot;0.041667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pxl_20210114_215722402" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Oliver (left) and Percival (right) seen here occupying the Pedant’s <a href="https://acoup.blog/category/fireside/">Fireside Chair</a>.</figcaption></figure>



<p>(Note that I have turned off comments for this post.  I know we all have opinions on this, often very strong opinions that others might find very frustrating.  I don’t particularly want to moderate that discussion and in any event, you are, at this point, much better off (if you are in the United States) <a href="https://youtu.be/KXXYkLa-HHI">Contacting Your Representatives</a> with your opinion, rather than arguing on the internet.)</p>



<p>We already talked, <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/">back in October</a>, about civil strife – <em>stasis</em> – in Greek communities and about how I thought that the United States has found itself in the early but accelerating stages of <em>stasis</em> as described by ancient Greek writers (I also worked in some Roman examples, but I really think the Greek parallel is more useful, as the fall of the Roman Republic was so heavily influenced by the involvement of the Roman Army; the United States military has played no such role, nor indicated it is interested in doing so.  For now, the civil-military relationship remains relatively healthy).</p>



<p>I’m going to assume you have all of that already, so if you want to go back and look at how I described <em>stasis</em> and what that meant, you may want to do that first.  Instead, I want to move forward and discuss what thinking in terms of <em>stasis</em> means in understanding the Capitol Insurrection and in particular the relevance of that Greek model of <em>stasis</em> in understanding both what has happened and what may need to happen going forward.  Starting with:</p>



<h2>This Was Serious</h2>



<p>While the insurrection was happening and in its immediate aftermath, there was a tendency to focus on the more frivolous, silly parts of it.  And there were truly silly looking things.  And there are still commentators – some deluded, some acting in bad faith – attempting to insist that this wasn’t serious.  <strong>They are wrong; the Capitol Insurrection was deadly serious</strong> both in the very literal sense that <em>people died</em> (which I think seems to be missed in some quarters), but also for what it means.  And, as time has passed and <a href="https://www.washingtonpost.com/dc-md-va/2021/01/14/dc-police-capitol-riot/?arc404=true">more reporting has been done</a> on <a href="https://twitter.com/CalebJHull/status/1348334770103660553">what was happening</a>, it has become increasingly apparent that we were perhaps <em>moments </em>away from mass-casualty events (either where politicians were taken by the mob or where the mob so endangered law enforcement or politicians that lethal force was required that would have left many insurrectionists dead).</p>



<p><strong>No ancient Greek would have had any trouble in understanding what happened on the 6th or that it was a serious attempt</strong> (albeit an incompetent one) <strong>to seize power</strong>.  Having a leader or a political faction move with a mob (often armed, but not always so) to<strong> try to disperse the normal civic assemblies of a Greek <em>polis</em> and occupy their normal meeting place was a standard maneuver to try to seize power during <em>stasis</em></strong>. As Dr. <a href="https://twitter.com/Roelkonijn">Roel Konijnendijk</a>, an ancient Greek history specialist, noted in this <a href="https://www.reddit.com/r/AskHistorians/comments/ks082p/meta_todays_sedition_at_the_united_states_capitol/giexmxe/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">excellent discussion</a> on the r/AskHistorians reddit (where he posts as Iphikrates), “In the Greek world, most attempts to seize power by force tended to take the same form: the seditious party would contrive an opportunity to gather in arms while their opponents were unarmed and off-guard, and seize control of all public spaces.”</p>



<p><strong>To take merely the examples in Athens</strong>, Cylon (the ‘c’ is hard, so Ki-lon – or if you prefer the Greek, Ku-lon – not Psi-lon) attempted it in 632, trying to seize the Athenian Acropolis with an armed mob (Thuc. 1.126; Hdt. 5.71; Plut. <em>Sol.</em> 12.1-2). Cylon’s effort failed in appropriately tragicomic fashion, with his supporters seeking shelter in the temple of Athena and only coming out with a cord that connected them to the altar and its notional protection (the cord breaks and they are all slain, Plut. <em>Sol</em>. 12).  Peisistratos also did it that way in Athens in 561 (Hdt. 1.59) using handpicked bodyguard that he armed with clubs, rather than spears; I cannot help but note just how many things we saw being used as clubs on the 6th. After the Pesistratids were thrown out, Isagoras attempted (with support from the Spartan king Cleomenes I) to institute an oligarchy the same way, seizing the Acropolis, but failing to take the Athenian <em>agora</em>; the Athenians rallied under the democratic leader Cleisthenes and besieged Cleomenes and Isagoras on the Acropolis (Hdt. 5.72; Arist. <em>Ath. Pol</em>. 20.1-4). Later in 411, the ‘Four Hundred’ would seize power in exactly the same way, arriving with a mob of armed supporters to disperse the Athenian <em>boule</em> – it’s council (Thuc. 8.69).  <strong>That’s four examples of this exact tactic from Athens alone</strong> (Athens was by no means the most <em>stasis</em>-prone ancient state, by the way – that was almost certainly Syracuse).</p>



<p>Moreover, <strong>One thing about coup attempts like this in the ancient world: they all look farcical, unless they work.</strong>  Peisistratos’ band of club-armed bodyguards would have looked terribly silly, except that they succeeded, for a time (put a pin in that, we’ll come back to it).  Peisistratos’ second attempt actually built support with something about as farcical as the <a href="https://www.bbc.com/news/world-us-canada-55606044">Q-Anon Shaman</a>, by riding into Athens on a chariot accompanied by a particularly tall woman dressed as Athena (Hdt. 1.60.2-5); the demonstration was taken by some as a sign of divine support. One assumes many Athenians thought it was laughable (Herodotus certainly does), but it was the precursor to another effort to seize power which also worked, albeit temporarily.</p>



<p>Just because it looks silly doesn’t mean it can’t work.  <strong>This was very serious</strong> and <strong>anyone pretending that ‘censorship’ on Twitter</strong> (a <em>private</em> platform, I thought these folks believed in markets?) <strong>or mean – but true – words from angry politicians is more consequential <em>than the violent attempt to seize the seat of government</em> is either a fool, an enemy, or both</strong> (though I will note that there is a world of difference between ‘fools’ and ‘enemies’ – fools may be persuaded and doing so is essential, see below.  We are all foolish at times; it is the cynics that get my dander up).</p>



<figure><img data-attachment-id="5938" data-permalink="https://acoup.blog/pxl_20210110_223238849-mp_/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610299958&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1919&quot;,&quot;shutter_speed&quot;:&quot;0.066683&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pxl_20210110_223238849.mp_" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Oliver, acting as my loyal research assistant.</figcaption></figure>



<h2>This Is Not Over</h2>



<p>Let’s come back to Peisistratos, because he is instructive here.  Peisistratos tried to make himself tyrant of Athens <em><strong>twice</strong></em> before his third attempt succeeded. We’ve discussed his <strong>first attempt </strong>above (in 561), where Peisistratos attempted to use a club-armed bodyguard to seize the city (Hdt. 1.59); that worked, but he was overthrown in a counter-coup sometime after (Hdt. 1.60.1; this was not immediately though, Herodotus notes that Peisistratos had time to set government affairs, Hdt. 1.59.6).</p>



<p><strong>For the <em>second</em> attempt </strong>in 559, Peisistratos made a key alliance with Megacles – someone we might term an ‘establishment’ figure in the Athenian politics of the day, looking to get the edge on his rivals in the continuing Athenian <em>stasis</em> (Herodotus uses the very word, I should note). He was then brought into the city (the chariot bit above, Hdt. 1.60.2-5) and seized power <em>again</em>, with a mob of his supporters. This effort ends because Peisistratos offends Megacles and once his ally turns on him, he is exiled again (Hdt. 1.61.1-2).</p>



<p>But that wasn’t the end of the matter. Peisistratos, once out of power again used his wealth and support – often foreign support, we are told – to raise an army, hire mercenaries (Argives, Herodotus reports) and rally his supporters before storming back into Athens in 545 (Hdt. 1.16.3-4). Herodotus notes that a great flock of Peisistratos’ partisans from the city swarmed out to support him (this should sound more than a little familiar) and<strong> with that mix of mercenaries and mob he was able to catch the Athenians unprepared</strong> (Hdt. 1.63.1) and scattered them, then used a mix of misinformation (implying he intended no violence, Hdt. 1.63.2) and speed to seize the key parts of the city to keep the Athenians disorganized. And then he murdered or exiled all of his enemies (Hdt. 1.64.3) because that is what tyrants <em>do</em>, whatever they are assuring you about their peaceful intentions ahead of time. People who seize power with violence instead of with votes do not suddenly become pacifists when they win!</p>



<p>I don’t know what form the continuation of the trends that led to the Capitol Insurrection will take, if there will be further attempts at violent disruption in D.C. itself, or if we’ll see a shift to a campaign of domestic terror (something like <a href="https://en.wikipedia.org/wiki/The_Troubles">The Troubles</a>, in terms of the violence committed), or if, as with the Nazis after the failure of the <a href="https://en.wikipedia.org/wiki/Beer_Hall_Putsch">Beer Hall Putsch</a>, the folks who supported this insurrection will focus on trying to use the democratic process to abolish the democratic process.  <strong>But this is not over</strong>.  There is abundant polling evidence that among a minority of Americans (but a plurality or majority of Republicans; we’ll come back to that) support for the lies (that the election was fraudulent, <em><a href="https://factcheck.thedispatch.com/p/fact-check-debunking-donald-trumps">which it wasn’t</a></em>; the liars were <a href="https://beta.documentcloud.org/documents/20423518-trump_case_decision">given plenty of chances to provide any evidence at all</a> for their lies and they didn’t) remains high.  As in 545, a great many Americans still support Peisistratos.  Some smaller subset of them have bought into messianic conspiracy theories like Q-Anon which fairly transparently could lead to considerable violence. <strong> The underlying conditions that made the tyrannical attempt possible still exist</strong>, so we should expect …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/">https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787594</guid>
            <pubDate>Fri, 15 Jan 2021 06:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Donut.c Without a Math Library]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25787545">thread link</a>) | @robin_reala
<br/>
January 14, 2021 | https://www.a1k0n.net/2021/01/13/optimizing-donut.html | <a href="https://web.archive.org/web/*/https://www.a1k0n.net/2021/01/13/optimizing-donut.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        

<article>
  <p>My little <a href="https://www.a1k0n.net/2011/07/20/donut-math.html">donut.c</a> has
 been making the rounds
again, after being featured in a couple YouTube videos (e.g., <a href="https://www.youtube.com/watch?v=DEqXNfs_HhY">Lex
Fridman</a> and <a href="https://www.youtube.com/watch?v=sW9npZVpiMI">Joma
Tech</a>).  If I had known how much
attention this code would get over the years, I would have spent more time on
it.</p>

<p>One thing that’s always been sort of unfortunate is the heavy use of <code>sin</code> and
<code>cos</code> – both because it necessitates linking the math library (<code>-lm</code>), but
also because it makes it much more CPU-intensive than it really needs to be.
This is especially apparent if you try to port it to an <a href="https://twitter.com/chainq/status/1297178062937825280">older
CPU</a> or an <a href="https://twitter.com/enjoy_digital/status/1341095343816118272">embedded
device</a>.</p>

<p>So, here’s a revised version with no use of <code>sin</code>, <code>cos</code>, and no need for
linking the math library (though this version still does use <code>float</code> types).</p>

<div><div><pre><code>             i,j,k,x,y,o,N;
         main(){float z[1760],a
      #define R(t,x,y) f=x;x-=t*y\
   ;y+=t*f;f=(3-x*x-y*y)/2;x*=f;y*=f;
   =0,e=1,c=1,d=0,f,g,h,G,H,A,t,D;char
 b[1760];for(;;){memset(b,32,1760);g=0,
h=1;memset(z,0,7040);for(j=0;j&lt;90;j++){
G=0,H=1;for(i=0;i&lt;314;i++){A=h+2,D=1/(G*
A*a+g*e+5);t=G*A        *e-g*a;x=40+30*D
*(H*A*d-t*c);y=          12+15*D*(H*A*c+
t*d);o=x+80*y;N          =8*((g*a-G*h*e)
*d-G*h*a-g*e-H*h        *c);if(22&gt;y&amp;&amp;y&gt;
 0&amp;&amp;x&gt;0&amp;&amp;80&gt;x&amp;&amp;D&gt;z[o]){z[o]=D;b[o]=(N&gt;0
  ?N:0)[".,-~:;=!*#$@"];}R(.02,H,G);}R(
  .07,h,g);}for(k=0;1761&gt;k;k++)putchar
   (k%80?b[k]:10);R(.04,e,a);R(.02,d,
     c);usleep(15000);printf('\n'+(
        " donut.c! \x1b[23A"));}}
          /*no math lib needed
             .@a1k0n 2021.*/
</code></pre></div></div>

<p>It’s a little misshapen and still has comments at the bottom. I used the first
frame of its output as a template and there’s <em>slightly</em> less code than filled
pixels – oh well. Output is pretty much the same as before:</p>


<pre id="d"></pre>



<p>So, how do we get sines and cosines without using <code>sin</code> and <code>cos</code>? Well, the
code doesn’t really <em>need</em> sine and cosine <em>per se</em>; what it actually does is
rotate a point around the origin in two nested loops, and also rotate two
angles just for the animation. If you’ll recall from the other article, the
inner loop is just plotting dots in a circle, which goes around another, larger
circle. In each loop, the sine/cosine terms are just moving by a small, fixed
angle.</p>

<p>So we don’t need to track the <em>angle</em> at all, we only need to start at cos=1,
sin=0 and rotate a circle around the origin to generate all the sines and
cosines we need. We just have to repeatedly apply a fixed rotation matrix:</p>

\[\begin{bmatrix}
c' \\
s'
\end{bmatrix} = \begin{bmatrix}
\cos \theta &amp; -\sin \theta \\
\sin \theta &amp; \cos \theta
\end{bmatrix} \begin{bmatrix} c \\ s \end{bmatrix}\]

<p>So for example, if we were to use an angle of .02 radians in our inner loop, it would look something like:</p>
<div><div><pre><code><span>float</span> <span>c</span><span>=</span><span>1</span><span>,</span> <span>s</span><span>=</span><span>0</span><span>;</span>  <span>// c for cos, s for sin</span>
<span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>314</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>  <span>// 314 * .02 ~= 2π</span>
  <span>// (use c, s in code)</span>
  <span>float</span> <span>newc</span> <span>=</span> <span>0</span><span>.</span><span>9998</span><span>*</span><span>c</span> <span>-</span> <span>0</span><span>.</span><span>01</span><span>9998666</span><span>*</span><span>s</span><span>;</span>
  <span>s</span> <span>=</span> <span>0</span><span>.</span><span>01</span><span>9998666</span><span>*</span><span>c</span> <span>+</span> <span>0</span><span>.</span><span>9998</span><span>*</span><span>s</span><span>;</span>
  <span>c</span> <span>=</span> <span>newc</span><span>;</span>
<span>}</span>
</code></pre></div></div>



<p>That works, but there’s a problem: no matter how precisely we define our
constants, after repeated iteration of this procedure, the magnitude of our \(\left(c, s\right)\) vector will exponentially grow or shrink over time. If we
only need to make one pass around the loop, maybe we can get away with that,
but if we have to make several (for the rotating animation, we do), we need to
fix that.</p>

<p><img src="https://www.a1k0n.net/img/sincos-mag.png" alt="sine and cosine magnitude creep"><br>
<em>an exaggerated illustration of what happens when repeatedly doing low-precision rotations</em></p>

<p>The simplest way to do that would be to multiply \(c\) and \(s\) by \(1/\sqrt{c^2 + s^2}\), but then we’re back to using the math library again. Instead, we can take
advantage of the fact that our magnitude starts out very close to 1, and we’re
going to be iterating this procedure: we can do a <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton
step</a> after each rotation, and
that will be enough to keep the magnitude “close enough” to 1 over time.</p>

<p>Our goal is to find the reciprocal square root (<a href="https://en.wikipedia.org/wiki/Fast_inverse_square_root">sound
familiar?</a>) of \(a =
c^2 + s^2\), our \(\left(c, s\right)\) vector magnitude.  Say we define a
function \(f(x) = \frac{1}{x^2} - a\). The function is 0 when \(x =
\frac{1}{\sqrt{a}}\). We can start with an initial guess of 1 for <em>x</em>,
perform a Newton iteration to obtain <em>x’</em>, which will be “closer to”
\(\frac{1}{\sqrt{a}}\), the correct value to scale <em>c</em> and <em>s</em> by so that their
magnitude \(c^2 + s^2\) is “close to” 1 again.</p>

<p>A Newton step is defined as \(x' = x - \frac{f(x)}{f'(x)}\). I used
<a href="https://www.sympy.org/">SymPy</a> to do the derivative and simplification and
came up with \(x' = \frac{x\left(3 - a x^2\right)}{2}\). Since we’re only doing
one step, we can plug in our initial guess of 1 for \(x\) and back-substitute
\(c^2 + s^2\) for \(a\) to finally get our adjustment: \(x' = (3 - c^2 - s^2)/2\).</p>



<p>But now that we don’t have to worry so much about the magnitude of our result
(within limits), we can take another shortcut (I got this idea studying old
<a href="https://en.wikipedia.org/wiki/CORDIC">CORDIC</a> algorithms).  If we divide out
the cosines from our original rotation matrix, we get</p>

\[\begin{bmatrix}
c' \\
s'
\end{bmatrix} = \frac{1}{\cos \theta}\begin{bmatrix}
1 &amp; -\tan \theta \\
\tan \theta &amp; 1
\end{bmatrix} \begin{bmatrix} c \\ s \end{bmatrix}\]

<p>using the trig identity \(\tan \theta = \frac{\sin \theta}{\cos \theta}\).
Since we’re only dealing with small angles, the leading \(\frac{1}{\cos
\theta}\) term is close enough to 1 that we can ignore it and have our Newton
step take care of it.</p>

<p>And now we can finally understand how the rotation is done in the code. Towards
the top of the donut code is this #define, which I’ve reindented:</p>

<div><div><pre><code><span>#define R(t,x,y) \ 
</span>  <span>f</span> <span>=</span> <span>x</span><span>;</span> \
  <span>x</span> <span>-=</span> <span>t</span><span>*</span><span>y</span><span>;</span> \
  <span>y</span> <span>+=</span> <span>t</span><span>*</span><span>f</span><span>;</span> \
  <span>f</span> <span>=</span> <span>(</span><span>3</span><span>-</span><span>x</span><span>*</span><span>x</span><span>-</span><span>y</span><span>*</span><span>y</span><span>)</span><span>/</span><span>2</span><span>;</span> \
  <span>x</span> <span>*=</span> <span>f</span><span>;</span> \
  <span>y</span> <span>*=</span> <span>f</span><span>;</span>
</code></pre></div></div>

<p>This does an in-place rotation of a unit vector <code>x, y</code> where <code>t</code> is \(\tan
\theta\). <code>f</code> is a temporary variable; the first three lines do the “matrix
multiplication” on <code>x, y</code>. <code>f</code> is then re-used to get the magnitude adjustment,
and then finally <code>x</code> and <code>y</code> are multiplied by <code>f</code> which moves them back onto
the unit circle.</p>

<p>With that operation in hand, I just replaced all the angles with their sines
and cosines and ran the rotation operator <code>R()</code> instead of calling <code>sin</code>/<code>cos</code>.
The code is otherwise identical.</p>



<p>We can use exactly the same ideas with integer fixed-point arithmetic, and not
use any <code>float</code> math whatsoever. I’ve redone all the math with 10-bit precision
and produced the following C code which runs well on embedded devices which can
do 32-bit multiplications and have ~4k of available RAM:</p>

<div><div><pre><code><span>#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;
</span>
<span>#define R(mul,shift,x,y) \
  _=x; \
  x -= mul*y&gt;&gt;shift; \
  y += mul*_&gt;&gt;shift; \
  _ = 3145728-x*x-y*y&gt;&gt;11; \
  x = x*_&gt;&gt;10; \
  y = y*_&gt;&gt;10;
</span>
<span>int8_t</span> <span>b</span><span>[</span><span>1760</span><span>],</span> <span>z</span><span>[</span><span>1760</span><span>];</span>

<span>void</span> <span>main</span><span>()</span> <span>{</span>
  <span>int</span> <span>sA</span><span>=</span><span>1024</span><span>,</span><span>cA</span><span>=</span><span>0</span><span>,</span><span>sB</span><span>=</span><span>1024</span><span>,</span><span>cB</span><span>=</span><span>0</span><span>,</span><span>_</span><span>;</span>
  <span>for</span> <span>(;;)</span> <span>{</span>
    <span>memset</span><span>(</span><span>b</span><span>,</span> <span>32</span><span>,</span> <span>1760</span><span>);</span>  <span>// text buffer</span>
    <span>memset</span><span>(</span><span>z</span><span>,</span> <span>127</span><span>,</span> <span>1760</span><span>);</span>   <span>// z buffer</span>
    <span>int</span> <span>sj</span><span>=</span><span>0</span><span>,</span> <span>cj</span><span>=</span><span>1024</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>j</span> <span>=</span> <span>0</span><span>;</span> <span>j</span> <span>&lt;</span> <span>90</span><span>;</span> <span>j</span><span>++</span><span>)</span> <span>{</span>
      <span>int</span> <span>si</span> <span>=</span> <span>0</span><span>,</span> <span>ci</span> <span>=</span> <span>1024</span><span>;</span>  <span>// sine and cosine of angle i</span>
      <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>324</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>int</span> <span>R1</span> <span>=</span> <span>1</span><span>,</span> <span>R2</span> <span>=</span> <span>2048</span><span>,</span> <span>K2</span> <span>=</span> <span>5120</span><span>*</span><span>1024</span><span>;</span>

        <span>int</span> <span>x0</span> <span>=</span> <span>R1</span><span>*</span><span>cj</span> <span>+</span> <span>R2</span><span>,</span>
            <span>x1</span> <span>=</span> <span>ci</span><span>*</span><span>x0</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x2</span> <span>=</span> <span>cA</span><span>*</span><span>sj</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x3</span> <span>=</span> <span>si</span><span>*</span><span>x0</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x4</span> <span>=</span> <span>R1</span><span>*</span><span>x2</span> <span>-</span> <span>(</span><span>sA</span><span>*</span><span>x3</span> <span>&gt;&gt;</span> <span>10</span><span>),</span>
            <span>x5</span> <span>=</span> <span>sA</span><span>*</span><span>sj</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x6</span> <span>=</span> <span>K2</span> <span>+</span> <span>R1</span><span>*</span><span>1024</span><span>*</span><span>x5</span> <span>+</span> <span>cA</span><span>*</span><span>x3</span><span>,</span>
            <span>x7</span> <span>=</span> <span>cj</span><span>*</span><span>si</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x</span> <span>=</span> <span>40</span> <span>+</span> <span>30</span><span>*</span><span>(</span><span>cB</span><span>*</span><span>x1</span> <span>-</span> <span>sB</span><span>*</span><span>x4</span><span>)</span><span>/</span><span>x6</span><span>,</span>
            <span>y</span> <span>=</span> <span>12</span> <span>+</span> <span>15</span><span>*</span><span>(</span><span>cB</span><span>*</span><span>x4</span> <span>+</span> <span>sB</span><span>*</span><span>x1</span><span>)</span><span>/</span><span>x6</span><span>,</span>
            <span>N</span> <span>=</span> <span>(</span><span>-</span><span>cA</span><span>*</span><span>x7</span> <span>-</span> <span>cB</span><span>*</span><span>((</span><span>-</span><span>sA</span><span>*</span><span>x7</span><span>&gt;&gt;</span><span>10</span><span>)</span> <span>+</span> <span>x2</span><span>)</span> <span>-</span> <span>ci</span><span>*</span><span>(</span><span>cj</span><span>*</span><span>sB</span> <span>&gt;&gt;</span> <span>10</span><span>)</span> <span>&gt;&gt;</span> <span>10</span><span>)</span> <span>-</span> <span>x5</span> <span>&gt;&gt;</span> <span>7</span><span>;</span>

        <span>int</span> <span>o</span> <span>=</span> <span>x</span> <span>+</span> <span>80</span> <span>*</span> <span>y</span><span>;</span>
        <span>int8_t</span> <span>zz</span> <span>=</span> <span>(</span><span>x6</span><span>-</span><span>K2</span><span>)</span><span>&gt;&gt;</span><span>15</span><span>;</span>
        <span>if</span> <span>(</span><span>22</span> <span>&gt;</span> <span>y</span> <span>&amp;&amp;</span> <span>y</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>x</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>80</span> <span>&gt;</span> <span>x</span> <span>&amp;&amp;</span> <span>zz</span> <span>&lt;</span> <span>z</span><span>[</span><span>o</span><span>])</span> <span>{</span>
          <span>z</span><span>[</span><span>o</span><span>]</span> <span>=</span> <span>zz</span><span>;</span>
          <span>b</span><span>[</span><span>o</span><span>]</span> <span>=</span> <span>".,-~:;=!*#$@"</span><span>[</span><span>N</span> <span>&gt;</span> <span>0</span> <span>?</span> <span>N</span> <span>:</span> <span>0</span><span>];</span>
        <span>}</span>
        <span>R</span><span>(</span><span>5</span><span>,</span> <span>8</span><span>,</span> <span>ci</span><span>,</span> <span>si</span><span>)</span>  <span>// rotate i</span>
      <span>}</span>
      <span>R</span><span>(</span><span>9</span><span>,</span> <span>7</span><span>,</span> <span>cj</span><span>,</span> <span>sj</span><span>)</span>  <span>// rotate j</span>
    <span>}</span>
    <span>for</span> <span>(</span><span>int</span> <span>k</span> <span>=</span> <span>0</span><span>;</span> <span>1761</span> <span>&gt;</span> <span>k</span><span>;</span> <span>k</span><span>++</span><span>)</span>
      <span>putchar</span><span>(</span><span>k</span> <span>%</span> <span>80</span> <span>?</span> <span>b</span><span>[</span><span>k</span><span>]</span> <span>:</span> <span>10</span><span>);</span>
    <span>R</span><span>(</span><span>5</span><span>,</span> <span>7</span><span>,</span> <span>cA</span><span>,</span> <span>sA</span><span>);</span>
    <span>R</span><span>(</span><span>5</span><span>,</span> <span>8</span><span>,</span> <span>cB</span><span>,</span> <span>sB</span><span>);</span>
    <span>usleep</span><span>(</span><span>15000</span><span>);</span>
    <span>printf</span><span>(</span><span>"</span><span>\x1b</span><span>[23A"</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The output is pretty much the same.</p>

</article>







      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://www.a1k0n.net/2021/01/13/optimizing-donut.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787545</guid>
            <pubDate>Fri, 15 Jan 2021 06:01:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mapping the videos of the Capitol building attack]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25786731">thread link</a>) | @basicplus2
<br/>
January 14, 2021 | https://thepatr10t.github.io/yall-Qaeda/ | <a href="https://web.archive.org/web/*/https://thepatr10t.github.io/yall-Qaeda/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://thepatr10t.github.io/yall-Qaeda/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786731</guid>
            <pubDate>Fri, 15 Jan 2021 03:40:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Composability of software components is the biggest benefit of K8s]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25786449">thread link</a>) | @airocker
<br/>
January 14, 2021 | https://lab.computer/static/blogs_p/jekyll/pixyll/2020/10/10/k8s-saas/ | <a href="https://web.archive.org/web/*/https://lab.computer/static/blogs_p/jekyll/pixyll/2020/10/10/k8s-saas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
    <div role="main">
      <div>
        




<article>
  <p><em>Pankaj Kumar</em></p>

<p><strong>Encapsulation in Kubernetes</strong></p>

<p>In 2018, for various reasons we moved our website to Kubernetes. When we started, we had little idea what Kubernetes had to offer. All we knew was that it can run a website based on containers that are full OS images. It is easier to move from one cloud provider to another. Cool! Little did we know the biggest advantage it offers: Encapsulation.</p>

<p>The biggest advantage of Kubernetes in my opinion is the encapsulation and composability of backend components. Any Saas product has to run a number of components from database, appserver, monitoring stack, pub/sub etc etc. Kubernetes makes everything a helm chart and some configuration away. The interfaces are neatly defined by the author of the helm chart and all the complexity is encapsulated well within a service. You could use many third party helm charts:
Monitoring: logging - Elasticsearch
Monitoring: metrics - Prometheus
Authentication - FusionAuth
Database - MongoDB
Chaos Monkey - Gremlin
CD - Argo
…
This abstraction of complexity lets every team focus on its unique IP and easily reuse third party components. Now why was it not possible before? VM images were too big, needed a lot of time to boot and it was hard to maintain a lot of them.</p>

<p>Composability is not just limited to third party components. Even your own code becomes very composable with well defined interfaces. Now how should we decide the boundary between two components in a Kubernetes cluster? The same priciples that apply in designing a database or paritioning a program to classes is useful here but with slightly different parameters. When we decide what should go into a class, we use the priciple of loose coupling and strong cohesion: The interface between classes
should be simple and the complexity can be captured inside the class. Also, strong cohesion means methods and properties inside the class should be related to each other: they should change together. A change in behavior should as much as possible be confined within the class.</p>

<p>Choosing the boundary of Kubernetes components depends on a few things apart from the Simplicity of the interface: 
Single process: Everything in one component should run as a single process/container. It should have the same dependencies. You dont really have to worry about this because you pretty much have little choice.
Configurability of the component: IF a configuration change requires the restart of certain parts, they should be in the same component.
Auto-scaling policies for the component. If one component is CPU bound and needs CPU scaling whereas other needs Memory based autoscaling, they should be in different components.
We should strive to decouple state of the containers from the runtime as much as possible, by using databases and volume claims. But ideally one component should not have too many different types of state.</p>

<p>It can also be thought of as taking a UML component diagram and giving each component a container of its own. The concept of components in UML closely resembles an image.</p>

<p>Now, let’s say someday that the component configuration is super easy and the  configuration/maintenance of these components rests in the hands of the creator of the component itself (for a fee of course).  The frontend app developer would go hire some of these backend components, configure them together and a new app is ready to run! The road will not be easy but this will be true low-code where complex services can be built by just knowing UI programming.</p>

</article>










  




      </div>
    </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://lab.computer/static/blogs_p/jekyll/pixyll/2020/10/10/k8s-saas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25786449</guid>
            <pubDate>Fri, 15 Jan 2021 02:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beating Up on Qsort (2019)]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25783617">thread link</a>) | @tjalfi
<br/>
January 14, 2021 | https://travisdowns.github.io/blog/2019/05/22/sorting.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2019/05/22/sorting.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Recently, Daniel Lemire <a href="https://lemire.me/blog/2019/05/07/almost-picking-n-distinct-numbers-at-random/">tackled the topic</a> of selecting N <em>distinct</em> numbers at random. In the case we want sorted output, an obvious solution presents itself: sorting randomly chosen values and de-duplicating the list, which is easy since identical values are now adjacent.<sup id="fnref:distinct" role="doc-noteref"><a href="#fn:distinct">1</a></sup></p>

<p>While Daniel suggests a clever method of avoiding a sort entirely<sup id="fnref:danmethod" role="doc-noteref"><a href="#fn:danmethod">2</a></sup>, I’m also interested in they <em>why</em> for the underlying performace of the sort method: it takes more than 100 ns per element, which means 100s of CPU clock cycles and usually even more instructions than that (on a superscalar processor)! As a sanity check, a quick benchmark (<code>perf record ./bench &amp;&amp; perf report</code>) shows that more than 90% of the time spent in this approach is in the sorting routine, <a href="https://devdocs.io/c/algorithm/qsort">qsort</a> - so we are right to focus on this step, rather than say the de-duplication step or the initial random number generation. This naturally, this raises the question: how fast is qsort when it comes to sorting integers and can we do better?</p>

<p>All of the code for this post <a href="https://github.com/travisdowns/sort-bench">is available on GitHub</a>, so if you’d like to follow along with the code open in an editor, go right ahead (warning: there are obviously some spoilers if you dig through the code first).</p>

<h2 id="benchmarking-qsort">Benchmarking Qsort</h2>

<p>First, let’s take a look at what <code>qsort</code> is doing, to see if there is any delicous low-hanging performance fruit. We use <code>perf record ./bench qsort</code> to capture profiling data, and <code>perf report --stdio</code> to print a summary<sup id="fnref:long-tail" role="doc-noteref"><a href="#fn:long-tail">3</a></sup>:</p>

<div><div><pre><code># Samples: 101K of event 'cycles:ppp'
# Event count (approx.): 65312285835
#
# Overhead  Command  Shared Object      Symbol
# ........  .......  .................  ..............................................
#
    64.90%  bench    libc-2.23.so       [.] msort_with_tmp.part.0
    21.45%  bench    bench              [.] compare_uint64_t
     8.65%  bench    libc-2.23.so       [.] __memcpy_sse2
     0.87%  bench    libc-2.23.so       [.] __memcpy_avx_unaligned
     0.83%  bench    bench              [.] main
     0.41%  bench    [kernel.kallsyms]  [k] clear_page_erms
     0.34%  bench    [kernel.kallsyms]  [k] native_irq_return_iret
     0.31%  bench    bench              [.] bench_one
</code></pre></div></div>

<p>The assembly for the biggest offender, <code>msort_with_tmp</code> looks like this<sup id="fnref:annotate-command" role="doc-noteref"><a href="#fn:annotate-command">4</a></sup> :</p>

<div><div><pre><code> Percent | Address      | Disassembly
--------------------------------------------------
   30.55 :   39200:       mov    rax,QWORD PTR [r15]
    0.61 :   39203:       sub    rbp,0x1
    0.52 :   39207:       add    r15,0x8
    7.30 :   3920b:       mov    QWORD PTR [rbx],rax
    0.39 :   3920e:       add    rbx,0x8
    0.07 :   39212:       test   r12,r12
    0.09 :   39215:       je     390e0   ; merge finished
    1.11 :   3921b:       test   rbp,rbp
    0.01 :   3921e:       je     390e0   ; merge finished
    5.24 :   39224:       mov    rdx,QWORD PTR [rsp+0x8]
    0.42 :   39229:       mov    rsi,r15
    0.19 :   3922c:       mov    rdi,r13
    6.08 :   3922f:       call   r14
    0.59 :   39232:       test   eax,eax
    3.52 :   39234:       jg     39200
   32.69 :   39236:       mov    rax,QWORD PTR [r13+0x0]
    1.31 :   3923a:       sub    r12,0x1
    1.01 :   3923e:       add    r13,0x8
    1.09 :   39242:       jmp    3920b &lt;bsearch@@GLIBC_2.2.5+0x205b&gt;
</code></pre></div></div>

<p>Depending on your level of assembly reading skill, it may not be obvious, but this is basically a classic merge routine: it is merging two lists by comparing the top elements of each list (pointed to by <code>r13</code> and <code>r15</code>), and then storing the smaller element (the line <code>QWORD PTR [rbx],rax</code>) and loading the next element from that list. There are also two checks for termination (<code>test   r12,r12</code> and <code>test   rbp,rbp</code>). This hot loop corresponds directly to this code from <code>glibc</code> (from the file<code>msort.c</code><sup id="fnref:msort-note" role="doc-noteref"><a href="#fn:msort-note">5</a></sup>) :</p>

<div><div><pre><code><span>while</span> <span>(</span><span>n1</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>n2</span> <span>&gt;</span> <span>0</span><span>)</span>
<span>{</span>
    <span>if</span> <span>((</span><span>*</span><span>cmp</span><span>)</span> <span>(</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>arg</span><span>)</span> <span>&lt;=</span> <span>0</span><span>)</span>
    <span>{</span>
        <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>tmp</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>b1</span><span>;</span>
        <span>b1</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
        <span>--</span><span>n1</span><span>;</span>
    <span>}</span>
    <span>else</span>
    <span>{</span>
        <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>tmp</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>b2</span><span>;</span>
        <span>b2</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
        <span>--</span><span>n2</span><span>;</span>
    <span>}</span>
    <span>tmp</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This loop suffers heavily from branch mispredictions, since the “which element is larger” branch is highly unpredictable (at least for random-looking input data). Indeed, we see roughly 128 million mispredicts while sorting ~11 million elements: close to 12 mispredicts per element.</p>

<p>We also note the presence of the indirect call at the <code>call r14</code> line. This corresponds to the <code>(*cmp) (b1, b2, arg)</code> expression in the source: it is calling the user provided comparator function through a function pointer. Since the <code>qsort()</code> code is compiled ahead of time and is found inside the shared libc binary, there is no chance that the comparator, passed as a function pointer, can be inlined.</p>

<p>The comparator function I provide looks like:</p>

<div><div><pre><code><span>int</span> <span>compare_uint64_t</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>l_</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>r_</span><span>)</span> <span>{</span>
    <span>uint64_t</span> <span>l</span> <span>=</span> <span>*</span><span>(</span><span>const</span> <span>uint64_t</span> <span>*</span><span>)</span><span>l_</span><span>;</span>
    <span>uint64_t</span> <span>r</span> <span>=</span> <span>*</span><span>(</span><span>const</span> <span>uint64_t</span> <span>*</span><span>)</span><span>r_</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span> <span>&lt;</span> <span>r</span><span>)</span> <span>return</span> <span>-</span><span>1</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span> <span>&gt;</span> <span>r</span><span>)</span> <span>return</span>  <span>1</span><span>;</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>which on gcc compiles to branch-free code:</p>

<div><div><pre><code>mov    rax,QWORD PTR [rsi]
mov    edx,0xffffffff
cmp    QWORD PTR [rdi],rax
seta   al
movzx  eax,al
cmovb  eax,edx
ret
</code></pre></div></div>

<p>Note that the comparator has to redundantly load from memory the two locations to compare, something the merge loop already did (the merge loop reads them because it is responsible for moving the elements).</p>

<p>How much better could things get if we inline the comparator into the merge loop? That’s what we do in <code>qsort-inlined</code><sup id="fnref:inline-hard" role="doc-noteref"><a href="#fn:inline-hard">6</a></sup>, and here’s the main loop which now includes the comparator function<sup id="fnref:cmdline1" role="doc-noteref"><a href="#fn:cmdline1">7</a></sup> :</p>

<pre><code> 0.07 :   401dc8:       test   rbp,rbp
 0.66 :   401dcb:       je     401e0c &lt;void msort_with_tmp&lt;CompareU64&gt;(msort_param const*, void*, unsigned long, CompareU64)+0xbc&gt;
 3.51 :   401dcd:       mov    rax,QWORD PTR [r9]
 5.00 :   401dd0:       lea    rdx,[rbx+0x8]
 1.62 :   401dd4:       mov    rcx,QWORD PTR [rbx]
 0.24 :   401dd7:       lea    r8,[r9+0x8]
 6.96 :   401ddb:       cmp    rax,rcx
20.83 :   401dde:       cmovbe r9,r8
 8.88 :   401de2:       cmova  rbx,rdx
 0.27 :   401de6:       cmp    rcx,rax
 6.23 :   401de9:       sbb    r8,r8
 0.74 :   401dec:       cmp    rcx,rax
 4.93 :   401def:       sbb    rdx,rdx
 0.24 :   401df2:       not    r8
 6.69 :   401df5:       add    rbp,rdx
 0.44 :   401df8:       cmp    rax,rcx
 5.34 :   401dfb:       cmova  rax,rcx
 5.96 :   401dff:       add    rdi,0x8
 7.48 :   401e03:       mov    QWORD PTR [rdi-0x8],rax
 0.00 :   401e07:       add    r15,r8
 0.71 :   401e0a:       jne    401dc8 &lt;void msort_with_tmp&lt;CompareU64&gt;(msort_param const*, void*, unsigned long, CompareU64)+0x78&gt;
</code></pre>

<p>A key difference is that the core of the loop is now branch free. Yes, there are still two conditional jumps, but they are both just checking for the termination condition (that one of the lists to merge is exhausted), so we expect this loop to be free of branch mispredictions other than the final iteration. Indeed, we measure with <code>perf stat</code> that the misprediction rate has dropped from to close to 12 mispredicts per element to around 0.75 per element. The loop has only two loads and one store, so the memory access redundancy between the merge code and the comparator has been eliminated<sup id="fnref:load-redundancy" role="doc-noteref"><a href="#fn:load-redundancy">8</a></sup>. Finally, the comparator does a three-way compare (returning distrinct results for <code>&lt;</code>, <code>&gt;</code> and <code>==</code>), but the merge code only needs a two-way compare (<code>&lt;=</code> or <code>&gt;</code>) - inlining the comparator manages to remove extra code associated with distinguishing the <code>&lt;</code> and <code>==</code> cases.</p>

<p>What’s the payoff? It’s pretty big:</p>

<p><img src="https://travisdowns.github.io/assets/2019-05-22/fig2.svg" alt="Effect of comparator inlining"></p>

<p>The speedup hovers right around 1.77x. Note that this is much larger than simply eliminating all the time spent in the separate comparator function in the original version (about 17% of the time implying a speedup of 1.2x if all the function time disapeared). This is a good example of how inlining isn’t just about removing function call overhead but enabling further <em>knock on</em> optimizations which can have a much larger effect than just removing the overhead associated with function calls.</p>

<h2 id="what-about-c">What about C++?</h2>

<p>Short of copying the existing glibc (note: LGPL licenced) sorting code to allow inlining, what else can we do to speed things up? I’m writing in C++, so how about the C++ sort functions available in the <code>&lt;algorithm&gt;</code> header? Unlike C’s <code>qsort</code> which is generic by virtue of taking a function pointer and information about the object size, the C++ sort functions use templates to achieve genericity and so are implemented directly in header files. Since the sort code and the comparator are being compiler together, we expect the comparator to be easily inlined, and perhaps other optimizations may occur.</p>

<p>Without further ado, let’s just throw <code>std::sort</code>, <code>std::stable_sort</code> and <code>std::partial_sort</code> into the mix:</p>

<p><img src="https://travisdowns.github.io/assets/2019-05-22/fig3.svg" alt="C vs C++ sort functions"></p>

<p>The C++ sort functions, other than perhaps <code>std::partial_sort</code><sup id="fnref:partial-sort" role="doc-noteref"><a href="#fn:partial-sort">9</a></sup>, put in a good showing. It is interesting that <code>std::stable_sort</code> which has <em>stricly more requirements</em> on its implementation than <code>std::sort</code> (i.e., any stable sort is also suitable for <code>std::sort</code>) ends up faster. I re-wrote this paragaph several times, since sometimes after a reboot <code>stable_sort</code> was slower and sometimes it was faster (as shown above). When it was “fast” it had less than 2% branch mispredictions, and when it was slow it was at 15%. So perhaps there was some type of aliasing issue in the branch predictor which depends on the physical addresses assigned, which can vary from run to run, I’m not sure. See <sup id="fnref:stablesort" role="doc-noteref"><a href="#fn:stablesort">10</a></sup> for an old note from when <code>std::stable_sort</code> was slower.</p>

<h2 id="can-we-do-better">Can we do better?</h2>

<p>So that’s as fast as it gets, right? We aren’t going to beat <code>std::sort</code> or <code>std::stable_sort</code> without a huge amount of effort, I think? After all, these are presumably highly optimized sorting routines written by the standard library implementors. Sure, we might expect to be able to beat <code>qsort()</code>, but that’s mostly because of built-in disadvantages that <code>qsort</code> has, lacking the ability to inline the comparator, etc.</p>

<h3 id="radix-sort-attempt-1">Radix Sort Attempt 1</h3>

<p>Well, one thing we can try is a non-comparison sort. We know we have integer keys, so why stick to comparing …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2019/05/22/sorting.html">https://travisdowns.github.io/blog/2019/05/22/sorting.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2019/05/22/sorting.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783617</guid>
            <pubDate>Thu, 14 Jan 2021 22:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sourcehut blog condeming Trump and supporters]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25783454">thread link</a>) | @lumpa
<br/>
January 14, 2021 | https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E | <a href="https://web.archive.org/web/*/https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783454</guid>
            <pubDate>Thu, 14 Jan 2021 22:12:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Goodbye Gutwhale (2020)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25782307">thread link</a>) | @BobbyVsTheDevil
<br/>
January 14, 2021 | http://stuffedwomb.at/goodbye_gutwhale | <a href="https://web.archive.org/web/*/http://stuffedwomb.at/goodbye_gutwhale">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><a href="http://stuffedwomb.at/thinking">back</a></p>

<div><p>Finally, almost 3 months after it released, I can stop thinking about Gutwhale.</p><p>
<em>This is the edited script of a talk I gave for the Game Dev Days 2020.</em></p></div>

<p><strong>Content</strong></p>
<ul>
  <li>the endles gamejam</li>
  <li>the call to action</li>
  <li>the important thing</li>
  <li>the power of deadlines</li>
  <li>the cost of deadlines</li>
  <li>the nice things</li>
  <li>conclusion</li>
</ul>



<h2>the endless gamejam</h2>

<div><p>A few years ago I only did gamejams.<br> 
Gamejams are essentially deadlines, forcing you finish something. <br>
I also did a lot of short jams alone, where i would sit down and give myself 30 minutes to make a prototype.<br>
Many of the gifs I post on twitter are the results of these solo jams.</p><p> 

This helped me to learn to code and to design and to schedule, but over time I found that simply making stuff was not enough anymore.</p><p>
What I really love is doing something new. <br>
Something that has not existed before.<br>
Finding a new angle on an old problem brings me an intense, deep joy that is really hard to describe.</p><p>

There is a lot of unexplored space in games and what I am currently really interested in is <strong>expression</strong>:<br>
How do I tell a story through a game? </p><p>
How do I communicate how I feel through videogames? </p><p>
Its really hard and kind of stupid, considering that videogames are all about endless repetition in closed systems, but its what i want to explore right now.</p><p>

And I explored it at my own pace while working as a receptionist, making games like <a href="https://www.google.com/">Up in the sky</a> and <a href="https://www.google.com/">Every Wall</a>.
</p></div>

<h2>the important thing</h2>
<div><p>There is a game developer called <a href="https://twitter.com/miziziziz">miziziziz</a>, one of the few who makes watchable youtube videos, 
who made a commercial game called <a href="https://store.steampowered.com/app/1232330/Theyest_Thou">Theyes Thou</a> in one month.</p><p>

When I lost my job as a receptionist because of the coronavirus, I decided to steal that idea.<br>
Since I am not overly interested in traditional FUN game design, I needed to make something that felt new to me. <br>
I needed to make a game that actually said something about the world we move through everyday. Just making an entertainment box would have been too boring and unfocused. </p><p>

But since I was unemployed I felt like I needed to make something that at least had a shot at commercial viability. One month is not a lot of time, but I needed to come up with something that people would also want to pay for.
<br>
The roguelike we ended up making contains a short section at the end where I try to actually say something, where I try to express myself. This part of the game was important to me, the rest was just decorations. <br>
I wanted people to buy the game because it looked like a nice little roguelike, and then, in the end, I wanted them to engage with this secret part of the game that was actually important to me. </p><p>

And I had one month to make that real.</p></div>

<h2>the power of deadlines</h2>
<p>Gutwhale is a product of its deadline.<br> 
All of it was made in the easiest way possible. The code is a mess of course, but I want to talk more about the decisions, forced upon us by the deadline, that permeate the whole project:<br></p>

<ul>
  <li>
    <p>Gutwhale is only called Gutwhale because the project needed an artist.
<a href="https://twitter.com/franek">Franek</a> is very good at making pixelart and he, for whatever reason, also loves to draw whales. So when he was on the fence about joining the project, I quickly changed the setting to take place inside of a whale. This does not make a lot of sense, but Franek got to draw a whale and the game had an artist.
<br></p>
  </li>
  <li>
    <p>Gutwhale used to take place on a single screen, because then I would not have to write a camera system. When it turned out that a single screen was pretty boring, we just glued multiple single screens together and make the floor break once all enemies were defeated. The core loop of Gutwhale was born out of not wanting to code a camera system.
<br></p>
  </li>
  <li>
    <p>The small size of the Levels themselves helped me in a lot of ways. The level generation code does not need to consider unreachable platforms and could be hacked together violently. Because there is so little space to move around in, enemies become more dangerous and I needed to code less of them to fill the game.<br></p>
  </li>
</ul>

<p>The deadline forced me to think quickly and to design dirtily, accidentally disovering some pretty neat things.<br>
It certainly has also hurt the game in a lot of ways.
<br></p>

<h2>the cost of deadlines</h2>

<p>Gutwhale is unbalanced in both directions. <br></p>

<div><p>For people with little to no platformer roguelike experience, it is extremely hard.minutes and then give up, never to touch the game again.</p><p>

For people who played downwell and gonner, it is a piece of cake and they can 100% the game in around 20 minutes. There is an endless nightmare mode, but it did not have an engaging highscore system, so the best players of Gutwhale quickly got bored.</p><p>

The save system of Gutwhale had horrible bugs and there were technical problems all over the place, prohibitung us from implementing Achievements and updating the game easily.<br>
We used Construct 2, an engine that is no longer supported by its developers in favour of Construct 3. This made it impossible to add Steam Achievements and created some other technical problems.
<br>
And these problems are just that: <br>
Problems. </p><p>

They exist because we rushed through development at an insane speed and I can forgive myself for making them, because I was actually focusing on this one secret thing at the end.
</p><p>
<strong>BUT</strong></p><p>
The part of the game that is most important to me, the ending, is also not working as intended. I was unable to clearly communicate what I wanted to communicate. 
<br>
There was not enough time to conduct long term playtests and interview players about how they perceived the ending.<br>
There was not enough time for me to really reflect and ponder and tweak and adjust the ending of Gutwhale.<br>
I started the project as a compromise between compelling gameplay and a secret, expressive part, which enabled me to keep working on the game.<br>
And that part did not work. It did not resonate. <br>
At least it feels like that to me now.</p></div>

<h2>the nice things</h2>

<p>Gutwhale was a success overall: <br></p>
<ul>
  <li>
    <p>It made me more money than I would have earned at my previous job, but not nearly enough to not have to go back to that job in 7 days.<br></p>
  </li>
  <li>
    <p>It may make substantially more money on consoles or in bundles in the future.</p>
  </li>
  <li>
    <p>It gave me a better understanding of how to sell stuff on steam.</p>
  </li>
  <li>
    <p>and last but defenitly not least, I got to work with Franek, Britt Brady and Clovelt who have thaught me a lot and are amazing people.
<br></p>
  </li>
</ul>

<h2>conclusion</h2>

<div><p>Finishing games is hard. <br>
Really hard. <br>
As a way to deal with this, a series of game jams has been created, where speed is key and the end product is only as important as the fact that it got finished.<br>
We have seen amazing games made in insanely short times and countless people have been able to dabble in game dev because of the contained nature of game jams.</p><p>

<strong>BUT</strong></p><p>
Applying this need for speed to bigger projects creates dynamics that should not be confused with efficiency and skill.</p><p>

The core part of Gutwhale, the one thing I was truly interested in, withered and died because of the deadline, because we were so wrapped up in getting the game done. <br>
There was simply not enough time to stop and smell the flowers.<br>
The deadline mercilessly  and in cold blood, pulled us away from being able to express ourselves.</p><p>

Gutwhale is nice and I am proud of it, but i think it is time for me to force myself to move on to a different way of development.</p><p>

When i did not know what I wanted express through the games I make, when i just wanted to MAKE, I needed frameworks to support me, to force me to do the work and to put in the hours, but after years of doing that, those structures have started to feel inhibiting in the best way possible. <br>
They are still able to teach me and to challenge me, but in the end, they are also keeping me from moving towards, to where I want to go, to do what I want to create.<br>
Deadlines keep me from really reflecting and looking at myself. They keep me from thinking about what i want to express through my work and they keep me from then actually saying that.</p></div>

<p><a href="https://store.steampowered.com/app/1267810/Gutwhale/">Gutwhale´s Steampage</a></p>

<p><a href="http://stuffedwomb.at/thinking">back</a></p>


      
    </div></div>]]>
            </description>
            <link>http://stuffedwomb.at/goodbye_gutwhale</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782307</guid>
            <pubDate>Thu, 14 Jan 2021 20:52:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Turing Machine]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25782120">thread link</a>) | @mr_tyzic
<br/>
January 14, 2021 | https://brandondong.github.io/css-turing-machine/ | <a href="https://web.archive.org/web/*/https://brandondong.github.io/css-turing-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://brandondong.github.io/css-turing-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782120</guid>
            <pubDate>Thu, 14 Jan 2021 20:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Complete Developer's Guide to Airtable]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25781916">thread link</a>) | @_acco
<br/>
January 14, 2021 | https://blog.syncinc.so/dev-guide | <a href="https://web.archive.org/web/*/https://blog.syncinc.so/dev-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>You might have missed <a href="https://blog.airtable.com/airtable-platform-launch-automations-sync-apps/">the memo</a>: Airtable is ready for developers.</p><p>In the span of a year, Airtable went from a simple <a href="https://airtable.com/api">REST API</a> to now supporting <a href="https://airtable.com/developers/scripting">scripting</a>, a <a href="https://airtable.com/developers/apps">custom apps SDK</a>, built in <a href="https://support.airtable.com/hc/en-us/articles/360050974153-Automations-Overview">automations</a>, and a small but growing ecosystem of <a href="https://airtable.com/marketplace">third-party tools and services</a>.</p><p>As a developer looking to build on Airtable, where should you start? And what is the developer experience like?</p><p>This guide aims to help developers navigate Airtable and build great applications on this growing platform.</p><h2><em>In</em> or <em>on</em> Airtable?</h2><p>Who is your user and what do they need? This age-old question is still the first one to ask as you begin to consider which Airtable developer tools to use.</p><p>At a high-level, you can classify Airtable's suite of <a href="https://airtable.com/developers">developer tools</a> as either supporting use cases that happen inside the Airtable interface (i.e. <em>in</em> Airtable) or outside Airtable in another app or tool (i.e. <em>on</em> Airtable).</p><p><img src="https://blog.syncinc.so/dev-guide/031_in_or_on.png" alt="in or on diagram"></p><p>When you are building <em>in</em> Airtable, the user is logged into Airtable and using your software within the Airtable interface. For any code you want to run <em>in</em> Airtable you'll be using either scripts, automations, or the custom app SDK.</p><blockquote><p>Note: Yes, I know, automations can trigger actions outside of Airtable. But by and large, the end user is <em>in</em> Airtable.</p></blockquote><p>If you are building <em>on</em> Airtable, then you are building for users outside of Airtable. This might be a custom internal tool, a dashboard built in Google Data Studio, a public Next.js website, or inside another SaaS application all together. In these use cases, you'll be using the Airtable REST API directly or using a tool like the one I helped build - <a href="https://syncinc.so/?utm_source=blog&amp;utm_medium=post&amp;utm_campaign=at-dev-guide">Sync Inc</a>.</p><p>As you decide whether to build <em>in</em> on <em>on</em> Airtable, you should consider what <a href="https://airtable.com/pricing">Airtable plan</a> your users are on as well. The REST API is available on every plan to every Airtable user. Automations are available on every plan, but capped at different limits. Meanwhile, scripts and custom apps are only available on pro and enterprise plans.</p><p><img src="https://blog.syncinc.so/dev-guide/020_pricing.png" alt="pricing"></p><blockquote><p>Note: Airtable Apps were formerly known as <em>Airtable Blocks</em>. The new name is slowly catching on but you'll still see the term <em>blocks</em> pop up here and there.</p></blockquote><p>Lastly, as your considering whether to build <em>in</em> or <em>on</em> Airtable, consider the functionality you need. When building <em>in</em> Airtable, you will face a couple constraints when working with 3rd party APIs, caching data, or manipulating the UI.</p><h2>Airtable's data quirks</h2><p>It's worth touching on Airtable's data model.</p><p>From a developer's perspective, Airtable is basically a hosted database fused to an easy interface for creating and managing data. This easy-to-use interface means the database schema is super flexible. Tables, columns, and field types can emerge, change, or disappear at anytime. Airtable is highly valuable because of this flexibility, but it also makes developing on Airtable a bit more unpredictable.</p><p>Additionally, as a data store, Airtable supports all sorts of <a href="https://airtable.com/developers/scripting/api/cell_values">data types</a>. Most of these data types are familiar and predictable.</p><p>However, two of these data types - <code>lookups</code> and <code>formulas</code> - can take the form of any other type. This makes sense given how Airtable works: if a formula is concatenating text, then its result is a string. If it is summing numbers, then its result is a number. This means the data type of these fields is a black box, sort of like the <code>any</code> type in TypeScript.</p><p>As a #protip to deal with Airtable's data flexibility, I highly recommend developing on a "staging" copy of the Airtable base you are working with. This helps reduce the likelihood that an end user will change data as you build. And, of course, this allows you to break things, a hallmark of a great development process. Airtable can duplicate a base remarkably fast (especially when you think about what's happening under the hood!) - so use this to your advantage.</p><p><img src="https://blog.syncinc.so/dev-guide/021_duplicate.png" alt="duplicate"></p><p>So: Which of the many options should you use to build on Airtable? Let's first consider building <em>in</em> Airtable with Airtable scripts.</p><h2>Airtable scripts: little record robots</h2><p><a href="https://airtable.com/developers/scripting">Airtable scripts</a> are short JavaScript snippets that allow you to manipulate data in your Airtable base.</p><p>You can do just about anything to the data in your base that is made possible with the standard JavaScript library. There are a couple limits:</p><ol><li>You can't import other JS libraries. You can copy and paste smaller, minified libraries that fit into one file - but it's usually a stretch.</li><li>You can't touch the DOM.</li><li>You can't change the schema of the base. You can't, for example, create new tables or views.</li></ol><p>To use scripts, you need to add the <em>scripting app</em> (f.k.a <em>scripting block</em>) to your base. This means you need to be on either the Pro or Enterprise Airtable plans.</p><p>It's also worth noting that Airtable now allows developers to share (no selling yet!) scripts in the <a href="https://airtable.com/marketplace/category/scripts">Airtable marketplace</a>. So if you write a killer script that is agnostic to a base, the entire community can benefit. In the marketplace you'll find all sorts of great script examples (in addition to those in the <a href="https://airtable.com/developers/scripting/examples">docs</a>).</p><h3>Elements of a script</h3><p>Before diving into a hands-on example, unpacking the building blocks of Airtable scripts will set the foundation for the rest of this guide.</p><p><strong>Getting data from the base</strong></p><p>Virtually every script (or automation/app for that matter) is going to start off by pulling data from an Airtable base.</p><p>Airtable follows a pretty straightforward relational model. Let's briefly step through it:</p><p>An Airtable workspace can contain many Airtable bases. Your script will run within one of these bases.</p><p>To add a script to a base, you'll install the <a href="https://support.airtable.com/hc/en-us/articles/360043041074-Scripting-app-overview"><strong>Scripting App</strong></a> in your base.</p><p>Then, to access information about the base in a script you'll use the <a href="https://airtable.com/developers/scripting/api/base">base model</a>.</p><p>For instance, if you pop open the scripting app, you can quickly retrieve the name of the Airtable base:</p><pre><p><span>console</span><span>.</span><span>log</span><span>(</span><span>`</span><span>The name of my base is </span><span>${</span><span>base</span><span>.</span><span>name</span><span>}</span><span>.</span><span>`</span><span>)</span><span>;</span><span></span></p></pre><p>Or, get the number of tables in the base:</p><pre><p><span>console</span><span>.</span><span>log</span><span>(</span><span>`</span><span>This base contains </span><span>${</span><span>base</span><span>.</span><span>tables</span><span>.</span><span>length</span><span>}</span><span> tables.</span><span>`</span><span>)</span><span>;</span><span></span></p></pre><p>As the prior query indicates, a base can contain many tables. You can interact with tables using the <a href="https://airtable.com/developers/scripting/api/table">table model</a>. So when you want to work with a table you retrieve it from the base:</p><pre><p><span>let</span><span> table </span><span>=</span><span> base</span><span>.</span><span>getTable</span><span>(</span><span>"Tasks"</span><span>)</span><span>;</span><span></span></p></pre><p>Once you have a table loaded into your script, you can access its <a href="https://airtable.com/developers/scripting/api/view">views</a>, <a href="https://airtable.com/developers/scripting/api/field">fields</a> and <a href="https://airtable.com/developers/scripting/api/record">records</a>.</p><p>A view is simply a filtered set of data in the table. So let's say you want to just pull all the records from a particular view:</p><pre><p><span>let</span><span> table </span><span>=</span><span> base</span><span>.</span><span>getTable</span><span>(</span><span>"Tasks"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> view </span><span>=</span><span> table</span><span>.</span><span>getView</span><span>(</span><span>"Todo"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>await</span><span> view</span><span>.</span><span>selectRecordsAsync</span><span>(</span><span>)</span><span>;</span><span></span></p></pre><p>The variable <code>query</code> is now going to contain all the records from the <code>Todo</code> view.</p><p>Now, when you want to inspect just one <code>Todo</code> record, you'll use the <a href="https://airtable.com/developers/scripting/api/record#get-cell-value"><code>getCellValue()</code> function</a>. As so:</p><pre><p><span>let</span><span> table </span><span>=</span><span> base</span><span>.</span><span>getTable</span><span>(</span><span>"Tasks"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> view </span><span>=</span><span> table</span><span>.</span><span>getView</span><span>(</span><span>"Todo"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> query </span><span>=</span><span> </span><span>await</span><span> view</span><span>.</span><span>selectRecordsAsync</span><span>(</span><span>)</span><span>;</span><span></span></p><p><span></span><span>let</span><span> record </span><span>=</span><span> query</span><span>.</span><span>records</span><span>[</span><span>0</span><span>]</span><span>;</span><span></span></p><p><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>record</span><span>.</span><span>getCellValue</span><span>(</span><span>"Description"</span><span>)</span><span>)</span><span>;</span><span></span></p></pre><p><img src="https://blog.syncinc.so/dev-guide/032_script_example.png" alt="Script example"></p><p>This quickly outlines the practical methods for pulling data from the base. You'll find that Airtable scripts includes some other models to get information on the user (a.k.a collaborator), session and more in the <a href="https://airtable.com/developers/scripting">docs</a>. But retrieving tables and records is the crux of working with data in Airtable.</p><p><strong>Collecting input from the user</strong></p><p>Beyond pulling data from the Airtable base, you'll also want to retrieve inputs from the user.</p><p>You may want to prompt the user for which table they want to evaluate in the script or which file they want to import. To do so, you'll use the <a href="https://airtable.com/developers/scripting/api/input">input object</a>. All input methods are asynchronous, so you'll always prefix each function call with <code>await</code>.</p><p>For instance, to ask the user their name:</p><pre><p><span>let</span><span> name </span><span>=</span><span> </span><span>await</span><span> input</span><span>.</span><span>textAsync</span><span>(</span><span>"What is your name?"</span><span>)</span><span>;</span><span></span></p><p><span>output</span><span>.</span><span>text</span><span>(</span><span>`</span><span>Your name is </span><span>${</span><span>name</span><span>}</span><span>.</span><span>`</span><span>)</span><span>;</span><span></span></p></pre><p><img src="https://blog.syncinc.so/dev-guide/033_name_prompt.png" alt="Name prompt"></p><p>You can have users enter text, click a button, select a table, view, field, or even a record. Combined, these inputs allow your script to interact with the user in all sorts of ways.</p><p><strong>Fetching data from an API</strong></p><p>In addition to collecting data from the Airtable base and user, you can also <a href="https://airtable.com/developers/scripting/api/fetch">fetch data</a> from third-party APIs.</p><pre><p><span>let</span><span> response </span><span>=</span><span> </span><span>await</span><span> </span><span>fetch</span><span>(</span><span>"https://api.github.com/orgs/Airtable"</span><span>)</span><span>;</span><span></span></p><p><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>await</span><span> response</span><span>.</span><span>json</span><span>(</span><span>)</span><span>)</span><span>;</span><span></span></p></pre><p>If the API you are calling requires authentication, your authentication token will be sitting right in the script. Keep in mind that users can view the underlying code in your script! If you don't trust the user, don't use an API fetch in your script.</p><p>Lastly, when using fetch, consider that <a href="https://airtable.com/developers/scripting/api/fetch#differences-from-fetch-in-the-browser">Airtable is not providing you with full fledge browser fetch</a>.</p><p><strong>Presenting data to the user</strong></p><p>Last but not least, after collecting data from the Airtable base, user or third-party API you'll then process that data and either update data in the base (using the table model functions of <code>createRecordAsync()</code>, <code>updateRecordAsync()</code>, or <code>deleteRecordAsync()</code>) or present data to the user.</p><p>To present a value to the user, you'll use the <a href="https://airtable.com/developers/scripting/api/output"><code>output</code> object</a>. You might output information as the scripts run to keep your user informed or to present a final results. Here is a simple "Hello, world!":</p><pre><p><span>output</span><span>.</span><span>markdown</span><span>(</span><span>"Hello, *world*!"</span><span>)</span><span>;</span><span></span></p></pre><p><img src="https://blog.syncinc.so/dev-guide/034_output.png" alt="Output"></p><p>You can present the user plain text, markdown, or a table.</p><h3>Writing a script</h3><p>Now, let's write a quick script to put these ideas to work.</p><p>To play along with this example (and make this post more enjoyable), you can add <a href="https://airtable.com/templates/sales-and-customers/expvjTzYAZareV1pt/sales-crm">this Sales CRM base template</a> to your workspace by clicking the <strong>Use Template</strong> button.</p><p>This template base is a simple Airtable CRM for tracking sales. As an example, let's say you want to write a script to calculate the current value of all open opportunities in the sales pipeline. This will give you a sense of how much potential revenue is available to the company. To do so, you want to sum up the <code>Estimated Value</code> for all deals that are active - that is, not yet won nor lost.</p><p>First, add the scripting app to the base by clicking the <strong>APPS</strong> button and selecting <strong>+ Install an app</strong>:</p><p><img src="https://blog.syncinc.so/dev-guide/001_add_app.png" alt="Add app"></p><p>Select the <strong>Scripting</strong> app.</p><p><img src="https://blog.syncinc.so/dev-guide/002_select_scripting.png" alt="Scripting app"></p><p>Apps live in Airtable dashboards. So click <strong>Install app</strong> and select the <strong>Sales CRM HQ</strong> dashboard.</p><p><img src="https://blog.syncinc.so/dev-guide/003_select_dash.png" alt="Scripting app"></p><p>The scripting app will now open. Start with a blank slate by deleting the <code>Hello, World</code> example that is pre-loaded.</p><p>Now, write your script. Initiate a variable that will store the total value of the pipeline. You can call it <code>pipeline_value</code>:</p><pre><p><span>let</span><span> …</span></p></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.syncinc.so/dev-guide">https://blog.syncinc.so/dev-guide</a></em></p>]]>
            </description>
            <link>https://blog.syncinc.so/dev-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781916</guid>
            <pubDate>Thu, 14 Jan 2021 20:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elasticsearch and Kibana are now business risks]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25781695">thread link</a>) | @vmbrasseur
<br/>
January 14, 2021 | https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks | <a href="https://web.archive.org/web/*/https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
          <p><strong> </strong> <time datetime="2021-01-14T00:00:00-08:00">January 14, 2021</time></p>
          
          
            <p> 




  4 minute read

</p>
          
        </header>
      

      <section itemprop="text">
        
        <p>In a play to convert users of their open source projects into paying customers, today Elastic announced that they are <a href="https://www.elastic.co/blog/licensing-change">changing the license</a> of both Elasticsearch and Kibana from the open source Apache v2 license to <a href="https://www.mongodb.com/licensing/server-side-public-license">Server Side Public License</a> (SSPL). If your organisation uses the open source versions of either Elasticsearch or Kibana in its products or projects, it is now at risk of being forced to release its intellectual property under terms dictated by another.</p>

<p>If you’re not yet aware of the SSPL, you can catch up <a href="https://mjg59.dreamwidth.org/51230.html">here</a>. As licenses go, it’s pretty problematic from a business perspective. Every <a href="https://en.wikipedia.org/wiki/Intellectual_property">IP lawyer</a> to whom I’ve showed the text of the SSPL has been rather alarmed before they even reach the end of it. Basically, it’s a hostile proprietary license masquerading in open source clothing. By using an SSPL project in your code, you are agreeing that if you provide an online service using that code then you will release not only that code but also the code for every supporting piece of software, all under the SSPL. It’s not a stretch to interpret the wording of the license as requiring users of the SSPL’d software therefore to release the code for everything straight down to the bare metal. There are those who will point to <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">the FAQ</a> for the SSPL and claim that the license isn’t interpreted in that way because the FAQ says so. Unfortunately, when you agree to a license you are agreeing to the <em>text of that license document</em> and not to a FAQ. If the text of that license document is ambiguous, then so are your rights and responsibilities under that license. Should your compliance to that license come before a judge, it’s <em>their</em> interpretation of those rights and responsibilities that will hold sway. This ambiguity puts your organisation at risk.</p>

<p>In <a href="https://www.elastic.co/blog/licensing-change">its announcement</a>, Elastic claims that this is simply a change of open source license. In one way they’re correct: they’re changing the license away from the open source Apache v2 license. However they are changing to what can best be described as a proprietary source available license, <em>not</em> to an open source one. MongoDB, the originators of SSPL, requested that <a href="https://opensource.org/">Open Source Initiative</a> (OSI) (the standards body that maintains the <a href="https://opensource.org/osd-annotated">Open Source Definition</a> and certifies licenses as open source) certify the SSPL as such. After a great deal of discussion among the panel of legal, licensing, and open source experts, MongoDB withdrew the SSPL from consideration as an open source license, as it appeared highly unlikely it would be certified as open source. That SSPL is not an open source license is no longer in dispute. That ship has sailed. If you have a problem with this, I suggest you <a href="https://lists.opensource.org/pipermail/license-discuss_lists.opensource.org/2019-May/020483.html">take it up</a> with OSI. As for Elastic’s public and verifiably false claim that SSPL is an open source license, it’s my hope that OSI will have a conversation with them and make a public statement of their own shortly.</p>

<p>No, this is a business decision, not an ideological one. Elastic made a business decision to change to this hostile proprietary license to give them a way to <del>extort</del>influence users to become customers. Without a great deal more strategic information about Elastic’s business and operations none of us are qualified to judge whether it’s the correct decision, but the decision itself is valid. They are allowed to make this sort of strategic move for their company.</p>

<p>However, you and your organisation have now also been forced into a business decision. If your organisation uses the Apache v2 licensed Elasticsearch or Kibana in its projects or products, it must now assume that it is at risk one way or another. It can upgrade to version 7.11 of these projects, thereby accepting the terms of SSPL and potentially also being required to release the code for its entire stack (a great deal of which it will not have the copyright over and will be unable to release, thereby potentially being in violation of SSPL). It can remain on version 7.10, but then it will no longer receive future updates, including important security fixes, thereby taking on another sort of risk. It could choose to pay for a Gold+ license for the software, but it’s unlikely that the budget is prepared for this sort of unexpected expense. And finally it can rearchitect its project or product, replacing Elasticsearch and/or Kibana with alternatives. Frankly, considering today’s unfriendly move by Elastic, putting some space between it and your organisation may be the safest alternative in the long run, but it will come with its own considerable price tag in time and other potential opportunity and switching costs.</p>

<p>The one thing your organisation cannot afford to do is ignore this. It’s time to call a meeting with your legal, software development, product, finance, and strategy teams to start to figure out the best option for you.</p>

<blockquote>
  <p>For more information on relicensing moves like this, please see <a href="https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/">The problem with Amazon and Open Source isn’t Amazon</a>.</p>
</blockquote>

<hr>

<blockquote>
  <p>Judging from the bandwidth usage stats on my hosting service, people seem to appreciate this post. Thank you for that. If you’d like me to provide corporate open source strategy for your company, please <a href="https://www.vmbrasseur.com/about/#contact">drop me an email</a>. I’ll soon be kicking my job search into high gear after <a href="https://anonymoushash.vmbrasseur.com/2020/06/01/farewell-juniper">Juniper laid off its open source team</a> last year. Contacting me now makes it more likely your company will be in consideration for my next role.</p>
</blockquote>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781695</guid>
            <pubDate>Thu, 14 Jan 2021 20:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Looking for a Free Website Categorization API?]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25781589">thread link</a>) | @alebrega
<br/>
January 14, 2021 | https://www.thestartupfounder.com/looking-for-a-free-website-categorization-api-check-this-company/ | <a href="https://web.archive.org/web/*/https://www.thestartupfounder.com/looking-for-a-free-website-categorization-api-check-this-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><strong>Website Categorization API</strong> classifies a site into a <strong>content</strong> <strong>category</strong>. It takes a <strong>URL</strong> as an input and assigns it into the relevant industry. There’s a lot of Categorizations API available on the internet but <a href="https://www.klazify.com/">Klazify</a> seems to be the most popular above all and should suit all your needs.</p>
<p><a href="https://www.klazify.com/">Klazify’s Website Categorization API</a> uses a machine learning (ML) engine to scan a website’s content and meta tags. It extracts text to classify the site and assigns up to three categories aided by natural language processing (NLP).</p>
<p>Their offline database is perfect for customers who require a local option for domain categorization. Typical use cases include hardware/product integrations, custom applications or internal use at an Enterprise organization with high request volume.</p>
<h2><strong>How Klazify works</strong></h2>
<p><a href="https://www.klazify.com/">Klazify</a> will navigate to the requested domain name or URL, collect its content,&nbsp; and determine appropriate categorizes based on a classification taxonomy: IAB V2 Standard, which can be used for 1-1 personalization, marketing segmentation, online filtering and more. The end result is that the URL or domain can now be placed in a specific category.</p>
<h2><strong>State Of The Art Accuracy</strong></h2>
<p>Their&nbsp; website categorization API is highly accurate, a simple lookup to a company’s URL will classify its industry within 385 possible topic categories.</p>
<h2><strong>Domain Processing</strong></h2>
<p><a href="https://www.klazify.com/">Klazify</a>’s domain processing begins one of two ways:</p>
<ul><li>New Domain Ingestion: Klazify examines the website, chasing new domains and re-indexing previously categorized domains.</li></ul>
<ul><li>External feeds: External data sources that are given to Klazify to process</li></ul>
<p><strong>Categorization</strong></p>
<p>Once a URL has been processed and passed the safety checks, it gets categorized.&nbsp;</p>
<h2><strong>Domain Categorization</strong></h2>
<p>There are over a lot of possible topic categories, making the list comprehensive but a little broader compared to other categorization taxonomies.&nbsp;</p>
<p><a href="https://www.klazify.com/category">Klazify’s categorization</a> is ideal for internet filtering and security applications, and best thing of all? They support all the domains available and almost all the languages of the world.</p>
<p>The Classification Taxonomy that Klazify uses is from the IAB, which was referenced before. IAB stands for “Interactive Advertising Bureau.” They’ve created a standard list of categories and subcategories for advertising purposes.</p>
<p>For example, if a publisher is putting together a campaign on Google Ads and only wants to show up on specific websites, Google utilizes the IAB classification to decide which category a certain domain belongs to. This means that if publishers are using Klazify to determine if websites URLs are relevant and pertinent for them to advertise on, the categorization that is given to them in Klazify is also used on advertising websites all over the internet.</p>
<h2><strong>Advertisers</strong></h2>
<p>For Advertisers, <a href="https://www.klazify.com/">Klazify</a> offers domain data categorized to the IAB taxonomy. Through Klazify’s API, customers can process large sets of data, allowing them to identify patterns between IPs and backlinking information or to categorize your data set. Advertisers often find this information useful in order to enhance customer demographics and better understand their behavior.</p>
<p>Once<a href="https://www.klazify.com/"> Klazify</a> finishes categorizing a domain, that domain can then have multiple categories associated with it. While a single website might only be placed in 3 categories using the IAB standards.</p>
<p>The IAB has nearly 385+ possible topic categories to choose from.&nbsp;</p>
<h2><strong>Network &amp; Cybersecurity</strong></h2>
<p>Network and Cybersecurity companies around the globe take advantage of <a href="https://www.klazify.com/">Klazify’s APIs </a>and data feeds to bring industry-leading threat intel and domain categorizations. Typical uses for Klazify include using their Domains API in order to dig deeper into network traffic or using their domain categorization API in order to categorize user access logs. Klazify incorporates over 66 data feeds to augment the engine.</p>
<h2><strong>Why Is <a href="https://www.klazify.com/">Klazify</a> The Best Option For Categorizing a Website?</strong></h2>
<h3><strong>Powerful &amp; Scalable</strong></h3>
<p>Klazify can scale to millions of requests and keep being stable under heavy workloads.</p>
<h3><strong>Easy-to-integrate</strong></h3>
<p>Customer’s time is valuable which is why Klazify’s APIs are simple to use and easy to integrate.</p>
<h3><strong>Dedicated Support Manager</strong></h3>
<p>Their Customer Support Team is always there to answer any questions.</p>
<h3><strong>Simple Documentation</strong></h3>
<p>Each endpoint is well documented with examples so a customer can quickly get started.</p>
<h2><strong>Key Features</strong></h2>
<h3><strong>Big Data</strong></h3>
<p>Using advanced machine learning, <a href="https://www.klazify.com/">Klazify</a> categorize billions of web pages, keeping the categorization database one of the most accurate in the industry.</p>
<h3><strong>Wide Range of Applications</strong></h3>
<p><a href="https://www.klazify.com/">Klazify’</a>s domain categorization allows customers to easily provide services such as Internet filtering, subscriber analytics, advertising networks, and fraud prevention.</p>
<h3><strong>Data Firehose</strong></h3>
<p>Need access to the raw data stream of everything as it’s being categorized? <a href="https://www.klazify.com/">Klazify</a> provides a real-time data firehose via HTTP.</p>
<p><strong>Advanced Algorithms</strong></p>
<p><a href="https://www.klazify.com/">Klazify’s technology</a> categorizes content found on URLs, as well as entire websites and IP addresses, perfect for security devices that may not have access to the full URL.</p>
<h3><strong>Developer-Friendly Responses</strong></h3>
<p>Every API response is returned as JSON, which can be easily read and implemented into your product.</p>
<h3><strong>Always Up to Date</strong></h3>
<p><a href="https://www.klazify.com/">Klazify’s web</a> crawlers are constantly visiting and classifying new and existing websites, providing real-time results and keeping the database always up to date.</p>
<h2><strong>So what’s the difference between the other website categorization API and <a href="https://www.klazify.com/">Klazify</a>?</strong></h2>
<p>The difference between all the other tools and <a href="https://www.klazify.com/">Klazify</a> is that the latter is the closest thing to a real human being checking every nook and cranny of the domain you’re interested in. The bonus is, this tool can do this on hundreds of thousands of websites in a single second for less than $790.00/year.</p>
<p><a href="https://accounts.google.com/o/oauth2/auth/oauthchooseaccount?client_id=24380142150-e2kucj4jf9r4gs2tgej0p6bgjabetibn.apps.googleusercontent.com&amp;redirect_uri=https%3A%2F%2Fwww.klazify.com%2Flogin%2Fgoogle%2Fcallback&amp;scope=openid%20profile%20email&amp;response_type=code&amp;state=44cTTtCgjoFTqsZxXHOX75pYpadRc5DTzwS89tBk&amp;flowName=GeneralOAuthFlow">If you want to try Klazify, you can sign up clicking here</a></p>
<hr>
<p>
<em>
Also published on <a href="https://medium.com/@aleb/looking-for-a-free-website-categorization-api-check-this-company-61012f526396">Medium</a>. </em>
</p>

 </div></div>]]>
            </description>
            <link>https://www.thestartupfounder.com/looking-for-a-free-website-categorization-api-check-this-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781589</guid>
            <pubDate>Thu, 14 Jan 2021 19:56:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yarh.io Micro 2 Raspberry Pi 3B+ Hacker's Linux Handheld]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25780972">thread link</a>) | @enchiridion
<br/>
January 14, 2021 | https://yarh.io/yarh-io-m2.html | <a href="https://web.archive.org/web/*/https://yarh.io/yarh-io-m2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section id="top-section">
        <div id="top-section-top">
            <nav>
                
            </nav>
            <p id="heading">
                
                <h2>Raspberry Pi 3B+ Hacker's Linux Handheld<br></h2>
            </p>
        </div>
    </section>
    <section id="yarh-io-mki">
        <div>
            <div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-hand-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-hand-large-t-001.png" alt="YARH.IO M2 Handheld"></a></p>
                    <div>
                        <p>Welcome to the new stage of the YARH.IO project, where our goal is to build a device designed for hacking, coding, and creative use. YARH.IO Micro 2 has been made with&nbsp;hackers in mind, for&nbsp;computer experts who uses their technical knowledge to achieve new goals and overcome computer system limitations by non-standard or 'hackable' means.&nbsp;<br></p>
                        <p>YARH.IO Micro 2 project continues to take on the challenge of building a full featured, micro sized handheld, based on Raspberry Pi 3B+, 4" touch screen and Bluetooth keyboard without touchpad.&nbsp;&nbsp;<br></p>
                        <p>YARH.IO Micro 2 can run Raspberry Pi OS or Kali Linux, providing users with a rich range of applications and development tools.&nbsp;This is a rare handheld that allows users to write new program code directly on the device for the use on the device itself.</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>YARH.IO Micro 2 is powered by&nbsp;Raspberry Pi 3B+, offering the best ratio of functionality and computing power requirements for a mobile, battery powered device. The board is stripped down to reduce the total height. The ethernet RJ45 connector on the Pi 3B+ has been removed, while the double stack USB connectors were replaced with single stack USB connectors.<br></p>
                        <p>Pimoroni Hyper Pixel 4" IPS 800x480 display delivers a sharp, clear, and bright picture with a wide viewing angle. Capacitive&nbsp;touch screen with multi-touch allows for a simple and easy interaction with the user interface.<br></p>
                        <p>Minimalist keyboard provides comfortable typing when holding the device with both hands. Modifier keys grant easy access to special control keys and functions. Custom key remapping simplifies interaction with the system and its applications.</p>
                    </div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-accessories-large-t-002.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-accessories-large-t-002.png" alt="YARH.IO M2 Handheld with accessories"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-left-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-left-large-t-001.png" alt="YARH.IO M2 Handheld front left"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 features extended USB connectivity. The two USB ports have been relocated to the top of the device and now allow users to simultaneously connect large profile USB accessories, such as WiFi adaptors, cellular modems, GPS, USB drives, and others.<br></p>
                        <p>A single, removable, high capacity Fenix ARB-L18-3500U 3500mAh Li-ion USB Rechargeable Battery powers the device. Removable battery ensures that an empty battery can be quickly replaced with a charged one. Fenix rechargeable battery provides direct charging via a Micro USB connector and a built-in battery charger.</p>
                        <p>High output Step-Up power supply has been used to effectively support power hungry USB accessories.&nbsp;</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>Arduino proMicro module controls the battery voltage. The module reads battery and power supply voltage, making the results available over I2C bus to the Raspberry Pi and to various custom build applications. The module also controls power LED as a way to indicate battery charge status.</p>
                        <p>With Arduino IDE installed, it is possible to program proMicro directly on the device, to customize battery charge LED indicator, and to add other creative functionality.</p>
                        <p>The DS3231 High Precision RTC Clock Module is used to store current time and date for the Raspberry Pi.</p>
                    </div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-top-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-top-large-t-001.png" alt="YARH.IO M2 Handheld top front"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-back-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-back-large-t-001.png" alt="YARH.IO M2 Handheld Back"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 features simple mechanical design. Main frame used for mounting Raspberry Pi board and screen, power bed with conjunction with front panel provides mounting points for keyboard, power supply, battery, RTC and proMicro module.&nbsp;</p>
                        <p>Back panel features an open battery bay, allowing for quick battery replacement. In instances when&nbsp;battery&nbsp;replacement is not required, the bay can be covered with the battery cover. This set-up ensures that the battery can always be charged using the battery's built-in charger.</p>
                        <p>The I2C bus is available while the I2C connector is mounted on the right side of the device and can be used to connect external modules with I2C connectivity.&nbsp;Pimoroni Hyper Pixel display utilises all Raspberry Pi GPIO pins, therefore no additional GPIO connectors are present for the external devices.&nbsp;<br></p>
                    </div>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-back-open-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-back-open-large-t-001.png" alt="YARH.IO M2 Handheld internals"></a></p>
                    <div>
                        <p>No 'click' assembly used. This is a fully hackable device with stainless steel button socket cap screws used&nbsp;throughout for multiple assembly and disassembly cycles.<br></p>
                        <p>The&nbsp;corners of the housing are protected with eight rugged-design rubber bumpers.&nbsp;<br></p>
                        <p>All parts are 3D printed using PLA and Flex plastics. ABS and ASA plastics can be used as an alternative, but require use of advanced printers and techniques.<br></p>
                        
                        <p>The list of parts used for the YARH.IO project can be purchased from Amazon and other online stores is available below.</p>
                    </div>
                </div>
                <div>
                    
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-front-kali-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-front-kali-large-t-001.png" alt="YARH.IO M2 Handheld Kali"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-usb-accessories-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-usb-accessories-large-t-001.png" alt="YARH.IO M2 Handheld USB accessories"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 Project at a Glance.&nbsp;</p>
                        <p>The outcome of this YARH.IO Micro 2 is a micro-size (116mm x 123mm x 27mm) handheld with the potential to run a unlimited applications and to be extended with an unlimited range of external USB devices. It is portable, has minimalist design, and can be relatively easily 3D printed and assembled.<br></p>
                        <p>The release of YARH.IO Micro 2 marks a new success in our line-up of goals&nbsp;towards the design, development, and release of innovative handhelds for hacking, coding, and creative use by computer experts and enthusiasts.&nbsp;<br></p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="yarh-io-mki-gallery">
        
    </section>
    <section id="yarh-io-mki-downloads">
        
    </section>
    <section id="yarh-io-mki-assembly-gallery">
        
    </section>
    <section id="yarh-io-mki-software">
        <div>
            <div>
                <p id="heading-software">
                    <h2>System &amp; Software<br></h2>
                </p>
                <div>
                    <div>
                        <div>
                            <h4>Software packages</h4><p><code>sudo apt install tmux vim mc -y<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>HyperPixel screen</h4><p><code>curl -sSL https://get.pimoroni.com/hyperpixel4 | bash<br></code><code>hyperpixel4-rotate right<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Turn off HyperPixel on shutdown</h4>
                            <p>The original link:&nbsp;https://github.com/pimoroni/hyperpixel4/issues/3. Thank you&nbsp;Florian Mirkes.<br></p><p><code># Create&nbsp;/etc/systemd/system/hyperpixel4-backlight.service and add the following:<br></code><code>[Unit]<br>Description=Sets up gpio-poweroff to handle Hyperpixel backlight upon shutdown/reboot<br>ConditionPathExists=/usr/bin/hyperpixel4-init<br>ConditionPathExists=/boot/overlays/gpio-poweroff.dtbo<br>ConditionPathExists=/usr/bin/dtoverlay<br>DefaultDependencies=no<br>Before=umount.target<br>[Service]<br>Type=oneshot<br>ExecStart=/bin/sh -c '/sbin/rmmod gpio-backlight;/usr/bin/dtoverlay /boot/overlays/gpio-poweroff.dtbo gpiopin=19 active_low=1'<br>[Install]<br>WantedBy=reboot.target halt.target poweroff.target<br></code><code>sudo systemctl enable hyperpixel4-backlight.service<br></code><code>sudo systemctl start hyperpixel4-backlight.service<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Enable right-click for the Raspberry Pi touchscreen</h4>
                            <p>The original article :&nbsp;https://fmirkes.github.io/articles/20190827.html. Thank you&nbsp;Philip Howard.<br></p><p><code>sudo apt install build-essential libevdev2 libevdev-dev -y<br></code><code>git clone 'https://github.com/PeterCxy/evdev-right-click-emulation.git'<br></code><code>cd 'evdev-right-click-emulation'<br></code><code>make all<br></code><code>sudo cp 'out/evdev-rce' '/usr/local/bin/'<br></code><code>sudo chmod +x '/usr/local/bin/evdev-rce'<br></code><code># Add evdev-rce to startup<br></code><code>sudo usermod -G 'input' -a pi<br></code><code>echo 'uinput' | sudo tee -a /etc/modules<br></code><code># Edit: /etc/udev/rules.d/99-uinput.rules<br></code><code>KERNEL=="uinput", MODE="0660", GROUP="input"<br></code><code>sudo udevadm control --reload-rules<br></code><code>sudo udevadm trigger<br></code><code>mkdir ~/.config/autostart<br></code><code># Create: ~/.config/autostart/evdev-rce.desktop and add the following:<br></code><code>[Desktop Entry]<br>Version=1.0<br>Type=Application<br>Name=evdev-rce<br>GenericName=Enable long-press-to-right-click gesture<br>Exec=env LONG_CLICK_INTERVAL=500 LONG_CLICK_FUZZ=50 /usr/local/bin/evdev-rce<br>Terminal=true<br>StartupNotify=false<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>RTC</h4><p><code># Create: ~/.rtc-init.sh and add the following:<br></code><code>echo "ds1307 0x68" | sudo -E tee -a /sys/bus/i2c/devices/i2c-11/new_device<br></code><code>sudo chmod +x ~/.rtc-init.sh<br></code><code># Create&nbsp;~/.config/autostart/rtc-init.desktop and add the following:<br></code><code>[Desktop Entry]<br>Version=1.0<br>Type=Application<br>Name=rtc-init<br>GenericName=Initialize ds3231 RTC on non standard i2c-11 bus, address 0x68<br>Exec=sh /home/pi/.rtc-init.sh<br>Terminal=true<br>StartupNotify=false<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Bluetooth Keyboard</h4>
                            <p>To connect Bluetooth keyboard for the first time use Bluetooth icon on the menu bar and select Add device. Press hard the Blue Bluetooth button on the keyboard, blue light on the keyboard starts blinking. The keyboard icon and name Bluetooth Keyboard should appear in the …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yarh.io/yarh-io-m2.html">https://yarh.io/yarh-io-m2.html</a></em></p>]]>
            </description>
            <link>https://yarh.io/yarh-io-m2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780972</guid>
            <pubDate>Thu, 14 Jan 2021 19:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowpack v3.0]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25780589">thread link</a>) | @dsego
<br/>
January 14, 2021 | https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0 | <a href="https://web.archive.org/web/*/https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
      <p>Snowpack v3.0 is here! This is our biggest release yet with brand new features including:</p>
<ul>
<li><strong>Pre-bundled streaming imports</strong> - Import any npm package, on-demand.</li>
<li><strong>Integrated build optimizations</strong> - Built-in bundling, preloading, minification, and more.</li>
<li><strong>JavaScript API</strong> - Integrate with Snowpack’s brand new native JS API.</li>
<li><strong>Node.js Runtime API</strong> - Import your Snowpack-built files directly into Node.js.</li>
<li><strong>Bug fixes, stability improvements, and a whole lot more!</strong></li>
</ul>
<p>Install the newest version of Snowpack to get started:</p>
<pre><code>$ npm install snowpack@^3.0.0
</code></pre>
<p>Or, try out one of our updated <a href="https://www.npmjs.com/package/create-snowpack-app">Create Snowpack App</a> starter templates:</p>
<pre><code>$ npx create-snowpack-app new-project-directory --template  @snowpack/app-template-react
</code></pre>
<h2 id="reimagining-web-development-for-esm">Reimagining Web Development for ESM</h2>
<p>1 year ago, Snowpack first released with the mission to reimagine web development for modern JavaScript and ESM. Snowpack leverages modern web features to deliver a frontend build tool that needs just 50ms to start up &amp; react to new file changes, regardless of project size. In comparison, traditional web bundlers could take several seconds or even full minutes to start up in large projects.</p>
<p>Snowpack v3.0 marks another huge leap on our mission to push web development forward with the release of <strong>streaming imports</strong>. Streaming imports make it possible to import any package directly into your project, pre-built and pre-bundled for immediate use. It’s the power of the entire JavaScript ecosystem, at your fingertips.</p>
<video preload="auto" autoplay="" loop="" muted="" playsinline="">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.webm" type="video/webm">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.mp4" type="video/mp4">
</video>
<h2 id="what-are-streaming-imports%3F">What are Streaming Imports?</h2>
<p>The typical web developer installs and manages their JavaScript dependencies locally using a package manager CLI like <code>npm</code>, <code>yarn</code> or <code>pnpm</code>. These npm packages can’t run directly in the browser, so additional work is needed to resolve, process, build and bundle these packages for the browser before you can actually use them.</p>
<p><strong>What if we could simplify this? What if you could skip the “npm install” step entirely and just fetch the relevant, pre-built package code on-demand via ESM import?</strong></p>
<pre><code><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'react'</span><span>;</span><p><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'https://cdn.skypack.dev/react@17.0.1'</span><span>;</span></p></code></pre>
<p>That URL in the example above points to <a href="https://www.skypack.dev/">Skypack</a>, a popular JavaScript CDN that we built to serve every package&nbsp;on npm as ESM. Importing dependencies by URL like this is well supported in Snowpack, Deno, and all major browsers. But writing these URLs directly into your source code isn’t ideal and makes development impossible without a network connection.</p>
<p><strong>Snowpack v3.0 brings together the best of both worlds:</strong> Get the simplicity of <code>import 'react'</code> in your own source code and let Snowpack fetch these dependencies behind the scenes, pre-built and ready to run in the browser. Snowpack caches everything for you automatically, so you can continue to work offline after the first package fetch.</p>
<p>This new workflow has several benefits over the traditional “npm install” approach:</p>
<ul>
<li><strong>Speed:</strong> Skip the install + build steps for dependencies, and load your dependencies on-demand as pre-build, pre-bundled ESM code.</li>
<li><strong>Safety:</strong> ESM packages are pre-built into JavaScript for you and never given access to <a href="https://www.usenix.org/system/files/sec19-zimmermann.pdf">run code on your machine</a>. Third-party code only ever runs sandboxed in the browser.</li>
<li><strong>Less Tooling:</strong> ESM packages are managed by Snowpack, so frontend projects that don’t need Node.js (Rails, PHP, etc.) can drop the npm CLI entirely if they choose.</li>
<li><strong>Identical Final Build:</strong> When you build your site for production, package code is transpiled with the rest of your site and tree-shaken to your exact set of imports.</li>
</ul>
<p>This is our bet on the future of web development. But if this all sounds too wild for you or you have some technical reason to keep managing your dependencies with npm, don’t worry. This is <strong>100% opt-in</strong> behavior for those who want it. By default, Snowpack will continue to pull your npm package dependencies out of your project <code>node_modules</code> directory like it always has.</p>
<p>Check out our guide on <a href="https://www.snowpack.dev/guides/streaming-imports">Streaming Package Imports</a> to learn more about how to enable this new behavior in your project today.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-esbuild.png" alt="js api"></p>
<h2 id="built-in-optimizations%2C-powered-by-esbuild">Built-in Optimizations, Powered by esbuild</h2>
<p><a href="https://esbuild.github.io/">esbuild</a> is a marvel: it performs 100x faster than most other popular bundlers their own benchmarks. esbuild is written in Go, a compiled language that can parallelize heavy bundling workloads where other popular bundlers – written in JavaScript – cannot.</p>
<p>Snowpack already uses esbuild internally as our default single-file builder for JavaScript, TypeScript and JSX files. Snowpack v3.0 takes this integration one step further, with a new built-in build optimization pipeline. Bundle, minify, and transpile your site for production in 1/100th of the time of other bundlers.</p>
<p>Snowpack is able to adopt esbuild today thanks to an early bet that we made on the future of bundling: <strong>bundling is just a post-build optimization.</strong> Thanks to this early design decision, esbuild can be plugged in and swapped out of your Snowpack build as easily as any other bundler.</p>
<p>esbuild is still a young project, but its future looks promising. In the meantime, we will also continue to invest in the existing bundler plugins for a long time to come, so that more mature projects can continue to use mature bundlers like Webpack &amp; Rollup.</p>
<p>To get started, check out the <code>optimize</code> option in our newest <a href="https://www.snowpack.dev/guides/optimize-and-bundle">Optimizing Your Snowpack Build</a> guide.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-jsapi.png" alt="js api"></p>
<h2 id="a-new-javascript-api">A New JavaScript API</h2>
<p>Snowpack’s new JavaScript API grants you more advanced control over Snowpack’s dev server and build pipeline, helping you build more powerful integrations on top of Snowpack to unlock new kinds of dev tooling and server-side rendering (SSR) solutions.</p>
<p><a href="https://svelte.dev/blog/whats-the-deal-with-sveltekit">SvelteKit</a> is the new official web app framework from the Svelte team, built with Snowpack. SvelteKit uses our new JavaScript API to manage the build pipeline and build files on-demand. Snowpack helps SvelteKit speed up development, with zero rapid updates on file change and zero upfront server start-up cost.</p>
<p><a href="https://www.npmjs.com/package/microsite">Microsite</a> is another exciting new project built with Snowpack. Microsite is a Static Site Generator (SSG) for Preact that features automatic partial hydration, so that you send as little JavaScript down to the client as possible.</p>
<p>Check out our new <a href="https://www.snowpack.dev/reference/javascript-interface">JavaScript API reference</a> to start building your own custom integrations on top of Snowpack.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-runtime.png" alt="js api"></p>
<h2 id="a-new-node.js-runtime">A New Node.js Runtime</h2>
<p>Speaking of Svelte, this next feature comes directly out of our collaboration with the Svelte team. As a part of building out SvelteKit, Rich Harris created a server-side runtime for Snowpack. This runtime lets you import any Snowpack-built file directly into Node.js, handling things like ESM-&gt;CJS conversion and CSS extraction automatically.</p>
<p>The result is a unified build pipeline across both Node.js and the frontend, with all of the on-demand build performance benefits of Snowpack. Importing frontend code to run in Node.js unlocks features like true server-side rendering (SSR), test runner integrations for Jest/uvu/Mocha, and more.</p>
<p>Check out our new <a href="https://www.snowpack.dev/guides/server-side-render">SSR guide</a> to get started and learn more about all of the different ways that you can connect to your Snowpack build.</p>
<p>🥳</p>
<h2 id="snowpack%E2%80%99s-one-year-anniversary">Snowpack’s One Year Anniversary</h2>
<p>Last week marked Snowpack’s one-year anniversary of the original v1.0.0 release. Looking back, I’m blown away by everything that’s happened since:</p>
<ul>
<li>150+ releases (from <code>v0.0.1</code>, all the way to v3.0 today)</li>
<li><a href="https://www.snowpack.dev/plugins">100+ Snowpack plugins</a> to choose from (and growing fast!)</li>
<li><a href="https://github.com/snowpackjs/snowpack/graphs/contributors">100+ individual contributors</a></li>
<li><a href="https://github.com/snowpackjs/snowpack/stargazers">15,000+ stars on GitHub</a></li>
<li>#1 Developer Productivity Boost Winner, <a href="https://osawards.com/javascript/2020">2020 JS Open Source Awards</a></li>
<li>#1 Highest Developer Interest, <a href="https://2020.stateofjs.com/en-US/technologies/build-tools/">2020 State of JS</a></li>
<li>#1 Highest Developer Satisfaction (tied), 2020 State of JS</li>
</ul>
<p>A huge thank you to everyone who has contributed code to Snowpack, and the hundreds of developers joining us on GitHub and on <a href="https://discord.com/invite/snowpack">Discord</a>. This project wouldn’t exist today without you and your support. Thank you!</p>
<p>– Fred K. Schott <a href="https://twitter.com/FredKSchott">(@FredKSchott)</a></p>

    </article>
    </div></div>]]>
            </description>
            <link>https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780589</guid>
            <pubDate>Thu, 14 Jan 2021 18:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing Time-to-Hire and Finding Niche Candidates via Text Mining and NLP]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25780588">thread link</a>) | @cl42
<br/>
January 14, 2021 | https://joinphase.com/talent-acquisition-nlp | <a href="https://web.archive.org/web/*/https://joinphase.com/talent-acquisition-nlp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>

   

    <p>Reducing Time-to-Hire and Finding Niche Candidates via Text Mining and NLP

    </p>
    
  </div>
</div><div>
  <div>

   

    <div>

<p><b>Summary:</b> Maison Battat, a global toy company, recently hired a uniquely qualified data science candidate in only 26 days. Phase describes how we worked with Maison Battat to build a text mining (i.e., “Natural Language Processing” or “NLP”) approach that could scan 1,000s of candidates in minutes and look for unique attributes and experiences shared by applicants and broader candidate pools alike.

</p><p>Skip to: <a href="#problem">Problem</a> | <a href="#solution">Solution</a> | <a href="#results">Result</a> | <a href="#quotes">Quotes</a>

    </p></div>

    </div>

    
  </div><div>
  <div>

   

    <div>

<p><a name="problem"></a>The Problem: too many candidates and poor screening options

</p><p>Most applicant screening systems are limited in how they enable searching and filtering of candidates. This means that they rarely allow you to include unique combinations of skills or score candidate profiles in a more flexible manner.

</p><p>Worse still, many job applications have <i>hundreds</i> or <i>thousands</i> of applicants. If you expand this to a passive pool, you can be looking at 10,000+ candidates for a single role. Hiring managers and recruiters struggle with reviewing so many profiles, and resort to keyword searches.

</p><p><a name="solution"></a>Our Solution: use recent advances in text mining to make candidate searches descriptive and holistic

</p><p>To address the challenge above, Phase uses two strategies to solve this problem.

</p><p><b>1. Make the search a conversational process</b>

</p><p>Rather than simply providing keywords, we ask recruiters to use a freeform description of the candidate they are looking for. To use the Battat example above...

</p><center>
<div><p>
A conventional exact-match keyword search might look like:</p><p>&nbsp;

“<span>Python</span>”, “<span>SQL</span>”, “<span>analyst</span>”, “<span>engineer</span>” or “<span>toys</span>”
</p><p>&nbsp;
But through our search, the candidate is described as:
</p><p>&nbsp;
“A <span>data scientist</span> who has with experience with
 <span>toys</span>, <span>education</span>, or <span>children’s products</span>.”
</p></div>
</center>

<p>We use descriptions because our search understands concepts and ideas. The algorithm knows that a “<span>data scientist</span>” is a person that is likely to know languages like “<span>Python</span>”, “<span>SQL</span>”, or others and takes on roles such as an “<span>analyst</span>” or “<span>engineer</span>”. By teaching the algorithm to seek out candidates who have experience with “<span>toys</span>”, “<span>education</span>” and “<span>children’s products</span>”, we can find people with relevant experience in related areas like “gaming” or “youth development”.

</p><p>Another way to think about this interface is that the recruiter simply has to <i>write</i> an answer to the question, “What sort of candidate are you looking for?” You need not worry about the specific structure of your response, or fitting keywords into specific parts of a search form. The above example could easily be “A former toy designer interested in analytics” or “A multilingual French-speaker who can design products and analyze data.”

</p><p>Our goal is to give the algorithm an idea of what type of candidate to look for. It will identify and make connections between concepts to find the strongest candidates. It is not limited by specific keywords. This means that a recruiter or hiring manager saves time by automating searches, while generating a broader diversity of qualified candidates.

</p><p><b>2. Search the whole resume, not just skills lists or keywords</b>

</p><p>Our semantic approach makes it easier for us to scan an entire resume to understand the person as a whole. For instance, a candidate might outline an interest in “children’s products” in one part of their resume, but not include this in their core skillsets elsewhere. This semantic approach tracks the <i>entire</i> resume and scores the <i>themes</i> that come up rather than just individual skills or keyword flags.

</p><p><a name="results"></a>The Result: 26 Days for Time-to-Hire and a Great Candidate Experience

</p><p>Maison Battat is a family-owned toy company that encourages kids to be bold, curious, and playful. For over 45 years, they have offered a range of engaging toys for babies, toddlers, and young children including Driven™ tough trucks to dolls of Our Generation™.

</p><p>Battat wanted to hire a unique candidate with experience in marketing, e-commerce, data science and analytics. They sought out someone who was a self-starter, fast learner, proficient in another language, has lived abroad, and shares their passion for improving the lives of children through play and education.

</p><p>Our text mining approach above was used to analyze over 1,000 data science candidate profiles. The top result was Sogra, a bilingual data analyst with international experience. Importantly, she was the ultimate self-starter having created an award-winning smart toy while she was working at a toy startup.

</p><p>Sogra was the first and only candidate interviewed – she was perfect for the role. Not only was the role filled in 26 days, but both employer and employee were thrilled with the significantly easier process and speedy approach.

    </p></div>

    </div>

    
  </div><div>
   <div>

     

     <div>

<p>“Phase reached out to me about a data analyst role at a toy company. Two weeks after I was introduced to the hiring manager, I accepted their job offer. I’m excited to have a data role that leverages my background as a toy designer. I feel amazing!”

</p><center></center>

<center><img src="https://joinphase.com/person_sogra.jpg"></center>

     </div>

     <div>

<p>“Phase has been a fantastic talent partner for our company. We hired the first candidate they sent us -- she was experienced in our industry and had a great analytics background. We went from first candidate introduction to first day on the job in 26 days.”

</p><center><p>Guillaume<br>Head of Amazon Business Unit,<br>Maison Battat<br>&nbsp;</p></center>

<center><img src="https://joinphase.com/person_guillaume.jpg"></center>

     </div>

     

    </div>
  </div></div>]]>
            </description>
            <link>https://joinphase.com/talent-acquisition-nlp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780588</guid>
            <pubDate>Thu, 14 Jan 2021 18:58:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Y Combinator’s First Batch: Where are they now?]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25779621">thread link</a>) | @smalera
<br/>
January 14, 2021 | https://www.businessofbusiness.com/articles/y-combinator-where-are-they-now-first-batch-reddit-twitch/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/y-combinator-where-are-they-now-first-batch-reddit-twitch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p><span>When Paul Graham and Jessica Livingston first began accepting applications for their new startup accelerator, they had $200,000 in seed money and four employees.</span></p>
<p><span>Graham, who had been working at a web application company called Viaweb, wasn’t particularly confident that their new venture would do well. But Graham wanted to invest in promising college students building innovative tech startups, much like his mentor, lawyer Julian Weber, had invested $10,000 in Graham’s own Viaweb.&nbsp;</span></p>
<p><span>Despite their misgivings, Graham and Livingston plowed ahead, creating a Silicon Valley icon in the process. To date, Y Combinator has helped launch and fund over 2,000 startups in Silicon Valley, including giants like Airbnb, Dropbox, Stripe, Reddit, DoorDash, Coinbase, and many more. As of 2021, the combined value of YC’s startups is estimated at $300 billion. Today, founders still aspire to get into one of YC’s batches.&nbsp;</span></p>
<p><span>Y Combinator’s consistently successful 16-year run all started with that First Batch, which included founders like Alexis Ohanian, Steve Huffman, Sam Altman, and Justin Kan. Last week, Kan </span><a href="https://twitter.com/justinkan/status/1337122637483364354?s=20"><span>tweeted an image</span></a><span> of YC’s First Batch dating back to the summer of 2005. It’s worth seeing how the years have treated that very first batch.</span></p>
<h2><b>2. Zak Stone</b></h2>
<p><b><img alt="" height="393" src="https://static.media.thinknum.com/media/uploads/.thumbnails/zak_stone.jpg/zak_stone-700x393.jpg" width="700"><span></span></b></p>
<p><b>Co-founder, Memamp<br></b><b>Where is he now?<br></b><b>Product manager for Cloud TPUs, Google</b></p>
<p><span>Along with Chris Slowe, Zak Stone co-founded Memamp, a desktop search startup. The two had been working on their idea for about a year before being accepted into Y Combinator’s First Batch, but it wasn’t meant to be. That summer, Google released its own desktop search feature, and Apple announced its Spotlight search feature for Macs. While Stone and Slowe decided to scrap the idea, Slowe joined up with Reddit’s founders. Stone, meanwhile, now works for Google’s Brain Team as a product manager for Cloud TPUs.</span></p>
<h2><span>3. Steve Huffman<br></span><span>4. Alexis Ohanian<br></span><span>6. Chris Slowe<br></span><span>10. Aaron Swartz</span></h2>
<p><span><img alt="" height="393" src="https://static.media.thinknum.com/media/uploads/.thumbnails/reddit.jpg/reddit-700x393.jpg" width="700"><span></span></span></p>
<p><b>Founders, Reddit<br></b><b>Where are they now?<br></b><b>Ohanian: Entrepreneur, investor<br></b><b>Huffman: CEO, Reddit<br></b><b>Slowe: CTO, Reddit<br></b><b>Swartz: Committed suicide in 2013 at age 26.</b></p>
<p>After the initial rejection of their first startup idea, MyMobileMenu, Alexis Ohanian and his fellow founders started work on “the front page of the internet.” That project,&nbsp;an idea that came from Paul Graham,&nbsp;turned into Reddit, one of Y Combinator’s most successful startups. When it was bought by Condé Nast in 2006, Ohanian was suddenly a multi-millionaire and one of Silicon Valley’s most revered founders, all by age 23. Since co-founding Reddit, Ohanian has founded several other startups and venture capital firms, including Breadpig, Hipmunk, Das Kapital Capital, and Initialized Capital. His wife, tennis superstar Serena Williams, also founded her own VC firm, Serena Ventures.&nbsp;</p>
<p><span>Steve Huffman, Reddit’s second co-founder, served as CEO of the company until 2009, then returned to the role in 2015. Although Huffman and Ohanian sold Reddit for $10 million to $20 million, Huffman later said that he regretted the decision, not realizing how popular the site would become. As of 2019, the company was worth $3 billion. Huffman went on to co-found Hipmunk, a travel search site, before returning to the startup that started it all.</span></p>
<p><span>Chris Slowe is still with Reddit as its CTO (and is a former CEO), but spent some years away from the company before returning in 2015. Slowe also worked for Hipmunk as chief scientist, citing the desire for change as his main reason for leaving Reddit.</span></p>
<p><span>Reddit’s fourth co-founder, Aaron Swartz, arrived late to the party when his own startup, Infogami, merged with the company. Later on, Swartz devoted his time to a number of social causes, helping launch the Progressive Change Campaign Committee to support online activism. He also founded the online group Demand Progress which led a campaign against the Stop Online Piracy Act in 2010.&nbsp;</span></p>
<p><span>In 2011, Swartz was arrested on breaking-and-entering charges on the MIT campus after illegally downloading academic articles from a university database. He was charged in federal court with two counts of wire fraud, among other charges, and faced 35 years in prison. Days after a rejected plea bargain and counter offer to minimize his sentence, Swartz was found dead in his Brooklyn apartment by apparent suicide. He was 26 years old.</span></p>
<h2><b>5. Emmett Shear<br></b><b><b>11. Justin Kan</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/justin_kan_emmett_shear.jpg/justin_kan_emmett_shear-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Kiko<br></b><b><b>Where are they now?<br></b></b><b><b>Shear: CEO, Twitch<br></b></b><b><b>Kan: CEO of shuttered startup Atrium</b></b></p>
<p><span>Justin Kan and Emmett Shear have found massive success since first signing up for Y Combinator’s first class. The founders sold their online calendar startup, Kiko, a year after graduating YC, when they realized the new Google Calendar would eclipse their own startup. Kan and Shear went on to found Justin.tv, a livestream site that Kan himself used to document his daily life for eight months. The two then founded livestream gaming site Twitch as a spin-off of Justin.tv, which has grown into a $15 billion business.&nbsp;</span></p>
<h2><span>8. Philip Yuen</span></h2>
<h3><strong><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/philip_yuen-2.jpg/philip_yuen-2-700x420.jpg" width="700"><span></span></strong></h3>
<h3><strong>Founder, TextPayMe<br>Where is he now?<br>CEO, Aurabeat Technology</strong></h3>
<h2><b><b>13. Mikhail Ledvich</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/mikhail_ledvich-2.jpg/mikhail_ledvich-2-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Clickfacts<br></b><b>Where is he now?<br></b><b></b><strong>VP, Senior Digital Product Consultant, Bank of America</strong></p>
<p><span>Clickfacts, one of the lesser known startups to come out of Y Combinator, was a malware software solutions company. After YC, its co-founders continued running their startup until its demise sometime after 2012. Although it didn’t generate much buzz while it was up and running, Clickfacts became the longest running startup from YC’s First Batch not to be acquired. Mikhail Ledvich, who was also a product architect at Clickfacts, today works for Bank of America as a VP and senior digital product consultant.</span></p>
<h2><b>14. Sam Altman<br></b><b><b>Not pictured: Nick Sivo&nbsp;</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/sam_altman_nick_sivo.jpg/sam_altman_nick_sivo-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Loopt<br></b><b>Where are they now?<br></b><b>Altman: CEO, OpenAI<br></b><b>Sivo: Runs YC Hacker News</b></p>
<p><span>After Loopt failed to gain traction in the years following its run with Y Combinator, Sam Altman and Nick Sivo sold their startup in 2012. Since then, Altman has kept close ties with YC, first becoming a part-time partner, then president of the startup accelerator in 2014. Altman is also CEO of OpenAI, an artificial intelligence research startup he co-founded with Elon Musk. Nick Sivo has also spent his post-Loopt years at Y Combinator, maintaining their Hacker News site, though he’s largely stayed out of the public eye.</span></p>
<h2><b><b>15. Jesse Tov</b></b></h2>
<p><b><b><img alt="" height="420" src="https://static.media.thinknum.com/media/uploads/.thumbnails/jesse_tov-2.jpg/jesse_tov-2-700x420.jpg" width="700"><span></span></b></b></p>
<p><b>Founder, Simmery Axe<br></b><b>Where is he now?<br></b><b></b><strong>Computer Science Professor at Northwestern University</strong></p>
<p><span>Like some of the other startups to come from Y Combinator’s First Batch, Simmary Axe shut down not long after the summer program ended. Its founder, Jesse Tov, hasn’t spent much time as an entrepreneur since, trading the startup life for academia. He now teaches computer science at Northwestern University. Before teaching, Tov spent time with the U.S. Navy Fleet Numerical Meteorology and Oceanography Center.</span></p>
<h2><b>1. Jessica Livingston<br></b><b>16. <b>Paul Graham</b></b></h2>
<p><b><b><img alt="" height="393" src="https://static.media.thinknum.com/media/uploads/.thumbnails/jessica-livingston-and-paul-graham.jpg/jessica-livingston-and-paul-graham-700x393.jpg" width="700"><span></span></b></b></p>
<p><b>Founders, Y Combinator<br></b><b>Where are they now?<br></b><b>Both Graham and Livingston still run Y Combinator.</b></p>
<p><span>As for Paul Graham and Jessica Livingston, the husband and wife duo&nbsp;have ceased running the startup accelerator day to day, and now have&nbsp;a full-time staff. Graham, who stepped down in 2014, has been called a “startup guru” for the major companies&nbsp;that have come out of YC. In recent years, Graham has authored numerous essays on startups and company growth, becoming one of the greatest minds behind Silicon Valley in the process.&nbsp;</span></p>
<p><span>Livingston also had a hands-on role in the early days of Y Combinator. Before getting married in 2008, Graham and Livingston were dating while running YC, and according to Graham, the program felt like a family. Today, Livingston is on sabbatical, but lives with Graham and their two children in England.</span></p>
<p><em>Note: the names of&nbsp;founders 7, 9, and 12 aren't known, and their startups aren't listed on the <a href="https://www.ycombinator.com/companies/?batch=S05">Y Combinator page</a> for the First Batch.</em></p>
      

      

      



    </section><!-- .article-body -->

    
  </div></div>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/y-combinator-where-are-they-now-first-batch-reddit-twitch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779621</guid>
            <pubDate>Thu, 14 Jan 2021 17:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expose a Rust Library to Other Languages (Esp. C++)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25779349">thread link</a>) | @ogoffart
<br/>
January 14, 2021 | https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html | <a href="https://web.archive.org/web/*/https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        
    <section>
        <div>

    
    <h5>Posted on January 13, 2021 by Olivier Goffart and Simon Hausmann</h5>
    
  <p>
    With <a href="https://sixtyfps.io/">SixtyFPS</a>, we are creating a GUI toolkit. We chose
    Rust as the implementation language for our runtime library, and we want to make the same library usable from different
    programming languages. We believe programmers in all languages need to build GUIs - powered by the same runtime library.
    Rust, with its Foreign Function Interface (FFI) is an excellent choice.<br> In
    this article we look at how to expose an idiomatic C++ API from our Rust library.
  </p>

<h3 id="the-challenge">The Challenge</h3>

    <p>Initially we chose to start with support for three languages:</p>
    <ul>
        <li><b>Rust</b>: Because it's our implementation language.</li>
        <li><b>C++</b>: It's a low level language that we're familiar with, and is still one of the most established languages
            in the embedded device space.</li>
        <li><b>JavaScript / TypeScript</b>: Because it's a very popular dynamic language.</li>
    </ul>


    <p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/diagrams.png"></p><p>The Rust library (also known as a crate) is split into two parts, the shared implementation crate and a thin idiomatic
        API crate.
    </p>
    <p>For JavaScript we use <a href="https://github.com/neon-bindings/neon">Neon</a> to expose an API. Neon enables us
        to conveniently write JavaScript APIs and create an NPM package.</p>
    <p>The C++ part is a bit more challenging.</p>

<h3 id="expose-idiomatic-cpp-api-through-ffi">Expose an Idiomatic C++ API through Rust FFI</h3>

    <p>We decided to keep the C++ API only in the header files. This is because, unlike with Rust, there's
        no widely adopted C++ equivalent of Cargo, to help with downloading and building dependencies. If we want to ship
        binaries, then we have to maintain ABI compatibility, which is difficult in C++.<br> This way, we can also keep the
        C++ binding as lightweight as possible: for performance and memory footprint.
    </p>
    
    <p>Rust cannot expose a C++ API: structures can only be exported using a C representation (<code>#[repr(C)]</code>) and
        <code>extern "C"</code> functions. This means that we cannot expose Rust features like traits, generics, or
        destructors even if they have a C++ equivalent.
     </p>
     
    <p>The Rust ecosystem provides a few helper crates to make the job easier:</p>
     <ul>
        <li><a href="https://github.com/eqrion/cbindgen"><b>cbindgen</b></a>: This helper crate automatically generates C/C++
            header files based on the <code>repr(C)</code> structure and the <code>extern "C"</code> functions. We use
            cbindgen to generate internal header files only. It's very helpful to avoid manually writing some unsafe error-prone
            boilerplate. 
        </li>
        <li><a href="https://github.com/mystor/rust-cpp">The <b>cpp</b> crate</a>: This
            helper crate is useful when calling C++ libraries from Rust, and we make use of that. However it is not suitable for
            exposing a C++ API from Rust. (Note: Olivier Goffart happens to be the maintainer.)
        </li>
                
        <li><a href="https://cxx.rs/">The <b>cxx</b> crate</a>: This would be a safer way than cbindgen to ensure that the
            interface between C++ and Rust is correct. While it could be useful, cbindgen already get us a long way. So
            we don't use it for now.
        </li>
    </ul>

<p>To build the correct shared library we use Cargo. The resulting library exports C mangled symbols. We ship
    a set of C++ header files that provide the C++ API and use the C functions behind the scenes. For convenience,
    we provide a CMake integration that ties together the library linkage and includes path setup. </p>

<h3 id="slices-vectors-strings">Slices, Vectors, and Strings</h3>

    <p>
    In FFI, passing a basic integer works out of the box. But what about more complex data types, like a 
    Rust slice or a string? Well, most classes like Rust's String, Vec, or slices are not <code>#[repr(C)]</code>,
    so we can't use them directly. While we could use these classes with an indirection, every simple call may need to go
    through a non-inline function boundary. So we would need to convert types, which means re-allocating memory.</p>
    <p>So instead of sharing code, we implemented data structures using <code>#[repr(C)]</code> and a stable ABI, so
        that they can be accessed directly from C++ and Rust, or any low-level language.</p>

   <p>For the slice we create a structure that holds a pointer and a size:</p>

<pre><code>#[repr(C)]
pub struct Slice&lt;'a, T&gt; {
    ptr: NonNull&lt;T&gt;,
    len: usize,
    phantom: PhantomData&lt;&amp;'a [T]&gt;,
}
</code></pre>

<p><code>Slice&lt;'a, T&gt;</code> can be dereferenced to <code>&amp;'a [T]</code>.
    In C++, cbindgen generates the following snippet:


</p><pre><code>template&lt;typename T&gt;
struct Slice {
    T *ptr;
    uintptr_t len;
};
</code></pre>

<p>We tell cbindgen to generate that code in a <code>cbindgen_private</code> namespace, and we wrap it an interface
similar to <code>std::span</code>.</p>

<p>We use strings and vectors to pass data between the engine and the user's code. This results in
    shared ownership where we want to avoid unnecessary copying of data. Our API is property based
    with setters and getters, therefore we implement shared ownership through
    <a href="https://en.wikipedia.org/wiki/Copy-on-write"></a>Implicit sharing / Copy-on-write. </p>

<p><img src="https://sixtyfps.io/blog/expose-rust-library-to-other-languages/sharedvector.png"></p><pre><code>#[repr(C)]
struct SharedVectorHeader {
    refcount: atomic::AtomicIsize,
    size: usize,
    capacity: usize,
}

#[repr(C)]
pub struct SharedVector&lt;T&gt; {
    inner: NonNull&lt;SharedVectorInner&lt;T&gt;&gt;,
}


/// These functions are called from the C++ constructor
/// and destructor
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_allocate(
    size: usize, align: usize) -&gt; *mut u8 { /*...*/ }
#[no_mangle]
pub unsafe extern "C" fn sixtyfps_shared_vector_free(
    ptr: *mut u8, size: usize, align: usize) { /*...*/ }
}
</code></pre>

<p>In Rust, the <code>impl Clone</code> and <code>impl Drop</code> make sure to increment
and decrement the atomic reference count and call the destructors. Similarly, in C++, we implement
copy constructor and destructor for the same purpose. Note that we still need to call the Rust
allocator function via the exposed C interface.</p>

<p>Now we can write a wrapper in C++:
(<a href="https://github.com/sixtyfpsui/sixtyfps/blob/master/api/sixtyfps-cpp/include/sixtyfps_sharedvector.h">full file</a>)
</p>

<pre><code>template&lt;typename T&gt; struct SharedVector {
  SharedVector() : inner(nullptr) {}

  SharedVector(const SharedVector &amp;other)
    : inner(other.inner)
  { if (inner) ++inner-&gt;refcount; }

  ~SharedVector() {
     if (inner &amp;&amp; (--inner-&gt;refcount) == 0) {
        for (auto it = begin(); it &lt; end(); ++it)
            it-&gt;~T();
        cbindgen_private::sixtyfps_shared_vector_free(
            reinterpret_cast&lt;uint8_t *&gt;(inner),
            sizeof(SharedVectorHeader)
                + inner-&gt;capacity * sizeof(T),
            alignof(SharedVectorHeader));
     }
  }
  SharedVector &amp;operator=(const SharedVector &amp;other)
  { /*...*/ }

  const T *begin() const { /* ... */ }
  const T *end() const { /* ... */ }
  void push_back(const T &amp;value) { /* ... */ }
  // ... more vector-like API

private:
  // (SharedVectorHeader is generated by cbindgen)
  cbindgen_private::SharedVectorHeader *inner;
};
</code></pre>


    <p>Right now these types, such as <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a>, are within the internal <code>sixtyfps-corelib</code>
        crate, and re-exported for Rust users through the public <code>sixtyfps</code> crate.  If there is demand for it, we may consider moving them into a
        smaller public crate with its own release schedule.</p>


<h3 id="destructors">Destructors</h3>

    <p>It's important to note that <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedvector">SharedVector</a> and
        <a href="https://sixtyfps.io/docs/rust/sixtyfps/struct.sharedstring">SharedString</a> have destructors in C++.
        We can't pass instances by value in <code>extern "C"</code> functions, because the calling conventions are different
        for arguments or return types with C++ destructors; not supported by C. Therefore we can only pass them by pointer
        or reference.
    </p>

    <p>If we want to add a C++ destructor, constructor, or any member functions to types directly exported by cbindgen to our public API, 
        we use 
        <code><a href="https://docs.rs/cbindgen/0.16.0/cbindgen/struct.ExportConfig.html">cbindgen::ExportConfig</a>::body</code>:</p>

<pre><code>cbindgen_config.export.body.insert(
    "MyStruct".to_owned(),
    "    inline MyStruct(); inline ~MyStruct();".to_owned()
  );
</code></pre>

    <p>
    Then we implement <code>MyStruct::MyStruct</code> and <code>MyStruct::~MyStruct</code> in a manually
    written header file, by either doing the memory management directly or calling C helper functions
    implemented in Rust.</p>
     <p>It's important to keep in mind that anything allocated from Rust needs to be freed by Rust. 
    The same applies to allocations in C++: they might not share the same allocator.
    </p>

<h3 id="dynamic-dispatch">Dynamic Dispatch (virtual table) Across the Language Barrier</h3>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Bon_toutou.png/186px-Bon_toutou.png"></p><p>
    Let's start with the classic example of dynamic dispatch in Rust:</p>
<pre><code>pub trait Animal {
  fn speak(&amp;self, loudness: i32) -&gt; String;
}
struct Dog { name: String }
impl Animal for Dog {
  fn speak(&amp;self, loudness: i32) -&gt; String
  { "Waf!".into() }
}
#[no_mangle]
pub extern "C" fn do_something_with(
  animal: &amp;dyn Animal
) {
  println!("{}", animal.speak(1));
}
</code></pre>

<p>Unfortunately the above code does not work. How could we implement a class <code>Cat</code>
in C++ and call the <code>do_something_with</code> function? What if we wanted to implement
<code>do_something_with</code> in C++? The problem is that trait objects (<code>&amp;dyn</code>) are not
valid in FFI - their binary representation is not guaranteed to be stable. If we try to compile the above code,
we get this warning:</p>

<pre><code>warning: `extern` fn uses type `dyn Animal`, which is not FFI-safe
  | extern "C" fn do_something_with(animal: &amp;dyn Animal)
  |                                         ^^^^^^^^^^^ not FFI-safe
  = note: `#[warn(improper_ctypes_definitions)]` on by default
  = note: trait objects have no C equivalent</code></pre>

  <!--https://doc.rust-lang.org/reference/types/trait-object.html-->
<p>Internally, <a href="https://brson.github.io/rust-anthology/1/all-about-trait-objects.html">we know</a> that
a trait object is composed of a pointer to the instance, and a pointer to a virtual table containing
pointers to functions. The layout of this trait object (which pointer comes first) and the layout of the virtual
table is an implementation detail of Rust. So we decided to re-implement them to work accross FFI. Instead of
writing a <code>trait Animal</code>, we write a virtual table by hand:</p>

<pre><code>#[repr(C)]
pub struct AnimalVTable {
    speak: extern "C" fn speak(
        VRef&lt;AnimalVTable&gt;, i32, &amp; mut SharedString);
}
</code></pre>
<p>In this case, our virtual table has only one function. It is <code>#[repr(C)]</code> so that
cbindgen can generate a structure that the C++ code can access. Since we can't use <code>String</code>
we changed the return type to <code>SharedString</code>. We also pass the parameter by mutable reference instead
of just returning it, because it is not allowed to return a type that has a destructor.<br>
Instead of passing a trait object, our functions receive a pointer to the virtual table and
a …</p></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html">https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</a></em></p>]]>
            </description>
            <link>https://sixtyfps.io/blog/expose-rust-library-to-other-languages.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779349</guid>
            <pubDate>Thu, 14 Jan 2021 17:36:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CMake and the Future of C++ Package Management]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25779120">thread link</a>) | @ibobev
<br/>
January 14, 2021 | http://ibob.github.io/blog/2020/01/13/cmake-package-management/ | <a href="https://web.archive.org/web/*/http://ibob.github.io/blog/2020/01/13/cmake-package-management/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<nav>
<ul>
    <li><a href="http://ibob.github.io/blog/">Blog home</a></li>
    <li><a href="http://ibob.github.io/blog/tags/">Tags</a></li>
    <li>
    <a href="http://ibob.github.io/feed.xml" title="iboB blog feed" target="_blank">
        
        <span>RSS Feed</span>
    </a>
    </li>
</ul>
</nav>
<section>
  
  <p>Published on Jan 13, 2020.
    </p>
  <p><em>Well, at least according to me</em></p>

<p>I recently encountered a CMake feature which I wasn’t aware of. It’s <a href="https://cmake.org/cmake/help/latest/module/FetchContent.html">FetchContent</a>. I’m sure this is not news to most people since it was added in CMake 3.14<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> and that’s been around since February of 2019, so two years now, but this feature is a revelation.</p>

<p>It can… no, it should… no, it <em>must</em> become the stepping stone for future of C and C++ package managers.</p>

<p><em>… after an issue with it is resolved, which I will talk about furhter down in the post</em></p>

<h2 id="so-what-is-fetchcontent">So, what is FetchContent?</h2>

<p>It’s pretty straight forward, actually. By using two CMake functions: <code>FetchContent_Declare</code> and <code>FetchContent_MakeAvailable</code><sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> users can declare a named content item which can then be… well… fetched <em>in configure time</em>. The key here is, as opposed to <code>file(DOWNLOAD ...)</code>, this allows three important things:</p>

<ul>
  <li>Define the means by which the content is produced (not just source, but also types of sources)</li>
  <li>Have an identifiable name for the content</li>
  <li>Maintain the coherency of the content in a well-defined manner</li>
</ul>

<p>Here’s an example directly from the CMake docs:</p>

<div><div><pre><code><span>include</span><span>(</span>FetchContent<span>)</span>
<span>FetchContent_Declare</span><span>(</span>
  googletest
  GIT_REPOSITORY https://github.com/google/googletest.git
  GIT_TAG        release-1.8.0
<span>)</span>
<span>FetchContent_Declare</span><span>(</span>
  Catch2
  GIT_REPOSITORY https://github.com/catchorg/Catch2.git
  GIT_TAG        v2.5.0
<span>)</span>

<span># After the following call, the CMake targets defined by googletest and</span>
<span># Catch2 will be defined and available to the rest of the build</span>
<span>FetchContent_MakeAvailable</span><span>(</span>googletest Catch2<span>)</span>
</code></pre></div></div>

<p>Ha! <code>GIT_REPOSITORY</code>! See? See? This lets us use CMake for package management.</p>

<h2 id="but-what-about-my-favorite-package-manager">But what about My-Favorite-Package-Manager™?</h2>

<p>I get it. Conan, vcpkg and the many<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> others that exist are great, but they are external. Of course I’ve experimented with the popular C++ package managers, but I’ve been reluctant to actually start using one for my projects. They may have CMake integrations but they are not triggered by CMake. They try — and succeed — to be more than CMake. The thing is that, like it or not, CMake is, or at least getting really close to being, the de-facto standard build system for C++<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>. CMake is terrible in many ways, but it has proven to be the best we’ve have<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>So what do we get by bundling the package manager with the build system?</p>

<p><a href="https://en.wikipedia.org/wiki/Nix_package_manager">Nix</a> (which is awesome) or <a href="https://doc.rust-lang.org/cargo/guide/">Rust’s Cargo</a></p>

<h3 id="packages-from-source">Packages from source</h3>

<p>Oh, this package has <code>CMakeLists.txt</code>? You don’t need to download a binary when you can just fetch it and <code>add_subdirectory</code>… it<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>. It will inherit everything you need from your project.</p>

<h3 id="only-the-packages-we-need">Only the packages we need</h3>

<p>Sure, you can define different packages depending on platform, <a href="https://vcpkg.readthedocs.io/en/latest/users/triplets/">triplet</a>, and other configurations from other package managers, but you’re using their language. And then you have to either reimplement the same configuration analysis in you CMake files, or use some exports from those package managers, which is not always easy. If your package manager is within CMake, you already, inevitably, have all the tools to configure your build. The information for <a href="https://cmake.org/cmake/help/v3.3/variable/CMAKE_LANG_COMPILER.html">the compiler</a>, the <a href="https://cmake.org/cmake/help/latest/variable/CMAKE_CXX_STANDARD.html">standard</a>, the <a href="https://cmake.org/cmake/help/latest/variable/CMAKE_SYSTEM_NAME.html">target platform</a>, the <a href="https://cmake.org/cmake/help/latest/variable/CMAKE_SYSTEM_PROCESSOR.html">architecture</a>, the <a href="https://cmake.org/cmake/help/latest/variable/BUILD_SHARED_LIBS.html">linkage</a>, and <a href="https://cmake.org/cmake/help/latest/manual/cmake-toolchains.7.html">everything else</a> is already there.</p>

<h3 id="single-command-configuration">Single command configuration</h3>

<p><code>$ cmake .</code></p>

<p>…and everything works, everything is up to date, and everything is there. You are ready to build.</p>

<h2 id="can-i-use-fetchcontent-now">Can I use FetchContent now?</h2>

<p>Sort of.</p>

<p>Of course you can use the raw calls, even though they are not yet a package manager. <a href="https://github.com/adobe/lagrange/tree/72f9a5447b6803245d43a37a18b76e59c16fbda8/cmake/recipes/external">Adobe do exactly that</a>.</p>

<p>And, though the feature has been around for some time, I’m only aware of a single package manager which is built with it: <a href="https://github.com/TheLartians/CPM.cmake">CPM</a>.</p>

<p>Now, CPM is awesome and I’ve started using it in my personal projects. Everything new I make uses CPM and I’ve migrated some old stuff, too. However it’s not a mature and complete package manager. It can’t error on package version inconsistencies (though it can detect them) and it’s not built to handle binary packages. Source only. That, however, might be the thing you need. It is enough for most of my needs. I wholeheartedly recommend it for personal and/or small projects.</p>

<p>But!</p>

<p>There is a huge problem. Not with CPM, but with FetchContent itself. FetchContent can’t be <strong>the</strong> API package managers are built upon today.</p>

<p>This problem is performance. FetchContent is just too slow to be used for a serious load. It’s not an unfixable problem, but as far as I understand the issue, it will most likely have to be reimplemented. Here’s a table with me experimentig on different machines containing roughly<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup> how much time it takes to run FetchContent per content item, or package. <a href="https://github.com/iboB/cmake-fetch-content-perf/blob/82ee13918550f18bbf22bd3bf38c721a7de9fb80/CMakeLists.txt">Here’s the CMakeLists.txt</a> I used. Note that these times are not from fetching the packages. They are from a “noop” run. One which identifies that everything is up to date, and does nothing.</p>

<table>
  <thead>
    <tr>
      <th>OS</th>
      <th>CMake Version</th>
      <th>Generator</th>
      <th>Machine</th>
      <th>~ ms per item</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ubuntu 20.04</td>
      <td>3.16.3</td>
      <td>Unix Makefiles</td>
      <td>ThreadRipper, SSD</td>
      <td>200</td>
    </tr>
    <tr>
      <td>Arch Linux</td>
      <td>3.19.2</td>
      <td>Unix Makefiles</td>
      <td>8 core @ 2.4 GHz, HDD</td>
      <td>800</td>
    </tr>
    <tr>
      <td>Windows 10</td>
      <td>3.19.2</td>
      <td>Visual Studio 2019</td>
      <td>ThreadRipper, SSD</td>
      <td>1200</td>
    </tr>
    <tr>
      <td>Windows 10</td>
      <td>3.19.2</td>
      <td>MinGW Makefiles</td>
      <td>ThreadRipper, SSD</td>
      <td>1200</td>
    </tr>
    <tr>
      <td>Windows 10</td>
      <td>3.16.3</td>
      <td>MinGW Makefiles</td>
      <td>6 core @ 3 GHz, SSD</td>
      <td>1500</td>
    </tr>
  </tbody>
</table>

<p>That’s at <em>configure time</em>, so every time the CMake scripts are touched, it will get executed. As you can see even the best time of roughly 200 ms per item is pretty bad, but the Windows times of over 1 second are abysmal. It’s simply prohibitive for a project with hundreds or even tens of dependencies to spend 1 second per dependency only to confirm that it’s up to date.</p>

<p>I opened <a href="https://gitlab.kitware.com/cmake/cmake/-/issues/21703">an issue on CMake’s tracker</a><sup id="fnref:8" role="doc-noteref"><a href="#fn:8">8</a></sup> about that, and hopefully it will get addressed in some way. I even have some ideas of how this can be addressed from the outside, just with CMake user code, but I hope it won’t come to this.</p>

<p>I truly believe that this is the future of C++ package management. If the preformance issue is fixed (or worked around), I think in several years C++ package management will be based on FetchContent. Whether CPM will become <em>the</em> new de-facto standard or some other not-yet-written software, I can’t tell, but this is it! I can feel it!</p>

<hr>



</section>







  
  



  

</div></div>]]>
            </description>
            <link>http://ibob.github.io/blog/2020/01/13/cmake-package-management/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25779120</guid>
            <pubDate>Thu, 14 Jan 2021 17:20:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. jobless numbers surge as worsening Covid-19 pandemic hurts businesses]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25778289">thread link</a>) | @heyheyheysome
<br/>
January 14, 2021 | https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The number of Americans filing first-time applications for unemployment benefits surged last week, confirming a weakening in labour market conditions as a worsening COVID-19 pandemic disrupts operations at restaurants and other businesses.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5872837.1610635730!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/usa-smallbusiness-ppp.JPG"></p></div><figcaption>A woman walks past a business that is closing in New York City in August. Initial claims for state unemployment benefits totalled a seasonally adjusted 965,000 for the week ended Jan. 9, compared to 784,000 in the prior week, the U.S. Labour Department said on Thursday.<!-- --> <!-- -->(Carlo Allegri/Reuters)</figcaption></figure><p><span><p>The number of Americans filing first-time applications for unemployment benefits surged last week, confirming a weakening in labour market conditions as a worsening COVID-19 pandemic disrupts operations at restaurants and other businesses.</p>  <p>Initial claims for state unemployment benefits totalled a seasonally adjusted 965,000 for the week ended Jan. 9, compared to 784,000 in the prior week, the U.S. Labour Department said on Thursday. Economists polled by Reuters had forecast 795,000 applications in the latest week.</p>  <p>It's the highest number since late August.&nbsp;Applications declined over the summer but have been stuck above 700,000 since September.</p>  <p>Claims were also likely lifted by re-applications for benefits following the government's renewal of a $300 US unemployment supplement until March 14 as part of nearly $900 billion in additional relief approved at the end of December.</p>    <p>Government-funded programs for the self-employed, gig workers and others who do not qualify for the state unemployment programs as well as those who have exhausted their benefits were also extended.</p>  <p>Authorities in many states have banned indoor dining to slow the spread of the coronavirus. The economy shed jobs in December for the first time in eight months.</p>  <p>The Federal Reserve's Beige Book report of anecdotal information on business activity collected from contacts nationwide in early January showed on Wednesday that "contacts in the leisure and hospitality sectors reported renewed employment cuts due to stricter containment measures."</p>  <p>The central bank also noted that the resurgence in the coronavirus was causing staff shortages in the manufacturing, construction and transportation&nbsp;sectors.</p>  <h2>Most infections of any country</h2>  <p>The virus has infected more than 22.5 million people in the United States and killed over 376,188, the most of any country.&nbsp;More than 4,300 deaths were reported Tuesday, a&nbsp;record high.</p>  <p>Though jobless claims have dropped from a record 6.867 million in March, they remain above their 665,000 peak during the 2007-09 Great Recession. Economists say it could take several years for the labour market to recover from the pandemic.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-usa-florida.JPG 300w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-usa-florida.JPG 460w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-usa-florida.JPG 620w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-usa-florida.JPG 780w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-usa-florida.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-usa-florida.JPG"></p></div><figcaption>Hundreds wait in line to receive the COVID-19 vaccine in Fort Myers, Fla., in late December. Economists are hopeful the economy will turn around in late 2021.<!-- --> <!-- -->(Andrew West/The News-Press/USA Today Network/Reuters)</figcaption></figure></span></p>  <p>"While prospects for the economy later in 2021 are upbeat, the labour market recovery has taken a step backward," said Nancy Vanden Houten, an economist at Oxford Economics, "and we expect claims to remain elevated, with the risk that they rise from last week's levels."</p>  <p>Last week's applications for aid might have been elevated in part because state employment offices had been closed over the holidays, requiring some jobless people to wait until last week to apply.&nbsp;</p>  <h2>5.3 million Americans receiving jobless benefits</h2>  <p>In addition to last week's first-time applications for unemployment aid, the government said Thursday that 5.3 million Americans are continuing to receive state jobless benefits, up from 5.1 million in the previous week. It suggests that fewer people who are out of work are finding jobs.</p>  <p>About 11.6 million people received jobless aid from two federal programs in the week that ended Dec. 26, the latest period for which data is available. One of those programs provides extended benefits to people who have exhausted their state aid. The other supplies benefits to self-employed and contract workers.</p>  <p>Those two programs had expired near the end of December. They were belatedly renewed, through mid-March, in the $900-billion rescue aid package that Congress approved and President Donald Trump signed into law. That legislation also included $600 relief cheques&nbsp;for most adults and a supplemental unemployment benefit payment of $300 a week. Congressional Democrats favour boosting the cheques&nbsp;to $2,000 and extending federal aid beyond March, as does president-elect Joe Biden.</p>    <p>The U.S. job market's weakness was made painfully clear in the December employment report that the government issued last week. Employers shed jobs for the first time since April as the pandemic tightened its grip on consumers and businesses.</p>  <p>The figures also depicted a sharply uneven job market: The losses last month were concentrated among restaurants, bars, hotels and entertainment venues. Educational services, mostly colleges and universities, also cut workers in December. So did film and music studios.</p>  <p>Most other large industries, though, reported job gains. Many economists had expected last spring that job losses would spread to more industries. Though all sectors of the economy initially laid off workers, most of them have avoided deep job cuts. Manufacturing, construction, and professional services like engineering and architecture, for example, all added jobs in December.</p>  <p>At the same time, many companies seem reluctant to sharply ramp up hiring. A government report Tuesday showed that employers advertised fewer open jobs in November than in October. The decline, while small, was widespread across most industries.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778289</guid>
            <pubDate>Thu, 14 Jan 2021 16:28:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing the Python GIL]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25777423">thread link</a>) | @mariuz
<br/>
January 14, 2021 | https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html | <a href="https://web.archive.org/web/*/https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>

<p>There are plenty of articles explaining why the Python GIL (The Global Interpreter Lock) exists<sup id="fnref-1"><a href="#fn-1">1</a></sup>, and why it is there. The TLDR version is: the GIL prevents multithreaded pure Python code from using multiple CPU cores.</p>
<p>However, in <a href="https://vaex.io/">Vaex</a> we execute most of the CPU intensive parts in C (C++) code, where we release the GIL. This is a common practice in high-performance Python libraries, where Python acts merely as a high-level glue.</p>
<p>However, the GIL needs to be released explicitly, and this is the responsibility of the programmer and might be forgotten, leading to suboptimal use of your machine.</p>
<p>I recently had this issue in <a href="https://github.com/vaexio/vaex/pull/1114">Vaex</a> where I simply forgot to release the GIL and found a similar issue in <a href="https://github.com/apache/arrow/pull/7756">Apache Arrow</a><sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
<p>Also, when running on 64 cores, I sometimes see a performance in Vaex that I am not happy with. It might be using 4000% CPU, instead of 6400% CPU, which is something I am not happy with. Instead of blindly pulling some levers to inspect the effect, I want to understand what is happening, and if the GIL is the problem, why, and where is it holding Vaex down.</p>


</div>
</div>
</div><div>
<div>
<div>

<p>I'm planning to write a series of articles explaining some tools and techniques available for profiling/tracing Python together with native extensions, and how these tools can be glued together, to analyze and visualize what Python is doing, and when the GIL it taken or dropped.</p>
<p>I hope this leads to improvement of tracing, profiling, and other performance tooling in the Python ecosystem, and the performance of the whole Python ecosystem.</p>

<h2 id="Linux">
Linux<a href="#Linux"> </a>
</h2>
<p>Get access to a Linux machine, and make sure you have root privileges (sudo is fine), or ask your sysadmin to execute some of these commands for you. For the rest of the document, we only run as user.</p>
<h2 id="Perf">
Perf<a href="#Perf"> </a>
</h2>
<p>Make sure you have perf installed, e.g. on Ubuntu:</p>

<pre><code>$ sudo yum install perf</code></pre>
<h2 id="Kernel-configuration">
Kernel configuration<a href="#Kernel-configuration"> </a>
</h2>
<p>To enable running it as a user:</p>

<pre><code># Enable users to run perf (use at own risk)
$ sudo sysctl kernel.perf_event_paranoid=-1

# Enable users to see schedule trace events:
$ sudo mount -o remount,mode=755 /sys/kernel/debug
$ sudo mount -o remount,mode=755 /sys/kernel/debug/tracing</code></pre>
<h2 id="Python-packages">
Python packages<a href="#Python-packages"> </a>
</h2>
<p>We will make use of <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> and <a href="https://github.com/maartenbreddels/per4m">per4m</a></p>

<pre><code>$ pip install "viztracer&gt;=0.11.2" "per4m&gt;=0.1,&lt;0.2"</code></pre>

</div>
</div>
</div><div>
<div>
<div>

<p>There is no way to get the GIL state in Python <sup id="fnref-3"><a href="#fn-3">1</a></sup> since there is no API for this. We can track it from the kernel, and the right tool for this under Linux is <strong>perf</strong>.</p>
<p>Using the linux perf tool (aka perf_events), we can listen to the state changes for processes/threads (we only care about sleeping and running), and log them. Although perf may look scary, it is a powerful tool. If you want to know a bit more about perf, I recommend reading <a href="https://jvns.ca/blog/2018/04/16/new-perf-zine/">Julia Evans' zine on perf</a> or <a href="http://www.brendangregg.com/perf.html">go through Brendan Gregg's website</a>.</p>
<p>To build our intuition, we will first run perf on a <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example0.py">very trivial program</a>:</p>


</div>
</div>
</div><div>
<div>
<div>
<p>We listen to just a few events to keep the noise down (note the use of wildcards):</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork \
        -e 'sched:sched_wak*' -- python -m per4m.example0
[ perf record: Woken up 2 times to write data ]
[ perf record: Captured and wrote 0,032 MB perf.data (33 samples) ]</code></pre>
<p>And use the <code>perf script</code> command to write human/parsable output.</p>

<pre><code>$ perf script
        :3040108 3040108 [032] 5563910.979408:                sched:sched_waking: comm=perf pid=3040114 prio=120 target_cpu=031
        :3040108 3040108 [032] 5563910.979431:                sched:sched_wakeup: comm=perf pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995616:                sched:sched_waking: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995618:                sched:sched_wakeup: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995621:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995622:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995624:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R+ ==&gt; next_comm=kworker/31:1 next_pid=2502104 next_prio=120
          python 3040114 [031] 5563911.003612:                sched:sched_waking: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.003614:                sched:sched_wakeup: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.083609:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083612:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083613:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R ==&gt; next_comm=ksoftirqd/31 next_pid=198 next_prio=120
          python 3040114 [031] 5563911.108984:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.109059:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.112250:          sched:sched_process_fork: comm=python pid=3040114 child_comm=python child_pid=3040116
          python 3040114 [031] 5563911.112260:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112262:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112273:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112418:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112450:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112473: sched:sched_wake_idle_without_ipi: cpu=31
         swapper     0 [031] 5563911.112476:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112485:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112485:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112489:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112496:                sched:sched_switch: prev_comm=python prev_pid=3040116 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/37 next_pid=0 next_prio=120
         swapper     0 [031] 5563911.112497:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
         swapper     0 [037] 5563912.113490:                sched:sched_waking: comm=python pid=3040116 prio=120 target_cpu=037
         swapper     0 [037] 5563912.113529:                sched:sched_wakeup: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040116 [037] 5563912.113595:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563912.113620:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
         swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></pre>

</div>
</div>
</div><div>
<div>
<div>
<p>Take a moment to digest the output. I can see a few things. Looking at the 4th column (time in seconds), we can see where the program slept (it skips 1 second). Here we see that we enter the sleeping state with a line like:</p>
<p><code>python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120</code></p>
<p>This means the kernel changed the state of the Python thread to <code>S</code> (=sleeping) state.</p>
<p>A full second later, we see it being woken up:</p>
<p><code>swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></p>
<p>Of course, you need to build some tooling around this, to really see what is happening. But one can imagine this output can be easily parsed and this is what <a href="https://github.com/maartenbreddels/per4m/">per4m</a> does. However, before we go there, I'd first like to visualize the flow of a slightly more advanced program using <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a>.</p>

</div>
</div>
</div><div>
<div>
<div>

<p><a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> is a Python tracer that can visualize what your program does in the browser. Let us run it on a slightly <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example1.py">more advanced example</a> to see what it looks like.</p>

</div>
</div>
</div><div>
<div>
<div>
<p>Running viztracer gives output like:</p>

<pre><code>$ viztracer -o example1.html --ignore_frozen -m per4m.example1
Loading finish                                        
Saving report to /home/maartenbreddels/github/maartenbreddels/per4m/example1.html ...
Dumping trace data to json, total entries: 94, estimated json file size: 11.0KiB
Generating HTML report
Report saved.</code></pre>
<p>And the HTML should render as:
<img src="https://www.maartenbreddels.com/images/copied_from_nb/per4m/example1.png" alt="image.png"></p>
<p>From this, it seems that <code>some_computation</code> seem to be executed in parallel (twice), while in fact, we know the GIL is preventing that. So what is really going on?</p>

</div>
</div>
</div><div>
<div>
<div>

<p>Let us run <code>perf</code> on this, similarly to what we did to example0.py. However, we add the argument <code>-k CLOCK_MONOTONIC</code> so that we use <a href="https://github.com/gaogaotiantian/viztracer/blob/3321ba4024afe5623f938a601d7f7db3b08f534d/src/viztracer/modules/snaptrace.c#L91">the same clock as VizTracer</a> and ask VizTracer to generate a JSON, instead of an HTML file:</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork -e 'sched:sched_wak*' \
   -k CLOCK_MONOTONIC  -- viztracer -o viztracer1.json --ignore_frozen -m per4m.example1</code></pre>
<p>Then …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</a></em></p>]]>
            </description>
            <link>https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25777423</guid>
            <pubDate>Thu, 14 Jan 2021 15:26:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Licensing changes to Elasticsearch and Kibana]]>
            </title>
            <description>
<![CDATA[
Score 266 | Comments 317 (<a href="https://news.ycombinator.com/item?id=25776657">thread link</a>) | @sl_
<br/>
January 14, 2021 | https://www.elastic.co/blog/licensing-change | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/licensing-change">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><h2>Upcoming licensing changes to Elasticsearch and Kibana</h2><p>We are moving our Apache 2.0-licensed source code in Elasticsearch and Kibana to be dual licensed under Server Side Public License (SSPL) and the Elastic License, giving users the choice of which license to apply. This license change ensures our community and customers have free and open access to use, modify, redistribute, and collaborate on the code. It also protects our continued investment in developing products that we distribute for free and in the open by restricting cloud service providers from offering Elasticsearch and Kibana as a service without contributing back. This will apply to all maintained branches of these two products and will take place before our upcoming 7.11 release. Our releases will continue to be under the Elastic License as they have been for the last three years.
</p><p>This change in source code licensing has <b>no impact on the overwhelming majority of our user community</b> who use our default distribution for free. It also has <b>no impact on our cloud customers or self-managed software customers</b>.</p><p>In recent years, the market has evolved, and the community has come to appreciate that open source companies need to better protect their software to continue to innovate and make the investments required. As companies continue the shift to SaaS offerings, some cloud service providers have taken open source products and provided them as a service without investing back into the community. Moving to the dual license strategy with <a href="https://www.mongodb.com/licensing/server-side-public-license">SSPL</a> or the Elastic License is a natural next step for us after opening our commercial code and creating a free tier, all under the Elastic License, nearly 3 years ago. It is similar to those made by many other open source companies over these years, including <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">MongoDB</a>, which developed the SSPL. The SSPL allows free and unrestricted use, as well as modification, with the simple requirement that if you provide the product as a service, you must also publicly release any modifications as well as the source code of your management layers  under SSPL.
</p><h2>Our open origins</h2><p>My personal journey with open source goes a long way back. In 2005, I open sourced my first project, Compass, to provide a Java framework on top of Apache Lucene while I was building a recipe app for my wife. In the following five years, I invested many weekends and nights working on it, from writing code to helping users with bugs, features, and questions.
</p><p>I had no idea what I was signing up for, especially with a day job “on the side,” but I fell in love with the opportunity to make such a positive impact — trying to build a great product, but more importantly, a great community around it, through the power of open source.
</p><p>In 2009, I decided to do it again, and started to write a brand new project called Elasticsearch. I spent many nights and weekends building it, and in 2010 open sourced it. I even quit my job and decided to dedicate my full attention to it. To be there for the users, through writing code, and engaging on GitHub, mailing lists, and IRC.
</p><p>And when we founded Elastic as a company in 2012, we brought the same spirit to our company. We invested heavily in our free and open products, and supported the rapid growth of our community of users. We expanded from just Elasticsearch to Kibana, Logstash, Beats, and now a complete set of solutions built into the Elastic Stack: Elastic Enterprise Search, Observability, and Security.
</p><p>We have matured the products, fostered vibrant communities around them, and focused on providing the greatest amount of value to our users. Today, we have hundreds of engineers who wake up every day and work to make our products even better. And we have hundreds of thousands of community members who engage with us and contribute to our shared success.
</p><p>I am proud of the company we built, and humbled by the level of trust that we have earned with our user base. This starts by being open and transparent, and continues with being true to our community and user base in our choices.
</p><h2>Free and open FTW</h2><p>Back in 2018, we <a href="https://www.elastic.co/blog/doubling-down-on-open">opened the code of our free and paid proprietary features</a> under the Elastic License, a source-available license, and we changed our default distribution to include all of our features, with all free features enabled by default.
</p><p>We did this for a few reasons. It allowed us to engage with our paying customers in the same way we engage with our community: in the open. It also allowed us to build free features that empower our users without providing those capabilities to companies that take our products and provide them as a service, like Amazon Elasticsearch Service, and profit from our open source software without contributing back.
</p><p>This approach was well received — today, over 90% of new downloads choose this distribution — and has allowed us to make so much of our work available for free while also building a successful company.
</p><p>The list of improvements under this new free and open, yet proprietary, license, is overwhelming. I am humbled by the amazing progress our team and community has made across all our products, so much so that I would love to share some of them:
</p><p>We've dramatically improved the speed, scalability, and reliability of Elasticsearch, with a new distributed consensus algorithm and significantly reduced memory usage, in addition to new data storage and compression approaches that have reduced the typical index size by nearly 40% while improving indexing and query throughput. We added new field types for geospatial analysis, and more efficient ways to store and search logs and perform fast, case-insensitive search on security data. In Kibana, we cut load time by 80% and eliminated whole-page refreshes thanks to a multiyear replatforming project, while at the same time introducing an intuitive drag-and-drop data visualization experience with Kibana Lens, key capabilities like dashboard drill-downs, and so much more.
</p><p>Over the last three years, we also built first-class experiences around our most common use cases. In the security area, we created a free and open SIEM right inside Kibana, with a powerful detection engine that supports simple rules as well as complex correlations via a new query language called EQL in Elasticsearch. We include hundreds of detection rules, which we develop publicly, in collaboration with our community. And we joined forces with Endgame, a leading endpoint security company, and have released powerful malware protection for free as part of the Elastic Agent, our unified, centrally managed observability and security agent for servers and endpoints, with more to come.
</p><p>In observability, the story is similar. We've built an entire observability suite right inside Kibana — from a live-tail logging UI to an intuitive infrastructure-level view of the key metrics and alerts across your hosts, pods, and containers. And we now have a fully featured APM product with open source data collectors and agents, supporting OpenTelemetry, real user monitoring (RUM), synthetic monitoring, and the recent addition of user experience monitoring.
</p><p>With Elastic Enterprise Search, we introduced App Search, a layer on top of Elasticsearch that simplifies building rich applications and provides powerful management interfaces for relevance tuning, as well as analytics on how it's being used. We also provide a free Workplace Search product that makes it easy to integrate and search the content sources that you use to run your life or company, like Google Workplace, Microsoft 365, Atlassian Jira and Confluence, and Salesforce.
</p><p>It is simply amazing that we've been able to build all of these capabilities and provide them for free to our community. It has been humbling to see the level of engagement and adoption around our products and how these new features have helped so many people and businesses succeed. And this was possible because the overwhelming majority of our community chose our default distribution under the Elastic License, where all these features are free and open.
</p><h2>Why change?</h2><p>As previously mentioned, over the last three years, the market has evolved and the community has come to appreciate that open source companies need to better protect their software in order to maintain a high level of investment and innovation. With the shift to SaaS as a delivery model, some cloud service providers have taken advantage of open source products by providing them as a service, without contributing back. This diverts funds that would have been reinvested into the product and hurts users and the community.
</p><p>Similar to our open source peers, we have lived this experience firsthand, from our trademarks being misused to outright attempts to splinter our community with “open” repackaging of our OSS products or even taking “inspiration” from our proprietary code. While each open source company has taken a slightly different approach to address this issue, they have generally modified their open source license in order to protect their investment in free software, while trying to preserve the principles of openness, transparency, and collaboration. Similarly, we are taking the natural next step of making a targeted change to how we license our source code. This change won't affect the vast majority of our users, but it will restrict cloud service providers from offering our software as a service.
</p><p>We expect that a few of our competitors will attempt to spread all kinds of FUD around this change. Let me be clear to any naysayers. We believe deeply in the principles of free and open products, and of transparency with the community. Our track record speaks to this commitment, and we will continue to build upon it.
</p><h2>The change</h2><p>Starting with the upcoming Elastic 7.11 release, we will be moving the Apache 2.0-licensed code of Elasticsearch and Kibana to be dual licensed under SSPL and the Elastic License, giving users the choice of which license to apply. SSPL is a source-available license created by MongoDB to embody the principles …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elastic.co/blog/licensing-change">https://www.elastic.co/blog/licensing-change</a></em></p>]]>
            </description>
            <link>https://www.elastic.co/blog/licensing-change</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776657</guid>
            <pubDate>Thu, 14 Jan 2021 14:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 years-ish of Elixir]]>
            </title>
            <description>
<![CDATA[
Score 395 | Comments 113 (<a href="https://news.ycombinator.com/item?id=25776525">thread link</a>) | @1_player
<br/>
January 14, 2021 | https://dashbit.co/blog/ten-years-ish-of-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/ten-years-ish-of-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> January 11th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/elixir">elixir</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/broadway">broadway</a>, <a href="https://dashbit.co/blog/tags/nerves">nerves</a>, <a href="https://dashbit.co/blog/tags/liveview">liveview</a>, <a href="https://dashbit.co/blog/tags/membrane">membrane</a>
  </li>
</ul>
<p>
This past weekend, on January 9th, we celebrated 10 years since <a href="https://github.com/elixir-lang/elixir/commit/337c3f2d569a42ebd5fcab6fef18c5e012f9be5b">the first commit to the Elixir repository</a>. While I personally don’t consider <a href="https://elixir-lang.org/">Elixir</a> to be 10 years old yet - the language that became what Elixir is today <a href="https://github.com/elixir-lang/elixir/commit/6052352b6281752b905b30eb5b08fac0f51f68cd">surfaced only 14 months later</a> - a decade is a mark to celebrate!</p>
<p>
The goal of this post is to focus on the current state of some projects in the ecosystem and then briefly highlight a few of the exciting efforts coming over the next months.</p>
<h2>
Recap: The language goals</h2>
<p>
When I started working on Elixir, I personally had the ambition of using it for building scalable and robust web applications. However, I didn’t want Elixir to be tied to the web. My goal was to design an <em>extensible</em> language with a diverse ecosystem. Elixir aims to be a general purpose language and allows developers to extend it to new domains.</p>
<p>
Given Elixir is built on top of Erlang and Erlang is used for networking and distributed systems, Elixir would naturally be a good fit in those domains too, as long as I didn’t screw things up. The Erlang VM is essential to everything we do in Elixir, which is why <em>compatibility</em> has become a language goal too.</p>
<p>
I also wanted the language to be <em>productive</em>, especially by focusing on the tooling. Learning a functional programming language is a new endeavor for most developers. Consequently their first experiences getting started with the language, setting up a new project, searching for documentation, and debugging should go as smoothly as possible.</p>
<p>
Extensibility, compatibility, and productivity are the goals we built the language upon.</p>
<h2>
Recap: Elixir in production</h2>
<p>
Last year we started <a href="https://elixir-lang.org/cases.html">a series of articles on companies using Elixir in production on the official website</a>. As of today, we have 7 production cases listed with more coming this year! Overall it is very exciting to see many different companies using a variety of business models and industries running Elixir in production.</p>
<p>
Companies like <a href="https://www.brex.com/">Brex</a> (<a href="https://elixir-lang.org/blog/2020/06/23/growing-with-elixir-at-brex/">case</a>), <a href="https://discord.com/">Discord</a> (<a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">case</a>), <a href="https://getdivvy.com/">Divvy</a>, <a href="https://www.podium.com/">Podium</a>, and <a href="https://salesloft.com/">SalesLoft</a> have reached <a href="https://en.wikipedia.org/wiki/Unicorn_(finance)">“unicorn status”</a> and rely heavily on Elixir. Startups like <a href="https://www.joinblvd.com/">Boulevard</a> (<a href="https://soundcloud.com/elixirtalk/episode-166-feat-sean-stavropoulos">podcast</a>), <a href="https://community.com/">Community</a>, <a href="https://duffel.com/">Duffel</a> (<a href="https://elixir-lang.org/blog/2020/12/10/integrating-travel-with-elixir-at-duffel/">case</a>), <a href="https://www.ockam.io/">Ockam</a>, <a href="https://www.mux.com/">Mux</a>, <a href="https://ramp.com/">Ramp</a>, <a href="https://remote.com/">Remote</a>, and <a href="https://www.v7labs.com/">V7</a> (<a href="https://elixir-lang.org/blog/2021/01/13/orchestrating-computer-vision-with-elixir/">case</a>) also use Elixir and have received funding in the last year or two. Elixir is also used within known brands and enterprises such as <a href="https://bleacherreport.com/">Bleacher Report</a>, <a href="https://www.change.org/">Change.org</a> (<a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">case</a>), <a href="https://heroku.com/">Heroku</a> (<a href="https://elixir-lang.org/blog/2020/09/24/paas-with-elixir-at-Heroku/">case</a>), <a href="https://www.pagerduty.com/">PagerDuty</a>, <a href="https://www.pepsico.com/">PepsiCo</a>, and <a href="https://www.therealreal.com/">TheRealReal</a>.</p>
<p>
There is also a special category of startups that run Elixir alonside an open source model, such as <a href="https://plausible.io/">Plausible Analytics</a>, <a href="https://app.supabase.io/">Supabase</a>, <a href="https://logflare.app/">Logflare</a> (<a href="https://runninginproduction.com/podcast/11-logflare-is-a-log-management-and-event-analytics-platform">podcast</a>), and <a href="https://hex.pm/">Hex.pm</a> (<a href="https://runninginproduction.com/podcast/19-hexpm-is-elixirs-official-package-manager">podcast</a>) itself. Still on the open source front, you will find projects like <a href="https://pleroma.social/">Pleroma</a> and <a href="https://changelog.com/">Changelog</a>. There also many small scale and hobby projects that use Elixir for a productive and joyful development experience.</p>
<h2>
Recap: Diverse ecosystem</h2>
<p>
Today, Elixir has a diverse ecosystem that works on a wide range of domains and industries. Let’s take a look at some examples.</p>
<h3>
Web</h3>
<p>
Most developers are familiar with using Elixir for web development thanks to <a href="https://phoenixframework.org/">the Phoenix web framework</a>. Phoenix gained traction in the ecosystem because it was the first to fully leverage the language and the platform for building real-time applications besides the usual MVC (Model-View-Controller) offering.</p>
<p>
It all started with Phoenix Channels, as a bi-directional communication between clients and servers, and Phoenix PubSub, which uses Erlang’s distributed compatibilities to broadcast messages across nodes. As far as I know, Phoenix was the first major web framework to provide a multi-node web real-time solution completely out-of-the-box. Regardless if you are using one node or ten nodes, everything just works, with minimal configuration and dependencies.</p>
<p>
Phoenix has matured a lot since its first stable release. Phoenix v1.2 included <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Phoenix Presence</a>, that allows developers to track which users, IoT devices, etc are connected to your cluster right now. No databases or external dependencies required! This is one of the problems that look deceptively simple at first, but once you outline all scalability, performance, and fault-tolerance requirements, it <a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/">becomes quite complex</a>. Luckily, Phoenix is running on a platform that excels at these problems, and I am not aware of any other framework that provides such a lean and elegant solution as part of its default stack.</p>
<p>
Most recently, <a href="https://github.com/phoenixframework/phoenix_live_view">Phoenix LiveView</a> was released and brought new ways to build rich, real-time user experiences with server-rendered HTML, inspiring developers to attempt similar solutions for other languages and frameworks. You can read the <a href="https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript">original announcement</a> or <a href="https://www.phoenixframework.org/blog/build-a-real-time-twitter-clone-in-15-minutes-with-live-view-and-phoenix-1-5">learn how to build a real-time Twitter clone in 15 minutes</a>. As part of the <em>Live</em> family, we have also announced <a href="https://twitter.com/josevalim/status/1250846714665357315">Phoenix LiveDashboard</a>, making monitoring and instrumentation a first-class citizen for Phoenix applications.</p>
<h3>
Embedded and IoT</h3>
<p>
While I always expected Elixir to shine for building web applications, I was taken by surprise when I heard about the <a href="https://www.nerves-project.org/">Nerves platform</a> for creating high-end embedded applications. However, once I learned their premise, it all made sense: writing embedded systems <em>is</em> complicated. Reasoning about failures is hard. So what if we could leverage the decades of lessons learnt by Erlang/OTP to design embedded applications? What if a fault on the Wi-Fi driver could be fixed by having a supervisor simply restart it? After all, the first major use of Erlang/OTP was in an embedded system, the Ericsson AXD301 ATM switch.</p>
<p>
Nerves brings the Elixir ecosystem and the battle-tested Erlang VM to edge computing, providing a rich developer experience using proven technology. Nerves started as a one step process for turning an Elixir project into a complete software image for common hardware devices. Today, Nerves is being used in production in industrial automation, machine learning, consumer electronics and more, with <a href="https://farm.bot/">Farmbot</a> (<a href="https://elixir-lang.org/blog/2020/08/20/embedded-elixir-at-farmbot/">case</a>) and <a href="https://www.rosepoint.com/">Rose Point Navigation</a> being two of the most notable examples.</p>
<p>
The Nerves team also created <a href="https://www.nerves-hub.org/">NervesHub</a>, a fully open-source device management system. Combining all these technologies makes Elixir a comprehensive language for building end-to-end IoT platforms.</p>
<h3>
Data ingestion and pipelines</h3>
<p>
Shortly after Elixir v1.0 was released, the Elixir Core Team and I started looking into abstractions for tackling data ingestions and data pipelines in Elixir. We ran through a couple designs until we eventually <a href="https://elixir-lang.org/blog/2016/07/14/announcing-genstage/">landed on GenStage</a>: a behaviour for exchanging data with back-pressure between Elixir processes and external systems. For an introduction, make sure to check out <a href="https://youtu.be/srtMWzyqdp8?t=242">my keynote introducing both GenStage and Flow</a>.</p>
<p>
Today, almost 5 years later, GenStage has been used by many industries and has become one of the factors driving Elixir adoption. For example, you can read how both <a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">Discord</a> and <a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">Change.org</a> have built systems on Elixir and GenStage that handle spikes and run at massive scale.</p>
<p>
However, GenStage was just the beginning. In 2019, <a href="https://www.youtube.com/watch?v=ZOExnT1PYjs">we announced Broadway</a>, which is a higher-level abstraction on top of GenStage that makes building data ingestion pipelines a breeze. We originally released with Amazon SQS support. Nowadays, RabbitMQ, Google Cloud PubSub, Apache Kafka, and other sources (known as producers in Broadway terms) are also available.</p>
<h3>
Audio/Video streaming</h3>
<p>
Since the Erlang VM was designed for scalable network processing, one can expect to also be an excellent platform for audio and video streaming. However, if you also wanted to process and transform those streams on the fly, the situation becomes much more complicated as you likely have to integrate with native code.</p>
<p>
Luckily, the tables have turned when Erlang/OTP 20 was released a couple years ago with the so-called Dirty NIFs. The Erlang VM always had the ability to invoke native code, but this native code could not run for long, as to not interfere with the preemptive features of the Erlang runtime. Dirty NIFs allow developers to tag native code either as IO or CPU bound, which runs on specific threads. Between ports (I/O based), NIFs, Dirty NIFs, and remote nodes, developers now have many options to interface with native code with different performance and reliability guarantees. That’s exactly the foundation the <a href="http://www.membraneframework.org/">Membrane Framework</a> builds on top of.</p>
<p>
Membrane was extracted from RadioKit, a startup aiming at disrupting the radio broadcasting industry. Originally it focused on processing and mixing audio. Later, <a href="https://www.swmansion.com/">Software Mansion</a> acquired the framework and provided stable funding and a solid team to help it grow into a full-scale framework. Currently, it allows developers to process, transmit, broadcast, and transform audio and videos streams on the fly. Whether you are building a Twitch clone, a VOD application or a video conferencing system, Membrane provides a growing set of high-level abstractions and pre-made modules so you don’t have to dive into idiosyncrasies of particular codecs, protocols, and formats. </p>
<h2>
Looking ahead: what is coming in 2021</h2>
<p>
The year of 2021 looks very exciting for the Erlang Ecosystem and the Elixir community. In this section, we are going to mention some of the things we expect to see in 2021.</p>
<h3>
Erlang/OTP 24 with JIT</h3>
<p>
In September 2020, <a href="https://github.com/erlang/otp/pull/2745">Lukas Larsson and the Erlang/OTP team</a> announced a JIT compiler for the Erlang VM called BeamAsm. How faster the JIT will be in practice depends on your application but the results posted in the announcement are promising. To quote Lukas:</p>
<blockquote>
  <p>
If we run the JSON benchmarks found in the <a href="https://github.com/devinus/poison/tree/master/bench">Poison</a> or <a href="https://github.com/michalmuskala/jason/tree/master/bench">Jason</a>, BeamAsm achieves anything from 30% to 130% increase (average at about 70%) in the number of iterations per second for all Erlang/Elixir implementations. For some benchmarks, BeamAsm is even faster than the pure C implementation <a href="https://github.com/davisp/jiffy">jiffy</a>.  </p>
</blockquote>
<blockquote>
  <p>
More complex applications tend to see a more moderate performance increase, for instance, RabbitMQ is able to handle 30% to 50% more messages per second depending on the scenario.  </p>
</blockquote>
<p>
I have been running …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/ten-years-ish-of-elixir">https://dashbit.co/blog/ten-years-ish-of-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/ten-years-ish-of-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776525</guid>
            <pubDate>Thu, 14 Jan 2021 14:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We don't need data scientists, we need data engineers]]>
            </title>
            <description>
<![CDATA[
Score 640 | Comments 319 (<a href="https://news.ycombinator.com/item?id=25775872">thread link</a>) | @winkywooster
<br/>
January 14, 2021 | https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/ | <a href="https://web.archive.org/web/*/https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="11"><figure>
    
  <a href="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-85f3f.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="world in data" title="" src="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c6823.jpg" srcset="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-dad4f.jpg 240w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-1808a.jpg 480w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c6823.jpg 960w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-e8e5f.jpg 1440w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-54793.jpg 1920w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c4df6.jpg 2880w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-85f3f.jpg 4256w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>Data. It’s everywhere and we’re <a href="https://techjury.net/blog/how-much-data-is-created-every-day/#gref">only getting more of it</a>. For the last 5-10 years, <em>data science</em> has attracted newcomers near and far trying to get a taste of that forbidden fruit. </p>
<p>But what does the state of <em>data science</em> hiring look like today?</p>
<p>Here’s the gist of the article in two-sentences for the busy reader.</p>
<p><strong>TLDR</strong>: There are <strong>70% more open roles</strong> at companies in <em>data engineering</em> as compared to <em>data science</em>. As we train the next generation of data and machine learning practitioners, let’s place more emphasis on engineering skills.</p>
<hr>
<p>As part of my work developing an <a href="https://www.confetti.ai/">educational platform</a> for data professionals, I think a lot about how the market for data-driven (machine learning and data science) roles is evolving. </p>
<p>In talking to dozens of prospective entrants to data fields including students at top institutions around the world, I’ve seen a tremendous amount of confusion around what skills are most important to help candidates stand out in the crowd and prepare for their careers. </p>
<p>When you think about it, a <em>data scientist</em> can be responsible for any subset of the following: machine learning modelling, visualization, data cleaning and processing (i.e. SQL wrangling), engineering, and production deployment. </p>
<p>How do you even begin to recommend a study curriculum for newcomers?</p>
<p>Data speaks louder than words. So I decided to do an analysis of the data roles being hired for at every company coming out of <a href="https://www.ycombinator.com/">Y-Combinator</a> since 2012. The questions that guided my research:</p>
<ul>
<li>What data roles are companies most frequently hiring for?</li>
<li>How in-demand is the conventional <em>data scientist</em> that we talk about so much?</li>
<li>Are the same skills that started the data revolution relevant today?</li>
</ul>
<p>If you want the full details and analysis, read on. </p>
<h2>Methodology</h2>
<p>I chose to do an analysis of YC portfolio companies that claim to make some sort of data work part of their value proposition. </p>
<p>Why focus on YC? Well, for starters, they do a good job of providing an easily searchable (and scrapable) <a href="https://www.ycombinator.com/companies/">directory of their companies</a>. </p>
<p>In addition, as a particularly forward-thinking incubator that has funded companies from around the world across domains for over a decade, I felt they provided a representative sample of the market with which to conduct my analyses. That being said, take what I say wit a grain of salt, as I didn’t analyze super-large tech companies.</p>
<p>I scraped the homepage URLs of every YC company since 2012, producing an initial pool of ~1400 companies. </p>
<p>Why stop at 2012? Well, 2012 was the year that <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a> won the ImageNet competition, effectively kickstarting the machine learning and data-modelling wave we are now living through. It’s fair to say that this birthed some of the earliest generations of data-first companies.</p>
<p>From this initial pool, I performed keyword filtering to reduce the number of relevant companies I would have to look through. In particular, I only considered companies whose websites included at least one of the following terms: AI, CV, NLP, natural language processing, computer vision, artificial intelligence, machine, ML, data. I also disregarded companies whose website links were broken. </p>
<p>Did this generate a ton of false positives? Absolutely! But here I was trying to prioritize high recall as much as possible, recognizing that I would do a more fine-grained manual inspection of the individual websites for relevant roles.</p>
<p>With this reduced pool, I went through every site, found where they were advertising jobs (typically a <em>Careers</em>, <em>Jobs</em>, or <em>We’re Hiring</em> page), and took note of every role that included data, machine learning, NLP, or CV in the title. This gave me a pool of about 70 distinct companies hiring for data roles. </p>
<p>One note here: it’s conceivable that I missed some companies as there were certain websites with very little information (typically those in stealth) that might actually be hiring. In addition, there were companies that didn’t have a formal <em>Careers</em> page but asked that prospective candidates reach out directly via email. </p>
<p>I disregarded both of these types of companies rather than reach out to them, so they are not part of this analysis.</p>
<p>Another thing: the bulk of this research was done towards the final weeks of 2020. Open roles may have changed as companies update their pages periodically. However, I don’t believe this will drastically impact the conclusions drawn. </p>
<h2>What Are Data Practitioners Responsible For?</h2>
<p>Before diving into the results, it’s worth spending some time clarifying what responsibilities each data role is typically responsible for. Here are the four roles we will spend our time looking at with a short description of what they do:</p>
<ul>
<li><em>Data scientist</em>: Use various techniques in statistics and machine learning to process and analyse data. Often responsible for building models to probe what can be learned from some data source, though often at a prototype rather than production level. </li>
<li><em>Data engineer</em>: Develops a robust and scalable set of data processing tools/platforms. Must be comfortable with SQL/NoSQL database wrangling and building/maintaining ETL pipelines.</li>
<li><em>Machine Learning (ML) Engineer</em>: Often responsible for both training models and productionizing them. Requires familiarity with some high-level ML framework and also must be comfortable building scalable training, inference, and deployment pipelines for models.</li>
<li><em>Machine Learning (ML) Scientist</em>: Works on cutting-edge research. Typically responsible for exploring new ideas that can be published at academic conferences. Often only needs to prototype new state-of-the-art models before handing off to ML engineers for productionization.</li>
</ul>
<h2>How Many Data Roles Are There?</h2>
<p>So what happens when we plot the frequency of each data role that companies are hiring for? The plot looks  like this:</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies" title="" src="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-3d61e.png" srcset="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-d182c.png 240w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-5220f.png 480w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-3d61e.png 960w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>What immediately stands out is how many more open <em>data engineer</em> roles there are compared to traditional <em>data scientists</em>. In this case, the raw counts correspond to companies hiring <strong>roughly 55% more</strong> for data engineers than data scientists, and roughly the same number of machine learning engineers as data scientists.</p>
<p>But we can do more. If you look at the titles of the various roles, there seems to be some repetition. </p>
<p>Let’s only provide coarse-grained categorization through role consolidation. In other words, I took roles whose descriptions were roughly equivalent and consolidated them under a single title. </p>
<p>That included the following set of equivalence relations: </p>
<ul>
<li><em>NLP engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>CV engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>ML engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Deep Learning engineer</em> (while the domains might be different, the responsiblities are roughly the same)</li>
<li><em>ML scientist</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Deep Learning researcher</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>ML intern</em> (the internship description very much seemed research-focused)</li>
<li><em>Data engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Data architect</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Head of data</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Data platform engineer</em></li>
</ul>
<figure>
    
  <a href="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies consolidated into coarse categories" title="" src="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-3d61e.png" srcset="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-d182c.png 240w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-5220f.png 480w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-3d61e.png 960w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>If we don’t like dealing with raw counts, here are some percentages to put us at ease:</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies normalized frequencies" title="" src="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-3d61e.png" srcset="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-d182c.png 240w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-5220f.png 480w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-3d61e.png 960w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>I probably could have lumped <em>ML research engineer</em> into one of the <em>ML scientist</em> or <em>ML engineer</em> bins, but given that it was a bit of a hybrid role, I left it as is. </p>
<p>Overall the consolidation made the differences even more pronounced! There are <strong>~70%</strong> more open <em>data engineer</em> than <em>data scientist</em> positions. In addition, there are <strong>~40%</strong> more open <em>ML engineer</em> than <em>data scientist</em> positions. There are also only <strong>~30%</strong> as many <em>ML scientist</em> as <em>data scientist</em> positions. </p>
<h2>Takeaways</h2>
<p><em>Data engineers</em> are in increasingly high demand compared to other data-driven professions. In a sense, this represents an evolution for the broader field. </p>
<p>When machine learning become hot 🔥 5-8 years ago, companies decided they need people that can make classifiers on data. But then frameworks like <a href="https://www.tensorflow.org/">Tensorflow</a> and <a href="https://pytorch.org/">PyTorch</a> became really good, democratizing the ability to get started with deep learning and machine learning. </p>
<p>This commoditized the data modelling skillset. </p>
<p>Today, the bottleneck in helping companies get machine learning and modelling insights to production center on data problems. </p>
<p>How do you annotate data? How do you process and clean data? How do you move it from A to B? How do you do this every day as quickly as possible?</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="patrick star moving data" title="" src="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png" srcset="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-8c52f.png 240w,
https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-0f208.png 480w,
https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png 720w" sizes="(max-width: 720px) 100vw, 720px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>All that amounts to having good engineering skills. </p>
<p>This may sound boring and unsexy, but old-school software engineering with a bend toward data may be what we really need right now. </p>
<p>For years, we’ve become enamored with the idea of data professionals that breathe life into raw data thanks to cool demos and media hype. After all, when was the last time you saw a <a href="https://techcrunch.com/">TechCrunch</a> article about an ETL pipeline? </p>
<p>If nothing else, I believe solid engineering is something we don’t emphasize enough in data science job training or educational programs. In addition to learning how to use <em>linear_regression.fit()</em>, learn how to write a unit test too!</p>
<p>So does that mean you shouldn’t study data science? No. </p>
<p>What it means is that competition is going to be tougher. There are going to be fewer positions available for what is looking to be an abundance of newcomers to the market trained to do data science. </p>
<p>There will always be a need for people that can effectively analyze and extract actionable insights from data. But they have to be good. </p>
<p>Downloading a pretrained model off the Tensorflow website on the <a href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html">Iris dataset</a> probably is no longer enough to get that data science job. </p>
<p>It’s clear, however, with the large number of <em>ML engineer</em> openings that companies often want a hybrid data practitioner: someone that can build and deploy models. Or said more succinctly, someone that can use Tensorflow but can also build it from source.</p>
<p>Another takeaway here is that there just aren’t that many ML research positions. </p>
<p>Machine learning research tends to get its fair share of hype because that’s where all the cutting-edge stuff happens, all the <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a> and <a href="https://openai.com/blog/openai-api/">GPT-3</a> and what-not. </p>
<p>But for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/">https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/</a></em></p>]]>
            </description>
            <link>https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775872</guid>
            <pubDate>Thu, 14 Jan 2021 13:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most thoroughly commented linker script (probably)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25775854">thread link</a>) | @signa11
<br/>
January 14, 2021 | https://blog.thea.codes/the-most-thoroughly-commented-linker-script/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>While developing the firmware for Winterbloom's <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux">Castor &amp; Pollux</a>, I got very curious as to just what the Microchip/Atmel-provided linker script was doing.</p>
<p>If you've never heard of or seen a linker script before you're not alone. Most of us never even have to think about them, however, on memory constained embedded devices it's not uncommon to need to modify the default linker script.</p>
<p>The linker script controls how <code>ld</code> combines all of your <code>.o</code> files into a single <code>.elf</code> and how that resulting <code>.elf</code> file gets loaded by the target processor.</p>
<p>So I was staring at this script that made absolutely no sense to me. It's filled with incantations and mysterious symbols and there's no indication of what they're for or where they come from.</p>
<p>So I did a <strong>lot</strong> of research and now I can present to you <strong>the most thoroughly commented linker script</strong><sup id="fnref:probably"><a href="#fn:probably">1</a></sup>.</p>
<p>You can see this script in its entirety, comments and all, on <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/blob/master/firmware/scripts/samd21g18a.ld">GitHub</a>. But if you'd like to read it here instead it's transcribed below.</p>
<h2 id="output-format">Output format</h2>
<p>Output format sets the ELF output format to use a specific BFD backend.</p>
<p>The first is the default BFD. The second and third arguments are used
when big (-EB) or little (-EL) endian is requested.</p>
<p>Since the SAM D series are configured with only little endian support,
"elf32-littlearm" is used across the board. This option seems to be
included by Atmel/Microchip out of an abundance of caution, as
arm-none-eabi-ld will do the right thing and use "elf32-littlearm" by
default.</p>
<p>The list of acceptable values can be obtained using <code>objdump -i</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands">https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands</a></li>
<li><a href="https://sourceware.org/binutils/docs/ld/BFD.html">https://sourceware.org/binutils/docs/ld/BFD.html</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 11.1.11, Cortex M0+ Configuration</li>
</ul>
<pre><span>OUTPUT_FORMAT</span><span>(</span><span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>)</span>
</pre>
<h2 id="cpu-memory-configuration-variables">CPU memory configuration variables</h2>
<p>These variables are used by the following "MEMORY" command to define
the various memory spaces.</p>
<p>For the SAMD21G18A used by this project, the available Flash is
262kB and the available SRAM is 32kB.</p>
<p>This project also reserves 8kB for the bootloader and 1kB for
"non-volatile memory" (NVM) - which is used by the application
to store calibration and user settings.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>FLASH_SIZE</span> <span>=</span> <span>0x40000</span><span>;</span>      <span>/* 256kB */</span>
<span>BOOTLOADER_SIZE</span> <span>=</span> <span>0x2000</span><span>;</span>  <span>/* 8kB */</span>
<span>NVM_SIZE</span> <span>=</span> <span>0x400</span><span>;</span>          <span>/* 1kbB */</span>
<span>SRAM_SIZE</span> <span>=</span> <span>0x8000</span><span>;</span>        <span>/* 32kB */</span>
</pre>
<p>ARM Cortex-M processors use a descending stack and generally
require stack space to be set aside in RAM.</p>
<p>The application's behavior determines just how much stack space
should be reserved. I generally start with 2kB (0x800) of
stack space for Cortex-M0+ projects programmed in C .</p>
<p>You can analyze stack usage in GCC using the <code>-fstack-usage</code>
flag and you can enable compiler warnings for stack usage
with <code>-Wstack-usage=STACK_SIZE</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/">https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/</a></li>
<li><a href="https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications">https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html">https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html</a></li>
</ul>
<pre><span>STACK_SIZE</span> <span>=</span> <span>DEFINED</span><span>(</span><span>__stack_size__</span><span>)</span> <span>?</span> <span>__stack_size__</span> <span>:</span> <span>0x800</span><span>;</span>
</pre>
<h2 id="memory-space-definition">Memory space definition</h2>
<p>This section declare blocks of memories for specific purposes. Since an
ARM's address space is generally split between Flash, SRAM, peripherals,
and other regions, it's necessary to tell the linker where different
types of data can go in the address space.</p>
<p>These blocks will be used in the <code>SECTIONS</code> command below.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY">https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>MEMORY</span>
<span>{</span>
</pre>
<p>Start with the Flash memory region. On the SAMD21, Flash starts at
the beginning of the address space (<code>0x00000000</code>) and is contiguous
right up to the size of the Flash. Flash is marked a <code>rx</code> so
that the linker knows that this space is read-only (<code>r</code>) and
executable (<code>x</code>).</p>
<p>The "bootloader" section allows this firmware to work with the uf2
bootloader. The bootloader takes the first 0x2000 bytes of flash
memory.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/adafruit/uf2-samdx1#configuration">https://github.com/adafruit/uf2-samdx1#configuration</a></li>
</ul>
<pre>    <span>bootloader</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>BOOTLOADER_SIZE</span>
</pre>
<p>Following the bootloader is the flash memory used by the application,
called "rom" here - even though it's flash, the name is just a name
and doesn't carry special meaning.</p>
<p>The total length of the rom block is the MCU's flash size minus the
bootloader's size and any space reserved for "non-volatile memory"
by the application.</p>
<pre>   <span>rom</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00002000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>BOOTLOADER_SIZE</span> <span>-</span> <span>NVM_SIZE</span>
</pre>
<p>The "nvm" block is space set aside for the application to store
user settings and calibration data in the MCU's flash.</p>
<p>The block is located right at the end of the flash space. This
is useful because it means that it says in a fixed location
regardless of how much flash space the application takes up
in "rom". Explicitly defining this section also lets the
linker ensure that application code doesn't overwrite the
data in this region.</p>
<p>This block is marked as read-only (<code>r</code>) because flash can not
be written in the same way as normal memory, however, the
application can use the SAMD's NVM peripheral to write data in
this region.</p>
<pre>   <span>nvm</span> <span>(</span><span>r</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>NVM_SIZE</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>NVM_SIZE</span>
</pre>
<p>The "ram" block is mapped to the CPU's SRAM and it's where
the stack, heap, and all variables will go.</p>
<p>For the SAMD21, SRAM starts at 0x20000000 and is contiguous
for the size of the SRAM.</p>
<pre>   <span>ram</span> <span>(</span><span>rwx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x20000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>SRAM_SIZE</span>
<span>}</span>
</pre>
<h2 id="sections">Sections</h2>
<p>The sections command tells the linker how to combine the
input files into an output ELF and where segments belong
in memory.</p>
<p>The linker takes a set of input files containing the "input
sections" and uses this to map them to "output sections"
which are placed in the output ELF file.</p>
<p>While the most important sections to think about here
are the ones that'll be placed into the memory (segments)
some sections are just placed in the output ELF for debugging.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS">https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS</a></li>
</ul>
<pre><span>SECTIONS</span>
<span>{</span>
</pre>
<p>The text segment contains program code and read-only data.</p>
<p>References:</p>
<ul>
<li><a href="https://developer.arm.com/documentation/dui0101/a/">https://developer.arm.com/documentation/dui0101/a/</a>
Page 5, Segments</li>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
</ul>
<pre>   <span>.</span><span>text</span> <span>:</span>
   <span>{</span>
</pre>
<p>This segment must be 4-byte aligned as defined in ARM ELF
File Format specification.</p>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
</pre>
<p>The vector table defines the initial stack pointer and
interrupt/exception routines for the ARM CPU and device
peripherals. Every Cortex-M project needs this.</p>
<p>For the SAM D series the vector table is expected
to be at address 0x00000000 after reset. Since
flash memory starts at 0x00000000, the first values
in flash should be the vector table.</p>
<p>When defining the vector table in code you must use
<code>__attribute__ ((section(".vectors")))</code> to tell
GCC to place the vector table into the section
named ".vectors" in the input object file so that
the linker can find it.</p>
<p>Note that since this project uses the UF2 bootloader,
this actually gets placed at the beginning of the
program's flash area (0x2000). The Cortex-M allows
changing the vector table after initialization,
so the startup script sets the Vector Table Offset
Register (<code>SCB-&gt;VTOR</code>) to <code>_sfixed</code> during its
intialization. The <code>_efixed</code> symbol is unused but
included for completeness.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
Secion 8.3.3, Fetching of Initial Instructions</li>
<li><a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf</a>
Section B1.5.3, The vector table
Section B3.2.5, Vector Table Offset Register, VTOR</li>
<li><a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/tree/master/firmware/third_party/samd21/gcc/gcc/startup_samd21.c">startup_samd21.c</a></li>
</ul>
<pre>      <span>_sfixed</span> <span>=</span> <span>.;</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>vectors</span> <span>.</span><span>vectors</span><span>.</span><span>*</span><span>))</span>
</pre>
<p>Include code and read-only data sections from all
input files.</p>
<p>By default, GCC places all program code into a section named
".text" and read-only data (such as const static variables) into
a section named ".rodata" in the input object files. This naming
convention is from the ELF ABI specification.</p>
<p>GCC generates three "flavors" of sections in object files:</p>
<ul>
<li><code>.{section}</code>: the basic section.</li>
<li><code>.{section}.*</code>: sections generated by <code>-ffunction-sections</code> and
<code>-fdata-sections</code> so that each function/data has a unique
section.</li>
<li><code>.gnu.linkonce.{type}.*</code>: sections generated by GCC so the
linker can remove duplicates. Seems to be related to
Vague Linking.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html">https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html</a></li>
<li><a href="https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section">https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section</a></li>
</ul>
<pre>      <span>*</span><span>(.</span><span>text</span> <span>.</span><span>text</span><span>.</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>t</span><span>.</span><span>*</span><span>)</span>
      <span>*</span><span>(.</span><span>rodata</span> <span>.</span><span>rodata</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>r</span><span>.</span><span>*</span><span>)</span>
</pre>
<h2 id="c-c-runtime-support">C &amp; C++ runtime support</h2>
<p>The following sections are for the C/C++ runtime. These are generally used by crt0.</p>
<p>References:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Crt0">https://en.wikipedia.org/wiki/Crt0</a></li>
</ul>
<h3 id="initializers">Initializers</h3>
<ul>
<li>C++ Runtime: initializers for static variables.</li>
<li>C Runtime: designated constructors</li>
</ul>
<p>For C++, handles variables at file scope like this:</p>
<pre><span>int</span> <span>f</span> <span>=</span> <span>some_func</span><span>()</span>
</pre>
<p>For C, handles functions designated as constructors:</p>
<pre><code>void intialize_thing(void) __attribute__((constructor));
</code></pre>
<p>Executed by the C runtime at startup via <code>__libc_init_array</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c">https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c</a></li>
<li><a href="https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c">https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c</a>;</li>
<li><a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">https://gcc.gnu.org/onlinedocs/gccint/Initialization.html</a></li>
<li><a href="https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction">https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction</a></li>
<li><a href="https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array">https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array</a></li>
</ul>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>init</span><span>))</span>
      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
  …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775854</guid>
            <pubDate>Thu, 14 Jan 2021 13:06:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parisian Accent in 1912]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 154 (<a href="https://news.ycombinator.com/item?id=25775091">thread link</a>) | @paganel
<br/>
January 14, 2021 | https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912 | <a href="https://web.archive.org/web/*/https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>"C’est extraordinaire que j’aie une voix aussi traînarde, jamais je l’aurais cru ! On ne s’entend pas, absolument !" Dans ce document unique en son genre, un Parisien réagit à l'écoute de son propre accent, celui du 14e arrondissement, en 1912. Il est interviewé par le linguiste Ferdinand Brunot. </p><div>
            <p>Cette archive exceptionnelle est l’une des premières interviews sonores, le premier enregistrement d'un échange spontané, non lu. C’est aussi l’une des rares traces de l’accent parisien d’avant-guerre. En 1912, le linguiste Ferdinand Brunot veut enregistrer les dialectes des artisans. Ici, c’est le parler parisien qui l’intéresse, l’accent populaire des différents quartiers de la capitale. Louis Ligabue, tapissier dans le 14e arrondissement, a alors 37 ans, et note déjà l'embourgeoisement de son quartier.</p>

<h2>Le parler d'un pur "Parisien de Paris"</h2>
<p>Le linguiste Ferdinand Brunot, fondateur des "Archives de la parole"&nbsp;en 1911, est l'un des rares universitaires de son temps à s'intéresser à l'enregistrement du français parlé&nbsp;"commun". Pour lui, le "parler parisien" est une forme de dialecte dont il faut garder la trace. Chaque quartier de la capitale est censé présenter ses spécificités linguistiques&nbsp;: on ne parle pas à Montrouge comme à Montmartre. Or pour <a target="_blank" rel="noopener" href="https://gallica.bnf.fr/blog/11052020/quand-un-parisien-entend-pour-la-premiere-fois-le-son-de-sa-voix?mode=desktop">Pascal Cordereix</a>, responsable du service des documents sonores à la BnF, "<em>ce 'dialecte' parisien renvoie lui-même à l’un des plus grands mythes de la linguistique romane parisienne de la fin du XIXe siècle, à savoir le "françien", un supposé dialecte d’Île-de-France dans lequel le français trouverait sa seule origine. On est là au cœur de la construction jacobine de la langue française mise en œuvre après 1870, opposant définitivement français et autres idiomes parlés sur le territoire.</em>"</p>
<p><em>Ferdinand Brunot interviewe Louis Ligabue en 1912&nbsp;:&nbsp;</em></p>


<p>- Vous êtes vraiment, vous monsieur, un Parisien de Paris&nbsp;?&nbsp;</p>
<p><em>-</em> Je suis né à Paris même, boulevard Sébastopol et j’ai monté du côté de Montrouge, rue Daguerre. Ensuite, j’ai été avenue d’Orléans. J’ai travaillé dans le quartier constamment. Je ne l’ai jamais quitté du reste.&nbsp;</p>
<p>- Et vous êtes exclusivement tapissier, alors&nbsp;?&nbsp;</p>
<p>- Absolument. (...) et je travaille pour le client personnel (...)</p>
<p>- Vous êtes exclusivement dans la clientèle bourgeoise&nbsp;?&nbsp;</p>
<p>- Oui, monsieur.</p>
<p>- Il y a eu beaucoup d’installations de ce côté-là, ce doit être un bon métier&nbsp;?</p>
<p><em>-</em> Ah le quartier a beaucoup gagné. Nous avons depuis quelques années travaillé admirablement.</p>
<p>- J’ai entendu dire que vous n’étiez pas payé très régulièrement...</p>
<p>- Oh vous savez, le 14e est tout à fait spécial. Nous avons de bons clients, de bons bourgeois, et puis régulièrement, on hésite à donner une affaire... Mais quant au règlement, jamais nous ne perdons quoi que ce soit.&nbsp;</p>
<p>- On m’avait dit au contraire que rue Alphonse Daudet, il y avait une clientèle peu recommandable...</p>
<p>- Ah dame ! Ça, je m’en réjouis bien !</p>
<h2>Entendre sa propre voix</h2>
<p>Ce document est unique à plus d'un titre&nbsp;: c’est aussi la première fois qu’on entend quelqu’un réagir à ses propos, à sa voix. &nbsp;Dans la foulée de l’interview, Louis Ligabue s’écoute, et s’étonne, toujours en dialoguant avec le linguiste Ferdinand Brunot. <a target="_blank" rel="noopener" href="https://gallica.bnf.fr/blog/11052020/quand-un-parisien-entend-pour-la-premiere-fois-le-son-de-sa-voix?mode=desktop">Pascal Cordereix</a>, spécialiste du fonds sonore ancien à la Bibliothèque nationale de France (BnF)&nbsp;: "<em>On connaît beaucoup de récits écrits d’un enregistrement et de la surprise du locuteur s’écoutant parler. Mais à notre connaissance, Ferdinand Brunot est le seul, avant longtemps, à avoir l’idée de graver ainsi sur disque les réactions du témoin à l’écoute de sa propre voix.</em>"</p>
<p><strong>Ferdinand Brunot interviewe Louis Ligabue en 1912&nbsp;:&nbsp;</strong></p>
<p>- Eh bien, vous avez entendu ce que vous avez dit. Vous êtes-vous reconnu&nbsp;?&nbsp;</p>
<p>- Oui, parfaitement monsieur !</p>
<p>- N’est-ce pas que c’est bien votre voix&nbsp;?&nbsp;</p>
<p>- C’est parfait, parfait, c’est même très très curieux ! C’est très drôle, il me semble même que c’est extraordinaire que j’aie une voix si traînarde, jamais je ne l’aurais cru ! On ne s’entend pas, absolument !&nbsp;</p>
<p>- Vous n’avez pas la voix traînarde, vous avez tout simplement l’accent de Paris, c’est justement ça que je veux enregistrer.&nbsp;</p>
<p>- Ah ça aujourd'hui j’en suis convaincu, bien des gens m’ont dit des fois&nbsp;: “Comme il traîne ce garçon dans sa conversation”. Ben, je disais non, pourtant, il me semble que c’est tout naturel&nbsp;; mais alors là, vous savez, j’ai un accent presque d’La Villette on dirait…</p>
<p>- La Villette&nbsp;? Ne croyez-vous pas qu’il y a une grande différence justement entre l’accent de La Villette et le vôtre&nbsp;?</p>
<p>- Ah peut-être, je ne sais pas…</p>
<p>- Vous qui êtes de Paris, est-ce que vous ne reconnaissez pas justement quelqu’un qui est de nos arrondissements&nbsp;?</p>
<p>- Ah absolument, si, il y a réellement des différences.</p>
<p>- Quelqu’un qui s’est beaucoup occupé de ça me disait par exemple qu’il reconnaissait du premier coup un habitant du 14e et un habitant de Montmartre.</p>
<p>- Ah peut-être, mais enfin, il me semble que c’est une étude assez sérieuse.</p>
<p>- Oui, il y a des gars qui imitent ça étonnamment et à volonté vous savez, ils se transforment en gens de Montparnasse, ou en gens de Montmartre comme ils veulent.</p>
<p>- Ah oui, on voit ça dans les revues, là, dans les concerts, là&nbsp;; on a des types spéciaux là-dessus.</p>
<p>- Oui. Est-ce que dans la rue de la Gaîté, là, il y a des gens qui imitent justement l’accent du quartier&nbsp;?</p>
<p>- Ah y en a, y en a. Mais alors, ça devient peut-être un peu en exagération. Tandis que là, moi, je cause naturellement, et quand j’écoute, il me semble que j’exagère… Je suis bien content, vous savez, d’avoir jugé et ça m’a bien intéressé !</p>
<p>- Et bien je vous remercie de vous être prêté à l’expérience.</p>
<p>- De rien.</p>
<h2>Les Archives de la parole à découvrir sur Gallica</h2>
<p>Archive conservée à la Bibliothèque nationale de France. Merci au service Son du département de l’Audiovisuel, BnF et au Service de la coopération numérique et de Gallica, BnF. Archives de la Parole, conservation&nbsp;: BnF, Département de l’Audiovisuel, service Son.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-ferdinand-brunot-1911-1914">Les Archives de la parole, 1911-1914</a></li>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-jean-poirot-enregistrements-la-sorbonne">Les Archives de la parole, 1920-1924</a></li>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-musee-de-la-parole-et-du-geste-hubert-pernot-1924-1930">Les Archives de la parole, 1924-1930</a></li>
</ul>



    </div></div>]]>
            </description>
            <link>https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775091</guid>
            <pubDate>Thu, 14 Jan 2021 11:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing and visualizing the Python GIL with perf and VizTracer]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25774945">thread link</a>) | @maartenbreddels
<br/>
January 14, 2021 | https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html | <a href="https://web.archive.org/web/*/https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>

<p>There are plenty of articles explaining why the Python GIL (The Global Interpreter Lock) exists<sup id="fnref-1"><a href="#fn-1">1</a></sup>, and why it is there. The TLDR version is: the GIL prevents multithreaded pure Python code from using multiple CPU cores.</p>
<p>However, in <a href="https://vaex.io/">Vaex</a> we execute most of the CPU intensive parts in C (C++) code, where we release the GIL. This is a common practice in high-performance Python libraries, where Python acts merely as a high-level glue.</p>
<p>However, the GIL needs to be released explicitly, and this is the responsibility of the programmer and might be forgotten, leading to suboptimal use of your machine.</p>
<p>I recently had this issue in <a href="https://github.com/vaexio/vaex/pull/1114">Vaex</a> where I simply forgot to release the GIL and found a similar issue in <a href="https://github.com/apache/arrow/pull/7756">Apache Arrow</a><sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
<p>Also, when running on 64 cores, I sometimes see a performance in Vaex that I am not happy with. It might be using 4000% CPU, instead of 6400% CPU, which is something I am not happy with. Instead of blindly pulling some levers to inspect the effect, I want to understand what is happening, and if the GIL is the problem, why, and where is it holding Vaex down.</p>


</div>
</div>
</div><div>
<div>
<div>

<p>I'm planning to write a series of articles explaining some tools and techniques available for profiling/tracing Python together with native extensions, and how these tools can be glued together, to analyze and visualize what Python is doing, and when the GIL it taken or dropped.</p>
<p>I hope this leads to improvement of tracing, profiling, and other performance tooling in the Python ecosystem, and the performance of the whole Python ecosystem.</p>

<h2 id="Linux">
Linux<a href="#Linux"> </a>
</h2>
<p>Get access to a Linux machine, and make sure you have root privileges (sudo is fine), or ask your sysadmin to execute some of these commands for you. For the rest of the document, we only run as user.</p>
<h2 id="Perf">
Perf<a href="#Perf"> </a>
</h2>
<p>Make sure you have perf installed, e.g. on Ubuntu:</p>

<pre><code>$ sudo yum install perf</code></pre>
<h2 id="Kernel-configuration">
Kernel configuration<a href="#Kernel-configuration"> </a>
</h2>
<p>To enable running it as a user:</p>

<pre><code># Enable users to run perf (use at own risk)
$ sudo sysctl kernel.perf_event_paranoid=-1

# Enable users to see schedule trace events:
$ sudo mount -o remount,mode=755 /sys/kernel/debug
$ sudo mount -o remount,mode=755 /sys/kernel/debug/tracing</code></pre>
<h2 id="Python-packages">
Python packages<a href="#Python-packages"> </a>
</h2>
<p>We will make use of <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> and <a href="https://github.com/maartenbreddels/per4m">per4m</a></p>

<pre><code>$ pip install "viztracer&gt;=0.11.2" "per4m&gt;=0.1,&lt;0.2"</code></pre>

</div>
</div>
</div><div>
<div>
<div>

<p>There is no way to get the GIL state in Python <sup id="fnref-3"><a href="#fn-3">1</a></sup> since there is no API for this. We can track it from the kernel, and the right tool for this under Linux is <strong>perf</strong>.</p>
<p>Using the linux perf tool (aka perf_events), we can listen to the state changes for processes/threads (we only care about sleeping and running), and log them. Although perf may look scary, it is a powerful tool. If you want to know a bit more about perf, I recommend reading <a href="https://jvns.ca/blog/2018/04/16/new-perf-zine/">Julia Evans' zine on perf</a> or <a href="http://www.brendangregg.com/perf.html">go through Brendan Gregg's website</a>.</p>
<p>To build our intuition, we will first run perf on a <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example0.py">very trivial program</a>:</p>


</div>
</div>
</div><div>
<div>
<div>
<p>We listen to just a few events to keep the noise down (note the use of wildcards):</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork \
        -e 'sched:sched_wak*' -- python -m per4m.example0
[ perf record: Woken up 2 times to write data ]
[ perf record: Captured and wrote 0,032 MB perf.data (33 samples) ]</code></pre>
<p>And use the <code>perf script</code> command to write human/parsable output.</p>

<pre><code>$ perf script
        :3040108 3040108 [032] 5563910.979408:                sched:sched_waking: comm=perf pid=3040114 prio=120 target_cpu=031
        :3040108 3040108 [032] 5563910.979431:                sched:sched_wakeup: comm=perf pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995616:                sched:sched_waking: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995618:                sched:sched_wakeup: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995621:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995622:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995624:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R+ ==&gt; next_comm=kworker/31:1 next_pid=2502104 next_prio=120
          python 3040114 [031] 5563911.003612:                sched:sched_waking: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.003614:                sched:sched_wakeup: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.083609:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083612:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083613:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R ==&gt; next_comm=ksoftirqd/31 next_pid=198 next_prio=120
          python 3040114 [031] 5563911.108984:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.109059:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.112250:          sched:sched_process_fork: comm=python pid=3040114 child_comm=python child_pid=3040116
          python 3040114 [031] 5563911.112260:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112262:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112273:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112418:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112450:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112473: sched:sched_wake_idle_without_ipi: cpu=31
         swapper     0 [031] 5563911.112476:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112485:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112485:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112489:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112496:                sched:sched_switch: prev_comm=python prev_pid=3040116 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/37 next_pid=0 next_prio=120
         swapper     0 [031] 5563911.112497:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
         swapper     0 [037] 5563912.113490:                sched:sched_waking: comm=python pid=3040116 prio=120 target_cpu=037
         swapper     0 [037] 5563912.113529:                sched:sched_wakeup: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040116 [037] 5563912.113595:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563912.113620:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
         swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></pre>

</div>
</div>
</div><div>
<div>
<div>
<p>Take a moment to digest the output. I can see a few things. Looking at the 4th column (time in seconds), we can see where the program slept (it skips 1 second). Here we see that we enter the sleeping state with a line like:</p>
<p><code>python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120</code></p>
<p>This means the kernel changed the state of the Python thread to <code>S</code> (=sleeping) state.</p>
<p>A full second later, we see it being woken up:</p>
<p><code>swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></p>
<p>Of course, you need to build some tooling around this, to really see what is happening. But one can imagine this output can be easily parsed and this is what <a href="https://github.com/maartenbreddels/per4m/">per4m</a> does. However, before we go there, I'd first like to visualize the flow of a slightly more advanced program using <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a>.</p>

</div>
</div>
</div><div>
<div>
<div>

<p><a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> is a Python tracer that can visualize what your program does in the browser. Let us run it on a slightly <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example1.py">more advanced example</a> to see what it looks like.</p>

</div>
</div>
</div><div>
<div>
<div>
<p>Running viztracer gives output like:</p>

<pre><code>$ viztracer -o example1.html --ignore_frozen -m per4m.example1
Loading finish                                        
Saving report to /home/maartenbreddels/github/maartenbreddels/per4m/example1.html ...
Dumping trace data to json, total entries: 94, estimated json file size: 11.0KiB
Generating HTML report
Report saved.</code></pre>
<p>And the HTML should render as:
<img src="https://www.maartenbreddels.com/images/copied_from_nb/per4m/example1.png" alt="image.png"></p>
<p>From this, it seems that <code>some_computation</code> seem to be executed in parallel (twice), while in fact, we know the GIL is preventing that. So what is really going on?</p>

</div>
</div>
</div><div>
<div>
<div>

<p>Let us run <code>perf</code> on this, similarly to what we did to example0.py. However, we add the argument <code>-k CLOCK_MONOTONIC</code> so that we use <a href="https://github.com/gaogaotiantian/viztracer/blob/3321ba4024afe5623f938a601d7f7db3b08f534d/src/viztracer/modules/snaptrace.c#L91">the same clock as VizTracer</a> and ask VizTracer to generate a JSON, instead of an HTML file:</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork -e 'sched:sched_wak*' \
   -k CLOCK_MONOTONIC  -- viztracer -o viztracer1.json --ignore_frozen -m per4m.example1</code></pre>
<p>Then …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</a></em></p>]]>
            </description>
            <link>https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774945</guid>
            <pubDate>Thu, 14 Jan 2021 11:06:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inline Caching]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25773724">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | https://bernsteinbear.com/blog/inline-caching/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/inline-caching/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Inline caching is a popular technique for runtime optimization. It was first
introduced in 1984 in Deutsch &amp; Schiffman’s paper <a href="http://web.cs.ucla.edu/~palsberg/course/cs232/papers/DeutschSchiffman-popl84.pdf">Efficient implementation
of the smalltalk-80 system [PDF]</a> but has had a long-lasting legacy in
today’s dynamic language implementations. Runtimes like the Hotspot JVM, V8,
and SpiderMonkey use it to improve the performance of code written for those
virtual machines.</p>

<p>In this blog post, I will attempt to distill the essence of inline caching
using a small and relatively useless bytecode interpreter built solely for this
blog post. The caching strategy in this demo is a technique similar to the
ideas from <a href="http://www.complang.tuwien.ac.at/kps09/pdfs/brunthaler.pdf">Inline Caching meets Quickening [PDF]</a> in that it
caches function pointers instead of making use of a JIT compiler.</p>

<h2 id="background">Background</h2>

<p>In many compiled programming languages like C and C++, types and attribute
locations are known at compile time. This makes code like the following fast:</p>

<div><div><pre><code><span>#include "foo.h"
</span>
<span>Foo</span> <span>do_add</span><span>(</span><span>Foo</span> <span>left</span><span>,</span> <span>Foo</span> <span>right</span><span>)</span> <span>{</span>
  <span>return</span> <span>left</span><span>.</span><span>add</span><span>(</span><span>right</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>The compiler knows precisely what type <code>left</code> and <code>right</code> are (it’s <code>Foo</code>) and
also where the method <code>add</code> is in the executable. If the implementation is in
the header file, it may even be inlined and <code>do_add</code> may be optimized to a
single instruction. Check out the assembly from <code>objdump</code>:</p>

<div><div><pre><code>0000000000401160 &lt;_Z6do_add3FooS_&gt;:
  401160:	48 83 ec 18          	sub    $0x18,%rsp
  401164:	89 7c 24 0c          	mov    %edi,0xc(%rsp)
  401168:	48 8d 7c 24 0c       	lea    0xc(%rsp),%rdi
  40116d:	e8 0e 00 00 00       	callq  401180 &lt;_ZN3Foo3addES_&gt;
  401172:	48 83 c4 18          	add    $0x18,%rsp
  401176:	c3                   	retq   
</code></pre></div></div>

<p>All it does is save the parameters to the stack, call <code>Foo::add</code>, and then
restore the stack.</p>

<p>In more dynamic programming languages, it is often impossible to determine at
runtime startup what type any given variable binding has. We’ll use Python as an
example to illustrate how dynamism makes this tricky, but this constraint is
broadly applicable to Ruby, JavaScript, etc.</p>

<p>Consider the following Python snippet:</p>

<div><div><pre><code><span>def</span> <span>do_add</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>):</span>
    <span>return</span> <span>left</span><span>.</span><span>add</span><span>(</span><span>right</span><span>)</span>
</code></pre></div></div>

<p>Due to Python’s various dynamic features, the compiler cannot in general know
what type <code>value</code> is and therefore what code to run when reading <code>left.add</code>.
This program will be compiled down to a couple Python bytecode instructions
that do a very generic <code>LOAD_METHOD</code>/<code>CALL_METHOD</code> operation:</p>

<div><div><pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; dis.dis("""
... def do_add(left, right):
...     return left.add(right)
... """)
[snip]
Disassembly of &lt;code object do_add at 0x7f0b40cf49d0, file "&lt;dis&gt;", line 2&gt;:
  3           0 LOAD_FAST                0 (left)
              2 LOAD_METHOD              0 (add)
              4 LOAD_FAST                1 (right)
              6 CALL_METHOD              1
              8 RETURN_VALUE

&gt;&gt;&gt; 
</code></pre></div></div>

<p>This <code>LOAD_METHOD</code> Python bytecode instruction is unlike the x86 <code>mov</code>
instruction in that <code>LOAD_METHOD</code> is not given an offset into <code>left</code>, but
instead is given the name <code>"add"</code>. It has to go and figure out how to read
<code>add</code> from <code>left</code>’s type — which could change from call to call.</p>

<p>In fact, even if the parameters were typed (which is a new feature in Python
3), the same code would be generated. Writing <code>left: Foo</code> means that <code>left</code> is a
<code>Foo</code> <em>or</em> a subclass.</p>

<p>This is not a simple process like “fetch the attribute at the given offset
specified by the type”. The runtime has to find out what kind of object <code>add</code>
is. Maybe it’s just a function, or maybe it’s a <code>property</code>, or maybe it’s some
custom descriptor protocol thing. There’s no way to just turn this into a
<code>mov</code>!</p>

<p>… or is there?</p>

<h2 id="runtime-type-information">Runtime type information</h2>

<p>Though dynamic runtimes do not know ahead of time what types variables have at
any given opcode, they do eventually find out <em>when the code is run</em>. The first
time someone calls <code>do_add</code>, <code>LOAD_METHOD</code> will go and look up the type of
<code>left</code>. It will use it to look up the attribute <code>add</code> and then throw the type
information away. But the second time someone calls <code>do_add</code>, the same thing
will happen. Why don’t runtimes store this information about the type and the
method and save the lookup work?</p>

<p>The thinking is “well, <code>left</code> could be any type of object — best not make any
assumptions about it.” While this is <em>technically</em> true, Deutsch &amp;
Schiffman find that “at a given point in code, the receiver is often the same
class as the receiver at the same point when the code was last executed”.</p>

<blockquote>
  <p><strong>Note:</strong> By <em>receiver</em>, they mean the thing from which the attribute is
being loaded. This is some Object-Oriented Programming terminology.</p>
</blockquote>

<p>This is huge. This means that, even in this sea of dynamic behavior, humans
actually are not all that creative and tend to write functions that see only a
handful of types at a given location.</p>

<p>The Smalltalk-80 paper describes a runtime that takes advantage of this by
adding “inline caches” to functions. These inline caches keep track of variable
types seen at each point in the code, so that the runtime can make optimization
decisions with that information.</p>

<p>Let’s take a look at how this could work in practice.</p>

<h2 id="a-small-example">A small example</h2>

<p>I put together a <a href="https://github.com/tekknolagi/icdemo">small stack machine</a> with only a few operations. There
are very minimal features to avoid distracting from the main focus: inline
caching. Extending this example would be an excellent exercise.</p>

<h3 id="objects-and-types">Objects and types</h3>

<p>The design of this runtime involves two types of objects (<code>int</code>s and <code>str</code>s).
Objects are implemented as a tagged union, but for the purposes of this blog
post the representation does not matter very much.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>kInt</span><span>,</span>
  <span>kStr</span><span>,</span>
<span>}</span> <span>ObjectType</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>ObjectType</span> <span>type</span><span>;</span>
  <span>union</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>str_value</span><span>;</span>
    <span>int</span> <span>int_value</span><span>;</span>
  <span>};</span>
<span>}</span> <span>Object</span><span>;</span>
</code></pre></div></div>

<p>These types have methods on them, such as <code>add</code> and <code>print</code>. Method names are
represented with an enum (<code>Symbol</code>) though strings would work just as well.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>kAdd</span><span>,</span>
  <span>kPrint</span><span>,</span>

  <span>kUnknownSymbol</span> <span>=</span> <span>kPrint</span> <span>+</span> <span>1</span><span>,</span>
<span>}</span> <span>Symbol</span><span>;</span>
</code></pre></div></div>

<p>The representation of type information isn’t super important. Just know that
there is a function called <code>lookup_method</code> and that it is very slow. Eventually
we’ll want to cache its result.</p>

<div><div><pre><code><span>Method</span> <span>lookup_method</span><span>(</span><span>ObjectType</span> <span>type</span><span>,</span> <span>Symbol</span> <span>name</span><span>);</span>
</code></pre></div></div>

<p>Let’s see how we use these <code>lookup_method</code> in the interpreter.</p>

<h3 id="interpreter">Interpreter</h3>

<p>There’s no way to call these methods directly. For the purposes of this demo,
the only way to call these methods is through purpose-built opcodes. For
example, the opcode <code>ADD</code> takes two arguments. It looks up <code>kAdd</code> on the left
hand side and calls it. <code>PRINT</code> is similar.</p>

<p>There are only two other opcodes, <code>ARG</code> and <code>HALT</code>.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>// Load a value from the arguments array at index `arg'.</span>
  <span>ARG</span><span>,</span>
  <span>// Add stack[-2] + stack[-1].</span>
  <span>ADD</span><span>,</span>
  <span>// Pop the top of the stack and print it.</span>
  <span>PRINT</span><span>,</span>
  <span>// Halt the machine.</span>
  <span>HALT</span><span>,</span>
<span>}</span> <span>Opcode</span><span>;</span>
</code></pre></div></div>
<p>Bytecode is represented by a series of opcode/argument pairs, each taking up
one byte. Only <code>ARG</code> needs an argument; the other instructions ignore theirs.</p>

<p>Let’s look at a sample program.</p>

<div><div><pre><code><span>byte</span> <span>bytecode</span><span>[]</span> <span>=</span> <span>{</span><span>/*0:*/</span> <span>ARG</span><span>,</span>   <span>0</span><span>,</span>
                   <span>/*2:*/</span> <span>ARG</span><span>,</span>   <span>1</span><span>,</span>
                   <span>/*4:*/</span> <span>ADD</span><span>,</span>   <span>0</span><span>,</span>
                   <span>/*6:*/</span> <span>PRINT</span><span>,</span> <span>0</span><span>,</span>
                   <span>/*8:*/</span> <span>HALT</span><span>,</span>  <span>0</span><span>};</span>
</code></pre></div></div>

<p>This program takes its two arguments, adds them together, prints the result,
and then halts the interpreter.</p>

<p>You may wonder, “how is it that there is an instruction for loading arguments
but no call instruction?” Well, the interpreter does not support calls. There
is only a top-level function, <code>eval_code</code>. It takes an object, evaluates its
bytecode with the given arguments, and returns. Extending the interpreter to
support function calls would be another good exercise.</p>

<p>The interpreter implementation is a fairly straightforward <code>switch</code> statement.
Notice that it takes a representation of a function-like thing (<code>Code</code>) and an
array of arguments. <code>nargs</code> is only used for bounds checking.</p>

<div><div><pre><code><span>typedef</span> <span>unsigned</span> <span>char</span> <span>byte</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>ObjectType</span> <span>key</span><span>;</span>
  <span>Method</span> <span>value</span><span>;</span>
<span>}</span> <span>CachedValue</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>// Array of `num_opcodes' (op, arg) pairs (total size `num_opcodes' * 2).</span>
  <span>byte</span> <span>*</span><span>bytecode</span><span>;</span>
  <span>int</span> <span>num_opcodes</span><span>;</span>
  <span>// Array of `num_opcodes' elements.</span>
  <span>CachedValue</span> <span>*</span><span>caches</span><span>;</span>
<span>}</span> <span>Code</span><span>;</span>

<span>static</span> <span>unsigned</span> <span>kBytecodeSize</span> <span>=</span> <span>2</span><span>;</span>

<span>void</span> <span>eval_code_uncached</span><span>(</span><span>Code</span> <span>*</span><span>code</span><span>,</span> <span>Object</span> <span>*</span><span>args</span><span>,</span> <span>int</span> <span>nargs</span><span>)</span> <span>{</span>
  <span>int</span> <span>pc</span> <span>=</span> <span>0</span><span>;</span>
<span>#define STACK_SIZE 100
</span>  <span>Object</span> <span>stack_array</span><span>[</span><span>STACK_SIZE</span><span>];</span>
  <span>Object</span> <span>*</span><span>stack</span> <span>=</span> <span>stack_array</span><span>;</span>
<span>#define PUSH(x) *stack++ = (x)
#define POP() *--stack
</span>  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>Opcode</span> <span>op</span> <span>=</span> <span>code</span><span>-&gt;</span><span>bytecode</span><span>[</span><span>pc</span><span>];</span>
    <span>byte</span> <span>arg</span> <span>=</span> <span>code</span><span>-&gt;</span><span>bytecode</span><span>[</span><span>pc</span> <span>+</span> <span>1</span><span>];</span>
    <span>switch</span> <span>(</span><span>op</span><span>)</span> <span>{</span>
      <span>case</span> <span>ARG</span><span>:</span>
        <span>CHECK</span><span>(</span><span>arg</span> <span>&lt;</span> <span>nargs</span> <span>&amp;&amp;</span> <span>"out of bounds arg"</span><span>);</span>
        <span>PUSH</span><span>(</span><span>args</span><span>[</span><span>arg</span><span>]);</span>
        <span>break</span><span>;</span>
      <span>case</span> <span>ADD</span><span>:</span> <span>{</span>
        <span>Object</span> <span>right</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Object</span> <span>left</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Method</span> <span>method</span> <span>=</span> <span>lookup_method</span><span>(</span><span>left</span><span>.</span><span>type</span><span>,</span> <span>kAdd</span><span>);</span>
        <span>Object</span> <span>result</span> <span>=</span> <span>(</span><span>*</span><span>method</span><span>)(</span><span>left</span><span>,</span> <span>right</span><span>);</span>
        <span>PUSH</span><span>(</span><span>result</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
      <span>case</span> <span>PRINT</span><span>:</span> <span>{</span>
        <span>Object</span> <span>obj</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Method</span> <span>method</span> <span>=</span> <span>lookup_method</span><span>(</span><span>obj</span><span>.</span><span>type</span><span>,</span> <span>kPrint</span><span>);</span>
        <span>(</span><span>*</span><span>method</span><span>)(</span><span>obj</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
      <span>case</span> <span>HALT</span><span>:</span>
        <span>return</span><span>;</span>
      <span>default:</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"unknown opcode %d</span><span>\n</span><span>"</span><span>,</span> <span>op</span><span>);</span>
        <span>abort</span><span>();</span>
    <span>}</span>
    <span>pc</span> <span>+=</span> <span>kBytecodeSize</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Both <code>ADD</code> and <code>PRINT</code> make use of <code>lookup_method</code> to find out what function
pointer corresponds to the given <code>(type, symbol)</code> pair. Both opcodes throw away
the result. How sad. Let’s figure out how to save some of that data. Maybe we
can use the <code>caches</code> slot in <code>Code</code>.</p>

<h3 id="inline-caching-strategy">Inline caching strategy</h3>

<p>Since the Smalltalk-80 paper tells us that the receiver type is unlikely to
change from call to call at a given point in the bytecode, let’s cache <em>one</em>
method address per opcode. As with any cache, we’ll have to store both a key
(the object type) and a value (the method address).</p>

<p>There are several states that the cache could be in when entering the an
opcode:</p>

<ol>
  <li><strong>If it is empty</strong>, look up the method and store it in the cache using the
current type as a cache key. Use the cached value.</li>
  <li><strong>If it has an entry and the entry is for the current type</strong>, use the cached
value.</li>
  <li>Last, <strong>if it has an entry and the entry is for a different …</strong></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/inline-caching/">https://bernsteinbear.com/blog/inline-caching/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/inline-caching/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773724</guid>
            <pubDate>Thu, 14 Jan 2021 08:35:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing the performance of Tensorflow training on M1 Mac Mini and Nvidia V100]]>
            </title>
            <description>
<![CDATA[
Score 222 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25773109">thread link</a>) | @briggers
<br/>
January 13, 2021 | https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg | <a href="https://web.archive.org/web/*/https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773109</guid>
            <pubDate>Thu, 14 Jan 2021 07:04:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimize Your Distractions]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25772946">thread link</a>) | @akhilkg
<br/>
January 13, 2021 | https://www.akhilkg.me/blog/distractions | <a href="https://web.archive.org/web/*/https://www.akhilkg.me/blog/distractions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I’m not a “systems” person.</p>
<p>It’s not like I never tried - making schedules, using a Pomodoro timer,&lt;insert productivity “hack”&gt; - they didn’t work because I was trying to fit a square peg in a round hole.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104540572-bb4c3d00-5645-11eb-86f9-de27e6b8d07d.jpg" alt="square_peg.jpg"> <small> <a href="https://baddadcartoons101.wordpress.com/2017/09/04/square-peg-and-a-round-hole/" target="_blank" rel="noopener noreferrer"> <i> Source: BadDadCartoons </i> </a> </small> </p>
<p>What I ended up doing was instead of focusing on optimising the time I spent productively - i.e. the “deep work” part (which happened rather spontaneously independent of whether I’m on a productivity hack or not) - I decided to focus on the time that was not “deep work” i.e. time spent on ‘distractions’ or entertainment.</p>
<p>I used to spend an unhealthy amount of time in a day on Instagram where the feed was mostly filled with memes. I also used Quora/Twitter a lot.</p>
<p>Consuming content is easy. Like junk food. It's almost embedded in our reflexes.</p>
<p>But here’s the thing - you can easily turn your distractions to things that can benefit you.</p>
<p>How?</p>
<p>Start with cutting off distractions that have too much noise i.e. do not give you a good return of investment on your time in any of the following:</p>
<ul>
<li>Specific knowledge/skills</li>
<li>Specific insight</li>
<li>Accessing and leveraging a network</li>
</ul>
<p>For the ones that remain, optimise the shit out of them.</p>
<p>For me, that meant Instagram was instantly off the list. Twitter and Quora were okay, but I had a long way to go.</p>
<br>
<h3> Optimising your feed </h3>
<p>Social media “feed”.
What comes to your mind when you think of the word - “feed”?</p>
<p>This comes to my mind when I think “feed”</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104541024-c0f65280-5646-11eb-92f6-de5227d4b8a1.png" alt="sheep.jpg"> <i> <small> Sheep, “feed”ing </small>
</i> </p>
<p>Our minds are literally “fed” content.</p>
<p>“We are what we eat” - this doesn’t just stand for physical, tangible food - it applies to the digital content we feed our mind with.</p>
<p>I want you to take this literally because we take our attention for granted. In a digital economy run by monetising attention - it will naturally be full of noise.</p>
<p>Most of the content we read or watch is optimised solely for capturing our attention and clicks. More times than not, you don’t need something that is being shown to you. You will be perfectly fine without knowing it existed. Yep, sounds crazy but it is true.</p>
<p>I’m not trying to say social media is bad. Social media is an amplifier of all there is - of both the good stuff and the bad. It is an amplifier of your primal instincts so if you don’t proactively weed out the bad stuff from your feed regularly, you are going to get sick. Really sick.</p>
<p>What that means is, with some conscious effort you can filter out your feed to keep only the things that benefit you. Here’s how:</p>
<p><strong>Tip #1</strong></p>
<p>Don’t follow brands. Follow people.</p>
<p>I’ll bring the sheep here, again.</p>
<p>When I imagine a brand account, I imagine the shepherd.</p>
<p>And all of the 100-200-500k followers as the sheep.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104541200-1599cd80-5647-11eb-8d7f-f89ae517eb81.png" alt="shepherd.jpg"></p><p>The only reason brand accounts exist is to convince you - in obvious or non-obvious ways - that you need their product in some way or the other. 99-100% of brand accounts posts are pure marketing. You do not need them.
It’s like bombarding your own feed with their ads - full time - <em>with your full consent</em>. Especially so if you are already consuming a brand’s product. Why?!</p>
<p>Who should you follow then?</p>
<p>Follow people. Now, you might argue that people themselves can be brands and you are absolutely right - avoid them too. This goes for popular celebrities, sportspeople, singers etc.
Around half the time, you are probably going to see marketing stuff from them as well. Not all are like that of course, apply your judgement. I respect a lot of celebrities but I don’t follow them because I simply don’t need their opinion in my feed - I couldn’t care any less - they are artists, I liked their art, I liked how they performed but that doesn’t mean I like their opinion nor do I need to listen to them on every single issue there is. At the end of the day, including every celebrity or band or anything in your feed just increases the “distraction” score in your feed.</p>
<p>Okay. Brands are out. Brand people are out. What next?</p>
<p>Follow thinkers. Follow do-ers. Follow people who are creating something.</p>
<p>Some follows I would recommend in no particular order:
<a href="https://twitter.com/naval/" target="_blank" rel="noopener noreferrer"> @naval </a>,
<a href="https://twitter.com/nntaleb/" target="_blank" rel="noopener noreferrer"> @nntaleb </a>,
<a href="https://twitter.com/JamesClear/" target="_blank" rel="noopener noreferrer"> @JamesClear </a>,
<a href="https://twitter.com/Kpaxs/" target="_blank" rel="noopener noreferrer">
@Kpaxs </a>,
<a href="https://twitter.com/ArmaniTalks" target="_blank" rel="noopener noreferrer"> @ArmaniTalks </a> ,
<a href="https://twitter.com/EdLatimore" target="_blank" rel="noopener noreferrer"> @EdLatimore </a>,
<a href="https://twitter.com/galjudo" target="_blank" rel="noopener noreferrer"> @galjudo </a>,
<a href="https://twitter.com/david_perell/" target="_blank" rel="noopener noreferrer"> @David_Perell </a>,</p>
<p>This is a subjective list, of course, but the idea remains the same: when you scroll - scroll to think, not to react. The posts/tweets in your feed should stop and make you think. If they enable <em>only</em> a reaction like rage or anxiety - remove it.</p>
<blockquote><div lang="en" dir="ltr"><p>A simple heuristic to clean your social media feed:</p><p>Scroll to think, not to react</p><p>Reduce content that enables only a reaction. <br>Increase content that stops and makes you think.</p></div>— Akhil (@akhlkg) <a href="https://twitter.com/akhlkg/status/1346891698861862913?ref_src=twsrc%5Etfw">January 6, 2021</a></blockquote> 

<p><strong>Tip #2</strong></p>
<p>When something is trending and it doesn’t really matter to you much, mute all the words/hashtags/etc related to it. The “Explore” section in Twitter is a black hole of distractions. Twitter will try to shove you up with random stuff all the time in your feed - but mute/block/ignore them all - this takes conscious effort but is well worth it.</p>
<p><img src="https://user-images.githubusercontent.com/32199592/104541285-5691e200-5647-11eb-93d6-ed60a6cfa293.png" alt="twet.jpg"></p><p>If it's a trending event you do genuinely care about and you must “react” to it - here’s my two step strategy:</p>
<ol>
<li>
<p><strong>Ignore ‘the first wave’</strong></p>
<p>The first wave is the most emotional one. The purpose of the first wave, knowingly or unknowingly, is to polarise. There is no place for rationality in the first wave of posts, trends, articles, etc. You are likely going to see the same type/flavour of content - over and over from all sorts of people which essentially just convey the same thing in different shades of rage. There is nothing against the stream, yet. Mute ‘em all.</p>
</li>
<li>
<p><strong>Assess the aftermath</strong></p>
<p>Once the first wave is gone and the hashtags die, start looking around. This can be anywhere from 1 week to several months depending on the issue. You are searching for truth, so don’t look at the news - if you’re reading articles online, don’t just look at one publisher, read on the same article by different publishers. Remember, each publishing house has a “flavour” of twisting things. An easy way to cancel the bias out is to read from many publishers and see what remains common. Now analyse the common facts - those are the fundamental facts that supposedly happened and anything above that, is just an opinion.</p>
<p>You can also look if the “thinkers” are reacting. If so, see what they are saying.
It takes effort to get to the truth and navigate through the noise, so I don’t end up doing this a lot of times because I simply didn't care about the event as much as I thought. And it looks like I end up doing okay.</p>
</li>
</ol>
<hr>

<p>That’s about it. In theory, you can apply these principles to any social media platform. I tested and developed these on Twitter but the fundamental idea remains the same: <strong>scroll to think, not to react.</strong></p>
<p>And this fundamental idea helped me a lot. Twitter taught me a lot of things that form a core part of who I am now - staying healthy, strength training, mental models, entrepreneurship, making money online, writing.</p>
<p>You can use your distractions to literally change your life - and I really hope you do!</p></div></div>]]>
            </description>
            <link>https://www.akhilkg.me/blog/distractions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772946</guid>
            <pubDate>Thu, 14 Jan 2021 06:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you want peace, study war]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 192 (<a href="https://news.ycombinator.com/item?id=25772365">thread link</a>) | @ascertain
<br/>
January 13, 2021 | https://www.persuasion.community/p/if-you-want-peace-study-war-533 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/if-you-want-peace-study-war-533">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg&quot;,&quot;height&quot;:960,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1194587,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><strong>“War…What is it good for?” </strong>the classic song asks. Many universities agree on the answer: “Absolutely nothing.”</p><p>Although anthropologists and archeologists still wonder why human beings have for so long organized themselves to fight, the study of war in history and political science departments is fading. Senior scholars are retiring and not being replaced, or their posts are allocated to other fields of history. Each year, fewer courses are offered on great conflicts such as the Napoleonic wars, the total wars of the 20th century, and the Cold War. The Second World War, you may hear on campus, “has been done.”</p><p>Yet war remains one of the events—along with revolution, famine, financial collapse and, as we are learning again, pandemics—that change the course of history. In privileged countries, we forget the importance of military conflicts because we have enjoyed the “Long Peace” that followed the Second World War. Other places have not been so fortunate, with wars around the world almost every year since 1945, bringing millions of deaths and creating millions more refugees. Meanwhile, the world’s great powers maintain large military establishments, and still prepare for battle. </p><p>It is as important as ever to understand war—its causes, nature and consequences—and the many ways that conflicts have shaped our societies. The conquering armies that came from the Arabian Peninsula in the 7th century after the Prophet Mohammad’s death created new empires and spread the new religion of Islam across the Middle East, North Africa and the Iberian Peninsula. The Seven Years’ War (1756-1763), a global conflict, laid the foundations for the dominance of the British Empire and the bankruptcy of France, which helped to fuel the French Revolution.&nbsp; </p><p>War can also speed up advances in science and technology that have benefits in peacetime. Think of the development of penicillin, blood transfusions, radar, or the transistor. And war can bring about significant social change, often for the better. The need for mass armies in the 19th and 20th centuries meant that governments had to treat the lower classes better, whether by educating them or by improving public health. In many countries that fought in the two world wars, ruling classes recognized the contributions of women and the working classes, granting them the franchise and introducing social benefits. </p><p>So why do history faculties, which accept the need to study other great forces in history, such as changes in the means of production or systems of belief, shy from war? I suspect that horror at the phenomenon itself has affected universities’ willingness to treat it as a subject for scholarship. Years ago, when I proposed a new course on war and society, an education consultant asked me, “Why don’t you call it peace studies?” </p><p>I have since met with incomprehension, even hostility, when I have pointed out that wars can bring unintended benefits. However much I say that we would not <em>choose</em> to make war in order to improve our societies, I am charged with loving war. Yet nobody would say that the study of imperialism, racism or famine means that we think those are good things.</p><p><strong>The history of war is neglected for other reasons, too. </strong>First, separate histories—of women, emotions, food and the environment, for example—have come along. Quite rightly, room has been made for them in the big and eclectic house that is the study of the past. However, part of the shift away from war studies owes to the quest for “social justice”—intended as a drive for radical change in society at large—that has taken root in many history faculties. </p><p>Here, for example, is how the chair of Historical and Cultural Studies at the Scarborough campus of the University of Toronto, Natalie Rothman, <a href="https://www.utsc.utoronto.ca/hcs/">welcomed students</a> this autumn: “As a department, we have strengthened our resolve to confront racism, colonialism and Islamophobia throughout our curriculum and in our co-curricular initiatives.” The University of Berkeley in California <a href="https://history.berkeley.edu/graduate/prospective-students/admissions">asks prospective graduate students</a> to provide “evidence of how you have come to understand the barriers faced by others, evidence of your academic service to advance equitable access to higher education for women, racial minorities, and individuals from other groups that have been historically underrepresented in higher education, evidence of your research focusing on underserved populations or related issues of inequality, or evidence of your leadership among such groups.” It is hard to quarrel with such goals, but their impact on curriculum has been to <a href="http://www.nytimes.com/2016/08/29/opinion/why-did-we-stop-teaching-political-history.html?smid=em-share">downgrade subjects such as political and military history,</a> which are seen as too focused on elites and complicit with hierarchy and oppression. </p><p>Another factor is that history overall is worryingly in decline as an academic subject. While it remains popular among publishers and readers, enrollments in history majors are significantly down. They have <a href="https://www.historians.org/publications-and-directories/perspectives-on-history/december-2018/the-history-ba-since-the-great-recession-the-2018-aha-majors-report">dropped more than any other major</a> in the humanities—perhaps by as much as <a href="http://www.chronicle.com/article/why-are-students-ditching-the-history-major">one-third</a> in <a href="https://www.insidehighered.com/news/2018/11/27/new-analysis-history-major-data-says-field-new-low-can-it-be-saved">American universities</a> in the past decade. At the University of Toronto, where I am a professor, colleagues fear that history enrollment may be down as much as 50% over the same period. Even in the United Kingdom, where history remains popular among undergraduates, the number of those majoring in history has dropped by about <a href="https://www.economist.com/britain/2019/07/18/the-study-of-history-is-in-decline-in-britain">one-tenth</a> in the past decade. </p><p>Part of the reason is that, given the lingering effects of the 2008 financial crisis and uncertainty over the economy, students and their parents want university courses to lead to jobs. The decline in history students in turn affects university hiring, and the fewer the tenured faculty, the fewer places for the doctoral students who are the future of the profession.&nbsp; </p><p>Faculties and administrators are not necessarily helping matters, reluctant to include popular courses on war in the curriculum, or to support well-established centers for the study of conflict, some of which are being remodeled, such as the Laurier Centre for Military, Strategic and Disarmament Studies, in Waterloo, Ontario, which will focus more on Canadian history; another at the University of Calgary is fading as those who retire are not replaced. This seems to be particularly true of elite universities. War studies remains in better health at military colleges or some second-tier public universities, while schools of public policy are also still teaching military history, strategic studies and diplomatic history. </p><p>But those in other fields stereotype war studies, characterizing it as too narrowly focused on tactics, battles, or “toys for boys,” meaning armaments. If that caricature were ever true, it has not been for decades. The great historian Sir Michael Howard, who pioneered the modern study of war and trained generations of historians, always insisted that what he was doing was to consider wars within their social and political contexts as a part of the great sweep of history, not somehow separate from it. &nbsp;</p><p><strong>My own evidence of the distaste for military and diplomatic history </strong>at North American universities comes from tales exchanged privately among fellow academics. One retired Canadian military historian recounted that his old faculty had asked him how to reverse the collapse in enrollment. He suggested a course in military history, but the response was a flat no. When a university in the Maritime provinces of eastern Canada was offered a fully funded post in naval history a few years ago—a good fit in a port town that had been deeply affected by conflict on the Atlantic—members of the department rejected it. </p><p>Yet, despite the overall downturn in university history programs, we know from course enrollments that students are interested in war, as indeed they are in international relations, when they get the chance to study them: At Yale, Paul Kennedy’s “Military History of the West” attracted large crowds; at Toronto’s Ryerson University, international relations courses are the most popular choices among students.</p><p>I would not suggest that student preference should determine what departments offer. But they should at least be listened to. Much more important is what we, as societies, want our future leaders to know. Political history, diplomatic history and the study of war—they all offer critical warnings and instructive analogies to our times. Social and cultural histories, and history from the bottom up, add to our understanding too. But we need balance, and a sense of how the micro- and macro-histories mesh with each other. </p><p>Do we really want citizens who have so little knowledge of how war helped to shape our values and societies and our world? Do we ever want another president asking, as Donald Trump <a href="https://www.businessinsider.com/trump-pearl-harbor-memorial-tour-john-kelly-stable-genius-2020-1?r=US&amp;IR=T">did</a> during a visit to the Pearl Harbor memorial: “What’s this all about? What’s this a tour of?” </p><p>If we aren’t aware of how wars happen, we may fail to recognize warning signs when the next conflict brews, as it will. </p><p><strong>Margaret MacMillan is a professor of history at the University of Toronto and emeritus professor at the University of Oxford. Her latest book, </strong><em><strong><a href="https://www.penguinrandomhouse.com/books/609692/war-how-conflict-shaped-us-by-margaret-macmillan/">War: How Conflict Shaped Us</a></strong></em><strong>, was among the </strong><em><strong>New York Times</strong></em><strong> 10 Best Books of 2020. </strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/if-you-want-peace-study-war-533</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772365</guid>
            <pubDate>Thu, 14 Jan 2021 05:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The most thoroughly commented linker script (probably)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25771834">thread link</a>) | @todsacerdoti
<br/>
January 13, 2021 | https://blog.thea.codes/the-most-thoroughly-commented-linker-script/ | <a href="https://web.archive.org/web/*/https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>While developing the firmware for Winterbloom's <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux">Castor &amp; Pollux</a>, I got very curious as to just what the Microchip/Atmel-provided linker script was doing.</p>
<p>If you've never heard of or seen a linker script before you're not alone. Most of us never even have to think about them, however, on memory constained embedded devices it's not uncommon to need to modify the default linker script.</p>
<p>The linker script controls how <code>ld</code> combines all of your <code>.o</code> files into a single <code>.elf</code> and how that resulting <code>.elf</code> file gets loaded by the target processor.</p>
<p>So I was staring at this script that made absolutely no sense to me. It's filled with incantations and mysterious symbols and there's no indication of what they're for or where they come from.</p>
<p>So I did a <strong>lot</strong> of research and now I can present to you <strong>the most thoroughly commented linker script</strong><sup id="fnref:probably"><a href="#fn:probably">1</a></sup>.</p>
<p>You can see this script in its entirety, comments and all, on <a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/blob/master/firmware/scripts/samd21g18a.ld">GitHub</a>. But if you'd like to read it here instead it's transcribed below.</p>
<h2 id="output-format">Output format</h2>
<p>Output format sets the ELF output format to use a specific BFD backend.</p>
<p>The first is the default BFD. The second and third arguments are used
when big (-EB) or little (-EL) endian is requested.</p>
<p>Since the SAM D series are configured with only little endian support,
"elf32-littlearm" is used across the board. This option seems to be
included by Atmel/Microchip out of an abundance of caution, as
arm-none-eabi-ld will do the right thing and use "elf32-littlearm" by
default.</p>
<p>The list of acceptable values can be obtained using <code>objdump -i</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands">https://sourceware.org/binutils/docs/ld/Format-Commands.html#Format-Commands</a></li>
<li><a href="https://sourceware.org/binutils/docs/ld/BFD.html">https://sourceware.org/binutils/docs/ld/BFD.html</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 11.1.11, Cortex M0+ Configuration</li>
</ul>
<pre><span>OUTPUT_FORMAT</span><span>(</span><span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>,</span> <span>"elf32-littlearm"</span><span>)</span>
</pre>
<h2 id="cpu-memory-configuration-variables">CPU memory configuration variables</h2>
<p>These variables are used by the following "MEMORY" command to define
the various memory spaces.</p>
<p>For the SAMD21G18A used by this project, the available Flash is
262kB and the available SRAM is 32kB.</p>
<p>This project also reserves 8kB for the bootloader and 1kB for
"non-volatile memory" (NVM) - which is used by the application
to store calibration and user settings.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>FLASH_SIZE</span> <span>=</span> <span>0x40000</span><span>;</span>      <span>/* 256kB */</span>
<span>BOOTLOADER_SIZE</span> <span>=</span> <span>0x2000</span><span>;</span>  <span>/* 8kB */</span>
<span>NVM_SIZE</span> <span>=</span> <span>0x400</span><span>;</span>          <span>/* 1kbB */</span>
<span>SRAM_SIZE</span> <span>=</span> <span>0x8000</span><span>;</span>        <span>/* 32kB */</span>
</pre>
<p>ARM Cortex-M processors use a descending stack and generally
require stack space to be set aside in RAM.</p>
<p>The application's behavior determines just how much stack space
should be reserved. I generally start with 2kB (0x800) of
stack space for Cortex-M0+ projects programmed in C .</p>
<p>You can analyze stack usage in GCC using the <code>-fstack-usage</code>
flag and you can enable compiler warnings for stack usage
with <code>-Wstack-usage=STACK_SIZE</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/">https://embeddedartistry.com/blog/2020/08/17/three-gcc-flags-for-analyzing-memory-usage/</a></li>
<li><a href="https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications">https://community.arm.com/developer/ip-products/processors/b/processors-ip-blog/posts/how-much-stack-memory-do-i-need-for-my-arm-cortex--m-applications</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html">https://gcc.gnu.org/onlinedocs/gnat_ugn/Static-Stack-Usage-Analysis.html</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html">https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html</a></li>
</ul>
<pre><span>STACK_SIZE</span> <span>=</span> <span>DEFINED</span><span>(</span><span>__stack_size__</span><span>)</span> <span>?</span> <span>__stack_size__</span> <span>:</span> <span>0x800</span><span>;</span>
</pre>
<h2 id="memory-space-definition">Memory space definition</h2>
<p>This section declare blocks of memories for specific purposes. Since an
ARM's address space is generally split between Flash, SRAM, peripherals,
and other regions, it's necessary to tell the linker where different
types of data can go in the address space.</p>
<p>These blocks will be used in the <code>SECTIONS</code> command below.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY">https://sourceware.org/binutils/docs/ld/MEMORY.html#MEMORY</a></li>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
    Section 10.2, Physical Memory Map</li>
</ul>
<pre><span>MEMORY</span>
<span>{</span>
</pre>
<p>Start with the Flash memory region. On the SAMD21, Flash starts at
the beginning of the address space (<code>0x00000000</code>) and is contiguous
right up to the size of the Flash. Flash is marked a <code>rx</code> so
that the linker knows that this space is read-only (<code>r</code>) and
executable (<code>x</code>).</p>
<p>The "bootloader" section allows this firmware to work with the uf2
bootloader. The bootloader takes the first 0x2000 bytes of flash
memory.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/adafruit/uf2-samdx1#configuration">https://github.com/adafruit/uf2-samdx1#configuration</a></li>
</ul>
<pre>    <span>bootloader</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>BOOTLOADER_SIZE</span>
</pre>
<p>Following the bootloader is the flash memory used by the application,
called "rom" here - even though it's flash, the name is just a name
and doesn't carry special meaning.</p>
<p>The total length of the rom block is the MCU's flash size minus the
bootloader's size and any space reserved for "non-volatile memory"
by the application.</p>
<pre>   <span>rom</span> <span>(</span><span>rx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x00002000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>BOOTLOADER_SIZE</span> <span>-</span> <span>NVM_SIZE</span>
</pre>
<p>The "nvm" block is space set aside for the application to store
user settings and calibration data in the MCU's flash.</p>
<p>The block is located right at the end of the flash space. This
is useful because it means that it says in a fixed location
regardless of how much flash space the application takes up
in "rom". Explicitly defining this section also lets the
linker ensure that application code doesn't overwrite the
data in this region.</p>
<p>This block is marked as read-only (<code>r</code>) because flash can not
be written in the same way as normal memory, however, the
application can use the SAMD's NVM peripheral to write data in
this region.</p>
<pre>   <span>nvm</span> <span>(</span><span>r</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>FLASH_SIZE</span> <span>-</span> <span>NVM_SIZE</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>NVM_SIZE</span>
</pre>
<p>The "ram" block is mapped to the CPU's SRAM and it's where
the stack, heap, and all variables will go.</p>
<p>For the SAMD21, SRAM starts at 0x20000000 and is contiguous
for the size of the SRAM.</p>
<pre>   <span>ram</span> <span>(</span><span>rwx</span><span>)</span> <span>:</span> <span>ORIGIN</span> <span>=</span> <span>0x20000000</span><span>,</span> <span>LENGTH</span> <span>=</span> <span>SRAM_SIZE</span>
<span>}</span>
</pre>
<h2 id="sections">Sections</h2>
<p>The sections command tells the linker how to combine the
input files into an output ELF and where segments belong
in memory.</p>
<p>The linker takes a set of input files containing the "input
sections" and uses this to map them to "output sections"
which are placed in the output ELF file.</p>
<p>While the most important sections to think about here
are the ones that'll be placed into the memory (segments)
some sections are just placed in the output ELF for debugging.</p>
<p>References:</p>
<ul>
<li><a href="https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS">https://sourceware.org/binutils/docs/ld/SECTIONS.html#SECTIONS</a></li>
</ul>
<pre><span>SECTIONS</span>
<span>{</span>
</pre>
<p>The text segment contains program code and read-only data.</p>
<p>References:</p>
<ul>
<li><a href="https://developer.arm.com/documentation/dui0101/a/">https://developer.arm.com/documentation/dui0101/a/</a>
Page 5, Segments</li>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
</ul>
<pre>   <span>.</span><span>text</span> <span>:</span>
   <span>{</span>
</pre>
<p>This segment must be 4-byte aligned as defined in ARM ELF
File Format specification.</p>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
</pre>
<p>The vector table defines the initial stack pointer and
interrupt/exception routines for the ARM CPU and device
peripherals. Every Cortex-M project needs this.</p>
<p>For the SAM D series the vector table is expected
to be at address 0x00000000 after reset. Since
flash memory starts at 0x00000000, the first values
in flash should be the vector table.</p>
<p>When defining the vector table in code you must use
<code>__attribute__ ((section(".vectors")))</code> to tell
GCC to place the vector table into the section
named ".vectors" in the input object file so that
the linker can find it.</p>
<p>Note that since this project uses the UF2 bootloader,
this actually gets placed at the beginning of the
program's flash area (0x2000). The Cortex-M allows
changing the vector table after initialization,
so the startup script sets the Vector Table Offset
Register (<code>SCB-&gt;VTOR</code>) to <code>_sfixed</code> during its
intialization. The <code>_efixed</code> symbol is unused but
included for completeness.</p>
<p>References:</p>
<ul>
<li><a href="https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf">https://ww1.microchip.com/downloads/en/DeviceDoc/SAM_D21_DA1_Family_DataSheet_DS40001882F.pdf</a>
Secion 8.3.3, Fetching of Initial Instructions</li>
<li><a href="https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf">https://static.docs.arm.com/ddi0403/eb/DDI0403E_B_armv7m_arm.pdf</a>
Section B1.5.3, The vector table
Section B3.2.5, Vector Table Offset Register, VTOR</li>
<li><a href="https://github.com/theacodes/Winterbloom_Castor_and_Pollux/tree/master/firmware/third_party/samd21/gcc/gcc/startup_samd21.c">startup_samd21.c</a></li>
</ul>
<pre>      <span>_sfixed</span> <span>=</span> <span>.;</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>vectors</span> <span>.</span><span>vectors</span><span>.</span><span>*</span><span>))</span>
</pre>
<p>Include code and read-only data sections from all
input files.</p>
<p>By default, GCC places all program code into a section named
".text" and read-only data (such as const static variables) into
a section named ".rodata" in the input object files. This naming
convention is from the ELF ABI specification.</p>
<p>GCC generates three "flavors" of sections in object files:</p>
<ul>
<li><code>.{section}</code>: the basic section.</li>
<li><code>.{section}.*</code>: sections generated by <code>-ffunction-sections</code> and
<code>-fdata-sections</code> so that each function/data has a unique
section.</li>
<li><code>.gnu.linkonce.{type}.*</code>: sections generated by GCC so the
linker can remove duplicates. Seems to be related to
Vague Linking.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections">http://www.sco.com/developers/gabi/latest/ch4.sheader.html#special_sections</a></li>
<li><a href="https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html">https://gcc.gnu.org/onlinedocs/gcc/Vague-Linkage.html</a></li>
<li><a href="https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section">https://stackoverflow.com/questions/5518083/what-is-a-linkonce-section</a></li>
</ul>
<pre>      <span>*</span><span>(.</span><span>text</span> <span>.</span><span>text</span><span>.</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>t</span><span>.</span><span>*</span><span>)</span>
      <span>*</span><span>(.</span><span>rodata</span> <span>.</span><span>rodata</span><span>*</span> <span>.</span><span>gnu</span><span>.</span><span>linkonce</span><span>.</span><span>r</span><span>.</span><span>*</span><span>)</span>
</pre>
<h2 id="c-c-runtime-support">C &amp; C++ runtime support</h2>
<p>The following sections are for the C/C++ runtime. These are generally used by crt0.</p>
<p>References:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Crt0">https://en.wikipedia.org/wiki/Crt0</a></li>
</ul>
<h3 id="initializers">Initializers</h3>
<ul>
<li>C++ Runtime: initializers for static variables.</li>
<li>C Runtime: designated constructors</li>
</ul>
<p>For C++, handles variables at file scope like this:</p>
<pre><span>int</span> <span>f</span> <span>=</span> <span>some_func</span><span>()</span>
</pre>
<p>For C, handles functions designated as constructors:</p>
<pre><code>void intialize_thing(void) __attribute__((constructor));
</code></pre>
<p>Executed by the C runtime at startup via <code>__libc_init_array</code>.</p>
<p>References:</p>
<ul>
<li><a href="https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c">https://github.com/gcc-mirror/gcc/blob/master/libgcc/crtstuff.c</a></li>
<li><a href="https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c">https://sourceware.org/git/?p=newlib-cygwin.git;a=blob;f=newlib/libc/misc/init.c</a>;</li>
<li><a href="https://gcc.gnu.org/onlinedocs/gccint/Initialization.html">https://gcc.gnu.org/onlinedocs/gccint/Initialization.html</a></li>
<li><a href="https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction">https://developer.arm.com/documentation/dui0475/h/the-arm-c-and-c---libraries/c---initialization--construction-and-destruction</a></li>
<li><a href="https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array">https://stackoverflow.com/questions/15265295/understanding-the-libc-init-array</a></li>
</ul>
<pre>      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
      <span>KEEP</span><span>(</span><span>*</span><span>(.</span><span>init</span><span>))</span>
      <span>.</span> <span>=</span> <span>ALIGN</span><span>(</span><span>4</span><span>);</span>
  …</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.thea.codes/the-most-thoroughly-commented-linker-script/">https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</a></em></p>]]>
            </description>
            <link>https://blog.thea.codes/the-most-thoroughly-commented-linker-script/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771834</guid>
            <pubDate>Thu, 14 Jan 2021 04:05:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Family Moves from Shed to Apartment, Thanks to 8 Year Old's Plant Business]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25771412">thread link</a>) | @danhodgins
<br/>
January 13, 2021 | http://thesassyplant.com/16-family-moves-from-shed-to-apartment-thanks-to-8-year-olds-plant-business | <a href="https://web.archive.org/web/*/http://thesassyplant.com/16-family-moves-from-shed-to-apartment-thanks-to-8-year-olds-plant-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://thesassyplant.com/16-family-moves-from-shed-to-apartment-thanks-to-8-year-olds-plant-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-25771412</guid>
            <pubDate>Thu, 14 Jan 2021 03:15:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Only M1 Benchmark That Matters]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25769469">thread link</a>) | @nemoniac
<br/>
January 13, 2021 | https://lars.ingebrigtsen.no/2021/01/13/the-only-m1-benchmark-that-matters/ | <a href="https://web.archive.org/web/*/https://lars.ingebrigtsen.no/2021/01/13/the-only-m1-benchmark-that-matters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-79875">
	
	<!-- .entry-header -->

	<div>
		<p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169.jpg"><img loading="lazy" src="https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169-scaled.jpg" alt="" width="840" height="558" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169-300x199.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169-1024x681.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169-768x511.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169-1536x1021.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02169-2048x1362.jpg 2048w" sizes="(max-width: 840px) 100vw, 840px"></a></p>
<p>I’ve got a new Apple laptop, so I thought I’d do an Emacs build benchmark.  Building Emacs is what people do on computers, right?  At least if I extrapolate from myself, which is the only natural thing to do.</p>
<p>It’s called proof by induction.  Look it up, nerds.</p>
<p>So here’s the benchmarks:</p>
<table>
<tbody><tr>
<td>My Main Build Machine</td>
<td>AMD Ryzen 7 3700X (8 Core/16 Threads)</td>
<td>2m14s</td>
<td>7m31</td>
</tr>
<tr>
<td>My Lenovo Carbon X1 Laptop</td>
<td>Intel(R) Core(TM) i7-10610U CPU (4 Core/4 Threads)</td>
<td>6m22s</td>
<td>15m22</td>
</tr>
<tr>
<td>My Old Apple Laptop</td>
<td>Intel(R) Core(TM) i5-7360U CPU (2 Core/4 Threads)</td>
<td>7m13s</td>
<td>12m33</td>
</tr>
<tr>
<td>My New M1 Apple Laptop</td>
<td>Apple M1 (4-to-8-ish Cores)</td>
<td>2m44s</td>
<td>6m37s</td>
</tr>
</tbody></table>
<p>The next-to-last column is with -jTO-THE-MAX, and the last column is with -j1.</p>
<p>I’m impressed!  The M1 is able to build Emacs almost as fast as my AMD machine…  which is a lot bigger.</p>
<p>Of course, on Debian I’m using gcc and on Macos I’m using clang, so it’s an apples-to-some-different-brand-of-apples comparison.</p>
<p>It’s even more impressive how much faster this laptop is compared to the Apple laptop from…  2019?  Yeah.  It’s more than twice as fast!  And doesn’t have a fan!  The old Apple laptop would sound like a VAX in a hurricane while building Emacs!</p>
<p>And it’s also twice as fast as the laptop I use daily here on the couch; last year’s Lenovo Carbon X1, which is just embarrassing.  Lenovo!  Get on it!  Make an ARM laptop that’s fast!</p>
<p>For the first time in my life, I have Apple envy.  That is, for the first time ever, they’ve made a laptop that’s clearly superior to what’s available for us Linux peeps.  My only comfort is that the Apple keyboard still sucks.  Yeah!  And it doesn’t have a TrackPoint!  Yeah!  My laptop is still the best!  Yeah!  Take that!</p>
<p><a href="https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170.jpg"><img loading="lazy" src="https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170-scaled.jpg" alt="" width="840" height="558" srcset="https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170-scaled.jpg 2560w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170-300x199.jpg 300w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170-1024x681.jpg 1024w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170-768x511.jpg 768w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170-1536x1021.jpg 1536w, https://lars.ingebrigtsen.no/wp-content/uploads/2021/01/DSC02170-2048x1362.jpg 2048w" sizes="(max-width: 840px) 100vw, 840px"></a></p>
<p>Yeah!  I’m not the least envious!</p>
<p>*sniff*</p>
<p>Edit some hours later:</p>
<p>But one thing that would be interesting to look at is Emacs performance on M1 vs the other machines.  And a way to broadly look at that is to see how long it takes to byte-compile a bunch of Emacs Lisp files: This exercises much of Emacs, except display-related stuff.</p>
<p>So:  Benchmarking with</p>
<pre>rm `find lisp -name '*.elc'`; time make -jMAX</pre>
<p>I get:</p>
<table>
<tbody><tr>
<td>My Main Build Machine</td>
<td>AMD Ryzen 7 3700X (8 Core/16 Threads)</td>
<td>0m57s</td>
</tr>
<tr>
<td>My Lenovo Carbon X1 Laptop</td>
<td>Intel(R) Core(TM) i7-10610U CPU (4 Core/4 Threads)</td>
<td>4m13s</td>
</tr>
<tr>
<td>My Old Apple Laptop</td>
<td>Intel(R) Core(TM) i5-7360U CPU (2 Core/4 Threads)</td>
<td>5m33s</td>
</tr>
<tr>
<td>My New M1 Apple Laptop</td>
<td>Apple M1 (4-to-8-ish Cores)</td>
<td>1m33s</td>
</tr>
</tbody></table>
<p>Here the AMD clearly wins over the ARM, but per-core performance is in advantage of the ARM.  And, of course, the ARM soundly wins over both of the other two laptops.</p>

	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]>
            </description>
            <link>https://lars.ingebrigtsen.no/2021/01/13/the-only-m1-benchmark-that-matters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25769469</guid>
            <pubDate>Wed, 13 Jan 2021 23:27:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Negotiating Is Just Like Doing Squats]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25769397">thread link</a>) | @montreal_prof
<br/>
January 13, 2021 | https://reyt.net/blog/why-negotiating-is-just-like-doing-squats/ | <a href="https://web.archive.org/web/*/https://reyt.net/blog/why-negotiating-is-just-like-doing-squats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article id="post-1749"><div><p>Let me share a short story. I used to hate doing squats at the gym. I would make good progress in every strength-training exercise except for the squat. My posture felt wrong, I had a hard time coordinating my movements, and my numbers would never improve. It was embarrassing, really. I ended up thinking of doing squats as something complicated, frustrating, and potentially dangerous; something I was better off avoiding altogether.</p><p>How do I feel about doing squats now? It’s become my #1 favorite strength-training exercise. Who changed my mind? A great personal trainer I met a few years ago who still trains me to this day. He taught me the right technique, helped me strengthen my weak spots while keeping the entire process challenging and motivating. He completely changed my perspective on squats. Now, I think they’re fun!</p><p>I have met many students over the years who saw negotiation just like I used to see squats: something hard and risky, something to avoid. Most people&nbsp;<em>want</em>&nbsp;to negotiate because they know that it’s the only way to obtain desirable outcomes. Their issue is they haven’t acquired the knowledge and developed the right skills to negotiate well enough yet to obtain these outcomes.</p><p>My goal is to help you acquire these skills. My approach to negotiation training is based on three tenets.</p><h3><strong>You can’t get stronger unless you learn the proper technique</strong></h3><p>A lot of people who claim to be great negotiators often mean that they are great at haggling. When people haggle, all they do is make price concessions until the other party agrees. It’s not hard, and it’s something you can learn quickly by mimicking others. Negotiation is a complex process designed to increase value and resolve conflicts. There are many ways one can screw up a negotiation.</p><p>To be a good negotiator, you need to know how to make the right decisions. Nobody was born knowing how to prepare for a negotiation, how to craft a first offer, or how to deal with negotiators who lie; these are learnt behaviors. Sure, you could rely on your intuition and figure things out on your own, but why would you try to reinvent the wheel when we already have established methods available?</p><p>For this reason, my next few emails will focus on proven methods and techniques to help you approach the main steps of a negotiation.</p><h3><strong>You can’t excel at everything, but you can mitigate your risks</strong></h3><p>Negotiation mobilizes so many different cognitive and interpersonal skills that it would be unreasonable to expect excelling at all of them. Nobody is THAT good. Negotiating is a stress test on your entire system, which means that you are only as strong as your weakest element.</p><p>Maybe you are too focused on making your counterpart happy, and you often leave the negotiation table having regrets about your own outcome. Maybe you have the opposite problem and you only see a negotiation as successful if you completely crush the other party. Now, nobody wants to negotiate with you anymore. It could be many things, but there are usual suspects and there are ways to deal with them.</p><p>You can’t completely fix your weaknesses, but you can use strategies to work around them. This will be the second phase of our negotiation training.</p><h3><strong>Becoming a good negotiator is a long-term commitment</strong></h3><p>Just like everything in life that has to do with human performance, negotiation training strictly follows the law of diminishing returns. This comes with good news and bad news.</p><p>The good news is that if you apply yourself to improving your negotiation skills, you will make progress very quickly in the beginning. This is a phase that people often find exhilarating because they feel like they have finally unlocked their potential.</p><p>The bad news is that the further you go in your negotiation training, the harder it will be for you to make new gains. You won’t be able to get by just by following basic rules anymore; it will be time to refine your skills. You will need to be exposed to increasingly complex negotiation situations, with incentives to keep you engaged and motivated throughout the process.</p><p>For this reason, my plan is to maintain this newsletter in the long-term, with fresh perspectives and different opportunities to engage.</p><h2>Do You Want to Improve Your Negotiation Skills?</h2><p>Sign-up using the form below. Not ready to commit yet? Read more about my <a href="http://reyt.net/newsletter">newsletter</a>.</p></div></article></div></div>]]>
            </description>
            <link>https://reyt.net/blog/why-negotiating-is-just-like-doing-squats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25769397</guid>
            <pubDate>Wed, 13 Jan 2021 23:19:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I’ve changed my mind on Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25768679">thread link</a>) | @davefreiburger
<br/>
January 13, 2021 | https://gradually.co/why-bitcoin-is-changing-the-mind-of-investors/ | <a href="https://web.archive.org/web/*/https://gradually.co/why-bitcoin-is-changing-the-mind-of-investors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

																					<div>
								<p><a href="https://en.bitcoin.it/wiki/Promotional_graphics" target="_blank">
									[Image source: Bitcoin Wiki]								</a></p><h5>
									<a href="https://ofdollarsanddata.com/why-ive-changed-my-mind-on-bitcoin/" target="_blank">
										Why I’ve Changed My Mind on Bitcoin									</a>
									 &nbsp;by Nick Maggiulli									<br>
								</h5>
								
								<p>
									Takeaways
								</p>
								<div>
									<p><i><span>I highly suggest consuming the full piece </span></i><a href="https://ofdollarsanddata.com/why-ive-changed-my-mind-on-bitcoin/"><i><span>here</span></i></a><span> (</span><i><span>7 min. read time</span></i><span>)</span></p>
<p><span>“As Paulo Coelho wrote in </span><a href="https://www.goodreads.com/book/show/18144590-the-alchemist?ac=1&amp;from_search=true&amp;qid=K3Q9uLgqQp&amp;rank=1"><i><span>The Alchemist</span></i></a><span>: Everything that happens once can never happen again. But everything that happens twice will surely happen a third time,” Nick references.</span></p>
<p><span>“What the Bitcoin bulls were right about was increased adoption and the ability of many Bitcoin owners to hold (‘</span><a href="https://www.urbandictionary.com/define.php?term=hodl"><span>HODL</span></a><span>’) even as prices rose dramatically. These two effects (more demand from buyers and reduced supply from sellers) have helped to boost Bitcoin’s price and cement it as a legitimate asset class within the investment community.” — Nick Maggiulli</span></p>
<p><span>People who were skeptical of Bitcoin before its recent price surge, told themselves that they’d buy Bitcoin if it dropped to the $1,000-$2,000 range. This range keeps going up for the skeptics. “…every time the price goes up in the future, these ‘mental buy limits’ go up as well, increasing the likelihood of Bitcoin’s future survival,” Nick explains.</span></p>
<p><span>“…both the price of gold and the price Bitcoin are based around one thing and one thing alone—belief. The belief that these assets will have value in the future.” — Nick Maggiulli</span></p>
<p><span>Nick compares Bitcoin to the early years of the ability to invest in gold. “Though Bitcoin is unlikely to follow a similar path to gold, it is likely to exhibit similar behavior. This means that Bitcoin will continue to have huge run ups in price followed by violent crashes. Crashes that may last years (and possibly decades) in the future.” — Nick Maggiulli</span></p>
<p><span>“…if Bitcoin’s market capitalization were to match that of gold, it would be worth over $500,000 a coin. This is why some investors are so bullish on Bitcoin.” — Nick Maggiulli</span></p>
								</div>
								<p><img src="https://gradually.co/wp-content/themes/gradually/img/two-cents.png">
								</p><!-- end half sqaure arrow -->
								<p><b><i>My two cents</i></b><span>: That last fact is pretty mind-blowing. As an investor, the question becomes will Bitcoin ever reach the same market capitalization as gold? Nobody knows the answer to that question, but choosing to invest in Bitcoin means you’re willing to find out. I’m willing to find out. Albeit, I barely put any money in, although many people don’t realize you don’t have to buy 1 whole Bitcoin to invest. You’re able to buy $100 worth or whatever amount you’re comfortable with and still “own Bitcoin.” You’d just be a partial owner alongside tons of other partial owners. </span></p>
								<p>
								<span>Share</span> (if you're an OG)  &nbsp;  <span></span><span><span>
									</span><span>


							</span></span></p></div><!-- end newsletter wrap content -->
													
						</div></div>]]>
            </description>
            <link>https://gradually.co/why-bitcoin-is-changing-the-mind-of-investors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25768679</guid>
            <pubDate>Wed, 13 Jan 2021 22:14:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Insurrection as a Service]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25768041">thread link</a>) | @Reedx
<br/>
January 13, 2021 | https://www.piratewires.com/p/insurrection-as-a-service | <a href="https://web.archive.org/web/*/https://www.piratewires.com/p/insurrection-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Ctrl + Alt + Delete the President.</strong> Last week, <a href="https://www.nytimes.com/live/2021/01/07/us/capitol-building-trump">after a violent riot at the capital</a>, Twitter and Facebook <a href="https://www.nytimes.com/2021/01/09/technology/trump-twitter-ban.html">erased the President of the United States from social media</a>. He was further banned from, or severely restricted from communicating by: <a href="https://www.axios.com/platforms-social-media-ban-restrict-trump-d9e44f3c-8366-4ba9-a8a1-7f3114f920f1.html">Reddit, Twitch, Shopify (??), Snapchat, TikTok, and Stripe.</a> Within 24 hours, amidst a chorus of “it’s just the free market, losers, if you don’t like it build your own app,” Google and Apple worked in concert to remove Parler, the “free speech” alternative social media app popular on the political right, from their app stores. Amazon followed the move with the equivalent of tech industry napalm, taking the extraordinary step of suspending Parler from using Amazon Web Services, effectively shutting the company down. The loosely-framed charge against both Trump and Parler was incitement of violence and insurrection. There were no trials. There was no evidence presented for any crime formally argued. This is law in the age of corporate oligarchy. It is purposefully ambiguous, it is uncompromising, and when you run afoul of the powers that be, there is no recourse. Not even for the “most powerful man in the world.” </p><p>This of course begs the question: who is actually in charge right now? </p><p>Today, the internet is a life-critical layer of our world. In some sense, what happens on the internet —&nbsp;from payments to communication —&nbsp;is all that matters, as without it few things of significance in the “real world” are possible. You would be forgiven for not remembering that Trump was impeached last year, as it meant practically nothing. But erasing him from the internet? If this sticks, and Trump can no longer communicate or raise funds at scale, a small handful of unelected tech executives just ended a president’s political career. In theory, they can legally do this to anyone, which means they are effectively the most powerful people alive. <a href="https://www.washingtonpost.com/opinions/how-should-we-address-the-growing-power-shift-from-washington-to-silicon-valley/2018/11/19/1470eb9a-e9e4-11e8-bbdb-72fdbf9d4fed_story.html">Silicon Valley is our nation’s shadow capital, argues Katherine Boyle,</a> and welcome to the shadow state. It is not a democracy. </p><p>The immediate arguments both in favor and against Trump’s censorship were equally ridiculous. From the camp against, we were told the technology industry’s actions were comparable to Chinese-style censorship. This is not even close to true. The Chinese Communist Party executes political dissidents, and while our nation is not immune to such governance, and many Americans do perversely seem to want CCP-style censorship, such dystopia has not yet descended on our country. As Dan Primack correctly notes: &nbsp;</p><p>From the camp in favor of vanishing Trump — people who have warned us of some ambiguous corporate overreach for decades, which I suppose in hindsight only ever meant “money people bad” —&nbsp;we were told this is simply what a free market looks like. Free speech cannot be constitutionally guaranteed where private corporations are concerned, as it infringes on the owner of a company’s rights to free association and speech (again, an interesting point of concern from the “business is always wrong” corner of the commentariat). If you don’t want to be vanished, we’re told, build your own sprawling, multibillion-dollar, duopolistic communications platform. But legally speaking, this is in the first place not straightforward. </p><p>In <em>Pruneyard Shopping Center Vs. Robins</em>, <a href="https://www.mtsu.edu/first-amendment/article/583/pruneyard-shopping-center-v-robins#:~:text=Robins%20(1980)&amp;text=In%20PruneYard%20Shopping%20Center%20v,afoul%20of%20the%20Fifth%20Amendment">the Supreme Court ruled California could protect political protesters from being evicted from private property.</a> This case built on a body of law that flourished throughout the 60s and 70s, and included such cases as <em>Marsh v. Alabama</em> (1946), <em>Lloyd Corporation Ltd. v. Tanner</em> (1972), and <em>Amalgamated Food Employees Union Local 590 v. Logan Valley Plaza</em> (1968). We haven’t even touched the <em>Sherman Antitrust Act</em>, or the much-discussed <em>Section 230</em>, and this is already complicated. In any case, the notion one should simply build a competitor platform if he isn’t happy with his Twitter ban has never really been serious, as everyone who works in tech is well aware it isn’t possible to build such a platform absent ideological submission to the shadow state. This was plainly evidenced by Parler’s fate last week. </p><p>If a natural right can’t meaningfully be exercised, can it really be said to exist? David Sacks has been absolute fire on this question all week:</p><p>The American Bill of Rights was written at the time of the printing press, a machine that anyone could buy, the street corner, on which anyone could sell a paper, a system of public roads and walks for distribution, and thousands of small businesses that comprised the “market,” any one of which, absolutely, could refuse to sell a paper, but no one or two (or five in obvious collusion) were capable of censoring a single voice out of public existence. Today, the internet is the gateway through which almost our entire democracy is conducted. It is where we go to learn about the world, almost without exception. It is our contemporary printing press, our street corner, our public roads and walks, and our market, all combined and dominated by a small handful of giants from the same class, of roughly the same politics, and from mostly the same region. </p><p>Should this tiny, unelected group of people so-empowered be allowed to vanish any voice from public, for any reason? Is this truly in keeping with the spirit of the Constitution? Separate from the legal questions: is this the kind of country you want to live in? </p><p>We are in danger, here —&nbsp;clearly, come on,<em> you know that this is true</em> —&nbsp;of something very dark. </p><p><strong>Ok but insurrection though.</strong> I recently spoke with a tech executive who supported Trump’s ban from public existence. He asked what theoretical action I would think worthy of such incredible censorship from the industry. A coup? Insurrection? What about incitement of violence? Herein lies tech’s only reasonable defense of itself, and the most popular argument in favor of Trump’s purge from the internet: he was hurting people. Isn’t that enough to act? The problem is the evidence here is ambiguous, and the argument lends itself to valid accusations of hypocrisy, as all of these things have been perpetrated by other political leaders, both at home and abroad, and often in a manner not ambiguous at all. The position is also somewhat naively oblivious of a political leader’s role, which is —&nbsp;I hate to break it to you, folks —&nbsp;violence. This is not to say violence is okay. This is not to excuse any of Trump’s deeply unhelpful ambiguity. This is only to say the logical consequence of the technology industry’s extraordinary actions last week must necessarily be massive, global censorship. Let’s set aside for a moment the question of whether or not censorship of this kind would be healthy. Is it really what our shadow state is planning? Because if dramatically accelerated speech crackdowns aren’t on the menu, tech’s actions sum only to narrow, draconian, partisan censorship. </p><p>It should go without saying I’m against activist political violence, and think everyone who participated in last week’s riot at the capitol should be tried and, when convicted, jailed. But I’ve said it anyway, repeatedly, both specifically in the context of the capitol riot and consistently, in every other context we’ve seen such behavior, throughout most of our batshit crazy 2020. I have felt compelled to speak about this issue as often as I have because what took place in Washington last week was not an outlier event. </p><p>The capitol riot was the latest in a string of unacceptably violent outbursts for which media personalities, activists, and politicians have spent the last year apologizing, and in many cases, by the standards to which we are now holding Trump —&nbsp;“dog whistles,” contributions to a “culture of hate” or “violence” —&nbsp;actively encouraging. Some cases have been less ambiguous. “Non-violence is an important tool for protests,” wrote Slate magazine this summer amidst a kind of chaos we have not seen on American streets for over half a century, <a href="https://twitter.com/Slate/status/1268415955937513473?s=20">“but so is violence.”</a> People were killed at the capitol, and property, both public and private, was destroyed. A federal building was invaded. All of these things are insane, and wrong, and intolerable. They are also illegal. Again: <em>these people should be tried, and when convicted sent to prison</em>. But have we so soon forgotten <a href="https://www.wsj.com/articles/goodbye-summer-of-love-11607898398">our summer of love in the CHAZ</a>? Or do we simply believe the MAGA Viking more likely to succeed in “insurrection” than the unhinged Stalinist baristas in Seattle explicitly calling for revolution? </p><p>I’ve been told repeatedly this week, while raising questions about a scale of censorship we have literally never before seen, that at least one of the capitol rioters was planning an assassination. This is chilling. If proven true, it will unfortunately also not be unique. Have we already memory-holed the Republican Congressional baseball shooting, where Congressman Steve Scalise and three of his colleagues were nearly killed by an unhinged Bernie Sanders stan? And how do we think this would-be assassin was radicalized? Carrier pigeon? No, the internet appears to be catalyzing significant political radicalization. The problem is deep, and broad. It is also by the way something <a href="https://www.piratewires.com/p/tether-part-i">I write about not infrequently.</a> I’m glad the industry is finally concerned with the phenomenon, but is Jack Dorsey really prepared to own the issue? Because I’m sorry, but the problem isn’t Trump’s Twitter account, no matter how easy that would make this —&nbsp;in a sense, the problem appears to be Twitter. I’m pretty sure it’s driving us insane. </p><p>Gather round, friends. Have I told you yet about the time (this Christmas Eve) when a wildly-popular Marxist podcaster expressed a desire to see me dead in direct response to a piece I wrote about his fiancé’s boss, my San Francisco district supervisor? What about the time, immediately after, when his followers asked for my address, presumably to kill me? Do yourself a favor and keyword search the word “guillotine,” or the hammer and sickle emoji (which, while we’re on the topic, why the fuck does that exist?). Here’s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.piratewires.com/p/insurrection-as-a-service">https://www.piratewires.com/p/insurrection-as-a-service</a></em></p>]]>
            </description>
            <link>https://www.piratewires.com/p/insurrection-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25768041</guid>
            <pubDate>Wed, 13 Jan 2021 21:13:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowpack v3.0]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25767819">thread link</a>) | @theBashShell
<br/>
January 13, 2021 | https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0 | <a href="https://web.archive.org/web/*/https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
      <p>Snowpack v3.0 is here! This is our biggest release yet with brand new features including:</p>
<ul>
<li><strong>Pre-bundled streaming imports</strong> - Import any npm package, on-demand.</li>
<li><strong>Integrated build optimizations</strong> - Built-in bundling, preloading, minification, and more.</li>
<li><strong>JavaScript API</strong> - Integrate with Snowpack’s brand new native JS API.</li>
<li><strong>Node.js Runtime API</strong> - Import your Snowpack-built files directly into Node.js.</li>
<li><strong>Bug fixes, stability improvements, and a whole lot more!</strong></li>
</ul>
<p>Install the newest version of Snowpack to get started:</p>
<pre><code>$ npm install snowpack@^3.0.0
</code></pre>
<p>Or, try out one of our updated <a href="https://www.npmjs.com/package/create-snowpack-app">Create Snowpack App</a> starter templates:</p>
<pre><code>$ npx create-snowpack-app new-project-directory --template  @snowpack/app-template-react
</code></pre>
<h2 id="reimagining-web-development-for-esm">Reimagining Web Development for ESM</h2>
<p>1 year ago, Snowpack first released with the mission to reimagine web development for modern JavaScript and ESM. Snowpack leverages modern web features to deliver a frontend build tool that needs just 50ms to start up &amp; react to new file changes, regardless of project size. In comparison, traditional web bundlers could take several seconds or even full minutes to start up in large projects.</p>
<p>Snowpack v3.0 marks another huge leap on our mission to push web development forward with the release of <strong>streaming imports</strong>. Streaming imports make it possible to import any package directly into your project, pre-built and pre-bundled for immediate use. It’s the power of the entire JavaScript ecosystem, at your fingertips.</p>
<video preload="auto" autoplay="" loop="" muted="" playsinline="">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.webm" type="video/webm">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.mp4" type="video/mp4">
</video>
<h2 id="what-are-streaming-imports%3F">What are Streaming Imports?</h2>
<p>The typical web developer installs and manages their JavaScript dependencies locally using a package manager CLI like <code>npm</code>, <code>yarn</code> or <code>pnpm</code>. These npm packages can’t run directly in the browser, so additional work is needed to resolve, process, build and bundle these packages for the browser before you can actually use them.</p>
<p><strong>What if we could simplify this? What if you could skip the “npm install” step entirely and just fetch the relevant, pre-built package code on-demand via ESM import?</strong></p>
<pre><code><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'react'</span><span>;</span><p><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'https://cdn.skypack.dev/react@17.0.1'</span><span>;</span></p></code></pre>
<p>That URL in the example above points to <a href="https://www.skypack.dev/">Skypack</a>, a popular JavaScript CDN that we built to serve every package&nbsp;on npm as ESM. Importing dependencies by URL like this is well supported in Snowpack, Deno, and all major browsers. But writing these URLs directly into your source code isn’t ideal and makes development impossible without a network connection.</p>
<p><strong>Snowpack v3.0 brings together the best of both worlds:</strong> Get the simplicity of <code>import 'react'</code> in your own source code and let Snowpack fetch these dependencies behind the scenes, pre-built and ready to run in the browser. Snowpack caches everything for you automatically, so you can continue to work offline after the first package fetch.</p>
<p>This new workflow has several benefits over the traditional “npm install” approach:</p>
<ul>
<li><strong>Speed:</strong> Skip the install + build steps for dependencies, and load your dependencies on-demand as pre-build, pre-bundled ESM code.</li>
<li><strong>Safety:</strong> ESM packages are pre-built into JavaScript for you and never given access to <a href="https://www.usenix.org/system/files/sec19-zimmermann.pdf">run code on your machine</a>. Third-party code only ever runs sandboxed in the browser.</li>
<li><strong>Less Tooling:</strong> ESM packages are managed by Snowpack, so frontend projects that don’t need Node.js (Rails, PHP, etc.) can drop the npm CLI entirely if they choose.</li>
<li><strong>Identical Final Build:</strong> When you build your site for production, package code is transpiled with the rest of your site and tree-shaken to your exact set of imports.</li>
</ul>
<p>This is our bet on the future of web development. But if this all sounds too wild for you or you have some technical reason to keep managing your dependencies with npm, don’t worry. This is <strong>100% opt-in</strong> behavior for those who want it. By default, Snowpack will continue to pull your npm package dependencies out of your project <code>node_modules</code> directory like it always has.</p>
<p>Check out our guide on <a href="https://www.snowpack.dev/guides/streaming-imports">Streaming Package Imports</a> to learn more about how to enable this new behavior in your project today.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-esbuild.png" alt="js api"></p>
<h2 id="built-in-optimizations%2C-powered-by-esbuild">Built-in Optimizations, Powered by esbuild</h2>
<p><a href="https://esbuild.github.io/">esbuild</a> is a marvel: it performs 100x faster than most other popular bundlers their own benchmarks. esbuild is written in Go, a compiled language that can parallelize heavy bundling workloads where other popular bundlers – written in JavaScript – cannot.</p>
<p>Snowpack already uses esbuild internally as our default single-file builder for JavaScript, TypeScript and JSX files. Snowpack v3.0 takes this integration one step further, with a new built-in build optimization pipeline. Bundle, minify, and transpile your site for production in 1/100th of the time of other bundlers.</p>
<p>Snowpack is able to adopt esbuild today thanks to an early bet that we made on the future of bundling: <strong>bundling is just a post-build optimization.</strong> Thanks to this early design decision, esbuild can be plugged in and swapped out of your Snowpack build as easily as any other bundler.</p>
<p>esbuild is still a young project, but its future looks promising. In the meantime, we will also continue to invest in the existing bundler plugins for a long time to come, so that more mature projects can continue to use mature bundlers like Webpack &amp; Rollup.</p>
<p>To get started, check out the <code>optimize</code> option in our newest <a href="https://www.snowpack.dev/guides/optimize-and-bundle">Optimizing Your Snowpack Build</a> guide.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-jsapi.png" alt="js api"></p>
<h2 id="a-new-javascript-api">A New JavaScript API</h2>
<p>Snowpack’s new JavaScript API grants you more advanced control over Snowpack’s dev server and build pipeline, helping you build more powerful integrations on top of Snowpack to unlock new kinds of dev tooling and server-side rendering (SSR) solutions.</p>
<p><a href="https://svelte.dev/blog/whats-the-deal-with-sveltekit">SvelteKit</a> is the new official web app framework from the Svelte team, built with Snowpack. SvelteKit uses our new JavaScript API to manage the build pipeline and build files on-demand. Snowpack helps SvelteKit speed up development, with zero rapid updates on file change and zero upfront server start-up cost.</p>
<p><a href="https://www.npmjs.com/package/microsite">Microsite</a> is another exciting new project built with Snowpack. Microsite is a Static Site Generator (SSG) for Preact that features automatic partial hydration, so that you send as little JavaScript down to the client as possible.</p>
<p>Check out our new <a href="https://www.snowpack.dev/reference/javascript-interface">JavaScript API reference</a> to start building your own custom integrations on top of Snowpack.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-runtime.png" alt="js api"></p>
<h2 id="a-new-node.js-runtime">A New Node.js Runtime</h2>
<p>Speaking of Svelte, this next feature comes directly out of our collaboration with the Svelte team. As a part of building out SvelteKit, Rich Harris created a server-side runtime for Snowpack. This runtime lets you import any Snowpack-built file directly into Node.js, handling things like ESM-&gt;CJS conversion and CSS extraction automatically.</p>
<p>The result is a unified build pipeline across both Node.js and the frontend, with all of the on-demand build performance benefits of Snowpack. Importing frontend code to run in Node.js unlocks features like true server-side rendering (SSR), test runner integrations for Jest/uvu/Mocha, and more.</p>
<p>Check out our new <a href="https://www.snowpack.dev/guides/server-side-render">SSR guide</a> to get started and learn more about all of the different ways that you can connect to your Snowpack build.</p>
<p>🥳</p>
<h2 id="snowpack%E2%80%99s-one-year-anniversary">Snowpack’s One Year Anniversary</h2>
<p>Last week marked Snowpack’s one-year anniversary of the original v1.0.0 release. Looking back, I’m blown away by everything that’s happened since:</p>
<ul>
<li>150+ releases (from <code>v0.0.1</code>, all the way to v3.0 today)</li>
<li><a href="https://www.snowpack.dev/plugins">100+ Snowpack plugins</a> to choose from (and growing fast!)</li>
<li><a href="https://github.com/snowpackjs/snowpack/graphs/contributors">100+ individual contributors</a></li>
<li><a href="https://github.com/snowpackjs/snowpack/stargazers">15,000+ stars on GitHub</a></li>
<li>#1 Developer Productivity Boost Winner, <a href="https://osawards.com/javascript/2020">2020 JS Open Source Awards</a></li>
<li>#1 Highest Developer Interest, <a href="https://2020.stateofjs.com/en-US/technologies/build-tools/">2020 State of JS</a></li>
<li>#1 Highest Developer Satisfaction (tied), 2020 State of JS</li>
</ul>
<p>A huge thank you to everyone who has contributed code to Snowpack, and the hundreds of developers joining us on GitHub and on <a href="https://discord.com/invite/snowpack">Discord</a>. This project wouldn’t exist today without you and your support. Thank you!</p>
<p>– Fred K. Schott <a href="https://twitter.com/FredKSchott">(@FredKSchott)</a></p>

    </article>
    </div></div>]]>
            </description>
            <link>https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25767819</guid>
            <pubDate>Wed, 13 Jan 2021 20:53:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Unlikely Database Migration]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 173 (<a href="https://news.ycombinator.com/item?id=25767128">thread link</a>) | @ifcologne
<br/>
January 13, 2021 | https://tailscale.com/blog/an-unlikely-database-migration/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/an-unlikely-database-migration/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h4 id="brad-joins-a-startup">Brad joins a startup</h4>
<p>When I first joined <a href="https://tailscale.com/">Tailscale</a> almost a year
ago, one of the first things I asked
<a href="https://github.com/crawshaw">Crawshaw</a> was, “So, what database do you
use? MySQL, PostgreSQL, SQLite maybe?”, knowing that he loved SQLite.</p>
<p>“A text file," he replied.</p>
<p>“Huh?”</p>
<p>“Yeah, we write out one big JSON object to a text file.”</p>
<p>“How? When? <em>What?</em>”</p>
<p>“Yeah, whenever something changes, we grab a lock in our single
process and rewrite out the file!” he chuckled with glee.</p>
<p>It sounded insane. It <em>was</em> insane. Sure, it was easily testable, but
it didn’t scale. We both knew that. But it worked.</p>
<p>Until it didn’t.</p>
<p>Even with fast NVMe drives and splitting the database into two halves
(important data vs. ephemeral data that we could lose on a tmpfs),
things got slower and slower. We knew the day would come. The file
reached a peak size of 150MB and we were writing it as quickly as the
disk I/O would let us. Ain’t that just peachy?</p>
<p>So, migrate to MySQL or PostgreSQL, right? Maybe SQLite?</p>
<p>Nope, Crawshaw had other ideas.</p>
<h4 id="a-bit-of-backstory-from-david">A bit of backstory from David</h4>
<p>Tailscale’s coordination server, our “control plane”, has become known
as <a href="https://getsmart.fandom.com/wiki/CONTROL">CONTROL</a>. It’s currently
a single Go process on a single VM. The very earliest prototypes for
CONTROL used SQLite. Our original designs were very different from
what we ended up with, involving configuration databases synchronized
onto client machines and all sorts of other concepts we ended up not
needing. Through this process we would do major reorganizations of our
SQL data model every week, which required an astonishing amount of
typing. SQL is widely used, durable, effective, and requires an
annoying amount of glue to bring into just about any programming
language. (Attempts to avoid this with ORMs usually replace an
annoying amount of typing with an annoying amount of magic and loss of
efficiency.)</p>
<p>One day, fed up with the refactorings, I threw it all out and built an
in-memory data model for experimentation. That made iterating
much faster. A couple of weeks later, a customer wanted to try it
out. I wasn’t ready to commit to the data model yet and do it properly
in SQL, so I took a shortcut: the object holding all the data was
wrapped in a <code>sync.Mutex</code>, all accesses went through it, and on edit the
whole structure was passed to <code>json.Marshal</code> and written to disk. This
gave us data model persistence in ~20 lines of Go.</p>
<p>The plan was always to migrate to something else but, uh, we got busy
with other stuff and kinda forgot.</p>
<h4 id="what-comes-after-jsonmutexdb">What comes after JSONMutexDB?</h4>
<p>The obvious next step to take was to move to SQL. My favorite is still
SQLite, but I couldn’t bring myself to make an argument for migrating
a rapidly growing service to it. It certainly could work, especially
as the design of our control plane doesn’t require the high
availability of typical web services: the result of a short outage is
that new nodes can’t log in; working networks continue to work.</p>
<p>MySQL (or PostgreSQL) would come next. I’m not particularly familiar
with anything MySQL post 1998, but I’m sure it would work. The HA
story for open source databases is somewhat surprising, though: you
can either have traditional lagging replicas, or commit to
no-primary-replica clusters that have very surprising transaction
semantics. I wasn’t excited about trying to design a stable API or
good network graph calculations on top of those semantics.
<a href="https://github.com/cockroachdb/cockroach#what-is-cockroachdb">CockroachDB</a>
looked very promising, and indeed still does! But it’s relatively new
for a database and I was a little concerned about getting attached to
features in a fresh DBMS that would be hard to migrate away from if we
needed to.</p>
<p>Making our control server depend on MySQL or PostgreSQL also means our
control server’s testing story gets slow &amp; ugly. Brad had fought that
battle with <a href="https://perkeep.org/">Perkeep</a> and previously written
<a href="https://godoc.org/perkeep.org/pkg/test/dockertest">perkeep.org/pkg/test/dockertest</a>
which works but isn’t something we wanted to subject future employees
to. It requires Docker on your machine and it’s not particularly fast.</p>
<p>Then one day we saw a <a href="https://jepsen.io/analyses/etcd-3.4.3">Jepsen report on
etcd</a>. Unlike the usual
less-than-satisfying Jepsen reports to which we’d become accustomed,
this one said <em>good things</em> about <a href="https://etcd.io/">etcd</a>.
Combined with some positive experiences <a href="https://github.com/danderson">Dave Anderson</a>
had with it, we started thinking about whether we could just use etcd directly.
Being written in Go, we could just link it into our tests and use it
directly. No Docker, no mocks, testing what we’d actually use in
production.</p>
<p>It turned out that the core data model we were writing to disk closely
followed the pattern:</p>
<pre><code>type AllTheData struct {
	BigLock    sync.Mutex
	Somethings map[string]Something
	Widgets    map[string]Widget
	Gadgets    map[string]Gadget
}
</code></pre><p>This maps surprisingly well onto a KV-store. So this led us to etcd as
a “minimally-viable database”. It does the critical things we needed
now, which was 1) breaking the BigLock into something more akin to a
<code>sync.RWMutex</code>, and 2) reducing our I/O to only write the changed data,
not the whole world on any write.</p>
<p>(We are careful not to use any etcd features that would be hard to map onto CockroachDB.)</p>
<p>The downside of this is that etcd, while popular in Kubernetes, has
relatively few users for a database system. As a company, Tailscale is
spending an <a href="https://mcfunley.com/choose-boring-technology">innovation
token</a> on it. But the
database is conceptually small enough that we don’t have to treat it
as a black box. When we ran into a surprisingly slow key pagination
edge case in etcd 3.4, I was able to read my way through its sources
and write a fix for it in an hour. (I then discovered an <a href="https://github.com/etcd-io/etcd/commit/26c930f27d46776da5fedae69267ba0b69c31185">equivalent
fix</a>
had already been applied to the next version of etcd, so we backported
that instead.)</p>
<h4 id="tailetc-our-etcd-client-wrapper">tailetc: our etcd client wrapper</h4>
<p>The client we use for etcd is open source at
<a href="https://github.com/tailscale/tailetc">github.com/tailscale/tailetc</a>. It
is built around two concepts: 1) the total data in the DB is small
enough to fit into the server’s memory and 2) reads are far more
common than writes. Given that, we want to make reads cheap.</p>
<p>The way we do that is by registering a watch against etcd. Every
change is sent to the client, which maintains an enormous cache
<code>map[string]interface{}</code> behind a <code>sync.RWMutex</code>. When you create a Tx
and do a Get, the value is read out of this cache (which may be behind
etcd, but is kept transactionally consistent by tracking the modrev: a
global incrementing ID that etcd uses to define revisions of key-value
pairs.). To avoid aliasing bugs with the cache, we copy the object
out, but avoid JSON decoding on each Get by implementing a more
efficient Clone call on objects in the cache.</p>
<p>The result is that fetching a value from etcd does not require any
network traffic.</p>
<p>This is one of those few times writing Go that I felt the limitations
of its type system as I was designing a package. If I were working in
a language with all the bells and whistles, there would be some kind
of const qualifier I could place on objects leaving the cache and
avoid cloning the memory. That said, running profiles on our server
show the copying is not a performance issue, so perhaps this is an
example of where I feel the pull towards a more complex type system
without actually having a real need for them. As is so often the case,
assumptions are dangerous, profiling is enlightening.</p>
<h4 id="one-snag-indexes">One snag: indexes</h4>
<p>The biggest problem with choosing a minimal viable “nosql” is the lack
of the wonderful index system every standard SQL DBMS supplies. We are
stuck with either storing indexes inside etcd, or managing them in
memory in our client.</p>
<p>With JSONMutexDB we generated them in memory, because it’s much easier
to make data model changes. The easy option with etcd would have been
writing them to the database, but that would have really complicated
data models. Unfortunately, if we want to move to running more than
one CONTROL process simultaneously for high-availability and better
release management, that means we no longer have exactly one process
managing the data, so our indexes need to be transaction (and
rollback) aware. So we invested what probably amounts to two or three
weeks of engineering time into designing in-memory indexes that are
transactionally consistent. This gets a bit tricky to describe, so
we’ll save that for a future blog post (and hopefully we can clean up
the code enough to open source it some day).</p>
<h4 id="the-migration">The migration</h4>
<p>The migration wasn’t very notable, which is always a good thing. We
ran both systems in parallel for a while and at some point stopped
using the old one. The most exciting thing was that our commit latency
dropped a bunch when we turned off the JSON writes. This was most
noticeable when editing networks in the admin panel. We’d include
pretty Grafana graphs here but the cut-over predates us changing our
Prometheus config to keep more history. In any case, writes went from
nearly a second (sometimes worse!) to milliseconds. When we’d started,
writes weren’t a second of course. Never underestimate how long your
“temporary” hack will stay in production!</p>
<h4 id="future">Future</h4>
<p>The most exciting thing about this work, besides ensuring the
Tailscale control plane can scale out for the foreseeable future, is
improving our release process. A consistent database we can easily
attach multiple control plane instances to means we can move to
<a href="https://en.wikipedia.org/wiki/Blue-green_deployment">blue-green deployment</a>.
This will let Tailscale engineers experiment with deploying features
with the confidence that the worst-case outcome of a change is
limited. The goal is to keep development speed as close to the early
days of JSONMutexDB, when you could recompile and run locally in a
fraction of a second and deploy ten times a day.</p>

    </div></div>]]>
            </description>
            <link>https://tailscale.com/blog/an-unlikely-database-migration/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25767128</guid>
            <pubDate>Wed, 13 Jan 2021 19:52:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ten years without Elixir]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 135 (<a href="https://news.ycombinator.com/item?id=25767030">thread link</a>) | @_nato_
<br/>
January 13, 2021 | http://blog.cretaria.com/posts/ten-years-without-elixir.html | <a href="https://web.archive.org/web/*/http://blog.cretaria.com/posts/ten-years-without-elixir.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <header>
                
                <p>Sync’ up! … without getting drained</p>
            </header>
	    <section>
<article>
<p><abbr>jan 13</abbr></p>
<h2>Ten years without Elixir</h2>
<p>José Valim committed the first bit of Elixir code January
9th, 2011, which marks a ten-year anniversary for the kid
brother of Erlang. It’s incredible how time flies on 
certain paradigms, while crawls on others.</p>

<p>I never got into Elixir, largely because it looked like
Ruby. I was a Rubyist for a good while, spent time
and effort to learn where to park my commas, semicolons,
and periods in Erlang, so I never felt that Elixir was
something I wanted.</p>

<p>Nor have I since. There was a good web framework that
came along, and since I’m of that age, you’d thing that
Phoenix would have pulled me in: it never did. I kept
hacking Erlang and just used lighter web <abbr>API</abbr>s like
Cowboy &amp; Elli, instead of going all in on a full
fledged web framework.</p>

<p>From my Erlang-colored glasses, Elixir seems to have
a lot of wins. Their packaging efforts looks like a
mature tool (Hex), and nobody seems to be complaining
about the documentation, an issue Erlang always had (though
to be honest, I never quite grasped what aspect of the
Erlang documentation to be problematic).</p>

<p>On the other hand, some of the syntax Elixir offers
is retrograde, in my humble opinion. Erlang seems to
have prettier syntax now that I have spent so much
time with it. A moot point, perhaps, considering how
subjective beauty is.</p>

<p>My strongest anti-Elixir sentiment (from armchair
reach) is their use of pipes. I know mixologists love
the Elixir pipe operator, but for someone who has
learned to necessarily un-nest code as severely as I have, I
feel as though this operator could be a detriment, or
at least come with some prickily moral hazards. More on that
can be read 
<a href="http://blog.cretaria.com/posts/erlang-beauty.html">here</a>.</p>

<p>Elixir is a cool project, and managed to out-pace Erlang
in a lot of areas it struggled (community,
tooling, etc.).</p>

<p>Hats off to the Elixir team on ten enormous years of
success!</p><p><svg xmlns:xlink="http://www.w3.org/1999/xlink" xmlns="http://www.w3.org/2000/svg" viewBox="200 0 400 800" width="400" height="800"><rect width="400" height="800" fill="#b33a3a"></rect><polygon points="299.5 150 254.5 247 351.5 247 "></polygon><path d="m321.9 548.9l-243.8 0"></path><path d="m303 247.1l0 243.8"></path><polygon points="94.5 150 49.5 247 146.5 247 "></polygon><path d="m98 247.1l0 243.8"></path><text font-family="Helvetica, Arial, sans-serif" font-size="60" y="112" x="10" style="fill-opacity:null">THIS END UP</text><a xlink:href="//cretaria.com"><text id="link-cretaria" font-family="Helvetica, Arial, sans-serif" font-size="50" y="680" x="10" fill-opacity="null">What’s Cretaria?</text></a><path d="m175 700l200 0" style="fill-opacity:null;fill:none;stroke-linejoin:null;stroke-opacity:null;stroke-width:4;stroke:#000"></path></svg></p></article>
            </section>
            
        </div></div>]]>
            </description>
            <link>http://blog.cretaria.com/posts/ten-years-without-elixir.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25767030</guid>
            <pubDate>Wed, 13 Jan 2021 19:44:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The future of social is ephemeral by default, P2P, and algorithmically-mediated]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25766491">thread link</a>) | @generativist
<br/>
January 13, 2021 | https://generativist.falsifiable.com/metaverse/what-should-social-look-like | <a href="https://web.archive.org/web/*/https://generativist.falsifiable.com/metaverse/what-should-social-look-like">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><a href="https://generativist.falsifiable.com/">generativist</a> / <a href="https://generativist.falsifiable.com/metaverse/">metaverse</a>
    <hr>
    
    
    <p>Ephemeral By Default, P2P, and Algorithmically-Mediated</p>
    <time datetime="2021-01-11 00:00:00 +0000 UTC">2021-01-11</time>
    <section>
        <figure><label for="zQmRVwjMUcU3bJWEhN2qExQ3DKBxEobAuqksX2DojHpocK8">⊕</label><span>This post will arouse some techbro suspicions so I’m just going to lean into it with technology boy, a character written by Neil Gaiman who understands probably understands belief space better than I do.</span><img src="https://p.falsifiable.page/zQmRVwjMUcU3bJWEhN2qExQ3DKBxEobAuqksX2DojHpocK8" alt="Technology boy from American Gods"></figure><h2 id="motivation">Motivation</h2><p>Recently, I wrote a post that proposed <a href="https://generativist.falsifiable.com/metaverse/centralized-social-partitions-considered-harmful">Twitter shouldn’t ban Donald Trump</a> because I thought the possibility of durable social fission exists. Hours later, <a href="https://blog.twitter.com/en_us/topics/company/2020/suspension.html">Twitter banned Donald Trump</a>. Soon after, <a href="https://www.axios.com/platforms-social-media-ban-restrict-trump-d9e44f3c-8366-4ba9-a8a1-7f3114f920f1.html">a broader group of major internet companies</a> did the same. Then, <a href="https://www.buzzfeednews.com/article/johnpaczkowski/amazon-parler-aws">Amazon brought the Ban Hammer down on Parler</a>, the hate reactor built by hapless fall guy John Matze and heiress Rebekah Mercer.</p>

<p>There are <a href="https://en.wikipedia.org/wiki/2021_storming_of_the_United_States_Capitol#:~:text=The%20storming%20of%20the%20United,in%20the%202020%20presidential%20election.">excellent justifications for why this was necessary</a> and <a href="https://twitter.com/generativist/status/1348310439331995650">why this emergent coordination occurred</a> and why was necessary. I don’t want to talk about them. What matters more for me right now? <a href="https://twitter.com/generativist/status/1348374694320250881">I don’t think it will ever work again</a>. <a href="https://twitter.com/generativist/status/1348374695452708864">A trans-national economy of people building censorship-resistant technology seems to have a new occasion for war</a>. The fire next time won’t be containable in similar ways.</p>

<p>This leads me to a simple conclusion: <strong>if you care about making social mediums work better in the future, your solutions must assume censorship resistance as a given</strong>. Otherwise, <a href="https://twitter.com/generativist/status/1348374705766498304">your building on an already-pruned branch</a>.</p>
<h2 id="engineering-our-augmented-space">Engineering Our Augmented Space</h2><p>Centralized social media – as it exists today – is Procrustean. On Twitter, <a href="https://generativist.falsifiable.com/metaverse/the-real-supernode-problem">super-nodes excessively synchronize attention in mal-adaptive ways</a>. <a href="https://generativist.falsifiable.com/metaverse/dunbars-number-is-quadratic">The weight of identity-to-context skews far enough towards the former that we’re prone to chronically ignoring or failing to consider the latter</a>. <a href="https://www.ribbonfarm.com/2020/01/16/the-internet-of-beefs/">Social beefs end proliferate in wild abundance</a>. <a href="https://www.ribbonfarm.com/2016/09/15/crowds-and-technology/">Crowds grow, swarm, and disassociate from reality</a>. All of this is all great for farming freely-offered attention. But, a good cybernetic ecosystem it does not make.</p>

<p>Given it’s defacto-albeit-not-really role as the world’s hyperspace <a href="https://en.wikipedia.org/wiki/Public_sphere">public sphere</a>, a great deal of (recent) attention seems to be on making a censorship-resistant Twitter. <a href="https://twitter.com/pfrazee/status/1348415859707023362">This is a mistake</a> borne of the DWeb/Blockchain communities’ ideological defaults.</p>

<p><strong>Censorship resistance <em>may be</em> necessary for solving some of these problems. But, it’s desperately far from sufficient.</strong> Missing is the attention dedicated to creating a social environment that fits us, not one that demands we fit it. It requires considering that – while there are a variety of technological architectures for creating a distributed and decentralized social medium – not all of them are sociological solutions.</p>
<p>I am interested in finding a solution at the intersection of both problems.</p>

<p>What follows is a small projection of my view from 10,000 feet.</p>
<h3 id="1-ephemeral-by-default">1. Ephemeral By Default</h3><p>Blockchains ensure immutability. Robust consensus mechanisms afford canonical state. Both can be useful. But the latter is computationally costly. More than that, there is an expense borne by <em>the forms of expression it selects for</em>.</p>

<p>In the context of ephemeral mediums, it’s excessively restrictive. <strong>Not every statement requires non-repudiation; in social contexts, very few do.</strong><label for="sn-0"></label><span>I’m bending what non-repudiation means a bit here. <a href="https://en.wikipedia.org/wiki/Right_to_be_forgotten">Right to be forgetten</a> is almost closer. Except, you can’t forget on a global immutable ledger…by definition. Ephemeral by default albeit with cryptographic signing for message authentication means what you socially reveal is <em>more</em> in your control, and fosters better norms.</span> If every utterance persists forever, people either self-censor or <em>excessively</em> fracture their identity into disposable fragments, as a defense.<label for="sn-1"></label><span><a href="https://twitter.com/balajis">@balaijis</a> <a href="https://www.youtube.com/watch?feature=youtu.be&amp;v=Dur918GqDIw">gives a talk worth listening to about pseudonymous economy</a> that proposes the use of cryptographic attestations to imbue alts with some of main’s properties, in a precise information theoretic way. He sees it as a way to manage social capital risks as any other capital asset. The talk is fascinating, but I think it’s solving the wrong problem.</span> Both behaviors frustrate social processes – including those of consensus formation.</p>

<p>The need to <em>optionally</em> commit a statement to a ledger in contexts where non-repudiation is desirable exists, as does the need.<label for="sn-2"></label><span>For example, if you are following someone whose reputation is derived from making accurate predictions about the future, <a href="http://www.investorhome.com/scam.htm">you want their full history, not the selectively trimmed version</a>. Global and immutable state makes such scams more difficult. <em>But</em>, my contention is that, making it impossible is too socially costly. <a href="https://www.tandfonline.com/doi/abs/10.1080/08913819508443369">Expressive behavior exists</a> and instrumentality is a dead end.</span> But it is not a good default. The temporal context of most expressions is now. Carrying prior utterances – generally without context – forward, creates conditions for maladaptive hysteresis. The past binds longer than it need to, in ways that don’t reflect the present – and, in doing so, it limits the future.</p>
<h3 id="2-peer-to-peer-by-necessity">2. Peer-to-peer by Necessity</h3><p>On the technological side, federation offers a means of decentralization that fits in well with existing skills and practices. For example, if you can deploy a website, you can probably set up a <a href="https://joinmastodon.org/">mastodon instance</a>. This matters for fostering adoption. Participation at an infrastructure/administration level doesn’t have a steep learning curve or cost of entry.</p>

<p>On the sociological side, it also seems to solve a critical problem: users have a stake in the communities they join.  Or, more accurately, users are part of communities – <a href="https://www.nationalaffairs.com/why-speech-platforms-can-never-escape-politics">it doesn’t make much sense to speak of communities absent individual stakes</a>.  This can help create incentives for the community to define and enforce its boundaries.</p>

<p>However, boundary enforcement and community cultivation seems inextricably tied up in communal ownership of identity. For example, on mastodon, your identity is subject to community/node intervention. Expulsion doesn’t render you a digital nomad; it erases the identity. For what will end up being the most passionate and proselytizing early adopters, this is too repulsive. And while you can propose networks that afford right of <em>intact</em> exit, these have the effect of neutering the enforcement mechanisms. What you have is less of a community and more of a federated network transport.</p>
<p><strong>More to the point, I think the model reflects an implement-what-we-know mentality</strong>. Early websites were nothing more than digital brochures. Federation models try to replicate…schools? Co-op boards? Cities? City states? Nation states? They tend to assume a one-to-one/belongs-to relationship often bound by geography. But the beauty of the internet is that meat space doesn’t bind. And, the brilliance of twitter showed us that association is so free, it’s almost a liquid.<label for="sn-3"></label><span>I saw this tweet from <a href="https://twitter.com/aaronzlewis/status/1349079811587780609">@aaronzlewis</a> yesterday and wanted to plug it some how. It vaguely fits, but in any case, Aaron is worth a follow for thinking about this stuff.</span></p>

<p>Recapitulating, Zuckerborg was almost preposterously wrong when he said,<label for="sn-4"></label><span>This is unfair. If you use a loss function which penalizes legibility for the purpose of algorithmic attention resale, he was <em>precisely</em> correct.</span></p>

<blockquote>
<p>You have one identity…The days of you having a different image for your work friends or co-workers and for the other people you know are probably coming to an end pretty quickly […] Having two identities for yourself is an example of a lack of integrity.”</p>
</blockquote>
<p>Identity is contextual. <a href="https://amzn.to/3bBieEq">We all wear different masks</a>. And, <a href="https://www.amazon.com/Distinction-Routledge-Classics-Pierre-Bourdieu/dp/0415567882/ref=sr_1_1?crid=PB4KYKEX2EUU&amp;dchild=1&amp;keywords=pierre+bourdieu&amp;qid=1610480340&amp;s=books&amp;sprefix=pierre+bor%2Cstripbooks%2C237&amp;sr=1-1">we act in ways conditional upon both our expectation, capital, and social environment</a>. This doesn’t betray a “lack of integrity.” It is a fundamental <em>and adaptive</em> part of being a human being.</p>
<p>With this rough sketch, I reach the following conclusions:</p>

<ul>
<li><strong>Individuals must own their identities</strong>. No one except the person associated with a particular identity can revoke it. The most motivated adopters won’t allow otherwise. </li>
</ul>
<ul>
<li><strong>The medium itself must not mediate voluntary associations</strong>. That is, for any possible relationship pair, no entity can inhibit <em>direct</em> communication except for either of the participants. This follows from the same adopter assumption. But, it’s also a consequence of the ethereal nature of association absent geographic confinement. While this environment has perils, it is also the source of its continuing promise.</li>
</ul>

<p>This largely precludes federation. Peer-to-peer is the way forward.<label for="sn-5"></label><span>This doesn’t mean there is no role for service providers that act as proxies, caches, aggregators, etc. There surely is and will be. But, I don’t believe they should be part of the p2p core.</span></p>
<h3 id="3-computation-is-the-massage">3. Computation is the Massage</h3><p>I argued that federation won’t work because it relies upon the wrong analogies. But, if any user can reach any user, the possible interaction space is quadratic. We do need something to structure something so incomprehensible.</p>

<p>The social graph is the scaffolding of that structure. It collapses <span>\(n^2\)</span> to something we can cope with. It affords repeated interactions and social recall. It defines an architecture for message passing <em>where we act as the processors</em>.</p>

<p>However, we are social creatures and social media is omnipresent. Viewing ourselves as the processors, <a href="https://en.wikipedia.org/wiki/Parkinson%27s_law">Parkinson’s Law</a> becomes oddly relevant: work expands so as to fill the time available for its completion.  Who we follow increases until we reach the point of desired infinity-scroll saturation. At this point (or well before it), processing demands on a one-to-one basis exceed our human capabilities. <a href="https://generativist.falsifiable.com/metaverse/dunbars-number-is-quadratic">We fall back upon higher-order generalizations. Fuckery ensues.</a></p>

<p>Here, social media critics generally prescribe something like “people-centric technology” as the antidote. Increasingly, I think it’s snake oil. More often then not, you can replace it with <em>RETVRN</em> without loss of meaning. Technology changes the way we relate to each other. With it, so do our aspirations, perceptions, mediators, and institutions. Some expand, and some contract. The way through isn’t to retreat to a now inaccessible past.<label for="sn-6"></label><span>Makes note to reread <em>Industrial Society and Its Future</em> as an exercise in Take Cartography.</span> The way out is to marshal our modern resources into new capabilities.</p>

<p>In …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://generativist.falsifiable.com/metaverse/what-should-social-look-like">https://generativist.falsifiable.com/metaverse/what-should-social-look-like</a></em></p>]]>
            </description>
            <link>https://generativist.falsifiable.com/metaverse/what-should-social-look-like</link>
            <guid isPermaLink="false">hacker-news-small-sites-25766491</guid>
            <pubDate>Wed, 13 Jan 2021 19:00:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lost Passwords Lock Millionaires Out of Their Bitcoin Fortunes]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25766111">thread link</a>) | @acdanger
<br/>
January 13, 2021 | https://www.nytimes.com./2021/01/12/technology/bitcoin-passwords-wallets-fortunes.html | <a href="https://web.archive.org/web/*/https://www.nytimes.com./2021/01/12/technology/bitcoin-passwords-wallets-fortunes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="story"><div id="fullBleedHeaderContent"><header><div><figure aria-label="media" role="group"><div><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2021/01/12/business/12LOSTKEYS1/merlin_181769928_d4ce2e0a-e927-47d9-97cc-8d87aa079f9a-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2021/01/12/business/12LOSTKEYS1/merlin_181769928_d4ce2e0a-e927-47d9-97cc-8d87aa079f9a-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2021/01/12/business/12LOSTKEYS1/merlin_181769928_d4ce2e0a-e927-47d9-97cc-8d87aa079f9a-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"><img alt="Stefan Thomas, a programmer in San Francisco, owns 7,002 Bitcoin that he cannot retrieve because he lost the password to his digital wallet." src="https://static01.nyt.com/images/2021/01/12/business/12LOSTKEYS1/merlin_181769928_d4ce2e0a-e927-47d9-97cc-8d87aa079f9a-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2021/01/12/business/12LOSTKEYS1/merlin_181769928_d4ce2e0a-e927-47d9-97cc-8d87aa079f9a-articleLarge.jpg?quality=90&amp;auto=webp 600w,https://static01.nyt.com/images/2021/01/12/business/12LOSTKEYS1/merlin_181769928_d4ce2e0a-e927-47d9-97cc-8d87aa079f9a-jumbo.jpg?quality=90&amp;auto=webp 820w,https://static01.nyt.com/images/2021/01/12/business/12LOSTKEYS1/merlin_181769928_d4ce2e0a-e927-47d9-97cc-8d87aa079f9a-superJumbo.jpg?quality=90&amp;auto=webp 1639w" sizes="100vw" decoding="async"></picture></div><figcaption><span><span>Credit...</span><span><span>Nicholas Albrecht for The New York Times</span></span></span></figcaption></figure></div><div><div><p>Bitcoin owners are getting rich because the cryptocurrency has soared. But what happens when you canâ€™t tap that wealth because you forgot the password to your digital wallet?</p></div></div></header><p><span>Stefan Thomas, a programmer in San Francisco, owns 7,002 Bitcoin that he cannot retrieve because he lost the password to his digital wallet.</span><span><span>Credit...</span><span><span>Nicholas Albrecht for The New York Times</span></span></span></p><div><div><ul><li><time datetime="2021-01-14T16:25:34-05:00"><span>Published <!-- -->Jan. 12, 2021</span><span>Updated <!-- -->Jan. 14, 2021</span></time></li></ul></div></div></div><section name="articleBody"><figure><figcaption><p><h3>Listen to This Article</h3></p></figcaption><div></div></figure><div><div><p><em>To hear more audio stories from publishers like The New York Times, </em><a href="https://www.audm.com/?utm_source=nyt&amp;utm_medium=embed&amp;utm_campaign=lost_keys_bitcoin_password" title="" rel="noopener noreferrer" target="_blank"><em>download Audm for iPhone or Android</em></a><em>.</em></p><p>Stefan Thomas, a German-born programmer living in San Francisco, has two guesses left to figure out a password that is worth, as of this week, about $220 million.</p><p>The password will let him unlock a small hard drive, known as an IronKey, which contains the private keys to a digital wallet that holds 7,002 Bitcoin. While the price of Bitcoin dropped sharply on Monday, it is still up more than 50 percent from just <a href="https://www.nytimes.com/2020/11/30/technology/bitcoin-record-price.html" title="">a month ago</a>, when it passed its previous all-time high of around $20,000. </p><p>The problem is that Mr. Thomas years ago lost the paper where he wrote down the password for his IronKey, which gives users 10 guesses before it seizes up and encrypts its contents forever. He has since tried eight of his most commonly used password formulations â€” to no avail.</p></div></div><div><div><p>â€œI would just lay in bed and think about it,â€� Mr. Thomas said. â€œThen I would go to the computer with some new strategy, and it wouldnâ€™t work, and I would be desperate again.â€�</p><p>Bitcoin, which has been on an extraordinary and volatile eight-month run, has made a lot of its holders very rich in <a href="https://www.nytimes.com/2020/12/16/style/bitcoin.html" title="">a short time</a>, even as the coronavirus pandemic has ravaged the world economy.</p><p>But the cryptocurrencyâ€™s unusual nature has also meant that many people are locked out of their Bitcoin fortunes as a result of lost or forgotten keys. They have been forced to watch, helpless, as the price has risen and fallen sharply, unable to cash in on their digital wealth.</p><p>Of the existing 18.5 million Bitcoin, around 20 percent â€” currently worth around $140 billion â€” appear to be in lost or otherwise stranded wallets, according to the cryptocurrency data firm Chainalysis. Wallet Recovery Services, a business that helps find lost digital keys, said it had gotten 70 requests a day from people who wanted help recovering their riches, three times the number of a month ago.</p><p>Bitcoin owners who are locked out of their wallets speak of endless days and nights of frustration as they have tried to get access to their fortunes. Many have owned the coins since Bitcoinâ€™s early days a decade ago, when no one had confidence that the tokens would be worth anything.</p></div></div><div><div><p>â€œThrough the years I would say I have spent hundreds of hours trying to get back into these wallets,â€� said Brad Yasar, an entrepreneur in Los Angeles who has a few desktop computers that contain thousands of Bitcoin he created, or mined, during the early days of the technology. While those Bitcoin are now worth hundreds of millions of dollars, he lost his passwords many years ago and has put the hard drives containing them in vacuum-sealed bags, out of sight.</p><p>â€œI donâ€™t want to be reminded every day that what I have now is a fraction of what I could have that I lost,â€� he said.</p><p>The dilemma is a stark reminder of Bitcoinâ€™s unusual technological underpinnings, which set it apart from normal money and give it some of its most vaunted â€” and riskiest â€” qualities. With traditional bank accounts and online wallets, banks like Wells Fargo and other financial companies like PayPal can provide people the passwords to their accounts or reset lost passwords.</p></div></div><div data-testid="photoviewer-wrapper"><div data-testid="photoviewer-children"><figure aria-label="media" role="group"><div><p><span>Image</span></p><picture><source media="(max-width: 599px) and (min-device-pixel-ratio: 3),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 3),(max-width: 599px) and (min-resolution: 3dppx),(max-width: 599px) and (min-resolution: 288dpi)" srcset="https://static01.nyt.com/images/2021/01/08/business/00LOSTKEYS2/00LOSTKEYS2-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=600"><source media="(max-width: 599px) and (min-device-pixel-ratio: 2),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 2),(max-width: 599px) and (min-resolution: 2dppx),(max-width: 599px) and (min-resolution: 192dpi)" srcset="https://static01.nyt.com/images/2021/01/08/business/00LOSTKEYS2/00LOSTKEYS2-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1200"><source media="(max-width: 599px) and (min-device-pixel-ratio: 1),(max-width: 599px) and (-webkit-min-device-pixel-ratio: 1),(max-width: 599px) and (min-resolution: 1dppx),(max-width: 599px) and (min-resolution: 96dpi)" srcset="https://static01.nyt.com/images/2021/01/08/business/00LOSTKEYS2/00LOSTKEYS2-mobileMasterAt3x.jpg?quality=75&amp;auto=webp&amp;disable=upscale&amp;width=1800"><img alt="â€œI would just lay in bed and think about it,â€� Mr. Thomas said." src="https://static01.nyt.com/images/2021/01/08/business/00LOSTKEYS2/00LOSTKEYS2-articleLarge.jpg?quality=75&amp;auto=webp&amp;disable=upscale" srcset="https://static01.nyt.com/images/2021/01/08/business/00LOSTKEYS2/00LOSTKEYS2-articleLarge.jpg?quality=90&amp;auto=webp 600w,https://static01.nyt.com/images/2021/01/08/business/00LOSTKEYS2/00LOSTKEYS2-jumbo.jpg?quality=90&amp;auto=webp 1024w,https://static01.nyt.com/images/2021/01/08/business/00LOSTKEYS2/00LOSTKEYS2-superJumbo.jpg?quality=90&amp;auto=webp 2048w" sizes="((min-width: 600px) and (max-width: 1004px)) 84vw, (min-width: 1005px) 60vw, 100vw" decoding="async"></picture></div><figcaption><span><span>Credit...</span><span>Nicholas Albrecht for The New York Times</span></span></figcaption></figure></div></div><div><p>But Bitcoin has no company to provide or store passwords. The virtual currencyâ€™s creator, a shadowy figure known as Satoshi Nakamoto, has said Bitcoinâ€™s central idea was to allow anyone in the world to open a digital bank account and hold the money in a way that no government could prevent or regulate.</p></div><div><p>This is made possible by the structure of Bitcoin, which is governed by a network of computers that agreed to follow software containing all the rules for the cryptocurrency. The software includes a complex algorithm that makes it possible to create an address, and associated private key, which is known only by the person who created the wallet.</p></div><div><div><p>The software also allows the Bitcoin network to confirm the accuracy of the password to allow transactions, without seeing or knowing the password itself. In short, the system makes it possible for anyone to create a Bitcoin wallet without having to register with a financial institution or go through any sort of identity check.</p><p>That has made Bitcoin <a href="https://www.nytimes.com/2020/01/28/technology/bitcoin-black-market.html" title="">popular with criminals</a>, who can use the money without revealing their identity. It has also attracted people in countries like China and Venezuela, where authoritarian governments are known for raiding or shutting down traditional bank accounts.</p><p>But the structure of this system did not account for just how bad people can be at remembering and securing their passwords.</p><p>â€œEven sophisticated investors have been completely incapable of doing any kind of management of private keys,â€� said<span>  </span>Diogo Monica, a co-founder of a start-up called Anchorage, which helps companies handle cryptocurrency security. Mr. Monica started the company in 2017 after helping a hedge fund regain access to one of its Bitcoin wallets.</p><p>Mr. Thomas, the programmer, said he was drawn to Bitcoin partly because it was <a href="https://www.nytimes.com/2019/02/23/opinion/sunday/venezuela-bitcoin-inflation-cryptocurrencies.html" title="">outside the control of a country</a> or company. In 2011, when he was living in Switzerland, he was given the 7,002 Bitcoin by an early Bitcoin fanatic as a reward for making an animated video, â€œ<a href="https://www.youtube.com/watch?v=Um63OQz3bjo" title="" rel="noopener noreferrer" target="_blank">What is Bitcoin?</a>,â€� which introduced many people to the technology.</p><p>That year, he lost the digital keys to the wallet holding the Bitcoin. Since then, as Bitcoinâ€™s value has soared and fallen and he could not get his hands on the money, Mr. Thomas has soured on the idea that people should be their own bank and hold their own money.</p><p>â€œThis whole idea of being your own bank â€” let me put it this way: Do you make your own shoes?â€� he said. â€œThe reason we have banks is that we donâ€™t want to deal with all those things that banks do.â€�</p></div></div><div><div><p>Other Bitcoin believers have also realized the difficulties of being their own bank. Some have outsourced the work of holding Bitcoin to start-ups and exchanges that secure the private keys to peopleâ€™s stashes of the virtual currency.</p><p>Yet some of these services have had just as much trouble securing their keys. Many of the largest Bitcoin exchanges over the years â€” including the onetime well-known exchange <a href="https://www.nytimes.com/2016/05/26/business/dealbook/mt-gox-creditors-seek-trillions-where-there-are-only-millions.html" title="">Mt. Gox</a> â€” have lost private keys or had them stolen.</p><p>Gabriel Abed, 34, an entrepreneur from Barbados, lost around 800 Bitcoin â€” now worth around $25 million â€” when a colleague reformatted a laptop that contained the private keys to a Bitcoin wallet in 2011.</p><p>Mr. Abed said this did not dim his enthusiasm. Before Bitcoin, he said, he and his fellow islanders had not had access to affordable digital financial products like the credit cards and bank accounts that are easily available to Americans. In Barbados, even getting a PayPal account was almost impossible, he said. The open nature of Bitcoin, he said, gave him full access to the digital financial world for the first time.</p><p>â€œThe risk of being my own bank comes with the reward of being able to freely access my money and be a citizen of the world â€” that is worth it,â€� Mr. Abed said.</p><p>For Mr. Abed and Mr. Thomas, any losses from mishandling the private keys have partly been assuaged by the enormous gains they have made on the Bitcoin they managed to hold on to. The 800 Bitcoin Mr. Abed lost in 2011 were a small fraction of the tokens he has since bought and sold, allowing him to recently buy a 100-acre plot of oceanfront land in Barbados for over $25 million.</p><p>Mr. Thomas said he also managed to hold on to enough Bitcoin â€” and remember the passwords â€” to give him more riches than he knows what to do with. In 2012, he joined a cryptocurrency start-up, Ripple, that aimed to improve on Bitcoin. He was rewarded with Rippleâ€™s own native currency, known as XRP, which rose in value.</p></div></div><div><div><p>(Ripple has recently <a href="https://www.nytimes.com/2020/12/21/technology/ripple-cryptocurrency-sec-lawsuit.html" title="">run into legal troubles</a>, in part because the founders had too much control over the creation and distribution of the XRP coins.)</p><p>As for his lost password and inaccessible Bitcoin, Mr. Thomas has put the IronKey in a secure facility â€” he wonâ€™t say where â€” in case cryptographers come up with new ways of cracking complex passwords. Keeping it far away helps him try not to think about it, he said.</p><p>â€œI got to a point where I said to myself, â€˜Let it be in the past, just for your own mental health,â€™â€� he said. </p></div></div></section></article></div>]]>
            </description>
            <link>https://www.nytimes.com./2021/01/12/technology/bitcoin-passwords-wallets-fortunes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25766111</guid>
            <pubDate>Wed, 13 Jan 2021 18:31:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: GS2JSON: Turn any Google Sheet to a JSON – No login – open-source]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25765560">thread link</a>) | @cosbgn
<br/>
January 13, 2021 | https://zero.sh/labs/gs2json | <a href="https://web.archive.org/web/*/https://zero.sh/labs/gs2json">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>GS2JSON is a free api which will allow you to transform any Google Sheet to a JSON file.</p>
<blockquote>
<p>Simply append your public spreadsheet url to: <a href="https://labs.zero.sh/api/gs2json?url=your-public-speadsheet-url" rel="nofollow noopener noreferrer" target="_blank">https://labs.zero.sh/api/gs2json?url=your-public-speadsheet-url</a> - Nothing else needed!</p>
</blockquote>
<p>It's free to use and doesn't require an API key or authentication. The code is available on <a href="https://github.com/Cosbgn/zero-labs/blob/master/api/gs2json.js" rel="nofollow noopener noreferrer" target="_blank">Github</a></p>
<p>With Zero you can build great interactive dashboards pulling data directly from a Google Sheet using this API.
It's free! Read more in our blog post: <a href="https://zero.sh/blog/create-a-dashboard-with-google-sheets">Create a dashboard with Google Sheets</a></p>
<h2 id="1-make-sure-that-your-sheet-is-public">1. Make sure that your sheet is public</h2>
<p>This API can read only public sheets. To make your sheet public open it and then click on:</p>
<ol>
<li>File (On the top left of the Google Sheet window)</li>
<li>Publish for the web</li>
<li>Publish</li>
</ol>
<p>At this point you can close this popup and copy the <strong>full page URL</strong>. Directly from your browser's address bar.</p>
<h2 id="2-format-your-request">2. Format your request</h2>
<p>This API accepts only <strong>GET</strong> requests to this endpoint: <code>https://labs.zero.sh/api/gs2json</code></p>
<p>The following query parameters are allowed:</p>
<blockquote>
<p>Since the spreadsheet url often contains a hashtag symbol (#) make sure you add the URL as the last parameter or you risk that the others will be ignored, for example:</p>
</blockquote>
<ul>
<li>Do <code>?format=2&amp;url=https://docs...</code></li>
<li>Don't do <code>?url=https://docs...&amp;format=1</code></li>
</ul>
<p>The following parameters are accepted:</p>
<ul>
<li><strong>format</strong>:
You can chose the format of your response. Possible values are 1,2 &amp; 3. Read about these below.</li>
<li><strong>sheet</strong>:
The number of the sheet in the spreadsheet (Defaults to the first sheet if nothing is passed)</li>
<li><strong>url</strong>:
This is the full spreadsheet url, something like: <em><a href="https://docs.google.com/spreadsheets/d/12345" rel="nofollow noopener noreferrer" target="_blank">https://docs.google.com/spreadsheets/d/12345</a></em></li>
<li><strong>id</strong>:
Instead of the full url, you can also simply pass the id like: <em>12345</em></li>
</ul>
<h2 id="3-format-your-response">3. Format your response</h2>
<p>You can chose to have your data returned in 3 different ways, use the <code>format</code> parameter to chose the response your prefer.</p>
<ol>
<li>An object <em>without</em> columns names</li>
<li>An object <em>with</em> column names</li>
<li>An Array of the rows with mapped column names</li>
</ol>
<h2 id="example">Example:</h2>
<p>With the following spreadsheet:
<a href="https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8" rel="nofollow noopener noreferrer" target="_blank">https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8</a></p>

<p>The response will be:</p>
<ul>
<li>
<p><em>With ?format=1</em>:</p>
<p><a href="https://labs.zero.sh/api/gs2json?format=1&amp;url=https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8" rel="nofollow noopener noreferrer" target="_blank">https://labs.zero.sh/api/gs2json?format=1&amp;url=https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8</a></p>
<div><pre><code><span>{</span><span>"1"</span><span>:</span><span>[</span><span>"Name"</span><span>,</span><span>"Sara"</span><span>,</span><span>"Tom"</span><span>]</span><span>,</span><span>"2"</span><span>:</span><span>[</span><span>"Age"</span><span>,</span><span>"35"</span><span>,</span><span>"50"</span><span>]</span><span>}</span>
</code></pre></div>
</li>
<li>
<p><em>With ?format=2</em>:</p>
<p><a href="https://labs.zero.sh/api/gs2json?format=2&amp;url=https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8" rel="nofollow noopener noreferrer" target="_blank">https://labs.zero.sh/api/gs2json?format=2&amp;url=https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8</a></p>
<div><pre><code><span>{</span><span>"Name"</span><span>:</span><span>[</span><span>"Sara"</span><span>,</span><span>"Tom"</span><span>]</span><span>,</span><span>"Age"</span><span>:</span><span>[</span><span>"35"</span><span>,</span><span>"50"</span><span>]</span><span>}</span>
</code></pre></div>
</li>
<li>
<p><em>With ?format=3</em>:</p>
<p><a href="https://labs.zero.sh/api/gs2json?format=3&amp;url=https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8" rel="nofollow noopener noreferrer" target="_blank">https://labs.zero.sh/api/gs2json?format=3&amp;url=https://docs.google.com/spreadsheets/d/1zdJnlYIO2dEMMDLJ5J_ny1uetbTVfQtinYW0QWAv9I8</a></p>
<div><pre><code><span>[</span><span>{</span><span>"Name"</span><span>:</span><span>"Sara"</span><span>,</span><span>"Age"</span><span>:</span><span>"35"</span><span>}</span><span>,</span><span>{</span><span>"Name"</span><span>:</span><span>"Tom"</span><span>,</span><span>"Age"</span><span>:</span><span>"50"</span><span>}</span><span>]</span>
</code></pre></div>
</li>
</ul>
<h2 id="questions">Questions?</h2>
<p>Feel free to send us an email at <a href="mailto:support@zero.sh">support@zero.sh</a> or open an issue on <a href="https://github.com/Cosbgn/zero-labs" rel="nofollow noopener noreferrer" target="_blank">Github</a></p></div></div></div>]]>
            </description>
            <link>https://zero.sh/labs/gs2json</link>
            <guid isPermaLink="false">hacker-news-small-sites-25765560</guid>
            <pubDate>Wed, 13 Jan 2021 17:53:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Complex Software: Asynchronous Machines]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25765376">thread link</a>) | @valand
<br/>
January 13, 2021 | https://valand.dev/blog/post/complex-software--async-machines | <a href="https://web.archive.org/web/*/https://valand.dev/blog/post/complex-software--async-machines">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Complex software can be daunting to author. I will dissect and reintroduce the concept of asynchronous machines, why we need it in the first place, and how delving into the concept might help conquer complex software.</p>
<h2>Software Complexity</h2>
<p>Software complexity is the number of components inside a software, assuming that <a href="https://en.wikipedia.org/wiki/Single-responsibility_principle">a single component has a single responsibility</a>. A software with a single component that does a lot of things is regarded as not only complex but also <em>amess</em>, but I'm not going to visit that idea. I don't stick to the strict definition of single-responsibility principle that comes from OOP, therefore a component is not necessarily a class, a struct. It's just one part of a software of many with a clear distinction from the others.</p>
<h2>Async Machines</h2>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Machine"><em>"Machine is a mechanical structure that uses power to apply forces and control movement to perform an intended action." - wikipedia.com</em></a></p>
</blockquote>
<p>Why are we mentioning "machine" at all?</p>
<p>Computer is an <a href="https://en.wikipedia.org/wiki/Automaton">automaton</a>, a self-operating machine that follows a predetermined sequence of operations. Those operations are what we call a program. Being <a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing complete</a>, a computer can simulate itself, therefore a program can be a machine too.</p>
<p>A video game runs, you play it. While it is running, it reads inputs from peripherals. Those inputs alter the internal state. At one point, the video game can reach a particular state that prompts it to quit. That video game is a machine. Another example, NodeJS. NodeJS loads and interprets JavaScript code and executes it. In this situation, NodeJS is the machine, while the JavaScript code is the program. This is why NodeJS is a VM.</p>
<p>A program can be as boring as receiving input, processing it, and spewing output, but each passing day that simple thing does not suffice. Computers gain new capabilities, file systems, networking, multi-threading, GPU processing, and those are made available through hardware with different speeds. And not to forget the most important part of the realm of computer, human, its user, doesn't like to be kept waiting. That's why a simple input, computation, output doesn't suffice. Everything around the program, hardware interfaces, humans, are all working and reacting at different paces. Inputs and outputs are needed at different intervals. This is the original reason why the concept of asynchronous machines exists.</p>
<p>Essentially, the concept of asynchronous machines is to make all parties, which are the I/O edges of the program, the happiest they can be.</p>
<p>A case: A browser is a complex system. It is responsible for many things, connecting to and loading from servers, running web pages, sandboxing tabs, synchronizing web storage to disks, etc. In it are asynchronous machines, each responsible for different parties:</p>
<ul>
<li>A tab is running a page. Inside a page is HTML DOM, CSS style computation and JavaScript code execution. This is a human facing machine. It must always be responsive to user input. You can find evidence that unresponsiveness is an intolerable behavior for this machine, such as calling a long-running JavaScript operation will trigger a prompt that says "page is unresponsive", offering the user an escape hatch, killing the page, to make sure that the user has options all the time.</li>
<li>A tab is running a page. Inside a page is HTML DOM, CSS style computation and JavaScript code execution. It is a human facing. It must always be responsive to user input. Unresponsiveness is intolerable for it. You can find evidence of that anywhere. For example, calling a long-running JavaScript operation will trigger a prompt that says "page is unresponsive". Then it offers the user an escape hatch: to kill the page.</li>
<li>A storage-facing program is "happy" when it efficiently reads and writes to storage.</li>
<li>And many more...</li>
</ul>
<p>Messaging is the most important basis of asynchronous machines. Messaging happens at small scale, like communication between threads, as well as at large scale, like blockchain mining. Synchronous APIs directed towards asynchronous machines are either wrapper for request/response with messaging underneath, or fire-and-forget message.</p>
<p>Messaging involves message queues at the receiver's side, and sometimes at the sender's side too. A <a href="https://en.wikipedia.org/wiki/Data_buffer">buffer</a> at the I/O to hardware is a message queue. Hardware and a program are separate asynchronous machines. They need buffers to store unprocessed messages.</p>
<p>Queues are abstracted out for a software developer most of the time. For example, NodeJS has a lot of APIs implementing stream. NodeJS's stream is actually a buffer and its processor behind the scene, which triggers events. NodeJS users only have to understand which events do what.</p>
<p>Many projects I have worked on involve writing two or more asynchronous machines at the same time. Usually one is the UI layer and the other is a layer that interacts with storage or network. Most of the time queues need to be handwritten because it needs a custom behavior, such as merging message duplicates, has a custom backpressure mechanism, etc. Then, because the queue is handwritten, the queue runner also needs to be handwritten. The queue is a "singleton function", in which only one instance of it can exist per queue. It runs at the start of the queue appendage and stops when the queue is empty. Then, at the caller's side, a wrapper is written to make an "illusion" of synchronous calls. Most of the time it is fun.</p>
<p>Messaging can either be <a href="https://en.wikipedia.org/wiki/Message_broker">brokered</a> or <a href="https://en.wikipedia.org/wiki/Peer-to-peer">not brokered</a>. A simple brokered messaging would be Mutex that guards access from multiple threads, or Kafka sending messages from one service to another. A message broker is essentially the party responsible for transporting messages from one party to the other. A message broker is essentially the party responsible for transporting messages from one party to the other. Meanwhile, unbrokered messaging is when two parties don't need another party to manage their messages. Peer-to-peer communication is one of those. Being brokered and unbrokered is not a hard 1 or 0 but a spectrum. There can be a messaging mechanism in the middle of the spectrum. Shared storage is, for example, is where multiple parties store data at the same site. The shared storage acts as a passive broker. The difference between brokered and not brokered lies in how a message gets transported and how the receiver and sender must do additional process before and after the transportation, like serialization, validation, etc.</p>
<p>Knowing the existence of a message broker is crucial when you design objects' lifecycle. The message broker must live before the components that rely on it. It also must die after them. This concept seems obvious, but it's not rare for projects to fail this aspect. An easy practice is to structure code chronologically, both for declarative and imperative styles.</p>

    <div data-language="react">
      <pre><code><span>// In declarative language/framework:
// example: react + jsx
(
	&lt;ComponentA&gt; {/* ComponentA is mounted first */}
    	&lt;ComponentB&gt; {/* ComponentB is mounted second */}
            &lt;ComponentC /&gt; {/* ComponentC is mounted last and dismounted first */}
        &lt;/ComponentB&gt; {/* ComponentB is dismounted second */}
    &lt;/ComponentA&gt; {/* ComponentA is dismounted last */}
)
// ComponentA is mounted first and dismounted last
// ComponentB is mounted second and dismounted second
// ComponentC is mounted last and dismounted first</span></code></pre>
    </div>

    <div data-language="rust">
      <pre><code><span>
</span><span>
</span><span>fn</span><span> </span><span>some_function</span><span>(){</span><span>
</span><span>    </span><span>let</span><span> </span><span>lock</span><span> </span><span>=</span><span> </span><span>Arc</span><span>::</span><span>new</span><span>(</span><span>Mutex</span><span>::</span><span>new</span><span>(</span><span>0_u32</span><span>)); </span><span>
</span><span>   	</span><span>let</span><span> </span><span>lock1</span><span> </span><span>=</span><span> </span><span>Arc</span><span>::</span><span>clone</span><span>(&amp;</span><span>lock</span><span>);</span><span>
</span><span>   	</span><span>let</span><span> </span><span>lock2</span><span> </span><span>=</span><span> </span><span>Arc</span><span>::</span><span>clone</span><span>(&amp;</span><span>lock</span><span>);</span><span>
</span><span>    </span><span>let</span><span> </span><span>thread1</span><span> </span><span>=</span><span> </span><span>thread</span><span>::</span><span>spawn</span><span>(</span><span>move</span><span> || {   </span><span>
</span><span>        </span><span>
</span><span>    });</span><span>
</span><span>    </span><span>let</span><span> </span><span>thread2</span><span> </span><span>=</span><span> </span><span>thread</span><span>::</span><span>spawn</span><span>(</span><span>move</span><span> || {   </span><span>
</span><span>        </span><span>
</span><span>    });</span><span>

</span><span>    </span><span>thread1</span><span>.</span><span>join</span><span>(); </span><span>
</span><span>    </span><span>thread2</span><span>.</span><span>join</span><span>(); </span><span>
</span><span>    </span><span>
</span><span>}</span></code></pre>
    </div>
<h2>The Line Separating FP vs OOP War Lies At The Edges of Asynchronous Machines</h2>
<p>Let's talk functional programming, or rather, programming with functional style. FP is often regarded as the opposite of OOP, while I think it's not the exact opposite. Sometime in the past birthed a language which forces you to write everything with <code>class</code>. A <code>class</code> has methods, which has call syntax <code>subject.predicate()</code>. <code>subject</code> in a sentence is active, an agent. This paradigm introduces a side effect. In the perspective of the programmer, a program written in an OOP style has many agents, whereas not every kind of program needs multiple agencies.</p>
<p>In an environment where there are no other machines with different paces, a machine only needs one agent, which is itself. The machine receives input and produces output and maybe some side effects. All components inside the machines work at the same pace, so there's no need for sub-agency, message passing, nor buffering. It is like a librarian with one mind and two hands cataloging and organizing books. The program manages data. It makes functional programming a prime paradigm in building a machine. Its principles like immutability over mutability, pure functions, recursion, higher-order functions, result in elegant code.</p>
<p>At the same time, two asynchronous machines have two agencies. Each has their memory, works at their own pace, acts on their own data, and occasionally communicates with each other. This is where the concept of multiple agencies needs to be introduced. This is, where I think, the original concept of OOP (not nowadays' OOP) makes sense. Alan Kay describes OOP as if computers are cells, and they occasionally send messages to each other. This is also why sometimes people throw jokes at functional programming for <a href="https://www.youtube.com/watch?v=ADqLBc1vFwI">being difficult to do side-effects</a> on.</p>
<p>The line that separates FP and OOP paradigms, moreover how programmers perceive machines because of the two, lies at the edges of asynchronous machines.</p>
<blockquote>
<p><a href="http://userpage.fu-berlin.de/~ram/pub/pub_jf47ht81Ht/doc_kay_oop_en">"I thought of objects being like biological cells and/or individual computers on a network, only able to communicate with messages" - Alan Kay</a></p>
</blockquote>
<h2>Coda</h2>
<p>Understanding the concept of asynchronous machines is a huge help to me if we're talking about system design. While this piece of writing is a big idea presented in a rough format, I hope you get something out of it as much as I did.</p></div></div>]]>
            </description>
            <link>https://valand.dev/blog/post/complex-software--async-machines</link>
            <guid isPermaLink="false">hacker-news-small-sites-25765376</guid>
            <pubDate>Wed, 13 Jan 2021 17:40:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[6 Predictions for How Privacy Will Impact DevOps in 2021]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25764838">thread link</a>) | @icoe
<br/>
January 13, 2021 | https://www.tonic.ai/post/how-data-privacy-will-impact-devops-in-2021 | <a href="https://web.archive.org/web/*/https://www.tonic.ai/post/how-data-privacy-will-impact-devops-in-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>TL;DR</strong>: With data breach risks and regulations on the rise, data access for developers will become increasingly restricted. Add to that the escalating complexity of mimicking production data in-house, and DevOps teams stand to face a sudden shortage of quality data for development and testing in the year ahead.</p><p>Perhaps the only thing riskier than making predictions for 2021, given the unprecedented year that was 2020, is not making predictions and responding to the trends when it comes to data privacy. Reflecting on what we’ve seen in the industry and in conversations with our customers, here are the developments we see unfolding in the year ahead.</p><h2>2021 will be the worst year for data breaches yet.</h2><p>The scale of data breaches will be worse in 2021 than ever before. How do we know? The <a href="https://www.identityforce.com/blog/2020-data-breaches" target="_blank">past few years</a> have been nothing but a steady upward climb. Even though the number of <em>breaches</em> decreased from 2019 to 2020, the number of <em>records exposed</em> in those breaches more than doubled, from 15.1 billion records in 2019 to <a href="https://pages.riskbasedsecurity.com/hubfs/Reports/2020/2020%20Q3%20Data%20Breach%20QuickView%20Report.pdf" target="_blank">36 billion in 2020 as of Q3</a>.&nbsp;<br></p><p>Companies may be fighting the good fight in safeguarding against breaches, but when a breach occurs, they’re losing more data than ever. And with work-from-home now the norm for so many, the risks of a breach are <a href="https://www.americanbanker.com/news/data-security-lapses-surge-in-work-from-home-era" target="_blank">heightened</a>.</p><h2>Remote work will redefine data governance—permanently.</h2><p>With the above in mind, the shift to remote work is changing how people think about <a href="https://www.tonic.ai/post/remote-work-data-sprawl">security for distributed teams</a>, especially around data minimization and access restrictions. We’re seeing changes in internal processing and an increase in tooling to reduce the use of sensitive data within an organization.&nbsp;<br></p><p>The real potential here is for ways that do so without limiting employees from getting work done. At Tonic, we're doubling down on this need as we believe these shifts are here to stay.</p><h2>Using production data in development is OUT.</h2><p>Thanks to privacy legislation like GDPR and CCPA/CPRA, the shift away from using production data in development and testing has been steadily picking up speed. But it’s not yet the gold standard that it should be.&nbsp;</p><p>&nbsp;Between the risks of remote work and ever stronger regulations on the horizon, we expect this shift to accelerate dramatically over the coming year. Some companies will opt to create dummy data in house; others will <a href="https://www.tonic.ai/post/building-data-de-identification-infrastructure">consider the work involved</a>, and seek out solutions like Tonic, to rapidly get high-quality, representative data at scale.</p><h2>Data access will make or break developer productivity.</h2><p>Developer productivity sets apart successful organizations from unsuccessful ones, making rapid, easy access to high quality data more important than ever. As applications become more advanced, the data involved in their use and creation is becoming increasingly complex.&nbsp;<br></p><p>Traditional dev tools simply aren't up to the challenge of meeting today’s data needs, and in-house solutions fail over time. Organizations that don’t find a faster, safer way to get their developers the data they need will be left behind.&nbsp;</p><h2>Privacy needs will impact cloud migrations.</h2><p>Simply put, migrating from on-prem to cloud data lakes needs to be done with privacy in mind. Compliance with regulations can impact how a company's data can be stored in the cloud. Data sanitization pre-migration may be a necessary step in the process, and data access post-migration must be carefully defined. We’re seeing many companies combine the potential of cloud data warehousing like Snowflake with streamlined data de-identification like Tonic to get the best that modern privacy tools and cloud storage solutions have to offer.</p><h2>Federal data privacy legislation is coming.</h2><p>You’ve probably heard <a href="https://www.businessinsider.com/congress-may-finally-pass-federal-data-privacy-law-in-2021-2020-12" target="_blank">this</a> <a href="https://iapp.org/news/a/2021-best-chance-for-federal-privacy-legislation/" target="_blank">elsewhere</a> <a href="https://www.zdnet.com/article/predictions-2021-privacy-becomes-an-imperative-in-a-year-of-transition/" target="_blank">as</a> <a href="https://www.information-age.com/forrester-releases-privacy-cyber-security-predictions-2021-123492371/" target="_blank">well</a>. We’re all in agreement: it’s high time the US set a federal standard for data privacy. In the past two years, as many as <a href="https://iapp.org/resources/article/state-comparison-table/" target="_blank">27 states</a> have taken matters into their own hands, introducing state-level privacy legislation. California, Maine, and Nevada have already signed their bills into law, complicating the landscape of compliance requirements companies must meet. Legislation at the federal level is in everyone’s best interest, from consumers to legislators to corporations.</p><p>So there you have it, the good, the bad, and the critical to keep in mind as we navigate another year in this unexpected landscape. We’re excited to see Tonic helping our customers address many of these concerns. If safe data access and developer enablement is top of mind for you in 2021 and our predictions strike a chord, <a href="https://www.tonic.ai/demo">drop us a line</a>. Here’s to a safe and happy new year!</p></div><div><h2>What’s a Rich Text element?</h2><p>The rich text element allows you to create and format headings, paragraphs, blockquotes, images, and video all in one place instead of having to add and format them individually. Just double-click and easily create content.</p><h5>Static and dynamic content editing</h5><blockquote>Static and dynamic content editing</blockquote><p>‍</p><h6>Static and dynamic content editing</h6><p>A rich text element can be used with static or dynamic content. For static content, just drop it into any page and begin editing. For dynamic content, add a rich text field to any collection and then <strong>connect</strong> a rich text element to that field in the settings panel. Voila!</p><h4>How to customize formatting for each rich text</h4><p>Headings, paragraphs, blockquotes, figures, images, and figure captions can all be styled after a class is added to the rich text element using the "When inside of" nested selector system.</p></div></div>]]>
            </description>
            <link>https://www.tonic.ai/post/how-data-privacy-will-impact-devops-in-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25764838</guid>
            <pubDate>Wed, 13 Jan 2021 17:03:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Workaholism leads to health problems, work addiction risk depends on occupation]]>
            </title>
            <description>
<![CDATA[
Score 438 | Comments 229 (<a href="https://news.ycombinator.com/item?id=25763863">thread link</a>) | @rustoo
<br/>
January 13, 2021 | https://www.hse.ru/en/news/research/433782660.html | <a href="https://web.archive.org/web/*/https://www.hse.ru/en/news/research/433782660.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img alt="Workaholism Leads to Mental and Physical Health Problems: Work Addiction Risk Depends on Occupation" src="https://www.hse.ru/data/2021/01/13/1347222870/iStock-1180554582.jpg" title="Workaholism Leads to Mental and Physical Health Problems: Work Addiction Risk Depends on Occupation"></p></div><div><p>Workaholism or work addiction risk is a growing public health concern that can lead to many negative mental and physical health outcomes such as depression, anxiety or sleep disorder. Perception of work (job demands and job control) may become a major cause of employees’ work addiction. The international group of researchers including the HSE University scientist explored the link between work addiction risk and health-related outcomes using the framework of Job Demand Control Model. The results were published in the <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7593928/" rel="nofollow"><em>International Journal of Environmental Research and Public Health</em></a>.</p>  <p>Workaholics are people who usually work seven and more hours more than others per week. There are potential reasons for that: financial problems, poor marriage or pressure by their organization or supervisor. What can differentiate a workaholic behaviour from similar behaviour like work engagement? Workaholism is also known as a behavioural disorder, which means the excessive involvement of the individual in work when an employer doesn’t require or expect it.</p> </div>








    
    
        <p>The scientists aimed to demonstrate the extent to which the work addiction risk is associated with the perception of work (job demands and job control), and mental health in four job categories suggested by Karasek’s model or Job Demand-Control-Support model (JDCS). The JDCS model assumes four various work environments (four quadrants) in which workers may experience a different level of job demands and job control: passive, low-strain, active, and tense/job-strain. Job control is the extent to which an employee feels control over doing work.</p>


<div><ul>  <li>Passive” jobs (low job control, low job demands) might be satisfying to a worker as long as the workers reach the set goal.</li>  <li>Low strain” jobs have high job control and low job demands. Individuals in this category are not particularly at risk of mental health problems, and it corresponds typically to creative jobs such as architects.</li>  <li>Active” workers have high job demands and high job control. They are highly skilled professionals with responsibilities, such as heads or directors of companies. Those highly skilled workers have very demanding tasks but they have high levels of decision latitude to solve problems.</li>  <li>Finally, workers at risk of stress-related disorders are those within the “job strain” group (high demand and low control). For example, healthcare workers from emergency departments are typically in job strain because they cannot control the huge workload.</li> </ul>  <p>The study was conducted in France because it is one of the industrial countries with growing numbers of occupations. The authors of the research collected data from 187 out of 1580 (11.8%) French workers who agreed to participate in a cross-sectional study using the WittyFit software online platform. The self-administered questionnaires were the Job Content Questionnaire by Karasek, the Work Addiction Risk Test, the Hospital Anxiety and Depression scale and socio-demographics. The authors of this study divided all the participants based on their occupational groups and investigated the link between work addiction risk and mental and physical health outcomes.</p> </div>








    
    
        <div>
            

            
                <p>
                     <img alt="" height="200" src="https://www.hse.ru/pubs/share/thumb/433782649:c456x456+5+6:r190x190!.jpg" width="200">
                </p>
             
            <h4><a href="https://www.hse.ru/en/org/persons/211299142">Morteza Charkhabi</a>,<br>
Assistant&nbsp;Professor at the HSE&nbsp;<a href="https://ioe.hse.ru/en/">Institute of Education</a></h4>

<p>‘One of the novelties of this research was to introduce vulnerable occupational groups to organizations or job holders. For example, if we find that work addiction risk can be found more in some occupations and may result in negative outcomes for the health situation then we can give this information to decision makers in this organization or, for example, to the ministry of health. And they could intervene to prevent this problem.’</p>

            
        </div>


<div><p>The results show that high job demands at work are strongly associated with work addiction risk but the job control level does not play the same role. The prevalence of work addiction risk is higher for active and high-strain workers than for passive and low-strain workers. These two groups of workers appeared to be more vulnerable and therefore can suffer more from the negative outcomes of work addiction risk, in terms of depression, sleep disorder, stress and other health issues.</p>  <p>‘We found that job demands could be the most important factor that can develop work addiction risk. So this factor should be controlled or should be investigated by the organization's manager, for example, HR staff, psychologists. Also another conclusion could be the job climate like job demands of each job category can influence the rate of work addiction risk. Thus in this study we actually focused on external factors like job demands not internal factors like the personal characteristics,’ adds Morteza Charkhabi.</p>  <p>The researchers found that people with higher work addiction risk compared to people with low work addiction risk have twice the risk of developing depression. Sleep quality was lower to workers with high risk of work addiction compared to workers with low risk of work addiction. Also women had almost twice the work addiction risk than men.</p> </div></div></div>]]>
            </description>
            <link>https://www.hse.ru/en/news/research/433782660.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25763863</guid>
            <pubDate>Wed, 13 Jan 2021 16:08:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A rabbit hole full of Lisp]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25763409">thread link</a>) | @todsacerdoti
<br/>
January 13, 2021 | https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At work I contribute to a moderately-sized monorepo at 70 thousand files,
8-digit lines of code and hundreds of PRs merged every day. One day I
opened a remote buffer at that repository and ran <code>M-x find-file</code>.</p><p><code>find-file</code> is an interactive function that shows a narrowed list
of files in the current directory, prompts the user to filter and scroll
through candidates, and for a file to open.</p><p>Emacs froze for <em>5 seconds</em> before showing me the <code>find-file</code> prompt. Which
isn’t great, because when writing software, opening files is actually
something one needs to do all the time.</p><figure><img src="https://www.murilopereira.com/find_file_linux.png"></figure><p>Luckily, Emacs is “the extensible, customizable, self-documenting real-time
display editor”, and comes with profiling capabilities: <code>M-x profiler-start</code>
starts a profile and <code>M-x profiler-report</code> displays a call tree showing how
much CPU cycles are spent in each function call after starting the profile.
Starting a profile and running <code>M-x find-file</code> showed that all time was being
spent in a function called <code>ffap-guess-file-name-at-point</code>, which was being
called by <code>file-name-at-point-functions</code>, an <a href="https://www.gnu.org/software/emacs/manual/html%5Fnode/emacs/Hooks.html#:~:text=A%20few%20hooks%20are%20abnormal,are%20used%20in%20some%20way.">abnormal hook</a> run when <code>find-file</code>
is called.</p><p>If you're familiar with Vim you can think of Emacs <i>hooks</i> as
Vim <i>autocommands</i>, only with much better ergonomics.</p><p>I checked the documentation for <code>ffap-guess-file-name-at-point</code> with <code>M-x describe-function ffap-guess-file-name-at-point</code> and it didn’t seem
to be something essential, so I removed the hook by running <code>M-x eval-expression</code>, writing the form below, and pressing <code>RET</code>.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>remove-hook</span> <span>'file-name-at-point-functions</span> <span>'ffap-guess-file-name-at-point</span>)
</code></pre></td></tr></tbody></table></div></div><p>This solved the immediate problem of Emacs blocking for 5 seconds every
time I ran <code>find-file</code>, with no noticeable drawbacks.</p><div><p>As I write this I attempt to reproduce the issue by re-adding
<code>ffap-guess-file-name-at-point</code>
to
<code>file-name-at-point-functions</code>.
I can't reproduce it anymore. The initial issue might have been</p><ul><li>caused by having manually mutated the Emacs environment via ad-hoc code
evaluation (drifting from the state defined in configuration)</li><li>caused by settings or packages that aren't in my configuration anymore</li><li>fixed by settings or packages that were recently added to my
configuration</li><li>fixed by some recent package upgrade</li></ul><p>Or some combination of the above. I have no idea exactly what.
Which is to say: maintaining Emacs configurations is complicated.</p></div><p>I could now navigate around and open files. The next thing I tried in this
remote git repository was searching through project files. The great
<em>projectile</em> package provides the <code>projectile-find-file</code> function for that,
but I had previously given up making projectile perform well with remote
buffers; given how things are currently implemented it seems to be
<a href="https://www.google.com/search?q=projectile+tramp">impractical</a>. So I installed the <em>find-file-in-project</em> package for use on
remote projects exclusively: <code>M-x package-install find-file-in-project</code>.</p><p>Most Emacs commands are accessible via key combinations, with defaults
that can be customized to be anything you want. I'll stick to referencing
command names themselves instead of their default keybindings.</p><p>Both <code>projectile-find-file</code> and <code>find-file-in-project</code> (aliased as <code>ffip</code>):</p><ul><li>show a narrowed list of all project files in the minibuffer</li><li>prompt the user to filter and scroll through candidates</li><li>open a file when <code>RET</code> is pressed on a candidate.</li></ul><figure><img src="https://www.murilopereira.com/projectile_find_file_linux.png"></figure><p>To disable projectile on remote buffers I had the following form in my
configuration.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>defadvice</span> <span>projectile-project-root</span> (<span>around</span> <span>ignore-remote</span> <span>first</span> <span>activate</span>)
  (<span>unless</span> (<span>file-remote-p</span> <span>default-directory</span> <span>'no-identification</span>) <span>ad-do-it</span>))
</code></pre></td></tr></tbody></table></div></div><p>Which causes the <code>projectile-project-root</code> function to not run its usual
implementation on remote buffers, but instead return <code>nil</code> unconditionally.
<code>projectile-project-root</code> is used as a way to either get the project root for
a given buffer (remote or not), or as a boolean predicate to test if the
buffer is in a project (e.g., a git repository directory). Having it return
<code>nil</code> on remote buffers effectively disables projectile on remote buffers.</p><p>Emacs
<i><a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Advising-Functions.html">advices</a></i> are a way of modifying the behavior of existing functions without
having to redefine them. They serve a similar purpose as hooks, but are
more flexible.</p><p>I then wrote a function that falls back to <code>ffip</code> when projectile is
disabled and bound it to the keybinding I had for <code>projectile-find-file</code>,
so that I could press the same keybinding whenever I wanted to search for
projects files, and not have to think about whether I’m on a remote buffer
or not:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>defun</span> <span>maybe-projectile-find-file</span> ()
  <span>"Run </span><span>`projectile-find-file'</span><span> if in a project buffer, </span><span>`ffip'</span><span> otherwise."</span>
  (<span>interactive</span>)
  (<span>if</span> (<span>projectile-project-p</span>)
      (<span>projectile-find-file</span>)
    (<span>ffip</span>)))
</code></pre></td></tr></tbody></table></div></div><p><code>projectile-project-p</code> uses <code>projectile-project-root</code> internally.</p><p>And called it:</p><p><code>M-x maybe-projectile-find-file</code></p><p>Emacs froze for <strong>30 seconds</strong>. After that, it showed the prompt with the
narrowed list of files in the project. 30 seconds! What was it doing during
the whole time? Let’s try out the profiler again.</p><ol><li><p>Start a new profile:</p><p><code>M-x profiler-start</code></p></li><li><p>Call the function to be profiled:</p><p><code>M-x maybe-projectile-find-file</code> (it freezes Emacs again for 30 seconds)</p></li><li><p>And display the report:</p><p><code>M-x profiler-report</code></p></li></ol><p>Which showed:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="text">Function                                                  CPU samples    %
+ ...                                                           21027  98%
+ command-execute                                                 361   1%
</code></pre></td></tr></tbody></table></div></div><p>This tells us that 98% of the CPU time was spent in whatever <code>...</code> is.
Pressing <code>TAB</code> on a line will expand it by showing its child function
calls.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td><td><pre><code data-lang="text">Function                                                  CPU samples    %
- ...                                                           21027  98%
 + ivy--insert-minibuffer                                       13689  64%
 + #&lt;compiled 0x131f715d2b6fa0a8&gt;                                3819  17%
   Automatic GC                                                  2017   9%
 + shell-command                                                 1424   6%
 + ffip-get-project-root-directory                                 77   0%
 + run-mode-hooks                                                   1   0%
+ command-execute                                                 361   1%
</code></pre></td></tr></tbody></table></div></div><p>Expanding <code>...</code> shows that Emacs spent 64% of CPU time in
<code>ivy--insert-minibuffer</code> and 9% of the time—roughly 3 whole seconds!—
garbage collecting. I had <code>garbage-collection-messages</code> set to <code>t</code> so I could
already tell that Emacs was GCing a lot; enabling this setting makes a
message be displayed in the echo area whenever Emacs garbage collects. I
could also see the Emacs process consuming 100% of one CPU core while it was
frozen and unresponsive to input.</p><p>The <code>profiler</code> package implements a
<a href="https://en.wikipedia.org/wiki/Profiling_(computer_programming)#Statistical_profilers">sampling profiler</a>. The <code>elp</code>
package can be used for getting actual wall clock times.</p><p>Drilling down on <code>#&lt;compiled 0x131f715d2b6fa0a8&gt;</code> shows that cycles there
(17% of CPU time) were spent on Emacs waiting for user input, so we can
ignore it for now.</p><p>As I get deep in drilling down on <code>ivy--insert-minibuffer</code>, names in the
“Function” column start getting truncated because the column is too narrow.
A quick Google search (via <code>M-x google-this emacs profiler report width</code>)
shows me how to make it wider:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>setf</span> (<span>caar</span> <span>profiler-report-cpu-line-format</span>) <span>80</span>
      (<span>caar</span> <span>profiler-report-memory-line-format</span>) <span>80</span>)
</code></pre></td></tr></tbody></table></div></div><p>Describing those variables with <code>M-x describe-variable</code> shows that the
default values are <code>50</code>.</p><p>From the profiler report buffer I run <code>M-x eval-expression</code>, paste the form
above with <code>C-y</code> and press <code>RET</code>. I also persist this form to my
configuration. Pressing <code>c</code> in the profiler report buffer (bound to
<code>profiler-report-render-calltree</code>) redraws it, now with a wider column,
allowing me to see the function names.</p><p>Here is the abbreviated expanded relevant portion of the call stack.</p><div><div><table><tbody><tr><td><pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span></code></pre></td><td><pre><code data-lang="text">Function                                                  CPU samples    %
- ffip                                                          13586  63%
 - ffip-find-files                                              13586  63%
  - let*                                                        13586  63%
   - setq                                                       13585  63%
    - ffip-project-search                                       13585  63%
     - let*                                                     13585  63%
      - mapcar                                                  13531  63%
       - #&lt;lambda 0xb210342292&gt;                                 13528  63%
        - cons                                                  13521  63%
         - expand-file-name                                     12936  60%
          - tramp-file-name-handler                             12918  60%
           - apply                                               9217  43%
            - tramp-sh-file-name-handler                         9158  42%
             - apply                                             9124  42%
              - tramp-sh-handle-expand-file-name                 8952  41%
               - file-name-as-directory                          5812  27%
                - tramp-file-name-handler                        5793  27%
                 + tramp-find-foreign-file-name-handler          3166  14%
                 + apply                                         1237   5%
                 + tramp-dissect-file-name                        527   2%
                 + #&lt;compiled -0x1589d0aab96d9542&gt;                337   1%
                   tramp-file-name-equal-p                        312   1%
                   tramp-tramp-file-p                              33   0%
                 + tramp-replace-environment-variables              6   0%
                   #&lt;compiled 0x1e202496df87&gt;                       1   0%
               + tramp-connectable-p                             1006   4%
               + tramp-dissect-file-name                          628   2%
               + eval                                            …</code></pre></td></tr></tbody></table></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/">https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25763409</guid>
            <pubDate>Wed, 13 Jan 2021 15:45:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authoritarianism Through Coding: Signal]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25762823">thread link</a>) | @Reingohya
<br/>
January 13, 2021 | https://oyd.org.tr/en/articles/signal/ | <a href="https://web.archive.org/web/*/https://oyd.org.tr/en/articles/signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>This isn’t a theoretical piece about freedom and digital technologies. This is a real ongoing trend that is at best observed around secure messaging application Signal by Open Whisper Systems and it’s founder Moxie Merlinspike. His view and management of Signal reflects a wider trend that jepordises world’s freedom.</p>
<p>Signal is a secure messaging software that has changed the field a lot. Signal is built upon propriety software Textsecure and RedPhone applications that had been developed by Merlinspike and his co-founder Stuart Anderson. When Twitter acquired Whisper Systems, it releases both software under free software licenses. Merlinspike left Twitter acquired Whisper Systems, founded Open Whisper Systems and merged -once the private property of himself- TextSecure and Redphone into Signal.</p>
<p>Signal is free software. “Free as in freedom”, their client and server code is licenced under GPLv3 and AGPLv3. This makes the code and only the code itself pro-freedom. Just because the code it self free does not necessarily make the coder “free” as well and that is the problem we face today!</p>
<p>Open Whisper Systems led by Moxie Merlinspike, who is behind Signal, is and was never behind freedom. This has been seen in the light of LibreSignal (<a href="https://github.com/LibreSignal/LibreSignal/issues/37#issuecomment-217211165">https://github.com/LibreSignal/LibreSignal/issues/37#issuecomment-217211165</a>) debate where a fork of Signal client is build without unfree dependencies and published on the F-droid free software repository on Android. After much debate about federation, the claimed server resources and freedom, followed by legal trademark threats Libresignal has been removed from F-droid and so was anybody’s chance of using Signal as a secure messenger who doesn’t use Google services. <a href="https://wire.com/en/blog/axolotl-proteus-encryption-protocols/">Wire</a> case is just another example.</p>
<p>This approach is not only a threat to free software it is a recurring threat to human kind!</p>
<p>To prove this bold claim one needs to look at one recent blog post from Open Whisper Systems and a presentation made in 36C3 by Merlinspike.</p>
<p><a href="https://signal.org/blog/the-ecosystem-is-moving/">Signal’s blog post</a>
<a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">Matrix’s blog Post</a></p>
<p>The main points of his claims can be listed as follows:</p>
<ul>
<li>Decentralized systems are harder to build</li>
<li>Decentralized systems are harder to evolve</li>
<li>Decentralized systems are harder to secure</li>
<li>Decentralized systems are becoming concentrated in predominant provider anyways</li>
<li>If users don’t trust their app provider they have the freedom to use something else</li>
</ul>
<p>While his claims are true up to a certain point they are only superficial. Through these points Merlinspike claims that, centralized services are superior in modern times!</p>
<p><a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">anyone who is interested in the depth of this debate can start reading Martix’s answer to Merlinspike at the link here</a></p>
<p>It is really unnecessary to explain in depth why this type of thinking is dangerous when a simple change in words can tell more than 1000 page work. Let’s rename the object and compare his digital dystopia with one that has occured several times through-out analog human history and which once again recures today;</p>
<ul>
<li>Democracies are harder to build</li>
<li>Democracies are harder to improve</li>
<li>Democracies are harder to secure</li>
<li>In democracies power is becoming concentrated in predominant hands anyways</li>
<li>If people do not like their democracy provider (country) they have the freedom to leave and go another provider.</li>
</ul>
<p>One doesn’t need to think hard to see what Merlinspike is advising. He claims democracies suck because of the hardships of human organization and proposes autocracy to manage the world in favour of the helpless people occupying it. Why? Because democracies are inefficient and people don’t want that!</p>
<p>If he had given the same statement about democracies and governmental politics as he gave about federative systems it would have provoked outrage! People died for freedom, they are still dying and struggling around the globe. Then someone comes and stomps over every ideal which human society ever build up until this point in history and proclaims themselves the world leader! Think about it!</p>
<p>The example given is bad but why are Merlinspike’s claims about decentralized systems not considered bad as well? Because digital freedom has not yet been lost and won by blood or are we still asleep? Just because code is free, it doesn’t necessarily mean that the coders mind is also free! Freedom is not just a license, it is an ideal in any condition that we must stand for!</p>

    
        <hr>



    
  </article>
  
</div></div>]]>
            </description>
            <link>https://oyd.org.tr/en/articles/signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25762823</guid>
            <pubDate>Wed, 13 Jan 2021 15:06:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiding execution of unsigned code in Windows system threads]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25762322">thread link</a>) | @jm1337
<br/>
January 13, 2021 | https://secret.club/2021/01/12/callout.html | <a href="https://web.archive.org/web/*/https://secret.club/2021/01/12/callout.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Anti-cheat development is, by nature, reactive; anti-cheats exist to respond to and thwart a videogame’s population of cheaters. For instance, a videogame with an exceedingly low amount of cheaters would have little need for an anti-cheat, while a videogame rife with cheaters would have a clear need for an anti-cheat. In order to catch cheaters, anti-cheats will employ as many methods as possible. Unfortunately, anti-cheats are not omniscient; they can not know of every single method or detection vector to catch cheaters. Likewise, the game hacks themselves must continue to discover new or unique methods in order to evade anti-cheats.</p><h2 id="the-reactive-development-cycle-of-game-hacking"> <a href="#the-reactive-development-cycle-of-game-hacking">The Reactive Development Cycle of Game Hacking</a></h2><p>This brings forth a reactive and continuous development cycle, for both the cheats and anti-cheats: the opposite party (cheat or anti-cheat) will employ a unique method to circumvent the adjacent party (anti-cheat or cheat) which, in response, will then do the same.</p><p>One such method employed by an increasing number of anti-cheats is to execute core anti-cheat functions from within the operating system’s kernel. A clear advantage over the alternative (i.e. usermode execution) is in the fact that, on Windows NT systems, the anti-cheat can selectively filter which processes are able to interact with the memory of the game process in which they are protecting, thus nullifying a plethora of methods used by game hacks.</p><p>In response to this, many (but not all) hack developers made (or are making) the decision to do the same; they too would, or will, execute their hack, either wholly or in part, from within the operating system’s kernel, thus nullifying what the anti-cheats had done.</p><p>Unlike with anti-cheats, however, this decision carries with it numerous concessions: namely, the fact that, for various reasons, it is most convenient (or it is only practical) to execute the hack as an unsigned kernel driver running without the kernel’s knowledge; the “driver” is typically a region of executable memory in the kernel’s address space and is never loaded or allocated by the kernel. In other words, it is a “manually-mapped” driver, loaded by a tool used by a game hack.</p><p>This ultimately provides anti-cheats with many opportunities to detect so-called “kernel-mode” or “ring 0” game hacks (noting that those terms are typically said with a marketable significance; they are literally used to market such game hacks, as if to imply robustness or security); if the anti-cheat can prove that the system is executing, or had executed, unsigned code, it can then potentially flag a user as being a cheater.</p><h3 id="analyzing-a-threads-kernel-stack"> <a href="#analyzing-a-threads-kernel-stack">Analyzing a Thread’s Kernel Stack</a></h3><p>One such method - the focus of this article, in fact - of detecting unsigned code execution in the kernel is to iterate each thread that is running in the system (optionally deciding to only iterate threads associated with the system process, i.e. system threads) and to initiate some kind of stack trace.</p><p>Bluntly, this allows the anti-cheat to quite effectively determine if a cheat were executing unsigned code. For example, some anti-cheats (e.g. BattlEye) will queue to each system thread an APC which will then initiate a stack trace. If the stack trace returns an instruction pointer that is not within the confines of any loaded kernel driver, the anti-cheat can then know that it may have encountered a system thread that is executing unsigned code. Furthermore, because it is a stack trace and not a direct sampling of the return instruction pointer, it would work quite reliably, even if a game hack were, for example, executing a spin-loop or continuous wait; the stack trace would always lead back to the unsigned code.</p><p>It is quite clear to any cheat developer that they can respond to this behavior by simply running their thread(s) with kernel APCs disabled, preventing delivery of such APCs and avoiding the detection vector. As is will be seen, however, this method does not entirely prevent detection of unsigned code execution.</p><h3 id="copying-out-then-analyzing-a-threads-kernel-stack"> <a href="#copying-out-then-analyzing-a-threads-kernel-stack">(Copying Out, Then) Analyzing a Thread’s Kernel Stack</a></h3><p>Certain anti-cheats - EasyAntiCheat, in particular - had a much more apt method of generating a pseudo-stacktrace: instead of generating a stack trace with a blockable APC, why not copy the contents of the thread’s kernel stack asynchronously? Continuing the reactive cheat-anti-cheat development cycle, EasyAntiCheat had opted to manually search for instances of nonpaged code pointers that may have been left behind as a result of system thread execution.</p><p>While the downsides of this method are debatable, the upside is quite clear: as long as the thread is making procedure calls (e.g. x86 call instruction) from within its own code, either to kernel routines or to its own, and regardless of its IRQL or if the thread is even running, its execution will leave behind detectable traces on its stack in the form of pointers to its own code which can be extracted and analyzed.</p><h2 id="callouts-continuing-the-reactive-development-cycle"> <a href="#callouts-continuing-the-reactive-development-cycle">Callouts: Continuing The Reactive Development Cycle</a></h2><p>Proposed is the “callout” method of system thread execution, born from the recognition that:</p><ol><li>A thread’s kernel stack, as identified by the kernel stack pointer in a thread’s ETHREAD object, can be analyzed asynchronously by a potential anti-cheat to detect traces of unsigned code execution; and that</li><li>To be useful in most cases, a system thread must be able to make calls to most external NT kernel or executive procedures with little compromise.</li></ol><h3 id="the-life-cycle-of-the-callout-thread"> <a href="#the-life-cycle-of-the-callout-thread">The Life-cycle of the Callout Thread</a></h3><p>The life-cycle of a callout thread is quite simple and can be used to demonstrate its implementation:</p><ul><li>Before thread creation:<ul><li>Allocate a non-paged stack to be loaded by the thread; the callout thread’s “real stack”</li><li>Allocate shellcode (ideally in executable memory not associated with the main driver module) which disables interrupts, preserves the old/kernel stack pointer (as it was on function entry), loads the real stack, and jumps to an initialization routine (the callout thread’s “bootstrap routine”)</li><li>Create a system thread (i.e. PsCreateSystemThread) whose start address points to the initialization shellcode</li></ul></li><li>At thread entry (i.e. the bootstrap routine):<ul><li>Preserve the stack pointer that had been given to the thread at thread entry (this must be given by the shellcode)</li><li>(Optionally) Iterate the thread’s old/kernel stack pointer, ceasing iteration at the stack base, eliminating any references/pointers to the initialization shellcode</li><li>(Optionally) Eliminate references to the initialization shellcode within the thread’s ETHREAD; for example, it may be worth changing the thread’s start address</li><li>(Optionally, but recommended) Free the memory containing the initialization shellcode, if it was allocated separately from the driver module</li><li>Proceed to thread execution</li></ul></li></ul><p>In clearer terms, the callout thread spends most of its time executing the driver’s unsigned code with interrupts disabled and with its own kernel stack - the real stack. It can also attempt to wipe any other traces of its execution which may have been present upon its creation.</p><h3 id="the-usefulness-of-the-callout-thread"> <a href="#the-usefulness-of-the-callout-thread">The Usefulness of the Callout Thread</a></h3><p>The callout thread must also be capable of executing most, if not all, NT kernel and executive procedures. As proposed, this is effectively impossible; the thread must run with interrupts disabled and with its own stack, thus creating an obvious problem as most procedures of interest would run at an IRQL &lt;= DISPATCH_LEVEL. Furthermore, the NT IRQL model may be liable to ignore our setting of the interrupt flag, causing most routines to unpredictibly enter a deadlock or enable interrupts without our consent.</p><p>A mechanism to allow for a callout thread to invoke these routines of interest, the callout mechanism, is therefore used to:</p><ol><li>Provide a routine which can be used to conveniently invoke (“call out”) an external function; and in this routine,</li><li>Load the thread’s original/kernel stack pointer;</li><li>Copy function arguments on to the kernel thread’s stack from the real stack;</li><li>Enable interrupts;</li><li>Invoke the requested routine (within the same instruction boundary as when interrupts are enabled);</li><li>Cleanly return from the routine without generating obvious stack traces (e.g. function pointers);</li><li>Load the real stack pointer and disable the interrupt flag, and do so before returning to unsigned code; and</li><li>Continue execution, preserving the function’s return value</li></ol><p>While somewhat complicated, the callout mechanism can be achieved easily and, to a reasonable degree, portably, using two widely-available ROP gadgets from within the NT kernel.</p><h3 id="the-usefulness-of-iretq"> <a href="#the-usefulness-of-iretq">The Usefulness of IRET(Q)</a></h3><p>The constraint of needing to load a new stack pointer, interrupt flag, and interrupt pointer within an instruction boundary was immediately satisfied by the IRET instruction.</p><p>For those unfamiliar, the IRET (lit. “interrupt return”) instruction is intended to be used by an operating system or executive (here, the NT kernel) to return from an interrupt routine. To support the recognition of an interrupt from any mode of execution, and to generically resume to any mode of execution, the processor will need to (effectively) preserve the instruction pointer, stack pointer, CPL or privilege level (through the CS and SS selectors; and while they have a more general use-case, this is effectively what is preserved on most operating systems with a flat memory model), and RFLAGS register (as interrupts may be liable to modify certain flags).</p><p>To report this information to the OS interrupt handler, the CPU will, in a specific order:</p><ol><li>Push the SS (stack segment selector) register;</li><li>Push the RSP (stack pointer) register;</li><li>Push the RFLAGS (arithmetic/system flags) register;</li><li>Push the CS (code segment selector) register;</li><li>Push the RIP (instruction pointer) register; and, for some exception-class interrupts,</li><li>Push an error code which may describe certain interrupt conditions (e.g. a page fault will know if the fault was caused by a non-present page, or if it were caused by a protection violation)</li></ol><p>Note that the error code is not important to the CPU and must be accounted for by the interrupt handler. Each operation is an 8-byte push, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://secret.club/2021/01/12/callout.html">https://secret.club/2021/01/12/callout.html</a></em></p>]]>
            </description>
            <link>https://secret.club/2021/01/12/callout.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25762322</guid>
            <pubDate>Wed, 13 Jan 2021 14:28:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS repeatedly warned Parler about posts urging murder]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25762164">thread link</a>) | @imraj96
<br/>
January 13, 2021 | http://e.customeriomail.com/e/c/eyJlbWFpbF9pZCI6ImRnT1I5d0tSOXdJQ0FBRjItNktITG9nMzJHMVJUMVpMMjM4PSIsImhyZWYiOiJodHRwczovL3d3dy5jb3VydGxpc3RlbmVyLmNvbS9yZWNhcC9nb3YudXNjb3VydHMud2F3ZC4yOTQ2NjQvZ292LnVzY291cnRzLndhd2QuMjk0NjY0LjEwLjBfMS5wZGY_dXRtX2NhbXBhaWduPSU1QlRJLUFNLUxFQURTJTVEK1RoZStJblx1MDAyNnV0bV9jb250ZW50PTEwMDI5NTlcdTAwMjZ1dG1fbWVkaXVtPWVtYWlsXHUwMDI2dXRtX3NvdXJjZT1jaW9cdTAwMjZ1dG1fdGVybT0xMDAwMzAxIiwicG9zaXRpb24iOjN9/a172f75edf7a67b53384dbdfe1e18c87ed799b438fb36dcbd364e9e32719d53a | <a href="https://web.archive.org/web/*/http://e.customeriomail.com/e/c/eyJlbWFpbF9pZCI6ImRnT1I5d0tSOXdJQ0FBRjItNktITG9nMzJHMVJUMVpMMjM4PSIsImhyZWYiOiJodHRwczovL3d3dy5jb3VydGxpc3RlbmVyLmNvbS9yZWNhcC9nb3YudXNjb3VydHMud2F3ZC4yOTQ2NjQvZ292LnVzY291cnRzLndhd2QuMjk0NjY0LjEwLjBfMS5wZGY_dXRtX2NhbXBhaWduPSU1QlRJLUFNLUxFQURTJTVEK1RoZStJblx1MDAyNnV0bV9jb250ZW50PTEwMDI5NTlcdTAwMjZ1dG1fbWVkaXVtPWVtYWlsXHUwMDI2dXRtX3NvdXJjZT1jaW9cdTAwMjZ1dG1fdGVybT0xMDAwMzAxIiwicG9zaXRpb24iOjN9/a172f75edf7a67b53384dbdfe1e18c87ed799b438fb36dcbd364e9e32719d53a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div è="">ì¸Ð±×ºA%'iŠˆZßŠ¬¤L¾þHv�ì‰$�Hdá12&gt;6Þ�ÚŒ’=lØ°¹äh“ÎN¬ø±òaç+ÔºÐK‰h"#­¤?UM²yJvÇÓØïøÊ·“})
r~¤±÷?AKfk—˜OPæJØ¨Ôo|ÊÔ-�o‹”vBŒLsÙï
“&lt;Êòk\{G=åøŽfSqþÝ›Ì±×{fkÆø:$ÒP5ôâC7¾€!Àb@P‡âíí{éÔð(ç{|øúúêš•è­¬ýúQ)±UW�Õ@AJÕ¯oµæ|6^Šœ�x!}v¨ÛjÃöqýE;Çû¿¿h\1N&gt;hL]�þC¦of<nz*÷�Òøwôç '�="" ¡n="" bð¥–Õí±°Ãº—,–Åê„-Ï="" h\Û’Žcßvpü“2ktbž'ØÕë�4woÀá²»!‹ì±="" n,èË—¤égá6Êo%5€"ª^œ¡eÈz»?¸»âaÏqi*="" ûzò])&e½ïin Æ¡px+m×<¸Ò½½€[„Þ\Ç‚í)ƒØ‘ò,ipÌa[öo‡&="" ¡°üŽ�nÀh•“p="" #€="" ª«ûù…""¼Ï©›+ŠÒ8àÔxvôåfÊË¡6‚eá“¢´ÆodŽ<ooéóoÉ³–»‘|àÏ�Ôp©£¢p�Çåˆ—ù[&øx’r’yÌ:)aÚrkø­�Œw+÷~åqÓâpú}xœ¿6="" l="" ¼à="" knsËÇÈú^r4"t–28ot$þi£.6nøx¾Ôç‘Ýçê�¥ùdaí‘j‡f£ü�aœÏ¼t3µ«“«¯~'¹^="" zvs’ÉaÔ:)Âkç"ôº­ü#Òéqn„×oàzÓˆ¦ÖÚ€Õ†Ó¸Œâ’5r="">ç1}v"L—O
­¹\Id”ª§é²’:_ŠrÞ¢Î®~½fËY±†^è5þÊ×‡Q�ÎNf‰å~ÆbvŸ[�–¿]ikßx\þý¾ˆUZäÎ7½&lt;$ºXFƒ7Ê¬Ô:bKüÍŒcTH†@u®±z,æš”šª”e”T×¢]‘Ý©ì¨Égë­ÚgþŸL&gt;�C+³ˆ4JË¨J9;×[çzì'ADöûôz%òÏcëv·]D£ö,§½H‚©ôjÚIòÞ•oÏ´¡­%à6j�Y[2âŠln*ÊŽóMÀÕ$a
‡	'—ÿI^«ÔMîr±·¶([wQßÚúä¬¡
endstream
endobj
54 0 obj
&lt;&gt;stream
xœ
Ì=‚@Eáþ­â–ZóîÅ`‰Ja%f6@` •ø»~§&lt;_qZyJÅ7â(dYè
›²*Öq…‚xM²ØuïÛ]ÿsªèêãÀ~î¿÷ôø€š«¹ÜÒ¥§yc†S7¥¼˜G0,ãUQZù�c%
endstream
endobj
58 0 obj
&lt;&gt;stream
xœ+äî|
endstream
endobj
2 0 obj
&lt;&gt;stream
xÚ•[YsÛF~×¯˜G&nbsp;JÄbwÞä+åÝXò:J¹¶â}&nbsp;JdBŒ@JI~}úš•€å*‘ ¦çèãë¯°V¹IJU5FéZÍªZ'ðõqyqñÛÅ›Û‹FüëƒVÚ¨Ûû­Rø§U‘'y­ªÔ$M©n·‘Žo¹x{ñß–*«ÚJ™3¤àC¤²3¤²ÔJågH¥¥•*¦KµÓFy†Tá´Q�!•9mÔgHi§�fŠT^£T^[müé4þÿí¿§
–Æês³Úšsuî³3³&amp;õ‚ù9‚e&nbsp;œâÁ<pnyŽ ”s�!hš@9õ9‚u œæÁÜ+Çœã9Æxå˜s<g7^9æÏÑ•wŽ9Çstá•cÎñmåœã9: ”sŽçt�nÇa‘²hê="" ’€n="" ­’:ƒdÀß)”ur¾~·(è;f�¤Òx="" Ì¸™†ÖõÛ©Œ*š$Íx="" 7Ÿã™n#ü«“,ºù1Öi}ŒË¤Šnág€.¸šåxï:žeð³ŠajºyÀÍø„k÷¢oø½„Ÿ�ê´ñÅr="" `$h"úxçækŒ="" ldÊf¼g�oøki[kqù="" rdw,ò?e³£ìØ¯9-æ|ä="" 1žæ="ÎžGx^">i	W_âüŠ ç¾¦O]oÏ?“ÝäÑ»÷´�$3"ùñ	®ûxV�D°˜�¢ïN˜CÚ†‹¨£Œ¨¹*zŠú¡ŠR¼ä[†`|Ûúó¾Î:‹+V AŸÐEM¦é"«�e�.r<p i="" ÿêšño3Ð’†="" q‚£x0�k¼ÛÀag±nè6�-i¼"ñ”z¢Ÿèà}¥Ý¦ô5¥�"þ$kg¼œ¬‘¾wòo<q¹�Æ�2‰�˜ƒ(Ï="" •�šaä¼$vÇÚÉ="" dh†â¤¡w1šwÎ.�ö\£šh°¾›ÁÅ×xw`ÒÇ8³·@[+ÖÖ­g="" ¸�ugz¤y–èfe´�s`ˆ\Ç§‡›šœí4Ä”g.ž7m’çáÆ�Ï(àocÄóÊ\£‰="" m�å9þe²òÃi²rkŽ¡ØÉý="" q4«+8ì×iË–pÚ@@dÚ²@Ê*\öè£="">ëš£¸ÁØ~+Ÿ±)‡ÐŸ²/ä°2µCÌÆ¤
M„F²FÓ7Ñ}œehém¹Bß%T¬Añ€'pñ´„•1Z»Ø&nbsp;ç–!—<f—°«Þag \Â„…—qÆóá´y–¦ÓŒ™è÷™ntÃ»Çéa²<Ú$´_œw1Ñ—,èî%í¦ ]¥`a\ü*6ÆžÈî¶©a—3„)]jÔk‘nt3l="" ¹2™³€bvÊÌrô|ò<%Á#—t7Çqt×Ž†û^gr­é="">¡�·³ÁÖJ¼¿…“b4%Æ¨£exçßLYáù*9÷xK¥Û„]´’û…,R›JñÊþ
+¤GÇãïQu¼�ßOªÍ‘	“7Xù±Ê&gt;&amp;Ód�?8™ëÛ/7ï(ËÿDnù�’u}¼A$ÒÑ5ÜÐ¯Úq&lt;¹N¡d«!A‹ƒÝ®b­ô+ð–àáœ2É°¤Œ¯Öìq4.»~ÏQ¤pXÝõúDC v;@U¸…~9x³&amp;ÛEÝCŒ	B
;ôF	‘%%âM¶R=Ì#ìI
81KÞÇ˜¦7¼7W¤ždw¸Ô3íw×¯yÅŽ¤‡ÿ*tÈ¢)‚�
n*š©Ç¿t�§ša•cÙSNS-¤ê²(�fáLQßáaé%žo!,ä�	ë^="¡óÀ(T@šeu‚d$Çímî‘´2çäÚ²LBgM‰j¼Ý±—¼vÔ^ÚÅV�ngI³Y´Ó­‘9cÃŽ?#.á„¼¹
+�÷ðHú
ê˜vPì9-î`ËÃzÚT(dOøDËF­:tÏ±±‡Ý°[mœ3ˆu¢$ñ0Ø#ºS×N·Ufœ­Ö¼H7§cßÑ:²ðZÜè�Øœ0»r‡{â�©{¾É
êå.[n%C¦‘,�j3˜u¬R­êz±É=éU®[XÌ£?™cö�úŠ¤…cêNýÈ,‡/ÙOëÅ’¸‘�Yo�Ÿj¸Ó\|eoú‘�nå``°bCŽ‡æíœWu{%Ê¢ëoÏš“³òòœÃ¬­ÝÞºaº½ÒÚÙKVX‰›îwÖ?ðçÿ:Ì	0ïgrN›&nbsp;i°c
—j8°*¤úg‘q ¨;‰'¢�€ÏnAF[û„ì`ŽI¤€Ïn¹Û°àœäºÎÆ2­ùàü‚vîcGÙÝy‡¼\Fîw‰K‘ÿã~í:âaÒ‡jÇ¸+³÷¸JÁ©zTï£«iÓ£«¨sg-6�&amp;1®‚Æ±?ævcvï‚÷Qs:9ê‘ãDLý$fšs8¯Do
�cÇÿÉøÎñ×az&nbsp;´&amp;!q»ât„ú—­„¹Bmltá.PI²UuÇ0�”EWÿN1«üÊ%+ñ:‚HãŽˆ(|`d$¸ˆ&lt;(Aù‡˜|10|-–Ù.»ý »è9;p�?Õ^¥ç}^´-ÙÕ*C¸�dþ^q,ôâ*;m«wnJytp%i¤W«ž¬8[Šýr›ÀqòÆ:å-§³.nIðàíyqÒÃYn¹‹õ„{L1Ë3z§ç�ãŒÜŠ½ ‘76�zWÃ�íFX?æs¿Qw–H1Íˆ¦C^‘Ó	»ª01 õ›Üývœivœ«Mb|8ðÀ�¼P;'«ØÉ*v2›œ8.¶¬:†}&gt;å%&amp;Á2±tî·»#Z5ci�YCU´q„�ü»’Ø1Œ^”Þ¹#&gt;áÙR#dŸ1¤Ähìj!ýÈldi—ì}¡”/-üzßåÚ–}‡ö&gt;p'kº™´y53á´=g'Þž�KÕwb=ú%
l—.�¢Arâí¹#€Û¯-~“R`à_f@õè3§|æJV7w=Š§®ˆ9¦½9æBL½çÄ:$kBš6Kµ·TEµ½†
Su‘XXZ1Y±yíSþp xË^`á%µÛL4&lt;5¹SÑ€Q¡Šìì]Éò�å.ó€»âw%Ïj^R¦/D‹�TŒ¤¨G'h=öpåÎÖ\ÝØDÖÍ¹Ñ´&nbsp;ûœ&lt;—¤})Ê†p-¤4†MC„†$8 ?\2uï‡ÖRß‡¸9'_äe�ßÅ=Ø:Þâk/ÙëIò:áTâ!�á pý5—¢Ã#‚F
å$�çG�`)Añ£®µŽI6ä@h¼±¹‰Ú&nbsp;¾iˆ­-|nüZžƒu(,DIj�¾K¦—ÛyîSë»XPwçVÎkqAÜH„èæ«BeqiGðÄ…¿ˆ÷œ¼F¬ø’±X‰&gt;ö¾Ü0¦b%M´K¸±ä|ë¬2Ùˆm‰²„êv9�-"ŽAUm�slHÓ6¼­£Ún
ŒÆ5-)‘ÓKìò�°�mÏP…ÎF
Ë’Ó½]ŸLÄaEO€´`ú71¢�k�ø„\áÖ³hBÐþ%ÛÑ&lt;Z6îoË}{[·»ø�[?µ
€{jf»ðqÜ¶õvñ:®î¨Ö©}íãy•ðPé×\ªÀ;\·à3?ï˜Å§çUÓaw•ƒp.¤&nbsp;cî&nbsp;EtÄ¢„o‰ö2ëÜ®Kp!ídóf�OàRE1¢àÅ�Oƒã^@ê80TM,ÐŽ¹«4¯fškNfXÌq²�TÒ5À.Ú©’”ÕÝw#-XðJx¥ØŒûÑ”é�4�l{Æòß™B¦ž×û•(0¥&lt;Æ6ømÑ±Ú­ÀF\Ê&amp;œ!ãéj/}z“Ûð	* ñ´­ƒ~¢–¹­‹X˜ÜŒK}r˜žù¯²MRA�å�¤r%ÂFŠŠ �Œ
Æ*òA5åIþ!MEW!Z–@
y±«&nbsp;#”'û«Þ¡që‹'[;¡æÃ^*ì./q\±úÇ¦(€TIfân’k¸fÄÖ�À—M§“Í™ç¯Ñ`)Ï¹'bÛÃ„$#R<vìqy¬é6Úïwr÷mfeù²u!É4¾ l¢«Žü|”ïÊfÞ ÜÉbh="" Ó·“:n Žø~="" §àƒddvûÂy£kkÈÔ¶!øl�™ÕÒÕgÜñž)'_q¥pq-`f•ÔeÀûy¹a[1…”žçqa5]o‡É6é+œï€‰«�qÆ»]pøÌ¥f@{8urú¾ÝÚzrÔt�š2Í"+knxØÊbâ¶cŒô óiv|×¿ðgsw›·rï�fk!ìíóñÞ÷|Ø{�dšhíhŒÓ–Ë%sí`š#6ÂtØÕÿ®æ$‹|ûaÅ4ln»¸lb¦y†="·eIðXs'ÅÊŽ°&amp;HDÓI±©|Ê}ËÜ²·Œ"> {.í¢·H‰"�ÜxÐMªm7	�ÆZ”¡¤&lt;¢ûbüÑÉÄUÅG†Kr!îsQ�""·éëhn_&nbsp;cKr¸lŸ“N˜Dø¯ëpº†±ã¹åODµ”I�/“¤$cöQO«îì“æ©¾“ûœ{èvžˆØbLc�ÔøÕG–ou\¡ dml7É–¬+‰ky&amp;¨º^yõëÒVZkÎw}ËÍ`€ú“ËÄ§º}ç*QËöå¨5uÅ”Þ­¯Ll!HŽÄ�ÛQ�A~mÕî‡Œ(|%"FŒÕS}F‹Ï˜ü˜zO3¨/nsú~Ìˆ(õíÙc7$l"ï…Ç?0×a‡IæÝ9Yjë­v.Û’snü»å¡[„r$	ö‚P«ÛU¬eƒjÛ»æ„TÎ¶jÈ‘Ú‡5áVîzû„“¾óef
§�ðI¢Å
ÿ(†�8Ý iÐÇyÛÀ¯‡•&lt;’–.�êÃ°”ÀY‡™¸¥‡³¯wY^¼–ß¶”W&gt;2NN|‹ OGÒð¥šÞò��·„b·ì=übÁ)ûq¨7h1DÚ·tó?|Þïée·/üÒÅ
oç'tMƒÞýMQmNä]¤öÕ#3ñT:Ï½Øg&gt;Òü‘&nbsp;bBàTo©‡±�!¦¡KÐY‚ûat;Xá‡³øXôŠz‡:1Ñà‰ù�‡î]÷O}òpÕ1’JlèÀ
$¹ÂÇªˆxÔ7‡mÎð
Ë^ÄöÒ!êf÷¬ÓOüðµ
·ˆ‡œï}‹ÇÏñš._¼&gt;W—&nbsp;Íì¬ÿ—@†3ÿ\¸]ç~Ç¨E{ôÌq92Âœë3ª‘4·l|Æá³¥_[nJÞ�TDMh‘}O$È¤•{|µíH­‚æ8&gt;j*	�
,ñìÚ&amp;zê…g7Â‰�OÕ	šJ)°wìËH¶ê„¾	¤j~ Øg¯&gt;·u�¸¸ëû_'¾Mw”qnŸCìÜ;ªè“
@×;nèFì·3ƒ–ÐÆö$ÞÿŽn
®H%,~þM�’¹ÌÅLÄ\ôÎ«±ìÀTZ¤å­ˆ¾±¦Þ+›õ‡=E¤çÍ\}7.±ìø�7�–^¡ëIs_ª
÷96–±�ñ�{èhP9¾ØØvÍ’¢9zá»D˜›¨ÊñåÊ!yÂ&nbsp;­tð¬ð Â90î(–î”�³%Fžû÷~	ÞâÖ×¯”¢Y?ïb÷wÌ;²t•à“ž7qBÏ_'Ü€
endstream
endobj
57 0 obj
&lt;&gt;stream
xœ
Ë=‚@Eáþ­â–ZóîŒb°D¥°ó6@` •ø»~§&lt;_rZyJmâ›Ø(dYè
›²*Ö6ˆBA¼&amp;YìºwBØºþçT5ÒÕÇ3€ýÜïéñ5Ws¹¥JÏà3œº)˜G0.í*“Vþ�ã'
endstream
endobj
60 0 obj
&lt;&gt;stream
xœ+äî|
endstream
endobj
4 0 obj
&lt;&gt;stream
xÚ�ZÛrÛF}×WÌÓP%b1ƒ{òäØÊ®S‰íµ•r¥l?P"%*&amp;Fe;_¿}�PRÆ®"EséÛéÓ=°æú¤tYmšÎÛšYÓÚþ¼]ž\�üqòÃùIOüûGk¬3çW'ÖäðßšªÌÊÖ4¹ËºÚœoN›žÿ~rv~ò¿¿U7­ŽrGŒ‚/U1ªÈuTyÄ¨¼ÖQÕôQUëµQ1ªòÚhŽUxm´GŒ²^Ý”Qe‹£ÊVµñ!±yúéü§©kÚcmèŽhË0°8b`Ñåa`yÌÀ:RNuÌÀ2RN}Ì@)§9b&nbsp;ë"å´Çl"åtÇ,ƒrÜ1žã\PŽ;Æsl”ãŽñÛå¸c&lt;ÇVA9îÏ±.RÎ1žcóH9ÇxNé&amp;rRWYÛ@°YeMÖ�øoJu“ÕOß­*ú3HÖX¼çÜLGë†í4ÎT]–¼—×oÒ™Íü´Y‘¼~—Ú¬M^¦uÖ$çp&nbsp;~ÍJ¼÷*�pÙ¤0%Ý¬àækø†Ÿî%¿àß5\¨³þ‰—8¬”á&lt;	šH~L¬óúmŠ`°“)KxâŒü‚WkÚZŽË¿…!UòŒ‡üfhv;¶Á"—&nbsp;Å’E~›¢4g8{™&nbsp;¼,i
¿Þ¦3ü r¿¢o—¼ú�Ê?“Ý”É‹3ÚF#xDù˜°¯†tÖÀˆ&amp;àaH¾s8a	i~Ì@ur‰šk’û´¢M’ã=ø�¿
ü€ç+ØÖÇ”÷epÖYÚ°Ñî]´dê‘.ŠYé¢D�[HcøiSThÁ—f&nbsp;%âŸê`Á<mñn‚ÎrÛÑmz¶¦á ÏùÒ="]&quot;Á+ú“v›ÓŸ9=(cãK²tÁËÉùÃçj¾Äé�X" )—9ˆ9ˆò¢2eÕ™fÎcbu¨�Òa@€8œ4ô"eóÎÙÀ="">à‚7h‡.Ù©ïðã}j0émZèíkÐÖŠµu‡Ö#œ§¶™niž%ºY�læ2®géá¦%g{bê/».+Ëxã?ƒgTðÙQ±Ã&lt;1×h"H€Fe‰ŸHV~~œ¬T‡šc(öã&gt;@ÍÚ„}?iÙ¤�†ˆL[(@ÝÄËþúÃè…ï¶å(î0¶ŸË7Fl�CèOÙrX™Ö#fçrƒ&amp;B#¹AÓwÉUZhém¹Bß%TlAñ€'ðã~	+c´ö©CÏÙ/	BNùC\Ã®fxû›´èà'Lèpð2-x&gt;œ¶(ò|š1‹
ý¾°™íx÷8=LV‚G»Œö‹³ã*.Yã’Ý=¥ÝT´«,ˆ‹?K�S‰t·]ºœ!LÙÚ¢^ª|¢›aj(�+¼Ý‹–PfV¢çC�—9!Š\ÓÝŸ¢»ú4Ü¯ðw!¿-Ý't¡çu6ØZ�÷7 )FsUc¼�@=-Ã;ÿèêåkDîñ–j¿	]´‘û•,ÒD›Êñ—^…òñxÅ+Toçë$2ðÝ€÷bÎý�¨#Ü1—)ºõÐ‹QÙeôWfÌt­–+aý[g“õå¥ñpç#P?˜hGéÐÒ—uð,)�§ÛâfÛ:Z²ZX,Y¯Ñ¹p´ƒ�aºã1¼”ÎŠ¾–Ö*`Ì„ÆÝ'öëí2•
&amp;ŸÍ�ºÅû&lt;
~ÂŽ1 ’o_‰Áû­ÿUfaapw»†hËæ„[ßqAE{Ô¨Îfèõ$ÀéÑ°‡
®ö¸Êþ�#ùÔL5OÝæÞ&lt;_RGnÆqfA£{ßðjK"
sš,8àu¸}AîÇÚÀñ°�žuÎŽ	Ê³$äbÉŒe»f¿.$˜�PPœu»Ã‚lL‹À#É€*³d!ž»c-áj‰¼¿aûûøBX¶ËØ˜0[Iv2�ë§8ÐO€dë‘Ž^Â6Ù$í@¥íXÃÆ°/S‹"ôæ†-‚€�½HP
k½‰§LYClpzFå­y¦¥7�¨.¸òsôñ³×¬&lt;Êõ]úÄ.à«¿7
ÏÅt¿ªj/õŠB�B7·&gt; ÑŸÿ„!m“Þo—]N]�ŒÙ6ê—Î&gt;ï»“ST¾2ŠvK]Ç»æˆV¸ø„‹cì\�Þ0	¾f¿iåâÐ+`ä:¨³az¿%t\Rª&lt;¼b3’Ëîe'bsKŸS(õŒ&lt;
F¢ˆU±gZ¶c-=Â%’‰
šMq$?¥nuj^ÐS/Èú`�ûé-œ·è‹ÔÑ†yÕµböÙWÆçÌ¼Ny]Á&lt;¹A‚{¸ÎÚ€S½m ¨+BÀµKg'Ápükôk\HžÝE`þ'³ÔÙç
ÑÖ{‹kÃZÛ•èšœaØ
øµ]a*dq9ÚÜ€¹�mäwÄðr‹dXÄ‡{Š
Æe�§Ê-·$ƒÊß¡¾9º�:‡Ðvyë'"#�‰^PMk&nbsp;ú#¬�j�©8ÆÌˆù‡Ô€i�L]×&nbsp;;¢ˆ\Pªªn"éHs1±ãÒ‘tÆ±Àr™S]q^�ïW©–’å†íßR
62ãçÓ�'ÃIum	Üd­O=²EDS�mÀŽY-\E‚¿Åb¶H¾×ÂK–•C.€|a‘M¼²npà¡Ž7¹˜)¿Ã‰Ám¦zEÕjÜåüÀ�€÷u‚˜+‘ä8_R	á�iî	ÄZ—dÓÆqŒ	t³Ò1¥Aô`‹©Eœ(È]ò;Fô~wÇO™~à˜ƒI0˜GÕÀ—{ÅºB8Ú8Oaá5svšË8ŽôÕRïA†ù,²·95£”«·ŒÃ6¤ Úèd£Ô�.hä&lt;Ï2kHY†KËI�Âõ&amp;ƒâ³Ý?ðY~X¼öYVé4Ô±•ºñ$ÆËA{©¾c9J‡ dÇfºRIÀ^0¥_�Ì2.Zy|-e€"ñ#¥¤#œcø]`\Íÿ�í0ìãZ&gt;éJE÷gƒ¯•‘:A=sÃ»ä|@-yH0Ú@“§:GX‚±ÏD¥¦!^EÅÝ&nbsp;X«@
¦8K;‰O%õkÆHE¹Y²ã\Ð{œ™çeŽÛx9øâÀ÷´•I¾æš)v,˜BÆ4?s]Ž-åxá!˜äˆó_i�ß9ÂÉœ¼†a¥MFO1ï¼æ
LÊ?âá…’‡9Í#�Á�ì}Àªo1ôÂW»:)±vé®$¨s�àtÇ°îP½¸$})µºØïnXÚž¯øšsà
Öx”[Ð%†ó$ªOØ�6c?fu1QEŸ¶(¤Õ¤t/ÄšQ}N±ÙS�AY`de¾ÙB¯½ý"&amp;�&lt;;GäzQt\Ü´rAðrHÂK*(}*Gy3ŽæÇí1-§#NVó(Š}
Œ,Ë0ò
6KÁßn)C²³¨f!ž±Ž°ÕCšÓöÀ-	Ë¡]'óž¡Ïp»îZ´xKó0§"\ÛÈxÛ£î8U|á‘"/­¸7,¾'?…5\X™÷er!7ÿ+…Ä�ÕêŸLZ&amp;×æ]Hê(XàòºE­Ë§¹9i¿”å5åºŸˆ‡î{	IëN�Ëm{Ê©¡ñý£"ª	E•c¡L$È{&amp;¡³ßš�óì=êîëüÔ0úkíÀ¹cEeN2¨œ‚ý£þ”Ù’Íe(`„µ.¤mz©
$"Lûé¥wYæã$Ax¾�Ò§ç0JÇã¢òžSÂ¥/7T€«T*]ßòÙ³E÷2õøéU€EzIE}”{Á�nnî¨	Ç$]º¥¼KÉ}¸—
‹óz:C€mFên©&nbsp;áq*5I¡ò°yÀQièZPvOó‡‹èâ´èi’§
¶ÇÔnë¿®�çBHˆZ�š+6@í¨Ð`:…X&amp;M"“”¢Tt¾‚F[íãÄu/p9ÎÕ5fýB;ª�G„¯Y
uLÁ÷¼tÉö€iI'å—6V�G©V÷¾U”…¾`
ûžå£†?em¸O„ü—ãs3
ßé©±èBjÄ•®qôR0U»YöwSs[”xdÏù’[›ë9|À£	˜­@&amp;!äÅos¾"ªÐˆ*p¸2l	°³é7»ç1)“?ö‚FR53ScN ö³£7¨{Z‹ÁI&lt;ƒÝ¾Øïö¼îmª-š‘�Œ©/ñÒ‹"³î¥ty®-7�ÜeLŽx‹Ò&lt;'^5Œê»éÎP‡:ZzSg}Š¨¿Ò\ ÑÒ¥&lt;Ô¤†Ï1˜4(¥RêÓãÕç|òÈ¹´âˆ\Üõ0Â…™É,K_È@5}sÉx(�`¾ãŽûU°¥áZ&amp;&nbsp;kÂBÆ¹/7kæ(D™|mr¯ÝMéÂGE½¬4W¶`EÛÀ6ñd²äÒ‹æ°Z„^j=*öãä7Õ2eÈìt&nbsp;ùpÜ…¢ŽÇV‹k¿l'}©‹˜M™u\¼`N?%ú'ï&gt;t”#¨Én Gmeòyœõ.Ç8ICBRò~NÉ†´þ&amp;”Ñ©•&gt;¯¼”¥@"&gt;&lt;øV¦óÑÌ…l�Ü7o™;mÇyuiäbbÈœ$šÔ…ôj¸q¥ÄíF÷QF‡Ó•
—ÿu™zJ'W
(síþyz‚ý1¸w¯L¬�lÓ‹k\òqG˜o6ïå¨Ìœ#9¥2ñ§ «JUã‡Š&gt;œÄÜÄiX‹]˜ÐþgcîâžvD¥àñKÁí’jÒ‰�CGÇà±*_ò±ÉÄÂ¸”TMÈ]6.Q&nbsp;c².GÓúYë(×ƒ?r�WÑ�v]`N²ÃÊŒ’ÔøÝ+/÷e&nbsp;Ä‹y�‡èX\XcV„s
cK“œÍœÑÛUàA¿Â2"¤´‚MI¹tˆ‰Öý–vÜ
õDN}ÌpA&lt;:¡´ròh©Ô£æ˜�9Ÿî	¨¦PŠå3ÈMðÁg×©•€ÄoüIbÍ“ƒÙ5�ª„Æ"µÙ�Gdáu8Òæšj�òAN�œ›�=%PHF„�x¬‹ŠhmùœÓ³ûÐH¤`!Üâ&amp;fèñ;ò&gt;‹B°:˜€í–HÊÂsf_µ1oÆ¶ƒuzî\(ØH_fŒ¢§†=ì¶´™n¸2p�uœ”ÃQG¯*E¤Bm&gt;àŠ„ú&nbsp;p‡»¸�3\H,œ~"‡fÜvÚuß™}¿XÒ›‘”â=�àFE­o¶ê±¸R\þyEÊ»"ÓNó½·«å%EíÔó|~1¯€ZÁ¦71Àüo¸G2÷M‰ux{E™Ž‘ÙÍµ*/åäsN…×‡gj‹4ÈòYƒ˜%ó­ÊCsØ÷àf£JCGÎ{:ïÏ°Î¥–�ž›µT4ê;£"†W.7„‹BG‹7…ÌEµ¾‹E°uœRâ¶Þcf(AñYU�[Óaç96FFoOâËWÙäôØ²SD³hA8Éª&lt;ÇwÊâñìT¶&lt;êÌã=?HÑ]œ¢©'3p=0ÑU-½žOËG�L,CÓ¡=l:HûCÎ„×Bœr3wT˜¥8å\ËïBYí×sNÑ—¤#iÁà¸w	˜SFÄž!DŠHf�‚äDäc2½¾¸E{“lzp’DàÑhÿFMùýœ¼;@,m-øºKp*|Û¦~ðâœ‘VI­¡¨“®†]ô¾šá†$sX…¼$�j{"û4^±—Ê�ðâžÏ�Üø½®Ñ;'¾ u½@•OfZqÍã›ÁZ@FÍ:Üö®põU»q¢ˆX9l'YÝÅ5Õpe†»•6yÛÐ‡B�"®ÚT;vzbµU`DÝ&gt;Õ‘Ê.D	T(¯æQQ¿¹Ú¯
�jfˆ�fÆ�†ÌÚÄäærz:ÞÚQÉ
ó’u!³=Ý�ŠûOícý§N_IKšMqÂ’£ÕMÈÿ¸ðŽLÈH5Qƒþ-Zåâ–™œó&lt;ÎoŽèÿ&nbsp;Ü$¬=&gt;ò¢è°pxsOÓp/Æ%õ€1û£‰·�ÞœåBè�ÁZ~%êIþ*üZR)¹U³ßBùÊ¨R®Ò,íPÈqàAoÕ¹X&gt;&lt;*gKoâ†pú!/î)oiÇ•¶¨ª7LX¤€§|«ißI¶'ƒia#í·Ðjì2¥NûYÔ€)’í 
½¿)®ÅXdªÿý¨G
endstream
endobj
59 0 obj
&lt;&gt;stream
xœ
È»‚@Ð~¾â–Z,;wW0Z‚RX‰™ °�B|~¿”ç4ò”ÒÄ×9`ƒ�E¦l‹]–GX/
ñeUµï„°tÝÏ©j¤+O‡¹û&gt;ÒôuQ}½§JÏà—8·cBÄ&lt;€qm79š4ò‚Ó*
endstream
endobj
62 0 obj
&lt;&gt;stream
xœ+äî|
endstream
endobj
6 0 obj
&lt;&gt;stream
xÚ�ZkoÜÆý®_1…€‚´,g†Ï´há&amp;và ±]G¨‘Úþ°W¦ª]r³/Ùÿ¾÷5�•¥fiÄÑî’¼ó¸�sÏ½C­&gt;�&amp;«TÝ¥5«�Á×Íâìæì÷³^žåðÄ_^h¥�º¼9Ó*‡ÿ´*‹¬hT�›¬­Ôåê,ÑéåÏž_žýë�¥ªºqRf‚|ˆ”� es'UL�Ê+'Už.U6^Õ©Òk£ž e½6š	RÚk£=EªhPªhœ6Þ':O?^þtª`e‚&nbsp;ž"h› h¦ê"Ú	‚¶Íƒ`1E°Š”SN,"åTSu¤œz‚&nbsp;i#å4SëH9íÁ"(ÇLñc‚rÌÏÑmPŽ™â9ºÊ1S<g—a9fŠçh)gŠçè<rÎÏ©#ÝdŽƒ"u™55$�•ze�…dÀß)tuv=}·,é;f�¬Öx Î¸˜–æ="" Ë©�*Û,·¼–×oÒ™Îü«3›¼þ5Õy“¼l«¬n.á"@üšxïu:³py¥0$Ý,áækø„Ÿ="" î%¿à÷="" .ÔiÿÄk+d¼„'aÉ‹ÔÀ<¯ß¦(�Âf†,à‰ç,ð^­hi9nÿdÊä‹ü¦ht”="¶Á[.@‹oùmŠ»yŽ£" î—wzÁ¯·é="" 7þŒ7="" û~eŸ&yõ£Ûÿlvs$?<§e´="" iáÙÈ‡„wðjlg5hd0�‹˜="" ùÎà€¤mø1utÉ5j®niiê$Ç{ðg¾yüÏ—°¬)¯ká¨³´f¢ì#ºhÈÔgº°5²="" Òe�n="" �á_�¢b-_š�–4d`ˆ|ª…="" ó´Á»-lt–ê–nÓ³‰×$žó¥]¢�—ô•v›Ó×œÙø’lmy:™#ÿú¹Š="" ñÀ6}àcÊdb¢Ü–ª([5ÃÈùšx="ÔNa" @,Š“†~hÑ¼sv°¸à-Ú¡m¶Îw-üx—êlºi­»ý="" ´Õ³¶vh="RÀeª-ìiCã,ÐÍªd5çÀ¹�w759ÛãS=pñ¢m³¢ˆþ3xF" [Š="" v˜'Æ:Ò qqà_$+??nvÊ‡šc(örï!Šfm="" ›}wÒ´ì69mz �uoûô‡ÑŸmÃqÜbl="" Ÿ±9<¡Êº�ÃbÈ41[“+4baÈ-š¾mnrkÑÒÚ²gß%tl@ñ€'ðã°€™1z‡Ô çì!üŒ"®`u3="" ¼ýmj[ø="" ^¤–ÇÃa­ÍóÓŒikô{«3Ýòêqx¬��6­gÇyl²Ä)kº{a«)iu9x'–ãvävÛ6 ËÂ”®4ê¥Ìot3l="" …2ÖÛ="" @Ñ6„2³="‚¼È" apËÝ-ð)ºëž†û%þ¶ò[Ó}bzÞ�k«ðþ="" vŠÑ\vo°¡�¦á•0u�û«eßÇkªü"Ü¤µÜ="" e’:ztŽ¿Üu˜!°="žñUÇËù|™�ø®Á{­˜s‹">ÔBú@‡Þúx‹ÂçqÄ
™PnnùãNáSÉÈ½¸Ø¯hè(P.R×ŒºòØkJààô´ØÀßh	%î€&gt;êdKIªIÆ
DƒNÔœ2&amp;&gt;„(�ëL”¸cO# LøÛ©5YcN›äk;ò?ÜžÁ).8.&gt; �àœã†þºÑœ7A2¹‡ÿ�@u‰ºÚà®4îŠ&amp;ðÛìQ¸f‚oK¿1�=ÃÝ"ºã„8Ï‚a›Õ²â±q´a—¡°z&lt;ì×v­šÜÛõ%Ðe'yDCÜ9VÏ?ã"u’)FõÁ5¤
Ä#nY„¥4oºª“+TbÃ7À?áªM¶{Ø�Aë­ÑÓêdØÞ¢€x=ì¯Žž²M@m�·*¶&gt;q·¦$¼?Ú.í®ÎŒÛî€×/�@^)xCaø'ÃÜ=ä/ù�eJ=a&lt;ó`Q:§	/ç{p«ì41@/öó}“Ì7KT{²�òøq©‘+kÌ.âæ;rB”êÐ4…MòEý;Õ!äG¦a}4îh«}&lt; 8�ÿæàeÜXPd,82V$Â—=iËl�dÔI–$¥Y¹¼ÆAÛ§›Ñd¯2Æ{(/sÅ†½ZD°&nbsp;LnòÉ’¸�whö_Y-j#{¿–ÝN9Œ×N!H¯Ç
E
!ã–°»oIv„	À©Ê„�‡§^ºÈw°©îÙds�#ýH£	¤çùc‰‚e�ó‰él&nbsp;oêÔäPå�×èŽÇïeßð•!tçA
-x„Ö-£5¬þ9Ž³7Xçš+$6Á…B#!* ŽZºn_8%õjdcÜ°}$S™32bò¸é•À;&gt;¦EŽˆk.®i¦½ì‘œåÀ�+£~H�¬p¦É(ªŠ×QÀh¯$õŠe&lt;ðâÅý®b\²¥®/N6AÙ„üÌþ(YšWtçtÆµŸƒ™X¼yÇ�Ð‡ö0&nbsp;¶÷ºàh[$�ÀNæd“¡So8šç&gt;!{ß¤øeKA®4ð‚sÒËzÍÖâ�Ç9ûšê•@é¨Ø¶ãpìHòKÅ»EèÇ{A)¡FzÇsqºf¡ñ…</g—a9fšçh)gšçè<rîï©#ýdžƒ"u™55$�•ze�…dàß)tuv=}·,é;f�¬öx></mñn‚îrûñmz¶¦á></vìqy¬é6úïwr÷mfeù²u!é4¾></f—°«þag></p></pnyž ”s�!hš@9õ9‚u œæáü+çœã9æxå˜s<g7^9æïñ•wž9çstá•cîñmåœã9:></nz*÷�òøwôç></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://e.customeriomail.com/e/c/eyJlbWFpbF9pZCI6ImRnT1I5d0tSOXdJQ0FBRjItNktITG9nMzJHMVJUMVpMMjM4PSIsImhyZWYiOiJodHRwczovL3d3dy5jb3VydGxpc3RlbmVyLmNvbS9yZWNhcC9nb3YudXNjb3VydHMud2F3ZC4yOTQ2NjQvZ292LnVzY291cnRzLndhd2QuMjk0NjY0LjEwLjBfMS5wZGY_dXRtX2NhbXBhaWduPSU1QlRJLUFNLUxFQURTJTVEK1RoZStJblx1MDAyNnV0bV9jb250ZW50PTEwMDI5NTlcdTAwMjZ1dG1fbWVkaXVtPWVtYWlsXHUwMDI2dXRtX3NvdXJjZT1jaW9cdTAwMjZ1dG1fdGVybT0xMDAwMzAxIiwicG9zaXRpb24iOjN9/a172f75edf7a67b53384dbdfe1e18c87ed799b438fb36dcbd364e9e32719d53a">http://e.customeriomail.com/e/c/eyJlbWFpbF9pZCI6ImRnT1I5d0tSOXdJQ0FBRjItNktITG9nMzJHMVJUMVpMMjM4PSIsImhyZWYiOiJodHRwczovL3d3dy5jb3VydGxpc3RlbmVyLmNvbS9yZWNhcC9nb3YudXNjb3VydHMud2F3ZC4yOTQ2NjQvZ292LnVzY291cnRzLndhd2QuMjk0NjY0LjEwLjBfMS5wZGY_dXRtX2NhbXBhaWduPSU1QlRJLUFNLUxFQURTJTVEK1RoZStJblx1MDAyNnV0bV9jb250ZW50PTEwMDI5NTlcdTAwMjZ1dG1fbWVkaXVtPWVtYWlsXHUwMDI2dXRtX3NvdXJjZT1jaW9cdTAwMjZ1dG1fdGVybT0xMDAwMzAxIiwicG9zaXRpb24iOjN9/a172f75edf7a67b53384dbdfe1e18c87ed799b438fb36dcbd364e9e32719d53a</a></em></p>]]>
            </description>
            <link>http://e.customeriomail.com/e/c/eyJlbWFpbF9pZCI6ImRnT1I5d0tSOXdJQ0FBRjItNktITG9nMzJHMVJUMVpMMjM4PSIsImhyZWYiOiJodHRwczovL3d3dy5jb3VydGxpc3RlbmVyLmNvbS9yZWNhcC9nb3YudXNjb3VydHMud2F3ZC4yOTQ2NjQvZ292LnVzY291cnRzLndhd2QuMjk0NjY0LjEwLjBfMS5wZGY_dXRtX2NhbXBhaWduPSU1QlRJLUFNLUxFQURTJTVEK1RoZStJblx1MDAyNnV0bV9jb250ZW50PTEwMDI5NTlcdTAwMjZ1dG1fbWVkaXVtPWVtYWlsXHUwMDI2dXRtX3NvdXJjZT1jaW9cdTAwMjZ1dG1fdGVybT0xMDAwMzAxIiwicG9zaXRpb24iOjN9/a172f75edf7a67b53384dbdfe1e18c87ed799b438fb36dcbd364e9e32719d53a</link>
            <guid isPermaLink="false">hacker-news-small-sites-25762164</guid>
            <pubDate>Wed, 13 Jan 2021 14:15:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thou shalt not run a database inside a container]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25761568">thread link</a>) | @swyx
<br/>
January 13, 2021 | https://patrobinson.github.io/2016/11/07/thou-shalt-not-run-a-database-inside-a-container/ | <a href="https://web.archive.org/web/*/https://patrobinson.github.io/2016/11/07/thou-shalt-not-run-a-database-inside-a-container/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <div>
        <div>
            <div>

				<p>So my last blog post, <a href="https://patrobinson.github.io/2016/11/05/docker-in-production/">Docker in Production: A retort</a>, generated a lot of comments. One of them was “Why shouldn’t you run a Database in Docker?” I’ve seen this questions a few times, but rarely reply because it’s such a long answer. But here goes.</p>

<p>EDIT: I’ve been made aware I’m not being clear that I am referring to running a database in a container management solution, like Kubernetes. The issues laid out below don’t relate to just running your database in docker with no shared storage or ability to start it automatically on a different node.</p>

<h2 id="kelsey-hightower-told-you-not-to">Kelsey Hightower told you not to</h2>

<p>He’s a smart guy, he’s worked at CoreOS and now works at Google. He has done some fantastic talks on Docker, Kubernetes and System Administration in general. <a href="https://youtu.be/Nosa5-xcATw?t=1080">Here’s him talking about it</a></p>

<h2 id="distributed-systems-are-hard">Distributed systems are hard</h2>

<p>Like really hard. But that’s ok when your application is stateless, because when it all goes to shit you just reboot things and they magically get better. But when your database gets fubar you can end up with permanent corruption. The most complex part of a distributed system is the <a href="https://en.wikipedia.org/wiki/Byzantine_fault_tolerance#The_Byzantine_Generals.27_Problem">Byzantine Generals problem</a>, which describes the problem of how we determine what is the source of truth and how do we know for certain it is the only source of truth. There are various solutions to this problem, usually implemented in the storage engine of databases. Some databases do this well, mostly NoSQL databases where it’s possible to shard data across multiple nodes by not supporting a JOIN operation. Traditional relational databases do not do this well, they generally only work  in a master-slave configuration. There are ways to run them in master-master configuration but you need a very specific skill type to execute this. If you’re doing this, well why are you reading my blog post? You know better than I do.</p>

<p>If you cannot determine what is the master node, which involves some kind of conensus algorithm and an odd number of nodes to vote on it, then you will end up with data loss and/or corruption.</p>

<h2 id="volume-management-for-docker-is-still-in-its-infancy">Volume management for Docker is still in it’s infancy</h2>

<p>There isn’t a well respected solution for how to do volume management for Docker clusters right now. Some people use NFS, but it lacks any kind of locking support on files (see <a href="http://0pointer.de/blog/projects/locking.html">this blog</a> for more details on linux file lock support). So you cannot guarentee that another system is not writing to your files.</p>

<p>GlusterFS is a recent successor to NFS, that offers much better performance, clustering and scalability. However it has several known issues that render locking unreliable.<a href="https://bugzilla.redhat.com/show_bug.cgi?id=1194546">1</a> <a href="https://bugzilla.redhat.com/show_bug.cgi?id=1287099">2</a></p>

<h2 id="you-lied-to-us-i-can-total-run-my-nosql-database-in-docker">You lied to us! I can total run my NoSQL database in Docker</h2>

<p>The answer here is it really depends on the underlying technology. As stated, there is no solution for filesystem level replication of data (except in a few proprietary solutions like AWS’s flagship database Aurora, VMware File System and Google File System, none of which tackle this specific use case). So instead we must rely on the storage engine of the database to do clustering and replication for us. Some are well known for their support of this (etcd, ElasticSearch and Riak KV to name a few), but it needs to be considered on a case by case basis to evaluate how well the particular database deals with this problem, because it’s so easy to get wrong.</p>

<h2 id="with-great-knowledge-comes-great-responsibility">With great knowledge comes great responsibility</h2>

<p>Now you know why there is significant anxiety to running databases in Docker, you have the power to make the decision for yourself.</p>

<p>If you find yourself wanting to learn more I highly recommend Pintrest’s blog on <a href="https://engineering.pinterest.com/blog/sharding-pinterest-how-we-scaled-our-mysql-fleet">how they sharded their MySQL Cluster</a>. They use Zookeeper, similar to etcd, to keep the configuration of which data lives in which MySQL database. This provides a highly available, consistent store. But they still recommend you “only read/write to the master… It simplifies everything and avoids lagged replication bugs.”</p>

<p>I’ve yet to see a blog post about somebody containerising their MySQL server and how it went really well.</p>

<h2 id="edit-some-solutions-to-the-problems-i-have-presented-here">EDIT: Some solutions to the problems I have presented here</h2>

<p>Some people have pointed out a couple of solutions to the problem presented here. One is the Kubernetes <a href="http://kubernetes.io/docs/user-guide/petset/">PetSet</a> concept. While still in Alpha (so obviuosly not fit for Production), this looks to be solving the exact problem of ensuring one and only one master exists at any one time.</p>

<p>Uber also <a href="https://eng.uber.com/dockerizing-mysql/">blogged about their dockerizing of MySQL</a> which is a very similar solution to the Kubernetes approach. They are defining the cluster topology up front, which guarentees a single master. They don’t talk about how they generate the master, but since that obviously comes from another source it’s likely highly consistent.</p>

<p>So today we still can’t run Docker inside a container cluster, but there are some good solutions on the roadmap.</p>

<p>Check out my <a href="http://patrobinson.github.io/2017/12/16/should-i-run-a-database-in-kubernetes/">follow up post</a> on this ∂subject.</p>


                <hr>

                

            </div>
        </div>
    </div>
</article></div>]]>
            </description>
            <link>https://patrobinson.github.io/2016/11/07/thou-shalt-not-run-a-database-inside-a-container/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25761568</guid>
            <pubDate>Wed, 13 Jan 2021 13:16:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A rabbit hole full of Lisp]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25760381">thread link</a>) | @mpereira
<br/>
January 13, 2021 | https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/ | <a href="https://web.archive.org/web/*/https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>At work I contribute to a moderately-sized monorepo at 70 thousand files,
8-digit lines of code and hundreds of PRs merged every day. One day I
opened a remote buffer at that repository and ran <code>M-x find-file</code>.</p><p><code>find-file</code> is an interactive function that shows a narrowed list
of files in the current directory, prompts the user to filter and scroll
through candidates, and for a file to open.</p><p>Emacs froze for <em>5 seconds</em> before showing me the <code>find-file</code> prompt. Which
isn’t great, because when writing software, opening files is actually
something one needs to do all the time.</p><figure><img src="https://www.murilopereira.com/find_file_linux.png"></figure><p>Luckily, Emacs is “the extensible, customizable, self-documenting real-time
display editor”, and comes with profiling capabilities: <code>M-x profiler-start</code>
starts a profile and <code>M-x profiler-report</code> displays a call tree showing how
much CPU cycles are spent in each function call after starting the profile.
Starting a profile and running <code>M-x find-file</code> showed that all time was being
spent in a function called <code>ffap-guess-file-name-at-point</code>, which was being
called by <code>file-name-at-point-functions</code>, an <a href="https://www.gnu.org/software/emacs/manual/html%5Fnode/emacs/Hooks.html#:~:text=A%20few%20hooks%20are%20abnormal,are%20used%20in%20some%20way.">abnormal hook</a> run when <code>find-file</code>
is called.</p><p>If you're familiar with Vim you can think of Emacs <i>hooks</i> as
Vim <i>autocommands</i>, only with much better ergonomics.</p><p>I checked the documentation for <code>ffap-guess-file-name-at-point</code> with <code>M-x describe-function ffap-guess-file-name-at-point</code> and it didn’t seem
to be something essential, so I removed the hook by running <code>M-x eval-expression</code>, writing the form below, and pressing <code>RET</code>.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>remove-hook</span> <span>'file-name-at-point-functions</span> <span>'ffap-guess-file-name-at-point</span>)
</code></pre></td></tr></tbody></table></div></div><p>This solved the immediate problem of Emacs blocking for 5 seconds every
time I ran <code>find-file</code>, with no noticeable drawbacks.</p><div><p>As I write this I attempt to reproduce the issue by re-adding
<code>ffap-guess-file-name-at-point</code>
to
<code>file-name-at-point-functions</code>.
I can't reproduce it anymore. The initial issue might have been</p><ul><li>caused by having manually mutated the Emacs environment via ad-hoc code
evaluation (drifting from the state defined in configuration)</li><li>caused by settings or packages that aren't in my configuration anymore</li><li>fixed by settings or packages that were recently added to my
configuration</li><li>fixed by some recent package upgrade</li></ul><p>Or some combination of the above. I have no idea exactly what.
Which is to say: maintaining Emacs configurations is complicated.</p></div><p>I could now navigate around and open files. The next thing I tried in this
remote git repository was searching through project files. The great
<em>projectile</em> package provides the <code>projectile-find-file</code> function for that,
but I had previously given up making projectile perform well with remote
buffers; given how things are currently implemented it seems to be
<a href="https://www.google.com/search?q=projectile+tramp">impractical</a>. So I installed the <em>find-file-in-project</em> package for use on
remote projects exclusively: <code>M-x package-install find-file-in-project</code>.</p><p>Most Emacs commands are accessible via key combinations, with defaults
that can be customized to be anything you want. I'll stick to referencing
command names themselves instead of their default keybindings.</p><p>Both <code>projectile-find-file</code> and <code>find-file-in-project</code> (aliased as <code>ffip</code>):</p><ul><li>show a narrowed list of all project files in the minibuffer</li><li>prompt the user to filter and scroll through candidates</li><li>open a file when <code>RET</code> is pressed on a candidate.</li></ul><figure><img src="https://www.murilopereira.com/projectile_find_file_linux.png"></figure><p>To disable projectile on remote buffers I had the following form in my
configuration.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>defadvice</span> <span>projectile-project-root</span> (<span>around</span> <span>ignore-remote</span> <span>first</span> <span>activate</span>)
  (<span>unless</span> (<span>file-remote-p</span> <span>default-directory</span> <span>'no-identification</span>) <span>ad-do-it</span>))
</code></pre></td></tr></tbody></table></div></div><p>Which causes the <code>projectile-project-root</code> function to not run its usual
implementation on remote buffers, but instead return <code>nil</code> unconditionally.
<code>projectile-project-root</code> is used as a way to either get the project root for
a given buffer (remote or not), or as a boolean predicate to test if the
buffer is in a project (e.g., a git repository directory). Having it return
<code>nil</code> on remote buffers effectively disables projectile on remote buffers.</p><p>Emacs
<i><a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Advising-Functions.html">advices</a></i> are a way of modifying the behavior of existing functions without
having to redefine them. They serve a similar purpose as hooks, but are
more flexible.</p><p>I then wrote a function that falls back to <code>ffip</code> when projectile is
disabled and bound it to the keybinding I had for <code>projectile-find-file</code>,
so that I could press the same keybinding whenever I wanted to search for
projects files, and not have to think about whether I’m on a remote buffer
or not:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>defun</span> <span>maybe-projectile-find-file</span> ()
  <span>"Run </span><span>`projectile-find-file'</span><span> if in a project buffer, </span><span>`ffip'</span><span> otherwise."</span>
  (<span>interactive</span>)
  (<span>if</span> (<span>projectile-project-p</span>)
      (<span>projectile-find-file</span>)
    (<span>ffip</span>)))
</code></pre></td></tr></tbody></table></div></div><p><code>projectile-project-p</code> uses <code>projectile-project-root</code> internally.</p><p>And called it:</p><p><code>M-x maybe-projectile-find-file</code></p><p>Emacs froze for <strong>30 seconds</strong>. After that, it showed the prompt with the
narrowed list of files in the project. 30 seconds! What was it doing during
the whole time? Let’s try out the profiler again.</p><ol><li><p>Start a new profile:</p><p><code>M-x profiler-start</code></p></li><li><p>Call the function to be profiled:</p><p><code>M-x maybe-projectile-find-file</code> (it freezes Emacs again for 30 seconds)</p></li><li><p>And display the report:</p><p><code>M-x profiler-report</code></p></li></ol><p>Which showed:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td><td><pre><code data-lang="text">Function                                                  CPU samples    %
+ ...                                                           21027  98%
+ command-execute                                                 361   1%
</code></pre></td></tr></tbody></table></div></div><p>This tells us that 98% of the CPU time was spent in whatever <code>...</code> is.
Pressing <code>TAB</code> on a line will expand it by showing its child function
calls.</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td><td><pre><code data-lang="text">Function                                                  CPU samples    %
- ...                                                           21027  98%
 + ivy--insert-minibuffer                                       13689  64%
 + #&lt;compiled 0x131f715d2b6fa0a8&gt;                                3819  17%
   Automatic GC                                                  2017   9%
 + shell-command                                                 1424   6%
 + ffip-get-project-root-directory                                 77   0%
 + run-mode-hooks                                                   1   0%
+ command-execute                                                 361   1%
</code></pre></td></tr></tbody></table></div></div><p>Expanding <code>...</code> shows that Emacs spent 64% of CPU time in
<code>ivy--insert-minibuffer</code> and 9% of the time—roughly 3 whole seconds!—
garbage collecting. I had <code>garbage-collection-messages</code> set to <code>t</code> so I could
already tell that Emacs was GCing a lot; enabling this setting makes a
message be displayed in the echo area whenever Emacs garbage collects. I
could also see the Emacs process consuming 100% of one CPU core while it was
frozen and unresponsive to input.</p><p>The <code>profiler</code> package implements a
<a href="https://en.wikipedia.org/wiki/Profiling_(computer_programming)#Statistical_profilers">sampling profiler</a>. The <code>elp</code>
package can be used for getting actual wall clock times.</p><p>Drilling down on <code>#&lt;compiled 0x131f715d2b6fa0a8&gt;</code> shows that cycles there
(17% of CPU time) were spent on Emacs waiting for user input, so we can
ignore it for now.</p><p>As I get deep in drilling down on <code>ivy--insert-minibuffer</code>, names in the
“Function” column start getting truncated because the column is too narrow.
A quick Google search (via <code>M-x google-this emacs profiler report width</code>)
shows me how to make it wider:</p><div><div><table><tbody><tr><td><pre><code><span>1
</span><span>2
</span></code></pre></td><td><pre><code data-lang="emacs-lisp">(<span>setf</span> (<span>caar</span> <span>profiler-report-cpu-line-format</span>) <span>80</span>
      (<span>caar</span> <span>profiler-report-memory-line-format</span>) <span>80</span>)
</code></pre></td></tr></tbody></table></div></div><p>Describing those variables with <code>M-x describe-variable</code> shows that the
default values are <code>50</code>.</p><p>From the profiler report buffer I run <code>M-x eval-expression</code>, paste the form
above with <code>C-y</code> and press <code>RET</code>. I also persist this form to my
configuration. Pressing <code>c</code> in the profiler report buffer (bound to
<code>profiler-report-render-calltree</code>) redraws it, now with a wider column,
allowing me to see the function names.</p><p>Here is the abbreviated expanded relevant portion of the call stack.</p><div><div><table><tbody><tr><td><pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span></code></pre></td><td><pre><code data-lang="text">Function                                                  CPU samples    %
- ffip                                                          13586  63%
 - ffip-find-files                                              13586  63%
  - let*                                                        13586  63%
   - setq                                                       13585  63%
    - ffip-project-search                                       13585  63%
     - let*                                                     13585  63%
      - mapcar                                                  13531  63%
       - #&lt;lambda 0xb210342292&gt;                                 13528  63%
        - cons                                                  13521  63%
         - expand-file-name                                     12936  60%
          - tramp-file-name-handler                             12918  60%
           - apply                                               9217  43%
            - tramp-sh-file-name-handler                         9158  42%
             - apply                                             9124  42%
              - tramp-sh-handle-expand-file-name                 8952  41%
               - file-name-as-directory                          5812  27%
                - tramp-file-name-handler                        5793  27%
                 + tramp-find-foreign-file-name-handler          3166  14%
                 + apply                                         1237   5%
                 + tramp-dissect-file-name                        527   2%
                 + #&lt;compiled -0x1589d0aab96d9542&gt;                337   1%
                   tramp-file-name-equal-p                        312   1%
                   tramp-tramp-file-p                              33   0%
                 + tramp-replace-environment-variables              6   0%
                   #&lt;compiled 0x1e202496df87&gt;                       1   0%
               + tramp-connectable-p                             1006   4%
               + tramp-dissect-file-name                          628   2%
               + eval                                            …</code></pre></td></tr></tbody></table></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/">https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/</a></em></p>]]>
            </description>
            <link>https://www.murilopereira.com/a-rabbit-hole-full-of-lisp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25760381</guid>
            <pubDate>Wed, 13 Jan 2021 10:43:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 Years(-Ish) of Elixir]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25760213">thread link</a>) | @signa11
<br/>
January 13, 2021 | https://dashbit.co/blog/ten-years-ish-of-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/ten-years-ish-of-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> January 11th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/elixir">elixir</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/broadway">broadway</a>, <a href="https://dashbit.co/blog/tags/nerves">nerves</a>, <a href="https://dashbit.co/blog/tags/liveview">liveview</a>, <a href="https://dashbit.co/blog/tags/membrane">membrane</a>
  </li>
</ul>
<p>
This past weekend, on January 9th, we celebrated 10 years since <a href="https://github.com/elixir-lang/elixir/commit/337c3f2d569a42ebd5fcab6fef18c5e012f9be5b">the first commit to the Elixir repository</a>. While I personally don’t consider <a href="https://elixir-lang.org/">Elixir</a> to be 10 years old yet - the language that became what Elixir is today <a href="https://github.com/elixir-lang/elixir/commit/6052352b6281752b905b30eb5b08fac0f51f68cd">surfaced only 14 months later</a> - a decade is a mark to celebrate!</p>
<p>
The goal of this post is to focus on the current state of some projects in the ecosystem and then briefly highlight a few of the exciting efforts coming over the next months.</p>
<h2>
Recap: The language goals</h2>
<p>
When I started working on Elixir, I personally had the ambition of using it for building scalable and robust web applications. However, I didn’t want Elixir to be tied to the web. My goal was to design an <em>extensible</em> language with a diverse ecosystem. Elixir aims to be a general purpose language and allows developers to extend it to new domains.</p>
<p>
Given Elixir is built on top of Erlang and Erlang is used for networking and distributed systems, Elixir would naturally be a good fit in those domains too, as long as I didn’t screw things up. The Erlang VM is essential to everything we do in Elixir, which is why <em>compatibility</em> has become a language goal too.</p>
<p>
I also wanted the language to be <em>productive</em>, especially by focusing on the tooling. Learning a functional programming language is a new endeavor for most developers. Consequently their first experiences getting started with the language, setting up a new project, searching for documentation, and debugging should go as smoothly as possible.</p>
<p>
Extensibility, compatibility, and productivity are the goals we built the language upon.</p>
<h2>
Recap: Elixir in production</h2>
<p>
Last year we started <a href="https://elixir-lang.org/cases.html">a series of articles on companies using Elixir in production on the official website</a>. As of today, we have 7 production cases listed with more coming this year! Overall it is very exciting to see many different companies using a variety of business models and industries running Elixir in production.</p>
<p>
Companies like <a href="https://www.brex.com/">Brex</a> (<a href="https://elixir-lang.org/blog/2020/06/23/growing-with-elixir-at-brex/">case</a>), <a href="https://discord.com/">Discord</a> (<a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">case</a>), <a href="https://getdivvy.com/">Divvy</a>, <a href="https://www.podium.com/">Podium</a>, and <a href="https://salesloft.com/">SalesLoft</a> have reached <a href="https://en.wikipedia.org/wiki/Unicorn_(finance)">“unicorn status”</a> and rely heavily on Elixir. Startups like <a href="https://www.joinblvd.com/">Boulevard</a> (<a href="https://soundcloud.com/elixirtalk/episode-166-feat-sean-stavropoulos">podcast</a>), <a href="https://community.com/">Community</a>, <a href="https://duffel.com/">Duffel</a> (<a href="https://elixir-lang.org/blog/2020/12/10/integrating-travel-with-elixir-at-duffel/">case</a>), <a href="https://www.ockam.io/">Ockam</a>, <a href="https://www.mux.com/">Mux</a>, <a href="https://ramp.com/">Ramp</a>, <a href="https://remote.com/">Remote</a>, and <a href="https://www.v7labs.com/">V7</a> (<a href="https://elixir-lang.org/blog/2021/01/13/orchestrating-computer-vision-with-elixir/">case</a>) also use Elixir and have received funding in the last year or two. Elixir is also used within known brands and enterprises such as <a href="https://bleacherreport.com/">Bleacher Report</a>, <a href="https://www.change.org/">Change.org</a> (<a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">case</a>), <a href="https://heroku.com/">Heroku</a> (<a href="https://elixir-lang.org/blog/2020/09/24/paas-with-elixir-at-Heroku/">case</a>), <a href="https://www.pagerduty.com/">PagerDuty</a>, <a href="https://www.pepsico.com/">PepsiCo</a>, and <a href="https://www.therealreal.com/">TheRealReal</a>.</p>
<p>
There is also a special category of startups that run Elixir alonside an open source model, such as <a href="https://plausible.io/">Plausible Analytics</a>, <a href="https://app.supabase.io/">Supabase</a>, <a href="https://logflare.app/">Logflare</a> (<a href="https://runninginproduction.com/podcast/11-logflare-is-a-log-management-and-event-analytics-platform">podcast</a>), and <a href="https://hex.pm/">Hex.pm</a> (<a href="https://runninginproduction.com/podcast/19-hexpm-is-elixirs-official-package-manager">podcast</a>) itself. Still on the open source front, you will find projects like <a href="https://pleroma.social/">Pleroma</a> and <a href="https://changelog.com/">Changelog</a>. There also many small scale and hobby projects that use Elixir for a productive and joyful development experience.</p>
<h2>
Recap: Diverse ecosystem</h2>
<p>
Today, Elixir has a diverse ecosystem that works on a wide range of domains and industries. Let’s take a look at some examples.</p>
<h3>
Web</h3>
<p>
Most developers are familiar with using Elixir for web development thanks to <a href="https://phoenixframework.org/">the Phoenix web framework</a>. Phoenix gained traction in the ecosystem because it was the first to fully leverage the language and the platform for building real-time applications besides the usual MVC (Model-View-Controller) offering.</p>
<p>
It all started with Phoenix Channels, as a bi-directional communication between clients and servers, and Phoenix PubSub, which uses Erlang’s distributed compatibilities to broadcast messages across nodes. As far as I know, Phoenix was the first major web framework to provide a multi-node web real-time solution completely out-of-the-box. Regardless if you are using one node or ten nodes, everything just works, with minimal configuration and dependencies.</p>
<p>
Phoenix has matured a lot since its first stable release. Phoenix v1.2 included <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Phoenix Presence</a>, that allows developers to track which users, IoT devices, etc are connected to your cluster right now. No databases or external dependencies required! This is one of the problems that look deceptively simple at first, but once you outline all scalability, performance, and fault-tolerance requirements, it <a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/">becomes quite complex</a>. Luckily, Phoenix is running on a platform that excels at these problems, and I am not aware of any other framework that provides such a lean and elegant solution as part of its default stack.</p>
<p>
Most recently, <a href="https://github.com/phoenixframework/phoenix_live_view">Phoenix LiveView</a> was released and brought new ways to build rich, real-time user experiences with server-rendered HTML, inspiring developers to attempt similar solutions for other languages and frameworks. You can read the <a href="https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript">original announcement</a> or <a href="https://www.phoenixframework.org/blog/build-a-real-time-twitter-clone-in-15-minutes-with-live-view-and-phoenix-1-5">learn how to build a real-time Twitter clone in 15 minutes</a>. As part of the <em>Live</em> family, we have also announced <a href="https://twitter.com/josevalim/status/1250846714665357315">Phoenix LiveDashboard</a>, making monitoring and instrumentation a first-class citizen for Phoenix applications.</p>
<h3>
Embedded and IoT</h3>
<p>
While I always expected Elixir to shine for building web applications, I was taken by surprise when I heard about the <a href="https://www.nerves-project.org/">Nerves platform</a> for creating high-end embedded applications. However, once I learned their premise, it all made sense: writing embedded systems <em>is</em> complicated. Reasoning about failures is hard. So what if we could leverage the decades of lessons learnt by Erlang/OTP to design embedded applications? What if a fault on the Wi-Fi driver could be fixed by having a supervisor simply restart it? After all, the first major use of Erlang/OTP was in an embedded system, the Ericsson AXD301 ATM switch.</p>
<p>
Nerves brings the Elixir ecosystem and the battle-tested Erlang VM to edge computing, providing a rich developer experience using proven technology. Nerves started as a one step process for turning an Elixir project into a complete software image for common hardware devices. Today, Nerves is being used in production in industrial automation, machine learning, consumer electronics and more, with <a href="https://farm.bot/">Farmbot</a> (<a href="https://elixir-lang.org/blog/2020/08/20/embedded-elixir-at-farmbot/">case</a>) and <a href="https://www.rosepoint.com/">Rose Point Navigation</a> being two of the most notable examples.</p>
<p>
The Nerves team also created <a href="https://www.nerves-hub.org/">NervesHub</a>, a fully open-source device management system. Combining all these technologies makes Elixir a comprehensive language for building end-to-end IoT platforms.</p>
<h3>
Data ingestion and pipelines</h3>
<p>
Shortly after Elixir v1.0 was released, the Elixir Core Team and I started looking into abstractions for tackling data ingestions and data pipelines in Elixir. We ran through a couple designs until we eventually <a href="https://elixir-lang.org/blog/2016/07/14/announcing-genstage/">landed on GenStage</a>: a behaviour for exchanging data with back-pressure between Elixir processes and external systems. For an introduction, make sure to check out <a href="https://youtu.be/srtMWzyqdp8?t=242">my keynote introducing both GenStage and Flow</a>.</p>
<p>
Today, almost 5 years later, GenStage has been used by many industries and has become one of the factors driving Elixir adoption. For example, you can read how both <a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">Discord</a> and <a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">Change.org</a> have built systems on Elixir and GenStage that handle spikes and run at massive scale.</p>
<p>
However, GenStage was just the beginning. In 2019, <a href="https://www.youtube.com/watch?v=ZOExnT1PYjs">we announced Broadway</a>, which is a higher-level abstraction on top of GenStage that makes building data ingestion pipelines a breeze. We originally released with Amazon SQS support. Nowadays, RabbitMQ, Google Cloud PubSub, Apache Kafka, and other sources (known as producers in Broadway terms) are also available.</p>
<h3>
Audio/Video streaming</h3>
<p>
Since the Erlang VM was designed for scalable network processing, one can expect to also be an excellent platform for audio and video streaming. However, if you also wanted to process and transform those streams on the fly, the situation becomes much more complicated as you likely have to integrate with native code.</p>
<p>
Luckily, the tables have turned when Erlang/OTP 20 was released a couple years ago with the so-called Dirty NIFs. The Erlang VM always had the ability to invoke native code, but this native code could not run for long, as to not interfere with the preemptive features of the Erlang runtime. Dirty NIFs allow developers to tag native code either as IO or CPU bound, which runs on specific threads. Between ports (I/O based), NIFs, Dirty NIFs, and remote nodes, developers now have many options to interface with native code with different performance and reliability guarantees. That’s exactly the foundation the <a href="http://www.membraneframework.org/">Membrane Framework</a> builds on top of.</p>
<p>
Membrane was extracted from RadioKit, a startup aiming at disrupting the radio broadcasting industry. Originally it focused on processing and mixing audio. Later, <a href="https://www.swmansion.com/">Software Mansion</a> acquired the framework and provided stable funding and a solid team to help it grow into a full-scale framework. Currently, it allows developers to process, transmit, broadcast, and transform audio and videos streams on the fly. Whether you are building a Twitch clone, a VOD application or a video conferencing system, Membrane provides a growing set of high-level abstractions and pre-made modules so you don’t have to dive into idiosyncrasies of particular codecs, protocols, and formats. </p>
<h2>
Looking ahead: what is coming in 2021</h2>
<p>
The year of 2021 looks very exciting for the Erlang Ecosystem and the Elixir community. In this section, we are going to mention some of the things we expect to see in 2021.</p>
<h3>
Erlang/OTP 24 with JIT</h3>
<p>
In September 2020, <a href="https://github.com/erlang/otp/pull/2745">Lukas Larsson and the Erlang/OTP team</a> announced a JIT compiler for the Erlang VM called BeamAsm. How faster the JIT will be in practice depends on your application but the results posted in the announcement are promising. To quote Lukas:</p>
<blockquote>
  <p>
If we run the JSON benchmarks found in the <a href="https://github.com/devinus/poison/tree/master/bench">Poison</a> or <a href="https://github.com/michalmuskala/jason/tree/master/bench">Jason</a>, BeamAsm achieves anything from 30% to 130% increase (average at about 70%) in the number of iterations per second for all Erlang/Elixir implementations. For some benchmarks, BeamAsm is even faster than the pure C implementation <a href="https://github.com/davisp/jiffy">jiffy</a>.  </p>
</blockquote>
<blockquote>
  <p>
More complex applications tend to see a more moderate performance increase, for instance, RabbitMQ is able to handle 30% to 50% more messages per second depending on the scenario.  </p>
</blockquote>
<p>
I have been running …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/ten-years-ish-of-elixir">https://dashbit.co/blog/ten-years-ish-of-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/ten-years-ish-of-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25760213</guid>
            <pubDate>Wed, 13 Jan 2021 10:13:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Milestone: Half a million downloads for VideoLAN packages in the .NET ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25760180">thread link</a>) | @martz
<br/>
January 13, 2021 | https://mfkl.github.io/2021/01/13/half-a-million-downloads.html | <a href="https://web.archive.org/web/*/https://mfkl.github.io/2021/01/13/half-a-million-downloads.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
            <p> 




  1 minute read

</p>
          
        </header>
      

      <section itemprop="text">
        
        <p><a href="https://www.nuget.org/profiles/videolan">The NuGet VideoLAN account</a> just reached half a million downloads in the .NET ecosystem.</p>

<p>
    <a href="https://nugettrends.com/packages?months=24&amp;ids=VideoLAN.LibVLC.Windows&amp;ids=LibVLCSharp&amp;ids=LibVLCSharp.Forms&amp;ids=VideoLAN.LibVLC.iOS&amp;ids=VideoLAN.LibVLC.Android"><img src="https://mfkl.github.io/assets/nugettrends.png"></a>
</p>

<p>The first publication of the first VideoLAN NuGet package dates back to April 1st, 2018 (no joke!). We have been steadily adding new packages since then to cover all platforms supported by both LibVLC and .NET.</p>

<p>Today, we actively publish and maintain <strong>15 NuGet packages</strong>, 6 of which  actually containing native platform-specific code. The remaining 9 packages are managed C# DLLs composed of the main binding (<a href="https://www.nuget.org/packages/LibVLCSharp/">LibVLCSharp</a>) and various GUI toolkit integrations for getting users up and running quickly.</p>

<ul>
  <li>Xamarin.Android</li>
  <li>Xamarin.iOS</li>
  <li>Xamarin.tvOS</li>
  <li>Xamarin.Mac (Cocoa)</li>
  <li>Windows Classic (WPF, WinForms, GTK)</li>
  <li>Windows Universal (UWP for Desktop, mobile and Xbox)</li>
  <li>Linux including desktop, server and Raspberry Pi (GTK)</li>
  <li>Xamarin.Forms</li>
  <li>Uno Platform (UWP, Android, iOS)</li>
  <li>Avalonia (Windows, macOS, Linux)</li>
</ul>

<p>LibVLCSharp counts about <strong>19 contributors</strong>, with most people doing one-off contributions and mainly 2 active maintainers (<a href="https://github.com/jeremyVignelles">Jérémy</a> and myself). I’d like to thank each of them for their valuable OSS contributions!</p>



<p>Many exciting things! More game engine integrations, ongoing LibVLC 4 support, interop performance improvements and plenty of new integrations, samples and features are yet to be implemented.</p>

<p>We have a diverse and (mostly) well-defined <a href="https://code.videolan.org/videolan/LibVLCSharp/-/issues">backlog</a> of both features to implement and bugs to fix, with a varying degree of difficulty, and always welcome new contributors. We are available on the <a href="https://discord.gg/3h3K3JF">LibVLC community Discord server</a> (320+ members).</p>

<p>Feel free to let me know what you think on <a href="https://twitter.com/martz2804">Twitter</a>.</p>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://mfkl.github.io/2021/01/13/half-a-million-downloads.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25760180</guid>
            <pubDate>Wed, 13 Jan 2021 10:07:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Foam: A personal knowledge management and sharing system for VSCode]]>
            </title>
            <description>
<![CDATA[
Score 388 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25760066">thread link</a>) | @lelf
<br/>
January 13, 2021 | https://foambubble.github.io/foam/ | <a href="https://web.archive.org/web/*/https://foambubble.github.io/foam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      






<p><strong>Foam</strong> is a personal knowledge management and sharing system inspired by <a href="https://roamresearch.com/">Roam Research</a>, built on <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>.</p>

<p>You can use <strong>Foam</strong> for organising your research, keeping re-discoverable notes, writing long-form content and, optionally, publishing it to the web.</p>

<p><strong>Foam</strong> is free, open source, and extremely extensible to suit your personal workflow. You own the information you create with Foam, and you’re free to share it, and collaborate on it with anyone you want.</p>

<p>
  <b>New!</b> Join <a href="https://discord.gg/rtdZKgj" target="_blank">Foam community Discord</a> for users and contributors!
</p>



<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#foam">Foam</a>
    <ul>
      <li><a href="#table-of-contents">Table of Contents</a></li>
      <li><a href="#how-do-i-use-foam">How do I use Foam?</a></li>
      <li><a href="#whats-in-a-foam">What’s in a Foam?</a></li>
      <li><a href="#getting-started">Getting started</a></li>
      <li><a href="#features">Features</a></li>
      <li><a href="#call-to-adventure">Call To Adventure</a></li>
      <li><a href="#thanks-and-attribution">Thanks and attribution</a></li>
      <li><a href="#license">License</a></li>
    </ul>
  </li>
</ul>

<h2 id="how-do-i-use-foam">How do I use Foam?</h2>

<p><strong>Foam</strong> is a tool that supports creating relationships between thoughts and information to help you think better.</p>

<p><img src="https://foambubble.github.io/foam/assets/images/foam-features-dark-mode-demo.png" alt="Foam kitchen sink, showing a few of the key features"></p>

<p>Whether you want to build a <a href="https://www.buildingasecondbrain.com/">Second Brain</a> or a <a href="https://zettelkasten.de/posts/overview/">Zettelkasten</a>, write a book, or just get better at long-term learning, <strong>Foam</strong> can help you organise your thoughts if you follow these simple rules:</p>

<ol>
  <li>Create a single <strong>Foam</strong> workspace for all your knowledge and research following the <a href="#getting-started">Getting started</a> guide.</li>
  <li>Write your thoughts in markdown documents (I like to call them <strong>Bubbles</strong>, but that might be more than a little twee). These documents should be atomic: Put things that belong together into a single document, and limit its content to that single topic. (<a href="https://zettelkasten.de/posts/overview/#principles">source</a>)</li>
  <li>Use Foam’s shortcuts and autocompletions to link your thoughts together with <code>[[wiki-links]]</code>, and navigate between them to explore your knowledge graph.</li>
  <li>Get an overview of your <strong>Foam</strong> workspace using a [<a href="https://foambubble.github.io/foam/features/graph-visualisation.md" title="Graph Visualisation">graph-visualisation</a>] (⚠️ WIP), and discover relationships between your thoughts with the use of [<a href="https://foambubble.github.io/foam/features/backlinking.md" title="Backlinking">backlinking</a>].</li>
</ol>

<p>Foam is a like a bathtub: <em>What you get out of it depends on what you put into it.</em></p>

<h2 id="whats-in-a-foam">What’s in a Foam?</h2>

<p>Like the soapy suds it’s named after, <strong>Foam</strong> is mostly air.</p>

<ol>
  <li>The editing experience of <strong>Foam</strong> is powered by VS Code, enhanced by workspace settings that glue together [<a href="https://foambubble.github.io/foam/recommended-extensions.md" title="Recommended Extensions">recommended-extensions</a>] and preferences optimised for writing and navigating information.</li>
  <li>To back up, collaborate on and share your content between devices, Foam pairs well with <a href="http://github.com/">GitHub</a>.</li>
  <li>To publish your content, you can set it up to publish to <a href="https://pages.github.com/">GitHub Pages</a> with zero code and zero config, or to any website hosting platform like <a href="http://netlify.com/">Netlify</a> or <a href="https://vercel.com/">Vercel</a>.</li>
</ol>

<blockquote>
  <p><strong>Fun fact</strong>: This documentation was researched, written and published using <strong>Foam</strong>.</p>
</blockquote>

<h2 id="getting-started">Getting started</h2>

<blockquote>
  <p>⚠️ Foam is still in preview. Expect the experience to be a little rough.</p>
</blockquote>

<p>These instructions assume you have a GitHub account, and you have Visual Studio Code installed.</p>

<ol>
  <li>
    <p>Use the <a href="https://github.com/foambubble/foam-template">foam-template project</a> to generate a new repository. If you’re logged into GitHub, you can just hit this button:</p>

    <p><a href="https://github.com/foambubble/foam-template/generate" data-icon="octicon-repo-template" data-size="large" aria-label="Use this template foambubble/foam-template on GitHub">Use this template</a></p>

    <p><em>If you want to keep your thoughts to yourself, remember to set the repository private, or if you don’t want to use GitHub to host your workspace at all, choose <a href="https://github.com/foambubble/foam-template/archive/master.zip"><strong>Download as ZIP</strong></a> instead of <strong>Use this template</strong>.</em></p>
  </li>
  <li>
    <p><a href="https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository">Clone the repository locally</a> and open it in VS Code.</p>

    <p><em>Open the repository as a folder using the <code>File &gt; Open...</code> menu item. In VS Code, “open workspace” refers to <a href="https://code.visualstudio.com/docs/editor/multi-root-workspaces">multi-root workspaces</a>.</em></p>
  </li>
  <li>
    <p>When prompted to install recommended extensions, click <strong>Install all</strong> (or <strong>Show Recommendations</strong> if you want to review and install them one by one)</p>
  </li>
</ol>

<p>After setting up the repository, open <code>.vscode/settings.json</code> and edit, add or remove any settings you’d like for your Foam workspace.</p>

<p>To learn more about how to use <strong>Foam</strong>, read the [<a href="https://foambubble.github.io/foam/recipes/recipes.md" title="Recipes">recipes</a>].</p>

<p>Getting stuck in the setup? Read the [<a href="https://foambubble.github.io/foam/frequently-asked-questions.md" title="Frequently Asked Questions">frequently-asked-questions</a>].</p>

<p>Check our <a href="http://github.com/foambubble/foam/issues">issues on GitHub</a> if you get stuck on something, and create a new one if something doesn’t seem right!</p>

<h2 id="features">Features</h2>

<p><strong>Foam</strong> doesn’t have features in the traditional sense. Out of the box, you have access to all features of VS Code and all the [<a href="https://foambubble.github.io/foam/recommended-extensions.md" title="Recommended Extensions">recommended-extensions</a>] you choose to install, but it’s up to you to discover what you can do with it!</p>

<p><img src="https://foambubble.github.io/foam/assets/images/foam-navigation-demo.gif" alt="Short video of Foam in use"></p>

<p>Head over to [<a href="https://foambubble.github.io/foam/recipes/recipes.md" title="Recipes">recipes</a>] for some useful patterns and ideas!</p>

<h2 id="call-to-adventure">Call To Adventure</h2>

<p>The goal of <strong>Foam</strong> is to be your personal companion on your quest for knowledge.</p>

<p>It’s currently about “10% ready” relative to all the features I’ve thought of, but I’ve only thought of ~1% of the features it could have, and I’m excited to learn from others.</p>

<p>I am using it as my personal thinking tool. By making it public, I hope to learn from others not only how to improve Foam, but also to improve how I learn and manage information.</p>

<p>If that sounds like something you’re interested in, I’d love to have you along on the journey.</p>

<ul>
  <li>Read about our [<a href="https://foambubble.github.io/foam/principles.md" title="Principles">principles</a>] to understand Foam’s philosophy and direction</li>
  <li>Read the [<a href="https://foambubble.github.io/foam/contribution-guide.md" title="Contribution Guide">contribution-guide</a>] guide to learn how to participate.</li>
  <li>Feel free to open <a href="https://github.com/foambubble/foam/issues">GitHub issues</a> to give me feedback and ideas for new features.</li>
</ul>

<h2 id="thanks-and-attribution">Thanks and attribution</h2>

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody><tr>
    <td><a href="https://jevakallio.dev/"><img src="https://avatars1.githubusercontent.com/u/1203949?v=4?s=60" width="60px;" alt=""><br><sub><b>Jani Eväkallio</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=jevakallio" title="Code">💻</a> <a href="https://github.com/foambubble/foam/commits?author=jevakallio" title="Documentation">📖</a></td>
    <td><a href="https://joeprevite.com/"><img src="https://avatars3.githubusercontent.com/u/3806031?v=4?s=60" width="60px;" alt=""><br><sub><b>Joe Previte</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=jsjoeio" title="Code">💻</a> <a href="https://github.com/foambubble/foam/commits?author=jsjoeio" title="Documentation">📖</a></td>
    <td><a href="https://github.com/riccardoferretti"><img src="https://avatars3.githubusercontent.com/u/457005?v=4?s=60" width="60px;" alt=""><br><sub><b>Riccardo</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=riccardoferretti" title="Code">💻</a> <a href="https://github.com/foambubble/foam/commits?author=riccardoferretti" title="Documentation">📖</a></td>
    <td><a href="http://ojanaho.com/"><img src="https://avatars0.githubusercontent.com/u/2180090?v=4?s=60" width="60px;" alt=""><br><sub><b>Janne Ojanaho</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=jojanaho" title="Code">💻</a> <a href="https://github.com/foambubble/foam/commits?author=jojanaho" title="Documentation">📖</a></td>
    <td><a href="http://bypaulshen.com/"><img src="https://avatars3.githubusercontent.com/u/2266187?v=4?s=60" width="60px;" alt=""><br><sub><b>Paul Shen</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=paulshen" title="Documentation">📖</a></td>
    <td><a href="https://github.com/coffenbacher"><img src="https://avatars0.githubusercontent.com/u/245867?v=4?s=60" width="60px;" alt=""><br><sub><b>coffenbacher</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=coffenbacher" title="Documentation">📖</a></td>
    <td><a href="https://mathieu.dutour.me/"><img src="https://avatars2.githubusercontent.com/u/3254314?v=4?s=60" width="60px;" alt=""><br><sub><b>Mathieu Dutour</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=mathieudutour" title="Documentation">📖</a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/presidentelect"><img src="https://avatars2.githubusercontent.com/u/1242300?v=4?s=60" width="60px;" alt=""><br><sub><b>Michael Hansen</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=presidentelect" title="Documentation">📖</a></td>
    <td><a href="http://klickverbot.at/"><img src="https://avatars1.githubusercontent.com/u/19335?v=4?s=60" width="60px;" alt=""><br><sub><b>David Nadlinger</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=dnadlinger" title="Documentation">📖</a></td>
    <td><a href="https://pluckd.co/"><img src="https://avatars2.githubusercontent.com/u/20598571?v=4?s=60" width="60px;" alt=""><br><sub><b>Fernando</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=MrCordeiro" title="Documentation">📖</a></td>
    <td><a href="https://github.com/jfgonzalez7"><img src="https://avatars3.githubusercontent.com/u/58857736?v=4?s=60" width="60px;" alt=""><br><sub><b>Juan Gonzalez</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=jfgonzalez7" title="Documentation">📖</a></td>
    <td><a href="http://www.louiechristie.com/"><img src="https://avatars1.githubusercontent.com/u/6807448?v=4?s=60" width="60px;" alt=""><br><sub><b>Louie Christie</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=louiechristie" title="Documentation">📖</a></td>
    <td><a href="https://supersandro.de/"><img src="https://avatars2.githubusercontent.com/u/7258858?v=4?s=60" width="60px;" alt=""><br><sub><b>Sandro</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=SuperSandro2000" title="Documentation">📖</a></td>
    <td><a href="https://github.com/Skn0tt"><img src="https://avatars1.githubusercontent.com/u/14912729?v=4?s=60" width="60px;" alt=""><br><sub><b>Simon Knott</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=Skn0tt" title="Documentation">📖</a></td>
  </tr>
  <tr>
    <td><a href="https://styfle.dev/"><img src="https://avatars1.githubusercontent.com/u/229881?v=4?s=60" width="60px;" alt=""><br><sub><b>Steven</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=styfle" title="Documentation">📖</a></td>
    <td><a href="https://github.com/Georift"><img src="https://avatars2.githubusercontent.com/u/859430?v=4?s=60" width="60px;" alt=""><br><sub><b>Tim</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=Georift" title="Documentation">📖</a></td>
    <td><a href="https://github.com/sauravkhdoolia"><img src="https://avatars1.githubusercontent.com/u/34188267?v=4?s=60" width="60px;" alt=""><br><sub><b>Saurav Khdoolia</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=sauravkhdoolia" title="Documentation">📖</a></td>
    <td><a href="https://anku.netlify.com/"><img src="https://avatars1.githubusercontent.com/u/22813027?v=4?s=60" width="60px;" alt=""><br><sub><b>Ankit Tiwari</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=anku255" title="Documentation">📖</a> <a href="https://github.com/foambubble/foam/commits?author=anku255" title="Tests">⚠️</a> <a href="https://github.com/foambubble/foam/commits?author=anku255" title="Code">💻</a></td>
    <td><a href="https://github.com/ayushbaweja"><img src="https://avatars1.githubusercontent.com/u/44344063?v=4?s=60" width="60px;" alt=""><br><sub><b>Ayush Baweja</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=ayushbaweja" title="Documentation">📖</a></td>
    <td><a href="https://github.com/TaiChi-IO"><img src="https://avatars3.githubusercontent.com/u/65092992?v=4?s=60" width="60px;" alt=""><br><sub><b>TaiChi-IO</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=TaiChi-IO" title="Documentation">📖</a></td>
    <td><a href="https://github.com/juanfrank77"><img src="https://avatars1.githubusercontent.com/u/12146882?v=4?s=60" width="60px;" alt=""><br><sub><b>Juan F Gonzalez </b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=juanfrank77" title="Documentation">📖</a></td>
  </tr>
  <tr>
    <td><a href="https://sanketdg.github.io/"><img src="https://avatars3.githubusercontent.com/u/8980971?v=4?s=60" width="60px;" alt=""><br><sub><b>Sanket Dasgupta</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=SanketDG" title="Documentation">📖</a> <a href="https://github.com/foambubble/foam/commits?author=SanketDG" title="Code">💻</a></td>
    <td><a href="https://github.com/nstafie"><img src="https://avatars1.githubusercontent.com/u/10801854?v=4?s=60" width="60px;" alt=""><br><sub><b>Nicholas Stafie</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=nstafie" title="Documentation">📖</a></td>
    <td><a href="https://github.com/francishamel"><img src="https://avatars3.githubusercontent.com/u/36383308?v=4?s=60" width="60px;" alt=""><br><sub><b>Francis Hamel</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=francishamel" title="Code">💻</a></td>
    <td><a href="http://digiguru.co.uk/"><img src="https://avatars1.githubusercontent.com/u/619436?v=4?s=60" width="60px;" alt=""><br><sub><b>digiguru</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=digiguru" title="Code">💻</a> <a href="https://github.com/foambubble/foam/commits?author=digiguru" title="Documentation">📖</a></td>
    <td><a href="https://github.com/chirag-singhal"><img src="https://avatars3.githubusercontent.com/u/42653703?v=4?s=60" width="60px;" alt=""><br><sub><b>CHIRAG SINGHAL</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=chirag-singhal" title="Code">💻</a></td>
    <td><a href="https://github.com/lostintangent"><img src="https://avatars3.githubusercontent.com/u/116461?v=4?s=60" width="60px;" alt=""><br><sub><b>Jonathan Carter</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=lostintangent" title="Documentation">📖</a></td>
    <td><a href="https://www.synesthesia.co.uk/"><img src="https://avatars3.githubusercontent.com/u/181399?v=4?s=60" width="60px;" alt=""><br><sub><b>Julian Elve</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=synesthesia" title="Documentation">📖</a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/thomaskoppelaar"><img src="https://avatars3.githubusercontent.com/u/36331365?v=4?s=60" width="60px;" alt=""><br><sub><b>Thomas Koppelaar</b></sub></a><br><a href="#question-thomaskoppelaar" title="Answering Questions">💬</a> <a href="https://github.com/foambubble/foam/commits?author=thomaskoppelaar" title="Code">💻</a> <a href="#userTesting-thomaskoppelaar" title="User Testing">📓</a></td>
    <td><a href="http://www.akshaymehra.com/"><img src="https://avatars1.githubusercontent.com/u/8671497?v=4?s=60" width="60px;" alt=""><br><sub><b>Akshay</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=MehraAkshay" title="Code">💻</a></td>
    <td><a href="http://johnlindquist.com/"><img src="https://avatars0.githubusercontent.com/u/36073?v=4?s=60" width="60px;" alt=""><br><sub><b>John Lindquist</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=johnlindquist" title="Documentation">📖</a></td>
    <td><a href="https://ashwin.run/"><img src="https://avatars2.githubusercontent.com/u/1689183?v=4?s=60" width="60px;" alt=""><br><sub><b>Ashwin Ramaswami</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=epicfaace" title="Documentation">📖</a></td>
    <td><a href="https://github.com/Klaudioz"><img src="https://avatars1.githubusercontent.com/u/632625?v=4?s=60" width="60px;" alt=""><br><sub><b>Claudio Canales</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=Klaudioz" title="Documentation">📖</a></td>
    <td><a href="https://github.com/vitaly-pevgonen"><img src="https://avatars0.githubusercontent.com/u/6272738?v=4?s=60" width="60px;" alt=""><br><sub><b>vitaly-pevgonen</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=vitaly-pevgonen" title="Documentation">📖</a></td>
    <td><a href="https://dshemetov.github.io/"><img src="https://avatars0.githubusercontent.com/u/1810426?v=4?s=60" width="60px;" alt=""><br><sub><b>Dmitry Shemetov</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=dshemetov" title="Documentation">📖</a></td>
  </tr>
  <tr>
    <td><a href="https://github.com/hooncp"><img src="https://avatars1.githubusercontent.com/u/48883554?v=4?s=60" width="60px;" alt=""><br><sub><b>hooncp</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=hooncp" title="Documentation">📖</a></td>
    <td><a href="http://rt-canada.ca/"><img src="https://avatars1.githubusercontent.com/u/13721239?v=4?s=60" width="60px;" alt=""><br><sub><b>Martin Laws</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=martinlaws" title="Documentation">📖</a></td>
    <td><a href="http://seanksmith.me/"><img src="https://avatars3.githubusercontent.com/u/2085441?v=4?s=60" width="60px;" alt=""><br><sub><b>Sean K Smith</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=sksmith" title="Code">💻</a></td>
    <td><a href="https://www.linkedin.com/in/kevin-neely/"><img src="https://avatars1.githubusercontent.com/u/37545028?v=4?s=60" width="60px;" alt=""><br><sub><b>Kevin Neely</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=kneely" title="Documentation">📖</a></td>
    <td><a href="https://ariefrahmansyah.dev/"><img src="https://avatars3.githubusercontent.com/u/8122852?v=4?s=60" width="60px;" alt=""><br><sub><b>Arief Rahmansyah</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=ariefrahmansyah" title="Documentation">📖</a></td>
    <td><a href="http://vhanda.in/"><img src="https://avatars2.githubusercontent.com/u/426467?v=4?s=60" width="60px;" alt=""><br><sub><b>Vishesh Handa</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=vHanda" title="Documentation">📖</a></td>
    <td><a href="http://www.linkedin.com/in/heroichitesh"><img src="https://avatars3.githubusercontent.com/u/37622734?v=4?s=60" width="60px;" alt=""><br><sub><b>Hitesh Kumar</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=HeroicHitesh" title="Documentation">📖</a></td>
  </tr>
  <tr>
    <td><a href="https://spencerwoo.com/"><img src="https://avatars2.githubusercontent.com/u/32114380?v=4?s=60" width="60px;" alt=""><br><sub><b>Spencer Woo</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=spencerwooo" title="Documentation">📖</a></td>
    <td><a href="https://ingalless.com/"><img src="https://avatars3.githubusercontent.com/u/22981941?v=4?s=60" width="60px;" alt=""><br><sub><b>ingalless</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=ingalless" title="Code">💻</a> <a href="https://github.com/foambubble/foam/commits?author=ingalless" title="Documentation">📖</a></td>
    <td><a href="http://jmg-duarte.github.io/"><img src="https://avatars2.githubusercontent.com/u/15343819?v=4?s=60" width="60px;" alt=""><br><sub><b>José Duarte</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=jmg-duarte" title="Code">💻</a> <a href="https://github.com/foambubble/foam/commits?author=jmg-duarte" title="Documentation">📖</a></td>
    <td><a href="https://www.yenly.wtf/"><img src="https://avatars1.githubusercontent.com/u/6759658?v=4?s=60" width="60px;" alt=""><br><sub><b>Yenly</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=yenly" title="Documentation">📖</a></td>
    <td><a href="https://www.hikerpig.cn/"><img src="https://avatars1.githubusercontent.com/u/2259688?v=4?s=60" width="60px;" alt=""><br><sub><b>hikerpig</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=hikerpig" title="Code">💻</a></td>
    <td><a href="http://sigfried.org/"><img src="https://avatars1.githubusercontent.com/u/1586931?v=4?s=60" width="60px;" alt=""><br><sub><b>Sigfried Gold</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=Sigfried" title="Documentation">📖</a></td>
    <td><a href="http://www.tristansokol.com/"><img src="https://avatars3.githubusercontent.com/u/867661?v=4?s=60" width="60px;" alt=""><br><sub><b>Tristan Sokol</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=tristansokol" title="Code">💻</a></td>
  </tr>
  <tr>
    <td><a href="https://umbrellait.com/"><img src="https://avatars0.githubusercontent.com/u/49779373?v=4?s=60" width="60px;" alt=""><br><sub><b>Danil Rodin</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=umbrellait-danil-rodin" title="Documentation">📖</a></td>
    <td><a href="https://www.linkedin.com/in/scottjoewilliams/"><img src="https://avatars1.githubusercontent.com/u/2026866?v=4?s=60" width="60px;" alt=""><br><sub><b>Scott Williams</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=scott-joe" title="Documentation">📖</a></td>
    <td><a href="https://jackiexiao.github.io/blog"><img src="https://avatars2.githubusercontent.com/u/18050469?v=4?s=60" width="60px;" alt=""><br><sub><b>jackiexiao</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=Jackiexiao" title="Documentation">📖</a></td>
    <td><a href="https://generativist.substack.com/"><img src="https://avatars3.githubusercontent.com/u/78835?v=4?s=60" width="60px;" alt=""><br><sub><b>John B Nelson</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=jbn" title="Documentation">📖</a></td>
    <td><a href="https://github.com/asifm"><img src="https://avatars2.githubusercontent.com/u/3958387?v=4?s=60" width="60px;" alt=""><br><sub><b>Asif Mehedi</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=asifm" title="Documentation">📖</a></td>
    <td><a href="https://github.com/litanlitudan"><img src="https://avatars2.githubusercontent.com/u/4970420?v=4?s=60" width="60px;" alt=""><br><sub><b>Tan Li</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=litanlitudan" title="Code">💻</a></td>
    <td><a href="http://shaunagordon.com/"><img src="https://avatars1.githubusercontent.com/u/579361?v=4?s=60" width="60px;" alt=""><br><sub><b>Shauna Gordon</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=ShaunaGordon" title="Documentation">📖</a></td>
  </tr>
  <tr>
    <td><a href="https://mcluck.tech/"><img src="https://avatars1.githubusercontent.com/u/1753801?v=4?s=60" width="60px;" alt=""><br><sub><b>Mike Cluck</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=MCluck90" title="Code">💻</a></td>
    <td><a href="http://brandonpugh.com/"><img src="https://avatars1.githubusercontent.com/u/684781?v=4?s=60" width="60px;" alt=""><br><sub><b>Brandon Pugh</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=bpugh" title="Code">💻</a></td>
    <td><a href="https://max.davitt.me/"><img src="https://avatars1.githubusercontent.com/u/27709025?v=4?s=60" width="60px;" alt=""><br><sub><b>Max Davitt</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=themaxdavitt" title="Documentation">📖</a></td>
    <td><a href="http://briananglin.me/"><img src="https://avatars3.githubusercontent.com/u/2637602?v=4?s=60" width="60px;" alt=""><br><sub><b>Brian Anglin</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=anglinb" title="Documentation">📖</a></td>
    <td><a href="http://deft.work/"><img src="https://avatars1.githubusercontent.com/u/1455507?v=4?s=60" width="60px;" alt=""><br><sub><b>elswork</b></sub></a><br><a href="https://github.com/foambubble/foam/commits?author=elswork" title="Documentation">📖</a></td>
  </tr>
</tbody></table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->

<p><strong>Foam</strong> was inspired by <a href="https://roamresearch.com/">Roam Research</a> and the <a href="https://zettelkasten.de/posts/overview">Zettelkasten methodology</a></p>

<p><strong>Foam</strong> wouldn’t be possible without <a href="https://code.visualstudio.com/">Visual Studio Code</a> and <a href="https://github.com/">GitHub</a>, and relies heavily on our fantastic open source [<a href="https://foambubble.github.io/foam/recommended-extensions.md" title="Recommended Extensions">recommended-extensions</a>] and all their contributors!</p>

<h2 id="license">License</h2>

<p>Foam is licensed under the <a href="https://foambubble.github.io/foam/license">MIT license</a>.</p>







      
      
      
    </div></div>]]>
            </description>
            <link>https://foambubble.github.io/foam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25760066</guid>
            <pubDate>Wed, 13 Jan 2021 09:51:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Year Work Retrospective]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25759512">thread link</a>) | @bshanks
<br/>
January 13, 2021 | https://simpixelated.com/two-year-work-retrospective | <a href="https://web.archive.org/web/*/https://simpixelated.com/two-year-work-retrospective">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>2020-07-14</time> — <a href="https://simpixelated.com/tags/work">work</a>, <a href="https://simpixelated.com/tags/ghost-inspector">Ghost Inspector</a>, <a href="https://simpixelated.com/tags/agile">Agile</a> — <span>3<!-- --> min read</span></p><section><p>It's been almost two years since I last published anything about work. A lot has changed for me. I gave up management by quitting my job as a Director of Engineering and took a job as just a good ol' Software Engineer at <a href="https://ghostinspector.com/">Ghost Inspector</a>. A lot of reasoning went into that decision, but to sum it up: I was sick of commuting and managing. Considering what's happened in the last year, I'm glad I made that choice!</p><p>As a lifelong introvert, I was being drained on a daily basis by having to manage other people. I had been juggling that while still coding for about four years straight. During that time, I was a user of Ghost Inspector, so when the opportunity opened up, I jumped at the chance to work there and I'm so glad that I did.</p><p>What attracted me to Ghost Inspector was the product, but what has kept me here is the amazing work environment. There may be bigger, more exciting challenges in the job market, but working here is without a doubt the best job I've ever had! For most of my career, I jumped from company to company, looking for that "hockey stick growth". But what I eventually realized is that I'd rather have stability and trust. At previous startups, we were only stable for the few months after the most recent funding round.&nbsp;<a href="https://ghostinspector.com/about/">Justin and the rest of the team</a>&nbsp;have built a business that grows at a very sustainable pace. We're only beholden to our customers, not venture capital investors. The only deadlines are the ones we set for ourselves, and those are pretty rare.</p><p>The typical Agile process used by most software companies creates a lot of meetings that, in my opinion, are not respectful of a software developer's time. The majority of meetings are focused on determining what they should work on, when they should start, and how long it should take. A system designed around tracking velocity with points, will heavily incentivize speed and efficiency. So now all those meetings talking about work, instead of doing it, feel like impediments to completing points. I have worked at places that handle this better than others, but there's always that underlying pressure that creates at least a bit of animosity around meetings.</p><p>We have a completely different process at Ghost Inspector. I would describe our software development methodology as Agile-lite -- we take the few good parts and leave the rest behind. We have a backlog of epics and stories with all the good features we want to deliver to our customers. However we&nbsp;<strong>don't do sprints</strong>. Without sprints, we're able to skip all the other Agile rituals that I personally loath. Here's a list of all the&nbsp;<a href="https://dzone.com/articles/types-of-meetings-in-scrum-and-agile">meetings we don't do</a>. No sprints means no sprint planning. No points means no estimation meetings. Without a product owner needing to constantly check the velocity of every story, we don't need to give a status update every day. We generally only meet once a week. Thankfully, not once do I remember anyone saying the word "blocker".</p><p>I've lost track of the amount of time wasted on just scheduling meetings at previous companies. Even the daily status was always hotly debated. Too early and all the night owls are grumbling. Too late and you risk interrupting the flow of the early birds. I can't tell you how nice it is to stop thinking so much about&nbsp;<em>how</em>&nbsp;we work and instead just think about the actual work. My levels of stress have been reduced to an extremely low level while working here. The meetings we do have feel particularly important and useful and I welcome them!</p><p>As a developer, I have all the autonomy I could ever wish for. There are constant opportunities to learn new skills. We don't work on the bleeding edge by any means, but we have a diverse set of projects that allow us to experiment with new technologies. Here's a truncated list of all the different projects I've worked on in the last year and a half:</p><ul><li><a href="https://ghostinspector.com/blog/continuous-integration-testing-for-wordpress/">a WordPress plugin with e2e tests in Docker on CI</a></li><li>two-factor authentication using Auth0</li><li>rebuilt the browser extension in React.js</li><li>built a user-facing search engine with Elasticsearch</li><li>added API endpoints to export to CSV (with documentation!)</li><li>created a deploy script with an <a href="https://github.com/nanovazquez/yargs-interactive">interactive CLI</a> and GitHub action checks</li><li>wrote <a href="https://ghostinspector.com/blog/ghost-inspector-wordpress-plugin/">several</a> <a href="https://ghostinspector.com/blog/develop-wordpress-plugin-with-webpack-and-react/">different</a> <a href="https://ghostinspector.com/blog/automated-ui-testing-for-wordpress/">blog</a> <a href="https://ghostinspector.com/blog/continuous-integration-testing-for-wordpress/">posts</a></li></ul><p>All of this is possible because we have a rock-solid customer base, a stable system for our application, a team who trusts and respects each other, and a CEO who enables us to do our best work. I'm really happy to have joined the team.</p><p>Follow me on <a href="https://twitter.com/simpixelated">Twitter</a> and don't hesitate to send me a message if you have any questions about moving from management back to individual contributor, or using the good parts of agile, or how to avoid meetings! Or leave a <a href="https://news.ycombinator.com/item?id=25759512">comment on HackerNews</a>.</p></section></div></div>]]>
            </description>
            <link>https://simpixelated.com/two-year-work-retrospective</link>
            <guid isPermaLink="false">hacker-news-small-sites-25759512</guid>
            <pubDate>Wed, 13 Jan 2021 08:18:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surprising Uses of Email]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25759470">thread link</a>) | @Zanneth
<br/>
January 13, 2021 | http://zanneth.com/2020/12/28/surprising-uses-of-email.html | <a href="https://web.archive.org/web/*/http://zanneth.com/2020/12/28/surprising-uses-of-email.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<hr>

<p>Email is a powerful tool that is an inextricable part of everyone’s lives.
Despite countless valiant efforts to kill it and replace it with something
better, email continues to live on in more or less the same form it has had
since the 1990s. Technology that endures this long deserves a fair amount of
attention and praise.</p>

<p>There are two main reasons why email continues to be useful today. It is simple
to use, and it is not owned or controlled by a single company. Every attempted
replacement has failed at excelling in either one or both of those qualities.
Simple tools can often be extended in ways that the original authors never could
have imagined in the beginning. And because users are in control of the core
functionality, new use cases can be explored completely independently.</p>

<p>Computer users have a tendency to over-generalize when solving problems. In
other words, when all you have is a hammer, everything looks like a nail. In
this post, we are going to be looking at a lot of nails that can probably be
hammered down with email. At a fundamental level, email clients are tools
designed for storing and retrieving sequences of messages which can contain
arbitrary data. Looking at it this way, it is not difficult to imagine a variety
of use cases that can be accomplished with minimal amounts of scripting.</p>

<p>I do seriously think that email is a solid tool for a lot of these purposes, and
in fact use it as such for a few of these purposes every day. However, the main
purpose of this post is exploration, not general advice.</p>

<h2 id="to-do-list-one-that-you-actually-check">To-Do List (One That You Actually Check)</h2>

<p><img src="http://zanneth.com/assets/post-assets/email/todo-list.png" alt="To-Do List"></p>

<p>The first use case is pretty obvious, and it is one that likely a large number of
people already employ on a daily basis.</p>

<p>By far the single most important productivity discovery that I made in my life
is <a href="http://www.43folders.com/2006/01/04/email-dmz">Inbox Zero</a>. Inbox Zero is
the simple idea that your email inbox should contain only a list of messages
that require some sort of action. Once the action associated with those messages
is completed, the message is archived or moved to a different folder. I have
been using Inbox Zero for years now and I rarely forget to do anything
important after integrating it into my life.</p>

<p>Need to remember to pack for your flight next week? You probably already got a
confirmation about your reservation in your email. Leave it in your inbox until
you are finished preparing for your trip, and archive it when you are done.</p>

<p>How about one-off reminders that are not associated with messages already in
your inbox? Just send an email to yourself with the action item in the subject
line. Use the body of the message to write down any notes you want, and reply to
the message to keep a record of additional notes if you need them.</p>

<p>What about periodic reminders that repeat on some interval, like reminding
yourself to pay a bill on time every month? Write a simple script that sends you
an email about it and schedule it to run once a month. At the end of each month,
you will have a new to-do item in your inbox with an actionable task in the
subject line.</p>

<p>The great part about using email as a to-do list is that you are already
checking it with some degree of regularity. Smartphone apps or web-based to-do
lists quickly lose their value the moment users lose interest or switch to using
something else. They also frequently become buggy or overburdened with features
that don’t add any value. This will never be a problem with email because you
can always use your favorite client as long as it continues to work with the
standard protocols. Syncing across multiple devices is a given, since your email
is already doing this.</p>

<h2 id="news-reader">News Reader</h2>

<p><img src="http://zanneth.com/assets/post-assets/email/rss2email.png" alt="RSS"></p>

<p>RSS is a really elegant and simple way to subscribe to a feed of updates from
your favorite websites. Since the early 2000s, RSS has been integrated into a
lot of different services all across the net, and serves as the foundation for a
variety of different web-based content platforms such as podcasts.</p>

<p>In order to actually use RSS, you need a client that is capable of aggregating
entries from multiple different feeds and displaying them in some manner.
Managing a list of entries, tracking read or unread state, and displaying HTML
content is exactly what every email client is already good at doing.</p>

<p>I like using <a href="https://github.com/rss2email/rss2email">rss2email</a> for this.
rss2email delivers stories from my feeds into a special mailbox on my email
server that I check approximately every morning. Since the end result is just
IMAP messages stored on my email server, I can read them using my favorite
email client on whatever device I happen to be using that day.</p>



<p><img src="http://zanneth.com/assets/post-assets/email/update-blog.png" alt="Updating a Blog"></p>

<p>Setting up a frictionless workflow for updating your personal website can be
rather difficult, especially if you want to be able to do it while on-the-go and
away from your usual workstation.</p>

<p>If you are maintaining a blog on a personal website or for a business, the focus
should primarily be on the content itself and not on writing markup, updating a
source control repository, or publishing static content to a file server or
database. At the end of the day, you want to be able to write your content in a
message and send it to your server to publish.</p>

<p>Writing rich-text or plain-text content, saving drafts, and publishing that
content to a server is the perfect job for an email client. Your email client
can even allow including inline images sent as attachments, or links that point
to other websites. Once you are done writing your post, send it to a special
email address that activates a script on the other end to convert your email
message into a blog post. <a href="https://www.gnupg.org/gph/en/manual/x135.html">PGP</a>
can be used by both the client and the server to ensure that it is actually you
who is authoring the blog post and not someone else. Forget about OAuth or
anything more complicated than that.</p>

<p>Social media feeds can be updated in a similar manner. All of your server-side
functionality can be multiplexed using different email addresses for each
service. For example, you can use <code>blog@mydomain.com</code> to send updates to your
blog, and <code>mastodon@mydomain.com</code> to publish toots on your
<a href="https://joinmastodon.org/">Mastodon</a> account. Writing the code for this is a
breeze, since your favorite programming language already has libraries for
dealing with SMTP and IMAP.</p>

<h2 id="a-user-interface-to-a-search-engine-or-database">A User Interface to a Search Engine or Database</h2>

<p>It’s pretty simple to build an API for a web service these days. However,
choosing the right library or designing the right API can sometimes be an
unnecessary burden when working on a personal project that only has one or two
users.</p>

<p>Email can be used as an interface between a user and a web service when the
input and output are simple enough.</p>

<p>For example, imagine that you have a file server with a large amount of photos
stored on it and you want to be able to search those photos and retrieve them at
random. The server could use machine learning libraries such as Tensorflow to
categorize the photos and attach metadata on them.</p>

<p>Instead of building a custom web-based user interface for this, you could use
email instead. The user sends an email with the search term in the subject line,
such as “pizza”, to a special email address that corresponds to the file server
containing the photos. Just like in the previous example, PGP or S-MIME can be
used as an authentication mechanism to ensure that only authorized users can
access the photos being requested. Once the server has collected a search
result, it replies to the query email with matching photos attached as MIME
parts. The email server keeps a record of previous queries, along with their
returned results as replies, in an easily displayable and searchable format.</p>

<h2 id="the-only-limit-is-your-imagination">The Only Limit is Your Imagination</h2>

<p>Connecting email accounts to small shell scripts is a simple but powerful
concept that can unlock a wide variety of different applications. You can build
these apps with the comforting knowledge that they are all based on federated
and robust protocols used by hundreds of different email clients which have
stood the test of time.</p>

<p>Using the rich text editing features of your email client, combined with a
hierarchical organization system based on folders, allows you to do a lot of
tasks that have previously been accomplished using buggy and monolithic tools.
Privacy and security issues that plague web-based tools can be effectively
avoided when using email, because you are in control of both the client and
the server. You also get syncing to multiple devices for free, since IMAP was
designed to facilitate managing email from multiple clients at once since the
beginning.</p>

<p>I’m always interested in learning about new uses of email. If you know about
some of these yourself, send me an email about them.</p>


                    </div></div>]]>
            </description>
            <link>http://zanneth.com/2020/12/28/surprising-uses-of-email.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25759470</guid>
            <pubDate>Wed, 13 Jan 2021 08:08:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The neural network of the Stockfish chess engine]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25759430">thread link</a>) | @c1ccccc1
<br/>
January 13, 2021 | https://cp4space.hatsya.com/2021/01/08/the-neural-network-of-the-stockfish-chess-engine/ | <a href="https://web.archive.org/web/*/https://cp4space.hatsya.com/2021/01/08/the-neural-network-of-the-stockfish-chess-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>Last time, we <a href="https://cp4space.hatsya.com/2020/12/13/shallow-trees-with-heavy-leaves/">briefly mentioned</a> the high-level differences between Stockfish and Leela Chess.</p>
<p>To recap, Stockfish evaluates about 100 million positions per second using rudimentary heuristics, whereas Leela Chess evaluates 40 000 positions per second using a deep neural network trained from millions of games of self-play. They also use different tree search approaches: Stockfish uses a variant of alpha-beta pruning, whereas Leela Chess uses Monte Carlo tree search.</p>
<p>An important recent change to Stockfish was to introduce a neural network to evaluate the positions in the search tree, instead of just relying on hardcoded heuristics. It’s still much simpler than Leela Chess’s neural network, and only slows down Stockfish to exploring 50 million positions per second.</p>
<p>The real cleverness of Stockfish’s neural network is that it’s an <strong>efficiently-updatable neural network (NNUE)</strong>. Specifically, it’s a simple feedforward network with:</p>
<ul>
<li>a large (10.5M parameters!) input layer, illustrated below, that can utilise two different levels of sparsity for computational efficiency;</li>
<li>three much smaller layers (with 17.5k parameters in total) which are evaluated densely using vector instructions;</li>
<li>a single scalar output to give a numerical score for the position, indicating how favourable it is for the player about to move.</li>
</ul>
<p>Everything is done using integer arithmetic, with 16-bit weights in the first layer and 8-bit weights in the remaining layers.</p>
<h3>The input layer</h3>
<p>Let’s begin by studying the first — and most interesting — layer. Here’s an illustration I made using Wolfram Mathematica:</p>
<p><img loading="lazy" src="https://cp4space.hatsya.com/wp-content/uploads/2021/01/nnue-initial.png" alt="" width="640" height="760" srcset="https://cp4space.hatsya.com/wp-content/uploads/2021/01/nnue-initial.png 640w, https://cp4space.hatsya.com/wp-content/uploads/2021/01/nnue-initial-253x300.png 253w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p>The inputs to the layer are two sparse binary arrays, each consisting of 41024 elements. It may seem highly redundant to encode a chess position using 82048 binary features, but this is similar to <a href="https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html">an approach</a> (called ‘feature crosses’) used in recommender systems.</p>
<p>What are the two sparse binary arrays, and why do they have 41024 features? My preferred way of interpreting these two arrays are as the ‘worldviews’ of the white king and the black king. In particular, the differences are:</p>
<ul>
<li><strong>Coordinate systems:</strong> because black and white pawns move in opposite directions, the two players need to ‘see the board from opposite angles’. This already happens in regular (human) chess because the two players are seated opposite each other at the chessboard, so one player’s ‘top’ is the other player’s ‘bottom’. If you imagine each player numbering the squares from top to bottom, left to right, then any physical square would be called <em>n</em> by one player and 63 − <em>n</em> by the other player.</li>
<li><strong>Piece types:</strong> instead of viewing the pieces as black or white, a player sees it as either ‘mine’ or ‘theirs’. The 10 non-king piece types are thus {my pawn, their pawn, my knight, their knight, my bishop, their bishop, my rook, their rook, my queen, their queen}.</li>
</ul>
<p>The reason for these ‘player-relative coordinate systems’ is that it means that Stockfish can use the same neural network irrespective of whether it’s playing as white or black. The network uses <em>both</em> your king’s worldview and your enemy king’s worldview for evaluating a position, because they’re both highly relevant (you want to protect your own king and capture your enemy’s king).</p>
<p>So, why does each worldview have 41024 features? It can be seen as an outer product (or tensor product) of:</p>
<ul>
<li>a 64-element feature encoding the position of the king whose worldview this is, in their own coordinate system. This is ‘one-hot encoding’, where exactly one of the 64 entries is ‘1’ and the other 63 entries are ‘0’.</li>
<li>a 641-element feature encoding, for each of the 64 × 10 ordered pairs (square, piece-type), whether or not that square is occupied by that piece. The 641st element is unused, and is (according to the <a href="https://www.chessprogramming.org/Stockfish_NNUE">Chess Programming Wiki</a>) apparently a result of the network being ported from Shogi to chess.</li>
</ul>
<p>Each of the two 64-by-641 outer product matrices* is then flattened (the matrix is ‘reshaped’ into a vector with the same entries) to yield the corresponding 41024-element ‘sparse worldview’. In the input layer, each of the two 41024-element sparse worldviews are then affinely transformed to form a 256-element ‘dense worldview’.</p>
<p><strong>*Important note:</strong> the 41024-element sparse binary arrays are never explicitly materialised, either as a 64-by-641 matrix or as a 41024-element vector. The Stockfish NNUE effectively ‘fuses’ the construction of these sparse vectors with the subsequent affine transformation (described below), updating the 256-element dense worldviews directly when the configuration of pieces on the chessboard is modified.</p>
<p>There are <strong>two levels of sparsity</strong> which are utilised when computing this affine transformation from <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%7B41024%7D&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" alt="\mathbb{R}^{41024}" title="\mathbb{R}^{41024}"> to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%7B256%7D&amp;bg=ffffff&amp;fg=000&amp;s=0&amp;c=20201002" alt="\mathbb{R}^{256}" title="\mathbb{R}^{256}">, allowing the network to be efficiently evaluated many times in a tree search:</p>
<ul>
<li>the 41024-element implicit vectors are themselves sparse: the number of nonzero elements is equal to the number of non-king pieces on the board.</li>
<li>moving a piece typically changes very few of the entries of the vector: if it’s a regular non-king move, only 2 entries change; if it’s a non-king move with capture, then 3 entries change.</li>
</ul>
<p>It’s this second aspect which warrants the name ‘efficiently updatable’: when a move is made (or unmade, since we’re doing a tree search), we only need to add/subtract a few 256-element matrix columns from the resulting ‘dense worldview’ to update it.</p>
<p>Unless a king is moved, this (2 or 3 vector additions/subtractions) beats summing all of the matrix columns corresponding to nonzero entries (up to 30 vector additions), which in turn unconditionally beats doing a regular dense matrix-vector multiplication (41024 vector additions). That is to say, the second-level sparsity is about 10 times more efficient than the first-level sparsity, which is in turn about 1000 times more efficient than naively doing a dense matrix-vector multiplication.</p>
<p>The two dense worldviews are concatenated according to which player is about to move, producing a 512-element vector, which is elementwise clamped to [0, 127]. This elementwise clamping is the nonlinear activation function of the input layer, and (as we’ll describe) the hidden layers use a similar activation function. We can think of this as a ‘clipped ReLU’, which is <a href="https://github.com/official-stockfish/Stockfish/blob/master/src/nnue/layers/clipped_relu.h">exactly what the Stockfish source code calls it</a>.</p>
<h3>The remaining layers</h3>
<p>The two hidden layers each use 8-bit weights and 32-bit biases. The activation function first divides the resulting 32-bit integer by 64 before again clamping to [0, 127], ready to be fed into the next layer. The output layer also uses 8-bit weights and 32-bit biases, but with no nonlinear activation function.</p>
<p>The first hidden layer takes 512 inputs (the clamped concatenated worldviews) and produces 32 outputs. The second hidden layer takes those 32 values as inputs, and again produces 32 outputs. The output layer takes those 32 values as inputs, and produces a single scalar output.</p>
<p>Since these subsequent layers are applied to dense vectors, they can’t use the same ‘efficiently updatable’ approach as the input layer; that’s why they’re necessarily substantially smaller. They can, however, use hardware vectorisation instructions (SSE/AVX) to apply the linear transformation and activation function.</p>
<p>This scalar output is then <a href="http://www.talkchess.com/forum3/viewtopic.php?f=7&amp;t=75506&amp;start=9">further postprocessed</a> using other Stockfish heuristics, including taking into account the 50-move rule which isn’t otherwise incorporated into the evaluation function.</p>
<p>Observe that the neural network doesn’t actually have complete information, such as whether a pawn has just moved two squares (relevant to <em>en passant</em>), whether a king is able to castle, and various other information pertaining to the rather complicated rules for determining a draw. This is okay: the network is only being used as a cheap approximate evaluation for a position; when deciding what move to make, Stockfish performs a very deep tree search and only uses this approximate evaluation in the leaves.</p>
<p>Equivalently, you can think of this as being a massive refinement of the approach of ‘look a few moves ahead and see whether either player gains a material or positional advantage’, using a neural network as a much more sophisticated position-aware alternative of crudely ‘counting material’.</p>
<p>This is a neural network, so the weight matrices and bias vectors of the layers were learned by training the network on millions of positions and using backpropagation and a gradient-based optimiser. Of course, for supervised learning, you need a ‘ground truth’ for the network to attempt to learn, which seems somewhat circular: how do you even gather training data? The answer is that you use the classical version of Stockfish to evaluate positions <strong>using the deep tree search</strong>, and use that as your training data.</p>
<p>In theory, you could then train another copy of the NNUE using the NNUE-enhanced Stockfish as the evaluation function, and then iterate this process. Leela Chess does the same thing: its current network is trained on positions evaluated by using deep lookahead with the previous network as the leaf evaluation function. Note that the construction of the training data is orders of magnitude more expensive than training the network with this data, as you’re doing thousands of evaluations of the previous network (owing to the deep tree search) to construct each item of training data for the new network.</p>
<h3>Further reading</h3>
<p>The network is <a href="https://www.chessprogramming.org/Stockfish_NNUE">described and illustrated</a> on the Chess Programming Wiki, which also has tonnes of references to forum discussions and other references. The first description of an NNUE was a Japanese paper by Yu Nasu (who suggested it for the board game Shogi instead of chess); the paper has <a href="https://github.com/asdfjkl/nnue">since been translated</a> into English and German. There’s also the Stockfish source code, which is very well organised (there’s <a href="https://github.com/official-stockfish/Stockfish/tree/master/src/nnue">a directory</a> for the NNUE) and clearly written.</p>
											</div></div>]]>
            </description>
            <link>https://cp4space.hatsya.com/2021/01/08/the-neural-network-of-the-stockfish-chess-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25759430</guid>
            <pubDate>Wed, 13 Jan 2021 08:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Drawbridge: What SQL Server on Linux is built on]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25758012">thread link</a>) | @tech234a
<br/>
January 12, 2021 | https://threedots.ovh/blog/2021/01/drawbridge-what-sql-server-on-linux-is-built-on/ | <a href="https://web.archive.org/web/*/https://threedots.ovh/blog/2021/01/drawbridge-what-sql-server-on-linux-is-built-on/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-146">

	

	<div>
		
<p>Interestingly, public materials about the <a href="https://www.microsoft.com/en-us/research/project/drawbridge/">Drawbridge</a> variant used on SQL Server are few and far between.</p>



<p>So <a href="https://threedots.ovh/slides/Drawbridge.pdf">here</a> is a slide deck about me working with Drawbridge from several years back. I’ve updated parts of it later on, keeping up partially with more recent SQLPAL versions.</p>



<p>Since I made that slide deck, lots of things happened… which will maybe be a subject for a story or two some day.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://threedots.ovh/blog/2021/01/drawbridge-what-sql-server-on-linux-is-built-on/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25758012</guid>
            <pubDate>Wed, 13 Jan 2021 04:12:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Attempting (and Failing) to Escape Google (2020)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25757531">thread link</a>) | @JoeyBananas
<br/>
January 12, 2021 | https://blog.knightsofthelambdacalcul.us/posts/2020-01-28-attempting-and-failing-to-escape-google/ | <a href="https://web.archive.org/web/*/https://blog.knightsofthelambdacalcul.us/posts/2020-01-28-attempting-and-failing-to-escape-google/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><em>Alternative title: Young NB Yells At The Cloud</em></p>
<p><strong>Note that this absolutely isn’t vetted for technical accuracy.</strong>
<strong>It’s probably also not a very coherent post altogether.</strong>
<strong>I just needed to get this off my chest.</strong></p>
<p>Ever since late 2019, I’ve been using a Google Pixel 2 as my day-to-day
cellphone. While I’ve known that it didn’t respect my privacy, per the Google
tradition of being creepy and generally terrifying, I wasn’t <em>entirely</em> aware of
this phenomenon until Google told me when I registered my rooted Nook Tablet
with their services in 2014. The fact that this has been recorded six years
later was enough to set me off on a path to de-Googlify my Google phone.</p>
<figure>
    <img src="https://blog.knightsofthelambdacalcul.us/img/2020-01-28-1.png"> 
</figure>

<p>The first option I found was <a href="https://github.com/dan-v/rattlesnakeos-stack">RattlesnakeOS</a>, which is basically just AOSP built
on EC2. While it seemed like a competent option, and it likely is, I didn’t want
to set up an AWS account and pay $5/mo to build it, as I’m already paying $10/mo
on my current servers (including the one hosting this website). In addition,
there’s <a href="https://grapheneos.org/">GrapheneOS</a>, which is the continuation of the ill-fated CopperheadOS
(which effectively died Because Capitalism^TM after CopperheadOS was
commercialized, effectively killing the project altogether). I opted for the
latter as I wouldn’t have to set up my own build infrastructure on AWS, and the
fact that GrapheneOS decidedly had more features directly geared towards a
“hardened” Android experience, regardless of de-Googlification.</p>
<p>This of course, would be wonderful… if not for a critical roadblock.</p>
<h2 id="trying-to-unlock-the-bootloader">Trying to unlock the bootloader</h2>
<p>Here’s how it went down:
“Hey, are you able to unlock the boot-loader?”</p>
<pre><code data-lang="nil"> Λ ~ fastboot flashing get_unlock_ability
(bootloader) get_unlock_ability: 1
OKAY [  0.000s]
</code></pre><p>(read: “yeah, sure”)</p>
<p>“Okay, <em>can</em> you unlock the boot-loader?”</p>
<pre><code data-lang="nil"> λ ~ fastboot flashing unlock
FAILED (remote: 'Flashing Unlock is not allowed')
fastboot: error: Command failed
</code></pre><p>(read: “No, because I’m not able to.")</p>
<p>…so I’m left with Schrödinger’s bootloader (and not the cat from Digital Devil
Saga). Wonderful! Furthermore, I’m not the only one with this issue; not only do
some carriers lock down your ability to OEM unlock, but Google Play Services’
anti-theft protection makes it impossible to do so without an internet
connection, <em>and</em> some refurbished Pixel devices (mine being case-in-point) just
<a href="https://forum.xda-developers.com/pixel-2/help/unlock-bootloader-refurbished-pixel-2-t4017557">don’t cooperate</a>, regardless as to whether or not it <em>should</em> work.</p>
<p>My experience with Google support on this topic basically boiled down to “why
are you even trying to unlock the bootloader, you idiot”, so that’s out of the
question. I’d imagine they’re probably not super happy about me stealing profits
from them by trying to escape their ecosystem.</p>
<p>On a happier note, I came across this person on Freenode’s channel #grapheneos,
which eased the tension due to them not breaking character:</p>
<pre><code data-lang="nil">       hazel1 │ hi yes okay so.
       hazel1 │ i'm on a pixel 2 non-xl, `fastboot flashing get_unlock_ability` returns 1, but `fastboot flashing unlock` says "Flashing Unlock is not allowed"
       hazel1 │ no idea where to go from here.
TheJollyRoger │ Avast! Did ye enable OEM unlocking in the OS under developer options?
       hazel1 │ i did, yes, that's what `fastboot flashing get_unlock_ability = 1` meant
       hazel1 │ also i appreciate your dedication to character.
       hazel1 │ i'm on linux, if that's important, and i'm running these commands as root.
TheJollyRoger │ Shiver me timbers, I be stuck too. Maybe someone else on this here tub will know.
</code></pre><h2 id="why-this-is-stupid">Why this is stupid</h2>
<p>This is where I turn this tech rant into a political rant, as I have no
self-control.</p>
<p>Per the majority of things that happen in the modern tech industry, this is, of
course, a byproduct of capitalism. The fact that carriers or refurbishers <em>can</em>
lock you out of customizing your own device is in it of itself terrifying, on
the merit that it’s an effective paywall to gain control of the hardware you own
— or rather, should own. While I’m a firm believer in security, and a firm
believer that the majority of people have devices that work well enough for them
(given that they’re not privacy conscious…), I’m also under the impression
that <em>people should have control over the things they own</em>. Capitalism, in the
name of profit, contradicts that scheme.</p>
<p>The fact that your carrier owns your phone, or your phone manufacturer owns your
phone, or Google owns your phone, etc, applies in bounds here. While the
saying is generally “if it’s free, you’re the product”, the fact that you’re
<strong>still</strong> the product when buying an expensive device speaks volumes about the
technological ecosystems we tend to depend on in 2020. I should be able to
unlock the bootloader without a second thought, but the fact that some
refurbisher owns the rights to do that with the device I should own, and not me,
worries me deeply.</p>
<p>I shouldn’t have to worry about whether some random thing I say is going to be
used against me in some creepy fashion three weeks later in an ad that shows up
on a torrent site when I’m trying to scrape the web for some obscure piece of
software that nobody uses or some movie that nobody watched.</p>
<p>I’m well aware that this point has been regurgitated. I’m well aware this post
doesn’t actually make much sense. But regardless, I’m scared that Google has
this much control, and I’m scared that I’m unable to remove it.</p>
<h2 id="follow-up--2020-01-29--and-a-potential-explanation">Follow-up (2020-01-29) and a potential explanation</h2>
<p>So apparently this is by design, which pretty much confirms my theory. Great.
Per a user on the <a href="https://support.google.com/pixelphone/thread/14920605?hl=en">Pixel Phone Help “official support forum”:</a></p>
<blockquote>
<p>Update: I was able to get a reply from the higher levels in Google and they
simply informed the man handling my case, to his astonishment, that the
refurbishment process is intentionally locking the bootloader and that is the
way they designed it to operate. No options were given to me to remedy the
issue and I was asked if there was anything else I wanted to discuss before
they ended the call.</p>
</blockquote>
<p><strong>This is ridiculous if true.</strong> Not only does it compound on my existing complaint
of bootloader unlocks being behind a paywall, which is already ridiculous, but
it means that even <strong>if</strong> you go through a paywall, any device defect could lead
to a permanently locked bootloader (such as my case). Even more ridiculous is
that Google’s factory Pixel images require a bootloader unlock to flash, meaning
that this locks users out of potential support options.</p>
<p>Furthermore, if the theory of a refurbished device just being an unlocked
carrier edition phone is true (despite my CID being all zeroes), this is just
<em>negligence</em>.</p>
<p>Even if 99.3\% of users should <em>never</em> have to touch this option, the fact that
Google not only sends refurbished phones, but RMAs of unlockable phones with
this defect is astounding. It attests to the fact that what you own is not truly
yours even moreso than this just being a coincidence — it’s an explicit
hostile action towards the privacy-focused by Google. The former glory of Nexus
devices of being “the modder’s phone” has been changed drastically upon a vision
of a more popular “Google phone”; again, driven by capitalism.</p>

			</div></div>]]>
            </description>
            <link>https://blog.knightsofthelambdacalcul.us/posts/2020-01-28-attempting-and-failing-to-escape-google/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25757531</guid>
            <pubDate>Wed, 13 Jan 2021 03:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signal community: Reminder: Please be nice]]>
            </title>
            <description>
<![CDATA[
Score 1143 | Comments 428 (<a href="https://news.ycombinator.com/item?id=25757398">thread link</a>) | @decrypt
<br/>
January 12, 2021 | https://community.signalusers.org/t/reminder-please-be-nice/21217 | <a href="https://web.archive.org/web/*/https://community.signalusers.org/t/reminder-please-be-nice/21217">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-outlet">
        

  


      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          


          <p><span>
              <meta itemprop="datePublished" content="2021-01-12T10:20:07Z">
              <time itemprop="dateModified" datetime="2021-01-14T09:19:59Z">
                January 14, 2021,  9:19am
              </time>
          <span itemprop="position">#1</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>I have seen a significant uptick of people posting or joining the forums and using belligerent language, making unilateral demands and insulting the process that is open source software. “The fact you haven’t done x is stupid”. “How can you write a piece of software that doesn’t do y?”. “It’s 2021 and you still can’t make a program do z, how pathetic”. Not exact words, but accurate sentiments.</p>
<p>Please don’t do this. Please be nice.</p>
<p>The Signal team, as with any open-source team, are not infinite resources to pour down the drain. Every hour they spend on their job working for Signal, every hour they spend after work helping out, every hour a volunteer puts into forum support and bug investigation, is an hour consumed. To receive insults and vitriol in return is corrosive. It is unfair and it is not in the spirit of giving, of making something and offering it for free.</p>
<p>You’re receiving this for free, this great software which is made by people who <em>literally care</em> about your privacy. They don’t know you, and they sure don’t know what you talk about on Signal, and yet they put in a lot of effort for this. Not to make wads of cash. Not to sell you to advertisers for your social life to be analysed and abused.</p>
<p>The developer for the Mastodon software Fedilab recently <a href="https://framagit.org/tom79/fedilab/-/issues/498" rel="noopener nofollow ugc">revealed he has been burnt out</a> and I’ve read elsewhere it was because people were screaming hate at him for a principle he upheld - which was that his software would not censor people screaming hate at each other. I’m sure you can appreciate the painful irony here. (Please note that his stepping down seems to be for real, the specific reasons I’ve gave are speculation). I, for one, chose his software specifically because it did not censor, because whilst I believe a service can censor if it chooses, software must remain neutral. (If you wish to discuss this, perhaps let’s do that on another thread).</p>
<p>Don’t be that person. Don’t jump on issues making demands. Don’t pile on forum threads that make some users’ opinions very clear as it is, and throw your bellicose howling in there too. Don’t insult the developers or their priorities, their choices. They are real people who have a finite capacity for work and for abuse. Add a thumbs up to an issue, add a heart to a forum request. Post only if you can materially add to the discussion, else use a reaction. Post in the spirit and the letter of the <a href="https://community.signalusers.org/guidelines">community guidelines</a>.</p>
<p>Please be nice.</p>
        </div>

        <meta itemprop="headline" content="Reminder: Please be nice">
          <meta itemprop="keywords" content="">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p>We as old community members should also be reminded to be nice even when other people are not nice.<br>
I can talk of myself (and think many other here feel the same) that sometimes when a wave of people hits and behave bad I am angry and I should be nicer to other people.</p>
<p>So to us, even when we have people misbehave and maybe even spaming or other stuff we should still try to be serious and nice to each other :)</p>
<p>Have a nice day all!</p>
        </div>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p><a href="https://community.signalusers.org/u/herohtar">@Herohtar</a> I’d suggest to pin this topic at the top wherever that’s possible (at least for now)</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/Herohtar"><span itemprop="name">Herohtar</span></a>
            
              pinned globally 
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-12T22:38:12Z">
                January 12, 2021, 10:38pm
              </time>
              <meta itemprop="dateModified" content="2021-01-12T22:38:12Z">
          <span itemprop="position">#6</span>
          </span>
        </p></div>
        

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>I’ve tried pinning it globally for a month, we’ll see how that goes.</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/Junkii"><span itemprop="name">Junkii</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-13T00:51:24Z">
                January 13, 2021, 12:51am
              </time>
              <meta itemprop="dateModified" content="2021-01-13T00:51:24Z">
          <span itemprop="position">#8</span>
          </span>
        </p></div>
        <p>Thank- you. Great reminder. Community is important.</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>This post was flagged by the community and is temporarily hidden.</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/Meteor0id"><span itemprop="name">Meteor0id</span></a>
            (Meteor0id)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-13T02:06:08Z">
                January 13, 2021,  2:06am
              </time>
              <meta itemprop="dateModified" content="2021-01-13T02:06:08Z">
          <span itemprop="position">#11</span>
          </span>
        </p></div>
        <p>Taking a risk of offending people is not a means to push your opinion. There is no law against it, but there are community guidelines against it.<br>
Pushing the buttons of other people, you full well know that sooner or later you will push a button that triggers something. That’s why we don’t push each others buttons in the first place. you can always make your point without being rude.</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/m-graf"><span itemprop="name">m-graf</span></a>
            (Graf)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-13T04:15:26Z">
                January 13, 2021,  4:15am
              </time>
              <meta itemprop="dateModified" content="2021-01-13T04:15:26Z">
          <span itemprop="position">#12</span>
          </span>
        </p></div>
        <p>Thank you for encouraging this. If y’all need an engineer who’s dabbling in product, message me. I’d love to help however I can.</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <p>You being offended by my offensive behaviour is offensive.</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/CatEars"><span itemprop="name">CatEars</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-13T06:11:57Z">
                January 13, 2021,  6:11am
              </time>
              <meta itemprop="dateModified" content="2021-01-13T06:11:57Z">
          <span itemprop="position">#14</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>This is a great example of what not to say.</p>
<p>When a community leader says “Please be nice to each other”, the appropriate response is not “cyber bullying is not against the law, so it is okay”.</p>
        </div>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          
<p>This is not cool, and you have kind of missed the point entirely.</p>
<p>As the post says, the people behind the non-profit app are spending time out of their days to help everyone get the best out of the app. Of late, with the influx of users requesting (and demanding!) features akin to WhatsApp and the other monstrosities, it’s likely to take its toll.</p>
<p>I appreciate what you are saying, to a degree. I also don’t think your post should be ‘hidden’ as it’s been reported by the Cancel-Culture-Community. I firmly believe that if you say something, you own that! As you will expect, people are entitled to reply to that to support or rebut. That’s called a conversation. So you shouldn’t be denied that. That said, the Community Guidelines are what they are. And if we disagree, we can chose not to participate.</p>
<p>In summary, the bottom line is being aware of the unkindness towards those trying to help. Berating developers for not having something featured isn’t likely to inspire ‘will’. Neither is your post. But then you have every right to say what you have said and others have the right to reply to it accordingly. In my opinion, anyway.</p>
        </div>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/Rafi993"><span itemprop="name">Rafi993</span></a>
            (Rafi)
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2021-01-13T09:17:16Z">
              <time itemprop="dateModified" datetime="2021-01-13T09:25:39Z">
                January 13, 2021,  9:25am
              </time>
          <span itemprop="position">#16</span>
          </span>
        </p></div>
        <p>Thanks for signal developers for this awesome product that is given for free and other people in the community for being awesome. Being nice to other people in the community might make some ones day little better.</p>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          <p>Firstly. Thank you to Signal Devs. I think you’re all doing an amazing job and I will be signing up to donate, even if it is a small amount.</p>
<p>One thing I want to say to the Signal Dev Team. I bet that 99% of your user base appreciate all the hard work you are doing and want to support you in any way they can, myself included, even if just morally. Please don’t let that 1% of intolerant users discourage you from all the great input you have.</p>
<p>I am a great supporter of free speech even if something is “offensive” but posters must also realize the difference between <strong>“saying something offensive”</strong> and <strong>"hate speech"</strong></p>
<p>Keep up the good work Signal <img src="https://community.signalusers.org/images/emoji/apple/+1.png?v=9" title=":+1:" alt=":+1:"></p>
        </div>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/Froiz"><span itemprop="name">Froiz</span></a>
            (Froiz)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-13T09:56:56Z">
                January 13, 2021,  9:56am
              </time>
              <meta itemprop="dateModified" content="2021-01-13T09:56:56Z">
          <span itemprop="position">#18</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          
<p>You might have the right to say what you want, but free speech isn’t about interrupting a conversation about football yelling about zebras. Free speech is about tolerance, about a productive and focused conversation –that’s why there’re guidelines, and why guidelines are there to be tolerated.</p>
        </div>

        <meta itemprop="headline" content="Reminder: Please be nice">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          
<p>I was one of the flaggers. I am fine with someone disagreeing with me and refuting or rebutting what I’ve said. I even tolerate them doing so rudely if their points are salient. (A few hours later I usually come back and +1 their post with begrudging flouncing) If their first post on a forum is flaming someone without addressing a single one of their points in a coherent or sensible way, misrepresenting the letter and spirit of the conversation and acting generally in bad-faith, then I will flag that as it’s not a conversation, it’s just pointless screaming. If they also break the rules then they’re definitely getting a flag.</p>
<p>Flagging/reporting a post is not cancel culture at all. Flagging a rude, abusive or entirely unconstructive post is doing your bit as a member of the community to weed out bad behaviour and bad actors. I urge everyone to flag anyone posting in bad faith, or breaking the rules. Flag it all and let the pages written by people who detract from the conversation burn.</p>
<p>I did not hunt down the user to find all of their …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://community.signalusers.org/t/reminder-please-be-nice/21217">https://community.signalusers.org/t/reminder-please-be-nice/21217</a></em></p>]]>
            </description>
            <link>https://community.signalusers.org/t/reminder-please-be-nice/21217</link>
            <guid isPermaLink="false">hacker-news-small-sites-25757398</guid>
            <pubDate>Wed, 13 Jan 2021 02:50:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Distributing Mac apps outside the App Store, a quick start guide]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 158 (<a href="https://news.ycombinator.com/item?id=25757228">thread link</a>) | @tosh
<br/>
January 12, 2021 | https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store | <a href="https://web.archive.org/web/*/https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>The Mac has always been very different from its close relative, iOS, especially when it comes to what a user is or is not allowed to run on their system. Even with the introduction of Apple Silicon, Apple <a href="https://developer.apple.com/videos/play/wwdc2020/10686/?t=1161">has made it very clear</a> that the Mac is still the Mac, and is still <em>hackable</em>, even when running on the new architecture.</p><p>What this means for us developers is that, when targeting the Mac platform, we have choices: we can distribute our apps independently, outside the Mac App Store, through the Mac App Store exclusively, or through both at the same time.</p><p>This article is my brain dump on the subject. It is meant to be a guide on the things that you’ll need to know about when distributing a Mac app outside the App Store, rather than a how-to tutorial. My hope is that having everything listed here will help demystify the process for beginners, and the descriptions of my own process will be useful as starting points.</p><h2>App Store x Direct: pros and cons</h2><p>All of these choices come with their pros and cons, and depending on which type of Mac app you’re making, you might not be able to have it in the Mac App Store to begin with. An example of that is my app <a href="https://v2.airbuddy.app/">AirBuddy</a> which, in order to provide deep integration with Apple’s wireless devices, needs to run a system agent and use some private APIs, which would never be allowed in the App Store. The same goes for many other types of apps which simply wouldn’t work with the restrictions of the Mac’s sandbox.</p><p>For those who do have that choice, I’ve compiled a list of what I believe to be the pros and cons between shipping through the Mac App Store or shipping directly.</p><h3>Mac App Store pros</h3><ul><li>Apple handles the distribution, billing and licensing for you</li><li>The app is easier to find and install for most users</li><li>Potential to get featured by Apple and reach more customers</li><li>Can use features such as Sign in With Apple which are not available for apps distributed outside the Mac App Store</li></ul><h3>Mac App Store cons</h3><ul><li>Have to pay a 15% or 30% cut of all sales to Apple, <a href="https://developer.apple.com/app-store/small-business-program/">depending on how much you make in a year across all apps</a></li><li>Every single update, no matter how minor, has to go through App Review and has the potential of being rejected for arbitrary and random reasons</li><li>Can’t unlock the full potential of macOS because of the strict sandboxing requirements</li><li>Can’t do paid upgrades</li></ul><h3>Direct distribution pros</h3><ul><li>Ship updates whenever you want, no need to wait for them to be reviewed and no fear of random rejections</li><li>Unlock the full potential of macOS with system extensions, daemons, no sandboxing, private API, and more</li><li>Keep a higher percentage of your sales</li><li>Do paid upgrades or other business models which are not allowed in the App Store</li><li>Live without the constant fear that your app will suddenly become a problem for Apple and be threatened with removal from the App Store</li></ul><h3>Direct distribution cons</h3><ul><li>Have to handle licensing, distribution, and updates (it’s not that hard, you’ll see)</li><li>Not as easy to do consumable or non-consumable in-app purchases (no StoreKit)</li><li>Can’t use some Apple services such as Sign in With Apple (others such as CloudKit still work just fine)</li></ul><h2>A note on Catalyst and SwiftUI</h2><p>With the introduction of Catalyst, we’re now seeing many new Mac apps being released, since it’s a lot easier to take an existing iPad app and turn it into a Mac app. Apps ported to macOS through Catalyst are not required to be released in the App Store, even if their counterpart on iOS is.</p><p>Additionally, there is currently no TestFlight for macOS (one of my wishes for 2021), so if you’d like to distribute beta builds of a Catalyst app, you’ll have to do that outside the Mac App Store, and it is not that different from distributing a production app.</p><p>A lot of what I’m presenting here will also apply for Catalyst apps — they’re Mac apps, after all — but some might require additional hacking in order to work around the fact that Apple doesn’t want you to use the entirety of AppKit directly from within a Catalyst app. With a bit of work though, you can make a Catalyst app very Mac-capable, including <a href="https://www.highcaffeinecontent.com/blog/20190607-Beyond-the-Checkbox-with-Catalyst-and-AppKit">support for AppleScript</a> and other features.</p><p>For SwiftUI apps targeting the Mac, there should be no major differences with the distribution process, since you can use all features of the macOS API in a SwiftUI app without requiring a lot of hacking like it does for Catalyst apps.</p><h2>Distribution</h2><p>Distribution of an app involves two parts: actually uploading, storing and serving the app binary and its updates somewhere, and also producing the right package that will work for your users.</p><h3>Hosting</h3><p>The first major step with getting your Mac app in the hands of users without the App Store is to figure out how to distribute its binary. No App Store means that you’ll have to host your app’s binaries and updates somewhere on the internet and provide a link for your users to download it.</p><p>There are several ways you can go about this. For an open-source app, you can use Github releases and even host your app’s update feed in the Github repo. That’s how I distribute the <a href="https://github.com/insidegui/WWDC/releases">WWDC app for macOS</a>.</p><p>For my commercial apps, I’ve been using <a href="https://www.backblaze.com/b2/cloud-storage.html">Backblaze B2</a> for storage of both the app binaries, delta updates and update feed, and proxying all requests through <a href="https://www.cloudflare.com/">Cloudflare</a> so that I can have a custom domain for the downloads/updates and also add filtering, caching and logic on the server if needed.</p><p>B2 is an extremely affordable provider (I rarely pay over US$1 in a month). Most Mac apps are not that large in size, so even if your app is downloaded a lot, it’s unlikely that you’ll end up having to pay a lot of money for storage/bandwidth. Another popular option is using <a href="https://aws.amazon.com/s3/">Amazon S3</a> buckets, but their control panel gives me nightmares so I prefer to use B2 which is a lot simpler (and less expensive).</p><p>I haven’t automated the publishing step for my app releases as of yet, so to upload a new release I just use <a href="https://panic.com/transmit/">Transmit</a> as a client for my B2 buckets. Speaking of that, before we even get to upload a release to whatever provider we’ve chosen, there’s a very important step: getting the right file to put out there.</p><h3>Notarization and packaging</h3><p>When exporting an archived app from within Xcode, we get two main options for distribution: App Store Connect and Developer ID. To distribute apps without the App Store, you’re going to be using Developer ID.</p><p>The same developer account you use for distributing apps to the Mac App Store can be used to sign your apps for Developer ID distribution. The certificate itself is different, but Xcode will auto-generate and install one for you during the process of exporting the archive if you haven’t done so yet.</p><p>Since macOS Catalina, all apps distributed directly to users must be notarized by Apple, otherwise they won’t launch by default. This process uploads your app to Apple, which will then run automated malware checks and “staple” your binary with a special signature that will allow it to run. This is not App Review, it’s an automated check to prevent malware from being distributed through this method, and it is also a way for Apple to flag a single binary for malware, instead of a developer’s entire account, should it become compromised at some point.</p><p>Whether or not you notarize the binary directly from within the Xcode organizer will depend on which packaging method you’ll be using to distribute your app. We can’t just upload a <code>.app</code> directory to a server and let users download that, we have to turn it into a flat file. The simple way to do that is to just zip the app and distribute it as a zip file, but I’ve found through experience that distributing the app as a DMG file reduces support requests by quite a bit.</p><p>You’ve probably seen DMGs before when downloading Mac apps. They’re disk images that are mounted by macOS when double-clicked in Finder, and they can also provide some artwork instructing the user to drag the app into their Applications folder. This makes it easy for a user to figure out what to do, and it also reduces the chances that a given user will be running your app from their Downloads folder or some other random place like that.</p><p>If you’re going to be distributing your app as a DMG, you should just export it using the Developer ID option in Xcode, without notarization, then notarize the DMG itself. There’s no option in Xcode to export a DMG, so you’ll have to use a third-party tool. The one I like to use is <a href="https://github.com/sindresorhus/create-dmg">create-dmg</a>. I’ve also created and open-sourced <a href="https://github.com/insidegui/dmgdist">dmgdist</a>, a tool that automates the process of creating, uploading and stapling the DMG so that you can get the image ready to be distributed by running a single command.</p><p>To distribute the app as a zip file, the process is simpler: pick the upload option from Xcode after selecting “Developer ID” and it’ll produce a notarized version of your app, which you can then zip up and distribute directly.</p><h2>App updates</h2><p>Another aspect of the App Store is that it also handles app updates. Whenever we upload a new version to App Store Connect and it gets approved, users receive the update in the App Store. For apps distributed directly, we need to replicate that somehow.</p><p>The best way to do that — and the most common — is to use <a href="https://sparkle-project.org/">Sparkle</a>. It’s been around for many many years and is pretty much the official way to distribute updates for Mac apps distributed outside the Mac App Store.</p><p>Sparkle is currently living a double life of sorts. You can either use the “legacy” version of Sparkle or use a more modern “v2” branch which includes many improvements such as the ability to update sandboxed apps. I still use the “legacy” version because it’s the one that I’m familiar with and I find that integrating the more modern version is still a bit more complicated. If it ain’t broke, don’t fix it.</p><p>The process of generating an app update usually goes as follows: ensure that with every update you increase the app’s version (of course), produce the package as described before (Sparkle can handle zips, DMGs and installer packages), then use the <code>generate_appcast</code> tool to update the feed. After doing that, upload the deltas, the package for the new version, and the updated AppCast …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store">https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store</a></em></p>]]>
            </description>
            <link>https://rambo.codes/posts/2021-01-08-distributing-mac-apps-outside-the-app-store</link>
            <guid isPermaLink="false">hacker-news-small-sites-25757228</guid>
            <pubDate>Wed, 13 Jan 2021 02:28:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflecting on quitting my job to bootstrap a data science business]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25757028">thread link</a>) | @data4lyfe
<br/>
January 12, 2021 | https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Over one year ago, I decided to quit my data science job and pursue my <a href="https://www.interviewquery.com/">bootstrapped data science side-project</a> full time. It was a hard decision to make, but once I quit and was freed from the corporate nine to five, my life turned to complete bliss.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>That bliss lasted about two weeks before it reverted back to the mean. Honeymoons exist in all facets of life, and bootstrapping a business does not make you impervious to Mondays. Rather every day just became a Thursday. But more on that later...</p><p>I wanted to reflect on this past year plus of bootstrapping and add in some frameworks for why anyone reading this on the fence of quitting their job for their side-hustle should do so. Quitting was one of the hardest decisions that I had to make, but the best one I went through with. It's also a decision that many people should not do. </p><p>But for the small percentage of the people out there, bootstrapping a startup can be an awesome thing. You resign yourself to make trades. </p><p>You trade a steady stream of work and meetings for flexibility in your own time and hours. You trade your current monthly salary now for no income but with future options of money. And you trade office externalities and politics for taking full control of how your career might turn out. </p><p>And ultimately if those trades and values are worth it, then quitting your job can make sense in a very real way. </p><h2 id="how-it-got-started">How it got started</h2><p>On November 1st 2019, I officially quit my job as a data scientist at Nextdoor after working there for exactly a year. I had started a side project called Interview Query with my co-founder, Shane, six months prior. </p><p>Interview Query started out as an email newsletter that each day sent a user a data science interview question, and then the solution the next day if the user upgraded to premium. Over the past year we’ve built the product into a fully-fledged data science course, questions database, and became the de-facto data science interview prep resource.<br></p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-18.png" alt="Interview Query SQL" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-18.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-18.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-18.png 1364w" sizes="(min-width: 720px) 720px"><figcaption>An example of a SQL interview question we would send out. If you paid for premium, we would send a detailed explanation + solution the next day.&nbsp;</figcaption></figure><p>The first time someone purchased a subscription in June of 2019, my co-founder Shane was convinced it was a stolen credit card. It took five more customers before he truly believed that we were not just a test platform for fraudsters. And we watched in fascination as our newsletter grew from $60/mo in revenue to $3,000/mo in revenue. <br></p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-19.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-19.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-19.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-19.png 1258w" sizes="(min-width: 720px) 720px"></figure><p>And while $3K/mo was a lot of money, it still wasn’t enough to constitute quitting our jobs. Shane was working part-time on it while also working a software engineering job. And I was also a pretty senior data scientist making <a href="https://www.interviewquery.com/blog-data-science-salaries">$160K/year</a>. So an apples to apples comparison of going from to $14K/month to $1.5K/month didn’t really seem worth it. </p><p>But direct income &nbsp;isn’t the only comparison you have to make. </p><h2 id="opportunity-cost">Opportunity Cost</h2><p>The hardest jump to make is almost always on money. Money has always had significance to me. I was born and raised as a Chinese American which meant money was and still is an intrinsic part of my identity. The comedian <a href="https://www.youtube.com/watch?v=O_KpLrHCAx0">Ronnie Chieng does a funny bit</a> on what money means to Chinese people.</p><blockquote>“Do you know what the direct translation of <em>Happy New Year</em> in Mandarin is? Hope - you - get - rich. <strong>That's not Happy New Year!</strong>"</blockquote><p>To my Chinese parents, they could have added an addendum of - <em>Hope you get rich while working a stable job with low risk.</em> For with all monetary pursuits, the equation that works best within typical Chinese American families is:</p><p><em>Current income * very stable job * years of working = <strong>Best Possible Outcome Ever</strong></em></p><p>It’s a pretty linear expectation of wealth that requires a normal day to day grind and the advantages of compound interest. But the equation never really took into account tweaking the risk factor. What happens when your current income drops and risk tolerance increases? </p><p>This was the pivotal question that made it difficult for me to quit. But a month before I ended up leaving, I met up with my old startup boss at a <a href="https://techcrunch.com/2016/06/08/monster-snaps-up-tinder-for-jobs-app-jobr/">company where we exited into an acquisition</a>. I told him about the dilemma I was in, and he illustrated a newer way of looking at it. </p><blockquote>If you have a product that’s making $3K/month and you can grow that into $5K/month in a few months by working full time on it, you have to realize that the <strong>actual added value of growing your business</strong> is turning it from $36K/year in revenue to $60K/year in revenue.<br></blockquote><p>This realization helped me understand the <strong>value investment of full-time work. </strong>Money and finances can be traded for time and investment in a business in ways that you can't when you work a job. Work your ass off for a year at any FAANG type of tech company and your boss will reward you with a 15% raise. Work hard on your business and double your monthly revenue after a year, <strong>well your business also just doubled in value. </strong></p><p>So the opportunity cost of trading a job that made me $160K/year didn’t seem that bad anymore if I could at least <strong>forecast a rate of growth that would be worth my time and investment</strong> as if I was working another full time job. </p><p>And at least on my own business, I’d enjoy the work. </p><h2 id="flexibility-and-values">Flexibility and Values</h2><p>Everything gets destroyed when you bulldoze a building. The walls, the appliances, even parts of the foundation. And while throwing a wrecking ball into the corporate 9-5 felt gratifying, picking up the pieces to rebuild <strong>exactly how I would work</strong> took just as much careful planning and thought. </p><p>Balancing structure and life is important when bootstrapping. A lifestyle business allows you flexibility in how you would like to run your business. Before I quit my job, I talked to a career coach (ironically employed by the company) who encouraged me to figure out my values - and try to see if quitting allowed me to prioritize them accordingly.</p><p>Eventually I realized it did when I wanted to re-prioritize my activity list from:</p><ol><li><em>Data science job</em></li><li><em>Surfing</em></li><li><em>Side-Hustle (Interview Query)</em></li><li><em>Friends and Relationships</em></li><li><em>Random data projects</em></li></ol><p>to</p><ol><li><em>Surfing</em></li><li><em>Interview Query</em></li><li><em>Friends and Relationships</em></li><li><em>Random data projects</em></li><li><em>Things I don’t want to do but have to do to make money</em></li></ol><p>This clear order of change in my lifestyle made me realize that valuing flexibility was extremely important. It was also something I couldn't attain in my day job.</p><p>For example, when an amazing swell approaches Ocean Beach now, I reschedule meetings, log off, and go surfing. Shane and I both have trust that I'm going to finish the work that needs to get done. But if I were to receive a meeting at my old job that conflicted or I didn't want to attend - there was no way around it. </p><p>As controllers of our own fate, we make it a priority to cut down all the things we don’t want to do, and hire for those roles. If we need vacation time, then we take it.</p><p>But on that note of flexibility comes the other way - how flexible can we be while still working? And how much did we really want to work in general?</p><h2 id="financial-independence-of-sorts">Financial Independence of Sorts</h2><p>In February of 2020, Interview Query was churning out a consistent $9K/month in revenue. We tripled revenue by increasing our distribution and had transitioned from the email newsletter to building a very simple interface for viewing all of the interview questions and solutions. It was also enough to now cover my rent and general expenses.</p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-22.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-22.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-22.png 1000w, https://blog.interviewquery.com/content/images/size/w1600/2021/01/image-22.png 1600w, https://blog.interviewquery.com/content/images/size/w2400/2021/01/image-22.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.interviewquery.com/questions/bank-fraud-model">Our current interface - much improved from before</a></figcaption></figure><p>And better yet we still weren’t even working that much. I had taken a long vacation in New Zealand and Shane was still working part time. For a moment, it seemed like it was going to be a 4-hour work week kind of business that we could maintain without adding new product features. </p><p>But realistically, <strong>I had nothing else to work on</strong>. I still hadn’t gotten any of my other side-projects off the ground at the time. Surfing season was slowly ramping down. I looked around at what I was doing and realized that this project was the only one working and growing on its own. So why not invest to work on it?</p><p>One of my favorite ice breakers is asking people what they would do with their life if they received $10,000/month forever. Kind of like a basic<strong> </strong>(wealthy) income. Many people say travel (<em>which seems illogical given the extent of traveling for the rest of your life</em>), others say they’d make music, volunteer full time, work on making furniture, even working at a boba shop.</p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-20.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-20.png 600w, https://blog.interviewquery.com/content/images/2021/01/image-20.png 800w" sizes="(min-width: 720px) 720px"><figcaption>Our New Zealand van!</figcaption></figure><p>It’s a thought experiment on the idea of financial independence (FIRE). And at its core, the question is asking about what you would practically do for the rest of your life if money wasn’t an issue. The current existence of career advancement is fueled by a never-ending competition in monetary and title status. But if those were all stripped away, what would be left to complete life satisfaction?</p><p>I realized there was nothing else I wanted to do but build a startup anyway. Of course money will always matter and I inherently want to grow the business bigger and bigger. But what happens when it’s just a question of: <em>what do I do with my time when my expenses are accounted for and I want to be productive?</em></p><p>Many people in the FIRE community seem to be at loss when they finally achieve their financial freedom. They grind at a job for 15 years to finally quit and reach the same elation that I felt for maybe a few weeks or even months to suddenly fall back into a depression of sorts. Their life has no purpose after hitting their number. Which makes sense, because for 15 years <strong>all they knew about was the grind</strong> and <strong>all they thought about was hitting their number</strong>.</p><p>I personally love startups and businesses. Building and running companies requires the experience and skillset to get better at doing so. And so the question posed that helped me understand things was: </p><p><em>Would you rather be completely financially independent at age X and then quit your job to try a startup, or get good at building startups now and be a complete pro at age X instead?</em></p><h2 id="buy-futures-in-yourself">Buy Futures in Yourself</h2><p>The first few weeks after quitting my job I enjoyed the classic freedom and flexibility I had …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/">https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-reflecting-on-bootstrapping-our-data-science-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25757028</guid>
            <pubDate>Wed, 13 Jan 2021 01:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Source Security, Inc. Announces Funding of GCC Front-End for Rust]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25756636">thread link</a>) | @nindalf
<br/>
January 12, 2021 | https://opensrcsec.com/open_source_security_announces_rust_gcc_funding | <a href="https://web.archive.org/web/*/https://opensrcsec.com/open_source_security_announces_rust_gcc_funding">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

<article>
  <div>
    
    

<p>Open Source Security, Inc is proud to announce its funding of a full-time and 
public development effort of a <a href="https://gcc.gnu.org/">GCC</a> front-end for <a href="https://www.rust-lang.org/">Rust</a>.
In this blog post, we'll detail the motivations for our involvement and the benefits the public will reap
as a result of this effort.</p>

<h2>A Security Need</h2>

<p>In July of last year, shortly after my virtual <a href="https://www.youtube.com/watch?v=F_Kza6fdkSU">presentation</a> at the Linux Security Summit 
North America entitled <a href="https://grsecurity.net/10_years_of_linux_security.pdf">"10 Years of Linux Security - A Report Card"</a>, we put out a 
<a href="https://twitter.com/spendergrsec/status/1283005179135221761">call</a> to other 
companies interested in funding a GCC front-end for Rust.

The motivation for this arose
from outreach from Nick Desaulniers of Google on <a href="https://lore.kernel.org/lkml/CAKwvOdmuYc8rW_H4aQG4DsJzho=F+djd68fp7mzmBp3-wY--Uw@mail.gmail.com/T/">LKML</a> 
to discuss the possibility of Rust support in the Linux kernel at the upcoming Linux 
Plumbers Conference.  One obvious hurdle mentioned immediately was that the kernel is most 
commonly compiled with GCC, while Rust currently requires rustc/LLVM.  According to reports of
the resulting discussion, kernel 
developers were open to the idea of allowing the kernel to be built with GCC and the Rust 
portions with LLVM, as long as the two were ABI compatible.</p>

<p>Such discussions appeared to sidestep a more fundamental issue however: the security 
viability of a mixed assembly/C/Rust execution environment and how cohesive security 
functionality could be provided while mixing different compilers with different 
implementations/availability of said functionality.  The importance of this topic, though apparent 
on reflection, was formalized just recently in a paper by Michalis Papaevripides and Elias 
Athanasopoulos of the University of Cyprus entitled <a href="https://www.cs.ucy.ac.cy/~eliasathan/papers/tops20.pdf">"Exploiting Mixed 
Binaries"</a>.  In it, they detail how the overall security of an execution 
environment can be reduced by the introduction of code written in Rust or that of another 
language where the same binary-level security is not provided by the compiler.  An excerpt from page 3 of the paper makes the impact clear:</p>

<blockquote>
"We experimentally show that CFI can be bypassed using Rust/Go code for developing clearly 
more straight-forward exploits than current state-of-the-art CFI bypasses [57, 70]. Our 
exploits do not rely on respecting the statically computed Control-flow Graph (CFG) for 
bypassing the enforced CFI and are much simpler to implement. [ ... ]
Again, we stress here that in the absence of the safe part (Rust/Go code), the unsafe part 
cannot be trivially exploited."
</blockquote>

<p>
The same exact scenario above was one of the motivations for Microsoft to recently push for their
<a href="https://msrc-blog.microsoft.com/2020/08/17/control-flow-guard-for-clang-llvm-and-rust/">Control Flow Guard (CFG) support</a>
in Clang and Rust (see the heading of "Rust linked with C/C++").
</p>

<p>As the source of the GCC plugin infrastructure in the Linux kernel and nearly all of the GCC plugins adapted
for inclusion in the upstream Linux kernel, we too immediately spotted the importance of this problem and set out
to ensure both those plugins as well as the security features built-in to GCC itself are able to instrument code
from all languages supported by the Linux kernel with compatible and consistent security properties.</p>

<h2>Funding Process</h2>

<p>So despite not expecting Rust code to land in the Linux kernel in the near future, we reached out to other 
companies as mentioned above to pull together funding for the GCC front-end effort.  None of the leads 
came to fruition, so we as a company decided to bootstrap the process, in the hopes that as progress in the work
is observed, others would join in.  Further, we wanted to offer funding under the same terms we would want as developers, 
across the entire spectrum: stability, salary, benefits, ownership, etc -- not token compensation or bounties 
that treat those working on free/open source software for the public as somehow <em>less</em> than 
developers of proprietary code.  To that end, we decided to fund the first year of a full-time
developer for the work ourselves.</p>

<p>If the failed experiment of the Core Infrastructure Initiative (<a href="https://www.coreinfrastructure.org/">CII</a>) taught us anything, it's that
one finds dedicated and competent developers for some work not among whoever happens to apply, but 
among those already involved in the work as a passion project.  This led us to reach out 
to <a href="https://thephilbert.io/">Philip Herron</a>, who we noticed was <a href="https://github.com/Rust-GCC/gccrs">already working</a> on a GCC front-end for Rust with involvement
of external contributors.  We were extremely pleased to hear Philip was interested in performing the work 
full-time.</p>

<p>News of our outreach eventually extended to the <a href="https://gcc.gnu.org/steering.html">GCC Steering 
Committee</a>, who contacted us to coordinate efforts.  They were very helpful in recommending to us <a href="https://www.embecosm.com/">Embecosm</a>, a UK-based company with deep experience and involvement in 
GCC/LLVM development, among many other areas.  Embecosm graciously offered to contribute to the effort by 
handling Philip's employment and, at no cost to us, providing project management services to help ensure the project's success.  
The location, expertise, and sharing of our vision of doing right by the developer couldn't have been a 
better match.</p>

<h2>Vendor-Neutral, Developed in the Open</h2>

<p>To make sure the project remains vendor-neutral and in the public interest, Open Source Security, Inc. will not own any of the copyright over the code developed through its funding.
All relevant GCC code for the project is GPLv3-licensed and copyright is assigned, as required for upstream GCC inclusion, to the Free Software Foundation (FSF).  The work is being performed in the open, with Philip providing public monthly status updates on GitHub at <a href="https://github.com/Rust-GCC/Reporting">https://github.com/Rust-GCC/Reporting</a>.  Reports are already available for the months of November and December.
</p>

<h2>Get Involved</h2>

<p>For more information about the "how" of this effort, Embecosm has prepared a 
blog at <a href="https://www.embecosm.com/2021/01/12/gcc-rust-how-it-can-be-achieved/">https://www.embecosm.com/2021/01/12/gcc-rust-how-it-can-be-achieved/</a> that we encourage 
all those interested to read.  To get involved in contributing technical work to the 
effort, Philip can be found on Twitter at <a href="https://twitter.com/the_philbert">@the_philbert</a> or committing to the project's Github repository at <a href="https://github.com/Rust-GCC/gccrs">https://github.com/Rust-GCC/gccrs</a>.  
To discuss additional funding of the work, please reach out to us at 
contact@opensrcsec.com.</p>

<p>Brad Spengler<br>President, Open Source Security, Inc.</p>


  </div><!-- .wrap -->
</article>



</div></div>]]>
            </description>
            <link>https://opensrcsec.com/open_source_security_announces_rust_gcc_funding</link>
            <guid isPermaLink="false">hacker-news-small-sites-25756636</guid>
            <pubDate>Wed, 13 Jan 2021 01:12:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Becoming physically immune to brute-force attacks]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25755909">thread link</a>) | @Seirdy
<br/>
January 12, 2021 | https://seirdy.one/2021/01/12/password-strength.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2021/01/12/password-strength.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="mainEntityOfPage">
		
		<section itemprop="articlebody">
			<p>This is a tale of the intersection between thermal physics, cosmology, and a tiny
amount of computer science to answer a seemingly innocuous question: “How strong does
a password need to be for it to be physically impossible to brute-force, ever?”</p>
<p><a href="#conclusiontldr">TLDR</a> at the bottom.</p>
<p><em>Note: this post contains equations. Since none of the equations were long or
complex, I decided to just write them out in code blocks instead of using images or
MathML the way Wikipedia does.</em></p>
<h2 id="introduction">Introduction</h2>
<p>I realize that advice on password strength can get outdated. As supercomputers grow
more powerful, password strength recommendations need to be updated to resist
stronger brute-force attacks. Passwords that are strong today might be weak in the
future. <strong>How long should a password be in order for it to be physically impossible
to brute-force, ever?</strong></p>
<p>This question might not be especially practical, but it’s fun to analyze and offers
interesting perspective regarding sane upper-limits on password strength.</p>
<h2 id="asking-the-right-question">Asking the right question</h2>
<p>Instead of predicting what tomorrow’s computers may be able to do, let’s examine the
<em>biggest possible brute-force attack</em> that the laws of physics can allow.</p>
<p>A supercomputer is probably faster than your phone; however, given enough time, both
are capable of doing the same calculations. If time isn’t the bottleneck, energy
usage is. More efficient computers can flip more bits with a finite amount of energy.</p>
<p>In other words, energy efficiency and energy availability are the two fundamental
bottlenecks of computing. What happens when a computer with the highest theoretical
energy efficiency is limited only by the mass-energy of <em>the entire <a href="https://en.wikipedia.org/wiki/Observable_universe">observable
universe</a>?</em></p>
<p>Let’s call this absolute unit of an energy-efficient computer the MOAC (Mother of All
Computers). For all classical computers that are made of matter, do work to compute,
and are bound by the conservation of energy, the MOAC represents a finite yet
unreachable limit of computational power. And yes, it can play Solitaire with
<em>amazing</em> framerates.</p>
<p>How strong should your password be for it to be safe from a brute-force attack by the
MOAC?</p>
<h3 id="quantifying-password-strength">Quantifying password strength.</h3>
<p>A good measure of password strength is <strong>entropy bits.</strong> The entropy bits in a
password is a base-2 logarithm of the number of guesses required to brute-force
it.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>A brute-force attack that executes 2<sup>n</sup> guesses is certain to crack a
password with <em>n</em> entropy bits, and has a one-in-two chance of cracking a password
with <em>n</em>+1 entropy bits.</p>
<p>For scale, <a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard">AES-256</a>
encryption is currently the industry standard for strong symmetric encryption. As the
name suggests, its keys have 256 bits of entropy. Be aware that AES keys are
typically derived from <a href="https://en.wikipedia.org/wiki/Key_derivation_function">key derivation
functions</a> that
<a href="https://en.wikipedia.org/wiki/Salt_(cryptography)">salt</a> and hash passwords, so a
brute-force attack to discover the password from an AES key would be against such a
function. Perhaps I could address that in a future article.</p>
<p>To calculate the entropy of a password, I recommend using a tool such as
<a href="https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/wheeler">zxcvbn</a>
or <a href="https://keepassxc.org/">KeePassXC</a>.</p>
<h2 id="the-problem">The Problem</h2>
<p>Define a function <code>P</code>. <code>P</code> determines the probability that MOAC will correctly guess
a password with <code>n</code> bits of entropy after using <code>e</code> energy:</p>
<pre><code>P(n, e)
</code></pre>
<p>If <code>P(n, e) ≥ 1</code>, the MOAC will certainly guess your password before running out of
energy. The lower <code>P(n, e)</code> is, the less likely it is for the MOAC to guess your
password.</p>
<h2 id="caveats-and-estimates">Caveats and estimates</h2>
<p>I don’t have a strong physics background.</p>
<p>When estimating, we’ll prefer higher estimates that increase the odds of it guessing
a password; after all, the point of this exercise is to establish an <em>upper</em> limit on
password strength. We’ll also simplify: for instance, the MOAC will not waste any
heat, and the only way it can guess a password is through brute-forcing. Focusing on
too many details would defeat the point of this thought experiment.</p>
<p>I won’t address any particular encryption algorithms; this is just a pure and simple
brute-force attack given precomputed password entropy. Furthermore, quantum computers
can use <a href="https://en.wikipedia.org/wiki/Grover%27s_algorithm">Grover’s algorithm</a> for
an exponential speed-up; to account for quantum computers using Grover’s algorithm,
calculate <code>P(n/2, e)</code> instead.</p>
<p>Obviously, I’m not taking into account future mathematical advances; my crystal ball
broke after I asked it if humanity would ever develop the technology to make anime
real.</p>
<p>Finally, there’s always a non-zero probability of a brute-force attack guessing a
password with a given entropy. Literal “immunity” is impossible. Lowering this
probability to statistical insignificance renders our password practically immune to
brute-force attacks.</p>
<h2 id="computation">Computation</h2>
<p>How much energy does MOAC use per guess during a brute-force attack? In the context
of this thought experiment, this number should be unrealistically low. I settled on
<a href="https://en.wikipedia.org/wiki/KT_(energy)"><code>kT</code></a>. <code>k</code> represents the <a href="https://en.wikipedia.org/wiki/Boltzmann_constant">Boltzmann
Constant</a> (about
1.381×10<sup>-23</sup> J/K) and <code>T</code> represents the temperature of the system. Their
product corresponds to the amount of heat required to create a 1 nat increase in a
system’s entropy.</p>
<p>A more involved approach to picking a good value might utilize the <a href="https://en.wikipedia.org/wiki/Planck%E2%80%93Einstein_relation">Plank-Einstein
relation</a>.</p>
<p>It’s also probably a better idea to make this value an estimate for flipping a single
bit, and to estimate the average number of bit-flips it takes to make a single
password guess. If that bothers you, pick a number <code>b</code> you believe to be a good
estimate for a bit-flip-count and calculate <code>P(n+b, e)</code> instead of <code>P(n, e)</code>.</p>
<p>What’s the temperature of the system? Three pieces of information help us find out:</p>
<ol>
<li>The MOAC is located somewhere in the observable universe</li>
<li>The MOAC will be consuming the entire observable universe</li>
<li>The universe is mostly empty</li>
</ol>
<p>A good value for <code>T</code> would be the average temperature of the entire observable
universe. The universe is mostly empty; <code>T</code> is around the temperature of cosmic
background radiation in space. The lowest reasonable estimate for this temperature is
2.7 degrees Kelvin.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> A lower temperature means less energy usage, less energy
usage allows more computations, and more computations raises the upper limit on
password strength.</p>
<p>Every guess, the MOAC expends <code>kT</code> energy. Let <code>E</code> = the total amount of energy the
MOAC can use; let <code>B</code> = the maximum number of guesses the MOAC can execute before
running out of energy.</p>
<pre><code>B = E/(kT)
</code></pre>
<p>Now, given the maximum number of passwords the MOAC can guess <code>B</code> and the bits of
entropy in our password <code>n</code>, we have an equation for the probability that the MOAC
will guess our password:</p>
<pre><code>P(n,B) = B/2ⁿ
</code></pre>
<p>Plug in our expression for <code>B</code>:</p>
<pre><code>P(n,E) = E/(2ⁿkT)
</code></pre>
<h3 id="calculating-the-mass-energy-of-the-observable-universe">Calculating the mass-energy of the observable universe</h3>
<p>The MOAC can use the entire mass-energy of the observable universe.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> Simply stuff
the observable universe into the attached 100% efficient furnace, turn on the burner,
and generate power for the computer. You might need to ask a friend for help.</p>
<p>Just how much energy is that? The mass-energy equivalence formula is quite simple:</p>
<pre><code>E = mc²
</code></pre>
<p>We’re trying to find <code>E</code> and we know <code>c</code>, the speed of light, is 299,792,458 m/s.
That leaves <code>m</code>. What’s the mass of the observable universe?</p>
<h3 id="calculating-the-critical-density-of-the-observable-universe">Calculating the critical density of the observable universe</h3>
<p>Critical density is smallest average density of matter required to <em>almost</em> slow the
expansion of the universe to a stop. Any more dense, and expansion will stop; any
less, and expansion will never stop.</p>
<p>Let <code>D</code> = critical density of the observable universe and <code>V</code> = volume of the
observable universe. Mass is the product of density and volume:</p>
<pre><code>m = DV
</code></pre>
<p>We can derive the value of D by solving for it in the <a href="https://en.wikipedia.org/wiki/Friedmann_equations">Friedman
equations</a>:</p>
<pre><code>D = 3Hₒ²/(8πG)
</code></pre>
<p>Where <code>G</code> is the <a href="https://en.wikipedia.org/wiki/Gravitational_constant">Gravitational
Constant</a> and <code>Hₒ</code> is the
<a href="https://en.wikipedia.org/wiki/Hubble%27s_law">Hubble Constant</a>. <code>Hₒd</code> is the rate of
expansion at proper distance <code>d</code>.</p>
<p>Let’s assume the observable universe is a sphere, expanding at the speed of light
ever since the Big Bang.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> The volume <code>V</code> of our spherical universe when given its
radius <code>r</code> is:</p>
<pre><code>V = (4/3)πr³
</code></pre>
<p>To find the radius of the observable universe <code>r</code>, we can use the age of the universe
<code>t</code>:</p>
<pre><code>r = ct
</code></pre>
<p>Hubble’s Law estimates the age of the universe to be around <code>1/Hₒ</code></p>
<h3 id="solving-for-e">Solving for E</h3>
<p>Let’s plug in all the derived values into our original equation for the mass of the
observable universe <code>m</code>:</p>
<pre><code>m = DV
</code></pre>
<p>Remember when I opened the article by saying that none of the equations would be long
or complex?</p>
<p>I lied.</p>
<pre><code>m = (3Hₒ²/(8πG))(4/3)π(ct)³
m = c³/(2GHₒ)

E = mc²
E = c⁵/(2GHₒ)
</code></pre>
<p>Yay, we found an expression for the total energy the MOAC can consume!</p>
<h2 id="final-solution">Final Solution</h2>
<pre><code>P(n,E) = E/(2ⁿkT)
P(n, c⁵/(2GHₒ)) = c⁵/(2GHₒ*2ⁿkT)
</code></pre>
<p>Let’s copy and paste the values for those constants from Wikipedia and Wolfram Alpha:</p>
<ul>
<li>c = 299,792,458 m/s</li>
<li>G ≈ 6.67408×10<sup>-11</sup> m³/kg/s²</li>
<li>Hₒ ≈ 2.2×10<sup>-18</sup> Hz (uncertain; look up the Hubble tension)</li>
<li>T ≈ 2.7 K</li>
<li>k ≈ 1.3806503×10<sup>-23</sup> J/K</li>
</ul>
<p>Plugging those in and simplifying:</p>
<p><strong>P(n) ≈ 2.21×10<sup>92</sup> / 2<sup>n</sup></strong></p>
<p>Here are some sample outputs:</p>
<ul>
<li>
<p>P(256) ≈ 1.9×10<sup>15</sup> (password certainly cracked after burning 1.9
quadrillionth of the mass-energy of the observable universe).</p>
</li>
<li>
<p>P(306.76) ≈ 1 (password certainly cracked after burning the mass-energy of the
observable universe)</p>
</li>
<li>
<p>P(310) ≈ 0.11 (about one in ten)</p>
</li>
<li>
<p>P(326.6) ≈ 1.1×10<sup>-6</sup> (about one in a million)</p>
</li>
</ul>
<p>If your threat model is a bit smaller, simulate putting a smaller object into the
MOAC’s furnace. For example, the Earth has a mass of 5.972×10²⁴ kg; this gives the
MOAC a one-in-ten-trillion chance of cracking a password with 256 entropy bits and a
100% chance of cracking a 213-bit password.</p>
<h2 id="sample-unbreakable-passwords">Sample unbreakable passwords</h2>
<p>According to KeePassXC’s password generator, each of the following passwords has an
entropy between 330 and 340 bits.</p>
<p>Using the extended-ASCII character set:</p>
<pre><code>¦=¦FVõ)Çb^ÄwÎ¡=,°m°B9®;&gt;3[°r:t®Ú"$3CG¨/Bq-y\;
</code></pre>
<p>Using the characters on a standard US QWERTY layout:</p>
<pre><code>%nUzL2XR&amp;Tz5hJfp2tiYBoBBX^vWo3`g6H#JSC#N6gWm#hVdD~ziD$YHW
</code></pre>
<p>Using only alphanumeric characters:</p>
<pre><code>tp8D69CGWE5t5a9si5XNsw32CKyCafh8qGrKWLwE6KJHpGyUtcJDWpgRz5mFNx
</code></pre>
<p>An excerpt from a religious text with a trailing space:</p>
<pre><code>I'd just like to interject for a moment. What you’re referring to as Linux, is in fact, GNU/Linux, 
</code></pre>
<p>Don’t use actual excerpts from pre-existing works as your password.</p>
<h2 id="conclusiontldr">Conclusion/TLDR</h2>
<p>Question: How much entropy …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://seirdy.one/2021/01/12/password-strength.html">https://seirdy.one/2021/01/12/password-strength.html</a></em></p>]]>
            </description>
            <link>https://seirdy.one/2021/01/12/password-strength.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25755909</guid>
            <pubDate>Wed, 13 Jan 2021 00:03:31 GMT</pubDate>
        </item>
    </channel>
</rss>
