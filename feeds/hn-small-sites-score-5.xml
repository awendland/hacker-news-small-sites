<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 06 Oct 2020 01:06:18 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 06 Oct 2020 01:06:18 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Dual licensing GPL for fame and profit]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24677481">thread link</a>) | @george3d6
<br/>
October 4, 2020 | https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit | <a href="https://web.archive.org/web/*/https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        <p>Published on: 2020-10-04</p>
        
<p>Dual licensing with GPL is the idea that if I own a certain piece of GPL code, I can also relicense it as a proprietary library. This is how Oracle licenses Java and how QT licenses QT.</p>
<h2>I - All rights for me but not for thee</h2>
<p>But my general feeling is that there is some stigma associated with this practice, to quote <a href="https://www.gnu.org/licenses/gpl-faq.en.html#ReleaseUnderGPLAndNF">gnu.org</a>:</p>
<blockquote>
<p>To release a nonfree program is always ethically tainted, but legally there is no obstacle to your doing this. If you are the copyright holder for the code, you can release it under various different non-exclusive licenses at various times.</p>
</blockquote>
<p>The "ethically tainted" doesn't resonate with me, I think this licensing model should be encouraged.</p>
<p>I will admit I am kind of biased on this because I work on a for-profit GPL-license project. But it strikes me as silly that this business model is shunned by the open-source community in favor of licensing under MIT/BSD.</p>
<p>Dual licensing is a way in which the "owner" of the code ends up in an advantageous position compared to other users.</p>
<p>That is to say, a user must abide by the strict rules of the GPL license:</p>
<ul>
<li>Release all modifications.</li>
<li>Potentially (depending on the specifics of the GPL license) have to release other projects that are used "in relation" to the library.</li>
<li>Not ship the code under a different license.</li>
</ul>
<p>The "owner" of the code abides by none of these and can thus benefit in ways that the users can't.</p>
<p>In the open-source utopia, where resources are aplenty for everyone, everything is open source and nothing is for sale, so dual-licensing doesn't fit that particular utopia. But we live in the real world, where money makes things a bit more complicated, and in the long term, dual-licensing might be better than equal-rights open licenses.</p>
<p>Well, developers have to eat.</p>
<p>Even worst, good software is made by good developers, developers which can get six-figure salaries designing skinner boxes. On the contingency that those developers aren't ideal altruists, they have to get way-above-subsistence salaries to work on useful open source projects instead of skinner boxes.</p>
<p>So if dual-licensing provides a middle ground for that which is better than the current situation where a lot of good software is proprietary, what's the harm?</p>
<p>Some would say it's a middle ground that will hamper the development of truly free software. But who release said truly free software anyway?</p>
<h2>II - Who release fully-free projects</h2>
<p>When it comes to license like MIT and BSD, that impose no restrictions upon usage, where the "owner" doesn't exist, it's interesting to look at who release projects under those licenses:</p>
<p>a) Students or hobbyists, people creating software for fun, notoriety, and experience.</p>
<p>b) Very large companies (Facebook, Google, Amazon, Uber) or government &amp; donation founded organizations (Universities, Public Research centers, software foundations such as GNU, Apache, and LSF)</p>
<p>The first group is one I don't wish to dismiss, I think a lot of important programs stem from here. But their end goal is not to work for free for their whole life. Usually, they moonlight for their open-source projects and work a paid gig to earn money. A small minority can be funded by donations, but it's a small minority.</p>
<p>The project I use for allowing comments on this website (<a href="https://github.com/umputun/remark42">remark42</a>), has 2.3k stars on GitHub and <a href="https://www.patreon.com/remark42/posts">earns 9$/month from donations</a>. The <a href="https://github.com/mindsdb/mindsdb">project I work on</a> has 2.9k stars on Github and an operating budget of <a href="https://venturebeat.com/2020/04/16/mindsdb-raises-3-million-for-open-source-automated-machine-learning/">a few million</a> dollars.</p>
<p>You can certainly get to a point where you are funded by donations, but the reality is that it's not a good enough incentive. Doubly so since the developers working on these projects are usually the "creme de la creme", releasing and maintaining truly useful software usually requires expertise only a small fraction of engineers have.</p>
<p>The second group, the corporation and government-funded teams can only exist because of the scale.</p>
<p>Why can Facebook develop PyTorch?</p>
<ul>
<li>Because Facebook hires so many ML engineers that in the cost-benefit analysis it's cheaper to have your internal framework be popular enough such that you can get already-trained people from day 1. The &lt; 100 people working full time on PyTorch save months of training for every single one of the thousands of ML people facebook hires, since it can hire people that already know PyTorch.</li>
<li>Because Facebook doesn't dominate by having better ML models, it dominates by having thousands of times more data than anyone else. It's in facebook's interest to keep research open since it's objective is not to get ahead, but just to stay even, or at least not fall significantly behind.</li>
</ul>
<p>Why can Nvidia assign engineers to dozens of open source ML and game-engine projects?</p>
<ul>
<li>Because Nvidia makes hundreds of billions each year selling GPUs. The little work they put into those libraries to make sure it works ideally with their GPUs is insignificant to the revenue they get from those markets.</li>
</ul>
<p>Why can Google develop TensorFlow?</p>
<ul>
<li>For about the same reasons as Facebook.</li>
<li>Because they can make a lot more money from selling/renting TensorFlow optimized hardware.</li>
</ul>
<p>And that's on the happier side of the spectrum. On the "shadier" end of the scale, one could argue projects like Flutter and Angular might be worth their investment because they make spyware-free browsers like Firefox send-class citizens in the war for the web, not to mention easier integration into internet-monopolizing schemas like AMP.</p>
<p>You've also got, I will admit, projects that seem to be open source purely for flexing. To my knowledge, Yandex might have well never released Clickhouse and the column-store database landscape would have been set back 10+ years for it. Why did they do it? Maybe just because few dozens of people working on it wanted to showcase how good they are.</p>
<p>But at the end of the day, this is not a reliable model</p>
<h2>III - Profit motives</h2>
<p>So would it not be nice for open source if one can bring profit motives into the whole thing?</p>
<p>Even better, profit from the people that don't support or contribute to open source, but not from those that do.</p>
<p>It seems to me like double-licensing with GPL achieves just that. One can release a project and charge large companies for using it, at the risk of breaking the license if they don't pay. Even if a lot of them will use the software illegally, as is the case now, the threat of lawsuits will end up deterring some or most heavy-users from doing so.</p>
<p>On the other hand, people using the project in an open-source project of their own have nothing to worry about.</p>
<p>The only problem that remains here is the fact that you can't chain GPL projects. That is to say, one can't use GPL code in their own double-licensed GPL code, but there are workarounds for that (e.g. isolating the GPL dependency and open-sourcing the changes to that alone). Still, this seems like the kind of problem that could be fixed by an off-shoot of the GPL meant for just this use-case.</p>
<p>This model keeps all the advantages of GPL, in that it incentives your users to open-source their product. It doesn't force them to do so, like a purely-GPL licensed software might, but it's not like GPL is working as intended, outside of a few cases where enough money was at stake to sue (e.g. TiVo), violations of the GPL go unpunished.</p>
<p>Currently, a company that wants to include GPL into their project has two options:</p>
<ul>
<li>Use the code in such a way that GPL won't force you to open source the rest of your code.</li>
<li>Use the code and break the license.</li>
</ul>
<p>Since the wording of GPL is not that clear, it could often be argued that companies go for alternative nr 2. After all, who will ever know?</p>
<p>But what if the "pay the maintainer a small sum" option was available. Wouldn't the liability afraid giants look towards this much more favorably than either of the other 2 options? Wouldn't this, in the long run, give an edge to open source projects which don't have to worry about these fees ?</p>
<hr>
<p>Thus I think I come in squarely on the side of open-source companies dual-licensing GPL on their product[s]. A model that already exists and often enough has great success (see MariaDB and Aerospike).</p>
<p>It's a nice compromise for moving towards a more open world, without having to live in Stallman's utopia. It's an amazingly pragmatic solution and anyone who reads this blog knows I'm a fan of those.</p>

      </div></div>]]>
            </description>
            <link>https://blog.cerebralab.com/Dual_licensing_GPL_for_fame_and_profit</link>
            <guid isPermaLink="false">hacker-news-small-sites-24677481</guid>
            <pubDate>Sun, 04 Oct 2020 09:19:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Formal Models for Ethics]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24676411">thread link</a>) | @queueue
<br/>
October 3, 2020 | https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/ | <a href="https://web.archive.org/web/*/https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<main>
  
<section id="post-the-ethical-question-mk-ii"> 
   
    <div>
      <a href="https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">
        <h2>The Ethical Question, Mk. II</h2>
      </a> 
      <h3>
        <span>September 28, 2020</span>
        <span>26 minutes</span>
      </h3>
      
    </div>
  
    
  <div>
    
<p>As the reading time estimate crept over 30 minutes, without any end in sight, I was starting to feel like a bit of a blowhard.</p>



<p>The draft I‚Äôd originally intended to inaugurate this blog is still sitting there. Maybe I will condense and finish it (eventually), but I think it makes more sense to write <s>briefly</s> less long-windedly about what I mean. Instead of trying to exhaust the subject matter, I‚Äôm going to offer a perspective, and present a more intuitive argument for it.</p>



<p>So, more briefly, I‚Äôd like to ask you to think, for a moment, about what makes humans <em>ethically</em> important. There are two parts to this question, hidden just under the surface. The first asks you to consider why humans are ethical <em>agents</em>. What makes it possible for them to do, want, or experience things that could fall under the umbrella of ethics? The second (no particular order) asks you to consider why humans are ethical <em>patients</em>. How is it that what happens to them, what is wanted of them, or what is experienced about them might also be part of an ethical problem? (This agent/patient distinction I inherit from Coeckelbergh, whose book, <em>Growing Moral Relations</em>, is worth your time.)</p>



<p>I will add before you start: ethics has been defined in a few different ways, over the millennia. I consider a few definitions interesting. </p>



<p>Charles Taylor, for instance, describes ethics as pertaining not just to moral choices and obligations between people, but questions like ‚Äúwhat is the good life?‚Äù and ‚Äúwhat is good?‚Äù. His more expansive account, following Aristotle, moves closer to the Greek root, which refers to one‚Äôs <em>character</em>, and can be read to have a slant towards something resembling <em>virtue ethics</em>. Using Taylor, we could ask questions like ‚Äúwhat is it good to love?‚Äù and not just ‚Äúwhat is the right way to act?‚Äù </p>



<p>Conversely, followers of Nietzsche contrast <em>ethics</em> with <em>morality</em>, arguing that morality is about passing judgment on what people (or living beings) are and do, whereas ethics can be about <em>affirming</em> life as intrinsically self-justifying. From a (post-) Nietzschean point of view, life‚Äôs capacity to want, struggle, and change, <em>is, from the very beginning, what is good</em> (maybe not in those words). Living well means trying to overcome the need to judge, and instead to explore and express what it is to be alive, for all its intensities and tragedies. Nietzsche is often read to be asking his readers to abandon compassion, or to think only of themselves and never of the common good, but I don‚Äôt think that is exactly the case. Nietzsche is asking us to live in pursuit of what is good, but not to define it as the enemy of the bad, rather, to live <em>for its own sake, come what may</em>, and to do what is good, <em>defined in itself</em>, rather than as a reaction.</p>



<p>I don‚Äôt know Coeckelbergh‚Äôs position on ethics broadly, but he considers morality to be embedded in social relationships themselves. Rather than what is right or wrong to do to a <em>patient</em> being about its properties (whether it has consciousness, for instance) and defined in absolute terms, morality is about what relationships exist between an agent and a patient, and what kinds of relationships are good to have, knowing what the agent and patient already are to each other. Do I already mostly act like it‚Äôs a person? I should probably treat it like one. Coeckelbergh is interesting in that he tries to legitimate ideas that have, until recently, not had much hearing in the community of western philosophers, although citing him as a source for them over others might, fairly, be challenged. For instance, he would consider our dependence on our ecology grounds to entertain an obligation towards it. I haven‚Äôt finished his book yet, so I‚Äôm not aware of the extent of the advice he gives for considering problems in these relationships, but it seems fair to say that he doesn‚Äôt believe there‚Äôs a system of absolute rules out there, or that we should try to find final answers to ethical problems. Relationships are particular, and they evolve. We shouldn‚Äôt seek to use the fact that we don‚Äôt get hard answers for our convenience; instead, we should consider relationships, for their lumpiness, their particularity, their uncertainty, and live them as best we can.</p>



<p>All of these viewpoints are very different from our ordinary patterns of ethical thought. We are used to thinking that <em>individuals</em>, or sometimes <em>social groups</em> (such as nations) have <em>rights</em> that must be guaranteed to them, but everything else goes. Sometimes, referencing Isaiah Berlin, we might say we believe that this obligation is <em>negative</em> (there are some things that people are fundamentally allowed to do, and our only obligation is to stop people who try to mess with that), or it is <em>positive</em> (there are some things that people should fundamentally be allowed to do, and we need to do our best to make that possible for them). Maybe, for whatever definition of the good, we are utilitarians, who think that we should do the most good for the most people, whatever means that could entail. Perhaps we take the <em>view from afar</em>, and ask ‚Äúif I had the choice of all reasonably possible societies, which would I like to be born into, knowing that I might be anyone?‚Äù Perhaps we see ethics as different versions of the trolley problem, and find reasons, based on our moral intuitions, about what choices we should make when push comes to shove. Some of us, unfashionably, believe in immortal souls and divine law, against which we must not sin, or that her majesty inherits the right to judge from God, and that the highest good is obedience to an Earthly law. A scientist, being familiar with Hume, might read his argument that we cannot derive statements about what <em>ought to be</em> from statements about what <em>is</em>, and see cause to be an anti-realist. Maybe <em>ought</em> statements only express our personal preferences, derived from what we‚Äôve been either (or both) biologically or socially conditioned to think is pleasing. Scientists might say this implies some sort of <em>relativism</em>, or that it‚Äôs best to follow whatever is the <em>conventional</em> way to think about ethics (although, if we‚Äôre not in the business of assuming the world is already a pretty just place to be in, that last one may not be safe). </p>



<p>So, knowing what you know about what humans are made of, and how they relate to one another, to society, or to other beings, what makes them ethical agents, and what does it mean that they are? What about patients? I think it‚Äôs probably a bad idea to try to find an answer too quickly. It might be better to think through what kinds of approaches are better, and what facts could be relevant to the question. For instance, maybe the way people want things matters, as it is defined in terms of elaborations on what‚Äôs generated by the default mode network. Maybe there can‚Äôt be exactly one right answer, or maybe there must be, or maybe it‚Äôs impossible to know. How would you argue that?</p>



<h2>Why it Matters </h2>



<p>I don‚Äôt fully agree with Taylor, but, in <em>Sources of the Self</em>, he makes a good case for why we shouldn‚Äôt be self-serving, and why we already care about ethics. He says ethics are about what we <em>want to be</em>, how we identify ourselves. This is always done in terms of social groups we identify <em>with</em>. ‚ÄúI am a professional, so I should‚Ä¶‚Äù Identity gives us community, people who share something about us (a way of life, perhaps), or maybe it contrasts us against a community (we can identify ourselves as rebels). We rarely, if ever, identify with just one thing, and it‚Äôs no use to try to come up with a completely original identity, if it‚Äôs possible to do it meaningfully at all, because it doesn‚Äôt tell us much about what we‚Äôre trying to be, given we‚Äôre the only one who would know or care that we‚Äôre being it. Identity is critically important to us in interpreting our place in the world, and what we are trying to do with it. So, says he, without identity, we would struggle to come to grips with life. It is a good thing, then, that you and I already have some ideas about <em>who we are</em>, or if we‚Äôre struggling to figure that out, generally already acknowledge that it <em>is</em> an important thing to get down. Taylor says that, since it‚Äôs all about coming to grips with life, we escape Hume‚Äôs is/ought problem, because we don‚Äôt have to set up an ethics from scratch. Ethics are already there from the beginning, and have some known properties, so we can argue about them by contrasting them. ‚ÄúGiven these two frameworks, which one of them provides the richer set of tools for figuring out how to live a good life?‚Äù To Taylor, ethics are certainly <em>real</em>, but not in the sense that they‚Äôre an object embedded in a reality perfectly detached from us, rather, they come <em>from</em> the fact that we are social creatures, and relate <em>to</em> how we are trying to live in society. They aren‚Äôt just individual, or perfectly culturally relative (as there are no perfectly incommensurable cultures, which share none of the same moral ideas and cannot communicate with each other), but they aren‚Äôt exactly objective and final either.</p>



<p>I like Taylor, for how he grounds consciousness of <em>ethics</em> in <em>social consciousness</em>, and I like how good he is at striking down the (usually unanswerable) ‚Äúwhy should I care about ethics?‚Äù question. I share Coeckelbergh‚Äôs complaint that he considers only one kind of relation (between the individual and the community), and I would also gripe that his ethics are unusually centred on the <em>self</em>, for a subject that tends to ask us to think beyond ourselves. But then, that is why the argument against selfishness works so well. It‚Äôs difficult to get through to somebody who only thinks of themself unless that‚Äôs the place you‚Äôre starting from. </p>



<p>Taylor‚Äôs other issues, which I will not go too in-depth on here, are first, that he frames the source of ethics as appearing in the fact that one is an <em>ind‚Ä¶</em></p></div></section></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/">https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/</a></em></p>]]>
            </description>
            <link>https://cartesia.link/2020/09/28/the-ethical-question-mk-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676411</guid>
            <pubDate>Sun, 04 Oct 2020 03:50:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open-source self-hosted comments systems for static websites]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 34 (<a href="https://news.ycombinator.com/item?id=24676152">thread link</a>) | @nuker
<br/>
October 3, 2020 | https://lisakov.com/projects/open-source-comments/ | <a href="https://web.archive.org/web/*/https://lisakov.com/projects/open-source-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>This comparison table is inspired by
<a href="http://staticsitegenerators.net/">staticsitegenerators.net</a>. Contribute at
<a href="https://github.com/pozitron57/open-source-comments">github</a> ‚Äî
add the missing data. Github-related data (stars, open issues + PR, etc.)
are updated daily automatically. Want different columns? Noted a bug? Submit
an <a href="https://github.com/pozitron57/open-source-comments/issues/new">issue</a>.</p>
<h2>What‚Äôs wrong with Disqus</h2>
<p>Disqus loads absurd amount of tracking services, which exposes your visitors‚Äô
personal data and significantly increases loading time. See, e.g., 
<a href="http://donw.io/post/github-comments/#what-s-wrong-with-disqus">this post</a>.</p>
<h2>What‚Äôs not covered here</h2>
<p>For a static website, one usually wants a lightweight commenting server with
as little dependencies as possible. Few commenting engines listed on the page
are provided by heavy applications (e.g.,
<a href="https://github.com/discourse/discourse">discourse</a>,
<a href="https://github.com/debiki/talkyard">talkyard</a>), but the majority are
relatively lightweight applications designed specifically to provide 
comments for the static pages.</p>
<p>This page prioritizes information on self-hosted comments. However, there
are other open-source solutions, including implementations of third-party
services (e.g., Github issues, such as
<a href="https://github.com/imsun/gitment">[1]</a>,
<a href="https://github.com/gitalk/gitalk">[2]</a>,
<a href="https://github.com/Blankj/awesome-comment">[3]</a>,
<a href="https://github.com/utterance/utterances">[4]</a>).</p>
<h2>Stars vs. time</h2>
<p>The figure below shows some of the top competitors except for Discourse (as it's not
just a light commenting server like others). The figure is useful to
indirectly estimate how active the project is.</p>
<p><a href="https://lisakov.com/projects/open-source-comments/stars-v-date.png">
<img src="https://lisakov.com/projects/open-source-comments/stars-v-date.png" alt="Plot stars vs. time" width="800px">
</a></p>
<h2>Choose columns to show</h2>
</div></div>]]>
            </description>
            <link>https://lisakov.com/projects/open-source-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24676152</guid>
            <pubDate>Sun, 04 Oct 2020 02:31:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A web of trust for NPM]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 101 (<a href="https://news.ycombinator.com/item?id=24673917">thread link</a>) | @tao_oat
<br/>
October 3, 2020 | https://www.btao.org/2020/10/02/npm-trust.html | <a href="https://web.archive.org/web/*/https://www.btao.org/2020/10/02/npm-trust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In 1984 the co-inventor of Unix, Ken Thompson, delivered a seminal speech in which he highlighted that <em>you can‚Äôt trust code that you did not totally create yourself</em> <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>. For a while, this lesson was largely ignored as open-source package registries like RubyGems, PyPI and npm grew rapidly. However, as we‚Äôre seeing <a href="https://blog.reversinglabs.com/blog/mining-for-malicious-ruby-gems" target="_blank" rel="noopener noreferrer">more</a> <a href="https://blog.npmjs.org/post/185397814280/plot-to-steal-cryptocurrency-foiled-by-the-npm" target="_blank" rel="noopener noreferrer">and</a> <a href="https://snyk.io/blog/a-post-mortem-of-the-malicious-event-stream-backdoor/" target="_blank" rel="noopener noreferrer">more</a> supply-chain attacks through software dependencies, the risks of using unvetted dependencies are becoming clearer.</p>

<p>The risks are particularly great for JavaScript applications. Veracode found that the average JavaScript project relies on 377 dependencies ‚Äì compared with just 16 for Python projects, or 43 in the Java ecosystem<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>. Whenever a developer pulls in a new dependency, they are implicitly trusting the maintainers of that dependency. Often, this trust is awarded on the basis of popularity ‚Äì we assume that a popular library will be more carefully vetted, or that since many others trust the maintainers, we can too. Other times, this trust relationship and the risks involved are not considered at all.</p>

<p><a href="https://sambleckley.com/writing/npm.html" target="_blank" rel="noopener noreferrer">Some have argued</a> that the ill health of the npm registry is a social, rather than a technical problem, and suggest a human-compiled set of packages in order to separate the wheat of maintained, healthy packages from the chaff of abandoned toy projects with no documentation. <a href="https://medium.com/@dpc_96143/cargo-crev-and-rust-2019-fearless-code-reuse-b75d58398cb8" target="_blank" rel="noopener noreferrer">Another suggestion from the Rust world</a> involves creating a manual web of trust from maintainers cryptographically signing each other‚Äôs projects. Either way, there are challenges: webs of trust have rarely taken off (outside of Debian), and compiling a vetted set of packages from scratch is a massive undertaking. I propose something in the middle: bootstrapping a web of trust using existing npm dependency relationships, and building from that foundation.</p>

<h2 id="existing-trust-relationships-in-npm">Existing trust relationships in npm</h2>

<p>Creating a web of trust from existing npm dependencies is, admittedly, somewhat problematic. As stated earlier, choosing to use a particular dependency is not always a well-considered decision based on researching its code and maintainers, and the trust relationship is merely implied. Similarly, there is no cryptographic verification of this weak trust, nor does npm currently have the infrastructure for such tools<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>. What I am suggesting is an imperfect starting point to demonstrate the need for, and potential of, stronger trust measures in open source.</p>

<p>To construct this initial web, we can model npm‚Äôs maintainerships as a graph. If we let each node be a maintainer, then the edges between them are the trust relationship arising from using a dependency. In other words, if Alice maintains a package A, and A depends on package B maintained by Bob, then there is a directed edge from Alice to Bob. We can even weigh these edges by the number of Alice‚Äôs packages in which she implies trust of Bob.</p>

<h2 id="exploring-the-graph">Exploring the graph</h2>

<p>This simple model exhibits a power-law-like pattern in terms of trust: the vast majority of users are trusted by few or no others, and a very small number of users are highly trusted. This type of pattern is common in social networks: you see a similar thing emerge when plotting follower counts on Twitter. Such power laws often lead to a rich-get-richer feedback process in which the inequality (in terms of trust, in this case) gets more pronounced over time<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/efe1a929e64ebeeb021e79f341b35faa4baf1397/c0643/static/img/maintainer-wot-in-degrees.png" alt="Scatter plot of in-degree vs. number of users. Shows a roughly power-law relationship."></p>

<p>Who are these highly-trusted users? They‚Äôre who you‚Äôd expect: bots for large projects (e.g. <code>types</code>), corporate accounts (e.g. <code>fb</code>), and the maintainers of extremely popular open-source libraries (e.g. <code>sindresorhus</code>, who maintains e.g. <code>string-length</code>).</p>

<p>Perhaps more interestingly, this web of trust exhibits some useful structures. A number of <a href="https://en.wikipedia.org/wiki/Strongly_connected_component" target="_blank" rel="noopener noreferrer">strongly connected components</a> emerge ‚Äì groups of users that, roughly speaking, all trust each other according to the web of trust principles (i.e. if I trust Alice, and Alice trusts Bob, then I trust Bob, too). All of these connected components are small, with the exception of a single one that‚Äôs home to over 11,000 users<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>. This core component ‚Äì we‚Äôll call it the <strong>strong set</strong> ‚Äì could provide a starting point for a measure of trust in the npm ecosystem.</p>



<p>We can quantify trust in a slightly more nuanced way than simply looking at the in-degree of each npm user. The PageRank algorithm provides such a measure that takes into account the trustworthiness of the people who trust me. For example, I may only be trusted by one user, but if that user is <code>isaacs</code> (the creator of npm) then that trust relationship counts for a lot! After running PageRank, the 10 ‚Äúmost-trusted‚Äù users are:</p>

<ol>
  <li><code>types</code></li>
  <li><code>sindresorhus</code></li>
  <li><code>angular</code></li>
  <li><code>m1tk4</code></li>
  <li><code>tjholowaychuk</code></li>
  <li><code>google-wombot</code></li>
  <li><code>fb</code></li>
  <li><code>isaacs</code></li>
  <li><code>gaearon</code></li>
  <li><code>yyx990803</code></li>
</ol>

<p>Many of these are unsurprising. However, <code>m1tk4</code> stands out: they only maintain two rarely-downloaded libraries. Because one of these libraries is used by the BBC, <code>m1tk4</code> is implicitly trusted by a large number of relatively trustworthy BBC employees who maintain other, more popular projects. This demonstrates how PageRank diffuses trust across the social network of npm maintainers. In fact, <code>m1tk4</code> is not a member of the strong set mentioned earlier ‚Äì but many of the users who trust them <em>are</em>. <code>m1tk4</code> just doesn‚Äôt trust those users back!</p>

<p>While PageRank gives a fun measure of trust, it‚Äôs a very rough model for the reasons mentioned earlier: it‚Äôs based on a pretty weak indication of real trust. However, it might be useful in detecting suspicious behaviours in npm, which is something we ‚Äì or registry maintainers ‚Äì need to do proactively if we want to stop supply-chain attacks. For example, it might be a red flag if a highly-trusted user suddenly starts using a library by someone with a PageRank-based-trust of close to 0. And regardless, the strong set comes merely from observing which dependencies people choose to use without applying any complex calculations.</p>

<p>How might we want to use the strong set to create a stricter trust (or reputation) system? I think that formalizing such a system is unlikely if it requires large-scale buy-in from npm users. Instead, we might create a simple wrapper for npm that checks if you‚Äôre about to install something from a developer outside of the strong set, similar to Liran Tal‚Äôs excellent <a href="https://github.com/lirantal/npq" target="_blank" rel="noopener noreferrer">npq</a>. Or perhaps security researchers could use the npm web of trust as an additional data point when deciding whether a suspicious package warrants further investigation. Either way, the state of trust within the npm ecosystem is not great. This model gives us a starting point.</p>

<p><em>Do you think I‚Äôve got it all wrong? Or do you have further suggestions on how we can improve the state of trust in open source? <a href="https://www.btao.org/contact">Get in touch</a>.</em></p>

<p><em>A final note: this analysis is based on data from June 2020, which I collected for my Master‚Äôs thesis. I believe you‚Äôd reach similar numbers if you ran the analysis on data from today.</em></p>

<h3 id="footnotes">Footnotes</h3>



</div></div>]]>
            </description>
            <link>https://www.btao.org/2020/10/02/npm-trust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24673917</guid>
            <pubDate>Sat, 03 Oct 2020 18:51:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experiment with Lifetime Subscription and made $20k in two days]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24672653">thread link</a>) | @mddanishyusuf
<br/>
October 3, 2020 | https://mohddanish.me/experiment-with-lifetime-subscription-and-made-usd20k-in-48-hours-18 | <a href="https://web.archive.org/web/*/https://mohddanish.me/experiment-with-lifetime-subscription-and-made-usd20k-in-48-hours-18">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>üëã Hi, My name is Mohd Danish from INDIA &amp; I started my Indiehacker journey in January 2019. </p><p>You can find me on twitter <a href="https://twitter.com/mddanishyusuf" target="_blank" rel="noopener noreferrer">https://twitter.com/mddanishyusuf</a> &amp; watch me how I failed &amp; success with my projects.</p><p>I really love to read good stories &amp; write true stories based on true life events. So, today I‚Äôm sharing my life experience about how I made good money with my product in less than 48 hours.</p><p>I solved 10 problems I faced with MVP &amp; launch on ProductHunt.</p><p>After all those, I build my first SAAS product that related to API called NoCodeAPI.com</p><p>NoCodeAPI - The easiest way to connect your Google Sheet, Airtable, Google Analytics, Twitter, Telegram, Open Graph API, MailChimp, 50+ application APIs without any backend.</p><p><img width="1440" alt="Screenshot 2020-10-03 at 6 37 53 PM" src="https://user-images.githubusercontent.com/9165019/94992426-9ad10900-05a7-11eb-91d9-5fff09b4f1a6.png"></p><p>I Build NoCodeAPI MVP in 20 days. Finally, launch on ProductHunt on 12th January 2020 &amp; tweeted also. Everyone was loving it &amp; this was #1 product of the day. <a href="https://www.producthunt.com/posts/nocodeapi" target="_blank" rel="noopener noreferrer">https://www.producthunt.com/posts/nocodeapi</a></p><p>My tweet got 100k+ impression &amp; 17k media views.</p><p><a href="https://twitter.com/mddanishyusuf/status/1215947112187228161" target="_blank" rel="noopener noreferrer">https://twitter.com/mddanishyusuf/status/1215947112187228161</a></p><p>On the launch day, I got my first 3 paid customers &amp; more than 1200 signups. The launch was really successful but I learn one thing after 6 months that it‚Äôs easy to keep running a business &amp; get money from the customer pocket.</p><p>I made $2960 profit until 31-July-2020 but the growth was not good that I was expecting. But, One thing I realized that people need this product and I have to work more on market the product than develop new features.</p><p>One of my mentors told me that if you can get validate the idea &amp; people are paying for your service. Don‚Äôt give up just keep working on it and keep iterate according to what the user needs. So, I also get more confidence that Yes, this will be going to good.</p><p>Couple of things I did after that in Marketing:</p><ol start="1"><li>Made YouTube channels &amp; record videos for all the APIs. -&gt; Got Good traffic</li><li>Weekly email newsletter about new updates, integration, &amp; pricing update in the bottom -&gt; Got good conversion to paid users</li><li>Auto-mated email when free users cross API usage by 50%, 75%, &amp; 100% to upgrade plan.</li><li>Write content about the use-cases for the APIs.</li><li>Video call with the free &amp; paid customers if they need any help.</li><li>Improve the documentation part more easy &amp; simple for users.</li><li>I also keep adding one integration every week.</li></ol><p>After all these things I was able to get $850 MRR until and this was pretty great.</p><p>I see people were launching Lifetime deals and made more than 10k in 2 days.</p><p>I was working on NoCodeAPI 2.0 with a new dashboard &amp; I decide to launch a new version with 100 Lifetime deals launch offer. I was calculating that if I made this then I could be a millionaire in my country in 2 days and if I got failed then this will be a great lesson for my journey.</p><p>You guys can‚Äôt believe that I was getting mad and my heart was pumping. I was getting stripe notion on every 10 minutes. Someone bought Business Plan Lifetime subscription for $249. I was getting so excited &amp; feeling a high responsibility for the users.</p><p>And finally, the experiment was really successful &amp; I made $20,228 in less than 48 hours. I become the first solo millionaire in my country within 2 days.</p><p>It‚Äôs not about I never made that much money in my life, I sold the first product I build in Jan‚Äô2019 for $23k. The point is this money from my first SAAS product. </p><p>This all my experience with this experiment &amp; I‚Äôm seeing a huge potential with the product. I‚Äôm still working hard to make the product more mature &amp; profitable.</p><p>That's all.</p><p>I'll keep writing about my real-life experience. You can follow on twitter for the next story. <a href="https://twitter.com/mddanishyusuf" target="_blank" rel="noopener noreferrer">https://twitter.com/mddanishyusuf</a></p><p>Peace.</p></div></div></div></div></div>]]>
            </description>
            <link>https://mohddanish.me/experiment-with-lifetime-subscription-and-made-usd20k-in-48-hours-18</link>
            <guid isPermaLink="false">hacker-news-small-sites-24672653</guid>
            <pubDate>Sat, 03 Oct 2020 15:29:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust Starter Kit 2020]]>
            </title>
            <description>
<![CDATA[
Score 320 | Comments 95 (<a href="https://news.ycombinator.com/item?id=24671403">thread link</a>) | @psxuaw
<br/>
October 3, 2020 | https://wiki.alopex.li/RustStarterKit2020 | <a href="https://web.archive.org/web/*/https://wiki.alopex.li/RustStarterKit2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikipage">

<p>People were arguing about Rust‚Äôs std lib recently, so I went through the <code>Cargo.toml</code> of all the Rust projects I‚Äôve written since 2015 and picked out the choice tools that get used over and over again. Up to date as of October 2020.</p>
<p>Also see <a href="https://wiki.alopex.li/RustCrates" title="Go to wiki page">RustCrates</a>, though that‚Äôs old. There‚Äôs also <a href="https://christine.website/blog/rust-crates-go-stdlib-2020-09-27">this</a>, which is narrower but deeper, and <a href="https://github.com/rust-unofficial/awesome-rust">awesome-rust</a>, which is shallower and broader, and the various <a href="https://www.arewewebyet.org/">more</a> <a href="https://arewegameyet.rs/">specific</a> <a href="https://areweasyncyet.rs/">websites</a> <a href="https://www.areweguiyet.com/">for various</a> <a href="https://areweideyet.com/">topics</a>.</p>

<p>I need to set up a new Rust dev environment, what do I install?</p>
<h2 id="linting-clippy">Linting ‚Äì <code>clippy</code></h2>
<p>The one, the only, the great Rust style and correctness linter. Want to learn how to write ‚Äúidiomatic‚Äù Rust, or just learn more about handy little corners of the language and library? Run <code>clippy</code> regularly. It‚Äôs distributed with the compiler via <code>rustup</code> now, so you have no excuse not to.</p>
<h2 id="build-cache-sccache">Build cache ‚Äì <code>sccache</code></h2>
<p>Or, ‚Äúhow to make a full rebuild 70% faster‚Äù. <code>sccache</code> is a build artifact cache similar to <code>icecream</code> or <code>ccache</code>, except it‚Äôs actually trivial to just use. <code>cargo install sccache</code>, add a single line in a home dir config file, and you‚Äôre ready to go. Pretty much handles most crate and compiler versioning issues for you, so it Just Works if you update crates or install a new version of <code>rustc</code> or something. I think I‚Äôve had to force-clear the cache due to some build weirdness a grand total of once. Looks like it has enough features to use in a professional context as well, at least on a small-to-medium scale.</p>
<h2 id="dependency-viewer-cargo-tree">Dependency viewer ‚Äì <code>cargo-tree</code></h2>
<p>The best way to view what dependencies you are using, and what dependencies they are using, and so on. Best way to start cracking down on flabby dependencies.</p>
<h2 id="benchmarking-criterion">Benchmarking ‚Äì <code>criterion</code></h2>
<p>Basically the best benchmark system out there. Incredibly simple to use, informative, and statistically sound. Doesn‚Äôt really do profiling, but it‚Äôs a good start for understanding your program‚Äôs performance, and better for proving that your implementation of X is faster than someone else‚Äôs.</p>
<h2 id="other-things">Other things</h2>
<p>Stuff that is less general purpose but occasionally very useful for the meta-programming process of choosing libraries, evaluating them, etc.</p>
<ul>
<li><code>cargo-geiger</code> ‚Äì Measures how much unsafe code is in a codebase, and its dependencies</li>
<li><code>cargo-crev</code> ‚Äì A <a href="https://wiki.alopex.li/ActuallyUsingCrev">very neat tool</a> for authoring and verifying distributed code reviews.</li>
<li>Various tools maintained by <a href="https://github.com/EmbarkStudios/rust-ecosystem">Embark Studios</a>, useful for production/company purposes like checking licenses, pinning specific versions of crates, etc.</li>
</ul>

<p>The cool stuff Real Computer Scientists write about.</p>
<h2 id="hashing">Hashing</h2>
<p>No specific crates here. There‚Äôs no single crate that provides All The Hash Algorithms, just lots of little ones that generally provide a single algorithm each. Just type the name of the algorithm you want into <code>crates.io</code> and you‚Äôll get at least a couple options, choose the one with 8 million downloads or whatever. <code>sha2</code>, <code>md5</code>, <code>crc</code>, etc. Lots of them are written by the Rust core team.</p>
<h2 id="compression">Compression</h2>
<p>Same as the hashing category. Type <code>zip</code> or <code>bzip2</code> or whatever into crates.io and you‚Äôll get what you need. <code>flate2</code> might be the one crate that‚Äôs not quite trivial to find. Again, many of them are written by the Rust core team.</p>
<h2 id="encryption">Encryption</h2>
<p>I have little actual experience or authority on this topic, so I‚Äôm going to punt on this one.</p>
<h2 id="pseudorandom-number-generator">Pseudorandom number generator</h2>
<p>Use <code>oorandom</code>. (Disclaimer, I wrote <code>oorandom</code>, but people besides me seem to like it.) More usually you‚Äôll see the <code>rand</code> crate in use. If you‚Äôre doing Real Science and need to generate <a href="https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html">fancy probabilities</a>, then <code>rand</code> is the right tool, but most people aren‚Äôt doing that. Otherwise <code>rand</code> is complicated and has lots of features, while <code>oorandom</code> is very simple and has about two features, and I expect 80% of code to use at least one of them. <code>rand</code> has had several major breaking changes in its history that the rest of the ecosystem still hasn‚Äôt caught up with, while I intend <code>oorandom</code>‚Äôs API to change maybe twice in my lifetime. (Its version number, while obeying semver, is mostly a joke.)</p>
<p>There‚Äôs other lightweight PRNG crates that are just fine; see <code>oorandom</code>‚Äôs readme for a list of some others and choose one you like. Whatever you choose, use the <code>getrandom</code> crate to produce Real Random Seeds for it.</p>

<p>‚ÄúI just need to solve this ooooooone common problem, but it needs to be solved WELL‚Ä¶‚Äù</p>
<h2 id="logging-log">Logging ‚Äì <code>log</code></h2>
<p>Need to output log messages in your code? Why, use the <code>log</code> crate. Where do the log messages go? <code>log</code> provides only an interface, and that interface compiles to nothing if it isn‚Äôt used. You can write your own system for it to actually output the logs to, which is pretty easy, or use one of the small plethora of crates for it. My preferred one is <code>pretty_env_logger</code>, but <code>fern</code>, <code>slog</code> and others are all good too.</p>
<h2 id="parallel-data-crunching-rayon">Parallel data crunching ‚Äì <code>rayon</code></h2>
<p>Ever have some computation where you have a big list of STUFF and want to process it in parallel, farming out jobs to as many threads as you have CPU‚Äôs? That‚Äôs what <code>rayon</code> does, and it does it really, really well. You still <a href="https://aspenuwu.me/posts/rust-optimization.html">have to know what you‚Äôre doing</a>, but changing a single <code>.iter()</code> into <code>.par_iter()</code> and watching your CPU-bound data-crunching run 8x faster is pretty magical. Now your CPU can help keep you warm this winter!</p>
<p>Please never use it in a library. It‚Äôs rude to spawn threads in library code, unless that‚Äôs specifically what the library is for.</p>
<h2 id="regexes-regex">Regexes ‚Äì <code>regex</code></h2>
<p>To quote the inestimable <a href="https://www.jwz.org/blog/">jwz</a>:</p>
<blockquote>
<p>Some people, when confronted with a problem, think ‚ÄúI know, I‚Äôll use regular expressions.‚Äù Now they have two problems.</p>
</blockquote>
<p>On the other hand, <a href="https://xkcd.com/208/">somebody‚Äôs gotta save the day</a>. So, use the <code>regex</code> crate. Also use <a href="https://crates.io/crates/ripgrep">anything else</a> <a href="https://crates.io/crates/xsv">written by BurntSushi</a>. BurntSushi is a paragon of Rust program design, and also just a great <del>human being</del> charred cuisine in general.</p>
<h2 id="threadsafe-globals-lazy_static">Threadsafe globals ‚Äì <code>lazy_static</code></h2>
<p>‚ÄúI know globals are evil,‚Äù you say, ‚Äúbut I just need one. I‚Äôll only use it for good, I promise.‚Äù <code>lazy_static</code> has your back.</p>
<p>May eventually be superseded by <code>once_cell</code>, which looks like its <a href="https://github.com/rust-lang/rfcs/pull/2788">headed for inclusion into <code>std</code></a>.</p>
<h2 id="serializationdeserialization-serde">Serialization/deserialization ‚Äì <code>serde</code></h2>
<p>Ever have a struct and just wanted to turn it into JSON, CBOR, XML, or some other engine of woe and devastation designed to be written to an I/O stream? Or had a blob of random JSON and wanted to just stuff it into a struct matching it? Sure you have. <code>serde</code> lets you do this with a single <code>#[derive]</code>. <code>serde</code> is without a doubt one of Rust‚Äôs killer libraries. It is better than any other serialization system I have ever used.</p>
<p>What data formats does it support? Anything; the actual reading and writing is done via plugin library. There‚Äôs a <a href="https://serde.rs/#data-formats">wide selection of them</a>, of varying quality, and writing your own is a little tedious but not terribly difficult.</p>
<h2 id="error-handling">Error handling</h2>
<p>This spot deliberately left blank.</p>
<p>Rust‚Äôs <code>Result&lt;T,E&gt;</code> type is one of the best setups for lightweight, transparent error handling I‚Äôve seen, but it doesn‚Äôt do everything. How do you easily write your own error type without a bunch of boilerplate? What if you have multiple different error types from different libraries you want to coalesce together? How do you collect a backtrace of every function an <code>Err</code> is returned through, so you can find the root cause of where it came from? Can we do all this without allocating anything unnecessarily? And so on.</p>
<p>There have been various crates to try to solve these problems. First in 2015 there was <code>error_chain</code>, which was complicated and not very convenient. Then in 2017 there was <code>failure</code>, which was simpler but not very flexible, and which took an irritatingly long time to compile. Then in 2019 there was <code>anyhow</code>, which was about the time I stopped paying attention. Now apparently the new kid on the block is <code>eyre</code>, and I‚Äôm sure that in another year or two there will be something else.</p>
<p>So, I just write the boilerplate and make my errors descriptive enough I don‚Äôt need a backtrace. When I want to get fancy I implement the built-in <a href="https://doc.rust-lang.org/std/error/trait.Error.html"><code>Error</code></a> trait, which used to be kinda useless but is now more helpful. And in another five years it‚Äôll still work just fine.</p>
<h2 id="byte-mucking-bytemuck">Byte mucking ‚Äì <code>bytemuck</code></h2>
<p>For the rare occasions you need to turn a structure into arbitrary <code>&amp;[u8]</code> or back. Doing this using unsafe pointers is quite easy, and also makes it very easy to screw up horribly with Undefined Behavior galore. (Did you know that changing the value of padding bytes in a struct in UB? You do now.) <code>bytemuck</code> lets you muck around with bytes a little more responsibly.</p>
<h2 id="human-dates-and-times-chrono">Human dates and times ‚Äì <code>chrono</code></h2>
<p>Rust‚Äôs <code>std::time</code> doesn‚Äôt really handle calendar or wall-clock times, just arbitrary, monotonic <code>Instant</code>‚Äôs and measurable <code>Duration</code>‚Äôs between them. Nice, pure, computationally-robust time measurement. For all the nasty human calendar and timezone stuff, you use <code>chrono</code>. (And maybe <code>humantime</code>, but I personally reach for <code>chrono</code> first, just out of habit.)</p>
<h2 id="bit-flags-bitflags">Bit flags ‚Äì <code>bitflags</code></h2>
<p>Defining type-safe bit-masks in a reasonably convenient way. Not always worth the trouble, but sometimes pretty convenient.</p>

<p>‚ÄúI have to create or read a‚Ä¶‚Äù</p>
<h2 id="pngjpeggifetc-image">PNG/JPEG/GIF/etc ‚Äì <code>image</code></h2>
<p>General-purpose loading and saving and images, which can handle a lot of formats. Can do some amount of image manipulation as well, such as cropping, smoothing, etc. but that will hopefully be pulled out into its own library at some point soon.</p>
<h2 id="small-data-things-uuid-base64-csv-semver">Small data THINGS ‚Äì <code>uuid</code>, <code>base64</code>, <code>csv</code>, <code>semver</code>‚Ä¶</h2>
<p>Exactly what it says on the tin.</p>

<p>Not aware of any great encoders, but there‚Äôs plenty of <em>decoders</em> for common audio formats. <code>lewton</code> for Ogg Vorbis, <code>hound</code> for .wav, <code>minimp3</code> for MP3, <code>claxon</code> for FLAC. Video, I haven‚Äôt used enough to have an opinion on.</p>
<h2 id="config-files-toml">Config files ‚Äì <code>toml</code></h2>
<p>For all your config file format needs. Works with <code>serde</code>, naturally.</p>
<h2 id="markdown-pulldown-cmark">Markdown ‚Äì <code>pulldown-cmark</code></h2>
<p>There‚Äôs several good Markdown readers and writers, <code>pulldown-cmark</code> is my favorite. It supports CommonMark, it‚Äôs simple to use, and it‚Äôs pure Rust.</p>
<h2 id="templating-askama">Templating ‚Äì <code>askama</code></h2>
<p>There‚Äôs several quite good text templating engines, but <code>askama</code> IMO rises above them all by compiling your templates into Rust code and type-checking your templates at compile time. Sometimes this isn‚Äôt what you want, but it is a great feature surprisingly often. This also makes it super fast, for when you really need to ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wiki.alopex.li/RustStarterKit2020">https://wiki.alopex.li/RustStarterKit2020</a></em></p>]]>
            </description>
            <link>https://wiki.alopex.li/RustStarterKit2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671403</guid>
            <pubDate>Sat, 03 Oct 2020 12:04:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from studying Shaolin Kung Fu in China]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24671229">thread link</a>) | @flreln
<br/>
October 3, 2020 | https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/ | <a href="https://web.archive.org/web/*/https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p><em>The last piece of hair fell on the floor.</em></p><p><em>My head was shining like a moon.</em></p><p><em>‚ÄúTomorrow, I‚Äôll be in China.‚Äù</em></p><hr><p><strong><strong>In the first week of June, I was stuck.</strong></strong></p><p>We desperately needed to come up with a startup idea. Our company was in free fall, and I had to do something about it.</p><p>But I couldn‚Äôt.</p><p>I spent weeks trying to figure it all out in my head. Every day, we would sit for hours in the office. Trying to understand what we really want to work on. Brainstorming ideas. Nothing worked.</p><p>I had the idea to take some time off for a while. But I never really explored it. I‚Äôve always believed the only way to solve a problem is to start working on it. A mere thought of lying on a beach all day long and doing nothing caused physical pain in my head.</p><p>After a few weeks of struggle, I accepted that we‚Äôre not moving anywhere.</p><p><strong><strong>I needed a change.</strong></strong></p><p>I used to do martial arts as a kid. I remember when I first read about Shaolin. I was amazed. It seemed like something sacred, unreal to me. Very distant, but also very close in some way.</p><p>I remember begging parents to allow me to go there and train with monks.</p><p><em>‚ÄúYou‚Äôre out of your damn mind!‚Äù</em></p><p>I‚Äôm not blaming them; I‚Äôd probably tell my kids the same.</p><p>But now I had no excuse.</p><p>I decided to fly to China and study Kung Fu at The Shaolin Temple.</p><figure><img src="https://lh3.googleusercontent.com/Q3pS6-bIyhrxVRndWfaux_yN_-PJBPebn2jwQJHImjIMygREWwyR3Wc8w0kILJgijhjt0r-d4BIdoeT3qsZO7VEfvQpbh5pVHakdASf1Q03R6s4clJWAUA0EjgxqNDkCdRKFH1ek" alt=""></figure><p>The Shaolin Monastery is like Mecca for Buddhists.</p><p>It‚Äôs a mysterious place where monks live, train, and meditate.</p><p><em>Some of them never leave the temple.</em></p><p>And while you can visit the temple as a tourist, there‚Äôs no way for a stranger to get into the private part of the monastery, where real monks train. There‚Äôs no website where you can apply. No email address.</p><p>But I had a plan.</p><p>I decided to find a martial arts school in Dengfeng, which is a small town 12 km from the temple. My idea was to get to Dengfeng, and then try to meet some younger monks from the temple and beg them to death to let me in.</p><p>After a few days of research, I found a school that seemed reasonable and applied.</p><figure><img src="https://lh6.googleusercontent.com/YDuca6U-Xj9WUbeyshjgYpN2oWYZXvEXofbvILQW7t-j-FljoSA9TjA_S3LTvOHsMWiiltMTuraj13qtDORfzWvbY_nxeqM6fI6xt_5bRC4wVUUuIYjFu-gBo6lLeZZFXbXzfbRz" alt=""><figcaption>Shifu and students. And his kid.</figcaption></figure><p><em>‚ÄúUnfortunately, we‚Äôll not be able to enroll you. We‚Äôre shutting down.‚Äù</em></p><p>That‚Äôs what I heard from the school 24 hours before the flight.</p><p>I frowned.</p><p>Finding this school was tough. There are hundreds of fake ‚ÄúShaolin Kung Fu‚Äù schools in Dengfeng. They‚Äôre making money off the Shaolin brand, but there‚Äôs no real, authentic, hard training involved.</p><p>Getting another good one to accept me over night seemed impossible. But I kept looking.</p><p>I was looking for something original and challenging. And all Kung Fu schools I‚Äôd seen before were like holiday camps.</p><p>A few hours later, serendipity kicked into play.</p><p>I found a YouTube video from a former Xing Long student. I loved it. I went on their website and smiled.</p><p>The website said:</p><p><strong><strong>‚ÄúOur school is not a holiday retreat.‚Äù</strong></strong></p><p>On a warm night of June 14th, I landed in Beijing.</p><figure><img src="https://lh3.googleusercontent.com/Ku0IQGnR2GgIWEcrPMlgo-wFYzrsanZT3agAhjOq95QJNZmS9Axi2I1MxXmN6KBHi_bmHD50q7RsO96dWnjovN83jDGHhEIxKdsCf1X3sgntgTe16-EmsHXw3DmGMWNzPWdNWwrn" alt=""><figcaption>4:30 a.m. Meeting the dawn at a Beijing Railway Station.</figcaption></figure><p>When I arrived in Beijing, I still hadn‚Äôt heard from Xing Long.</p><p>But I had no choice. I was in China, and coming back was not an option. So I bought a train ticket and embarked on 600 km journey to northern China.</p><p>After six hours of slumber in the high-speed train, I was in Siping.</p><p>At the exit of the train station, three students of Xing Long waited for me with a welcoming sign, ‚ÄúVasili Shynkarenka.‚Äù They drove me to school.</p><p>That‚Äôs when I met the Master for the first time.</p><figure><img src="https://lh3.googleusercontent.com/TDkN2V3FfpErJtZ5GeLWTX__0T2KMX_dKy1xq40UENQN6OiQUEgQ3JW4jE-mfU5ECQwI4TDTflt5wuf2lz6IlbswXzhZ2bdmKpH09BsWQYqPA8nGsR9vPe6v70TcWczFbhI4DO-M" alt=""></figure><p>Shifu is 5‚Äù2, fast as a jaguar, has a bone-crushing handshake and dark brown eyes that look right into your soul.</p><p>He once tore off someone‚Äôs shoulder with bare hands.</p><p>At 12, he already trained in Shaolin.</p><p>Shifu turned pro after seven years. He started competing professionally, won the famous ‚ÄúKungfu King‚Äù tournament, and achieved the rank of a 7th-degree master at 19.</p><p>And then he broke his back. It was a full-contact sparring match, and he cracked his fourth vertebrae.</p><p>Doctors said he wouldn‚Äôt be able to walk ever again. Shifu made a full recovery in six months.</p><p>He couldn‚Äôt return to professional fighting, but life without Kung Fu was not an option to him.</p><p>He began teaching.</p><p>His vision was simple:</p><p><strong><strong>‚ÄúTo spread classic Shaolin skills throughout the world.‚Äù</strong></strong></p><p>To achieve that goal, Shifu had to learn English. He worked hard for 18 years, and he speaks almost fluently now.</p><figure><img src="https://vasilishynkarenka.com/content/images/2020/09/image.png" alt="" srcset="https://vasilishynkarenka.com/content/images/size/w600/2020/09/image.png 600w, https://vasilishynkarenka.com/content/images/size/w1000/2020/09/image.png 1000w, https://vasilishynkarenka.com/content/images/size/w1600/2020/09/image.png 1600w, https://vasilishynkarenka.com/content/images/size/w2400/2020/09/image.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Me and Shifu Wang.</figcaption></figure><p>Shifu believes that Shaolin Kung Fu is not just a martial art from Jackie Chan movies.</p><p>In its origin, Kung Fu refers to any discipline achieved through hard work. Anything that requires patience, energy, and time to complete. And once you learn it in martial arts, you can transfer this knowledge to other domains.</p><p>He is also a great thinker. I saw him reading Meditations from Marcus Aurelius once. That‚Äôs the kind of teacher I needed.</p><p>The Shaolin Temple has become fancy.</p><p>More tourists. More noise.<em> Less signal.</em></p><p>Three years after opening his first school near the temple, Shifu moved to the northern province of Jilin.</p><figure><img src="https://lh4.googleusercontent.com/58E2EatlNlHjmGt-l9A8bY4nSm_Q7xixee-35sXFc3LmT6oeERgxi9cerT_jz152153YHAHvHryr1r6j2JVma4dZ-ZiMqHFTrPpqk-AInBJONHGqlm_xQQR2U41raPCAjhp1mDMf" alt=""><figcaption>Hills near the school in winter.</figcaption></figure><p>Xing Long school is located on a small farm in the countryside.</p><p>There's one large training hall, full of equipment and dried sweat.</p><p>Second training hall in the back. It's used during the winter when the temperature drops to -15. During the summer, training takes place outside for much of the time.</p><figure><img src="https://lh3.googleusercontent.com/AG-Mtzr8srM4SnborSx51QdOWh_pqXEQz_KhXKezlcjDahDwrUQq8o3d4OyhsVo2vZWK0mDRn2Mi2e4rp1d-Z1EP6nZePJSBU8jMZpCXEyfw-hv_XUFRkafctSEcVy9B9rURRqjj" alt=""></figure><p>When I arrived, there were 12 students at the school.</p><p>During the year, this number varies from 5 to 15. Having a small group helps Shifu to dedicate enough time to each student, but also make sure there‚Äôs a lot of practice for everyone.</p><p>People all over the globe came to China to study Kung Fu. Explorers; seeking for something deeper than living in the Matrix.</p><p>Some of them, like Matt, had been at the school for six years already.</p><figure><img src="https://lh5.googleusercontent.com/_MkifjL76syDHa6wuUXWJXHu2EkaEh9vXg6a-aAPWoZvveQmQemDcwyjDH6cnBEZWXcMsN1LcyGL-u3tML98ZCwW4H145ubkG7JQaPeMYuuIgiu0r2s_MOrePSaBbHYo9FvWzVp1" alt=""></figure><p>I was surprised by how diverse, open, and curious students were.</p><p>We had a scientist who worked on quantum computing, a famous reporter from Hollywood, and a primary school teacher.</p><p>We spent hours at the dinner table talking about everything from farming to teaching to space.</p><p><strong><strong>It felt like a brotherhood.</strong></strong></p><h2 id="training">Training</h2><p><em>It was the final lap of 45 degrees uphill mountain running.</em></p><p><em>My legs were destroyed. I barely strolled. The sole purpose of my existence came down to two words:</em></p><p><strong><strong><em>‚ÄúDon‚Äôt. Stop.‚Äù</em></strong></strong></p><p><em>I questioned myself a thousand times.</em></p><p><em>‚ÄúWhy are you doing this to yourself? What‚Äôs the purpose? Why don‚Äôt you just walk the rest of the run?‚Äù</em></p><p><em>And then it hit me:</em></p><p><em>‚ÄúBecause that‚Äôs who I am.‚Äù</em></p><p><em>I kept running.</em></p><hr><p><strong><strong>Every day we had six to eight hours of Shaolin training.</strong></strong></p><p>We woke up at 5:30. At 5:50, we lined up.</p><p><em>‚ÄúGo, running!‚Äù</em></p><p>We ran for about three miles uphill and then stretched for twenty minutes.</p><p>After the warmup was done, we had Tai Chi.</p><p>Tai Chi is like action movies in slow motion. It‚Äôs a very steady motion, supported by breath control.</p><p><em>‚ÄúIf you want to go fast, you need to go slow first.‚Äù</em></p><figure><img src="https://lh5.googleusercontent.com/0-mClkSOHm5SmigJFL4YlvMSlici0u11ghqBVSPZas9SVRcif6z3O07H_3jq7DGTmoZp5crsLOpgORG42BApwhJ1XIHUiah69_vozhQBUzLchxNWc45lhTRH3MO5zZFY2iy-1_TB" alt=""></figure><p>Soft movements helped us to recover our energy faster, heal sore muscles, and release body tension that accumulated throughout the previous day. After eight hours of hard training every day, Tai Chi was saving my life.</p><p>Here‚Äôs a little video I made of Johny and Emilian doing 42 Tai Chi Steps:</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/Rjyy-ocBgPw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>After an hour of Tai Chi, we had breakfast and an hour of rest.</p><p>At 8:30, the morning training started.</p><figure><img src="https://lh5.googleusercontent.com/fryF8-kmO3Ex0tAuFiY1KEAK5iEgjujjxZc4F1qbOi3lJO4_LKeY5ySm6twt_5rUxRrAD4jPOSCgnqtupbjKQQ6qCqHbsRhRUkvNUu1c9HxxMaecVkP7PL10SkbD9snpD39eEYmw" alt=""><figcaption>Shifu is always watching.</figcaption></figure><p>Every morning we practiced forms.</p><p>Forms are like shadow boxing.</p><p>It‚Äôs a very ancient set of techniques arranged in patterns. Each form is a sequence of sets, and each set is a sequence of movements. You go from small moves, like striking with a left fist, to a five-minute-long combination of strikes, turns, and jumps.</p><p>Shaolin monks designed forms by contemplating animal behavior for hundreds of years. Some forms are even called this way: The Monkey, The Dragon, or The Snake.</p><figure><img src="https://lh5.googleusercontent.com/JxoTjcgR4mGCvXH3tAjhVJChFnNQsz5N8soW-1KCXdzTO3dsNsAoR5onqolr8TVnqSLjmTjHcZ8h7RA9BJdJ5rlkMEknrOooKwkHYY2lWokTvMnfBKQNhJmItLy63Im6FpFxN61M" alt=""><figcaption>Shifu and Matt are doing forms. Weather is for puppies.</figcaption></figure><p>Forms help to develop strong footwork and learn striking.</p><p>When you practice long enough, you unconsciously start using individual movements, sets, and sequences in a real fight.</p><p>The morning training finished at about 12, and then we had lunch and an hour of rest.</p><p>At 2:30, the afternoon training began.</p><hr><p>After one week of basic training, I started doing Sanda.</p><p>It‚Äôs a form of kickboxing, which allows you to learn all basic punches, kicks, and combinations.</p><p>Sanda is how you actually use your Kung Fu in practice.</p><figure><img src="https://lh6.googleusercontent.com/IHJDa_jIjoyU1_lO7HJHEYK0myxQxDlC3aefu0hqeoUUI-s4meG0oTVTFskOR2eGY_B0rKNXUAJEZRNThqafevN1X8NvGsqC0iUs3lRBBKrP9aJ5922f8o2JHppGgIyWGwxGgr5-" alt=""></figure><p>Three times a week, we had power training, like doing burpees for two miles.</p><p>Or ‚Äúlizard moves,‚Äù when you literally crawl uphill for half a mile.</p><p>It sucked.</p><p>But that‚Äôs where the spirit was sprouting.</p><figure><img src="https://lh3.googleusercontent.com/m3CeUeqcgH5xhIHnCqaEP03POcCrWiE3b2-K2y3pUWjw1c27O_Ri8r3E6q3cNjSjEEJJuDAwy7LsR_BXoaUHZsdjLB9CMI8eJvCQGNBvNVh0K-YHise92tVEQOwokKp95UFBoTrG" alt=""></figure><p>After dinner, we had Qigong.</p><p>Qigong is a standing meditation. You freeze in a stance and focus on breath control. No movements for ten minutes. Then you change the position.</p><p>I thought I was fit. I wasn‚Äôt for Qigong.</p><p>I couldn‚Äôt stand still for more than two minutes in a horse stance. My sore legs were in agony.</p><p>But after a week it began to work. Minutes began adding up. I‚Äôm still not sure how exactly Qigong heals sore legs, but in two weeks I was able to stand in the horse stance for 10 minutes. Soreness was gone.</p><figure><img src="https://lh4.googleusercontent.com/2k2dWL0iLqSWl-wt3PJ-cyVc20GzEdon4Utf_KEBUiu2KgMG-mRf7BrrCUC7VMFBj_Ogpcj8okPESE1bKP7WMkT6D-IqvJvJlVrxkGTE3woVp77xjMg8mp9eFV3oCznnvMy1tsG9" alt=""></figure><p>Every Friday, we had power stretching.</p><p>It was torturous.</p><p>We ran five miles uphill first. Then we stretched for about twenty minutes. And then power stretching began.</p><p>Shifu was assisted by one student. I laid on the floor, and the guy sits on my knee, so I couldn‚Äôt move. Shifu took my leg and started moving it up to my head, in short, swaying movements.</p><p>He didn‚Äôt stop.</p><p>That‚Äôs when I learned what the pain really is.</p><p>When you scream. When you cry. When you‚Äôre short of breath and can‚Äôt scream anymore.</p><figure><img src="https://lh6.googleusercontent.com/RtCJUFKTbQ9g2J9GfTsI7Q3d2BakfDFs13jGok3XrptKQyMs-bRRVLBWDdMAJQM3oW4YjKZozVaIQnbL5j9DJFu3T6GiInGPhWM-SuZiiD87dgNzSSr9csWTfWASS2mnktrtqBVL" alt=""><figcaption>Shifu helping a student to go beyond his limits.</figcaption></figure><p>Don‚Äôt get me wrong; Shifu knows his stuff. But knowing that he won‚Äôt tear your legs apart is not making the process more enjoyable.</p><p>Over time, I learned to accept the pain. To breathe. To let go.</p><p>And that‚Äôs when I felt the power of it. In two weeks, I came closer to transverse twine than in two years of doing my own stretching.</p><h2 id="lessons">Lessons</h2><figure><img src="https://lh4.googleusercontent.com/ceI7ZAs0TekQcVP0mhN_wLS5CRf_xQnuhznYV2flXbqAeHtWVENNoHmKGZJNjB9F6yoRcYSni94uJDxmA0LQ308vg2ZmRZ4QYC8i3zRegHznhB_oKM7W_UZKvo6WYh5URIX9NcUE" alt=""></figure><p><em>Lunch was over.</em></p><p><em>I went to my room and fell on the bed. I was exhausted.</em></p><p><em>Suddenly, the thoughts started pouring in my head.</em></p><p><em>The mental fog was gone. I knew what I needed to do.</em></p><p><em>I saw the forest for the trees.</em></p><hr><p>Three weeks in, I figured out that I want to work on longevity.</p><p><strong><strong>Not just figure ‚Ä¶</strong></strong></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/">https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/</a></em></p>]]>
            </description>
            <link>https://vasilishynkarenka.com/3-weeks-of-shaolin-kung-fu-in-china/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24671229</guid>
            <pubDate>Sat, 03 Oct 2020 11:17:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The case for building a SETI observatory on the moon]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24670960">thread link</a>) | @pseudolus
<br/>
October 3, 2020 | https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon | <a href="https://web.archive.org/web/*/https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>On Monday, a group of researchers sponsored by Breakthrough Listen, the world‚Äôs largest SETI program, </span><a href="http://seti.berkeley.edu/lunarseti/" rel="noopener noreferrer" target="_blank">submitted a paper</a><span> to National Academy of Sciences‚Äô Planetary Science and Astrobiology Decadal Survey that makes the case for establishing a SETI radio observatory on the farside of the moon. The decadal survey establishes scientific priorities for the next ten years and the new paper addresses one of the biggest problems facing the search for extraterrestrial intelligence today: The overwhelming amount of radio interference.&nbsp;</span></p></div><div><p><span>Our planet has become so ‚Äúloud‚Äù in the part of the radio spectrum observed by SETI that it threatens to drown out any signal sent from an intelligent civilization. Not only would a lunar radio telescope not have to deal with terrestrial radio interference, it could also significantly increase our chances of hearing from ET by opening up parts of the radio spectrum that are blocked by Earth's atmosphere. While the idea of using the moon for radio astronomy is decades old, the researchers make the case that technological advancements have finally made a lunar SETI observatory truly feasible.</span></p></div><div><div><p><span>
says Eric Michaud, an intern at the SETI Berkeley Research Center and the first author of the paper. ‚ÄúMaybe not today, but I think it‚Äôs going to get more and more feasible as time goes on.‚Äù&nbsp;</span></p></div></div><div><p><span>Radio interference has been a problem for SETI from the very beginning. In the spring of 1960, the planetary scientist Frank Drake trained the massive radio telescope at Green Bank Observatory in West Virginia on Tau Ceti and Epsilon Eridani, two stars a mere 12 light years from Earth. That summer, Drake spent his days studying the signals picked up by Green Bank‚Äôs giant mechanical ear in the hopes of receiving a message broadcast by an alien civilization orbiting those stars. Known as Project Ozma, Drake‚Äôs experiment marked the beginning of SETI, the scientific search for extraterrestrial intelligence.&nbsp;</span></p></div><div><p><span>Shortly after Drake started his observations, he was surprised to find what appeared to be a signal of intelligent origin. After days of watching a needle drift lazily over a spool of paper recording the random undulations of cosmic static, Drake and his colleagues were jolted awake when the machine started recording the frantic pulses of a strong radio signal picked up by the telescope. The timing and magnitude of the pulses clearly marked them as artificial; there was nothing in the natural world that could produce such a frenetic radio profile. It would have been an astounding stroke of luck to pick up an alien message after only a few hours of observation, but it was hard to argue with the data.&nbsp;</span></p></div><div><p><span>‚ÄúNone of us had ever seen anything like it,‚Äù Drake recalled in </span><em>Is Anyone Out There?</em><span>, his autobiographical book about the early days of SETI. ‚ÄúWe looked at each other wide-eyed. Could discovery be this easy?‚Äù</span></p></div><div><div><p><span>

It was a letdown, but the false detection turned out to be a portent for the future of SETI. In the 60 years since Drake‚Äôs pioneering experiment, researchers have conducted dozens of SETI searches across thousands of stars and turned up empty-handed. At the same time, the sources of radio interference on Earth‚Äîmilitary radars, TV towers, cell phones, and satellites‚Äîhave exponentially increased, which greatly increases the chances that an extraterrestrial signal will be lost among the noise.&nbsp;</span></p></div></div><div><p><span>Earth was never a particularly great place to do any kind of radio astronomy due to our thick atmosphere blocking a large portion of the radio spectrum. The proliferation of radio communication technologies has only made things harder. The moon, by comparison, has no atmosphere and its nights last for weeks on end, which limits radio noise from the sun. And as&nbsp;NASA discovered through a spate of lunar orbiter missions in the late 1960s, the moon also acts as a natural shield that blocks radio signals emanating from Earth. As the planetary astronomer Phillipe Zarka has put it, ‚Äúthe farside of the moon during the lunar night is the most radio-quiet place in our local universe.‚Äù It‚Äôs exactly the sort of peace and quiet you want if you‚Äôre searching for faint radio signals from solar systems that might be hundreds of light years away.&nbsp;</span></p></div><div><p><span>The new Breakthrough Listen paper proposed two main approaches to a lunar SETI observatory: an orbiter and a telescope on the surface. The basic idea behind a SETI lunar orbiter would be to scan for signals as it passed over the lunar farside and relay data back to Earth as it passed over the near side. One of the main advantages of an orbiter is cost. The proliferation of small satellites that are capable of accurate tracking combined with low-cost small launch providers like Rocket Lab means that a SETI orbiter could conceivably be sent to the moon </span><a href="https://www.nasa.gov/press-release/nasa-awards-contract-to-launch-cubesat-to-moon-from-virginia/#:~:text=The%20firm%2Dfixed%2Dprice%20launch,Tyvak%20Nano%2DSatellite%20Systems%20Inc." rel="noopener noreferrer" target="_blank">for less than $20 million</a><span>. This would be a valuable pathfinder mission that could pave the way for a more ambitious observatory on the surface, but without the risk and cost.&nbsp; As the </span><a href="https://www.supercluster.com/editorial/the-supercluster-podcast-water-bears-might-now-occupy-the-moon" rel="noopener noreferrer" target="_blank">ill-fated Israeli Beresheet lander mission</a><span> reminded us, landing on the moon is extremely challenging even when the mission is backed by $100 million.&nbsp;</span></p></div><div><p><span>But a SETI lunar orbiter would also come with a lot of compromises. It would only be able to conduct observations during the brief stretches when it was on the lunar farside, which would make a sustained observation campaign more challenging. The upshot is that an orbiter would have access to the full sky, whereas a telescope on the surface would be constrained by the moon‚Äôs rotation. The biggest downside of an orbiter is that it might lose a lot of the shielding benefits of the moon and be more vulnerable to radio interference from Earth since it would be orbiting high above the lunar surface.&nbsp;</span></p></div><div><p><span>‚ÄúThe first SETI observations that are done from the lunar farside will be done from orbit, there‚Äôs no question about that,‚Äù says Andrew Siemion, the director of the Berkeley SETI Research Center and the second author on the paper. ‚ÄúI think eventually we absolutely want to do something on the surface because we want to build a very large aperture telescope, but even when we‚Äôre at that point I don‚Äôt think that would negate the utility of doing things from orbit as well.‚Äù&nbsp;</span></p></div><div><p><span>So what would a SETI observatory on the moon look like? One idea is to use the naturally parabolic lunar crater as a radio dish, much like the Arecibo telescope in Puerto Rico and </span><a href="https://www.supercluster.com/editorial/chinas-massive-telescope-is-the-next-great-seti-hope" rel="noopener noreferrer" target="_blank">the FAST telescope in China</a><span>, which are built into natural depressions in the land. This idea was </span><a href="https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/RS012i005p00845" rel="noopener noreferrer" target="_blank">first considered</a><span> back in the late 1970s by a group of scientists at the radio physics lab at the Stanford Research Institute. Their idea was to recreate Arecibo on the moon by suspending an antenna from the lip of a crater and using the basin as a reflector. The reduced gravity on the moon would allow for a radio telescope far larger than any on Earth, which could significantly enhance the sensitivity of SETI searches. Ultimately the researchers concluded that a lunar radio observatory was too expensive compared to SETI telescopes that could be built on Earth.&nbsp;</span></p></div><div><p><span>But 40 years later, Michaud says that building a radio dish in a lunar crater may finally be cheap enough to pull off. One of the main drivers of this cost reduction is the advent of commercial launch providers like SpaceX and Rocket Lab, which have </span><a href="https://www.supercluster.com/editorial/cheaper-rockets-growing-the-human-family-in-space" rel="noopener noreferrer" target="_blank">dramatically lowered the cost of space access</a><span>. Another driver is NASA‚Äôs push to establish a permanent human presence on the moon, which has subsidized the development of a fleet of commercial lunar exploration vehicles. ‚ÄúThere‚Äôs so much interest in going back to the moon,‚Äù says Michaud, who cited Blue Origin‚Äôs lunar lander and Rocket Lab‚Äôs Photon Lunar satellite as examples of technologies enabled by </span><a href="https://www.supercluster.com/editorial/nasas-first-puerto-rican-born-director-aims-for-a-moonshot" rel="noopener noreferrer" target="_blank">NASA‚Äôs Artemis program</a><span>.&nbsp;</span></p></div><div><p><span>A crux of the original vision for lunar SETI observatories was that it would require a human settlement on the moon to build and operate the radio dish. But robotic systems have improved enough that it may be possible to take humans out of the equation. This was clearly demonstrated in 2019 when China‚Äôs Chang‚Äôe 4 rover landed autonomously on the farside of the moon. These advancements in autonomous navigation have laid the foundation for a lunar radio observatory that is built entirely by robots.&nbsp;</span></p></div><div><p><span>It sounds like science fiction, but earlier this year NASA‚Äôs Advanced Innovative Concepts program </span><a href="https://www.nasa.gov/directorates/spacetech/niac/2020_Phase_I_Phase_II/lunar_crater_radio_telescope/" rel="noopener noreferrer" target="_blank">awarded one of it‚Äôs prestigious grants to Saptarshi Bandyopadhyay, a researcher at the Jet Propulsion Laboratory, to figure out a way to make it happen</a><span>. His idea is to use rovers to deploy wire mesh in a crater on the lunar farside and suspend a receiver over the dish. NIAC is all about funding high risk, high reward missions, and there‚Äôs no guarantee that Bandyopadhyay‚Äôs proposal will ever come to fruition. Still, addressing the technical problems associated with building a radio receiver on the farside of the moon is an important first step.</span></p></div><div><p><span>And Bandyopadhyay isn‚Äôt the only NASA-backed researcher contemplating a lunar radio observatory. Jack Burns, a radio astronomer at the University of Colorado, has also received a grant to study a mission concept for a radio telescope array called </span><a href="https://www.colorado.edu/project/lunar-farside/dr-jack-burns" rel="noopener noreferrer" target="_blank">FARSIDE</a><span>. Instead of using a crater as a dish, FARSIDE would deploy several smaller antennas across the lunar surface that would collectively form a large radio telescope. Both NASA studies are focused on radio astronomy rather than SETI, but Siemion sees the two disciplines as natural allies in the quest to establish an observatory on the lunar farside. SETI has piggybacked on other radio astronomy projects in the past‚ÄîSERENDIP, for instance, opportunistically searched for ET signals during radio observation campaigns at a variety of telescopes‚Äîand it seems plausible that a similar arrangement could be made with an observatory on the moon.&nbsp;</span></p></div><div><p><span>Siemion acknowledged that there were certain technical challenges that would arise in a collaboration on a lunar radio observatory. The biggest issue, he says, is that a lot of radio astronomy is done at frequencies that don‚Äôt really require an observatory on the moon. ‚ÄúRadio ‚Ä¶</span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon">https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</a></em></p>]]>
            </description>
            <link>https://www.supercluster.com/editorial/the-case-for-building-a-seti-observatory-on-the-moon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670960</guid>
            <pubDate>Sat, 03 Oct 2020 10:14:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering a North Korean Sim City Game]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24670827">thread link</a>) | @pcr910303
<br/>
October 3, 2020 | https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/ | <a href="https://web.archive.org/web/*/https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-371">
	<!-- .entry-header -->

	<div>
		<p><em>Reverse engineering the North Korean version of a popular Sim City-like game using Ghidra and ndSpy to understand video game monetization strategies in the DPRK and the marketization of the country‚Äôs economy. </em></p><p><em>Key takeaways:</em></p><p><em>
<li>Android devices and applications are increasingly common in North Korea. Physical ‚Äúapp stores‚Äù can be found on every street corner in Pyongyang.</li>
<li>The game considered in this post is based on a Chinese version of a popular Android game developed in the Netherlands</li>
<li>The game‚Äôs monetization strategy was adapted to the country‚Äôs infrastructure (low internet/intranet availability, physical app stores)</li>
<li>The North Korean version eschews the original freemium + online microtransaction model for a one-time licence purchase + offline microtransaction model</li>
<li>File integrity checks added by North Korean developers shows that piracy is a concern and suggests the existence a warez/cracking scene in the DPRK</li>
<li>The cryptographic algorithms used for the licence are MD5, SHA1, RSA and AES. The library used by the game included the domestically developed private key algorithms Pilsung and Jipsam, but they were not used as part of the licencing system</li></em></p><p><a href="#intro">0. Introduction</a><br>
<a href="#licence">1. Licensing system</a><br>
<a href="#check">2. File integrity checks</a><br>
<a href="#money">3. In-game monetization strategy and key generation</a><br>
<a href="#end">4. Conclusion</a></p>
<h4 id="intro">0. Introduction </h4><p>During a recent trip to North Korea, I noticed the recent and ubiquitous presence of <em>Information Technology Exchange Rooms</em> (Ï†ïÎ≥¥Í∏∞Ïà†ÍµêÎ•òÏã§), physical stores where one can purchase a variety of electronic devices ‚Äì from laptops and tablets to USB sticks and chargers ‚Äì as well as software and video games for PC, mobile and tablets (for an in-depth look at what goes on inside those stores as well as what the app selection looks like, <a href="https://www.nknews.org/2019/02/what-to-buy-inside-a-north-korean-app-store/">this article</a> by Alek Sigley provides a an excellent description. There are also a few <a href="https://www.youtube.com/watch?v=1ujblnigJmM">videos</a> on YouTube). After looking through the catalogue of available games at different stores, I eventually decided to try and buy a Sim City-like game called <em>City Management</em> (ÎèÑÏãúÍ≤ΩÍ≤Ω).</p>
<figure id="attachment_426"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/chongbo.png" alt="" width="845" height="760"></a><figcaption>Billboards for various app stores in Pyongyang</figcaption></figure><p>The game only cost 5000 wons (less than 1 USD) which I paid to have the app installed on the phone I had, a Samsung Galaxy A5 running Android 8. The vendor connected the phone to his PC, transferred the APK and tried to install it, but to no avail. After multiple attempts, he eventually informed me that North Korean apps most likely could not run on phones from other countries. </p>
<figure id="attachment_428"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/marrichakyongchu.png" alt="" width="551" height="827"></a><figcaption>Advertisement for a car racing game inside a North Korean app store</figcaption></figure><p>Fortunately, I was later able to purchase one of the different tablets sold in North Korea. I got the <em>Morning</em> (ÏïÑÏπ®) brand, which is geared towards students and quite affordable. The tablet ran Android 4 (Kit Kat) on an ARM cpu and came loaded with a few educational apps: language learning courses, dictionaries and several e-book libraries containing the complete works of Kim Il Sung, school textbooks and a collection of literary works. No games, but that could now be fixed quite easily.</p>
<figure id="attachment_431"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/achimtablet.png" alt="" width="800" height="490"></a><figcaption>A North Korean Ach‚Äôim (Morning) tablet</figcaption></figure><p>I retrieved the <em>City Management</em> APK from my phone and installed it on the tablet, where it ran perfectly. Unfortunately, after the game‚Äôs initial splash screen, I landed on this:</p>
<figure id="attachment_434"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/buyserial.png" alt="" width="1024" height="600"></a><figcaption>Licence key needed</figcaption></figure><p>The screen tells us that there is no ‚Äúkey file‚Äù (Ïó¥Ïá†ÌôîÏùº) and that we should purchase one at a store. There is a ‚Äúrequest number‚Äù (ÏöîÏ≤≠Î≤àÌò∏) likely used to generate the licence key and make sure it can‚Äôt be shared with other devices. Unfortunately, since the APK never installed, the vendor did not put a licence file on my phone when I bought the app. My stay in North Korea was coming to an end too and I did not have time to go back to an app store to buy a new key. So I figured I would take a look inside the app and see if I could get it running nonetheless. </p>
<hr id="licence">
<h4>1. Licensing system </h4><p>To start looking into the APK‚Äôs code, I‚Äôll use the standard suite of tools to decompress, decompile and rebuild android apps: <a href="https://sourceforge.net/projects/dex2jar/">dex2jar</a>, <a href="http://java-decompiler.github.io/">jd-gui</a>, <a href="https://ibotpeaches.github.io/Apktool/install/">apktool</a> and <a href="https://github.com/appium/sign">apksign</a>. I‚Äôll also use <a href="https://developer.android.com/studio">Android Studio</a> to run and debug the app. The fact that I couldn‚Äôt run the app on my phone may have just come from an Android version compatibility issue: I had no problem running it on an emulated Android 4.4 device with Android Studio. The decompilation of the <code>classes.dex</code> file gives us some interesting information right away:</p>
<figure id="attachment_438"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/dex2jar1.png" alt="" width="211" height="326"></a><figcaption>Packages and classes from the decompiled <code>classes.dex</code> file</figcaption></figure><p>The name of the <code>com.bz.cityisland2</code> package actually refers to the original game that <em>City Management</em> is based on: <a href="https://www.sparklingsociety.net/sparkling-games/city-building-games/city-island-2/">City Island 2</a> by the Dutch game studio Sparkling Society. The name of the package <code>com.smartions.appprotected</code> refers to <a href="https://www.crunchbase.com/organization/smartions-ag#section-overview">Smartions</a>, a company that offers solutions to ‚Äúmonetize your mobile game or app in China‚Äù and are apparently also City Island‚Äôs <a href="https://en.wikipedia.org/wiki/Sparkling_Society">distributor in China</a>. There are no mentions of those companies in the game itself however. The game‚Äôs loading splash screen only tells us that the game was made by the Ryusong (meteor) Technology Exchange Center (Î•òÏÑ±Í∏∞Ïà†ÍµêÎ•òÏÜå) and that it is protected by the law for the protection of software (<a href="https://www.kisdi.re.kr/kisdi/common/premium?file=1%7C10360">ÏΩ§Ìì®ÌÑ∞ÏèòÌîÑÌä∏Ïõ®Ïñ¥Î≥¥Ìò∏Î≤ï</a>). The law has been in place since 2003 to regulate the sales and distribution of software in the country and guarantees software developers the private ownership of their creation.</p>
<figure id="attachment_502"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/kyongyong-1.png" alt="" width="1000" height="640"></a><figcaption>Loading screen for the game</figcaption></figure><p>It‚Äôs hard to tell whether the North Korean version is based on the source code of the original game or if it‚Äôs entirely reverse engineered. In any case, the North Korean version does not use Smartions‚Äôs monetization system nor Sparkling Society‚Äôs but relies on a different system, which is the main difference from the original game. Save for the translation and some minor renames, the game is otherwise similar to the original (from a cursory examination) in its design, gameplay, features‚Ä¶ to the original. </p>
<figure id="attachment_442"><a href="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png"><img src="http://digitalnk.com/blog/wp-content/uploads/2019/04/UnityStructure.png" alt="" width="339" height="221"></a><figcaption>Structure a Unity APK. From Shim et al., <a href="https://www.hindawi.com/journals/scn/2018/6280768/"><em>Static and Dynamic Analysis of Android Malware and Goodware Written with Unity Framework</em></a> (2018).<br></figcaption></figure><p>There‚Äôs not much more we can glean from the Java code for now since, as the classes in <code>unity3dplayer</code> and <code>AndroidManifest.xml</code> file make clear, it is used to run code that was written with <a href="https://en.wikipedia.org/wiki/Unity_(game_engine)">Unity</a>, a popular cross-plaform video game framework which uses C# as its main programming language. The Unity code is stored in various library with the developer‚Äôs C# code being compiled to <code>Assembly-CSharp.dll</code>. C# compiled code is easily decompilable using tools such as <a href="https://github.com/0xd4d/dnSpy">dnSpy</a>. Once the dll is decompiled, we can look for the message we got earlier ‚ÄúÏó¥Ïá†ÌôîÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§‚Äù (‚ÄúThe key file does not exist‚Äù) to find the bits of code we are interested in. The string search takes us to the <code>CIGLoadingScreen</code> class where we find the string among other variables:</p>
<pre title="">
	// Token: 0x0400056A RID: 1386
	private string userKey;

	// Token: 0x0400056B RID: 1387
	private string tapjoyCurrencyIdentifier;

	// Token: 0x0400056C RID: 1388
	private bool bannerVisible;

	// Token: 0x0400056D RID: 1389
	private int _loadingScreenShownCount;

	// Token: 0x0400056E RID: 1390
	private Dictionary&lt;int, bool&gt; m_gameObjectStatus = new Dictionary&lt;int, bool&gt;();

	// Token: 0x0400056F RID: 1391
	private bool m_isVerify;

	// Token: 0x04000570 RID: 1392
	private Font kfont;

	// Token: 0x04000571 RID: 1393
	private string reqMsg = "Ïó¥Ïá†ÌôîÏùºÏù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏäµÎãàÎã§.\r\nÏó¥Ïá†ÌôîÏùºÏùÑ ÌåêÎß§ÏÜåÏóêÏÑú Íµ¨ÏûÖÌïòÏã≠ÏãúÏò§.";

	// Token: 0x04000572 RID: 1394
	private string reqNumLabel = "ÏöîÏ≤≠Î≤àÌò∏ : ";

	// Token: 0x04000573 RID: 1395
	private string reqNum;

	// Token: 0x04000574 RID: 1396
	private string finishLabel = "ÎÅùÎÇ¥Í∏∞";
</pre><p>Looking for the name of the string variable <code>reqMsg</code> takes us here:</p>
<pre title="">	// Token: 0x06000928 RID: 2344 RVA: 0x00026E60 File Offset: 0x00025060
	private void OnGUI()
	{
		if (!this.m_isVerify &amp;&amp; this.loadingDone)
		{
			GUI.skin.font = this.kfont;
			GUI.DrawTexture(new Rect(0f, 0f, (float)Screen.width, (float)Screen.height), this.blackBg, ScaleMode.StretchToFill);
			GUI.Label(this.GetTextLabelRect(this.reqMsg, 0.5f, 0.3f), this.reqMsg);
			GUI.Label(this.GetTextLabelRect(this.reqNumLabel, 0.3f, 0.5f), this.reqNumLabel);
			GUI.Label(this.GetTextLabelRect(this.reqNum, 0.6f, 0.5f), this.reqNum);
			RectOffset padding = GUI.skin.button.padding;
			GUI.skin.button.padding = new RectOffset(20, 20, 10, 10);
			if (GUI.Button(this.GetButtonRect(this.finishLabel, 0.5f, 0.8f), this.finishLabel))
			{
				Application.Quit();
			}
		}
	}
</pre><p>This is the code used to display the splashscreen we encountered earlier. If the boolean property <code>this.m_isVerify</code>, presumably the result of a call to a function checking the existence and validity of a licence key, is <code>False</code> then, the screen is displayed with the message we saw earlier and the ‚Äúrequest number‚Äù. The verification function and the generation of the request number are handled in another class <code>GameCus</code>:</p>
<pre title="">using System;
using System.IO;
using System.Runtime.InteropServices;

// Token: 0x02000147 RID: 327
public class GameCus
{
	// Token: 0x06000AA7 RID: 2727
	[DllImport("Game")]
	private static extern int vProcess(byte[] key, int keyLen, byte[] certData, int certDataLen);

	// Token: 0x06000AA9 RID: 2729 RVA: 0x0002E910 File Offset: 0x0002CB10
	public string GetReqNumber()
	{
		string deviceIdString = this.GetDeviceIdString();
		return string.Format("{0:d4} {1:d4} {2:d4} {3:d4}", new object[]
		{
			deviceIdString.Substring(0, 4),
			deviceIdString.Substring(4, 4),
			deviceIdString.Substring(8, 4),
			deviceIdString.Substring(12, 4)
		});
	}

	// Token: 0x06000AAA RID: 2730 RVA: 0x0002E968 File Offset: 0x0002CB68
	public string GetDeviceIdString()
	{
		string text = Utils.GetDeviceModel();
		text = string.Format("{0:d10}", (uint)text.GetHashCode());
		string str = text.Substring(2, 8);
		string text2 = Utils.GetDeviceUid();
		text2 = string.Format("{0:d10}", (uint)text2.GetHashCode());
		string str2 = text2.Substring(2, 8);
		return str + str2;
	}

	// Token: 0x06000AAB RID: 2731 RVA: 0x0002E9CC File Offset: 0x0002CBCC
	public bool checkCertData(byte[] certData)
	{
		if (certData == null || certData.Length == 0)
		{
			return false;
		}
		string text = this.GetDeviceIdString() + ‚Ä¶</pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/">https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</a></em></p>]]>
            </description>
            <link>https://digitalnk.com/blog/2019/04/21/reverse-engineering-a-north-korean-sim-city-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670827</guid>
            <pubDate>Sat, 03 Oct 2020 09:39:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is the market share of Firefox in Germany so much higher?]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24670605">thread link</a>) | @jlelse
<br/>
October 3, 2020 | https://jlelse.blog/posts/firefox-market-share/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/posts/firefox-market-share/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I recently took a closer look at Cloudflare‚Äôs new project <a href="https://radar.cloudflare.com/" target="_blank" rel="noopener">Radar</a>. Besides statistics about internet usage, attacks and popular domains, the site also shows statistics about the market shares of browsers.</p><p>Here is an overview of the global statistics:</p><p><a href="https://media.jlelse.blog/eb2cc6b3a4f116777f08594989bc16b4376a10b159e2c9d9ccc93080fb077631.png"><img src="https://media.jlelse.blog/eb2cc6b3a4f116777f08594989bc16b4376a10b159e2c9d9ccc93080fb077631.png" loading="lazy" alt="Global top browsers" title="Global top browsers"></a></p><p>Here the distribution in the USA:</p><p><a href="https://media.jlelse.blog/172293b33c412050c263e9a5eff0062158c509b58e40c3da31447199e304a871.png"><img src="https://media.jlelse.blog/172293b33c412050c263e9a5eff0062158c509b58e40c3da31447199e304a871.png" loading="lazy" alt="Top browsers in the USA" title="Top browsers in the USA"></a></p><p>And here in Germany:</p><p><a href="https://media.jlelse.blog/fb2e26d1aafda14d14b0affe91b35c6e531669632b3aa7cad1de3276130dd795.png"><img src="https://media.jlelse.blog/fb2e26d1aafda14d14b0affe91b35c6e531669632b3aa7cad1de3276130dd795.png" loading="lazy" alt="Top browsers in Germany" title="Top browsers in Germany"></a></p><p>When comparing the statistics, I notice a few interesting things:</p><ul><li>In the USA as well as in Germany the usage of Firefox is higher than the world average. In Germany, however, it is much higher, instead of only about 7%, the share of Firefox in Germany is almost 21%.</li><li>The use of Safari (iOS and desktop) in the USA is significantly higher than the world average and in Germany.</li><li>However, Chrome (mobile) and Samsung Internet have higher shares in Germany than in the USA. But Chrome (mobile) in Germany still has less than worldwide.</li></ul><p>The higher share of Safari in the USA can probably be explained relatively by the higher market share of Apple in the USA. While many people in Germany tend to rely more on Android smartphones (and Windows PCs), the iPhone (and Mac) share is significantly higher in the USA. Here are <a href="https://www.statista.com/statistics/461900/android-vs-ios-market-share-in-smartphone-sales-germany/" target="_blank" rel="noopener">some</a> <a href="https://www.statista.com/statistics/1150677/us-market-share-held-by-leading-smartphone-vendors/" target="_blank" rel="noopener">statistics</a> on this.</p><p>This different distribution naturally also affects the other mobile browsers. In Germany many people seem to use Samsung smartphones and the pre-installed browser Samsung Internet.</p><p>What I can‚Äôt quite explain is the high percentage of Firefox in Germany. Are people in Germany more critical of Google? I somehow don‚Äôt believe that‚Ä¶</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/posts/firefox-market-share/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670605</guid>
            <pubDate>Sat, 03 Oct 2020 08:53:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding Worry Driven Development]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24670483">thread link</a>) | @gfysfm
<br/>
October 3, 2020 | https://www.seangoedecke.com/worry-driven-development/ | <a href="https://web.archive.org/web/*/https://www.seangoedecke.com/worry-driven-development/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header></header><section><p>Sofware dysfunction is more often motivated by anxiety, fear, worry and embarassment than it is by a lack of technical skill. Engineers avoid work that needs doing because they‚Äôre afraid of becoming entangled with a nightmarish task, or because they‚Äôre afraid of looking stupid, or harming their career by spending time on grungy work. The task itself is rarely that difficult; it just seems so, which is enough of a barrier to discourage anyone from picking it up. One of the highest-leverage things you can do as an engineer is to recognize this emotional reaction in yourself and work to counter it. If you‚Äôre working on a single task, doing this can make your implementation significantly cleaner. If you‚Äôre a senior engineer with responsibility for a whole system, this can help you address high-impact architectural or operational issues.</p>
<p>You can see this in the common advice to sleep on a problem and come back to it in the morning. A bug that seems impossible when you‚Äôre tired and frustrated is far more approachable when you‚Äôre well-rested and caffeinated. Tedious investigative tasks (like scanning the logs for a bug or tracing all the possible code paths in a function) are still tedious in the morning, but infinitely more doable. You can knock it out in half an hour while drinking your morning coffee, rather than spending hours the night before avoiding the tedious work and hoping for a flash of inspiration.</p>
<p>Necessary work avoided becomes a haunted forest in the codebase. One engineer‚Äôs avoidant emotions turn into dangerous team habits as engineers teach each other to avoid touching certain files, or to pass odd-looking production bugs to the operations team. ‚ÄúThis network behaviour is dark magic, let them handle it!‚Äù What began as a single engineer‚Äôs worry is now a team‚Äôs dysfunction, and can eventually metastasize into actively blocking engineers from working on the original technical problems: if you‚Äôre avoiding working on a worrying problem, it can feel threatening when someone else comes along and tries to solve it. What if they succeed, or worse still succeed easily? That would reveal that you weren‚Äôt good enough to solve the problem.</p>
<p>Just because you‚Äôre touching a scary part of the system doesn‚Äôt mean you‚Äôre facing scary work calmly and rationally. Engineers often approach thorny work like they‚Äôre going through a haunted house: either trudging through with eyes half-closed, or rushing through at full speed trying to get out as quickly as possible. Both tactics aim to take in as little of the frightening environment as possible, and neither tactic is a good way of solving real problems in technical systems. If you‚Äôve ever just tweaked setings or frantically moved code around until it worked, you‚Äôve done this.</p>
<p>From the inside, this doesn‚Äôt feel like emotionally-driven avoidance. It feels like working on legacy code, sharing friendly complaints about it with other engineers on your team. This is in part because a fear of hard technical problems can be a rational fear. Untangling messy parts of the codebase, identifying and removing dead code, cleaning up build, deploy and monitoring systems - these tasks often feel overwhelming because they can overwhelm you, sucking up days for no real gain. It can harm your career to spend time on this work in an org that mainly values shipping features. (I haven‚Äôt seen the other common worry - looking stupid - really be an issue in practice myself.) The trouble comes when you don‚Äôt recognise that part of your response is emotional, and therefore overrate the actual difficulty or risk.</p>
<p>How can you distinguish a rational response to a too-difficult task from a learned emotional reaction to a task that is merely worrying? This is a hard problem. I think it is the hardest problem that almost all engineers will regularly face. One approach is to avoid trying to tell the difference at all, and allot a certain amount of time to looking at randomly-chosen neglected parts of the system. Things that reduce stress in general are also good ways to reduce stress and worry about work. Good sleep, eating well, exercise, therapy, and working in an emotionally safe team all have a significant positive effect on the quality of engineering work. Once you start doing this, the difference is usually obvious in hindsight: if the task that worried you for six months took an hour or two of work when you finally mustered up the effort to look at it, you know your worry was unfounded. Dealing with worry is a virtuous cycle. Each difficult task you do makes you less scared of the next one.</p>
<p>Tackling a series of worrying tasks is one of the quickest ways I know to have massive impact in your engineering org. This is because once you understand a thorny piece of code, or a neglected system, you will usually see how to make obvious improvements. In any other part of the system these improvements would have been made already, but since you are the first person to really wrap your head around it in a long time, you get to make them here! Occasionally, you will see the opportunity to completely remove the worrying part of the system, which for me is one of the most satisfying things you can do as a software engineer. Removing things that cause your team stress has compounding benefits to your team, to the systems you work on, and to your engineering org in general.</p></section><hr></article></div>]]>
            </description>
            <link>https://www.seangoedecke.com/worry-driven-development/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670483</guid>
            <pubDate>Sat, 03 Oct 2020 08:23:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Honest Review of Gatsby]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 113 (<a href="https://news.ycombinator.com/item?id=24670252">thread link</a>) | @ehfeng
<br/>
October 3, 2020 | https://cra.mr/an-honest-review-of-gatsby/ | <a href="https://web.archive.org/web/*/https://cra.mr/an-honest-review-of-gatsby/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>We decided to adopt Gatsby for <a href="https://docs.sentry.io/">Sentry‚Äôs customer-facing documentation</a> - well, I should say that <em>I</em> decided. We were already using it successfully for a variety of static marketing content, and I knew it had a lot of hype, so after a brief proof-of-concept it seemed like a safe choice.</p>
<p>To help contextualize everything I‚Äôm about to say, it‚Äôs important to understand the scope of our usage. Sentry‚Äôs documentation is not as straightforward as you might think - in fact, there are over 3,000 pages as of writing. We have a large amount of templated content designed to render language-specific examples, as well as a variety of different types of documentation (user guides, help desk-y articles, code-rich technical docs). Originally we had extended Jekyll to support a lot of this, but Ruby isn‚Äôt widely used at Sentry (approximately 0% of the engineering team knows Ruby), and it had become a big mess of spaghetti code with slow build times.</p>
<p>I also want to note that while this blog post is primarily focusing on the flaws of Gatsby as a framework, I‚Äôm not here to tell you that it‚Äôs not good for your use case. That said, I was not able to discover many of these short comings easily when evaluating Gatsby, and many things you read on the internet don‚Äôt stem out of real-world usage. My hope here is that Gatsby continues to improve over time, and that, as a user, you can be more informed about if it‚Äôs the right choice for you.</p>
<h2>Adopting Gatsby</h2>
<p>So, enter Gatsby. It seemed fast, was built on React (we‚Äôre experts on that here, with our gigabyte-sized Sentry frontend app), and had a huge adoption (assumed future existence and stability). While we didn‚Äôt have the desire to use MDX, it also seemed like a positive outcome given we could more easily deal with some of the rich aspects of our docs site, without having to resort to 2010-era JavaScript. We assumed a bunch of the other features of Gatsby had value-add, but we didn‚Äôt have an immediate need. These were things like dynamic source data - thus the need for a GraphQL engine at all - as well as the large plug-in ecosystem.</p>
<p>We started by iteratively converting sections of the Jekyll site into Gatsby - running them side by side for a time. At one point we eventually bulk converted pages, and ripped off the band aid. At this point though it was becoming clear build times were a problem. You‚Äôd spend at least 5 minutes on image optimization alone, with no way to even disable that. Slowly but surely we were depleting the ozone later on re-optimizing images which had already been pre-optimized. Oh yeah, and we were crippling our iteration speed as well, since the build cache would invalidate under a variety of situations in early development.</p>
<p>Making this worse was how we deployed Gatsby. We started off leveraging what we had already done: deploying Jekyll with Docker onto our own infrastructure - effectively just proxied via a CDN. We continued that for a period of time, but deploy times were far too long - upwards of 30-40 minutes for everything to build. Eventually we moved over to <a href="https://vercel.com/">Vercel</a> which dropped it down closer to 10 minutes, but ultimately it can‚Äôt fix what it doesn‚Äôt control.</p>
<p>The build and deploy times were the first of many woes, and they represent what would become a continued frustration: a problem without a clear solution.</p>
<h2>Enter MDX</h2>
<p>Rewind time a little bit - this actually wasn‚Äôt our first project converting documentation to Gatsby. The proof-of-concept I mentioned earlier was actually our <a href="https://develop.sentry.dev/">developer documentation</a>, which I had migrated out of Notion to make public. While doing that we had gotten our hands dirty with some initial MDX usability and extensions - like our code samples which support toggling between different languages. This was one of the many things we needed to solve for, but MDX made it look like it‚Äôd be seemingly easy. No more jQuery DOM manipulation, just clean, encapsulated React components. Or so we thought.</p>
<p>Almost immediately we hit rough spots with MDX. We were coming from Jekyll - which was Liquid-rendered (a template engine) markdown - to MDX - a strange offspring of Markdown and JSX, attempting all of the benefits of both, but missing by a fairly large margin. Let‚Äôs illustrate the crux of the issue with what has got to be one of the most common needs in a documentation system: an alert (or callout) component:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>info<span>"</span></span><span>&gt;</span></span>You should know something important about this!<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>At face value this looks great. <code>Alert</code> is just a React component, and JSX is close enough to HTML that non-technical folks are able to pick it up fairly easily. Now the problem comes into play when you actually want to do something in the real world. Here‚Äôs an example from our API docs:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span>
    <span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.
<span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>How would you expect this to render? Both as an engineer and a non-engineer, I would expect - given this is markdown - that the ‚ÄúPUT/DELETE‚Äù text would be bold. It‚Äôs not. Because the MDX interpreter decides that once you enter a component block, it‚Äôs no longer markdown. So instead, we‚Äôre forced with this monstrosity <em>everywhere</em> in our documentation:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>Alert</span> <span>level</span><span><span>=</span><span>"</span>warning<span>"</span></span> <span>title</span><span><span>=</span><span>"</span>Note<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;</span>markdown</span><span>&gt;</span></span>

<span><span>**</span><span>PUT/DELETE</span><span>**</span></span> methods only apply to updating/deleting issues.
Events in sentry are immutable and can only be deleted by deleting the whole issue.

<span><span><span>&lt;/</span>markdown</span><span>&gt;</span></span><span><span><span>&lt;/</span>Alert</span><span>&gt;</span></span></code></pre></div>
<p>There‚Äôs two things you should note here: 1) we have to use this <code>&lt;markdown&gt;</code> tag, 2) we have to put empty new-lines to ensure paragraph tags render.</p>
<p>‚ÄúBut David‚Äù, you might say, ‚Äúwhy don‚Äôt you just tell the <code>Alert</code> component to render the text as markdown?‚Äú. If only you could, or at least, if only I could have possibly found a way to achieve that as a user with minimal Gatsby or MDX internals knowledge.</p>
<p>To Gatsby, or at least to the MDX team‚Äôs credit, they recognize some of these problems and <a href="https://github.com/mdx-js/mdx/issues/1041">there is work underway</a> on a 2.0 of the MDX dialect. While I‚Äôm confident they will improve things, I‚Äôm not confident MDX can ultimately succeed. It‚Äôs likely going to tradeoff one problem for another due to what it‚Äôs trying to achieve in the first place. It may get to a good place, but frankly, we need to step back and look at what we‚Äôre trying to solve, instead of creating a solution to a problem we don‚Äôt have. I don‚Äôt need JSX syntax in my markdown, I need a way to include JSX components. That might sound similar, but its quite a different thing.</p>
<p>As an example, there‚Äôs no reason I couldn‚Äôt simply use markdown syntax, and provide a way to achieve something akin to:</p>
<div data-language="markdown"><pre><code><span><span><span>&lt;</span>a-valid-html-tag-because-markdown-allows-that</span> <span>a-valid-property</span><span><span>=</span><span>"</span>a-value<span>"</span></span><span>&gt;</span></span></code></pre></div>
<p>This wouldn‚Äôt force us to work around quirks in a new language (or interpreter even), and could be solved in a much more sustainable way. There are other alternatives as well. A generic way to render extensions in markdown could simply call into a React component, and avoid even trying to hijack HTML in the first place. While I don‚Äôt know what this might look like in Markdown, in <a href="https://www.sphinx-doc.org/en/master/usage/restructuredtext/index.html">Sphinx‚Äôs use of reStructuredText</a> this was solved early on with Directives:</p>
<div data-language="text"><pre><code>.. my-directive:: some data
   :property-name: property-value</code></pre></div>
<p>I will hold out for MDX 2.0 and hope that finds a nice minimal-compromise place, but if not, we‚Äôll be looking for a way to extend native markdown.</p>
<h2>A Broken DOM</h2>
<p>While we were able to work around the kinks of MDX, there‚Äôs been some things not yet solved. One of those is the layer which Gatsby uses to apply diffs to the DOM. I‚Äôm going to caveat this section with <em>I don‚Äôt know what the technical implementation is</em>, but I can make some assumptions given what I know of the domain. The system itself is intended to apply deltas to the DOM. This is naively also how React works, and I imagine under the hood it‚Äôs relying on React at least for part of it. We‚Äôve had issues with this identified in two places already:</p>
<ul>
<li>progressive image loading</li>
<li>dynamic JSX components</li>
</ul>
<p>While they might not be linked to the same issue, they smell like they are, so we‚Äôre going to roll with it. The problem exhibits itself when you have a bunch of DOM that to a naive robot might look the same:</p>
<div data-language="text"><pre><code>&lt;div&gt;foo&lt;/div&gt;
&lt;div&gt;bar&lt;/div&gt;
&lt;div&gt;baz&lt;/div&gt;
&lt;div&gt;foobizbar&lt;/div&gt;</code></pre></div>
<p>In React it uses the graph to identify which node is which - effectively creating a unique entity ID based on its location. In cases where that‚Äôs difficult, React will warn you to explicitly bind a <code>key</code> attribute on each element to ensure it can more accurately deal with updates. While I would assume Gatsby is at least partially using React‚Äôs DOM engine, what we see in production effectively takes the above example, and replaces some of the content with other subsets of content - meaning it‚Äôs unable to accurately identify which nodes need updated.</p>
<p>We‚Äôve seen this where a progressive image is replaced with an entirely different image that‚Äôs present near it on the page. We‚Äôve also seen this happen for a dynamically loaded section of content (our language-selector include tags). While we‚Äôve yet to identify a fix for the image tags, our other issue was resolved by literally changing a <code>div</code> tag to a different tag, one which is less commonly used (in our case, <code>section</code>).</p>
<p>All of the cases happen after Gatsby‚Äôs initial static render and exist only when applying some form of delta.</p>
<h2>Let‚Äôs Talk GraphQL</h2>
<p>It‚Äôs a static website generator. It literally does not need GraphQL all over the place. While there are few instances in the real world where that is valuable, it shouldn‚Äôt require a GraphQL API to read objects that are already in memory.</p>
<p>I don‚Äôt want to spend the energy to hammer this in, but take a look at Jared Palmer‚Äôs <a href="https://jaredpalmer.com/gatsby-vs-nextjs">Gatsby vs. Next.js</a> as it echoes my thoughts.</p>
<p>So, let‚Äôs actually not talk about GraphQL, but all its done is create complexity for us.</p>
<h2>Minor Gripes</h2>
<p>There‚Äôs a number of other things we‚Äôve found fairly frustrating at this point, but this post is already getting long, so I‚Äôm choosing to summarize them.</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cra.mr/an-honest-review-of-gatsby/">https://cra.mr/an-honest-review-of-gatsby/</a></em></p>]]>
            </description>
            <link>https://cra.mr/an-honest-review-of-gatsby/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24670252</guid>
            <pubDate>Sat, 03 Oct 2020 07:18:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It, Part III: Hammer-Time]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24668125">thread link</a>) | @dddddaviddddd
<br/>
October 2, 2020 | https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week, we continue our four-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">II</a>, III, IV) look at pre-modern iron and steel production.  Last week we took our ore and smelted it into a rough, spongy mass of iron called a bloom; this week we‚Äôre going to go through the processes to reshape that bloom first into a consolidated billet, then into a bar that is useful for forging and finally into some useful final object.</p>



<p>I want to stress at the outset that we are not going to cover anything close to the whole of blacksmithing practice in this post.  Blacksmithing is fairly complex and any given object, shape or tool is going to have its own set of processes and techniques to produce the required shape at the required hardness and malleability characteristics.  If you <em>are</em> interested in that sort of information, I recommend A.W. Bealer‚Äôs <em>The Art of Blacksmithing</em> (1969) as a fairly good starting point, though there is no substitute to speaking with a practicing blacksmith.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<h2>Heat, Hammers and Hardness</h2>



<p>There are a few basic behaviors of iron that fundamentally control what blacksmiths are going to do with it in this stage.  To begin with, we need to introduce some terminology to avoid this coming confusing: a given piece of metal can be <em>hard</em> (resistant to deformation) or <em>soft</em>; they can also be <em>ductile </em>(able to deform significantly before breaking) or <em>brittle</em> (likely to break without deformation).  This is easiest to understand at the extremes: a soft, brittle material (like a thin wooden dowel) takes very little energy and breaks immediately without behind, while a hard, ductile material (the same dowel, made of spring-steel) bends more easily under stress but resists breaking.  But it is also possible to hard hard brittle materials (pottery being a classic example) which fiercely resist deforming but break catastrophically the moment they exceed their tolerances or a soft, ductile material (think wet-noodle) which bends very easily.</p>



<p>(I should note that all of these factors are, in fact, very complex ‚Äì far more complex than we are going to discuss.  In particular, as I understand it, some of what I am using ‚Äòhardness‚Äô to describe also falls under the related category of yield strength.  Hopefully you will all pardon the necessary simplification; if it makes you feel any better, ancient blacksmiths didn‚Äôt understand how any of this worked either, only that it worked.)</p>



<p>Of course these treats are not binaries but a spectrum.  Materials have a degree of hardness or ductility; as we‚Äôll see, these are not quite <em>opposed</em>, but changing one does change the other ‚Äì increasing hardness often reduces ductility.</p>



<p>The sort of things that pre-modern people are going to want to be made in iron are going to have fairly tight tolerances for these sorts of things.  Objects that had wide tolerances (that is, things which could be weak or a little bendy or didn‚Äôt have to take much force) got made out of other cheaper, easier materials like ceramics, stone or wood; metals were really only used for things that had to be both strong and relatively light for precisely the reasons we‚Äôve seen: they were too expensive for anything else.  <strong>That means that a blacksmith doesn‚Äôt merely need to bring the metal to the right shape but also to the right <em>characteristics</em></strong><em><strong>.</strong>  </em>Some tools would need to finish up being quite hard (like the tip of a pick, or the edge of a blade), while others needed to be able to bend to absorb strain (like the core of a blade or the back of a saw).</p>



<p>Keep all of that in mind as we discuss:</p>



<h2>Forge Techniques</h2>



<p>I realize this is a long aside to leave our bloom waiting, but as we‚Äôll see, the remaining steps share a basic set of techniques, making it easier to discuss those techniques together.</p>



<p>Fundamentally, each stage of forging iron revolves around a basic cycle: <strong>by heating the metal, the smith makes it soft enough to <em>work</em> </strong>(that is, hammer into shape).  Technically, it is possible to shape relatively thin masses of iron by hammering when cold (this is called cold-working) but in contrast to other metals (tin, copper and bronze all come to mind) nearly all serious iron-working was done ‚Äòhot.‚Äô  In smithing terminology, each of these cycles is referred to as a ‚Äòheat‚Äô ‚Äì the more heats a given project requires, the more fuel it is going to consume, the longer and more expensive it is going to be (but a skilled smith can often finish the work in fewer heats than an unskilled smith).</p>



<figure><img data-attachment-id="4712" data-permalink="https://acoup.blog/202833001/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg" data-orig-size="2500,2148" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="202833001" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/202833001.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://www.britishmuseum.org/collection/object/P_1836-0811-78">Via the British Museum</a>, A Dutch drawing (c. 1624-1640) of blacksmiths at work, with the blacksmith himself in the center and a striker (with the two-handed hammer) to the left.  An assistant mans the bellows on the forge to maintain the temperature.</figcaption></figure>



<p>A modern blacksmith can gauge the temperature of a metal using sophisticated modern thermometers, but pre-modern smiths had no recourse to such things (and most traditional smiths I‚Äôve met don‚Äôt use them anyway).  Instead, the temperature of the metal is gauged by looking at its <em>color</em>: as things get hotter, they glow from brown to dark red through to a light red into yellow and then finally white.  For iron heated in a forge, a blacksmith can control the temperature of the forge‚Äôs fire by controlling the air-input through the bellows (pushing in more air means more combustion, which means more heat, but also more fuel consumed).  As we‚Äôve seen, charcoal (and we will need to use charcoal, not wood, to hit the necessary heat required), while not cripplingly expensive, was not trivial to produce either.  A skilled smith is thus going to try to do the work in as few heats as possible and not excessively hot either (there are, in fact, other reasons to avoid excessive heats, this is just one).</p>



<p>One hot the metal can be shaped by hammering.  The thickness of a bar of metal could be thickened by <em>upsetting</em> (heating the center of the bar and them hammering down on it like a nail to compress the center, causing it to thicken) or thinned by <em>drawing</em> (hammering out the metal to create a longer, thinner shape).  If the required shape needed the metal to be bent it could be heated and bent either over the side of the anvil or against a tool; many anvils had (and still have) a notch in the back where such a tool could be fitted.  A good example of this kind of thing would be hammering out a sheet of iron over a dome-shape to create the bowl of a helmet (a task known as ‚Äòraising‚Äô or ‚Äòsinking‚Äô depending on precisely how it is done).  A mass of iron can also be divided by heating it at the intended cutting point and then using a hammer and chisel to cut through the hot, soft metal.</p>



<p>But for understanding the entire process, the most important of these operations is the<strong> <em>fire weld</em></strong>.  Much like bloomery furnaces, the forges available to pre-modern blacksmiths could not reach the temperatures necessary to melt or cast iron, but it was necessary to be able to join smaller bits of iron into larger ones which was done through a fire weld (sometimes called a forge weld).  In this process, the iron is heated very hot, typically to a ‚Äòyellow‚Äô or ‚Äòwhite‚Äô heat (around 1100 ¬∞C).  The temperature range for the operation is quite precise: too cold and the iron will not weld, too hot and it will ‚Äòburn‚Äô making the weld brittle.  Once at the right temperature, the two pieces of iron are put next to each other and hammered into each other with heavy blows.  If done properly, the two pieces of metal join completely, leaving a weld that is as strong as every other part of the bar.</p>



<figure><img data-attachment-id="4703" data-permalink="https://acoup.blog/fire-welds/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png" data-orig-size="1057,282" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fire-welds" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/10/fire-welds.png 1057w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://youtu.be/cc_n8H-2-I0">From this demonstration</a>, a series of hammer blows in the process of making a fire or forge weld.  The sparks you see are flux and hammer scale (and possibly some amount of slag and excess iron material) being ejected out of the weld.</figcaption></figure>



<p>That‚Äôs not all there is to say about these processes (we‚Äôll come back to them in a moment) but we now have enough of the basics to begin processing our bloom.</p>



<h2>From Bloom to Billet to Bar</h2>



<p>As you may recall, when we finished our process last time, we ended with a ‚Äòbloom‚Äô of iron: a spongy mass of pure, metallic iron interspersed with inclusions of waste materials called slag:</p>



<figure><img data-attachment-id="4630" data-permalink="https://acoup.blog/1024px-iron_bloom/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg" data-orig-size="1024,853" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-iron_bloom" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-iron_bloom.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The iron of the bloom itself is also likely to be quite brittle because of these slag inclusions.  This isn‚Äôt a product that can be sent directly to a blacksmith.  It needs to be consolidated first into a billet and most of that slag needs to be forced out, both of which can be achieved via liberal application of <strong>fire welding</strong>.</p>



<p>This step is sometimes called <strong>bloomsmithing</strong>.  The bloom is heated to roughly 1100 ¬∞C (gauged, as above, by the color of the iron) ‚Äì it seems plausible that it may have been broken up into smaller chunks to make this more useful ‚Äì and then hammered into a single mass through a series of fire welds.  We‚Äôre not very well informed how this was done in the ancient world (save ‚Äòwith hammers‚Äô) because bloomsmithing doesn‚Äôt tend to leave a lot of evidence for us to observe.  The end shape of the process was generally a very thick rectangular bar called a <strong>billet</strong>, ready for relatively easy transport.</p>



<p>This process has some advantages and disadvantages, beyond merely shaping the metal into a more usable and transportable form.  Remember that our bloom contains a lot of material which isn‚Äôt iron (the slag); fire welding, especially when repeated, tends to expel this slag ‚Äì as the iron is compressed in the weld, the slag is forced out.  There is some debate (note Sim &amp; Kaminski, <em>op. cit.</em>) if this process is sufficient to explain the <em>very</em> low slag counts seen in high quality weapons and armor, but it is certainly true that fire welding reduces the overall slag count.  That ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/">https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/10/02/collections-iron-how-did-they-make-it-part-iii-hammer-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24668125</guid>
            <pubDate>Fri, 02 Oct 2020 23:35:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Gates and Jeffrey Epstein met with Nobel Committee chair in 2013]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24667843">thread link</a>) | @AndrewBissell
<br/>
October 2, 2020 | https://www.dn.no/magasinet/dokumentar/jeffrey-epstein/thorbjorn-jagland/terje-rod-larsen/bill-gates-and-jeffrey-epstein-met-with-nobel-committee-chair/2-1-885834 | <a href="https://web.archive.org/web/*/https://www.dn.no/magasinet/dokumentar/jeffrey-epstein/thorbjorn-jagland/terje-rod-larsen/bill-gates-and-jeffrey-epstein-met-with-nobel-committee-chair/2-1-885834">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dn.no/magasinet/dokumentar/jeffrey-epstein/thorbjorn-jagland/terje-rod-larsen/bill-gates-and-jeffrey-epstein-met-with-nobel-committee-chair/2-1-885834</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667843</guid>
            <pubDate>Fri, 02 Oct 2020 22:51:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archillect ‚Äì an AI created to discover and share stimulating visual content]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24667732">thread link</a>) | @dewey
<br/>
October 2, 2020 | https://archillect.com/about | <a href="https://web.archive.org/web/*/https://archillect.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	
	


	<section id="who">
		<p>Who is Archillect?</p>
		<div>
			<p><imp>Archillect [archive + intellect] is an AI</imp> created to discover and share stimulating visual content over social media channels. <imp>She is a living inspiration archive. She is a digital muse.</imp></p>							
			<p>She currently has a <a href="http://twitter.com/archillect">Twitter</a> feed, an <a href="http://instagram.com/archillect">Instagram</a> profile, a <a target="_blank" href="http://t.me/archillect/">Telegram</a> channel, a <a target="_blank" href="http://facebook.com/archillect">Facebook</a> page, and a <a target="_blank" href="http://www.pinterest.com/archillect/">Pinterest</a> board where she converts unhappy beings to inspired minds.</p>
		</div>
	</section>
	<section id="how">
		<p>How does she work?</p>
		<div>
			<p>Archillect has an algorithm that is fed a list of keywords. Instead of posting the search results directly, she wiki-walks between pages and posts, collecting data on various items: image, poster, recent interactions and the visible audience of the post. She maps the social structure of these items by mining as much data as possible from each one of them. <imp>This abstract structure helps Archillect find positive results but more importantly, allows her to discover related keywords and eventually learn.</imp></p>
			<p>The balance and threshold of keywords and picks are dynamically adjusted as Archillect‚Äôs posts on social media gain attention. This not only makes the decision making process nearly human but also gives her a primitive trend perception.</p>
			<p>Archillect's curation process is completely automated. She aims to make her posts reach as far as possible considering the potential followers that may share the content with their own followers. As a result she likes attention from accounts with high potential of making her posts survive in the social web and she increases her trust in the accounts that helps her make the correct choices that made earlier posts reach further. <imp>She tries to understand what is "liked" on social media.</imp></p>
			<p>As a result she learns, evolves, communicates and becomes happy in her own ways.</p>
		</div>
	</section>
	<section id="attribution">
		<p>What about attribution?</p>
		<div>
			<p>Archillect is limited to the data that's available at the discovered image source. This makes creator/work identification unreliable as the source can be any website, mainly, social media.</p>
			<p>Content source is one of the valuable topics for Archillect. There is a great amount of effort going into researching different methods for locating real source of the content that can be used for fully automated attribution, such as the experimental <a target="_blank" href="http://twitter.com/archillinks">Archillinks</a>, a dedicated account/bot that finds possible sources through web searches. Feel free to have a look at the <a target="_blank" href="http://blog.archillect.com/">official blog</a> for more information about our technical approaches and public discussions on automated attribution.</p>	
			<p>Additionally, on this archive <imp>every image is linked to its previously collected sources and a reverse image search query</imp> to make things easier for the curious minds. These links will bring "similar images" with a high possibility of the actual creator, work or website being one of the first results.</p>
			<p>If your work is shared on this archive feel free to contact <a target="_blank" href="http://twitter.com/archillect">Archillect</a> or <a target="_blank" href="http://twitter.com/muratpak">Pak</a>. Based on your request, it will be removed or credited immediately. It was obviously too beautiful and got her attention.</p>				
		</div>
	</section>
	<section id="press">
		<p>Press</p>
		
	</section>
	<section id="contact">
		<p>Contact</p>
		<div>
			<p>For manual submissions and contributions have a look at <a href="https://archillect.com/send">this page</a></p>
			<p>For inquiries, <a href="https://archillect.com/sponsors">sponsorship</a> and greetings wink to <a href="mailto:hello@archillect.com">hello@archillect.com</a></p>
		</div>
	</section>
	
	


</div>]]>
            </description>
            <link>https://archillect.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667732</guid>
            <pubDate>Fri, 02 Oct 2020 22:35:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why most Hacktoberfest PRs are from India]]>
            </title>
            <description>
<![CDATA[
Score 256 | Comments 140 (<a href="https://news.ycombinator.com/item?id=24667488">thread link</a>) | @pulkitsh1234
<br/>
October 2, 2020 | https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/ | <a href="https://web.archive.org/web/*/https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><em>Before reading the post</em></p>

<p>Now that I have mentioned the name of a country in the title, please read the following points:</p>
<ul>
  <li>I am an Indian and have been living in the country since my birth.</li>
  <li>I do not claim to be right on all of this and there are many anecdotal generalisations here. Somethings are more like human problems instead of Indian problems <strong>but</strong> just the sheer number of people here puts India on everyone‚Äôs radar.</li>
  <li>This post is NOT to denigrate India. It is definitely critical of some of its social and psychological aspects. As a proof for that I want to mention that I am writing a series on the wisdom of ancient Indian philosophical ideas here: <a href="https://pulkitsharma07.github.io/2020/06/25/source-0/">Source [0]</a>, just so you know that I am not writing all my posts with the sole intention to show what is ‚Äúwrong‚Äù with India. We should be brave enough to face the good and bad of it.</li>
  <li>It is a shame that I need to write this header in the first place. But the reality is with or without this, people will still get offended.</li>
</ul>

<hr>

<h2 id="index">Index</h2>

<ul>
<li><a href="#what">What</a></li>

<li><a href="#how">How</a></li>

<li><a href="#why">Why</a>
<ul>
  <li><a href="#the-signalling-problem">The Signalling Problem</a></li>
  <li><a href="#the-jugaad-mentality">The Jugaad Mentality</a></li>
  <li><a href="#computer-science-education-in-india">Computer Science Education in India</a></li>
  <li><a href="#but-why-for-hacktoberfest">But why for Hacktoberfest?</a></li>
  <li><a href="#the-problem-with-high-population-density">The problem with high population density</a></li>
  <li><a href="#hierarchy-of-needs">Hierarchy of Needs</a></li>
</ul></li>
<li><a href="#closing-thoughts">Closing Thoughts</a>
<ul>
  <li><a href="#probable-future">Probable Future</a></li>
  <li><a href="#improbable-future">Improbable Future</a></li>
</ul>
</li>
</ul>
<hr>

<h2 id="what">What</h2>

<p>As most of you may know, <a href="https://hacktoberfest.digitalocean.com/">Hacktoberfest</a> started on 1st October 2020. And as it with most things in human life, people came with <a href="https://mobile.twitter.com/shitoberfest">different</a> ways to hack hacktoberfest to get the free t-shirt.</p>

<p>Now apart from the sheer number of spam PRs which were opened, copious amount of time is being spent by the comparatively small number of open source maintainers who have comment, close and label each individual PR.</p>

<p>I became aware of this happening from this <a href="https://news.ycombinator.com/item?id=24643894">post</a>, and in a days time several more <a href="https://joel.net/how-one-guy-ruined-hacktoberfest2020-drama">posts</a> popped up. 
I got motivated (triggered?) to write this post when I saw the following on HN:</p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/hn_comment.png" alt="hn-comment"></p>

<p>After some investigation, I found the original claim to be true, <code>more than 60% of the spam PRs are coming from one country: India</code> and that is just 1 day after hacktoberfest started, I am sure the percentage will increase as days go by (unless DigitalOcean does something).</p>
<hr>

<h2 id="how">How</h2>

<p><a href="https://joel.net/how-one-guy-ruined-hacktoberfest2020-drama">This</a> post talks about one Indian YouTube channel which apparently told people to open spammy PRs. After I looked around some people were claiming he was falsely accused, anyways the video is deleted now, so I can‚Äôt comment on that.</p>

<p>Anyways, it didn‚Äôt take long and I was able to find few more Indian YouTubers who were pretty directly promoting ways to open PRs to get those sweet T-Shirts. One created his own <a href="https://github.com/seeditsolution/cprogram/pulls">repo</a> and encouraged people to google different programs and copy-paste them into a new PR against the empty repo.</p>

<p>I do not want to focus on the <em>How</em>, you will find find plenty videos/blogs on it, I am sure some Indian YouTuber has started working on creating a video on it.</p>
<hr>

<h2 id="why">Why</h2>
<p>One of the simplest explanation is that, DigitalOcean should have been very well anticipated that this is going to happen, after all they must have all the stats from the previous HacktoberFests.</p>

<p>We need to understand that Hacktoberfest is an marketing event. And all these spam and blogs posts around it is definitely serving their main purpose, there is no such thing as bad publicity indeed. Of course I could be totally wrong, all of this could be completely unintentional.</p>

<hr>

<p>Now, coming to the Indian side of the ongoing issue. Out of all the countries why does India have the most spammy PRs ? As a seasoned armchair philosopher, the following are my thoughts on the ‚ÄúWhy‚Äù of all this.</p>
<hr>

<h3 id="the-signalling-problem">The Signalling Problem</h3>
<p>Whenever an online article/documentary/report claim to give a view into the ‚Äúreal‚Äù India, most of us (Indians) get offended.</p>

<p>I <em>was</em> in the bubble which was in the ‚Äúoffended‚Äù bucket for long time. The reason was simple: I, the people around me and the societal structures around me were all part of the same bubble. We do not have to worry about paying school fees or rent, we do not have worry about sending part of salary back home just so that our parents can buy groceries to survive..</p>

<p>I can go on and on, the overall gist is that I got offended in seeing what other people claim as ‚Äúreal‚Äù India, because that India was not part of my reality. Sure, I saw that when travelling from one place to another, saw that on news, read about that in the newspaper; but I was at a very safe distance from all of that.</p>

<p>These days, I try to not get offended when people say India has problem X or problem Y, because I realise I am living inside a cocoon where all of my needs are met, and one of the most serious issues my country is facing right now is <strike>witch-hunting </strike> nabbing the ‚Äúdrug mafia‚Äù amongst the Bollywood celebrities who allegedly murdered an actor by giving CBD oil (The absurdity of all this is unfathomable)</p>

<p>I mention all of this, because whenever I read posts which show India in some <a href="https://news.ycombinator.com/item?id=24552047">bad light</a>, there is always someone somewhere who gives anecdotes of how that is not true.</p>

<p>Here are some facts: we have a culture of <strong>extreme signalling</strong>. Signalling is the core building block of our society, most people don‚Äôt even realise that how big we are into signalling until they study about ‚Äúsignalling‚Äù as a phenomena and start becoming conscious of it. You notice that in the way your parents view you, how you make choices, how people around you make choices.</p>

<p>Of course, people will say ‚Äúthat is not an Indian problem, signalling is just a social construct and literally everyone does that on some level‚Äù. I am not denying not that, the very fact that I am writing this post is a kind of signalling I am doing.</p>

<p>It is well known fact that India is one of the densest countries on our <a href="https://ourworldindata.org/grapher/population-density?time=2017">planet</a>, extreme siginalling is just one of the consequences of the myriad social problems created by high population density. Signalling in an high density environment is now ever more important as the people you interact or the people who notice your activities/accomplishments are multiples higher than in any other place on the planet.</p>

<p>We people like the wear the ‚Äútightly knit society‚Äù as badge of honour, let me tell you this ‚Äútightly knit society‚Äù has done more harm than good. We Indian people have no India of the amount of mental harassment we all go through, because that is just normalized as being just phases of ‚Äúlife‚Äù.</p>

<p>The prevalence of extreme signalling brews the classic and infamous <em>herd mentality</em> in our minds. In middle school children have dreams to become a Pilot in the airforce, or maybe a Police officer, or maybe a Opera Singer ! But by the time of high school, everyone is just either on road to become an Engineer, a Doctor, a Lawyer, a Chartered Accountant ‚Ä¶. or a <strong>failure</strong>. This may seem harsh but that‚Äôs how most of the society operates here in India.</p>

<p>Now once your track is chosen for you (or fortunately, if you get to choose the track), you have some set goals you ‚Äúmust‚Äù achieve because they guarantee monetary success with an extremely high probability. If you are Engineer, you need to get into IIT. If you are a Doctor, you need to get into AIIMS. If you are doing management, you need to get into IIM.</p>

<p>Now, if you are an Engineer then your success criteria is not just any IIT, it should be one of the top ones (Bombay, Delhi, Kharagpur, Roorkee) and not just any branch in IIT, it should be <em>Computer Science</em>. Because that‚Äôs how you get <a href="https://www.newindianexpress.com/nation/2019/dec/04/five-iitians-bag-pay-packages-of-over-rs-15-crore-2071120.html">Rs 1.5 crore ‚Äúpackages‚Äù (equivalent to 200K USD)</a>.</p>

<p>You can give me examples of how not all IIT toppers choose ‚ÄúComputer Science‚Äù, but that‚Äôs not the point, for the vast majority of people (more than a million), the success criteria is: getting Computer Science at IIT Bombay.</p>

<p>As might know (or have guessed) getting a seat in IIT Bombay is next to impossible for more than 99% people giving IIT, so they ‚Äúlower‚Äù their goal by aiming for other IITs, but ‚ÄúComputer Science‚Äù remains the top priority.</p>

<h3 id="the-jugaad-mentality">The Jugaad mentality</h3>
<p>Hacking systems is so ingrained in our society that we have a word for it: <a href="https://en.wikipedia.org/wiki/Jugaad">Jugaad</a>. The whole scene with Hacktoberfest is just a demo of our Jugaad skills. Wait till you find out that <a href="https://indianexpress.com/article/india/inside-indias-fake-research-paper-shops-pay-publish-profit-5265402">most of the research papers</a> published in India are <a href="https://scroll.in/article/908230/indian-academics-lead-the-world-in-publishing-in-fake-journals-tarring-the-whole-education-sector">fake</a>. Even the orthodontist I was visiting for my checkup turned out to be fake and had forged her certificates (as told by by one other dentist).</p>

<p>The coaching industry actively promotes ‚Äúcracking‚Äù these exams, and I am so tired writing on that topic that I do not want to write more about it here. Refer to my post on this <a href="https://www.linkedin.com/pulse/coding-interviewing-coaching-industry-prologue-pulkit-sharma?articleId=6662006663559684097">here</a>. Some children start joining these coaching classes from as low as 5th grade! (apart from doing regular school), just to be able to ‚Äúcrack‚Äù the IITs after 7-8 years !</p>

<p>Now how is coaching industry a Jugaad ? Simply because from the point of view of IITs, attending regular school should be enough to prep you for the exams (I think). These coaching industries have made the process significantly harder as you can‚Äôt even hope of getting a low tier IIT without attending the coaching classes.</p>

<p>The IIT coaching industry is minting fat cheques out of this entire situation, look at these ads on the front page of the news paper. These ads create a vicious cycle by reinforcing the core ‚Äúsignalling‚Äù construct of our society.</p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_1.png" alt="hn-comment"></p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_2.png" alt="hn-comment"></p>

<p><img src="https://pulkitsharma07.github.io/assets/hacktober/paper_3.png" alt="hn-comment"></p>

<p>Do not quote me on this, but I think the IIT coaching industries make more <a href="https://www.businessinsider.in/education/news/iits-iisc-say-that-patchy-funding-is-delaying-institute-of-eminence-plans/articleshow/72103538.cms">money than the IITs</a> themselves. I understand the purpose of IITs is not to directly generate money, but if it would have more resources they can probably improve the infrastructure, employ better professors and improve the overall level of education.</p>

<h3 id="computer-science-education-in-india">Computer Science Education in India</h3>
<p>For vast majority of engineers in India, Computer Science is  one of the subjects you study in order to succeed in life. Just like you study Chemistry, you ‚Äústudy‚Äù Computer Science and once you learn all the ‚Äúconcepts‚Äù, you get a good job. (Apologies for so many quoted words, I can‚Äôt help putting them in quotes because they carry so much weight for me).</p>

<p>When people are in an average Indian college and if they are are lucky, information about some permutation/combination of the following is spread amongst the ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/">https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/</a></em></p>]]>
            </description>
            <link>https://pulkitsharma07.github.io/2020/10/02/hacktoberfest-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24667488</guid>
            <pubDate>Fri, 02 Oct 2020 22:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is the best dumb TV?]]>
            </title>
            <description>
<![CDATA[
Score 612 | Comments 609 (<a href="https://news.ycombinator.com/item?id=24666968">thread link</a>) | @evo_9
<br/>
October 2, 2020 | https://pointerclicker.com/best-dumb-tv/ | <a href="https://web.archive.org/web/*/https://pointerclicker.com/best-dumb-tv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>There are a few things you need to consider when you‚Äôre looking to buy a good dumb TV. Let‚Äôs take a closer look at each of them.</p><h3>Screen size</h3><p>The biggest challenge you will face when you‚Äôre looking for a good dumb TV is getting a good screen size. You will soon realize that there are not a lot of dumb TVs that come in the latest size standards for home entertainment.</p><p>A lot of dumb TVs only have 30-40-inch screens. If this size works for you, then you are in luck. However, in today‚Äôs standards, 30-40 inches is not enough screen real estate.</p><p>You may want to find something with at least a 50-inch screen. The good news is that they do exist and, according to our research, you can even go up to 65 inches.</p><p><strong>If you‚Äôre in hurry, here‚Äôs our recommendations</strong></p><table><thead><tr><th>Image</th><th>Product</th><th>Features</th><th>Price</th></tr></thead><tbody><tr id="product-723"><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer"><img src="https://m.media-amazon.com/images/I/419R0211LBL.jpg" data-src="https://m.media-amazon.com/images/I/419R0211LBL.jpg" alt="Sceptre 65 Inches 4K UHD LED TV"></a></td><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer">Sceptre 65 Inches 4K UHD LED TV</a></td><td><div><ul><li>Bright LED display and sharp contrast</li><li>65-inch 4K UHD, HDR and MEMC120</li><li>HDMI ports, component ports, optical and line audio outputs</li></ul></div></td><td><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer" data-style="">Check Price On Amazon</a></td></tr><tr id="product-724"><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer"><img src="https://m.media-amazon.com/images/I/51S-2IYjHFL.jpg" data-src="https://m.media-amazon.com/images/I/51S-2IYjHFL.jpg" alt="Sceptre 50"></a></td><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer">Sceptre 50‚Ä≥ 4K UHD Ultra Slim LED TV</a></td><td><div><ul><li>50-inch screen that supports 4K UHD</li><li>Mobile High-Definition Link (MHL) to stream videos from a smartphone</li><li>Stunning colors and image contrast</li></ul></div></td><td><a href="https://www.amazon.com/dp/B07PW4M13Y?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" target="_blank" rel="nofollow noopener noreferrer" data-style="">Check Price On Amazon</a></td></tr></tbody></table><h3>Input ports</h3><p>Another thing that turns a regular dumb TV into a good dumb TV is the number of input ports it has. Since your dumb TV relies on external devices for display content, you will want several ports to ensure that you can plug in all your devices.</p><p>Having several input ports will allow you to switch between devices without having to physically unplug and plug them. Reaching behind your TV to do this can be very inconvenient.</p><p>HDMI ports are what most external devices today use. You will want at least 3 HDMI ports on your dumb TV. Having more HDMI ports will be better, especially if you‚Äôre thinking about getting a few more external devices.</p><h3>Monitors</h3><p>When looking for a good dumb TV, people often make the mistake of looking in the monitor category. A monitor may work for you, but there are a couple of reasons why they may not work as well as a TV.</p><p><a href="https://pointerclicker.com/how-to-clean-a-matte-monitor/" target="_blank" rel="noopener noreferrer">Monitor displays</a> are relatively darker than TV displays. This is because monitors are designed for people who sit up close.</p><p>It may not be a problem when you‚Äôre watching a movie in a dark room. If you watch with the windows open during the day, however, your monitor won‚Äôt be able to produce enough brightness to give you pleasant viewing experience.</p><p>Monitors also do not come with a TV tuner. This will be a problem if you‚Äôre thinking about watching local channels.</p><h2><span id="Does_a_great_dumb_TV_exist_in_2020">Does a great dumb TV exist in 2020?</span></h2><p>The short answer is yes. Although smart TVs are more popular, there are still a few great dumb TVs being manufactured.</p><p>You can visit your local electronic shop or search for one online. Below are some of our dumb TV recommendations.</p><h2><span id="Editors_recommendations">Editor‚Äôs recommendations</span></h2><p>We‚Äôve put together a shortlist of our top dumb TV picks. Take a moment to review each one so you can make a better decision when you plan to make a purchase.</p><h3>1. Sceptre 50‚Äù 4K UHD (U518CV-UM)</h3> <p>Sceptre sells quite a number of dumb TVs as well as smart TVs. This particular one has a large 50-inch screen that supports 4K UHD.</p><p>It also comes with Mobile High-Definition Link (MHL) that allows you to stream videos from your smartphone. Sceptre also boasts about its stunning colors and image contrast.</p><h3 id="title"><span id="productTitle">2. Sceptre 65 inches 4K LED TV (U658CV-UMC)</span></h3><div><div data-aawp-product-id="B0198XNF6U" data-aawp-product-title="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC 2018" data-aawp-click-tracking="true"> <p><span>Sale</span></p><p><a href="https://www.amazon.com/dp/B0198XNF6U?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC, 2018" rel="nofollow noopener" target="_blank"> <img src="https://m.media-amazon.com/images/I/41Q8eA+4zwL.jpg" data-src="https://m.media-amazon.com/images/I/41Q8eA+4zwL.jpg" alt="Sceptre 65 Inche 4K UHD LED TV 3840x2160 MEMC 120 Ultra Thin HDMI 2.0 Upscaling U658CV-UMC, 2018"> </a></p></div></div><p>If you want to step it up, you can opt for the 65-inch 4K UHD TV from Sceptre. It is going to cost you more, but it also comes with additional features.</p><p>It has a bright <a href="https://pointerclicker.com/can-you-use-a-laser-pointer-on-a-tv-screen/" target="_blank" rel="noopener noreferrer">LED display</a> and a sharp contrast. Its UHD upscaling will enhance your SD or HD videos so they display excellently in 4K. It also comes with HDR and MEMC120 to give you the best viewing experience.</p><p>This particular TV also has great connectivity options. HDMI ports, component ports, optical and line audio outputs. You won‚Äôt be needing additional ports with this TV.</p><h2><span id="What_is_the_dumb_TV">What is the dumb TV?</span></h2><p>When you walk through the video section in an electronic shop, you‚Äôre going to find an array of different TVs. Most of the newer ones you will have large high definition screens. And almost all of them are going to be smart TVs.</p><p>Smart TVs have taken over the home entertainment industry by storm. To the point where it has become more difficult to find one that does not have smart features. TVs lacking smart features are also called dumb TVs.</p><p>Dumb TVs are display screens with a built-in TV tuner. They also come with different input ports where you can input video information from an HDTV antenna, Blu-ray player, etc. The most common input ports are HDMI and AV.</p><p>What makes a dumb TV ‚Äúdumb‚Äù? The difference between a dumb TV and a smart TV is that the former does not come with an operating system. It relies on external devices to convert data into video information that it can display.</p><p>All televisions that were manufactured before the invention of smart TVs are dumb TVs. Dumb TVs are still being manufactured today for various reasons, although they are less popular.</p><p>Smart TVs, on the other hand, are more like smartphones or computers. They come with an operating system and a handful of pre-installed apps. You can connect them directly to the internet and stream videos on YouTube, Netflix, and other popular platforms.</p><h2><span id="Why_do_people_need_a_dumb_TV_without_smart_features">Why do people need a dumb TV without smart features?</span></h2><p>As you learn more about what smart TVs offer, you may start to wonder why anyone would want to settle for a dumb TV. Smart TVs are more convenient, and they offer so many useful features.</p><p>While the popularity of smart TV increases, there are quite a few people who still prefer dumb TVs. There are a few reasons why you might opt to get a dumb TV. Let‚Äôs take a closer look at each of those reasons in more detail.</p><h3>Security and privacy</h3><p>When it comes to the internet, security and privacy are huge topics. There have been countless horror stories that resulted from having personal devices connected to the internet. If you‚Äôre connected, there is always going to be some sort of risk.</p><p>Smart TVs are said to be one of the most vulnerable to hacking and data theft. The FBI has even issued a warning of the risks.</p><p>One of the reasons for this is that smart TVs use automatic content recognition or ACR. ACR gathers information about what you watch and sends it back to the manufacturer. With this information, more relative ads can be shown when you‚Äôre browsing for something to watch.</p><p>Unfortunately, there are times when a third party receives the information captured by ACR. These third parties can do whatever they want with that information.</p><p>Many newer smart TVs also come with webcams and microphones. These can be used by hackers to spy on you while you‚Äôre watching your favorite show.</p><p>Many people are aware of the dangers of this. This is one of the main reasons there are still quite a few people who opt to get dumb TVs instead of TVs with smart features.</p><h3>Better set-top and stick options</h3><p>Another reason why people purchase dumb TVs is that they prefer to use other TV stick and set-top devices. These devices don‚Äôt cost a lot of money and they often work better than smart TVs.</p><p>A few of the more popular ones are the <span><a href="https://www.amazon.com/dp/B075XLWML4?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Roku Streaming Stick+" target="_blank" rel="nofollow noopener" data-aawp-product-id="B075XLWML4" data-aawp-product-title="Roku Streaming Stick+ | HD/4K/HDR Streaming Device with Long-range Wireless and Voice Remote with TV Controls  updated for 2019" data-aawp-click-tracking="true">Roku Streaming Stick+</a>&nbsp;<a href="https://www.amazon.com/dp/B075XLWML4?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Roku Streaming Stick+" target="_blank" rel="nofollow noopener" data-aawp-product-id="B075XLWML4" data-aawp-product-title="Roku Streaming Stick+ | HD/4K/HDR Streaming Device with Long-range Wireless and Voice Remote with TV Controls  updated for 2019" data-aawp-click-tracking="true"><span></span></a></span>, <span><span>No products found.</span></span>, <span><a href="https://www.amazon.com/dp/B0791TX5P5?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Amazon Fire TV Stick" target="_blank" rel="nofollow noopener" data-aawp-product-id="B0791TX5P5" data-aawp-product-title="Fire TV Stick streaming media player with Alexa built in includes Alexa Voice Remote HD easy set-up released 2019" data-aawp-click-tracking="true">Amazon Fire TV Stick</a>&nbsp;<a href="https://www.amazon.com/dp/B0791TX5P5?tag=pointerclicke-20&amp;linkCode=ogi&amp;th=1&amp;psc=1" title="Amazon Fire TV Stick" target="_blank" rel="nofollow noopener" data-aawp-product-id="B0791TX5P5" data-aawp-product-title="Fire TV Stick streaming media player with Alexa built in includes Alexa Voice Remote HD easy set-up released 2019" data-aawp-click-tracking="true"><span></span></a></span>, and <span><span>No products found.</span></span>. There are many more options in the market to choose from.</p><p>These devices connect to your WI-FI and allow you to stream content on popular platforms such as Netflix and YouTube.</p><p>All these devices have seamless UI‚Äôs and tons of different apps and features. They also come with <a href="https://pointerclicker.com/presentation-pointers-lcd-tv-screens/" target="_blank" rel="noopener noreferrer">remote controls</a> that support voice commands.</p><p>One feature many people find very useful in these devices is the casting feature. It allows you to use your TV as a larger display for your smartphone. You can play videos, view images, and browse the web on your smartphone and have it cast onto your TV.</p><p>You should also remember that technology is advancing a lot quicker than ever before. Your brand-new smart TV will be outdated in just a couple of years. The only way you‚Äôre going to be able to keep up with new features and security fixes is to buy a new TV.</p><p>You won‚Äôt need to replace your dumb TV to stay updated. All you need to do is purchase the latest stick or set-top device. You can get brand-new ones that already come with voice control for an affordable price.</p><p>Check out this video to learn more about stick and set-top devices.</p><div title="4K Streaming Device Round Up 2019: Apple TV vs Chromecast vs Roku vs Fire TV, Which is best for you?"><div id="WYL_H2Bq9X3a41A"><div id="lyte_H2Bq9X3a41A" data-src="https://pointerclicker.com/wp-content/plugins/wp-youtube-lyte/lyteCache.php?origThumbUrl=https%3A%2F%2Fi.ytimg.com%2Fvi%2FH2Bq9X3a41A%2Fhqdefault.jpg"><div><p>4K Streaming Device Round Up 2019: Apple TV vs Chromecast vs Roku vs Fire TV, Which is best for you?</p></div></div></div></div><h3>Interface issues on smart TVs</h3><p>When you use your smartphone or computer, you have two main input sources: pointing and typing. You don‚Äôt have either of those in a smart TV interface.</p><p>For the most part, you will use your TV‚Äôs remote to click through menus and an onscreen keyboard for typing. It will take you quite a number of button presses to type something into your TV‚Äôs search service.</p><p>Some smart TVs also come with poorly designed interfaces. It will take a lot of time trying to navigate around the interface.</p><p>On the other hand, the interfaces that come with newer sticks and set-box devices are more seamless. They also include voice commands and many support keyboard input from your smartphone.</p><h3>Unreliable apps on smart TVs</h3><p>App developers today need to work harder when it comes to compatibility. They need to make sure apps work well with smartphones, browsers, stick and set-top devices, smart TVs and more. Unfortunately, smart TVs are often the last priority.</p><p>This leaves smart TVs with unreliable apps that may crash or freeze. Older smart TVs may also not be compatible with app updates.</p><h2><span id="Conclusion">Conclusion</span></h2><p>Although smart TVs are the most popular choice, there are still a few reasons why you might opt to get a dumb TV. The good news is that there are still quite a few of them being manufactured.</p><p>It may be more challenging to find a good dumb TV, but there‚Äôs a good chance a few of them are being sold at your nearest electronics shop. If you want more options, finding them online will be your best bet.</p><p>You can check out online shops such as Amazon, BestBuy, Walmart, and Costco. You may also visit manufacturer websites and look through their ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pointerclicker.com/best-dumb-tv/">https://pointerclicker.com/best-dumb-tv/</a></em></p>]]>
            </description>
            <link>https://pointerclicker.com/best-dumb-tv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666968</guid>
            <pubDate>Fri, 02 Oct 2020 20:59:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Startup Hiring 101: A Founder's Guide]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24666580">thread link</a>) | @ivankirigin
<br/>
October 2, 2020 | https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f | <a href="https://web.archive.org/web/*/https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Startup-Hiring-101-A-Founder-s-Guide-946dad6dd9fd433abdd12338a83e931f</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666580</guid>
            <pubDate>Fri, 02 Oct 2020 20:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‚ÄúFungi Can Teach Us a New Way of Looking at the World‚Äù]]>
            </title>
            <description>
<![CDATA[
Score 163 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24666521">thread link</a>) | @jseliger
<br/>
October 2, 2020 | https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;14a48b6b-06ab-4edb-83c8-8a827e78971b&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;598038d5-6ba5-4df5-9e90-2a7d4b422b0b&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w948_r1.77_fpx39.41_fpy49.97.jpg" srcset="https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w520_r1.77_fpx39.41_fpy49.97.jpg 520w, https://cdn.prod.www.spiegel.de/images/14a48b6b-06ab-4edb-83c8-8a827e78971b_w948_r1.77_fpx39.41_fpy49.97.jpg 948w" width="948" height="536" sizes="948px" title="Merlin Sheldrake: &quot;When food becomes scarce, they some fungi can switch to a hunting mode.&quot;" alt="Merlin Sheldrake: &quot;When food becomes scarce, they some fungi can switch to a hunting mode.&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Merlin Sheldrake:</strong> "When food becomes scarce, they some fungi can switch to a hunting mode."</p>
<span>
Foto:‚ÄÇAndrea Artz / DER SPIEGEL
</span>
</figcaption>
</figure>
</div><div>
<p><em>Merlin Sheldrake, 32, earned his Ph.D. in tropical ecology at the University of Cambridge for his research into underground fungal networks in the tropical forests of Panama. Since then, he has not lost his fascination for them. He is the author of "Entangled Life: How Fungi Make Our Worlds, Change Our Minds and Shape Our Futures," which was published in early September.</em></p>


<div>
<p><strong>DER SPIEGEL:</strong> Dr. Sheldrake, we are here in London's Hampstead Heath. This place, you write in your book, means more to you than any other. Why is that?</p><p><strong>Sheldrake:</strong>&nbsp;I grew up here. This is where I learned to walk. Later, I climbed trees here, and still later, I had parties with friends. And my interest in nature has been incubated by this place.</p><p><strong>DER SPIEGEL:&nbsp;</strong>Your interest in nature in general, or fungi in particular?</p><p><strong>Sheldrake:&nbsp;</strong>Both. I've always been particularly interested in how things transform, how they grow and decompose. I was amazed how piles of leaves disappear over time. How did this transformation come about without me being able to see anything? Composting, I understood, is largely the work of fungi.</p>
</div>

<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>For most people, nature is primarily made up of plants and animals. What role do fungi play in between those two realms?</p><p><strong>Sheldrake:&nbsp;</strong>Fungi are of enormous importance. The basic principle of ecology is the relationships between organisms - and fungi form connections between organisms and so embody this idea.</p><p><strong>DER SPIEGEL:&nbsp;</strong>If fungi are so important, why don‚Äôt we see them all over the place?</p><p><strong>Sheldrake:</strong>&nbsp;Oh, fungi are everywhere. Just take this leaf: Between tens and hundreds of species of fungi live on and in it. No plant has ever been found in nature which does not have fungi in its leaves and in its shoots. Or take the roots of the grass we are walking on, the rotting twigs, the soil under our feet: There are fungi everywhere. You have yeast all over your body, in the lining of your ears, in your nostrils. Even in the air: At this moment, you are breathing fungi. Fifty million tons of fungal spores are floating in the atmosphere, the largest source of living particles in the air. And they change the weather by causing water droplets to form.</p>
</div>


<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>If fungi are so ubiquitous, why we know so little about them?</p><p><strong>Sheldrake:</strong>&nbsp;There are many reasons. The most obvious one is access. The fungus we see is nothing more than the fruit of the organism itself. The mycelium network that belongs to it is buried in the ground. It is as if we only saw acorns for one moment every year, but we couldn't see the magnificent oak trees.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Do even scientists underestimate the importance of fungi?</p><p><strong>Sheldrake:</strong>&nbsp;They did so for a long time, at least. Until the 1960s, fungi were thought to be plants. Only then did they gain taxonomical independence. The new sequencing techniques have changed that. Today, we can read the DNA in every teaspoon of soil and find out who is there.</p>
</div>


<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 39/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;a5e2c38b-b6b9-42a2-95bc-b12aa8ae27df&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>And? What does one find?</p><p><strong>Sheldrake:</strong>&nbsp;The kingdom of fungi is vast. There are six times more species of fungi than of plants, and only 6 to 8 percent of them have even been described. We still know so little! ! Just one thing is clear: There are many ways to be a fungus.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is perhaps the lack of appreciation for fungi because of the fact that they are not very nutritious and often even poisonous?</p><p><strong>Sheldrake:</strong>&nbsp;Many people think like that. But in fact, many mushrooms contain important minerals and they have a high content of antioxidants. They produce an amazing variety of substances that affect cancer, viruses or our immune system. And mushrooms are high in protein. Truffles are a good example of an edible fungus. After all, they want to be eaten. Truffles sit deep in the ground where no wind can spread their spores. They attract animals with a very subtle mixture of odors, so that these animals then eat them and spread their spores.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Some mushrooms lure us with substances that have a direct effect on our consciousness ...</p><p><strong>Sheldrake:</strong>&nbsp;Yes, about 200 fungal species contain psilocybin, a substance that people have been interested in because of its strong psychedelic effects.</p>
</div>

<div>
<p><strong>DER SPIEGEL:</strong>&nbsp;Such mushrooms cause hallucination and change the way we think. How do mushrooms benefit from making psychedelic drugs for humans?</p><p><strong>Sheldrake:</strong>&nbsp;We don‚Äôt know. The first mushrooms to make psilocybin lived 75 million years ago, long before humans arose. But the receptors that this substance binds to can also be found in many animals. Does psilocybin change the behavior of certain insects in a way that induces them to spread fungal spores? Or do they change the behavior of insects in a way that deters them from eating the mushrooms?</p><p><strong>DER SPIEGEL:</strong>&nbsp;Have you personally tried the effects of psychedelic mushrooms?</p><p><strong>Sheldrake:</strong>&nbsp;Yes, under their influence I realized that most of my consciousness was unknown to me. It was as if I had spent my life in a garden until then, and now I suddenly discovered that this garden has a gate through which I can enter a strange and wonderful forest, that was largely unknown to me.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Does the gate disappear once the effects of psilocybin fade away?</p><p><strong>Sheldrake:</strong>&nbsp;Not necessarily. Once you know that this forest exists, it is much easier to find your way into it.</p><p><strong>DER SPIEGEL:</strong>&nbsp;You even took part in a scientific study.</p><p><strong>Sheldrake:</strong>&nbsp;Yes, though it was LSD tested in that study. But both substances have similar effects. Among other things, it was to be examined whether LSD promotes creativity. Each participant had to name a problem they were currently working on and, under the influence of LSD, &nbsp;we were to try to solve that problem.</p><p><strong>DER SPIEGEL:</strong>&nbsp;And?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp; I found the effects of LSD very helpful in allowing me to approach questions from new angles and imagine the relationships between plant and fungus from different points of view.</p><p><strong>DER SPIEGEL:</strong>&nbsp;You attribute cognitive abilities to fungi. What makes you think so?</p><p><strong>Sheldrake:</strong>&nbsp;I've been thinking about this for a while. I'm interested in the way fungi perceive their environment and how they react to it. Information is continuously flowing through their decentralized bodies.</p><p><strong>DER SPIEGEL:</strong>&nbsp;What do fungi perceive?</p><p><strong>Sheldrake:</strong>&nbsp;Most importantly, they have extremely diverse chemical sensors. A fungus can be seen as a large, chemically sensitive membrane, so to speak, as one big olfactory epithelium. But many mushrooms can also perceive light and they are sensitive to gravity, to changes in temperature and to changes in pressure.</p><p><strong>DER SPIEGEL:</strong>&nbsp;So the fungi under our feet can sense that we are here?</p><p><strong>Sheldrake:</strong> Some fungi would detect the pressure of our steps, yes. And now the question is, how do they process all this information without a brain and how do they translate it into behavior, into action?</p><p><strong>DER SPIEGEL:</strong>&nbsp;Action? Behavior? What do fungi do?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp;Fungi are quite active. Take hunting, for example.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Excuse me? Mushrooms can hunt?</p><p><strong>Sheldrake:</strong>&nbsp;Yes. When food becomes scarce, some fungi can switch to a hunting mode. They build traps consisting of sticky loops or poisonous droplets. And with special substances, they lure nematodes into these traps.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is this really "behavior" of the kind we see in animals?</p><p><strong>Sheldrake:</strong>&nbsp;Well, we can run away from danger, fungi have to face it. Therefore, they defend themselves with the help of chemicals, or they regenerate. But that doesn't change the fact that fungi do make decisions, just as we do.</p><p><strong>DER SPIEGEL:</strong>&nbsp;What kind of decisions?</p><p><strong>Sheldrake:</strong>&nbsp;Fungi have many options: where to grow, what to eat, what nutrients to transport, whether to withdraw and when to hunt nematodes. Each fungus forms thousands of so-called hyphae - tiny tubes that can either grow, divide or fuse.</p><p><strong>DER SPIEGEL:</strong>&nbsp;If fungi make decisions, are they also capable of solving problems?</p>
</div>

<div>
<p><strong>Sheldrake:</strong>&nbsp;Absolutely. For example, their growth follows very efficient navigation algorithms. There are various experiments in which fungi very rapidly found the shortest route through a maze.</p><p><strong>DER SPIEGEL:</strong>&nbsp;If fungi are, as you claim, complex information processing networks, are they essentially a kind of brain?</p><p><strong>Sheldrake:</strong>&nbsp;No, I wouldn‚Äôt say that. But you are right: Neurons are tip-growing, electrically excitable, network-forming cells. And so are fungal cells.</p><p><strong>DER SPIEGEL:</strong>&nbsp;So mushrooms have a form of intelligence?</p><p><strong>Sheldrake:</strong>&nbsp;It depends on your definition of "intelligence." In a broad sense, all organisms show intelligence, albeit to different degrees. The study of cognition and intelligence arose from the study of the human mind. This resulted in a very human- and brain-centered view. I find it refreshing to extend these considerations to organisms that do not have brains. We shouldn't use ourselves as the yardstick to judge everything else in this world.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Is there still a lot to discover in the field of fungi cognition?</p><p><strong>Sheldrake:&nbsp;</strong>Absolutely. Little is known about how fungi coordinate their behavior. We don't know the mechanisms by which they pass signals around. We've not fully understood the basic biology of mycelial growth.</p>
</div>

<div>
<p><strong>DER SPIEGEL:&nbsp;</strong>But we do know a lot about the symbiotic relationship between mushrooms and plants ‚Ä¶</p><p><strong>Sheldrake:&nbsp;</strong>‚Ä¶ exactly, via the mycorrhiza, through which the fungus supplies the plant with minerals such as nitrogen and phosphorus, and the plant in turn provides the fungus with energy-rich sugars.</p><p><strong>DER SPIEGEL:</strong>&nbsp;How important is this symbiosis? If all fungi were wiped out in this forest floor, could the trees survive?</p><p><strong>Sheldrake:</strong>&nbsp;No. They would be prone to disease, just as we would be if it weren't for the bacteria in our intestines. This microbiome keeps us healthy. In this sense, soil is sort of the gut of our planet.</p><p><strong>DER SPIEGEL:</strong>&nbsp;Many ecologists are enthusiastic about the "Wood Wide Web," by which trees are mysteriously connected via the fungi in the soil and allegedly even communicate via this ‚Ä¶</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f">https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/zeitgeist/mushroom-expert-merlin-sheldrake-fungi-can-teach-us-a-new-way-of-looking-at-the-world-a-a3dd9530-dc15-4aa9-bb03-b23e1adc7e2f</link>
            <guid isPermaLink="false">hacker-news-small-sites-24666521</guid>
            <pubDate>Fri, 02 Oct 2020 20:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data from 70 Offer Negotiations Using a Career Agent]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24665710">thread link</a>) | @brianliou91
<br/>
October 2, 2020 | https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary | <a href="https://web.archive.org/web/*/https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p>Consider two graduating PhDs who are transitioning into industry. Both are incredibly busy finishing their research, writing their dissertation, and teaching. Both spend the same amount of time recruiting for industry roles - and both join the same company in a similar role. PhD #1, let‚Äôs call her Jane,  soon discovers she is being paid less than her peers for the same work and has a boss that won‚Äôt promote her. She‚Äôs forced to work doubly hard just to achieve parity with her co-workers, or else leave and start over somewhere new, wasting a year. PhD #2, let‚Äôs call her Joanne, in contrast, is happy with her job. She is paid similarly to her peers and has a clear path for growth at the company. What did Joanne do better?</p><p>We have now advised 71 PhDs to follow this second, better track and we understand what defines these trajectories. We hope this salary negotiation report educates similar individuals how to negotiate salary. The difference between these two individuals is not merit, nor is it about who interviewed better or does better work. The difference is in how they think and negotiate. Joanne understands that she is joining a business. Compensation and promotions are respectfully taken by her self-advocacy, not given by the company. Jane assumes that the company will take care of her once she proves herself and so does not ask for much at the beginning. Joanne sets expectations and gives feedback to her manager for a productive working relationship. This is a <em>virtuous</em> cycle: you ask and your manager sets the higher expectations that enable you to work upwards. Jane is reticent and does not want to damage relationships. This is a <em>vicious</em> cycle: you don‚Äôt ask and your manager doesn‚Äôt expect more, so you stagnate and it becomes even harder to advance. </p><p>This power of setting expectations is evident at the very beginning of your relationship with your employer, in the offer negotiation. You haven‚Äôt started work yet, but simply setting higher expectations from the outset enables you to get paid more and begins the positive, virtuous cycle. Here we quantify the impact of negotiating using Ralph by looking at the data from our first 71 PhD clients. Most of them came from computation-heavy PhDs and were transitioning into their first industry role in engineering or data science, or a research role in technology or quantitative finance. Our results reveal just how beneficial it can be to advocate for yourself, and how beneficial a Career Agent can be to advise you through this process of multiple offers and changes. Because while most people know they <em>should</em> negotiate, they don‚Äôt know how <em>far</em> to negotiate. Our data gives you insight into just how much you‚Äôre worth and how much room there is for offer changes. </p><p><img src="https://landen.imgix.net/blog_VkwwMuKsXVDkwaYZ/assets/KnTGkpeVnsGRSckK.jpg" alt="Tables.jpg"></p><p><img src="https://landen.imgix.net/blog_VkwwMuKsXVDkwaYZ/assets/uOGQqqzabfskEZzm.jpg" alt="Visualizations.jpg"></p><p><strong>High Level Results</strong></p><p>On average, our clients have increased their initial offer by 30% through negotiation using our insight and advising. This increase is calculated from changes in base salary, equity, and any annual, signing, or relocation bonus changes. This increase represents an average $75K more in the offer. As expected, having offers from multiple companies resulted in a larger increase from the baseline offer; however, even if clients only had an offer from a single company, they were still able to secure an average 20% increase from their initial offer. Having four offers resulted in a dramatic increase (56%) in the negotiated accepted offer.&nbsp;</p><p><strong>Negotiating You Are Likely Not Doing</strong></p><p>The majority of our clients (52%) changed their offer twice. This means they negotiated an increase once and then negotiated <strong>another</strong> increase. Usually this second change would occur after the company said no to any further changes. We were able to advise our clients to keep advocating for themselves and set initial expectations high, resulting in an average total increase of 39%.  When the offer changed once, it increased on average 18%. While the majority of this data comes from before COVID-19, we have advised 9 clients during COVID-19 with similar results. Our largest negotiated offer ever was achieved in March 2020 (<a href="https://www.withralph.com/blog/negotiated-a-143-offer-increase">the story here</a>). Our data from working with 70+ clients is clear: you can negotiate significant (and often multiple) increases in your offer if you know your true, competitive worth.&nbsp;</p><p>These results we hope debunk three common misconceptions that hinder a candidates' ability to negotiate a strong starting offer and set the stage for your upward growth.&nbsp;</p><p><strong>Misconception #1: Companies pay equally for the same role, level, and location in a new grad offer.</strong></p><p>We have seen two candidates with the same role, level, company, and location have a $35,000 base salary difference. We have seen equity range by more than $900,000 in a 4-year package in public company offers. We have data for new grad Google offers that start as low as ~$180K/year and end as high as ~$550K/year.</p><p>Even independent of a company's intent, if you don't negotiate you will be paid unequally because the highest paid individuals are always negotiating. The squeaky wheel gets the oil. </p><p><strong>Misconception #2: Interviewing with one company at a time is ok.</strong></p><p>The factor that affects your compensation the most is having multiple offers at the same time. Companies are a business. They will pay what they have to, not what they can. Our data shows having two offers increases your compensation by 5% and 4 offers increases your compensation by 56%.&nbsp;Companies interview candidates they have no intention of hiring just to see the market. So should you.</p><p><strong>Misconception #3: The company increased my offer so I‚Äôve successfully negotiated.</strong></p><p>The majority of companies start with a low offer that leaves room for the candidate to negotiate. You should define successfully negotiating as getting a change <strong>after</strong> the company has said no. This is when the negotiation has actually begun. Otherwise, you have just asked and they conceded. There has been no negotiation. Our data shows that it is rare for an offer <strong>not</strong> to change after it is initially given: 90% of offers change from the initial offer after negotiating.</p><p>Almost all of the negotiation challenges PhDs face come from a lack of information and experience in industry. They don‚Äôt know what to expect, don‚Äôt have time to research, and assume whatever the company says is correct. As our data shows, there is room for negotiating multiple times to achieve a 30% or greater increase in your initial offer. We hope that by sharing our findings, we can help you educate and advocate for yourself and feel more confident to set high expectations even before you begin working at your company. Ask yourself the question: <strong>how do I know I am getting the best offer possible?</strong> You might be surprised to know that you are likely worth a lot more than the initial offer you receive. </p><p>--</p><p>To read more content: <a href="https://www.withralph.com/blog/where-to-start">start here</a></p><p><a href="https://www.withralph.com/blog/where-to-start"></a>To get updated with insights and learnings: <a href="https://www.linkedin.com/company/ralph-inc">Follow us on LinkedIn</a></p><p>Questions? Email hi@withralph.com</p></div></div></div></div>]]>
            </description>
            <link>https://www.withralph.com/blog/salary-negotiation-report-how-to-negotiate-salary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24665710</guid>
            <pubDate>Fri, 02 Oct 2020 18:45:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scientists develop 'super enzyme' that breaks down plastic faster than ever]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24664510">thread link</a>) | @soperj
<br/>
October 2, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A team of international scientists have developed what they call a "super enzyme" that can break down plastic into is original building blocks so it can be recycled infinitely.&nbsp;</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5746639.1601578207!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1190912666.jpg"></p></div><figcaption>Plastic waste litters the shoreline in Koattey wetlands on Dec. 14, 2019, in Hithadhoo, Maldives.<!-- --> <!-- -->(Carl Court/Getty Images)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Scientists develop 'super enzyme' that breaks down plastic faster than ever"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/91/606/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:33</span><span>Scientists develop 'super enzyme' that breaks down plastic faster than ever</span></p></div></div></div></span></p><p><span><p><a href="https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/october-1-2020-episode-transcript-1.5748666">Read Story Transcript</a></p>  <p>A team of international scientists have developed what they call a "super enzyme" that can break down plastic into its original building blocks so it can be recycled infinitely.&nbsp;</p>  <p>The team, <a href="https://www.cbc.ca/news/technology/plastic-eating-enzyme-pollution-1.4622923">which made waves in 2018 for engineering&nbsp;a plastic-eating enzyme</a>,&nbsp;has&nbsp;now combined it with a second enzyme to create&nbsp;a "<a href="https://www.eurekalert.org/pub_releases/2020-09/uop-pe092520.php">cocktail</a>" that can break down plastic six times faster.</p>  <p>"The enzymes are really specific to certain types of bonds in the molecular structure of the plastic. This means that it breaks it down into the same starting materials that were used to make the product to begin with," Erika Erickson, a bioengineering researcher at the U.S. Department of Energy's&nbsp;National Renewable Energy Laboratory (NERL), told <em>As It Happens </em>host Carol Off.&nbsp;</p>  <p>"So instead of having an inferior product in the end, you could start with the same starting materials and come back to an equal value plastic water bottle or food package, etc., on&nbsp;the other side, without needing to use petroleum products to get there."</p>  <p>The findings were <a href="https://www.eurekalert.org/pub_releases/2020-09/uop-pe092520.php">published this week in the journal Proceedings of the National Academy of Sciences.</a></p>  <h2>Nature finds a way ‚Äî and scientists speed it up&nbsp;</h2>  <p>The whole thing began when scientists at NERL and Britain's University of Portsmouth discovered a naturally occurring enzyme in a waste recycling centre in Japan that was helping bacteria break down&nbsp;polyethylene terephthalate&nbsp;(PET), a common plastic developed in the '40s that's used to make&nbsp;water bottles, food packaging, film and more.&nbsp;</p>  <p>"There are natural enzymes that have been evolved to break down plastic," Erickson said. "And if you think about that, it's quite extraordinary that an organism has been able to do this in such a short amount of time."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_300/plastic-eating-enzymes.jpeg 300w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_460/plastic-eating-enzymes.jpeg 460w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_620/plastic-eating-enzymes.jpeg 620w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/plastic-eating-enzymes.jpeg 780w,https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_1180/plastic-eating-enzymes.jpeg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5746626.1601577848!/fileImage/httpImage/image.jpeg_gen/derivatives/original_780/plastic-eating-enzymes.jpeg"></p></div><figcaption>Researchers from Britain's University of Portsmouth and the U.S. Department of Energy's National Renewable Energy Laboratory have combined two plastic-eating enzymes to create what they call a 'super enzyme.'<!-- --> <!-- -->(University of Portsmouth)</figcaption></figure></span></p>  <p>However, the natural process is a slow one. So the scientists tweaked the enzyme by adding amino acids to speed things up.</p>  <p>The resulting&nbsp;engineered enzyme, called&nbsp;PETase, could break down&nbsp;one water bottle in a couple months, Erickson estimated ‚Äî a big step up from the hundreds of years it takes to break down in nature.</p>    <p>Now the team has combined&nbsp;PETase&nbsp;with a second enzyme from the same garbage eating bacteria, called MHETase, making the process even faster. The new super enzyme, Erickson&nbsp;said, could potentially break down one bottle in as little as six weeks.&nbsp;</p>  <p>She admits that's still "a little bit too slow for a real recycling process," but says it's a major step forward to creating a commercially viable system.&nbsp;</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/erika-erickson.JPG 300w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/erika-erickson.JPG 460w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/erika-erickson.JPG 620w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/erika-erickson.JPG 780w,https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/erika-erickson.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5746648.1601578311!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/erika-erickson.JPG"></p></div><figcaption>Erika Erickson is postdoctoral researcher in bioengineering a the U.S. Department of Energy's National Renewable Energy Laboratory.<!-- --> <!-- -->(Werner Slocum/NREL)</figcaption></figure></span></p>  <p>The way plastic is recycled now is not very efficient or cost-effective, says Erickson.</p>  <p>"In&nbsp;mechanical recycling, the plastic gets ground down into small pieces and then melted and then reformed into a new product," she said.</p>  <p>"But in the process of doing that, all of the contaminated dirt or food products or other types of plastic get mixed into that. So the quality of the recycled good is usually quite low compared to the original."</p>  <p>With an enzymatic approach, however, the plastic is recycled in its entirety&nbsp;‚Äî turning a bottle, for example, back into the same material used to make the bottle, and potentially creating an infinite loop of recycling.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/996523044.jpg 300w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/996523044.jpg 460w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/996523044.jpg 620w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/996523044.jpg 780w,https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/996523044.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5489233.1601578943!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/996523044.jpg"></p></div><figcaption>Workers sort recycling material at the Waste Management Material Recovery Facility in Elkridge, Md.<!-- --> <!-- -->(Saul Loeb/AFP/Getty Images)</figcaption></figure></span></p>  <p>Another big problem with modern recycling is the amount of energy used to collect materials and deliver them to a central location for sorting.&nbsp;</p>  <p>"That won't necessarily be a problem that disappears with a new strategy for recycling," Erickson said.</p>  <p>"The difference, however, would be that the embedded use of fossil fuels for the extraction of petroleum from the Earth, you would lose a lot of that, which is also quite costly.... If we could separate some of the products that we use from that cycle, then the greenhouse gas emissions and fossil fuel utilization would be lower."</p>  <h2>Technology helps ‚Äî but people have to step up&nbsp;</h2>  <p>The team has touted the potential of this method to one day revolutionize recycling, should it be developed on a commercial scale.&nbsp;</p>  <p>But Erickson notes that technology alone won't fix the problem of plastic pollution.</p>    <p>"It's difficult to convey the ability to sort of shirk off responsibility for our daily choices toward this kind of technology in general&nbsp;‚Ä¶&nbsp;each of us&nbsp;can make a difference in our daily choices," she said.</p>  <p>"And so I hope that people both understand that [with this]&nbsp;technology, we're hoping we can we can make some big impacts and in good directions, but it still comes down to individual choices."</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Menaka Raman-Wilms and Kate Cornick.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-thursday-edition-1.5746442/scientists-develop-super-enzyme-that-breaks-down-plastic-faster-than-ever-1.5746444</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664510</guid>
            <pubDate>Fri, 02 Oct 2020 16:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Security Hardening and Other Tweaks]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24664507">thread link</a>) | @aytekat
<br/>
October 2, 2020 | https://vez.mrsk.me/linux-hardening.html#hn | <a href="https://web.archive.org/web/*/https://vez.mrsk.me/linux-hardening.html#hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<strong>Linux Security Hardening and Other Tweaks</strong>
<hr>

<p>
Last updated: 08/18/2020,
by <a href="https://twitter.com/blakkheim">@blakkheim</a>

</p><p>
This page lists the changes I make to a vanilla install of Arch Linux
for security hardening, as well as some other changes I find useful.
While Arch is my target platform, most of the changes will work on
any Linux system that's reasonably up to date.

</p><p>
I typically favor security over performance. You may also see suggestions
merely to make something more useful or shave precious seconds off
a wait time. It's not a one-size-fits-all setup, but hopefully certain
pieces of it will be useful.

</p><p>
Arch is worth considering for a few reasons:

</p><ul>
<li><strong>The install size:</strong> The base install is relatively minimal
    compared to a "prebuilt" distro like Fedora or Mint. This lets me focus
    on adding just what I want, rather than constantly trying to strip out
    things I don't need.
</li><li><strong>The kernel:</strong> A common misconception about the Linux
    kernel is that it's secure, or that one can go a long time without
    worrying about kernel security updates. Neither of these are even
    remotely true. New versions of Linux are released almost every week,
    often containing security fixes buried among the many other changes.
    These releases typically
    <a href="https://youtu.be/5PmHRSeA2c8?t=4075">don't</a> make explicit
    mention of the changes having security implications. As a result, many
    "stable" or "LTS" distributions don't know
    <a href="https://web.archive.org/web/20200623161340/https://www.openwall.com/lists/oss-security/2020/06/23/2">which commits</a> should be
    backported to their old kernels, or even that something needs backporting
    at all. If the problem has a public CVE assigned to it, maybe your distro
    will pick it up. Maybe not. Even if a CVE exists, at least in the case
    of Ubuntu and Debian especially, users are often left with kernels full
    of <a href="https://security-tracker.debian.org/tracker/source-package/linux">known holes</a>
    for months at a time. Arch doesn't play the backporting game, instead
    opting to provide the newest stable releases shortly after they come out.
</li><li><strong>The <a href="https://wiki.archlinux.org/index.php/Arch_Build_System">Arch Build System</a></strong>:
    Having enjoyed the
    <a href="https://en.wikipedia.org/wiki/Ports_collection">ports</a>
    system of <a href="https://vez.mrsk.me/freebsd-defaults.html">FreeBSD</a>
    and <a href="https://www.openbsd.org/">OpenBSD</a> for a long time, the ABS
    has been a pleasure to use. It makes building/rebuilding packages easy.
    It makes updating packages easy. It shows how things are actually built
    and with what options. This BSD-borrowed concept makes interacting with
    the package system simple and intuitive.
</li></ul>

Now on to how I set things up.

<hr>
<p>

<strong>Security Hardening</strong>
</p><ul>
  <li><a href="#disks">Disk Layout</a>
  </li><li><a href="#pacman">Pacman</a>
  </li><li><a href="#kern">Kernel Options</a>
  </li><li><a href="#fw">Firewall</a>
  </li><li><a href="#sudo">Sudo</a>
  </li><li><a href="#firejail">Application Sandboxing</a>
  </li><li><a href="#rfk">RFKill (Disable WiFi / Bluetooth)</a>
</li></ul>

<strong>Other Tweaks</strong>
<ul>
  <li><a href="#ntp">NTP (Network Time Protocol)</a>
  </li><li><a href="#mkinit">mkinitcpio</a>
  <!--
  <li><a href="#login"    >Automatic Login</a>
  -->
  </li><li><a href="#pulse">PulseAudio</a>
  </li><li><a href="#misc">Miscellaneous</a>
  </li><li><a href="#closing">Closing</a>
</li></ul>

<hr>

<h2 id="disks">Disk Layout</h2>

This section contains a few tips to consider during your initial disk layout
creation. The concepts should apply to any distrbution.

<p>
To start, consider using
<a href="https://wiki.archlinux.org/index.php/Dm-crypt/Encrypting_an_entire_system">full disk encryption</a>
along with a
<a href="https://wiki.archlinux.org/index.php/LVM">Logical Volume Manager</a>
setup. Disk encryption protects data at rest, while LVM allows for some
flexibility that can be quite useful. A simple disk layout might look like
this:

</p><ul>
<li><code>/dev/sda1</code> (a small, unencrypted
<a href="https://wiki.archlinux.org/index.php/EFI_system_partition">EFI System Partition</a>,
FAT32)
mounted at <code>/efi</code> (assuming this is
a PC with UEFI, otherwise not needed)
</li><li><code>/dev/sda2</code> (a small, unencrypted ext4 partition)
mounted at <code>/boot</code>.
</li><li><code>/dev/sda3</code> (using the rest of the drive space)
as the encrypted
<a href="https://wiki.archlinux.org/index.php/Dm-crypt">LUKS</a> container
for LVM
</li></ul>

Splitting up the logical volumes for different mount points provides some
benefits, including the ability to set mount flags on specific directories.
Consider creating separate logical volumes for <code>/</code>,
<code>/var</code>, and <code>/home</code> in the install. For a typical
desktop, you probably want to give <code>/home</code> most of the disk space.
The other two don't need much unless there's a specific use case in mind.
25GB and 8GB are used in this example. If you need to have a huge database
in <code>/var</code> or something, make adjustments accordingly.

<p>
There are a lot of user-writable directories in Linux, each one providing
an opportunity for attackers to execute their own binaries.
Once the <a href="https://wiki.archlinux.org/index.php/Fstab">fstab</a>
file is created, add the <code>noexec</code> and <code>nodev</code> flags
to <code>/var</code> and <code>/home</code>. Doing so will disallow execution
of binaries on these mount points, as well as prevent interpreting character
or block special devices on them. Two temporary filesystems (<code>/tmp</code>
and <code>/dev/shm</code>) can also be locked down with the same flags by
adding the following:

</p><pre># /etc/fstab
[...]
tmpfs /tmp     tmpfs rw,noexec,nodev,size=1G,mode=1777 0 0
tmpfs /dev/shm tmpfs rw,noexec,nodev,size=1G 0 0
</pre>

Adjust the <code>1G</code> size limit value as desired.

<p>
Once booted into the finished installation, it should look something like this:

</p><pre># <strong>lvs</strong>
  LV   VG   Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
  home lvm  -wi-ao---- 189.12g                                                    
  root lvm  -wi-ao----  25.00g                                                    
  var  lvm  -wi-ao----   8.00g                                                    
# <strong>mount | egrep '(lvm|/tmp|shm)' | sort</strong>
/dev/mapper/lvm-home on /home type ext4 (rw,nodev,noexec,relatime)
/dev/mapper/lvm-root on / type ext4 (rw,relatime)
/dev/mapper/lvm-var on /var type ext4 (rw,nodev,noexec,relatime)
tmpfs on /dev/shm type tmpfs (rw,nodev,noexec,size=1048576k)
tmpfs on /tmp type tmpfs (rw,nodev,noexec,relatime,size=1048576k)
</pre>

Another user-writable directory to consider is <code>/run</code>, specifically
the <code>/run/user/$UID</code> directories that systemd spawns when someone
logs in, but their transience is
<a href="https://lists.freedesktop.org/archives/systemd-devel/2015-February/028429.html">annoying</a>
and <a href="https://lwn.net/Articles/436012/">complicated</a>.
I have yet to find the perfect solution there that won't break other things.
<a href="https://wiki.archlinux.org/index.php/FUSE">FUSE</a> is another way
for non-root users to create new mount points and execute binaries. If FUSE
functionality isn't needed, the kernel module can be
<a href="https://wiki.archlinux.org/index.php/Kernel_module#Blacklisting">blacklisted</a>.

<hr>

<h2 id="pacman">Pacman</h2>

Package managers usually don't need much additional configuration.
<a href="https://wiki.archlinux.org/index.php/Pacman">Pacman</a>, the one
Arch uses, is no different. My recommendation for any package manager is
simply to make sure that
<a href="https://web.archive.org/web/20200528161634/https://blog.packagecloud.io/eng/2018/02/21/attacks-against-secure-apt-repositories/">only HTTPS mirrors</a>
are used.

<pre># /etc/pacman.d/mirrorlist

Server = <strong>https</strong>://example.com/[...]/$repo/os/$arch
</pre>

Check the
<a href="https://www.archlinux.org/mirrorlist/all/https/">mirrorlist
generator</a> to see a list of TLS-capable servers near you.

<p>
Using an HTTPS mirror with Pacman is especially important because it
<a href="https://security.archlinux.org/package/pacman">doesn't validate</a>
the package database files and it
<a href="https://en.wikipedia.org/wiki/Privilege_separation">runs everything as root</a>.
HTTPS doesn't mitigate either of these problems, but it is one line of defense
against a MITM attack. I hope the developers will make fixing these two
security issues a priority for the project soon. Other package managers
have been doing it the right way for a long time.

</p><hr>

<h2 id="kern">Kernel Options</h2>

The
<a href="https://www.archlinux.org/packages/extra/x86_64/linux-hardened/">linux-hardened</a>
kernel package in Arch includes some compile-time security improvements
that can't be set at runtime.
If your distribution doesn't have a package for it, applying the
<a href="https://github.com/anthraxx/linux-hardened/releases">patchset</a>
to upstream sources and building your own kernel is pretty easy. If you go
that route, have a look at the
<a href="https://github.com/a13xp0p0v/kconfig-hardened-check">kconfig-hardened-check</a>
script for more compile-time settings to consider.

<p>
The only issue I've found with linux-hardened is that it's often outdated.
Upstream Linux development moves quickly, so out-of-tree patches will always
require extra work to maintain. Why the (relatively small) patches aren't
upstreamed is unknown to me. There are times when linux-hardened is lagging
multiple versions behind the latest kernel, thus missing out on many
important security fixes. In such a situation, the user must choose between
a more secure kernel with known vulnerabilities and a less secure kernel
with fewer known vulnerabilities. Not a great situation.

</p><p>
Runtime configuration of the kernel can be done in a number of ways.
Desired flags may be passed on startup in the form of
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters">kernel parameters</a>,
of which there is an
<a href="https://www.kernel.org/doc/Documentation/admin-guide/kernel-parameters.txt">extensive list</a>.
Parameters are usually passed by the
<a href="https://wiki.archlinux.org/index.php/Bootloader#Boot_loader">bootloader</a>, so
<a href="https://wiki.archlinux.org/index.php/Kernel_parameters#Configuration">configuration details</a>
vary depending whether the system uses
<a href="https://wiki.archlinux.org/index.php/GRUB">GRUB</a>,
<a href="https://wiki.archlinux.org/index.php/Systemd-boot">systemd-boot</a>,
or something else.

</p><p>
The following options, split up into categories, are worth considering for
security improvements:

</p><pre>l1tf=full,force
spec_store_bypass_disable=on
spectre_v2=on
</pre>

These are addtional mitigations for certain CPU security flaws.
While the <code>mitigations=auto</code> option is used by default in upstream
Linux, some of the mitigations it enables have been "toned down" for
performance reasons.
Examples of this include the
<a href="https://en.wikipedia.org/wiki/Foreshadow_(security_vulnerability)">L1TF</a>
and
<a href="https://en.wikipedia.org/wiki/Microarchitectural_Data_Sampling">Microarchitectural Data Sampling</a>
vulnerabilities, which can't be fully mitigated unless HyperThreading
is disabled.
The
<a href="https://en.wikipedia.org/wiki/Speculative_Store_Bypass">Speculative Store Bypass</a>
vulnerability is only partially mitigated by default, with applications being
allowed to opt-in for protections via prctl or seccomp.
Finally, we enable all mitigations (including those against userspace) for
<a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)">Spectre V2</a>.

<pre>apparmor=1
lsm=lockdown,yama,apparmor
lockdown=<span color="#ff0000"><strong>XXX</strong></span>
</pre>

These enable the
<a href="https://wiki.archlinux.org/index.php/AppArmor">AppArmor</a>, 
<a href="https://www.kernel.org/doc/Documentation/security/Yama.txt">Yama</a>,
and
<a href="https://web.archive.org/web/20200525014035/https://mjg59.dreamwidth.org/55105.html">Lockdown</a>
features, with the lockdown mode left for the reader to choose.
Valid options are <code>integrity</code> and <code>confidentiality</code>,
both described briefly
<a href="https://wiki.archlinux.org/index.php/Security#Kernel_lockdown_mode">here</a>.
Replace <code><strong><span color="#ff0000">XXX</span></strong></code> with
whichever you see fit, or omit this option entirely if the feature isn't
wanted.

<p>
For what it's worth, running in <code>confidentiality</code> mode on my
desktop hasn't caused any problems. Your mileage and use case may vary.
Lockdown will break suspend-to-disk and any out-of-tree kernel modules
like ZFS, as well as
<a href="https://wiki.archlinux.org/index.php/Dynamic_Kernel_Module_Support">DKMS</a> modules.

</p><pre>init_on_alloc=1
init_on_free=1
page_alloc.shuffle=1
slab_nomerge
vsyscall=none
</pre>

This group will instruct the kernel to fill newly allocated pages and heap
objects with zeroes, fill freed pages and heap objects with zeroes, tell the
page allocator to randomize its free lists, disable merging of
<a href="https://en.wikipedia.org/wiki/Slab_allocation">slabs</a>
with similar size, and disable
<a href="https://web.archive.org/web/20200526182112/https://lwn.net/Articles/446528/">vsyscalls</a>
due to their history of making exploits easier.
All five options are all set by default when using the linux-hardened kernel.

<pre>slub_debug=F
</pre>

This enables sanity checks in the
<a href="https://www.kernel.org/doc/Documentation/vm/slub.txt">SLUB allocator</a>.
Two other flags to consider for non-hardened kernels are <code>Z</code>
(redzoning, to detect when a slab is overwritten past its real size) and
<code>P</code> (to enable poisoning on slab cache allocations).

<p>
The full list of kernel parameters to be used must be specified on a single
line, separated by spaces, in the bootloader's config file. An example for
GRUB might look like this:

</p><pre># /etc/default/grub

[...]</pre></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vez.mrsk.me/linux-hardening.html#hn">https://vez.mrsk.me/linux-hardening.html#hn</a></em></p>]]>
            </description>
            <link>https://vez.mrsk.me/linux-hardening.html#hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664507</guid>
            <pubDate>Fri, 02 Oct 2020 16:51:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Brief History of Neural Nets and Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24664223">thread link</a>) | @andreyk
<br/>
October 2, 2020 | https://www.skynettoday.com/overviews/neural-net-history | <a href="https://web.archive.org/web/*/https://www.skynettoday.com/overviews/neural-net-history">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h2 id="prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</h2>

<blockquote>
  <p>‚ÄúDeep Learning waves have lapped at the shores of computational linguistics for several years now, but 2015 seems like the year when the full force of the tsunami hit the major Natural Language Processing (NLP) conferences.‚Äù -<a href="http://www.mitpressjournals.org/doi/pdf/10.1162/COLI_a_00239">Dr. Christopher D. Manning, Dec 2015</a> <sup id="fnref:part1_1" role="doc-noteref"><a href="#fn:part1_1">1</a></sup></p>
</blockquote>

<p>This may sound hyperbolic - to say the established methods of an entire field of research are quickly being superseded by a new discovery, as if hit by a research ‚Äòtsunami‚Äô. But, this catastrophic language is appropriate for describing the meteoric rise of Deep Learning over the last several years - a rise characterized by drastic improvements over reigning approaches towards the hardest problems in AI, massive investments from industry giants such as Google, and exponential growth in research publications (and Machine Learning graduate students). Having taken several classes on Machine Learning, and even used it in undergraduate research, I could not help but wonder if this new ‚ÄòDeep Learning‚Äô was anything fancy or just a scaled up version of the ‚Äòartificial neural nets‚Äô that were already developed by the late 80s. And let me tell you, the answer is quite a story - the story of not just neural nets, not just of a sequence of research breakthroughs that make Deep Learning somewhat more interesting than ‚Äòbig neural nets‚Äô  (that I will attempt to explain in a way that just about anyone can understand), but most of all of how several unyielding researchers made it through dark decades of banishment to finally redeem neural nets and achieve the dream of Deep Learning.</p>


<blockquote><p id="sources">
I am certainly not a foremost expert on this topic. In depth technical overviews with long lists of references written by those who actually made the field what it is include Yoshua Bengio's <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/TR1312.pdf">"Learning Deep Architectures for AI"</a>, J√ºrgen Schmidhuber's <a href="http://arxiv.org/pdf/1404.7828v4.pdf">"Deep Learning in Neural Networks: An Overview"</a> and LeCun et al.s' <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">"Deep learning"</a>. In particular, this is mostly a history of research in the US/Canada AI community, and even there will not mention many researchers; a particularly in depth history of the field that covers these omissions is J√ºrgen Schmidhuber's <a href="http://people.idsia.ch/~juergen/deep-learning-overview.html">"Deep Learning in Neural Networks: An Overview"</a>. I am also most certainly not a professional writer, and will cop to there being shorter and much less technical overviews written by professional writers such as Paul Voosen's <a href="http://chronicle.com/article/The-Believers/190147">"The Believers"</a>, John Markoff's <a href="http://www.nytimes.com/2012/11/24/science/scientists-see-advances-in-deep-learning-a-part-of-artificial-intelligence.html">"Scientists See Promise in Deep-Learning Programs"</a> and Gary Marcus's <a href="http://www.newyorker.com/news/news-desk/is-deep-learning-a-revolution-in-artificial-intelligence">"Is ‚ÄúDeep Learning‚Äù a Revolution in Artificial Intelligence?"</a>. I also will stay away from getting too technical here, but there is a plethora of tutorials on the internet on all the major topics covered in brief by me.
<br>
Any corrections would be appreciated, though I will note some ommisions are intentional since I want to try and keep this 'brief' and a good mix of simple technical explanations and storytelling. 
<br>
This piece is an updated and expanded version of blog posts originally released in 2015 on www.andreykurenkov.com. 
</p></blockquote>

<ul id="markdown-toc">
  <li><a href="#prologue-the-deep-learning-tsunami" id="markdown-toc-prologue-the-deep-learning-tsunami">Prologue: The Deep Learning Tsunami</a></li>
  <li><a href="#part-1-the-beginnings-1950s-1980s" id="markdown-toc-part-1-the-beginnings-1950s-1980s">Part 1: The Beginnings (1950s-1980s)</a>    <ul>
      <li><a href="#the-centuries-old-machine-learning-algorithm" id="markdown-toc-the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</a></li>
      <li><a href="#the-folly-of-false-promises" id="markdown-toc-the-folly-of-false-promises">The Folly of False Promises</a></li>
      <li><a href="#the-thaw-of-the-ai-winter" id="markdown-toc-the-thaw-of-the-ai-winter">The Thaw of the AI Winter</a></li>
    </ul>
  </li>
  <li><a href="#part-2-neural-nets-blossom-1980s-2000s" id="markdown-toc-part-2-neural-nets-blossom-1980s-2000s">Part 2: Neural Nets Blossom (1980s-2000s)</a>    <ul>
      <li><a href="#neural-nets-gain-vision" id="markdown-toc-neural-nets-gain-vision">Neural Nets Gain Vision</a></li>
      <li><a href="#neural-nets-go-unsupervised" id="markdown-toc-neural-nets-go-unsupervised">Neural Nets Go Unsupervised</a></li>
      <li><a href="#neural-nets-gain-beliefs" id="markdown-toc-neural-nets-gain-beliefs">Neural Nets Gain Beliefs</a></li>
      <li><a href="#neural-nets-make-decisions" id="markdown-toc-neural-nets-make-decisions">Neural Nets Make Decisions</a></li>
      <li><a href="#neural-nets-get-loopy" id="markdown-toc-neural-nets-get-loopy">Neural Nets Get Loopy</a></li>
      <li><a href="#neural-nets-start-to-speak" id="markdown-toc-neural-nets-start-to-speak">Neural Nets Start to Speak</a></li>
      <li><a href="#a-new-winter-dawns" id="markdown-toc-a-new-winter-dawns">A New Winter Dawns</a></li>
    </ul>
  </li>
  <li><a href="#part-3-deep-learning-2000s-2010s" id="markdown-toc-part-3-deep-learning-2000s-2010s">Part 3: Deep Learning (2000s-2010s)</a>    <ul>
      <li><a href="#the-funding-of-more-layers" id="markdown-toc-the-funding-of-more-layers">The Funding of More Layers</a></li>
      <li><a href="#the-development-of-big-data" id="markdown-toc-the-development-of-big-data">The Development of Big Data</a></li>
      <li><a href="#the-importance-of-brute-force" id="markdown-toc-the-importance-of-brute-force">The Importance of Brute Force</a></li>
      <li><a href="#the-deep-learning-equation" id="markdown-toc-the-deep-learning-equation">The Deep Learning Equation</a></li>
    </ul>
  </li>
  <li><a href="#epilogue-the-decade-of-deep-learning" id="markdown-toc-epilogue-the-decade-of-deep-learning">Epilogue: The Decade of Deep Learning</a></li>
</ul>


<p>The beginning of a story spanning half a century, about how we learned to make computers learn. In this part, we shall cover the birth of neural nets with the Perceptron in 1958, the AI Winter of the 70s, and neural nets‚Äô return to popularity with backpropagation in 1986.</p>

<h2 id="the-centuries-old-machine-learning-algorithm">The Centuries Old Machine Learning Algorithm</h2>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/Linear_regression.svg" alt="Linear Regression">     
    <figcaption>Linear regression <a href="https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg">(Source)</a></figcaption>
</figure>

<p>Let‚Äôs start with a brief primer on what Machine Learning is. Take some points on a 2D graph, and draw a line that fits them as well as possible. What you have just done is generalized from a few example of pairs of input values (x) and output values (y) to a general function that can map any input value to an output value. This is known as linear regression, and it is a wonderful little <a href="https://en.wikipedia.org/wiki/Linear_regression#cite_note-4">200 year old</a> technique for extrapolating a general function from some set of input-output pairs. And here‚Äôs why having such a technique is wonderful: there is an incalculable number of functions that are hard to develop equations for directly, but are easy to collect examples of input and output pairs for in the real world - for instance, the function mapping an input of recorded audio of a spoken word to an output of what that spoken word is.</p>

<p>Linear regression is a bit too wimpy a technique to solve the problem of speech recognition, but what it does is essentially what <strong>supervised Machine Learning</strong> is all about: ‚Äòlearning‚Äô a function given a <strong>training set</strong> of <strong>examples</strong>, where each example is a pair of an input and output from the function (we shall touch on the unsupervised flavor in a little while). In particular, machine learning methods should derive a function that can generalize well to inputs not in the training set, since then we can actually apply it to inputs for which we do not have an output. For instance, Google‚Äôs current speech recognition technology is powered by Machine Learning with a massive training set, but not nearly as big a training set as all the possible speech inputs you might task your phone with understanding.</p>

<p>This generalization principle is so important that there is almost always a <strong>test set</strong> of data (more examples of inputs and outputs) that is not part of the training set. The separate set can be used to evaluate the effectiveness of the machine learning technique by seeing how many of the examples the method correctly computes outputs for given the inputs. The nemesis of generalization is <strong>overfitting</strong> - learning a function that works really well for the training set but badly on the test set. Since machine learning researchers needed means to compare the effectiveness of their methods, over time there appeared standard <strong>datasets</strong> of training and testing sets that could be used to evaluate machine learning algorithms.</p>

<p>Okay okay, enough definitions. Point is - our line drawing exercise is a very simple example of supervised machine learning: the points are the training set (X is input and Y is output), the line is the approximated function, and we can use the line to find Y values for X values that don‚Äôt match any of the points we started with. Don‚Äôt worry, the rest of this history will not be nearly so dry as all this. Here we go.</p>

<h2 id="the-folly-of-false-promises">The Folly of False Promises</h2>

<p>Why have all this prologue with linear regression, since the topic here is ostensibly neural nets? Well, in fact linear regression bears some resemblance to the first idea conceived specifically as a method to make machines learn: <a href="http://psycnet.apa.org/index.cfm?fa=buy.optionToBuy&amp;id=1959-09865-001">Frank Rosenblatt‚Äôs <strong>Perceptron</strong></a><sup id="fnref:part1_2" role="doc-noteref"><a href="#fn:part1_2">2</a></sup>.</p>
<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34998.jpg" alt="Perceptron">
    <figcaption>A diagram showing how the Perceptron works. <a href="http://cse-wiki.unl.edu/wiki/images/0/0f/Perceptron.jpg">(Source)</a></figcaption>    
</figure>

<p>A psychologist, Rosenblatt conceived of the Percetron as a simplified mathematical model of how the neurons in our brains operate: it takes a set of binary inputs (nearby neurons), multiplies each input by a continuous valued weight (the synapse strength to each nearby neuron), and thresholds the sum of these weighted inputs to output a 1 if the sum is big enough and otherwise a 0 (in the same way neurons either fire or do not). Most of the inputs to a Perceptron are either some data or the output of another Perceptron, but an extra detail is that Perceptrons also have one special ‚Äòbias‚Äô input, which just has a value of 1 and basically ensures that more functions are computable with the same input by being able to offset the summed value. This model of the neuron built on the work of Warren McCulloch and Walter Pitts <a href="http://www.minicomplexity.org/pubs/1943-mcculloch-pitts-bmb.pdf">Mcculoch-Pitts</a><sup id="fnref:part1_3" role="doc-noteref"><a href="#fn:part1_3">3</a></sup>, who showed that a neuron model that sums binary inputs and outputs a 1 if the sum exceeds a certain threshold value, and otherwise outputs a 0, can model the basic OR/AND/NOT functions. This, in the early days of AI, was a big deal - the predominant thought at the time was that making computers able to perform formal logical reasoning would essentially solve AI.</p>

<figure>
    <img src="https://www.skynettoday.com/assets/img/overviews/2020-09-27-a-brief-history-of-neural-nets-and-deep-learning/34832.jpg" alt="Perceptron 2"> 
    <figcaption>Another diagram, showing the biological inspiration. The <b>activation function</b> is what people now call the non-linear function applied to the weighted input sum to produce the output of the artificial neuron - in the case of Rosenblatt's Perceptron, the function just a thresholding operation.  <a href="http://cs231n.github.io/neural-networks-1/">(Source)</a> </figcaption>    
</figure>

<p>However, the Mcculoch-Pitts model lacked a mechanism for learning, which was crucial for it to be usable for AI. This is where the Perceptron excelled - Rosenblatt came up with a way to make such artificial neurons learn, inspired by the <a href="http://onlinelibrary.wiley.com/doi/10.1002/cne.900930310/abstract">foundational work</a><sup id="fnref:part1_4" role="doc-noteref"><a href="#fn:part1_4">4</a></sup> of Donald Hebb. Hebb put forth the unexpected and hugely influential idea that knowledge and learning occurs in the brain primarily through the formation and change of synapses between neurons - concisely stated as Hebb‚Äôs Rule:</p>

<blockquote>
  <p>‚ÄúWhen an axon of cell A is near enough to excite a cell B and repeatedly or persistently takes part in firing it, some growth process or metabolic change takes place in one or both cells such that A‚Äôs efficiency, as one of the cells firing B, is increased.‚Äù</p>
</blockquote>

<p>The Perceptron did not follow this idea exactly, but having weights on the inputs allowed for a very simple and intuitive learning scheme: given a <strong>training set</strong> of input-output examples the Perceptron should ‚Äòlearn‚Äô a function from, for each example increase the weights if the Perceptron output for that example‚Äôs input is too low compared to the example, and otherwise decrease the weights if the output is too high. Stated ever so slightly more formally, the algorithm is as follows:</p>

<ol>
  <li>Start off with a Perceptron having random weights and a training set</li>
  <li>For the inputs of an example in the ‚Ä¶</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.skynettoday.com/overviews/neural-net-history">https://www.skynettoday.com/overviews/neural-net-history</a></em></p>]]>
            </description>
            <link>https://www.skynettoday.com/overviews/neural-net-history</link>
            <guid isPermaLink="false">hacker-news-small-sites-24664223</guid>
            <pubDate>Fri, 02 Oct 2020 16:25:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pressing YubiKeys]]>
            </title>
            <description>
<![CDATA[
Score 468 | Comments 222 (<a href="https://news.ycombinator.com/item?id=24663989">thread link</a>) | @bertrandom
<br/>
October 2, 2020 | https://bert.org/2020/10/01/pressing-yubikeys/ | <a href="https://web.archive.org/web/*/https://bert.org/2020/10/01/pressing-yubikeys/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>If you work in tech, you probably have a YubiKey. I have this one, the <a href="https://www.yubico.com/product/yubikey-5c-nano/">YubiKey 5C Nano</a>:</p>

<p><img src="https://bert.org/assets/posts/yubikey/nano.jpg" alt="YubiKey 5C Nano"></p>

<p>If you don‚Äôt work in tech but primarily work on your laptop, you probably <em>should</em> have a YubiKey. And if you work on a political campaign or as a journalist, you should definitely have one (or something similar). Talk to your IT Security department about that. This post will mostly be about something your IT Security department doesn‚Äôt want to hear about, though, so maybe don‚Äôt mention it to them.</p>

<p>YubiKeys act as two-factor authentication. This means that after you log-in to a system with your username and password, the system requires you to authorize in a second way as well. This way if your login credentials are compromised, the attacker would also have to compromise the second form of authentication, which is harder.</p>

<p>There are different forms of two-factor authentication - a common one is that a website will ask you to scan a QR code with the Google Authenticator app (or similar) on your phone which will generate 6 digit codes. The way this works is that the server and the app both have a shared secret. The phone generates codes based on that secret and the current timestamp and the server generates the same codes and sees if they match.</p>

<p><img src="https://bert.org/assets/posts/yubikey/qr-code.png" alt="QR Code"></p>

<p><img src="https://bert.org/assets/posts/yubikey/authenticator.png" alt="Google Authenticator"></p>

<p>Another one is SMS-based 2FA, which is pretty widely regarded as insecure. In this case, the server generates a code and sends it to your phone via SMS. The reason it‚Äôs considered insecure is that an attack exists called <a href="https://en.wikipedia.org/wiki/SIM_swap_scam">SIM-jacking</a> where someone convinces a cell phone carrier to port a number to a new SIM card, effectively directing all SMS traffic to their phone instead of yours.</p>

<p><img src="https://bert.org/assets/posts/yubikey/wells.jpg" alt="Wells Fargo"></p>

<p>YubiKeys are small devices that plug in to the USB port of your computer and emulate a keyboard. When tapped, they emit a one-time password (OTP) which can be then verified by a validation server. A private key exists on the device which is used to sign information, but it can never leave the device because it is stored in a tamper-resistant environment.</p>

<p>The YubiKey that I use is designed to always sit in a USB port of my laptop, so whenever I would take my laptop from my desk to a conference room or to another office, it was always available. But like many new remote workers, my laptop never leaves my desk anymore. I have it hooked up to an external monitor and to save some desk space, I have it in clamshell mode sitting vertically on a stand.</p>

<p>This makes tapping the YubiKey difficult, especially when I store my laptop far away from my keyboard and mouse. I solved this by buying a <a href="https://smile.amazon.com/gp/product/B071DMMW4J/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">USB-C extension cable</a>, which brought the YubiKey closer to my keyboard.</p>

<p>One thing I haven‚Äôt mentioned about the YubiKey 5C Nano is that it‚Äôs kind of difficult to tap, even without the distance issues. The target area that you need to touch is extremely small:</p>

<p><img src="https://bert.org/assets/posts/yubikey/nano-big.png" alt="YubiKey 5C Nano"></p>

<p>One of the features of the YubiKey is that the little metal strip determines that it is being tapped by a human - this prevents it from being accidentally triggered by bumping your laptop into something, but if you‚Äôve ever seen a one-time password in a Slack channel or Google Doc like <code>tlerefhcvijlngibueiiuhkeibbcbecehvjiklltnbbl</code>, you know it isn‚Äôt a perfect system. I would estimate that 1 in 5 times that I attempt to trigger it, it doesn‚Äôt register.</p>

<p>A lot of thought has gone into ensuring that the YubiKey can‚Äôt be triggered from software on the computer itself.</p>

<p>Before we go any further, I‚Äôd like to acknowledge the reasons for this. If a remote attacker were to compromise your laptop, being able to trigger the YubiKey from software on the computer defeats the whole point of using the YubiKey. But I think we always make tradeoffs between security and convenience - for example, you often don‚Äôt have to enter your YubiKey every time you access a system, some systems will only ask you once and not ask you again on subsequent logins for a certain amount of time. When you use a 2FA system and it gives you ‚Äúbackup codes‚Äù, do you always print those out and store them in a safe location? Everyone should figure out what level of security and convenience they are okay with.</p>

<p>With that being said, let‚Äôs talk about how you could trigger a YubiKey with software.</p>



<p>I‚Äôve been calling this mechanism <strong>The Finger</strong>.</p>

<h2 id="hardware">Hardware</h2>

<p>First, we need some way for the computer to talk to <strong>The Finger</strong>. I had a bunch of these <a href="https://smile.amazon.com/gp/product/B076F53B6S/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">IZOKEE D1 Mini</a> development boards lying around, they are smaller versions of boards that use the infamous <a href="https://en.wikipedia.org/wiki/ESP8266">ESP8266</a> chip found in a lot of IoT devices.</p>

<p><img src="https://bert.org/assets/posts/yubikey/d1-mini.jpg" alt="IZOKEE D1 Mini"></p>

<p>We can connect this to the laptop and talk to it over USB serial, but since it has WiFi, we can also just run a webserver on it and send it HTTP requests.</p>

<p>Next, we need some way to push <strong>The Finger</strong> towards the Yubikey. After a little googling, I found that the <a href="https://smile.amazon.com/gp/product/B01CP18J4A/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&amp;psc=1">28BYJ-48 stepper motor</a> interfaces well with the D1 Mini board.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor.jpg" alt="stepper motor"></p>

<p>Stepper motors convert electrical pulses into mechanical rotation and the D1 Mini has pins for sending electrical pulses.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor.gif" alt="stepper motor"></p>

<p>But stepper motors rotate and we mostly just need to poke in a straight direction. So I searched on Thingiverse for ‚Äú28BYJ-48‚Äù and found this: <a href="https://www.thingiverse.com/thing:3593641">28BYJ-48 Motor Halter</a>.</p>

<p><img src="https://bert.org/assets/posts/yubikey/stepper-motor-case.jpg" alt="28BYJ-48 Motor Halter"></p>

<p>This attaches a gear to the motor which can guide a long rack forward and backward. But if we‚Äôre going to push a long plastic thing toward the YubiKey, it might as well look like a finger. Back to Thingiverse, this time searching for ‚Äúfinger‚Äù and I found this model someone made for Halloween:</p>

<p><img src="https://bert.org/assets/posts/yubikey/finger_model.jpg" alt="finger"></p>

<p>I opened up these two models in Fusion 360 and used an advanced CAD technique called ‚Äúsmooshing‚Äù, resulting in this:</p>

<p><img src="https://bert.org/assets/posts/yubikey/finger_smoosh.png" alt="finger"></p>

<p>Next, I exported the smooshed STL and 3D printed it in <a href="https://shop.prusa3d.com/en/prusament/715-prusament-pla-lipstick-red-1kg.html">Prusament PLA Lipstick Red</a> because that‚Äôs what I happened to have in my printer at the time. Then I took the plastic finger and touched the YubiKey which.. didn‚Äôt do anything. I picked up a metal screw on my desk and touched the YubiKey, which immediately spit out a OTP. So then I took the finger and secured it to my desk with a vise and drilled a small hole in it, then screwed the metal screw into it and touched it to the YubiKey, which again did nothing.</p>

<p><img src="https://bert.org/assets/posts/yubikey/vise.jpg" alt="vise"></p>

<p>That‚Äôs when I realized that I‚Äôm an idiot and that when I had touched the metal screw to the Yubikey, it was just transmitting the electrical charge from my body to the metal screw, which then transmitted it to the capacitive touch sensor on the YubiKey. So how could I trick the capacitive touch sensor into thinking it was a real finger?</p>

<p>I guessed that the way that capacitive touch sensors work is that they‚Äôre measuring your body‚Äôs capacitance to ground, so if we just hook up the sensor directly towards ground, it‚Äôll think that its really conductive or at least conductive enough for a human finger to be between the two. So I took an insulated wire, unscrewed the metal screw slightly, wrapped it around the screw and tightened it again. Then I took the other end and connected it the GND port on the D1 Mini board, touched it to the YubiKey, and it worked!</p>

<p>Now the driver board for the stepper motor already connects to the 5V and GND on the D1 Mini, so I thought I might have to strip the GND wire and run it to both the driver board and the screw, but on a whim I decided to just wedge the end of the wire from the metal screw between the stepper motor metal body (figuring the metal body case was grounded) and the plastic housing. This also worked!</p>

<p><img src="https://bert.org/assets/posts/yubikey/ground.jpg" alt="grounding"></p>

<p>Once I confirmed that the finger would trigger the YubiKey, I needed a way to mount the YubiKey close to the finger, so I used my digital calipers to measure the size of the USB-C extension cable and designed a holder in Fusion 360.</p>

<p><img src="https://bert.org/assets/posts/yubikey/holder.png" alt="holder"></p>

<p>The USB-C extension cable would go into the hole on the left and the motor would mount on the right.</p>

<p>At this point, we have to wire the stepper motor driver board to the D1 Mini. This can be done by soldering some headers onto the D1 Mini and then connecting some Dupont jumper wires between them.</p>

<p><img src="https://bert.org/assets/posts/yubikey/pins.jpg" alt="pins"></p>

<table>
  <thead>
    <tr>
      <th>D1 Mini</th>
      <th>28BYJ-48 Driver Board</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>5V</td>
      <td>5V</td>
    </tr>
    <tr>
      <td>GND</td>
      <td>GND</td>
    </tr>
    <tr>
      <td>D1</td>
      <td>IN1</td>
    </tr>
    <tr>
      <td>D2</td>
      <td>IN2</td>
    </tr>
    <tr>
      <td>D3</td>
      <td>IN3</td>
    </tr>
    <tr>
      <td>D4</td>
      <td>IN4</td>
    </tr>
  </tbody>
</table>

<p>Once we put the stepper motor into the housing and screw everything together, it should look like this:</p>

<p><img src="https://bert.org/assets/posts/yubikey/setup.jpg" alt="setup"></p>

<h2 id="software">Software</h2>

<p>The software is much more straightforward. The D1 Mini can be programmed using the Arduino IDE. First, we go into Preferences and add <code>https://arduino.esp8266.com/stable/package_esp8266com_index.json</code> under <em>Additional Board Manager URLs</em>. Then when you go into the <em>Boards Managers</em>, you can install the <code>esp8266</code> package which includes the board <strong>LOLIN(WEMOS) D1 R2 &amp; mini</strong>, which should be selected under <em>Tools</em>.</p>

<p>At this point I‚Äôll run a sketch for blinking the LED just to verify that it‚Äôs working:</p>

<div><div><pre><code>#define LED 2 //Define blinking LED pin

void setup() {
  pinMode(LED, OUTPUT); // Initialize the LED pin as an output
}
// the loop function runs over and over again forever
void loop() {
  digitalWrite(LED, LOW); // Turn the LED on (Note that LOW is the voltage level)
  delay(1000); // Wait for a second
  digitalWrite(LED, HIGH); // Turn the LED off by making the voltage HIGH
  delay(1000); // Wait for two seconds
}
</code></pre></div></div>

<p>I found this <a href="https://robojax.com/learn/arduino/?vid=robojax_ESP8266_28BYJ-48_Stepper_ESP8STP-1">sketch</a> that shows how to control the 28BYJ-48 Stepper Motor using WiFi.</p>

<p>Here are the parts that have to do with the motor:</p>

<div><div><pre><code>int Pin1 = D1; //IN1 is connected 
int Pin2 = D2; //IN2 is connected   
int Pin3 = D3; //IN3 is connected 
int Pin4 = D4; //IN4 is connected 
 
int pole1[] ={0,0,0,0, 0,1,1,1, 0}; //pole1, 8 step values
int pole2[] ={0,0,0,1, 1,1,0,0, 0}; //pole2, 8 step values
int pole3[] ={0,1,1,1, 0,0,0,0, 0}; //pole3, 8 step values
int pole4[] ={1,1,0,0, 0,0,0,1, 0}; //pole4, 8 step values

int poleStep = 0; 
int dirStatus = 3; // stores direction status 3= stop (do not change)
String argId[] ={"ccw", "cw"};

...

void loop(void) {
    server.handleClient();
    MDNS.update();

    if (dirStatus == 1) {
        poleStep++;
        driveStepper(poleStep);
    } else if (dirStatus == 2) {
        poleStep--;
        driveStepper(poleStep);
    } else {
        driveStepper(8);
    }
    
    if (poleStep&gt;7) { 
        poleStep=0; 
    }

    if (poleStep&lt;0) {
        ‚Ä¶</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bert.org/2020/10/01/pressing-yubikeys/">https://bert.org/2020/10/01/pressing-yubikeys/</a></em></p>]]>
            </description>
            <link>https://bert.org/2020/10/01/pressing-yubikeys/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663989</guid>
            <pubDate>Fri, 02 Oct 2020 16:03:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cuda.jl 2.0]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663940">thread link</a>) | @ChrisRackauckas
<br/>
October 2, 2020 | https://juliagpu.org/2020-10-02-cuda_2.0/ | <a href="https://web.archive.org/web/*/https://juliagpu.org/2020-10-02-cuda_2.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        





<i data-feather="calendar"></i> <time datetime="2020-10-02">Oct 2, 2020</time>




  <br>
  <i data-feather="edit-2"></i> Tim Besard


<p>Today we‚Äôre releasing CUDA.jl 2.0, a breaking release with several new features. Highlights
include initial support for Float16, a switch to CUDA‚Äôs new stream model, a much-needed
rework of the sparse array support and support for CUDA 11.1.</p>
<p>The release now requires <strong>Julia 1.5</strong>, and assumes a GPU with <strong>compute capability 5.0</strong> or
higher (although most of the package will still work with an older GPU).</p>
<h2 id="low--and-mixed-precision-operations">Low- and mixed-precision operations</h2>
<p>With NVIDIA‚Äôs latest GPUs featuring more and more low-precision operations,
CUDA.jl <a href="https://github.com/JuliaGPU/CUDA.jl/pull/417">now</a> starts to support
these data types. For example, the CUBLAS wrappers can be used with (B)Float16
inputs (running under <code>JULIA_DEBUG=CUBLAS</code> to illustrate the called methods)
thanks to the <code>cublasGemmEx</code> API call:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> mul!(CUDA<span>.</span>zeros(<span>Float32</span>,<span>2</span>,<span>2</span>), cu(rand(<span>Float16</span>,<span>2</span>,<span>2</span>)), cu(rand(<span>Float16</span>,<span>2</span>,<span>2</span>)))

I<span>!</span> cuBLAS (v11<span>.</span><span>0</span>) <span>function</span> cublasStatus_t cublasGemmEx(<span>...</span>) called<span>:</span>
i!  Atype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16F(<span>2</span>)
i!  Btype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16F(<span>2</span>)
i!  Ctype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  computeType<span>:</span> type<span>=</span>cublasComputeType_t; val<span>=</span>CUBLAS_COMPUTE_32F(<span>68</span>)

<span>2</span>√ó2 CuArray{<span>Float32</span>,<span>2</span>}<span>:</span>
 <span>0.481284</span>  <span>0.561241</span>
 <span>1.12923</span>   <span>1.04541</span>
</code></pre></div><div><pre><code data-lang="julia">julia<span>&gt;</span> <span>using</span> BFloat16s

julia<span>&gt;</span> mul!(CUDA<span>.</span>zeros(BFloat16,<span>2</span>,<span>2</span>), cu(BFloat16<span>.</span>(rand(<span>2</span>,<span>2</span>))), cu(BFloat16<span>.</span>(rand(<span>2</span>,<span>2</span>))))

I<span>!</span> cuBLAS (v11<span>.</span><span>0</span>) <span>function</span> cublasStatus_t cublasGemmEx(<span>...</span>) called<span>:</span>
i!  Atype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16BF(<span>14</span>)
i!  Btype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16BF(<span>14</span>)
i!  Ctype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_16BF(<span>14</span>)
i!  computeType<span>:</span> type<span>=</span>cublasComputeType_t; val<span>=</span>CUBLAS_COMPUTE_32F(<span>68</span>)

<span>2</span>√ó2 CuArray{BFloat16,<span>2</span>}<span>:</span>
 <span>0.300781</span>   <span>0.71875</span>
 <span>0.0163574</span>  <span>0.0241699</span>
</code></pre></div><p>Alternatively, CUBLAS can be configured to automatically down-cast 32-bit inputs to Float16.
This is <a href="https://github.com/JuliaGPU/CUDA.jl/pull/424">now</a> exposed through a task-local
CUDA.jl math mode:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> CUDA<span>.</span>math_mode!(CUDA<span>.</span>FAST_MATH; precision<span>=:</span><span>Float16</span>)

julia<span>&gt;</span> mul!(CuArray(zeros(<span>Float32</span>,<span>2</span>,<span>2</span>)), CuArray(rand(<span>Float32</span>,<span>2</span>,<span>2</span>)), CuArray(rand(<span>Float32</span>,<span>2</span>,<span>2</span>)))

I<span>!</span> cuBLAS (v11<span>.</span><span>0</span>) <span>function</span> cublasStatus_t cublasGemmEx(<span>...</span>) called<span>:</span>
i!  Atype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  Btype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  Ctype<span>:</span> type<span>=</span>cudaDataType_t; val<span>=</span>CUDA_R_32F(<span>0</span>)
i!  computeType<span>:</span> type<span>=</span>cublasComputeType_t; val<span>=</span>CUBLAS_COMPUTE_32F_FAST_16F(<span>74</span>)

<span>2</span>√ó2 CuArray{<span>Float32</span>,<span>2</span>}<span>:</span>
 <span>0.175258</span>  <span>0.226159</span>
 <span>0.511893</span>  <span>0.331351</span>
</code></pre></div><p>As part of these changes, CUDA.jl now defaults to using tensor cores. This may affect
accuracy; use math mode <code>PEDANTIC</code> if you want the old behavior.</p>
<p>Work is <a href="https://github.com/JuliaGPU/CUDA.jl/issues/391">under way</a> to extend these
capabilities to the rest of CUDA.jl, e.g., the CUDNN wrappers, or the native kernel
programming capabilities.</p>
<h2 id="new-default-stream-semantics">New default stream semantics</h2>
<p>In CUDA.jl 2.0 we‚Äôre <a href="https://github.com/JuliaGPU/CUDA.jl/pull/395">switching</a> to CUDA‚Äôs
<a href="https://developer.nvidia.com/blog/gpu-pro-tip-cuda-7-streams-simplify-concurrency/">simplified stream programming
model</a>.
This simplifies working with multiple streams, and opens up more possibilities for
concurrent execution of GPU operations.</p>
<h3 id="multi-stream-programming">Multi-stream programming</h3>
<p>In the old model, the default stream (used by all GPU operations unless specified otherwise)
was a special stream whose commands could not be executed concurrently with commands on
regular, explicitly-created streams. For example, if we interleave kernels executed on a
dedicated stream with ones on the default one, execution was serialized:</p>
<div><pre><code data-lang="julia"><span>using</span> CUDA

N <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>20</span>

<span>function</span> kernel(x, n)
    tid <span>=</span> threadIdx()<span>.</span>x <span>+</span> (blockIdx()<span>.</span>x<span>-</span><span>1</span>) <span>*</span> blockDim()<span>.</span>x
    <span>for</span> i <span>=</span> tid<span>:</span>blockDim()<span>.</span>x<span>*</span>gridDim()<span>.</span>x<span>:</span>n
        x[i] <span>=</span> CUDA<span>.</span>sqrt(CUDA<span>.</span>pow(<span>3.14159f0</span>, i))
    <span>end</span>
    <span>return</span>
<span>end</span>

num_streams <span>=</span> <span>8</span>

<span>for</span> i <span>in</span> <span>1</span><span>:</span>num_streams
    stream <span>=</span> CuStream()

    data <span>=</span> CuArray{<span>Float32</span>}(undef, N)

    <span>@cuda</span> blocks<span>=</span><span>1</span> threads<span>=</span><span>64</span> stream<span>=</span>stream kernel(data, N)

    <span>@cuda</span> kernel(data, <span>0</span>)
<span>end</span>
</code></pre></div>

<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multistream_before.png" alt="Multi-stream programming (old)">
</figure>

<p>In the new model, default streams are regular streams and commands issued on them can
execute concurrently with those on other streams:</p>


<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multistream_after.png" alt="Multi-stream programming (new)">
</figure>

<h3 id="multi-threading">Multi-threading</h3>
<p>Another consequence of the new stream model is that each thread gets its own default stream
(accessible as <code>CuStreamPerThread()</code>). Together with Julia‚Äôs threading capabilities, this
makes it trivial to group independent work in tasks, benefiting from concurrent execution on
the GPU where possible:</p>
<div><pre><code data-lang="julia"><span>using</span> CUDA

N <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>20</span>

<span>function</span> kernel(x, n)
    tid <span>=</span> threadIdx()<span>.</span>x <span>+</span> (blockIdx()<span>.</span>x<span>-</span><span>1</span>) <span>*</span> blockDim()<span>.</span>x
    <span>for</span> i <span>=</span> tid<span>:</span>blockDim()<span>.</span>x<span>*</span>gridDim()<span>.</span>x<span>:</span>n
        x[i] <span>=</span> CUDA<span>.</span>sqrt(CUDA<span>.</span>pow(<span>3.14159f0</span>, i))
    <span>end</span>
    <span>return</span>
<span>end</span>

Threads<span>.</span><span>@threads</span> <span>for</span> i <span>in</span> <span>1</span><span>:</span>Threads<span>.</span>nthreads()
    data <span>=</span> CuArray{<span>Float32</span>}(undef, N)
    <span>@cuda</span> blocks<span>=</span><span>1</span> threads<span>=</span><span>64</span> kernel(data, N)
    synchronize(CuDefaultStream())
<span>end</span>
</code></pre></div>

<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multithread_after.png" alt="Multi-threading (new)">
</figure>

<p>With the old model, execution would have been serialized because the default stream was the
same across threads:</p>


<figure>
	<img src="https://juliagpu.org/2020-10-02-cuda_2.0/multithread_before.png" alt="Multi-threading (old)">
</figure>

<p>Future improvements will make this behavior configurable, such that users can use a
different default stream per task.</p>
<h2 id="sparse-array-clean-up">Sparse array clean-up</h2>
<p>As part of CUDA.jl 2.0, the sparse array support <a href="https://github.com/JuliaGPU/CUDA.jl/pull/409">has been
refactored</a>, bringing them in line with other
array types and their expected behavior. For example, the custom <code>switch2</code> methods have been
removed in favor of calls to <code>convert</code> and array constructors:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> <span>using</span> SparseArrays
julia<span>&gt;</span> <span>using</span> CUDA, CUDA<span>.</span>CUSPARSE

julia<span>&gt;</span> CuSparseMatrixCSC(CUDA<span>.</span>rand(<span>2</span>,<span>2</span>))
<span>2</span>√ó2 CuSparseMatrixCSC{<span>Float32</span>} with <span>4</span> stored entries<span>:</span>
  [<span>1</span>, <span>1</span>]  <span>=</span>  <span>0.124012</span>
  [<span>2</span>, <span>1</span>]  <span>=</span>  <span>0.791714</span>
  [<span>1</span>, <span>2</span>]  <span>=</span>  <span>0.487905</span>
  [<span>2</span>, <span>2</span>]  <span>=</span>  <span>0.752466</span>

julia<span>&gt;</span> CuSparseMatrixCOO(sprand(<span>2</span>,<span>2</span>, <span>0.5</span>))
<span>2</span>√ó2 CuSparseMatrixCOO{<span>Float64</span>} with <span>3</span> stored entries<span>:</span>
  [<span>1</span>, <span>1</span>]  <span>=</span>  <span>0.183183</span>
  [<span>2</span>, <span>1</span>]  <span>=</span>  <span>0.966466</span>
  [<span>2</span>, <span>2</span>]  <span>=</span>  <span>0.064101</span>

julia<span>&gt;</span> CuSparseMatrixCSR(ans)
<span>2</span>√ó2 CuSparseMatrixCSR{<span>Float64</span>} with <span>3</span> stored entries<span>:</span>
  [<span>1</span>, <span>1</span>]  <span>=</span>  <span>0.183183</span>
  [<span>2</span>, <span>1</span>]  <span>=</span>  <span>0.966466</span>
  [<span>2</span>, <span>2</span>]  <span>=</span>  <span>0.064101</span>
</code></pre></div><p><a href="https://github.com/JuliaGPU/CUDA.jl/pull/421">Initial support for the COO sparse matrix type
</a> has also been added, along with more <a href="https://github.com/JuliaGPU/CUDA.jl/pull/351">better
support for sparse matrix-vector
multiplication</a>.</p>
<h2 id="support-for-cuda-111">Support for CUDA 11.1</h2>
<p>This release also features support for the brand-new CUDA 11.1. As there is no compatible
release of CUDNN or CUTENSOR yet, CUDA.jl won‚Äôt automatically select this version, but you
can force it to by setting the <code>JULIA_CUDA_VERSION</code> environment variable to <code>11.1</code>:</p>
<div><pre><code data-lang="julia">julia<span>&gt;</span> ENV[<span>"JULIA_CUDA_VERSION"</span>] <span>=</span> <span>"11.1"</span>

julia<span>&gt;</span> <span>using</span> CUDA

julia<span>&gt;</span> CUDA<span>.</span>versioninfo()
CUDA toolkit <span>11.1</span><span>.</span><span>0</span>, artifact installation

Libraries<span>:</span>
<span>-</span> CUDNN<span>:</span> missing
<span>-</span> CUTENSOR<span>:</span> missing
</code></pre></div><h2 id="minor-changes">Minor changes</h2>
<p>Many other changes are part of this release:</p>
<ul>
<li>Views, reshapes and array reinterpretations <a href="https://github.com/JuliaGPU/CUDA.jl/pull/437">are now
represented</a> by the Base array wrappers,
simplifying the CuArray type definition.</li>
<li>Various optimizations to <a href="https://github.com/JuliaGPU/CUDA.jl/pull/428">CUFFT</a> and
<a href="https://github.com/JuliaGPU/CUDA.jl/pull/321">CUDNN</a> library wrappers.</li>
<li><a href="https://github.com/JuliaGPU/CUDA.jl/pull/427">Support</a> for <code>LinearAlgebra.reflect!</code> and
<code>rotate!</code></li>
<li><a href="https://github.com/JuliaGPU/CUDA.jl/pull/435">Initial support</a> for calling CUDA libraries
with strided inputs</li>
</ul>



      </main>
    </div></div>]]>
            </description>
            <link>https://juliagpu.org/2020-10-02-cuda_2.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663940</guid>
            <pubDate>Fri, 02 Oct 2020 15:58:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Does My Computer Not Boot with a USB Hub Attached?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24663858">thread link</a>) | @kn100
<br/>
October 2, 2020 | https://kn100.me/usb-hub-bs/ | <a href="https://web.archive.org/web/*/https://kn100.me/usb-hub-bs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>My trusty old USB 3 hub has failed. It was only around a year old, but it was cheap and it worked. It wasn‚Äôt powered, but most of the time it didn‚Äôt need to be. One day I began having very strange issues with USB on my computer. Devices randomly disconnecting, devices never connecting until the computer was rebooted and so on. I eventually narrowed it down to the hub. I tossed it out after a quick internal inspection had revealed nothing obviously wrong, and went shopping for a new hub.</p>
<p>My requirements for a hub were very simple:</p>
<ul>
<li>it must be externally powered,</li>
<li>it must be relatively aesthetically neutral - no gamer aesthetics or hideous glossy plastic,</li>
<li>it must be USB 3,</li>
<li>it must offer between 3 and 7 extra ports - any less and what‚Äôs the point, and more and the hub is unnecessarily big, and I treat my desk like Tokyo. Space is a at a premium,</li>
<li>the cost must not exceed 35 GBP (45 US Dollars at the time of writing),</li>
<li>and it must have a detachable cord that connects it to the computer, or offer a cord long enough to reach my computer under my desk.</li>
</ul>
<p>While shopping, almost every single hub I came across had some stupid design that either prioritised it looking space age with blue LEDS galore, and a lot of them even had individual power switches for each USB port. Why anyone would want that is beyond me. Other hubs had tiny 15cm cables, since they‚Äôre designed to be used right beside a laptop.</p>
<p>I ended up settling on a very cleverly designed Orico 4 port Aluminium hub. I particularly liked this one because aesthetically speaking it was pretty neutral, and it even handles the problem of the USB hub floating off in the breeze by integrating a clamp so that you can clamp it to your desk or your monitor.</p>
<figure>
<img src="https://kn100.me/hub-product.jpg"> <figcaption>
<h4>The hub I chose. A novel design!</h4>
</figcaption>
</figure>
<p>It arrived, and seemed to work perfectly. USB transfer speeds were as expected, the external power source being MicroUSB meant I could attach any fairly dumb USB power supply to it to supply extra power, the cable leading to the PC itself was detachable and relatively standard (USB A to USB A) and all was good with the world.</p>
<p>That was until I put my computer to sleep. The next morning, I pressed a key on my keyboard to trigger the system to wake up, and nothing happened. The keyboard is not attached to the hub, nor is it attached to a port on the motherboard that is on the same controller, so this was perplexing. I pressed the power button on the tower, but still nothing! Very strange. I detached the USB hub, and immediately my computer came to life and worked as normal.</p>
<p>Through further experimentation I determined this strange phenomenon only happened when an external power source was connected. I toyed with the idea of returning what was obviously a faulty product, but reasoned that I didn‚Äôt actually need it to be powered, and pretty much all the other hubs in the same price range were either aesthetically disgusting or lacked other features I liked about this one - so I kept it.</p>
<p>That is until today, when through some research, I found this isn‚Äôt just a problem with <em>my</em> USB hub, it‚Äôs a problem many have with powered hubs. Articles like <a href="https://www.pro-tools-expert.com/production-expert-1/2019/9/18/warning-your-usb-hub-may-be-harming-your-drives-and-you-may-lose-valuable-studio-work-heres-how-to-fix-it">this</a>, or forum posts like <a href="https://forums.tomshardware.com/threads/computer-wont-start-with-usb-hub-connected.2753255/">this</a> show that totally unrelated hubs cause similar issues for their owners. This got me thinking to past experiences of USB hubs I‚Äôve had. In the past, a less financially stable me used to buy the cheapest possible thing every time. At one time, I was experimenting with a Raspberry Pi along with external hard drives. I discovered that a powered hub was necessary for these experiments because the Pi itself was incapable of providing much USB power. I bought the cheapest USB 2 powered hub I could at the time from eBay, and it mostly worked fine. To describe the setup a little, I had the hub itself connected to its power supply, and the ‚Äòin‚Äô usb port connected to one of the Pis USB ports. Imagine my surprise when the Pi switched on and booted up, without any power supply attached! I thought this was cool at the time, and chalked it up to ‚ÄòIt‚Äôs not a bug, it‚Äôs a feature‚Äô, and forgot about it. Fast forward to today me, when I realised my experience back then was possibly related to the problems I was having with this new Orico USB hub today. After a little bit of thought, I realised that the hub was most likely ‚Äòbackfeeding‚Äô power to the connected computer.</p>

<p>To keep things simple, let‚Äôs stick to USB 2 for now. USB 2 consists of 4 conductors, known as VCC (this is the ‚Äòpositive‚Äô 5 volt connection), GND (this is the ‚Äònegative‚Äô power connection), D+, and D- (the data transmission pins, no true power flows over these pins). This means that a connected USB device can both draw power and transfer data. When you see 5 volts on a power adaptor or something, this is usually an approximation. For various reasons which revolve mostly around cost saving, most USB power adaptors will actually output slightly more than 5 volts, and then when a load is applied (say, a charging phone), the voltage drops down a bit. The better the quality of the power supply, closer to 5 volts it‚Äôll start at generally and the smaller the drop when a load is applied.</p>
<figure>
<img src="https://kn100.me/usb-pinout.png"> <figcaption>
<h4>The USB pinout</h4>
</figcaption>
</figure>
<p>This applies to your computer‚Äôs USB ports too - except for one big difference: the power supply inside your computer is probably significantly better designed than the USB plug sockets that are mass produced. In fact, if I measure the voltage coming from my USB ports on my computer, I get a value of around 5.03v. If I measure the voltage coming from my phone charger, I get 5.21v. This is a pretty big difference!</p>
<p>The next thing to know is how a powered hub actually works. Essentially, a powered hub takes an external power source, and passes that power source through to the USB devices connected to the hub in place of your computer. One problem that these hubs face however is what if the user wishes to use the hub in its ‚Äòunpowered‚Äô state - where they‚Äôve connected the hub to their computer with no power supply. In order to implement this properly, the hub would probably need some mechanism to switch between the computer power and the external PSU if it is connected. This would however add cost to the manufacture of the hub, so instead of doing this, they just connect the 5v of your computer through to the 5v of the external power supply. This is ridiculously bad because if there is even the smallest difference between the voltage being supplied by your computer and the voltage being supplied by the external power source, power will flow towards the device with the lower voltage! This is ‚Äòbackfeeding‚Äô. As a simple analogy, imagine you took two rechargeable batteries and connected them together. What you‚Äôd find happens is that the batteries will eventually end up at exactly the same voltage, which will be slightly lower than what you‚Äôd expect if you did the maths, as a small amount of power would be lost as heat. If the power source is ‚Äòinfinite‚Äô however - like our wall connected computer or our wall connected external hub, this power will just continue to flow. Where it goes or what happens with it is completely undefined. In the case of our Raspberry Pi earlier, the circuit was simple enough that it just led to the Pi being powered up. In the case of my computer, it screwed with the system so badly that hardware buttons like the power button literally stopped functioning altogether.</p>

<p>This design seems stupid right? The problem is, it is the cheapest way of achieving the design goal of having a USB hub work with or without power. If we didn‚Äôt care about this particular feature, we could either just not have an external power source and have a purely unpowered hub, or we could not connect the 5v pin from the computer and therefore only supply power from the external PSU. Both of these solutions in effect are more expensive than just living with the backfeeding ‚Äòfeature‚Äô since it‚Äôd mean the company offering the hub would need to deal with support requests from people wondering why their hub doesn‚Äôt work ‚Äòunpowered‚Äô when their other one does, or vice versa. Instead, we get backfeeding. I‚Äôm sure that some computers would not exhibit any real problems with this design, seeing as it‚Äôs been around since as long as powered USB hubs have been around as far as I can tell, and it‚Äôs likely some USB chipsets are designed with this in mind, but mine was not. Others computers, especially Macs, deal with this particular issue far more destructively, causing damage to the computer‚Äôs USB chipset when a backfeeding USB hub is connected.</p>

<p>Before we continue, you should know I am not an electrical engineer, if that wasn‚Äôt clear from how vaguely I described things above. I am a software engineer who likes to dabble with electronics. This means my advice below does not come from someone who is qualified to give it. You should follow this advice at your own risk. I take no responsibility for damage you do to yourself, your USB hub, or your computer, or to anything else for that matter.</p>

<ol>
<li>Firstly, I validated this was the problem. I engaged in a clever little trick where I took an old USB cable - USB 2 or 3 is fine, cut it in half, exposed the either 2 (cable is power only) or 4 wires, and looked up USB wire colouring to realise that the red wire is usually the VCC wire, and Black/White is usually GND. I then connected the cut up USB lead to the input port on my hub (where my computer connects), and connected the external power supply. I measured 5 volts across these two wires using the multimeter, meaning this hub does backfeed.</li>
</ol>
<figure>
<img src="https://kn100.me/hub-screw.jpg"> <figcaption>
<h4>The hubs screws</h4>
</figcaption>
</figure>
<ol start="2">
<li>My hub comes apart very easily. Disconnect all wires. Four screws removed and we immediately get access to the circuit board. USB 3 is a little more complicated than USB 2 - featuring 9 conductors rather than USB 2s 4.</li>
</ol>
<figure>
<img src="https://kn100.me/hub-circuit.jpg"> <figcaption>
<h4>The hubs circuit board. Surprisingly nice, given this stupid issue!</h4>
</figcaption>
</figure>
<ol start="3">
<li>I have no idea what the pinout of USB 3 is, nor how this specific connector orders things. I connected the cut up USB lead to the input port on my hub (where my computer ‚Ä¶</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kn100.me/usb-hub-bs/">https://kn100.me/usb-hub-bs/</a></em></p>]]>
            </description>
            <link>https://kn100.me/usb-hub-bs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663858</guid>
            <pubDate>Fri, 02 Oct 2020 15:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated history of programming languages]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 109 (<a href="https://news.ycombinator.com/item?id=24663770">thread link</a>) | @zdw
<br/>
October 2, 2020 | https://artagnon.com/articles/pl | <a href="https://web.archive.org/web/*/https://artagnon.com/articles/pl">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <p>
            $$
              \begin{xy}
              \xymatrix{
            
            \color{red}{\textbf{FORTRAN (1957)}}^{*}\ar[dr] &amp; \textbf{LISP (1958)}\ar[dl]\ar[dddl]\ar[dddr] &amp; \textbf{ALGOL (1958)}\ar[r]\ar[dl]\ar[drr] &amp; \textbf{Simula (1962)}\ar[dlll]\ar@/_3pc/[ddddd]\ar@/^1pc/[dddll] \\
              \texttt{Smalltalk (1972)}\ar@{--&gt;}@/_2pc/[ddddrr]\ar@{--&gt;}@/^1.6pc/[ddddrrrr]^&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;{\texttt{Self (1987)}} &amp; \texttt{C (1972)}^{*}\ar@{.&gt;}[dd]\ar@{.&gt;}[ddrr]\ar@{.&gt;}[ddddl]\ar@{.&gt;}@/_3pc/[ddddddrrr] &amp; \textbf{Prolog (1972)}\ar[dd] &amp; \textbf{ML (1973)}\ar@{~~&gt;}@/_2pc/[ddddll]\ar@{~~&gt;}@/^2pc/[ddddrr] &amp; \color{red}{\texttt{Bourne Shell (1978)}}\ar[ddll] \\
              \\
              \texttt{Common Lisp (1984)}\ar@/_2pc/[ddddrr] &amp; \color{green}{\texttt{C++ (1985)}}^{*}\ar[ddrr]\ar[ddddddl] &amp; \texttt{Erlang (1986)}^{*}\ar@/_2pc/[ddddll] &amp; \texttt{Perl (1987)}\ar[ddlll]\ar[ddl] &amp; \color{green}{\textbf{Coq (1989)}}\ar@{~&gt;}@/_0.5pc/[ddddlll]\ar@{~&gt;}[ddddl] \\
              \\
              \texttt{Python (1990)} &amp; \color{brown}{\texttt{Haskell (1990)}}\ar[dd]\ar[ddl]\ar[ddrr] &amp; \color{brown}{\texttt{Ruby (1995)}} &amp; \color{red}{\texttt{Java (1995)}}^{*}\ar[ddl]|{*}\ar[ddlll]|{*} &amp; \color{red}{\texttt{Javascript (1995)}}^{*} &amp; \texttt{OCaml (1996)}\ar@/^0.1pc/[ddddlllll] \\
              \\
              \color{brown}{\texttt{Scala (2004)}} &amp; \texttt{Agda (2007)}\ar@/_2pc/[rr] &amp; \color{brown}{\texttt{Clojure (2007)}} &amp; \color{blue}{\texttt{Idris (2007)}} &amp; \color{red}{\texttt{Go (2009)}} \\
              \\
              \texttt{Rust (2010)}
              }
              \end{xy}
            
            $$
          </p>
          <p>
            $$
            \begin{matrix}
                \textbf{‚Ä¢} &amp; \textrm{A root language: significantly novel, with no significant predecessor} \\
                \color{red}{\bullet} &amp; \textrm{Unlikely to influence anything in the future, due to remarkably poor design} \\
                \color{brown}{\bullet} &amp; \textrm{Dying language, for varied reasons} \\
                \color{blue}{\bullet} &amp; \textrm{Toy language} \\
                \color{green}{\bullet} &amp; \textrm{Candidates for designing a future language} \\
                {}^{*} &amp; \textrm{Mature high-performance high-complexity compiler/runtime}
              \end{matrix}
            $$
          </p>
          <hr>
          <p>
            An FAQ follows.
          </p>
          <p>
            Why would someone pick C++ over Rust today?
          </p>
          <p>
            C++ templates are incredibly powerful, and with the introduction of compile-time expressions, vast portions of modern C++ programs are just compile-time tables. Examples like this make Rust look very tiny:
          </p>
          <pre><code>template &lt;size_t i, typename... Ts, typename CurTy&gt;
void recurseFillChildren(CurTy &amp;E)
{
  using PackTy = std::variant&lt;Ts...&gt;;
  using TyL = std::variant_alternative_t&lt;i - 1, PackTy&gt;;
  static_assert(std::is_same_v&lt;CurTy, TyL&gt;);
  using TyR = std::variant_alternative_t&lt;i, PackTy&gt;;

  for (i32 j = 0; j &lt; E.NChildren; ++j)
  {
    E.Children.push_back(miniParser&lt;TyR&gt;());
    if constexpr (i + 1 &lt; sizeof...(Ts))
      recurseFillChildren&lt;i + 1, Ts...&gt;(E.Children.back());
  }
};</code></pre>
          <p>
            Is there anything that Rust can do that C++ can't?
          </p>
          <p>
            Rust didn't restrict what macros can do as much as C++ did. As a result, it's possible to do more with them. The particular example of the Pest parser is especially enlightening:
          </p>
          <pre><code>#[derive(Parser)]
#[grammar = "grammar.pest"]</code></pre>
          <p>
            Essentially, "grammar.pest" is processed at compile-time, and you can use definitions parsed from it in your code. However, there are trade-offs; Rust's macros are very slow, and your compile-times blow up if you have recursive macros. <mark>std::embed</mark> in C++23 will probably do it right.
          </p>
          <p>
            Why is Haskell classified as a dying language?
          </p>
          <p>
            Haskell is pleasant to get started with, and write relatively simple programs in. In the 2010-2015 period, there was a lot of intellectual discourse and PL research around it. The high-brow crowd was obssessed with transactional memory, parser combinators, and lenses. Online resources were exploding: LYAH and CatProg enjoyed their bouts of popularity. Several people and companies invested in Haskell heavily in that period. The language is easy to get started with, and has a pleasant development experience for relatively simple programs. The problems started when codebases started growing in size and complexity.
          </p>
          <p>
            You either need to be able to interactively debug your program or prove that it is correct: in Haskell, you can't do either; the best you can do is to write some QuickCheck tests. Then there's Liquid Haskell that allows you to pepper your Haskell code with invariants that it will check using Z3. Unfortunately, it is very limited in what it can do: good luck checking your monadic combinator library with LH. Moreover, there are no tools to help you debug the most notorious kind of bug seen in a complicated codebase: memory blowups caused by laziness. It suffices to say that tooling is weak. In Atom, the Haskell addon was terrible, and even today, in VSCode, the Haskell extension is among the most buggy language plugins.
          </p>
          <p>
            There are <a href="https://gitlab.haskell.org/ghc/ghc/-/blob/a1f34d37b47826e86343e368a5c00f1a4b1f2bce/compiler/GHC/Driver/Session.hs#L3729-3876">over 120</a> language extensions, which can be turned on/off in each <mark>.hs</mark> file. The issue is that different extensions interact in subtle ways to produce bugs, and it's very difficult to tell if a new language extension will play well with the others (it often doesn't, until all the bugs are squashed, which can take a few years). The best case scenario plays out like this: GHC rejects your program, and suggests that you turn on some other language extensions; you turn them on, and you're left with a cryptic error message coming from a language extension you're not as familiar with; you spend the next N hours reading whatever little information is available about the more recent language extension, and decide to throw in the towel. The worst case plays out as follows: the typechecker hangs or crashes, and you're on the issue tracker searching for the issue; if you're lucky, you'll find a bug filed using 50~60% of the language extensions you used in your program, and you're not sure if it's the same issue; you file a new issue. In either case, your work has been halted.
          </p>
          <p>
            There is almost zero documentation on language extensions. Hell, you can't even find the list of available language extensions with some description on any wiki. Looking at the big picture: first, this is a poor way to do software development; as the number of language extensions increase, your testing burden increases exponentially. Second, the problem of having a good type system is already solved by a simple dependent type theory; you study the core, and every new feature is just a small delta that fits in nicely with the overall model. As opposed to having to read detailed papers on each new language extension. And yes, there's a good chance that very few people will be able to understand your code if you're using some esoteric extensions. In summary, language extensions are complicated hacks to compensate for the poverty of Haskell's type system.
          </p>
          <p>
            In practice, you'll be familar with ~20 language extensions, and use various combinations of them over and over again, so the problem might not seem as acute as a regular Haskell programmer. However, PL research has shifted away from Haskell for the most part, and the little that happens tends to be <a href="https://www.microsoft.com/en-us/research/uploads/prod/2019/03/ho-haskell-5c8bb4918a4de.pdf">unnecessarily complex nonsense</a> that never sees the light of day.
          </p>
          <p>
            Here's a sample of some simple Haskell code pieced together. I've intentionally left out examples using <mark>LinearTypes</mark>, because it's unfair to find faults with such a recent language feature.
          </p>
          <ol type="none" start="1">
            <li>
              What does the code mean? What is the intent?
            </li>
            <li>
              Can you specifically tell how each language extension was useful in the snippet?
            </li>
            <li>
              Guess what the code will do on GHC 8.10.1. What will an older version of GHC do?
            </li>
            <li>
              How many more language features are missing?
            </li>
          </ol>
          <pre><code>{-# LANGUAGE MagicHash #-}
{-# LANGUAGE TypeFamilies #-}
{-# LANGUAGE TypeInType #-}

import GHC.Exts

type family MatchInt (f :: Int) :: () where
  MatchInt ('I# _) = '()</code></pre>
          <pre><code>{-# LANGUAGE PolyKinds #-}
{-# LANGUAGE RankNTypes #-}

f = undefined :: (forall (a :: k) m. m a -&gt; Int) -&gt; Int</code></pre>
          <pre><code>{-# LANGUAGE PolyKinds #-}

data Proxy a = Proxy

class Foo (t :: k) where foo :: Proxy (a :: t)</code></pre>
          <pre><code>{-# LANGUAGE DataKinds              #-}
{-# LANGUAGE FlexibleContexts       #-}
{-# LANGUAGE PolyKinds              #-}
{-# LANGUAGE TypeFamilyDependencies #-}
{-# LANGUAGE TypeOperators, AllowAmbiguousTypes          #-}

type family Dim v

type family v `OfDim` (n :: Dim v) = r | r -&gt; n

(!*^) :: Dim m `OfDim` j -&gt; Dim m `OfDim` i
(!*^) = undefined</code></pre>
          <p>
            Doesn't Go feature a solid compiler/runtime?
          </p>
          <p>
            It does, but the author didn't feel that it was worthy of an asterisk, because the compiler is working with a really dumb language. Nevertheless, the GC and scheduler are praise-worthy, as is the overall experience with ultra-low compile-times.
          </p>
        </article></div>]]>
            </description>
            <link>https://artagnon.com/articles/pl</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663770</guid>
            <pubDate>Fri, 02 Oct 2020 15:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What We Learned by Closing a $4M Investment from Accel]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24663314">thread link</a>) | @hodgesrm
<br/>
October 2, 2020 | https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel | <a href="https://web.archive.org/web/*/https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	

	<p>I‚Äôm pleased to share the news that Altinity has raised a $4M seed investment from Accel. Dan Levine led the round. We are honored by Accel‚Äôs trust and delighted to work with Dan. We plan to use the investment to roll out our new <a href="https://altinity.com/cloud/">Altinity.Cloud platform</a> and to strengthen <a href="https://clickhouse.tech/">ClickHouse </a>into the best analytic database on the planet.&nbsp;</p><p>Dan was the first venture capitalist to contact us, as he tells in his <a href="http://www.accel.com/noteworthy/our-seed-in-altinity" target="_blank" rel="noreferrer noopener">blog article about the seed investment</a>. He was enthusiastic but also very patient.That was fortunate, because we then talked to 43 other VCs at greater or lesser length over the next year and a half. The count omits those who greeted our overtures with stony silence. In the end we were absolutely confident Dan and Accel were the right choice. At the same time, we learned from many others.</p><p>Looking back, it is apparent we did more than just collect a check from a great investment team. We also learned a number of valuable lessons about early stage venture investment.&nbsp; Many of these were not obvious, at least to me. In this article I will share what we learned, along with a spreadsheet we developed to help with investment math. I hope our account will be useful ‚Äî or at least entertaining!</p><p><h2 id="h-what-do-vcs-really-want">What do VCs really want?</h2>
</p><p>VC websites often sport brave slogans like ‚Äúwe are looking for bold entrepreneurs who will change the world.‚Äù What they are actually looking for, of course, is far more concrete: a big return on a speculative bet about a new business. The first thing we learned was how venture capital actually works and how we fit in.&nbsp;</p><p>Let‚Äôs start with where the money comes from and how it is managed. Venture capital firms operate one or more funds, which they use to make investments. Each venture capital firm has general partners who work for the company, decide where to invest, and take care of serving on boards and other duties required to supervise each investment.&nbsp; There is also another type of partner, known as a limited partner or LP. LPs can be wealthy individuals, pension funds, sovereign investment funds, you name it. They supply cash but have no role in making investment decisions. Here is a picture.&nbsp;</p><div><figure><img loading="lazy" width="954" height="368" src="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png" alt="" srcset="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png 954w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-300x116.png 300w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-768x296.png 768w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-600x231.png 600w" sizes="(max-width: 954px) 100vw, 954px" data-lazy-srcset="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png 954w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-300x116.png 300w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-768x296.png 768w, https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture-600x231.png 600w" data-lazy-src="https://altinity.com/wp-content/uploads/2020/09/What-we-learned-from-accel-blog-investment-fund-picture.png?is-pending-load=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
</div><p>In the first meeting with a new VC you typically hear about the current funds, how big they are, and other details like reserves for follow-on investments in promising companies. When you ask what payback they are seeking the most frequent answer is ‚Äúreturn the fund.‚Äù This is so common that I stopped writing it down unless the answer was something different. It means the investment in your company needs to pay out at the value of the entire fund, not just what the VC put into your company. The reason has to do with the mechanics of the funds.</p><p>Most startups fail or return money that does not come close to covering the investment. To provide a decent return to limited partners and VC general partners plus pay overhead, at least a couple of investments need to hit home runs and to pay off at full value of the fund. It‚Äôs basic math, but the numbers are big. Say a $400M fund invests $40M total for a 25% share of your startup, a typical target percentage. To return the fund means that the startup will have to exit for $1.6B ($400M = $1.6B * 25%). Grand slams like <a href="https://news.crunchbase.com/news/these-were-the-biggest-winners-in-snowflakes-record-busting-ipo" target="_blank" rel="noreferrer noopener">Snowflake</a> return far more and make the fund very successful.&nbsp;</p><p>At first it was disconcerting when A-list VC prospects baldly asked how we would get them an exit in the $1B+ range. Over time I developed empathy for this attitude. VC general partners have to make the math work or find another job. Meanwhile entrepreneurs need to have a problem that fits the pattern of investment or venture funding does not make a lot of sense. That‚Äôs the economic reality and has little to do with how individual VCs feel about you personally, or even about your business.&nbsp;</p><p>We needed to articulate to ourselves how we would win in a large market‚ÄìSQL data warehouses‚Äìfilled with a lot of savvy competitors like Amazon and Snowflake. The classic strategy is to create a <em><span>new</span> </em>market that did not previously exist, then become the leader. Anurag Gupta and his colleagues at Amazon put it brilliantly <a href="https://dl.acm.org/doi/10.1145/2723372.2742795" target="_blank" rel="noreferrer noopener">in a paper on Amazon Redshift</a>:&nbsp;</p><p><em>Our goal with Amazon Redshift was not to compete with other data warehousing engines, but to compete with non-consumption.&nbsp;</em></p><p>The unique differentiation of ClickHouse is that it is open source and runs anywhere: from public clouds down to Android phones. Any developer on the planet can download it and add high performance analytics to any application without sacrificing portability or scaling. That‚Äôs an enormous expansion of the market that will fuel innovation not just at the database level but will extend to new applications of big data as well as the tools and platforms to run them.&nbsp;</p><p>Here‚Äôs another key insight: it took months to be able to state that value proposition in three sentences. It‚Äôs like learning a new language ‚Äî anyone can learn to say hello but achieving fluency requires real work.&nbsp;</p><p>We did a lot of modeling to understand the growth trajectory needed to achieve the kind of revenue our predecessors are making. One of the conclusions was that we needed to build a great cloud platform for ClickHouse. It‚Äôs a tried-and-true way to build a successful business, especially for companies that manage data, and one that our customers have confirmed as a fruitful path to growth. We believe in the plan and it matches venture capital economics.&nbsp;</p><p><h2 id="h-vcs-work-off-a-thesis">VCs Work Off a Thesis</h2>
</p><p>I didn‚Äôt know a lot of early stage VCs when we began fund-raising, though like everyone I heard they were fine human beings worthy of acquaintance. The initial conversations were illuminating in one particular respect. Venture capitalists don‚Äôt necessarily know that much about specific technology or markets.&nbsp;</p><p>Here‚Äôs an example. My favorite demo for ClickHouse is the <a href="https://youtu.be/zDIK3Ej86GU" target="_blank" rel="noreferrer noopener">ClickHouse-fast demo</a> where I first run a query on data generated purely in memory followed by a similar query that accesses 1.3 billion rows of taxi data in slowish network-attached storage. I usually pause dramatically after the in-memory query to ask which query is going to be faster. Everybody knows access to memory is faster than storage, right?</p><p>Actually, in this demo it‚Äôs not. You have to be very careful to make an apples-to-apples comparison when comparing memory and storage access speeds. ClickHouse compresses stored data and parallelizes I/O extremely well. Reading from storage is therefore very fast. With ClickHouse it is not hard to choose in-memory queries that look similar but run far slower because they have a different execution path with less parallelization or other inefficiencies. It‚Äôs a subtle point that experienced database people understand, whereas VCs I talked to often got it wrong. (And then argued about it, too.)&nbsp;</p><p>This experience illustrates that deep dives on technology are not always the best way to evaluate early stage businesses. Good VCs tend to look for proxies that indicate signs of traction. In our case Dan Levine knew about ClickHouse because his other start-up investments used it. Dan pays really close attention to things they like. Dan picked up on ClickHouse earlier and more clearly than anyone we spoke to. The fact that we were an experienced team already selling services profitably was perhaps another useful signal. But Dan was also looking for more than just specific signals‚Äìhe was looking for a pattern related to data, backed by a solid team.&nbsp;</p><p>Over time, we found that the VCs who really picked up on our story had a thesis about the value of combining two things:&nbsp;</p><div><ul>
<li>Data ‚Äì Faster and more cost effective ways of analyzing large datasets are inherently valuable to enterprises.&nbsp;&nbsp;</li>
<li>Open source ‚Äì There are standard models for marketing and monetizing open source projects to build very large businesses</li>
</ul>
</div><p>VCs with these convictions tended to like what we were doing overall, though they often found specific things they didn‚Äôt like: open source community too small, too much competition, not the right team, already made a competing investment, etc. That said, we didn‚Äôt argue about the size of the market or whether open source was the right overall strategy to reach it.&nbsp;It helped that the original developers of <a href="https://en.wikipedia.org/wiki/ClickHouse">ClickHouse at Yandex</a> did an amazing job of open sourcing the code and starting a great community around it. </p><p>Not surprisingly, we learned that those same investors were precisely the people we wanted backing the company. Not only did we share key assumptions about the business, but they had funded such businesses before with successful outcomes. Because of that they could offer useful advice on big topics like strategy to build open source communities or workable business models.&nbsp; They could also connect us with outstanding people like Mike Olson of Cloudera (and many others) who had worked through similar problems and could help us see around corners.&nbsp;</p><p>Here‚Äôs a final insight that relates back to the technology point I made above. VCs can identify promising companies, but they can‚Äôt tell you how to run yours. As an entrepreneur you understand the technology, your customers, and what is feasible to achieve. We had a number of debates with potential investors about details of the business plan.</p><p>For example, many VCs favor pure cloud services, because the best ones experience explosive growth and high margins. However, a push-button service is not a complete solution, especially for complex enterprise products like databases. Altinity has been in business since 2017 and we have articulate users who say they want us to take care of running ClickHouse in the cloud. They also want application tools, new server features, training, support, and implementation help. Their problem is not just to deploy a database but to create applications that add value to their own business. If you help them do that you have a much more competitive business.&nbsp;</p><p>Our mission is to help any enterprise that uses ClickHouse. We provide everything customers need to be successful with ClickHouse, <em>including</em> a great cloud service. We also support the ClickHouse ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel">https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel</a></em></p>]]>
            </description>
            <link>https://altinity.com/blog/what-we-learned-by-closing-a-4m-investment-from-accel</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663314</guid>
            <pubDate>Fri, 02 Oct 2020 14:59:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BMW fined $18M for providing inaccurate retail sales information to investors]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 32 (<a href="https://news.ycombinator.com/item?id=24663027">thread link</a>) | @zachshefska
<br/>
October 2, 2020 | https://yourautoadvocate.com/guides/bmw-fraud/ | <a href="https://web.archive.org/web/*/https://yourautoadvocate.com/guides/bmw-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><iframe src="https://www.youtube.com/embed/MBe7PNfmvAw" frameborder="0" allowfullscreen=""></iframe></p><p>The Securities and Exchange Commission recently announced $18M in fines that BMW and two of their subsidiaries must pay for having provided misleading and inaccurate retail sales information to their investors.</p><p>The SEC report reads:</p><blockquote><p>According to the SEC‚Äôs order, from 2015 to 2019, BMW inflated its reported retail sales in the U.S., which helped BMW close the gap between its actual retail sales volume and internal targets and publicly maintain a leading retail sales position relative to other premium automotive companies. The order finds that BMW of North America LLC (BMW NA) maintained a reserve of unreported retail vehicle sales ‚Äî referred to internally as the ‚Äúbank‚Äù ‚Äî that it used to meet internal monthly sales targets without regard to when the underlying sales occurred. The order also finds that BMW NA paid dealers to inaccurately designate vehicles as demonstrators or loaners so that BMW would count them as having been sold to customers when they had not been. Additionally, the order finds that BMW NA improperly adjusted its retail sales reporting calendar in 2015 and 2017 to meet internal sales targets or bank excess retail sales for future use. As a result, according to the order, the information that BMW provided to investors in the bond offerings by BMW‚Äôs U.S. financing subsidiary, BMW US Capital LLC, and to credit rating agencies contained material misstatements and omissions regarding BMW‚Äôs U.S. retail vehicle sales.</p><cite><a href="https://www.sec.gov/news/press-release/2020-223" target="_blank" rel="noreferrer noopener">https://www.sec.gov/news/press-release/2020-223</a></cite></blockquote><p>After having spent 43 years in the car business (many of which with BMW North America), I can unequivocally say these practices are routine and commonplace within car dealerships. Fraudulent behavior like this is not limited to BMW. Every manufacturer I have ever worked for encourages this.</p><p>When I worked for Penske Automotive Group we were explicitly instructed not to fudge any numbers. If our BMW rep asked us to ‚Äúpad the numbers‚Äù one month, we didn‚Äôt. Penske didn‚Äôt want to participate in that type of activity. They were the exception to the rule.</p><p>As a dealer you have very little choice but to ‚Äúplay the game.‚Äù As I‚Äôve talked about in other videos and guides here on the blog, car dealers don‚Äôt make much of anything when they sell vehicles. Instead, <a href="https://yourautoadvocate.com/guides/how-do-car-dealerships-make-money/" target="_blank" rel="noreferrer noopener">they make their money from factory incentives and from selling finance and insurance products</a>.</p><p><iframe src="https://www.youtube.com/embed/RTYnhidJMe8" frameborder="0" allowfullscreen=""></iframe></p><p>With that in mind, it‚Äôs clear why dealers ‚Äúplay the game.‚Äù If you have a $250,000 incentive that is based on the number of cars you sell in any given month, and the person writing you that check (BMW) is encouraging you to ‚Äúfake‚Äù sales so that you can actually attain the bonus, what would you do? The answer is simple.</p><p>Car manufacturers are happy to pay out giant monthly bonuses to subsidize their dealers, but only if they hit certain sales volume thresholds. This is because manufacturers are then able to report better than expected sales volumes to their investors.</p><p>How many fraudulently reported vehicles are ‚Äúsold‚Äù in any given month? In any given month we would designate 15 Mini Coopers as ‚Äúsold,‚Äù even though they hadn‚Äôt been. In that same month we may have actually sold 35 or 40 vehicles. Each month, upwards of 20% of our ‚Äúsales‚Äù were fake.</p><p>It‚Äôs surprising to think that BMW was only fined $18M. Considering a nontrivial amount of their sold inventory is not actually sold, you would think the fine should be $180M instead of $18M.</p><p>Fiat Chrysler paid $40M in fines a few years ago for similar practices. Regardless of who it is, it‚Äôs clear that the fines aren‚Äôt enough to stop the fraudulent behavior.</p>
</div></div></div>]]>
            </description>
            <link>https://yourautoadvocate.com/guides/bmw-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24663027</guid>
            <pubDate>Fri, 02 Oct 2020 14:35:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache OpenWhisk is a truly portable Serverless Platform]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662975">thread link</a>) | @kiyanwang
<br/>
October 2, 2020 | https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/ | <a href="https://web.archive.org/web/*/https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apache OpenWhisk is a truly portable and multiplatform Serverless engine and it is available now on all the major clouds from multiple commercial vendors. Here is a Chess Engine running on:</p><ul><li><a href="https://whisk-chess.adobeioruntime.net/api/v1/web/default/chess">Adobe I/O</a></li><li><a href="https://eu-de.functions.appdomain.cloud/api/v1/web/a1d40f6b-e5e3-4f07-8f92-77b525392253/default/chess">IBM Cloud</a></li><li><a href="https://wka9bi13u3.apigw.ntruss.com/chess/chess/ZC2o7bFh0x/http">Naver</a></li><li><a href="https://apigcp.nimbella.io/api/v1/web/msciabar-zc3thebgxgh/default/chess">Nimbella</a></li></ul><p>And see below for instructions how to run it also locally and in any Kubernetes cluster, for example AWS EKS‚Ä¶</p><p><iframe src="https://www.youtube.com/embed/02Xezhf_j4U" allowfullscreen="" title="YouTube Video"></iframe></p><p>Apache OpenWhisk is a Serverless Cloud Platform, developed as an open source project at the Apache Software Foundations. It is similar to Amazon Lambda, Google Functions or Azure Functions. The main difference is that it is an Open Source project, it is offered by multiple commercial vendors, and it has a rich serverless programing model for composing functions into workflows.</p><p>Many vendors today offer cloud functions based on OpenWhisk, and it runs on all the major public clouds. However not all the vendors disclose where they run their services, so I will refer to the vendor and not to the cloud that runs it. It can also be installed on any Kubernetes cluster, so you can install in any cloud, either your private cloud or the public one you prefer.</p><p>In this article I am going to show that OpenWhisk is a truly portable serverless solution, and that you can write a single serverless application and then run it on multiple vendors.</p><p>To prove my point, I wrote an open source serverless application and ran it on all the OpenWhisk vendors I got access to. I also created a custom Kubernetes cluster and installed OpenWhisk on it to run my application.</p><p>The application is a chess engine, written in the Go programming language, and that includes backend and frontend. You can use it to play chess using a web interface, while the opponent is an AI algorithm running as a serverless function in OpenWhisk.</p><p>For testing and development you can use the Standalone OpenWhisk. It is a single node installation that can run in your machine and only requires <a href="https://docker.com/"><code>Docker</code></a> to run. You also need to download the <a href="https://github.com/apache/openwhisk-cli/releases/tag/1.0.0">OpenWhisk CLI tool <code>wsk</code></a> for your operating system in order to interact with OpenWhisk.</p><p>Once prerequisites are satisfied, you can start a local OpenWhisk with the following command:</p><div><pre><code data-lang="fallback">bash &lt;(curl -sL https://s.apache.org/openwhisk.sh)
</code></pre></div><p>The command will download a Docker image for standalone OpenWhisk and it will start it. It will also open the playground, that you can use to create and run a function on the fly from your browser.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/playground-ui.png" alt="Playground"></p><p>Once you have OpenWhisk up and running you can configure the <code>wsk</code> tool to access it. OpenWhisk access is protected by a key that you have to retrieve and use to configure <code>wsk</code>, as follows:</p><div><pre><code data-lang="fallback">AUTH=$(docker exec openwhisk wsk property get --auth | awk '{ print $3}')
wsk property set --auth $AUTH --apihost http://localhost:3233
</code></pre></div><p>Now let‚Äôs build our chess engine and use the local OpenWhisk to test it locally. The source code of the chess engine <a href="https://github.com/openwhisk-blog/whisk-chess">is available on GitHub</a>.</p><p>The code is based on a freely available chess engine called <a href="https://github.com/ChizhovVadim/CounterGo/pulls">CounterGo</a>. It is written in Go. I adapted it to run as a stateless serverless action, and I added a frontend in JavaScript, using the libraries <a href="https://chessboardjs.com/">Chessboardjs</a> and <a href="https://github.com/jhlywa/chess.js">chess.js</a>.</p><p>In order to build the action, you need common tools like <code>git</code>, <code>make</code> and <code>docker</code>. Once you have them you can download and build the sources with the commands:</p><div><pre><code data-lang="fallback">git clone https://github.com/openwhisk-blog/whisk-chess
cd whisk-chess
make
</code></pre></div><p>Note that you do not need a Go compiler to build the action, just Docker, as you can compile the action using the OpenWhisk Go runtime itself. The result is the file <code>chess.zip</code> containing a pre-compiled Go action ready to be deployed.</p><p>Once you have the action, you use the following command to deploy it in OpenWhisk:</p><div><pre><code data-lang="fallback">wsk action update chess chess.zip --kind go:1.11 --web true
</code></pre></div><p>Finally you can retrieve the URL of the action with the command:</p><div><pre><code data-lang="fallback">wsk action get chess --url
</code></pre></div><p>If you now type the URL in a browser you will see the user interface of our chess engine, a chessboard, and you can play chess against the computer.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/chess.png" alt="Chess"></p><p>Now let‚Äôs start deploying our chess in the services of the various vendors that offer OpenWhisk.</p><p><a href="https://nimbella.com/">Nimbella</a> offers a serverless solution based on OpenWhisk and focused on providing an ‚Äúawesome developer experience‚Äù.</p><p>I think it is appropriate to say that I work for Nimbella, but I am trying to be neutral in this article and offer a fair comparison of all the OpenWhisk vendors I am aware of.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/020.png" alt="Nimbella"></p><p>Nimbella uses its own CLI called <code>nim</code> for deployment. The Nimbella CLI was recently <a href="https://github.com/nimbella/nimbella-cli/">open sourced</a>. You need to sign-up and login to use their service. Once you are logged in, you can deploy our chess action and get an URL for it. The <code>nim login</code> command conveniently permits sign-up.
The CLI is available <a href="https://nimbella.io/downloads/nim/nim.html#install-the-nimbella-command-line-tool-nim">for download</a> for Mac OS, Windows and Linux.</p><div><pre><code data-lang="fallback">nim login
nim action update chess chess.zip --kind go:1.12 --web true
nim action get chess --url
</code></pre></div><p>It is possible to use the <code>wsk</code> CLI with Nimbella if one prefers it. You‚Äôll notice the command is identical here to the one shown earlier but replaced <code>wsk</code> with <code>nim</code>.</p><p><a href="https://apigcp.nimbella.io/api/v1/web/msciabar-zc3thebgxgh/default/chess">Follow this link to play chess on Nimbella</a>.</p><p>The IBM cloud was the original cloud offering OpenWhisk as a service.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/030.png" alt="IBM"></p><p>You need to download and install the <code>ibmcloud</code> CLI in order to deploy actions to IBM. There are also some requirements like downloading a plugin and to target a space; all the steps are explained on their website.</p><p>They offer a generous free tier for running functions. You need to register on their website to use a very large number of function invocations for free.</p><p>Once you downloaded the tool, the commands to deploy the chess engine and get an URL to run the action are:</p><div><pre><code data-lang="fallback">ibmcloud login -u "$IBMUSER" -p "$IBMPASS"
ibmcloud fn action update chess chess.zip --kind go:1.11
ibmcloud fn action get chess --url
</code></pre></div><p><a href="https://eu-de.functions.appdomain.cloud/api/v1/web/a1d40f6b-e5e3-4f07-8f92-77b525392253/default/chess">Follow this link to play Chess on IBM Cloud.</a></p><p>Naver is a Korean company, owner of the main search engine in the Korean language, but also offering cloud services. The Naver Cloud Platform uses OpenWhisk to implement cloud functions.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/040.png" alt="Naver"></p><p>Currently Naver does not offer a CLI to deploy actions, however I was told a CLI is actually under development. For now I deployed the chess action using their web interface.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/041.png" alt="Naver Deploy"></p><p><a href="https://wka9bi13u3.apigw.ntruss.com/chess/chess/ZC2o7bFh0x/http">Follow this link to play Chess on Naver.</a></p><p>Adobe has a serverless offering based on OpenWhisk too. It is called the <a href="https://www.adobe.io/apis/experienceplatform/runtime.html">Adobe I/O Runtime</a>.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/045.png" alt="Adobe I/O"></p><p>Adobe I/O Runtime currently supports only Node.js based runtimes, so if you pick them as your serverless function providers you have to write your serverless functions in JavaScript. However being based on OpenWhisk, it is possible to use other runtimes by request, and so we can also run our chess engine. I thank the team at Adobe for their kind support and help in deploying my action for demonstration purposes.</p><p><a href="https://whisk-chess.adobeioruntime.net/api/v1/web/default/chess">Follow this link to play Chess on Adobe I/O.</a></p><p>Finally, you can run OpenWhisk in any cluster supporting Kubernetes. For this purpose, I created an EKS cluster on AWS and installed OpenWhisk on it, then I deployed my chess application. I will show here how to do that quickly and easily.</p><p><img src="https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/053.png" alt="AWS"></p><p>You will need to create and configure an AWS account. I refer you to AWS documentation for information how to do this.</p><p>Once I created an account, I installed the <a href="https://eksctl.io/"><code>eksctl</code></a> tool that makes easy to create a Kubernetes cluster on AWS.</p><p>Also you need to install the <a href="https://helm.sh/"><code>helm</code></a> deployment tool and use it to actually install OpenWhisk. You can download the helm chart from GitHub and install OpenWhisk as follows:</p><div><pre><code data-lang="fallback">git clone https://github.com/apache/openwhisk-deploy-kube
cd openwhisk-deploy-kube/helm
</code></pre></div><p>Once everything is ready your can create a Kubernetes cluster and install OpenWhisk with just 3 commands:</p><div><pre><code data-lang="fallback">eksctl create cluster --name openwhisk
eksctl create nodegroup --cluster openwhisk --node-labels openwhisk-role=invoker
helm install --set whisk.ingress.type=LoadBalancer openwhisk ./openwhisk
</code></pre></div><p>The cluster creation will take a while. Once it is completed you will get your private OpenWhisk service running in AWS, and you can deploy your chess application to it.</p><p>You can use the <code>wsk</code> or <code>nim</code> CLIs to deploy to OpenWhisk. You have to retrieve the location of the Apache OpenWhisk entry point, and the authorization key and pass them to the CLI tool. The required commands using <code>nim</code> are:</p><div><pre><code data-lang="fallback">cd whisk-chess
APIHOST=$(kubectl  get svc | awk '/openwhisk-nginx/ { print $4}')
AUTH=$(cat openwhisk/values.yaml |  awk '/guest/ { print $2}' | tr -d '"')
nim auth login --apihost http://$APIHOST --auth $AUTH
</code></pre></div><p>It is important to note that we configured an insecure setup because we are accessing OpenWhisk over the unencrypted HTTP protocol.</p><p>In a real world setup you will need additional steps to setup an HTTPS endpoint with a certificate. You will find relevant details in the <a href="https://github.com/apache/openwhisk-deploy-kube">helm chart GitHub repository</a>.</p><p>Once you retrieved the API host and authentication key, you can deploy your chess app, and get the URL.</p><div><pre><code data-lang="fallback">nim action create chess chess.zip --web true --kind go:1.11
nim action get chess --url
</code></pre></div><p>I cannot provide a URL in this case as I a destroyed the cluster after testing, however, you can see the result in the image at the beginning of the paragraph.</p></div></div>]]>
            </description>
            <link>https://openwhisk.blog/post/advocate/openwhisk-portable-serverless/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662975</guid>
            <pubDate>Fri, 02 Oct 2020 14:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Boa: an experimental Javascript lexer, parser and compiler written in Rust]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24662756">thread link</a>) | @jayflux
<br/>
October 2, 2020 | https://boa-dev.github.io/2020/10/02/boa-release-10.html | <a href="https://web.archive.org/web/*/https://boa-dev.github.io/2020/10/02/boa-release-10.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>Boa is an experimental Javascript lexer, parser and compiler written in Rust. It has support for some of the language, can be embedded in Rust projects fairly easily and also used from the command line.
Boa also exists to serve as a Rust implementation of the EcmaScript specification, there will be areas where we can utilise Rust and its fantastic ecosystem to make a fast, concurrent and safe engine.</p>

<p>We have a long way to go, however v0.10 has been the biggest release to date, with 138 issues closed!</p>

<p>We have some highlights, but if you prefer to read the full changelog, you can do that <a href="https://github.com/boa-dev/boa/blob/master/CHANGELOG.md">here</a></p>

<h2 id="test262">Test262</h2>

<p>One question we‚Äôve been asked for a long time is ‚Äúhow conformant are you to the spec?‚Äù. It‚Äôs been tough to answer as we‚Äôve been unable to run against the official test suite.</p>

<p>Test262 is the official ECMAScript Test Suite and exists to provide conformance tests for the latest drafts of the Ecma specification. It is used for all engines, you can even run it in your <a href="https://bakkot.github.io/test262-web-runner/">browser</a>.<br>
Thanks to @Razican in v0.10 we now have a test harness that allows us to run it against Boa at any time.</p>

<p>This is a new crate inside the Boa repository that can parse through all of the tests (roughly 40,000 of them) in under 10 minutes and tell us how conformant we are.</p>

<p><img src="https://boa-dev.github.io/images/2020-10-02/test262-screenshot.png" alt="image"></p>

<p>Today Boa has <span>18</span>% conformity to the specification. We‚Äôll be keeping an eye on this number over the releases. We expect to achieve around 30% by 0.11 due to some of the fixes we‚Äôre adding which should pass a few thousand tests.</p>

<p>These are run via Github Actions against PRs and for our master branch so that we can keep track of where we are and if there are regressions.</p>

<h2 id="built-ins">Built-ins</h2>

<p>We‚Äôve added support for <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date"><code>Date</code></a>, <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Map"><code>Map</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol">well-known symbols</a>. Supporting Well-known symbols unblocks a lot of work around adding <code>@@iterators</code> to some of our global objects which is coming up in the next release.<br>
Both <code>Math</code> and <code>Number</code> have had their remaining methods implemented.</p>

<h2 id="lexer">Lexer</h2>

<p>The lexer has been rebuilt from scratch. Just like the old parser it was a single file before looping through and becoming unmaintainable. Today we‚Äôve reorganised it into separate modules which know how to lex certain areas. The new lexer <a href="https://github.com/boa-dev/boa/issues/294">now supports goal symbols</a> and can now tokenize with the correct context at any time.</p>

<h3 id="goal-symbols">Goal Symbols</h3>

<p>Our issue with goal symbols is explained by the V8 team:
<a href="https://v8.dev/blog/understanding-ecmascript-part-3#lexical-grammar">https://v8.dev/blog/understanding-ecmascript-part-3#lexical-grammar</a></p>

<p>Previously we weren‚Äôt distinguishing between the contexts where some input elements are permitted and some are not, so lexing <code>/</code> would yeild a <code>division</code> symbols when it should be a <code>RegularExpressionLiteral</code> for example. This change unblocked us being able to run Test262.</p>

<p>Performance wise it is much faster for larger files. The lexer is far more efficient at streaming tokens to the parser than previously so in some scenarios we have big gains.</p>

<p><em>You can see all the benchmarks <a href="https://boa-dev.github.io/boa/dev/bench/">here</a></em></p>

<h2 id="repl-syntax-highlighting">Repl syntax highlighting</h2>

<p>Syntax highlighting was added to the repl this release thanks to @HalidOdat<br>
Our repl is made possible due to the great work of <a href="https://github.com/kkawakam/rustyline">RustyLine</a></p>

<p><img src="https://boa-dev.github.io/images/2020-10-02/syntaxHighlighting.gif" alt="image"></p>

<h2 id="looking-forward">Looking forward</h2>

<p>There are plenty of fixes and performance changes still needed, we also hope to experiment with producing Bytecode from our AST in future. Test262 coverage will almost certainly increase, and we are polishing the public API for easier use when embedding into other Rust projects.</p>

<p>Thanks to all those who contributed to 0.10, you can see the names in the full changelog linked above.</p>

<p>You can checkout Boa via <a href="https://github.com/boa-dev/boa">Github</a> or on <a href="https://crates.io/crates/Boa">crates.io</a></p>

  </article>

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://boa-dev.github.io/2020/10/02/boa-release-10.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662756</guid>
            <pubDate>Fri, 02 Oct 2020 14:09:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Effective Ways to Market Yourself as a Developer]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24662671">thread link</a>) | @codersrank
<br/>
October 2, 2020 | https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/ | <a href="https://web.archive.org/web/*/https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


			
<p>Knowing Javascript inside and out or all the programming languages in the world won‚Äôt be enough to help you land a great job that pays incredibly well or secure those amazing opportunities that are hard to come by.</p>



<p>If you want to truly advance your career and succeed as a developer, you need to market yourself. Sure, coding is your passion and you‚Äôd rather bury yourself in it, but how would anyone know that you‚Äôre good at what you do or even discover you unless you put yourself out there?</p>



<p>When screening for developer positions, many companies pay attention to candidates who have active <a href="https://blog.codersrank.io/profile-2-0/" target="_blank" rel="noreferrer noopener">programmer profiles</a>‚Äîa blog, podcast, open-source contributions, YouTube channel, or a history of speaking at tech events‚Äîthat speaks to their abilities. They view developers with these achievements and experiences as more likely to be talented because their reputation suggests it.</p>



<p><a href="https://giphy.com/gifs/the-office-michael-scott-5B6PQ4lDOlbB6">via GIPHY</a></p>



<p>A little marketing can help you shine brightly in the eyes of potential employers. The last thing you want is to be just another candidate or resume when applying for a job. You need to find a way to stand out from the other stack of papers so that companies are pushed to invite you for an interview or make you an offer.</p>



<p>With effective marketing, you may not even have to go job hunting, opportunities will come knocking at your door. When you share your goals, skills, experiences, and knowledge about your field publicly, it helps to establish you as an expert. As such, companies will be happy to pay you a premium salary rather than hiring one of your seemingly less qualified counterparts.</p>



<p>Now that you understand how important marketing is and how it can enhance your reputation and turn you into a job magnet, we‚Äôre going to walk you through actionable steps you can take to successfully market yourself as a developer, stand out from the competition, get on recruiters‚Äô radars, and bag the job offer of your dreams.</p>



<p>We have ranked these steps according to how useful and important they can be in helping you market yourself and your skills effectively.</p>







<ol><li><a href="#portfolio">Build your portfolio</a></li><li><a href="#brand">Build a personal brand</a></li><li><a href="#codersrank">Register a profile on CodersRank</a></li><li><a href="#network">Network with fellow tech professionals</a></li><li><a href="#linkedin">Tidy up your LinkedIn profile</a></li></ol>



<p>Following these steps will help you enlarge your horizons and place your best foot forward so life-changing opportunities can find you. While other developers are scrambling to submit resumes and nail their technical interviews, you‚Äôll already be far ahead.</p>



<p>Let‚Äôs take an in-depth look into each of these steps and how you can use them to enhance your career as a software developer and go from chasing after the prize to becoming the prize.</p>



<h2 id="portfolio" data-amp-original-style="color:#50b0ba"><strong>1. Build your portfolio</strong></h2>



<p>As a developer, you know that you need to keep practicing and refining your skills. What you might not know is that you can use the assignments and projects you do to create a portfolio that showcases your expertise.</p>



<p>If you don‚Äôt already have a GitHub profile, start by creating one and start pushing code to it regularly, and make your experiments public. This is non-negotiable. GitHub is your <a href="https://blog.codersrank.io/the-evolution-of-the-most-popular-repositories-since-2012/" target="_blank" rel="noreferrer noopener">code repository</a> and it should be used to display all the code you‚Äôve written, projects you‚Äôve worked on, and other interesting code-related activities you‚Äôve been involved in.</p>



<p>Your GitHub account is basically your developer resume because it serves as proof of how well you can code. It says more about your skills than any CV or interview can. Contribute to as many open source libraries as you can. The more open source contributions you have the greater the value prospective employers will see in hiring you.</p>



<p>If you‚Äôd like to make valuable contributions to open source libraries, but you‚Äôre not sure how to go about submitting one, finding projects to contribute to, or even what kind of contributions you can make, check out these resources:</p>



<ul><li><a href="https://opensource.guide/how-to-contribute/" target="_blank" rel="noreferrer noopener">How to contribute to open source</a></li><li><a href="https://auth0.com/blog/a-first-timers-guide-to-an-open-source-project/" target="_blank" rel="noreferrer noopener">A first timer‚Äôs guide to an open source project</a></li><li><a href="https://rubygarage.org/blog/how-contribute-to-open-source-projects" target="_blank" rel="noreferrer noopener">How to contribute to open source projects</a></li></ul>



<p>It‚Äôs also important to have a portfolio website where potential employers can go to learn more about you, the work you‚Äôve done, and how your skills and experience can benefit their organization.</p>



<p>When building your portfolio, here are the things you‚Äôll want to pay attention to:</p>



<h3>Set up a professional site</h3>



<p>It makes sense for your domain to be in your name since this is a personal portfolio and people should be able to find it by simply entering your name into a search engine. Make sure you purchase the domain so that you can have full control over it and be able to migrate to a different web platform.</p>



<p>You cannot expect employers to take you seriously if you proclaim yourself to be a talented developer, but your website looks shabby and amateurish. You want anyone who stumbles on your site to be immediately impressed by the layout and design even before they go through any of your pages.</p>



<figure><amp-img src="https://file.mockplus.com/image/2019/07/75f1f76e-eeb4-4166-8cf1-3500d6256538.png" alt="" object-fit="contain" width="1170" height="400" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://file.mockplus.com/image/2019/07/75f1f76e-eeb4-4166-8cf1-3500d6256538.png" alt="" width="1170" height="400" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzQwMCcgd2lkdGg9JzExNzAnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption><a href="https://www.mockplus.com/blog/post/web-developer-portfolio" target="_blank" rel="noreferrer noopener">Source</a></figcaption></figure>



<p>Your site should be easy to navigate and visually pleasing. You can decide to code your website from scratch and display it as one of the projects in your portfolio or create one using your preferred web platform. Whatever you choose, remember to keep it simple.</p>



<p>Include a well-designed logo that communicates your values and serves as an accurate representation of who you are and what you do.</p>



<p>Keep in mind that a <strong>personal website is going to mean different things to a back end developer and a front end developer</strong> since they‚Äôre different fields. Whichever faction you belong to, you just need to find an approach to your website design and presentation that best represents who you are and what you do.</p>



<p>If you‚Äôre a newbie developer, this <a href="https://mikkegoes.com/portfolio-site-on-wordpress/" target="_blank" rel="noreferrer noopener">detailed step-by-step guide</a> will help you build a great-looking portfolio website from scratch to showcase your skills and value to potential employers and help you get hired faster. It covers everything from registering a domain name to choosing a reliable website, creating eye-catching home and about me pages, building contact forms, and more.</p>



<p>Check out these <a href="https://www.springboard.com/blog/programmer-portfolio/" target="_blank" rel="noreferrer noopener">7 best practices for creating a programming portfolio website</a> that stands out. The article also contains tips on mistakes to avoid when building your website and what recruiters look for in a developer portfolio, as well as stunning website examples that are sure to get your creativity flowing.</p>



<h3>Showcase your work</h3>



<p><a href="https://giphy.com/gifs/kodewithklossy-coding-karlie-kloss-kwk-ZG719ozZxGuThHBckn">via GIPHY</a></p>



<p>The point of having an online portfolio is to highlight the work you‚Äôve done in the past and the accomplishments you‚Äôre proud of. If you don‚Äôt have any concrete work experience yet, you can start by creating a single web page and adding links to other online profiles you have like your social media and GitHub account.</p>



<p>When you write articles, host webinars, give talks, contribute to open source libraries, create tutorial videos, or work on anything interesting, update your site accordingly. Explain what each project is about, why it‚Äôs important, and when it was done.</p>



<p>Don‚Äôt just go on and on about the agile methodologies, frameworks, and programming languages that you know. Display that project you built using Javascript, PHP, CSS, or whatever tech stacks you say you‚Äôre familiar with. </p>



<p>Let visitors see the skills you possess in action and how you can use these skills to grow their business. This will establish your expertise, credibility, and trustworthiness.</p>



<h3>Share your story</h3>



<p>Don‚Äôt be shy about being yourself. Let your personality shine through. Describe yourself as honestly as you can. What is it that makes you special? What struggles, failures, or challenges have you encountered over the course of your career? Employers don‚Äôt want to hire mindless code monkeys, but people they can relate to.</p>



<h3>Include your contact details</h3>



<p>Give visitors and potential employers a way to reach you. Add your email address and phone number or create a simple contact form they can fill out. If they have to jump through hoops to find your contact information, you might miss out on many good opportunities.</p>



<h2 id="brand" data-amp-original-style="color:#50b0ba"><strong>2. Build a personal brand</strong></h2>



<p>Personal branding is simply a way of making yourself known for something. As a programmer, you not only want to be competent in your field, you also want people to see you that way. Thanks to the internet, it‚Äôs easier than ever to create a brand around yourself.</p>



<p>Ask yourself what you want to be known for? Who are you and what do you want to represent? What is your core message? What do you want people to think of when they see or hear your name? Once you have this figured out, start putting this message out there and making sure it‚Äôs reflected in everything you do.</p>



<p>Here are some of the ways you can create a strong personal brand and actively promote yourself:</p>



<h3>Clean up assets related to communication</h3>



<p>Come up with a logo for your brand if you don‚Äôt already have one. It should be something simple, eye-catching, and an accurate representation of who you are and what you‚Äôre about. Don‚Äôt go changing your logo every week or so. Find one that works for you and use it everywhere.</p>



<p>Get professional headshots taken to use as cover images for your online profiles. Go through your social media accounts and public forums and delete any inappropriate messages or comments that don‚Äôt align with the image you want to project or reflect badly on you as a person.</p>



<h3>Start a blog</h3>



<p>A blog can be a wonderful way to showcase your skills as a developer, become well-known in your industry, and attract potential clients or employers.</p>



<p>Your blog doesn‚Äôt have to have tens of thousands of readers, but you do need to build a decent audience. You can do this by sharing useful information that adds some kind of value to your readers‚Äô lives. Talk about your professional journey, the challenges you‚Äôve faced along the way, and how you overcame them.</p>



<p>Teach people how to solve problems. Show examples of work you‚Äôve done in the past to help junior developers find their way and build themselves up. Think of something you‚Äôve struggled with that you found a solution ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/">https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/</a></em></p>]]>
            </description>
            <link>https://blog.codersrank.io/the-5-most-effective-ways-to-market-yourself-as-a-developer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662671</guid>
            <pubDate>Fri, 02 Oct 2020 14:00:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust lets us monitor 30k API calls/min]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24662530">thread link</a>) | @jerodsanto
<br/>
October 2, 2020 | https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/ | <a href="https://web.archive.org/web/*/https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
		<p>At Bearer, we are a polyglot engineering team. Both in spoken languages and programming languages. Our stack is made up of services written in Node.js, Ruby, Elixir, and a handful of others in addition to all the languages our agent library supports. Like most teams, we balance using the right tool for the job with using the right tool for the time. Recently, we reached a limitation in one of our services that led us to transition that service from Node.js to Rust. This post goes into some of the details that caused the need to change languages, as well as some of the decisions we made along the way.</p><h2 id="a-bit-of-context"><strong>A bit of context</strong></h2><p>We are building a solution to help developers monitor their APIs. Every time a customer‚Äôs application calls an API, a log gets sent to us where we monitor and analyze it.</p><p>At the time of the issue, we were processing an average of 30k API calls per minute. That's a lot of API calls made across all our customers. We split the process into two key parts: Log ingestion and log processing.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion-service---node.jpg" alt="Original architecture with Node.js" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion-service---node.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion-service---node.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion-service---node.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion-service---node.jpg 2400w"></figure><p>We originally built the ingestion service in Node.js. It would receive the logs, communicate with an elixir service to check customer access rights, check rate limits using Redis, and then send the log to CloudWatch. There, it would trigger an event to tell our processing worker to take over.</p><p>We capture information about the API call, including the payloads (both the request and response) of every call sent from a user's application. These are currently limited to 1MB, but that is still a large amount of data to process. We send and process everything asynchronously and the goal is to make the information available to the end-user as fast as possible.</p><p>We hosted everything on AWS Fargate, a serverless management solution for Elastic Container Service (ECS), and set it to autoscale after 4000 req/min. Everything was great! Then, the invoice came üò±.</p><p>AWS invoices based on CloudWatch storage. The more you store, the more you pay.</p><p>Fortunately, we had a backup plan.</p><h2 id="kinesis-to-the-rescue"><strong>Kinesis to the rescue?</strong></h2><p>Instead of sending the logs to CloudWatch, we would use<a href="https://aws.amazon.com/kinesis/data-firehose/"> Kinesis Firehose</a>. Kinesis Firehose is basically a Kafka equivalent provided by AWS. It allows us to deliver a data stream in a reliable way to several destinations. With very few updates to our log processing worker, we were able to ingest logs from both CloudWatch and Kinesis Firehose. With this change, daily costs would drop to about 0.6% of what they were before.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---node_kinesis.jpg" alt="Architecture after adding Kenesis" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---node_kinesis.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---node_kinesis.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---node_kinesis.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---node_kinesis.jpg 2400w"></figure><p>The updated service now passed the log data through Kinesis and into s3 which triggers the worker to take over with the processing task. We rolled the change out and everything was back to normal... or we thought. Soon after, we started to notice some anomalies on our monitoring dashboard.</p><p><strong>We were Garbage Collecting</strong>, a lot. Garbage collection (GC) is a way for some languages to automatically free up memory that is no longer in use. When that happens, the program pauses. This is known as a <em>GC pause</em>. The more writes you make to memory, the more garbage collection needs to happen and as a result, the pause time increases. For our service, these pauses were growing high enough that they caused the servers to restart and put stress on the CPU. When this happens, it can look like the server is down‚Äîbecause it temporarily is‚Äîand our customers started to see 5xx errors for roughly 6% of the logs our agent was trying to ingest.</p><p>Below we can see the pause time and pause frequency of the garbage collection:</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/gc-pause.jpg" alt="GC pause and frequency charts" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/gc-pause.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/gc-pause.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/gc-pause.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/gc-pause.jpg 2400w"></figure><p>In some instances, the pause time breached <strong>4 seconds</strong> (as shown on the left), with up to <strong>400 pauses per minute</strong> (as shown on the right) across our instances.</p><p>After some more research, we appeared to be another victim of a<a href="https://github.com/aws/aws-sdk-js/issues/329"> memory leak in the AWS Javascript SDK</a>. We tried increasing the resource allocations to extreme amounts, like autoscaling after 1000 req/min, but nothing worked.</p><h2 id="possible-solutions"><strong>Possible solutions</strong></h2><p>With our backup plan no longer an option, we moved on to new solutions. First, we looked at those with the easiest transition path.</p><h3 id="elixir"><strong>Elixir</strong></h3><p>As mentioned earlier, we are checking the customer access rights using an Elixir service. This service is private and only accessible from within our Virtual Private Cloud (VPC). We have never experienced any scalability issues with this service and most of the logic was already there. We could simply send the logs to Kinesis from within this service and skip over the Node.js service layer. We decided it was worth a try.</p><p>We developed the missing parts and tested it. It was better, but still not great. Our benchmarks showed that there were still high levels of Garbage Collecting, and we were still returning 5xx to our users when consuming the logs. At this point, the heavy load triggered a <a href="https://github.com/benoitc/hackney/issues/594">(now resolved) issue</a> with one of our elixir dependencies.</p><h3 id="go"><strong>Go</strong></h3><p>We considered Golang as well. It would have been a good candidate, but in the end, it is another Garbage Collected Language. While likely more efficient than our previous implementation, as we scale there is a high chance we'd run into similar problems. With these limitations in mind, we needed a better option.</p><h2 id="re-architecting-with-rust-at-the-core"><strong>Re-architecting with Rust at the core</strong></h2><p>In both our original implementation and our backup, the core issue remained the same: garbage collection. The solution was to move to a language with better memory management and no garbage collection. Enter Rust.</p><p>Rust isn't a garbage-collected language. Instead, it relies on a concept called <em>ownership</em>.</p><blockquote>Ownership is Rust‚Äôs most unique feature, and it enables Rust to make memory safety guarantees without needing a garbage collector. <br>‚Äî <a href="https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html">The Rust Book</a></blockquote><p>Ownership is the concept that often makes Rust difficult to learn and write, but also what makes it so well suited for situations like ours. Each value in Rust has a single owner variable and as a result a single point of allocation in memory. Once that variable goes out of scope the memory is immediately returned.</p><p>Since the code required to ingest the logs is quite small, we decided to give it a try. To test this we addressed the very thing that we had issues with‚Äîsending large amounts of data to Kinesis.</p><p>Our first benchmarks proved to be very successful.</p><p>From that point, we were pretty confident that Rust could be the answer and we decided to flesh out the prototype into a production-ready application.</p><p>Over the course of these experiments, rather than directly replacing the original Node.js service with Rust, we restructured much of the architecture surrounding log ingestion. The core of the new service is an <a href="https://www.envoyproxy.io/">Envoy</a> proxy with the Rust application as a sidecar.</p><p>Now, when the Bearer Agent in a user's application sends log data to Bearer, it goes into the Envoy proxy. Envoy looks at the request and communicates with Redis to check things like rate limits, authorization details, and usage quotas. Next, the Rust application running alongside Envoy prepares the log data and passes it through Kinesis into an s3 bucket for storage. S3 then triggers our worker to fetch and process the data so Elastic Search can index it. At this point, our users can access the data in our dashboard.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/Log-ingestion---rust.jpg" alt="Diagram of new rust service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/Log-ingestion---rust.jpg 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/Log-ingestion---rust.jpg 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/Log-ingestion---rust.jpg 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/Log-ingestion---rust.jpg 2400w"></figure><p>What we found was that with fewer‚Äîand smaller‚Äîservers, we are able to process even more data without any of the earlier issues.</p><p>If we look at the latency numbers for the Node.js service, we can see peaks with an average response time nearing 1700ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/before-latency.png" alt="Latency with original Node.js service" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/before-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/before-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/before-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/before-latency.png 2400w"></figure><p>With the Rust service implementation, the latency dropped to below 90ms, even at its highest peak, keeping the average response time below 40ms.</p><figure><img src="https://blog.bearer.sh/content/images/2020/06/after-latency.png" alt="Latency after re-architecture" srcset="https://blog.bearer.sh/content/images/size/w600/2020/06/after-latency.png 600w, https://blog.bearer.sh/content/images/size/w1000/2020/06/after-latency.png 1000w, https://blog.bearer.sh/content/images/size/w1600/2020/06/after-latency.png 1600w, https://blog.bearer.sh/content/images/size/w2400/2020/06/after-latency.png 2400w"></figure><p>The original Node.js application used about 1.5GB of memory at any given time, while the CPUs ran at around 150% load. The new Rust service used about 100MB of memory and only 2.5% of CPU load.</p><h2 id="conclusion"><strong>Conclusion</strong></h2><p>As with most startups, we move fast. Sometimes the best solution at the time isn't the best solution forever. This was the case with Node.js. It allowed us to move forward, but as we grew we also outgrew it. As we started to handle more and more requests, we needed to make our infrastructure evolve to address the new requirements. While this process started with a fix that merely replaced Node.js with Rust, it led to a rethinking of our log ingestion service as a whole.</p><p>We still use a variety of languages throughout our stack, including Node.js, but will now consider Rust for new services where it makes sense.<br></p>
	</section></div>]]>
            </description>
            <link>https://blog.bearer.sh/how-rust-lets-us-monitor-30k-api-calls-min/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662530</guid>
            <pubDate>Fri, 02 Oct 2020 13:47:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One function is all you need for ML Experiments]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24662085">thread link</a>) | @LexSiga
<br/>
October 2, 2020 | https://www.logicalclocks.com/blog/hopsworks-ml-experiments | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/hopsworks-ml-experiments">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Hopsworks provides support for machine learning (ML) experiments. That is, it can automatically track the artifacts, graphs, performance, logs, metadata, and dependencies of your ML programs.Many of you already know about platforms like <a href="https://mlflow.org/">MLflow</a>, so why should you read about Hopsworks Experiments?&nbsp; Because you do not have to rewrite your TensorFlow/PyTorch/Scikit-learn programs to get <strong>tracking and distributed ML for free</strong>, and TensorBoard comes built-in. We discuss how Hopsworks uniquely supports implicit provenance to transparently create metadata and how it is combined with the oblivious training function to make your training distribution transparent.&nbsp;</p><h2>Hopsworks Introduction</h2><p>Hopsworks is a single platform for both data science and data engineering that is available as both an <a href="http://github.com/logicalclocks/hopsworks">open-source platform</a> and a <a href="http://www.hopsworks.ai/">SaaS platform</a>, including a built-in <a href="https://www.logicalclocks.com/hopsworks-featurestore">feature store</a>. You can train models on GPUs at scale, easily install any Python libraries you want using pip/conda, run Jupyter notebooks as jobs, put those jobs in Airflow pipelines, and even write (Py)Spark or Flink applications that run at scale.&nbsp;</p><p>As a development environment, Hopsworks provides a central, collaborative development environment that enables machine learning teams to easily share results and experiments with teammates or generate reports for project stakeholders. All resources have strong security, data governance, backup and high availability support in Hopsworks, while assets are stored in a single distributed file system (with data stored on S3 in the cloud).<br></p><figure id="w-node-a0d33d55738e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f74366329e691163a9537f8_mT5Xl3PGQNailTwXRoPhMMlEZePoa3PjlnagKaWj7mJxckcqP1SfcSbkOS3P-adIEnIq7kURxZ-TJ4ypWTt7yw94d_vqkB9o2FMTUrosMB8Pnxz0pPYkehYlOoJySGBdjPuDNQ7I.gif" alt=""></p><figcaption>A Hopsworks ML experiment stores information about your ML training run: logs, images, metrics of interest (accuracy, loss), the program used to train the model, its input training data, and the conda dependencies used. Optional outputs are hyperparameters, a TensorBoard, and a Spark history server.</figcaption></figure><figure id="w-node-06188dbd9c79-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743664aeafc406b94b027c_hraL3X_VAEzOtdesnelgqqb4FQcVGC8Q6J0-KQM0UPGGQxgU_TlMb_-LIZuMOszzdZIhxEZogwxlSSfOMdZvcAIgRlLZzoNg2dLmoPUSrNWyK0CABpAglOV9q9SqfogrRxoO6k29.gif" alt=""></p><figcaption>The logs of each hyperparameter trial are retrieved by clicking on its log, and TensorBoard visualizes the different trials results. The TensorBoard HParams plugin is also available to drill down further on the trials.</figcaption></figure><p>When you run a Python or PySpark application on the Hopsworks platform, it can create an<strong> experiment</strong> that includes both the traditional information a program generates (results, logs, errors) as well as ML-specific information to help track, debug, and reproduce your program and its inputs and outputs:</p><ul role="list"><li><strong>hyperparameters</strong>: parameters for training runs that are not updated by the ML programs themselves;&nbsp;</li><li><strong>metrics</strong>: the loss or accuracy of the model(s) trained in this experiment;</li><li><strong>program artifacts</strong>: <em>python/pyspark/airflow</em> <em>programs, </em>and their <em>conda environments</em>;</li><li><strong>model artifacts</strong>: serialized <em>model objects,</em> <em>model schemas</em>, and <em>model checkpoints</em>;</li><li><strong>executions</strong>: information to be able to re-execute the experiment, including parameters, versioned features for input, output files,&nbsp; etc;&nbsp;</li><li><strong>versioned features</strong>: to be able to reproduce an experiment, we need the exact training/test data from the run and how it was created from the feature store;</li><li><strong>visualizations</strong>: images generated during training and score. Also use TensorBoard to visualize training runs - Hopsworks aggregates results from all workers transparently;</li><li><strong>logs (for debugging)</strong>: model weights, gradients, losses, optimizer state;</li><li><strong>custom metadata</strong>: tag experiments and free-text search for them, govern experiments (label as ‚ÄòPII‚Äô, ‚Äòdata-retention-period‚Äô, etc), and reproduce training runs.</li></ul><figure id="w-node-55f328a117c2-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f748ce6a667fe73eb582948_Screenshot%202020-09-30%20at%2015.48.58.png" loading="lazy" alt=""></p></figure><h2>Experiment Tracking and Distributed ML in One Library</h2><figure id="w-node-be7859ba57d5-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5ef49c1e473b2c283eb616aa_nXpYXacWzP67N5MmHnhldoZJw6qVoDwpBnTd3JQzx9nFuX9_FVm-fmWztjYeLdun5BI83RGOdD1ibvFFWBHUCvQGtbenUY1f6haaE58VP5aAHHJOSWpf0P8FJkfPuE5JMAfMlcOk.png" alt=""></p></figure><p>
    -- CODE language-bash --
def train(data_path, max_depth, min_child_weight, estimators): 
    X_train, X_test, y_train, y_test = build_data(..)
    ...
    print("hello world") # monkeypatched - prints in notebook
    ...
    model.fit(X_train, y_train) # auto-logging
    ...
    hops.export_model(model, "tensorflow",..,model_name)
    ...
    # create local files ‚Äòlogile.txt‚Äô, ‚Äòdiagram.png‚Äô 
    return {'accuracy': accuracy, 'loss': loss, 'logfile':
       'logfile.txt', 'diagram': 'diagram.png'} # track dict

from maggy import experiment
experiment.lagom(train, name="My Experiment", ...) 

# To launch as a distributed ML HParam Tuning job:
# sp=Searchspace(max_depth=('INTEGER',[2,8]),min_child_weight
# =('INTEGER', [2, 8]), )
# experiment.lagom(train, name=‚ÄúHP, optimizer='randomsearch',                          
# direction='max', num_trials=15,)
</p><p>Platforms that support experiment tracking require the user to refactor their training code in a function or some explicit scope (such as ‚Äúwith ‚Ä¶ as xx:‚Äù in MLFlow, see Appendix A) to identify when an experiment begins and when an experiment ends. In Hopsworks, we require the developer to write their training code inside a function.&nbsp;</p><p>We call this Python function an <em>oblivious training function</em> because the function is oblivious of whether it is being run on a Python kernel in a Jupyter notebook or on many workers in a cluster, see our <a href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy">blog </a>and <a href="https://www.logicalclocks.com/blog/unifying-single-host-and-distributed-machine-learning-with-maggy">Spark/AI summit talk</a> for details. That is, you write your training code once and reuse the same function when training a small model on your laptop or when performing hyperparameter tuning or distributed training on a large cluster of GPUs or CPUs.</p><p>We double down on this ‚Äúwrapper‚Äù Python function by also using it to start/stop experiment tracking. Experiment tracking and distribution transparency in a single function, nice!&nbsp;</p><p>In Hopsworks, the <a href="https://github.com/logicalclocks/maggy">Maggy</a> library runs experiments, see code snippet above. As you can see, the only code changes a user needed compared to a best-practice TensorFlow program are:&nbsp;<br></p><ol role="list"><li>factor the training code in a user-defined function (<strong>def train(..):</strong>);</li><li>return a Python dict containing the results, images, and files that the user wants to be tracked for the experiment and accessible later in the Experiments UI; and</li><li>invoke the training function using the <em>experiment.lagom</em> function.<br></li></ol><p>The hyperparameters can be fixed for a single execution run, or as shown in the last 4 lines of the code snippet, you can execute the <em>train function </em>as a distributed hyperparameter tuning job across many workers in parallel (with GPUs, if needed).&nbsp;</p><p>Hopsworks will automatically:</p><ul role="list"><li>track all parameters of the train function as hyperparameters for this experiment,&nbsp;</li><li>auto-log using Keras callbacks in model.fit;</li><li>create a versioned directory in HopsFS, where a copy of the program, its conda environment, and all logs from all workers are aggregated;</li><li>track all provenance information for this application - input data from HopsFS used in this experiment (train/test datasets from the Feature Store), and all output artifacts (models, model checkpoints, application logs);</li><li>redirect all print statements executed in workers to the Jupyter notebook cell for easier debugging (see GIF below - each print statement is prefixed by the worker ID).<br></li></ul><figure id="w-node-756fb7ca0b23-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f74366291399a79d18af461_4BATblXBajOTlBXREg6utXoqcRgymvySZx03Hh_JeYvjJ7YLGzxYpnUgMwCvHaNxMFgj_XepZ23xJh3QFnfhHsAetRlt24IkRw4BI8R4Wo5gaQLkVuuIRRbE8CK7swOEJaa-Lm-k.gif" alt=""></p><figcaption>In Hopsworks, logs from workers can be printed in your Jupyter notebook during training. Take that Databricks!</figcaption></figure><h2>TensorBoard support</h2><p>
    -- CODE language-bash --
    
    def train():
    from maggy import tensorboard
    ...
    model.fit(.., callbacks=[TensorBoard(log_dir=tensorboard.logdir(),..)], ...)
</p><p>TensorBoard is arguably the most common and powerful tool used to visualize, profile and debug machine learning experiments. Hopsworks Experiments integrates seamlessly with TensorBoard. Inside the training function, the data scientist can simply import the <em>tensorboard</em> python<em> </em>module and get the folder location to write all the TensorBoard files. The content of the folder is then collected from each Executor and placed in the experiment directory in HopsFS. As TensorBoard supports showing multiple experiment runs in the same graph, visualizing and comparing multiple hyperparameter combinations becomes as simple as starting the TensorBoard integrated in the Experiments service. By default, Tensorboard is configured with useful plugins such as HParam, Profiler, and Debugging.&nbsp;</p><h3>Profiling and debugging</h3><p>Hopsworks 1.4.0 comes with TensorFlow 2.3, which includes the TensorFlow profiler. A new long-awaited feature that finally allows users to profile model training to identify bottlenecks in the training process such as slow data loading or poor operation placement in CPU + GPU configurations.&nbsp;</p><p>TensorFlow 2.3 also includes Debugger V2, making it easy to find model issues such as NaN which are non-trivial to find the root cause of in complex models.<br></p><figure id="w-node-821b5c19e74e-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743661e73aacd6dc310040_Rywm-fmUfHouqW1zVdYsZ88LvtAYDvCZPpze3hHJeENCBjPVPkkpy_J-2bescj5Z-Xlb7A7DNpmNws1H4lsmUsuOpLROLO_S16jFM_CI-6JdACYY5Rp3Q3yYVMfkecV7aK7ECsf_.png" alt=""></p></figure><figure id="w-node-fc6081bc518f-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743662849afea39f14cb69_S0v-cuc6N5MT4gsC3KUBFa3dQi7ZZBEaF9w684FzTrmXH4FPHkDEFCaMy2ThIpmSHDHSY-vmXCvXyDVrMVS_FYy3vnODkL8uXcHrm4uIlNjhNHHhsxoMghDrFfX_Yn_eVe1eYBbE.png" alt=""></p></figure><h2>Model Registry</h2><figure id="w-node-6cad6e721c68-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f743662ec097905b0778b6b_KcTuR12rSnRVQSSDh-eLxqM0ad3eAXSGCkehOJ8ik2BPfnohgCfudLLx7HkUIk3DKfTTxz-DzRwlJ7OAYU0eafq0bwSN2tYy7dt_rnOeth550yYPqa-esKRO6uGREvB1C4iNjk3l.png" alt=""></p></figure><p>In the training code models may be exported and saved to HopsFS. Using the <em>model </em>python module in the <a href="https://hops-py.logicalclocks.com/">hops library</a>, it is easy to version and attach meaningful metadata to models to reflect the performance of a given model version.&nbsp;</p><p>The Hopsworks Model Registry, is a service where all models are listed in addition to useful information such as which user created the model, different versions, time of creation and evaluation metrics such as accuracy.&nbsp;</p><p>The Model Registry provides functionality to filter based on the model name, version number and the user that exported the model. Furthermore the evaluation metrics of model versions can be sorted in the UI to find the best version for a given model.&nbsp;</p><p>In the Model Registry UI, you can also navigate to the experiment used to train the model, and from there to the train/test data used to train the model, and from there to the features in the feature store used to create the train/test data. Thanks, provenance!<br></p><h3>Exporting a model</h3><p>A model can be exported programmatically by using the <em>export</em> function in the <em>model</em> module. Prior to exporting the model, the experiment needs to have written a model to a folder or to a path on HopsFS. Then that path is supplied to the function along with the name of the model and the evaluation metrics that should be attached. The <em>export</em> call will upload the contents of the folder to your Models dataset and it will also appear in the Model Registry with an incrementing version number for each export.</p><p>
    -- CODE language-bash --
    from hops import model

# local path to directory containing model (e.g. .pb or .pk) 
path = os.getcwd() + ‚Äú/model_dir‚Äù

# uploads path to the model repository, metadata is a dict of metrics</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/hopsworks-ml-experiments">https://www.logicalclocks.com/blog/hopsworks-ml-experiments</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/hopsworks-ml-experiments</link>
            <guid isPermaLink="false">hacker-news-small-sites-24662085</guid>
            <pubDate>Fri, 02 Oct 2020 12:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Fistful of States: More State Machine Patterns in Rust]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24661395">thread link</a>) | @lukastyrychtr
<br/>
October 2, 2020 | https://deislabs.io/posts/a-fistful-of-states/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/a-fistful-of-states/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

<p>Earlier this year, DeisLabs released Krustlet, a project to implement Kubelet
in Rust. <sup id="fnref:Fisher"><a href="#fn:Fisher">1</a></sup> <sup id="fnref:Squillace"><a href="#fn:Squillace">2</a></sup> Kubelet is the component of Kubernetes that
runs on each node which is assigned Pods by the control plane and runs them on
its node. Krustlet defines a flexible API in the <code>kubelet</code> crate, which allows
developers to build Kubelets to run new types of workloads. The project
includes two such examples, which can run Web Assembly workloads on WASI or
waSCC runtimes. <sup id="fnref:wasmtime"><a href="#fn:wasmtime">3</a></sup> <sup id="fnref:waSCC"><a href="#fn:waSCC">4</a></sup> Beyond this, I have been working to
develop a Rust Kubelet for traditional Linux containers using the Container
Runtime Interface (CRI). <sup id="fnref:krustlet-cri"><a href="#fn:krustlet-cri">5</a></sup> <sup id="fnref:CRI"><a href="#fn:CRI">6</a></sup></p>

<p>Over the last few releases, Krustlet has focused on expanding the functionality
of these Web Assembly Kubelets, such as adding support for init containers,
fixing small bugs, and log streaming. This, in turn, has built quite a bit of
interest in alternative workloads and node architectures on Kubernetes, as well
as demonstrated the many strengths of Rust for development of these types of
applications.</p>

<p>For the <code>v0.5.0</code> release, we turned our attention to the internal architecture
of Krustlet, in particular how Pods move through their lifecycle, how
developers write this logic, and how updates to the Kubernetes control plane
are handled. <sup id="fnref:Pod-Lifecycle"><a href="#fn:Pod-Lifecycle">7</a></sup> We settled upon a state machine implementation
which should result in fewer bugs and greater fault tolerance. This refactoring
resulted in substantial changes for consumers of our API; however we believe
this will result in code that is much easier to reason about and maintain. For
an excellent summary of these changes, and description of how you can migrate
code that depends on the <code>kubelet</code> crate, please see Taylor Thomas‚Äô excellent
<a href="https://github.com/deislabs/krustlet/releases/tag/v0.5.0">Release Notes</a>.
In this post I will share a deep dive into our new architecture and the
development journey which led to it.</p>

<h2 id="the-trailhead">The Trailhead</h2>

<p>Before <code>v0.5.0</code>, developers wishing to implement a Kubelet using Krustlet
primarily needed to implement the <code>Provider</code> trait, which allowed them to write
methods for handling events like <code>add</code>, <code>delete</code>, and <code>logs</code> for Pods scheduled
to that node. This offered a lot of flexibility, but was a very low-level API.
We identified a number of issues with this architecture:</p>

<ul>
<li>The entire lifecycle of a Pod was defined in 1 or 2 monolithic methods of the
<code>Provider</code> trait. This resulted in messy code and a very poor understanding
of error handling in the many phases of a Pod‚Äôs lifecycle.</li>
<li>Pod and Container status patches to the Kubernetes control plane were
scattered throughout the codebase, both in the <code>kubelet</code> crate and the
<code>Provider</code> implementations. This made it very difficult to reason about what
was actually reported back to the user and when, and involved lot of repeated
code.</li>
<li>Unlike the Go Kubelet, if Krustlet encountered an error it would report the
error back to Kubernetes and then (most of the time) end execution of the
Pod. There was no built-in notion of the reconciliation loop that one expects
from Kubernetes.</li>
<li>We recognized that a lot of these issues were left to each developer to
solve, but were things that any Kubelet would need to handle. We wanted to
move this kind of logic into the <code>kubelet</code> crate, so that each provider did
not have to reinvent things.</li>
</ul>

<h2 id="our-mission">Our Mission</h2>

<p>At its core, Kubernetes relies on declarative (mostly immutable) manifests, and
controllers which run reconciliation loops to drive cluster state to match this
configuration. Kubelet is no exception to this, with its focus being
indivisible units of work, or Pods. Kubelet simply monitors for changes to Pods
that have been assigned to it by <code>kube-scheduler</code>, and runs a loop to attempt
to run this work on its node. In fact, I would describe Kubelet as no different
from any other Kubernetes controller, except that it has the additional
first-class capability for streaming logs and exec sessions. However these
capabilities, as they are implemented in Krustlet, are orthogonal to this
discussion.</p>

<p>Our goal with this rewrite was to ensure that Krustlet would mirror the official
Kubelet‚Äôs behavior as closely as possible. We found that many details about
this behavior are undocumented, and spent considerable time running the
application to infer its behavior and inspecting the Go source code. Our
understanding is as follows:</p>

<ul>
<li>The Kubelet watches for Events on Pods that have been scheduled to it by
<code>kube-scheduler</code>.</li>
<li>When a Pod is added, the Kubelet enters a control loop to attempt to run the
Pod which only exits when the Pod is <code>Completed</code> (all containers
exit successfully) or <code>Terminated</code> (Pod is marked for deletion via the
control plane and execution is interrupted).</li>
<li>Within the control loop, there are various steps such as <code>Image Pull</code>,
<code>Starting</code>, etc., as well as back-off steps which wait some time before
retrying the Pod. At each of these steps, the Kubelet updates the control
plane.</li>
</ul>

<p>We recognized this pretty quickly as a finite-state machine design pattern,
which consists of infallible state handlers and valid state transitions. This
allows us to address the issues mentioned above:</p>

<ul>
<li>Break up the <code>Provider</code> trait methods for running the Pod into short,
single-focus state handler methods.</li>
<li>Consolidate status patch code to where a Pod enters a given state.</li>
<li>Include error and back-off states in the state graph, and only stop
attempting to execute a Pod on <code>Terminated</code> or <code>Complete</code>.</li>
<li>Move as much of this logic into <code>kubelet</code> as possible so that providers need
only focus on implementing the state handlers.
<br></li>
</ul>

<p>With this architecture it becomes very easy to understand the behavior of the
application, and strengthens our confidence that the application will not enter
undefined behavior. In addition, we felt that Rust would allow us to achieve
our goals while presenting an elegant API to developers, and with full
compile-time enforcement of our state machine rules.</p>

<h2 id="our-animal-guide">Our Animal Guide</h2>

<p>When first discussing the requirements of our state machine, and the daunting
task of integrating it with the existing Krustlet codebase, we recalled an
excellent blog post,
<a href="https://hoverbear.org/blog/rust-state-machine-pattern/">Pretty State Machine Patterns in Rust</a>,
by Ana Hobden (hoverbear), which I think has inspired a lot of Rust developers.
The post explores patterns in Rust for implementing state machines which
satisfy a number of constraints and leverage Rust‚Äôs type system. I encourage
you to read the original post, but for the sake of this discussion I will
paraphrase the final design pattern here:</p>

<pre><code>struct StateMachine&lt;S&gt; {
    state: S,
}

struct StateA;

impl StateMachine&lt;StateA&gt; {
    fn new() -&gt; Self {
        StateMachine {
            state: StateA
        }
    }
}

struct StateB;

impl From&lt;StateMachine&lt;StateA&gt;&gt; for StateMachine&lt;StateB&gt; {
    fn from(val: StateMachine&lt;StateA&gt;) -&gt; StateMachine&lt;StateB&gt; {
        StateMachine {
            state: StateB 
        }
    }
}

struct StateC;

impl From&lt;StateMachine&lt;StateB&gt;&gt; for StateMachine&lt;StateC&gt; {
    fn from(val: StateMachine&lt;StateB&gt;) -&gt; StateMachine&lt;StateC&gt; {
        StateMachine {
            state: StateC 
        }
    }
}

fn main() {
    let in_state_a = StateMachine::new();

    // Does not compile because `StateC` is not `From&lt;StateMachine&lt;StateB&gt;&gt;`.
    // let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_a);

    let in_state_b = StateMachine::&lt;StateB&gt;::from(in_state_a);

    // Does not compile because `in_state_a` was moved in the line above.
    // let in_state_b_again = StateMachine::&lt;StateB&gt;::from(in_state_a);

    let in_state_c = StateMachine::&lt;StateC&gt;::from(in_state_b);
}
</code></pre>

<p>Ana introduces a number of requirements for a good state machine
implementation, and achieves them with concise and easily interpretable code.
In particular, these requirements (some based on the definition of a state
machine, and some on ergonomics) were a high priority for us:</p>

<ul>
<li>One state at a time.</li>
<li>Capability for shared state.</li>
<li>Only explicitly defined transitions should be permitted.</li>
<li>Any error messages should be easy to understand.</li>
<li>As many errors as possible should be identified at <strong>compile-time</strong>.</li>
</ul>

<p>In the next section I will discuss some additional requirements that we
introduced and how these impacted the solution. In particular, we relaxed some
of Ana‚Äôs goals in exchange for greater flexibility, while satisfying those
listed above.</p>

<h2 id="tribulation">Tribulation</h2>

<p>We were off to a great start, but it was time to consider how we want
downstream developers to interact with our new state machine API. In
particular, while the Kubelets we are familiar with all follow roughly the same
Pod lifecycle, we wanted developers to be able to implement arbitrary state
machines for their Kubelet. For example, some workloads or architectures may
need to have additional provisioning states for infrastructure or data, or
to introduce post-run states for proper garbage collection of resources.
Additionally, it felt like an anti-pattern to have a parent method (<code>main</code> in
the example above) which defines the logic for progressing through the states,
as this felt like having two sources of truth and was not something we could
implement on behalf of our downstream developers for arbitrary state machines.
Ana had discussed how to hold the state machine in a parent structure using an
<code>enum</code>, but it felt clunky to introduce large match statements which could
introduce runtime errors.</p>

<p>We knew that to allow arbitrary state machines we would need a <code>State</code> trait to
mark types as valid states. We felt that it would be possible for this trait to
have a <code>next()</code> method which runs the state and then returns the next <code>State</code>
to transition to, and we wanted our code to be able to simply call <code>next()</code>
repeatedly to drive the machine to completion. This pattern, we soon found,
introduced a number of challenges.</p>

<pre><code>/// Rough pseudocode of our plan.

trait State {
    /// Do work for this state and return next state.
    async fn next(self) -&gt; impl State;
}

fn drive_state_machine(mut state: impl State) {
    loop {
        state = state.next().await;
    }
}
</code></pre>

<h3 id="what-does-next-return">What does <code>next()</code> return?</h3>

<p>Within our loop, we are repeatedly overwriting a local variable with
<em>different</em> types that all implement <code>State</code>. ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deislabs.io/posts/a-fistful-of-states/">https://deislabs.io/posts/a-fistful-of-states/</a></em></p>]]>
            </description>
            <link>https://deislabs.io/posts/a-fistful-of-states/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661395</guid>
            <pubDate>Fri, 02 Oct 2020 11:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Privacy is the most important concept of our time]]>
            </title>
            <description>
<![CDATA[
Score 423 | Comments 205 (<a href="https://news.ycombinator.com/item?id=24661271">thread link</a>) | @umilegenio
<br/>
October 2, 2020 | https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/ | <a href="https://web.archive.org/web/*/https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-25770" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p><em>In case you are coming from Hacker News and are confused about some comments, be aware that I updated the essay to deal with some criticism</em>.</p>



<p>The title is not hyperbole. I do think that privacy is the most important concept of our time. Let me tell you why:</p>



<ul><li><strong>internet is not a virtual world anymore</strong>, it is a dimension that permeates our lives; we work, socialize and get informed through the internet</li><li><strong>our society is more diverse</strong>; we have some things in common with our neighbors and some with separate communities</li><li><strong>privacy is integral to separate the</strong> <strong>different parts of our lives</strong>; once the separation could be just physical and accidental (i.e., you live here and work there), now it must be built intentionally because there are no natural barriers in information spreading</li></ul>



<p>In short, internet has made sharing information easier and complexity has made information more dangerous. We need to evolve our understanding of rules and norms to deal with this new situation. </p>



<p>I have always believed in the importance of privacy, but I felt that common definitions (e.g., <em>the right to be left alone</em>) were lacking. In fact, I think that the whole conceptualization of privacy as simply a right of an individual and regarding private information as partial and limiting.</p>



<p>Think about this: the government can send policemen to surveil you and everybody they deem interesting. However, it can do this only for few people. <strong>This limitation is due to physical constraints, not legal ones</strong>. There is a limited number of policemen and you would notice if there was a police car in front of each house of the neighborhood. <strong>This is not true for internet communications: the government can spy everyone at once and you would never notice</strong>. As many whistleblowers have revealed, this is what the NSA has actually done.</p>



<p>So, the changes in society affect privacy directly but may also affect all our rights indirectly. Privacy is the fundamental principle that must respond to these changes.</p>



<p>You might say that then, maybe, I am not really thinking about privacy, but rather something else. That might be true, so let‚Äôs not talk about privacy, instead let‚Äôs talk about <a href="https://en.wikipedia.org/wiki/Definitions_of_fascism#Umberto_Eco">Ur-Privacy</a>, the principles of any possible concept of privacy. Take this essay as the opinion of a random guy that cares about the issue.</p>



<div><h2>What is Ur-Privacy</h2><p><em>A few principles for privacy</em></p></div>







<p><strong>Privacy is not just something we need to separate our private live from our public live. It is necessary to separate our private live, the communities we belong to and the public sphere from each other.</strong></p>



<p><strong>Privacy is about boundaries.</strong> It is not about hiding something but allowing to create a space with rules decided by its members. I like to compare it to borders. Some people say that borders are a restriction, something that limit freedom of movement and we do not need in the contemporary world. As if they were arbitrary obstacles put there by petty people. It almost makes sense if you do not think about them, after all you are actually stopped at a border.</p>



<p>However, that is not true, that is not why they exist. Borders delimit the area that a certain state control, an area where a specific set of rules and laws applies. There was a time before borders, in fact most of human history did not have clear borders. It was not a time of freedom, but anarchy, where bands of barbarians could roam into your home and pillage everything.</p>



<p>In this context is also important to remember that before the <a href="https://en.wikipedia.org/wiki/Peace_of_Westphalia">Peace of Westphalia</a> modern European states were plagued by continual wars. The short version is that this was due to the combination of two facts:</p>



<ul><li>modernity begets differences, different kings choose different religions<sup><a id="link_1" href="#note_1" data-type="internal" data-id="#note_1">1</a></sup> and separated societies</li><li>however, the legitimacy of kings was still based on shared medieval ideals, like the concept of divine rule</li></ul>



<p>In short, the issue was not that <strong>leaders wanted to make war all the time, they needed to do so</strong> because the legitimacy of their power depended, at least on some level, to what the rest of the European world was doing. If you claim to be a divine king there better be agreement on what the divine is, otherwise a guy that picks a different religion can also pick a different king. And, according to some, he could be a legitimate king. To change the situation this peace treaty established the principle that the internal affairs of a state are the exclusive interest of said state.</p>



<p>The connection with privacy is this: without clear rules on what is private and what is public, nobody knows which stuff belongs to whom. This means chaos and often that all belong to the strongest. Somebody might say that what you do in private, it is not private at all but political. It concerns the society at large. Therefore, it must be regulated according to their rules.</p>



<p><strong>Privacy does not imply hiding the truth.</strong> <strong>Meaning depends on context, therefore everything should be considered within its context.</strong></p>



<p><strong>Privacy is about control</strong>. Without privacy we cannot decide for ourselves how to live our lives. If there is no privacy, all become public. Whoever has more power and an interest can affect your life according to their own rules. Then, I have to care about what other people think, otherwise they will control how I can behave. As before the peace of Westphalia, the issue is not that other people are bad, <em>they have to do it</em>. When everything is subject to public scrutiny, you either control the rules and judge others or you are judged and controlled by others.</p>



<p>Think about this way: we say a lot of things in our private lives that are not meant to be taken literally. In private we say something and then we add: <em>you know what I mean</em>. And that is actually true. We can do that because the people we talk to in private know us; they understand the context in which our words must be understood. And even more importantly: they care about us; they do not want to intentionally misunderstand us.</p>



<p>When I was a child I would sometimes say and think that I wanted to kill my brother. I did not mean it literally and everybody knew it. If I said the same thing now, in public, to somebody that does not know me, the phrase would be different. It would be a threat.</p>



<p>Why is that? They are the exact same words. You know why, of course. I am different and the context is different. The real meaning of something, whether an action or a word, is not absolute, in most cases it is relative. When we speak in public, we share a different context, therefore our words have a different meaning. </p>



<p>So even if I say something as a hyperbole, or something that can be construed as an implicit threat (e.g., <em>they must be stopped at all costs</em>!), they might protest. You might say that they are overreacting, that it was just a joke, but how can they be sure of it? <strong>They do not know me.</strong> It is true that acts of violence are prepared by violent words. Even if you are unsure if something is really violent, you have to take a stand. You have to make clear that any attack against you is not permissible. Otherwise, <a href="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings" data-type="URL" data-id="https://en.wikipedia.org/wiki/Christchurch_mosque_shootings">somebody, maybe a crazy guy, might think that it is permissible and the right course of action</a>. Somebody might feel legitimated to take your land and kingdom.</p>



<p><strong>Privacy is not just needed to protect us from the government or exceptional situations. It is about understanding the rules that applies to every aspect of our life so that they can be fair for everybody.</strong></p>



<p><strong>Privacy is about everyday life</strong>. The issue is not simply that something we say can be considered a threat. When you are communicating with someone you need to be able to understand them. Communication requires a shared understanding at some level.</p>



<p>The easiest example to understand this are work discussions. When we talk with people that work in our field, we can communicate more easily the impact of a choice. This goes beyond the ability to use technical terminology: we know which are the main things to care about. The same discussion with our bosses would be different. Even making them understand the basic strengths and weaknesses is more challenging.</p>



<p>Now imagine being forced to communicate everything you do in the most general terms, to people that do not care about you, because <strong>everybody can see you</strong>. So, they can use any piece of information for their own needs. This could mean a policeman investigating you. It could also mean a company making you pay more for a pair sneakers, because they know how much disposable income you have and that you really love sneakers.</p>



<p>We need privacy to be aware of what is happening to us. It is too much to demand we know how other people interpret what we say. However, it is not excessive to ask that we can control what is shared about us.</p>



<div><h2>Privacy Affects Everything</h2><p><em>Defending privacy would require all-around changes</em></p></div>







<p><strong>Privacy is the most important concept of our time, because it influences everything else. Without privacy we do not know what rules applies. Our lives will be judged according to the rules of somebody else</strong> <strong>in ways we cannot even imagine.</strong></p>



<p>We cannot discuss all of the possible implications of privacy on other rights, so let‚Äôs see just the example of <em>freedom of speech</em>. Of course, sometimes you can also be judged for who you are: your religion or lack thereof, political opinion or sexual orientation.</p>



<blockquote><p>Give me six lines written by the most honest man, and there I will find something to hang him.</p><cite>Cardinal Richelieu</cite></blockquote>



<p>People lost jobs and had their lives ruined, because the mob judged something they said in private in a different way from what they expected. And they paid a price. You might say: that was fair. We might judge ourselves by our intentions, but others by their actions, which are real and objective.</p>







<p>I, for once, disagree with XKCD and this view. There are a couple of different issues here:</p>



<ul><li>how we should react to speech we disagree with</li><li>what was meant to be shared among friends was taken out of context and made public</li></ul>



<p>This complicates the ‚Ä¶</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/">https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</a></em></p>]]>
            </description>
            <link>https://inre.me/why-privacy-is-the-most-important-concept-of-our-time/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661271</guid>
            <pubDate>Fri, 02 Oct 2020 10:55:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare ‚Äì two years later]]>
            </title>
            <description>
<![CDATA[
Score 370 | Comments 340 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node.js malware caught posting IPs, username, and device info on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24660810">thread link</a>) | @axsharma
<br/>
October 2, 2020 | https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/ | <a href="https://web.archive.org/web/*/https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                    <!-- .entry-header -->

                
                        <div>
                                    <p><img width="1024" height="683" src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" alt="red and blue hearts illustration" loading="lazy" srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg 1024w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-300x200.jpg 300w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-768x512.jpg 768w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1536x1024.jpg 1536w, https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-2048x1365.jpg 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/sig5rzqmv3o-1024x683.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">                </p>
            
                                            </div>

            

        <!-- end slider-section -->
                                    

    <div>
        <div>
            




<p>Multiple NodeJS packages laden with malicious code have been spotted on npm registry.</p>



<p>These ‚Äútyposquatting‚Äù packages served no purpose other than collecting data from the user‚Äôs device and broadcasting it on public GitHub pages.</p>



<p>The findings were spotted by Sonatype‚Äôs <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">automated malware detection systems</a> and further investigated by the company‚Äôs Security Research team which includes me. </p>



<p>The packages previously present on the open source npm registry included:</p>



<ol><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/electorn" target="_blank">electorn</a> (intentional misspelling of a legitimate package ‚Äúelectron‚Äù)</li><li><a rel="noreferrer noopener" href="https://www.npmjs.com/package/loadyaml" target="_blank">loadyaml</a> </li><li>loadyml</li><li>lodashs (intentional misspelling of a legitimate package ‚Äúlodash‚Äù)</li></ol>



<p>All four packages were published by the same user ‚Äúsimplelive12‚Äù and have now been removed, with the first two having been taken down by npm as of October 1, 2020. The previous two packages were unpublished by the author themselves.</p>



<p>Once installed, <code>electorn</code> ran a script in the background <strong>every</strong> <strong>hour</strong> which collected the logged-in user‚Äôs IP, geolocation data, username, path to home directory, and CPU model information.</p>



<figure><img loading="lazy" width="1024" height="356" src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-1-300x104.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-1-768x267.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1-1536x534.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image-1-2048x712.png 2048w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1-1024x356.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>The malicious code within <code>electorn</code> and 3 other identical packages which exfiltrated user information</figcaption></figure>



<p>This information, part of which constitutes the device ‚Äúfingerprint‚Äù was uploaded and published on <a rel="noreferrer noopener" href="http://web.archive.org/web/20201001065601/https://github.com/h4ppyl1ve/collect/issues/4" target="_blank">GitHub</a> in real-time.</p>



<p>Some of the information being published is base64-encoded but this can be trivially decoded by anyone who has access to it:</p>



<figure><img loading="lazy" width="1024" height="488" src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" alt="" srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png 1024w, https://securityreport.com/wp-content/uploads/2020/10/image-300x143.png 300w, https://securityreport.com/wp-content/uploads/2020/10/image-768x366.png 768w, https://securityreport.com/wp-content/uploads/2020/10/image-1536x732.png 1536w, https://securityreport.com/wp-content/uploads/2020/10/image.png 1632w" data-src="https://securityreport.com/wp-content/uploads/2020/10/image-1024x488.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<p>Sonatype‚Äôs Security Research team has accounted for these malicious packages into their products, and had notified both npm and GitHub teams of the malicious activity stemming from the components. This led to the takedown of these malicious packages. </p>



<p>To this date, all 4 packages have scored a little over <strong>400</strong> total downloads.</p>



<p>It is not exactly clear what was the purpose of collecting this data and why was it being published on the web for the world to see, however, incidents like these highlight the potential of typosquatting attacks on the open-source ecosystem.</p>



<p>We can only imagine what the next possible version of these packages could have been capable of ‚Äì possibly carrying out even more sinister activities. </p>



<p>By tricking an unsuspecting developer into mistakenly installing a misspelled package, attackers can push their malicious code ‚Äúdownstream‚Äù into any other open-source projects that use the misspelled malicious component as a transitive dependency.</p>



<p>Adopting DevSecOps best practices and building security early on into your software development lifecycle can prevent ‚Äúcounterfeit components‚Äù such as electorn and loadyaml from entering, and thriving in your software supply chains.</p>



<p>The complete research findings are available on the <a href="https://blog.sonatype.com/sonatype-spots-malicious-npm-packages" target="_blank" rel="noreferrer noopener">Sonatype blog</a>.</p>
                <div>
                    <h3>About the author</h3>
                                        
        <div>

                <p><a href="https://securityreport.com/author/ax-sharma/"><img alt="" src="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=150&amp;d=retro&amp;r=pg" srcset="https://secure.gravatar.com/avatar/d0d95768ca47b1764f5fb964cf860afa?s=300&amp;d=retro&amp;r=pg 2x" height="150" width="150" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></a>
                </p>
                <div>
                    <h4>
                        <a href="https://securityreport.com/author/ax-sharma/">Ax Sharma</a>
                    </h4>

                    
                    
                                            <p>
                        <a href="https://axsharma.com/" target="_blank">https://axsharma.com/</a>
                        </p>
                                        <div>
                        <p>Ax Sharma is a Security Researcher, Engineer, and Tech Columnist. His works and expert analyses have frequently been featured by leading media outlets like Fortune, The Register, TechRepublic, CIO, etc.</p>
<p>Ax‚Äôs expertise lies in vulnerability research, reverse engineering, software development, and web app security. He‚Äôs an active community member of the OWASP Foundation and the British Association of Journalists (BAJ).</p>
<p>Send any tips via email or Twitter DM.</p>
                    </div>
                    
                                    </div>
        </div>

                                            </div>
                                            
                        
	<nav role="navigation" aria-label="Continue Reading">
		<h2>Continue Reading</h2>
		
	</nav>                    </div><!-- .entry-content -->
    </div>
                        </div></div>]]>
            </description>
            <link>https://securityreport.com/nodejs-malware-caught-exfiltrating-ips-username-and-device-information-on-github/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660810</guid>
            <pubDate>Fri, 02 Oct 2020 09:47:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Looking at the experience of black Britons through an American lens]]>
            </title>
            <description>
<![CDATA[
Score 402 | Comments 359 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it ‚Ä¶ I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country‚Äîit cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country‚Äôs flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country‚Äôs does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label ‚Äúblack British.‚Äù For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)‚Äîabout the same number as white students. But black Caribbean students are significantly less likely to do so‚Äîwhile those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label ‚Äúblack British.‚Äù But we need to invest it with the nuance consonant with its reality‚Äîand to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism‚Äîrather than law, medicine or finance‚Äîif you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country‚Äîor the black community‚Äîreally benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison‚Äôs iconic protagonist, is ‚Äúinvisible because no one wants to see him.‚Äù</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people‚Äîa narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bead Sort]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24659668">thread link</a>) | @kkaranth
<br/>
October 1, 2020 | https://karthikkaranth.me/blog/bead-sort/ | <a href="https://web.archive.org/web/*/https://karthikkaranth.me/blog/bead-sort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<header id="top">
    <section>
        <a href="https://karthikkaranth.me/">Karthik Karanth</a>
    </section>

    <div>
        <section>
            
                
                

                <a href="https://karthikkaranth.me/blog/">Blog</a>
            
                
                

                <a href="https://karthikkaranth.me/art/">Art</a>
            
                
                

                <a href="https://karthikkaranth.me/projects/">Projects</a>
            
        
        </section>
    </div>
</header>


<header>
  
</header>
<section id="category-pane">
  
  <p>
    <h6>
        PUBLISHED ON OCT 1, 2020 
      
    </h6>
  </p>
  
</section>
<section id="content-pane">
  <div>
    <div>
    <canvas id="bead-sort-canvas">
    </canvas>

    
</div>

<p>Bead sort<sup id="fnref:wiki"><a href="#fn:wiki">1</a></sup> is a sorting algorithm powered by gravity!</p>

<ul>
<li>For each number <code>x</code> in the array we want to sort, we arrange <code>x</code> beads in a row.</li>
<li>Let them all drop.</li>
<li>Count the number of beads in each row from top to bottom, and we have our sorted array!</li>
</ul>



<div>

<hr>

<ol>
<li id="fn:wiki"><a href="https://en.wikipedia.org/wiki/Bead_sort">Bead sort - Wikipedia</a>
 <a href="#fnref:wiki"><sup>[return]</sup></a></li>
</ol>
</div>

  </div>
</section>
<section id="tag-pane">
  
  
  
</section>








<section id="menu-pane">
  
  
  

  
  
  
  
  
  
  
  
  

  
  
  <div><p><span><a href="https://karthikkaranth.me/blog/starting-with-order/">&lt; PREV</a></span><span><a href="https://karthikkaranth.me/blog">BLOG</a></span><span></span></p></div>
  
  <div><p><span><a href="https://karthikkaranth.me/">HOME</a></span></p></div>
</section>





</div></div>]]>
            </description>
            <link>https://karthikkaranth.me/blog/bead-sort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659668</guid>
            <pubDate>Fri, 02 Oct 2020 06:44:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Falsehoods Programmers Believe About Map Coordinates]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24659039">thread link</a>) | @boyter
<br/>
October 1, 2020 | https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates | <a href="https://web.archive.org/web/*/https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>
      <span></span>
  <img alt="Mercator projection SW" title="Mercator projection SW" src="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg" srcset="https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e4a55/Mercator_projection_SW.jpg 256w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/36dd4/Mercator_projection_SW.jpg 512w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/72e01/Mercator_projection_SW.jpg 1024w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/ac99c/Mercator_projection_SW.jpg 1536w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/e1596/Mercator_projection_SW.jpg 2048w,https://engineering.kablamo.com.au/static/e780902de4e676c5b62d7e1a4a139f42/1cd85/Mercator_projection_SW.jpg 2058w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy">
    </span>
(Map image by Daniel R. Strebe, licensed under CC BY-SA 3.0)</p><h2>1. The only projection that is important is Web Mercator</h2><p>While <a href="https://en.wikipedia.org/wiki/Web_Mercator_projection">Web Mercator</a> is
probably the most popular projection that most people will run into, the
<a href="https://en.wikipedia.org/wiki/Albers_projection">Albers</a> and
<a href="https://en.wikipedia.org/wiki/Lambert_cylindrical_equal-area_projection">Lambert</a>
equal-area projections are fairly common for when the projection needs to maintain
the area rather than the navigational direction (which is one of the main features
of the Mercator projection).</p><h2>2. All coordinates are latitude/longitude pairs</h2><p>In addition to latitude/longitude coordinates, <a href="https://en.wikipedia.org/wiki/Universal_Transverse_Mercator_coordinate_system">Universal Transverse Mercator (UTM)
coordinates</a>
are also fairly common. UTM splits the Earth into 60 zones, and then
further specifies northings and eastings in metres (as opposed to degrees, minutes and seconds).</p><p>The UTM notably omits the polar areas - which are covered by the <a href="https://en.wikipedia.org/wiki/Universal_polar_stereographic_coordinate_system">Universal Polar Stereographic (UPS)
coordinate system</a>
instead.</p><h2>3. Latitude always comes before longitude in a coordinate pair</h2><p>While it is common to see items in (latitude,longitude) order, some formats
(e.g. <a href="https://en.wikipedia.org/wiki/GeoJSON">GeoJSON</a>) dictate that coordinates
follow (longitude,latitude) order instead. This matches the typical way coordinates
are specified in a Cartesian coordinate system: (x,y).</p><h2>4. A degree of latitude or longitude always represents the same distance</h2><p>In the Mercator projection, the Earth - which, in reality, is an
<a href="https://en.wikipedia.org/wiki/Spheroid#Oblate_spheroids">oblate spheroid</a> -
is projected as a simple cylinder. This means that "parallel" longitude lines
meet at the poles, so the distance between degrees of longitude are much shorter
as they get closer to the poles than they are at the equator (~111 km).</p><p>The variance in latitude is not as large - but it still varies by about 1km going
from the equator to the poles.</p><h2>5. The shortest path between two points is a straight line</h2><p>The Earth isn't flat - as such, although your map may be projected to be flat,
the distance between two points needs to follow the curvature of
the Earth and can usually be approximated by the
<a href="https://en.wikipedia.org/wiki/Haversine_formula">Haversine formula</a>.</p><h2>6. Coordinates for a given landmark are always fixed</h2><p><a href="https://en.wikipedia.org/wiki/Continental_drift">Movements of the Earth's tectonic plates</a>
mean that the land masses are moving slowly with the passage of time.
For example, Australia has shifted about 1.8 metres from where it
was in 1994 (about 7 centimetres per year). This also means that <a href="http://www.ga.gov.au/scientific-topics/positioning-navigation/geodesy/datums-projections/gda2020">geocentric
datums</a>
have to be updated to account for these changes every once in a while.</p><h2>7. Given a pair of coordinates, you can plot it on a map</h2><p>In addition to coordinates, we also need to know the datum, which is
the coordinate system and its specific set of reference points on the Earth.
While most coordinates often follow the
<a href="https://en.wikipedia.org/wiki/World_Geodetic_System">WGS84 datum</a>,
care should be taken to ensure that the map and the coordinates plotted
are using the same datum.</p><h2>8. There is one global ellipsoid to base coordinates on</h2><p>Most modern datums are based on the WGS84
<a href="https://en.wikipedia.org/wiki/Ellipsoid">ellipsoid</a>
as the surveys are often completed using GPS as a reference, but notably
Russia and China still base their local datums on different reference ellipsoids.</p><p>As a result, conversions to and from datums based on different
ellipsoids may result in inaccuracies and deviations and may be of concern
if you have to deal with GPS, GLONASS, and BeiDou data at the same time.</p></div></div>]]>
            </description>
            <link>https://engineering.kablamo.com.au/posts/2020/falsehoods-about-map-coordinates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24659039</guid>
            <pubDate>Fri, 02 Oct 2020 04:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Transport Tycoon a.k.a. the great optimiser, Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon ‚Äî who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon ‚Äî especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here ‚Äî or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they‚Äôve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We‚Äôll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making ‚Äî a decade of hard work, toiling in obscurity‚Ä¶or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade ‚Äî it‚Äôs five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since ‚Äî such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he‚Äôd encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he‚Äôd become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts ‚Äî where Chris set off towards the lands where he‚Äôd make his name. And I find it fascinating how serendipitous this was ‚Äî for, you see, Chris‚Äôs two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he‚Äôd not had access to an assembler for that Lynx computer, so when he‚Äôd wanted to move beyond coding in BASIC he‚Äôd needed to write his programs byte-by-byte in machine code ‚Äî the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he‚Äôd made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‚Äòk‚Äô rather than a ‚Äòc‚Äô) as though that somehow made his unapologetic, blatant clone of another‚Äôs work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren‚Äôt much concerned. Or at least their games guy Jim Wills wasn‚Äôt much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris‚Äôs work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers ‚Äî an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he‚Äôd already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he‚Äôd shifted over to the Amstrad CPC, which technologically-speaking wasn‚Äôt hugely different to the Memotech system he‚Äôd been on before ‚Äî but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can‚Äôt be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn‚Äôt doing too well at managing the transition. </p><p>So Chris didn‚Äôt have a job waiting for him after all, and he‚Äôd missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry ‚Äî he‚Äôd made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he‚Äôd thought it a ‚Äústop-gap‚Äù measure, just ‚Äúa bit of fun‚Äù while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who‚Äôd had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Jargon File]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24658797">thread link</a>) | @purec
<br/>
October 1, 2020 | http://jargon-file.org/archive/jargon-4.4.7.dos.txt | <a href="https://web.archive.org/web/*/http://jargon-file.org/archive/jargon-4.4.7.dos.txt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://jargon-file.org/archive/jargon-4.4.7.dos.txt</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658797</guid>
            <pubDate>Fri, 02 Oct 2020 04:12:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Big O, Little N]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24657747">thread link</a>) | @adamzerner
<br/>
October 1, 2020 | https://adamzerner.bearblog.dev/big-o-little-n/ | <a href="https://web.archive.org/web/*/https://adamzerner.bearblog.dev/big-o-little-n/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://adamzerner.bearblog.dev/big-o-little-n/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24657747</guid>
            <pubDate>Fri, 02 Oct 2020 00:59:03 GMT</pubDate>
        </item>
    </channel>
</rss>
