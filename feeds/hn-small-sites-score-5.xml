<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 23 Oct 2020 12:48:33 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 23 Oct 2020 12:48:33 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[AWS and their Billions in IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24845464">thread link</a>) | @tomklein
<br/>
October 21, 2020 | https://toonk.io/aws-and-their-billions-in-ipv4-addresses/ | <a href="https://web.archive.org/web/*/https://toonk.io/aws-and-their-billions-in-ipv4-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>Earlier this week, I was doing some work on AWS and wanted to know what IP addresses were being used. Luckily for me, AWS publishes this all here <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="nofollow noopener">https://ip-ranges.amazonaws.com/ip-ranges.json</a>. When you go through this list, youâ€™ll quickly see that AWS has a massive asset of IPv4 allocations. Just counting quickly I noticed a lot of big prefixes.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Ever wondered what all of the AWS network ranges are? You can find them all here:<a href="https://t.co/NBaBF6w0la">https://t.co/NBaBF6w0la</a><br>That's *a lot* of big prefixes!<br>4x /11, 14x /12, 30x /13, 78x /14, 184x /15, 278x /16</p>â€” Andree Toonk, Adelante! (@atoonk) <a href="https://twitter.com/atoonk/status/1316098702260359168?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

</figure><p>However, the IPv4 ranges on that list are just the ranges that are in use and allocated today by AWS. Time to dig a bit deeper.</p><h3 id="ipv4-address-acquisitions-by-aws">IPv4 address acquisitions by AWS</h3><p>Over the years, AWS has acquired a lot of IPv4 address space. Most of this happens without gaining too much attention, but there were a few notable acquisitions that Iâ€™ll quickly summarize below.</p><h4 id="2017-mit-selling-8-million-ipv4-addresses-to-aws">2017: MIT selling 8 million IPv4 addresses to AWS</h4><p>In 2017 <a href="https://www.internetsociety.org/blog/2017/05/mit-goes-on-ipv4-selling-spree/" rel="noopener">MIT sold half of its 18.0.0.0/8</a> allocation to AWS. This 18.128.0.0/9 range holds about 8 million IPv4 addresses.</p><h4 id="2018-ge-sells-3-0-0-0-8-to-aws">2018: GE sells 3.0.0.0/8 to AWS</h4><p>In 2018 the IPv4 prefix 3.0.0.0/8 was transferred from GE to AWS. With this, AWS became the proud owner of its first /8! Thatâ€™s sixteen million new IPv4 addresses to feed us hungry AWS customers. <a href="https://news.ycombinator.com/item?id=18407173" rel="nofollow noopener">https://news.ycombinator.com/item?id=18407173</a></p><h4 id="2019-aws-buys-amprnet-44-192-0-0-10">2019: AWS buys AMPRnet 44.192.0.0/10</h4><p>In 2019 AWS bought a /10 from AMPR.org, the Amateur Radio Digital Communications (ARDC). The IPv4 range 44.0.0.0/8 was an allocation made to the Amateur Radio organization in 1981 and known as the AMPRNet. This sell caused a fair bit of discussion, check out the <a href="https://mailman.nanog.org/pipermail/nanog/2019-July/thread.html#102103" rel="noopener">nanog discussion here.</a></p><p>Just this month, it <a href="http://www.southgatearc.org/news/2020/october/sale-of-amateur-radio-amprnet-tcp-ip-addresses.htm" rel="noopener">became public knowledge</a> AWS paid $108 million for this /10. Thatâ€™s $25.74 per IP address.</p><p>These are just a few examples. Obviously, AWS has way more IP addresses than the three examples I listed here. The IPv4 transfer market is very active. Check out this website to get a sense of all transfers: <a href="https://account.arin.net/public/transfer-log#NRPM-8.3IPv4" rel="noopener">https://account.arin.net/public/transfer-log</a></p><h3 id="all-aws-ipv4-addresses">All AWS IPv4 addresses</h3><p>Armed with the information above it was clear that not all of the AWS owned ranges were in the <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">JSON</a> that AWS published. For example, parts of the 3.0.0.0/8 range are missing. Likely because some of it is reserved for future use.</p><p>Combining all those IPv4 prefixes, removing duplicates and overlaps by aggregating them results in the following list of unique IPv4 address owned by AWS: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes</a></p><p>The total number of IPv4 addresses in that list is just over 100 Million (100,750,168). Thatâ€™s <strong>the equivalent of just over six /8â€™s,</strong> not bad!</p><p>If we break this down by allocation size, we see the following:</p><pre><code>1x /8     =&gt; 16,777,216 IPv4 addresses
1x /9     =&gt; 8,388,608 IPv4 addresses
4x /10    =&gt; 16,777,216 IPv4 addresses
5x /11    =&gt; 10,485,760 IPv4 addresses
11x /12   =&gt; 11,534,336 IPv4 addresses
13x /13   =&gt; 6,815,744 IPv4 addresses
34x /14   =&gt; 8,912,896 IPv4 addresses
53x /15   =&gt; 6,946,816 IPv4 addresses
182x /16  =&gt; 11,927,552 IPv4 addresses
&lt;and more&gt;</code></pre><p>A complete breakdown can be found here: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size</a></p><h3 id="putting-a-valuation-on-aws-ipv4-assets">Putting a valuation on AWSâ€™ IPv4 assets</h3><blockquote>Alright.. this is just for funâ€¦</blockquote><p>Since AWS is (one of) the largest buyers of IPv4 addresses, they have spent a significant amount on stacking up their IPv4 resources. Itâ€™s impossible, as an outsider, to know how much AWS paid for each deal. However, we can for fun, try to put a dollar number on AWSâ€™ current IPv4 assets.</p><p>The average price for IPv4 addresses has gone up over the years. From ~$10 per IP a few years back to ~$25 per IP <a href="https://auctions.ipv4.global/" rel="noopener">nowadays</a>. <br>Note that these are market prices, so if AWS would suddenly decide to sell its IPv4 addresses and overwhelm the market with supply, prices would drop. But that wonâ€™t happen since weâ€™re all still addicted to IPv4 ;)</p><p>Anyway, letâ€™s stick with $25 and do the math just for fun.</p><pre><code>100,750,168 ipv4 addresses x $25 per IP = $2,518,754,200</code></pre><p>Just<strong> over $2.5 billion worth of IPv4 addresses,</strong> not bad! </p><h3 id="peeking-into-the-future">Peeking into the future</h3><p>Itâ€™s clear AWS is working hard behind the scenes to make sure we can all continue to build more on AWS. One final question we could look at is: <em>how much buffer does AWS have?</em> ie. how healthy is their IPv4 reserve?</p><p>According to their <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="noopener">published data</a>, they have allocated roughly 53 Million IPv4 addresses to existing AWS services. We found that all their IPv4 addresses combined equates to approximately 100 Million IPv4 addresses. That means they still have ~47 Million IPv4 addresses, or 47% available for future allocations. Thatâ€™s pretty healthy! And on top of that, Iâ€™m sure theyâ€™ll continue to source more IPv4 addresses. The IPv4 market is still hot!</p></div>
    </div></div>]]>
            </description>
            <link>https://toonk.io/aws-and-their-billions-in-ipv4-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845464</guid>
            <pubDate>Wed, 21 Oct 2020 07:15:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What ORMs Have Taught Me: Just Learn SQL (2014)]]>
            </title>
            <description>
<![CDATA[
Score 208 | Comments 187 (<a href="https://news.ycombinator.com/item?id=24845300">thread link</a>) | @IA21
<br/>
October 20, 2020 | https://wozniak.ca/blog/2014/08/03/1/ | <a href="https://web.archive.org/web/*/https://wozniak.ca/blog/2014/08/03/1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<p>
Iâ€™ve come to the conclusion that, for me, ORMs are more detriment than
benefit. In short, they can be used to nicely augment working with SQL
in a program, but they should not replace it.
</p>

<p>
Some background: For the past 30 months Iâ€™ve been working with code
that has to interface with Postgres and to some extent, SQLite. Most
of that has been with <a href="http://sqlalchemy.org/">SQLAlchemy</a> (which I quite like) and <a href="http://hibernate.org/">Hibernate</a>
(which I donâ€™t). Iâ€™ve worked with existing code and data models, as
well as designing my own. Most of the data is event-based storage
(â€œtimelinesâ€) with a heavy emphasis on creating reports.
</p>

<p>
Much has been written about the Object/Relational Impedance
Mismatch. Itâ€™s hard to appreciate it until you live it. Neward, in his
<a href="http://blogs.tedneward.com/post/the-vietnam-of-computer-science/">well known essay</a>, lays out many cogent reasons why ORMs turn into
quagmires. In my experience, Iâ€™ve had to deal directly with a fair
number of them: <i>entity identity issues</i>, <i>dual-schema problem</i>, <i>data
retrieval mechanism concern</i>, and the <i>partial-object problem</i>. I want to
talk briefly about my experiences with these issues and add one of my
own.
</p>

<div id="outline-container-orge4f50a6">
<h2 id="orge4f50a6">Partial objects, attribute creep, and foreign keys</h2>
<div id="text-orge4f50a6">
<p>
Perhaps the most subversive issue Iâ€™ve had with ORMs is â€œattribute
creepâ€ or â€œwide tablesâ€, that is, tables that just keep accruing
attributes. As much as Iâ€™d like to avoid it, sometimes it becomes
necessary (although things like <a href="http://www.postgresql.org/docs/9.3/interactive/hstore.html">Postgresâ€™ hstore</a> can help). For
example, a client may be providing you with lots of data that they
want attached to reports based on various business logic. Furthermore,
you donâ€™t have much insight into this data; youâ€™re just schlepping it
around.
</p>

<p>
This in and of itself isnâ€™t a terrible thing in a database. It becomes
a real pain point with an ORM. Specifically, the problem starts to
show up in any query that uses the entity directly to create the
query. You may have a Hibernate query like so early on in the project.
</p>

<pre>query(Foo.class).add(Restriction.eq("x", value))
</pre>

<p>
This may be fine when Foo has five attributes, but becomes a data fire
hose when it has a hundred. This is the equivalent of using <code>SELECT
*</code>, which is usually saying more than what is intended. ORMs, however,
encourage this use and often make writing precise projections as
tedious as they are in SQL. (I have optimized such queries by adding
the appropriate projection and reduced the run time from minutes to
seconds; all the time was spent translating the database row into a
Java object.)
</p>

<p>
Which leads to another bad experience: the pernicious use of foreign
keys. In the ORMs Iâ€™ve used, links between classes are represented in
the data model as foreign keys which, if not configured carefully,
result in a large number of joins when retrieving the object. (A
recent count of one such table in my work resulted in over 600
attributes and 14 joins to access a single object, using the preferred
query methodology.)
</p>

<p>
Attribute creep and excessive use of foreign keys shows me is that in
order to use ORMs effectively, you still need to know SQL. My
contention with ORMs is that, if you need to know SQL, just use SQL
since it prevents the need to know how non-SQL gets translated to SQL.
</p>
</div>
</div>

<div id="outline-container-org2d7e33d">
<h2 id="org2d7e33d">Data retrieval</h2>
<div id="text-org2d7e33d">
<p>
Knowing how to write SQL becomes even more important when you attempt
to actually write queries using an ORM. This is especially important
when efficiency is a concern.
</p>

<p>
From what Iâ€™ve seen, unless you have a really simple data model (that
is, you never do joins), you will be bending over backwards to figure
out how to get an ORM to generate SQL that runs efficiently. Most of
the time, itâ€™s more obfuscated than actual SQL.
</p>

<p>
And if you elect to keep the query simple, you end up doing a lot of
work in the code that could be done in the database faster. <a href="https://en.wikipedia.org/wiki/Window_function_%28SQL%29#Window_function">Window
functions</a> are relatively advanced SQL that is painful to write with
ORMs. Not writing them into the query likely means you will be
transferring a lot of extra data from the database to your
application.
</p>

<p>
In these cases, Iâ€™ve elected to write queries using a templating
system and describe the tables using the ORM. I get the convenience of
an application level description of the table with direct use of
SQL. Itâ€™s a lot less trouble than anything else Iâ€™ve used so far.
</p>
</div>
</div>

<div id="outline-container-org05d550b">
<h2 id="org05d550b">Dual schema dangers</h2>
<div id="text-org05d550b">
<p>
This one seems to be one of those unavoidable redundancies.  If you
try to get rid of it, you only make more problems or add excessive
complexity.
</p>

<p>
The problem is that you end up having a data definition in two places:
the database and your application.  If you keep the definition
entirely in the application, you end up having to write the SQL Data
Definition Language (DDL) with the ORM code, which is the same
complication as writing advanced queries in the ORM.  If you keep it
in the database, you will probably want a representation in the
application for convenience and to prevent too much â€œstring typingâ€.
</p>

<p>
I much prefer to keep the data definition in the database and read it
into the application.  It doesnâ€™t solve the problem, but it makes it
more manageable.  Iâ€™ve found that reflection techniques to get the
data definition are not worth it and I succumb to managing the
redundancy of data definitons in two places.
</p>

<p>
But the damn migration issue is a real kick in the teeth: changing the
model is no big deal in the application, but a real pain in the
database.  After all, databases are persistent whereas application
data is not.  ORMs simply get in the way here because they donâ€™t help
manage data migration at all.  I work on the principle that the
databaseâ€™s data definitions arenâ€™t things you should manipulate in the
application.  Instead, manipulate the results of queries.  That is,
the queries are your API to the database.  So instead of thinking
about objects, I think about functions with return types.
</p>

<p>
Thus, one is forced to ask, should you use an ORM for anything but
convenience in making queries?
</p>
</div>
</div>

<div id="outline-container-org7033826">
<h2 id="org7033826">Identities</h2>
<div id="text-org7033826">
<p>
Dealing with entity identities is one of those things that you have to
keep in mind at all times when working with ORMs, forcing you to write
for two systems while only have the expressivity of one.
</p>

<p>
When you have foreign keys, you refer to related identities with an
identifier. In your application, â€œidentifierâ€ takes on various
meanings, but usually itâ€™s the memory location (a pointer). In the
database, itâ€™s the state of the object itself. These two things donâ€™t
really get along because you can really only use database identifiers
in the database (the ultimate destination of the data youâ€™re working
with).
</p>

<p>
What this results in is having to manipulate the ORM to get a database
identifier by manually flushing the cache or doing a partial commit to
get the actual database identifier.
</p>

<p>
I canâ€™t even call this a leaky abstraction because the work â€œleakâ€
implies small amounts of the contents escaping relative to the source.
</p>
</div>
</div>

<div id="outline-container-orgddbdda4">
<h2 id="orgddbdda4">Transactions</h2>
<div id="text-orgddbdda4">
<p>
Something that Neward alludes to is the need for developers to handle
transactions. Transactions are dynamically scoped, which is a powerful
but mostly neglected concept in programming languages due to the
confusion they cause if overused.  This leads to a lot of boilerplate
code with exception handlers and a careful consideration of where
transaction boundaries should occur.  It also makes you pass session
objects around to any function/method that might have to communicate
with the database.
</p>

<p>
The concept of a transaction translates poorly to applications due to
their reliance on context based on time. As mentioned, dynamic scoping
is one way to use this in a program, but it is at odds with lexical
scoping, the dominant paradigm. Thus, you must take great care to know
about the â€œwhenâ€ of a transaction when writing code that works with
databases and can make modularity tricky (â€œHereâ€™s a useful function
that will only work in certain contextsâ€).
</p>

<p>
Where do I see myself going?
</p>

<p>
At this point, Iâ€™m starting to question the wisdom behind the outright
rejection of <a href="http://c2.com/cgi/wiki?StoredProcedures">stored procedures</a>.  It sounds <a href="http://c2.com/cgi/wiki?StoredProceduresAreEvil">heretical</a>, but it may work
for my use cases.  (And hey, with the advent of â€œdevopsâ€, the divide
between the developer and the database administrator is basically
non-existent.)
</p>

<p>
Iâ€™ve found myself thinking about the database as just another data
type that has an API: the queries.  The queries return values of some
type, which are represented as some object in the program. By moving
away from thinking of the objects in my application as something to be
stored in a database (the raison dâ€™Ãªtre for ORMs) and instead thinking
of the database as a (large and complex) data type, Iâ€™ve found working
with a database from an application to be much simpler. And wondering
why I didnâ€™t see it earlier.
</p>

<p>
(It should be made clear that I am not claiming this is how all
applications should deal with a database.  All I am saying is that
this fits my use case based on the data I am working with.)
</p>

<p>
Regardless of whether I find that stored procedures arenâ€™t actually
that evil or whether I keep using templated SQL, I do know one thing:
I wonâ€™t fall into the â€œORMs make it easyâ€ trap. They are an acceptable
way to represent a data definition, but a poor way to write queries
and a bad way to store object state. If youâ€™re using an RDBMS, bite
the bullet and learn SQL.
</p>

<p>
August 03, 2014
</p>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://wozniak.ca/blog/2014/08/03/1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24845300</guid>
            <pubDate>Wed, 21 Oct 2020 06:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Diablo (Pitch from 1994) (2016) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24844666">thread link</a>) | @tosh
<br/>
October 20, 2020 | http://www.graybeardgames.com/download/diablo_pitch.pdf | <a href="https://web.archive.org/web/*/http://www.graybeardgames.com/download/diablo_pitch.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div ï¿½oe="">â‚¬Ã¶Å’A]Ã¸Ã½Ã§Ãâ€°9_ÃÅ’GÆ’Ã€Ã Â«Ã›OlFâ€¢t|Ã­fl5ÂµÃÃ¦"8Â²36%vLFÃ”nÂ¸â€™Ã–ÃYâ€°Ã’-ÃŸÃ‹Ã–Â¢Â§Â¼Ã¹â‚¬â€˜2oÅ¾â„¢â€º;^0YÃnÃ™Â°Å¾@3GnÃ–?Ã±$â€ S;\Â«ÃŠÃšâ‚¬Ã©Å¸Â¾ËœÃ¸"#Â¸Ã¹Â©Æ’ &lt;â€ Â¸â€°Â´(Ã˜Fâ€˜F%}EBÃ¬â„¢Câ€˜Ã†Ã¤S P|Ã®}0&nbsp;â€˜Â¬Å¡Â£]*Cgqg"}ÂºaÃƒpÃ‹â€¢2â„¢g!Ã–FÃ²Â¥Ã›Ã¦$Ã´jHÃ¤â€¹Tï¿½oÃ´Ã“Ã¶M2Ã‘Â¥kÂ»o-WÃ
Å Ã¯Ã»Â´&amp;9|Ã„Ã½Ã$aÂ°Â¨ÃµÂ±5Â¬ÃšÃ¡Ã»Â¼Ã¶Ia$kÃ¶Æ’Å’Ã:Ã¼ï¿½Ã;â€œ(2N3Â¶â‚¬Ã“Ã«.Å¡â€œÂ¥Ã…Æ’Ã˜Â´Å½Â¶Â¸9Â¹*7ï¿½Å“FÃ›ÃŸ
Æ’dâ‚¬Â©Â©jÂ¬gÅ TÃ¾Ã—Ã»ÂºFPÃ˜Ã¹@eÃ·â€¢Ã¿Tâ€œÃ¾Âµâ€Â¢PÃ»ï¿½0H%â€™;uM@	Ã´Â«â€˜ÂµÂ´Ã²ÃƒyEï¿½2%Ãâ€¢TWRÃˆÃ‡~Ã¢Ãœgc|ÃŠGË†BMÃ…OÃ¬Ã¡ï¿½Ywâ€ÃœU&gt;XÃœ% Ã‚pÃ‹Â»8Â¡â€“sÂ¥â€œÂ®HÂ²\IÂ¨* Â±lÃ¡Ã²OÃŒYSÃ‹;â€Â¤nâ€œâ‚¬"KÂ¨ÃŠÂ·Sjï¿½:AqnÃ‡d HÃœÃ°â€™Â±Ã®Ã†Ã€y"Âª$hÃ¥Ã„Å¡Ã¤Æ’â€¹Ã‚IÃ²Ã”Ã¥ÃŠyÃ¬&lt;Ã L!â€mCï¿½Ã Ã—â€“vÃ’Yâ€¢Â§gVâ„¢â„¢Â¶"Ã™Å’JÃƒ/â€¦o1Âª*1Å½1Â¤Ã€â€¡BÃŸÂ±Ã‰2:Ãª@Ã\Ã´Ãœ7dÃÃ§}Ã–ÃÃ€Ã/'ï¿½zÃ‹Â¥ZoÂ«BÃ’}Â¢Ã¯Ã(eT'*$_ÃŸKÂ¿Ã¥bÂ¬Â¿.ÃŒÃ£â€šW'QÂ·#Oï¿½Ã¬Ã¿dÂ¶ctÃ¢l5Ã‡#qeÃˆÃ³`ÃÆ’Å“â€ Ã‡ÃˆÂ¦Ã‡Å¸Â¡Z!hbKy$eÂ½ï¿½Ã­YBâ„¢
Å’CoÃ®Ã­â€™R@9Â»Â¢Ã•"Â¾ÃhÃ–â€“Ã¹Ã Â¦w`#`â€˜Ãbsâ‚¬FJ/Jâ€¹tâ€™ÃªÂ°Ã¹V0Ã‰Å¸l'oÅ“Ã®Ã´Â§;CJâ€“fLÃ¼Ã@!oÃšm9Â®X-Å¸Ãšâ‚¬Ã¾Y*A+Â¸Â¨
FÃ†RaÅ¾xoËœÃªJâ€“â€“ÃoÃ¤fÃ—$yÃ„0$Â¬{@*Ãƒâ€ Â¢}Ã¯Ã¯3Æ’Ã„ï¿½Ã½ÂªÃ˜IÃ¶â€šâ€šÃ„Ã‡â€¢
cÃ»Ã»sÅ“$ï¿½â€(p Ã¼ï¿½GÃ¶zEq{Â¸Â´Å¾)â€¦Â¼~y_ÃŒWÃšFy
Ã…Â·â€˜Â½qDÃ°Â½â€šËœÃ¯Â£Kâ„¢Â®mÃ£6Ã²Â´Ã¤Ë†PÃ¤+\Â¸Ã‰U]ËœÂ©5Ã…Â§bÃ´%Â­ÃŠÃ$ÃÂ­Ã°Oâ€œÃ³eydÃ‡Ã°Â¥7rwÃ“â€”Â¥Ã„Ã‘/Ã™nÃ…ÃœLËœ.Ã–Ã¥Â²;Â«Å’Ã¼ÃƒÂ²Å¾â€ºXJHÅ¸Mâ„¢ÃªRÃÃ›Ãƒ;Â³#a07lÃÅ½&nbsp;Å“Ã®Ã‹t%â„¢Â»M"Ã©Ã–Ãˆâ€˜ÃŸ$â€œ	.Ã…Ãƒï¿½7Ã¯Ã®\Ã }Ã @Ã®N9sUyDVâ€¦Â´ÃÃ–Â²Ã…#Ã†~Ã˜Â±Â³Ã”Ã¬$+Ã§`rÂ£w%Ã”Å“Å¸â€¢Â¬Â±Ã‹Â·N&amp;Ã$Ã¿JÃšÃƒÃŒÅ“Â³
Ã›â€Ã°Ã¿ÃR@1Ã¤A--ZÃÃÃŒÃ¬nÃ¹Ã»vâ€ Ã£,O!ÃšsÅ’Ã¡W3Kâ€˜%Ã¥Âº$Ã–Ã¾Gï¿½jnt&nbsp;0|&nbsp;ï¿½zpA'fÃ¦Ã¢Â«yâ€¹~â€¹â€ &gt;ÃÃ¡Ã„eZR1â‚¬Ã„â„¢ÃÃ°â€™Ëœâ€˜â€œÆ’$â€™Ã‡Â¨oÂ¹?eÂ·6Ã©Ã›pÂ¤yÃ¸8Ã¹GÃŒXÂ°Ã¡Ã°yw`Ã´3,$Ã¿iÃ¹1?;gÃ˜Ã¾ÃÃ¡Â·yx$Æ’Å’Ã¼Ã„ÃµÃ¾lÃ¦Â«Ã‰Â°ÂªÃœÂ¨Ã²Â¡Â¹2Ë†Ã•$ÃŸÂ±wdÃ†Ã„sÃ‚â€¢0â‚¬Ã‰Â«KrÅ¾iÃ”Ã˜ZÂ¤â€¹(_Â±yL^ÃÃ»;`Ã²â€¡$Æ’Ã²Å¡%bL\Â«DÃ9â€”t
Â¬Â¢/ËœÃ qï¿½â€nÃŒxlÂ¼Rn9â€šÂ§Ã“Â£
ÃºbÂ¾gÅ“Ã­Å’Ã´Ã­Æ’Å“`Ã¤`Ã³Ã—Ã¹Ãºbâ€ Â¢Å )â‚¬QEQEQEQERc&gt;Ã”Â´PIKF)QÅ JZJ)i(Â¤â€”Â¥ÃÃ’fâ€“Å (Â¢â€™ËœEbï¿½QLÅ (&nbsp;Å (&nbsp;Å (&nbsp;Å (#4QEQEQEQESÂ§Ã£OÂ¦IÃ“Ã±Â¤Â¨Â¤Pm+S(z(Â¢ËœQ@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@Q@yÃ¯Ã„0ï¿½onÂ²Â¨gÃ¤Â¨Ã‰Ã¢7ÃÃ Ã„Æ’Å’Ã£Â½zyÂ¿Ã„V";QÅ½&lt;Ã—Ã§Â¾vp3Ã¨rr;Ã zPÅ¾Ã‰p/"X/Â¦eâ€ Ãš	Â¸)ÃƒavÂ¦UAÃ¹Â¶â‚¬]Ã²^H'5zÃ¢yÃ®Ã¥Ã»NÂ£$Ã‘ÃªQ,&amp;Ã‰&gt;Ã?zwâ€“N~|ÃµÃ€Ã‰Ã 1IhÃ•ÃÃ”Ã†ÃXF
Å¸â€Å“Æ’â€¢ÃŠ0OPEk\A-Â´Â­mÂ¨Â¤Ã²jÂ²Ã¹?câ€œÃ­Ã¼Â²\â€¦Ã‹oÃ¹NÃ¼Ã£%Ã¹Ã¤l; ÃÂºkÂ¿Âµâ„¢$ÃšÃ‹ÂµmÃÂ¿XÃŒXÃÃ˜Ã‚sÅ“&nbsp;Â¶:=2ÃŠ[Ã‹yÃÃÅ¾Ã²KÂªMÃ¶ï¿½ÂµEÃ¤gÃ‹`$Å¸â€”nK<pÂ­â€!~Ã«h-nÃ‡Ã˜Ã¶ÃŒuÃ6~Ã‘Ã§Å¸ÃµbÃ›wÃ¹ËœÃÃ:goâ€°Ã¹j+k{Â»Â©mÂ¶Å¾Â²Ã…Âªb'7râ€¹â€š Ëœï¿½="" ÃÂ·!Â±Å“Â¬~bn2Â°x-Å¸Ã»ydi`sÂ¨Â³fÂ¸â€¹!Âºn]ÃŸ*â„¢rpÂ±Ã€,Ã¶Å¾xâ€šÃ„Ã±iÃ²ÃˆÃº#Ã‰Âºï¿½Ã£]ÃŠÃ›â€œpÃ¦5â€˜Â¶ï¿½="" Â©Å’Å“â€šiÅ½ÃÃ›Ã­Â¶Ã®tÂ¥{dÂµâ€h="Â¿Ã’08" vÂ·="" 'urtuÂµ,="" yÃªrÂ´zdâ€šÃ¢Ã‘Â¥â€˜="" ÃŒÂ¥cÂ´3Â¡ÃŠÂ²="" â€“sâ€¦â‚¬tÃšÂ¬Â©o,Â³="" \1Å½sï¿½Ã‰![!â€“-Â¹3Â´Æ’Ã‰*0pvÃ›Ã§Ã…:â€Â²Ã…dâ€˜ÃŒÃ–Å’!ÃÃ£Â¸="" Â Ã‰Ã,ÃŸ(ï¿½Â¡ÃƒuÃ‡â‚¬$1ÃªÅ’â€Ã¨Ã¯+*Ã™-Ã„Ã„Â£mâ€˜71Ã .\$6pÃ¡zukhÃ¢Â¸Â¿Å iÃ¬Ã§iÃ¾Ã‰ÃšÃ®Â¾u#6s="" Â²â€“â€”2isâ€œuâ€™xÃ®#Â·Å’Ã™Â¯â€¢Ã¾Â±k1Â°â‚¬mÃ´câ€šsÅ“â€™Â¥zyÃ¤Â¸3<Ã·2lÂºÃŠmÅ½1="" Ã ï¿½Â£i!sÂ±Å’="" ;Â²Â£kmâ€¢Â®mâ€ºo="" j6Â¸Å¾[xÂ¾ÃˆÃ¾{~Ã¥imÂ ="" â€¢*ï¿½â€¡="" ï¿½â€¡="" Â¾Â¦Å¾Ã–x.Ãuâ€™]uÂ¥â€¹dÃ¿ï¿½hÃÂ¨Ã¹Ë†Ã‰<aâ„¢ï¿½_â€”Ãƒ="" o,Ã¾rÃlÃ³ï¿½eÃ¦â€ºÃŒï¿½ÃŠ@â€¦mÃ‡="" Â¡wc="" Â©)mrÂªyÃ¶mpâ€º[eyeÂ¾â€“)zÃµz(Ã°Å¸2ï¿½Âª6Ã ï¿½Ã8ï¿½);dÃq="Ã‚ÃšÃ›Â¬â€˜Ãªâ€¹,Â¾dÂ¿h" Â±ÃƒÃ‰â€¦*7eâ€¢Å½Ã±Å“Ã®$ï¿½Â¶pÃ‹Âªâ€¢ï¿½kÃ’Ã¦+wkâ„¢mÃ‹ï¿½;â€ÃÅ¸Ã®Ã¥Â²h8\Â·Ã~phÃÂ·yscâ€“iÂ´Â³Ã¢uÂ¨bÃªÃ»dâ€˜Â¡ÃˆË†ËœÃ”Ã£fÃ€Â­Â¹qdâ€šÃÃ®â€ Ã·Ã¹Â²yj[vÃ˜â€¹dÃ¬`Â¸Ã Â»Ã²Â³Â¹Ë†Â¿miÂ®4ÃˆÅ¾Ã–ÃÃ8Ã¾Ã•Ãš\ï¿½fÃn~lÂ¡`Ã ï¿½p2ÃjÃ„Â±="Ã¼QlÃ’Ã’Ã¡Z}Â¥Â¹rÅ ï¿½ÃœÅ“â€š[Ã¯(8_â€˜" v!Â¾{Â¼qÃ›nÃ“ï¿½%&ï¿½Ã‚|â€¢'Ã¾z!â€šÂ¨g;ÃÃ¥ÃŸâ€¦Ãœh(Ã‰Â¦i"rkâ€¦hmÃ—Ã¬;#eÃ¹z&Ã¦Ã‚Â³gÃ‚Ã Ã²Ã‡Ã¦!Â³ÃƒÃ#6Ã°gqâ€ºÂ¦m4Â¾]Â¯Ãš\l?8\Ã±Ã•vÅ“8Ã‹="">|nÅ tÃ» _EÃ¶â€œulï¿½jÃ{ï¿½Â³Â¡ÃÂ´`Å’Â­Â·Ã®Ã¼Â¸Ã®| -ÃœÃ½Â§Ã­Ã·Â¦Ã­Â¡$gUHvï¿½TÂ¶ÃPâ€˜ÃˆÃ‡;sÂ¸o
Â¡Â®â€“Ã¬4fÃ­Ã£3]ï¿½y{|Â²		Ã™Æ’Â»â€¦Ã$tV1ÃœÃ›Ã‹kpÃ–)Ã¦Ãªo,,â€”Å¸iâ€œ)â€˜Ã‘â€™ÃŠâ‚¬FÃ¢rÂ»ï¿½
Â¹Å¾ÃšÃiÂ®Ã—L@`Ã•Ã¤i/~Ã‘#3ï¿½Â¬JÃ¼Â£â€šTÂ¨ÃsÃ²Å“Å’Â±Ã€mâ€¡ÃšÃ¤â€”Ã¾$Ã­pÃšâ€¹Â¤Â¦Ã³ÃŒÂªâ€šÃÂ¹Ãš_ï¿½Ã³Ã§Å“Ã¯8ÃˆÃŠâ€¦Â´Å’Â¬r
!Â§6&gt;Z
HÂ¸â€0P~ÃÃŸ7â„¢8AÅ“Å½Â­Å¡[Âµ2ltÃâ€“7VÅ Ã«q0Å¾OÃŸï¿½Ã_â€BJÃ¯]Ã›I*Â«ÃˆÃºÂºIyÂ§Dâ€“vvhÃªÃ™et
Â¡ï¿½â€Ã¹qÃ­mÃˆÂ¬Å¸0Ã£&lt;Ã¤Ã²Â¬Ã¶c3Ã¸{zÃ¹Ã¸Ã²Dâ€šCÂ³Â¦Ã %Ã‡â„¢Ã¥Å½1ï¿½8Â¨eÃ‡â€¢\Å¸Ã¬!#Ã½ËœÂ¢Ã…Â¼Â°Ã”â€¢Ã‹&gt;Ã°#Â¦Ã¡+Ãâ€°Ã£:Â¬QFÅ¡dr*I`&amp;(Â®Ã¸;FÂ±Ë†Ãºâ€nA'fH#8Ã\(Âºâ€Ã‘G5Å’Ã’ÃŠ#Â²[â€”&amp;9Ã¤â‚¬Â¼/P Â®@E&gt;}Ã¾TcV7&gt;@â‚¬Ã½â€*Ã„88Ã›Â»Å¾r9|mÃÂ·6Ã®
Ã—Å¾Â§T?Ãšâ€DÃ–!|â€šÂ¡Â·/xÃ»Â£Ã·â‚¬eHÂ©`IÂªÂªiÃ±Â¤Â·IÃ’\Ã‚ÃBâ€ -oÃ@aï¿½Ã¡ÃÃ·sâ€šCrjÅ¡Ã¦b~Ã…vâ€˜\Ã\Â¬^MÃ—ÃšXË†TÃ¡Wâ€™8Ã—â€šÃ¥â€”â€ jâ€ Â¹70â€ºÃ¾5?+~Ã£Ã‹(Ppy0Ã CÅ¾ÃÂ·â€˜ÃŸÂ¤Ã‘Ã‰tÃFâ€“â€™.Â¶3Ã¶Ã—&gt;NÃ†Ã¹â€ Å’YÃŸÃ¥Ã­Ã²â€erMeâ€¢xÃ¤:AÃ»:ÃŸâ„¢Â·Ã½Â¼ÃŒrÃÃ›|ÃÅ¾g lÃ»ÃNÃÂ»Å½jÅ =Eâ€¦â€šÃ½â€“ÃÃ¢Ã—ÃŒÃ³oÃ ï¿½9Ã¦ÃšÃ®'pÃ‰cï¿½Ã˜zÃœÃ‹)oÃ¬UÂ¸â€œÃ¾&amp;!ÃŒ[[Ã»Ã…7Â·Ã?Â½Ã¥JÅ“cn&gt;jÂ»Ã‰$m&amp;ï¿½â€˜h+â€˜w)Â½Å“Â¾Ã’Ã®Ã’Ã Â¡â€°NÃ‡^Ã‡9Ã/s$7ÃˆÂ¢aÂµEâ€°16
Ã†
Ã§Â®ÃÃ„Ã£!FÃ¦9'qÃ€Ã…Ã³uÃƒâ€ºÃ˜câ€šÃÃ–ÃœÃ…Â¾ÃƒÃÃ‡Ãš
Å¸Â½Â´Â¦Ã—&lt;ï¿½Ã„Â§AÃNIC5Ã¤â€˜DBfÅ½gÃ°Ã Ã»â€˜nMÃ»Ã³Â´cÃ·â€šmÂ¾nHÃ¸Ã¶Ã†Qâ€º*Â¾Â¨Â·gL}Ã†Ã…Ã„]zl$Ãˆ
â€¡$Å½ï¿½GZÃ‚{x%Ã¾Ã—hÂ¬ÃbÂ£OÃ³AdÃŠâ€¢ÃœPÂ¡P27}ÃŒr6ï¿½ÃG-Â¾â€“~Ã™,vâ€”iveÂ¸ï¿½Â±Â·Ãœr7
Â§n3ï¿½ÃœÃ Ã¡â€Å’ÃÃ«Ã‰7â„¢Ã–â€“yoÃ¥Ã‡Ã˜
â€Gâ€™63ltâ€¹Ã£vÃµn&gt;Ã—Â¤IÃ„Ã«Ã’Â´Å¡Ã»)kyÃ•â€DÂ¨7c 2Ã†Q  Ã„I'Â¾Es1Â­Â¶Å½Â¦ÃšUÂ´Â»kÃÂ»fÃ»6xÃ‹
Å’ÃŠW;â€°RÂ¹Ã‡$Ã¢Â¬`ï¿½Â±Ã¥kIÂ¥â€”â€˜Â¨Ã¹ï¿½â€j~mÂ»ÃŠâ€™Â·E8Ã«Ã‰Ã›TÂ¸â€“vâ€šÃ™]5Ã¤PÃ—Ã«Ã¥â€Ã¹sï¿½Â½â€œÃ€Ã†:Mï¿½Ã¦Gï¿½EIaÂ¼â€°Â±~Ã*Ã¢SÃ³Ã›â„¢$â€¹â€ ÃšÃŠ.zÅ’Å’gF-Â®qÂ¥yâ€“Â¶ï¿½n2ÃšË†eÃŒÃÃˆÃ˜Lâ€œÂ¸Sï¿½Â¾Ã˜Â«Ã±,:Ãƒ#Ã»=â€°Â±92Ã‡Å’]Ã£#â€š&lt;Â¿â€˜Â°KeÂ¤ÃÃ¡Ãï¿½CÂ­Ã–)Ã•Â¦Ã’â€™H4Ã˜Ã‹Ã¨Å¾OÅ¡L`Â¶ÃœÃ‰!Â¯â€¡MÃƒï¿½Ã¯b7â€Ã›}Â±Wnâ€šÂ¨GÃ™zÃŠ_Â¦Ã®Â§Ã¸Â½fÃ­Å¸zâ€š!oÂ«bÃ¹bÅ½Ã‰mÂ¡m]Â·8Â³Ã’0sÃ“Ã½[Ã²*Ã´
dÃ¿â€°ÃŠÃ‚CyEL	â€œÃÃ€qÃ‡B0Ã™Ãºs@Ã‰w$QÂ¥ÃÃ§Ã¯tÃ‰Ãš!enÂ«Ã»Ãˆï¿½Ë†ÃšX|Â¸
3Å¸Ã7\Å“
â€™XÂ¤Âµâ€˜`Ã”Ãš/Â§wÃ»ÃŠâ€¦â€“Ã‡Å½â€š9&lt;&lt;Ãº
Ã‘ï¿½'Â±cÂ©,w=Ã§â€“ï¿½lÃ¿G
Ã”Ã£Ã®Âº1Ã‰lHÂ°ï¿½IÂ§fÅ¸iÂ¹KÂ¶ï¿½Ã‰pdÃ‰Æ’#ï¿½Ãâ€¦Ã‡nÆ’&lt;Å¸J?Â¯Ã€JÃ¢Ã…ÃŒâ€¹`Ã¬Ã¯Â­Â²â€“[Âµy:Ã£zï¿½x_â€”2Ã”ï¿½XÃ¯kpÃ³Ã½â€ ÃY5(ï¿½3ÃœÃ½Â­Ã‡Å¡:Â¼AÃ Ã£Æ’ï¿½ÃˆÃ´Ã«Ã®Â­&lt;ËœÂ¿Â±Â¿~mÂ¤VwÂ¿vÃŠÂ©$Â¶Â°Å’Ã Â¸ÃºW#wsâ€¦Ã’ÃÃ­aÂ·â‚¬â€”Â¦2Â¢bÂ£ÃŸÂ»i$Å“Ã	Ã‡ Ã¢VÂ¹4Ã´{S
Ã¿Â¥Â¶&amp;LÅ’Ã§
ÃcÅ“Ãªï¿½Ã¡Ã²Ã–Å¸{sxxG$Ã Â¶~`@y/ Ã¢ÂºyËœÃ„ï¿½ghlÃmÃ‚m7ÃœnÃƒÂ·ÃŠ9Ã†In:\Ã½ÃÃ˜:â€Å¸dÂ·Â¸Æ’Ã½]â€”Ã™Ã°&amp;Å“â€.Ã®Ã‰Ã‚Ãµï¿½
Â±&nbsp;Â½xIÃ’Ã˜Ã±mÃ¶Â³ï¿½ÃŸw8CsÃ“8Ã†xÃ¦Å’CfÃ¢Ã¶Â´ZÃÅ¸Â³ÃƒÃ¶Â¦ÃŒY$Å’Ã Ã±Ã€ÃÃ·Ã­Å¾ï¿½#_Ã­HÃ¾ÃŠÃ·lvï¿½?Ã¬Ã§
1Â´ï¿½â€šBÃ£Ã§ÃÃ:Ã³Ã†(FKÃ¶Â»Sow5Ã‡ÃºÃ˜&gt;ÃŒÃ„[â€ Ã¤ï¿½7m#o*
G*Ã½ï¿½lÃ¨.Ã¦ï¿½Ã‘Å“ÃÂ¾ &nbsp;Ã´3ï¿½â€”ÃÃ¦â€“KsÅ¸aÅ“	u'Ã¥.Ã¾Ã˜Ã›TÆ’Å¸@^yËœÂ«
â€˜iÂ¿Ã¨ÃImwÃ§ÃºÃ©ÃŒ;Â¾ÃÅ¸Â£ï¿½Â¸Ã~bÃ‡ bï¿½Ã¤El?Â²kwÂ³ï¿½eÂ¯â€Â¶Â±Ã§fÃ±!NÃw9Ã¤r(Â¡â€™I&gt;Ã…jâ€šF&gt;^Ã­ooï¿½Ã›â€˜ï¿½Ã=	Ã€Ã¦ï¿½-oÃ·%Å Â­Â³@3tÃ­tÃ¸Å“Å’ÃŒAA?Å½20*7Âµâ€šSÃ½Å¸$â€“Ã±ZÃ…ÃŠ_bÂ§Ã›Â¼&gt;'{Å¸|TÂ¾";Â£obÂ¶Ãƒ0Ãˆ-Y~Ã“Å½w0ÃÅ“gÂ§RxÃ¦ï¿½Ã«Ã²aÂ½Ã®Ã–(Ã Â³Æ’Ã½}Â¹ÂºpfÃµÃ‡~sï¿½Ã€Ã¶Ã‰4Â·XÃ¿Â´LQ&lt;Ã¼Â¿aRoÃÃ½Ã£Ã²ÃºÃ³Å½Â£Â§NiKÂ­Ã¨Ã»tÃ­omsoÃ„VÂ¢Ã˜ï¿½0â€šWv[wÃ»Â¤Å“a&gt;ÃÃ¿iÆ’	Â¾?)Â±Ã»+mÃ”.Ã¬Ã¾=sÃhÃ¸QÂ¥(Â»Â¹Å½Â«KÅ“-Â¾ÃÃ¯Ã¤nÃ®!Ã¤t%FAAÃ…O,
Â¦ÂºAÂ¨,wrÃÃ´iMÃŒÂ¸Â·R&gt;QÃ³.UTÃ²
Ã â€¢Å¸Ã«Â¦1Â¼Âµx.Ã®.0&amp;Â·6ÃË†AÃ¥Â°Ã±Å½AÃ¨Ã¬GIÃ â€˜4Ã€ÃYÃ‹ÃŒ7Å’~Ã‘'Ã™Ãœâ€ºpx=Â¸nâ€¡Å ?Â¯Ã€bÃ”Ã‚Ã£OÅ¸lÂºÂ¤&nbsp;ËœÃ¯EÃƒÃ¡GUÃ‹Å¸ÃÃgÂ­*Ã‚Ã·-Ã½â„¢oÃ¥Ã…ÂªD3%Ã ï¿½Ãâ€œ{Â«Ã¦ÃÃÃ©ï¿½zÅ Â¶Ã°ï¿½.)c}6@KÃÃ½ï¿½Å½Ã–&lt;Ã­,fsÃ€'$
qï¿½.a\Ã²Gï¿½;Ã‘/ËœÃƒÂ¶Ã¶o,â€™:â€˜â€™p;Ã“Ã¾Â¿ï¿½ubÂ²XÂ¬Ã¤Âµ#Ã­geÃ³Ã‡R2Å g%ï¿½|vÂ¨Ã€â€ Ã»7Ã¶Â±CÂ­Â©"k8Æ’6:Å“ÃšrÃnN=zK;QU/dK8Ã­RÃ–Ã¬Ã£â€š0ï¿½TÃ«Å“Å â€¢Â¤â€™Ã¾UÂ¾Â»+o{mâ€˜omÃ¤Â²yÃ€t*Â®Ã…Ã˜Ã¿qï¿½J@UdË†D5_)?Â³XÃ´/9ÃÃÃ“vÃ€&lt;Â¼Ã§Ã¦Ã†;ï¿½Â­+Ã¬Ã“â€^Ã$Wâ€”-Å¡wo#w?uÃÂ¨Ãš8$cï¿½JÃyâ€”Ã»TmÂ±L}Ë†Â¯;znÃ™Â¸H8Ã§'Â¿Â½2#5â€ï¿½yfÃ·Ã·â€º/qâ€¡'Å¾Ã®\{â€™Ã’ï¿½Ã«Ã±GÃ‰K3%Â½ÃœÃ—â€ºÅ’wc7Ã™ÃÃ¡FÃ¢â€¦â€.AJÃ»Ã§ï¿½S-&nbsp;Ã±(	Â¹Ã˜Ã­Ã¡Ã›Ã«Â·~Ã€Ã¹Ã­ï¿½0Å½zwÂ§Â©6[Â¬Â¬Å“Â½Â­ÃcypÂ±Ã¤Â±Ã¡â€”rÃ¼Â£=sÅ’cÂ®iTÃ„4Ã¥â€¢â€ ï¿½Â´tb&lt;Â·]Â»Ã¸^ÃvÅ¡Å’[GÂª3X[Â¬Â³Yï¿½^Ã¤9Ã„Ã¾Â£zÂ¨by,ÃŒ@Ã¬*`Ã•OÅ“â€°if,Ëœâ€°Ã‰ï¿½Â´mÃzFâ€â€šGÃ¤Å“Å’Ã²jÃ¼Â¡/Ã™/]Â¡Ã“Ã­ÃŠÃ½Å¡o(Â©â„¢Â»ï¿½AÃ§&lt;Ã†3Å¾Å½ï¿½Â½Ã³,Âºâ€˜6Ã“[1qÃ¹D	Â±Ã·IXÂ¶Ã¬ï¿½Â·qï¿½GÃµÃ¸â€¢Ã¦Ã›\Ã£WXÂ¬Ã¢Å½ AÂ²-ÃŒËœÃ‡;D`dÃ¶Ã½ÃÃsÃ^Â²[Ã›gWÃ²Â­fÅ½PÂª,QÃ²PÅ¾3Â´Â£Ã·?Â»cÂ«Ã¾mÃ„Ã5Æ’Ã¥ÃªÃ¨Â¤EiÃ¥pÃ‹Ã›Ã¥Ã‰sÅ¸]Ã€ï¿½Ã¥0Ã‚Ã†Ã¶Ã—Ã§Ã–eQÃ¦Ã›2Â¨U^â€â€¦Ã¹HÃ‡\Ã¹â€¡4Ã¿Â¯Ã„"ï¿½4vÃ³Â¼Â¸oÃµÃ€Tï¿½Ã¦6Ã™yV Ã²&gt;NxÃˆÃ…[Ã²Mï¿½Ã¾ÃV7â€ Ã¬Â·ÃºWÂµâ€â€šÃ¸Ã‡Ã»Ã©ÃªjH?Ãw6ËœEÃ•ÃŒÃŒ&gt;ÃšÃ¾Y)Ã»Ã»Tmolâ€“Ãºï¿½#[/Ã™tÃ¬Ã‹Â§MÂ¸ÃÃ‹â€šÃ[w
Ã˜PÂ£Ã¬Â¿ÃÅ¡_Ã—Ã !Å¾NGÃ¶(p@RÃ‡P=Ã»=O?Ã¶Ã”tÃ¼DÃ€GÂ¨gNÃœmEÂ¦Ã’.ï¿½QÃ¶Å’vÃ¥Ã«Ã“â€¡9'â€˜Ã…UCâ€”Ã¶/Å“h{sÃ¶ï¿½Â¬Â¿LoÃšÃ~CÃµÂ«3Â¹_#PÃŒ:l;&gt;Ã‹.Nd#Ã®â€šÃ¸9ÃÃ¹Wï¿½^Â¡Ã¿_Ë†&lt;Æ’TÃ½Ã¼Ã›Â¬Ã‰Â¾Ã£p.Â¶Å½?Â¹Ã·ÃÃ¸Ã†	ÃÂ³\ÃƒzÃ£UTÂ´â€°Â¢â€â€¡/'mÃ›B)$Ã½Ã¡â€¦aÅ½Â§Æ’ZW[â€ ÃªÂ­%Â¼Â°Â¿Ãº
Ã„Å Ã‚L}ÃŒÂ¨Yâ€°Ã·Ã›Ã¸U6Â»ï¿½Ëœ]\ÂµÃŠk*A
Ã›Ã¼Â¥:giï¿½ï¿½Ã¹rNh9Ã§HÃª~]â€¹4ÂªÃ¬d1hÃ³Ã¼F=Â£cÂ®1Ã‰Ã¼ FÆ’NbÃ©Ã¶;Â¿ÂµpWk7â€˜Å¸b&gt;R3ï¿½^1Ã’Â´Ã•ÃˆsqlÃ—Ã›14gRÂ¡;Ã¡gÃƒâ€š}{PÂ·3[Ã®Ã¾ÃŒâ€™ÃªFâ€Ã¿Â¦Â³.SÆ’Å¾L/VÃ©Ã©Ã—Â¦ÃŠâ€˜Â´6â€¹Ã½Å¾Â­e<sÃ¤ÂµÃ‰b|ï¿½ÃœcqnÃÂ£ÃÅ¾Ã™Ã¢Ã€Â·Â·u[ÂµÂª@Â´câ€œÃ‰Ã›Â»!noÃŠrÃ£Ã“â€˜Å â€¢%Ã²sÃ‹Â°â€™Ã±Â´Ã‡'Ã­-Ã¤Â©*oÃŸÃƒyy.3ï¿½Â¡ÃˆÃ…Ã¹â€¹ÃˆfÂºÃ¾Ã„ÃªÂ²â€1lÃ±Ã³lï¿½Ã¼0~Â¼rgm}â€¹iÂ¾Ã‹iÂ¹]Ãâ€wÃ­sÃ€!â€¡'â€™iÃÃµhÅ¡ÃÃ½â€“Ã¦oÂ³Ã™Ã‹hoâ€¢â€Ã¢Ã§ Ã©Ã—="" Ã–Â§â€“s6#Ã•zÃ©,ï¿½ï¿½Â±Â¸â€¦'.nÃƒÂ»Ã¥Ã¬zÅ½Ã½Ã¨kâ€¹â€°Ã¤vÃ”zÃ­="" c'Ã¬aa@Ãâ€˜Ã¥Ã²oÃ§Ã«Å“bï¿½Ã«Ã°ï¿½Ã»râ„¢ÂµÅ“eÃ²Â®Ã‘``lÂ·8="" Ã‰ÃÅ¾Â§;{uÃ©l?cvÃ”mÅ¡ÃÃ¢Ã®Ã£kcnÃ§ÃŠÃ…ï¿½Â­Â¸`u$="" Å’Å½jeâ€“ÃªwhnfÂ½Â·Â¯â€”Â¦ÃŒÃ·{qÅ“Å¸ÃÂ½="" â€™Ãª9Â¬~Ã’uÆ’ï¿½Âµâ€šâ€˜ÃŸiltÃ›Å½Ã¿ï¿½â€¦o:Ã©Â»Ã–ÃÃƒvÂ·lmÃx$Ã…Â¶zÃ¤~piÃ†vÅ“ï¿½ï¿½1Ã‹Â¢Ã²Â£Âµ:lwÃ¶Ã’^y.6-â€˜wâ€Ã¹Â±Ã-â‚¬2zÂ¡Ã³p7Ã¶k]Â²3Â·Ã¥b8Ã¹Â¶Ã®qÆ’Ã—â€¦Ã§;Ã‘Â±g="" Å½tt="" Ã%"ÃÂ¼Å¾ï¿½Å Ã†Ã¬gï¿½qâ€˜@nÃ‘ÃŸb,.dÅ½ÃšÃ’ÃŸiâ€šÃ¨Ã€ÃfÃ†2,qÅ’Ã¡Å½zsgâ€œÃ»mâ€“kÃ·Å ÃÂ­}Å“wÃ¿ï¿½hqÃ·hÃÃƒ="" Å¾ï¿½Ã—â€˜k30â€¹vÂ¨.Å½â€¢Ã²â€ºmÂ¦-Ã¹Ã¾Ã¡h|Ã£7tÃ­Ã…i#oâ€Â¸Â¹3â€“Ãâ€ Ã'Å½="">MÃ…0wÃºÃ¯&gt;Ã·4	Â¹â€™iSPâ€Ã‡Â£Ã¡ËœÂ´â€œ2Å p[q%NF2@Ã¨GQs<sj-â€œÃªâ€™Â®Ã™,Â¾ÃŠÃ¹Å’w8ÃœÃ€Ã‹Ãy'Å“ÃˆÃ¦Ã jÂ¢Ã¬\mï¿½Ãacï¿½b1Ã†vÃ¾Ã¯Ã®Ã½Ã­ÃƒÃºÃ’bÃ®f)l.Â·6Ã¦sÂ¾1ÃŒÃ³ÃÃ¡ÃœÃ­Ãšï¿½ÃºgÆ’lbÃ›k6Å“\Ã©Å½.ÃÃ¨Ã¿ï¿½Â¥ ï¿½â€¡Ã™Ã²9<0#nÃÃ¢Å¸Å½Ã’Ã˜Ã©Ã–lgÂ±â€ºqÂºÂ»toÃgÂ¨Â Ã€Ã·n="Ãª5Å½W,4â€¦ÂºIï¿½Ã¿ï¿½Â§Ã®â€˜Fx9Ã†Ã¶" Â¶wcf:sÃ¡="" Â§Ã½Â£Ã»w}Â­Ã6â€¹hsÂ»Â¦2="" Å¾â€â€="">Wâ€š[aÂ§tÃ‘ï¿½Ã¶Ã-Ã‰g!r(Â¸Ã‰Sâ€œR]OÃ®Ã˜u
Ã¶Ã–vÃ…Mâ€Â¢9Å“â‚¬Ã§*Ã™râ€¦88ÃDÃ¡"Ë†M*\&gt;â‚¬TmÅ’Ãˆ7n'Ã¥$Ã›Ã¦tÃ€Â¯\Seâ€¹Ã¬Ã˜â€œWÅ½yld XÂ¨Å“#)Å“HÂ¤Â½Â³ÃÂ¯&nbsp;Â©Ã®dÂºâ€™;Â­I^ÃšÃºÃŸbâ€¦coÃŸwâ€â€ 9ÃÃ¹â€œÃ9Ã…)Â¹4_HÅ’uÃ¦MÂ©jÂªÃ›gÃˆÃ l$ï¿½Ã’Ã£Ã› Å¡Â©,SÃ›:Ã…Â©Â¤Ã²ÃªRâ€œÃ¶YÃÃ²Ãº	Â¡Hb2X8onÂ¦o*eÂ²Ã¢OÃ¸H3Ã§Ã¹Â¿(ï¿½9Ã†Ã­Ã›~Ã  â„¢Â¾)ï¿½f)gÂ¶ï¿½Ã§Ã“â€”ÃÃ•Â¦Ã›Ã¶Ã‹vÃ¦8â€ 	;XlÃ®
ÃÃ¸'Â·CnÃŒÂ­Â¹dÃ’Â¸â€šiÅ“ÃªHÃ„Â³Ã·â€šÃ§Ã‹8
\â€šÂªÃ½9,jÅ’6Ã¯s#ZiÃmÃµXvÃ‰Ã˜Â¶Ã™qÃƒÃ­ Â±?9ï¿½Ë†Ã©Å¡â€“Ã™cÃ”36â€™~Ãko#Ã¤pÃŠgÃ„"â€”ÃˆeÂ±B	Ã¨
 /AÃ¶XÂ­Â¼â€ºtï¿½Ã´â€ yâ„¢Ã¤Ã³â€šrÃˆ|â€“
TÃ§Â¨ Ã â„¢Ã­Å’&gt;UÃ¼q.â€Â«Âµâ€&lt;â€¦Ã™Ë†AÃšÃgwÃUvï¿½Ã‰ YÃâ€ºy-Ã¾ÃÃ¤Ãâ€˜eÂ´ Ã¹Å’Ã¹# `rÃ¥7Å¡6Ã£Ã¸FjGÅ¾HÂ¿Â´/â€ºFâ„¢#Kk@ï¿½Å¡7Ã â€šQÂ°Å T,â‚¬Â°â€˜Â³Å¾Â§ï¿½@ï¿½IÂ¼Â·â€¢[Å½V9â€šiÂ¥LÂ¿&lt;Ã˜Ã­Ã²Ã±YÃ‚Â¨'ï¿½23Å¡Ã*IÂ¨G
Ã«Âªâ€™Ã½â€™%gÃ˜ÃŠl-â€ hÃ-Ã¦mÃÃ£<rÂ­ÃŠÃ„Ã“.â€º"Â¾ÂªÃ‚Ã¬^ÃŒÃ€Ã¹{ÃŒï¿½â‚¬7pÂ¢0eÃ²&na â€™+:Ã‹fÃ‰Â§^:Ã‹Â¬nÂ­Â®Ã¶o+ÂµkÂ°9y0uâ€¢Â¿ï¿½ï¿½@Æ’Ãˆâ€¦Å¾Ã¢o4+Ã¦Â f*r="" Ã¼ÃŒ="" Ã¥â€$+â€™jÃ¥o3Ã…)y\Ã¨â€°="" Â½iÂ£Ã¾Ã‘rÃÂµÃÂ»irâ‚¬Ã¾`cÃ¦ÃÃ°â€œÃ“ÃŠâ€™ijâ€¦ÃŠÃ«hâ€¹Ã¦ÃÃ¼ÃŠasÃŒpdÃ¡="" kÂ¼Â ÃwiÃª3Â£n_sâ€¢Ã­Â´Ã‰="">Ã‰wg2}Â¶o-Ã­,Â»â€˜Å¸	ï¿½ÃŸ:Â»ÃŸ
Ã›Ã²y'vâ€šÃ”GÂ·HXâ€Ã†oÂ·3Â´â„¢@
Ã§ lÃ¨W(zÃ¼Â£â€™nÂ´6Â»ÃƒÃ¿Ã°â€¡%â€¹KÂ¿ÃŒÃ³IÃ€Ã§ÃŒ&gt;8#vzÃ¼Â¡m.Â¡Ã”â€œÃ»COskclÃ’Ã½Âª!q&gt;3Â¶Ã•?1eÃ€Ã§,:Ã£&lt;1ÂµÂ¯Ã¶Â¨$Ã©V&gt;Ã‚-Ã£=Â©8ÃÃ‘â€¡Ã³Ã·vÃ¤Ã¤(â‚¬GvÃ–o5XÃ¡M%?aeiw6c8ÃˆOâ€ºsï¿½Ã@Ã‡;Ã†â€ bÃ’Â«jIÃ–Aâ€ºÃ¬*â€ºJâ‚¬vn*JÃ£vÃ­Â¢B	kâ€“ÂªÂ·â€œÃ…Â¦Â¡Ã”ÂµÃ¶Ã&gt;Ã¬ÃƒÃ¶kSâ€˜cÃœÂ¤#Â·â€”HÃƒ/Ã‰Ã‹â€œâ€™G8ï¿½Ã¤â€“Ã†dÂ°ÂºcqxdkkÃÂ¤ËœPQ@ÃˆÂ¸!â„¢â€¢HXÆ’Ã±ï¿½(CÃŒrÃ‡jÃÃ¿	ï¿½22Ã¥BdzÃ¾Ã¨IÃ¥â€˜Ã†zÃ·1pmDÃ»Â¦â€˜tÆ’oÃ½Â¡Â¾/Â·Ã®Ã³Bï¿½Â¹
Â³+Â·Ã¯nÂ¨Ãˆâ€“Ã¹Ãˆ5ï¿½&lt;Ã—'EÂ³Wï¿½Ã—Â¡NYAÃ„ÃƒÃ·Â¤lÃšÂ¥Ã2TÅ’nÃ Ã›Ë†Â¶Â«3Ã˜Ã™ÃŠÃ–â€”vOÂ¹Â¸XÃ‚â€ºâ€™Å Qâ€¹*HÃâ€™Ã‹+1â€¢Ã¨jÃÂ­â„¢7Ã©&amp;Ã¬Ã“$Ã§P,_Â¼cqÃ²vÃ­Ã§Ã¤Ã‚Ã½ÃœÂ»Â©Y5Ëœ(`Ã¿â€|BÃÃÃ³Dâ€šA/^FÃ¿Â½Å’rÂ±$gÃ¥ÃŒÂ·â€˜Ã«)Ã¶Ã»&amp;{KkIfkâ€ºq?hC1eR3Â¯0bÃ§Â¨Â¤â€ Ãª-â€ Â¯tÃ’Ã–ï¿½Â¬*Ã˜â€˜Æ’6Ã€vc&lt;â€œÅ½ÃŒÂ°/Å¡ÃÃï¿½H@4â€š â€º|ÃÃ„Ã¬ÃŠÃ®Ã›Ã``Â³Ã¯Ã6Ã±Gï¿½Ã¶ÃÃ™ï¿½Ã‰ËœÃ¿g3}Ã¢Whâ€œhâ€y$Ã‰Ã­Ã€Â§\ÃÃƒeÃ¶â€Ã¾mÃï¿½Ã—Ã™â€â€šÃIâ€!KmÅ¾rÃ¼Ã›TÃ‚Ã“Â¥Kâ€¢bÂ¼â€˜Ã®Ã¦Â¼ï¿½ï¿½Â«Ëœ}â„¢Ëœcâ€šÃŒÃ€*Ã¤)BÃœh.PÃ¬Ã¨.D#Ã„F'6Ã¤oÃ›Â³2`Å¾;Ã‚Ã¹â€ºwÃ‘wPboÅ“XËœÃ¿Ã¡"Ã²Ã“Ã­G-Ã¾Â¯Ã·{Â¶Ã¯fÃŸÃ¾Â¨0\7Ã­Ã¤
Â¶Ã°ySEâ€™Y%Ã”&amp;â€°Ã-@Ã†Ã†Â¥Ëœâ€_ÃŒjÂ¸Ãˆ~7(@VÂ½Â»^JÃºDÃ‰
Ã½Â¼qÂ´Â·Ã¾P20â€¦Ã•Ã„â‚¬|Ã‘Å“â€”;Â¶0ÃÃ†H[Ã¡Â¥Ã†â€b'SÂ©Å¸Å¸[!|Ã Gâ€“Hâ€~Ã¨Ã¤|Â»x$â€ [â€¹vAÃ½ï¿½Ã¥ï¿½$Ã†Ã³&gt;fÃ¢Ã»&gt;aÃ³Æ’0!vÃ²Ã±ÃŸÂ¾Ã_Ã¿kJÃ±Ã˜1Â³k	Ã—Ã­l"	Ã¶Â¼g,Ã¢&lt;â€™Â²f6Ãœ8-â€šp+ÃqÃ´?ÃšÂ¶Æ’Ã¬ÃšmÂ¨ËœMd"f`Â¼â€“TÃ½Ã›â€¡F@Kâ€š#+Ã—`+â€ºgË†â„¢Ã¼Â¯Ã¸GH!Ã¿XÃŒÃŸÅ’Å’Â´nÃŸÂ¸6p
`Ã³Ã³Å¡â€Â¬;Æ’k&gt;QÂ´3F4Ã…]Ã¹ï¿½â€œ!Ã¢Â¥|Â½Ãn@lÃ¤TÂ­vâ€˜Buâ€°â€”ÃŒÃ’eâ€¦;â‚¬Â¬r;Â¬DÅ“Â¼Â¿w3MpÅ¡c}Â§QÃym,mhâ€ =ÃŸfÃ‡#u
Â¨	mâ€Ã£962ï¿½Â­Â«Â¿Â¶Â·IÃ¶â€œÂ·lÃ‹&gt;^7Ã®Ã™Ã¦Å“Å¾7â€šjÂ¤ï¿½&amp;Ã±Â°)Ã±)Å’UÂ¯'Ã¬Ã¾aÆ’nqâ€˜Ã—gâ„¢Å¾94Ã¹LÂ¾cs}vÃ’yâ€ºw=ÂºÂ¶U
Â³|Ã â€ Å Â£/â€”Â»Ã¥cÃÂ§Ãm3Â»hÂ®Ã¯Â¦!6&nbsp;â‚¬â€”eÃaâ€œÃ¥â€&nbsp;c_Â®Ã’ï¿½ÂªÃ‹Ã¦nÃ‘|Â³Âªâ€ AÂ¨Ã§;sï¿½Ã&gt;#Ã˜e\Ãƒâ€¡Ã£Ã¥Ãª*Ãµâ€™[Âª)ÃÃŒ#MY$Ã¢]Ã¤Â»Â¹â€3#Ã0vFx-â€°Ã’MAÂ¤Â²Âµy,Â®lÃ=Ãâ€¹k]ï¿½Å’6
â€™eÂ°Ã¬ÃªÃ€Æ’â€šEÃ«PÂ·Ã§ÃÂ²Ã³,aÂµÅ¾_Â´AÃ¶p&gt;Ã’vÂ¨$Â¨ÃƒÃ‹â€˜ÃŠÂ³Ã‡ÃŠTï¿½Ã¬ZU1Ã¹?Ã°Å½Ëœâ€ºÃŒÃÃ§yÅ¾gâ€ºÃn|ÃÂ¡yÃÃ¾â„¢Ã“Â®VÃ—Ã‰ÃÂ¦aÃ¾Ã…"ÃŸÃ¬CÃ·Â»ï¿½Ã˜vÃ§IÃŠdÂ°bp:Ã oÂ©Ã£â€™'Â¶Â¤BDÃ“â€™	Â´Ã±Ã¡Â¿xÃËœ&nbsp;%y8'Å½XqRÃ"Ã™DÃšï¿½ÃˆÅ¡Ã¦Ã’Ã [Ã¹VboÂ³Ã°
ï¿½Â¥Å â€š3ï¿½Â¸lÂ±Ãš@KÃ¥â€¹Ë†Ã¿Â¶Vâ€¢niÂ¡Å¾Â«Â·vÃœÅ½Â¢&gt;X`1Ã»Â£Ã¥HÃ†Ã‰Â£fÃÂµÃ“â€š&lt;ÃŸ,Â®\Â®p\Ã°ï¿½Ã»xÃKÃ¥ï¿½.UÂ­%Ã³]\Å¸!Â¼â€¢?f.Ã¡â€°mÂªqï¿½â‚¬HLnÂ§ÃÂ¶ÂªÂº|â€™K5Ã£Ã….Ã‹Ã¯#!1!Yâ€°`8Ã¹K@Qï¿½JdÂªÃ„ÃŒÃ¢Ã˜ZÃ¿l*EÃ¶â€™DÂ»6Â»â€˜ï¿½Â£9Ã†ÃÃ¼Â«â€g#LÃ‚ÃŸÃâ€¢oC\`0PÃ’Ãœï¿½Ã›Ã¸#Ã Ã•ÂµÃ³\}â€˜dâ€¢&amp;â€DZÃ¡Â¡eâ‚¬%vÃƒ!Â¶Ã²â€¦ï¿½ Å ÂºÃŒC#:,lÃÃ”Ã†FÃ¼qÂ½A+Å¾C&amp;Ccâ€šEsQÃ‡j-6Ã„-Ã†â€¡Ã¤Â¾Ã³Âº_0ï¿½Ã‡8Ã¶Ã\â€œ!nÅ“Ã Âº[SnVÃ¼[
#Ã½â€ºiï¿½6p
Ã®Ã†UÃ˜~Ã¦wÃ¤Â­/Âµ4â€¹Ã½Â¢|Ã´ï¿½bpÃ–Â­$,Ã¯m#~Ã¬Ã·H!Â²sÃ“ÂµÂ¸kÃ¹Å’Ã“Ã›L!Ã²Ã­DxÃâ€˜Ã·Â³Å“HÃ€Ã‰ÃšÃ³*JÆ’TÃÃšr,vâ€ cÃ“Ã¥$Â²Ã¼Â¯Ã“,0Â¹Ã€Ã­Ã‰Ã¤:CyÃ¶oÃ­câ€ =Å Ã¥Ã¤Ã£ÃƒxSÃ†Ã¡Â¸!Â¶Ã°8â€I5Æ’pÃ“]Ã½Â¢cÃ¥Â´p[Â©Ã¶Ã¤â€¦^â€¦Ã˜dÃ§â€˜ï¿½Ã†Ë†â€Ã°FÂ¶I4Â³Ãˆâ€™ÂµË†â‚¬U9;wu@Ã€Ã®Ã›â€œÅ’ï¿½@Â¡ï¿½YÃŒ@Ã†nÃ‘ÃŠ#Â¯Ã¯m';rN;Ã•Ã„â€¢$ÃÃ‚iÃšÃ˜9ÃAÃ´#=+/386HÃ³G,Hâ€ÃœËœâ€Â«Å¾â€¡ï¿½BÃ‡pÃ¥Ã[viÃÃ®Ã™Ã¢Ã²Å“oÃ½ÃŸÃŸr&nbsp;ÂºÃ²Ã·â€œÃ°4^{ËœÃ„f\Ã„lâ€¢_Ã''â‚¬9@*G]Ã€Ã³Ã˜Å¡Ã¥Ã¯Â¦ÂµhÂ¼Ã‹Å¸$Ã¨/yjÅ ÃªÃ‚MÃ™TPÃ£Â¡Ã cÃ±ÃlItÃ³Â¨Ã”Å¸Â¼(â€“Ã•Ã Ã¹Ã¥Ã Å’Ã Å“Ã£ÂºÃµuÃ‡5ÃŠÃªWA#]fE3Ã©Â²"Â¢XÃˆUnï¿½Å Ã‘Å’NÃ¬Ã£Å Cyâ€šAÃ•Æ’"Ã‹Ã½Å“ Ã›Â¸d|Æ’ â€¡ÃÃ€Â¿Ã«\Ãµ=ÂªÂ´Â¦Ã­dï¿½uqÃ½Â®w}ï¿½â€Ã›Ã¹j?â€¡vÃ†r~Ã¾Ã°sÃ†*ÂµÃÃ”v'Ã­IoÂ¨Gxq}&nbsp;Å¸Â²Â©â€¦
Qâ€šï¿½ï¿½7 R
Ã£#5XtÃ½ÂºtÅ¸fÂºÂ¸ÂºÃÃ‹Ã‘9&gt;Fx_ËœÂ©eÃ›Ã—Ã¥uÃœ1Å¡])x&amp;Ã›ï¿½Ã½Â¿Â´b`Ã²Â¼Â³Ã›1Ã£oL.Ã¬Ã¶ÃFÃ«ÃÃ¬â€˜8Â¿Sâ€¹Ã²Ã	Ã»Ã…â€¦Â³Å“mÂ¶*	Ã‘Ã¿dfÃ˜]â€¦uËœâ€š{Ã­-Â´Â¾qÃ²â€¢ÃGÂµWâ€™ÃÃŸS?dâ€°m,Ã¥Â´#ÃŒÅ“ÃvÃœ`sÆ’Â±rÂ©$Â¶&gt;Æ’ï¿½â€HÃ©'Ã¶RÃ&amp;Å¸Ã¿/Â»ÃšÃœ99Ã¹Â¶&lt;uÃ›Å’Ã´#S#râ€¹Â¿Ã¬ryÆ’ÃÃŸï¿½AÃÃÃŸï¿½ÃµÃÅ â€G&nbsp;
ÃŒ)kkÂ·Ã€Ã—MÃ^Â¤|Â£Ã¯cÅ’Ã³ÃˆÃ&amp;Â«Ã¯ÂµsÃ½Â¤!â‚¬ZÆ’ï¿½Â±â€œÂ¸ï¿½1Â»AÃ†y)Â±Å Â¿&gt;Ã£hâ€ºÃÂ¥sÃ¶@Â¢!Ã¾Ã®Ã¼tÃ‚Ã§Â³Ã¨Â¼fÂ²o&amp;Â¹â€Â¯Ã›}Ã¨Â£ÃˆÃœ&nbsp;|Â¹Ã¹Â»Ã¹â‚¬r{Ã¢Â¦hÂ¢Â·Ã…Ã¬Â±Ãƒqo6v[%Ã“nâ€¹&lt;â‚¬vÃ¼ÃƒÃ«Å Ãâ€™Ã”Ã›Ã¡[ÃŠ&amp;Qâ€¢Ã™*Â¸\Ã¶bÂ¤Ã­&gt;Â¡Â¹Ã®hHÅ’Ã¯01â„¢ï¿½Ã™oâ€Â©;Âºv9ÃÅ“tÃ¶Ã©Z6Ã’ÃœA&amp;Ã«ÂµiÃ¼Ã¢|Â¢8Ã›Å¸â€ºÂ·6Ã¬Ã£%â€”9Ã¨Fi-ÂºÃ¶6HÅ¡vlÂ¬Ã¿hTc;N	Å’Å½Ã™Ãˆ9Ã Ã²$LÂ«kqÃ…q&gt;eÃ‡Ãš2Â²Å¾$FÂ½Â°TÅ“Ã zÃ‘Ã½tÃ–ï¿½`lÃ¤Â¸RÃ©â€¹â‚¬ÃPÃœÂ¬w)Ã‰Ãˆl~Â¦ÂªÂ«`mO$â€˜Â¸R2Å¸NiByÂ«Ã²Ã—Ã‹7Ã¯-Ã®7Â·'Å½â€¹Å¾Â¸Ã‡"Â£8oËœ.Ã­Å“Ã¿&gt;iÂ­ÃŠÃ±Â¤zÆ’\}Å½5o FÂ©ï¿½Ã„Ã¿Âµï¿½Å½Â¹Ã¤Ã´Ã€#Â¨Ã™ivâ€°u_Â´Ã½Â°ï¿½Ã½Å“WÃ‰UnÃ¬Â¹ÃÂ³vÃ¾qÃƒs\Å“2Eâ€™1*ï¿½FÃ’Ã¬Ëœ'Â£duÃ‡Â¡Ã Ã—CÂ®ËœÃ˜Ã Â»{Ã•LÂ­qÅ¸Â³â€š9d;
â€™FÃ‘Ã†#8_Â¶â€\yÃƒ_Ã†a Ã›Ã¹[p0Ã‹]Ã™ÃˆÃOzÃâ€¢.|Ã²agXâ€ºâ€™Â»6Ã·&lt;Â¬Ã¶ Ã¡Ã¤ï¿½JÂ¿Ã¥qÂ¥ÃŠÃ–Ã³^ÃŠ7.&nbsp;nËœÃ€Ã¨Â¹*\0â‚¬Â»Ã”Å½:g2HcwÃ»Â»â€Ã¦KÃvÃŠÂ²Å’ï¿½â€º' IÃˆÃ´Ã02yÃ¿â€“&amp;LÃ Ã¹Â¹sÅ¾GrÂ¿P9Ã­NÂ·â„¢Ã€Ã²Ã¤iâ€¦Â«02Â¬dr=BÂ±[Ã“5.Ã®UÃš0H|Ã§Â±Ã§Ã©Ã—Â­1H8Â²yÃ¶ÃˆÃÃ¾Âµ#:o1ï¿½Â²Â¥Ã—ÃšÃ¿Â±Ë†â€¡jÃ›Ã¹â€ºï¿½;Cw`Ã™Ã‰ â€˜â‚¬8Ã¡nÃŒÃ›#Ã¾Ã–Ã»OÃ™Ã•Ã6Ë†ÃÃŸ3nIÃ .AÃ‰Ã¯ÃsYVÃ¾]Â¹SÃ…Ã°ï¿½Â³â„¢Ã°A=Ã¶ngÃ‡RÂ¤Ã„â„¢V;%\Ã…Ã‚\. _ÂµÃ´|Ã·Ã›â€ #:Ã§Â¥Ã•Â¸kÃ‡â„¢NÂ¥Ã¶Å¸Ã­SÂ·Ã¬{ÃSnrÂ»ÃŠÃ gqlÃ¤t=Ã€â€°â€¦Ã§ÃšÂ³Ã¾â€œÃ½Âº,@â€¡ÃŠÃ™Â³`Ã­ÃÃŒsÅ’c#Ã¦Â«5ÂªYÂ¿Ã˜.R	Ã®n1]}Â©Å Ã‚8H'Â¨Ã«ÃÅ½Â¨m@Ã¬Â¿Ã´syï¿½ÃŸnÃ»S*FÃ­â„¢Ãš	 |Â¿^Ã¯@%Â½ÃŒÂ²fn$Â¼Ã¹ÃÃˆ
iÃÃÃ³+â€™Ã™nÂ¹'Â©Â­â€“O-Ã…Å¸ÃšMâ€˜	Ã¶Ãâ€™-Ã€Ã§oÃŒrÃœG Ã¿xbâ€ºÃ¶EÂ½Ã¿DÂ·X-Ã®-â€â€°Â¦Ã»Q9Å’Å’Å“Å¾0{
rË†ÂµÃœZÃ…
Â¬6Ãª&lt;Ã¨~Ã”AÅ¸â€œÅ’Â¨'ï¿½Å½Ã½xÃ‰Ã¢ï¿½Ã‹(Hâ€â‚¬nÂ¿Â°â€¹â€šÃŸ,&gt;a~8Ãˆ!Â¶Ã®â€˜Ã‡|nÃ¢Â§ï¿½ÃœÃ‚Â¿Ãšj&gt;Ã‘&lt;ÃŒÅ’Ã­ÃŸÃ¼Cv7g?Njâ‚¬X]NÂ¦ â€°,â€¦6Å¸j9fÃ nÃ¥I&lt;ï¿½p8Â¸n-Ã­GÃ›gâ€ â€¹Yâ€°[-Ã™Ãzdc=Ã‰Ã›Ã†rpqL	Ã¥39VÃ•MÃâ€ºhÃ»UË†Æ’ï¿½Â¹Â»Å’w'Å½rOJÅ¡fÂ½Â®
ÃÃ¶Ã+Ã¥ Ã²Ã¶cÅ½Å¸/Â®p6ÃµÃœN(â€ºxÂ¬Ã‹ËœÃ¡Â¹{Â¡Ã»â€¡[â€™|Å’Ã´Â¶Fsï¿½Ã‡SÃ)Â·[SÃ½Å¸*DÃ·Â®AKÃtÃ€F0	Ã›ï¿½â€dÅ“Ã³Ã“ï¿½@ï¿½8&gt;Ã˜foÂ±}Â¤Ã«}n7â€ºqÃâ€Ã„Â¡wo@8Â«6M;n/ÃšÃ?Â´Å¾FÃ’yÃœTÂ±,ÃŸÃ»ËœÃ£Ã¤
ÃÅ #pÃŸÃ™Ã¶ÃEÂ­Ã¬C/z.Ãœ	GFPUrÃ›Â²22zï¿½ÃhÃ™â€¡Ã•rÂ¶ÃƒblÂ¿Ã£Ã¤Ã‡3fÃ¥GÃ
Â±ÃµlÂ³â€“Ã«â€šhVÃ!Ã²Ã‡Ã˜6aâ€¢ÂµÃ¹Å“6Ã¬|Ã„â€™&lt;ÃœÃ½Ãœm8Ã«Å’|Â¦ÂµÃÃ™Ã—lÅ¸gâ€Â»2foÃœ1Å“Ã ï¿½Å“Ã¿Â·Å“wÃfiÂ³Ã½Â¾1Â¨ÃšÃ¿Â¢Ã˜[YFâ‚¬Â¬Â¸'â‚¬ÂªÃ›Â¸Ã¤Â©Ã©Æ’Å½MmÃ›\Ã¹ï¿½Â®&nbsp;ï¿½BÃ™efVÃˆÃ2xÃ¾Ã®09Ã R+Ã‰*51iÃ¶RÃ±â€¹-Â¡Ã™Â³ï¿½â€”qeÃ€8Ã†
Ã±Å’Æ’Ã¯$â€ºÃƒÂ©ÂºÃ»!Ã”3/Ã˜Ã¾Ã¸vÃ±â€™FÃ¬Ã£Ã¯Ã­Ã‡JÂ²ï¿½5â€º4Ã“&lt;â€”ÃÃ©Ã¥FÂ°Ã¤Ã‚Â©\Å“gâ€™X
Â¸ÃºÃ“KMÃº#K#Ãpd1L!bÃˆÃï¿½â€œÅ½Ã™Ã¥ï¿½Â­Ã¾Â¿Â­Ã¦_.Vâ€™Â²Â¶Â¸Ã‘(â€˜KÃˆfW8\Ã§Â¦N:â€°Å G}[â€ºÂ·â„¢&gt;ÃœGl}Ã­Ã˜Ã¹Â¸!â€°Ã†Ã¯Ã²Ã¤`&lt;Â¯Å¡Ã­eÃ‚-Q#C-Ã—Ã™W.â‚¬ï¿½QÂ°Æ’Ã‡Ë†8,2Ã™$â€¹Nâ€[Om*Ã½Â­Â¾ÃŒÂ¹Ëœâ‚¬AÃqÃ·Â°~aÃ³cÂ¡VÂ´KtO/JXM-(Â¼,Ã²no;I'Å’uÃ†AÃ›ï¿½Ã³T%-&gt;Ã‹Ã¥â€¦Â·â€¢â€™Ã›Ã¥Ã³7Ã¯ÃˆÃ¯Â»;Ã°0rÃ„Ã¿~JÂ±Ã‘^/ÃšÃ¬ËœÃ›Ã™Ã›&lt;ÃŸhÂ·Ã£Ã·Ã¤Å“Ã sÃ8$â€œÃˆb&nbsp;Ã»UÂ¹ÂµÃ¾Ã“gÃ†â€œÃ¥Ã­Ã»Âµ@3Â»ÃµÃ;Â¹=2hÃ‘Â³hÂ¶jbÂ¤/â€,Å Â´â€¦ËœÃ­Ã€9R[dÃ£Â®FM$Â²â€°%ï¿½Ã»b8â€™Ã®9_Ã»4+Iâ€°1Â´Â¡mÅ’Ã€eÂ¶cÃŒ
z|Â¹ÃeÂ¹ÂºK7â€”Ã§Ã­:}ÃƒD-Ã Ã Ã¹$ï¿½â€â€¢`6Ã vÃªOÃÃ€ÂªÃ³Â§JÂ±Ãª,nÃ®/&amp;oÂ±Ã‹Ã¥â€š-Ã‰Ã€BcaÃ‰RUAÃ›Å’Ã³Å’Ã2Å¾%Ã³cÂ¸ÂºÃ¿	Ã†ÃLÃ½Ã›Â¨-â€šÃYÃ˜fÃ²Ëœ&nbsp;Ã·Ã†&gt;TÃŸ"ÃŒÃ³Ã©Ã©Ã«Ãâ€¹Ã¶Â¨wâ€™â€˜Â¦FÃ²Â»ËœGÂ»"0ÃƒÃŒmÂ¿Ã‚;Ëœ. tÃ“&amp;`ÃºÃ”Ë†ÃUÃ¦Xâ€Å’Ã®mÂ¾aOÂºd!Ã›Â¸Ã£ÃÂªâ€™Ã#Ã©â€“Â¤CÂ¬FÂªgÂ»Ã€JÂ£â€ Ã°Â¥Ã¹Ãœï¿½TdÂ¨ÃÂ¥1Ã‡â€“Ã®4`â€™Ã‰$Å¸Ã±3ÃœÃ¸w*Ã®Ã˜6dÃŠwFâ€ 08Ã€Â¨Â¢Kdâ€¡Ã‹Ã“Å½Ã½â„¢</rÂ­ÃªÃ¤Ã³.â€º"Â¾ÂªÃ¢Ã¬^Ã¬Ã Ã¹{Ã¬ï¿½â‚¬7pÂ¢0eÃ²&na></sj-â€œÃªâ€™Â®Ã¹,Â¾ÃªÃ¹Å“w8Ã¼Ã Ã«Ã®y'Å“Ã¨Ã¦Ã jÂ¢Ã¬\mï¿½Ã¾acï¿½b1Ã¦vÃ¾Ã¯Ã®Ã½Ã­Ã£ÃºÃ²bÃ®f)l.Â·6Ã¦sÂ¾1Ã¬Ã³Ã®Ã¡Ã¼Ã­Ãºï¿½ÃºgÆ’lbÃ»k6Å“\Ã©Å¾.Ã¾Ã¨Ã¿ï¿½Â¥></sÃ¤ÂµÃ©b|ï¿½Ã¼cqnÃ¾Â£Ã°Å¾Ã¹Ã¢Ã Â·Â·u[ÂµÂª@Â´câ€œÃ©Ã»Â»!noÃªrÃ£Ã³â€˜Å¡â€¢%Ã²sÃ«Â°â€™Ã±Â´Ã§'Ã­-Ã¤Â©*oÃŸÃ£yy.3ï¿½Â¡Ã¨Ã¥Ã¹â€¹Ã¨fÂºÃ¾Ã¤ÃªÂ²â€1lÃ±Ã³lï¿½Ã¼0~Â¼rgm}â€¹iÂ¾Ã«iÂ¹]Ã¯â€wÃ­sÃ !â€¡'â€™iÃ¯ÃµhÅ¡Ã¾Ã½â€“Ã¦oÂ³Ã¹Ã«hoâ€¢â€Ã¢Ã§></pÂ­â€!~Ã«h-nÃ§Ã¸Ã¶Ã¬uÃ¡6~Ã±Ã§Ã¿ÃµbÃ»wÃ¹ËœÃ®Ã®:goâ€°Ã¹j+k{Â»Â©mÂ¶Å¾Â²Ã¥Âªb'7râ€¹â€š></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.graybeardgames.com/download/diablo_pitch.pdf">http://www.graybeardgames.com/download/diablo_pitch.pdf</a></em></p>]]>
            </description>
            <link>http://www.graybeardgames.com/download/diablo_pitch.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844666</guid>
            <pubDate>Wed, 21 Oct 2020 04:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AOC plays Among Us live on Twitch and has 330k viewers]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24844474">thread link</a>) | @tomashertus
<br/>
October 20, 2020 | https://www.twitch.tv/aoc | <a href="https://web.archive.org/web/*/https://www.twitch.tv/aoc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.twitch.tv/aoc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844474</guid>
            <pubDate>Wed, 21 Oct 2020 03:22:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How the Jamstack is failing at comments]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24844172">thread link</a>) | @leoloso
<br/>
October 20, 2020 | https://leoloso.com/posts/jamstack-failing-at-comments/ | <a href="https://web.archive.org/web/*/https://leoloso.com/posts/jamstack-failing-at-comments/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>A few weeks ago I added <a href="https://wptavern.com/matt-mullenweg-clarifies-jamstack-remarks#comment-344626">this comment in WPTavern</a>, on an article where WordPress founder's Matt Mullenweg clarifies his earlier remarks that the Jamstack is "a regression for the vast majority of the people adopting it".</p><p>Since I like owing my own content, I reproduce it here in my own blog.</p><hr><p>I think Mattâ€™s brutal honesty is welcome, because most information out there about the Jamstack praises it. However, it also comes from developers using these modern new tools, evaluating their own convenience and satisfaction. As Matt points out, that doesnâ€™t mean it makes it easier for the end user to use the software, which is what WordPress is good at.</p><p>I actually like the Jamstack, but because of how complex it is, itâ€™s rather limiting, even to support some otherwise basic functionality.</p><p>The definitive example is comments, which should be at the core websites building communities. WordPress is extremely good at supporting comments in the site. The Jamstack is sooooo bad at it. In all these many years, nobody has been able to solve comments for the Jamstack, which for me evidences that it is inherently unsuitable to support this feature.</p><p>All attempts so far have been workarounds, not solutions. Eg:</p><ul><li>Netlify forms: no hierarchy, so can post a comment but not a response (unless adding some meta to the comment body? how ugly is that?)</li><li>Storing comments in a GitHub repo: it takes a long time to merge the PR with the comment</li></ul><p>Also, all these solutions are overtly complicated. Do I need to set-up a webhook to trigger a new build just to add a comment? And then, maybe cache the new comment in the clientâ€™s LocalStorage for if the user refreshes the page immediately, before the new build is finished? Seriously?</p><p>And then, they donâ€™t provide the killer feature: to send notifications of the new comment to all parties involved in the discussion. Thatâ€™s how communities get built, and websites become successful. Speed is a factor. But more important than speed, it is dynamic functionality to support communities. The website may look fancy, but it may well become a ghost town.</p><p>(Btw, as an exercise, you can research which websites started as WordPress and then migrated to the Jamstack, and check how many comments they had then vs nowâ€¦ the numbers will, most likely, be waaaaaaay down)</p><p>Another way is to not pre-render the comments, but render them dynamically after fetching it with an API. Yes, this solution works, but then you still have WordPress (or some other CMS) in the back-end to store the comments :P</p><p>The final option is to use 3rd parties such as Disqus to handle this functionality for you. Then, I will be sharing my usersâ€™ data with the 3rd party, and they may use it who knows how, and for the benefit of who (most likely, not my usersâ€™). Since I care about privacy, thatâ€™s a big no for me.</p><p>As a result, my own blog, which is a Jamstack site, doesnâ€™t support comments! What do I do if I want feedback on a blog post? I add a link to a corresponding tweet, asking to add a comment there. I myself feel ashamed at this compromise, but given my siteâ€™s stack, I donâ€™t see how I can solve it.</p><p>I still like my blog as a Jamstack, though, because itâ€™s fast, itâ€™s free, and I create all the blog posts in Markdown using VSCode. But I canâ€™t create a community! So, as Matt says, there are things the Jamstack can handle. But certainly not everything. And possibly, not the one(s) that enable your your website to become successful.</p></div></div>]]>
            </description>
            <link>https://leoloso.com/posts/jamstack-failing-at-comments/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24844172</guid>
            <pubDate>Wed, 21 Oct 2020 02:01:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Virtual Corn Maze]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24842857">thread link</a>) | @jtolmar
<br/>
October 20, 2020 | http://noisyowl.com/corn/ | <a href="https://web.archive.org/web/*/http://noisyowl.com/corn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://noisyowl.com/corn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24842857</guid>
            <pubDate>Tue, 20 Oct 2020 22:12:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Spec, No Problem: How I Autogenerated an API Spec for Notion]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24842329">thread link</a>) | @jeanyang
<br/>
October 20, 2020 | https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion | <a href="https://web.archive.org/web/*/https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-398c45a3fde378e52a9c"><div><p>Software is eating the world and APIs are at the forefront. Not only do APIs give developers instant access to powerful functionality, but their programmability also makes it easy for developers to integrate disparate pieces of functionality.</p><p>But today, this only applies to <em>documented</em> APIs. This means the company responsible for the API has made a conscious choice to expose the APIâ€”and theyâ€™ve allocated the resources to creating and maintaining documentation. This also means there are a <em>lot</em> of SaaS APIs out there that could make usersâ€™ lives easier, but that havenâ€™t been documented.</p><p>This blog post is about a new feature that my team and I built after I spent a painful couple of days figuring out how to script against Notion. After my experience trying to learn the undocumented Notion API, we decided to automate the process of learning web APIs so that nobody would have to suffer like this again.</p><p>In this blog post, I talk about:</p><ul data-rte-list="default"><li><p>How I tried to automate against the Notion the hard way.</p></li><li><p>How this led my team at Akita to build a new feature to automatically learn undocumented APIs.</p></li><li><p>How to use Akita to <em>automatically</em> learn APIs, including the Notion API. (See what we learned on SwaggerHub <a href="https://app.swaggerhub.com/apis/Akita-Software/notion-api-experiment/0.0.1?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>!)</p></li></ul><p>To anyone who wants to learn an undocumented APIâ€“or document your own API so people donâ€™t have to do thisâ€”you may be interested in checking out <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">our private beta</a>!<br></p><h2>ğŸ• First, some background</h2><p>Iâ€™m Chris, the product manager at Akita. I joined Akita after eight years at Twilio, where I helped define products like Twilio Marketplace and Twilio Channels. While I was making APIs easier to use at Twilio, I also saw how APIs made software development harder. For instance, the rise of internal and external APIs make it much more difficult to prevent breaking changes. These observations led me to join Akita about a year ago.</p><p>At Akita, weâ€™ve been working to give structure to the interaction graph of APIs, for instance to <a href="https://www.akitasoftware.com/blog/2020/9/22/faster-better-earlier-catch-breaking-changes-by-diffing-api-behavior?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">detect breaking changes in web apps</a>. Akita watches API traffic to automatically generate API specs and infer implicit API contracts. Core to Akitaâ€™s approach is diffing API specs and contracts learned across different environments. Weâ€™ve been working hard to make this technology easily accessible to developers, no code changes required, in just minutes.</p><h2>ğŸ’¡ An observation about Notion&nbsp;</h2><p>Now for how I came to autogenerate an API spec for Notion.</p><p>As the product manager at a small startup, I spend a lot of time making sure that the right information gets to the right place. Customer feedback, blog posts like this one, product usage, and engineering metrics are just a few of the things I need to track. I also require some sleep, food, and the occasional trip outside. How do I manage to keep up? Thatâ€™s easy: AUTOMATE ALL THE THINGS!!!</p><p>When I joined Akita, I realized that Notion was what we needed to organize information across the team. But the problems started when we needed to add <em>new</em> information to Notion. For instance, we keep team meeting information in Notion. Most of our team meetings began with â€œDid someone create a Notion page?â€ or â€œWhere is the page from last weekâ€™s meeting?â€ The same thing would happen during customer meetings.</p><p>Given how many meetings we have a week, I figured we could get several hours back <em>a week</em> if we could get computers to automate creating the Notion page for us. All we needed was to figure out how to automate Notion.<br></p><h2>ğŸ˜° Thwarted by the Private API</h2><p>The catch? Notion doesnâ€™t have a publicly documented API.</p><p>The good news is that itâ€™s still possible to use an undocumented API. Itâ€™s easy. You could set up a headless browser to automate clicks or turn to that olâ€™ standby Grease Monkey script for watching your browser traffic. I recently read a blog post where the author ran a proxy and executed a man-in-the-middle attack in order to build a calendar widget for one of his favorite websites.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_27960"><div><p>Okay, itâ€™s not easy. It took me a couple days of hacking to get a <a href="https://gist.github.com/chriscorcoran/51b2f37a807e6f09cbbf320b63b8931a?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">reasonable solution working</a> the first time. And the undocumented API problem is prevalent among newer SaaS tools, and it makes sense: APIs are hard to build, document, and maintain. If more of these tools had APIs, I would automate more and integrate them more deeply into our workflows.<br></p><h2>âš¡ï¸ Using Akita to learn the Notion API</h2><p>I wondered if there was a better way.</p><p>Then I realized: oh wait, Iâ€™m working on building a tool that <em>lets you generate API specifications by monitoring network traffic</em>. Surely we could use Akita to build API specs from watching my interactions with Notion?</p><p>But it wasnâ€™t completely straightforward. Up to this point, we had set up Akita with the assumption that the user wants to document their <em>own</em> API, so Akita worked by listening to network traffic through an agent.</p><p>But when I posed this problem to my engineering team, they came up with a solution that let me generate this beautiful rendition of the Notion API spec.&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_67186"><p>This feature was a game-changer! Now that Akita could learn this spec, I had an OpenAPI specification that detailed every endpoint, parameter, and property that the Notion frontend used. And what made this <em>really</em> useful was Akitaâ€™s analysis layered on top.</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_72403"><div><p><a href="https://www.akitasoftware.com/blog/2020/9/29/taking-types-to-the-next-level-stop-api-bugs-by-inferring-data-formats?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">Akita Data Formats</a>, detecting precise data formats like unique IDs and specific datetime RFCs,&nbsp; and API Relationships, surfacing which endpoints accept values of the same data type, made it easier to understand how the endpoints worked together.</p><div><p>You can check out the API spec we were able to generate on SwaggerHub <a href="https://app.swaggerhub.com/apis/Akita-Software/notion-api-experiment/0.0.1?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>.</p></div><h2>ğŸ›  How it works</h2><p>The secret to this new feature? HAR Files.</p><p>Previously, to run Akita you ran an agent alongside where you hosted a service. The agent would listen to network traffic and allow you to autogenerate API specs without having to make code changes or use a proxy. While this was super easy to use if you were learning your <em>own</em> API, it was less helpful for learning other peopleâ€™s web APIs. Our new HAR file ingest allows you to learn <em>any web API</em> that relies on AJAX-style requests, <em>using any major web browser,</em> in a matter of minutes.</p><p>HAR Files are a little known feature of the Webkit Developer Console (available in major browsers including Chrome, Firefox, Safari, and Edge) that allows you to record requests, performance metrics, and other interesting data from a debugging session. It turns out that itâ€™s not so hard to extend Akita to accept HAR files instead of network traffic. HAR files are key to making it easy to autogenerate API specs, without needing headless servers or proxies.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_160214"><p>Below I show a screen capture of me trying to break this new feature by returning to my old nemesis, Notion. In just minutes, I was able to automatically learn what had previously taken me days to uncover!</p></div><div data-block-type="2" id="block-yui_3_17_2_1_1603217507152_122897"><div><p>All you need to do in order to generate a spec is:</p><ol data-rte-list="default"><li><p>Navigate to the website you want to learn an API for and start network log recording. (See instructions across different browsers <a href="https://support.zendesk.com/hc/en-us/articles/204410413-Generating-a-HAR-file-for-troubleshooting">here</a>.)</p></li><li><p>Interact with the website to generate traffic.</p></li><li><p>Save your HAR file and use the Akita CLI to upload it to Akita.</p><pre><code>akita har ingest --service {SERVICE} {PATH_TO_HAR_FILE}</code></pre></li><li><p>Youâ€™re done! Youâ€™ll get a link for the generated API spec. ğŸ‰</p></li></ol><p>Note that if youâ€™re on the other side and want to learn a spec for your <em>own</em> API, the steps you follow are even simpler!</p><h2>ğŸ&nbsp; Itâ€™s your turn to live your best life</h2><p>Now that HAR file ingest is an official Akita feature, you, too, can wield this incredible power. With our new HAR File Ingest feature, you can now use Akita to learn the spec of any website you are usingâ€”and write time-saving automations like my script <a href="https://gist.github.com/chriscorcoran/51b2f37a807e6f09cbbf320b63b8931a?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>.</p><p>If youâ€™re interested in autogenerating API specs, sign up for our private beta <a href="https://www.akitasoftware.com/get-invite?utm_campaign=2020_pre_launch&amp;utm_medium=blog&amp;utm_source=2020_10_20_product_update">here</a>. Weâ€™d love to see what you think!</p></div></div></div>]]>
            </description>
            <link>https://www.akitasoftware.com/blog/2020/10/20/no-spec-no-problem-how-i-autogenerated-an-api-spec-for-notion</link>
            <guid isPermaLink="false">hacker-news-small-sites-24842329</guid>
            <pubDate>Tue, 20 Oct 2020 21:02:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unconditioned Texas Garage Lab â€“ 1 year later]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24842218">thread link</a>) | @monstermunch
<br/>
October 20, 2020 | https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/ | <a href="https://web.archive.org/web/*/https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.networkprofile.org/content/images/size/w300/2020/10/2020-10-20-14.21.11.JPG 300w,
                            https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.21.11.JPG 600w,
                            https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.21.11.JPG 1000w,
                            https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-20-14.21.11.JPG 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.networkprofile.org/content/images/size/w2000/2020/10/2020-10-20-14.21.11.JPG" alt="Unconditioned Texas Garage Lab - 1 year later (Its all fine)">
            </figure>

            <section>
                <div>
                    <p>A little over a year ago I mounted a rack in my garage, threw a Cisco Switch in there, an APC UPS and my Flight Tracking setup, and a second ESXi host. See below for the original:</p><figure><a href="https://blog.networkprofile.org/mounting-a-network-rack-in-my-garage/"><div><p>Garage Network Rack with 10G Fiber</p><p>This details my 12u rack in my detached garage which has a 10G uplink to my mainnetwork I needed some networking in my detached garage for an access point, my flighttracking setup, 3 x PoE cameras and some future additions, and instead ofrunning multiple Cat6 cables across, I decided to just runâ€¦</p><p><img src="https://blog.networkprofile.org/favicon.ico"><span>NetworkProfile.org</span></p></div><p><img src="https://blog.networkprofile.org/content/images/2020/01/ndEotkV-1.jpg"></p></a></figure><p>Its been through the "cold" of a Houston Winter and the heat and humidity of the brutal Houston Summer. To date, nothing has even complained that its hot, in fact the fans are not even spun all the way up on the switch</p><p>The temperatures actually never got above what I see equipment go to in my air conditioned lab in the Houston, which proves that as long air is flowing through the hardware, its fine. No equipment failures, no battery failures, no SSD failures, no HDD failures, no Transceiver failures</p><p>I replaced the UPS batteries last week, but they still reported 1 hour of runtime, and passed the test fine. I now use those batteries in a spare test UPS, they were 7 years old...</p><p>There is however a LOT of dust... but it has not affected the systems. I plan to give them a good clean later on this year</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.48.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.48.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.48.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.48.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.48.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.19.02.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.19.02.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.19.02.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.19.02.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.19.02.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.18.50.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.18.50.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.18.50.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.18.50.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.18.50.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.45.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.45.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.45.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.45.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.45.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>There is a nice dust/dirt stain in the plywood behind the switch. I guess that means a lot of the dust ends up out the switch at least!</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/2020-10-20-14.17.42.JPG" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/2020-10-20-14.17.42.JPG 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/2020-10-20-14.17.42.JPG 1000w, https://blog.networkprofile.org/content/images/size/w1600/2020/10/2020-10-20-14.17.42.JPG 1600w, https://blog.networkprofile.org/content/images/size/w2400/2020/10/2020-10-20-14.17.42.JPG 2400w" sizes="(min-width: 1200px) 1200px"></figure><p>There isn't much more to say, because nothing of note happened, it all just works fine...</p><p>Apart from a power outage during electrical work I had done, its been running 24/7 with no problem</p><figure><img src="https://blog.networkprofile.org/content/images/2020/10/image-2.png" alt="" srcset="https://blog.networkprofile.org/content/images/size/w600/2020/10/image-2.png 600w, https://blog.networkprofile.org/content/images/size/w1000/2020/10/image-2.png 1000w, https://blog.networkprofile.org/content/images/2020/10/image-2.png 1332w" sizes="(min-width: 1200px) 1200px"></figure><p>Full Equipment Listing for those Wondering</p><ul><li><strong>Cisco Catalyst 2960-S</strong> PoE+ 10G 48 Port Switch (48 x 1G PoE+ and 2 x 10G SFP+) connected back to my main rack with OM3 Fiber @ 10G</li><li><strong>APC SMT1000RM2U</strong> UPS</li><li><strong>Lenovo M73 Tiny</strong> (i5, 16GB DDR3, 800GB Intel DC S3700 SSD, 5TB 2.5" SATA HDD) Running ESXi 6.7</li><li><strong>Raspberry Pi4</strong> running ADSB Flight Tracking duties (FlightAware, ADSDX and FA24)</li></ul><p>If you are wondering if you can run your lab in your garage, go for it. You have my permission </p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.networkprofile.org/unconditioned-garage-lab-1-year-later/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24842218</guid>
            <pubDate>Tue, 20 Oct 2020 20:47:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swedish virologist says her country's strategy has failed, but nobody admits it]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24841972">thread link</a>) | @colinprince
<br/>
October 20, 2020 | https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Sweden's health authority maintains its approach to COVID-19 was a success. But our guest says the data speaks differently, and that new measures announced Monday are insufficient.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5768038.1603128831!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/1228596918.jpg"></p></div><figcaption>People walk on Stranvagen in Stockholm on Sept. 19. The country has had no lockdowns or mask policies during the coronavirus pandemic. <!-- --> <!-- -->(Jonathan Nackstrand/AFP/Getty Images)</figcaption></figure><p><span><div><div role="button" tabindex="0" title="Swedish virologist says her country's COVID-19 strategy has failed, but nobody will admit it"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/942/999/AsItHappens-podcast-640x360.jpg" alt=""></p><p><span>As It Happens</span><span>6:45</span><span>Swedish virologist says her country's COVID-19 strategy has failed, but nobody will admit it</span></p></div></div></div></span></p><p><span><p>Eight months after the start of the&nbsp;global pandemic,&nbsp;Sweden is&nbsp;changing its COVID-19 strategy â€” but&nbsp;virologist Dr. Lena Einhorn&nbsp;says it's far too little, too late.</p>  <p>Last spring, as other countries went into lockdown, Swedish citizens were mostly living as usual. The government issued advice and guidance in place of rules and restrictions. School and work went ahead. Many businesses stayed open.&nbsp;</p>  <p>But as of Monday,&nbsp;Sweden's per capita death rate from COVID-19 was the 15th highest in the world, or 13th if you exclude the tiny countries of Andorra and San Marino,&nbsp;<a href="https://time.com/5800901/coronavirus-map/">according to data from Time magazine and Johns Hopkins University</a>.&nbsp;</p>  <p>Now Sweden&nbsp;is shifting its policy. <a href="https://www.telegraph.co.uk/news/2020/10/17/sweden-considers-local-lockdowns-shift-coronavirus-strategy/">According to the Telegraph</a>,&nbsp;starting Monday, the government has empowered regional health authorities â€” in consultation with the federal public health agency â€”&nbsp;to instruct citizens&nbsp;to stay away from crowded spaces like shopping malls, museum, gyms, and concerts, and avoid taking public transport or visiting the elderly. However, there will be no&nbsp;legal or financial consequences for non-compliance.</p>  <p>Einhorn,&nbsp;a virologist, author and filmmaker in Sweden,&nbsp;is one dozens of medical experts who have been critical of the country's COVID-19 response from the start. Here is part of her conversation with <em>As It Happens</em> host Carol Off.&nbsp;</p>  <p><strong>Is the Swedish government finally willing to admit that its approach to tackling COVID-19 has failed?</strong></p>  <p>I haven't seen any such signs, no.</p>  <p><strong>Do you think they'll just continue as they are?</strong></p>  <p>There have been incremental changes in the recommendations. There has never been, and I doubt there ever will be, any kind of admission of having made mistakes.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/dr-lena-einhorn.jpg 300w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/dr-lena-einhorn.jpg 460w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/dr-lena-einhorn.jpg 620w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-lena-einhorn.jpg 780w,https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/dr-lena-einhorn.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768547.1603144639!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/dr-lena-einhorn.jpg"></p></div><figcaption>Dr. Lena Einhorn is an author, filmmaker and virologist in Sweden. <!-- --> <!-- -->(Submitted by Lena Einhorn)</figcaption></figure></span></p>  <p><strong>If you were to describe Sweden's approach to tackling the coronavirus, what words would you use?</strong></p>  <p>Stubborn is probably the best word I can come up with.</p>  <p>When they started, their initial assumptions were fair. They assumed that this would be like SARS; it would never sort of be a major problem in Sweden or outside of Southeast Asia. They were convinced it's only spread from symptomatic people, so like SARS, you could isolate the symptomatic people and stop the spread that way.</p>  <p>That was fair, you know, sometime in January. It was not fair in April or in May. So they stuck to that. And one could say that when the spread really â€¦&nbsp;hit Europe and Sweden, they did the opposite of our Scandinavian and Nordic neighbours who went into lockdown, and we did not.</p>  <p><strong>There was an idea that we heard from coming from Sweden in the spring, and I guess it continued, that Sweden would attempt something called "herd immunity," that if enough people were to contract the virus, that eventually there would be a general immunity enough within the population that it would have a better effect than locking things down and keeping people from getting it. Is that what happened?</strong></p>  <p>It has been assumed that they were going for herd immunity, but they've been speaking through two sides of their mouths. On the one hand, they've been denying it. On the others, on the other hand, they said it would be a bonus.</p>  <p>They said that come fall, and the second wave, we will be much better protected than our Scandinavian neighbours who had 10 times less deaths than we did in relation to population. But it became very clear once broad testing of antibodies was being done that there was nothing close to herd immunity.</p>  <p>And so, of course, they realize that they can't go for herd immunity. It's going to kill too many people. I mean, it's already killed almost 6,000 people in a population of 10 million. So they are no longer going for herd immunity, which doesn't mean that they're prepared to say, "we were wrong and we're going to change our recommendations."</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-sweden.JPG 300w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-sweden.JPG 460w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-sweden.JPG 620w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden.JPG 780w,https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-sweden.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768040.1603128896!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden.JPG"></p></div><figcaption>Anders Tegnell of the Public Health Agency of Sweden attends a news conference updating the country about COVID-19 on Oct. 9.<!-- --> <!-- -->(Claudio Bresciani/TT News Agency/Reuters)</figcaption></figure></span></p>  <p><strong>At the centre of all of this, as we have followed what's going on in Sweden, is a man named </strong><strong>Anders&nbsp;Tegnel, Sweden's chief epidemiologist, and he seems to be a bit of a rock star in your country for the decisions he made. <a href="https://www.reuters.com/article/us-health-coronavirus-tegnell-tattoo-idUSKCN2292G7">People have tattoos of him on their bodies.</a> So why is he so popular?</strong></p>  <p>This is a combination of factors, and this deserves a long discussion. Part of it, I'm sure, is that when there's a national crisis, people want to believe in authority.</p>  <p>The other aspect is that he has a very calming demeanour. Even when the numbers were going through the roof, he kept saying that we're flattening out, we're hitting the peak. He had a way of sounding extremely calming.</p>  <p>And also, you know, 90 per cent of the deaths were in the elderly, so â€¦&nbsp;most people didn't see it.</p>  <p><strong>And what do you think of&nbsp;Anders&nbsp;Tegnel?</strong></p>  <p>I have no opinions about him personally, but I think he has not handled this well and he keeps on not handling this well.</p>  <p>Just as an example, Sweden is [one of the only countries],&nbsp;together with Somalia, Yemen, Eritrea, Syria, Greenland and some Pacific islands, who have still no recommendations for face masks whatsoever. So, you know, he hates face masks. He says they don't help. He keeps saying there's no support for them.</p>  <p>In the spring, that could have been a fair assumption. But by now, there's the studies are overwhelmingly showing the benefit of face masks, especially when it's used in the whole population, because it protects against someone who is sick.</p>  <p>So if everybody wears it, face masks are extremely efficient. But if only 50 per cent wear it, it's not at all sufficient. But he will not even say that they're good. I mean, you have to understand, in the Swedish hospitals, the doctors and nurses do not wear face masks.</p>    <p><strong>Well, it seems that [U.S. President] Donald Trump and the people around him would agree with Anders&nbsp;Tegnel.&nbsp;But the rest of the world, at least in countries where they have policies, they are not doing that. So somebody is right and somebody is wrong.</strong></p>  <p>The interesting thing is that in Sweden, we have a social democratic government dominated by the Social Democrats, so â€¦&nbsp;it's more of a left-wing policy. Whereas in the rest of the world, it's very much a right-wing <em>laissez faire</em> policy to have herd immunity, or to try to have herd immunity, or to not wear face masks. Freedom, you know?</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-sweden-cases.JPG 300w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-sweden-cases.JPG 460w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-sweden-cases.JPG 620w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden-cases.JPG 780w,https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-sweden-cases.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5768036.1603128765!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-sweden-cases.JPG"></p></div><figcaption>A sign promoting physical distancing is pictured in the Gallerian in Stockholm, Sweden, May 12.<!-- --> <!-- -->(Henrik Montgomery/TT News Agency/Reuters)</figcaption></figure></span></p>  <p><strong>There was <a href="https://time.com/5899432/sweden-coronovirus-disaster/">a freedom of information [request</a>, and] a bunch of emails that have been published by journalists in your country that show that Mr. Tegnel said that at one point that when it was suggested that 10 per cent of those who would get the disease would be the elderly and maybe they would die, 10 per cent might be "worth it," he apparently said. How much of the decisions are being driven by this idea that, well, maybe we have to keep Sweden moving, keeping the businesses open, and that's part of the motivation?</strong></p>  <p>They will never admit that the economy is an aspect. By the way, Sweden's economy has not fared any better than its Nordic neighbours. Rather, it's more at the bottom than at the top among our neighbours. So it hasn't benefited from it, and it has certainly not benefited from the herd immunity.</p>  <p><strong>Today we saw the announcement that citizens in Sweden should avoid places like shopping malls, museums, gyms, concerts, and avoid public transportation or visiting the elderly. So is there a shift perhaps in perception?</strong></p>  <p>There are policies. You know, it's not a completely<em> laissez faire</em>. I mean, people are advised to stay to work from home if they can. People are advised to not fill up the public transportation, the busses and the subways. There is still a maximum amount of people gathering of 50.</p>  <p>It's not a complete "let's live as normal" â€” but it's all recommendations and advice.</p>  <p>I would say that incrementally, Sweden has has gotten closer to other countries. I mean, we do a lot of testing now. We do, you know, about as much as Canada per capita. So it's not like in the spring, where nobody was tested outside of the hospital.</p>  <p>But it still is always too little.</p>  <hr>  <p><em>Written by Sheena Goodyear. Interview produced by Jeanne Armstrong. Q&amp;A has been updated for length and clarity.&nbsp;</em></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/radio/asithappens/as-it-happens-monday-edition-1.5767947/swedish-virologist-says-her-country-s-covid-19-strategy-has-failed-but-nobody-will-admit-it-1.5767967</link>
            <guid isPermaLink="false">hacker-news-small-sites-24841972</guid>
            <pubDate>Tue, 20 Oct 2020 20:22:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Julia GPU]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24840972">thread link</a>) | @cdsousa
<br/>
October 20, 2020 | https://notamonadtutorial.com/julia-gpu-98a461d33e21 | <a href="https://web.archive.org/web/*/https://notamonadtutorial.com/julia-gpu-98a461d33e21">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><div><div><div><p><a href="https://medium.com/@federicocarrone?source=post_page-----98a461d33e21--------------------------------" rel="noopener"><img alt="Federico Carrone" src="https://miro.medium.com/fit/c/96/96/2*p2NbnNI4sEc75QvzOZ1gaA.jpeg" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2816/1*KJX3T1Y9T1Cj0aV3m-A22w.png" width="1408" height="528" srcset="https://miro.medium.com/max/552/1*KJX3T1Y9T1Cj0aV3m-A22w.png 276w, https://miro.medium.com/max/1104/1*KJX3T1Y9T1Cj0aV3m-A22w.png 552w, https://miro.medium.com/max/1280/1*KJX3T1Y9T1Cj0aV3m-A22w.png 640w, https://miro.medium.com/max/1400/1*KJX3T1Y9T1Cj0aV3m-A22w.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*KJX3T1Y9T1Cj0aV3m-A22w.png?q=20"></p></div></div></div></figure><p id="58dc">We are living in a time where more and more data is being created every day as well as new techniques and complex algorithms that try to extract the most out of it. As such, CPU capabilities are approaching a bottleneck in their computing power. GPU computing opened its way into a new paradigm for high-performance and parallel computation a long time ago, but it was not until recently that it become massively used for data science.<br>In this interview, <a href="https://twitter.com/maleadt" rel="noopener">Tim Besard</a>, one of the main contributors to the JuliaGPU project, digs into some of the details about GPU computing and the features that make Julia a language suited for such tasks, not only from a performance perspective but also from a user one.</p></div></div></section><section><div><div><p id="38e1"><em>Join the Not a Monad Tutorial Telegram </em><a href="https://t.me/notamonadtutorial" rel="noopener"><em>group</em></a><em> or </em><a href="https://t.me/channel_notamonadtutorial" rel="noopener"><em>channel</em></a><em> to talk about programming, computer science and papers. See you there!</em></p><p id="b3d6"><em>If you are looking for good engineers send me an email to mail@fcarrone.com or you can also reach me via twitter at </em><a href="https://twitter.com/federicocarrone" rel="noopener"><em>@federicocarrone</em></a><em>.</em></p></div></div></section><section><div><div><h2 id="6d6e">Please tell us a bit about yourself. What is your background? what is your current position?</h2><p id="b291">IÃ¢â‚¬â„¢ve always been interested in systems programming, and after obtaining my CS degree I got the opportunity to start a PhD at Ghent University, Belgium, right when Julia was first released around 2012. The language seemed intriguing, and since I wanted to gain some experience with LLVM, I decided to port some image processing research code from MATLAB and C++ to Julia. The goal was to match performance of the C++ version, but some of its kernels were implemented in CUDA CÃ¢â‚¬Â¦ So obviously Julia needed a GPU back-end!</p><p id="7f14">That was easier said than done, of course, and much of my PhD was about implementing that back-end and (re)structuring the existing Julia compiler to facilitate these additional back-ends. Nowadays IÃ¢â‚¬â„¢m at Julia Computing, where I still work on everything GPU-related.</p><h2 id="8f7f">What is JuliaGPU? What is the goal of the project?</h2><p id="43d9">JuliaGPU is the name we use to group GPU-related resources in Julia: ThereÃ¢â‚¬â„¢s a <a href="https://github.com/JuliaGPU" rel="noopener">GitHub organization</a> where most packages are hosted, a <a href="https://juliagpu.org/" rel="noopener">website</a> to point the way for new users, we have <a href="https://github.com/JuliaGPU/gitlab-ci" rel="noopener">CI infrastructure</a> for JuliaGPU projects, thereÃ¢â‚¬â„¢s a Slack channel and Discourse category, etc.</p><p id="ceaa">The goal of all this is to make it easier to use GPUs for all kinds of users. Current technologies often impose significant barriers to entry: CUDA is fairly tricky to install, C and C++ are not familiar to many users, etc. With the software we develop as part of the JuliaGPU organization, we aim to make it easy to use GPUs, without hindering the ability to optimize or use low-level features that the hardware has to offer.</p><h2 id="5da7">What is GPU computing? How important is it nowadays?</h2><p id="4de0">GPU computing means using the GPU, a device originally designed for graphics processing, to perform general-purpose computations. It has grown more important now that CPU performance is not improving as steadily as it used to. Instead, specialized devices like GPUs or FPGAs are increasingly used to improve the performance of certain computations. In the case of GPUs, the architecture is a great fit to perform highly-parallel applications. Machine learning networks are a good example of such parallel applications, and their popularity is one of the reasons GPUs have become so important.</p><h2 id="f596">Do you think Julia is an appropriate language to efficiently use GPU capabilities? Why?</h2><p id="775f">JuliaÃ¢â‚¬â„¢s main advantage is that the language was designed to be compiled. Even though the syntax is high-level, the generated machine code is<br>compact and has great performance characteristics (for more details, see <a href="http://janvitek.org/pubs/oopsla18b.pdf" rel="noopener">this paper</a>). This is crucial for GPU execution, where we are required to run native binaries and cannot easily (or efficiently) interpret code as is often required by other languageÃ¢â‚¬â„¢s semantics.</p><p id="b90b">Because weÃ¢â‚¬â„¢re able to directly compile Julia for GPUs, we can use almost all of the languageÃ¢â‚¬â„¢s features to build powerful abstractions. For example, you can define your own types, use those in GPU arrays, compose that with existing abstractions like lazy "Transpose" wrappers, access those on the GPU while benefiting from automatic bounds-checking (if needed), etc.</p><h2 id="824e">From a Python programmer perspective, how does CUDA.jl compare to PyCUDA? Are their functionalities equivalent?</h2><p id="cf3f">PyCUDA gives the programmer access to the CUDA APIs, with high-level Python functions that are much easier to use. CUDA.jl provides the same, but in Julia. The `hello world` from PyCUDAÃ¢â‚¬â„¢s home page looks almost identical in Julia:</p><pre><span id="a986">using CUDA</span><span id="03e4">function multiply_them(dest, a, b)<br> i = threadIdx().x<br> dest[i] = a[i] * b[i]<br> return<br>end</span><span id="9e7d">a = CuArray(randn(Float32, 400))<br>b = CuArray(randn(Float32, 400))</span><span id="5833">dest = similar(a)<br>@cuda threads=400 multiply_them(dest, a, b)</span><span id="1372">println(dest-a.*b)</span></pre><p id="396f">ThereÃ¢â‚¬â„¢s one very big difference: "multiply_them" here is a function written in Julia, whereas PyCUDA uses a kernel written in CUDA C. The reason is straightforward: Python is not simple to compile. Of course, projects like Numba prove that it is very much possible to do so, but in the end those are separate compilers that try to match the reference Python compilers as closely as possible. With CUDA.jl, we integrate with that reference compiler, so itÃ¢â‚¬â„¢s much easier to guarantee consistent semantics and follow suit when the language changes (for more details,<br>refer to <a href="https://arxiv.org/abs/1712.03112" rel="noopener">this paper</a>).</p><h2 id="5cf6">Are the packages in the JuliaGPU organization targeted to experienced programmers only?</h2><p id="6590">Not at all. CUDA.jl targets different kinds of (GPU) programmers. If you are confident writing your own kernels, you can do so, while using all of the low-level features CUDA GPUs have to offer. But if you are new to the world of GPU programming, you can use high-level array operations that use existing kernels in CUDA.jl. For example, the above element-wise multiplication could just as well be written as:</p><pre><span id="9c1f">using CUDA</span><span id="476a">a = CuArray(randn(Float32, 400))<br>b = CuArray(randn(Float32, 400))</span><span id="efdf">dest = a .* b</span></pre><h2 id="4c26">Is it necessary to know how to code in CUDA.jl to take full advantage of GPU computing in Julia?</h2><p id="208b">Not for most users. Julia has a powerful language of generic array operations ("map", "reduce", "broadcast", "accumulate", etc) which can be applied to all kinds of arrays, including GPU arrays. That means you can often re-use your codebase developed for the CPU with CUDA.jl (<a href="https://www.sciencedirect.com/science/article/abs/pii/S0965997818310123" rel="noopener">this paper</a> shows some powerful examples). Doing so often requires minimal changes: changing the array type, making sure you use array operations instead of for loops, etc.</p><p id="672d">ItÃ¢â‚¬â„¢s possible you need to go beyond this style of programming, e.g., because your application doesnÃ¢â‚¬â„¢t map cleanly onto array operations, to use specific GPU features, etc. In that case, some basic knowledge about CUDA and the GPU programming model is sufficient to write kernels in CUDA.jl.</p><h2 id="1a33">How is the experience of coding a kernel in CUDA.jl in comparison to CUDA C and how transferable is the knowledge to one another?</h2><p id="6a08">ItÃ¢â‚¬â„¢s very similar, and thatÃ¢â‚¬â„¢s by design: We try to keep the kernel abstractions in CUDA.jl close to their CUDA C counterparts such that the programming environment is familiar to existing GPU programmers. Of course, by using a high-level source language thereÃ¢â‚¬â„¢s many quality-of-life improvements. You can allocated shared memory, for example, statically and dynamically as in CUDA C, but instead of a raw pointers we use an N-dimensional array object you can easily index. An example from the <a href="https://developer.nvidia.com/blog/using-shared-memory-cuda-cc/" rel="noopener">NVIDIA developer blog</a>:</p><pre><span id="ef8a">__global__ void staticReverse(int *d, int n)<br>{<br> __shared__ int s[64];<br> int t = threadIdx.x;<br> int tr = n-t-1;<br> s[t] = d[t];<br> __syncthreads();<br> d[t] = s[tr];<br>}</span></pre><p id="9cb0">The CUDA.jl equivalent of this kernel looks very familiar, but uses array objects instead of raw pointers:</p><pre><span id="996c">function staticReverse(d)<br> s = @cuStaticSharedMem(Int, 64)<br> t = threadIdx().x<br> tr = length(d)-t+1<br> s[t] = d[t]<br> sync_threads()<br> d[t] = s[tr]<br> return<br>end</span></pre><p id="9a14">Using array objects has many advantages, e.g. multi-dimensional is greatly simplified and we can just do "d[i,j]". But itÃ¢â‚¬â„¢s also safer, because these accesses are bounds checked:</p><pre><span id="3d65">julia&gt; a = CuArray(1:64)<br>64-element CuArray{Int64,1}:<br> 1<br> 2<br> 3<br> Ã¢â€¹Â®<br> 62<br> 63<br> 64</span><span id="0d9c">julia&gt; @cuda threads=65 staticReverse(a)<br>ERROR: a exception was thrown during kernel execution.<br>Stacktrace:<br> [1] throw_boundserror at abstractarray.jl:541</span></pre><p id="c17a">Bounds checking isnÃ¢â‚¬â„¢t free, of course, and once weÃ¢â‚¬â„¢re certain our code is correct we can add an "@inbounds" annotation to our kernel and get the high-performance code we expect:</p><pre><span id="6846">julia&gt; @device_code_ptx @cuda threads=64 staticReverse(a)<br>.visible .entry staticReverse(.param .align 8 .b8 d[16]) {<br> .reg .b32 %r&lt;2&gt;;<br> .reg .b64 %rd&lt;15&gt;;<br> .shared .align 32 .b8 s[512];</span><span id="09c9">mov.b64 %rd1, d;<br> ld.param.u64 %rd2, [%rd1];<br> ld.param.u64 %rd3, [%rd1+8];<br> mov.u32 %r1, %tid.x;<br> cvt.u64.u32 %rd4, %r1;<br> mul.wide.u32 %rd5, %r1, 8;<br> add.s64 %rd6, %rd5, -8;<br> add.s64 %rd7, %rd3, %rd6;<br> ld.global.u64 %rd8, [%rd7+8];<br> mov.u64 %rd9, s;<br> add.s64 %rd10, %rd9, %rd6;<br> st.shared.u64 [%rd10+8], %rd8;<br> bar.sync 0;<br> sub.s64 %rd11, %rd2, %rd4;<br> shl.b64 %rd12, %rd11, 3;<br> add.s64 %rd13, %rd9, %rd12;<br> ld.shared.u64 %rd14, [%rd13+-8];<br> st.global.u64 [%rd7+8], %rd14;<br> ret;<br>}</span><span id="4489">julia&gt; a<br>64-element CuArray{Int64,1}:<br> 64<br> 63<br> 62<br> Ã¢â€¹Â®<br> 3<br> 2<br> 1</span></pre><p id="3cee">Tools like "@device_code_ptx" make it easy for an experienced developer to inspect generated code and ensure the compiler does what he wants.</p><h2 id="164a">Why does having a compiler have such an impact in libraries like CUDA.jl? (How was the process of integrating it to the Julia compiler?)</h2><p id="e360">Because we have a compiler at our disposal, we can rely on higher-order functions and other generic abstractions that specialize based on the arguments that users provide. That greatly simplifies our library, but also gives the user very powerful tools. As an example, we have carefully implemented a `mapreduce` function that uses shared memory, warp intrinsics, etc to perform a high-performance reduction. The implementation is generic though, and will automatically re-specialize (even at run time) based on the arguments to the function:</p><pre><span id="9da7">julia&gt; mapreduce(identity, +, CuArray([1,2,3]))<br>6</span><span id="c680">julia&gt; mapreduce(sin, *, CuArray([1.1,2.2,3.3]))<br>-0.11366175839582586</span></pre><p id="52e8">With this powerful `mapreduce` â€¦</p></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notamonadtutorial.com/julia-gpu-98a461d33e21">https://notamonadtutorial.com/julia-gpu-98a461d33e21</a></em></p>]]>
            </description>
            <link>https://notamonadtutorial.com/julia-gpu-98a461d33e21</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840972</guid>
            <pubDate>Tue, 20 Oct 2020 18:48:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dev Methodology mostly doesnâ€™t matter, just make up your own]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24840880">thread link</a>) | @necco908
<br/>
October 20, 2020 | https://linearb.io/blog/dev-methodology-doesnt-matter/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/dev-methodology-doesnt-matter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			




<h2><strong>A waterfall of old-schoolness&nbsp;</strong></h2>







<p>I worked as a developer using Waterfall for exactly 9 months. I was 22 years old and it was my first programmer job and first corporate environment. This place was old school. Like suit-wearing, personal cubicle type old school. Our CEO would hold all-hands meetings where everyone was required to stand the whole time and he would call people up to give speeches at random because he believed everyone should be good at public speaking.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-1024x488.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-768x366.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology.png.webp 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/10/2-Blog-Methodology.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
<figcaption>22 year old Dan was NOT good at public speaking ğŸ™‚&nbsp;</figcaption></figure>







<p>At one offsite event, the CEO designated me as the company Complaint Manager. During the 4-day event employees were directed to give me their complaints. Of course my friends dropped anonymous and hilarious complaints because they knew that, at the end of each day, I was going to be called up to the stage to repeat back all of the complaints. What?!? Super old school.&nbsp;</p>



<p>One time, I was sent to work at a clientâ€™s office for a week, just so they could visibility see my team working on their project. And I mean that in the most literal sense. We didnâ€™t have any meetings or recent project updates, they just wanted to make sure we were actually working.&nbsp;</p>



<p>I never saw a single line of my code in production during my 9 months I spent working there. I actually remember learning that my project was finally being sent to QA for testing the week I left. After 9 months. Old. School.</p>



<p>But I didnâ€™t know any better at the time. I hadnâ€™t heard of Agile yet, and no one told me we were doing Waterfall. Luckily I got out of there and found a job at Cloudlock where I learned about Agile and eventually worked my way up to VP of Engineering. But Iâ€™ll never forget my first year as a Waterfall programmer.</p>



<p>So does methodology matter? Absolutely. Butâ€¦&nbsp;</p>







<h2><strong>We do agileâ€¦ But</strong></h2>







<p>If you ask a software developer&nbsp; what methodology they follow, 95% of us will say we do agileâ€¦but, usually followed by some version of Scrum or Kanban. While this sounds like a worldwide consensus, the reality is that every dev team Iâ€™ve worked on or managed has had a different development process.&nbsp;</p>



<p>During my time as VP of Engineering at Cloudlock, I looked after 75 developers across 5 teams. Each team had their own unique process. There were team leads who had been working in software development for 25+ years and others that had <a href="https://linearb.io/blog/promoted-from-dev-to-team-lead-8-things-they-didnt-tell-me/">just gotten promoted</a>. The younger leads liked having a more strict process to follow, whereas the more senior managers had a process they had customized over the years.&nbsp;</p>



<p>All of those teams built amazing software even though their methods differed per team. Why? Because software development is not a zero sum game. Just because one team is successful using Agile Scrum doesnâ€™t mean another team will be less successful using Agile Kanban. Or Scrumban. Or SAFe.&nbsp;</p>



<p>Thereâ€™s a lot of options out there so, instead of focusing on methodology, I find it makes sense to start with what youâ€™re trying to do and work backwards.&nbsp;</p>







<h2><strong>A bespoke development process â€“ The GigSmart dev team&nbsp;</strong></h2>







<p><em>â€œYou got rid of teams?!?â€&nbsp;</em></p>



<p>I recently caught up with my friend Chris Downard, VP of Engineering at GigSmart, to chat about dev methodology changes in light of current events. I was completely taken aback when the first thing he said to me was that he just got rid of teams in his engineering department.&nbsp;</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-1024x488.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-768x366.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology.png.webp 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/10/3-Blog-Methodology.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>Iâ€™m not personally strict about following this or that development method, but getting rid of teams felt a little extreme.&nbsp;&nbsp;</p>



<p>Chris: â€œIt naturally evolved that way. Because of this remote culture that we adopted very rapidly, we just found that the back end people tended to support each other on their backend tickets; whether or not it was on their direct team or a direct feature they were working on. They were helping each other, committing to each otherâ€™s code, etc. So we kept the team thing going up until last month, and we were measuring that way, so we just eliminated it because it didnâ€™t make sense anymore.â€</p>



<p>Getting rid of teams works for Chris for two reasons. He runs a small-ish team of 14 developers and the team uses a Kanban style framework. If there are 3 or 4 features in flight, each team member is assigned to one as their dominant project, but theyâ€™re all on one team.&nbsp;</p>



<p>Many of the classic Scrum ceremonies are still followed, but heâ€™s working on making them more effective as well.&nbsp;</p>



<p>â€œWe do one large standup and it takes us 15 minutes to get through. People give their standup updates in order based on their dominant feature. So the first set of people who go, are the ones who are working on Feature A, and the second group that goes are all working on Feature B.â€</p>



<p>On top of no teams and restructuring their daily, Chris says they work in sprints but use a Kanban board to increase speed.&nbsp;</p>



<p>â€œThe product team loves that because if they decide that something is suddenly really hot because sales has run into this or that, we can address it immediately.â€</p>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-1024x488.png.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-300x143.png.webp 300w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-768x366.png.webp 768w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology.png.webp 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/10/4-Blog-Methodology.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<h3><strong>Why does GigSmart work this way?&nbsp;</strong></h3>







<ul><li>Chris believes in continuous improvement based on team feedback.</li></ul>







<p>When he runs sprint retros, anything that engineering brings up that isnâ€™t working, they have a conversation about. He brings in product and they chat about ways to make it better, and then they test it. And if it doesnâ€™t work, he readjusts, and tries to fix it. Since he started at GigSmart, there hasnâ€™t been a 4 week period where their process has stayed the same.&nbsp;</p>







<ul start="2"><li>GigSmartâ€™s most valuable outcome is speed.</li></ul>







<p>The methodology, process, or ethos that drives your team needs to be purpose built to achieve the outcome you want. At GigSmart theyâ€™re defined outcome was high quality and speed. As an on-demand staffing platform, they choose to prioritize hotfixes and bugs. Other companies might need to be more predictable, quality-driven, stable, consistent, etc. based on their business type and needed outcome.</p>







<ul start="3"><li>GigSmart is culture-driven&nbsp;</li></ul>







<p>â€œBuild better, more engaged engineering teamsâ€¦ Thatâ€™s probably what my actual official job description is. So culture really matters.â€ <a href="https://linearb.io/blog/our-dev-culture-is-based-on-bushido-samurai-code-my-interview-with-the-vp-of-engineering-at-gigsmart/">Chris and GigSmart CTO,&nbsp; Jason Waldrip, modeled their team cultural values</a> on the ancient samurai code of Bushido. 8 values that theyâ€™ve written down and strive to live and work by every day.&nbsp;</p>







<ul start="4"><li>GigSmart is data-driven</li></ul>







<p>Measuring is not enough, you have to measure with a purpose. You get what you measure. Everyone is familiar with this saying. Chris takes it a step further and actually encourages the team to look data about how they work in all of their day-to-day practices and ceremonies.&nbsp;</p>



<p>By defining his companyâ€™s most valuable outcome and listening to his developers, Chris has created a development process that is bespoke to his team today. Just like a custom tailored suit, his development method cannot be easily used by another company. It had to be made up.&nbsp;&nbsp;</p>







<h2><strong>Make up your own dev methodology: 4 guiding ideas</strong></h2>







<figure><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-1024x488.gif.webp 1024w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-300x143.gif.webp 300w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-768x366.gif.webp 768w" sizes="(max-width: 1024px) 100vw, 1024px">
<img src="https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-1024x488.gif" alt="" srcset="https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-1024x488.gif 1024w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-300x143.gif 300w, https://linearb.io/wp-content/uploads/2020/10/5-Blog-Methodology-1-1-768x366.gif 768w" sizes="(max-width: 1024px) 100vw, 1024px">
</picture>
</figure>







<p>Sometimes I just like building my own thing from the ground up. Itâ€™s why I started <a href="https://linearb.io/">LinearB.</a> Do you NEED to create your own development method? Definitely not.&nbsp;</p>



<p>Itâ€™s much easier to start with Scrum or Kanban and adapt from there. But times, they are a changinâ€™, and maybe this is a good year to go through the exercise of redefining how you work.&nbsp;</p>



<p>After we started full-time remote back in March, my co-founder, Ori Keren, and I did just that. We created <a href="https://linearb.io/blog/asynchronous-development/">Asynchronous Development</a>, a development methodology designed around async communication and purpose-built for hybrid remote teams. Itâ€™s our favorite parts of Agile. A little bit of Scrum. A lot of what Ori and I learned over the years that really works for us. And a big dose of where we think the future of software development teamwork is headed.&nbsp;</p>



<p>Hundreds of teams are now following the Async Dev methodology. If we can make up our own dev methodology, you can too!&nbsp;</p>







<p><strong>Hereâ€™s 4 guiding ideas that will help you make up your own dev methodology</strong></p>







<ol><li><strong>Know your â€œwhyâ€&nbsp;</strong></li></ol>







<p>What matters to you? If itâ€™s aligning to your companyâ€™s most important business goals, do you&nbsp; know what they are? Start-ups tend to want lots of new features as quickly as possible. More mature companies like predictability and quality. Find out and work backwards from there.&nbsp;</p>







<ol start="2"><li><strong>Donâ€™t be dogmatic</strong></li></ol>







<p>Forget about the rules and just ask yourselfâ€¦ â€œHow do we really want to work?â€ Ask your people. Especially your out-of-the-box thinkers. The more crazy ideas you throw in the mix, the more discussion youâ€™ll create and the more youâ€™ll end up with something that is really bespoke.&nbsp;</p>



<p>For example, the Agile manifesto says face-to-face communication is the most efficient way to transfer information. Is that still true for your team?</p>







<ol start="3"><li><strong>Retro your current process</strong></li></ol>



<p><strong><br></strong>Askâ€¦ â€œWhy are we doing all of these things we do every day?â€ Do you really need a daily stand-up? Do you really need two week sprints? Are you realy getting value from them? The answer may be yes. But I bet if your team will have a lot of ideas of how they could be more dev-friendly and more efficient.&nbsp;</p>







<ol start="4"><li><strong>Bring data to the conversation&nbsp;</strong></li></ol>







<p>After youâ€™re done exploring all of the pain from step 3, see if you can prove or disprove any of the assumptions and anecdotes with actual data. This might be the hard part, actually. The type of data you need is not necessarily accessible in your Git or project management system. If you need help, check out LinearB. Our <a href="https://linearb.io/pricing/">free-forever plan</a> provides tons of metrics and process visualizations to show you whatâ€™s working, bottlenecks and how you can improve efficiency, quality and teamwork. <a href="https://app.linearb.io/register">Click here to sign up</a> with your Git account.&nbsp;</p>







<p><strong>Whatâ€™s your made up methodology?</strong></p>







<p>I know many of you have already customized your own dev methodology. Iâ€™d love to hear about it! What pieces of existing methods did you use? What new things did you invent? What is special about your approach? Please â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/dev-methodology-doesnt-matter/">https://linearb.io/blog/dev-methodology-doesnt-matter/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/dev-methodology-doesnt-matter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840880</guid>
            <pubDate>Tue, 20 Oct 2020 18:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Palo Alto Networks sends cease-and-desist letter to take down review videos]]>
            </title>
            <description>
<![CDATA[
Score 431 | Comments 116 (<a href="https://news.ycombinator.com/item?id=24840119">thread link</a>) | @bonfire
<br/>
October 20, 2020 | https://orca.security/cybersecurity-community-transparency/ | <a href="https://web.archive.org/web/*/https://orca.security/cybersecurity-community-transparency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main">

				
							<div data-elementor-type="single" data-elementor-id="1240" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="665134c3" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="12af1bce" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
					<div>
				<div data-id="19996313" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p><em>Abstract: A few weeks ago, Orca Security published a comparison between the Orca Cloud Security Platform and a few other cloud security toolsâ€”including a&nbsp;<a href="https://orca.security/prisma-cloud-security/">comparison with Palo Alto Networks Prisma</a>. In response, Palo Alto Networks sent a <a href="https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf" target="_blank" rel="noopener noreferrer">cease and desist letter</a>, demanding the comparison be removed immediately. Here is my response. I urge you to see&nbsp;<a href="https://www.youtube.com/playlist?list=PLDnqJTEi6ynvsGkSJHYeEmhz6_NfzKgbf">the videos in question</a>&nbsp;and if you, like me, believe the cybersecurity community deserves transparency and vendors shouldnâ€™t be allowed to prevent publishing reviews or benchmarks via legal threats, then please share this post. You can also leave your own comments down below.</em></p>
<p><strong>To: Palo Alto Networks</strong></p>
<p><strong>CC: The cybersecurity community</strong></p>
<p><strong>Subject: The Cybersecurity community demands transparency, not legal threats&nbsp;</strong></p>
<p>Security has always been about transparency. The concept of security by obscurity was frowned upon as early as 1851â€”even before the invention of electricityâ€”when&nbsp;<a href="https://en.wikipedia.org/wiki/Alfred_Charles_Hobbs">Alfred Hobbs</a>, a Massachusetts-based locksmith, demonstrated how then state-of-the-art locks could be picked. He explained that exposing the information would make the public more secure, as rogues already knew the deficiencies. The public needed to be educated, and heâ€™d pursue better locks. Todayâ€™s locks are more advanced, but the principle is the same.</p>
<p>The cybersecurity community preaches about many products. All come with their own advantages and disadvantages, capabilities, and limitations. I believe that the only way practitioners can choose the tools that fit their environments best is by viewing factual evidenceâ€”not by relying solely on marketing materials. This is why we launched our&nbsp;<a href="https://orca.security/cloud-security-solutions/">Cloud Security Punch-Out! Series</a>, where we deploy a few toolsâ€”including Orca Securityâ€”on the exact same environment and share the results with viewers who deserve to see them. I urge you to take&nbsp;<a href="https://orca.security/prisma-cloud-security/">a look at the one we did with Palo Alto Networks;</a>&nbsp;as youâ€™ll see we donâ€™t hide those areas where Palo Alto Networks shines.</p>
<p>Unfortunately, Palo Alto Networks is now trying to use legal threats to prevent us from publishing&nbsp;these video&nbsp;reviews. In <a href="https://orca.security/wp-content/uploads/PANW-Legal-Letter-Cease-Desist.pdf" target="_blank" rel="noopener noreferrer">its letter</a>, Palo Alto Networks does not point to any factual inaccuracies in the reviews of its productsâ€™ performance. Instead, it premises its threats on flimsy, boilerplate contract terms that prohibit reviews and comparisons of its products and hollow trademark allegations purporting that Palo Alto Networks is sponsoring the videos.</p>
<p>Itâ€™s outrageous that the worldâ€™s largest cybersecurity vendor (its products being used by over 65,000 organizations according to its website), believes that its users arenâ€™t entitled to share any benchmark or performance comparison of its products. According to its boilerplate contract terms that prohibit â€œdisclosing, publishing, or otherwise making publicly available any benchmark, performance, or comparison testsâ€ of its products, youâ€™re in violation even if you publish the results of an internal comparison of Palo Alto Networks against other products as part of your procurement process. The same goes for the hundreds of Palo Alto Networks reviews on various sites that include G2 Crowd, Capterra, and Gartner Peer Insights. It means that only benchmarks approved by Palo Alto Networks can be published.</p>
<p>Palo Alto Networks appears oblivious to the fact that the New York Attorney Generalâ€™s office&nbsp;<a href="https://www.leagle.com/decision/2003579195misc2d3841519">sued and won an injunction</a>&nbsp;against McAfee from enforcing its contractual restrictions against publishing reviews or comparisons of its products without its consent more than 17 years ago. In enacting the&nbsp;<a href="https://www.law.cornell.edu/uscode/text/15/45b">Consumer Review Fairness Act</a>, Congress has also prohibited businesses from including contract terms that prohibit consumers from reviewing products or services they purchase.</p>
<blockquote><p>Palo Alto Networks, do you think your products are flawless or that the bad guys will follow along, not openly talking about productsâ€™ deficiencies? If the answer is no to both, then why resort to legal threats to remove such benchmarks and comparisons? I refuse to accept a world where any vendor believes it has the right to prevent the free flow of information, and control which product reviews are made publicly available.</p></blockquote>
<p>I urge you to make your products better and focus your marketing efforts on demonstrating that, rather than throwing away money on ill-conceived gag efforts. Such action doesnâ€™t benefit anyone. If you believe we missed something in our test, then tell us so we can make adjustmentsâ€”weâ€™ll happily integrate your comments and suggestions.</p>
<p>We could contract an objective third party to conduct additional tests. You could conduct your own tests with Palo Alto Networks and Orca Securityâ€™s products, then let the audience see and decide for themselves. All such actions would be far more beneficial to the industry, permitting both companies to learn and improve our products for the sake of customers.</p>
<p>As we all recently learned too well,&nbsp;<a href="https://www.contagionlive.com/news/sunlight-inactivates-the-airborne-virus-that-causes-covid19">sunlight is the best disinfectant</a>. The cybersecurity community deserves better than a vendorâ€™s lack of transparency while wielding dubious legal methods. Palo Alto Networks is the worldsâ€™ largest cybersecurity vendor; with great power comes great responsibility. Your products are greatâ€”but nothing is perfect, and the public should have free access to all of the facts.</p>
<p>Yours faithfully,<br>
Avi Shua, CEO and Co-Founder<br>
Orca Security</p>
		</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
					</div>
		</div>
		</div>
		
					
					
				
			</div></div>]]>
            </description>
            <link>https://orca.security/cybersecurity-community-transparency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840119</guid>
            <pubDate>Tue, 20 Oct 2020 17:31:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My platonic ideal for how engineering hiring should work]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 260 (<a href="https://news.ycombinator.com/item?id=24840013">thread link</a>) | @leeny
<br/>
October 20, 2020 | http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/ | <a href="https://web.archive.org/web/*/http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>Iâ€™ve been in and around eng hiring for the past 13 years, as an engineer, a recruiter, and a founder of a technical recruiting marketplace (interviewing.io). Over the course of those 13 years, Iâ€™ve become increasingly disgruntled at the state of hiring, and now Iâ€™m mad enough to write this blog post.</p>



<p>If youâ€™ve ever been on either end of the table, youâ€™re probably mad at the state of hiring, too. Whether you have given it a lot of thought or whether you just feel it deep down, something about the whole process feels off.</p>



<p>But weâ€™ve been doing it this way for so long that we probably take much of how hiring works as gospel, and itâ€™s really hard to tease apart all the different components of the process and examine why they are the way they are. In this post, Iâ€™d like to challenge many of the things we assume about hiring, and, perhaps most importantly, Iâ€™d like to lay out my platonic ideal for how eng hiring should work. Itâ€™s a simple axiom, really:</p>



<p><em>It should be easy for smart people to talk to other smart people.</em></p>



<p>Or, another way to put it â€¦ if Iâ€™m a good engineer, it should be easy for me to talk to a hiring manager at a company I might be interested in, at a time of my choosing. But thatâ€™s simply not possible today. Despite the refrain that weâ€™re in a candidateâ€™s market and that thereâ€™s a shortage of good candidates, which should mean that candidates should have the power to call the shots, todayâ€™s hiring process couldnâ€™t be further removed from this ideal. And itâ€™s not just broken for a specific type of candidate. Itâ€™s broken for <em>everyone.</em></p>



<p>If youâ€™re reading this, you might be an engineering manager, a senior engineer with stellar credentials, a recent bootcamp grad, an engineer from a background traditionally underrepresented in tech, or some combination of these. <strong>Whatâ€™s truly messed up about the status quo is that, regardless of which of these groups you fall into, your journey will be unnecessarily unpleasant. Though the degree of unpleasantness will not always be the same, itâ€™s not about race, seniority, pedigree, or gender â€¦ or even which side of the table youâ€™re on. Hiring, in its current incarnation, is broken for everybody.</strong></p>



<p>Why? Let us go then, you and I, into the bowels of the status quo.</p>



<h2>A candidate and a hiring manager, never the twain shall meet</h2>



<p>Letâ€™s say that Iâ€™m a competent generalist engineer who looks good on paper, and Iâ€™m thinking that itâ€™s time to look for a new job. What happens next? The idea of having to mount a full-on job search is so daunting.&nbsp;</p>



<p>I could try some job boards to see which companies are out there. But what would I filter on? I know a lot of programming languages but am not set on having to work in a specific one. How can I tell if Iâ€™ll hit it off with the team? Iâ€™m applying via a job board to a position I know next to nothing about â€” will anyone even respond?</p>



<p>Suppose I find some companies where I might want to work. If Iâ€™m lucky enough to know someone there, Iâ€™ll have to get them to refer me, even though that may not actually do much to speed things along. And if I donâ€™t know anyone there, applying will be an exhausting long shot. Odds are no one will look at my application, and having to redo my resume â€” or worse, write cover letters â€” seems like the most tedious kind of busywork.</p>



<p>I guess I can always dig through the recruiter spam Iâ€™ve gotten. But do those recruiters still work at the company? If they do, how long will it actually take to get into the process?</p>



<p>Breaking character for a moment, a friend of mine recently got this recruiting email from Google, who has elevated gaslighting to an art form: somehow the fact that it takes two months to get through their process has become a <em>selling point.</em></p>



<figure><img loading="lazy" width="750" height="319" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-750x319.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-750x319.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-450x191.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail-768x327.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Fwd__Hello_From_Google__-_aline_interviewing_io_-_Interviewing_io_Mail.png 1004w" sizes="(max-width: 750px) 100vw, 750px"></figure>



<p>Once I do get into the process, why do I have to endure the same intro call ten times with different recruiters who canâ€™t tell me anything about what Iâ€™d be working on at any level of depth?</p>



<p>Do I join some platform, create a profile that I copy-paste everywhere (with writing that was just as painful as the aforementioned resume/cover letter) and sort of hope that decent companies contact me â€¦ only to have to begin the same recruiter calls over and over again, as above?</p>



<p>Will I have to take some quizzes that drill me on obscure syntax or make me solve toy problems that have no bearing on my engineering ability before I even get to have the aforementioned inane conversation with a recruiter?</p>



<p><strong>If Iâ€™m actually good at my job, why canâ€™t I just set up some conversations with companies I think are cool and see if itâ€™s a fit? Why do I have to subject myself and others to an endless parade of vapid conversations and the inevitable busywork that precedes them?</strong></p>



<p>Hereâ€™s the truth. Even if I look good on paper and am well-connected, hiring still sucks because of all the noise, uncertainty, and time wasted â€¦ but at least I have options. They might not be exactly the right options for me, but at least they exist. On the other hand, if Iâ€™m an engineer without a pedigree or a network, my choices are extremely limited, no matter how good I am. Recruiters arenâ€™t reaching out to me, Iâ€™m not well-networked enough to have friends refer me, and I <em>definitely </em>donâ€™t hear back when I apply.</p>



<hr>



<p>Letâ€™s take a look at the other side of the table. Letâ€™s say Iâ€™m an eng manager who needs to hire more competent generalists for my team. Having worked as both an eng manager and a recruiter, I can tell you that what happens next isnâ€™t particularly inspiring.</p>



<p>As an eng manager, I sit down with a recruiter and try to explain what Iâ€™m looking for. Nine times out of ten, I want a <a href="https://www.joelonsoftware.com/2007/06/05/smart-and-gets-things-done/">smart person who can get shit done</a>. But, after a farcical game of telephone, somehow those criteria get warped into years of experience with a specific technology or requirements about where the candidate went to school. I also end up with an uninspired, sterile job description that fails to capture the imagination of any candidates who might unwittingly stumble upon it.</p>



<p><strong>My recruiter then goes to any number of sourcing tools of which LinkedIn Recruiter is the ubiquitous, lackluster market leader. They type in keywords I didnâ€™t ask for and filter on credentials I donâ€™t care about to come up with the same homogenous list of candidates every other recruiter at every other tech company is chasing.</strong></p>



<p>They then contact these candidates en masse with generic copy about my team and the hard problems weâ€™re solving. They celebrate single-digit response rates and spend the minimal time left over to give a cursory glance at candidates applying directly.</p>



<h2>Why is hiring broken?</h2>



<p>So therein lies the ineffectual dance. This is the process weâ€™ve come to accept. As far as I can tease out, the axioms that underlie todayâ€™s recruiting best practices go something like this (some of these were told to me verbatim when I was starting out as a recruiter, even):</p>



<ol><li><strong>Thou shalt not engage with active candidates. After all, in this market, strong candidates arenâ€™t looking. Good recruiters build relationships so that when a good candidate does decide to enter the market, the recruiter is there, behind the next doorway, ready to spring!</strong></li><li><strong>Engineering time is expensive, so itâ€™s critical to do as much top-of-funnel filtering as possible to make sure that itâ€™s spent on the right candidates.</strong></li></ol>



<p>Are these axioms wrong? The sad truth is â€¦ not really. Iâ€™ve written in a <a href="http://blog.alinelerner.com/the-unvarnished-unbundled-guide-to-hiring-tools/">previous post about how market forces rule everything around me</a>, and recruiting best practices are no exception. In an economy with a surplus of jobs and a shortage of talent, it follows that the best talent is going to be harder to find, engineering time will be expensive, and recruiters in their current incarnation are, dare I say it, a necessary evil. <sup><a href="#footnote_0_2455" id="identifier_0_2455" title="From what youâ€™ve read up until this point, you might think that I hate recruiters and find them useless. Not so, dear reader! I hate bad recruiters. And, unfortunately, most of them are bad. Whatâ€™s sad is that the good ones, instead of spending time on tasks for which theyâ€™re uniquely qualified and well-suited, are instead stuck at the top of the funnel sourcing engineers whose qualifications they donâ€™t have the domain expertise to evaluate and selling them on roles they donâ€™t have the domain expertise to describe. The best recruiters Iâ€™ve worked with are singularly amazing at shepherding candidates through the process, tirelessly stewarding a companyâ€™s employer brand, advising hiring managers on the best ways to close, keeping an analytical eye on the funnel to identify issues before they even arise, and much more.">1</a></sup></p>



<p>The data supports our current world view. According to Lever (one of the two application tracking systems widely used by startups, Greenhouse is the other), hereâ€™s a breakdown of how many candidates from each source it takes to make a hire. Note that here, larger numbers are bad â€” for many companies, internal referrals are the best source and inbound applications are the worst.</p>



<figure><img loading="lazy" width="750" height="375" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-750x375.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-750x375.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-450x225.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2-768x384.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/graphLever2.png 1008w" sizes="(max-width: 750px) 100vw, 750px"><figcaption>Source: <a href="https://www.lever.co/recruiting-resources/articles/recruitment-process/" target="_blank" rel="noreferrer noopener">https://www.lever.co/recruiting-resources/articles/recruitment-process/</a></figcaption></figure>



<p>Looking at this data, you can see why recruiters simply ignore online applications. The same dynamics also apply to platforms such as AngelList â€” like any jobs board, itâ€™s noisy and probably full of candidates who donâ€™t have much leverage (e.g., juniors/bootcamp grads and people requiring visa sponsorship).</p>



<p>As for the value of eng time, guarding it carefully isnâ€™t exactly wrong either. In fact, if you look at what a typical hiring process looks like today, youâ€™ll see that most of the time spent is by engineers conducting interviews.</p>



<figure><table><thead><tr><th><strong>Hiring process stage</strong></th><th>Who does it?</th><th>How long does it take?</th></tr></thead><tbody><tr><td>Resume review</td><td>Recruiter</td><td>10-30 seconds</td></tr><tr><td>Recruiter screen</td><td>Recruiter</td><td>45 min</td></tr><tr><td>Technical phone screen</td><td>Engineer</td><td>1 hour</td></tr><tr><td>Onsite â€“ Eng portion</td><td>Engineer</td><td>6 hours</td></tr><tr><td>Onsite â€“ Recruiter portion</td><td>Recruiter</td><td>1 hour</td></tr><tr><td>Offer</td><td>Recruiter OR Eng mgr</td><td>1 hour</td></tr></tbody></table></figure>



<p>Engineering salaries are high, so given that most of the time spent on a single candidate is with engineers, itâ€™s <em>rational</em> to put some recruiter gates at the top of the funnel to protect eng time. The idea is that recruiters will effectively screen out most candidates and only pass on the most promising ones to the eng team.</p>



<p>Unfortunately, when you look at an actual typical <em>funnel</em>, youâ€™ll see that despite attempts to gate the top with recruiters filtering resumes and making intro calls, itâ€™s not really working. Below is what a typical funnel looks like.</p>



<figure><img loading="lazy" width="750" height="89" src="http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-750x89.png" alt="" srcset="http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-750x89.png 750w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-450x53.png 450w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42-768x91.png 768w, http://blog.alinelerner.com/wp-content/uploads/2020/10/Screenshot-2019-03-23-17.34.42.png 1092w" sizes="(max-width: 750px) 100vw, 750px"></figure>



<p>If you <a href="https://blog.interviewing.io/you-probably-dont-factor-in-engineering-time-when-calculating-cost-per-hire-heres-why-you-really-should/" target="_blank" rel="noreferrer noopener">do the math</a> and look at how many hours are spent â€” not per candidate but per hire (more useful because hires are ultimately what we want) â€” youâ€™ll see that despite attempts to save eng time, recruiters spend roughly 15 hours a hire <sup><a href="#footnote_1_2455" id="identifier_1_2455" title="If we add in time to review resumes, itâ€™s an extra five hours (at most).">2</a></sup> and engineers spend about 40. In a process where you donâ€™t make an offer 50% of the time and only convert those offers to hires 50% of â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/">http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/</a></em></p>]]>
            </description>
            <link>http://blog.alinelerner.com/ive-been-an-engineer-and-a-recruiter-hiring-is-broken-heres-why-and-heres-what-it-should-be-like-instead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24840013</guid>
            <pubDate>Tue, 20 Oct 2020 17:22:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS and their billions in IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 159 (<a href="https://news.ycombinator.com/item?id=24839887">thread link</a>) | @bgpdude
<br/>
October 20, 2020 | https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html | <a href="https://web.archive.org/web/*/https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div id="post-body"><p>Earlier this week, I was doing some work on AWS and wanted to know what IP addresses were being used. Luckily for me, AWS publishes this all here <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="nofollow noopener">https://ip-ranges.amazonaws.com/ip-ranges.json</a>. When you go through this list, youâ€™ll quickly see that AWS has a massive asset of IPv4 allocations. Just counting quickly I noticed a lot of big prefixes.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Ever wondered what all of the AWS network ranges are? You can find them all here:<a href="https://t.co/NBaBF6w0la">https://t.co/NBaBF6w0la</a><br>That's *a lot* of big prefixes!<br>4x /11, 14x /12, 30x /13, 78x /14, 184x /15, 278x /16</p>â€” Andree Toonk, Adelante! (@atoonk) <a href="https://twitter.com/atoonk/status/1316098702260359168?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

</figure><p>However, the IPv4 ranges on that list are just the ranges that are in use and allocated today by AWS. Time to dig a bit deeper.</p><h3 id="ipv4-address-acquisitions-by-aws">IPv4 address acquisitions by AWS</h3><p>Over the years, AWS has acquired a lot of IPv4 address space. Most of this happens without gaining too much attention, but there were a few notable acquisitions that Iâ€™ll quickly summarize below.</p><h4 id="2017-mit-selling-8-million-ipv4-addresses-to-aws">2017: MIT selling 8 million IPv4 addresses to AWS</h4><p>In 2017 <a href="https://www.internetsociety.org/blog/2017/05/mit-goes-on-ipv4-selling-spree/" rel="noopener">MIT sold half of its 18.0.0.0/8</a> allocation to AWS. This 18.128.0.0/9 range holds about 8 million IPv4 addresses.</p><h4 id="2018-ge-sells-3-0-0-0-8-to-aws">2018: GE sells 3.0.0.0/8 to AWS</h4><p>In 2018 the IPv4 prefix 3.0.0.0/8 was transferred from GE to AWS. With this, AWS became the proud owner of its first /8! Thatâ€™s sixteen million new IPv4 addresses to feed us hungry AWS customers. <a href="https://news.ycombinator.com/item?id=18407173" rel="nofollow noopener">https://news.ycombinator.com/item?id=18407173</a></p><h4 id="2019-aws-buys-amprnet-44-192-0-0-10">2019: AWS buys AMPRnet 44.192.0.0/10</h4><p>In 2019 AWS bought a /10 from AMPR.org, the Amateur Radio Digital Communications (ARDC). The IPv4 range 44.0.0.0/8 was an allocation made to the Amateur Radio organization in 1981 and known as the AMPRNet. This sell caused a fair bit of discussion, check out the <a href="https://mailman.nanog.org/pipermail/nanog/2019-July/thread.html#102103" rel="noopener">nanog discussion here.</a></p><p>Just this month, it <a href="http://www.southgatearc.org/news/2020/october/sale-of-amateur-radio-amprnet-tcp-ip-addresses.htm" rel="noopener">became public knowledge</a> AWS paid $108 million for this /10. Thatâ€™s $25.74 per IP address.</p><p>These are just a few examples. Obviously, AWS has way more IP addresses than the three examples I listed here. The IPv4 transfer market is very active. Check out this website to get a sense of all transfers: <a href="https://account.arin.net/public/transfer-log#NRPM-8.3IPv4" rel="noopener">https://account.arin.net/public/transfer-log</a></p><h3 id="all-aws-ipv4-addresses">All AWS IPv4 addresses</h3><p>Armed with the information above it was clear that not all of the AWS owned ranges were in the <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">JSON</a> that AWS published. For example, parts of the 3.0.0.0/8 range are missing. Likely because some of it is reserved for future use.</p><p>Combining all those IPv4 prefixes, removing duplicates and overlaps by aggregating them results in the following list of unique IPv4 address owned by AWS: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#all-prefixes</a></p><p>The total number of IPv4 addresses in that list is just over 100 Million (100,750,168). Thatâ€™s <strong>the equivalent of just over six /8â€™s,</strong> not bad!</p><p>If we break this down by allocation size, we see the following:</p><pre><code>1x /8     =&gt; 16,777,216 IPv4 addresses
1x /9     =&gt; 8,388,608 IPv4 addresses
4x /10    =&gt; 16,777,216 IPv4 addresses
5x /11    =&gt; 10,485,760 IPv4 addresses
11x /12   =&gt; 11,534,336 IPv4 addresses
13x /13   =&gt; 6,815,744 IPv4 addresses
34x /14   =&gt; 8,912,896 IPv4 addresses
53x /15   =&gt; 6,946,816 IPv4 addresses
182x /16  =&gt; 11,927,552 IPv4 addresses
&lt;and more&gt;</code></pre><p>A complete breakdown can be found here: <a href="https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size" rel="nofollow noopener">https://gist.github.com/atoonk/b749305012ae5b86bacba9b01160df9f#breakdown-by-ipv4-prefix-size</a></p><h3 id="putting-a-valuation-on-aws-ipv4-assets">Putting a valuation on AWSâ€™ IPv4 assets</h3><blockquote>Alright.. this is just for funâ€¦</blockquote><p>Since AWS is (one of) the largest buyers of IPv4 addresses, they have spent a significant amount on stacking up their IPv4 resources. Itâ€™s impossible, as an outsider, to know how much AWS paid for each deal. However, we can for fun, try to put a dollar number on AWSâ€™ current IPv4 assets.</p><p>The average price for IPv4 addresses has gone up over the years. From ~$10 per IP a few years back to ~$25 per IP <a href="https://auctions.ipv4.global/" rel="noopener">nowadays</a>. <br>Note that these are market prices, so if AWS would suddenly decide to sell its IPv4 addresses and overwhelm the market with supply, prices would drop. But that wonâ€™t happen since weâ€™re all still addicted to IPv4 ;)</p><p>Anyway, letâ€™s stick with $25 and do the math just for fun.</p><pre><code>100,750,168 ipv4 addresses x $25 per IP = $2,518,754,200</code></pre><p>Just<strong> over $2.5 billion worth of IPv4 addresses,</strong> not bad! </p><h3 id="peeking-into-the-future">Peeking into the future</h3><p>Itâ€™s clear AWS is working hard behind the scenes to make sure we can all continue to build more on AWS. One final question we could look at is: <em>how much buffer does AWS have?</em> ie. how healthy is their IPv4 reserve?</p><p>According to their <a href="https://ip-ranges.amazonaws.com/ip-ranges.json" rel="noopener">published data</a>, they have allocated roughly 53 Million IPv4 addresses to existing AWS services. We found that all their IPv4 addresses combined equates to approximately 100 Million IPv4 addresses. That means they still have ~47 Million IPv4 addresses, or 47% available for future allocations. Thatâ€™s pretty healthy! And on top of that, Iâ€™m sure theyâ€™ll continue to source more IPv4 addresses. The IPv4 market is still hot!</p></div>
    </div></div>]]>
            </description>
            <link>https://toonk.io/aws-and-their-billions-in-ipv4-addresses/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839887</guid>
            <pubDate>Tue, 20 Oct 2020 17:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[HTTP/3 Explained]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24839451">thread link</a>) | @makeworld
<br/>
October 20, 2020 | https://http3-explained.haxx.se/en/ | <a href="https://web.archive.org/web/*/https://http3-explained.haxx.se/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div data-editioncontainer="true"><div data-slate-editor="true" data-key="36cee8ea3e414cd592256f94bc6aeec7" autocorrect="on" spellcheck="true" data-gramm="false"><p data-key="ca91c66b1b1d47aa811801782b0040bf"><span><span data-key="5ca71efed92d4b09a9d6f5c6a6a231e8"><span data-offset-key="5ca71efed92d4b09a9d6f5c6a6a231e8:0">This book effort was started in March 2018. The plan is to document HTTP/3 and its underlying protocol: QUIC. Why, how they work, protocol details, the implementations and more.</span></span></span></p><p data-key="de30b46033534cb1a67156d01db21b78"><span><span data-key="4f22c1a5296849d4a79f407336fbea6b"><span data-offset-key="4f22c1a5296849d4a79f407336fbea6b:0">The book is entirely free and is meant to be a collaborative effort involving anyone and everyone who wants to help out.</span></span></span></p><p data-key="23c9519016f547be98eea91704bb1aaf"><span><span data-key="15c5a9c4648f44f49bbdf3d8efc1deab"><span data-offset-key="15c5a9c4648f44f49bbdf3d8efc1deab:0">A reader of this book is presumed to have a basic understanding of TCP/IP networking, the fundamentals of HTTP and the web. For further insights and specifics about HTTP/2 we recommend first reading up the details in </span></span><a href="https://daniel.haxx.se/http2/" target="_blank" rel="noopener noreferrer" data-key="f1b6b5f3082c40e18d7ba0d92f8bc4b8"><span data-key="c7cbabdd89114e2eb0476511547b0002"><span data-offset-key="c7cbabdd89114e2eb0476511547b0002:0">http2 explained</span></span></a><span data-key="60e14d9bef6b4f26b870c7fcde14cb20"><span data-offset-key="60e14d9bef6b4f26b870c7fcde14cb20:0">.</span></span></span></p><p data-key="257d025d390b42ae922e267a7b148923"><span><span data-key="de7313f8809647cbaff62d2997157223"><span data-offset-key="de7313f8809647cbaff62d2997157223:0">This book is created and the work is started by </span></span><a href="https://daniel.haxx.se/" target="_blank" rel="noopener noreferrer" data-key="0a4468c7093e47fcac8c01387870fbb1"><span data-key="29c04820a9724abbbc6e88f1f92fd2bf"><span data-offset-key="29c04820a9724abbbc6e88f1f92fd2bf:0">Daniel Stenberg</span></span></a><span data-key="70062ee310d5452fb962073362cea07a"><span data-offset-key="70062ee310d5452fb962073362cea07a:0">. Daniel is the founder and lead developer of </span></span><a href="https://curl.haxx.se/" target="_blank" rel="noopener noreferrer" data-key="349104d21fa249899c7f5778afd90c9a"><span data-key="664be569505e4df890cbaef88bb10e20"><span data-offset-key="664be569505e4df890cbaef88bb10e20:0">curl</span></span></a><span data-key="dacaa499f14f40ccbc8b61706a6f5e66"><span data-offset-key="dacaa499f14f40ccbc8b61706a6f5e66:0">, the world's most widely used HTTP client software. Daniel has worked with and on HTTP and internet protocols for over two decades and is the author of </span></span><a href="https://daniel.haxx.se/http2/" target="_blank" rel="noopener noreferrer" data-key="dee8c14c9f1844e09924193f400d2626"><span data-key="450d2f9d803a470fad4bedebe6a804eb"><span data-offset-key="450d2f9d803a470fad4bedebe6a804eb:0">http2 explained</span></span></a><span data-key="5a75e213258744d193202559829a122b"><span data-offset-key="5a75e213258744d193202559829a122b:0">.</span></span></span></p><p data-key="966986e70f8848fb9b978ebadf68263d"><span><span data-key="4e308dba6be34beb9d58d543d834f0da"><span data-offset-key="4e308dba6be34beb9d58d543d834f0da:0">The home page for this book is found at </span></span><a href="https://daniel.haxx.se/http3-explained" target="_blank" rel="noopener noreferrer" data-key="35c2412b01834a078b087683c67338e9"><span data-key="988f99e3f2914161a6a943e710a47005"><span data-offset-key="988f99e3f2914161a6a943e710a47005:0">daniel.haxx.se/http3-explained</span></span></a><span data-key="9878cf802a68430b873bad387780a929"><span data-offset-key="9878cf802a68430b873bad387780a929:0">.</span></span></span></p><p data-key="4e5debc9ee4943b197d009a4b9c3bfd2"><span><span data-key="9c3c3b42e84c429f8b77749679e96e78"><span data-offset-key="9c3c3b42e84c429f8b77749679e96e78:0">If you find mistakes, omissions, errors or blatant lies in this document, please send us a refreshed version of the affected paragraph and we will make amended versions. We will give proper credits to everyone who helps out. I hope to make this document better over time.</span></span></span></p><p data-key="1c615ee8d6a4493d82ffb90bf48a9a40"><span><span data-key="6840bb7163f8436c9df88d203b93850d"><span data-offset-key="6840bb7163f8436c9df88d203b93850d:0">Preferably, you submit </span></span><a href="https://github.com/bagder/http3-explained/issues" target="_blank" rel="noopener noreferrer" data-key="52b0b5f7bb864bcdaa8058d1d7e94397"><span data-key="3960e1d6da784d028baeede2d1b8f18c"><span data-offset-key="3960e1d6da784d028baeede2d1b8f18c:0">errors</span></span></a><span data-key="b72988a27e064077b6282f123b26ade0"><span data-offset-key="b72988a27e064077b6282f123b26ade0:0"> or </span></span><a href="https://github.com/bagder/http3-explained/pulls" target="_blank" rel="noopener noreferrer" data-key="72cd8e413c4442abaf2d69bc8da3916c"><span data-key="cd1b1d9cbe5a426abebd0b99fda9f70d"><span data-offset-key="cd1b1d9cbe5a426abebd0b99fda9f70d:0">pull requests</span></span></a><span data-key="d7864170226e4dbfb0380516ee3518fc"><span data-offset-key="d7864170226e4dbfb0380516ee3518fc:0"> on the book's GitHub page.</span></span></span></p><p data-key="d0548303fa104c6c8aa49d1151472bff"><span><span data-key="5944aa3c293849a6852bbf98e0745f6b"><span data-offset-key="5944aa3c293849a6852bbf98e0745f6b:0">This document and all its contents are licensed under the </span></span><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" data-key="f113fd53b3fd40b3be71f69bd34d0f5d"><span data-key="c1b5ecd2704745dbadfa7fc9a01d4e8d"><span data-offset-key="c1b5ecd2704745dbadfa7fc9a01d4e8d:0">Creative Commons Attribution 4.0 license</span></span></a><span data-key="2b3b8b952d37464097e5f9f75bc4975b"><span data-offset-key="2b3b8b952d37464097e5f9f75bc4975b:0">.</span></span></span></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://http3-explained.haxx.se/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839451</guid>
            <pubDate>Tue, 20 Oct 2020 16:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beam Manifesto â€“ A Tool for Thoughts]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24839414">thread link</a>) | @domleca
<br/>
October 20, 2020 | https://beamapp.co/bright_paper.html | <a href="https://web.archive.org/web/*/https://beamapp.co/bright_paper.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://beamapp.co/bright_paper.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839414</guid>
            <pubDate>Tue, 20 Oct 2020 16:36:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Document API for Cassandra]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24839327">thread link</a>) | @dwettlaufer
<br/>
October 20, 2020 | https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html | <a href="https://web.archive.org/web/*/https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>
        
        <h4>Because, sometimes, we just want JSON.</h4>
      </p>
    </div><div>
      <div>
        <p><img data-src="/assets/images/stargate-profile.png" alt="Eric Borczuk" width="32" height="32" src="https://stargate.io/assets/images/stargate-profile.png">
          <span>By <span>Eric Borczuk</span></span>
          â€¢
          <span>Oct 19, 2020</span>
        </p>
      </div>
    </div><div>
      <div>
        <div>
          <p>If youâ€™re like me, when you start coding something new, youâ€™re probably finding yourself working with JSON.  Maybe youâ€™re using Node.js or Python or any other dynamic language that uses JSON-like data natively or maybe youâ€™re working with data that youâ€™re pulling or serving from REST APIs. Either way, increasingly it seems like everything is ending up in JSON at some point.  Most of the time, this isnâ€™t a problem, itâ€™s just the way that we build software these days.  Thereâ€™s just one problem, and thatâ€™s that Cassandra isnâ€™t particularly good at JSONâ€¦</p>

<p>To double-click on that, the problem isnâ€™t the JSON data format itself, although Cassandra doesnâ€™t make JSON easy, itâ€™s the way most devs use JSON when weâ€™re building our apps.  Iterative development means that plans change.  The user registration form now needs a couple of more fields and the front-end dev went ahead and added them.  That API Iâ€™m calling returns some extra data.   Welcome to the loosely coupled world, itâ€™s all fun and games until my app needs to send it to the database.</p>

<p>In the early days, Cassandra actually made this pretty simple to do, but as the project matured and added features like enterprise-friendly SQL-like query languages and better indexing, that meant that we needed the database to enforce a schema.  Over time, it became harder and harder to use Cassandra for things like JSON and other document-oriented use cases.</p>

<p>Enter Stargate - if thereâ€™s one thing you should know about the Stargate team itâ€™s that our personal mission is to make Cassandra easy for every developer.  Figuring out how to give Javascript devs native JSON support without having to give up any of the reliability and scalability goodness of Cassandra was a challenge we couldnâ€™t pass up.</p>

<p>This idea gave rise to the Stargate <strong>Documents API</strong>, which lets most Cassandra distros (Cassandra 3.11, Cassandra 4.0, and DataStax Enterprise 6.8), work with JSON through a REST API.</p>

<h2 id="api-features-and-design">API features and design</h2>

<p>As <a href="https://github.com/tjake">Jake Luciani</a> and I started to create the bones of this API, we realized that Cassandra is nothing like a document store. Expressing data as rows is straightforward, but expressing trees of JSON data is really not. In addition, mapping that JSON data onto a table managed by Stargate and keeping both writes and reads reasonably fast adds an additional layer of complexity.</p>

<p>From here, we mapped out three main design components in order for this work:
Modeling Documents in Cassandra
Handling Reads and Writes
Figuring out Deletes</p>

<p>The rest of this blog walks through how we approached each design and resolved some hiccups along the way.
Modeling Documents in Cassandra with Document Shredding</p>

<p>The first thing that we had to decide  was the schema of the managed table that backs a document collection. Due to some great discussions with some Cassandra specialists, it was decided that when a user creates a document, a table will be created with a statement of the form:</p>

<figure><pre><code data-lang="sql"><span>create</span> <span>table</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>(</span>
  <span>key</span> <span>text</span><span>,</span>
  <span>p0</span> <span>text</span><span>,</span>
  <span>â€¦</span> <span>p</span><span>[</span><span>N</span><span>]</span> <span>text</span><span>,</span>
  <span>bool_value</span> <span>boolean</span><span>,</span>
  <span>txt_value</span> <span>text</span><span>,</span> <span>d</span>
  <span>bl_value</span> <span>double</span><span>,</span> <span>leaf</span> <span>text</span>
<span>)</span></code></pre></figure>

<p>At this point is where we had to solve an unbounded data modeling problem. Because any JSON document that has a depth of [N] or less can be added to this table, each value in the JSON will get stored as a row in the table. So if I wanted to represent a document called â€œxâ€ that has the JSON:</p>

<figure><pre><code data-lang="json"><span>{</span><span>"a"</span><span>:</span><span> </span><span>{</span><span> </span><span>"b"</span><span>:</span><span> </span><span>1</span><span> </span><span>},</span><span> </span><span>"c"</span><span>:</span><span> </span><span>2</span><span>}</span></code></pre></figure>

<p>The document would be â€œshreddedâ€ into rows looking like this:</p>

<table>
  <thead>
    <tr>
      <th>key</th>
      <th>p0</th>
      <th>p1</th>
      <th>dbl_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>x</td>
      <td>a</td>
      <td>b</td>
      <td>1</td>
    </tr>
    <tr>
      <td>x</td>
      <td>c</td>
      <td>null</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>For data with an array, such as:</p>

<figure><pre><code data-lang="json"><span>{</span><span>"a"</span><span>:</span><span> </span><span>{</span><span> </span><span>"b"</span><span>:</span><span> </span><span>1</span><span> </span><span>},</span><span> </span><span>"c"</span><span>:</span><span> </span><span>[{</span><span>"d"</span><span>:</span><span> </span><span>2</span><span>}]}</span></code></pre></figure>

<p>there would be two rows, like so:</p>

<table>
  <thead>
    <tr>
      <th>key</th>
      <th>p0</th>
      <th>p1</th>
      <th>p2</th>
      <th>dbl_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>x</td>
      <td>a</td>
      <td>b</td>
      <td>null</td>
      <td>1</td>
    </tr>
    <tr>
      <td>x</td>
      <td>c</td>
      <td>[0]</td>
      <td>d</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>Array elements are stored with square braces in the column.</p>

<h3 id="handling-reads-and-writes">Handling Reads and Writes</h3>

<p>The next problem that arose was that naÃ¯vely, updates to a document could require reading the document from the database, seeing what modification would have to be made, and then writing the updated data.  This â€œread-before-writeâ€ process is a notorious source of performance and consistency issues in most data stores.</p>

<p>Therefore, we resolved to avoid doing any read-before-write operations at all costs.</p>

<p>An interesting implementation detail that came up is that when you write some data to a document, the resulting write operation is just a simple batch with some inserts and deletes. In some cases, this can cause the document rows in the database to show two different states for the same JSON field.</p>

<p><em>And, upon reading the rows out, the Documents API reconciles conflicting information by accepting the data that has a later Cassandra write time (much like Cassandra itself!).</em></p>

<p>This allows us to write data really quickly while not compromising too much in reads either, as the reconciliation does not happen often and is also quite fast. It also gives us a very important core principle to our basic write and read operations:</p>
<ol>
  <li>Every write to a single document is a single batch of statements, and</li>
  <li>Every read from a single document is a single SELECT statement.</li>
</ol>

<p>So writes and reads are squared away - but what about deletes?</p>

<h3 id="figuring-out-deletes">Figuring out Deletes</h3>

<p>Because of the distributed nature of the database, a deletion in Cassandra actually is very similar to an insert, but instead a â€œtombstoneâ€ is written at a particular write time to signify the death of a row.</p>

<p>Rest in peaceâ€¦ almost</p>

<p>Cassandra periodically (the frequency here depends on your compaction strategy and/or cluster load) does a compaction operation to remove tombstones and alleviate this pressure, so the only way to avoid overwhelming Cassandra is to make sure that the frequency of deletions is low enough.</p>

<p>This poses a problem for the Document API specifically because of arrays. Letâ€™s walk through this one.</p>

<p>Imagine that you have an array at some key that is of length 100000. If you then issue a replace operation (via a PUT) and decide to replace that array with some other value, then all of those 100000 rows would be deleted, causing 100000 tombstones to be written.  This is an enormous number of tombstones to be written in one operation, and if you do that just a few more times, Cassandra will likely get super slow. So the structure of the data in each table needed one last major modification.</p>

<p>We said before that array paths are stored in the database with square brackets; for example the element at index 0 would be stored as [0]. That would mean a deletion of 100000 elements would look like this:</p>

<figure><pre><code data-lang="sql"><span>DELETE</span> <span>FROM</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>where</span> <span>p0</span> <span>in</span> <span>(</span><span>'[0]'</span><span>,</span> <span>'[1]'</span><span>,</span> <span>'[2]'</span><span>,</span> <span>â€¦</span><span>,</span> <span>'[99999]'</span><span>)</span></code></pre></figure>

<p>Causing 100000 tombstones to be written. Instead of doing that, we decided to pad all array elements with leading zeros, so the element at index 0 would instead be represented as [000000], and the element at index 99999 would be [099999]. Doing this allowed us to change the deletion statement to:</p>

<figure><pre><code data-lang="sql"><span>DELETE</span> <span>FROM</span> <span>&lt;</span><span>name</span><span>&gt;</span> <span>where</span> <span>p0</span> <span>&gt;=</span> <span>'[000000]'</span> <span>and</span> <span>p0</span> <span>&lt;=</span> <span>'[999999]'</span></code></pre></figure>

<p>Which causes only a single so-called â€œrangeâ€ tombstone to be written, instead of 100000 cell tombstones (note that greater and less than works on strings in Cassandra and will compare lexically). It also relaxes the array length limit to one million elements, which is pretty neat! The time series below shows how the old vs. new implementation might behave, if you performed compactions every week:</p>

<p><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/tombstone_counts.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/tombstone_counts.png"></p>

<p>So the new strategy is just safer for deletions; it would require an incredibly large amount of deletion with the new strategy to even come close to the theoretical tombstone limits!</p>

<h2 id="preliminary-look-at-api-performance">Preliminary Look at API performance</h2>

<p>âš ï¸ Before starting on this section, we want to mention that benchmarking is a great tool, but does not necessarily represent how a system will behave under real load, out in the wild. We also havenâ€™t done comparisons on the same hardware with other document storesâ€¦yet. Alright, letâ€™s get to it!</p>

<p>In order to test that the Document API is reasonably fast, we ran a benchmark test using a single Cassandra storage node and a single Stargate node (Stargate is the API that contains the Documents API). We then ran two different benchmarks, one that uses HTTP GET to repeatedly get random paths in a document, and another that performs HTTP POSTs repeatedly to create brand new documents.  Each of these actions got run 100000 times, and here are two graphs of the results.</p>

<p>To keep things simple, as there is no baseline to compare things against just yet, the benchmark was performed using only one requester at a time, with light concurrency (10 users at once), and with more concurrency (100 users at once). Note that itâ€™s expected with only one backend node that higher concurrency would cause degradation in performance; you should have multiple nodes to service that degree of concurrent requests!</p>

<p>Here are the results for reads:</p>



<table>
  <thead>
    <tr>
      <th>1 user:</th>
      <th>10 users:</th>
      <th>100 users:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_1_User.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_1_User.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_10_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_10_Users.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Reads_100_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Reads_100_Users.png"></td>
    </tr>
  </tbody>
</table>

<p>And for writes:</p>



<table>
  <thead>
    <tr>
      <th>1 user:</th>
      <th>10 users:</th>
      <th>100 users:</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_1_User.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_1_User.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_10_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_10_Users.png"></td>
      <td><img alt="" data-src="/assets/images/the-stargate-cassandra-documents-api/Writes_100_Users.png" src="https://stargate.io/assets/images/the-stargate-cassandra-documents-api/Writes_100_Users.png"></td>
    </tr>
  </tbody>
</table>

<p>From the above, we can see that the API performs pretty well at a reasonable level of concurrency for our setup.</p>



<p>We hope you enjoyed taking this quick tour of the Documents API. If you are interested in using the API head over to <a href="https://stargate.io/docs/stargate/0.1/quickstart/quickstart.html">Stargate.io</a> for more information about how to use it in your own Cassandra distribution.</p>

<p>If you are interested in contributing to Stargate, which is entirely open-source, we have two places for you to join us:</p>

<ol>
  <li>Come join our <a href="https://discord.gg/5gY8GDB">Discord Community</a> to follow the latest with Stargate and get early access to new stuff</li>
  <li>For any issues or pull requests, come on over to our <a href="https://www.github.com/stargate/stargate">GitHub Repository</a>
</li>
</ol>

<p>The APIs in Stargate are being actively developed, so we are hoping to be able to get back to you soon with news of even more improvements!</p>

        </div>
      </div>
    </div></div>]]>
            </description>
            <link>https://stargate.io/2020/10/19/the-stargate-cassandra-documents-api.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839327</guid>
            <pubDate>Tue, 20 Oct 2020 16:29:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sym Raises $12M to Help Engineers Reclaim Security]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24839074">thread link</a>) | @abuggia
<br/>
October 20, 2020 | https://compliance.dev/2020/10/20/hello-sym/ | <a href="https://web.archive.org/web/*/https://compliance.dev/2020/10/20/hello-sym/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <h2 id="ode-to-the-accidental-security-engineer">Ode to the Accidental Security Engineer</h2>

<p><img src="https://d33wubrfki0l68.cloudfront.net/4fe780d6b00b9e7113ff3250d350453a4abcb8df/1fba2/assets/hello-sym/salute.png" alt="Salute"></p>

<blockquote>
  <p>Hereâ€™s to the accidental security engineers. The misfits. The rebels. The troublemakers. The round pegs in the square holes. The ones who see things differently.</p>

  <p>To every engineer whoâ€™s ever spent a day scratching their head, wondering how to comply with a new security policy.</p>

  <p>To all those lost sprints building annoying primitives that â€œ<em>have</em> to exist somewhere alreadyâ€.</p>

  <p>To all the stressful weeks of getting pulled off new features to help prepare for an audit.</p>

  <p>To every web app, Slack bot, CLI, and microservice that was hacked together to help roll out a new control, only to become a pain-in-the-ass to maintain.</p>

  <p>It was us. Weâ€™ve been the ones tasked with building this mess. Constantly trading off velocity and security. But no more. Weâ€™re going to solve this problem, together, once and for all.</p>

  <p>Enter: Sym.</p>
</blockquote>

<h2 id="hello-sym">Hello, Sym</h2>

<p>Sym is the security workflow platform made for engineers, by engineers. We solve the intent-to-execution gap between policies and workflows by providing fast-moving engineering teams with the just-right primitives to roll out best-practice controls.</p>

<p>Our hand-crafted Terraform templates let you easily provision instances of common security controls, while our Python SDK unlocks ridiculously simple customization to meet your teamâ€™s needs and integrate with existing tools. Weâ€™ve got our sights set on fixing the â€œBuild vs Buyâ€ problem with security workflowsâ€¦ the problem being that both options currently suck.</p>

<p>Iâ€™m overjoyed and humbled to share that weâ€™re not embarking on this quest alone. Weâ€™re off to the races with a <a href="https://techcrunch.com/2020/10/20/sym-raises-9m-series-a-for-its-security-workflow-platform/">$9M Series A led by Sunil Dhaliwal at Amplify Partners</a>, following hot on the heels of a $3M Seed led by Robin Vasan at Mango Capital and Andy McLoughlin at Uncork Capital.</p>

<p>They say â€œnever meet your heroesâ€, but with participation from security &amp; technology executives at GitHub, Datadog, Atlassian, Google, Bugsnag, and Segment, alongside early design partners like LaunchDarkly, weâ€™re sure glad we met ours!</p>

<p>Weâ€™re excited to unveil our vision to the world, and announce that weâ€™ve partnered with some of the best investors, engineers, and leaders in the industry to tackle this mountainous problem space. Every single person behind Sym has experienced our struggle first-hand (phew, weâ€™re not crazy!), and wonâ€™t rest until we solve it. Letâ€™s do this!</p>

<h2 id="howd-we-get-here">Howâ€™d we get here?</h2>

<p>Story time! I met Adam and Jon when I was a freshman at MIT. I distinctly remember walking into the Startup Career Fair wondering how I could circumvent the â€œno freshmenâ€ rule most companies seemed to have when hiring interns. A friendly senior had let me know to watch out for the scores that recruiters would scrawl on resumes before haphazardly throwing them on the pile. A week prior, I watched a Facebook recruiter scratch a â€œ1â€ onto mine, circling the sad number repeatedly before smiling and telling me to have a nice day. My world fell apart. This week was going to be different.</p>

<p>After having a great chat with this guy named <a href="https://en.wikipedia.org/wiki/Vladimir_Tenev">Vlad</a> (Robinhood wasnâ€™t a Big Deal yet), I ran into Adam. He was the VP of Engineering at a Boston-based company called Localytics, and seemed as relieved as I was to be having a conversation. I hesitantly bought into his pitch, and scheduled a time to come onsite. Little did I know, that thoughtless commitment would totally change the trajectory of my life, and one day be responsible for the founding of Sym!</p>

<p>The first meeting was uneventful, or so I thought. I showed up 30 minutes late to a rather exasperated Adam lecturing me on the demerits of interview tardiness. Throughout the years, Iâ€™ve grown very accustomed to that frustrated expression ğŸ˜…. Though Iâ€™m still notoriously late for most things in life, Iâ€™ve never again failed to be punctual for a job interview!</p>

<p>Against his better judgement, Adam brought me on as an early intern at Localytics. It was my first job, and he was my first boss. I learned the ropes (read: how to ignore everyoneâ€™s advice while minimally pissing them off), and got to collaborate on some <a href="https://eng.localytics.com/your-code-coverage-is-bad-and-you-should-feel-bad/">really fun projects</a>. Jon (our third cofounder) spent a lot of time reprimanding me.</p>

<p>We spent the rest of the summer <del>fighting</del> working together, and ended with a particularly controversial project where, against the better judgement of basically everyone, I pumped out a heap of flaky Javascript code for saving reports, and then peaced out from the company âœŒï¸.</p>

<p>Iâ€™m extremely grateful that over the span of a decade, I stayed in touch with these two. Our relationship evolved, from manager-intern, to mentor-mentee, to peers, to cofounders. When I stepped away from my last company to start Sym, those two were my first call. And boy, am I glad they were.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/e009c90866e63034acc943efabdfa4a6457078d7/c6517/assets/hello-sym/map.png" alt="Map"></p>

<h2 id="evolution-of-sym">Evolution of Sym</h2>

<p>When Jon, Adam, and I sat down to build Sym, we wanted to solve a very simple problem: every engineering org we know in a heavily-regulated space was building the same damn tooling. Coming from healthcare and enterprise SaaS, weâ€™d seen permutations of the same few workflows time and time again throughout our careers. A way to grant engineers temporary access to infrastructure? Check. A way to approve one-off queries? Check. Something to make quarterly risk assessments suck less? Check. Chat-Ops for approving outgoing deploys? Check.</p>

<p>The crazy thing was, these seemed to be ubiquitous across companies, compliance standards, even industries. Chatting with fellow founders about stuff Iâ€™d built to help keep my team productive would always result in one of two reactions: â€œ<em>oh yea, we built the same thing! letâ€™s trade notesâ€¦â€œ</em>, or <em>â€œoh shit, we should have built this years agoâ€</em>. So we came up with a crazy idea: what if we just build all this stuff once, and put it out in the world for everyone to use. We were going to start with HIPAA-induced workflows. Sym: HIPAA in a box, for engineers. Of course, things rarely work out that simply.</p>

<p>We rapidly discovered something while talking to potential users: our hypothesis that everyone is building tools for the same workflows was a bit off. It wasnâ€™t the case that everyoneâ€™s workflows were identical, but instead that they had the same <em>shared core</em>. It turns out, what most teams do is they start by building the same <strong>primitives</strong>, and then they layer on <strong>customizations</strong> that reflect existing processes and tools. So, we adjusted our approach to match this revelation.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/dc4f6494be10e2dfb90dc745bd96e83fffad695e/7aa7d/assets/hello-sym/graph.gif" alt="Graph"></p>

<p>Today, Sym is a set of workflow templates (<strong>primitives</strong>) for engineering teams working on improving security posture, and a suite of integrations (<strong>customizations</strong>) that connect those templates to existing systems and policies. Our mission is to enable any team to effortlessly build unobtrusive security and governance workflows, so we make sure to meet developers where they are: our primitives are exposed as Infrastructure-as-Code, and our SDK captures last-mile variance in workflows. The tools we use to distribute Sym Workflows are Terraform and Python, but your organization doesnâ€™t have to be familiar with either to use us.</p>

<p>With Sym, you can roll out many common security and governance workflows with ~30 lines of declarative config and a couple function body definitions. Our goal is for you to blow your InfoSec team away; bring speed, sophistication, and thoroughness to your controls, without losing a whole month each time. Beautiful dashboards with just-right reports will materialize, without a single tedious line of logging code.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/8b56882478ed2e08f51d3f70075e993d385a2eef/193db/assets/hello-sym/code.png" alt="Code"></p>

<p>Weâ€™re currently live (in production!) at a handful of public and private companies in the Healthcare and B2B SaaS spaces. Our initial workflows focus on governance and just-in-time access of cloud and app-level resources.</p>

<p>Our latest customer is locking down SSH access by rolling out <a href="https://compliance.dev/2020/03/23/aws-session-manager-ssh-tunnels-with-less-user-management/">AWS Session Manager tunnels</a> as the preferred way to connect to instances, with the IAM Role required to use SSM protected by Sym. This is one of many examples where weâ€™re able to help infra teams adopt cutting-edge cloud offerings while increasing security posture. If this sounds like something that youâ€™d like for your team, please <a href="https://symops.com/">reach out</a>!</p>

<h2 id="but-what-about-x">But what about X?</h2>

<p>Weâ€™re in a crowded space! Luckily, we see the world with a unique lens. Sym brings an emphasis on developer experience, opinionated workflows that codify best practices, and an aspiration to be the bridge between Security and Compliance. The juryâ€™s still out on whether weâ€™re totally brilliant or totally out to lunch.</p>

<p>Our vision at Sym is to become the de-facto standard for implementing and showcasing security posture. Importantly, weâ€™re not setting out to be a middleman levying a tax on the system. We saw enough of those in our healthcare days. Instead, weâ€™re striving to improve the status quo for every stakeholder in the security equation; our place as the obvious-choice bridge between security and compliance will be an emergent property of the system weâ€™re fighting to improve.</p>

<p>Weâ€™ve got a long way to go to make that vision a reality. In the interim, weâ€™re tackling several problems plaguing our friends and colleagues.</p>

<h3 id="security-intent-to-implementation-gap">Security intent-to-implementation gap</h3>

<p>A security intent-to-implementation gap is endemic in our industry today. Experts are laying out guidelines, policies, and best-practices, only to be foiled by the gargantuan effort required to implement workflows that reflect these intents. And to be honest, we canâ€™t really blame engineering teams for this. As an industry, weâ€™ve learned not to roll our own crypto, because itâ€™s so easy to shoot yourself in the foot, but can you imagine how many ways there are to screw up a Slack bot that issues temporary database credentials? Or how easy it is to forget to put MFA around an admin God-mode dashboard? Twitter hack, anyone?</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/2fa7f55e98cd8c615f0db83c6fd96236b49266a2/67dc7/assets/hello-sym/headlines.png" alt="Headlines"></p>

<p>Sensitive access workflows are the perfect example of a control that should be implemented once, and safely customized many times. This is where Sym is starting today.</p>

<h3 id="everyone-is-building-the-same-damn-things">Everyone is building the same damn things</h3>

<p>Weâ€™ve talked about this one extensively already. How many of us have to fight with the same <a href="https://compliance.dev/2020/07/17/okta-aws-join-all-roles-setting/">obscâ€¦</a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://compliance.dev/2020/10/20/hello-sym/">https://compliance.dev/2020/10/20/hello-sym/</a></em></p>]]>
            </description>
            <link>https://compliance.dev/2020/10/20/hello-sym/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24839074</guid>
            <pubDate>Tue, 20 Oct 2020 16:12:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Predicting Football Results with Statistical Modelling]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24838958">thread link</a>) | @henrik_w
<br/>
October 20, 2020 | https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/ | <a href="https://web.archive.org/web/*/https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      

      <section itemprop="text">
        <p>Football (or soccer to my American readers) is full of clichÃ©s: â€œItâ€™s a game of two halvesâ€, â€œtaking it one game at a timeâ€ and â€œLiverpool have failed to win the Premier Leagueâ€. Youâ€™re less likely to hear â€œTreating the number of goals scored by each team as independent Poisson processes, statistical modelling suggests that the home team have a 60% chance of winning todayâ€. But this is actually a bit of clichÃ© too (it has been discussed <a href="https://www.pinnacle.com/en/betting-articles/soccer/how-to-calculate-poisson-distribution">here</a>, <a href="https://help.smarkets.com/hc/en-gb/articles/115001457989-How-to-calculate-Poisson-distribution-for-football-betting">here</a>, <a href="http://pena.lt/y/2014/11/02/predicting-football-using-r/">here</a>, <a href="http://opisthokonta.net/?p=296">here</a> and <a href="https://dashee87.github.io/data%20science/football/r/predicting-football-results-with-statistical-modelling/">particularly well here</a>). As weâ€™ll discover, a simple Poisson model is, well, overly simplistic. But itâ€™s a good starting point and a nice intuitive way to learn about statistical modelling. So, if you came here looking to make money, <a href="http://www.make5000poundspermonth.co.uk/">I hear this guy makes Â£5000 per month without leaving the house</a>.</p>

<h2 id="poisson-distribution">Poisson Distribution</h2>

<p>The model is founded on the number of goals scored/conceded by each team. Teams that have been higher scorers in the past have a greater likelihood of scoring goals in the future. Weâ€™ll import all match results from the recently concluded Premier League (2016/17) season. Thereâ€™s various sources for this data out there (<a href="https://www.kaggle.com/hugomathien/soccer">kaggle</a>, <a href="http://www.football-data.co.uk/englandm.php">football-data.co.uk</a>, <a href="https://github.com/jalapic/engsoccerdata">github</a>, <a href="http://api.football-data.org/index">API</a>). I built an <a href="https://github.com/dashee87/footballR">R wrapper for that API</a>, but Iâ€™ll go the csv route this time around.</p>

<div><div><pre><code><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>seaborn</span>
<span>from</span> <span>scipy.stats</span> <span>import</span> <span>poisson</span><span>,</span><span>skellam</span>

<span>epl_1617</span> <span>=</span> <span>pd</span><span>.</span><span>read_csv</span><span>(</span><span>"http://www.football-data.co.uk/mmz4281/1617/E0.csv"</span><span>)</span>
<span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>[[</span><span>'HomeTeam'</span><span>,</span><span>'AwayTeam'</span><span>,</span><span>'FTHG'</span><span>,</span><span>'FTAG'</span><span>]]</span>
<span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>.</span><span>rename</span><span>(</span><span>columns</span><span>=</span><span>{</span><span>'FTHG'</span><span>:</span> <span>'HomeGoals'</span><span>,</span> <span>'FTAG'</span><span>:</span> <span>'AwayGoals'</span><span>})</span>
<span>epl_1617</span><span>.</span><span>head</span><span>()</span>
</code></pre></div></div>

<div>
<table>
  <thead>
    <tr>
      <th></th>
      <th>HomeTeam</th>
      <th>AwayTeam</th>
      <th>HomeGoals</th>
      <th>AwayGoals</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Burnley</td>
      <td>Swansea</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Crystal Palace</td>
      <td>West Brom</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Everton</td>
      <td>Tottenham</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Hull</td>
      <td>Leicester</td>
      <td>2</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Man City</td>
      <td>Sunderland</td>
      <td>2</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>

<p>We imported a csv as a pandas dataframe, which contains various information for each of the 380 EPL games in the 2016-17 English Premier League season. We restricted the dataframe to the columns in which weâ€™re interested (specifically, team names and numer of goals scored by each team). Iâ€™ll omit most of the code that produces the graphs in this post. But donâ€™t worry, you can find that code on <a href="https://github.com/dashee87/blogScripts/blob/master/Jupyter/2017-06-04-predicting-football-results-with-statistical-modelling.ipynb">my github page</a>. Our task is to model the final round of fixtures in the season, so we must remove the last 10 rows (each gameweek consists of 10 matches).</p>

<div><div><pre><code><span>epl_1617</span> <span>=</span> <span>epl_1617</span><span>[:</span><span>-</span><span>10</span><span>]</span>
<span>epl_1617</span><span>.</span><span>mean</span><span>()</span>
</code></pre></div></div>

<div><div><pre><code>HomeGoals    1.591892
AwayGoals    1.183784
dtype: float64
</code></pre></div></div>

<p>Youâ€™ll notice that, on average, the home team scores more goals than the away team. This is the so called â€˜home (field) advantageâ€™ (discussed <a href="https://jogall.github.io/2017-05-12-home-away-pref/">here</a>) and <a href="http://bleacherreport.com/articles/1803416-is-home-field-advantage-as-important-in-baseball-as-other-major-sports">isnâ€™t specific to soccer</a>. This is a convenient time to introduce the <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson distribution</a>. Itâ€™s a discrete probability distribution that describes the probability of the number of events within a specific time period (e.g 90 mins) with a known average rate of occurrence. A key assumption is that the number of events is independent of time. In our context, this means that goals donâ€™t become more/less likely by the number of goals already scored in the match. Instead, the number of goals is expressed purely as function an average rate of goals. If that was unclear, maybe this mathematical formulation will make clearer:</p>



<p> represents the average rate (e.g. average number of goals, average number of letters you receive, etc.). So, we can treat the number of goals scored by the home and away team as two independent Poisson distributions. The plot below shows the proportion of goals scored compared to the number of goals estimated by the corresponding Poisson distributions.</p>

<p><img src="https://dashee87.github.io/images/home_away_goals_python.png" alt=""></p>

<p>We can use this statistical model to estimate the probability of specfic events.</p>



<p>The probability of a draw is simply the sum of the events where the two teams score the same amount of goals.</p>



<p>Note that we consider the number of goals scored by each team to be independent events (i.e. P(A n B) = P(A) P(B)). The difference of two Poisson distribution is actually called a <a href="https://en.wikipedia.org/wiki/Skellam_distribution">Skellam distribution</a>. So we can calculate the probability of a draw by inputting the mean goal values into this distribution.</p>

<div><div><pre><code><span># probability of draw between home and away team</span>
<span>skellam</span><span>.</span><span>pmf</span><span>(</span><span>0.0</span><span>,</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>0</span><span>],</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>1</span><span>])</span>
</code></pre></div></div>



<div><div><pre><code><span># probability of home team winning by one goal</span>
<span>skellam</span><span>.</span><span>pmf</span><span>(</span><span>1</span><span>,</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>0</span><span>],</span>  <span>epl_1617</span><span>.</span><span>mean</span><span>()[</span><span>1</span><span>])</span>
</code></pre></div></div>



<p><img src="https://dashee87.github.io/images/skellam_goals_python.png" alt=""></p>

<p>So, hopefully you can see how we can adapt this approach to model specific matches. We just need to know the average number of goals scored by each team and feed this data into a Poisson model. Letâ€™s have a look at the distribution of goals scored by Chelsea and Sunderland (teams who finished 1st and last, respectively).</p>

<p><img src="https://dashee87.github.io/images/chelsea_sunderland_goals_python.png" alt=""></p>

<h2 id="building-a-model">Building A Model</h2>

<p>You should now be convinced that the number of goals scored by each team can be approximated by a Poisson distribution. Due to a relatively sample size (each team plays at most 19 home/away games), the accuracy of this approximation can vary significantly (especially earlier in the season when teams have played fewer games). Similar to before, we could now calculate the probability of various events in this Chelsea Sunderland match. But rather than treat each match separately, weâ€™ll build a more general Poisson regression model (<a href="https://en.wikipedia.org/wiki/Poisson_regression">what is that?</a>).</p>

<div><div><pre><code><span># importing the tools required for the Poisson regression model</span>
<span>import</span> <span>statsmodels.api</span> <span>as</span> <span>sm</span>
<span>import</span> <span>statsmodels.formula.api</span> <span>as</span> <span>smf</span>

<span>goal_model_data</span> <span>=</span> <span>pd</span><span>.</span><span>concat</span><span>([</span><span>epl_1617</span><span>[[</span><span>'HomeTeam'</span><span>,</span><span>'AwayTeam'</span><span>,</span><span>'HomeGoals'</span><span>]]</span><span>.</span><span>assign</span><span>(</span><span>home</span><span>=</span><span>1</span><span>)</span><span>.</span><span>rename</span><span>(</span>
            <span>columns</span><span>=</span><span>{</span><span>'HomeTeam'</span><span>:</span><span>'team'</span><span>,</span> <span>'AwayTeam'</span><span>:</span><span>'opponent'</span><span>,</span><span>'HomeGoals'</span><span>:</span><span>'goals'</span><span>}),</span>
           <span>epl_1617</span><span>[[</span><span>'AwayTeam'</span><span>,</span><span>'HomeTeam'</span><span>,</span><span>'AwayGoals'</span><span>]]</span><span>.</span><span>assign</span><span>(</span><span>home</span><span>=</span><span>0</span><span>)</span><span>.</span><span>rename</span><span>(</span>
            <span>columns</span><span>=</span><span>{</span><span>'AwayTeam'</span><span>:</span><span>'team'</span><span>,</span> <span>'HomeTeam'</span><span>:</span><span>'opponent'</span><span>,</span><span>'AwayGoals'</span><span>:</span><span>'goals'</span><span>})])</span>

<span>poisson_model</span> <span>=</span> <span>smf</span><span>.</span><span>glm</span><span>(</span><span>formula</span><span>=</span><span>"goals ~ home + team + opponent"</span><span>,</span> <span>data</span><span>=</span><span>goal_model_data</span><span>,</span> 
                        <span>family</span><span>=</span><span>sm</span><span>.</span><span>families</span><span>.</span><span>Poisson</span><span>())</span><span>.</span><span>fit</span><span>()</span>
<span>poisson_model</span><span>.</span><span>summary</span><span>()</span>
</code></pre></div></div>

<table>
<caption>Generalized Linear Model Regression Results</caption>
<tbody><tr>
  <th>Dep. Variable:</th>        <td>goals</td>      <th>  No. Observations:  </th>  <td>   740</td> 
</tr>
<tr>
  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   700</td> 
</tr>
<tr>
  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>    39</td> 
</tr>
<tr>
  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th>    <td>1.0</td>  
</tr>
<tr>
  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -1042.4</td>
</tr>
<tr>
  <th>Date:</th>           <td>Sat, 10 Jun 2017</td> <th>  Deviance:          </th> <td>  776.11</td>
</tr>
<tr>
  <th>Time:</th>               <td>11:17:38</td>     <th>  Pearson chi2:      </th>  <td>  659.</td> 
</tr>
<tr>
  <th>No. Iterations:</th>         <td>8</td>        <th>                     </th>     <td> </td>   
</tr>
</tbody></table>
<table>
<tbody><tr>
               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P&gt;|z|</th> <th>[95.0% Conf. Int.]</th> 
</tr>
<tr>
  <th>Intercept</th>                  <td>    0.3725</td> <td>    0.198</td> <td>    1.880</td> <td> 0.060</td> <td>   -0.016     0.761</td>
</tr>
<tr>
  <th>team[T.Bournemouth]</th>        <td>   -0.2891</td> <td>    0.179</td> <td>   -1.612</td> <td> 0.107</td> <td>   -0.641     0.062</td>
</tr>
<tr>
  <th>team[T.Burnley]</th>            <td>   -0.6458</td> <td>    0.200</td> <td>   -3.230</td> <td> 0.001</td> <td>   -1.038    -0.254</td>
</tr>
<tr>
  <th>team[T.Chelsea]</th>            <td>    0.0789</td> <td>    0.162</td> <td>    0.488</td> <td> 0.626</td> <td>   -0.238     0.396</td>
</tr>
<tr>
  <th>team[T.Crystal Palace]</th>     <td>   -0.3865</td> <td>    0.183</td> <td>   -2.107</td> <td> 0.035</td> <td>   -0.746    -0.027</td>
</tr>
<tr>
  <th>team[T.Everton]</th>            <td>   -0.2008</td> <td>    0.173</td> <td>   -1.161</td> <td> 0.246</td> <td>   -0.540     0.138</td>
</tr>
<tr>
  <th>team[T.Hull]</th>               <td>   -0.7006</td> <td>    0.204</td> <td>   -3.441</td> <td> 0.001</td> <td>   -1.100    -0.302</td>
</tr>
<tr>
  <th>team[T.Leicester]</th>          <td>   -0.4204</td> <td>    0.187</td> <td>   -2.249</td> <td> 0.025</td> <td>   -0.787    -0.054</td>
</tr>
<tr>
  <th>team[T.Liverpool]</th>          <td>    0.0162</td> <td>    0.164</td> <td>    0.099</td> <td> 0.921</td> <td>   -0.306     0.338</td>
</tr>
<tr>
  <th>team[T.Man City]</th>           <td>    0.0117</td> <td>    0.164</td> <td>    0.072</td> <td> 0.943</td> <td>   -0.310     0.334</td>
</tr>
<tr>
  <th>team[T.Man United]</th>         <td>   -0.3572</td> <td>    0.181</td> <td>   -1.971</td> <td> 0.049</td> <td>   -0.713    -0.002</td>
</tr>
<tr>
  <th>team[T.Middlesbrough]</th>      <td>   -1.0087</td> <td>    0.225</td> <td>   -4.481</td> <td> 0.000</td> <td>   -1.450    -0.568</td>
</tr>
<tr>
  <th>team[T.Southampton]</th>        <td>   -0.5804</td> <td>    0.195</td> <td>   -2.976</td> <td> 0.003</td> <td>   -0.963    -0.198</td>
</tr>
<tr>
  <th>team[T.Stoke]</th>              <td>   -0.6082</td> <td>    0.197</td> <td>   -3.094</td> <td> 0.002</td> <td>   -0.994    -0.223</td>
</tr>
<tr>
  <th>team[T.Sunderland]</th>         <td>   -0.9619</td> <td>    0.222</td> <td>   -4.329</td> <td> 0.000</td> <td>   -1.397    -0.526</td>
</tr>
<tr>
  <th>team[T.Swansea]</th>            <td>   -0.5136</td> <td>    0.192</td> <td>   -2.673</td> <td> 0.008</td> <td>   -0.890    -0.137</td>
</tr>
<tr>
  <th>team[T.Tottenham]</th>          <td>    0.0532</td> <td>    0.162</td> <td>    0.328</td> <td> 0.743</td> <td>   -0.265     0.371</td>
</tr>
<tr>
  <th>team[T.Watford]</th>            <td>   -0.5969</td> <td>    0.197</td> <td>   -3.035</td> <td> 0.002</td> <td>   -0.982    -0.211</td>
</tr>
<tr>
  <th>team[T.West Brom]</th>          <td>   -0.5567</td> <td>    0.194</td> <td>   -2.876</td> <td> 0.004</td> <td>   -0.936    -0.177</td>
</tr>
<tr>
  <th>team[T.West Ham]</th>           <td>   -0.4802</td> <td>    0.189</td> <td>   -2.535</td> <td> 0.011</td> <td>   -0.851    -0.109</td>
</tr>
<tr>
  <th>opponent[T.Bournemouth]</th>    <td>    0.4109</td> <td>    0.196</td> <td>    2.092</td> <td> 0.036</td> <td>    0.026     0.796</td>
</tr>
<tr>
  <th>opponent[T.Burnley]</th>        <td>    0.1657</td> <td>    0.206</td> <td>    0.806</td> <td> 0.420</td> <td>   -0.237     0.569</td>
</tr>
<tr>
  <th>opponent[T.Chelsea]</th>        <td>   -0.3036</td> <td>    0.234</td> <td>   -1.298</td> <td> 0.194</td> <td>   -0.762     0.155</td>
</tr>
<tr>
  <th>opponent[T.Crystal Palace]</th> <td>    0.3287</td> <td>    0.200</td> <td>    1.647</td> <td> 0.100</td> <td>   -0.062     0.720</td>
</tr>
<tr>
  <th>opponent[T.Everton]</th>        <td>   -0.0442</td> <td>    0.218</td> <td>   -0.202</td> <td> 0.840</td> <td>   -0.472     0.384</td>
</tr>
<tr>
  <th>opponent[T.Hull]</th>           <td>    0.4979</td> <td>    0.193</td> <td>    2.585</td> <td> 0.010</td> <td>    0.120     0.875</td>
</tr>
<tr>
  <th>opponent[T.Leicester]</th>      <td>    0.3369</td> <td>    0.199</td> <td>    1.694</td> <td> 0.090</td> <td>   -0.053     0.727</td>
</tr>
<tr>
  <th>opponent[T.Liverpool]</th>      <td>   -0.0374</td> <td>    0.217</td> <td>   -0.172</td> <td> 0.863</td> <td>   -0.463     0.389</td>
</tr>
<tr>
  <th>opponent[T.Man City]</th>       <td>   -0.0993</td> <td>    0.222</td> <td>   -0.448</td> <td> 0.654</td> <td>   -0.534     0.335</td>
</tr>
<tr>
  <th>opponent[T.Man United]</th>     <td>   -0.4220</td> <td>    0.241</td> <td>   -1.754</td> <td> 0.079</td> <td>   -0.894     0.050</td>
</tr>
<tr>
  <th>opponent[T.Middlesbrough]</th>  <td>    0.1196</td> <td>    0.208</td> <td>    0.574</td> <td> 0.566</td> <td>   -0.289     0.528</td>
</tr>
<tr>
  <th>opponent[T.Southampton]</th>    <td>    0.0458</td> <td>    0.211</td> <td>    0.217</td> <td> 0.828</td> <td>   -0.369     0.460</td>
</tr>
<tr>
  <th>opponent[T.Stoke]</th>          <td>    0.2266</td> <td>    0.203</td> <td>    1.115</td> <td> 0.265</td> <td>   -0.172     0.625</td>
</tr>
<tr>
  <th>opponent[T.Sunderland]</th>     <td>    0.3707</td> <td>    0.198</td> <td>    1.876</td> <td> 0.061</td> <td>   -0.017     0.758</td>
</tr>
<tr>
  <th>opponent[T.Swansea]</th>        <td>    0.4336</td> <td>    0.195</td> <td>    2.227</td> <td> 0.026</td> <td>    0.052     0.815</td>
</tr>
<tr>
  <th>opponent[T.Tottenham]</th>      <td>   -0.5431</td> <td>    0.252</td> <td>   -2.156</td> <td> 0.031</td> <td>   -1.037    -0.049</td>
</tr>
<tr>
  <th>opponent[T.Watford]</th>        <td>    0.3533</td> <td>    0.198</td> <td>    1.782</td> <td> 0.075</td> <td>   -0.035     0.742</td>
</tr>
<tr>
  <th>opponent[T.West Brom]</th>      <td>    0.0970</td> <td>    0.209</td> <td>    0.463</td> <td> 0.643</td> <td>   -0.313     0.507</td>
</tr>
<tr>
  <th>opponent[T.West Ham]</th>       <td>    0.3485</td> <td>    0.198</td> <td>    1.758</td> <td> 0.079</td> <td>   -0.040     0.737</td>
</tr>
<tr>
  <th>home</th>                       <td>    0.2969</td> <td>    0.063</td> <td>    4.702</td> <td> 0.000</td> <td>    0.173     0.421</td>
</tr>
</tbody></table>

<p>If youâ€™re curious about the <code>smf.glm(...)</code> part, you can find more information <a href="http://www.statsmodels.org/stable/examples/notebooks/generated/glm_formula.html">here</a> (edit: earlier versions of this post had erroneously employed a Generalised Estimating Equation (GEE)- <a href="https://stats.stackexchange.com/questions/16390/when-to-use-generalized-estimating-equations-vs-mixed-effects-models">whatâ€™s the difference?</a>). Iâ€™m more interested in the values presented in the <code>coef</code> column in the model summary table, which are analogous to the slopes in linear regression. Similar to <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>, we take the <a href="http://www.lisa.stat.vt.edu/sites/default/files/Poisson.and_.Logistic.Regression.pdf">exponent of the parameter values</a>. A positive value implies more goals (), while values closer to zero represent more neutral effects (). Towards the bottom of the table you might notice that <code>home</code> has a <code>coef</code> of 0.2969. This captures the fact that home teams generally score more goals than the away team (specifically, =1.35 times more likely). But not all teams are created equal. Chelsea has a <code>coef</code> of 0.0789, while the corresponding value for Sunderland is -0.9619 (sort of saying Chelsea (Sunderland) are better (much worse!) scorers than average). Finally, the <code>opponent*</code> values â€¦</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/">https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/</a></em></p>]]>
            </description>
            <link>https://dashee87.github.io/football/python/predicting-football-results-with-statistical-modelling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24838958</guid>
            <pubDate>Tue, 20 Oct 2020 16:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I created a webapp to help me learn simplified Chinese characters]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24838236">thread link</a>) | @tmsbrg
<br/>
October 20, 2020 | https://www.thomasvanderberg.nl/blog/cn-hanzi/ | <a href="https://web.archive.org/web/*/https://www.thomasvanderberg.nl/blog/cn-hanzi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  
  

  

  <div itemprop="articleBody">
    <p>Find common Chinese characters using pinyin.</p>

<p>Click the image to try it now:</p>

<p><a href="https://www.thomasvanderberg.nl/cn/hanzi/"><img src="https://www.thomasvanderberg.nl/images/hanzi_screenshot.png" alt="Hanzi searchtool showing common Chinese characters pronounced &quot;shi&quot;"></a></p>

<h2 id="what">What</h2>

<p>Itâ€™s a tool that allows you to enter pinyin and optionally a tone number and shows only the <em>commonly used</em> Chinese characters with this pronunciation.</p>

<p>It allows you to switch between the top 3500 character list (frequently used) or the top 6500 (relatively common),</p>

<p>Some other features include showing or hiding all pinyin pronunciations for the characters, and showing or searching by the index of the character from the source <a href="https://en.wikipedia.org/wiki/Table_of_General_Standard_Chinese_Characters">Table of General Standard Chinese Characters</a>.</p>

<p>It currently only deals with simplified characters, because thatâ€™s what the source deals with and what Iâ€™m trying to learn.</p>

<p>Note that this is not a comprehensive Chinese learning tool. To learn Chinese you need to learn words, not just characters. Characters are just one layer in the Chinese language, and even full understanding of all Chinese characters would not mean youâ€™ve learned the language.</p>

<h2 id="why-i-made-this">Why I made this</h2>

<p>While learning Chinese, I wanted to get an understanding of which Chinese characters are actually in common use. If you look in a dictionary for a list of Chinese characters, you will get a bewildering amount of characters. Dictionaries try to be comprehensive. Fortunately, most of these are only in historic use.</p>

<p>I wanted to remove the forest of irrelevant (for my purposes) characters and find get a list of ones actually worth investing time into.</p>

<p>I made this to get an overview and easily be able to answer questions like â€œhow many common characters share this pronunciation?â€.</p>

<p>I also wanted it to work without having to wait for a web page to load for each query. I made it work using a fully offline search (you download the data when loading the page itself).</p>

<h2 id="sources-and-data">Sources and data</h2>

<p>During my search I found this official list of <a href="https://en.wikipedia.org/wiki/Table_of_General_Standard_Chinese_Characters">Table of General Standard Chinese Characters</a> made by the Chinese government.</p>

<p>Sadly, this list is a rasterized PDF which does not even contain the pronunciation of these characters.</p>

<p>Still, it seemed like a good authoritative reference of commonly used characters. I started searching around and found a text version of it on <a href="http://xh.5156edu.com/page/z6211m4474j19255.html">this Chinese webpage</a>. While checking the data I found it had some mistakes around characters 3649 to 3668, which I had to fix manually.</p>

<p>To combine this with pronunciation data I found the <a href="ftp://ftp.cuhk.hk/pub/chinese/ifcss/software/data/Uni2Pinyin.gz">Unicode Pinyin Table</a>. Iâ€™ve added numerouos pronunciations manually, when I found them missing from that source. Iâ€™ve logged my manual edits in <a href="https://www.thomasvanderberg.nl/files/edits-to-hanzi-pinyin.txt">edits-to-hanzi-pinyin.txt</a>. Note that since Iâ€™m only a basic Chinese speaker myself, I canâ€™t exclude that thereâ€™s likely more mistakes. Iâ€™m open to using a more reliable source for pronunciation data if one is available.</p>

<p>Using this data I created the <a href="https://www.thomasvanderberg.nl/files/hanzi-pinyin.6500.csv">hanzi-pinyin.6500.csv</a> and <a href="https://www.thomasvanderberg.nl/files/hanzi-pinyin.3500.csv">hanzi-pinyin.3500.csv</a> files which are the source of the Hanzi search tool.</p>

<h2 id="how-did-i-make-this">How did I make this</h2>

<p>Originally I just used <a href="https://en.wikipedia.org/wiki/Grep">grep</a> to search the hanzi-pinyin CSV files, but found it to become cumbersome due to the need to write regular expressions when I just wanted to think about pinyin.</p>

<p>I created the <a href="https://www.thomasvanderberg.nl/files/cnhz.py">cnhz</a> python script for myself, originally as a simple wrapper to build the grep regexes for me so I could just write pinyin. I then added more features around it.</p>

<p>As it got more useful I thought about how I could make it more accessible for other Chinese learners too. Most of them do not use Linux or have Python installed. I thought of rewriting it in Go to make it a single executable - but found the command line format would be awkward for most people. Also Windows cmd.exe does not support Chinese characters.</p>

<p>I eventually decided to turn it into a webpage. the CSV files were sufficiently small that the entire database could be loaded into the browserâ€™s memory so you could do a completely client side search - making the experience much smoother than loading an online dictionary entry.</p>

<p>Also, because I can easily host it on my own web page, which I pay for anyway, I donâ€™t have any need to add advertisements or anything to make the experience worse.</p>

<p>Furthermore, the page can easily be downloaded and used offline by any learner in case my site goes down or for when you donâ€™t have internet.</p>

<p>I tried to support offline working more by making the site into a <a href="https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps">progressive web app</a>. However, while adding a manifest was easy, I found that to add a <a href="https://developer.mozilla.org/en-US/docs/Web/API/Service_Worker_API">service worker</a> (which allows offline caching) - I would have to move all assets including a copy of my main CSS file to /cn/hanzi/. Not having time to figure this out at the moment, I decided to not add service workers for now.</p>

<p>By the way, the <a href="http://localhost:4000/js/hanzi_list.js">hanzi_list.js</a> file was generated from the CSV sources using an <code>awk</code> script:</p>

<div><div><pre><code>&lt; ../files/hanzi-pinyin-full.csv \
    awk \
    'NR==1 { printf "const hanzi_3500 = \"" }
     NR==3501 { printf "\"; const hanzi_6500 = hanzi_3500 + \"" }
     { print NR","$0"\\n\\" }
     END { print "\";\nconst hanzi_6500_split = hanzi_6500.split(\"\\n\");" }' \
 &gt; ../js/hanzi_list.js
</code></pre></div></div>

<p>I hope you find my <a href="https://www.thomasvanderberg.nl/cn/hanzi">Chinese hanzi tool</a> useful. If you have any questions or want to contact me, see my details below.</p>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.thomasvanderberg.nl/blog/cn-hanzi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24838236</guid>
            <pubDate>Tue, 20 Oct 2020 15:11:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why build another website builder?]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 85 (<a href="https://news.ycombinator.com/item?id=24837331">thread link</a>) | @apledger3
<br/>
October 20, 2020 | https://www.makeswift.com/blog/why-build-another-website-builder | <a href="https://web.archive.org/web/*/https://www.makeswift.com/blog/why-build-another-website-builder">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div width="[object Object]" data-slate-editor="true" data-key="8882" autocorrect="on" spellcheck="true" data-gramm="false"><p data-slate-object="block" data-key="8883"><span data-slate-object="text" data-key="8884"><span data-slate-leaf="true" data-offset-key="8884:0"><span><span data-slate-string="true">Name something expensive that's difficult to build and trashed after each use.</span></span></span></span></p><p data-slate-object="block" data-key="8887"><span data-slate-object="text" data-key="8888"><span data-slate-leaf="true" data-offset-key="8888:0"><span><span data-slate-string="true">Did you say rockets? No, SpaceX figured out how to reuse those in 2015. </span></span></span></span></p><p data-slate-object="block" data-key="8891"><span data-slate-object="text" data-key="8892"><span data-slate-leaf="true" data-offset-key="8892:0"><span><span data-slate-string="true">I'm talking about your company's website. Completely overhauling the website has become so routine that we've become numb to the pain of throwing it all away, over and over again.</span></span></span></span></p><p data-slate-object="block" data-key="8895"><span data-slate-object="text" data-key="8896"><span data-slate-leaf="true" data-offset-key="8896:0"><span><span data-slate-string="true">Let's explore why this happens.</span></span></span></span></p><p data-slate-object="block" data-key="8899"><span data-slate-object="text" data-key="8900"><span data-slate-leaf="true" data-offset-key="8900:0"><span><span data-slate-string="true">Imagine you're the cofounder of a new company. You need to set up a website, but your product partner is already behind on features so that leaves it solely up to you. What's your plan? Given the tight budget and schedule, the disciplined move would be to quickly use a template in an inexpensive website builder. You can graduate to something a little more custom once you have more resources and your brand, positioning, and voice figured out.</span></span></span></span></p><p data-slate-object="block" data-key="8903"><span data-slate-object="text" data-key="8904"><span data-slate-leaf="true" data-offset-key="8904:0"><span><span data-slate-string="true">Sounds like a good plan, but anyone who's gone down this path knows it's never as simple as it seems.</span></span></span></span></p><p data-slate-object="block" data-key="8907"><span data-slate-object="text" data-key="8908"><span data-slate-leaf="true" data-offset-key="8908:0"><span><span data-slate-string="true">For one, the template never lasts as long as you need it to. You realize the design isn't working, or your competitor just unexpectedly made a move. So you start trying to make changes. Swapping out the text and images comes easy, but as soon as you start adjusting the layout, frustration begins to set in. You've got a million other things to do and for some reason you can't get the page to look right on mobile. </span></span></span></span></p><p data-slate-object="block" data-key="8911"><span data-slate-object="text" data-key="8912"><span data-slate-leaf="true" data-offset-key="8912:0"><span><span data-slate-string="true">As it turns out, the same features and guard rails that made it easy to stand up the template have now become the reason it's hard to iterate. You're stuck, and whether or not you were ready, the time has come</span></span></span></span><span data-slate-object="text" data-key="8913"><span data-slate-leaf="true" data-offset-key="8913:0"><span><span data-slate-string="true"> to deal with the classic website building dilemma:</span></span></span></span></p><p data-slate-object="block" data-key="8916"><span data-slate-object="text" data-key="8917"><span data-slate-leaf="true" data-offset-key="8917:0"><span><span data-slate-string="true">Do you stay put and compromise on your vision, or invest in another solution that </span></span></span></span><span data-slate-object="text" data-key="8918"><span data-slate-leaf="true" data-offset-key="8918:0"><span><span data-slate-string="true">might</span></span></span></span><span data-slate-object="text" data-key="8919"><span data-slate-leaf="true" data-offset-key="8919:0"><span><span data-slate-string="true"> be better?</span></span></span></span></p><p data-slate-object="block" data-key="8922"><span data-slate-object="text" data-key="8923"><span data-slate-leaf="true" data-offset-key="8923:0"><span><span data-slate-string="true">After researching more advanced solutions for a few days, it starts to become apparent that you're out of your depth. There are so many different products, and every time you begin stepping away from the template you're consistently met with a giant learning curve. Frustration sets in again so you decide to call that technical friend. You're in luck! She's got her favorite tool and she's available to help.</span></span></span></span></p><p data-slate-object="block" data-key="8926"><span data-slate-object="text" data-key="8927"><span data-slate-leaf="true" data-offset-key="8927:0"><span><span data-slate-string="true">Unfortunately, all you're about to do is move your bottleneck. You may think once things are set up you can say your goodbyes, but the reality is you're never free. As your team and ideas grow you'll need more and more help, and she'll be the only one who can make the big changes. Your projects will start moving slower and slower. But on the bright side, at least you'll be able to get it done... eventually.</span></span></span></span></p><p data-slate-object="block" data-key="8930"><span data-slate-object="text" data-key="8931"><span data-slate-leaf="true" data-offset-key="8931:0"><span><span data-slate-string="true">But what happens if she leaves? Nobody likes stepping into someone else's mess, so it ends up being cheaper to just rebuild using whatever tool the new technical expert is comfortable with. </span></span></span></span><span data-slate-object="text" data-key="8932"><span data-slate-leaf="true" data-offset-key="8932:0"><span><span data-slate-string="true">Is it any mystery, then, why we're stuck in this constant build, trash, move, build cycle?</span></span></span></span><span data-slate-object="text" data-key="8933"><span data-slate-leaf="true" data-offset-key="8933:0"><span><span data-slate-string="true"> </span></span></span></span><span data-slate-object="text" data-key="8934"><span data-slate-leaf="true" data-offset-key="8934:0"><span><span data-slate-string="true">The solutions have changed, but the underlying trade-off hasn't. </span></span></span></span><span data-slate-object="text" data-key="8935"><span data-slate-leaf="true" data-offset-key="8935:0"><span><span data-slate-string="true">All options are either too basic and restrictive, or too technical and complex.</span></span></span></span></p><p data-slate-object="block" data-key="8938"><span data-slate-object="text" data-key="8939"><span data-slate-leaf="true" data-offset-key="8939:0"><span><span data-slate-string="true">Founders building out early marketing for their startups are not the only ones who experience this. At some point, all marketers feel this pain.</span></span></span></span></p><p data-slate-object="block" data-key="8942"><span data-slate-object="text" data-key="8943"><span data-slate-leaf="true" data-offset-key="8943:0"><span><span data-slate-string="true">The problem is so widespread that it's given birth to a whole category of products called landing page builders.</span></span></span></span></p><p data-slate-object="block" data-key="8946"><span data-slate-object="text" data-key="8947"><span data-slate-leaf="true" data-offset-key="8947:0"><span><span data-slate-string="true">Marketers are so fed up with being sidelined that they're willing to duct tape their site with </span></span></span></span><span data-slate-object="text" data-key="8948"><span data-slate-leaf="true" data-offset-key="8948:0"><span><span data-slate-string="true">mostly</span></span></span></span><span data-slate-object="text" data-key="8949"><span data-slate-leaf="true" data-offset-key="8949:0"><span><span data-slate-string="true"> on-brand pages, just to have some operational independence when it comes to web content. Sure, landing page builders can have extra features bolted on like A/B testing and analytics, but they aren't the real reason marketers are out shopping for a solution. Marketers are looking for a place where they can get creative and not break anything.</span></span></span></span></p><p data-slate-object="block" data-key="8952"><span data-slate-object="text" data-key="8953"><span data-slate-leaf="true" data-offset-key="8953:0"><span><span data-slate-string="true">We know this because we built and eventually sunset a landing page builder, Landing Lion. Many of our customers wished they could build full websites in it, and some actually did. Despite its many shortcomings around bulk management, a surprising number of customers were willing to put in extra manual work to build and maintain full websites. The reason? Our user experience was actually designed for themâ€”intelligent and tech-savvy generalists who wanted to break free from the template without having to go get a degree. They could finally build exactly what they envisioned and they could do it by themselves, quickly.</span></span></span></span></p><p data-slate-object="block" data-key="8956"><span data-slate-object="text" data-key="8957"><span data-slate-leaf="true" data-offset-key="8957:0"><span><span data-slate-string="true">The real problem was that for the rest of our customers, their websites were locked down. They'd been delicately constructed by the real owners, the technical experts. But who is ultimately responsible for the </span></span></span></span><span data-slate-object="text" data-key="8958"><span data-slate-leaf="true" data-offset-key="8958:0"><span><span data-slate-string="true">entire</span></span></span></span><span data-slate-object="text" data-key="8959"><span data-slate-leaf="true" data-offset-key="8959:0"><span><span data-slate-string="true"> brand experience, website included? The marketers.</span></span></span></span></p><p data-slate-object="block" data-key="8962"><span data-slate-object="text" data-key="8963"><span data-slate-leaf="true" data-offset-key="8963:0"><span><span data-slate-string="true">That's why we're building Makeswift.</span></span></span></span></p></div></div><div><div width="[object Object]" data-slate-editor="true" data-key="8965" autocorrect="on" spellcheck="true" data-gramm="false"><p data-slate-object="block" data-key="8966"><span data-slate-object="text" data-key="8967"><span data-slate-leaf="true" data-offset-key="8967:0"><span><span data-slate-string="true">Marketers need a website builder designed just for them. Our mission is to tackle the issues holding back marketing teams from building, shipping, and iterating on </span></span></span></span><span data-slate-object="text" data-key="8968"><span data-slate-leaf="true" data-offset-key="8968:0"><span><span data-slate-string="true">all</span></span></span></span><span data-slate-object="text" data-key="8969"><span data-slate-leaf="true" data-offset-key="8969:0"><span><span data-slate-string="true"> web content, on their own schedule.</span></span></span></span></p><p data-slate-object="block" data-key="8972"><span data-slate-object="text" data-key="8973"><span data-slate-leaf="true" data-offset-key="8973:0"><span><span data-slate-string="true">To do this, we need to fix the user experience. More specifically, we need to move away from the split "template &amp; content" user experience found in nearly all advanced website solutions. This approach exposes two distinct experiences to the end user: One for a technical specialist to build a template, and another basic experience, usually a form, to plug in content. This creates a problem where the people responsible for the content can't change the templateâ€”sound familiar?</span></span></span></span></p><p data-slate-object="block" data-key="8976"><span data-slate-object="text" data-key="8977"><span data-slate-leaf="true" data-offset-key="8977:0"><span><span data-slate-string="true">To move as fast as possible, the people in charge of </span></span></span></span><span data-slate-object="text" data-key="8978"><span data-slate-leaf="true" data-offset-key="8978:0"><span><span data-slate-string="true">what</span></span></span></span><span data-slate-object="text" data-key="8979"><span data-slate-leaf="true" data-offset-key="8979:0"><span><span data-slate-string="true"> to build need to also control </span></span></span></span><span data-slate-object="text" data-key="8980"><span data-slate-leaf="true" data-offset-key="8980:0"><span><span data-slate-string="true">how</span></span></span></span><span data-slate-object="text" data-key="8981"><span data-slate-leaf="true" data-offset-key="8981:0"><span><span data-slate-string="true"> it's built.</span></span></span></span></p><p data-slate-object="block" data-key="8984"><span data-slate-object="text" data-key="8985"><span data-slate-leaf="true" data-offset-key="8985:0"><span><span data-slate-string="true">That's why we're focused on designing a single, elegant user experience that can be easily taught to an entire team of tech-savvy generalists. The challenge is to provide enough power for advanced use cases without making the product difficult to </span></span></span></span><span data-slate-object="text" data-key="8986"><span data-slate-leaf="true" data-offset-key="8986:0"><span><span data-slate-string="true">learn</span></span></span></span><span data-slate-object="text" data-key="8987"><span data-slate-leaf="true" data-offset-key="8987:0"><span><span data-slate-string="true">. Learning to build completely custom websites should be no more complicated than learning to design a slide show presentation.</span></span></span></span></p><p data-slate-object="block" data-key="8990"><span data-slate-object="text" data-key="8991"><span data-slate-leaf="true" data-offset-key="8991:0"><span><span data-slate-string="true">So why build another website builder? With what feels like a new website builder popping up everyday, it's apparent that we're all still searching for something better. If you're interested in shaping the way we build, ship, and iterate on web content, please sign up for our early access program.</span></span></span></span></p></div></div></div>]]>
            </description>
            <link>https://www.makeswift.com/blog/why-build-another-website-builder</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837331</guid>
            <pubDate>Tue, 20 Oct 2020 13:57:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I made a curated Moon page for anyone to learn why we explore the Moon]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24837248">thread link</a>) | @uncertainquark
<br/>
October 20, 2020 | https://jatan.space/the-moon/ | <a href="https://web.archive.org/web/*/https://jatan.space/the-moon/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header role="banner">
		<a href="#content" tabindex="0">
			Skip to content		</a>
		<div id="header-grid">
	<div data-row-id="top" data-show-on="desktop">

	<div>
		<div>
			<div data-section="hfg_header_layout_top">
				<div><div data-section="title_tagline" data-item-id="logo">
	<div>
	<a href="https://jatan.space/" title="Jatan's Space" aria-label="Jatan's Space"><div><p><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/moon-rocket-logo-transparent.png?fit=1000%2C1000&amp;ssl=1" alt=""></p><div><p>Jatan's Space</p><p><small>Advocating space exploration and Moon settlements</small></p></div></div></a></div>

	</div>

</div>							</div>
		</div>
	</div>
</div>


<nav data-row-id="main" data-show-on="desktop">

	<div>
		<div>
			<div data-section="hfg_header_layout_main">
				<div><div data-section="header_menu_primary" data-item-id="primary-menu">
	<div>
	<div role="navigation" aria-label="Primary Menu">

		<ul id="nv-primary-navigation-main"><li id="menu-item-1915"><a href="https://jatan.space/">Blog</a></li>
<li id="menu-item-3556"><a href="https://jatan.space/sitemap/">Topics</a></li>
<li id="menu-item-3687"><a href="https://jatan.space/subscribe/">Subscribe</a></li>
<li id="menu-item-2904"><a href="https://jatan.space/talks/">Talks</a></li>
<li id="menu-item-2120"><a href="https://jatan.space/about/">About</a></li>
</ul>	</div>
</div>

	</div>

<div data-section="header_button" data-item-id="button_base">
	<div><p><a href="https://jatan.space/support">Support Me</a></p></div>	</div>

<div data-section="header_search_responsive" data-item-id="header_search_responsive">
	<div>
	<div [class]="visible ? 'menu-item-nav-search active canvas' : 'menu-item-nav-search canvas'" id="nv-search-icon-responsive" tabindex="0">
		<a href="#">
				<svg width="15" height="15" viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1216 832q0-185-131.5-316.5t-316.5-131.5-316.5 131.5-131.5 316.5 131.5 316.5 316.5 131.5 316.5-131.5 131.5-316.5zm512 832q0 52-38 90t-90 38q-54 0-90-38l-343-342q-179 124-399 124-143 0-273.5-55.5t-225-150-150-225-55.5-273.5 55.5-273.5 150-225 225-150 273.5-55.5 273.5 55.5 225 150 150 225 55.5 273.5q0 220-124 399l343 343q37 37 37 90z"></path></svg>
			</a>		<div aria-label="search">
			<div>
				<form role="search" method="get" action="https://jatan.space/"><label><span>Search for...</span></label><div></div></form>			</div>
							
					</div>
	</div>
</div>
	</div>

</div>							</div>
		</div>
	</div>
</nav>

<div data-row-id="top" data-show-on="mobile">

	<div>
		<div>
			<div data-section="hfg_header_layout_top">
				<div><div data-section="title_tagline" data-item-id="logo">
	<div>
	<a href="https://jatan.space/" title="Jatan's Space" aria-label="Jatan's Space"><div><p><img src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/09/moon-rocket-logo-transparent.png?fit=1000%2C1000&amp;ssl=1" alt=""></p><div><p>Jatan's Space</p><p><small>Advocating space exploration and Moon settlements</small></p></div></div></a></div>

	</div>

</div>							</div>
		</div>
	</div>
</div>


<nav data-row-id="main" data-show-on="mobile">

	<div>
		<div>
			<div data-section="hfg_header_layout_main">
				<div><div data-section="header_menu_icon" data-item-id="nav-icon">
	 <!--.navbar-toggle-wrapper-->


	</div>

<div data-section="header_button" data-item-id="button_base">
	<div><p><a href="https://jatan.space/support">Support Me</a></p></div>	</div>

<div data-section="header_search_responsive" data-item-id="header_search_responsive">
	<div>
	<div [class]="visible ? 'menu-item-nav-search active canvas' : 'menu-item-nav-search canvas'" id="nv-search-icon-responsive" tabindex="0">
		<a href="#">
				<svg width="15" height="15" viewBox="0 0 1792 1792" xmlns="http://www.w3.org/2000/svg"><path d="M1216 832q0-185-131.5-316.5t-316.5-131.5-316.5 131.5-131.5 316.5 131.5 316.5 316.5 131.5 316.5-131.5 131.5-316.5zm512 832q0 52-38 90t-90 38q-54 0-90-38l-343-342q-179 124-399 124-143 0-273.5-55.5t-225-150-150-225-55.5-273.5 55.5-273.5 150-225 225-150 273.5-55.5 273.5 55.5 225 150 150 225 55.5 273.5q0 220-124 399l343 343q37 37 37 90z"></path></svg>
			</a>		<div aria-label="search">
			<div>
				<form role="search" method="get" action="https://jatan.space/"><label><span>Search for...</span></label><div></div></form>			</div>
							
					</div>
	</div>
</div>
	</div>

</div>							</div>
		</div>
	</div>
</nav>

<div id="header-menu-sidebar">
	<div id="header-menu-sidebar-bg">
		
		<div id="header-menu-sidebar-inner">
			<div><div data-section="header_menu_primary" data-item-id="primary-menu">
	<div>
	<div role="navigation" aria-label="Primary Menu">

		<ul id="nv-primary-navigation-sidebar"><li><a href="https://jatan.space/">Blog</a></li>
<li><a href="https://jatan.space/sitemap/">Topics</a></li>
<li><a href="https://jatan.space/subscribe/">Subscribe</a></li>
<li><a href="https://jatan.space/talks/">Talks</a></li>
<li><a href="https://jatan.space/about/">About</a></li>
</ul>	</div>
</div>

	</div>

</div>		</div>
	</div>
</div>


</div>
	</header>
		
	<main id="content" role="main">

<div>
	<div>
				<div>
			<div>
	<!--.nv-page-title-->
</div> <!--.nv-page-title-wrap-->
<div>
<p>Our Moon is a unique place to answer fundamental questions about the Solar System, and enable sustained human presence in space. Here are some curated resources for you to learn more about the Moon and join the exploration gang! ğŸš€</p>


				<div>
			<div data-posts="">
								
	<article data-post-id="2625">
					<figure>
				<a href="https://jatan.space/why-explore-the-moon/" rel="bookmark">
					<img width="1200" height="900" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=800%2C600&amp;ssl=1 800w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/04/orientale-basin.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/why-explore-the-moon/" rel="bookmark">Why explore the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3564">
					<figure>
				<a href="https://jatan.space/the-moon-as-a-rocket-platform/" rel="bookmark">
					<img width="1200" height="900" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=400%2C300&amp;ssl=1 400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?zoom=2&amp;resize=1200%2C900&amp;ssl=1 2400w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/starship-takeoff-the-moon.jpg?zoom=3&amp;resize=1200%2C900&amp;ssl=1 3600w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/the-moon-as-a-rocket-platform/" rel="bookmark">Rocket Science 101: The Moon as a rocket platform</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				


<div>
<div><p><a href="https://www.planetary.org/space-missions/every-moon-mission">Every Mission to the Moon, ever</a></p></div>
</div>







<p><strong>APOLLO </strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="1261">
					<figure>
				<a href="https://jatan.space/apollo-moon-origin/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/01/7f278-the-moon-by-galileo.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/apollo-moon-origin/" rel="bookmark">How the Apollo missions transformed our understanding of the Moonâ€™s origin</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3809">
					<figure>
				<a href="https://jatan.space/space-digest-apollo-moon-landings/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/04/apollo-11-buzz-aldrin-footprint.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/space-digest-apollo-moon-landings/" rel="bookmark">Space Digest â€“ The Apollo Moon landings</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3755">
					<figure>
				<a href="https://jatan.space/apollo-11-landing-site/" rel="bookmark">
					<img width="800" height="600" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?w=1023&amp;ssl=1 1023w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=768%2C577&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/07/apollo-11-landing-site-map.jpg?resize=400%2C300&amp;ssl=1 400w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/apollo-11-landing-site/" rel="bookmark">The landing site of NASA Apollo 11</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				


<div>
<div><p><a href="https://www.planetary.org/space-missions/celebrating-apollo-at-50">Curated Apollo stories</a></p></div>



<div><p><a href="https://svs.gsfc.nasa.gov/Gallery/apollo.html#section3-id">Views from Apollo </a></p></div>
</div>







<p><strong>CHANDRAYAAN</strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="1176">
					<figure>
				<a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/" rel="bookmark">
					<img width="800" height="600" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/01/3cc0f-water-ice-moon-map-m3.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/how-nasa-and-chandrayaan-discovered-water-on-the-moon/" rel="bookmark">How NASA and Chandrayaan discovered water on the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3900">
					<figure>
				<a href="https://jatan.space/interviewing-isro-chandrayaan-1-mission-director/" rel="bookmark">
					<img width="800" height="600" src="https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?w=1024&amp;ssl=1 1024w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=800%2C600&amp;ssl=1 800w, https://i0.wp.com/jatan.space/wp-content/uploads/2020/08/ch-1-mission-director-interview.jpg?resize=400%2C300&amp;ssl=1 400w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/interviewing-isro-chandrayaan-1-mission-director/" rel="bookmark">Interviewing Chandrayaan 1â€™s Mission Director on Indiaâ€™s role in the new Moon race</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				






<p><strong>LUNAR SCIENCE</strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="4045">
					<figure>
				<a href="https://jatan.space/exploring-moon-mountains/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/09/tycho-mountain-lro.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/exploring-moon-mountains/" rel="bookmark">Exploring the marvel that are mountains on the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3944">
					<figure>
				<a href="https://jatan.space/radio-astronomy-from-the-moon/" rel="bookmark">
					<img width="400" height="300" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?resize=400%2C300&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/08/lunar-radio-telescope.jpg?zoom=2&amp;resize=400%2C300&amp;ssl=1 800w" sizes="(max-width: 400px) 100vw, 400px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/radio-astronomy-from-the-moon/" rel="bookmark">The Moonâ€™s potential for radio astronomy and Changâ€™e 4</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="2425">
					<figure>
				<a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/" rel="bookmark">
					<img width="400" height="300" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/01/5459c-ch-2-orbiter.png?resize=400%2C300&amp;ssl=1" alt="" loading="lazy">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/chandrayaan-2-is-creating-the-highest-resolution-map-of-the-moon/" rel="bookmark">ISROâ€™s Chandrayaan 2 orbiter is creating the highest resolution map of the Moon</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				


<div>
<div><p><a href="http://lunarexploration.esa.int/library">ESAâ€™S LIBRARY OF MOON SCIENCE</a></p></div>
</div>







<p><strong>STORIES OF MOON EXPLORATION</strong></p>


				<div>
			<div data-posts="">
								
	<article data-post-id="3371">
					<figure>
				<a href="https://jatan.space/the-moons-lumpy-gravity-field/" rel="bookmark">
					<img width="1200" height="900" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=1200%2C900&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?w=1440&amp;ssl=1 1440w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=1200%2C900&amp;ssl=1 1200w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/grail-gravity-map.jpg?resize=400%2C300&amp;ssl=1 400w" sizes="(max-width: 1200px) 100vw, 1200px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/the-moons-lumpy-gravity-field/" rel="bookmark">How we got to know the Moonâ€™s gravity is lumpy</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="2160">
					<figure>
				<a href="https://jatan.space/its-craters-all-the-way-down/" rel="bookmark">
					<img width="800" height="600" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=800%2C600&amp;ssl=1 800w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=400%2C300&amp;ssl=1 400w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/01/ranger-7-8-9-craft.jpg?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/its-craters-all-the-way-down/" rel="bookmark">The first time NASA figured out the Moon has craters all the way down</a></h2>								</div><!-- .entry-wrapper -->
	</article>

		
	<article data-post-id="3771">
					<figure>
				<a href="https://jatan.space/3d-moon-by-nasa-lro/" rel="bookmark">
					<img width="800" height="600" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=800%2C600&amp;ssl=1" alt="" loading="lazy" srcset="https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=800%2C600&amp;ssl=1 800w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=400%2C300&amp;ssl=1 400w, https://i2.wp.com/jatan.space/wp-content/uploads/2020/07/moon-lro-wac-100m-high-sun.png?resize=200%2C150&amp;ssl=1 200w" sizes="(max-width: 800px) 100vw, 800px">				</a>

							</figure><!-- .featured-image -->
		
		<div>
			<h2><a href="https://jatan.space/3d-moon-by-nasa-lro/" rel="bookmark">How NASA LRO captures the Moon in 3D</a></h2>								</div><!-- .entry-wrapper -->
	</article>

					</div>
			
		</div>
				






<p><strong>EXPLORE AWAY!</strong></p>



<div>
<div>
<div id="block-4d121109-b58f-4c67-ae47-2c05bfa34745"><figure><a href="https://moontoday.jatan.space/"><img loading="lazy" src="https://i2.wp.com/jatan.space/wp-content/uploads/2020/06/moon-monday-logo.png?resize=160%2C160&amp;ssl=1" alt="This image has an empty alt attribute; its file name is moon-monday-logo.png" width="160" height="160" data-recalc-dims="1"></a><figcaption>Browse craters, mountains, lava channels and more at <a rel="noreferrer noopener" href="https://moontoday.jatan.space/" target="_blank">Moon Today ğŸŒ”</a></figcaption></figure></div>
</div>



<div>
<div><figure><a href="http://quickmap.lroc.asu.edu/"><img loading="lazy" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/quickmap-lro.jpg?resize=150%2C150&amp;ssl=1" alt="" width="150" height="150" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/quickmap-lro.jpg?w=385&amp;ssl=1 385w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/quickmap-lro.jpg?resize=200%2C200&amp;ssl=1 200w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1"></a><figcaption>Explore the Moon like Google maps with <a href="http://quickmap.lroc.asu.edu/">LRO QuickMap</a></figcaption></figure></div>
</div>



<div>
<div><figure><a href="https://www.virtualmicroscope.org/collections/apollo"><img loading="lazy" src="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?resize=150%2C150&amp;ssl=1" alt="" width="150" height="150" srcset="https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?w=468&amp;ssl=1 468w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?resize=200%2C200&amp;ssl=1 200w, https://i1.wp.com/jatan.space/wp-content/uploads/2020/09/apollo.png?resize=400%2C400&amp;ssl=1 400w" sizes="(max-width: 150px) 100vw, 150px" data-recalc-dims="1"></a><figcaption><a href="https://www.virtualmicroscope.org/collections/apollo">See Moon rocks</a> brought  back by Apollo missions in a virtual microscope.</figcaption></figure></div>
</div>
</div>



<p><strong>Like my work?<br></strong>I donâ€™t display ads, <a href="https://jatan.space/support">support me</a> and get exclusive benefits in return.&nbsp;ğŸš€</p>
<!-- Required values for loading comments via ajax -->
<div id="llc_comments">
	<div>
		
		<!-- Show comments button if "On Click" option is set -->
					<!-- Filter to modify loading button text and button class -->
			</div>
</div></div>		</div>
			</div>
</div>
</main><!--/.neve-main-->




</div></div>]]>
            </description>
            <link>https://jatan.space/the-moon/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837248</guid>
            <pubDate>Tue, 20 Oct 2020 13:50:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Differential Dataflow]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24837031">thread link</a>) | @timhigins
<br/>
October 20, 2020 | https://timelydataflow.github.io/differential-dataflow/introduction.html | <a href="https://web.archive.org/web/*/https://timelydataflow.github.io/differential-dataflow/introduction.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
        <!-- Provide site root to javascript -->
        

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        

        <!-- Set the theme before any content is loaded, prevents flash -->
        

        <!-- Hide / unhide sidebar before it is displayed -->
        

        <nav id="sidebar" aria-label="Table of contents">
            
            
        </nav>

        <div id="page-wrapper">

            <div class="page">
                
                
                

                
                
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                

                <div id="content">
                    <main>
                        
<p>In this book we will work through the motivation and technical details behind <a href="https://github.com/frankmcsherry/differential-dataflow">differential dataflow</a>, a computational framework build on top of <a href="https://github.com/frankmcsherry/timely-dataflow">timely dataflow</a> intended for efficiently performing computations on large amounts of data and <em>maintaining</em> the computations as the data change.</p>
<p>Differential dataflow programs look like many standard "big data" computations, borrowing idioms from frameworks like MapReduce and SQL. However, once you write and run your program, you can <em>change</em> the data inputs to the computation, and differential dataflow will promptly show you the corresponding changes in its output. Promptly meaning in as little as milliseconds.</p>
<p>This relatively simple set-up, write programs and then change inputs, leads to a surprising breadth of exciting and new classes of scalable computation. We will explore it in this document!</p>
<hr>
<p>Differential dataflow arose from <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2013/11/naiad_sosp2013.pdf">work at Microsoft Research</a>, where we aimed to build a high-level framework that could both compute and incrementally maintain non-trivial algorithms.</p>

                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        
                            <a rel="next" href="https://timelydataflow.github.io/differential-dataflow/chapter_0/chapter_0.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>
                        

                        
                    </nav>
                </div>
            </div>

            <nav aria-label="Page navigation">
                

                
                    <a rel="next" href="https://timelydataflow.github.io/differential-dataflow/chapter_0/chapter_0.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
                
            </nav>

        </div>

        

        

        

        
        
        

        

        
        
        
        
        

        
        
        

        <!-- Custom JS scripts -->
        

        

    

</div>]]>
            </description>
            <link>https://timelydataflow.github.io/differential-dataflow/introduction.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24837031</guid>
            <pubDate>Tue, 20 Oct 2020 13:31:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The surprising impact of medium-size texts on PostgreSQL performance]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24836979">thread link</a>) | @haki
<br/>
October 20, 2020 | https://hakibenita.com/sql-medium-text-performance | <a href="https://web.archive.org/web/*/https://hakibenita.com/sql-medium-text-performance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-progress-indicator="">
        <hr>
<p>Any database schema is likely to have plenty of text fields. In this article, I divide text fields into three categories:</p>
<ol>
<li>
<p><strong>Small texts</strong>: names, slugs, usernames, emails, etc. These are text fields that usually have some low size limit, maybe even using <code>varchar(n)</code> and not <code>text</code>.</p>
</li>
<li>
<p><strong>Large texts</strong>: blog post content, articles, HTML content etc. These are large pieces of free, unrestricted text that is stored in the database.</p>
</li>
<li>
<p><strong>Medium texts</strong>: descriptions, comments, product reviews, stack traces etc. These are any text field that is between the small and the large. These type of texts would normally be unrestricted, but naturally smaller than the large texts.</p>
</li>
</ol>
<p><strong>In this article I demonstrate the surprising impact of medium-size texts on query performance in PostgreSQL.</strong></p>
<figure><img alt="Sliced bread... it gets better<br><small>Photo by <a href=&quot;https://unsplash.com/photos/WHJTaLqonkU&quot;>Louise LyshÃ¸j</a></small>" src="https://hakibenita.com/images/00-sql-medium-text-performance.jpg"><figcaption>Sliced bread... it gets better<br><small>Photo by <a href="https://unsplash.com/photos/WHJTaLqonkU">Louise LyshÃ¸j</a></small></figcaption>
</figure>
<details open="">
    <summary>Table of Contents</summary>

</details>
<hr>
<h2 id="understanding-toast"><a href="#understanding-toast">Understanding TOAST</a></h2>
<p>When talking about large chunks of text, or any other field that may contain large amounts of data, we first need to understand how the database handles the data. Intuitively, you might think that the database is storing large pieces of data inline like it does smaller pieces of data, but in fact, <a href="https://www.postgresql.org/docs/current/storage-toast.html" rel="noopener">it does not</a>:</p>
<blockquote>
<p>PostgreSQL uses a fixed page size (commonly 8 kB), and does not allow tuples to span multiple pages. Therefore, it is not possible to store very large field values directly.</p>
</blockquote>
<p>As the documentation explains, PostgreSQL can't store rows (tuples) in multiple pages. So how does the database store large chunks of data?</p>
<blockquote>
<p>[...] large field values are compressed and/or broken up into multiple physical rows. [...] The technique is affectionately known as TOAST (or â€œthe best thing since sliced breadâ€).</p>
</blockquote>
<p>OK, so how is this TOAST working exactly?</p>
<blockquote>
<p>If any of the columns of a table are TOAST-able, the table will have an associated TOAST table</p>
</blockquote>
<p>So TOAST is a separate table associated with our table. It is used to store large pieces of data of TOAST-able columns (the <code>text</code> datatype for example, is TOAST-able).</p>
<p>What constitutes a large value?</p>
<blockquote>
<p>The TOAST management code is triggered only when a row value to be stored in a table is wider than TOAST_TUPLE_THRESHOLD bytes (normally 2 kB). The TOAST code will compress and/or move field values out-of-line until the row value is shorter than TOAST_TUPLE_TARGET bytes (also normally 2 kB, adjustable) or no more gains can be had</p>
</blockquote>
<p>PostgreSQL will try to compress a the large values in the row, and if the row can't fit within the limit, the values will be stored out-of-line in the TOAST table.</p>
<h3 id="finding-the-toast"><a href="#finding-the-toast">Finding the TOAST</a></h3>
<p>Now that we have <em>some</em> understanding of what TOAST is, let's see it in action. First, create a table with a text field:</p>
<div><pre><span></span><span>db=#</span> <span>CREATE</span> <span>TABLE</span> <span>toast_test</span> <span>(</span><span>id</span> <span>SERIAL</span><span>,</span> <span>value</span> <span>TEXT</span><span>);</span>
<span>CREATE TABLE</span>
</pre></div>


<p>The table contains an id column, and a value field of type <code>TEXT</code>. Notice that we did not change any of the default storage parameters.</p>
<p>The text field we added supports TOAST, or is TOAST-able, so PostgreSQL should create a TOAST table. Let's try to locate the TOAST table associated with the table <code>toast_test</code> in <a href="https://www.postgresql.org/docs/current/catalog-pg-class.html" rel="noopener"><code>pg_class</code></a>:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>relname</span><span>,</span> <span>reltoastrelid</span> <span>FROM</span> <span>pg_class</span> <span>WHERE</span> <span>relname</span> <span>=</span> <span>'toast_test'</span><span>;</span>
<span>  relname   â”‚ reltoastrelid</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span> toast_test â”‚        340488</span>

<span>db=#</span> <span>SELECT</span> <span>relname</span> <span>FROM</span> <span>pg_class</span> <span>WHERE</span> <span>oid</span> <span>=</span> <span>340488</span><span>;</span>
<span>     relname</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span> pg_toast_340484</span>
</pre></div>


<p>As promised, PostgreSQL created a TOAST table called <code>pg_toast_340484</code>.</p>
<h3 id="toast-in-action"><a href="#toast-in-action">TOAST in Action</a></h3>
<p>Let's see what the TOAST table looks like:</p>
<div><pre><span></span><span>db=#</span> <span>\d</span> <span>pg_toast.pg_toast_340484</span>
<span>TOAST table "pg_toast.pg_toast_340484"</span>
<span>   Column   â”‚  Type</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span> chunk_id   â”‚ oid</span>
<span> chunk_seq  â”‚ integer</span>
<span> chunk_data â”‚ bytea</span>
</pre></div>


<p>The TOAST table contains three columns:</p>
<ul>
<li><code>chunk_id</code>: A reference to a toasted value.</li>
<li><code>chunk_seq</code>: A sequence within the chunk.</li>
<li><code>chunk_data</code>: The actual chunk data.</li>
</ul>
<p>Similar to "regular" tables, the TOAST table also has the same restrictions on inline values. To overcome this restriction, large values are split into chunks that can fit within the limit.</p>
<p>At this point the table is empty:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id â”‚ chunk_seq â”‚ chunk_data</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span>(0 rows)</span>
</pre></div>


<p>This makes sense because we did not insert any data yet. So next, insert a small value into the table:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>'small value'</span><span>);</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id â”‚ chunk_seq â”‚ chunk_data</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span>(0 rows)</span>
</pre></div>


<p>After inserting the small value into the table, the TOAST table remained empty. This means the small value was small enough to be stored inline, and there was no need to move it out-of-line to the TOAST table.</p>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 176.3 111" height="10em"><path d="M9 47c62-3 116 2 153-2M13 47c49 0 93 0 150 2m-3-4c3 17 2 22 4 53m-2-52c-3 14-2 31 0 56m2-4c-37 1-78 7-150 5m149-4H13m0 4c-3-15 1-28-4-56m3 55c2-11-1-25 1-54" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(33 60)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(61 61)">"small value"</text><path d="M10 12l155-1v37L12 46" stroke-width="0" fill="#f2f2f2"></path><path d="M10 9c43-1 84 0 156 2M11 11c36 1 75 0 155-1m1-2l-2 38m1-36v39m1 0c-39 2-78 1-159 0m158-2c-39 2-77 2-155 0m-3 1c0-8 3-20 3-36m-1 37V10" stroke="currentColor" fill="none"></path><path d="M52 16l4 81m0-84c-1 19-5 36-3 88" stroke="currentColor" fill="none"></path><text y="15" font-size="16" transform="translate(23 18)">id</text><g><text x="20" y="15" font-size="16" text-anchor="middle" transform="translate(68 19)">value</text></g></svg>
<figcaption>Small text stored inline</figcaption>
</figure>

<p>Let's insert a large value and see what happens:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>'n0cfPGZOCwzbHSMRaX8 ... WVIlRkylYishNyXf'</span><span>);</span>
<span>INSERT 0 1</span>
</pre></div>


<p>I shortened the value for brevity, but that's a random string with 4096 characters. Let's see what the TOAST table stores now:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>*</span> <span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span><span>;</span>
<span> chunk_id â”‚ chunk_seq â”‚ chunk_data</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span>   995899 â”‚         0 â”‚ \x30636650475a4f43...</span>
<span>   995899 â”‚         1 â”‚ \x50714c3756303567...</span>
<span>   995899 â”‚         2 â”‚ \x6c78426358574534...</span>
<span>(3 rows)</span>
</pre></div>


<p>The large value is stored out-of-line in the TOAST table. Because the value was too large to fit inline in a single row, PostgreSQL split it into three chunks. The <code>\x3063...</code> notation is how psql displays binary data.</p>
<figure>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 435.8 254" height="20em"><path d="M9 43c58 5 116 4 154 6M14 48c34-1 70 1 148-1m2 0c-5 34-4 68-3 92m0-94c1 34 4 69 2 96m-4 0c-27-2-54-2-143-5m145 3c-47 2-96 2-147 1m-2 3c5-29 2-60 0-94m2 89c1-36-2-72-3-90" stroke="currentColor" fill="none"></path><path d="M10 95c45-2 79 3 150 0M12 96c53 0 106-3 147-3" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(33 60)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(61 61)">"small value"</text><text y="15" font-size="16" fill="currentColor" transform="translate(34 106)">2</text><path d="M108 109l4 3 3 5-2 4-5 4h-4l-4-3v-7c0-2 1-2 3-3l6-3 1 1m-4-2l3 3 3 5 1 4c0 2-1 2-2 3l-6 3-4-5c-1-2-3-4-2-5l2-4 4-4 1 3" stroke-width="0" fill="#f41d92"></path><path d="M105 110h5l2 4 2 5c0 2-3 3-4 4l-4 2c-2 0-2-1-3-2l-4-6 2-4 4-5 1 2m-1 0l6 1 3 3-1 4-1 4-6 3-3-1-3-5v-7l6-2-2-1M115 115c30 2 64 1 141 0m-141 1c34-1 70-3 142-1" stroke="currentColor" fill="none"></path><path d="M229 125c5-1 13-4 26-11m-26 11l27-10" stroke="currentColor" fill="none"></path><path d="M229 104c5 4 13 6 26 10m-26-9c6 3 14 4 27 10" stroke="currentColor" fill="none"></path><path d="M275 104h152v137l-151 3" stroke-width="0" fill="#f41d92"></path><path d="M276 99c36 2 66 5 146 7m-148-3c47-2 87-3 150 0m2 4c-5 40-4 85-2 135m2-139c-2 41-1 78 0 140m1-3c-53 5-105-2-149 0m146 4c-45 1-90 0-146-2m1-1c-4-56-3-110 0-135m-5 135c5-48 3-100 2-138" stroke="currentColor" fill="none"></path><path d="M314 107c1 30 5 66 8 136m-3-136v137" stroke="currentColor" fill="none"></path><path d="M279 153c36 6 77 8 145 2m-145 0c50-2 102-2 146-2M271 194c46 0 91 2 151 5m-148-2c29-3 59-1 146-1" stroke="currentColor" fill="none"></path><text y="15" font-size="16" fill="currentColor" transform="translate(294 165)">2</text><text y="15" font-size="16" fill="currentColor" transform="translate(295 119)">1</text><text y="15" font-size="16" fill="currentColor" transform="translate(292 207)">3</text><text y="15" font-size="16" fill="currentColor" transform="translate(329 118)">\x.....</text><text y="15" font-size="16" fill="currentColor" transform="translate(331 164)">\x.....</text><text y="15" font-size="16" fill="currentColor" transform="translate(332 206)">\x.....</text><g><path d="M12 9l153 1-1 36-153 1" stroke-width="0" fill="#f2f2f2"></path><path d="M11 12c50 0 100-4 157-2M9 11c48-3 97-3 158-1m1 0c-3 13 0 29-2 39m0-39v39m-1-1c-41-2-80 1-154-2m156 2c-62 2-122 2-158 0m2 1c1-12-2-25-3-40m1 39c1-12 2-23 1-38" stroke="currentColor" fill="none"></path></g><g><path d="M55 11c-1 39 2 67 0 130M54 16c4 36 3 74 1 120" stroke="currentColor" fill="none"></path></g><g><text y="15" font-size="16" transform="translate(23 18)">id</text></g><g><text x="20" y="15" font-size="16" text-anchor="middle" transform="translate(68 19)">value</text></g></svg>
<figcaption>Large text stored out-of-line, in the associated TOAST table</figcaption>
</figure>

<p>Finally, execute the following query to summarize the data in the TOAST table:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>
<span> chunk_id â”‚ chunks â”‚ pg_size_pretty</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span>   995899 â”‚      3 â”‚ 4096 bytes</span>
<span>(1 row)</span>
</pre></div>


<p>As we've already seen, the text is stored in three chunks.</p>
<div>
<p>size of database objects</p>
<p>There are several ways to get the <a href="https://www.postgresql.org/docs/current/functions-admin.html#FUNCTIONS-ADMIN-DBSIZE" rel="noopener">size of database objects in PostgreSQL</a>:</p>
<ul>
<li><code>pg_table_size</code>: Get the size of the table including TOAST, but excluding indexes</li>
<li><code>pg_relation_size</code>: Get the size of just the table</li>
<li><code>pg_total_relation_size</code>: Get the size of the table, including indexes and TOAST</li>
</ul>
<p>Another useful function is <code>pg_size_pretty</code>: used to display sizes in a friendly format.</p>
</div>
<h3 id="toast-compression"><a href="#toast-compression">TOAST Compression</a></h3>
<p>So far I refrained from categorizing texts by their size. The reason for that is that the size of the text itself does not matter, what matters is its size after compression.</p>
<p>To create long strings for testing, we'll implement a function to generate random strings at a given length:</p>
<div><pre><span></span><span>CREATE</span> <span>OR</span> <span>REPLACE</span> <span>FUNCTION</span> <span>generate_random_string</span><span>(</span>
  <span>length</span> <span>INTEGER</span><span>,</span>
  <span>characters</span> <span>TEXT</span> <span>default</span> <span>'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'</span>
<span>)</span> <span>RETURNS</span> <span>TEXT</span> <span>AS</span>
<span>$$</span>
<span>DECLARE</span>
  <span>result</span> <span>TEXT</span> <span>:=</span> <span>''</span><span>;</span>
<span>BEGIN</span>
  <span>IF</span> <span>length</span> <span>&lt;</span> <span>1</span> <span>then</span>
      <span>RAISE</span> <span>EXCEPTION</span> <span>'Invalid length'</span><span>;</span>
  <span>END</span> <span>IF</span><span>;</span>
  <span>FOR</span> <span>__</span> <span>IN</span> <span>1..</span><span>length</span> <span>LOOP</span>
    <span>result</span> <span>:=</span> <span>result</span> <span>||</span> <span>substr</span><span>(</span><span>characters</span><span>,</span> <span>floor</span><span>(</span><span>random</span><span>()</span> <span>*</span> <span>length</span><span>(</span><span>characters</span><span>))</span><span>::</span><span>int</span> <span>+</span> <span>1</span><span>,</span> <span>1</span><span>);</span>
  <span>end</span> <span>loop</span><span>;</span>
  <span>RETURN</span> <span>result</span><span>;</span>
<span>END</span><span>;</span>
<span>$$</span> <span>LANGUAGE</span> <span>plpgsql</span><span>;</span>
</pre></div>


<p>Generate a string made out of 10 random characters:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>generate_random_string</span><span>(</span><span>10</span><span>);</span>
<span> generate_random_string</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span> o0QsrMYRvp</span>
</pre></div>


<p>We can also provide a set of characters to generate the random string from. For example, generate a string made of 10 random digits:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>generate_random_string</span><span>(</span><span>10</span><span>,</span> <span>'1234567890'</span><span>);</span>
<span> generate_random_string</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span> 4519991669</span>
</pre></div>


<p>PostgreSQL TOAST uses the <a href="https://doxygen.postgresql.org/pg__lzcompress_8c_source.html" rel="noopener">LZ family of compression</a> techniques. Compression algorithms usually work by identifying and eliminating repetition in the value. A long string containing fewer characters should compress very well compared to a string made of many different characters when encoded into bytes.</p>
<p>To illustrate how TOAST uses compression, we'll clean out the <code>toast_test</code> table, and insert a random string made of many possible characters:</p>
<div><pre><span></span><span>db=#</span> <span>TRUNCATE</span> <span>toast_test</span><span>;</span>
<span>TRUNCATE TABLE</span>

<span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>));</span>
<span>INSERT 0 1</span>
</pre></div>


<p>We inserted a 10kb value made of random characters. Let's check the TOAST table:</p>
<div><pre><span></span><span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id â”‚ chunks â”‚ pg_size_pretty</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span>  1495960 â”‚      6 â”‚ 10 kB</span>
</pre></div>


<p>The value is stored out-of-line in the TOAST table, and we can see it is not compressed.</p>
<p>Next, insert a value with a similar length, but made out of fewer possible characters:</p>
<div><pre><span></span><span>db=#</span> <span>INSERT</span> <span>INTO</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>VALUES</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>,</span> <span>'123'</span><span>));</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id â”‚ chunks â”‚ pg_size_pretty</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span>  1495960 â”‚      6 â”‚ 10 kB</span>
<span>  1495961 â”‚      2 â”‚ 3067 bytes</span>
</pre></div>


<p>We inserted a 10K value, but this time it only contained 3 possible digits: <code>1</code>, <code>2</code> and <code>3</code>. This text is more likely to contain repeating binary patterns, and should compress better than the previous value. Looking at the TOAST, we can see PostgreSQL compressed the value to ~3kB, which is a third of the size of the uncompressed value. Not a bad compression rate!</p>
<p>Finally, insert a 10K long string made of a single digit:</p>
<div><pre><span></span><span>db=#</span> <span>insert</span> <span>into</span> <span>toast_test</span> <span>(</span><span>value</span><span>)</span> <span>values</span> <span>(</span><span>generate_random_string</span><span>(</span><span>1024</span> <span>*</span> <span>10</span><span>,</span> <span>'0'</span><span>));</span>
<span>INSERT 0 1</span>

<span>db=#</span> <span>SELECT</span> <span>chunk_id</span><span>,</span> <span>COUNT</span><span>(</span><span>*</span><span>)</span> <span>as</span> <span>chunks</span><span>,</span> <span>pg_size_pretty</span><span>(</span><span>sum</span><span>(</span><span>octet_length</span><span>(</span><span>chunk_data</span><span>)</span><span>::</span><span>bigint</span><span>))</span>
<span>FROM</span> <span>pg_toast</span><span>.</span><span>pg_toast_340484</span> <span>GROUP</span> <span>BY</span> <span>1</span> <span>ORDER</span> <span>BY</span> <span>1</span><span>;</span>

<span> chunk_id â”‚ chunks â”‚ pg_size_pretty</span>
<span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span>
<span>  1495960 â”‚      6 â”‚ 10 kB</span>
<span>  1495961 â”‚      2 â”‚ 3067 bytes</span>
</pre></div>


<p>The string was compressed so well, that the database was able to store it in-line.</p>
<h3 id="configuring-toast"><a href="#configuring-toast">Configuring TOAST</a></h3>
<p>If you are interested in configuring TOAST for a table you can do that by setting storage parameters at <code>CREATE TABLE</code> or <code>ALTER â€¦</code></p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hakibenita.com/sql-medium-text-performance">https://hakibenita.com/sql-medium-text-performance</a></em></p>]]>
            </description>
            <link>https://hakibenita.com/sql-medium-text-performance</link>
            <guid isPermaLink="false">hacker-news-small-sites-24836979</guid>
            <pubDate>Tue, 20 Oct 2020 13:25:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The biggest thing I learned launching Zapier (2014)]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24836252">thread link</a>) | @andrelaszlo
<br/>
October 20, 2020 | https://mikeknoop.com/biggest-thing-learned-launching-zapier/ | <a href="https://web.archive.org/web/*/https://mikeknoop.com/biggest-thing-learned-launching-zapier/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>

      

        
        <!--<p><img src="/static/img/upload/9f67b80a8be311e3b2c528cfe91e44cb.png" /></p>-->
        

        <p>Last updated Feb. 3, 2014 â€” read <span id="post-views">25755</span> times</p>

        <p><strong>This post is adapted from <a href="https://mikeknoop.com/iowaconf-road-to-zapier">a talk I gave</a> at <a href="http://iowaconf.com/">iowaconf</a> October 2013</strong></p>

<p>I was one of three co-founders of <a href="https://zapier.com/">Zapier</a>. If you're unfamiliar with the origin story, we got started out of a <a href="http://columbia.startupweekend.org/">Startup Weekend</a> in Columbia, Mo. in 2011.</p>

<p>The prompt for this talk was to describe â€œwhat you learned building Zapierâ€. The most obvious thing I could share is tactical advice or early anecdotes. Things like how we got our first dozen customers to pay us before we really had a product or how we almost missed our acceptance call into <a href="https://ycombinator.com/">Y Combinator</a>.</p>

<p>And to be clear, I'm still leaning <em>a ton</em> through today. Startups are very much â€œtrial-by-fireâ€ as a first-time founder.</p>

<p>But the more I thought about that talk prompt, I realized the biggest thing I learned actually began way, way earlier. It's a lesson that applies equally to launching Zapier as to endeavors which lie beyond.</p>



<p>Growing up I've was always into tech and I loved building things (I originally wanted to be an architect when I thought that's what they did).</p>

<p>I learned how to build websites after borrowing a friend's â€œLearn HTML in 24 Hoursâ€ book. My goal was to build an AOL Instant Messenger profile for myself, which conveniently, could render actual HTML.</p>

<p>Later I learned how to code â€œhardcoreâ€ by picking up assembly language. I did this so I could write TI-83+ calculator games and play them during class (much to the dismay to my teachers growing up).</p>

<p>Towards the end of high school though, it was time to pick a major. Computer Science was the obvious shoe-in. But I didn't want to do it! I feared that I would burn out and not have time/energy for side projects.</p>

<p>So I decided instead to do Mechanical Engineering instead â€“ also maybe not the best choice considering my goal outlined above but at least I wouldn't be coding 24/7 for school.</p>



<p>Facebook was just taking off during my freshman year of college. They launched their original developer platform that fall and I was instantly hooked.</p>

<p>I spent a good chunk of free time building apps. Like this one that you could use to request phone numbers from your fiends.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e5f24a618be311e3ae7628cfe91e44cb.png" alt=""></p>

<p>Or this one which was a developer toolkit, making it easy to embed Facebook-style form elements.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e45bf5828be311e3b0bb28cfe91e44cb.png" alt=""></p>

<p>Or even my last solo Facebook endeavor, a monitoring tool for the Facebook Platform, which peaked at a grand total of 1 paying user.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e35826a88be311e3982b28cfe91e44cb.png" alt=""></p>

<p>You can probably guess: my ROI wasn't too great. But I was very active in the Facebook developer community and made a name for myself. Facebook reached out and asked if I'd like to become a community moderator. I have to imagine this was because of my community participation and not because they looked at any of my app analytics. </p>

<p><img src="https://mikeknoop.com/static/img/upload/e5897b478be311e3a69228cfe91e44cb.png" alt=""></p>

<p>This moderator gig led me to write developer columns for Inside Facebook and in combination, these two things generally kept my around the platform much longer than I otherwise should have.</p>

<p>It did turn out to be useful though.</p>



<p>I was applying for summer engineering internships after my Junior year of college. I applied about two dozen engineering firms in Missouri as well as a few web development gigs.</p>

<p>Of all resume's I sent out I only heard back from one place, <a href="http://veteransunited.com/">Veterans United</a>, a VA loan lender based in Columbia Mo. I learned they wanted to build an app for military personnel to reconnect inside of Facebook.</p>

<p><img src="https://mikeknoop.com/static/img/upload/e4ebb0e88be311e3864128cfe91e44cb.png" alt=""></p>

<p>I worked on Military Basebook for about a year. It peaked around 20,000 monthly active users but ultimately wasn't sticky enough. Around this time I learned a few things:</p>

<p><em>1. Facebook apps that aren't games just don't work well</em></p>

<p>Even today the most successful apps on Facebook are games. Users on Facebook just aren't in mindset to seek out utilities.</p>

<p><em>2. I didn't want to do the traditional engineering career</em></p>

<p>Although the sentiment had been brewing for a while, that summer was a turning point where I actively decided I would focus on side projects post college instead of seeking a full time job. I was going to keep throwing stuff at the wall and see if something stuck.</p>

<p>I began my mechanical engineering masters program (which I ended up dropping out of) as part of this strategy. I was able to secure a 2-year grant which paid for school living expenses. This left me with a lot of free time for my side projects.</p>



<p>Around the middle of my junior year I discovered <a href="https://news.ycombinator.com/">Hacker News</a>. If you're unfamiliar, it is a lot like Reddit (HN actually came first) where stories and articles are upvoted to the frontpage. Usually people post about programming and startups.</p>

<p>One convention on Hacker News is called â€œShow HNâ€ which is a way for people to show off their side projects and solicit feedback.</p>

<p>One â€œShow HNâ€ caught my eye by a user called <a href="https://news.ycombinator.com/?user=phpnode">phpnode</a> (thank you phpnode!). He launched a side project called <a href="http://zpr.io/6dM7.png">Hackernewsers</a> which was a map of users who used Hacker News.</p>

<p>The idea was simple. You submit your username, real name, and location and you get access to a map where you can see others who've done the same. I checked out Columbia Mo. and I saw something interesting â€“ there was someone else in the area! It turns out that other person was this guy:</p>

<p>[Bryan Helmig]</p>

<p>I remember clicking through all the information I could find online about him. I found his <a href="http://bryanhelmig.com/">personal blog</a>, some of his <a href="http://rankiac.com/">side projects</a>, and even <a href="http://youtube.com/">his YouTube channel</a>. But the most important thing I learned was that he worked at same company I did, <a href="http://veteransunited.com/">Veterans United</a>.</p>

<p>That was enough of a connection for me so I got in touch over Facebook. We met up several times that year for beers and wanted to work on something together.</p>



<p>Mizzou, the university I attended in Columbia, sent out a weekly email with things happening on campus and in the area. I usually auto-archived these. I must have been pretty bored the day I <a href="http://google.com/">opened this one</a>, but I'm glad I did. I found an enticing headline â€œStartup Weekend is Coming to Columbiaâ€.</p>

<p>I had never heard of Startup Weekend but I knew I liked building things, I knew I liked startups, so maybe this is something I wanted to be a part of. I then discovered tickets cost $50 and was a bit turned off.</p>

<p>Maybe if I could find someone else going, it would be worth the money. So I messaged Bryan and he said he was going! I bought tickets later that night, and that's how I wound up at Columbia Missouri's first ever Startup Weekend.</p>

<p>At Startup Weekend I formally met <a href="http://wadefoster.net/">Wade Foster</a> who also happened to work at Veterans United. We got together and worked on the project that Bryan originally pitched as â€œAPI Mixerâ€. The idea was simple: make a tool that enables anyone (marketers, sales, HR, developers) to connect together two web services they use.</p>

<p>In true startup fashion we took to the back garage and got to work. The <a href="https://zapier.com/blog">story of Zapier</a> is still being written today.</p>



<p>When I look back on the decisions that lead me to Startup Weekend I am amazed how many times the proverbial train of life could have been derailed.</p>

<p>What if I hadn't opened that email? What if I never got into Facebook development? What if I hadn't worked at Veterans United?</p>

<p>In reminds me a lot of the game Plinko on The Price is Right. The one where the contestant drops the puck down a pegged board and it randomly makes it's way down to one of the buckets at the bottom with the winning bucket in the middle.</p>

<p><img src="https://mikeknoop.com/static/img/upload/9ed525578be311e39e8a28cfe91e44cb.png" alt="Plinko"></p>

<p>The funny thing about plinko is, if you run sufficiently many trials, the middle bucket is actually the easiest to hit! The outcome follows a normal distribution.</p>

<p><img src="https://mikeknoop.com/static/img/upload/9dfcebde8be311e3ae7b28cfe91e44cb.png" alt="Plink Distrobution"></p>

<p>The take away here is if you go through life making random decisions, statistically, you'll wind up in the middle. While in Plinko the middle is the best, in reality, the really exciting stuff happens at the edges of the board. That's where Zapier happened. And to get there you've got to purposely push yourself towards the outsides.</p>

<p>Although I didn't realize it at the time, there was a guiding principle for all my decisions. I was always putting myself out there, in uncomfortable, new situations that challenged my own status quo.</p>

<p>That's the road to the outside of the Plinko board. And that's the biggest thing I learned by creating Zapier.</p>


        

          <p>If you'd like to see more posts like this one, <a href="https://twitter.com/intent/user?screen_name=mikeknoop">follow me on Twitter</a>!</p>

        

        

            <!-- removed disqus commenting -->

        

      

    </div>

    

    </div></div>]]>
            </description>
            <link>https://mikeknoop.com/biggest-thing-learned-launching-zapier/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24836252</guid>
            <pubDate>Tue, 20 Oct 2020 11:47:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raymarching with Fennel and LÃ–VE]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24835766">thread link</a>) | @forgotpwd16
<br/>
October 20, 2020 | https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/ | <a href="https://web.archive.org/web/*/https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>Previously Iâ€™ve decided to implement a rather basic <a href="https://andreyorst.gitlab.io/posts/2020-06-04-simple-ray-casting-with-clojurescript/">raycasting engine in ClojureScript</a>.
It was a lot of fun, an interesting experience, and ClojureScript was awesome.
Iâ€™ve implemented small <a href="https://andreyorst.gitlab.io/posts/2020-06-04-simple-ray-casting-with-clojurescript/#labyrinth-game">labyrinth game</a>, and thought about adding more features to the engine, such as camera shake, and wall height change.
But when Iâ€™ve started working on these, I quickly understood, that Iâ€™d like to move on to something more interesting, like real 3D rendering engine, that also uses rays.</p>
<p>Obviously, my first though was about writing a ray-tracer<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.
This technique is wide known, and gained a lot of traction recently.
With native hardware support for ray tracing, a lot of games are using it, and there are a lot of tutorials teaching how to implement one<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>.
In short, we cast a bunch of rays in 3D space, and calculate their trajectories, looking for what ray will hit and bounce off.
Different materials have different bounce properties, and by tracing rays from camera to the source of light, we can imitate illumination.
There are also a lot of different approaches how to calculate bouncing, e.g. for global illumination, and ambient light, but Iâ€™ve felt that it is a rather complicated task, for a weekend post.
And unlike raycasting, most ray-tracers require polygonal information in order to work, where raycasting only need to know wall start and end points.</p>
<p>Iâ€™ve wanted a similar approach for 3D rendering, where we specify an object in terms of itâ€™s mathematical representation.
Like for sphere, weâ€™ll just specify coordinate of a center, and a radius, and our rays will find intersection points with it, providing us a sufficient data to draw this sphere on screen.
And recently, Iâ€™ve read about a similar technique, that uses rays for drawing on screen, but instead of casting infinite rays as in raycasting, it marches a ray in terms of steps.
And it also uses a special trick, to make this process very optimized, therefore we can use it for rendering real 3D objects.</p>
<p>Iâ€™ve decided to structure this post similarly to the one about raycasting, so this will be another long-read, often more about Fennel rather than raymarching, but at the end I promise that weâ€™ll get something that looks like this:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/end-result.png"> 
</figure>

<p>So, just as in raycasting, first we need to do is to understand how raymarching engine works <em>on paper</em>.</p>
<h2 id="raymarching-basics">Raymarching basics</h2>
<p>Raymarching can be illustrated similarly to raycaster, except it requires more steps until we could render our image.
First, we need a camera, and an object to look at:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle.svg"> 
</figure>

<p>Our first step would to cast a ray, however, unlike with raycasting, weâ€™ll cast a portion of a ray:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-short-ray.svg"> 
</figure>

<p>We then check, if the ray intersects with the sphere.
Itâ€™s not, so we do one more step:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-two-steps.svg"> 
</figure>

<p>Itâ€™s not intersecting yet, so we repeat again:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-ray-overshoot.svg"> 
</figure>

<p>Oops, ray overshoot, and is now inside the sphere.
This is not really good option for us, as we want for our rays to end directly at the objectâ€™s surface, without calculating intersection point with the object itself.
We can fix this by casting shorter ray:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/camera-and-circle-small-rays.svg"> 
</figure>

<p>However, this is very inefficient!
And besides, if weâ€™ll change the angle a bit or move the camera, we will overshoot again.
Which means that weâ€™ll either have incorrect result, or require a very small step size, which will blow up computation process.
How we can fix this?</p>
<h3 id="distance-estimation">Distance estimation</h3>
<p>The solution to this is a signed distance function, or a so called Distance Estimator.
Imagine if we knew how far we are from the object at any point of time?
This would mean that we can shoot a ray of this length in any direction and still donâ€™t hit anything.
Letâ€™s add another object to the scene:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/scene-with-two-objects.svg"> 
</figure>

<p>Now, letâ€™s draw two circles, which will represent distances from the objects, to the point from where weâ€™ll cast rays:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/distances.svg"> 
</figure>

<p>We can see, that there are two circles, and one is bigger than another.
This means, that if we choose the shortest safe distance, we can safely cast ray in any direction and not overshoot anything.
For example, letâ€™s cast a ray towards the square:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/ray-in-safe-zone.svg"> 
</figure>

<p>We can see, that we havenâ€™t reached the square, but more importantly we did not overshoot it.
Now we need to march the ray again, but what distance should it cover?
To answer this question, we need to take another distance estimation from ray end to the objects in the scene:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/second-safe-march.svg"> 
</figure>

<p>Once again we choose shorter distance, and march towards the square, then get the distance again, and repeat the whole process:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/another-safe-match.svg"> 
</figure>

<p>You can see that with each step the distance to the object becomes smaller, and thus we will never overshoot the object.
However this also means, that we will take a lot of really small steps, until we finally fully hit the object, if we ever do.
This is not a good idea, because it is even more inefficient than using fixed distance, and produces too accurate results, which we donâ€™t really need.
So instead of marching up until we exactly hit the object, we will march <em>enough</em> times.
E.g. until the distance to the object is small enough, then thereâ€™s no real point to continue marching, as it is clear that we will hit the object soon.
But this also means, that if the ray goes near the edge of an object, we do a lot of expensive steps of computing distance estimations.</p>
<p>Hereâ€™s a ray that is parallel to the side of the square, and marches towards the circle:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/expensive-marching.svg"> 
</figure>

<p>We do a lot of seemingly pointless measurements, and if a ray was closer to the squareâ€™s side, we would do even more steps.
However this also means, that we can use this data (since weâ€™re already computed it) to render such things as glow, or ambient occlusion.
But more on this later.</p>
<p>Once ray hit an object we have all the data we need.
Ray represents a point on the screen, and the more rays we cast the higher resolution of our image will be.
And since weâ€™re not using triangles to represent objects, our spheres will always be smooth, no matter how close we are to it, because thereâ€™s no polygons involved.</p>
<p>This is basically it.
Ray marching is quite simple concept, just like raycaster, although itâ€™s a bit more complicated, as we do have to compute things in 3D space now.
So letâ€™s begin implementing it by installing required tools, and setting up the project.</p>
<h2 id="project-structure">Project structure</h2>
<p>As you know from the title we will use two main tools to create ray-marcher, which are <a href="https://love2d.org/">LÃ–VE</a>, a free game engine, and <a href="https://fennel-lang.org/">Fennel</a> the programming language.
Iâ€™ve chosen Fennel, because it is a Lisp like language, that compiles to Lua, and Iâ€™m quite a fan of Lisps.
But we also needed to draw somewhere, and I know no GUI toolkit for Lua.
But there is LÃ–VE - a game engine that runs Lua code, which is capable on running on all systems, thus a perfect candidate for our task.</p>
<p>Installation steps may differ per operating system, so please refer to manuals<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup><sup>, </sup><sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>.
At the time of writing this post Iâ€™m using Fedora GNU/Linux, so for me it means:</p>
<div><pre><code data-lang="sh">$ sudo dnf install love luarocks readline-devel
$ luarocks install --local fennel
$ luarocks install --local readline <span># requires readline-devel</span>
$ <span>export</span> <span>PATH</span>=<span>"</span><span>$PATH</span><span>:</span><span>$HOME</span><span>/.luarocks/bin"</span>
</code></pre></div><p>Itâ€™s better to permanently add <code>$HOME/luarocks/bin</code> (or another path, if your installation differs) to the <code>PATH</code> variable in your shell, in order to be able to use installed utilities without specifying full path every time.
You can test if everything is installed correctly, by running <code>fennel</code> in you command line.</p>
<div><pre><code data-lang="sh">$ fennel
Welcome to Fennel 0.5.0 on Lua 5.3!
Use (doc something) to view documentation.
&gt;&gt; (+ 1 2 3)
6
&gt;&gt;
</code></pre></div><p>For other distributions installation steps may vary, and for Windows, I think itâ€™s safe to skip the <code>readline</code> part, which is fully optional, but makes editing in a REPL a bit more comfortable.</p>
<p>Once everything is installed, letâ€™s create the project directory, and the <code>main.fnl</code> file, where we will write our code.</p>
<div><pre><code data-lang="sh">$ mkdir love_raymarching
$ <span>cd</span> love_raymarching
$ touch main.fnl
</code></pre></div><p>And thatâ€™s it!
We can test if everything works by adding this code to <code>main.fnl</code>:</p>
<div><pre><code data-lang="clojure">(<span>fn </span><span>love.draw</span> []
  (<span>love.graphics.print</span> <span>"It works!"</span>))
</code></pre></div><p>Now we can compile it with <code>fennel --compile main.fnl &gt; main.lua</code>, thus producing the <code>main.lua</code> file, and run <code>love .</code> (dot is intentional, it indicates current directory).</p>
<p>A window should appear, with white text <code>It works!</code> in upper left corner:</p>
<figure>
    <img src="https://andreyorst.gitlab.io/2020-10-15-raymarching-with-lua-and-love/love-works.png"> 
</figure>

<p>Now we can begin implementing our raymarcher.</p>
<h2 id="scene-setup">Scene setup</h2>
<p>Just as in raycaster, we need a camera that will shoot rays, and some objects to look at.
Letâ€™s begin by creating a camera object, that will store coordinates and rotation information.
We can do so, by using <code>var</code> to declare a variable that is local to our file, and that we can later change with <code>set</code><sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>:</p>

<div><pre><code data-lang="clojure">(<span>var </span><span>camera</span> {<span>:pos</span> [0.0 0.0 0.0]
             <span>:x-rotate</span> 0.0
             <span>:z-rotate</span> 0.0})
</code></pre></div><blockquote>
<p>For those unfamiliar with Lisps, and especially Clojure, let me quickly explain what this syntax is.
If you know this stuff, feel free to <a href="#org6f2d291">skip this part</a>.</p>
<p>We start by using a <code>var</code> special form, that binds a value to a name like this: <code>(var name value)</code>.
So if we start the REPL, using <code>fennel</code> command in the shell, and write <code>(var a 40)</code>, a new variable <code>a</code> will be created.
We then can check, that it has the desired value by typing <code>a</code>, and pressing return:</p>
<p>We can then alter the contents of this variable by using <code>set</code> special form, which works like this <code>(set name new-value)</code>:</p>
<div><pre><code data-lang="clojure"><span>&gt;&gt;</span> (<span>set </span><span>a</span> (<span>+ </span><span>a</span> 2))
<span>&gt;&gt;</span> <span>a</span>
42
</code></pre></div><p>Now to curly and square brackets.
Everything enclosed in curly braces is a hashmap.
We can use any Lua value as our key, and the most common choice is a string, but Fennel has additional syntax for defining keys - a colon followed by a word: <code>:a</code>.
This is called a keyword, and in Fennel it is essentially the same as <code>"a"</code>, but we donâ€™t need to write a pair of quotes.
However keywords canâ€™t contain spaces, and some other symbols.</p>
<p>So writing this <code>{:a 0 :b 2 :c :hello}</code> in the REPL will make a new table, that holds three key value pairs, which we can later get with another syntax - the dot <code>.</code>.
Combining it with <code>var</code>, we can see that it works:</p>
<div><pre><code data-lang="clojure"><span>&gt;&gt;</span> (<span>var </span><span>m</span> {<span>:a</span> 1 <span>:b</span> 2 <span>:c</span> <span>:hello</span>})
<span>&gt;&gt;</span> (<span>. </span><span>m</span> <span>:b</span>)
2
</code></pre></div><p>Thereâ€™s also a shorthand for this â€¦</p></blockquote></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/">https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/</a></em></p>]]>
            </description>
            <link>https://andreyorst.gitlab.io/posts/2020-10-15-raymarching-with-fennel-and-love/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835766</guid>
            <pubDate>Tue, 20 Oct 2020 10:26:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minimalism in Programming: How Complexity Harms Your Productivity]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24835759">thread link</a>) | @zweig
<br/>
October 20, 2020 | https://blog.finxter.com/minimalism-in-programming/ | <a href="https://web.archive.org/web/*/https://blog.finxter.com/minimalism-in-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15315" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<div><figure><img loading="lazy" src="https://images.pexels.com/photos/3768126/pexels-photo-3768126.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" data-src="https://images.pexels.com/photos/3768126/pexels-photo-3768126.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" alt="Complexity" width="839" height="563" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"></figure></div>



<p><em>This article is based on a book chapter from my upcoming book <strong>â€œFrom One to Zero: A Minimalistic Approach to Programmingâ€</strong>. </em></p>



<p>My <a href="https://blog.finxter.com/subscribe/" title="Subscribe" target="_blank" rel="noreferrer noopener">programming students</a> often write in with their struggles and failures. Many students ultimately overcome their strugglesâ€”but a large percentage of them <strong><em>give up their programming ambitions</em></strong> after realizing how hard creating software can be. These students started with the goal of becoming professional coders, but, ultimately, they missed that target. </p>



<p>After thousands of personal conversations with these students, it became apparent that many new coders donâ€™t fail because they donâ€™t know one or the other Python feature or because they lack technical skills, intelligence, or even talent. </p>



<p>These are not the underlying reasons <strong><em>why </em></strong>they fail. </p>



<p>Instead, they fail because they are<strong> overwhelmed by the complexity lurking everywhere in programming</strong>. The complexity causes them to throw in the towel. This is unfortunate because there are many ways to mitigate the harmful effects of complexity in programming. In the previous chapter, youâ€™ve already learned some strategies about the <a href="https://blog.finxter.com/the-80-20-principle-in-programming/" target="_blank" rel="noreferrer noopener" title="The 80/20 Principle in Programming"><strong>80/20 principle</strong></a> (Focus on the vital few and sacrifice the trivial many!).</p>



<p>In this chapter, weâ€™re going to have a comprehensive look at this important and highly underexplored topic. <strong>What exactly is complexity?</strong> Where does it occur? How does it look like?</p>



<p>Letâ€™s start with a quick overviewâ€”thereâ€™s significant complexity in selecting the right</p>



<ul><li>programming language among dozens of popular languages,</li><li>coding project to work onâ€”from thousands of open-source projects and myriads of problems,</li><li>libraries within a language (<a href="https://blog.finxter.com/why-does-the-scikit-learn-library-use-a-trailing-underscore-convention-for-attribute-names/" target="_blank" rel="noreferrer noopener" title="Why Does the Scikit-learn Library use a Trailing Underscore Convention for Attribute Names?">scikit-learn</a> vs <a href="https://blog.finxter.com/numpy-tutorial/" target="_blank" rel="noreferrer noopener" title="NumPy Tutorial â€“ Everything You Need to Know to Get Started">NumPy </a>vs <a href="https://blog.finxter.com/2-min-computer-science-papers-tensorflow/" target="_blank" rel="noreferrer noopener" title="[2-min CS Papers] A Short Introduction to the TensorFlow System">TensorFlow</a>),</li><li>emerging technologies to â€œbet onâ€â€”Alexa apps, smartphone apps, browser-based web apps, integrated Facebook or WeChat apps, virtual reality appsâ€”and</li><li><a href="https://blog.finxter.com/best-python-ide/" target="_blank" rel="noreferrer noopener" title="Best Python IDE and Code Editors [Ultimate Guide]">coding editor</a> such as PyCharm, IDLE, and Atom.</li></ul>



<p>Given the great confusion caused by these sources of complexity, itâ€™s no surprise that<strong><em> â€œHow to start?â€</em></strong> is one of the most common questions from programming beginners. </p>



<p>To answer the question right away, the best way to start is <strong><em>not </em></strong>by choosing a programming book and reading over all <a href="https://blog.finxter.com/python-crash-course/" title="Python Programming Tutorial [+Cheat Sheets]" target="_blank" rel="noreferrer noopener">syntactical features</a> of the programming language. Surprisingly, these coding books sell wellâ€”even I am a<a href="https://coffeebreakpython.com/" target="_blank" rel="noreferrer noopener" title="https://coffeebreakpython.com/"> seller of such books</a>. However, interacting with thousands of programming students personally I realized that many ambitious students buy programming books as a commitment device to put the learning task on their ToDo listsâ€”if theyâ€™ve spent money on the book, they better read it or the investment will be lost. But as so many other tasks on their ToDo lists, reading a programming book is seldomly one to be completed. </p>



<p><strong>Many students buy these programming tutorial books but very few actually read them.</strong></p>



<p>So, what is the <strong><em>best way to start to learn to program</em></strong>? In my opinion, the best way to start is to choose a practical code projectâ€”a simple one if youâ€™re a beginnerâ€”and push it to completion. </p>



<ul><li>Donâ€™t read coding books before you do this. </li><li>Donâ€™t read random tutorials on the web. </li><li>Donâ€™t scroll through endless feeds on StackOverflow. </li></ul>



<p><strong><em>Just set up the project and start coding with the limited skills you have</em></strong> and your common sense. </p>



<p>Itâ€™s okay if you donâ€™t understand what youâ€™re doing, you will gradually increase your understanding. You read books and articles only to make progress on the project in front of you. By diving into the process of finishing your first project, you need to solve a number of highly relevant problems: </p>



<ul><li><a href="https://blog.finxter.com/best-python-ide/" target="_blank" rel="noreferrer noopener" title="Best Python IDE and Code Editors [Ultimate Guide]">Which code editor should you use? </a></li><li><a href="https://blog.finxter.com/install-python-win/" target="_blank" rel="noreferrer noopener" title="How to Install Python on Windows? [7 Easy Steps]">How to install Python? </a></li><li><a href="https://blog.finxter.com/how-to-read-all-lines-of-a-file-in-a-python-one-liner/" target="_blank" rel="noreferrer noopener" title="How to Read All Lines of a File in a Python One-Liner?">How to read input from a file? </a></li><li>How to store the input in your program for later use? </li><li>How to manipulate the input to obtain the desired output?</li></ul>



<p>By answering these questions, you gradually build a well-rounded skill set of a practitioner. Over time, youâ€™ll answer these questions better and better. Your speed and skill to solve these problems will grow. Youâ€™ll be able to solve similar problems much bigger and youâ€™ll create your internal database of programming patterns and conceptual insights. Even advanced coders learn and improve with the exact same processâ€”only the coding projects have become much larger and more complicated.</p>



<p>Letâ€™s assume you adopt this <a href="https://blog.finxter.com/how-to-start-your-freelancing-business-on-the-side/" target="_blank" rel="noreferrer noopener" title="[7 Steps] How to Start Your Freelancing Business on the Side?">project-based learning approach</a>. You focus on a single project and work on it for a considerable amount of time. What is your biggest enemy now? You guessed it: <strong><em>complexity</em></strong>.</p>



<p>Youâ€™ll struggle with complexity in:</p>



<ul><li>finding bugs in ever-growing codebases,</li><li>understanding code components and how they interact,</li><li>choosing the right feature to be implemented next,</li><li>understanding the mathematical and conceptual basics of the code.</li></ul>



<p><strong>Complexity is everywhere</strong>, at every stage of a project that comes to life. And the hidden costs of this complexity are very tangible: coders who are just starting out throw in the towel and the projects never see the light of day. The beginner argues: <em>â€œcoding is too difficult for meâ€</em> and he truly believes itâ€”even though nothing can be further from the truth.</p>



<p>The root of the problem is overwhelming complexity and a lack of focus. So, the question arises: </p>



<p><strong><em>How to solve complexity and a lack of focus?</em></strong></p>



<div><figure><img loading="lazy" src="https://images.pexels.com/photos/509922/pexels-photo-509922.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" data-src="https://images.pexels.com/photos/509922/pexels-photo-509922.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" alt="Minimalism" width="844" height="563" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"></figure></div>



<p>The answer is straightforward, and Iâ€™ve already stressed it a few times in this book: <strong>minimalism</strong>. Seek simplicity and focus â€“ in every stage of the coding cycle. I want you to take this one concept out of the book: Take a radically minimalistic position in every area youâ€™ll encounter in the programming space. If this book can convince you to take more extreme measures to increase your focus, it has accomplished its mission!</p>



<p>Letâ€™s dive deeper into the concept of complexity to develop an understanding of one of the great enemies of your coding productivity.</p>




<h2><span id="What_is_Complexity"></span>What is Complexity?<span></span></h2>



<p>In different fields, the term complexity comes with different meanings. Sometimes, itâ€™s strictly defined, such as in computational complexity of a computer program that provides a means to analyze a given code function for varying inputs. Other times, itâ€™s loosely defined as the amount or structure of interactions between system components. But in this book, weâ€™re going to use it in a more generic way.</p>



<p>The Merriam Webster dictionary defines complexity as <em>â€œsomething complexâ€</em>. The term complex is defined as <em>â€œa whole made up of complicated [â€¦] partsâ€</em>. If you resolve the term complicatedâ€”<em>â€œdifficult to analyze, understand, or explainâ€</em>â€”you end up with the following rough definition:</p>



<p><strong>Complexity</strong>: <em>â€œa whole, made up of parts, that is difficult to analyze, understand, or explainâ€</em>.</p>



<p>This is how we use the term complexity in this book. Complexity describes a whole system or entity. It is difficult to explain or describe. Because of its difficulty, complexity causes struggle and confusion. When confronted with complexity, people find themselves cognitively unable to comprehend the deeper meaning, implications, or effects of â€œthe wholeâ€.</p>



<div><figure><img loading="lazy" src="https://images.pexels.com/photos/4183195/pexels-photo-4183195.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" data-src="https://images.pexels.com/photos/4183195/pexels-photo-4183195.jpeg?auto=compress&amp;cs=tinysrgb&amp;h=750&amp;w=1260" alt="Complexity" width="450" height="563" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif"></figure></div>



<p>They cannot see the big pictureâ€”complexity is the enemy of clarity, closure, and predictability, because a complex system behaves in highly unpredictable ways. Where do you find complexity? Youâ€™ll find it everywhere, because real-world systems are messy: A highly interrelated web of causes and effects that obfuscates the behavior of a real system, and that is impossible to decode for individuals who are themselves caught in this complex web. Like a differential equation, the output of one system feeds into another systemâ€™s input which, in turn, feeds back into the first system as an input. Examples of highly complex systems are the stock market, social trends, emerging political viewpoints, and big computer programs with hundreds of thousands of lines of codeâ€”such as the Windows operating system.</p>



<p>If you are a coder, you are especially prone to overwhelming complexity. Letâ€™s dive into different sources of complexity in the field of programming:</p>



<ul><li>Complexity in a Project Lifecycle</li><li>Complexity in Software and Algorithmic Theory</li><li>Complexity in Learning</li><li>Complexity in Processes</li><li>Complexity in Social Networks</li><li>Complexity in Your Daily Life</li><li>Complexity in a Project Lifecycle</li></ul>



<p>The best way to learn and create lasting value is through your participation or initiation of a real-world project. But how does it look like when a real-world project comes to life? Letâ€™s dive into the different stages of the project lifecycle: Planning, Defining, Designing, Building, Testing, and Deployment (see Figure 1).</p>



<p><em><strong>Figure 1</strong>: A software project comes to life â€“ the project lifecycle consists of six conceptual phases: Planning, Defining, Designing, Building, Testing, Deployment.</em></p>



<div><figure><img loading="lazy" width="604" height="340" src="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png" data-src="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png" alt="" data-srcset="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png 604w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-300x169.png 300w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-150x84.png 150w" data-sizes="(max-width: 604px) 100vw, 604px" data-old-src="//blog.finxter.com/wp-content/plugins/a3-lazy-load/assets/images/lazy_placeholder.gif" srcset="https://blog.finxter.com/wp-content/uploads/2020/10/image-182.png 604w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-300x169.png 300w, https://blog.finxter.com/wp-content/uploads/2020/10/image-182-150x84.png 150w"></figure></div>



<p>Figure 1 shows the software development life cycle consisting of six phases. Even if youâ€™re working on a very small software project, youâ€™re likely going through all six phases of the software development lifecycle. Next, youâ€™ll quickly dive into all six phasesâ€”and how complexity has a significant impact on every one of them.</p>



<h3><span id="Planning"></span>Planning<span></span></h3>



<p>The first stage of the software development life cycle is the planning phase. From software engineering literature, you may know this as <strong><em>requirement analysis</em></strong>. The purpose of this phase is to determine how the end product will look like. A successful planning phase leads to a strictly defined set of required features to deliver to the customer or the end user.</p>



<p>The planning phase solves a multi-dimensional problem where different departments and functions must collaborate to determine the optimal set of features of the software. A number of factors must be taken into consideration: the costs of building a feature, the risk of not being able to successfully implement the feature, the expected value for the end user, marketing and sales implications, maintainability, scalability, legal restrictions and many more.</p>



<p>This phase is crucial because it can save you from massive wastages of downstream energy in the following phases. Business owners know that <strong><em>capital allocation</em></strong> (or â€¦</p></div></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.finxter.com/minimalism-in-programming/">https://blog.finxter.com/minimalism-in-programming/</a></em></p>]]>
            </description>
            <link>https://blog.finxter.com/minimalism-in-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835759</guid>
            <pubDate>Tue, 20 Oct 2020 10:25:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assorted Thoughts on Zig and Rust]]>
            </title>
            <description>
<![CDATA[
Score 325 | Comments 278 (<a href="https://news.ycombinator.com/item?id=24835357">thread link</a>) | @ikskuh
<br/>
October 20, 2020 | https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I've been using <a href="https://ziglang.org/">zig</a> for ~4 months worth of side projects, including a <a href="https://git.sr.ht/%7Ejamii/focus/tree">toy text editor</a> and an <a href="https://git.sr.ht/%7Ejamii/imp">interpreter for a relational language</a>. I've written ~10kloc.</p>
<p>That's not nearly enough time to form a coherent informed opinion. So instead here is an incoherent assortment of thoughts and experiences, in no particular order :)</p>
<p>This is not meant to be an introduction to zig - check out the excellent <a href="https://ziglang.org/documentation/master/">language docs</a> or the new <a href="https://ziglearn.org/">ziglearn.org</a> instead. I'll try to focus instead on things that are not immediately obvious from reading intro material.</p>
<p>The obvious point of comparison is to rust. For context, I've been using rust <a href="https://scattered-thoughts.net/writing/three-months-of-rust/">since 2015</a>. Mostly in research positions writing throwaway code, but also ~14 months working on <a href="https://materialize.io/">a commercial database</a> which is ~100kloc.</p>
<hr>
<p>Zig is dramatically simpler than rust. It took a few days before I felt proficient vs a month or more for rust.</p>
<p>Most of this difference is <strong>not</strong> related to lifetimes. Rust has patterns, traits, dyn, modules, declarative macros, procedural macros, derive, associated types, annotations, cfg, cargo features, turbofish, autoderefencing, deref coercion etc. I encountered most of these in the first week. Just understanding how they all work is a significant time investment, let alone learning when to use each and how they affect the available design space.</p>
<p>I still haven't internalized the full rule-set of rust enough to be able predict whether a design in my head will successfully compile. I don't remember the order in which methods are resolved during autoderefencing, or how module visibility works, or how the type system determines if one impl might <a href="https://github.com/Ixrec/rust-orphan-rules#what-are-the-orphan-rules">overlap another or be an orphan</a>. There are frequent moments where I know what I want the machine to do but struggle to encode it into traits and lifetimes.</p>
<p>Zig manages to provide many of the same features with a single mechanism - compile-time execution of regular zig code. This comes will all kinds of pros and cons, but one large and important pro is that I already know how to write regular code so it's easy for me to just write down the thing that I want to happen.</p>
<hr>
<p>One of the key differences between zig and rust is that when writing a generic function, rust will prove that the function is type-safe for every possible value of the generic parameters. Zig will prove that the function is type-safe only for each parameter that you actually call the function with.</p>
<p>On the one hand, this allows zig to make use of arbitrary compile-time logic where rust has to restrict itself to structured systems (traits etc) about which it can form general proofs. This in turn allows zig a great deal of expressive power and also massively simplifies the language.</p>
<p>On the other hand, we can't type-check zig libraries which contain generics. We can only type-check specific uses of those libraries.</p>
<pre><span>// This function is typesafe if there exist no odd perfect numbers
// https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers
fn foo(comptime n: comptime_int, i: usize) usize {
  const j = if (comptime is_odd_perfect_number(n)) "surprise!" else 1;
  return i + j;
}
</span></pre>
<p>This means zig also doesn't get the automatic, machine-checked documentation of type constraints that rust benefits from and may face more challenges providing IDE support.</p>
<p>This might harm the zig ecosystem by making it harder to compose various libraries. But <a href="https://julialang.org/">julia</a> has a similar model and in practice it has worked very well (<a href="https://youtu.be/dmWQtI3DFFo?t=1710">eg</a>, <a href="https://www.oxinabox.net/2020/02/09/whycompositionaljulia.html">eg</a>).</p>
<hr>
<p>Zig's comptime allows expressing <a href="https://scattered-thoughts.net/writing/open-multiple-dispatch-in-zig/">open multiple dispatch</a> as a library.</p>
<p>It should be relatively trivial to implement specialization the same way, which has been a <a href="https://github.com/rust-lang/rust/issues/31844">work in progress</a> in rust for years and is critical to many optimizations in julia's math libraries.</p>
<p>Julia chose dynamic typing because it's very difficult to encode the types of various mathematical operations into a general schema (eg fortress <a href="https://youtu.be/EZD3Scuv02g?t=3011">struggled with this</a>). Zig's approach of not requiring general schemas but still type-checking individual cases may be an interesting sweet spot.</p>
<hr>
<p>I used the <a href="https://cwe.mitre.org/data/definitions/1350.html">2020 CWE Top 25 Most Dangerous Software Weaknesses</a> to get a sense of the relative frequency of different causes of memory unsafety.</p>
<p>(I'm assuming that the zig programmer is using release-safe mode instead of the unfortunately named release-fast mode which disables all runtime safety checks.)</p>
<ul>
<li>Out-of-bounds Write (787/1350)</li>
<li>Out-of-bounds Read (125/1350)</li>
<li>Improper Restriction of Operations within the Bounds of a Memory Buffer (119/1350)</li>
</ul>
<p>Both languages primarily use bounds-checked slices and relegate pointer arithmetic to a separate type (<code>*T</code> in rust, <code>[*]T</code> in zig).</p>
<ul>
<li>NULL Pointer Dereference (476/1350)</li>
</ul>
<p>Both languages require explicit annotations for nulls (<code>Option&lt;T&gt;</code> in rust, <code>?T</code> in zig) and require code to either handle the null case or safely crash on null (<code>x.unwrap()</code> in rust, <code>x.?</code> in zig).</p>
<p>Dereferencing/casting a null c pointer is undefined behavior in both languages, but is checked at runtime in zig.</p>
<ul>
<li>Integer Overflow or Wraparound (190/1350)</li>
</ul>
<p>Rust catches overflow in debug and wraps in release. Zig catches overflow in debug/release-safe and leaves behavior undefined in release-fast.</p>
<p>Both languages allow explicitly asking for wraparound (<code>x.wrapping_add(1)</code> in rust, <code>x +% 1</code> in zig).</p>
<ul>
<li>Use After Free (416/1350)</li>
</ul>
<p>As long as all unsafe code obeys the aliasing and lifetime rules, rust protects completely against UAF.</p>
<p>Zig has little protection. The recently merged
<a href="https://github.com/ziglang/zig/blob/575fbd5e3592cff70cbfc5153884d919e6bed89f/lib/std/heap/general_purpose_allocator.zig">GeneralPurposeAllocator</a> avoids reusing memory regions (which prevents freed data from being overwritten) and reusing pages (which means that UAF will eventually result in a page fault). But this comes at the cost of fragmentation and lower performance and it also won't provide protection for child allocators using the GPA as a backing allocator.</p>
<hr>
<p>Both languages will insert implicit casts between primitive types and pointers whenever it is safe to do so, and require explicit casts otherwise. (With the odd exception that rust will not implicitly upcast numbers).</p>
<p>Both languages support generics which almost entirely avoids the need to cast void pointers.</p>
<hr>
<p>In rust the Send/Sync traits flag types which are safe to move/share across threads. In the absence of unsafe code it should be impossible to cause data races.</p>
<p>Zig has no comparable protection. It's possible to implement the same logic as Send/Sync in comptime zig, but without the ability to track ownership the rules would have to be much more restrictive.</p>
<hr>
<p>Rust prevents having multiple mutable references to the same memory region at the same time.</p>
<p>This means that eg iterator invalidation is prevented at compile time, because the borrow checker won't allow mutating a data-structure while an iterator is holding a reference to the data-structure. Similarly for resizing a data-structure while holding a reference to the old allocation. Both examples are easy sources of UAF in zig.</p>
<hr>
<p>Neither language is able to produce stack traces for stack overflows at the moment (<a href="https://github.com/rust-lang/rust/issues/51405">rust</a>, <a href="https://github.com/ziglang/zig/issues/1616">zig</a>)</p>
<p>In the future zig is <a href="https://github.com/ziglang/zig/issues/1006">intended</a> to statically check the maximum stack usage of your program and force recursive code to explicitly allocate space on the heap, so that stack overflows produce a recoverable OutOfMemory error rather than a crash.</p>
<p>This is not an academic problem - I've seen real-world crashes from recursive tree transformations in compilers (<a href="https://github.com/MaterializeInc/materialize/pull/3996">eg</a>) and it's often painful to write the same logic without recursion.</p>
<hr>
<p>Undefined behavior in rust is defined <a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">here</a>. It's worth noting that breaking the aliasing rules in unsafe rust can cause undefined behavior but these rules are not yet well-defined. So far this hasn't caused me any problems but it is a little unnerving.</p>
<p><a href="https://github.com/rust-lang/miri">Miri</a> is an interpreter for rusts Mid-level Intermediate Representation which will detect many (but not all) cases of undefined behavior in unsafe rust. It's far too slow to use for the whole materialize test suite but was useful for unit-testing an unsafe module.</p>
<p>Undefined behavior in zig is defined <a href="https://ziglang.org/documentation/master/#Undefined-Behavior">here</a>. This list is <a href="https://github.com/ziglang/zig/issues/1966">probably incomplete</a> given that the core language is still under development.</p>
<p>Zig <a href="https://github.com/ziglang/zig/issues/2301">aspires</a> to insert runtime checks for almost all undefined behavior when compiling in debug mode. So far all the easy cases are handled, which is already a dramatic improvement over c.</p>
<p>Zigs compile-time partial evaluation is done by an IR interpreter - it seems plausible that this could also be used as a miri-like tool in the future.</p>
<hr>
<p><code>@import</code> takes a path to a file and turns the whole file into a struct. So modules are just structs. And vice-versa - if you have a large struct declaration you can move it into a file to reduce the indentation.</p>
<p>Zig doesn't care at all where you put files on the filesystem.</p>
<p><code>@import</code> is part of the compile-time execution system so things like platform-specific modules and configurable features can be specified in regular code rather than rust's limited set of <code>#[cfg(...)]</code> macros.</p>
<hr>
<p>Array, struct, enum and union literals can be anonymous - <code>.{.Constant = 1.0}</code> is an anonymous union with it's own type, but can be implicitly cast to any union with a <code>Constant: f64</code> field because they share the same structure.</p>
<p>In rust my code is littered with <code>use Expr::*</code> and I'm careful to avoid name collisions between different enums that I might want to import in the same functions. In zig I just use anonymous literals everywhere and don't worry about it.</p>
<hr>
<p>Anonymous literals are also nice when using structs to simulate keyword arguments. No need to find and import the correct type:</p>
<pre><span>fn do_things(config: struct {
  max_things: usize = 1000, // default value
  flavor: Flavor,
}) void {
  ...
}

do_things(.{.flavor = .Strawberry});
</span></pre>
<hr>
<p>There is a pattern that shows up a lot in the materialize codebase:</p>
<pre><span>let</span><span> constant </span><span>= </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(constant) </span><span>=</span><span> expr { constant } </span><span>else </span><span>{ </span><span>panic!</span><span>() }</span><span>;
</span></pre>
<p>It's common enough that many types have methods like <code>expr.unwrap_constant()</code>.</p>
<p>In zig:</p>
<pre><span>const constant = expr.Constant;
</span></pre>
<p>A similar pattern is:</p>
<pre><span>if</span><span> some_condition {
    </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(</span><span>_</span><span>) </span><span>=</span><span> expr {
        </span><span>...
    </span><span>}
}
</span></pre>
<p>Again, many types get methods like <code>expr.is_constant()</code>.</p>
<pre><span>if</span><span> some_condition </span><span>&amp;&amp;</span><span> expr</span><span>.</span><span>is_constant</span><span>(â€¦</span></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</a></em></p>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835357</guid>
            <pubDate>Tue, 20 Oct 2020 09:22:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Design Stripe or Hacker News-like favicons in seconds]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24835219">thread link</a>) | @hosshams
<br/>
October 20, 2020 | https://formito.com/tools/favicon | <a href="https://web.archive.org/web/*/https://formito.com/tools/favicon">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Copy the following code and put it inside the<!-- --> <code>&lt;head&gt;</code> tag of your website.</p><pre><code></code></pre><p>Or, download the SVG file, add the following code to<!-- --> <code>&lt;head&gt;</code> tag of your website, and replace<!-- --> <code>href</code> attribute with URL to your SVG file.</p><pre><code>&lt;link rel="icon" type="image/svg+xml" href="favicon.svg" /&gt;</code></pre></div></div>]]>
            </description>
            <link>https://formito.com/tools/favicon</link>
            <guid isPermaLink="false">hacker-news-small-sites-24835219</guid>
            <pubDate>Tue, 20 Oct 2020 08:56:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discipline Doesnâ€™t Scale]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 104 (<a href="https://news.ycombinator.com/item?id=24834965">thread link</a>) | @ingve
<br/>
October 20, 2020 | https://www.sicpers.info/2020/10/discipline-doesnt-scale/ | <a href="https://web.archive.org/web/*/https://www.sicpers.info/2020/10/discipline-doesnt-scale/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>If programmers were just more disciplined, more <em>professional</em>, theyâ€™d write better software. All they need is a <a href="https://www.pearson.com/us/higher-education/program/Martin-Clean-Coder-The-A-Code-of-Conduct-for-Professional-Programmers/PGM8366.html">code of conduct</a> telling them how to work like those of us whoâ€™ve worked it out.</p>
<p>The above statement is true, which is a good thing for those of us interested in improving the state of software and in helping our fellow professionals to improve their craft. However, itâ€™s also very difficult and inefficient to apply, in addition to being entirely unnecessary. In the common parlance of our industry, â€œdiscipline doesnâ€™t scaleâ€.</p>
<p>Consider the trajectory of object lifecycle management in the Objective-C programming language, particularly the NeXT dialect. Between 1989 and 1995, the dominant way to deal with the lifecycle of objects was to use the <tt>+new</tt> and <tt>-free</tt> methods, which work much like <tt>malloc/free</tt> in C or <tt>new/delete</tt> in C++. Of course itâ€™s <em>possible</em> to design a complex object graph using this ownership model, it just needs discipline, thatâ€™s all. Learn the heuristics that the experts use, and the techniques to ensure correctness, and get it correct.</p>
<p>But you know whatâ€™s better? Not having to get that right. So around 1994 people introduced new tools to do it an easier way: reference counting. With NeXTSTEP Mach Kitâ€™s <tt>NXReference</tt> protocol and OpenStepâ€™s <tt>NSObject</tt>, developers no longer need to know when <em>everybody</em> in an app is done with an object to destroy it. They can indicate when a reference is taken and when itâ€™s relinquished, and the object itself will see when itâ€™s no longer used and free itself. Learn the heuristics and techniques around auto releasing and unretained references, and get it correct.</p>
<p>But you know whatâ€™s better? Not having to get that right. So a couple of other tools were introduced, so close together that they were probably developed in parallel[*]: Objective-C 2.0 garbage collection (2006) and Automatic Reference Counting (2008). ARC â€œwonâ€ in popular adoption so letâ€™s focus there: developers no longer need to know exactly when to retain, release, or autorelease objects. Instead of describing the edges of the relationships, they describe the <em>meanings</em> of the relationships and the compiler will automatically take care of ownership tracking. Learn the heuristics and techniques around weak references and the â€œweak selfâ€ dance, and get it correct.</p>
<p>[*] Iâ€™m ignoring here the significantly earlier integration of the Boehm conservative GC with Objective-C, because so did everybody else. That in itself is an important part of the technology adoption story.</p>
<p>But you know whatâ€™s better? You get the idea. You see similar things happen in other contexts: for example C++â€™s move from <tt>new/delete</tt> to smart pointers follows a similar trajectory over a similar time. The reliance on an entire programming community getting some difficult rules right, when faced with the alternative of using different technology <em>on the same computer</em> that follows the rules for you, is a tough sell.</p>
<p>It seems so simple: computers exist to automate repetitive information-processing tasks. Requiring programmers who have access to computers to recall and follow repetitive information processes is wasteful, when the computer can do that. So give those tasks to the computers.</p>
<p>And yet, for some people the problem with software isnâ€™t a lack of automation but a lack of discipline. Software would be better if only people knew the rules, honoured them, and slowed themselves down so that instead of cutting corners they just chose to ignore important business milestones instead. Back in my day, everybody knew â€œno Markdown around townâ€ and â€œdonâ€™t code in an IDE after Labour Dayâ€, but now the kids do whatever they want. The motivations seem different, and Iâ€™d like to sort them out.</p>
<p>Letâ€™s start with hazing. A lot of the software industry suffers from â€œI had to go through this, you should tooâ€. Look at software engineering interviews, for example. Iâ€™m not sure whether anybody actually believes â€œI had to deal with carefully ensuring NUL-termination to avoid buffer overrun errors so you should tooâ€, but I do occasionally still hear people telling less-experienced developers that they should learn C to learn more about how their computer works. <a href="https://queue.acm.org/detail.cfm?id=3212479">Your computer is not a fast PDP-11</a>, all you will learn is how the C virtual machine works.</p>
<p>Just as Real Men Donâ€™t Eat Quiche, so <a href="https://www.codeproject.com/articles/927/real-programmers-don-t-use-pascal">real programmers donâ€™t use Pascal</a>. Real Programmers use FORTRAN. This motivation for sorting discipline from rabble is based on the idea that if it isnâ€™t at least as hard as it was when <em>I</em> did this, it isnâ€™t hard enough. And that means that the goalposts are movable, based on the oratorâ€™s experience.</p>
<p>This is often related to the <em>term</em> of their experience: you donâ€™t need TypeScript to write good React Native code, just Javascript and some discipline. You donâ€™t need React Native to write good front-end code, just JQuery and some discipline. You donâ€™t need JQueryâ€¦</p>
<p>But along with the term of experience goes the breadth. You see, the person who learned reference counting in 1995 and thinks that you can only <em>really</em> understand programming if you manually type out your own reference-changing events, presumably didnâ€™t go on to use garbage collection in Java in 1996. The person who thinks you can only <em>really</em> write correct software if every case is accompanied by a unit test presumably didnâ€™t learn Eiffel. The person who thinks that you can only <em>really</em> design systems if you use the Haskell type system may not have tried OCaml. And so on.</p>
<p>The conclusion is that for this variety of disciplinarian, the appropriate character and quantity of discipline is whatever they had to deal with at some specific point in their career. Probably a high point: after theyâ€™d got over the tricky bits and got productive, and after you kids came along and ruined everything.</p>
<p>Sometimes the reason for suggesting the disciplined approach is entomological in nature, as in the case of the eusocial insect the â€œperformantâ€ which, while not a real word, exists in greater quantities in older software than in newer software, apparently. The performant is capable of making software faster, or use less memory, or more concurrent, or less dependent on I/O: the specific characteristics of the performant depend heavily on context.</p>
<p>The performant is often not talked about in the same sentences as its usual companion species, the irrelevant. Yes, there may be opportunities to shave a few percent off the runtime of that algorithm by switching from the automatic tool to the manual, disciplined approach, but does that matter (yet, or at all)? There are software-construction domains where specific performance characteristics are desirable, indeed thatâ€™s true across a lot of software. But itâ€™s typical to focus performance-enhancing techniques on the bits where they enhance performance that needs enhancing, not to adopt them across the whole system on the basis that it was better when everyone worked this way. You might save a few hundred cycles writing native software instead of using a VM for that UI method, but if itâ€™s going to run after a network request completes over EDGE then trigger a 1/3s animation, nobody will notice the improvement.</p>
<p>Anyway, whatever the source, the problem with calls for discipline is that thereâ€™s no strong motivation to <em>become</em> more disciplined. I can use these tools, and my customer is this much satisfied, and my employer pays me this much. Or I can learn from you how Iâ€™m <em>supposed</em> to be doing it, which will slow me down, forâ€¦your satisfaction? So you know Iâ€™m doing it the way itâ€™s supposed to be done? Or so that I can tell everyone else that theyâ€™re doing it wrong, too? Sounds like a great deal.</p>
<p>Therefore discipline doesnâ€™t scale. Whenever you ask some people to slow down and think harder about what theyâ€™re doing, some fraction of them will. Some will wonder whether thereâ€™s some other way to get what youâ€™re peddling, and may find it. Some more will not pay any attention. The dangerous ones are the ones who thought they <em>were</em> paying attention and yet still end up not doing the disciplined thing you asked for: they either torpedo your whole idea or turn it into not doing the thing (see OOP, Agile, Functional Programming). And still more people, by far the vast majority, just werenâ€™t listening at all, and youâ€™ll never reach them.</p>
<p>Letâ€™s flip this around. Letâ€™s look at where we <em>need</em> to be disciplined, and ask if there are gaps in the tool support for software engineers. Some people want us to always write a failing test and make it pass before adding any code (or want us to write a passing test and revert our changes if it accidentally fails): does that mean our tools should not let us write code for which thereâ€™s no test? Does the same apply for acceptance tests? Some want us to refactor mercilessly; does that mean our design tools should always propose more parsimonious alternatives for passing the same tests? Some say we should get into the discipline of writing code that always reveals its intent: should the tools make a crack at interpreting the intention of the code-as-prose?</p>
	</div></div>]]>
            </description>
            <link>https://www.sicpers.info/2020/10/discipline-doesnt-scale/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834965</guid>
            <pubDate>Tue, 20 Oct 2020 08:11:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose the Browser Carefully]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24834960">thread link</a>) | @URfejk
<br/>
October 20, 2020 | https://unixsheikh.com/articles/choose-your-browser-carefully.html | <a href="https://web.archive.org/web/*/https://unixsheikh.com/articles/choose-your-browser-carefully.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>


<p>Published on <span id="published">2020-10-20</span>. Updated on <span id="modified">2020-10-23</span></p>

<p><a href="https://en.wikipedia.org/wiki/Internet_privacy">Privacy on the Internet</a> is important because privacy risks range from the gathering of statistics on users to more malicious acts such as the spreading of spyware and the exploitation of various forms of bugs (software faults). Many companies, such as Google, track which websites people visit and then use the information, for instance by sending advertising based on one's web browsing history. Sometimes prices on products are changed on the same website, depending on tracking information, and two people may view the exact same product on the exact same website yet be presented with very different prices.</p>

<h3>Table of contents</h3>
<ul>
<li><a href="#privacy-compromising">Introduction</a></li>
<li><a href="#third-party-clones">Third party clones</a></li>
<li><a href="#privacy-compromising">Privacy compromising browsers</a></li>
<ul>
<li><a href="#firefox">Mozilla Firefox</a></li>
<li><a href="#chrome">Google Chrome and Chromium</a></li>
<li><a href="#brave">Brave</a></li>
<li><a href="#palemoon">Palemoon</a></li>
<li><a href="#waterfox">Waterfox</a></li>
<li><a href="#librewolf">Librewolf</a></li>
<li><a href="#epiphany">GNOME Web (Epiphany) and Eolie</a></li>
<li><a href="#midori">Midori</a></li>
<li><a href="#other-problematic-browsers">Other problematic browsers</a></li>
</ul>

<li><a href="#alternatives">Privacy respecting browsers</a></li>
<ul>
<li><a href="#falkon">Falkon</a></li>
<li><a href="#icecat">GNU IceCat</a></li>
<li><a href="#ungoogled-chromium">ungoogled-chromium</a></li>
<li><a href="#tor">Tor browser</a></li>
<li><a href="#tweaking-firefox">Tweaking Firefox - the best solution</a>
<ul>
<li><a href="#firefox-configuration-guide">The 12bytes.org Firefox Configuration Guide</a></li>
<li><a href="#control">Controlling Firefox's DNS over HTTPS</a></li>
<li><a href="#blocking">Blocking DoH via a firewall</a></li>
</ul>
</li><li><a href="#other-okay-browsers">Other okay browsers</a></li>
</ul>

<li><a href="#conclusions">Conclusions</a></li>
</ul>

<h2 id="introduction">Introduction</h2>

<p>This article isn't specifically about privacy issues only, it's about promises that are being broken, which might be about privacy. It is also about the lack of user freedom, as in the choice to enable or disable features, such as automatic updates, or forced usage of third party services, or software that the user generally is unaware of or don't have a say about.</p>

<p>Privacy as a subject regarding the usage of services on the Internet is a very difficult subject to deal with. Not only can it be difficult to actually define privacy, but it also requires a balance between freedom of choice by the users, security and usability. Naturally you need to be able to use the browser on the Internet and as such you will always leave some kind of trail behind, and this article is not about how you can hide your tracks. What I am addressing in this article are browsers that are either promoted as "privacy respecting" by the developers, or in general are considered to be so (mostly due to misunderstanding or misinformation), while it is very clear they are not.</p>

<p>Some browsers either directly violate users by collecting telemetric data without consent, or you have to opt-out rather than opt-in, or they bounce around the Internet visiting places in the background without you knowing (using dns-prefetch or automatic updates etc.), using third party services that operates with a privacy policy you either cannot trust, or that are directly violating your privacy, or they have integrated third party software that do some of these things.</p>

<p>I will try to keep this article updated with relevant information as much as possible. I know several other browsers exist, but if they are not mentioned on this list I have either not had a change to investigate them, they are closed source and completely irrelevant (such as Microsoft Edge or Opera), or they are not actively maintained, or they are perhaps a "one mans show" which cannot be trusted for some reason or another.</p>

<p>I will also <strong>not</strong> be looking at browsers that only work on Microsoft Windows or macOS, even if they are Open Source. Both Microsoft Windows and macOS are highly controversial and completely untrustworthy operating systems.</p>

<p>Also please note that just because the developers of a browser are promising that their browser is privacy respecting doesn't mean that you can trust the information. As you will see with the examples of some of the browsers below even developers some times compromise user privacy perhaps without even thinking about it.</p>

<p>I also want to make a strong advice to people recommending browsers to other people without investigation or knowledge. The <a href="https://old.reddit.com/r/privacy/">privacy related channel on Reddit</a> is filled with wrong recommendations regarding privacy respecting browsers and many people are merely guessing or blindly trusting the information the browser producers are publishing. Neither Mozilla Firefox, Google Chrome or Chromium, Brave, Waterfox, or several of the other recommended browsers truly respect privacy. They all do some form of telemetry and/or privacy compromising actions without the user consenting to it or even knowing about it.</p>

<p>Also, privacy doesn't mean that you simply pull out telemetry from Firefox, rebrand it, and then ship it. Privacy is more than that. Unless the browser is automatically checking for an updated version, and the website isn't logging that request, it cannot be considered truly private if the browser starts bouncing around on the Internet visiting all kinds of places without the user has done anything more than open the browser up! Every time the browser makes a DNS request, that DNS request is in most cases logged unless the user actively does something to mitigate that - such as using a trusted VPN or non-logging DNS service etc. Furthermore, the Mozilla add-on CDN is logging user activity, as is <a href="https://en.wikipedia.org/wiki/Amazon_CloudFront">Amazon Cloudfront</a>, so if the browser visits these places without the user explicitly pushes a "check for updates" option, the browser is compromising user privacy. The point I'm trying to make is that the user needs to have the choice and that nothing happens until the user actively do something.</p>

<p>Last, but not least, if you discover any mistakes on my part, feel free to email me about it so that I can correct the information.</p>

<h2 id="third-party-clones">Third party clones</h2>
<p>Several third party clones of Firefox and Chromium exist that are branded and promoted as secure and privacy respecting alternatives that cannot fully be trusted for some reason or another. The code base for both Firefox and Chromium are huge and many skillful people work on the code every day. Having a "one mans show" or a small team of developers diverted browser clone running on your computer that are days, weeks or even months behind security updates does not improve neither your privacy nor your security in any way.</p>

<h2 id="privacy-compromising">Privacy compromising browsers</h2>

<h3 id="firefox">Mozilla Firefox</h3>
<p>In the past I have always supported Mozilla and promoted <a href="https://en.wikipedia.org/wiki/Firefox">Firefox</a>, but Mozilla has made some pretty controversial decisions as of late and I no longer feel that Mozilla is an organization that deserves any support.</p>
<p>Firefox is promoted by Mozilla as a privacy respecting browser, but this is highly misleading. Firefox "phones home" every time you start it up even when you have disabled telemetry and automatic updates of extensions. Domains such as mozilla.org, cloudfront.net, firefox.settings.services.mozilla.com (see: <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12">https://bugzilla.mozilla.org/show_bug.cgi?id=1598562#c12</a>), autopush.prod.mozaws.net, detectportal.firefox.com and location.services.mozilla.com are visited each time you start Firefox.</p>
<p>In 2017 Mozilla made a <a href="https://en.wikipedia.org/wiki/Cliqz#Integration_with_Firefox">deal with Cliqz</a> where approximately 1% of users downloading Firefox in Germany would receive a version with Cliqz software included. And in 2018 Mozilla revealed that they had no data on the number of Firefox installations with disabled Telemetry.</p>
<blockquote>
<p>Finally, we need better insight into our opt-out rates for telemetry. We use telemetry to ensure new features improve your user experience and to guide Mozilla's business decisions. However, an unknown portion of our users do not report telemetry for a variety of reasons. This means we may not have data that is representative of our entire population.</p>
</blockquote>
<p>Mozilla then developed the <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1487578">Telemetry Coverage</a> system and distributed it to 1% of the Firefox installations. The system is automatically installed and designed to inform Mozilla whether telemetry is enabled in the browser.</p>
<p>Mozilla also <a href="https://support.mozilla.org/en-US/kb/telemetry-collection-windows-default-browser-trend">developed a Windows-only scheduled task</a> which runs in the background once a day for each installation of Firefox installed on a computer running Microsoft Windows. The task collects information related to the system's current and previous default browser setting and the operating system locale and version.</p>
<p>This is a list of some of the things that Mozilla collects: <a href="https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content">https://www.mozilla.org/en-US/privacy/firefox/#suggest-relevant-content</a>.</p>
<p>On the <a href="https://www.mozilla.org/en-US/about/">Mozilla website</a> we can read (when I originally started writing this article) that <q>We put people over profit</q>, and <q>a product to support user privacy</q>. We can also read in the <a href="https://www.mozilla.org/en-US/about/manifesto/">Mozilla manifesto</a>, in the fourth principle, that <q>Individuals' security and privacy on the internet are fundamental and must not be treated as optional.</q> However, with their decision to make Cloudflare the default DNS provider for DNS over HTTPS, they are definitely not supporting user privacy or putting people over profit!</p>
<p>DNS over HTTPS is by itself <a href="https://www.youtube.com/watch?v=ZxTdEEuyxHU">bad enough</a>, and <a href="https://en.wikipedia.org/wiki/DNS_over_HTTPS#Criticism">highly criticized</a> with good reason, but combining it with a US based company like Cloudflare makes it even worse.</p>
<p>Cloudflare has made an <a href="https://developers.cloudflare.com/1.1.1.1/commitment-to-privacy/privacy-policy/firefox/">agreement</a> with Mozilla that when it acts as a DNS resolver for Firefox, that:</p>
<ul>
<li>DNS requests will be stored as part of Cloudflare's "temporary" logs which are permanently deleted within 24 hours.</li>
<li>Cloudflare will also collect and store the following information as part of its permanent logs:
<ul>
<li>Total number of requests processed by each Cloudflare co-location facility.</li>
<li>Aggregate list of all domain names requested.</li>
<li>Samples of domain names queried along with the times of such queries.</li>
</ul>
</li>
<li>Information stored in Cloudflare's permanent logs will be anonymized and may be held indefinitely by Cloudflare for its own internal research and development purposes.</li>
</ul>
<p>Anyone who has worked with DNS servers knows what goes into such logs and in order for Cloudflare to keep their promise they need to: Delete the DNS requests information, but at the same time somehow still keep "anonymized" logs of the total number of requests, a list of all domain names requested, a so-called "sample" of complete DNS queries along with date and time.</p>
<p>This means that even if Cloudflare could be trusted and they have the best of intentions, they will still log everything the first 24 hours. If Cloudflare is ever compromised all these logs could be copied and distributed over a period of time.</p>
<p>Furthermore, the actual wording of the â€¦</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://unixsheikh.com/articles/choose-your-browser-carefully.html">https://unixsheikh.com/articles/choose-your-browser-carefully.html</a></em></p>]]>
            </description>
            <link>https://unixsheikh.com/articles/choose-your-browser-carefully.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834960</guid>
            <pubDate>Tue, 20 Oct 2020 08:10:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Long Road to HTTP/3]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24834767">thread link</a>) | @todsacerdoti
<br/>
October 20, 2020 | https://scorpil.com/post/the-long-road-to-http3/ | <a href="https://web.archive.org/web/*/https://scorpil.com/post/the-long-road-to-http3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="container"><div><article itemscope="" itemtype="http://schema.org/BlogPosting"><div itemprop="articleBody"><p>While HTTP/3 specification is still in the draft stage, the latest version of the Chrome browser already <a href="https://blog.chromium.org/2020/10/chrome-is-deploying-http3-and-ietf-quic.html" target="_blank" rel="nofollow">supports it by default</a>
. With Chrome holding around 70% of browser market share, you could say HTTP/3 has gone mainstream.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/quic-logo.png" alt="QUIC logo"></p><p>The new revision of this foundational protocol aims to make the web more efficient, secure, and shorten the content-delivery latencies. In some ways, itâ€™s a braver take of HTTP2: similar goals addressed by replacing the underlying TCP protocol with a new, purpose-built protocol QUIC. The best way to explain the benefits of QUIC is to illustrate where TCP falls short as a transport for HTTP requests. And to do that, weâ€™ll start at the very beginning.</p><h3 id="http-the-original">HTTP. The Original.</h3><p>When Sir Tim Berners-Lee formalized the design of a simple <a href="https://www.w3.org/Protocols/HTTP/AsImplemented.html" target="_blank" rel="nofollow">one-line hyper-text-exchange protocol</a>
in 1991, TCP was already an old, reliable protocol. The original definition document of what later became known as HTTP 0.9 specifically mentions TCP as a preferred, albeit not exclusive, transport protocol:</p><blockquote><p>Note: HTTP currently runs over TCP, but could run over any connection-oriented service.</p></blockquote><p>Of course, this proof-of-concept version of HTTP had very few similarities to HTTP we now know and love today. There were no headers and no status codes. The typical request was as simple as <code>GET /path</code>. The response contained only HTML and ended with the closing of the TCP connection.
Since browsers were not yet a thing, user was supposed to read HTML directly. It was possible to link to other resources, but none of the tags present in this early version of HTML requested additional resources asynchronously. A single HTTP request delivered a complete, self-sufficient page.</p><h3 id="emergence-of-http10">Emergence of HTTP/1.0</h3><p>In subsequent years the internet has exploded, and HTTP evolved to be an extendable and flexible general-purpose protocol, although transporting HTML remained its chief specialty. There are three critical updates to HTTP that enabled this evolution:</p><ul><li>introduction of methods allowed the client to identify the type of action it wants to perform. For example, POST was created to allow client sending data to the server to process and store</li><li>status codes provided a way for client to confirm that the server has processed the request successfully, and if not - to understand what kind of error has occured</li><li>headers added an ability to attach structured textual metadata to requests and responses that could modify the behavior of the client or server. Encoding and content-type headers, for example, allowed HTTP to transfer not just HTML, but any type of payload. â€œCompressionâ€ header allowed the client and server to negotiate supported compression formats, thus reducing the amount of data to transfer over the connection</li></ul><p>At the same time, HTML advanced to support images, styles, and other linked resources. Browsers were now forced to perfrom multiple requests to display a single web page, which the original connection-per-request architecture was not designed to handle. Establishing and ending a TCP connection involves a lot of back-and-forth packet exchange, so it is relatively expensive in terms of latency overhead. It didnâ€™t matter much when a web-page consisted of a single text file, but as the number of requests per page increased, so did the latency.</p><p>The picture below illustrates how much overhead was involved in establishing a new TCP connection per request.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-tcp-overhead.png" alt="TCP connection requires three requests to establish connection and four to close it cleanly"></p><p>A â€œconnectionâ€ header was created to address this problem. Client sends a request with â€œconnection: keep-aliveâ€ header to signal intent to keep the TCP connection open for subsequent requests. If server understands this header and agrees to respect it, its response will also contain the â€œconnection: keep-aliveâ€ header. This way, both parties maintain TCP channel open and use it for subsequent communication until either party decides to close it. This became even more important with the spread of SSL/TLS encryption, because negotianting an encryption algorithm and exchanging cryptographic keys requires an additional request/response cycle on each connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http1-keepalive.png" alt="A single TCP connection can be reused for multiple requests with â€œconnection: keep-aliveâ€ header"></p><p>At the time, many of the HTTP improvements appeared spontaneously. When a popular browser or a server app saw a need for a new HTTP feature, they would simply implement it themselves and hoped that other parties would follow the suit. Ironically, a decentralized web needed a centralized governing body to avoid fragmentation into incompatible pieces. Tim Berners-Lee, the original creator of the protocol, recognized the danger and founded the World Wide Web Consortium (W3C) in 1994, which together with the Internet Engineering Task Force (IETF) worked on formalizing stack of internet technologies. As the initial step to bring more structure to the existing environment, they documented the most common features used in HTTP at the time and named the resulting protocol HTTP/1.0. However, because this â€œspecificationâ€ described varied, often inconsistent techniques as seen â€œin the wildâ€, it never received a status of a standard. Instead, the work on the new version of the HTTP protocol has begun.</p><h3 id="standardization-of-http11">Standardization of HTTP/1.1</h3><p>HTTP/1.1 fixed inconsistencies of HTTP/1.0 and adjusted the protocol to be more performant in the new web ecosystem. Two of the most critical changes introduced were the use of persistent TCP connections (keep-aliveâ€™s) by default and HTTP pipelining.</p><p>HTTP pipelining simply means that client does not need to wait for the server to respond to a request before sending subsequent HTTP requests. This feature resulted in even more efficient use of bandwidth and reduced latencies, but it could be improved even more. HTTP pipelining still requires from server to respond in the order of requests received, so if a single request in a pipeline is slow to fulfill, all subsequent responses to a client will be delayed accordingly. This problem is known as head-of-the-line blocking.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http11-blocking.png" alt="Since large-picture.jpg was requested first, itâ€™s blocking the delivery of the style.css"></p><p>At this point in time, the web is gaining more and more interactive capabilities. Web 2.0 is just around the corner, some webpages include dozens or even hundreds of external resources. To work around the head-of-the-line blocking, and to decrease page loading speeds, clients establish multiple TCP connections per host. Of course, the connection overhead never went anywhere. In reality, it got worse, since more and more applications encrypt HTTP traffic with SSL/TLS. So most browsers set the limit of maximal possible simultaneous connections in an attempt to strike a delicate balance.</p><p>Many of the larger web-services have recognized that existing limitations are too restricting for their exceptionally heavy interactive web-applications, so they â€œgamed the systemâ€ by distributing their app through multiple domain names. It all worked, somehow, but the solution has been far from elegant.</p><p>Despite a few shortcomings, the simplicity of HTTP/1.0 and HTTP/1.1 has made them widely successful, and for over a decade no one has made a serious attempt to change them.</p><h3 id="spdy-and-http2">SPDY and HTTP/2</h3><p>In 2008 Google released the Chrome browser, which rapidly gained popularity for being quick and innovative. It has given Google a strong vote on matters of internet technologies. In the early 2010s, Google adds support for its web protocol SPDY to Chrome.</p><p>HTTP/2 standard was based on SPDY with some improvements. HTTP/2 solved the head-of-the-line blocking problem by multiplexing the HTTP requests over a single open TCP connection. This allowed server to answer requests in any order, client could then re-assemble the responses as it received them, making the whole exchange faster within a single connection.</p><p><img src="https://scorpil.com/img/the-long-road-to-http3/http2-multiplexing.png" alt="style.css was returned before the large-picture.jpg, becuase of HTTP/2 multiplexing"></p><p>In fact, with HTTP/2 server can serve the resources to a client before it even asked for it! To give an example, if the server knows that client will most likely need a stylesheet to display an HTML page, it can â€œpushâ€ the CSS to the client without waiting for a corresponding request. While beneficial in theory, this feature rarely seen in practice, since it requires a server to understand the structure of the HTML it serves, which is rarely the case.</p><p>HTTP/2 also allows compressing request headers in addition to the request body, which further reduces the amount of data transferred over the wire.</p><p>HTTP/2 solved a lot of problems for the web, but not all of them. A similar type of head-of-the-line problem is still present on the level of TCP protocol, which remains a foundational building block of the web. When a TCP packet gets lost in transit, the receiver canâ€™t acknowledge incoming packages until the lost package is re-sent by a server. Since TCP is by design oblivious to higher-level protocols like HTTP, a single lost packet will block the stream for all in-flight HTTP requests until the missing data is re-sent. This problem is especially prominent on an unreliable connection, which is not rare in the age of ubiquitous mobile devices.</p><h3 id="http3-revolution">HTTP/3 revolution</h3><p>Since issues with HTTP/2 can not be resolved purely on the application layer a new iteration of the protocol must update the transport layer. However, creating a new transport-layer protocol is not an easy task. Transport protocols need to be supported by hardware vendors and deployed by the majority of network operators, which are reluctant to update because of the costs and efforts involved. Take IPv6 as an example: it was introduced 24 years ago and is still far from being universally supported.</p><p>Fortunately, there is another option. UDP protocol is as widely supported as TCP but is simple enough to serve as a building block for custom protocols running on top of it. UDP packets are fire-and-forget: there are no handshakes, persistent connections, or error-correction. The primary idea behind HTTP3 is to abandon TCP in favor of a UDP-based QUIC protocol. QUIC adds the necessary features (those that were previously provided by TCP, and more) in a way that makes sense for the web environment.</p><p>Unlike HTTP2, which technically allowed an unencrypted communication, QUIC strictly requires encryption to establish a connection. Additionally, encryption is applied to all data â€¦</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scorpil.com/post/the-long-road-to-http3/">https://scorpil.com/post/the-long-road-to-http3/</a></em></p>]]>
            </description>
            <link>https://scorpil.com/post/the-long-road-to-http3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834767</guid>
            <pubDate>Tue, 20 Oct 2020 07:37:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adolphe Sax, Inventor of the Saxophone]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24834716">thread link</a>) | @bobf
<br/>
October 20, 2020 | http://www.dinant.be/en/inheritance/adolphe-sax | <a href="https://web.archive.org/web/*/http://www.dinant.be/en/inheritance/adolphe-sax">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<tbody>
<tr>
<td>


<h2><span>Adolphe Sax, a Dinantais of genius</span></h2>
<blockquote>
<p>Along with Joachim Patenier (1485-1524), the creator of landscape painting; with Antoine Wiertz (1806-1865), the lyrical painter; with a plethora of sculptors, painters, musicians, brassworkers and others, Dinant can legitimately pride itself on having been the birthplace on 6 November 1814 of Antoine-Joseph, or Adolphe, Sax, a prolific and inspired inventor in the manufacture of musical instruments.</p>
<p>In 1860, the diarist, Oscar Comettant, wrote, "In the services that he has rendered to musical art, in the battles he has had to go through to bring his discoveries to the light of day and defend them from despoilment and in the rewards he has been the object of from all the industrial nations, [Sax's life] rises to the heights of a social event. Novelists will draw from this strange life mysterious and moving episodes (we would add: the legal world will find in the account of the "Sax trial" a vast domain for a case law study) and the moralists will find in it the features of self-denial, physical courage and perseverance, of which only a lifted soul and a great heart are capable.</p>
</blockquote>
<a name="Enfance"></a>
<h2><span>An Agitated Childhood</span></h2>

<blockquote>
<p>Antoine-Joseph Sax was born in the street that has borne his name since 1896, in a modest house, which was destroyed in 1914, and which was built on the present site of an important commercial building.</p>
<p>In its faÃ§ade, there is a stained-glass window and an inscription chiselled into the stonework: "Adolphe Sax, 1814-1894, was born here". This window was solemnly inaugurated on 27 June 1954, on the initiative of the Tourist Information Centre, under the mayorship of Mr LÃ©on Sasserath. It is the work of Mr Jean Jadin, who designed the cartoon, and Miss Maggy ArzÃ©e. Both were taught by Miss Yvonne GÃ©rard and Mr Perot, teachers of graphic art and decoration at the Fine Arts Academy in Namur, which was then directed by Mr Lambeau. It was created under the direction of Mr Van de Capelle.</p>
<p>Son of Charles-Joseph Sax (1791-1865) and Marie-Joseph Masson (1813-1861), Antoine-Joseph was the eldest of eleven children (six boys and five girls, only four of whom survived, the others dying between the ages of 20 and 25).</p>
<p>His childhood was tragic. Hardly able to stand, Antoine-Joseph fell from a height of three floors, seriously bumping his head against a stone: he was believed dead. At the age of three, he swallowed a bowl of vitriolized water, and then a pin. Later, he was seriously burned in a gunpowder explosion; he fell onto a cast iron frying pan and burned himself on one side. Three times he escaped poisoning and asphyxiation in his bedroom, where varnished items were lying about during the night. Another time, he was hit on the head by a cobblestone; he fell into a river and was saved by the skin of his teeth.</p>
<p>"<em>He's a child condemned to misfortune; he won't live," his mother said. In the district, they called him "little Sax, the ghost</em>".</p>
<p>These initial serious incidents were, alas, but the prelude to an eventful existence such as only a few have known. In 1858, Adolphe Sax was miraculously saved from a cancer of the lip by a black doctor who knew the properties of certain Indian plants. What would the future have been but for this intervention?</p>
</blockquote>
<a name="Charles-Joseph"></a>
<h2><span>Charles-Joseph Sax</span></h2>

<blockquote>
<p>A joiner-cabinetmaker, Charles-Joseph Sax quickly launched himself, with success, into the manufacture of musical instruments. In the "New Street" he ran a large workshop. In this trade, he acquired such a reputation that, in 1815 (his eldest son was only one year old), he also set up a workshop in Brussels (where Antoine-Joseph's brothers and sisters were to be born), where he was summoned by William I of Orange (we were then under Dutch occupation). The latter appointed him as maker to the Court and entrusted him with the task of supplying suitable instruments to Belgium regimental music corps.</p>
<p>A self-taught man, therefore, Charles-Joseph Sax made woodwind and brass instruments, even violins and pianos. He registered a dozen patents and brought his instruments to perfection. He successfully participated in numerous exhibitions, where he was awarded flattering distinctions.</p>
<p>At the time when he could have spend the day playing, laughing and having fun, Antoine-Joseph observed the work in his father's workshop, besides being given instruction by one of his uncles, a teacher in Dinant. He was intelligent and his inventive mind was already showing itself, thanks to his love for music (whilst very young, he took singing and flute lessons). Thereafter, he was given lessons by his father, who quickly appreciated his abilities and did all he could to develop them.</p>
<p>Far from disregarding his son's aspirations, Charles-Joseph Sax made him his apprentice and, from a young age, he was conscious of the importance of his work, as though he were anticipating his destiny.</p>
<p>In 1853, after the death of seven of his eleven children, and following financial worries at his Brussels business, Charles-Joseph joined his son in Paris. The master was to become the servant, and was from then on in charge of making saxophones until his death in 1865.</p>
</blockquote>
<a name="Jeunesse"></a>
<h2><span>A productive childhood</span></h2>

<blockquote>
<p>Supported and assisted by his father, the youth worked. He created, he perfected instruments and he played them. He was 16 when he went to the Industrial Exposition in Brussels to present flutes and ivory clarinets. At the age of 20, he made an entirely new clarinet, with 24 keys, a work of imagination and a masterpiece of manual work. Then, a new bass clarinet, which incited enthusiasm in Habeneck, the leader of the orchestra at the Paris Opera House, who was passing through Brussels, and who called the other clarinets "barbarian instruments".</p>
<p>Even at that early stage, this creation provoked jealousy in the soloist at the "Great Royal Harmony" in Brussels, who refused to use it because, he said, it had come from "that weedy little pupil, Sax". "Play your clarinet, then" Sax answered, " and I shall play mine." The challenge accepted, Sax triumphed in front of four thousand people. He became a soloist. Works were written for him that, after his departure, were no longer played because they were so difficult!</p>
<p>The young genius pursued his work. He invented a sound reflector, a new double-bass clarinet, a piano-tuning process that remained the inventor's secret and who probably was unable to exploit it for want of money, a steam organ "capable of being heard throughout the province": now that just shows Sax's tendency to think big!</p>
<p>Sax's beginnings throw a very curious light on his character (we shall call him Adolphe from now on): energy, courage, dynamism, total self-confidence. He refused to go and set up a business in St Petersburg, rejected an offer to set up in London. That means that his reputation exceeded frontiers. Sax was conscious of all his possibilities and his talent; he conceived the work that he felt the call to achieve; he was full of hope and he believed he had every chance of success; he had great visions, he believed in what he saw. He suffocated in his little country.</p>
<p>In 1840, he presented nine inventions at the Belgian Exhibition. He was denied the first medal on the plea of his young age; there would be nothing left to offer him the year after. He was thwarted in his true-love, if not in his pride. He refused the vermeil medal he was awarded, replying with pride, "<em>If they think me too young to deserve the gold medal, I myself think me too old to accept this vermeil one</em>."</p>
</blockquote>
<a name="Paris"></a>
<h2><span>The Call to Paris</span></h2>

<blockquote>
<p>Europe's centre of attraction, Paris haunted him, Paris called him.</p>
<p>The composer HalÃ©vy wrote to him of the hope that composers had in his inventions: "<em>Hurry and finish your new family of instruments (saxophones) and come and succour to the poor composers that are looking for something new and to the public that is demanding it, if not to the world itself.</em>"</p>
<p>Let us add to this call and the snub in Brussels the fact of his family trials, and the decision was made: Adolphe Sax left for Paris "rich in ideas and light in cash": he had thirty francs in his pocket!</p>
<p>The year 1842 formed the turning point in Sax's life, possessing as he did his new invention: the saxophone and its family.</p>
<p><img src="http://www.dinant.be/uploads/pages/286/sax_atel.jpg" alt="">Moreover, in 1841, had he not presented it anonymously in Brussels, behind a curtain, so as not to disclose it and avoid the risk of plagiarism?</p>
<p>Adolphe Sax was almost thirty, "the age at which man's creative character affirms itself, at which the human personality is drawn." At the age of 27, Napoleon won his first battle in Italy; Newton was 24 and Einstein 26 when they devised their theories. Mozart died aged 35 and Schubert at 31. Examples of precocious geniuses are manifold.</p>
<p>As one former inhabitant of Dinant once rightfully said (1) "<em>a distinction has to be drawn here between a man who draws from his own abstract thoughts the stuff that his genius will knead, him for whom symbols and signs are sufficient to bring forth a thought laden with restrained life and latent splendours; and the other man for whom a technique, slow and tenacious apprenticeship on a complicated apparatus is necessary for him to be able to physically achieve the formal idea. Count, for example, how many early-developing mathematicians there are compared with child physicists. The former exist, the latter are nowhere to be found. Sax is of the category of intellectuals that concentrated on matter and not pure form"</em>.</p>
<p>In 1842, there was Adolphe Sax living in a simple shed in Rue Saint-Georges, Paris. To set up business, he had to borrow money from a musician acquaintance.</p>

</blockquote>
<a name="Berlioz"></a>
<h2><span>Thanks to Berlioz</span></h2>
<blockquote>
<div>
<p><span><strong>About the saxophone, he said "<em>Its principal merit in my view is the varied beauty of its accent, sometimes serious, sometimes calm, sometimes impassioned, dreamy or melancholic, or vague, like the weakened echo of an echo, like the indistinct plaintiff moans of the breeze in the woods and, even better, like the mysterious vibrations of a bell, long after it has been struck; there does not exist another musical instrument â€¦</em></strong></span></p></div></blockquote></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dinant.be/en/inheritance/adolphe-sax">http://www.dinant.be/en/inheritance/adolphe-sax</a></em></p>]]>
            </description>
            <link>http://www.dinant.be/en/inheritance/adolphe-sax</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834716</guid>
            <pubDate>Tue, 20 Oct 2020 07:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My chatbot is dead â€“ Why yours should probably be too]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 157 (<a href="https://news.ycombinator.com/item?id=24834552">thread link</a>) | @raphaelsaunier
<br/>
October 19, 2020 | https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/ | <a href="https://web.archive.org/web/*/https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                
<audio controls="controls"><source src="https://azumbrunnen.me/audio/chatbot-is-dead" type="audio/mpeg"></audio>



<p>Personal websites are usually like old books in a shelf. They languish, accumulate dust, and their wrinkles and cracks become more apparent over time. About 3 years ago I embarked on a simple experiment that would end up prolonging the shelf-life of my website by an unusually large margin.</p>



<p>Back in 2017, it seemed like Conversational UI was poised to take over the world. We saw Quartz turning news into a conversation, WeChat being featured as the poster-child of a post application world, iMessage turning into an unnecessarily complex mess, and chatbots popping up like mushrooms in moist forests.</p>



<p>Of course, any trend gaining so much traction and interest needs to be taken seriously. As such, I decided to familiarize myself with the topic, and turned my website into a chatbot.</p>



<p>Instead of being greeted by the internationally standardized greeting every designer used at some point in their career, there was no bold, dramatically oversized, and deep black sans-serif reading: <em>Hi, Iâ€™m a designer.</em> (To be fair, I didnâ€™t use Proxima Nova either)</p>



<p>Instead, a couple of chat bubbles exuberantly ushered onto the canvas to greet users as if we had all been long time friends.</p>



<figure><video autoplay="" loop="" muted="" src="https://azumbrunnen.me/wp-content/uploads/chatbot-animated.mp4" playsinline=""></video><figcaption>Conversational intro</figcaption></figure>



<p>It was witty, new, and slightly awkward. People would send messages that ranged from simple chit chat, to deep philosophical topics, to downright disturbing and ridiculous insults.</p>



<p>The experiment got featured on Hackernews, Medium, was used in psychological studies conducted by Dan Arielyâ€™s team, and the source code was ripped and edited by various startups to fit their needs. One business in the Bay Area had an idea to use it to sell flowers in a conversational way. It looks like they went out of business.</p>



<p>The reaction and feedback was surprising to say the least. It was an idea so simple, so silly, that the outcome was in many ways unexpected. After all, the only one who really cares about your website, is usually yourself.</p>



<p>That didnâ€™t stop me from revamping my website and kill the very thing that had turned it into a micro-celebrity before. With the death of my old chatbot, some angry emails by schools who are using it as a reference for â€œcreativeâ€ web design, and a good amount of time that has passed ever since, I wanted to take a step back and set the record straight.</p>



<hr>



<h2>When chatbots matter</h2>



<p>So letâ€™s be honest with ourselves for a moment: <em>when did you actually ever enjoy talking to a chat bot?</em> And Iâ€™m not talking about the type of bots you talk to when youâ€™re bored, but about those that provide a deeper purpose.</p>



<p>It turns out that the answer is, at least for most of us, almost never.</p>



<p>I love you Intercom, except when I donâ€™t. 99% of time I donâ€™t want to talk to a silly and obtrusive avatar popping up from some corner of the screen before I even had a chance to check out whatâ€™s going on. Somehow, I canâ€™t help but think others feel the same.</p>



<p>In fact, we do know that others feel the same. Chat heads jumping at us unasked, are the quintessential equivalent of the infamous sales clerk who eagerly talks to us upon entering a store.</p>



<p>To further add to the challenges: as soon as users go off-script, chat botâ€™s donâ€™t just become awkward and unpredictableâ€”they turn into little sociopaths that might rub users the wrong way.</p>



<figure><img loading="lazy" width="400" height="346" src="https://azumbrunnen.me/wp-content/uploads/grandma.png" alt="" srcset="https://azumbrunnen.me/wp-content/uploads/grandma.png 400w, https://azumbrunnen.me/wp-content/uploads/grandma-300x260.png 300w" sizes="(max-width: 400px) 100vw, 400px"><figcaption>UX Chat.me â€”&nbsp;Conversational UX News</figcaption></figure>



<p>The moment you create a chat bot is the moment you allow customers to have a conversation with <em>your brand</em>. Not with yourself, not with your friend, but with an uber entityâ€”a symbolâ€”that represents everything you and your team stand for. Thatâ€™s not a step to be taken lightly.</p>



<p>This simple conversational entity can be a fun tool to engage with people but depending on how the conversation goes, it can quickly turn into a misrepresentation of the values of your team and your company. So building a chat bot should never be the default choice, but an intentional one.</p>



<p>Thatâ€™s why itâ€™s worth asking yourself the following three questions before venturing into this space:</p>



<h3>1. Is your use case simple enough to be solved through chat?</h3>



<p>Conversation is incredibly complex and itâ€™s challenging enough to keep it on track in the real world. If the use case isnâ€™t simple, chances are, chat bots are not the right tool for the job.</p>



<h3>2. Is your NLP capable and sophisticated enough?</h3>



<p>There are two types of bots: pre-scripted bots with a range of default answers users can choose from, and Natural Language Processing based ones.</p>



<p>Choosing the right one is hard. While pre-scripted can feel too limiting, NLP can break at every corner. Often times, teams quickly fall into the trap of spending a huge amount of time focusing on personality and silly jokes, instead of solving the problem users hired you for in the first place.</p>



<p>Therefore, building on top of the first point above, within the conversational landscape, simple always wins.</p>



<h3>3. Are your users actually in chat based environments?</h3>



<p>Chat bots work best where users already are. If your users are primarily spending time in messaging platforms where bots and micro-apps can be seamlessly embedded, great. That can serve as an effective and natural way to engage with your audience because it matches the â€œbe where users already areâ€ principle.</p>



<p>If on the other hand, people come to your website, a medium that has made great strides to provide content in a non-linear and quick way, it often unnecessarily slows users down. </p>



<hr>



<h2>Farewell chatbot</h2>



<p>I donâ€™t want to discredit chat bots as a paradigm. They have their use in certain industries, medium, and work well for a specific set of use cases. The important part is being deliberate, rather than jumping ship blindfolded.</p>



<p>So whereas turning my website into a chat was a fun experiment, I ultimately feel like it has slowly turned into a fad. I got fooled by the trend, and as a by-product became part of the trend itself.  Fads come and go, and as they get refined and re-interpreted, they ultimately find their true purpose. What weâ€™re left with is the age old insight that itâ€™s only through experimentation, that we can unlock concepts and ideas that last.</p>



<p>Rest in peace chat bot, long live chat bots.</p>
            </article></div>]]>
            </description>
            <link>https://azumbrunnen.me/blog/my-chatbot-is-dead-%C2%B7-why-yours-should-probably-be-too/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834552</guid>
            <pubDate>Tue, 20 Oct 2020 06:52:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney Animation data sets (2018)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24834299">thread link</a>) | @ascorbic
<br/>
October 19, 2020 | https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html | <a href="https://web.archive.org/web/*/https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

            
            <span>July 03, 2018 
                 | Tags: 
                     
                        Datasets
                      
                </span>

            <section>
                <p>Today at <a href="https://cg.ivd.kit.edu/egsr18/">EGSR 2018</a>, Walt Disney Animation Studios announced the release of two large, production quality/scale data sets for rendering research purposes.
The data sets are available on a new <a href="https://disneyanimation.com/data-sets/">data sets page on the official Disney Animation website</a>.
The first data set is the Cloud Data Set, which contains a large and highly detailed volumetric cloud data set that we used for our â€œ<a href="https://blog.yiningkarlli.com/2017/07/spectral-and-decomposition-tracking.html">Spectral and Decomposition Tracking for Rendering Heterogeneous Volumes</a>â€ SIGGRAPH 2017 paper, and the second data set is the Moana Island Scene, which is a full production scene from <a href="https://blog.yiningkarlli.com/2016/11/moana.html">Moana</a>.</p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_hyperion.jpg" alt="Figure 1: The Moana Island Data Set, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/wdas_cloud_hyperion_render.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/wdas_cloud_hyperion_render.jpg" alt="Figure 2: The Cloud Data Set, rendered using Disney's Hyperion Renderer."></a></p>

<p>In this post, Iâ€™ll share some personal thoughts, observations, and notes.
The release of these data sets was announced by my teammate, Ralf Habel, at EGSR today, but this release has been in the works for a very long time now, and is the product of the collective effort of an enormous number of people across the studio.
A number of people deserve to be highlighted: Rasmus Tamstorf spearheaded the entire effort and was instrumental in getting the resources and legal approval needed for the Moana Island Scene.
Heather Pritchett is the TD that did the actual difficult work of extracting the Moana Island Scene out of Disney Animationâ€™s production pipeline and converting it from proprietary data formats into usable, industry-standard data formats.
Sean Palmer and Jonathan Garcia also helped in resurrecting the data from Moana.
Hyperion developers Ralf Habel and Peter Kutz led the effort to get the Cloud Data Set approved and released; the cloud itself was made by artists Henrik Falt and Alex Nijmeh.
On the management side of things, technology manager Rajesh Sharma and Disney Animation CTO, <a href="https://twitter.com/ncannon?lang=en">Nick Cannon</a>, provided crucial support and encouragement.
Matt Pharr has been crucial in collaborating with us to get these data sets released.
Matt was highly accommodating in helping us get the Moana Island Scene into a PBRT scene; Iâ€™ll talk a bit more about this later.
Intelâ€™s Embree team also gave significant feedback.
My role was actually quite small; along with other members of the Hyperion development team, I just provided some consultation throughout the whole process.</p>

<p>Please note the licenses that the data sets come with.
The Cloud Data Set is licensed under a <a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/6/asset/License_Cloud.pdf">Creative Commons Attribution ShareAlike 3.0 Unported License</a>; the actual cloud is based on a photograph by Kevin Udy on his <a href="https://coclouds.com/436/cumulus/%202012-07-26/">Colorado Clouds Blog</a>, which is also licensed under the same Creative Commons license.
The Moana Island Scene is licensed under a more restrictive, custom Disney Enterprises <a href="https://disney-animation.s3.amazonaws.com/uploads/production/data_set_asset/4/asset/License_Moana.pdf">research license</a>.
This is because the Moana Island Scene is a true production scene; it was actually used to produce actual frames in the final film.
As such, the data set is being released only for pure research and development purposes; itâ€™s not meant for use in artistic projects.
Please stick to and follow the licenses these data sets are released under; if people end up misusing these data sets, then it makes releasing more data sets into the community in the future much harder for us.</p>

<p>This entire effort was sparked two years ago at SIGGRAPH 2016, when Matt Pharr made an appeal to the industry to provide representative production-scale data sets to the research community.
I donâ€™t know how many times Iâ€™ve had conversations about how well new techniques or papers or technologies will scale to production cases, only to have further discussion stymied by the lack of any true production data sets that the research community can test against.
We decided as a studio to answer Mattâ€™s appeal, and last year at SIGGRAPH 2017, Brent Burley and Rasmus Tamstorf announced our intention to release both the Cloud and Moana Island data sets.
Itâ€™s taken nearly a year from announcement to release because the process has been complex, and it was very important to the studio to make sure the release was done properly.</p>

<p>One of the biggest challenges was getting all of the data out of the production pipeline and our various proprietary data formats into something that the research community can actually parse and make use of.
Matt Pharr was extremely helpful here; over the past year, Matt has added support for <a href="http://ptex.us/">Ptex</a> textures and implemented the <a href="http://blog.selfshadow.com/publications/s2015-shading-course/burley/s2015_pbs_disney_bsdf_notes.pdf">Disney Bsdf</a> in <a href="https://github.com/mmp/pbrt-v3">PBRT v3</a>.
Having Ptex and the Disney Bsdf available in PBRT v3 made PBRT v3 the natural target for an initial port to a renderer other than Hyperion, since internally all of Hyperionâ€™s shading uses the Disney Bsdf, and all of our texturing is done through Ptex.
Our texturing also relies heavily on procedural <a href="https://www.disneyanimation.com/technology/seexpr.html">SeExpr</a> expressions; all of the expression-drive texturing had to be baked down into Ptex for the final release.</p>

<p>Both the Cloud and Moana Island data sets are, quite frankly, enormous.
The Cloud data set contains a single OpenVDB cloud that weighs in at 2.93 GB; the data set also provides versions of the VDB file scaled down to half, quarter, eighth, and sixteenth scale resolutions.
The Moana Island data set comes in three parts: a base package containing raw geometry and texture data, an animation package containing animated stuff, and a PBRT package containing a PBRT scene generated from the base package.
These three packages combined, uncompressed, weigh in at well over 200 GB of disk space; the uncompressed PBRT package along weighs in at around 38 GB.</p>

<p>For the Moana Island Scene, the provided PBRT scene requires a minimum of around 90 GB if RAM to render.
This many seem enormous for consumer machines, because it is.
However, this is also what we mean by â€œproduction scaleâ€; for Disney Animation, 90 GB is actually a fairly mid-range memory footprint for a production render.
On a 24-core, dual-socket Intel Xeon Gold 6136 system, the PBRT scene took me a little over an hour and 15 minutes to render from the â€˜shotCamâ€™ camera.
Hyperion renders the scene faster, but I would caution against using this data set to do performance shootouts between different renders.
Iâ€™m certain that within a short period of time, enthusiastic members of the rendering community will end up porting this scene to Renderman and Arnold and Vray and Cycles and every other production renderer out there, which will be very cool!
But keep in mind, this data set was authored very specifically around Hyperionâ€™s various capabilities and constraints, which naturally will be very different from how one might author a complex data set for other renderers.
Every renderer works a bit differently, so the most optimal way to author a data set for every renderer will be a bit different; this data set is no exception.
So if you want to compare renderers using this data set, make sure you understand the various ways how the way this data set is structured impacts the performance of whatever renderers you are comparing.</p>

<p>For example, Hyperion subdivides/tessellates/displaces everything to as close to sub-poly-per-pixel as it can get while still fitting within computational resources.
This means our scenes are usually very heavily subdivided and tessellated.
However, the PBRT version of the scene doesnâ€™t come with any subdivision; as a result, silhouettes in the following comparison images donâ€™t fully match in some areas.
Similarly, PBRTâ€™s lights and lighting model differ from Hyperionâ€™s, and Hyperion has various artistic controls that are unique to Hyperion, meaning the renders produced by PBRT versus Hyperion differ in many ways:</p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_hyperion.jpg" alt="Figure 3a: 'shotCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/shotCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/shotCam_pbrt.jpg" alt="Figure 3b: 'shotCam' camera angle, rendered using PBRT v3."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/beachCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/beachCam_hyperion.jpg" alt="Figure 4a: 'beachCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/beachCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/beachCam_pbrt.jpg" alt="Figure 4b: 'beachCam' camera angle, rendered using PBRT v3."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/dunesACam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/dunesACam_hyperion.jpg" alt="Figure 5a: 'dunesACam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/dunesACam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/dunesACam_pbrt.jpg" alt="Figure 5b: 'dunesACam' camera angle, rendered using PBRT v3. Some of the plants are in slightly different locations than the Hyperion render; this was just a small change that happened in data conversion to the PBRT scene."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/flowersCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/flowersCam_hyperion.jpg" alt="Figure 6a: 'flowersCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/flowersCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/flowersCam_pbrt.jpg" alt="Figure 6b: 'flowersCam' camera angle, rendered using PBRT v3. Note that the silhouette of the flowers is different compared to the Hyperion render because the Hyperion render subdivides the flowers, whereas the PBRT render displays the base cage."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/grassCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/grassCam_hyperion.jpg" alt="Figure 7a: 'grassCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/grassCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/grassCam_pbrt.jpg" alt="Figure 7b: 'grassCam' camera angle, rendered using PBRT v3. The sand dune in the background looks particularly different from the Hyperion render due to subdivision and displacement."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/palmsCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/palmsCam_hyperion.jpg" alt="Figure 8a: 'palmsCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/palmsCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/palmsCam_pbrt.jpg" alt="Figure 8b: 'palmsCam' camera angle, rendered using PBRT v3. The palm leaves look especially different due to differences in artistic lighting shaping and curve shading differences. Most notably, the look in Hyperion depends heavily on attributes that vary along the length of the curve, which is something PBRT doesn't support yet. Some more work is needed here to get the palm leaves to look more similar between the two renders."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/rootsCam_hyperion.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/rootsCam_hyperion.jpg" alt="Figure 9a: 'rootsCam' camera angle, rendered using Disney's Hyperion Renderer."></a></p>

<p><a href="https://blog.yiningkarlli.com/content/images/2018/Jul/rootsCam_pbrt.png"><img src="https://blog.yiningkarlli.com/content/images/2018/Jul/preview/rootsCam_pbrt.jpg" alt="Figure 9b: 'rootsCam' camera angle, rendered using PBRT v3. Again, the significant difference in appearance in the rocks is probably just due to subdivision/tesselation/displacement."></a></p>

<p>Another example of a major difference between the Hyperion renders and the PBRT renders is in the water, which Hyperion renders using photon mapping to get the caustics.
The provided PBRT scenes use unidirectional pathtracing for everything including the water, hence the very different caustics.
Similarly, the palm trees in the â€˜palmsCamâ€™ camera angle look very different between PBRT and Hyperion because Hyperionâ€™s lighting controls are very different from PBRT; Hyperionâ€™s lights include various artistic controls for custom shaping and whatnot, which arenâ€™t necessarily fully physical.
Also, the palm leaves are modeled using curves, and the shading depends on varying colors and attributes along the length and width of the curve, which PBRT doesnâ€™t support yet (getting the palm leaves is actually the top priority for if more resources are freed up to improve the data set release).
These difference between renderers donâ€™t necessarily mean that one renderer is better than the other; they simply mean that the renderers are different.
This will be true for any pair of renderers that one wants to compare.</p>

<p>The Cloud Data Set includes an example render from Hyperion, which implements our Spectral and Decomposition Tracking paper in its volumetric rendering system to efficiently render the cloud with thousands of bounces.
This render contains no post-processing; what you see in the provided image is exactly what Hyperion outputs.
The VDB file expresses the cloud as a field of heterogeneous densities.
Also provided is an example <a href="https://www.mitsuba-renderer.org/">Mitsuba</a> scene, renderable using the <a href="https://github.com/zhoub/mitsuba-vdb">Mitsuba-VDB plugin that can be found on Github</a>.
Please consult the README file for some modifications in Mitsuba that are necessary to render the cloud.
Also, please note that the Mitsuba example will take an extremely long time to render, since Mitsuba isnâ€™t really meant to render high-albedo heterogeneous volumes.
With proper acceleration structures and algorithms, rendering the cloud only takes us a few minutes using Hyperion, and should be similarly fast in any modern production renderer.</p>

<p>One might wonder just why production data sets in general are so large.
This is an interesting question; the short answer across the industry basically boils down to â€œartist time is more expensive and valuable than computer hardwareâ€.
We could get these scenes to fit into much smaller â€¦</p></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html</a></em></p>]]>
            </description>
            <link>https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834299</guid>
            <pubDate>Tue, 20 Oct 2020 05:54:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thumbnails and Screenshots using FFmpeg]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24834226">thread link</a>) | @ponderingfish
<br/>
October 19, 2020 | https://ottverse.com/thumbnails-screenshots-using-ffmpeg/ | <a href="https://web.archive.org/web/*/https://ottverse.com/thumbnails-screenshots-using-ffmpeg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<figure>
<img src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/thumbnails-ffmpeg-featured-image.png?resize=678%2C381&amp;ssl=1" alt="thumbnails ffmpeg" title="thumbnails-ffmpeg-featured-image" data-src="https://i2.wp.com/ottverse.com/wp-content/uploads/2020/10/thumbnails-ffmpeg-featured-image.png?resize=678%2C381&amp;ssl=1" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">
</figure>


<p>There are several easy ways to take screenshots/thumbnails of movies using FFmpeg. But why do this in the first place?</p>



<ol><li>You might want to generate thumbnails for your videos and show those thumbnails to the user when he scrolls through the video. </li><li>Or, you might want to compare two videos by doing a side-by-side comparison â€“ this is quite common in video compression research. </li></ol>



<p>FFmpeg offers very simple techniques to extract screenshots or thumbnails at any position of the video (or rather, a way to dump frames at any point you choose). </p>



<p>Letâ€™s see how! </p>




<h2><span id="Single_Screenshot/Thumbnail_Using_frames_v"></span>Single Screenshot/Thumbnail Using <code>-frames:v</code><span></span></h2>



<p>First, letâ€™s understand how to take a single screenshot or thumbnail using FFmpeg. </p>



<pre><code>ffmpeg -i inputvideo.mp4 -ss 00:00:03 -frames:v 1 foobar.jpeg</code></pre>



<p>Understanding this is very simple! Here goes â€“ </p>



<ol><li><code>-ss</code> is the seek command and it can be used to seek to the right position. For accurate seeking, you need to use output seeking and not input seeking (i.e., putting <code>-ss</code> before the input sequence). The syntax for specifying the time is <code>HH:MM:SS.MILLISECONDS</code>. For example, you can tell FFmpeg to seek to&nbsp;<code>01:02:03</code>&nbsp;â€“ i.e., the 3rd second of the 2nd minute of the 1 hour of the movie!</li><li><code>-frames:v 1</code> tells FFmpeg to take only 1 screenshot. Note that, <code>-vframes</code> is deprecated. </li><li>then, you mention the name of the output file (<code>screenshot_10.jpg</code>). </li></ol>



<p>Simple, wasnâ€™t it? Now that you know how to produce a single thumbnail or screenshot, letâ€™s move to the next section where we understand how to create regular or periodic thumbnails.</p>



<h2><span id="Periodic_Screenshot/Thumbnail_with_Resizing"></span>Periodic Screenshot/Thumbnail with Resizing<span></span></h2>



<p>Here is another common use case that FFmpeg can solve easily â€“ <strong>how do you take screenshots/thumbnails at regular intervals, and store them to JPG files after resizing them?</strong></p>



<p>Here is a simple one-liner that can take care of creating a thumbnail and resizing it for you. </p>



<pre><code>ffmpeg -i input1080p.mp4 -r 1 -s 1280x720 -f image2 screenshot-%03d.jpg</code></pre>



<p>The <code>-r</code> command sets the output frame rate (=1) and <code>image2</code> is an image file muxer that is used to write video frames to image files. Using the <code>-s 1280x720</code> command, we can resize the video frames before writing them as images. Note, that the input video is a 1920x1080p video.</p>



<p>The above command will take a screenshot every 1 second. The screenshots would be named <code>001</code>, <code>002</code>, etc. because we have specified the formatting as <code>%3d</code>.</p>



<p>However, in my experience, I have found this technique<strong> to be not frame-accurate</strong>.</p>



<p>In the next section, letâ€™s look at a more accurate way of extracting thumbnails. </p>



<h2><span id="Screenshot/Thumbnail_every_10_seconds"></span>Screenshot/Thumbnail every 10 seconds<span></span></h2>



<p>As an extension of the previous section, letâ€™s do a quick exercise and learn how to create a thumbnail every 10 seconds using FFmpeg. </p>



<pre><code><code>ffmpeg -i inputvideo.mp4 -vf "select='not(mod(n,300))',setpts='N/(30*TB)'" -f image2 thumbnail%03d.jpg</code></code></pre>



<p>Here, </p>



<ol><li>we use the <code>select</code> filter to extract a frame if the expression in single-quotes evaluates to non-zero. If the expression is zero, then <code>select</code> filter discards that frame.</li><li><code>mod(A,B)</code>&nbsp;returns the modulus (remainder after division) result after dividing A by B. So, if we divide 0 by 300, we get 0. Then, 1/300 is 1, and so on. </li><li><code>not</code> inverts this result. So, if the modulus is zero, then the final result is <code>1</code>. If the modulus is non-zero, then the result is evaluated to <code>zero</code>. </li><li>Based on this <code>not</code> operation, the <code>select</code> filter picks up a frame. </li></ol>



<p>The sequence I am using has a frame-rate of <code>30 fps</code>. And, I want a frame every 10 seconds. So, I have to choose a frame out of every 300 frames, right? That is why I used <code>select='not(mod(n,300))'</code></p>







<p>Depending on your sequenceâ€™s frame-rate, you can modify the command line shown. If you donâ€™t know your videoâ€™s frame-rate, you can use <code>ffprobe</code> to find out. </p>



<pre><code>ffprobe -show_entries format=duration globe-with-timestamp.mp4</code></pre>



<h2><span id="Conclusion"></span>Conclusion<span></span></h2>



<p>There you have it â€“ multiple easy ways to generate thumbnails and screenshots using FFmpeg. You can choose to take single screenshots or periodic ones with a highly frame-accurate technique! </p>



<p>Until next time, take care and donâ€™t forget to share this article and check out the rest of the news, articles, and tutorials on OTTVerse.com</p>



<p><strong><a href="https://ottverse.com/category/ffmpeg/">Go here</a> to access all the FFmpeg tutorials on OTTVerse.com </strong></p>
		
		
		
	</div></div>]]>
            </description>
            <link>https://ottverse.com/thumbnails-screenshots-using-ffmpeg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24834226</guid>
            <pubDate>Tue, 20 Oct 2020 05:38:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Moana Motunui Renderer on GPU]]>
            </title>
            <description>
<![CDATA[
Score 325 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24833218">thread link</a>) | @Impossible
<br/>
October 19, 2020 | https://www.render-blog.com/2020/10/03/gpu-motunui/ | <a href="https://web.archive.org/web/*/https://www.render-blog.com/2020/10/03/gpu-motunui/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>03 Oct 2020</span></p><p>Disney Animationâ€™s Moana island dataset is a production-scale scene with memory requirements that make it challenging to render. This post summarizes some of those challenges, and describes how the <a href="https://github.com/chellmuth/gpu-motunui">GPU-Motunui</a> project is able to efficiently render the scene on a consumer-grade GPU with less than 8GB of memory. <a href="#renders">Click here</a> to skip ahead to the results.</p>

<h2 id="the-moana-island">The Moana island</h2>

<p>In 2018, Disney Animation released the Moana island dataset to the rendering research community. Compared to traditional research scenes, the scale of the Moana island scene is massive: the scene contains 90 million quad primitives, 5 million curves, and more than 28 million instances. All told, the island consists of over 15 billion primitives, weighing in at just under 30GB of geometry files.</p>

<p>The shots included with the dataset are beautiful, and showcase the amazing imagery that can be created by combining the best artists in the world with path tracing techniques and modern hardware. Here are two reference images, rendered with Disneyâ€™s proprietary Hyperion renderer:</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-shotCam.png" alt="Hyperion shotCam reference"></p><p>Hyperion shotCam reference</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-reference-beachCam.png" alt="Hyperion beachCam reference"></p><p>Hyperion beachCam reference</p>
</div>

<h2 id="gpu-motunui-project">GPU-Motunui Project</h2>

<p>The goal of the GPU-Motunui project is to render all the Moana shots efficiently and accurately on a consumer-grade graphics card. There are two main challenges to accomplishing this with the Moana dataset. First, with a typical graphics card having only 8GB of memory, an out-of-core rendering solution is required to handle the large amounts of geometry. Second, the sceneâ€™s textures are provided in the Ptex format, and Ptex doesnâ€™t have a publicly available CUDA implementation. This project currently only solves the first problem, and Ptex texture lookup is done on the CPU (although conveniently its cost is fully hidden by being computed concurrently with GPU shadow ray tracing).</p>

<p>The Hyperion reference images are impossible to match exactly; for example the varying brown and green colors along the palm tree fronds in the palmsCam shot are not provided in the dataset. Other features of the scene are possible to render but out of my initial scope, notably subdivision surfaces and their displacement maps, and a full Disney BSDF implementation.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/hyperion-unique-palmsCam.png" alt="Example of an unreproducible material variation on the palm tree frond"></p><p>Example of an unreproducible material variation on the palm tree frond</p>
</div>

<p>All ray tracing operations are run through Nvidiaâ€™s OptiX 7 API. This means GPU-Motunui gets the full benefits of available RT cores and a world-class BVH implementation. The following sections describe how GPU-Motunui maps dataset assets to OptiX data structures, and how GPU-Motunuiâ€™s out-of-core rendering solution works.</p>

<h3 id="scene-representation">Scene representation</h3>

<p>The Moana scene makes widespread use of multi-level instancing. In OptiX, this requires a three-level hierarchy of acceleration structures to manage: two levels of IASs, and a base level of GASs (Instance Acceleration Structures and Geometry Acceleration Structures, respectively). GPU-Motunui makes use of OptiXâ€™s AS compaction and relocation APIs to further reduce memory usage.</p>

<p>The isHibiscus element makes a good example of how a typical element in the scene is organized and built. The tree is assembled from a base model in one Wavefront .obj file (containing the trunk and branches), and four primitives: one flower and three leaf models (each with their own .obj file).</p>

<div>

<p>Left: The four simple primitives that will be instanced to fill out the hibiscus tree <br>Right: The base trunk and branches model </p>
</div>

<p>In OptiX, each of these models has an associated GAS, and each GAS can be subdivided into multiple build inputs. Build inputs are used to map sections of the model to information needed at shading time by indexing into OptiXâ€™s shader binding table. These GASs form the bottom level of the hierarchy.</p>

<p>Next, an IAS is used to build the full isHibiscus element. This IAS is in the middle level of the hierarchy. The figure below shows each primitiveâ€™s instances in isolation, and combined to make the full element:</p>

<div>

<p>Left: Isolated instances for each primitive<br>Right: Full isHibiscus element</p>
</div>

<p>Finally, a second IAS is built to track all of the elementâ€™s instances present in the scene. This second IAS is the top level of the instance hierarchy.</p>

<div>
  <p><img src="https://www.render-blog.com/assets/isHibiscus-instanced-elements.png" alt="The shotCam view rendered with only isHibiscus instances"></p><p>The shotCam view rendered with only isHibiscus instances</p>
</div>

<p>Although the isHibiscus element has a typical structure, there are some more complicated elements included in the dataset. The isCoral element, for example, has different base geometry and instanced primitives for each of its element instances, but the underlying primitive geometries are shared across all the element instances.</p>

<p>The Moana GAS and IASs alone require 18.5 GB, well past the memory budget of my 8GB RTX 2070. Because OptiX has no native support for out-of-core rendering, the traditional OptiX pipeline had to be put aside for a custom-made solution.</p>

<h3 id="out-of-core-rendering">Out-of-core rendering</h3>

<p>To solve the out-of-core rendering problem, GPU-Motunui divides the sceneâ€™s geometry into different sections, and ray traces each separately, while tracking the closest hit. Replacing a traditional device trace call with a host loop comes with many design consequences to the renderer, from asset loading to the core path tracing loop that sends rays through the scene.</p>

<p>Before rendering, the asset loading process allocates a large chunk of GPU memory (currently 6.7GB). A custom allocator is implemented that manages this block of memory. It is responsible for allocating two types of memory: output and temporary. Output memory is allocated from the left of the block, and is used for OptiX structures. Temporary memory is managed on a stack from the right end of the memory block. Managing the temporary memory this way ensures that the output structures are always tightly packed.</p>

<p>After elements are processed into their accelerator structures on the GPU, their used memory is snapshotted onto the host, and the allocator is cleared. The process is repeated until all of the sceneâ€™s geometry is processed, resulting in the host managing a list of GPU memory snapshots. The figure below shows an example layout of GPU memory that could be snapshotted:</p>

<div>
  <p>GPU memory layout after loading the isHibiscus element.<br>(Dotted arrows show that an IAS holds instances of the pointed-at AS)</p>

</div>

<p>As mentioned above, when it comes time to ray trace, each snapshot is processed in a loop. This means a call to <code>cudaMemcpy</code> and <code>optixLaunch</code> for each snapshot. A global buffer is maintained that indicates the depth of the current closest intersection. This value is used as the <code>tmax</code> parameter for the CUDA kernelâ€™s call to <code>optixTrace</code>, and a successful intersection will update the depth buffer for the next launch.</p>

<p>In a traditional OptiX path tracer, the entire render loop can run in device code inside a single call to <code>optixLaunch</code>; i.e., a successful intersection will lead to more BSDF and shadow rays being traced in the same kernel launch. Because GPU-Motunuiâ€™s design mandates multiple launches for tracing each path segment, the render loop is pulled out into host code. While this potentially diminishes OptiXâ€™s ability to efficiently schedule program execution, it also opens up opportunties for optimization, such as running Ptex texture lookups on the CPU concurrently with GPU kernels and I/O.</p>

<h3 id="shading">Shading</h3>
<p>As with any OptiX application, GPU-Motunui makes use of the shader binding table (SBT). SBT records contain pointers to normal buffers and material attributes. The underlying data for the normal buffers is stored alongside OptiX acceleration structures and included in geometry snapshots. This ensures that GPU memory is never wasted on unreachable normal buffer data.</p>

<h2 id="renders">Renders</h2>
<p>Included below are GPU-Motunui renders of the six scenes included in the dataset. shotCam is the slowest to render at 18.2 seconds per sample at 1024x429 resolution, and took just over five hours total for the final image. All shots are 1024spp, capped at a maximum of five bounces, and were run on an Nvidia RTX 2070.</p>
<div>
  <p><img src="https://www.render-blog.com/assets/ours-shotCam.png" alt="shotCam"></p><p>shotCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-beachCam.png" alt="beachCam"></p><p>beachCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-dunesACam.png" alt="dunesACam"></p><p>dunesACam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-palmsCam.png" alt="palmsCam"></p><p>palmsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-birdseyeCam.png" alt="birdseyeCam"></p><p>birdseyeCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-rootsCam.png" alt="rootsCam"></p><p>rootsCam</p>
</div>

<div>
  <p><img src="https://www.render-blog.com/assets/ours-grassCam.png" alt="grassCam"></p><p>grassCam</p>
</div>

<h2 id="optimization">Optimization</h2>
<p>The initial implementation of the renderer required 42.6 seconds per 1spp on the shotCam scene. A few optimizations combined to make significant reductions in rendering time, cutting each pass down to 18.2 seconds (a 57.3% reduction).</p>

<h4 id="cpugpu-concurrency">CPU/GPU concurrency</h4>
<p>Tracing shadow rays on the GPU in parallel with Ptex lookups on the CPU cut rendering time by 23.4%. It was disappointing to be forced to do texture lookups on the CPU, but the time savings make up for it.</p>

<h4 id="multiple-ptex-caches">Multiple Ptex caches</h4>
<p>Parallelizing the Ptex lookups and using multiple Ptex caches eliminated texture lookups as a bottleneck to the system; shadow ray casting time fully dominates the texture lookup. Empirically, spawning two threads per core (totaling 12 on an Intel i7-8700K) and sharing three Ptex caches comfortably reduced the texture lookup time beneath the shadow ray budget. This improved the time savings to a 33.9% reduction over the baseline.</p>

<h4 id="pinned-memory">Pinned memory</h4>
<p>The acceleration structure snapshots are all saved to pinned host memory. Switching from normal to pinned host memory increased the transfer throughput from 7.73 GB/s to 11.84 GB/s, cutting the baseline render time by 19.5%.</p>

<h2 id="future-steps">Future Steps</h2>
<p>Getting this scene running on my RTX 2070 card was a very fun and rewarding project, but there are still many improvements to be made:</p>
<ul>
  <li>Implementing the Disney BSDF</li>
  <li>Rendering subdivision surfaces along with displacement mapping</li>
  <li>More efficiently packing the acceleration structures, and optimizing ray tracing throughput</li>
  <li>Experimenting with how various research results hold up on production scenes (e.g., testing select path guiding techniques)</li>
</ul>

<h2 id="references">References</h2>
<ul>
  <li><a href="https://github.com/chellmuth/gpu-motunui/">GPU-Motunui</a></li>
  <li><a href="https://technology.disneyanimation.com/islandscene/">Moana Island Scene</a></li>
  <li><a href="https://pharr.org/matt/blog/2018/07/16/moana-island-pbrt-all.html">Swallowing the elephant</a> - Matt Pharr</li>
  <li><a href="https://blog.yiningkarlli.com/2018/07/disney-animation-datasets.html">Disney Animation Data Sets</a> - Yining Karl Li</li>
  <li><a href="https://schuttejoe.github.io/post/disneypostmortem/">Rendering the Moana Island Scene Part 2: A production scene from a hobby renderer</a> - Joe Schutte</li>
  <li><a href="https://ingowald.blog/2020/01/09/digesting-the-elephant/">Digesting the elephant</a> - Ingo Wald</li>
  <li>Brent Burley and Dylan Lacewell. <a href="http://ptex.us/ptexpaper.html">Ptex: â€¦</a></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.render-blog.com/2020/10/03/gpu-motunui/">https://www.render-blog.com/2020/10/03/gpu-motunui/</a></em></p>]]>
            </description>
            <link>https://www.render-blog.com/2020/10/03/gpu-motunui/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833218</guid>
            <pubDate>Tue, 20 Oct 2020 01:45:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding the Junior Developer]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24833142">thread link</a>) | @mooreds
<br/>
October 19, 2020 | https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html | <a href="https://web.archive.org/web/*/https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          


        </header>
      

      <section itemprop="text">
        
        <p>So first off a personal update â€“ last year, I got laid off the day I returned from maternity leave! Within a half hour of returning to my desk! Whew boy! It was a blessing in disguise in some ways, because 1) Iâ€™d been thinking for some time I could be more effective in a consulting role and 2) as part of my severance package, I got to attend a General Assembly coding bootcamp.</p>

<p>I ended up auditing the bootcamp because wow, it demands a ton of sacrifice with the end goal of getting a developer job. In contrast, I am happy to do a bit of scripting on the side, work with developers, and improve their experiences. Nonetheless, I worked through all the lectures, did a few homework assignments, and got a lot out of it. Not the least of which is that I validated my existing coding skills, gained deeper insight into the â€œjunior developerâ€ persona, and reaffirmed my conviction that tailoring your developer experience and docs to junior developers is a <strong>Good Thing</strong>.</p>

<p>There are a couple of big takeaways Iâ€™d like to share:</p>

<h3 id="everyone-is-a-junior-developer">Everyone is a junior developer</h3>

<p>Well, no, not actually â€¦ but every developer has to learn new concepts.  And yes, of course, as you gain experience as a developer, â€œtotally newâ€ concepts get rarer and rarer. Still, thereâ€™s a lot of learning:</p>

<p>Some developers must learn a breakneck pace (think of all the Javascript frameworks coming out all the time! Those front-end folks have to sprint just to stay in place). Others face big disruptions to their coding world only occasionally (your Enterprise Java programmer with a 20 year career in monolithic app development who now lives in a brave new world of microservices, CI/CD, devops, oh my!)</p>

<p>I felt I experienced this disruption myself as part of the coding bootcamp. Up till then, my background was in writing Python scripts, and in documenting big Java applications in a analytics microservices context. I knew about RedHat, Docker, Kubernetes, Spark, Lucene, Cassandra, etc.</p>

<p>Now, I was learning about a whole new world: the ecosystems, the mindset, the business of â€¦.  JavaScript.  Like probably many people outside the JavaScript world, I was fooled by the â€œscriptâ€ part of the name â€“ especially since Iâ€™d only used JavaScript myself to write macros in an XML docs tool.  Now I realize itâ€™s <a href="https://www.javaworld.com/article/2886368/java-vs-nodejs-an-epic-battle-for-developer-mindshare.html">epic battle</a> between Java and JavaScript. And while I havenâ€™t fallen in love (Python, you still have my heart), I had lots of â€œoh, thatâ€™s neat!â€ moments. I also recognized that my learning curve was not dissimilar to that of experienced â€“ but JavaScript-naÃ¯ve â€“ developers.</p>

<p>Which brings me to my main point:</p>

<h3 id="we-should-all-design-for-the-junior-developer">We should all design for the junior developer</h3>

<p>Creating experiences with a junior developer in mind forces you to discard your comfy assumption that everyoneâ€™s drunk your product Kool-aid. If you assume youâ€™re writing for someone whoâ€™s technically savvy and can learn quickly, but who knows nothing about your world, youâ€™re positioning yourself to vastly decrease your developer onboarding friction. And if you assume that your â€œjunior developerâ€ is super impatient because they have, like, 10 other things on the docket to learn about, then youâ€™ll learn to answer up front the question: â€œwhy should I care? Why should I do this work?â€</p>

<p>Itâ€™s a fine line to tread, assuming not too much about technical knowledge, but also not coming across as condescending or silly (like, at the level of â€œopen a terminal by taking the following stepsâ€¦â€). Still, I think itâ€™s actually quite achievable. For example, itâ€™s quite low effort to provide high-level context for coding instructions. Even something as simple as â€œClone this repository and open a terminal at the local directory locationâ€ is a direction that often gets left out in GitHub readmesâ€¦but it really shouldnâ€™t be left out.  And it never hurts to link to frameworksâ€™ getting started guides, even if you donâ€™t want to provide the details yourself. At the very least, no one is likely to roll their eyes at it, and it helps your reader understand what level of granularity your instructions will provide.</p>

<p>When I look for inspiration, I think the <a href="https://reactjs.org/tutorial/tutorial.html">React newbie tutorials</a> do an outstanding job of introducing junior developers to React, helping them understand why they should care, and explicitly stating their audience. I also really love (who doesnâ€™t) the <a href="https://dashboard.stripe.com/register">Stripe developer onboarding</a> experience.</p>

<p>Ultimately, I think I came away from the coding bootcamp more confident that I <em>am</em> a junior developer. And while Iâ€™d never make the classic UX mistake of thinking I am the user, still â€“ my confusions, my pain points in learning about a productâ€“ these are things that other developers likely share.</p>

<h3 id="postscript-fun-with-javascript">Postscript: Fun with Javascript!</h3>

<p>Iâ€™ll end on another personal note. The coding bootcamp turned out to be quite serendipitous, because I took on contracting work that immediately benefited from my new knowledge. Iâ€™d just learned about Express, and now here I was, entering a pull request to change the authentication method for an Express server. Iâ€™d just learned about React, and now here I was, wading into a web UI to change some text. Itâ€™s always nice when you can put what youâ€™ve learned to immediate use.</p>


        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://www.franceselliott.com/2020/04/08/understanding-the-junior-developer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24833142</guid>
            <pubDate>Tue, 20 Oct 2020 01:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assorted Thoughts on Zig (and Rust)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24832844">thread link</a>) | @todsacerdoti
<br/>
October 19, 2020 | https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/ | <a href="https://web.archive.org/web/*/https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I've been using <a href="https://ziglang.org/">zig</a> for ~4 months worth of side projects, including a <a href="https://git.sr.ht/%7Ejamii/focus/tree">toy text editor</a> and an <a href="https://git.sr.ht/%7Ejamii/imp">interpreter for a relational language</a>. I've written ~10kloc.</p>
<p>That's not nearly enough time to form a coherent informed opinion. So instead here is an incoherent assortment of thoughts and experiences, in no particular order :)</p>
<p>This is not meant to be an introduction to zig - check out the excellent <a href="https://ziglang.org/documentation/master/">language docs</a> or the new <a href="https://ziglearn.org/">ziglearn.org</a> instead. I'll try to focus instead on things that are not immediately obvious from reading intro material.</p>
<p>The obvious point of comparison is to rust. For context, I've been using rust <a href="https://scattered-thoughts.net/writing/three-months-of-rust/">since 2015</a>. Mostly in research positions writing throwaway code, but also ~14 months working on <a href="https://materialize.io/">a commercial database</a> which is ~100kloc.</p>
<hr>
<p>Zig is dramatically simpler than rust. It took a few days before I felt proficient vs a month or more for rust.</p>
<p>Most of this difference is <strong>not</strong> related to lifetimes. Rust has patterns, traits, dyn, modules, declarative macros, procedural macros, derive, associated types, annotations, cfg, cargo features, turbofish, autoderefencing, deref coercion etc. I encountered most of these in the first week. Just understanding how they all work is a significant time investment, let alone learning when to use each and how they affect the available design space.</p>
<p>I still haven't internalized the full rule-set of rust enough to be able predict whether a design in my head will successfully compile. I don't remember the order in which methods are resolved during autoderefencing, or how module visibility works, or how the type system determines if one impl might <a href="https://github.com/Ixrec/rust-orphan-rules#what-are-the-orphan-rules">overlap another or be an orphan</a>. There are frequent moments where I know what I want the machine to do but struggle to encode it into traits and lifetimes.</p>
<p>Zig manages to provide many of the same features with a single mechanism - compile-time execution of regular zig code. This comes will all kinds of pros and cons, but one large and important pro is that I already know how to write regular code so it's easy for me to just write down the thing that I want to happen.</p>
<hr>
<p>One of the key differences between zig and rust is that when writing a generic function, rust will prove that the function is type-safe for every possible value of the generic parameters. Zig will prove that the function is type-safe only for each parameter that you actually call the function with.</p>
<p>On the one hand, this allows zig to make use of arbitrary compile-time logic where rust has to restrict itself to structured systems (traits etc) about which it can form general proofs. This in turn allows zig a great deal of expressive power and also massively simplifies the language.</p>
<p>On the other hand, we can't type-check zig libraries which contain generics. We can only type-check specific uses of those libraries.</p>
<pre><span>// This function is typesafe if there exist no odd perfect numbers
// https://en.wikipedia.org/wiki/Perfect_number#Odd_perfect_numbers
fn foo(comptime n: comptime_int, i: usize) usize {
  const j = if (comptime is_odd_perfect_number(n)) "surprise!" else 1;
  return i + j;
}
</span></pre>
<p>This means zig also doesn't get the automatic, machine-checked documentation of type constraints that rust benefits from and may face more challenges providing IDE support.</p>
<p>This might harm the zig ecosystem by making it harder to compose various libraries. But <a href="https://julialang.org/">julia</a> has a similar model and in practice it has worked very well (<a href="https://youtu.be/dmWQtI3DFFo?t=1710">eg</a>, <a href="https://www.oxinabox.net/2020/02/09/whycompositionaljulia.html">eg</a>).</p>
<hr>
<p>Zig's comptime allows expressing <a href="https://scattered-thoughts.net/writing/open-multiple-dispatch-in-zig/">open multiple dispatch</a> as a library.</p>
<p>It should be relatively trivial to implement specialization the same way, which has been a <a href="https://github.com/rust-lang/rust/issues/31844">work in progress</a> in rust for years and is critical to many optimizations in julia's math libraries.</p>
<p>Julia chose dynamic typing because it's very difficult to encode the types of various mathematical operations into a general schema (eg fortress <a href="https://youtu.be/EZD3Scuv02g?t=3011">struggled with this</a>). Zig's approach of not requiring general schemas but still type-checking individual cases may be an interesting sweet spot.</p>
<hr>
<p>I used the <a href="https://cwe.mitre.org/data/definitions/1350.html">2020 CWE Top 25 Most Dangerous Software Weaknesses</a> to get a sense of the relative frequency of different causes of memory unsafety.</p>
<p>(I'm assuming that the zig programmer is using release-safe mode instead of the unfortunately named release-fast mode which disables all runtime safety checks.)</p>
<ul>
<li>Out-of-bounds Write (787/1350)</li>
<li>Out-of-bounds Read (125/1350)</li>
<li>Improper Restriction of Operations within the Bounds of a Memory Buffer (119/1350)</li>
</ul>
<p>Both languages primarily use bounds-checked slices and relegate pointer arithmetic to a separate type (<code>*T</code> in rust, <code>[*]T</code> in zig).</p>
<ul>
<li>NULL Pointer Dereference (476/1350)</li>
</ul>
<p>Both languages require explicit annotations for nulls (<code>Option&lt;T&gt;</code> in rust, <code>?T</code> in zig) and require code to either handle the null case or safely crash on null (<code>x.unwrap()</code> in rust, <code>x.?</code> in zig).</p>
<p>Dereferencing/casting a null c pointer is undefined behavior in both languages, but is checked at runtime in zig.</p>
<ul>
<li>Integer Overflow or Wraparound (190/1350)</li>
</ul>
<p>Rust catches overflow in debug and wraps in release. Zig catches overflow in debug/release-safe and leaves behavior undefined in release-fast.</p>
<p>Both languages allow explicitly asking for wraparound (<code>x.wrapping_add(1)</code> in rust, <code>x +% 1</code> in zig).</p>
<ul>
<li>Use After Free (416/1350)</li>
</ul>
<p>As long as all unsafe code obeys the aliasing and lifetime rules, rust protects completely against UAF.</p>
<p>Zig has little protection. The recently merged
<a href="https://github.com/ziglang/zig/blob/575fbd5e3592cff70cbfc5153884d919e6bed89f/lib/std/heap/general_purpose_allocator.zig">GeneralPurposeAllocator</a> avoids reusing memory regions (which prevents freed data from being overwritten) and reusing pages (which means that UAF will eventually result in a page fault). But this comes at the cost of fragmentation and lower performance and it also won't provide protection for child allocators using the GPA as a backing allocator.</p>
<hr>
<p>Both languages will insert implicit casts between primitive types and pointers whenever it is safe to do so, and require explicit casts otherwise. (With the odd exception that rust will not implicitly upcast numbers).</p>
<p>Both languages support generics which almost entirely avoids the need to cast void pointers.</p>
<hr>
<p>In rust the Send/Sync traits flag types which are safe to move/share across threads. In the absence of unsafe code it should be impossible to cause data races.</p>
<p>Zig has no comparable protection. It's possible to implement the same logic as Send/Sync in comptime zig, but without the ability to track ownership the rules would have to be much more restrictive.</p>
<hr>
<p>Rust prevents having multiple mutable references to the same memory region at the same time.</p>
<p>This means that eg iterator invalidation is prevented at compile time, because the borrow checker won't allow mutating a data-structure while an iterator is holding a reference to the data-structure. Similarly for resizing a data-structure while holding a reference to the old allocation. Both examples are easy sources of UAF in zig.</p>
<hr>
<p>Neither language is able to produce stack traces for stack overflows at the moment (<a href="https://github.com/rust-lang/rust/issues/51405">rust</a>, <a href="https://github.com/ziglang/zig/issues/1616">zig</a>)</p>
<p>In the future zig is <a href="https://github.com/ziglang/zig/issues/1006">intended</a> to statically check the maximum stack usage of your program and force recursive code to explicitly allocate space on the heap, so that stack overflows produce a recoverable OutOfMemory error rather than a crash.</p>
<p>This is not an academic problem - I've seen real-world crashes from recursive tree transformations in compilers (<a href="https://github.com/MaterializeInc/materialize/pull/3996">eg</a>) and it's often painful to write the same logic without recursion.</p>
<hr>
<p>Undefined behavior in rust is defined <a href="https://doc.rust-lang.org/nomicon/what-unsafe-does.html">here</a>. It's worth noting that breaking the aliasing rules in unsafe rust can cause undefined behavior but these rules are not yet well-defined. So far this hasn't caused me any problems but it is a little unnerving.</p>
<p><a href="https://github.com/rust-lang/miri">Miri</a> is an interpreter for rusts Mid-level Intermediate Representation which will detect many (but not all) cases of undefined behavior in unsafe rust. It's far too slow to use for the whole materialize test suite but was useful for unit-testing an unsafe module.</p>
<p>Undefined behavior in zig is defined <a href="https://ziglang.org/documentation/master/#Undefined-Behavior">here</a>. This list is <a href="https://github.com/ziglang/zig/issues/1966">probably incomplete</a> given that the core language is still under development.</p>
<p>Zig <a href="https://github.com/ziglang/zig/issues/2301">aspires</a> to insert runtime checks for almost all undefined behavior when compiling in debug mode. So far all the easy cases are handled, which is already a dramatic improvement over c.</p>
<p>Zigs compile-time partial evaluation is done by an IR interpreter - it seems plausible that this could also be used as a miri-like tool in the future.</p>
<hr>
<p><code>@import</code> takes a path to a file and turns the whole file into a struct. So modules are just structs. And vice-versa - if you have a large struct declaration you can move it into a file to reduce the indentation.</p>
<p>Zig doesn't care at all where you put files on the filesystem.</p>
<p><code>@import</code> is part of the compile-time execution system so things like platform-specific modules and configurable features can be specified in regular code rather than rust's limited set of <code>#[cfg(...)]</code> macros.</p>
<hr>
<p>Array, struct, enum and union literals can be anonymous - <code>.{.Constant = 1.0}</code> is an anonymous union with it's own type, but can be implicitly cast to any union with a <code>Constant: f64</code> field because they share the same structure.</p>
<p>In rust my code is littered with <code>use Expr::*</code> and I'm careful to avoid name collisions between different enums that I might want to import in the same functions. In zig I just use anonymous literals everywhere and don't worry about it.</p>
<hr>
<p>Anonymous literals are also nice when using structs to simulate keyword arguments. No need to find and import the correct type:</p>
<pre><span>fn do_things(config: struct {
  max_things: usize = 1000, // default value
  flavor: Flavor,
}) void {
  ...
}

do_things(.{.flavor = .Strawberry});
</span></pre>
<hr>
<p>There is a pattern that shows up a lot in the materialize codebase:</p>
<pre><span>let</span><span> constant </span><span>= </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(constant) </span><span>=</span><span> expr { constant } </span><span>else </span><span>{ </span><span>panic!</span><span>() }</span><span>;
</span></pre>
<p>It's common enough that many types have methods like <code>expr.unwrap_constant()</code>.</p>
<p>In zig:</p>
<pre><span>const constant = expr.Constant;
</span></pre>
<p>A similar pattern is:</p>
<pre><span>if</span><span> some_condition {
    </span><span>if let </span><span>Expr</span><span>::</span><span>Constant(</span><span>_</span><span>) </span><span>=</span><span> expr {
        </span><span>...
    </span><span>}
}
</span></pre>
<p>Again, many types get methods like <code>expr.is_constant()</code>.</p>
<pre><span>if</span><span> some_condition </span><span>&amp;&amp;</span><span> expr</span><span>.</span><span>is_constant</span><span>(â€¦</span></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/">https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</a></em></p>]]>
            </description>
            <link>https://scattered-thoughts.net/writing/assorted-thoughts-on-zig-and-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24832844</guid>
            <pubDate>Tue, 20 Oct 2020 00:47:18 GMT</pubDate>
        </item>
    </channel>
</rss>
