<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 23 Jul 2020 08:18:17 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 23 Jul 2020 08:18:17 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Monitoring your own infrastructure using Grafana, InfluxDB, and CollectD]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906165">thread link</a>) | @crecker
<br/>
July 21, 2020 | https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://serhack.me/images/grafana/all%20together%20now_wide.jpg" alt="Grafana, InfluxDB and CollectD"></p><h4 id="for-some-companies-infrastructure-is-the-heart-of-its-business-specifically-i-am-referring-to-those-companies-which-need-to-manage-data-and-applications-located-on-more-than-one-server">For some companies, infrastructure is the heart of its business. Specifically, I am referring to those companies which need to manage data and applications located on more than one server.</h4><p>It is essential for a company to monitor its infrastructure nodes, especially if the company does not have on-site access to intervene when issues arise. In fact, the intensive use of some resources can be an indication of malfunctioning or overcrowding. However, in addition to prevention, monitoring could be used to assess possible implications of new software in the production environment. Currently, there are several “ready-to-use” solutions on the market to keep track of all the resources consumed. These solutions, which appear reasonable, present two key problems: the high price of setup and security issues related to third parties.</p><p>The first problem is related to cost. Prices vary from 10 euros per month up to thousands depending on how many hosts you need to monitor — with the former being consumer pricing and the latter being enterprise pricing. So, for example, let’s imagine that I have three nodes to monitor during the course of a year. At 10 euros per month, I would spend 120 euros. For smaller enterprises, where the price can range between 10,000 and 20,000 euro per year, such an expense can bloat its underlying cost structure and become financially untenable.</p><p>The second problem is third party risk. Typically, infrastructure data must pass through a third party company in order to be seen and analysed for the customer — whether that be an individual consumer or an enterprise. How does the third party company capture the data and then present it to the customer? Simply put, the third party company often collects data through a custom agent that is installed onto a node and monitored. Quite often is it found that this installation is not up-to-date and compatible with operating systems. Previous work has been done by security researchers who cast light upon problems with <a href="https://www.rapid7.com/db/modules/exploit/linux/misc/nagios_nrpe_arguments">“proprietary collectors”</a>. Would you trust them? I would not.</p><p>In keeping nodes for both <a href="https://trac.torproject.org/projects/tor/wiki/TorRelayGuide">Tor</a> and some <a href="https://getmonero.org/">cryptocurrencies</a>, I prefer to opt for a cost free, easy to configure, and open-source alternative. Here, we will use the triad: Grafana, InfluxDB, and CollectD.</p><p><img src="https://serhack.me/images/grafana/grafana-graphs.png" alt="An example of a Grafana dashboard"></p><h2 id="monitoring">Monitoring</h2><p>In order to be able to analyse every metric of our infrastructure, it is necessary to use a program capable of capturing statistics on the machines we want to monitor. In this regard, <a href="https://collectd.org/">CollectD</a> comes to your aid: it is a daemon that groups and collects (hence the name) all the parameters that can be stored on disk or sent over the network.</p><p>The data will be transmitted to an instance of <a href="https://www.influxdata.com/">InfluxDB</a>: a particular time series database that associates to each data the time (coded in UNIX timestamp) in which the server received it. In this way, the data sent by CollectD will already be set in a temporal way, as a succession of events.</p><p>Finally, you will use <a href="http://grafana.org/">Grafana</a> which will connect to InfluxDB to create flashy dashboards to display the data in a user-friendly way. Through histograms and graphs of every kind, it will be possible to observe in real time all the data related to CPU, RAM, etc.</p><p><img src="https://serhack.me/images/grafana/grafana-diagram.png" alt="Grafana infrastructure"></p><h2 id="influxdb">InfluxDB</h2><picture>
<source media="(min-width: 535px)" data-original-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone_wide.jpg 2x"><source media="(max-width: 534px)" data-original-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone.jpg 2x" src-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone.jpg 2x"><img data-original="/images/grafana/db_alone.jpg" data-original-set="/images/grafana/db_alone_wide.jpg 2x" src="https://serhack.me/images/grafana/db_alone_wide.jpg" alt=""></picture><p>Let’s start with InfluxDB, which is the beating heart of our monitoring “system”. InfluxDB is a time series database <a href="https://github.com/influxdata/influxdb">open-source</a> developed in <a href="https://golang.org/">Go</a> to store data as a sequence of events.</p><p>Each time data is added, it is linked to <a href="https://en.wikipedia.org/wiki/Unix_time">a UNIX timestamp</a> by default. This allows enormous flexibility for the user who no longer has to worry about saving, as an example, the “time” variable, which is sometimes cumbersome to configure. Let’s imagine we have several machines located in a number of continents. How do we manage the “time” variable? Do we use the <a href="https://en.wikipedia.org/wiki/Greenwich_Mean_Time">Greenwich</a> meridian for all the data? Or do we set a different time zone for each node? If data is saved on different time zones, how can we accurately display the graphs? As you can see, this can be very complicated.</p><p>As a time-aware database that automatically timestamps any data point, InfluxDB has the advantage of simultaneously being able to write to a certain database. This is why we often imagine InfluxDB as a timeline. Writing data does not affect the performance of the database (as sometimes happens in MySQL), since writing is simply the addition of a certain event to the timeline. The name of the program derives precisely from the conception of time as an infinite and indefinite “flow” that flows.</p><h3 id="installation-and-configuration">Installation and configuration</h3><p>Another advantage of InflxuDB is the <a href="https://docs.influxdata.com/influxdb/v1.8/introduction/install/">ease of installation</a> and the extensive <a href="https://docs.influxdata.com/">documentation</a> provided by the community that widely supports the project. It has two types of interfaces: via <a href="https://docs.influxdata.com/influxdb/v1.8/tools/shell/">Command Line</a> (which is powerful and flexible for developers, but poorly prepared to see large amounts of data) and an <a href="https://docs.influxdata.com/influxdb/v1.8/guides/write_data/#sidebar">HTTP API</a> that allows direct communication with the database.</p><p>InfluxDB can be downloaded not only from the official website, but also from the package manager of the distribution (in this example we use a Debian system). It is advisable to check the package via GPG before installation, so (below) we import the keys of the InfluxDB package:</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="1e6c71716a5e70717a7b">[email&nbsp;protected]</a>#~: curl -sL https://repos.influxdata.com/influxdb.key | sudo apt-key add -
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="8cfee3e3f8cce2e3e8e9">[email&nbsp;protected]</a>#~: source /etc/os-release
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="7b0914140f3b15141f1e">[email&nbsp;protected]</a>#~: echo <span>"deb https://repos.influxdata.com/debian </span><span>$(</span>lsb_release -cs<span>)</span><span> stable"</span> | sudo tee /etc/apt/sources.list.d/influxdb.list</code></pre></div><p>Finally, we update and install InfluxDB:</p><p>To start it, we use <code>systemctl</code>:</p><p>To make sure that no one nefarious enters, we create the user “administrator”. InfluxDB uses a particular query language called <a href="https://docs.influxdata.com/influxdb/v1.8/query_language/">“InfluxQL”</a>, similar to SQL, which allows you to interact with the database. To create a new entry, we use the query <a href="https://docs.influxdata.com/influxdb/v1.8/administration/authentication_and_authorization/#user-management-commands"><code>CREATE USER</code></a>.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="a0d2cfcfd4e0cecfc4c5">[email&nbsp;protected]</a>#~: influx
Connected to http://localhost:8086
InfluxDB shell version: x.y.z
&gt;
&gt; CREATE USER admin WITH PASSWORD <span>'MYPASSISCOOL'</span> WITH ALL PRIVILEGES</code></pre></div><p>From the same CLI interface, we create the “metrics” database that will be used as a container for our metrics.</p><div><pre><code data-lang="bash">&gt; CREATE DATABASE metrics</code></pre></div><p>Next, let’s modify the configuration of InfluxDB (<code>/etc/influxdb/influxdb.conf</code>) to have the interface open on port <strong>24589</strong> (UDP) with direct connection to the database named “metrics” in support of CollectD. You also need to download and place the <a href="https://raw.githubusercontent.com/collectd/collectd/master/src/types.db">types.db</a> file in <code>/usr/share/collectd/</code> (or any other folder) to define the data that <a href="https://docs.influxdata.com/influxdb/v1.8/supported_protocols/collectd/">CollectD sends in native format</a>.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="b1c3dedec5f1dfded5d4">[email&nbsp;protected]</a>#~: nano /etc/influxdb/influxdb.conf
<span>[</span>Collectd<span>]</span>
enabled <span>=</span> true
bind-address <span>=</span> <span>":24589"</span>
database <span>=</span> <span>"metrics"</span>
typesdb <span>=</span> <span>"/usr/share/collectd/types.db"</span></code></pre></div><p>For further information on the CollectD block within the configuration, see the <a href="https://docs.influxdata.com/influxdb/v1.8/administration/config/#collectd-settings">reference to documentation</a>.</p><h2 id="collectd">CollectD</h2><picture>
<source media="(min-width: 535px)" data-original-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone_wide.jpg 2x"><source media="(max-width: 534px)" data-original-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone.jpg 2x" src-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone.jpg 2x"><img data-original="/images/grafana/daemon_alone.jpg" data-original-set="/images/grafana/daemon_alone_wide.jpg 2x" src="https://serhack.me/images/grafana/daemon_alone_wide.jpg" alt=""></picture><p>CollectD is a data aggregator, in our monitoring infrastructure, that facilitates the transmission of data to InfluxDB. By default, CollectD captures metrics on CPU, RAM, memory (on disk), network interfaces, processes, etc. The potential of the program is endless, given that it can be extended with a preinstalled <a href="https://collectd.org/wiki/index.php/Table_of_Plugins">plugin enablement</a> or through the <a href="https://collectd.org/wiki/index.php/Roadmap#Wishlist_.2F_Ideas">creation of new ones</a>.</p><p>As you can see, installing CollectD is simple:</p><p>In a simplistic manner, let’s illustrate how CollectD works. Suppose that I want to check how many processes my node has. In doing so, CollectD does nothing more than make an API call to get the number of processes per time unit (defined as 5000 ms, by default). Once captured, the data will be sent to InfluxDB via a module (called “Network”) to be configured.</p><p>Open the file <code>/etc/collectd.conf</code> with our editor, scroll to find the <code>Network</code> section, and edit as written in the following snippet. Be sure to specify the IP where the interface of InfluxDB (<code>INFLUXDB_IP</code>) is located.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="9ae8f5f5eedaf4f5feff">[email&nbsp;protected]</a>#~: nano /etc/collectd.conf
    ...
&lt;Plugin network&gt;
  &lt;Server <span>"INFLUXDB_IP"</span> <span>"24589"</span>&gt;
  &lt;/Server&gt;
  ReportStats true
&lt;/Plugin&gt;
    ...</code></pre></div><p>My suggestion is to modify, within the configuration, the hostname that is sent to InfluxDB (which in our infrastructure is a “centralized” database, since it resides on a single node). In doing so, the data will not be redundant and there is no risk that other nodes will overwrite the information.</p><p><img src="https://serhack.me/images/grafana/tres_caballeros.jpg" alt="Three daemon"></p><h2 id="grafana">Grafana</h2><p><img src="https://serhack.me/images/grafana/grafana_alone.jpg" alt=""></p><blockquote><p>A graph is worth thousand of images</p></blockquote><p>In remembrance of this famous “quote”, observing the infrastructure metrics live through graphs and tables enables us to act in an efficient and timely manner. To create and configure the dashboard, we will use Grafana.</p><p>Grafana is an open-source tool, compatible with a wide range of databases (including InfluxDB), that presents a graphical representation of metrics and allows a user to create alerts if a particular piece of data meets a condition. For example, if your CPU reaches high peaks, you can be notified on Slack, Mattermost, by email, etc. In fact, I have personally configured an alert every time someone enters SSH, so I can actively monitor who “enters” my infrastructure.</p><p>Grafana does not require any special settings: once again, it is InfluxDB that “scans” the “time” variable. The integration is simple. Let’s start by import the public key to add the package from the <a href="https://grafana.com/grafana/download">Grafana official website</a> (it depends on the OS you are using):</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="ddafb2b2a99db3b2b9b8">[email&nbsp;protected]</a>#~: wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="1e6c71716a5e70717a7b">[email&nbsp;protected]</a>#~: echo <span>"deb https://packages.grafana.com/oss/deb stable main"</span> | sudo tee -a /etc/apt/sources.list.d/grafana.list 
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="b8cad7d7ccf8d6d7dcdd">[email&nbsp;protected]</a>#~: apt-get update <span>&amp;&amp;</span> apt-get install grafana</code></pre></div><p>Let’s start it through systemctl:</p><p>Next, as we go to the localhost:3000 page through the browser, we should be presented with a login interface for Grafana. By default, you should use <strong>admin</strong> as username and <strong>admin</strong> as password (it is advisable to change the password after the first login).</p><p><img src="https://serhack.me/images/grafana/login-page.png" alt="Login page"></p><p>Let’s go to Sources and add our Influx database:</p><p><img src="https://serhack.me/images/grafana/add-data-source.png" alt="Add data source to Grafana"></p><p><img src="https://serhack.me/images/grafana/influxdb.png" alt="InfluxDB"></p><p>The screen now shows a small green rectangle just below the New Dashboard. Hover your mouse over this rectangle and select Add Panel, then Graph:</p><p><img src="https://serhack.me/images/grafana/add-new-panel.png" alt="Add a new panel"></p><p>A graph with the test data is now shown. Click on the title of this chart and choose Edit. Grafana allows the writing of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/">https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906165</guid>
            <pubDate>Tue, 21 Jul 2020 12:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presentation: The Technical Evolution of Mailinator.com]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906102">thread link</a>) | @zinxq
<br/>
July 21, 2020 | https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/ | <a href="https://web.archive.org/web/*/https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Mailinator started 17 years ago as a weekend project to define the idea of “Free, Disposable, Email”. Back then, it ran on a single server with only a single developer. Over time, it’s popularity has exploded in terms of both incoming email and active users. As you might guess when you go from thousands of emails-per-day to <strong>thousands of emails-per-second</strong>, the behind-the-scenes technical stack needs to evolve - and Mailinator’s stack has had a quite a technical journey.</p>
<p><img src="https://manybrain.github.io/m8r_blog/img/2020/07/image1.png" alt="Slide showing beginning and end tech evolution for Mailinator.com"></p>
<p>Today Mailinator still provides free, disposable, email - but also serves thousands of daily corporate users in testing their Email and SMS Workflows with an API, Webhooks, and Private Domains. Website owners quickly realized that having an infinite number of inboxes “on tap” was incredibly useful for testing things their like their Signup system, Marketing email systems, and more. Quality Assurance teams found it to be an invaluable tool.</p>
<p>In February 2020, Mailinator’s creator Paul Tyma gave a talk on the “Technical Evolution of Mailinator.com”. Below you can find a link to the slides and watch the video. The talk explores the site’s journey from a “Free, Disposable, Email” to a becoming SaaS service helping thousands of companies test their Email and SMS Workflows (and of course, scaling a system to tens of millions of emails per day).</p>
<p><a href="https://drive.google.com/file/d/1HV8BZUPBp4HT5C8Ob3rMXCWhSo5F9oRa/view?usp=sharing">GET THE SLIDES HERE</a></p>

<p>
  <iframe src="https://www.youtube.com/embed/BqNfHsZ3QUc" allowfullscreen="" title="YouTube Video"></iframe>
</p>


  </div></div>]]>
            </description>
            <link>https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906102</guid>
            <pubDate>Tue, 21 Jul 2020 11:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pine64’s $199.99 14 inch Pine Pro laptop now available for pre-order]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23905298">thread link</a>) | @darshansavla
<br/>
July 21, 2020 | https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9147"><div><div><div><h2>Pine64’s $199.99 14 inch Pine Pro Linux laptop with 64-bit ARM chip and Manjaro Linux distro now available for pre-order</h2><p>If you are a Linux fanboi, you shouldn’t miss this one. <a href="https://androidrookies.com/pine64-launches-the-cheapest-linux-tablet-ever-priced-at-just-99-99/">Pine64</a>, the makers of Linux based laptops have reopened their pre-order window for the 14.1 inch ARM-based Linux laptop Pinebook Pro. Pine64 had last opened the pre-order window in March 2020 and If you missed placing an order last time, you now have another chance to grab $199.99 Pinebook Pro.</p><p>PINE64 has <a href="https://www.pine64.org/2020/07/20/pinebook-pro-pre-orders-open-with-shipping-in-august-2020/" target="_blank" rel="noreferrer noopener nofollow" aria-label="undefined (opens in a new tab)">started</a> to take the next batch of pre-orders for Pinebook Pro. The pre-order has both the ISO and ANSI keyboard versions of Pinebook Pro and is available for order from their official website <a href="https://store.pine64.org/product/14%e2%80%b3-pinebook-pro-linux-laptop-ansi-us-keyboard-estimated-dispatch-in-december-2019/" target="_blank" rel="noreferrer noopener">here</a>. Both ANSI and ISO keyboard editions cost <strong>$199.99</strong><strong>&nbsp;excluding the shipping charges</strong>. Pine64 says that it will deliver the laptops by late August 2020.</p><h2>14.1 inch Pine Pro Linux Laptop specifications</h2><p>The Pine Pro Linux laptop comes with a 14.1 IPS inch screen giving a resolution of 1920 x 1080. It is powered by the 64-bit dual-core ARM 1.8GHz Cortex A72 and Quad-Core ARM 1.4GHz Cortex A53 processor and a Mali T-860 GPU. It runs on 4GB of LPDDR4 RAM and has 64GB of eMMC 5.0 of internal storage. You can extend the memory with external MicroSD card.</p><p>For connectivity, the Pine Pro laptop comes with WiFi 802.11AC + Bluetooth 5.0. It has one 3.5 mm headphone jack, one USB 3.0 and one USB 2.0 Type-A host port. On top of that, Pinebook also has USB 3.0 Type-C ports with alt-mode display out (DP 1.2). Using this USB-C port, you can connect your existing Linux laptops or <a href="https://androidrookies.com/pine64-launches-the-cheapest-linux-tablet-ever-priced-at-just-99-99/" target="_blank" rel="noreferrer noopener" aria-label="undefined (opens in a new tab)">PineTab.</a> The laptop comes with a Multi-Touch Touchpad and has a 10000 mAH battery. The Pine Pro laptop has a 2MP front camera which doesn’t seem like much. The product comes with a 30-day warranty and the makers warn of small numbers (1-3) of stuck or dead pixels on Pine Pro laptop LCD screens. The makers say these are normal and should not be considered a defect</p><p>Pine Pro laptop runs on Manjaro Linux distro by default. However, if you don’t like Manjaro Linux you can install other Linux distributions such as Debian and Fedora Linux. You can check out the supported Pine Pro laptop supported distros <a href="https://wiki.pine64.org/index.php/Pinebook_Pro_Software_Release" target="_blank" rel="noreferrer noopener nofollow" aria-label="undefined (opens in a new tab)">here.</a></p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905298</guid>
            <pubDate>Tue, 21 Jul 2020 08:44:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invert, Always, Invert]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23905221">thread link</a>) | @anupj
<br/>
July 21, 2020 | https://www.anup.io/2020/07/20/invert-always-invert/ | <a href="https://web.archive.org/web/*/https://www.anup.io/2020/07/20/invert-always-invert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.anup.io/content/images/size/w300/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 300w,
                            https://www.anup.io/content/images/size/w600/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 600w,
                            https://www.anup.io/content/images/size/w1000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 1000w,
                            https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg" alt="Invert,  always, invert">
            </figure>

            <section>
                <div>
                    <blockquote>man muss immer umkehren - Carl Gustav Jacob Jacobi</blockquote><p>(loosely translated - Invert, always, invert)</p><p>Today, we will look at one of my favourite mental models called - The<strong><em> Inversion principle</em></strong>. <a href="https://fs.blog/mental-models/#what_are_mental_models">Mental models</a> are a set of simple, abstract but useful principles that help us make sense of the world around us.</p><p>I came across the Inversion principle on the <a href="https://fs.blog/2013/10/inversion/">Farnam Street blog</a>. It is also a favourite of Charlie Munger (Vice Chairman of Berkshire Hathaway and Warren Buffets mate) - "...it is in the nature of things that many hard problems are best solved when they are addressed backward", he pontificates.</p><p>In another interview, he recalls how, as an Air Force meteorologist during World War II, instead of asking what would keep pilots safe, he asked what would kill them and focussed all his efforts "on trying to predict snow, ice or fog—and to ignore pretty much everything else.".</p><p>I could write a book on all the other cool stuff Charlie Munger has said so I'll stop here.</p><h3 id="what-is-it">What is it?</h3><p>Inversion is based on the maxim - invert, always, invert. It is about considering an inverse (usually a negative) outcome and listing the reasons for these. It forces you to either stop doing certain things or avoid the actions that lead to the negative outcomes. It gives us <em><em>new possibilities</em> and capabilities</em> that we might not have considered otherwise.</p><p>The algorithm for inversion is very simple:</p><ul><li><strong>Define the problem</strong> - what is it that &nbsp;you're trying to achieve?</li><li><strong>Invert it </strong>- what would guarantee the failure to achieve this outcome?</li><li>Finally, <strong>consider solutions to avoid this failure</strong></li></ul><p>This is very abstract and vague, so let's look at a few examples:</p><ol><li>Instead of asking how do we increase the adoption of a product or feature? You could instead consider - what are some of things preventing adoption? This would lead to a list like this that you could potentially fix:</li></ol><ul><li>Slow load time i.e. performance issues</li><li>Not enough marketing, or marketing on the platform, or to the wrong audience</li><li>The user guide instructions are not clear ... you get the idea</li></ul><p>2. &nbsp;Following the inversion principle it is <em>better to ask</em> what is preventing me from reading all the unread books on my kindle/bookshelf, instead of asking how can i read more books? Possible reasons and something you could give up:</p><ul><li>I spend a lot of time on social media</li><li>I watch too many shows on Netflix or Disney +</li><li>Spend a lot of time on reddit or browsing hacker news</li></ul><p>3. Instead of wondering how do I always choose a winning stock during investing, ask yourself how do you prevent losses in the long term?</p><ul><li>Am I diversifying enough to prevent long term loss?</li><li>Am I investing &nbsp;based on sound principles, or am I speculating? </li></ul><p>Hopefully this &nbsp;gives you a flavour of how powerful inversion is as a mental model. I should add that it is NOT a silver bullet and it won't always give you concrete answers, but it will act as a forcing function to avoid obvious lapses in judgment. I'll leave you with another one of my favourite quotes about Inversion from Charlie.</p><blockquote>"It is remarkable how much long-term advantage people like us have gotten by trying to be consistently not stupid, instead of trying to be very intelligent."</blockquote><hr><p>Further reading:</p><figure><blockquote><a href="https://fs.blog/2014/06/avoiding-stupidity/">Avoiding Stupidity is Easier than Seeking Brilliance</a></blockquote>
</figure><figure><a href="https://commoncog.com/blog/putting-mental-models-to-practice-part-3-better-trial-and-error/"><div><p>Putting Mental Models to Practice Part 3: Better Trial and Error</p><p>Instrumental rationality is the sort of thinking that allows you to achieve your goals. We take a closer look at what decision science says is the ‘best’ way to pursue this purpose.</p><p><img src="https://commoncog.com/blog/favicon.png"><span>Commonplace - The Commoncog Blog</span></p></div><p><img src="https://commoncog.com/blog/content/images/2018/12/burst-530182-unsplash--1-.jpg"></p></a></figure><p>Thanks for taking the time to read this post, if you found it useful and if you have any comments or more tips, please hit me up on twitter (@<a href="https://twitter.com/anup">anup</a>).</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Anup Jadhav</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.anup.io/2020/07/20/invert-always-invert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905221</guid>
            <pubDate>Tue, 21 Jul 2020 08:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brick Block – by Oskar Stålberg (desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23904991">thread link</a>) | @thdrdt
<br/>
July 21, 2020 | http://oskarstalberg.com/game/house/index.html | <a href="https://web.archive.org/web/*/http://oskarstalberg.com/game/house/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
    <canvas id="canvas" oncontextmenu="event.preventDefault()" height="100%" width="100%"></canvas>
	<div id="loadingBox">
	  
	  
	  <p id="loadingInfo">Loading...</p>
	</div>
		
    


  

</div>]]>
            </description>
            <link>http://oskarstalberg.com/game/house/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904991</guid>
            <pubDate>Tue, 21 Jul 2020 07:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic RBAC with zero performance overhead in Hopsworks]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23904812">thread link</a>) | @jamesblonde
<br/>
July 20, 2020 | https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Feature stores are the new cool kids in the neighbourhood of Data engineering and AI (artificial intelligence). Hyperscale&nbsp; AI companies (such as Uber, Netflix) have <a href="http://www.featurestore.org/">built their own feature stores</a> to solve the problems of reusing, governing and securing access to features (data for AI) in a shared platform. Hopsworks is a modular open-source platform, developed by Logical Clocks, for managing data for AI (a standalone Feature Store), computing features (Spark, Python), and training models. In this post, we introduce the project-based multi-tenancy security model in Hopsworks for users, data, and programs. We describe how our project-based multi-tenant security model is, in effect, a form of dynamic role-based access control with zero performance overhead.</p><figure id="w-node-591b61e7aa1b-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f10585a943c7738c589d3c5_Screenshot%202020-07-16%20at%2015.38.14.png" alt=""></p></figure><p><a href="https://www.logicalclocks.com/blog/introducing-hopsworks-ai">Hopsworks.ai</a> is a SaaS version of Hopsworks, currently available on AWS. Hopsworks clusters can be run with an IAM profile, providing them with an identity in AWS with permission policies that capture what operations the Hopsworks cluster is authorized to perform in AWS - such as read/write data in S3 buckets. Hopsworks can also be used from Data Science and Feature Engineering platforms (Databricks, Sagemaker, KubeFlow, EMR) using API keys exported from Hopsworks.</p><p>This post is concerned primarily with the internal security model in Hopsworks that enables you to host sensitive data in a shared cluster, providing powerful access control and self-service capabilities. The benefit of Hopsworks project-based multi-tenancy model is that you can host many users and feature stores (and other projects) on a single cluster, with self-service access to different feature stores. The advantage of our security model is that you can host production, staging, and development feature stores in a single cluster - you do not need to manage and pay for separate clusters.&nbsp;</p><p><a href="https://en.wikipedia.org/wiki/Role-based_access_control#:~:text=Role%2Dbased%20access%20control%20(RBAC)%20is%20a%20policy%2D,simple%20to%20perform%20user%20assignments.">Role-based access control</a> (RBAC) is a well-known security model that enables administrators to give a group of users the same access rights to selected resources. With roles, an administrator at a company could define a single security policy and apply it to all members of a department. But individuals may be members of multiple departments, so a user might be given multiple roles. <a href="https://link.springer.com/chapter/10.1007/978-3-540-85776-1_17">Dynamic role-based access control</a> means that, based on some other policy, you can change the set of roles a user can hold at a given time. For example, if a user has two different roles - one for accessing banking data and another one for accessing trading data, with dynamic RBAC, you could restrict the user to only allow her to hold one of those roles at a given time. The policy for deciding which role the user holds could, for example, depend on what VPN (virtual private network) the user is logged in to or what building the user is present in. In effect, dynamic roles would allow to hold only one of the roles at a time and sandbox her inside one of the domains - banking or trading. It would prevent her from cross-linking or copying data between the different trading and banking domains.</p><p>Hopsworks implements a dynamic role-based access control model through a project-based <strong>multi-tenant security model. </strong>Inspired by GDPR, in Hopsworks a <em>Project </em>is a sandboxed set of users, data, and programs (where data can be shared in a controlled manner between projects). Every Project has an <strong>owner</strong> with full read-write privileges and zero or more <strong>members</strong>.&nbsp;</p><p>A project owner may invite other users to his/her project as either a <strong>Data Scientist </strong>(read-only privileges and run jobs privileges) or <strong>Data Owner</strong> (full privileges). Users can be members of (or own) multiple Projects, but inside each project, each member (user) has a unique identity - we call it a <em>project-user identity</em>.&nbsp; For example, user <em>Alice</em> in <em>Project A</em> is different from user <em>Alice </em>in <em>Project B - </em>(in fact, the system-wide (project-user) identities are <strong><em>ProjectA__Alice</em></strong> and <strong><em>ProjectB__Alice</em></strong>, respectively)<em>. </em>As such, each project-user identity is effectively a role with the project-level privileges to access data and run programs inside that project. If a user is a member of multiple projects, she has, in effect, multiple possible roles, but only one role can be active at a time when performing an action inside Hopsworks. When a user performs an action (for example, runs a program) it will be executed with the project-user identity. That is, the action will only have the privileges associated with that project. The figure below illustrates how Alice has a different identity for each of the two projects (A and B) that she is a member of. Each project contains its own separate private assets. Alice can use only one identity at a time which guarantees that she can’t access assets from both projects at the same time.<br></p><figure id="w-node-20ac5438fa1d-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f1058b3943c77358489d4b1_Screenshot%202020-07-16%20at%2015.39.44.png" alt=""></p></figure><p>An <strong>important </strong>aspect of Project based multi-tenancy is that assets can be shared between projects - sharing does not mean that data is duplicated. The current assets that can be shared between projects are: files/directories in HopsFS, Hive databases, feature stores, and Kafka topics. For example, in the figure below there are three users (User1, User2, and User3)&nbsp; and two projects (A and B). User1 is a member of project A, while User2 and User3 are members of project B. All three users (User1, User2, User3) can access the assets shared between project A and project B. As sharing does not mean copying, the access control rules for the asset are updated to give users in the other project read or write permissions on the shared asset.</p><figure id="w-node-7c5391a82675-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f1059150895622a73e57f16_Screenshot%202020-07-16%20at%2015.40.47.png" alt=""></p></figure><p>As we will see later on, <em>project-user identity</em> is based on a X.509 certificate issued internally by Hopsworks. Access control policies, however, are implemented by the platform services:<br></p><ul role="list"><li>files/directories permissions for HopsFS, Hive (storage-based security policy), and the offline Feature Store;</li><li>Kafka ACLs using a <a href="https://github.com/logicalclocks/hops-kafka-authorizer">Hopsworks project-based authorizer plugin</a>;</li><li>Elasticsearch Open Distro permissions using a <a href="https://github.com/logicalclocks/elasticsearch-chef">Hopsworks project-based authorizer plugin</a>.</li></ul><h3>User Identity in Hopsworks</h3><p>When a user authenticates with Hopsworks, they are logged into the platform with a <em>Hopsworks user identity</em>. This user identity is needed to be able to construct the project-user identity - it is the “user” part of the project-user identity. In Hopsworks, a user-identity is mapped to a global Hopsworks role (independent of project membership) - a <strong>normal</strong> user or an <strong>administrator</strong>. A normal user can search for assets, update her profile, generate API keys, and change to/from projects. Administrators have access to user, project, storage, and application management pages, system monitoring and maintenance services. They can activate or block users, delete Projects, manage Project quotas, promote normal users to administrators, and so on. It’s important to mention here that a Hopsworks administrator <strong>cannot</strong> view the data&nbsp; inside a project - even if they are allowed to delete a project.<br></p><p>A user interacts with Hopsworks through the web application and they don’t necessarily realize that the web application is a facade to a modular distributed system. In the background we run <strong>HopsFS</strong> - our next-generation HDFS-on-S3 filesystem, <strong>HopsYARN</strong> - a cluster management system and scheduler, Apache Hive, Elasticsearch, (optionally Kafka and Airflow), and other logging and monitoring services.</p><p>A fundamental principle in every distributed system is that processes exchange messages over the network or through shared state (such as a filesystem or database). When communication is performed by message passing, it is imperative that we protect the messages from adversaries reading or modifying their content and validate the identity of the caller. Traditionally in Hadoop, they use Kerberos and GSSAPI to authenticate and authorize users and encrypt data in-transit. While Kerberos (Active Directory) is widely adopted by big organizations, the administration of users and services is a painful process and the system does not scale. On top of that Kerberos APIs are so complicated that <a href="https://apachebigdata2015.sched.com/event/3zv3/hadoop-and-kerberos-the-madness-beyond-the-gate-steve-loughran-hortonworks">programming against them can be really challenging</a>.</p><p>To avoid the pain of Kerberos (and be able to natively integrate with platforms like Kubernetes), we completely <a href="https://github.com/hopshadoop/hops">re-designed the security model for HopsFS and YARN to use certificates</a>. We replaced Kerberos with Public Key Infrastructure (PKI) with X.509 certificates to authenticate and authorize users. Certificates enabled us to also use the well established TLS protocol to provide confidentiality and data integrity. Every user and every service in a Hopsworks cluster has a private key and an X.509 certificate.</p><figure id="w-node-daa745592959-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f105955f5d5389cb463a175_Screenshot%202020-07-16%20at%2015.42.26.png" alt=""></p></figure><h3>TLS-Based Multi-Tenant Services</h3><p>Hopsworks supports a number of stateful and compute services that use X.509 certificates to authenticate users, applications, and services: HopsFS, HiveServer2, Kafka, YARN. These services all provide their own authorization schemes. We unified HopsFS and Hive’s authorization models by providing 2-way TLS in HiveServer2 and <a href="https://cwiki.apache.org/confluence/display/Hive/Storage+Based+Authorization+in+the+Metastore+Server">storage based authorization for the Hive metastore</a>, that we <a href="https://github.com/logicalclocks/hive">ported to Hive 3.X</a>, to delegate access control decisions for Hive to HopsFS. In Hive, tables and databases store their data files inside directories on HopsFS, so HopsFS&nbsp; ACLs (access control lists) authorize file system operations by Hive (read from tables, write to tables). The easy-to-understand ACLs that we expose in Hopsworks (for Hive, and datasets in HopsFS) are captured in two roles: Data Scientists can read, Data Owners can read/write. HopsFS ACLs can be customized directly in Hopsworks from version 1.4.</p><p>For Kafka, we developed a <a href="https://github.com/logicalclocks/hops-kafka-authorizer">Hopsworks Authorizer plugin</a> that authorizes operations on Kafka topics by extracting the <em>project-user identity </em>from the client supplied X.509 certificate. The Hopsworks Kafka Authorizer then validates that the user is a member of the project that has permissions to perform the requested action on the Kafka topic.&nbsp;</p><p>HopsYARN uses X.509 certificates to identify users. HopsYARN also creates and manages (including renewal) application certificates for YARN applications (such as Spark jobs). Application certificates in HopsYARN are a key feature missing …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks">https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904812</guid>
            <pubDate>Tue, 21 Jul 2020 06:46:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Many Faces of an Undying Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23904104">thread link</a>) | @grugagag
<br/>
July 20, 2020 | http://jakob.space/blog/thoughts-on-lisps.html | <a href="https://web.archive.org/web/*/http://jakob.space/blog/thoughts-on-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>July 20, 2020 ❖ Tags: <a href="http://jakob.space/blog/tag/tag/opinion.html">opinion</a>, <a href="http://jakob.space/blog/tag/tag/programming.html">programming</a>, <a href="http://jakob.space/blog/tag/tag/lisp.html">lisp</a>, <a href="http://jakob.space/blog/tag/tag/common-lisp.html">common-lisp</a>, <a href="http://jakob.space/blog/tag/tag/scheme.html">scheme</a></p><article><p>
This is a post I've been meaning to write for a while now: one anecdotally
comparing programming languages in the Lisp family. I consider myself to be a
Lisp hacker. Perhaps that much was obvious from the letter λ adorning my
website's header, a reference to the λ-calculus which inspired John McCarthy to
design the first LISP [1]. Yet, "Lisp hacker" likely means little unless you,
too, consider yourself to be a Lisp hacker. Calling yourself one seems carry
some level of unstated meaning. Indeed, some identify with more specific groups.
"Schemer," or "Guiler," or "Racketeer," or "Clojurist." But "Lisp Hackers" ⊇
"Schemers". There is commonality shared among all, or at least most, of these
programming languages, and the Lisp hackers recognize and appreciate that
commonality – the characteristics that make a programming language a Lisp.
Homoiconic syntax, powerful metaprogramming facilities, and editor support that,
in my opinion, is unparalleled. (Yes, I am alluding to GNU Emacs.) This article,
however, is concerned with the differences. In it, I will be considering the
specifics of each dialect, and whether or not those specifics make for a
language I would want to use to develop a new piece of software.
</p><p>
I'm specifically concerned with game development at the time of writing this
article. An idea for a turn-based tactics game came to me and I felt a Lisp
would be the best tool for realizing it, but the decision to use "a Lisp" still
leaves me with several choices. When I enumerate the notable design choices
behind each dialect, and talk about the approaches I prefer, my opinions will
be, in some capacity, framed as partial answers to the question of "will I be
able to comfortably use this to write a video game?" As such, there are a few
things I am specifically interested in:
</p><ul>
<li><b>Ergonomics</b>, or "a measure of the friction [one experiences] when trying to get
things done" [2].</li>
<li><b>Expressiveness</b>, or the ease with which code may be understood by a reader.</li>
<li><b>Performance</b>, which is nontrivial to properly quantify [3]. I won't be rigorous
with this; a one-off run with <code>time</code> can give a good idea of the order of
magnitude for execution time.</li>
<li><b>Ease of distribution</b>, which is difficult to define, but with which I associate
platform agnosticism, a runtime that won't bloat my tarballs by several
gigabytes, and a lack of baroque and difficult to obtain dependencies.</li>
<li><b>Ability to interface with other libraries</b>, as I'll want to be able to
draw to the screen, and play sounds, and so on.</li>
</ul><p>
For each dialect, I'm allowing myself to use nonstandard functions. I'm aiming
for an evaluation of the practical aspects of each language, and if you were
writing software, you'd likely be using more than what's included in the R5RS or
ANSI CL standards. Though, if these nonstandard functions are specific to a
single implementation, I will avoid them. SRFI's and QuickLisp are fair game,
but CHICKEN's Eggs are not. Ah, I'm already getting ahead of myself. Yes, I will
be comparing Scheme and Common Lisp. I almost have to – the history of Lisp
tends to be spun as a schism between Common Lisp and Scheme. I will be speaking
of a few others as well. I've mostly chosen dialects for which there exists some
"game engine" type library. For R7RS (CHICKEN), there is <a href="http://alex-charlton.com/projects/Hypergiant/">Hypergiant</a>, for R6RS
(Guile) there is <a href="https://dthompson.us/projects/chickadee.html">Chickadee</a>, for Common Lisp there is <a href="http://www.xelf.me/">Xelf</a>, and for Fennel there
is, of course, <a href="https://love2d.org/">LÖVE</a>.
</p><figure>
<img src="http://jakob.space/static/image/lisp-personality-test.png" alt="lisp-personality-test.png">

<figcaption><span>Figure 1: </span>My take on the drawing in Conrad Barski's <i>Land of Lisp</i>. From left to right: Common Lisp, Scheme, <del>Haskell</del> Fennel.</figcaption>
</figure><p>
What follows are my opinions, so I'd like to lead with the background that
motivated them. My earliest "serious" experience with Lisp was with Peter
Seibel's <i>Practical Common Lisp</i>, which I picked up in high school following a
failed attempt at reading <i>Structure and Interpretation of Computer
Programs</i>.<sup><a id="fnr.1" href="#fn.1">1</a></sup> The portion of the latter book that I did manage was enough to
convince me that learning <span>a</span> Lisp would be valuable, but that learning Common
Lisp may be more tractable than learning Scheme. The summer following my first
year of university, I taught myself Scheme to do <a href="http://summerofcode.withgoogle.com/">GSoC</a> for <a href="https://guix.gnu.org/">GNU Guix</a>. Guile
quickly grew on me, and I soon began <a href="http://jakob.space/blog/transition-to-haunt.html">using Haunt</a> for my personal website. I've
been unknowingly using Emacs Lisp since much earlier – not in the sense of
writing packages – my old man taught me how to use Emacs when I was nine, but I
was <a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Easy-Customization.html">mostly shielded from having to write <code>setq</code> forms</a>. I've also used <a href="https://docs.hylang.org/en/stable/">Hy</a>, <a href="https://fennel-lang.org/">Fennel</a>,
… well, I'm wildly off track now. Point being, I've used many Lisps, and I've
subconsciously acknowledged the differences between them, but never turned that
acknowledgment into coherent thought.
</p><p>
To aid in the comparison, I've written the same raytracer in several dialects of
Lisp. My reasons for choosing a raytracer are that:
</p><ul>
<li>I'm reasonably familiar with how they work.</li>
<li>Performance matters, and differences in performance is noticeable.</li>
<li>It's nontrivial, but several implementations of a raytracer is also more
tractable than, say, several implementations of a high-performance database.</li>
</ul><p>
Another consideration was the number of advancements in raytracing that build
upon the same basic structure, potentially giving me a way to compare the ease
with which a change to a system can be made, but writing these raytracers took
enough out of me that I didn't want to play with them any more.
</p><p>
This was not nearly as telling of a comparison as I had hoped. Once I'd
completed the first raytracer, everything that followed had the same structure.
Regardless, writing these raytracers gave me an idea of the characteristics I
was interested in, especially performance. For anyone who would like to look at
the code, the implementations are available <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo">here</a>.
</p><p>
<b>Table of Contents</b>
</p><ul>
<li><a href="#org9a5541d">The Issue of Rendering an Image</a></li>
<li><a href="#orga8f893b">Scheme</a>
<ul>
<li><a href="#org4538c39">R7RS</a></li>
<li><a href="#org47b9bd9">R6RS</a></li>
<li><a href="#org3eedb31">Conclusions on Scheme</a></li>
</ul></li>
<li><a href="#org9e27a4b">Common Lisp</a>
<ul>
<li><a href="#org0df9ac3">Conclusions on Common Lisp</a></li>
</ul></li>
<li><a href="#org4d7f824">Fennel</a>
<ul>
<li><a href="#org3eb9b83">Conclusions on Fennel</a></li>
</ul></li>
<li><a href="#org0fbbf7a">Lisps I've Neglected</a>
<ul>
<li><a href="#org1bb9256">Emacs Lisp</a></li>
<li><a href="#orga47743c">Gerbil Scheme</a></li>
<li><a href="#orgcca7e64">Racket</a></li>
<li><a href="#org883fd6d">Janet</a></li>
<li><a href="#org965e8ce">Clojure</a></li>
</ul></li>
</ul><div id="outline-container-org9a5541d">
<h2 id="org9a5541d">The Issue of Rendering an Image</h2>
<div id="text-org9a5541d">
<p>
Well, if we're writing a raytracer, then, we had better have some way of seeing
the results. The issue is portability. Ideally, I'd like to be able to run the
raytacers on different implementations of each language, but none of them have
standardized support for drawing graphics. An idea I had was to render the image
to the terminal using ANSI escape sequences, but I thought the resulting images
would be quite shitty. Instead, I decided to go the <a href="https://github.com/ssloy/tinyrenderer/wiki/Lesson-0-getting-started">route that tinyrenderer
takes</a>, which is to output to an image file. Initially, the image format I went
with was the venerable PNG. This was a mistake. Even if it did lead to a rather
elegant CRC procedure in Scheme.
</p>

<div>
<pre>(<span>define</span> (<span>chunk-crc</span> bytes)
  (<span>define</span> (<span>process-byte</span> crc byte)
    (bitwise-xor (vector-ref png-crc (bitwise-and #xff (bitwise-xor crc byte)))
                 (arithmetic-shift crc -8)))
  (reduce process-byte bytes #xffffffff))
</pre>
</div>

<p>
Realizing PNG was needlessly complex, I went on to write a <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo/tree/master/write-bmp.scm">BMP encoder</a>, which
was fine until I came across <a href="https://nullprogram.com/blog/2017/11/03/">an article</a> from Chris Wellons about rendering video
with C by encoding frames as <a href="http://netpbm.sourceforge.net/doc/">Netpbm</a> images. I decided to scrap my BMP encoder
and go with PPM instead. Netpbm is text-based: the issue with a PNG or BMP
encoder in Scheme, for example, is that you're dealing with a binary format.
Glancing over the standards now, it seems there are, indeed, standardized
procedures for dealing with binary data in both R6RS and R7RS. Regardless,
dealing with those binary structures and having to consider endianness is a
pain. PPM is <span>dead</span> simple. In fact, I'd wager that if all you had access to were
the examples on the <a href="https://en.wikipedia.org/wiki/Netpbm">Wikipedia</a> page, you'd be able to write an encoder. Here's
the Scheme implementation:
</p>

<div>
<pre>(<span>define</span> (<span>write-ppm</span> width height pixels)
  <span>"Encode the WIDTH by HEIGHT image given as PIXELS into the portable pixmap</span>
<span>format (PPM), writing the result to `(current-output-port)'."</span>
  (<span>define</span> (<span>delimit-values</span> values)
    (<span>cond</span> ((null? values)
           (newline))
          ((= 1 (length values))
           (display (car values))
           (delimit-values (cdr values)))
          (<span>else</span>
           (display (car values))
           (display <span>" "</span>)
           (delimit-values (cdr values)))))

  
  (delimit-values '(<span>"P3"</span>))

  
  (delimit-values (list width height))

  
  (delimit-values '(<span>"255"</span>))

  
  (<span>for-each</span> delimit-values (vector-&gt;list pixels)))
</pre>
</div>

<p>
If you do away with my nice formatting, that's twelve lines of code, all of
which are R5RS-compatible. We have access to the Netpbm suite, too, so if we
want a PNG, we can always <code>./write-ppm | pnmtopng &gt; test.png</code>. Netpbm is a
real hidden gem. Well, hidden to me, at least.
</p>
</div>
</div><div id="outline-container-orga8f893b">
<h2 id="orga8f893b">Scheme</h2>
<div id="text-orga8f893b">
<p>
If you aren't familiar with Scheme, it has somewhat of a self-imposed<sup><a id="fnr.2" href="#fn.2">2</a></sup>
reputation for appealing to academic types. It's also one of the most
opinionated languages I know of; all the specs of interest lead with an
assertion that "programming languages should be designed not by piling feature
on top of feature, but by removing the weaknesses and restrictions that make
additional features appear necessary." The way that Scheme embraces purity and
simplicity makes it clear it was designed by math nerds. (Hey, I'm a math nerd,
too. Take it easy.)
</p>

<p>
As I've just mentioned, there are specs. A few, to be sure. The evolution of
Scheme standards begins in a linear fashion: RRS → RRRS → R3RS → R4RS → R5RS. I
like to think of this as "classic Scheme". But when it came time to revise R5RS,
the ratification of the subsequent R6RS caused some controversy. It was
"bloated", or whatever. Something like that. So when it came time to design R7RS
(small), the Scheme Language Steering Committee decided to let the language
fork, beginning with the earlier R5RS as a blank slate [4]. That way, the nerds
that hated everything about R6RS could have their way, and the nerds that liked
R6RS could have their way. Scheme was divided, but at peace. Oh, and nowadays
there's a work-in-progress <a href="https://bitbucket.org/cowan/r7rs-wg1-infra/src/default/R7RSHomePage.md">R7RS-large</a>. ಠ_ಠ
</p>

<p>
I'm not going to talk about R7RS-large here. It's just too …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jakob.space/blog/thoughts-on-lisps.html">http://jakob.space/blog/thoughts-on-lisps.html</a></em></p>]]>
            </description>
            <link>http://jakob.space/blog/thoughts-on-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904104</guid>
            <pubDate>Tue, 21 Jul 2020 03:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assessing Abstractions]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23904080">thread link</a>) | @stopachka
<br/>
July 20, 2020 | https://stopa.io/post/245 | <a href="https://web.archive.org/web/*/https://stopa.io/post/245">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Some abstractions are ticking time bombs, while others help you move fast. How can you tell? What follows is my personal exploration for how I assess abstractions.</p><h2>Problem</h2><p>We add abstractions in our programs to solve problems. So, let’s start with the fundamental value proposition: what problem does our abstraction solve? </p><p>Let’s take a look at one example abstraction:</p><pre><code>NLP.parse(...) // =&gt; { intent: "set_alarm", at: "1593538633430" }</code></pre><p>This could be a natural language processing abstraction, which lets us take a piece of text, and extract meaning from it. The inherent problem of natural language processing is pretty darn complex, so an abstraction that helps us solve it would be very valuable. This is a sign of a good abstraction.</p><p>Now let’s compare that to </p><pre><code>StringSplitter.easySplit(str, splitStr)</code></pre><p>Maybe this abstraction, adds a light layer on top of string.split. For example, it may make it so you don’t have to worry about regexes, and can turn common string patterns into regexes. The value of a <code>StringSplitter</code> abstraction is pretty darn low. Maybe  <code>StringSplitter</code> treats <code>splitStr</code> in a way that’s a bit more in-line with the someone’s thinking, but at the end of the day this boils down to an indirection. </p><p>This leads us to the first principle. The more complex the problem it solves for you, the better the abstraction (1).</p><h2>Interface</h2><p>After we’re convinced that the abstraction we are about to add solves a tough problem for us, the next thing to consider is the interface: <em>how</em> do we interact with the abstraction? Imagine if <code>NLP.parse</code> was called like this:</p><pre><code>NLP.parse(lang, text)</code></pre><p>This is a great interface. It’s small. We don’t need to understand any internals. For the main use-case, all we need to do is to provide language and text. Compare that with</p><pre><code>NLP.parse(
  text,
  lang, 
  strategy,
  shouldUseFlagA,
  ...
  shouldUseFlagZ
)</code></pre><p>In order to use this version, we’d need to deeply understand the internals of NLP.parse. This lowers the value of the abstraction, because we need to do more work to solve the same level of complexity. </p><p>This leads us to the second principle: <strong>great abstractions have small interfaces.</strong></p><h2>Breakthrough Cost</h2><p>Now that we have an abstraction with a simple interface that solves a hard problem, we need to ask a possibly fatal question: what happens when we need to break through the abstraction? </p><p>All abstractions are leaky at some point. What will happen when you need the abstraction to behave differently? What will happen when it doesn’t work as you expect? </p><p>For example, for <code>NLP.parse(lang, text)</code>, what if we needed to sort and score the results differently? What if there’s a bug, and we aren’t getting the entity we expect, can we look through and debug?</p><p>Understanding the answer to this, will give us the breakthrough cost. To do this, we need to peak through the code. How is <code>NLP.parse</code> implemented?</p><pre><code>parse(lang, text) { 
  return format(scoreEntities(fetchEntities(lang, text)))
}</code></pre><p>In one solution, it could be composed of other abstractions that we can take advantage of. This is a great sign, because we can reuse the underlying abstractions in cases where we need to do something more complicated. Compare that to </p><pre><code>parse(lang, text) { 
  internalParse(lang, text, flagA, flagB, ...flagZ)
}</code></pre><p>This feels more dangerous. If these flags all head to the same function, it’s a sign that a bunch of different features are complected together. It’s also worrying: what if one of these flags don’t do what you want? you may have to fork the abstraction.</p><p>This leads us to the third principle: <strong>great abstractions are transparent.</strong> I think this principle is the most overlooked. It’s easy to take the productivity win upfront, but if the abstraction you add can’t be changed, and can’t be introspected, it’s very likely to bite you at some point.</p><h2>Generality</h2><p>The final principle is orthogonal to the last three, but maybe it’s the most important. Hardy said <em>there is no permanent place in the world for ugly mathematics —</em> So it is with abstractions. The beauty in math relates to how “general” and “tight” the solution is. I think this parallels well with abstractions. </p><p>If you use an abstraction that is “essentially” simpler, it’s more likely to last, and it’s likely to be more powerful.</p><p>Consider if the abstraction for <code>NLP</code>, was made up of specific algorithms, <em>just</em> for natural language processing. This would still be very valuable, but what would be <em>even more</em> valuable, is if the abstractions that this library was composed of was more general: if the parts that compose it were deep learning abstractions, you could reuse them for other problems.</p><h2>Fin</h2><p>And we reach the end. To pick great abstractions: pick the ones that solve a complex problem for you. Make sure they have a simple interface, and take a look at the internals, so you’re confident you can jig things up if needed. The more general and simple you can get for the same amount of power, the better. </p><p>Want to see some great abstractions in the wild? First, chances are you are using many of them: TCP, higher order functions like map &amp; filter, React. Some you may not have explored: Go’s CSP, Rich Hickey’s Datomic, or his <code>seq</code> abstraction in Clojure. As you pick up abstractions, I encourage you to run each one as an experiment: ask yourself at the end how things went, discuss them with your friends, and soon you’ll develop a much more nuanced taste.</p><p>(1) The rabbit hole gets deeper. Even if an abstraction solves a complex problem you have, you may need to take a step back and also ask: why do I have this problem? For example, kubernetes may be a great solution to building distributed systems, but why do you have a distributed systems problem? Many times the problem itself can be avoided. For the answer to that, <a href="https://stopa.io/post/241" target="_blank">Hacker’s Paradise</a> tries to covers it.</p><p><em>Thanks to Alex Reichert, Daniel Woelfel, Martin Raison, Sean Grove for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/245</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904080</guid>
            <pubDate>Tue, 21 Jul 2020 03:24:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essays on programming I think about a lot]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23903737">thread link</a>) | @jchook
<br/>
July 20, 2020 | https://www.benkuhn.net/progessays/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/progessays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Every so often I read an essay that I end up thinking about, and citing in conversation, over and over again.</p><p>Here’s my index of all the ones of those I can remember! I’ll try to keep it up to date as I think of more.</p><p>(Some of them are extremely well-known. I’m leaving them here anyway just in case you’re one of <a href="https://xkcd.com/1053/" target="_blank">the lucky 10,000</a>.)</p><p>I’m curious what essays are in this category for other folks—post yours in the comments!</p><hr><p><a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>:</p><blockquote><p>I approach software with a deep-seated belief that computers and software systems can be understood. …</p><p>In some ways, this belief feels radical today. Modern software and hardware systems contain almost unimaginable complexity amongst many distinct layers, each building atop each other. …</p><p>In the face of this complexity, it’s easy to assume that there’s just too much to learn, and to adopt the mental shorthand that the systems we work with are best treated as black boxes, not to be understood in any detail.</p><p>I argue against that approach. You will never understand every detail of the implementation of every level on that stack; but you can understand all of them to some level of abstraction, and any specific layer to essentially any depth necessary for any purpose.</p></blockquote><hr><p><a href="https://mcfunley.com/choose-boring-technology" target="_blank">Choose Boring Technology</a>:</p><blockquote><p>Let’s say every company gets about three innovation tokens. You can spend these however you want, but the supply is fixed for a long while. You might get a few more after you achieve a certain level of stability and maturity, but the general tendency is to overestimate the contents of your wallet. Clearly this model is approximate, but I think it helps.</p><p>If you choose to write your website in NodeJS, you just spent one of your innovation tokens. If you choose to use MongoDB, you just spent one of your innovation tokens. If you choose to use service discovery tech that’s existed for a year or less, you just spent one of your innovation tokens. If you choose to write your own database, oh god, you’re in trouble.</p></blockquote><hr><p><a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction" target="_blank">The Wrong Abstraction</a>:</p><blockquote><ol start="4"><li><p>Time passes.</p></li><li><p>A new requirement appears for which the current abstraction is almost perfect.</p></li><li><p>Programmer B gets tasked to implement this requirement.</p><p><em>Programmer B feels honor-bound to retain the existing abstraction, but since isn’t exactly the same for every case, they alter the code to take a parameter….</em></p></li><li><p>… Loop until code becomes incomprehensible.</p></li><li><p>You appear in the story about here, and your life takes a dramatic turn for the worse.</p></li></ol></blockquote><hr><p><a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/" target="_blank">Falsehoods Programmers Believe About Names</a>:</p><blockquote><ol start="32"><li>People’s names are assigned at birth.</li><li>OK, maybe not at birth, but at least pretty close to birth.</li><li>Alright, alright, within a year or so of birth.</li><li>Five years?</li><li>You’re kidding me, right?</li></ol></blockquote><hr><p><a href="https://sockpuppet.org/blog/2015/03/06/the-hiring-post/" target="_blank">The Hiring Post</a>:</p><blockquote><p>Nothing in Alex’s background offered a hint that this would happen. He had Walter White’s resume, but Heisenberg’s aptitude. None of us saw it coming. My name is Thomas Ptacek and I endorse this terrible pun. Alex was the one who nonced.</p><p>A few years ago, Matasano couldn’t have hired Alex, because we relied on interviews and resumes to hire. Then we made some changes, and became a machine that spotted and recruited people like Alex: line of business .NET developers at insurance companies who pulled Rails core CVEs out of their first hour looking at the code. Sysadmins who hardware-reversed assembly firmware for phone chipsets. Epiphany: the talent is out there, but you can’t find it on a resume.</p><p>Our field selects engineers using a process that is worse than reading chicken entrails. Like interviews, poultry intestine has little to tell you about whether to hire someone. But they’re a more pleasant eating experience than a lunch interview.</p></blockquote><hr><p><a href="https://blog.pragmaticengineer.com/the-product-minded-engineer/" target="_blank">The Product-Minded Engineer</a>:</p><blockquote><p>Proactive with product ideas/opinions • Interest in the business, user behavior and data on this • Curiosity and a keen interest in “why?” • Strong communicators and great relationships with non-engineers • Offering product/engineering tradeoffs upfront • Pragmatic handling of edge cases • Quick product validation cycles • End-to-end product feature ownership • Strong product instincts through repeated cycles of learning</p></blockquote><hr><p><a href="https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to" target="_blank">Write code that is easy to delete, not easy to extend</a>:</p><blockquote><p>If we see ‘lines of code’ as ‘lines spent’, then when we delete lines of code, we are lowering the cost of maintenance. Instead of building re-usable software, we should try to build disposable software.</p></blockquote><blockquote><p>Business logic is code characterised by a never ending series of edge cases and quick and dirty hacks. This is fine. I am ok with this. Other styles like ‘game code’, or ‘founder code’ are the same thing: cutting corners to save a considerable amount of time.</p><p>The reason? Sometimes it’s easier to delete one big mistake than try to delete 18 smaller interleaved mistakes. A lot of programming is exploratory, and it’s quicker to get it wrong a few times and iterate than think to get it right first time.</p></blockquote><hr><p><a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a>:</p><blockquote><p>Back to TCP. Earlier for the sake of simplicity I told a little fib, and some of you have steam coming out of your ears by now because this fib is driving you crazy. I said that TCP guarantees that your message will arrive. It doesn’t, actually. If your pet snake has chewed through the network cable leading to your computer, and no IP packets can get through, then TCP can’t do anything about it and your message doesn’t arrive. If you were curt with the system administrators in your company and they punished you by plugging you into an overloaded hub, only some of your IP packets will get through, and TCP will work, but everything will be really slow.</p><p>This is what I call a leaky abstraction. TCP attempts to provide a complete abstraction of an underlying unreliable network, but sometimes, the network leaks through the abstraction and you feel the things that the abstraction can’t quite protect you from. This is but one example of what I’ve dubbed the Law of Leaky Abstractions:</p><p><strong>All non-trivial abstractions, to some degree, are leaky.</strong></p><p>Abstractions fail. Sometimes a little, sometimes a lot. There’s leakage. Things go wrong. It happens all over the place when you have abstractions. Here are some examples.</p></blockquote><hr><p><a href="https://blog.nelhage.com/post/reflections-on-performance/" target="_blank">Reflections on software performance</a>:</p><blockquote><p>It’s probably fairly intuitive that users prefer faster software, and will have a better experience performing a given task if the tools are faster rather than slower.</p><p>What is perhaps less apparent is that having faster tools changes how users use a tool or perform a task. Users almost always have multiple strategies available to pursue a goal — including deciding to work on something else entirely — and they will choose to use faster tools more and more frequently. Fast tools don’t just allow users to accomplish tasks faster; they allow users to accomplish entirely new types of tasks, in entirely new ways. I’ve seen this phenomenon clearly while working on both Sorbet and Livegrep:</p></blockquote><hr><p>Brandur Leach’s series on using databases to ensure correct edge-case behavior: <a href="https://brandur.org/acid" target="_blank">Building Robust Systems with ACID and Constraints</a>, <a href="https://brandur.org/http-transactions" target="_blank">Using Atomic Transactions to Power an Idempotent API</a>, <a href="https://brandur.org/job-drain" target="_blank">Transactionally Staged Job Drains in Postgres</a>, <a href="https://brandur.org/idempotency-keys" target="_blank">Implementing Stripe-like Idempotency Keys in Postgres</a>.</p><blockquote><p>I want to convince you that ACID databases are one of the most important tools in existence for ensuring maintainability and data correctness in big production systems. Lets start by digging into each of their namesake guarantees.</p></blockquote><blockquote><p>There’s a surprising symmetry between an HTTP request and a database’s transaction. Just like the transaction, an HTTP request is a transactional unit of work – it’s got a clear beginning, end, and result. The client generally expects a request to execute atomically and will behave as if it will (although that of course varies based on implementation). Here we’ll look at an example service to see how HTTP requests and transactions apply nicely to one another.</p></blockquote><blockquote><p>In APIs <em>idempotency</em> is a powerful concept. An idempotent endpoint is one that can be called any number of times while guaranteeing that the side effects will occur only once. In a messy world where clients and servers that may occasionally crash or have their connections drop partway through a request, it’s a huge help in making systems more robust to failure. Clients that are uncertain whether a request succeeded or failed can simply keep retrying it until they get a definitive response.</p></blockquote><hr><p><a href="https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/" target="_blank">Notes on Distributed Systems for Young Bloods</a>:</p><blockquote><p>Distributed systems are different because they fail often • Implement backpressure throughout your system • Find ways to be partially available • Use percentiles, not averages • Learn to estimate your capacity • Feature flags are how infrastructure is rolled out • Choose id spaces wisely • Writing cached data back to persistent storage is bad • Extract services.</p></blockquote><hr><p><a href="http://web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf" target="_blank">End-to-End Arguments in System Design</a>:</p><blockquote><p>This paper presents a design principle that helps guide placement of functions among the modules of a distributed computer system. The principle, called the end-to-end argument, suggests that functions placed at low levels of a system may be redundant or of little value when compared with the cost of providing them at that low level. Examples discussed in the paper include bit error recovery, security using encryption, duplicate message suppression, recovery from system crashes, and delivery acknowledgement. Low level mechanisms to support these functions are justified only as performance enhancements.</p></blockquote><hr><p><a href="https://vimeo.com/36579366" target="_blank">Inventing on Principle</a>:</p><blockquote><p>I’ve spent a lot of time over the years making creative tools, using creative tools, thinking about them a lot, and here’s something I’ve come to believe: Creators need an immediate connection to what they’re creating.</p></blockquote><p>I can’t really excerpt any of the actual demos, which are the good part. Instead I’ll just endorse it: this talk dramatically, and productively, raised my bar for what I think programming tools (and tools in general) can be. Watch it and be amazed.</p><hr><p>Post the essays you keep returning to in the comments!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/progessays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903737</guid>
            <pubDate>Tue, 21 Jul 2020 02:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Strong Opinions, Weakly Held’ Doesn't Work That Well]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 120 (<a href="https://news.ycombinator.com/item?id=23903172">thread link</a>) | @shadowsun7
<br/>
July 20, 2020 | https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>There’s a famous thinking framework by ‘futurist’, ‘forecaster’, and scenario consultant Paul Saffo called ‘strong opinions, weakly held’. The phrase itself became popular in tech circles in the 2010s — I remember reading about it on Hacker News or a16z.com or one of those thinky tech blogs around the period. It’s still rather popular today.</p><p>Saffo’s framework — laid out in his original <a href="https://www.saffo.com/02008/07/26/strong-opinions-weakly-held/">2008 blog post</a> — goes like this:</p><blockquote>I have found that the fastest way to an effective forecast is often through a sequence of lousy forecasts. Instead of withholding judgment until an exhaustive search for data is complete, I will force myself to make a tentative forecast based on the information available, and then systematically tear it apart, using the insights gained to guide my search for further indicators and information. Iterate the process a few times, and it is surprising how quickly one can get to a useful forecast.<p>Since the mid-1980s, my mantra for this process is “strong opinions, weakly held.” Allow your intuition to guide you to a conclusion, no matter how imperfect — this is the “strong opinion” part. Then – and this is the “weakly held” part – prove yourself wrong. Engage in creative doubt. Look for information that doesn’t fit, or indicators that pointing in an entirely different direction. Eventually your intuition will kick in and a new hypothesis will emerge out of the rubble, ready to be ruthlessly torn apart once again. You will be surprised by how quickly the sequence of faulty forecasts will deliver you to a useful result.</p><p>This process is equally useful for evaluating an already-final forecast in the face of new information. It sensitizes one to the weak signals of changes coming over the horizon and keeps the hapless forecaster from becoming so attached to their model that reality intrudes too late to make a difference.</p><p>More generally, “strong opinions weakly held” is often a useful default perspective to adopt in the face of any issue fraught with high levels of uncertainty, whether one is venturing a forecast or not. Try it at a cocktail party the next time a controversial topic comes up; it is an elegant way to discover new insights — and duck that tedious bore who loudly knows nothing but won’t change their mind!</p></blockquote><p>On the face of it, it all sounds very reasonable and smart. And ‘strong opinions weakly held’ is such a catchy phrase — which probably explains its popularity.</p><p>The only problem with it is that it doesn’t seem to work that well.</p><h2 id="swimming-upstream-against-the-architecture-of-the-mind">Swimming Upstream Against the Architecture Of The Mind</h2><p>How do I know that it doesn’t work that well? I know this because I’ve tried. I tried to use Saffo’s framework in the years between 2013 and 2016, and when I was running my previous company I attempted it with my boss, whenever we convened to <a href="https://commoncog.com/blog/what-uncertainty-feels-like/">discuss company strategy</a>.</p><p>Eventually I read Phillip Tetlock’s <a href="https://commoncog.com/blog/the-forecasting-series/"><em>Superforecasting</em></a>, and then I gave up on ‘Strong Opinions, Weakly Held’.</p><p>Why does the framework not work very well? From experience, Saffo’s approach fails in two ways.</p><p>The first way is if the person <em>hasn’t</em> read Saffo’s original post. This is, to be fair, most of us — Saffo’s original idea is so quotable it has turned into a memetic phenomenon, and I’ve seen it cited in fields far outside tech. In such cases, the failure mode is that ‘Strong Opinions, Weakly Held’ turns into ‘Strong Opinions, Justified Loudly, Until Evidence Indicates Otherwise, At Which Point You Invoke It To Protect Your Ass.’</p><p>In simpler terms, ‘strong opinions, weakly held’ sometimes becomes a license to hold on to a bad opinion strongly, with downside protection, against the spirit and intent of Saffo’s original framework.</p><p>Now, you might say that this is through no fault of Saffo’s, and is instead the problem of popularity. But my response is that if an idea has certain affordances, and people seem to always grab onto those affordances and abuse the idea in the exact same ways, then <em>perhaps you shouldn’t use the idea in the first place.</em> This is especially true — as we’re about to see — if there are better ideas out there.</p><p>The second form of failure is if the person has taken the time to look up the original intention of the phrase. In this situation, the failure mode is when you attempt to integrate new information into your judgment. Saffo’s framework offers no way for us to do this.</p><p>Here’s an example. Let’s say that you’ve decided, along with your boss, to build a particular type of product for a particular subsection of the self-service checkout market. You both come to the opinion that this subsection is the best entry-point to the industry: it is relatively lucrative, and you think that it is the easiest customer segment to service.</p><p>What happens to your opinion when you <em>slowly</em> discover that the subsegment is overcrowded? Of course, you don’t find out immediately — what happens instead is that you spot little hints, spread over the course of a couple of months, that many competitors are entering the market at the same time. These are tiny things like competitor brochures lying in the corner table of a client’s office, or pronouncements by industry groups that “they are looking to engage vendors for large deployments”, and then much later, clearer evidence in the form of increased competition in deals.</p><p>“Well,” I can hear you say, “‘Strong opinions weakly held’ means that you should change your opinion when you encounter these tiny hints!”</p><p>But at which point do you change your mind? At which point do you switch away from your strong opinion? At which point do you think that it’s time to reconsider your approach?</p><p>The problem, of course, is that <em>this is not how the human brain works.</em></p><p>Both forms of failure stem from the same tension. It’s easy to have strong opinions and hold on to them strongly. It’s easy to have weak opinions and hold on to them weakly. But it is quite difficult for the human mind to vacillate between one strong opinion to another.</p><p>I don’t mean to say that people <em>can’t</em> do this — only that it is very difficult to do so. For instance, Steve Jobs was famous for arguing against one position or another, only to decide that you were right, and then come back a month later holding exactly your opinion, as if it were his all along.</p><p>But most people aren’t like Jobs. Psychologist Amos Tversky used to joke that by default, human brains fall back to “yes I believe that, no I don’t believe that, and maybe” — a three-dial setting when it comes to uncertainty. People then hold on to their opinion for as long as their internal narratives allow them to. Saffo’s thinking framework implies that you sit in ‘yes I believe that’ territory, and then rapidly switch away to ‘maybe’ or to ‘no’, depending on the information you receive.</p><p>Perhaps you may — like Jobs! — be able to do this. But if you are like most people, the attempt will feel a lot like whiplash.</p><p>So, you might ask, what to do instead?</p><h2 id="use-probability-as-an-expression-of-confidence">Use Probability as an Expression of Confidence</h2><p>The gentler answer lies in <em>Superforecasting.</em> In the book, Tetlock presents an analytical framework that is easier to use than Saffo’s, while achieving many of the same goals.</p><ol><li>When forming an opinion, phrase it in a way that is very clear, and may be verified by a particular date.</li><li>Then state the probability you are confident that it is correct.</li></ol><p>For instance, you may say “I believe that Tesla will go bankrupt by 31 December 2021, and I am about 76% confident that this is the case.” Or you can be slightly sloppier with the technique — with my boss, I would say: “I think this subsegment is a good market to enter, and I think we would know if this is true within four months. I believe this on the order of 70% ish. Let’s check back in September.”</p><p>(My boss was an ex-investment banker, so he took to this like a duck to water.)</p><p>Tetlock’s stated technique was developed in the context of a geopolitical forecasting tournament called the Good Judgment Project. In 2016, when I read <em>Superforecasting</em> for the first time, I remember thinking that geopolitical forecasting wasn’t particularly relevant to my job running an engineering office in Vietnam. But I also glommed onto the book’s <a href="https://commoncog.com/blog/how-the-superforecasters-do-it/">ideas around analysis</a>, because it was too attractive to ignore.</p><p>The truth is that Tetlock’s ideas are not unique to his research group. Annie Duke’s <em><a href="https://www.goodreads.com/book/show/35957157-thinking-in-bets">Thinking in Bets</a></em> proposes the same approach, but drawn from poker, and the ‘rationalist’ community <a href="https://www.lesswrong.com/">LessWrong</a> has long-held norms around stating the confidence of their opinions.</p><p>More importantly, Duke and LessWrong have both discovered that the <em>fastest</em> way to provoke such nuanced thinking is to ask: “Are you willing to bet on that? What odds would you take, and how much?”</p><p>You’d be surprised by how effective this question is.</p><p>Why is it so effective? Why does it succeed where ‘Strong Opinions, Weakly Held’ does not?</p><p>The answer lies in the ‘strong opinion’ portion of the phrase. First: by forcing you to state your opinion as a probability judgment — that is, a percentage — you are forced to calibrate the strength of your belief. This makes it easier to move away from it. In other words, you are forced to let go of the ‘yes, no, maybe’ dial in your head.</p><p>Second: by framing it as a bet, you suddenly have skin in the game, and are motivated to get things right.</p><p>Of course, you don’t actually <em>have</em> to bet — you can merely propose the bet as a thinking frame. Later, as new information trickles in, you are allowed to update the % confidence you have in your belief. This allows you to see the world in shades of grey; it also allows you to communicate that confidence to those around you.</p><h2 id="revisiting-the-hierarchy-of-practical-evidence">Revisiting The Hierarchy of Practical Evidence</h2><p>I have one final point to make about this approach.</p><p>Long term readers of this blog would know that my shtick is “apply a technique to my career or to my life, over the period of a couple of months, and report on its efficacy.” Over time, I’ve noticed that techniques are more likely to be effective when they come from believable practitioners. This is what led to my <a href="https://commoncog.com/blog/the-hierarchy-of-practical-evidence/">Hierarchy of Practical Evidence</a>.</p><p>Saffo’s and Tetlock’s …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903172</guid>
            <pubDate>Tue, 21 Jul 2020 00:08:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Architectures for a Responsive IDE]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23903131">thread link</a>) | @ubolonton_
<br/>
July 20, 2020 | https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The first architecture is reminiscent of the map-reduce paradigm.
The idea is to split analysis into relatively simple indexing phase, and a separate full analysis phase.</p>
<p>The core constraint of indexing is that it runs on a per-file basis.
The indexer takes the text of a single file, parses it, and spits out some data about the file.
The indexer can’t touch other files.</p>
<p>Full analysis can read other files, and it leverages information from the index to save work.</p>
<p>This all sounds way too abstract, so let’s look at a specific example — Java.
In Java, each file starts with a package declaration.
The indexer concatenates the name of the package with a class name to get a fully-qualified name (FQN).
It also collects the set of methods declared in the class, the list of superclasses and interfaces, etc.</p>
<p>Per-file data is merged into an index which maps FQNs to classes.
Note that constructing this mapping is an embarrassingly parallel task — all files are parsed independently.
Moreover, this map is cheap to update.
When a file change arrives, this file’s contribution from the index is removed, the text of the file is changed and the indexer runs on the new text and adds the new contributions.
The amount of work to do is proportional to the number of changed files, and is independent from the total number of files.</p>
<p>Let’s see how FQN index can be used to quickly provide completion.</p>
<div>
<div>
<pre><code data-lang="java"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre><span>// File ./mypackage/Foo.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>import</span> <span>java.util.*</span><span>;</span>

<span>public</span> <span>class</span> <span>Foo</span> <span>{</span>
    <span>public</span> <span>static</span> <span>Bar</span> <span>f</span><span>()</span> <span>{</span>
        <span>return</span> <span>new</span> <span>Bar</span><span>();</span>
    <span>}</span>
<span>}</span>

<span>// File ./mypackage/Bar.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>public</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>public</span> <span>void</span> <span>g</span><span>()</span> <span>{}</span>
<span>}</span>

<span>// File ./Main.java</span>
<span>import</span> <span>mypackage.Foo</span><span>;</span>

<span>public</span> <span>class</span> <span>Main</span> <span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
        <span>Foo</span><span>.</span><span>f</span><span>().</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The user has just typed <code>Foo.f().</code>, and we need to figure out that the type of receiver expression is <code>Bar</code>, and suggest <code>g</code> as a completion.</p>
<p>First, as the file <code>Main.java</code> is modified, we run the indexer on this single file.
Nothing has changed (the file still contains the class <code>Main</code> with a static <code>main</code> method), so we don’t need to update the FQN index.</p>
<p>Next, we need to resolve the name <code>Foo</code>.
We parse the file, notice an <code>import</code> and look up <code>mypackage.Foo</code> in the FQN index.
In the index, we also find that <code>Foo</code> has a static method <code>f</code>, so we resolve the call as well.
The index also stores the return type of <code>f</code>, but, and this is crucial, it stores it as a string <code>"Bar"</code>, and not as a direct reference to the class <code>Bar</code>.</p>
<p>The reason for that is <code>import java.util.*</code> in <code>Foo.java</code>.
<code>Bar</code> can refer either to <code>java.util.Bar</code> or to <code>mypackage.Bar</code>.
The indexer doesn’t know which one, because it can look <strong>only</strong> at the text of <code>Foo.java</code>.
In other words, while the index does store the return types of methods, it stores them in an unresolved form.</p>
<p>The next step is to resolve the identifier <code>Bar</code> in the context of <code>Foo.java</code>.
This uses the FQN index, and lands in the class <code>mypackage.Bar</code>.
There the desired method <code>g</code> is found.</p>
<p>Altogether, only three files were touched during completion.
The FQN index allowed us to completely ignore all the other files in the project.</p>
<p>One problem with the approach described thus far is that resolving types from the index requires a non-trivial amount of work.
This work might be duplicated if, for example, <code>Foo.f</code> is called several times.
The fix is to add a cache.
Name resolution results are memoized, so that the cost is paid only once.
The cache is blown away completely on any change — with an index, reconstructing the cache is not that costly.</p>
<p>To sum up, the first approach works like this:</p>
<div>
<ol>
<li>
<p>Each file is being indexed, independently and in parallel, producing a "stub" — a set of visible top-level declarations, with unresolved types.</p>
</li>
<li>
<p>All stubs are merged into a single index data structure.</p>
</li>
<li>
<p>Name resolution and type inference work primarily off the stubs.</p>
</li>
<li>
<p>Name resolution is lazy (we only resolve a type from the stub when we need it) and memoized (each type is resolved only once).</p>
</li>
<li>
<p>The caches are completely invalidated on every change</p>
</li>
<li>
<p>The index is updated incrementally:</p>
<div>
<ul>
<li>
<p>if the edit doesn’t change the file’s stub, no change to the index is required.</p>
</li>
<li>
<p>otherwise, old keys are removed and new keys are added</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<p>Note an interesting interplay between "dumb" indexes which can be updated incrementally, and "smart" caches, which are re-computed from scratch.</p>
<p>This approach combines simplicity and stellar performance.
The bulk of work is the indexing phase, and you can parallelize and even distribute it across several machine.
Two examples of this architecture are <a href="https://www.jetbrains.com/idea/">IntelliJ</a> and <a href="https://sorbet.org/">Sorbet</a>.</p>
<p>The main drawback of this approach is that it works only when it works — not every language has a well-defined FQN concept.
I think overall it’s a good idea to design name resolution and module systems (mostly boring parts of a language) such that they work well with the map-reduce paradigm.</p>
<div>
<ul>
<li>
<p>Require <code>package</code> declarations or infer them from the file-system layout</p>
</li>
<li>
<p>Forbid meta-programming facilities which add new top-level declarations, or restrict them in such way that they can be used by the indexer.
For example, preprocessor-like compiler plugins that access a single file at a time might be fine.</p>
</li>
<li>
<p>Make sure that each source element corresponds to a single semantic element.
For example, if the language supports conditional compilation, make sure that it works during name resolution (like Kotlin’s <a href="https://kotlinlang.org/docs/reference/platform-specific-declarations.html">expect/actual</a>) and not during parsing (like conditional compilation in most other languages).
Otherwise, you’d have to index the same file with different conditional compilation settings, and that is messy.</p>
</li>
<li>
<p>Make sure that FQNs are enough for most of the name resolution.</p>
</li>
</ul>
</div>
<p>The last point is worth elaborating. Let’s look at the following Rust example:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>// File: ./foo.rs</span>
<span>trait</span> <span>T</span> <span>{</span>
    <span>fn</span> <span>f</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{}</span>
<span>}</span>
<span>// File: ./bar.rs</span>
<span>struct</span> <span>S</span><span>;</span>

<span>// File: ./somewhere/else.rs</span>
<span>impl</span> <span>T</span> <span>for</span> <span>S</span> <span>{}</span>

<span>// File: ./main.s</span>
<span>use</span> <span>foo</span><span>::</span><span>T</span><span>;</span>
<span>use</span> <span>bar</span><span>::</span><span>S</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>s</span> <span>=</span> <span>S</span><span>;</span>
    <span>s</span><span>.f</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Here, we can easily find the <code>S</code> struct and the <code>T</code> trait (as they are imported directly).
However, to make sure that <code>s.f</code> indeed refers to <code>f</code> from <code>T</code>, we also need to find the corresponding <code>impl</code>, and that can be roughly anywhere!</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903131</guid>
            <pubDate>Mon, 20 Jul 2020 23:59:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Certificate Transparency: a bird's-eye view]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23902730">thread link</a>) | @fanf2
<br/>
July 20, 2020 | https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Certificate Transparency (CT) is a still-evolving technology for detecting
incorrectly issued certificates on the web. It’s cool and interesting, but
complicated. I’ve given talks about CT, I’ve worked on Chrome’s CT
implementation, and I’m actively involved in tackling ongoing deployment
challenges – even so, I still sometimes lose track of how the pieces fit
together. I find it easy to forget how the system defends against particular
attacks, or what the purpose of some particular mechanism is.</p>

<p>The goal of this post is to build up a high-level description of CT from
scratch, explaining why all the pieces are the way they are and how they fit
together. A lot of this material is drawn from a
<a href="https://web.stanford.edu/class/cs253/lectures/Lecture%2012.pdf">guest lecture</a>
I gave with my colleague <a href="http://noncombatant.org/">Chris Palmer</a> as part of a
Stanford web security course (CT portion starts at slide 52).</p>

<h2 id="why-ct">Why CT?</h2>

<p>Certificate authorities (CAs) are the organizations that browsers trust to issue
certificates for domain names after checking that the person receiving the
certificate really does own their domain. CAs can be companies and governments
or the occasional non-profit. It’s fairly common for CAs to issue bad
certificates. Like any organization, sometimes CAs make mistakes, and sometimes
they are compromised or malicious. And sometimes certificates are issued
improperly without the CA doing anything wrong at all: a rogue insider, BGP
hijacker, or hapless vendor might request a certificate for a domain they do not
own.</p>

<p>The security community has invented various mechanisms to prevent browsers from
accepting these “misissued” certificates. For example, server operators could
once use
<a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">public key pinning</a> to
limit the CAs that could issue certificates for their domains, so that not just
any CA compromise would put them at risk. (Unfortunately, pinning turned out to
be a giant footgun, never gained widespread adoption, and is currently dying a
slow death.)</p>

<p>Preventing browsers from accepting misissued certificates is only one part of
the puzzle, though. It’s also important to detect misissued certificates. For
example, in 2011, an attacker hacked the
<a href="https://en.wikipedia.org/wiki/DigiNotar#Issuance_of_fraudulent_certificates">DigiNotar</a>
CA and improperly issued a wildcard google.com certificate, which they used to
target victims in Iran. While the Google Chrome browser didn’t accept the
certificate due to public key pinning, Google only
<a href="https://slate.com/technology/2016/12/how-the-2011-hack-of-diginotar-changed-the-internets-infrastructure.html">found out</a>
about the attack by chance because a user posted about the error on a help
forum. This was a close call: would anyone have ever learned about this attack
if that one user hadn’t happened to report it?</p>

<p>Thus was born the desire for a technical means of detecting misissued
certificates. If a domain owner can detect an unauthorized certificate for their
domain, they can revoke<sup id="fnref:1"><a href="#fn:1">1</a></sup> the misissued certificate. If the misissuance happened
because a CA misbehaved, the domain owner can report the incident to a browser
or OS vendor, who might choose to no longer trust the CA to issue certificates.</p>

<p>An unauthorized certificate for a domain isn’t the only type of misissuance. CAs
might create certificates that are bad because they use outdated cryptographic
algorithms, violate rules like the maximum lifetime of a certificate or specific
encodings that are supposed to be used, etc. If browser vendors could detect
these types of misissuances (which are not necessarily malicious, but signs of
bad hygiene), they could ask the CAs to fix these problems or even remove trust
in them if appropriate.</p>

<h2 id="a-strawperson-and-a-slightly-less-strawperson">A strawperson and a slightly-less-strawperson</h2>

<p>The very simplest attempt to allow detection of bad certificates would be to
require that CAs publish a list of every certificate they issue. They could
either directly publish their certificates themselves, or forward them to some
other service that publishes them. Domain owners could monitor every CA’s
published certificates for unauthorized certificates, and browser
vendors/researchers/etc. could monitor each CA for bad hygiene.</p>

<p>But the root problem we are trying to solve is that CAs might be compromised,
malicious, or error-prone, so we can’t just rely on CAs to publish their own
issuances. An evil CA issuing an evil certificate would simply not publish that
certificate.</p>

<p>In a slightly more robust system, CAs could submit each issued certificate to a
publisher. The publisher would return a signature on the certificate, and
provide a publicly accessible feed of certificates that it has seen. Browsers
would only accept certificates that come with a signature from a trusted
publisher. This is a little closer to what CT looks like, but there are still a
number of problems to solve.</p>

<h2 id="signed-certificate-timestamps">Signed Certificate Timestamps</h2>

<p>One minor wrinkle with this publisher signature system is that it takes time for
the CA to submit each certificate to these publishers and verify that it got
logged before issuing the certificate. (As will become clear later on, logging a
certificate can require operations on a large data structure and global write
consensus, which can take minutes or hours.) CAs don’t want other services’
potentially slow operations in the critical path of certificate issuance, which
is their core money-making business operation – and their customers don’t want
this slowdown either, since some web servers rely on fast certificate issuance
to meet business and uptime requirements. So in CT, a signature from one of
these publishers (which is called a CT log) does not actually guarantee that the
log has published the certificate. Instead, the log issues a Signed Certificate
Timestamp (SCT), which is a signed statement that the log has seen the
certificate and promises to publish it within 24 hours of the timestamp it
provides.</p>

<h2 id="trusted-logs"><em>Trusted</em> logs?</h2>

<p>So far, the system we’ve built up is as follows: CAs submit certificates to logs
as they are issued, and the logs return SCTs promising to publish the
certificate within 24 hours. Browsers don’t accept certificates unless they come
with SCTs from trusted logs. Interested parties, such as domain owners or
researchers, can monitor the data that the logs publish for malicious
certificates.</p>

<p>Now the key question is: why should we trust logs? If a CA could be compromised,
malicious, or error-prone, why couldn’t a log be compromised, malicious, or
error-prone too? One could even imagine a log and CA colluding to issue evil
certificates. The designers of CT wanted logs to be untrusted, and this is how
CT gets complicated.</p>

<p>As a simple way to remove trust from the logs, browsers could require multiple
SCTs from different logs per certificate. With this policy, an attacker would
have to compromise multiple logs to prevent an evil certificate from being
published by any of them. In practice, though, it’s difficult to say what
constitutes distinct logs. If the same organization controls multiple logs and
is colluding with the attacker, a multiple-log policy doesn’t help. Chrome
currently deploys CT with a “One Google, One Non-Google” policy: each
certificate must come with at least one SCT from a Google-operated log and one
from a non-Google-operated log, on the premise that it would be difficult for an
attacker to compromise two such logs. This policy, however, was always meant as
a temporary measure until something more technically sound and organizationally
neutral could be put into place.</p>

<p>To understand how to remove trust from the logs in a more technically sound way,
we need to think about a deep question: what does it actually technically mean
to “publish” a certificate? Each log has an API endpoint that produces a feed of
certificates – but, intuitively, providing the certificate on that endpoint to
one client at one particular point in time is not sufficient to have “published”
the certificate. To truly publish the certificate, that endpoint must provide
the certificate to anyone querying it at any time after the log signed an SCT
for the certificate. To verify that the log has truly published the certificate,
we need everyone to efficiently check with everyone else that they’ve seen the
certificate in the feed they’ve received from that endpoint. “Everyone” here
includes end-user devices that are validating TLS certificates, as well as
researchers, browser vendors, domain owners, and anyone else who is interested
in monitoring a log’s feed to look for misissued certificates.</p>

<p>Of course, it’s not practical to ask everyone to maintain the list of all
certificates that each log publishes and check with each other to compare that
the entire sequence matches. That could be billions of devices each maintaining
sets of millions or billions of certificates. Furthermore, some of these
entities might be interested in only a very small subset of certificates; for
example, a domain owner is only interested in monitoring for misissued
certificates for their own domain, and has no interest in doing a lot of work to
help other entities verify that unrelated certificates were properly published.</p>

<p>Imagine that the log could produce a short summary of the sequence of
certificates that it has published. The summary is like a cryptographic hash: if
you can provide a sequence of certificates that produces a given summary, then
it’s infeasible to find any other sequence that produces the same summary.
Unlike a vanilla cryptographic hash, these summaries have two special
properties:</p>

<ol>
  <li>If the log produces a summary, it can then add more certificates and produce
an updated summary, and efficiently prove that these two summaries are
consistent with each other, i.e. the latter summary’s underlying sequence of
certificates is a supersequence of the former’s.</li>
  <li>After adding a certificate, when asked for a current summary of the
certificates it has published, the log can provide an efficient proof that
the summary contains that certificate.</li>
</ol>

<p>This magical summary is all the state that anyone observing the log needs to
keep to be able to verify with everyone else that the certificates they care
about have been published. For example, a web browser validating a TLS
certificate can request a summary and a proof …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html">https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html</a></em></p>]]>
            </description>
            <link>https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902730</guid>
            <pubDate>Mon, 20 Jul 2020 22:51:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maximum Entropy Intuition for Fundamental Statistical Distributions]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23902712">thread link</a>) | @yetanothermonk
<br/>
July 20, 2020 | https://longintuition.com/2020/07/20/max-entropy-intuition.html | <a href="https://web.archive.org/web/*/https://longintuition.com/2020/07/20/max-entropy-intuition.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Imagine you wake up tomorrow in an empty white room, <em>a la</em> The Matrix. You don’t remember how you got there. <em>Anything can happen.</em></p>

<ul>
  <li>If Keanu Reeves appears, you’d probably think this is related in some way to the Matrix.
    <ul>
      <li>If Keanu appears and then Laurence Fishburne (Morpheus) appears, you’d think—okay, this is almost definitely related to the Matrix.</li>
    </ul>
  </li>
  <li>On the other hand, if Obama and Clinton appear in your white room, in your head, you’d think, okay, the Matrix-related possibilities are less likely; the politics-related possibilities are more likely, whatever those are.</li>
</ul>

<p>For the first few seconds in that empty white room, without knowing anything, everything is pretty much equally likely to us. In statistics, we call this a <strong>uniform distribution</strong>. It’s a good starting point when we know nothing. However, once we get new information, we shift probability mass from the less likely events to the more likely events, conditional on what we’ve just learned—in the Neo case, from Obama/Clinton related probabilities to Matrix-related probabilities; in the Obama/Clinton case, from Matrix-related probabilities to political event-related probabilities.</p>

<p>Often, in statistics education, we learn distributions in a vacuum of intuition. But, inevitably, we ask ourselves:</p>

<ul>
  <li>Why do we use the statistical distributions we use? For example, why is the Normal Distribution everywhere?</li>
</ul>

<p>We’ll find that statistical distributions aren’t pulled out of thin air. The statistical distributions we’re most familiar with—uniform, exponential, Normal—are exactly determined when we want to maximize our information gain from very simple and very few initial constraints.</p>

<p>We’ll find that we can use our intuition from the Matrix example to help us understand where these statistical distributions come from!</p>



<p>First, we need some intuition as to what expected information gain means.</p>

<p>Let’s start with the commonplace notion of an “average”. The average, in mathematical terms, is a sum of the value of each event weighted by the probability of that event occurring.</p>

<p>For example, if we have a rigged die with a heavy “six” side, we would expect the next value to be higher than the next value if we used a fair die. The higher frequency of occurrence of sixes pulls up the <strong>expected value</strong> (also known as the <strong>average</strong>, <strong>mean</strong>, or <strong>mathematical expectation</strong>).</p>

<p>Mathematically, what happens is we weigh the value of each event by the probability of that event occurring, and the sum gets us a rough idea of where the next numerical value will land.</p><p>

\[\text{mathematical expectation} = p(x) \cdot x \text{ for all } x \\ = \sum_i p(x_i) * x_i\]

</p><p>This basic concept of weighing things by the probability of those things occurring is a very useful concept. We can also weigh the <em>information gain</em> of an event occurring by the probability of that event occurring to get an expected information value across all the events we care about. But how do we measure information gain?</p>

<p>Intuitively we know that the more surprising something is, the more information it contains. In other words, <em>the informational value of an event is proportional to all the choices it killed off by virtue of that event occurring</em>.</p>

<p>The information value of an event is related to how much probability mass it moves versus itself once that thing occurs.</p>

<h2 id="leverage-can-be-surprising">Leverage Can Be Surprising</h2>

<p>One interesting way to think about this is leverage. Roughly, leverage means how much mass you move versus your own mass. In financial markets, if you outlay $1 million for $5 million of exposure, you’re levered 5 times. For our purposes, we want a good way to formalize our intuitional understanding of information; I haven’t seen information talked about in leverage terms elsewhere and I think it’s an… informative way to look at things.</p><p>

\[\text{leverage} \propto \frac{\text{exposure controlled}}{\text{initial outlay}}\]

</p><p>When we talk about “how much probability mass an event moves” or the amount of choices an event kills by virtue of its occurrence, this is in some sense a leverage ratio. What this looks like is the total amount of probability (normalized, we say 1, but it could just as well be some arbitrary sum, like 10000) divided by the probability of that particular event (p). The 10,000 factor cancels out when we divide the total by the individual probability, so we just get</p><p>

\[\text{info} \propto \frac{1}{p}\]

</p><p>Binary is, in a sense, the ultimate form of compression. Boiling things down to the most informative, basic essence of truth or falsity is a beautiful feature of a bit. We can count the number of bits needed to represent a value by taking its logarithm, base two, so we get</p><p>

\[\text{info} \propto \log_2{\frac{1}{p}}\]

</p><p>And if we weigh this by the probability of that particular event happening, we get</p><p>

\[\text{info} \propto p \cdot \log_2{\frac{1}{p}}\]

</p><p>And if we use the simplified version, we get</p><p>

\[\text{info} = p \cdot \log_2{\frac{1}{p}} \\ = p \cdot (\log_21 - \log_2p) \\ =-p \cdot \log_2p\]

</p><p>Awesome! We’ve built the definition of informational entropy from nothing other than a… bit… of intuition. Similar to our understanding for the mathematical expected value of a set of events, we can talk about the mathematical expected information for a set of events.</p><p>

\[\text{mathematical information expectation} = \sum_i -p(x_i) * \log_2{p(x_i)}\]

</p><p>Why is this useful? It turns out that the major statistical distributions maximize the expected information gain subject to certain constraints (each major distribution corresponding to different constraints).</p>

<p>Stated in a different way:</p>

<p>Take that our goal is to model the probability distribution for data we’re looking at.</p>

<p>We generally know a few things about the data—these will be our constraints—and we want to pick the probability distribution that maximizes our expected information gain (aka, maximizes our subsequent surprise, or <strong>entropy</strong>)—because if we had a distribution that had any less expected information gain than **the maximum entropy distribution, we’ve inadvertently encoded some information extra to our constraints into our distribution.</p>

<p>So the maximum entropy distribution is the closest thing we can get to a zero-knowledge guess, subject to what we know about the data (our constraints).</p>



<p>We found at the beginning of our journey that the uniform distribution—where we prescribe to each event an equal amount of probability mass—makes intuitive sense as the distribution we should pick when we don’t know anything at all. This isn’t saying that everything in reality has equal probability of occurring—a bit subtle; it’s just saying that, <em>given what we currently know</em> (assumed to be nothing), no one event is more likely than any other event.</p>

<p>What if we work from the mathematical end? What do we find if we just start out with very few, very basic assumptions and work forward?</p><p>

\[\text{information, the quantity we want to maximize: } \\ f(x)=-\int_a^b p(x) \cdot \log_2p(x)\,dx \\ \text{unity constraint: }g(x)=\int_a^b p(x)\,dx - 1 = 0\]

</p><p>In English, we want to maximize the information subject to the unity constraint, and we want to see what p(x) looks like.</p>

<p>Mathematically, we’re going to want to find the local extrema (local minima and maxima) of the information function along the unity constraint. Analogous to minimization and maximization in single-variable calculus, we want to find the points at which the derivative of our information function is zero along the constraint function. Intuitively, this should make sense—we want the extrema, and if the slope of the information function is (for example) greater than zero along the constraint, we would just walk along that direction, increasing our expected information gain along the way, all the while getting closer to a local maximum.</p>

<p>Finding where the derivative of f is zero along g is equivalent to saying the directional derivative of f along a vector s that lies on constraint g is zero.</p>

<p>Because the directional derivative of f along that vector s is zero, we know that the projection of the gradient of f on g is zero (aka, the dot product of the gradient of f and g is zero).</p>

<p>Therefore, we know that the gradient of f is parallel to the norm of the surface of g, so the gradient of f is parallel to the gradient of g.</p>

<p>In other words, the gradient of f is some scalar multiple of the gradient of g!</p>

<p>If we find where this occurs, we’ll have found the extrema.</p>

<p>If the above calc-related ideas sounds a bit unfamiliar, ping me at longintuition@protonmail.com so I know that there’s demand for me writing something on gradients.</p>

<p>Anyway, mathematically, we’re trying to do this:</p><p>

\[\nabla f(x) = a \cdot \nabla g(x)\]

</p><p>Which is equivalent to:</p><p>

\[\frac{\partial f}{\partial p(x)} = a \cdot \frac{\partial g}{\partial p(x)}\]

</p><p>Taking the derivative with respect to a function requires a bit of variational calculus, specifically the Euler Lagrange equation. Thankfully, we have some pretty easy functional derivatives here:</p><p>

\[\frac{-1-\ln(p(x))}{\ln(2)}=a \cdot 1\]

</p><p>Let’s simplify! We want to get an expression for p(x):</p><p>

\[-1-\ln(p(x))=a \cdot \ln(2) \\ 1 + \ln(p(x)) = -a \cdot \ln(2) \\ \ln(p(x)) = -1-a \cdot \ln(2) \\ \implies p(x) = e^{-1-a\ln(2)} \\ p(x) =e^{-1} \cdot e^{-a\ln(2)} \\ p(x) = e^{-1} \cdot 2^{-a}\]

</p><p>We’ll plug this expression into our unity constraint:</p><p>

\[\int_a^b p(x)\,dx=1 \\ \int_a^b e^{-1} \cdot 2^{-a} \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot \int_a^b \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot (b-a) = 1 \\ e^{-1} \cdot 2^{-a} = \frac{1}{b-a}\]

</p><p>This looks like p(x)!</p><p>

\[p(x)=\frac{1}{b-a}\]

</p><p>which is the PDF of a continuous uniform distribution!</p>

<p>This is super promising—the probability distribution that maximizes our surprise given we know basically nothing aside from a unity constraint is the uniform probability distribution!</p>

<p>What we’ve just done is confirm mathematically a very solid intuition we explored at the beginning of the piece!</p>



<p>Very rarely do we know absolutely nothing about the data …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://longintuition.com/2020/07/20/max-entropy-intuition.html">https://longintuition.com/2020/07/20/max-entropy-intuition.html</a></em></p>]]>
            </description>
            <link>https://longintuition.com/2020/07/20/max-entropy-intuition.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902712</guid>
            <pubDate>Mon, 20 Jul 2020 22:49:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Sudoku with Graph Theory]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23901678">thread link</a>) | @cypressious
<br/>
July 20, 2020 | https://rakhman.info/blog/solving-sudoku-with-graph-theory/ | <a href="https://web.archive.org/web/*/https://rakhman.info/blog/solving-sudoku-with-graph-theory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-4aeb25cd="" data-v-469b7dbe=""><p>In a game of Sudoku you have to fill the numbers 1 to 9 in a 9x9 grid that is also divided into 3x3 boxes. Each row, column and box must contain each digit exactly once. A game starts with a number of given digits in the grid, and the player can use multiple techniques to deduct the missing digits.</p>
<p>Easy variants can usually be completed by using simple eliminations, i.e. all but one candidate are eliminated from a cell because the column, row or box already contains it. However, harder variants require using more complicated techniques where you eliminate candidates from cells in multiple steps.</p>
<p>Programming a Sudoku solver is not very difficult. Even though Sudokus are known to be <a href="https://en.wikipedia.org/wiki/Mathematics_of_Sudoku#Mathematical_context" target="_blank" rel="nofollow noopener noreferrer">NP-complete</a>, because the <em>n</em> in a 9x9 Sudoku is fairly small, brute forcing a solution can be done in a few seconds. The more interesting task is to write a human-like Sudoku solver that uses human-possible techniques to identify the next move. In this post we'll discuss one technique that can be implemented using a fairly elegant graph algorithm. </p>
<h2 id="the-tuple-technique">The tuple technique</h2>
<p>Consider the following row of a Sudoku. Completed cells contain one big number. The other cells contain remaining <em>candidates</em> as smaller digits. </p>
<p><img src="https://rakhman.info/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png" width="593" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 593 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a5acc91205e16e24254440c26a02a598'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a5acc91205e16e24254440c26a02a598)' width='593' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAJCAIAAAANXL0tAAAACXBIWXMAAAsSAAALEgHS3X78AAAC9UlEQVQ4y62Ue1PaUBDF/f4fp3ZaZ7QdrCiPqBUQeRgGeT9DJAFCQhL6u1lyJ0Nn%2bld31Fn3nj27Zzf3XiwWi36/P0xtMBiUy%2bVhxohMp9OnpyfTNMfjsQ7O5/NisXh7e5tlGI1GHx8fhmFMJhMwGkwiQY4ASJAUEnO5XKlUgkqDQVKIchTVQbG/GyPx4ng87na7fWqe55GvfbEwDLvd7ufnZxAE%2bojEdrtdqVSEwfP48Xzf32w2nU7ncDickhMwiQQ5AiDEpJBI%2bvv7O06K3IO0bZtyFAW1z1imsZ1mUAKiKDqmFscxyo4ZI8JfBiNNZ4NMtNlsnjHQOuPRGO0Q5EjDJKXRaPR6vSxYxkG5syB21pgwnASgW9jJYbmCcB17mBBhrF4UA2YGkowAOsAJ9l671Vy7W%2bUHga406PfstaPLS4nxsFep1g6hYnh7exMBvpqsLzOi0Gik6urZiw4aE0mtZmM6t4Q2ERCG9UrNNDtKQBRpATffv/zM3Z0JsK1lqfi42W6zAsir/n7uD2eqFT8QBme1vLy8NLuDjIAAZ7WYPhTLEkSAUhvH7VbbKJcK9w%2bfrvrMZId85vl83jAe/UAlIlVWYpTuK/VWRkAUbTcbd7MRn7ZwwvCQu776dVcQHIzbpGma4BsNklnypdIBznwy%2bPrtyt16iQBfhrpz1z9uro3nyjGdH0cqy2yPJjMtoJeUcx3HspaWZbEZJiUCXNddLhaUUwuPY2hl812zmS%2bUo/j43%2b4AapEUJjz6Dig/CDS5vgNRrLL1HZB1nd0BHrF/3IGDqsVhcgdAL5fLVWrMoFarIRqPuJVEHMdhVGjgITqBLIsnhTeER5DNWNZqvV7bifG0vb6%2b8i8Y8AmTcqDlSDBwQE5pHuJqtQqVYlydkHyulHPUTqxVxmAQJ6G1YaD0Bb%2b8x1ZqRGG0MkaEbur1Oryk6SD7fXl5oYMsA%2byz2YxK1FD6UzCJBDlK5VukkFgoFJiC%2blRSMEgRQFEdFDtrDAaU/wHGqU4NfHWAdQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png 593w" data-src="/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png" srcset="https://rakhman.info/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png 593w"></p>
<p>Cells 1 and 3 of the row can only contain the digits 1 and 9. The two possible solutions are:</p>
<ul>
<li>1 in cell 1 and 9 in cell 3 or</li>
<li>9 in cell 1 and 1 in cell 3.</li>
</ul>
<p>From this we can deduce that the digits 1 and 9 can <strong>never</strong> appear in any other cell in this row. This means we can eliminate the candidates 1 and 9 from cells 7 and 8. From now on we'll mark tuples as colored in cyan, and the cells with possible eliminations colored in purple.</p>
<p><img src="https://rakhman.info/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png" width="597" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 597 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-3373d5f8983748651b5c73a2cd1ac44b'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-3373d5f8983748651b5c73a2cd1ac44b)' width='597' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAICAIAAADGAG6IAAAACXBIWXMAAAsSAAALEgHS3X78AAAEJklEQVQ4y31UW1PbVhDmh3Yy01IoONiG9KHTaWn6UghtZ0oTSMydJH1oM3noBci0A8MlUBtfsI1ljA2%2bYMuWZekcHckSBlvSdiURJslkuiPtfNrznT36tLvqYy3y47%2b/TSs7083NaXFrurn1UN5%2bUPgzXTihMmm6JjSblJBENv1Daf1naRs5yPxJ2Hyo7H69uVgpliRZdmiCIIpiq9VKpVKIEXh7MYgAgxhBjEv4KIlSRSy/Gv9H6FcuhpvVIREvfljKf1o5usPVfeRiyAmirw/LXP/ZaSxPmIzpBNcYY/v7%2b/V6vY815VluYxmyS1ZyGY6X7PQKZGaV/brSAgDbtm/9RasR0iPLkF620w7TSq4AN3n00tDaDgfglol5LcuCtwwfMQjvmgF67EECfNAdtcwgWEEbRoH5jPqACGPQC9pWEMygbY%2bC7GOkRJ38lu1lQ5/L5RqNRh8T5ZnM2iIcz/dioU4kdH24BKlHZJcnondMuVzSdMMBzdpjbX8RknPdaOgyjPwlSE8kXrSZhqsKkTku6%2baHWq3W6/UQiEK9VhcQmKZZrVa9hGf5U%2b7kFEHb1iKTsZ4PWOBK9XfJiNEOmvJdvTIgdMeg7b%2bmI5eKv3M9CoKPSucSbmGUcBzXMx0B2WzWFdCUZ7i1ZeDmrw6/L/wxdba2CtzMGwFSqzE/N9cQWq4A/kn7AL/9LN37LvnrI%2bXAqUDiha46FWirLBw%2b9ATwPAowEWys/fX6IOJ9M1TlCTgv5LhcHoFutyOTcWsYqsONRD/390fb2cGyOnJVHhDse3A%2beL51Z%2b/g42QnCKJPkYqyJ%2bDV%2bjrTdFfAyU0FZjNrTkuYiYVubP46tgLpWbLHy00kqYxGIhFJol4FQhoKSC1Zifmr6GIvvgLHKEBjKq6eZI%2bPkmnvFavVmwpwx6loLI6iLLcCXoNVyiXmaXYExMy70B7r0sAl8RvGqCWP6JVBoXsPlMAlDRhKoIPVcCvgCDC73Vg0KlPlvQpsLEJ2wUouQGrBTi1CZubDM1B/rEew2VxOCvlLwE28mQHvM783A7Zr/zcDEwkYhK7fMkfA9Nu2H9Qho/6JCAHojdgY7LlB%2bbObGbCcM6x3ZkBpyU8Of39mxJ%2bS8FMaXiXh51osVNrMlc7amiZ7RgjiTOFkobbzjEWRuYpMOfxcj0/t/MJXa0xVKaWKolBK0GOb4iaMEII3dYHTuy7hxhhlPOE3p7bJV7rwjSyMk8Y4ad1n5S/5zOd5%2bVsNI94l3VcLX5SL6aKmq5gQk2BywzCwNZy/EP724ofRrtHRiNKmDH1H1WslrHNJVXED8Y5XNbVQKDRrdYNpHlOVaVe/fL2zi72hugI85tsCbu0DAhjja/z23rbe00mbUINSnbIO4yU%2bX85r1xrRnSB69UotN8rFUlFTNe993hbwH7TSL274t7MFAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png 597w" data-src="/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png" srcset="https://rakhman.info/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png 597w"></p>
<p>After the elimination, the 19-tuple is still there, but it's not <em>useful</em> anymore because we can't deduce any more eliminations.</p>
<p><img src="https://rakhman.info/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png" width="600" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 600 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-74dd1e02634693877e8b2be848f175ed'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-74dd1e02634693877e8b2be848f175ed)' width='600' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAICAIAAADGAG6IAAAACXBIWXMAAAsSAAALEgHS3X78AAACgklEQVQ4y51UTXOiQBDN//8Nu/sPUnvJxZNVVrTKLyIqmKyKAgIqCCiCCAh5TMdZpPaS7QPV08y816%2b7Z552u50oikVRxJdLzOx2u2232/1%2bn2VZfDcENU3zfT9N02qw3W4HQZCQXUtDXFEUrOBgSX9Op5Oqqgzwii82gXG9Xo/HYziXCrVpmrZtV6nh4ywQQA1ASgDBTqcD/wm5TqdToOAwvnme4%2bu6LnLlS/piZxRFxd0o2Ov1AFoez0ojnM1mw/dkDBaUlmXRX2ggLsMwZrNZjdpxnOPxWKPG2ZhpxjJJUk79ICBLU8e2HddjKAfP8yiJtzchOEeEQgKiMLRM85qkhELQzn4nCCPKRt/odHYsjjbWjtU4RmlJlDDsv8%2bX8KCTBKRJYpqGz/JG%2bUlAeD4ZpnG5JvBxlqjlqSjJMwLvdrsPAtL4ulaUlapTGdCEkkNXfv745TgeCQjDEI7vujNZCsK4KsDc6OL4q5O6zgTc0t/Pz6PJlObzLqCQJclx/XsHZDjJ9TIcDFZrnQRQ813b6vZ63ikkARgzOPut%2bfrazlgH6gKqfTwcvjoQRWfwBUFY7UBthEiANBl9/Fk8CCiKxfxjpWpshO4C8nLAkjT77giRAN9z5dl7/s8O1AR89w5U4/wOcINIElAF/I87UKMuBeC1abVaeIvwyKBy%2bIJpMplIkgRHZUZBQRDm8zlYdWYIAvfl5WW5XCJjOk7xfr%2bPCPmarsHHnuFwCBCNQpqGcgwGg2aziQSq1HiXoIp28iDOLhaLv5haidloNPBsVC5xhtHKqRgoA40QljzI70DOjILoI38feJxGiEfooYTyGiCSkGW5Rs3vQHUnv8Q1anTgE/ikpWEBGBRdAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png 600w" data-src="/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png" srcset="https://rakhman.info/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png 600w"></p>
<p>This technique isn't limited to pairs. The following image shows a 4789-quadruple (cyan). Accordingly, the candidates 7 and 9 can be eliminated from cells 1 and 3 (purple).</p>
<p><img src="https://rakhman.info/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png" width="601" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 601 85' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-add802a2270b11616a5e0f13608d63ba'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-add802a2270b11616a5e0f13608d63ba)' width='601' height='85' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAJCAIAAAANXL0tAAAACXBIWXMAAAsSAAALEgHS3X78AAAEjElEQVQ4y9VT%2b1MTVxT2v%2bwv/lAHBBStgm1nOn3MdFpfFbUGUAKSgDhVRLQiGh5GA9lk994khE0IyCNgNpvshoAk5LXZx709d7Mt/gu9c7Jz59zvOznfPd89Rf/n6xT88Fu8PMAJo5gfQa0Iu4XA3BKOYiSg1sIYh7lwYHhZGHFg4REBj0QXhv3jgb%2bnIouTwvwkYvEUz79YnhPCPMIOV0BCFEdeLc3/JfieIQfGkMKcxzc1iU8yEE943%2bOl18/wwkkSACFfMBiEHhA66YfjuFqtxgQEfg0efaVVOozjNh2i0m4cndbS3B6hlq7plmWZhmFRq3xQ3vk622ijZRtWatPMNorPpH5IPx2iK/eaYZfO9%2bv8Xco/ljmtVDUs0zSBbWl6kxL6Yo%2b/2QgMmghgLj3cb/KuZujysnvAamVY9JvC3erSb5mZQYJddkH2JcLA4ZKSV6BVw2AVm80m7EVRlGWZCQj34UqHqX9H9V5qXGFROW9mIzk2IUK1Rh1osK2Va5lvVL2Har3E7KXNXov2UPHS9rXszARNeS1xnCbHiDhM49OFqFnTgKIBuV4n9qx9ufiAIYxRcQxgNOGh8VEr9jOe8FLRSyBp02liWEN3lUXY2MnEOEl6AHCMDooHUARar9UbhLCSGxsb%2bXyeCQj9gWrtVuFiabcrnzq7JZ0v1s9RCWfhqPL50O/3lyt1JqBUy3SrxiW631362LG31SnRy3T14tbv2VeP6Nodae566sW9wvthKk6p2KgyAZgPJlKbLbO%2blVdcpuAhKze3Xt2W5j10ddiM/ogejdL4n8pi3%2b6bG%2bsvB0pBtxG5nV94SGJQ8FZ69sbGywc69lRQcb8IRUpHB%2b8/BHR2n0xALpdzBNTbiXLhcKdTSnfKmfMFEJBBEhyp2cxb31x6LwP76lEVBFiXqNJ9mGzf3u7MMgEXmAC4vOvJ6aurU/dUR4BpC9hX5LCADeIIAIfArV9LPAcBo46ACei1Lz0LGaD3lzi3ge%2bo79x14db269sZ3zXx%2bZcCGrUqF1wu2%2bNdX/9XQPgWqnaY5rfU6KHgDfMKrZ5YiMCY6g2tNQHpogqYZg%2bxesFvjoWuZmce0XWvlRina2Mk4W5ZyBZwCIM//OxMILfSbwhe20JemoCLf2jFfkITzCEkwdwCdJpwa%2bgOs1ASkl5mobVRKnqYhZiA49KRoqq2g76YAHddKJ1uVrvNSpcBUT1nls40P/ESocSwpwXvBvbHnyu7Z3ONTtqClbt0q4vGOj/%2bkpkeoauDunDfQA8M5KL4SZ7Xj%2bsmafGIbujwlmakSJ8WHLKiAGNhYaB8z3sfkIiTAboVcdVCN2TfEAUYK3hfR4M0MnTEFdQCdAJP2H7KBnxTqZTzBvxT73dnP8n%2bfHYxByG/y3/ySbFwTCkosr1yck5RlJ3tnfjz1bxflRZlgEkL8v6HA%2b4JPy0sxItpQV5HuQ0kr2N1MyAKuztpoMhytlWhoKiBGM9JSZz/yGB28NmUZ3YSK5tIdjJwGtwT38SXo%2brWfwUj6ubSZmwtmVQLBTnrFCwWi6FQCP7iH1QlqpjbljhEAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png 601w" data-src="/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png" srcset="https://rakhman.info/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png 601w"></p>
<p>We can generalize the rule by defining a tuple as follows:</p>
<blockquote>
<p>A tuple is a subset of cells in a row, column or box with size <strong>n</strong> that contains <strong>exactly n</strong> distinct candidates.</p>
</blockquote>
<p>So the elimination rule can be defined as follows:</p>
<blockquote>
<p>In a row, column or box with a tuple T, all candidates that are inside T can be eliminated from cells outside of T.</p>
</blockquote>
<p>Furthermore, we define that a tuple T is <em>useful</em> if T shares any candidates with cells outside of T.  </p>
<h2 id="drafting-an-algorithm">Drafting an algorithm</h2>
<p>Let's think of a naive algorithm to find tuples of size n with n distinct candidates. We have to consider tuples of all sizes with all possible candidate combinations:</p>
<pre><code>for each row, column, box
    for each size n between 2 and 8 
        // 1 and 9 don't make sense
        for each subset of the digits 1 to 9 with size n
            for each ... </code></pre>
<p>It is easy to see that our implementation has to involve a lot of nested loops. That's not a problem per se, but I find it hard to visualize it and thus it's not straight forward for me to write down. Instead, let's look at the problem from a different angle.</p>
<p>Consider an undirected graph, where the vertices are the cells of the row, column or box (that don't have a solution filled in). For every two cells that <em>share</em> a candidate, we'll add an edge. Let's look at our first example visualized as a graph:</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png" width="821" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 821 244' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a48166cfe4c168e75b128b3cc7b52f32'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a48166cfe4c168e75b128b3cc7b52f32)' width='821' height='244' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAATCAIAAACvEZzQAAAACXBIWXMAAAsSAAALEgHS3X78AAADOElEQVRIx7XXS08iQRAH8Pn%2bX8CjR70ar0aPejHRg5HE%2bMbnIiK4Lr6W/WVKZ9uZYQCXrQNpmnr861/V3UU2%2bq78np%2bM/kGymeCO/r/MGij7niM//foqT09PDw8P9/f33W630%2bn8qBP7FAaDwc9E2DYHmjmB1CbSGA6HIvkUG8perwdHv98fJELh%2bfn5PZeS%2bfunvL290QknqXRz4dOan8fHR2olBsdlktWyHgSL1MuFX2v8WfBuR7wifC8RIHzSgUNNIJ7pOL2%2bvoYtt3d3d1EuxDXkUFMB9oyjuEBgOnKIVrE/DlaaPEOBg13mcAA3a6MqWgCAx6I2jazU1qenp7R9tRY7CGiI8fLyEu2Udk5JQA9vNCVPM2o4fUp2rq%2bvz87OorVqEuD38vKSxtXVlYU0NExJtXrr0aHJpN1us01Jqs0Z4nB%2be3vLlomUmlsrOOJfApi9uLiwSJ1/JMAvHHEc0ekrvXFtF5tiQxDHg/AOWS2pablOTk5w32q1dnd3hTg/P2fbfNvQcYMdHR1tbW35vMmlMMmiW0CBm%2bre3h4l64losCIHvlq56Ao78qlFEzuIp09ze3t7fX398PBQMshqMHHkIsmdnZ3FxcXNzU11xkKh/5EAJar7%2b/urq6sbGxuhJF5cLFUR%2bPj4GFyg19bWVlZW7Kgv/YkJROkODg46uWBqXBT%2bpQebhQbBrDoLZKc4clnRZLz4OZqHgRgORsPjTzMeJpiYK5oExvVD7IgtB/2wtLS0sLCAIxGjVwGqjYLKqAC%2blpeXo4B2/p6B0OPIblx5MMW6%2bQyoGATxOBDo5Vw97ukaSjhwyT/ioYmLpfkQB0Fxgn3GwftyBkIih3YugX6iIIayNDhFLQ%2beoXH3qXr6lU5cdD4BKi6u5jeOlUDgFV1avoUiG6fWrR/v1MQhpCBYGtDEHKEsAvQ/BeLiqUaKrwEo3sRSicbNp9wChiCtUUWVVYeN6efBQlPOxXyB1JhnhrmIHY/XTDOpY4kRfuL5I3ElVrFlo/kJ17CiVhroTyclWZVG1%2bpODLPF/cMqxpbm5LM5oq%2b%2b3MUQCl86ukZu6Y6K4biYW6cfqudZgTn%2b%2b5n%2bz9ofhAjTd/wPZrcAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1.82a2fbd.a964474d9018de0f0aaf005304ce9f9e.png 480w, /assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png 821w" data-src="/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png" srcset="https://rakhman.info/assets/static/sudoku-graph1.82a2fbd.a964474d9018de0f0aaf005304ce9f9e.png 480w, https://rakhman.info/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png 821w"></p>
<p>A <a href="https://en.wikipedia.org/wiki/Component_(graph_theory)" target="_blank" rel="nofollow noopener noreferrer">component</a> is a subgraph where all vertices are connected directly or indirectly. If you start at any cell you can construct the component it's part of using a breadth-first or depth-first search.</p>
<p>We can see that tuples <em>have to be</em> part of a component as they need to share candidates<sup id="fnref-1"><a href="#fn-1">1</a></sup>. But how can we tell if the tuple is <em>useful</em>? Let's ask the opposite question: When is a tuple not useful? If it doesn't share any candidates with another cell, then the tuple must be <em>the whole</em> component. Here's an example:</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png" width="846" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 846 153' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-03b60ebedf59d3229099e95d98c4ee17'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-03b60ebedf59d3229099e95d98c4ee17)' width='846' height='153' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAMCAIAAABdkSyeAAAACXBIWXMAAAsSAAALEgHS3X78AAACEUlEQVRIx6WWS47CMBBEc/8LcAMkDjAHYA0LZoWQsuH/DSRA%2bGeYJ9co4xAwBnphHKeru6rbsQmulv1YdvWzNyA26g3IDSpwAHyCfgjxZ//oMbBXd7vdcrlMkuR8Pj9Npren0ymOY1BgPdlkWbbdboGs1%2bvL5eLJ/nA4rIwxudMBnCaTSb/fH4/Ho9GIyWazeRoaBt1udzgcgur1etPp9CmE0uA/GAyAMJJIhNzFiqKIRBADxQTx/wKEXCwWvIZ0mqaUB6EQUh8cJcEHz9QYKAjx6GYDA3TiLMh8PkfDI3%2btUyYSsS%2bUSI9MCh1QbsK1Wq12u82uoCGo4hVdzoqmvlMVae50OqCYk4M47vKTGwikG41GGIbMgcDJkQgmEIPet7HIGItSGOiHttIXGH8Zw2M2m0k366uisYJCSBCFSjSbzVqthmyxcQg4Ho84UHicK5VKvV4HzorElxPJ2DPw4S1ZqtUqPWSR8U%2bA2kQI2BOFEbmUBEn6DMr9zTuLDyOh2RVIAqvCOD5HZONJCtUVOAIQ5thCCqtNQSJIMiKpIGC/31NvVmNj6Mt75DC54S/lRLg5Isps8MRNEEZKoI3KhnmUhY2HbNQmxtgaaM6PryAPTTfpgxpKUCL6HIgKJ5TnSarWCUX3fG4GWkSlBGHC2X3/IiOWvp6XbhxBXr1WP0yUo4IP78vc0/%2bvge32XiJ7/Rcr4rn26992uQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1_after.82a2fbd.dbe97fe18d4799f5a49f399b8b182406.png 480w, /assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png 846w" data-src="/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png" srcset="https://rakhman.info/assets/static/sudoku-graph1_after.82a2fbd.dbe97fe18d4799f5a49f399b8b182406.png 480w, https://rakhman.info/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png 846w"></p>
<p>If, however, the tuple is part of a bigger component, then it must be useful, i.e. there are candidates that can be eliminated. In our original case, the tuple helps us eliminate us 1 and 9 from the rest of the component.</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png" width="794" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 794 220' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-49ff9d1fa77a96567b4ec7bf44d02793'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-49ff9d1fa77a96567b4ec7bf44d02793)' width='794' height='220' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAASCAIAAABkTU91AAAACXBIWXMAAAsSAAALEgHS3X78AAAE%2bUlEQVRIx61WWU8bVxT2T%2btLH/rUh/atD1ULISYsJaQvlaKqEkrVJUkrURLCniZRpSjpoqYLpEvUQlmM2ZcgQijYxuOZO/viGc%2bde3pmLnaM8Rho%2b8HD%2bN57zv3Oek8CTgKL0PgMpbRUBa8h8EBjhawMOAUScSpqVoIgcF0Xr/d937IsTdP0GOCWLMukDLkeyFEoilIsFj00vORRn57Jg4m4DSSKjG3bVlUVaRmGYZomkhNFEX/aVXAchxtWwYluQ3fURAx14kVaBPxAk/BGHq4Gbj1iAN/GZEAHozwnjUCK%2bI1uq6wc8Xfk8hqoZaAq9ELFpNMkBh7gXsCYcJMqxtTVEBpQWXAtBwWQMZqBftXL5PCbZzl67jR5icdoBB5ATgK/D8WrCbCTUwWluDG6rQVQqyHBIPxTbH0xv53a27C9Il4uEYK3ohuOa%2bTXBCxAKd0yN8jeGtklpoY/g5jiwxXq%2b%2bhFmSjoBdd2pSVZ%2bEvUszoKAWtYzRG9MDV8mk3nno0/13Z1GtBwkfEIMEiTZ4PGdL8/h/9jxmx6bzMo%2bQ0cw1VuKdlRdQZFbvqzKL5AdupSeSEbigXZlWy%2bR7bbA7cT1It2/juJsoY1E0mbopW7Jlkdvt8Feqd78KXoud5hBHbkXK81OQzLY7B6G9YGYHFAn5IMtUK0LiHRUPq1STw8BisoheKo5LlyEFdqXJNjO/n3ZXoeds5lpt9YkJK61UzzTwpRosSa4IOfuy7Sc7DbcvDT67/ttwheE2QfCJxgYpys3oD54WDh08zPV7a%2bGWGLfUFqqvCUub5br4vjIm5Nipt4bAQWrwuPezYeDpRSNyE9QVaBxmRExI%2bkZLPFK12CbIs0/trvu%2bfzrA2Eq8T0zZJX5/UIGwD44raktju0Gzbf2hl8eWzlzS3oAvGyahftMALfyyv9sDDMFi6n7l74%2btognb8FC49zy5aia0a9Nm/ouDWRWw6lYBHZJ%2b9/0qf/OQBLj8gyeBTiDRCfSE4yKF4Epc0Wkqr9TuC1gXRFyZO8aZj6sadFUzXTNfdnM1ZHye0Cq5OqbbbXBW4HaO/ZmqyFBkzKT3vp7BgsD9H0reIMfvR60%2bvqXmwKRYtr6j4ew8MYuv7izChEcZO3IqoszgB1W1dbbXYJ7r/67dWXPt9JZlkS8kMkLOUgtgAsxSLdBuuCQrs28sodpzsotULhI7kE4RORMGzztjLTB6lBWByCpS/Y3EMpXSqXSBzwwANpvpfNohQWAIqPilOGZVYPAjVANhRoZvTAepsKzVq2iZjNVHxXVzNabW%2btdRgTfhT1Js9pZYUWzUsCuWCRFZnvhu%2bAYmo/SMv3rPRXZvpXsu4UnTj3VwfBduxfxLW7euqOPjehrGeFA0PTsfc36IkoUiCF/CNR/dA2e0rCDVn9W4u2GnVSvC2shD%2bI9LGufuAInylkTa6018RhjwyYbVlFx2lEvJ4pKJXZ33fNsJ7wueEPn3UMmNA482Ci87fMcW3DNCij1V3rSLiOXUTBF6S8IAgBHJFK8B%2bVxA1OzZ%2bVD9MgwMoWJRGHJScCJ41PL5rEV6qniTDdWfmygDUeSLm2cACUZNdxj0slzjQ2Nx62%2bfCHLy6PQ8Weig1x5cGHheqI8XmOT1MvZpByRp1qGj2rGccXsZHz6xF8AlfKwHSSJAndWlnh1lYm3LpD1wnT6P9ixr%2bI4X/U%2bQ8i4s20LfMurQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1_colored.82a2fbd.d20250e2b8fbded9a1ce6268eee66188.png 480w, /assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png 794w" data-src="/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png" srcset="https://rakhman.info/assets/static/sudoku-graph1_colored.82a2fbd.d20250e2b8fbded9a1ce6268eee66188.png 480w, https://rakhman.info/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png 794w"></p>
<p>Let's look at one more example. We can see that the 4789-quadruple allows us to eliminate the 9 from the purple vertex as they are part of a component.</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png" width="967" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 967 228' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-0ca3d0e9f3d486fc088e18419c41b3af'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-0ca3d0e9f3d486fc088e18419c41b3af)' width='967' height='228' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAPCAIAAADbBV4wAAAACXBIWXMAAAsSAAALEgHS3X78AAAEqklEQVRIx71WXU8jVRjmL3rvDYkSRaPRxBv1ZmPihcSYLBS2LWi8MhtIVNaogU1gl9W2UNqylC3sykehLf2amTMzZ77OzJzjM3NKbUvJogm%2bTCaHznve8zzv55kQdyCcc/F/ycRdQw%2bCwIvFcRxCiKqqZED0cWIYhuu6cpfv%2b7ci8FqfRQqhwMPDGzXxkcearhMJcHQ6nVar1Wg06vU63l1FUTRVUVVN0yQTSimw8lhA1ccTBizwbdu2LIvGIlnhF%2bYxHh%2bBg4YIvD7iXL4kCSFuVg8cZusmtSjAgYBpmmAy1lREOAwBCzrQhLN7X/kY38FrsANKLrVDl42JAKw0Y4Gtsegt1VLXDfWRYRybvAdg8LuwXKegnTxuPj8zW45BgWzEDCDuk%2bqWdvRSb4RBMBS6MAQAy6CHen1LPSqTc89j40LMX5HG%2bmVpT686nvsPAXirVqvJSGGhaupITtOG1flcVyat9qShTFvKn0RmTN%2bXpmP9oO0kwu20KCW87FbrRZ8jv0L/o1pMBNspUZpj2Q31hQiGXB36waPm7izLJkVxLsj9ou4FzB/yUSieKocwvij2cNAKKThuFNsJVAkSFI6vVqunp6dYgAPyEl6JUpIFTLDWdwqfEoXJg5U3Vs13POUz06JWyCMF/IlAPFOO5sRO2tu5391M8d20lVMsvRf9%2bPQ97QynPrAyX1/8ng52553sud7CF5weWQjFK60%2bz7aXRHFW2Uw623N%2brkJqsdO5dGLTVJJuLhXkYSFpZ2fD3I52HBGAb1BeSK%2b1tbXl5WWUF/igwlA9pmFS0ySUtGYU/wPRec%2bsTXXcj4TyoamcqdSNFJDmtk5X28Ul8fyL8sr7P38zqzxZ8LYvrK4kIAvuiXqUisF9vL4wc/rrA7FbaP/FqKMj/03Do3ameZgWxfvdjXeXv/ry8Cco5PRjSSCMCRzp9ZSfB4dPM9/fKz1MisJjUokIwNMggCzqdrvtdhsLEAhkjvYKnnceav5bojbd%2bePNbT4tOvd0j3lXCRRZz5MTuORbXkjBSaKwRHOGQwcjUNFrs34WDl7082lRSDq5FlUHFS7MzryL9CimnNyiKMx5mWPjsqcQE1AssuggRYuLXn4pLMDaHqn2agAFhLRRYsFisI7lZps4rRmNvO0ZU0z5hJKyPlADkaBpr6qlhJ9dEPkkzRzoF/3y6Kf4mlJOeBkoLNiZp5cHve09gFF7e6a%2bnHcihYST2VQrskh4nwEXmWYFSYjgJFj2N60cxCOi14XQpCSB0a53hdFzPLVE6huXZsccxtYTn/knerNMLqLsH9dnUS7nRntfq7Ysjdku0cnIkEKuNKiyT87rtCuCcGQawq3M8S71bq5eqZodeOTGOXB9LFzFWTDuGdQwiIGaiUo8CMbOEH7Nzsj0iUwxBkzoe4h/r2eEQX9zGGU%2bB0PoqLFggfFimZT74eAoGp3ENw21eJr09sEuAtUf%2b3Jg2Zbt%2bYzFDxRueR0CbmkNzQNFiFHdVaMHEwmliCmOpEBZQgGGZWWOmcT/6qozgkwi6FOSZORwHfxX/iLvP8awyCsDFORbLlgM93qErwOYuKNLorzb3F7%2b8wX2byuprAPYvfWFAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph2_colored.82a2fbd.34afc064d94ea30c3957db1592335c2f.png 480w, /assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png 967w" data-src="/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png" srcset="https://rakhman.info/assets/static/sudoku-graph2_colored.82a2fbd.34afc064d94ea30c3957db1592335c2f.png 480w, https://rakhman.info/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png 967w"></p>
<p>With this knowledge at hand I found it relatively easy to write down the algorithm. Here's how it could look:</p>
<pre><code>for each row, column, box C
    let g be a graph where cells in C are vertices
    
    for each cell c1 in g
        for each cell c2 in g
            if c1 and c2 share a candidate
                create an edge between c1 and c2

    while g is not empty
        let comp be any component in g
        
        for each subset s of comp
            if size of s == number of distinct candidates in s
            and size of s &lt; size of comp
                return s  

        remove all vertices in comp from g</code></pre>
<p>You can find my own implementation of the algorithm on <a href="https://github.com/cypressious/vue3-sudoku-solver/blob/master/src/logic/strategies/tuples.ts" target="_blank" rel="nofollow noopener noreferrer">Github</a> and the runnable application at <a href="https://sudoku-solver.rakhman.info/" target="_blank" rel="nofollow noopener noreferrer">sudoku-solver.rakhman.info</a>.</p>

<p><sup id="fnref-1"><a href="#fn-1">1</a></sup> Technically, we can construct pseudo tuples that aren't connected where each cell only has one candidate, but then we could immediately enter the digit into that cell.</p>
</div></div>]]>
            </description>
            <link>https://rakhman.info/blog/solving-sudoku-with-graph-theory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901678</guid>
            <pubDate>Mon, 20 Jul 2020 20:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I no longer host my emails myself]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23901516">thread link</a>) | @jlelse
<br/>
July 20, 2020 | https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recently, there has been a lot of talk in my blog bubble about email self-hosting again (here is <a href="https://www.paritybit.ca/blog/a-month-and-a-half-of-self-hosted-email" target="_blank" rel="noopener">one example</a>, here is a <a href="https://www.garron.blog/posts/host-your-email-server.html" target="_blank" rel="noopener">second one</a>). I myself <a href="https://jlelse.blog/thoughts/2019/mail-server/">switched to a self-hosted mail server</a> over a year ago, only to <a href="https://jlelse.blog/micro/2020/02/migrated-mailcow/">switch back to a hosted version</a> a few months later.</p><p>For me there were no technical problems running <a href="https://mailcow.email/" target="_blank" rel="noopener">Mailcow</a>, I was even quite happy with my setup. Nevertheless I switched because I realized that email is a topic where it’s not really worth hosting it myself. Neither is it much cheaper, nor does it bring me many other advantages. Both <a href="https://www.fastmail.com/" target="_blank" rel="noopener">Fastmail</a> in the past and the <a href="https://www.servercow.de/mailcow" target="_blank" rel="noopener">Hosted Mailcow</a>, where I have my emails now, are completely sufficient for my needs.</p><p>I don’t have to take care of anything myself and just have to make sure that the monthly automatic money withdrawal works successfully. No more updates, no more worries about my server suddenly going down and the backups not working. Someone else with probably more knowledge will take care of it now. And by having my emails hosted by the developer of the open source project mailcow, I support that others still have the easy possibility to host their emails themselves. And of course my emails are stored on a server in Germany and <a href="https://jlelse.blog/thoughts/2019/email-own-domain/">I use my own domains</a> to send and receive emails.</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901516</guid>
            <pubDate>Mon, 20 Jul 2020 20:24:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I asked GPT-3 to make a presentation for me]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 96 (<a href="https://news.ycombinator.com/item?id=23901059">thread link</a>) | @bemmu
<br/>
July 20, 2020 | http://www.bemmu.com/gpt3-presentation | <a href="https://web.archive.org/web/*/http://www.bemmu.com/gpt3-presentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			<div id="posts">
	
				<article>
					<header>	
						<section>
							<time pubdate="pubdate" datetime="2020-07-20">2020-07-20</time>
						</section>
					</header>
					

					<div id="droparea"><p>I told GPT-3 I would be presenting at a Hacker News meetup in Japan, and asked it to generate a presentation for me. Here's what it came up with, read by yours truly.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vZalOEmdHFo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>There's also a tweet-sized version <a href="https://twitter.com/bemmu/status/1285284131656445952">here</a>, and the slides are also on SlideShare <a href="https://www.slideshare.net/bemmu/this-presentation-was-generated-by-gpt3">here</a>.</p>
<h2>Details</h2>
<p>I used the <a href="https://openai.com/blog/openai-api/">OpenAI API</a> to generate one slide and one image caption at a time, asking GPT-3 about three times for each and picking the best output. When it generated image caption, I would go online to find a matching image, or if none was available I'd try to splice up an image using <a href="https://www.photopea.com/">Photopea</a> and <a href="https://www.remove.bg/">Remove.bg</a>.</p>
<p>My starting prompt was:</p>
<pre><code>A presentation was given at the Hacker News event in Kansai. 
The title of the presentation was
</code></pre>
<p>When it generated bullet points, I let it generate several and then picked the best 5 out of what it came up with. Once it generated a slide, I edited that into the prompt as well so it could continue generating more slides for the same presentation, and re-ran it to generate the next slide. </p>
<p>Piecewise concatenated output from OpenAI:</p>
<pre><code>"Strategies for Learning to Code in Japan" and the subtitle was 
"Fairly easily and rather effortlessly achieve practical software 
development skills."

The first presentation slide had a picture of a man playing a violin 
in front of a wall of violins, and the title of the slide was "Violin 
skills are of almost no value". Text under the slide said: "a metaphor 
for how useful programming ability can be for starters".

The next slide suggested a number of strategies for how to best use 
ones time to achieve productivity quickly:

1. Nobody figures out how to code perfectly their first time.
2. It's mostly luck.
3. Learn just the right skills, in the right order.
4. Avoid perfectionism.
5. Not doing something is sometimes the best way to learn something.

The next slide had a picture of a monkey drawn in crayon, and
and the words "All problems are pretty much the same." written 
under the monkey drawing. The text of that slide was:
"Not only are all software development problems more or less 
the same, but the best way to solve them is usually so simple, 
that a monkey could do it."

The next slide had a picture of a monkey, a sand hourglass, 
and a spoon and the words "Let's get started then!" written 
under it.

The text of that slide was: "Just like a monkey makes sand castles 
with an hourglass, all our time is of limited duration, so let's get 
started to code a product for clients. Software development is 
actually a bunch of often complicated problems. But that's not a big 
deal, is it!?" and the color of the text was red.

The next slide had a picture of a happy architect with a blueprint 
in one hand and blue pencil in the other hand, standing in front of a 
huge complex, and the words "Looking smart is the social norm".

The text of that slide was:
"Almost all developers feel the pressure (for whatever reason) to have the
look of the competent coder, most likely due to peer pressure. So it might
be counter-productive to cut corners during the development phase." and
the color of the text was purple.

The next slide had a sign: "DANGER do not enter" and this text under it: 
"If you don't need your code to run during actual product development, 
stuff it in a module in a separate directory." The color of the text 
was orange.

The next slide just had the text: Richard Feynman was reported to have 
said: "What I cannot create, I do not understand," something that has 
been paraphrased in the programming world as "If you don't regularly turn 
code into poetry, you probably aren't a good programmer."

The next slide had a picture of a happy runner and this sentence next 
to it: "If you've written 500 lines of code and have an actual working 
program that doesn't crash, sprint to the finish line." 
and the color of text was green.

The next slide had a picture of a swordsman catching a bullet and 
this text: "A happy ending to all of our code." and the color of 
text was yellow. The text of the slide was: "So you built a program
and it worked in like 10 minutes. All your code was beautiful." 
and the color of text was blue.

The final slide had the title of the presentation: "Why you should 
always code like it's your last day on Earth". Next to it was a picture 
of a person with their whole life ahead of them staring into a terminal, 
a ball and chain attached to each leg, and a long nose and a beard. The 
text of the slide was:
"If you always think like it's the last day on Earth (your last day coding), 
it'll push you just enough to get you to finish whatever you might need 
to finish."

The last remark at the last slide of the presentation was:
"So now that you know it's impossible to not 
learn to code, go write something, anything.
So stop writing nuclear missile designs, or the best 
ad blocker ever, and just get started on whatever.

The next slide had the text "And then when you finally do finish this nice 
feature, you should always make sure you drink the required amount of alcohol." 
with a background image of whiskey bottles. The decorative text on that slide 
was: "But don't drink too much alcohol and end up like me."

And the concluding remark of the presentation:
"So basically just go ahead before you wake up in a cold sweat from a scary 
dream about the future, coding-less, uh, eating those annoying squares of tofu."
The background image of that slide was a plate of tofu next to a glass of beer
and the font color was orange to emphasize the suggestion to drink.
</code></pre></div>

				</article>
	
			</div>
			
		</div></div>]]>
            </description>
            <link>http://www.bemmu.com/gpt3-presentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901059</guid>
            <pubDate>Mon, 20 Jul 2020 19:29:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for great product managers]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23900783">thread link</a>) | @AlexDReeve
<br/>
July 20, 2020 | http://reeve.blog/blog/principles/ | <a href="https://web.archive.org/web/*/http://reeve.blog/blog/principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p><strong>Edit 07.20.20:</strong><br>This post was #1 on <a href="https://en.wikipedia.org/wiki/Hacker_News">Hacker News</a> today, which did 2 things: First, it crashed this site (sorry, won’t happen again). Second, it catalyzed some great dialogue <a href="https://news.ycombinator.com/item?id=23900783">here</a>. If you’d like to continue the conversation, hit me up on <a href="https://twitter.com/AlexDReeve">Twitter</a>.</p>



<hr>



<p>A few years ago, I read&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://amzn.to/2C4RbBY">Principles</a>&nbsp;by Ray Dalio, and I became enamored with the concept of codifying my own. So, I borrowed the idea and started noting them down.</p>



<p>This list—pieced together over the past few years—reflects what I believe are some of the most important principles for product managers. I can’t claim credit for inventing these; they are the summation of what I’ve learned through experience, coaching, and osmosis. This list wouldn’t exist if not for the incredible people I’m fortunate to work with and from whom I’ve learned so much.</p>



<p><strong><strong>Product Management is a broad function, so I’ve tried to distill this down to the top 3-4 across 6 categories:</strong>&nbsp;</strong>These principles are very much a “living” list. I don’t intend for this list to be exhaustive—nor does it reflect the entire scope of the product manager role—and these principles will continue to develop over time.</p>



<h3>Leading Your Team</h3>



<p><strong><strong>1.</strong>&nbsp;<strong>Your team should be able to repeat the vision, goal, and value</strong>. </strong>If your team can’t, you probably haven’t communicated it enough or aren’t aligned.</p>



<p><strong>2. You should know what game you’re playing, and how you keep score</strong>. Credit to Adam Nash for this framing, see here for his <a href="https://adamnash.blog/2011/12/16/be-a-great-product-leader/">fantastic article</a>.</p>



<ul><li><strong>The game you’re playing:</strong> Your vision for the product, your product’s value to the customer, your competitive advantage, and how you’ll win.</li><li><strong>How you’ll keep score</strong>: What does winning mean? How will you measure success? What’s your “compass” to tell whether you’re traveling in the right direction?</li></ul>



<p><strong><strong>3. Your team should know the path to reach the goal.&nbsp;</strong></strong>You need not detail execution to the point of false precision, but you and your team must understand the high-level milestones. If the milestones aren’t clear because of unknows, these unknowns should be explicit.</p>



<h3>Making Decisions</h3>



<p><strong>4. Decisions should be documented, explained, and widely communicated</strong>. It should&nbsp;<em>feel&nbsp;</em>like over-communication. If you don’t feel like you’re over-communicating, you probably aren’t communicating enough.</p>



<p><strong>5. Decisions, and what you prioritize, need evidence.&nbsp;</strong>It’s your job to make sure this evidence exists. Inevitably, you will base some decisions on your judgment in place of data. Judgment-weighted decisions are okay, provided it’s explicitly communicated.</p>



<p><strong>6. Stakeholders should be involved early and often, and alignment should be explicit.&nbsp;</strong>You’re looking for either a “yes, I agree with this decision, or a “no, I disagree, but I can commit to moving forward.” Escalate quickly and cleanly to resolve misalignments.</p>



<h3>Communication Effectively</h3>



<p><strong>7. There is no such thing as over-communication.</strong> “Fluff” communication = enough communication.</p>



<ul><li>If you’re not sick of saying it, you probably aren’t saying it enough. Constant communication might feel like “fluff,” but it isn’t. Evangelism is a critical part of the role—and it’s your job to make sure the organization is aligned and swimming in the same direction.</li><li>Marty Cagan, in <a href="https://amzn.to/3eMLBS0">Inspired</a>, said it best: <em>Evangelize continuously and relentlessly. There is no such thing as over‐communicating when it comes to explaining and selling the vision. Especially in larger organizations, there is simply no escaping the need for near‐constant evangelization. You’ll find that people in all corners of the company will at random times get nervous or scared about something they see or hear. Quickly reassure them before their fear infects others.</em></li></ul>



<p><strong>8. You, the product manager, should have a uniquely high communication bar.  </strong>Most functions have a primary “output” that isn’t communication: Designers design, engineers code, etc. For you, communication&nbsp;<em>is</em>&nbsp;a primary “output,” and it should be exceptional.</p>



<p><strong>9. You have to own the narrative.&nbsp;</strong>When there’s a narrative vacuum, people will “creatively” fill in the blanks themselves—and you might not like it. Losing control of the narrative can be incredibly disruptive to your team’s ability to deliver.</p>



<h3>Being an Effective Operator</h3>



<p><strong><strong>10.</strong>&nbsp;<strong>Strong relationships enable strong collaboration.&nbsp;</strong></strong>“Have strong relationships” sounds obvious, but the importance of relationships “up,” “down,” and “across” can’t be overstated. Without a solid mix of relationships and credibility, you won’t succeed.</p>



<p><strong><strong>11. Don’t be in the weeds managing every nuance of every project; save this for emergencies</strong>. </strong>Swim in your lane, and give your team space to do their job(s). Focus on:</p>



<ul><li>Setting the goal, i.e., “what game are we playing?” and lead/help the team in figuring out how to get there (milestones, dependencies, alignment, etc.).</li><li>Leading the team. E.g., establish the communication cadence (updates, Slack channels, syncs), meeting rhythm, high-level project milestones, success metrics.</li><li>Don’t pester. Establish the right communication channels upfront, and let your team keep you updated. See “maker’s schedule” under (12).</li></ul>



<p><strong><strong>12. Greatness is achieved in the agency of others</strong></strong>. Product managers follow the “manager’s<a rel="noreferrer noopener" target="_blank" href="http://www.paulgraham.com/makersschedule.html">&nbsp;schedule</a>.”<strong> </strong>Engineers &amp; designers follow the “maker’s schedule.” Help your team be great “makers”—keep them unblocked; respond effectively to unfolding situations.</p>



<p><strong>13. Your job is to create clarity</strong>:<strong> </strong>This is some sound advice that I got early on (thank you, Greg!). As a product manager, constantly think about how you can <em>create clarity</em> for your team: Clearer product requirements, resolving edge cases, answering questions, etc.</p>



<ul><li>If you’re drowning in questions, you probably aren’t proactively communicating effectively, or the product requirements lack clarity. Some questions are natural, so use your judgment.</li></ul>



<p><strong>14. Be on top of your shit.</strong> Until I figure out how to better articulate this, I’ll say it ineloquently as “just be on it.” Know your business, your product, your team, be responsive, communicate relentlessly, make good decisions, own your results, get 1% better every day.</p>



<h3>Managing Your Time</h3>



<p><strong>15. 80% of your role is discovering the right product &amp; driving organizational alignment, and 20% is answering clarifying questions for the “makers” on your team. </strong>Product teams are in a constant cycle of discovery and delivery, which run in parallel: </p>



<ul><li>In an ideal world, engineers are ~80% delivery, ~20% discovery; product managers are ~80% discovery, 20% delivery.</li><li>In large complex organizations, this is a difficult target to achieve, but strive to spend 80% of your time on discovering the right product (ideation, validation, testing, etc.) and communication (driving organizational alignment, creating clarity).</li><li>“Organizational alignment” is an intentionally broad term, including everything from 1-1 meetings to executive strategy reviews to product “deep dives” to all-hands presentations.</li></ul>



<p><strong>16. Ensuring that you have time set aside for strategy and “focus” work is your responsibility. </strong>Getting sidetracked with 1,000 emails and Slack messages is natural, but it can’t be an excuse. Make sure you have time set aside for focused work.</p>



<h3>Running Effective Meetings</h3>



<p><strong>17. Send agenda items beforehand. At the start of the meeting, collect input,</strong> <strong>and align on the goal. </strong>Meetings are expensive; when people are meeting, they often aren’t making. Own the meetings you run, and make sure they’re productive.</p>



<p><strong>18. Use “DAD” to help structure and run meetings</strong>. Most meetings are a mix of Discussion, Actions, and Decisions: Document any decisions, communicate topics of discussion and enumerate any action items.</p>



<p><strong>19. “ABFU,” or Always Be Following Up (terrible, I know).</strong> Make sure you (or someone else) sends notes to all relevant stakeholders within ~24 hours. They don’t need to be perfect, but make sure they exist and that you communicate them.</p>



<p><strong>20. Be deeply curious, and ask the “dumb” questions.</strong> Asking the right questions, even if they seem dumb, is a catalyst for creating clarity. Ask questions openly, in earnest, and let everyone else hear the answer. You probably weren’t the only one with that question.</p>



<h3>Running Projects &amp; Other</h3>



<p><strong><strong>21.</strong>&nbsp;<strong>Every project includes a mix of Discovery, Design, and Delivery (and iteration); you should make sure these run in sequence.&nbsp;</strong></strong>While we expect and&nbsp;<em>desire</em>&nbsp;some overlap, aspire not to make sweeping changes to design during delivery (as an example).</p>



<p><strong>22. Be responsive; if you’re not, you might be holding things up. </strong>As the hub between every other function, and often the decision-maker, you have to keep the wheels greased for your team. One idea: ~2 hours for Slack, ~2 days for email (but much faster for anything urgent).  </p>



<hr>



<h4>Further Reading</h4>



<ul><li><a href="https://amzn.to/3em4Fqi">Principles</a>, by Ray Dalio, which inspired this exercise.</li><li><a href="https://amzn.to/3eMLBS0">Inspired</a> by Marty Cagan. If there’s one book on Product Management you should read, it’s this. At some point, I’ll publish my ~3,000 words of notes from it!</li></ul>

			<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://reeve.blog/blog/principles/"
    dc:identifier="https://reeve.blog/blog/principles/"
    dc:title="22 Principles for Great Product Managers"
    trackback:ping="https://reeve.blog/blog/principles/trackback/" />
</rdf:RDF>-->
</div></article></main></div></div></div>]]>
            </description>
            <link>http://reeve.blog/blog/principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900783</guid>
            <pubDate>Mon, 20 Jul 2020 18:56:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I compiled book recommendations from 1300+ leaders]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23900185">thread link</a>) | @vhpoet
<br/>
July 20, 2020 | https://readthistwice.com/people | <a href="https://web.archive.org/web/*/https://readthistwice.com/people">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://readthistwice.com/people</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900185</guid>
            <pubDate>Mon, 20 Jul 2020 17:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bunkerpunk: Short Stories About Bunkers During the Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23899998">thread link</a>) | @jamesjyu
<br/>
July 20, 2020 | https://sudowriters.com/anthology/bunkerpunk/ | <a href="https://web.archive.org/web/*/https://sudowriters.com/anthology/bunkerpunk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  	<header>
  		<a href="https://sudowriters.com/"></a>
  		<a href="https://sudowriters.com/"><span><span>sudo</span>writers</span></a>
  		
  		<p>SUDOANTHOLOGY VOLUME TWO</p>
  		
  	</header>
  	
    <section id="intro">

  <p>The following stories were crafted in the dismal months of April, May and June, in the unfortunate year 2020. While the theme for this anthology, Bunkerpunk, was chosen in late March, the proceeding months saw real-life bunkers in the news as the world descended further into the persistent, low-grade chaos that has come to define our era. If you happen to be reading this from a bunker, we hope you’re well stocked on cola and emotionally prepared for an alien invasion. May these six works of fiction remain such, at least until you’ve had the chance to finish reading them.</p>

  <p><em>Thea Boodhoo</em></p>

</section>







<section>
	<h2><a href="#indomitable-inc">Indomitable, Inc.</a> by Amit Gupta</h2>
	<p>5 min read • A bunker to stop the zombies becomes anything but.</p>
</section>

<section>
	<h2><a href="#cells">Cells</a> by Thea Boodhoo</h2>
	<p>1 min read • Do you wonder what your cells are doing today?</p>
</section>

<section>
	<h2><a href="#the-dead-do-not-live-underground">The Dead Do Not Live Underground</a> by James Yu</h2>
	<p>11 min read • A coroner and his drone investigate one more bunker.</p>
</section>

<section>
	<h2><a href="#contained">Contained</a> by Elizabeth Menozzi</h2>
	<p>7 min read •&nbsp;The year can't get any worse, so it does.</p>
</section>

<section>
	<h2><a href="#the-secrets-of-facility-oscar-zero">The Secrets of Facility Oscar Zero</a> by Scott Hurff</h2>
	<p>6 min read • A girl shocks her parents when she discovers a long-forgotten chat protocol.</p>
</section>

<section>
	<h2><a href="#432-park-avenue">432 Park Avenue</a> by Sahil Lavingia</h2>
	<p>5 min read • A couple tries to find a way off their rooftop.</p>
</section>



<section id="indomitable-inc" data-author="Amit Gupta" data-title="Indomitable Inc.">
  <h3 id="indombitable-inc">Indombitable Inc.</h3>

  <div>
  <div>
  <p><img src="https://sudowriters.com/assets/amit.jpg"></p><h4>Amit Gupta</h4>
  <p>Amit is a science-fiction writer, optimist, and occasional advisor &amp; investor. More at <a href="http://amitgupta.com/">amitgupta.com</a> or <a href="https://www.twitter.com/superamit">@superamit</a>.</p>  
</div>

</div>

  <p>A month after Mohit moved, bankrupt and alone, into the underground bunker he built for 100, perimeter alarms echoed through the enormous structure for the first time. A lanky, dusty man popped up on the screens, torn-up backpack over one shoulder.</p>

  <p>Mohit pulled a baseball cap over his shaved head. He trotted through wide tunnels and up concrete stairs to the surface. Then he walked to the perimeter fencing, his body tense, his eyes glued to the lone figure. The man seemed unusually nonchalant, as if walking through the Mojave desert to a private compound miles from the closest city was something he did every day.</p>

  <p>“That laser wire up there?” the man asked, squinting up at the fence.</p>

  <p>“It is,” Mohit replied.</p>

  <p>The man observed Mohit for a minute, then asked, “this some kind of cult thing?”</p>

  <p>Mohit shook his head. He considered asking the man who he was, or turning and retreating underground, but found himself happy to be talking to anyone after a month alone. “It’s just a safe place. Safe from disease, dust storms, war, everything we’ve done to mess things up up here.”</p>

  <p>The man nodded thoughtfully, following the miles of laser wire and fencing with his eyes. Mohit waited. The air was dry, hot, and sharp. It felt dangerous, like if you inhaled it too quickly, you’d be rewarded with a nosebleed.</p>

  <p>“What’s it like inside?” the man asked, clearly in no rush.</p>

  <p>“Kind of like a big hotel,” Mohit answered. “But better! Loads of community spaces. Kitchens, movie rooms with great sound, meditation gardens–”</p>

  <p>“Meditation gardens, huh?”</p>

  <p>Mohit shrugged and adjusted his pitch. “Nice beds. Plenty of food, water, and medicine.”</p>

  <p>The man nodded, as if considering an unspoken offer. He looked past Mohit at the gray windowless edifice poking up through the sand. “Those walls–pretty thick…”</p>

  <p>“A meter thick. Mesh-embedded concrete to block radio signals,” Mohit boasted.</p>

  <p>“Zombie-proof?”</p>

  <p>Mohit felt himself blushing. He’d given dozens of interviews since his disastrous appearance on CNBC to announce his project. The one where, in a moment of youthful exuberance, he joked that the walls were so thick, “they’d even keep the zombies out.” The host chuckled, glanced off-screen and pumped his eyebrows, then turned back with a false smile, his teeth bright and sharp. Right away, Mohit knew it was over.</p>

  <p>After that, nobody cared that he’d risked all of his then-considerable fortune to bury 500 bunkers miles outside Berlin, Brooklyn, Buenos Aires, Boise, Cork, Cape town and so many others. It no longer mattered that he’d designed anti-contamination vacuum gaps and positive air pressure between sections and incorporated medical-grade fabricators, self-contained water cycling and food production, and layouts modeled on anthropological studies of successful, peaceful communes.</p>

  <p>Onstage at TED, he’d declared, “when our governments fail to take responsibility, we must rise to the challenge.” They applauded. But what spread were the SNL parodies and viral headlines: “10 Reasons Why Even the Wealthiest Preppers Aren’t Willing to Waste Money on Indombitable’s Zombie-proof Bunker.” The world thought he was a joke.</p>

  <p>Now Mohit squirmed in utility coveralls damp with sweat, the space between his skin and the thick canvas like a sauna. He thought about how much cooler it was down below.</p>

  <p>“So no zombies, then?” the man asked.</p>

  <p>“Just me.”</p>

  <p>A silence unfolded between the men standing on opposite sides of the fence. Each considered the other, the choices made to bring them there, and the options that lay before them. The man with the backpack shifted his weight from one foot to the other, then asked, “what do you got to eat? I’m Henry, by the way.”</p>

  <hr>

  <p>They came alone, then in small clumps. There were homeless men fleeing overcrowded shelters, mothers and fathers with arms full of children and eyes full of fear, trying to outrun the latest outbreak.</p>

  <p>Mohit showed each one around and welcomed them to the community. Henry developed strict quarantine procedures. A UCLA microbiologist, he’d been scorned for sounding the alarm on the rising viral threat and all but ostracized by the scientific community.</p>

  <p>As the geneticists and pharma corps fell a year behind, then two, then ten…as the mutation rate increased and new viruses tore through cities…as politicians implored people to go about their lives while they built shelters for themselves, the people kept coming.</p>

  <p>Then came the calls from would-be buyers from all over the world, offering vast sums for Mohit’s bunkers. Amounts that would have saved his company and reputation, if only they’d come a few months before. Mohit unlocked all the doors instead. What good was money when the world was on fire?</p>

  <p>A few years later, the bunkers filled and sealed shut. Decades passed. New waves of illness, climate catastrophe, and so many deaths.</p>

  <p>Outside, parking lots gave way to forest. Robins and sparrows nested in office drop ceilings, while small mammals took up grocery store shelves. Cities went wild once again.</p>

  <p>Inside, they maintained the hydroponic farms, tended to the sick, cooked together, sang together. Mohit’s empty concrete shells rang with life. He met his wife in the bunkers. Their sons were born here, raised here.</p>

  <hr>

  <p>“Shhhhh, wake up, Mohit,” Sandra said, ruffling her husband’s hair as he leaned against their bedroom doorway, tracing the notches etched into its frame with his fingertips.</p>

  <p>“Couldn’t sleep at all last night,” he said.</p>

  <p>She smiled, slipping an arm around his waist and leaning her head into his shoulder. “I couldn’t either. Thirty years. It doesn’t seem real.”</p>

  <p>They pressed against each other, lost in thought. All through the structure, people murmured excitedly. Viral transmission had fallen for 100 days straight and airborne contaminants were back to normal levels. Today the next phase would begin. One Mohit had never imagined when he’d created this place. The community had voted, and they’d decided to emerge.</p>

  <p>“I wish we didn’t have to leave those behind,” she said, nodding at the notches in the door frame. “I don’t want to forget that Munu and Sam were once that little.”</p>

  <p>“I traced them onto paper,” he said. “We can recreate them above.”</p>

  <p>Their sons met them outside their door, their faces set in wide grins. No longer children, but nervous and jittery just the same.</p>

  <p>Mohit’s heart swelled. This place had taken everything from him and given everything to him. He thought he’d earned his vindication when the bunkers filled. But he’d been wrong. This moment, when their faces met the sun and their feet felt the earth once more, when their sons would see the sky with their eyes for the first time. When they’d have a chance, along with whoever was left, to try again. This was the reason he had built them all.</p>

  <p>As the crowd moved up towards the vivid colors of rock and cactus, and into the startling warmth of the early morning sun, Munu nudged him.</p>

  <p>“Dad,” he said. “You know how we buried ourselves underground, and now we’re slowly rising to live again?”</p>

  <p>“Yes,” Mohit replied.</p>

  <p>“So we’re basically zombies, right?”</p>

  <p>Mohit smirked, nodding. Perhaps he’d just gotten it backwards. The bunkers hadn’t kept the zombies out, they’d kept them in.</p>

</section>



<section id="cells" data-author="Thea Boodhoo" data-title="Cells">
  <h3 id="cells">Cells</h3>

  <div>
	<div>
  <p><img src="https://sudowriters.com/assets/thea.jpg"></p><h4>Thea Boodhoo</h4>

  <p>Thea is a San Francisco based writer of science fiction and other things. You can find her at <a href="https://theaboodhoo.com/">theaboodhoo.com</a> and <a href="https://www.twitter.com/tharkibo">@tharkibo</a>.</p>
</div>
</div>

  <p>I wonder what my cells are doing today.<br>
As I putter from the first room to the second room and back<br>
As I brush my teeth. Did I just brush my teeth?<br>
Nope<br>
It feels like five minutes ago <br>
But it was last night.<br>
I wonder what my cells are doing as I lean into the glass<br>
Skin of my cheek pressed against the cold clear barrier <br>
between the shut-down world and the shut-in<br>
There are seagulls flying out there <br>
As if nothing’s changed<br>
I wonder what my cells are doing as I flip the calendar another month<br>
It’s been three years now<br>
No five<br>
No wait<br>
a thousand<br></p>

  <p>Since the choice<br></p>

  <p>We thought we were so informed <br>
The doctors and I<br>
Bake the breast with X-rays<br>
Keep the appointments<br>
Every six months <br>
An MRI here<br>
A mammogram there<br>
And you can keep the cells.<br>
Well I would have<br>
But no one told the appointments to keep me<br>
And now there are none<br></p>

  <p>I kind of thought 2025 would be better<br></p>

  <p>What are those cells up to now?<br>
Cooking ATP<br>
Weaving DNA<br>
Staying put, behaving<br>
Being good neighbors <br>
Good cells do what they’re told<br>
Just be breast tissue<br>
Nothing more<br>
No need for ambition …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sudowriters.com/anthology/bunkerpunk/">https://sudowriters.com/anthology/bunkerpunk/</a></em></p>]]>
            </description>
            <link>https://sudowriters.com/anthology/bunkerpunk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899998</guid>
            <pubDate>Mon, 20 Jul 2020 17:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What about Design?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23898679">thread link</a>) | @ppjet6
<br/>
July 20, 2020 | https://bouah.net/2020/07/what-about-design/ | <a href="https://web.archive.org/web/*/https://bouah.net/2020/07/what-about-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Who around here hasn’t heard about the tragic and inevitable death of XMPP
(eXtensible Messaging and Presence Protocol)? It’s a pretty common topic in
the community and around, often started by users of XMPP themselves missing a
certain feature in one or multiple specific implementations, or users of
alternative solutions. In a way this is my own version of why XMPP is or isn’t
doomed.</p>
<p>To go down this rabbit hole, we first need to set a few definitions. Most of
my readers would probably know what XMPP is, but I feel obligated to provide a
short reminder as it will allow me to highlight specific points I want to talk
about.</p>

<p>XMPP is a communication protocol, that is “nerd” speak to say it’s a language
for applications to use and talk together at a level that the end-user doesn’t
see. An example would be a chat application: your desktop or smartphone app
talking to a server that then talks to another app.</p>
<p>It is defined as a standard at the <a href="https://ietf.org/">IETF (Internet Engineering Task
Force)</a> – a standard being the specification of a protocol
(a document, in this case publicised and accessible by anyone), which allows
multiple products implementing what it describes to be able to work together
in an interoperable way.</p>
<p>Core specifications of XMPP are written so that it is easily extendible
allowing any developer to use custom (XML) elements for their own use, and
optionally write a specification for their new feature for everyone else to
use.</p>
<p>XMPP also defines a client-server-server-client model, where a client can talk
with a server that can then talk with multiple servers before reaching other
clients, thus allowing for <a href="https://en.wikipedia.org/wiki/Decentralization#Technological_decentralization">decentralization</a> – anyone setting up their own
server to be free from restrictions of other operators, and communicating with
the world or part of it.</p>
<p>So there we have it: (IETF) <strong>Standard</strong>, <strong>Decentralized</strong>, and
<strong>Extensible</strong>. These are, I believe, the 3 selling-points of XMPP.</p>
<p>From there tons of features can be implemented and then negotiated (as part of
the extensibility) and many things can change to use newer extensions that
weren’t considered in the core specifications. For example even the
serialization format (words of the language applications talk, originally XML)
can be changed (just as <a href="https://xmpp.org/extensions/xep-0322.html">EXI</a> is doing), and it’s also perfectly
fine to have non-compliant behaviour as long as it has been negotiated by
entities taking part in it. And so on…</p>
<p>The <a href="https://xmpp.org/">XSF</a> (XMPP Standards Foundation, previously known as Jabber Software
Foundation) is the entity that did the original work on the protocol and
submitted it to the IETF. It now has a sheperding role. There is no
requirement that XMPP extensions be brought to the XSF, but it aims to be the
place where technical knowledge around XMPP is gathered, so people can get
better feedback when submitting their new specification. Developers have
already layed out lots of protocol bricks for others to reuse through the XSF.</p>

<p>This is indeed the core of the problem. While extensibility is one of the
strenghs of XMPP, it’s also its main weakness, one of the main points of its
critics. That said, I believe it’s not as bad as they make it look like.</p>
<p>It is true that most applications are incompatible one way or another, with
various degrees of significance, either because they don’t implement the same
set of extensions, or because an author interprets extensions differently,
or simply because of bugs.</p>
<p>For the rest of this article I will leave aside the last two points –
interpretation issues and bugs – as I consider both of them bugs – of
specifications and/or implementations – and bugs happen everywhere and can be
fixed. Generally, determining what is a bug and what is a (unintended?) feature
is where the issue lies.</p>
<p>While there have been attempts within the XSF at defining common sets of
extensions in what is called “Compliance Suites” (currently updated on a
yearly-basis: <a href="https://xmpp.org/extensions/xep-0423.html">2020</a>, <a href="https://xmpp.org/extensions/xep-0412.html">2019</a>, etc.), they have in my opinion
had mild success for the effort it takes the author to gather feedback and
come up with not-so-controversial changes for newer revisions.</p>
<p>What these Compliance Suites don’t take into account so well, despite recent
efforts; and what critics don’t account for either when saying XMPP is
missing X, or that all implementations should do Y, is that it’s not just
about features and protocols.</p>
<p>The process of coming up with a common set of extensions for an implementation
requires a lot more groundwork. This includes figuring out who the userbase
is, and how the experience for it should be, i.e., design. This process should
be applied across a set of implementations, using the same design guidelines and
ensuring interoperability.</p>
<p>It is not enough if somebody using <a href="https://conversations.im/">Conversations</a> on mobile talks to somebody
else using <a href="https://dino.im/">Dino</a> on desktop, even if they both follow the Compliance Suites
for a given year and can then interop on a “basic” level, which to be honest, is
still pretty advanced, they have different design guidelines and there will
inevitably be areas where they differ and some features won’t behave as
expected on the other side. The issue is not that there is no design
guidelines, it’s that they’re not the same.</p>

<p>Multiple solutions following this design process already exist, such as
<a href="https://www.xabber.com/">Xabber</a> and <a href="https://tigase.net/tigase-instant-communication">Tigase</a>. <a href="https://snikket.org/">Snikket</a> is a new addition in this domain. You can
read about its goals <a href="https://blog.prosody.im/introducing-snikket/">in the introduction article</a> or in a
<a href="https://www.reddit.com/r/xmpp/comments/f0el07/can_someone_explain_to_me_whats_the_point_of/fgto5h0/">more detailed explanation</a> from its author. At the time
of writing it is composed of a rebranded <a href="https://prosody.im/">Prosody</a> (server) and Conversations
(client), is entirely based on XMPP and federates with the XMPP network. But
the important part – and also why it deserves a name other than “XMPP” – is
its goal: to provide a server and a (set of) client(s) that interoperate
properly and have common design guidelines that match the expected userbase.</p>
<p>Maybe you’re not part of Snikket’s target, in which case there might someday
be a similar solution that’s more adapted to your use-case. For the more
technical of us who understand the protocol and/or can deal with less unified
designs, it may be ok to continue using our current applications and work
around these issues ourselves. For the mass audiences I believe this is not an
option.</p>

<p>To the question I set to answer at the beginning I say this: Why does it
matter? For whom? My goal is to bring standardization, decentralization, and
extensibility to mass audiences. Not to bring XMPP to them. As explained above
I believe we need product suites with common design guidelines, and they
should include these properties. XMPP has good building blocks but lacks
consorted design.</p>
<p>I want decentralization and standardization to prevent users from being locked
in closed – often also proprietary – silos such as WhatsApp, Hangouts,
Slack, MS Teams, Tik-Tok, or even Signal. And I want extensibility to prevent being
stuck in the past and to adapt to the people’s needs.</p>
<p><em>Comments available on your usual centralized platforms: <a href="https://www.reddit.com/r/xmpp/comments/hun47q/what_about_design/">reddit</a> and <a href="https://news.ycombinator.com/item?id=23898679">HN</a>,
but also <a href="https://post.lurk.org/@pep/104546844162627507">mastodon</a>.</em></p>

      
    </div></div>]]>
            </description>
            <link>https://bouah.net/2020/07/what-about-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898679</guid>
            <pubDate>Mon, 20 Jul 2020 15:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Look at Early Japanese Typewriters (2016)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23898649">thread link</a>) | @caust1c
<br/>
July 20, 2020 | https://filthyplaten.com/2016/07/23/__trashed/ | <a href="https://web.archive.org/web/*/https://filthyplaten.com/2016/07/23/__trashed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg"><img data-attachment-id="2747" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg"><img data-attachment-id="2746" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender-7/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg" data-orig-size="3264,566" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1469299298&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1396 1396w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1024 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
A little while ago a friend of mine by the name of John Munroe sent me this great little Olivetti 32 ‘Katakana’ typewriter. I’d been keeping an eye out for such a machine for a number of years now, but as you may expect – such typewriters are generally non existent in markets that are available to Australia.</p>
<p>I spoke to John a little while back after he found a Royal that was set up for Japanese somewhere online, and I asked him to keep an eye out for one for my foreign language collection. John lives in Tokyo, and was confident that he’d come across another one pretty quickly.</p>
<p>And quickly he did. It wasn’t long before he managed to get his hands on this magnificent Olivetti Lettera 32. Of all the L32’s I have had, after this guy was cleaned up I found that &nbsp;types nicer than any other machine I have ever owned of this model.</p>
<p>So John Munroe. I owe you heaps, and much more than a huge, huge thank you!</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg"><img data-attachment-id="2748" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-side/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg" data-orig-size="1000,601" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti side" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
I’m very grateful to John for sending me this machine. Back when I was at high school, we were required to study two languages. Japanese and German. I was far better at German than Japanese, but I have long had a fascination with Japanese &nbsp;culture. My sister also lived there for 10 years and is fluent in Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg"><img data-attachment-id="2749" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard-overview/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard overview" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Katakana is only one piece of Japanese written language, and is often used to articulate English words into Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg"><img data-attachment-id="2750" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg" data-orig-size="1000,509" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The history of the Katakana keyboard dates right back to the late 1800’s. But it really came into existence in the 1920’s &nbsp;when some members of society in Japan were pushing for a simplified or reduced version of the Japanese language. The idea was to use that Katakana syllabary in a gestalt structure that is closer to the structure of European languages. While earlier keyboards were designed with a full set of Katakana glyphs (Kana), later they used dead keys on keyboards to allow the completion of characters.</p>
<p>This Olivetti has a couple of dead keys. Note the placement of the ‘P’ key? Right next to that… On the left, is the first dead key to be found on the keyboard. If found this positioning especially peculiar.</p>
<p><b>But wait..</b></p>
<p>What about the English characters on this typewriter?</p>
<p>Ahhhh yes… Well… That decreases the Kana (Katakana means Fragmented Kana) characters used one this keyboard.. Right?</p>
<p>The thing about katakana is, that it is also used in circumstances where English words are crammed into Japanese language – in the way that in English we italicise foreign language words.</p>
<p>So what does this typewriter do?</p>
<p>John’s suggestions that it is a typewriter that would be in use by telegraph operators to move between Japanese and English is a pretty sound one. Katakana can be used as a simplified Japanese language.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg"><img data-attachment-id="2752" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender2/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg" data-orig-size="1024,194" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender2" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
But it could also be used in a studio to produce Katakana segments for English words on this machine – when the writer was using a different keyboard featuring other kana – Say… Hiragana. But I don’t think so. The push in Japanese society was based around making language more universal. Contentiously, several key developments occurred when there was a push in Japanese society towards using English langauge more universally. Although the by the late 40’s – post World Ward 2, there was also a push towards using French.</p>
<p>Either way, in the 20’s the first Typewriters &nbsp;were being produced based to write a &nbsp;in romanized gestalt structure in Katakana. Just for reference, the company that produced these first machines was Underwood – who Olivetti eventually bought and absorbed into their organization.</p>
<p><b>Let’s not mention Kanji.&nbsp;</b></p>
<p>No… Let’s. Let’s talk about Kanji.</p>
<p>Written Japanese language can be something of a horror to people that grew up outside of Japan. Even inside of it, there’s plenty of things that can – and do – often go wrong. It’s not that romanised languages are perfect – but the diverse structure in Japanese (a problem also shared with Chinese languages) often causes complexities. The positive thing about Kanji is that it allows for quite an efficient expression with more nuance.</p>
<p>So… Like every other language in existence, there’s plenty of people that take a much more puritanical view to their language and many &nbsp;in Japan resisted change. The problem was that there wasn’t much of a way to easily produce written documents on a machine. Considering that the Japanese language has thousands of characters – it obviously wasn’t going to be easily presented on the keyboard unless the keyboard was huge.</p>
<p>Enter item number 2 that is new to my collection. &nbsp;Welcome to the Nippon Type.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg"><img data-attachment-id="2751" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg" data-orig-size="1000,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Over a century ago the Japanese started producing heavy and lumbering machines that had thousand of typeface characters that operated wtih a feed mechanism which pulled characters out of a grill. It involved moving the carriage over the top of the grill and positioning it above the character and then feeding it upwards to a type hammer that pushed it against the page and the ribbon. It then drops the hammer back, and the character falls back into the grill.</p>
<p>This mechanism improved dramatically in later years, and instead of a moving carriage, the grill floated on a rack which moved under the carriage.</p>
<p>Eventually a character board was put in front of the carriage, allowing the user to type by moving the arm that was connected to the grill, that has a stylus on the end that the user points at a desired character with.</p>
<p>The characters are grouped into syllabary or kana, and kept together in an order that is predictable. As you can see in the photo below such groups are colored to make it easier for the typist.</p>
<p><b>Enter the Nippon Type.&nbsp;</b></p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg"><img data-attachment-id="2753" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-front/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg" data-orig-size="1000,605" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon front" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><b><br>
</b></p>
<p>On the left of the machine is a solid arm that has a black knob that operates the character pulling mechanism. The small black lever next to that is the space bar. This allows the typist to quickly use operate with their left hand, while swinging the arm with the stylus with their right – selecting characters and quickly tapping it in.</p>
<p>The carriage has a large black lever that operates like every other carriage lever. Interestingly, the machine is set up to type right to left with the characters positioned to be read along the page, rather than down it as was traditional. Maybe the Katakana brigade made some in-roads there.</p>
<p>Interestingly, the typewriter also has a group of Roman characters grouped on the machine, allowing the user to type in English – or at use least English word. These are also regarded as Kana – and known as Romaji.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg"><img data-attachment-id="2754" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-elements_/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon elements_" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The characters are kept in a smooth moving tray that feels like it is floating under the machine. When the mechanism operatingarm is pulled down on the machine you can feel the tray Bing pulled into alignment to the closest character. Then the mechanism starts and the hammer makes a solid thump as it punches a character piece against the platen. It’s a surprisingly noisy operation. But quick.</p>
<p>To reduce the noise around the typewriter the rear of the machine has a noise deadening bulkhead that is supposed to absorb some of the noise.</p>
<p>But it isn’t anywhere near as fast as typing on a keyboard. The efficiencies that most typewriters produce for writers are all but wiped out by the movement which is more energy consuming than writing Kana by hand by hand.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg"><img data-attachment-id="2757" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-back/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg" data-orig-size="1000,656" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon back" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
This machine belonged to a former Australian Journalist that had been living in Japan and working there. I bought this machine off his daughter who was moving house on the day that I arrived to collect it. I can understand the appeal of this machine to a journalist in a foreign country. It would give a great refer ace board to access all the Japanese Kana on, which would make it quicker to learn and access. Obviously it has some great advantages over handwriting for legibility as well</p>
<p>The interesting thing about this machine is that – unlike the lumbering and heavy old &nbsp;Japanese typewriters of the early years, this beast is surprisingly light – weighing less than an Olympia SM4 in its case.</p>
<p>Sadly though, some of the type elements are missing, so the machine isn’t complete. Although interestingly enough, type elements can still be ordered.</p>
<p>Anyway, this is just a brief look at that crazy world that is Japanese typewriting. I hope you found these machines interesting. I’ll have a closer look at both and maybe their history in another post.</p>
<p>Thanks for reading.</p>
			
			
						</div></div>]]>
            </description>
            <link>https://filthyplaten.com/2016/07/23/__trashed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898649</guid>
            <pubDate>Mon, 20 Jul 2020 15:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Screwed by Lufthansa and the German Government, Saved by PayPal]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23898423">thread link</a>) | @ZeljkoS
<br/>
July 20, 2020 | https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal | <a href="https://web.archive.org/web/*/https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span data-preserver-spaces="true">The travel and tourism sectors are suffering because of the COVID-19 pandemic, and governments are scrambling to offer subsidies to affected businesses. But, there is little talk on how companies are transferring their costs to citizens, with government approval.</span></p><p><span data-preserver-spaces="true">In this case, the company is Lufthansa, who canceled my May flight from Croatia to Germany three weeks before the flight date. I booked the flight before the pandemic started, so I was a bit relieved. My reason for being in Berlin was valid for entry, but I was to either self-isolate for two weeks or get tested for COVID-19, both a hassle. If Lufthansa decided to cancel the flight and return the money, no problem.</span></p><p><span data-preserver-spaces="true">But that is not what Lufthansa decided. Their <a href="https://svedic.org/wp-content/uploads/2020/07/Lufthansa-cancelation-email.png" target="_blank" rel="noopener noreferrer">cancellation email didn’t mention refunds, but offered flight vouchers instead</a>. As the email was a no-reply email, calling customer support was the only option. Lufthansa’s support representative agreed to issue a full refund. But they said that processing the refund can take up to six weeks, as they are overwhelmed with requests. EU consumer protection law requires refunds for an undelivered product or service to be issued within 30 days, but these are exceptional times, so I agreed. What Lufthansa didn’t agree to was stating that in writing, in a letter or email.</span></p><p><span data-preserver-spaces="true">Six weeks came and passed without a refund. On a second call, Lufthansa’s support representative repeated the story. They are overwhelmed with requests, my refund will be processed in 2-3 weeks, no need to worry, but they will not provide that statement in writing.&nbsp;</span></p><p><span data-preserver-spaces="true">While waiting for their promise, I stumbled across an article explaining my issue as part of a bigger, EU-wide story. Lufthansa was on the verge of bankruptcy and <a href="https://www.theguardian.com/business/2020/may/26/lufthansa-9bn-bailout-german-government-coronavirus-flights" target="_blank" rel="noopener noreferrer">agreed to a €9 billion bailout from the German government</a>. In an effort to save the company, <a href="https://onemileatatime.com/lufthansa-refund-policy/" target="_blank" rel="noopener noreferrer">the German government told Lufthansa that they don’t need to obey EU consumer protection law</a>, and that they don’t need to issue refunds. Lufthansa can issue vouchers for future travels instead. This situation is controversial because:</span></p><ul><li><span data-preserver-spaces="true">The German government is telling a German company they don’t need to follow EU law.</span></li><li><span data-preserver-spaces="true">The German government is playing favorites with one company. Other companies don’t have such luxury during the crisis, both in getting the loan or escaping the laws.</span></li><li><span data-preserver-spaces="true">German tax-payers are giving a large, risky loan to one air carrier.</span></li><li><span data-preserver-spaces="true">With the voucher system, other EU citizens are effectively giving indefinite, interest-free loans to Lufthansa.</span></li></ul><p><span data-preserver-spaces="true">Notice that the procedure of getting a voucher from Lufthansa is much easier than getting a refund. For a voucher, click on the link in the email and fill a form. For a refund, wait on the customer support line. But I am a stubborn person, and I hate vouchers. A few times in my life, given vouchers got unused or companies put restrictions on voucher use. In this case, there is a possibility Lufthansa will go bankrupt, and then their vouchers will be as useful as toilet paper. Wait, that may <a href="https://www.bbc.com/news/world-australia-51731422" target="_blank" rel="noopener noreferrer">come in handy in COVID-19 times!</a></span></p><p><span data-preserver-spaces="true">I was not surprised when three weeks passed and there was no refund. I felt screwed by Lufthansa, the EU, and German politicians. However, there was still one overseas ace up my sleeve I could use.&nbsp;</span></p><p><span data-preserver-spaces="true">I paid for my flight via PayPal, which offers consumer protection on purchases, and I decided to activate it. I didn’t have much hope, as worldwide pandemic cancellations were not typical PayPal disputes. Additionally, I didn’t have much proof except for the cancellation email. Lufthansa didn’t provide a written reply, the flight was erased from the Lufthansa website, and I didn’t record phone conversations.&nbsp;</span></p><p><span data-preserver-spaces="true">But, as soon I made my claim, I realized there is a hidden benefit. When a PayPal claim is created, there is a deadline and a written trail. In this case, Lufthansa was given until July 13th to respond:</span></p><p><a href="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg"><img title="PayPal deadline screenshot" src="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg" alt="" width="927" height="317" srcset="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg 927w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-300x103.jpg 300w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-768x263.jpg 768w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-500x171.jpg 500w" sizes="(max-width: 927px) 100vw, 927px"></a></p><p><span data-preserver-spaces="true">It seems that someone from Lufthansa replied before that, as I got my money on July 7th:</span></p><p><span data-preserver-spaces="true"><a href="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history.jpg"><img src="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history-197x300.jpg" alt="PayPal-case-history" width="197" height="300" srcset="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history-197x300.jpg 197w, https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history.jpg 540w" sizes="(max-width: 197px) 100vw, 197px"></a></span></p><p><span data-preserver-spaces="true">I am impressed by PayPal’s straightforward claims procedure. There was no paper forms or PDFs that I needed to sign. As an example, my friend Chris also got a Lufthansa April transatlantic flight canceled (a month before my trip). He asked Lufthansa for a refund, and to this day he still hasn’t received any of 700 EUR.</span></p><p><span data-preserver-spaces="true">You have all the facts above, so make your conclusions. These are my modest takeaways:</span></p><ul><li><span data-preserver-spaces="true">During a crisis, EU laws get overridden by national interests.</span></li><li><span data-preserver-spaces="true">During a crisis, businesses labeled a “national interest” by politicians get favorable treatment.</span></li><li><span data-preserver-spaces="true">PayPal consumer protection works, even in times of crisis.</span></li><li><span data-preserver-spaces="true">Creating a PayPal or credit company claim is easier than waiting on customer support lines, enforces deadlines, and has traceable communication.</span></li></ul><p><span data-preserver-spaces="true">To come to the beginning of this article, there are analyses of money lost by different business sectors due to COVID-19. It would be interesting to see an analysis of how much consumer money is currently locked in unused vouchers, and what percentage of them will actually get used in the future. For comparison, in normal times, just US consumers </span><a href="https://www.cbsnews.com/news/unused-gift-cards-add-up-to-3-billion-annually/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">lose up to $3 billion annually in unspent gift cards</span></a><span data-preserver-spaces="true">. It seems that 2020 is going to be an outlier.</span></p></div></div>]]>
            </description>
            <link>https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898423</guid>
            <pubDate>Mon, 20 Jul 2020 14:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Learn How to Build, Launch and Run a Shopify App]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23897934">thread link</a>) | @igrabes
<br/>
July 20, 2020 | https://courses.iangrabill.com/how-to-build-a-shopify-app | <a href="https://web.archive.org/web/*/https://courses.iangrabill.com/how-to-build-a-shopify-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://courses.iangrabill.com/how-to-build-a-shopify-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897934</guid>
            <pubDate>Mon, 20 Jul 2020 14:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A man trying to automate Thailand’s hospitals]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23897845">thread link</a>) | @danso
<br/>
July 20, 2020 | https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>O</span>n a balmy Bangkok afternoon in March 2020, Professor Djitt Laowattana was sitting in his second-floor office in the Institute of Field Robotics (FIBO), <a href="https://www.nytimes.com/2020/02/23/world/europe/italy-coronavirus.html">watching the news</a> out of Italy. Photos of doctors with<a href="https://www.cnn.com/2020/03/21/world/health-workers-doctors-photos-coronavirus-italy-wuhan-trnd/index.html"> faces marked from their masks</a> spread across social media as the country rapidly became the epicenter of Europe’s Covid-19 outbreak. “I told my staff, stop what you’re doing and focus on this,” Laowattana told <em>Rest of World</em>. “I wanted to make sure the same thing doesn’t happen in Thailand.”</p>



<p>His concerns were correct. According to <a href="https://www.icn.ch/news/more-600-nurses-die-covid-19-worldwide">recent estimates</a> by the International Council of Nurses, nearly half a million healthcare workers may have been infected by the virus. Thailand had already confirmed its first Covid-19 death by the end of February, and <a href="https://www.pri.org/stories/2020-02-07/virus-fears-spread-thailand-chinese-tourism-magnet">experts warned</a> that the country could become the next Covid-19 hot spot in the region. Sensing the urgency, Laowattana, who is known as Thailand’s most prolific roboticist, asked his staff to drop working on the 20 or so prototypes they had in various stages in production and focus on helping him create an arsenal to fight what he called “the great virus war.” Together, Laowattana and his team of students and engineers created FIBO Against Covid-19 (FACO), a group of fully autonomous robots designed to protect doctors and nurses on the front lines of the pandemic.&nbsp;</p>



<p>Over the last 20 years, Laowattana has built nearly 300 types of robots for industries ranging from food processing to automobiles, half of which are still used today. His innovations have earned him the moniker “the Godfather of Thai Robotics.” His robots do everything from disinfecting rooms and delivering supplies to remotely monitoring patients’ temperatures and symptoms.</p>



<p>In hopes of rapidly scaling the use of these robots, Laowattana also added 5G connectivity, which will allow hospitals to add as many robots as they need without overloading their systems. “I don’t like the coronavirus,” said Laowattana, “but the pandemic is a fast-forward button.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="BANGKOK, THAILAND - APRIL 22: Medical staff wearing PPE work in the acute respiratory illness clinic in Vibhavadi Hospital as they deal with the COVID-19 Coronavirus outbreak on April 22, 2020 in Bangkok, Thailand. The hospital is due to discharge their final coronavirus patient today as numbers of infections continue to drop across the country. The Thai government has imposed a 10pm to 4am curfew and has ordered the closure of entertainment venues, schools and parks in order to curb the spread of the COVID-19 coronavirus across the country. (Photo by Jack Taylor/Getty Images)">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Jack Taylor/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p><strong>Since the pandemic</strong> began, hospitals around the world have adopted robots for everything from cleaning hospital wards to allowing patients to socialize with friends and family while quarantined. Recent estimates predict the medical robotics industry will quadruple to <a href="https://www.prnewswire.com/news-releases/surgical-robots-market-growth%E2%80%94-24-4-cagr-up-to-2025%E2%80%94says-global-market-insights-inc-300984546.html">more than $24 billion</a> by 2025, from around $6 billion in 2018. Thailand also faces a shortage of nurses, a problem that’s been exacerbated by the pandemic. Laowattana hopes his robots may be able to lighten their load and allow them to focus on more-critical tasks.&nbsp;</p>



<p>“The genie is out of the bottle,” Robin Murphy, a robotics professor at Texas A&amp;M, told <em>Rest of World</em>. “It’ll get to a point where it’s not going to shock anyone that robots are wandering around a hospital.”</p>



<p>Thailand is keen to develop its medical robots. Last year, the <a href="https://www.mobihealthnews.com/content/thailand-board-investment-help-promote-medical-robotics">government announced</a> an eight-year tax break for manufacturers of medical robots and released statements encouraging hospitals to use medical robots. According to Laowattana, the virus came at a fortuitous moment.</p>



<p>After a month of blueprinting and prototyping, in early April, Laowattana introduced his arsenal to a select group of doctors from Thailand’s most prestigious teaching hospitals. He had two new robots.&nbsp;</p>



<figure><blockquote><p>“I don’t like the coronavirus, but the pandemic is a fast-forward button.”</p></blockquote></figure>



<p>The first was CARVER. Prototyped in FIBO’s headquarters and equipped with ultraviolet lights to disinfect wards as it moves, CARVER looks like a giant Roomba dressed for a rave. The robot’s 18&nbsp;shelves also help carry medicine and other essential supplies to Covid-19 patients. Laowattana hoped CARVER would reduce the amount of exposure for nurses commonly assigned to routine but high-risk tasks.</p>



<p>The crown jewel of Laowattana’s arsenal, however, was SOFA: a 150-centimeter-tall humanoid with a conical lower half that gives it a feminized appearance. Its placid blue and white tones and three protruding high-tech cameras make it look both dainty and unsettling. One camera helps tell a patient’s temperature, while another is used for video conferencing. On its chest, a third high-definition magnifying camera allows doctors to examine a patient’s tongue or eyes without ever having to leave their offices. Like CARVER, SOFA can also be programmed to roam autonomously or controlled from afar.&nbsp;</p>



<p>While most telepresence robots help doctors consult with patients remotely, SOFA’s decked-out sensors also allow doctors to monitor a patient’s vitals. “When the crisis started, we didn’t have any solutions to help us examine patients from afar,” Dr. Sithakom Phusanti, deputy director at Chakri Naruebodindra Medical Institute in Bangkok, told <em>Rest of World. </em>Doctors at Phusanti’s hospital are among the first in Thailand to be able to examine patients in their Covid-19 ward from the comfort of their offices.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/1594910343458-small-40x23.gif" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/1594910343458-small.gif" data-srcset="" sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>According to a</strong> study conducted by the University of Edinburgh, hospitals have traditionally been reluctant to introduce robotics in large part due to fears of worker displacement and the negative connotations of robots for healthcare workers and patients alike. To quell some of these anxieties, Laowattana stressed that SOFA isn’t here to take their jobs. His robots have no diagnostic abilities, and when interacting with patients, a doctor is always in the cockpit.&nbsp;</p>



<p>Designing robots to interact with patients also comes with its own set of challenges. While doctors can adopt a good bedside manner when dealing with vulnerable patients, giving a robot the appearance of congeniality requires both design and cultural considerations.&nbsp;</p>



<p>Laowattana created SOFA by redesigning a prototype of a greeting bot for one of Bangkok’s luxury malls. He thought its tiny stature and childlike appearance would help disarm otherwise vulnerable patients. He even tweaked SOFA to operate at 10% of its original speed.&nbsp;</p>



<p>“In Thailand, going fast doesn’t convey good meaning. It’s impolite,” he says. When roaming the wards, SOFA projects two baby-blue eyes and a pixelated smile on a small screen, though it can show a range of positive emotions, from surprise to love. A second screen sits on its waist, allowing doctors to remotely share a patient’s medical records. Its jointed arms and fingers serve no medical purpose, but according to Laowattana, patients would rather communicate with something that looks like themselves. When interacting with patients, SOFA replaces its digital smile with a video of the controlling doctor, reminding patients that a human is still in the driver’s seat.&nbsp;</p>



<p>SOFA robots have become something of a national treasure in Thailand. They have even <a href="https://www.facebook.com/fibokmutt/posts/3139870376075286">earned a nickname</a> from the country’s princess: “<em>Mod Borirkasa</em>,” or “Guardian Ant.”&nbsp;</p>



<p>There are also consequences for culturally inadequate design. In 2018, Bangkok’s Mongkutwattana General Hospital <a rel="noreferrer noopener" href="https://www.thailandmedical.news/news/acute-shortage-of-nurses-in-thailand-forces-hospital-to-turn-to-robot-nurses." target="_blank">met with internet infamy</a> after photos of its robots’ glowing red eyes spread across the web. Purchased from a manufacturer in China, where red is considered an auspicious color, the robots were perceived as menacing in Thailand. “People would joke, if they bring you to our hospital late at night, you better run away,” a doctor who worked at the hospital told&nbsp;<em>Rest of World</em>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-400x294.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/IMG_5910-600x440.jpg 600w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>Despite their initial</strong> hesitance, doctors and nurses at his hospital have responded positively to their new mechanical colleagues, according to Phusanti: “They believe the system can help prevent viral transmission.” So far, none of Phusanti’s staff has been infected by the virus.&nbsp;</p>



<p>But while some doctors have been happy to adopt robotics in the wake of Covid-19, others have said the robots, at their $100,000 price tag, may be untenable for many Thai hospitals. A number of hospitals use cheaper, Chinese-produced robots, in part because they are able to receive them at low costs.&nbsp;</p>



<p>To address this concern, Laowattana has advocated for hospitals to obtain funding from the Thai government to purchase robots throughout the pandemic. While 40 have expressed interest in procuring them — pending government funding — bureaucratic delays have meant that only three hospitals have received the robots so far. The rest are still awaiting their funds to be approved.</p>



<p>Scaling the operation during a pandemic has also proven difficult, as parts have to be sourced from China and Europe. While FIBO was able to make the robots for three hospitals in-house, the institute partnered with Thailand’s Automation and Robotics Association (TARA), a consortium of industrial robotics manufacturers, to build more robots. But due to the pandemic, some essential parts have taken nearly three times longer to arrive. While Laowattana hoped to have the robots in eight more hospitals by the end of the month, such sourcing issues mean they may have to wait even longer.</p>



<p>For now, Thailand has successfully contained the virus. As far as his robots go, Laowattana sees their role expanding to treating other infectious patients, like those suffering from tuberculosis.&nbsp;</p>



<p>Two decades ago, Laowattana was considered a fringe scientist by his peers. But the pandemic has been a bittersweet validation of his life’s work. “I used to tell people that automation will happen over the next five years,” he said, “but today I tell people, it needs to happen now.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897845</guid>
            <pubDate>Mon, 20 Jul 2020 13:55:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Manage My Notes]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897371">thread link</a>) | @peterlk
<br/>
July 20, 2020 | http://peterklipfel.com/blog/taking_notes/ | <a href="https://web.archive.org/web/*/http://peterklipfel.com/blog/taking_notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-body">
                    



<p>I use obsidian for desktop, IA Writer for mobile, and keep everything in sync with Dropbox.</p>



<p>During college, while I was freelancing, I developed a habit of taking notes. This has served me well since then, and I have tried to manage my notes in more ways than I can remember.</p>

<p>The ones that I can remember trying are: Google Keep, Google Docs, Evernote, Jupyter notebooks, Aha!, Omni-notes, Notability, Apple notes, Nebo, vim + github, and a bunch of miscellaneous mobile apps.</p>



<p>After finding the solution that works for me, I’ve discovered what my requirements are:</p>

<ul>
<li><strong>Portable format</strong>: I want to be able to load my notes in any system. Potential candidates include docx files, markdown, and pdfs</li>
<li><strong>Access everywhere</strong>: I want to be able to see and read my notes after they’ve been synchronized</li>
<li><strong>Vim mode</strong>: When I’m at a computer, I’d like to be able to use vim mode to modify and update my notes</li>
<li><strong>Metadata</strong>: I need a good way of associating metadata with my notes like the time the note was taken and a way of linking notes</li>
</ul>

<p>But I also want to be able to use notes for other things:</p>

<ul>
<li>I have lots of miscellaneous thoughts during the day and need a way to capture them</li>
<li>I like to keep track of quotes</li>
<li>I often track things like grocery lists</li>
<li>I like to keep track of todo items</li>
</ul>

<p>And it would be nice if the apps that I took my notes on had a dark mode.</p>



<p>I think I may have finally found the solution that works for me, and I want to share my setup just in case it works for other people too. The keystone to my new note-taking strategy is Obsidian. I absolutely love this note-taking app, and whole-heartedly recommend it to anyone. I hope that it continues to be the simple, elegant, and powerful editor that it is today. Disclaimer: I’m not affiliated with them in any way, and don’t have anything to gain by promoting them.</p>

<h2 id="markdown">Markdown</h2>

<p>When I have used other formats, I always run into corner cases where the note system breaks down. For example, I have always wanted to have my blog posts in the same place as the rest of my notes, but they always seem to get out of sync - I’ll write the original post in one place, and then have to copy it back and forth between systems. This led to my notes and my blog getting out of sync (the blog that you’re reading is my third “real” attempt at getting my blog going).</p>

<p>But markdown has become universal. I can write things in a single format, and load them into any system for viewing. There are a bunch of apps that allow for markdown authoring. I like IA Writer for mobile, and I use Obsidian on all my computers to keep things in sync.</p>

<h2 id="daily-notes">Daily Notes</h2>

<p>Obsidian gives me a convenient format to put all my day-to-day ramblings, todos, and notes called “Daily Notes”. I have a folder called “Daily Notes”, and each file in this folder is the date of the note (for example, 2020-08-10.md). I also use Obsidian’s Daily Note Template to automatically generate a note with my default format.</p>

<p>Obsidian handles this all for my automatically, but the system is simple, so I can do it manually pretty quickly if I want to, say, plan for the next day while I’m laying in bed.</p>

<h3 id="daily-note-format">Daily Note Format</h3>

<p>My daily notes contain the following sections specified as markdown headings:</p>

<ul>
<li><strong>TODO</strong>: I put all the tasks that I want to get done “today” in this section

<ul>
<li><strong>Stretch</strong>: As things come up during the day, I often put them in this section, and move them to the next day if I don’t get to them</li>
</ul></li>
<li><strong>Personal Goals</strong>: I generally have personal objectives that I am actively  working on. This is where I track those objectives, and their output (metrics, notes, links, etc.)</li>
<li><strong>Business Goals</strong>: I like to track the ongoing goals at my job separately from my personal goals.</li>
<li><strong>Accomplished</strong>: It’s nice to lay in bed at night and make a list the things that I got done that day</li>
<li><strong>Daily thoughts</strong>: This section is freeform, and is more like my “journaling” section. As I’m wandering through the day, for example, and I have the next billion dollar business idea, solutions to world hunger, or breakthroughs on artificial general intelligence, I’ll add them to this section.</li>
</ul>

<h2 id="vim-mode">Vim Mode</h2>

<p>Despite how cumbersome it was to constantly have to boot jupyter notebooks, I loved being able to write my notes with a vim mode. I am so much more efficient when I can take note in vim mode. For example, if I’m on a call, I can simply press enter to separaet things in a list, and then make the list when there is a lull in noteworthy conversation by using <code>ctrl+v</code> + move up several lines + <code>shift+i</code> + “-”.</p>

<h2 id="synchronization">Synchronization</h2>

<p>I use dropbox to synchronize files across all my devices. My only gripe with Dropbox is that it <em>really</em> wants you to use a folder called “Dropbox”, which is kind of annoying. But it’s available in all places, and it does a good job of synchronization, so it’s fine.</p>

<h2 id="blog">Blog</h2>

<p>The blog that you’re reading right now is generated with markdown files, so I cloned the repository into my dropbox, and now I can modify and write blog posts in the same place that I take my notes! This was a huge win for me.</p>

<p>I’m still looking for a way to automatically deploy my site when I push to master in order to remove the need to run a deploy script (and have the necessary dependencies in place to do so). Netlify looks like it might be a good solution to this problem, but I haven’t set it up yet.</p>

<h2 id="zettelkasten">Zettelkasten</h2>

<p>I didn’t know there was a word for this style of taking notes until it became trendy a few months ago, but I find that prepending notes with dates is extremely useful for cases where I might have had multiple meetings on the same subject, or where I met with the same person multiple times, but do not have a regularly scheduled meeting with them (I put those in dedicated “1x1” notes).</p>



<p>I haven’t figured out a good way to use tags yet. I’ve tried it in the past, and I end up with more tags than I do notes, making the tags less useful than full-text search. Side note: full text search comes for free with markdown because it’s such a simple file format. Most applications can do it, or you can just do a <code>grep</code> if you have a terminal open.</p>

<p>Also, I still haven’t figured out a great way to link notes to each other. Folders do a pretty good job of grouping similar notes, and I haven’t found a compelling use case for linking notes. But it’s nice to have solutions in the tool box in case problems arise.</p>

                </section></div>]]>
            </description>
            <link>http://peterklipfel.com/blog/taking_notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897371</guid>
            <pubDate>Mon, 20 Jul 2020 13:04:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Problem with Tor]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23897288">thread link</a>) | @worldofmatthew
<br/>
July 20, 2020 | https://worldofmatthew.com/post/tor-german-avoid/ | <a href="https://web.archive.org/web/*/https://worldofmatthew.com/post/tor-german-avoid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>
<div>
<p>Over the past year, relay operators have done a good job in diversifying the range of network that they use to host their relays. The problem is that the move away from popular ASNs has not always translated to a move away from popular countries.</p>
<p>This is where we come to Germany, which has the highest amount of Tor relay capacity in the World at 167Gbps, in contrast France is in 2nd place with 64.5Gbps of capacity aka more than 100Gbps lower than Germany.</p>
<h2 id="the-problem-with-germany">The problem with Germany</h2>
<p>The German state is that exactly in love with the Tor network. This is the state who started <a href="https://itnomad.wordpress.com/2006/09/10/germany-crackdown-on-tor-node-operators/">raiding Tor relay operators in 2006</a>, <a href="https://blog.torservers.net/20180704/coordinated-raids-of-zwiebelfreunde-at-various-locations-in-germany.html">illegally seized</a> documents from German exit relay operator; torservers.net in 2018, tried to pass a <a href="https://www.privateinternetaccess.com/blog/germany-considers-amendment-to-law-which-makes-it-illegal-to-run-a-tor-node-or-website/">really vague law in order to the running of Tor relays</a> and now are about to vote on a <a href="https://www.privateinternetaccess.com/blog/new-german-law-would-force-isps-to-allow-secret-service-to-install-trojans-on-user-devices/">law to hijack traffic</a> to download Trojans on the computer of anyone they target.</p>
<p>This is the aggressive anti-privacy shit that most people would expect of somewhere like Russia. This might not be what you expect from a country that claims to love the right to privacy and pushed for the GDPR.</p>
<p>In reality, the German government has a double standard when it comes to the right to privacy. They will fully support that right if it's company's violating your privacy (especially, if they are American because protectionism) but in contrast, the German will give itself as many powers as it can to spy on its own citizens and those abroad.</p>
<p>Now you know how the Germans hate privacy, you will almost certainly be asking about alternative locations.</p>
<h2 id="but-tor-is-encrypted">But Tor is encrypted?</h2>
<p>The high number of high-speed relays and exits in Germany mean that it is not too uncommon to get both a German guard and exit. This gives the state an easier time if they want to target someone using traffic correlation attacks.</p>
<p>That also does not take in account the planned German law that will allow authorities to redirect traffic to state-owned servers, to infect users with viruses/Trojans. This is especially a concern for third-world users of Tor who are going to mainly accessing non-HTTPS sites on a computer without the best security.</p>
<h2 id="what-alternatives-are-there-to-germany">What alternatives are there to Germany?</h2>
<p>The current country with the best privacy to cost ratio is Luxembourg, where a 200Mbit can be gotten <a href="https://gcorelabs.com/pricing/hosting/">for 3.25 EUR per month</a>. Or if you have the money than Switzerland would be more ideal but you would not want to waste a Switzerland VPS on a non-exit relay.</p>
<p>Or if you are cheap, you could get a VPS from a country who hates the western spy powers like Russia or Moldova which will still help enhance the security of the Tor network by decreasing the chances that someone's traffic will just travel though one spying block which will make traffic correlation attacks much harder.</p>
</div>

</article>
</div></div>]]>
            </description>
            <link>https://worldofmatthew.com/post/tor-german-avoid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897288</guid>
            <pubDate>Mon, 20 Jul 2020 12:55:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter Got Hacked, Is Mastodon Immune?]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 95 (<a href="https://news.ycombinator.com/item?id=23896994">thread link</a>) | @yogthos
<br/>
July 20, 2020 | https://mikestone.me/twitter-got-hacked-is-mastodon-immune | <a href="https://web.archive.org/web/*/https://mikestone.me/twitter-got-hacked-is-mastodon-immune">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Unless you've been hiding under a rock the last week or so, you probably know that Twitter got “hacked”. So, is Mastodon immune from having the same thing happen to it?</p>

<p>Before we can determine if Mastodon is in any better place than Twitter, we have to understand how Twitter's “hack” occurred.</p>

<p><a href="https://www.cnet.com/news/twitter-says-hackers-got-access-to-internal-tools-for-hijacking-spree/" rel="nofollow">CNET Reports</a>:</p>

<blockquote><p>We detected what we believe to be a coordinated social engineering attack by people who successfully targeted some of our employees with access to internal systems and tools</p></blockquote>

<p>Social engineering is <a href="https://en.wikipedia.org/wiki/Social_engineering_(security)" rel="nofollow">defined</a> as, “The psychological manipulation of people into performing actions or divulging confidential information.”</p>

<p>I would argue, and I'm sure most people would agree with me, that no one is perfectly immune from social engineering. It's part of being human, and as long as humans are involved in the situation, it's going to be a vulnerability.</p>

<p>I would also argue Mastodon's distributed nature makes such a coordinated and far reaching attack much less likely.</p>

<p>The attackers in this case targeted high profile individuals, and gained access to Twitter's own internal tools using social engineering. Obviously Mastodon has it's own internal tools, but those tools on <a href="https://mastodon.social/" rel="nofollow">mastodon.social</a> have absolutely no effect on <a href="https://fosstodon.org/" rel="nofollow">Fosstodon</a>, and vise versa.</p>

<p>If attackers wanted to coordinate a similar attack on Mastodon, they'd have to stick to individuals on a particular instance, or they'd have to socially engineer moderators/administrators on multiple instances.</p>

<p>No, this isn't an impossible task. After all, more than one individual was compromised in the Twitter hack. I do think it's more difficult though.</p>

<p>Twitter's response to this whole mess is also worth taking a look at. When Twitter discovered the “hack”, they immediately locked out all access to verified Twitter accounts. This caused a whole lot of problems for a whole lot of people, but I'm not going to talk about this now.</p>

<p>If Mastodon were to be “hacked” in the same way, the same outcome would not occur. Just because one instance of Mastodon is compromised does not mean that they all are. If one instance has to lock down accounts to reduce risk, the rest can continue to operate as they always have.</p>

<p>For the time being, Mastodon remains a small enough presence in the social media sphere that this kind of attack hasn't been worth the time. It is growing, and in time it very well may grow to a point where it is. While Mastodon isn't entirely immune to this kind of attack, it is more difficult and less rewarding. That makes is less of a target, even if all other things are equal.</p>

<p>Day 68 of the <a href="https://mikestone.me/tag:100DaysToOffload" rel="nofollow"><span>#</span><span>100DaysToOffload</span></a> Series:</p>
</div></div>]]>
            </description>
            <link>https://mikestone.me/twitter-got-hacked-is-mastodon-immune</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896994</guid>
            <pubDate>Mon, 20 Jul 2020 12:17:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer – a Zilog Z80 netlist-level simulator]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23896816">thread link</a>) | @segfaultbuserr
<br/>
July 20, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I’ve found that the Visual6502 team have done a wonderful work with mapping the cpu’s traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I originally imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user’s guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will expand on it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those “speeds”, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>That program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator’s internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added that version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> has "Image views" where it shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters.</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The chip/layer view can also be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, “annot_internals.json” (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain "macros", which are tokens that expand into named net's and bus' values, and those are updated in real time, as the simulation runs.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image.png" alt=""><figcaption>Dynamic annotations showing U and V bus values (~ means "inverted")</figcaption></figure></div>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the “Driven by” option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such “Driven by” algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the “Driving nets” option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate “Driving nets”, following the highlighted lines. Soon, you should reach a “dead end”, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type “img.state()” in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is “int_reset”, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various “gating” to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image-1.png" alt=""><figcaption>Waveform view can display signals in a variety of formats</figcaption></figure></div>
<p>The important thing to remember is to “name” the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select “Edit net name...”. You can type any name; a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896816</guid>
            <pubDate>Mon, 20 Jul 2020 11:41:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Different Take on Fukushima]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23896730">thread link</a>) | @baud147258
<br/>
July 20, 2020 | http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/ | <a href="https://web.archive.org/web/*/http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><span>I don’t know how many times I’ve started, stopped, and deleted trying to write something up on my trip to the Fukushima Hard-To-Return-To Area, AKA the Futaba District of the Fukushima Prefecture. Unfortunately, thanks to COVID-19, I have plenty of time to write this up now. I want to give thanks at the outset to my friend Robyn, the Hollywood photographer who I went with to Chernobyl, who came on this trip too and can view her gorgeous work <span><a href="https://www.vonswank.com/Curiosities-/JAPAN:-FUKUSHIMA/thumbs">here</a><span>, some of which I’ve used in this post</span></span>. I also want to give high fives to Jen Miller for inspiring me to see if I could make this visit even happen when we went to see sumo and to Brian Wanamaker who’s translation skills allowed the serendipitous, sake-filled meeting with Kae to be an inspiration. And, lastly, thanks to everyone who purchased a <span><a href="https://shop.funraniumlabs.com/products.php?product=The-Coffee-Wave-750ml">“Coffee Wave” BBotE</a></span> bottle for making sure we had the cash on hand to have ADVENTURES!</span></p>
<p><span>From the top, I’m not gonna discuss the ongoing work at Fukushima Daiichi. Plenty of ink and electrons already spent on TEPCO and JAEA doing what they can there. We can hope for a TV show that summarizes the events at the power plant as the Tōhoku quake and tsunami struck as well as HBO’s Chernobyl did. My quibbles with that show are minor at best. My favorite thing about it was people coming to me saying “Phil, I think they got something wrong on Chernobyl” and my grin of evil delight when I got to tell them that <a href="https://twitter.com/clmazin">Craig Mazin</a> lovingly captured period authentic Soviet bullshit and presented it faithfully. But I digress, because what is more interesting to me is the efforts to decontaminate, rehabilitate, and re-inhabit the abandoned area around the power plant. The example of the Chernobyl Exclusion Zone and the “settlers”, who are mostly pensioners left in the lurch by the Soviet collapse, gives one path. </span></p>
<p><span>That’s not what Japan did/is doing. But let me say this right now, because belaboring this is what caused me to abort so many previous versions of this post:</span></p>
<h4><span>These towns aren’t coming back. Not because they’re doing a bad job at cleanup. On the contrary, they’re doing an amazing job and are <em><strong>WAY </strong></em>more thorough than the Soviet Liquidators ever were. That is my professional opinion. Unlike Pripyat, a young nuclear boomtown for high fliers, the rural communities around Fukushima Daiichi were already fading away. The quake and tsunami just accelerated the pace.</span></h4>
<p><span>There. I said it. Now maybe I can explain why without tripping over myself.</span></p>
<p><span>This tale starts eight years ago, on March 11, when my career took a dramatic shift when some tectonic plates moved too. If you search for “UC Berkeley radiation specialist” this is very close to my and a former coworker’s job title. We both lost <em>month</em>s of work responding to a fire hose of phone calls, emails, and even faxes as the entire Pacific Rim turned to us as because The Algorithm™ <em>clearly</em> indicated we were the experts on what to do in when a reactor accident happened. More often than not, we had to refer everyone to the public affairs office who promptly turned around and asked us what they should say. This is the price of being professional staff and not tenured faculty; we don’t have the freedom of expression that comes with tenure, we’re just employees. I would like to note that this doesn’t necessarily mean the tenured faculty knew anything about what they were commenting on, but they do have the freedom to spout off to their heart’s content to any microphone and camera that came near. I actually went back to read <span><a href="http://www.funraniumlabs.com/2011/03/post-tsunami-japanese-reactor-problems/">the post I made two days after the quake</a></span> and was quite surprised to see how well I covered things.</span></p>
<p><span>For everyone that has now seen the Chernobyl miniseries on HBO and has that vision in their head for Fukushima Daiichi, you missed the big differences: there was no graphite fire and, holy crap, that was a hell of a quake and tsunami. For everyone now coming to grips with the idea of a double hit of pandemic and then economic collapse with COVID-19, try the <em>triple</em> disaster of one of the largest earthquakes ever recorded, a huge tsunami, and then slap a nuclear reactor accident on top of that. On a positive note, at least this triple disaster was relatively local in scope. The contamination around the Futaba District is due to the fuel rods leaking some fission products and a bunch of contaminated/activated sea water from the tsunami plus the cooling water of last resort pumping into the spent fuel pools without filtration (much less deionization) first. There were thousands of tons of graphite that lit on fire and exploded at Chernobyl, lofting a totally different set of radioactive materials across the world. Don’t get me wrong, we could detect Fukushima drifting on the breeze across the Pacific within 48hrs but the isotopic mix and quantity was <em>very</em> different than Chernobyl’s. And, as always, the drum I beat constantly for public education: there is a world of difference between “detectable” and “dangerous”.</span></p>
<hr>
<p><span>We were met at the train station by Shuzo in a prefectural government van. He made sure that the ID we’d brought with us matched what I’d supplied to him a few months earlier because and, I quote, “It would be very embarrassing if it did not as I wrote the security procedures.” A little later as we drove past a cultural festival and Shuzo gave an embarrassed chuckle as he said he should probably drive a little bit faster in case some of his people working the fairgrounds saw the van. I asked him how many people worked for him in his office. He replied with some uncertainty “”Four…five hundred? Plus contractors, of course.” I slowly turned my head as realized I wasn’t talking to someone in a roughly similar position to me back in the states, but rather an agency head that reported directly to the governor… and he had volunteered himself as a driver and guide because this project is so important to him. Some recalibration of the honor that was being done for us happened in my head then and there.</span></p>
<p><span>Shuzo has a dream to get his hometown back. As a “hometown boy done good” he isn’t just any prefectural official, he had to order his own family out of their homes and off their farms. He evacuated the JAEA office during the emergency. What he wants more than anything is for the communities to come back after the quake/tsunami/nuclear accident triple disaster. And, yes, you should always look at this is in that order of severity; the reactors were the least of the three but it has the consequences everyone is afraid of. The people most afraid of the quake and tsunami are, well, dead. As part of the TEPCO/JAEA remediation plan, as the Japanese government made a commitment that Futaba would not be abandoned like the Chernobyl Exclusion Zone and had learned some lessons from that; all of the local towns and farms were offered a settlement to turn everything over for decontamination and/or demolition. Shuzo’s job is to make that happen. He is quite literally in charge of everything that is outside of the power plant decontamination project. The first place he wanted to take us was to his father’s farm.</span></p>
<p><span>I helpfully already did some work of sharing an introduction to my hosts in 2018 when I first started writing this up. From that <span><a href="http://www.funraniumlabs.com/2018/10/fukushima-exclusion-zone-preview-announcements/">post</a></span>:</span></p>
<blockquote><p><span>First off, let me introduce you to Shuzo Sakai, Karin Taira and their project, <span><a href="https://real-fukushima.com/">Real Fukushima</a></span>. Unlike the Chernobyl tours of varying quality done by various independent operators, this is a Fukushima Prefecture government project to show the work done for decontamination and rehabitation of the towns in the Fukushima Exclusion Zone. Karin runs the prefecturally sponsored B&amp;B in Odaka called <span><a href="https://www.tripadvisor.com/Hotel_Review-g1022396-d12926635-Reviews-The_Lantern_House-Minamisoma_Fukushima_Prefecture_Tohoku.html">Lantern House</a></span> which I highly recommend if you have the time to stay overnight (sadly, I did not). Shuzo is a prefectural government official who grew up in a town that is now in the exclusion zone and he’s become head of the redevelopment agency. When you are the boss, you’re allowed to give yourself any extra tasks you want; the one he has chosen for his extracurricular activities is showing people the work done to rebuild and reoccupy. Only foreigners at the moment because, and I quote, “I feel foreigners have less radiophobia than the Japanese.” While I didn’t laugh out loud at this, I did tell him that if this was actually the case that my day job would be much easier. As a local boy done good, Shuzo’s desire is to see the people in the towns he’s always known and loved come home. He would also like people all over the world to see their hometowns in his. That you might remember to give your loved ones a call now and then, maybe go home and visit. They miss you, you know. :)</span></p>
<p><span>Shuzo is the person that wrote the procedures for entry into the Fukushima Exclusion Zone. Shuzo is the person who is ultimately responsible for the decon, demolition and reconstruction of all the towns in the Exclusion Zone. This is personal to him.&nbsp;</span></p></blockquote>
<div id="attachment_5054"><p><a href="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262.jpg"><img aria-describedby="caption-attachment-5054" src="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-225x300.jpg" alt="forest line" width="225" height="300" srcset="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-225x300.jpg 225w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-773x1030.jpg 773w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-768x1024.jpg 768w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-529x705.jpg 529w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262.jpg 1080w" sizes="(max-width: 225px) 100vw, 225px"></a></p><p id="caption-attachment-5054"><span>The Treeline At Shuzo’s Dad’s Place – once you hit that forest litter, the background count rate triples</span></p></div>
<p><span>Among the people that had to be evacuated were Shuzo’s parents. Shuzo isn’t the eldest son, so his brother’s family ended up taking them in. And then when the evacuation area was expanded, all of them got evacuated again together. This was a bit too much stress on his mother and she passed away. For the next several years, his father lived with his brother’s family even after dad’s home and farm were decontaminated because they didn’t necessarily trust dad to live on his own. At 82, he’d literally never done laundry or really cooked a meal in his life so they needed to teach him some basic survival skills before they could let him go back home to live alone. His father’s farm is a good demonstration piece to show the success of decon allowing reoccupation, but also it’s limitation. The house, driveway, sheds, and yard had no detectable radiation above background, but you didn’t have to walk far into the trees at the edge of the property for the count rate to rise a bit. This is a reflection of the phased approach to decontamination: homes/cities, then farms, …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/">http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/</a></em></p>]]>
            </description>
            <link>http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896730</guid>
            <pubDate>Mon, 20 Jul 2020 11:23:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI for Neovim Plugins in Lua]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896684">thread link</a>) | @lukzar
<br/>
July 20, 2020 | https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua | <a href="https://web.archive.org/web/*/https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>In the last <a href="https://www.2n.pl/blog/how-to-write-neovim-plugins-in-lua">article</a>, we saw the basics of creating plugins in Lua using floating windows. Now it's time for a more traditional approach. Let's create a simple plugin that will show us last opened files in handy side navigation. As we focus on learning the interface, we will use vim native oldfiles list for this purpose. It will look something like this:</p>

<p><img src="https://www.2n.pl/system/photos/imgs/000/000/011/original/oldfiles.gif" alt=""></p>

<p>If you didn't read previous <a href="https://www.2n.pl/blog/how-to-write-neovim-plugins-in-lua">article</a>, I highly recommend you to do so, because this article expands on the ideas from the last one and is full of new things in comparison.</p>

<h2>Plugin window</h2>

<p>Ok, so we should start by writing a function that will create our first window, where the <code>oldfiles</code> list will be displayed. But first, we will declare three variables in the main scope of our script: <code>buf</code> and <code>win</code> that will contain our navigation window and buffer references and <code>start_win</code> that will remember the position where we opened our navigation. We will be using these often across our plugin functions.</p>
<div><pre><span>-- It's our main starting function. For now we will only creating navigation window here.</span>
<span>local</span> <span>function</span> <span>oldfiles</span><span>()</span>
  <span>create_win</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>create_win</span><span>()</span>
  <span>-- We save handle to window from which we open the navigation</span>
  <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>botright vnew'</span><span>)</span> <span>-- We open a new vertical window at the far right</span>
  <span>win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span> <span>-- We save our navigation window handle...</span>
  <span>buf</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_buf</span><span>()</span> <span>-- ...and it's buffer handle.</span>

  <span>-- We should name our buffer. All buffers in vim must have unique names.</span>
  <span>-- The easiest solution will be adding buffer handle to it</span>
  <span>-- because it is already unique and it's just a number.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_name</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>Oldfiles #'</span> <span>..</span> <span>buf</span><span>)</span>

  <span>-- Now we set some options for our buffer.</span>
  <span>-- nofile prevent mark buffer as modified so we never get warnings about not saved changes.</span>
  <span>-- Also some plugins treat nofile buffers different.</span>
  <span>-- For example coc.nvim don't triggers aoutcompletation for these.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>buftype'</span><span>,</span> <span>'</span><span>nofile'</span><span>)</span>
  <span>-- We do not need swapfile.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>swapfile'</span><span>,</span> <span>false</span><span>)</span>
  <span>-- And we would rather prefer that buffer will be destroyed when hide.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>bufhidden'</span><span>,</span> <span>'</span><span>wipe'</span><span>)</span>
  <span>-- It's not necessary but it is good practice to set custom filetype.</span>
  <span>-- This allows users to create their own autocommand or colorschemes on filetype.</span>
  <span>-- and prevent collisions with other plugins.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>filetype'</span><span>,</span> <span>'</span><span>nvim-oldfile'</span><span>)</span>

  <span>-- For better UX we will turn off line wrap and turn on current line highlight.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_set_option</span><span>(</span><span>win</span><span>,</span> <span>'</span><span>wrap'</span><span>,</span> <span>false</span><span>)</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_set_option</span><span>(</span><span>win</span><span>,</span> <span>'</span><span>cursorline'</span><span>,</span> <span>true</span><span>)</span>

  <span>set_mappings</span><span>()</span> <span>-- At end we will set mappings for our navigation.</span>
<span>end</span>
</pre></div>
<h2>Drawing function</h2>

<p>Okay, so we have a window, now we need something to display in it. We will use vim <code>oldfiles</code> special variable, which stores paths to previously opened files. We will take as many items from it, as we can display without scrolling, but of course, you can take as many as you want in your script. We will call this function <code>redraw</code> because it can be used to refresh navigation content. File paths might be long, so we will try to make them relative to the working directory.</p>
<div><pre><span>local</span> <span>function</span> <span>redraw</span><span>()</span>
  <span>-- First we allow introduce new changes to buffer. We will block that at end.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>true</span><span>)</span>

  <span>local</span> <span>items_count</span> <span>=</span>  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_get_height</span><span>(</span><span>win</span><span>)</span> <span>-</span> <span>1</span> <span>-- get the window height</span>
  <span>local</span> <span>list</span> <span>=</span> <span>{}</span>

  <span>-- If you using nightly build you can get oldfiles like this</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>v</span><span>.</span><span>oldfiles</span>
  <span>-- In stable version works only that</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_vvar</span><span>(</span><span>'</span><span>oldfiles'</span><span>)</span>

  <span>-- Now we populate our list with X last items form oldfiles</span>
  <span>for</span> <span>i</span> <span>=</span> <span>#</span><span>oldfiles</span><span>,</span> <span>#</span><span>oldfiles</span> <span>-</span> <span>items_count</span><span>,</span> <span>-</span><span>1</span> <span>do</span>

    <span>-- We use build-in vim function fnamemodify to make path relative</span>
    <span>-- In nightly we can call vim function like that</span>
    <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>fn</span><span>.</span><span>fnamemodify</span><span>(</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>)</span>
    <span>-- and this is stable version:</span>
    <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_call_function</span><span>(</span><span>'</span><span>fnamemodify'</span><span>,</span> <span>{</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>})</span>

    <span>-- We iterate form end to start, so we should insert items</span>
    <span>-- at the end of results list to preserve order</span>
    <span>table.insert</span><span>(</span><span>list</span><span>,</span> <span>#</span><span>list</span> <span>+</span> <span>1</span><span>,</span> <span>path</span><span>)</span>
  <span>end</span>

  <span>-- We apply results to buffer</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_lines</span><span>(</span><span>buf</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>false</span><span>,</span> <span>list</span><span>)</span>
  <span>-- And turn off editing</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>false</span><span>)</span>
<span>end</span>
</pre></div>
<p>We can now update our main function. We will also add some code that prevents opening multiple navigation windows. For this purpose, we can use <code>nvim_win_is_valid</code> which checks if our plugin window already exists.</p>
<div><pre><span>local</span> <span>function</span> <span>oldfiles</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
  <span>else</span>
    <span>create_win</span><span>()</span>
  <span>end</span>

  <span>redraw</span><span>()</span>
<span>end</span>
</pre></div>
<h2>Openings files</h2>

<p>We can now look at our oldfiles, but it would be much handier if we can also open them. We will allow users to open files in 5 different ways! In a new tab, in horizontal or vertical splits, in the current window and in preview mode, which will keep the focus on navigation.</p>

<p>Let's start by opening files in the current window. We should prepare for two scenarios:<br>
1. Opening a file in the window from which the user opens navigation.<br>
2. Closing the starting window, when we will create a new one for opening file.</p>
<div><pre><span>local</span> <span>function</span> <span>open</span><span>()</span>
  <span>-- We get path from line which user push enter on</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>-- if the starting window exists</span>
  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>-- we move to it</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>-- and edit chosen file</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>edit '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>-- if there is no starting window we create new from lest side</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove vsplit '</span> <span>..</span> <span>path</span><span>)</span>
    <span>-- and set it as our new starting window</span>
    <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>
  <span>end</span>
<span>end</span>

<span>-- After opening desired file user no longer need our navigation</span>
<span>-- so we should create function to closing it.</span>
<span>local</span> <span>function</span> <span>close</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_close</span><span>(</span><span>win</span><span>,</span> <span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>-- Ok. Now we are ready to making two first opening functions</span>

<span>local</span> <span>function</span> <span>open_and_close</span><span>()</span>
  <span>open</span><span>()</span> <span>-- We open new file</span>
  <span>close</span><span>()</span> <span>-- and close navigation</span>
<span>end</span>

<span>local</span> <span>function</span> <span>preview</span><span>()</span>
  <span>open</span><span>()</span> <span>-- WE open new file</span>
  <span>-- but in preview instead of closing navigation</span>
  <span>-- we focus back to it</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
<span>end</span>
</pre></div><div><pre><span>-- To making splits we need only one function</span>
<span>local</span> <span>function</span> <span>split</span><span>(</span><span>axis</span><span>)</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>-- We still need to handle two scenarios</span>
  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>-- We pass v in axis argument if we want vertical split</span>
    <span>-- or nothing/empty string otherwise.</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>axis</span> <span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>-- if there is no starting window we make new on left</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove '</span> <span>..</span> <span>axis</span><span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
    <span>-- but in this case we do not need to set new starting window</span>
    <span>-- because splits always close navigation </span>
  <span>end</span>

  <span>close</span><span>()</span>
<span>end</span>
</pre></div>
<p>And in the end the simplest opening in new tab.</p>
<div><pre><span>local</span> <span>function</span> <span>open_in_tab</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>tabnew '</span> <span>..</span> <span>path</span><span>)</span>
  <span>close</span><span>()</span>
<span>end</span>
</pre></div>
<p>For everything to work, we need to add the key mappings, export all public functions, and add a command to trigger our navigation.</p>
<div><pre><span>local</span> <span>function</span> <span>set_mappings</span><span>()</span>
  <span>local</span> <span>mappings</span> <span>=</span> <span>{</span>
    <span>q</span> <span>=</span> <span>'</span><span>close()'</span><span>,</span>
    <span>[</span><span>'</span><span>&lt;cr&gt;'</span><span>]</span> <span>=</span> <span>'</span><span>open_and_close()'</span><span>,</span>
    <span>v</span> <span>=</span> <span>'</span><span>split("v")'</span><span>,</span>
    <span>s</span> <span>=</span> <span>'</span><span>split("")'</span><span>,</span>
    <span>p</span> <span>=</span> <span>'</span><span>preview()'</span><span>,</span>
    <span>t</span> <span>=</span> <span>'</span><span>open_in_tab()'</span>
  <span>}</span>

  <span>for</span> <span>k</span><span>,</span><span>v</span> <span>in</span> <span>pairs</span><span>(</span><span>mappings</span><span>)</span> <span>do</span>
    <span>-- let's assume that our script is in lua/nvim-oldfile.lua file.</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_keymap</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>n'</span><span>,</span> <span>k</span><span>,</span> <span>'</span><span>:lua require"nvim-oldfile".'</span><span>..</span><span>v</span><span>..</span><span>'</span><span>&lt;cr&gt;'</span><span>,</span> <span>{</span>
        <span>nowait</span> <span>=</span> <span>true</span><span>,</span> <span>noremap</span> <span>=</span> <span>true</span><span>,</span> <span>silent</span> <span>=</span> <span>true</span>
      <span>})</span>
  <span>end</span>
<span>end</span>

<span>-- at file end</span>
<span>return</span> <span>{</span>
  <span>oldfiles</span> <span>=</span> <span>oldfiles</span><span>,</span>
  <span>close</span> <span>=</span> <span>close</span><span>,</span>
  <span>open_and_close</span> <span>=</span> <span>open_and_close</span><span>,</span>
  <span>preview</span> <span>=</span> <span>preview</span><span>,</span>
  <span>open_in_tab</span> <span>=</span> <span>open_in_tab</span><span>,</span>
  <span>split</span> <span>=</span> <span>split</span>
<span>}</span>
</pre></div><div><pre>command<span>!</span> Oldfiles <span>lua</span> require<span>'nvim-oldfile'</span>.<span>oldfiles</span><span>()</span>
</pre></div>
<p>And that's it! Have fun and make grate things!</p>

<h2>The whole plugin</h2>
<div><pre><span>local</span> <span>buf</span><span>,</span> <span>win</span><span>,</span> <span>start_win</span>

<span>local</span> <span>function</span> <span>open</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>edit '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove vsplit '</span> <span>..</span> <span>path</span><span>)</span>
    <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>
  <span>end</span>
<span>end</span>

<span>local</span> <span>function</span> <span>close</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_close</span><span>(</span><span>win</span><span>,</span> <span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>local</span> <span>function</span> <span>open_and_close</span><span>()</span>
  <span>open</span><span>()</span>
  <span>close</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>preview</span><span>()</span>
  <span>open</span><span>()</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
<span>end</span>

<span>local</span> <span>function</span> <span>split</span><span>(</span><span>axis</span><span>)</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>axis</span> <span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove '</span> <span>..</span> <span>axis</span><span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>end</span>

  <span>close</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>open_in_tab</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>tabnew '</span> <span>..</span> <span>path</span><span>)</span>
  <span>close</span><span>()</span>
<span>end</span>


<span>local</span> <span>function</span> <span>redraw</span><span>()</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>true</span><span>)</span>
  <span>local</span> <span>items_count</span> <span>=</span>  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_get_height</span><span>(</span><span>win</span><span>)</span> <span>-</span> <span>1</span>
  <span>local</span> <span>list</span> <span>=</span> <span>{}</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_vvar</span><span>(</span><span>'</span><span>oldfiles'</span><span>)</span>

  <span>for</span> <span>i</span> <span>=</span> <span>#</span><span>oldfiles</span><span>,</span> <span>#</span><span>oldfiles</span> <span>-</span> <span>items_count</span><span>,</span> <span>-</span><span>1</span> <span>do</span>
    <span>pcall</span><span>(</span><span>function</span><span>()</span>
      <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_call_function</span><span>(</span><span>'</span><span>fnamemodify'</span><span>,</span> <span>{</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>})</span>
      <span>table.insert</span><span>(</span><span>list</span><span>,</span> <span>#</span><span>list</span> <span>+</span> <span>1</span><span>,</span> <span>path</span><span>)</span>
    <span>end</span><span>)</span>
  <span>end</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_lines</span><span>(</span><span>buf</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>false</span><span>,</span> <span>list</span><span>)</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>false</span><span>)</span>
<span>end</span>

<span>local</span> <span>function</span> <span>set_mappings</span><span>()</span>
  <span>local</span> <span>mappings</span> <span>=</span> <span>{</span>
    <span>q</span> <span>=</span> <span>'</span><span>close()'</span><span>,</span>
    <span>[</span><span>'</span><span>&lt;cr&gt;'</span><span>]</span> <span>=</span> <span>'</span><span>open_and_close()'</span><span>,</span>
    <span>v</span> <span>=</span> <span>'</span><span>split("v")'</span><span>,</span>
    <span>s</span> <span>=</span> <span>'</span><span>split("")'</span><span>,</span>
    <span>p</span> <span>=</span> <span>'</span><span>preview()'</span><span>,</span>
 …</pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua">https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua</a></em></p>]]>
            </description>
            <link>https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896684</guid>
            <pubDate>Mon, 20 Jul 2020 11:17:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Architectures for a Responsive IDE]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896380">thread link</a>) | @todsacerdoti
<br/>
July 20, 2020 | https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The first architecture is reminiscent of the map-reduce paradigm.
The idea is to split analysis into relatively simple indexing phase, and a separate full analysis phase.</p>
<p>The core constraint of indexing is that it runs on a per-file basis.
The indexer takes the text of a single file, parses it, and spits out some data about the file.
The indexer can’t touch other files.</p>
<p>Full analysis can read other files, and it leverages information from the index to save work.</p>
<p>This all sounds way too abstract, so let’s look at a specific example — Java.
In Java, each file starts with a package declaration.
The indexer concatenates the name of the package with a class name to get a fully-qualified name (FQN).
It also collects the set of methods declared in the class, the list of superclasses and interfaces, etc.</p>
<p>Per-file data is merged into an index which maps FQNs to classes.
Note that constructing this mapping is an embarrassingly parallel task — all files are parsed independently.
Moreover, this map is cheap to update.
When a file change arrives, this file’s contribution from the index is removed, the text of the file is changed and the indexer runs on the new text and adds the new contributions.
The amount of work to do is proportional to the number of changed files, and is independent from the total number of files.</p>
<p>Let’s see how FQN index can be used to quickly provide completion.</p>
<div>
<div>
<pre><code data-lang="java"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre><span>// File ./mypackage/Foo.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>import</span> <span>java.util.*</span><span>;</span>

<span>public</span> <span>class</span> <span>Foo</span> <span>{</span>
    <span>public</span> <span>static</span> <span>Bar</span> <span>f</span><span>()</span> <span>{</span>
        <span>return</span> <span>new</span> <span>Bar</span><span>();</span>
    <span>}</span>
<span>}</span>

<span>// File ./mypackage/Bar.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>public</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>public</span> <span>void</span> <span>g</span><span>()</span> <span>{}</span>
<span>}</span>

<span>// File ./Main.java</span>
<span>import</span> <span>mypackage.Foo</span><span>;</span>

<span>public</span> <span>class</span> <span>Main</span> <span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
        <span>Foo</span><span>.</span><span>f</span><span>().</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The user has just typed <code>Foo.f().</code>, and we need to figure out that the type of receiver expression is <code>Bar</code>, and suggest <code>g</code> as a completion.</p>
<p>First, as the file <code>Main.java</code> is modified, we run the indexer on this single file.
Nothing has changed (the file still contains the class <code>Main</code> with a static <code>main</code> method), so we don’t need to update the FQN index.</p>
<p>Next, we need to resolve the name <code>Foo</code>.
We parse the file, notice an <code>import</code> and look up <code>mypackage.Foo</code> in the FQN index.
In the index, we also find that <code>Foo</code> has a static method <code>f</code>, so we resolve the call as well.
The index also stores the return type of <code>f</code>, but, and this is crucial, it stores it as a string <code>"Bar"</code>, and not as a direct reference to the class <code>Bar</code>.</p>
<p>The reason for that is <code>import java.util.*</code> in <code>Foo.java</code>.
<code>Bar</code> can refer either to <code>java.util.Bar</code> or to <code>mypackage.Bar</code>.
The indexer doesn’t know which one, because it can look <strong>only</strong> at the text of <code>Foo.java</code>.
In other words, while the index does store the return types of methods, it stores them in an unresolved form.</p>
<p>The next step is to resolve the identifier <code>Bar</code> in the context of <code>Foo.java</code>.
This uses the FQN index, and lands in the class <code>mypackage.Bar</code>.
There the desired method <code>g</code> is found.</p>
<p>Altogether, only three files were touched during completion.
The FQN index allowed us to completely ignore all the other files in the project.</p>
<p>One problem with the approach described thus far is that resolving types from the index requires a non-trivial amount of work.
This work might be duplicated if, for example, <code>Foo.f</code> is called several times.
The fix is to add a cache.
Name resolution results are memoized, so that the cost is paid only once.
The cache is blown away completely on any change — with an index, reconstructing the cache is not that costly.</p>
<p>To sum up, the first approach works like this:</p>
<div>
<ol>
<li>
<p>Each file is being indexed, independently and in parallel, producing a "stub" — a set of visible top-level declarations, with unresolved types.</p>
</li>
<li>
<p>All stubs are merged into a single index data structure.</p>
</li>
<li>
<p>Name resolution and type inference work primarily off the stubs.</p>
</li>
<li>
<p>Name resolution is lazy (we only resolve a type from the stub when we need it) and memoized (each type is resolved only once).</p>
</li>
<li>
<p>The caches are completely invalidated on every change</p>
</li>
<li>
<p>The index is updated incrementally:</p>
<div>
<ul>
<li>
<p>if the edit doesn’t change the file’s stub, no change to the index is required.</p>
</li>
<li>
<p>otherwise, old keys are removed and new keys are added</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<p>Note an interesting interplay between "dumb" indexes which can be updated incrementally, and "smart" caches, which are re-computed from scratch.</p>
<p>This approach combines simplicity and stellar performance.
The bulk of work is the indexing phase, and you can parallelize and even distribute it across several machine.
Two examples of this architecture are <a href="https://www.jetbrains.com/idea/">IntelliJ</a> and <a href="https://sorbet.org/">Sorbet</a>.</p>
<p>The main drawback of this approach is that it works only when it works — not every language has a well-defined FQN concept.
I think overall it’s a good idea to design name resolution and module systems (mostly boring parts of a language) such that they work well with the map-reduce paradigm.</p>
<div>
<ul>
<li>
<p>Require <code>package</code> declarations or infer them from the file-system layout</p>
</li>
<li>
<p>Forbid meta-programming facilities which add new top-level declarations, or restrict them in such way that they can be used by the indexer.
For example, preprocessor-like compiler plugins that access a single file at a time might be fine.</p>
</li>
<li>
<p>Make sure that each source element corresponds to a single semantic element.
For example, if the language supports conditional compilation, make sure that it works during name resolution (like Kotlin’s <a href="https://kotlinlang.org/docs/reference/platform-specific-declarations.html">expect/actual</a>) and not during parsing (like conditional compilation in most other languages).
Otherwise, you’d have to index the same file with different conditional compilation settings, and that is messy.</p>
</li>
<li>
<p>Make sure that FQNs are enough for most of the name resolution.</p>
</li>
</ul>
</div>
<p>The last point is worth elaborating. Let’s look at the following Rust example:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>// File: ./foo.rs</span>
<span>trait</span> <span>T</span> <span>{</span>
    <span>fn</span> <span>f</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{}</span>
<span>}</span>
<span>// File: ./bar.rs</span>
<span>struct</span> <span>S</span><span>;</span>

<span>// File: ./somewhere/else.rs</span>
<span>impl</span> <span>T</span> <span>for</span> <span>S</span> <span>{}</span>

<span>// File: ./main.s</span>
<span>use</span> <span>foo</span><span>::</span><span>T</span><span>;</span>
<span>use</span> <span>bar</span><span>::</span><span>S</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>s</span> <span>=</span> <span>S</span><span>;</span>
    <span>s</span><span>.f</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Here, we can easily find the <code>S</code> struct and the <code>T</code> trait (as they are imported directly).
However, to make sure that <code>s.f</code> indeed refers to <code>f</code> from <code>T</code>, we also need to find the corresponding <code>impl</code>, and that can be roughly anywhere!</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896380</guid>
            <pubDate>Mon, 20 Jul 2020 10:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nanopublications: Fair data containers for scientific results]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23896279">thread link</a>) | @melvinroest
<br/>
July 20, 2020 | http://nanopub.org/wordpress/ | <a href="https://web.archive.org/web/*/http://nanopub.org/wordpress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                                
                        
            <p>FAIR data containers for scientific results,
<br>
and more</p>            
            		             
            
        </div></div>]]>
            </description>
            <link>http://nanopub.org/wordpress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896279</guid>
            <pubDate>Mon, 20 Jul 2020 09:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TileDB closes $15M Series A for universal data engine]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 61 (<a href="https://news.ycombinator.com/item?id=23896131">thread link</a>) | @k-rus
<br/>
July 20, 2020 | https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14 | <a href="https://web.archive.org/web/*/https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Cambridge, MA, July 14, 2020: <a href="https://tiledb.com/">TileDB, Inc.</a> has secured a $15M Series A investment round led by <a href="https://twobearcapital.com/">Two Bear Capital</a>, joined by <a href="https://uncorrelated.com/">Uncorrelated Ventures</a> and all existing investors: <a href="https://nexusvp.com/">Nexus Venture Partners</a>, <a href="http://www.intelcapital.com/">Intel Capital</a>, and <a href="https://bigpi.vc/">Big Pi Ventures</a>. The funding will help the company expand go-to-market and product development for its “universal data engine,” a novel database that goes beyond tables to manage any complex data and beyond SQL to analyze the data with any tool, all serverless and at planet scale. Montana philanthropist and Two Bear Capital Managing Partner Mike Goguen will join TileDB’s Board of Directors.</p>
<p>The Series A financing comes after TileDB was chosen by customers who experienced two key pains: scalability for complex data and deployment. Whole-genome population data, single-cell gene data, spatio-temporal satellite imagery, and asset-trading data all share multi-dimensional structures that are poorly handled by monolithic databases, tables, and legacy file formats. Newer computational frameworks evolved to offer “pluggable storage” but that forces another part of the stack to deal with data management. As a result, organizations waste resources on managing a sea of files and optimizing storage performance, tasks traditionally done by the database. Moreover, developers and data scientists are spending excessive time in data engineering and deployment, instead of actual analysis and collaboration.</p>
<p>“We flipped the data management model,” said Dr. Stavros Papadopoulos, CEO and original creator of TileDB. “We invented a database that focuses on universal storage and data management rather than the compute layer, which we’ve instead made `pluggable.` We cleared the path for analytics professionals and data scientists by taking over the messiest parts of data management, such as optimized storage for all data types on numerous backends, data versioning, metadata, access control within or outside organizational boundaries, and logging. On top, we developed numerous APIs for fast direct data access and efficient integrations with a growing set of popular tools such as Spark, Dask, MariaDB and PrestoDB. Finally, we built a serverless infrastructure for easy, secure cross-organizational sharing and scalable compute, called TileDB Cloud.”</p>
<p>According to Scott Soenen, VP of Product Engineering at Capella Space: “The partnership with TileDB gelled perfectly with our desire to deliver a new level of innovation in open data programs aimed at the geospatial community. Open data alone isn’t enough. It’s also about easy access to compute resources and versatility of analytics. TileDB Cloud removes multiple manual steps in data access for the geospatial developer community and offers intuitive self-service and interactive analytics."</p>
<p>“We have chosen TileDB as the storage engine to power our cellxgene project at CZI, which is an interactive data explorer for single-cell transcriptomics datasets,” said Bruce Martin, Director of Engineering, Chan Zuckerberg Initiative. “TileDB provides an easy and powerful way to manage our huge array data on various backends, including cloud object stores. The serverless infrastructure of TileDB Cloud opens the door to extreme scale with very low engineering efforts on our part, allowing us to focus more on scientific discoveries instead.”</p>
<p>Magnus Isaksson, Director of Bioinformatics, Helix shared, “The synergy between our two companies has enabled us to take an innovative approach to storing and analyzing genomic data at population-scale. We were excited to find TileDB after extensive diligence of potential solutions that could meet Helix's needs and advance our vision to revolutionize population health via the power of genomics."</p>
<p>“Many of the world’s most urgent problems - from COVID to climate change - require the analysis of large volumes of data in order to find solutions. TileDB’s technology addresses the infrastructure deficit that adds friction, delay, and cost to generating the key insights and discoveries needed from this data,” said Mike Goguen, Managing Partner at Two Bear Capital and lead investor. “We are excited to partner with Stavros and TileDB to build an enduring company delivering massive value for the developers and enterprise customers working to solve these and other critically important problems.”</p>
<p><br>
To learn more about TileDB visit <a href="https://tiledb.com/">our website</a>, check out the open-source <a href="https://github.com/TileDB-Inc/TileDB">TileDB Embedded</a> storage engine on Github or sign up on <a href="https://tiledb.com/cloud">TileDB Cloud</a>.</p>
<p>--------------------------------------------------------------------------------------</p>
<p><strong>About Two Bear Capital</strong></p>
<p>Two Bear Capital (TBC) was founded and is led by venture capitalist and Montana philanthropist Michael Goguen. With professionals in Whitefish, MT, the San Francisco Bay area and San Diego, CA, TBC invests in early stage companies with disruptive innovations at the intersections of biotech, bioinformatics, machine learning / AI and cybersecurity that could deliver dramatically better solutions to the most critical problems affecting human health, security and wellness. To learn more, visit <a href="http://www.twobearcapital.com/">www.twobearcapital.com</a> and follow TBC on LinkedIn.</p>
<p><strong>About Uncorrelated Ventures</strong></p>
<p><a href="https://uncorrelated.com/">Uncorrelated Ventures</a> was founded by <a href="https://www.baincapitalventures.com/team/salil/">Salil Deshpande</a> in 2020 with Bain’s backing to focus on open source and infrastructure software, both traditional and decentralized. Over 14 years as general partner and managing director at Bay Partners and Bain Capital, Salil invested $350M+ into 50+ companies early, including MuleSoft, DynaTrace, Buddy Media, SpringSource, Redis Labs, SysDig, Jambool, Dropcam, Tealium, Sonatype, Frame, DataStax, Netdata, Quantum Metric, Philz Coffee, Upgrade and DeFi projects Compound and Maker. Salil was on the Forbes Midas List of the 100 best-performing venture investors worldwide in 2013, 2014, 2015, 2016, 2017, 2018, and 2019.</p>
<p><strong><br>
About Nexus Venture Partners</strong></p>
<p>Nexus Venture Partners is a leading early-stage venture capital firm partnering with extraordinary entrepreneurs building product-first companies. With $1.5B under management, Nexus operates as one team across the US and India. The Nexus family includes Aryaka, Biz2Credit, Cloud.com, Clover Health, Delhivery, Druva, Gluster, H2O.ai, Hasura, Headspin, Kaltura, Mezi, Observe.ai, OLX, Paysense, Postman, Pubmatic, Rancher, Snapdeal, Unacademy, Whitehatjr, and Zomato. For more information, visit <a href="http://www.nexusvp.com/">www.nexusvp.com</a>.</p>
<p><strong>About Intel Capital</strong></p>
<p>Intel Capital invests in innovative startups targeting artificial intelligence, autonomous vehicles, datacenter and cloud, 5G, next-generation compute, and a wide range of other disruptive technologies. Since 1991, Intel Capital has invested US$12.9 billion in more than 1,582 companies worldwide, and 692 portfolio companies have gone public or participated in a merger. Intel Capital curates thousands of business development introductions each year between its portfolio companies and the Global 2000. For more information on what makes Intel Capital one of the world’s most powerful venture capital firms, visit www.intelcapital.com or follow @Intelcapital.</p>
<p><strong>About Big Pi Ventures</strong></p>
<p>Big Pi Ventures is a seed-stage fund investing in innovative technology companies connected to Greece and engaged primarily in enterprise/B2B software, materials and life sciences. Big Pi is managed by seasoned investment professionals and successful entrepreneurs that assist companies in attracting highly technical and loyal human capital. Find out more about our fund, portfolio, and career opportunities by visiting <a href="http://www.bigpi.vc/">www.bigpi.vc</a>.</p></div></div></div>]]>
            </description>
            <link>https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896131</guid>
            <pubDate>Mon, 20 Jul 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minecraft@Home]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23895789">thread link</a>) | @networked
<br/>
July 20, 2020 | https://minecraftathome.com/minecrafthome/ | <a href="https://web.archive.org/web/*/https://minecraftathome.com/minecrafthome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p><span>Server outage resolved and supporting our infrastructure</span><br>

        Between 23:54 UTC yesterday (2020-07-20) and 15:35 UTC today, we suffered from a catastrophic SQL failure which forced us to restore from backup.</p><p>

There may be some credit issues where the system granted more or fewer credits than you expect for work done during this time.<br>
I can't apologize enough. If our BOINC deployment was architected for scale rather than for low cost, we could've avoided this.</p><p>

There are several enhancements to our infrastructure and upgrades we'd like to make, such as migrating services to Kubernetes and potentially using a managed SQL service.</p><p>

<span><b><span color="red">You can help!</span> Please consider visiting our Patreon page, reviewing the current set of benefits, and making a contribution of any size; any amount helps - <a href="https://patreon.com/minecraftathome" rel="nofollow">patreon.com/minecraftathome</a></b></span></p><p>

All contributions go towards covering infrastructure cost and quality-of-life improvements to ensure the project's longevity.
        <br>
        <span>21 Jul 2020, 20:10:54 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=44"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>That was fast</span><br>

        The origin of the panorama image used in the Minecraft main menu from beta version 1.8.1, released in September 2011, has remained a mystery until now.</p><p>

<b><span>In less than 24 hours after launching the panorama application; a volunteer host for Minecraft@Home, in a sheer stroke of luck, found the world seed, 25357015387625.</span></b><br>
This was approximately </p><p><span color="red">93 days of processing time at a total of 54.5 exaFLOPs</span> compressed into the last 24 hours.</p><p>

The specific host which located the seed belongs to the user <a href="https://minecraftathome.com/minecrafthome/show_user.php?userid=2558" rel="nofollow">vanos0512</a>.<br>
Thank you to the 137 users who contributed 181 hosts with 231 GPUs over the last 24 hours. You all accomplished this.</p><p>

<img src="https://i.imgur.com/f6lGCEn.png"></p><p>

Here are the details if you want to generate this world for yourself:<br>
<b>Minecraft version:</b> <i>Beta 1.7</i><br>
<b>Either of these two valid world seeds:</b> <i>2151901553968352745 or 8091867987493326313</i><br>
<b>Co-ordinates:</b> <i>x60, y76, z-67</i></p><p>

<a href="https://www.youtube.com/watch?v=caLCZNLPgrM" rel="nofollow">See the video released by EarthComputer announcing the finding.</a>
        <br>
        <span>18 Jul 2020, 15:32:11 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=42"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Enjoy the scenery</span><br>

        <span>Minecraft@Home is now <span color="red">over one month old</span>! To celebrate this milestone, I present a new research focus; the panorama project.</span></p><p>

If you were here during beta-testing, you might have received a very early version of panorama tasks, and the eagle-eyed among you may have seen the application details <a href="https://minecraftathome.com/minecrafthome/server_status.php" rel="nofollow">on the server status page</a>.</p><p>

<span><b>The panorama app is a CUDA-only app for Linux and Windows with an Nvidia driver version of 418.96 or higher.</b></span></p><p>

This project attempts to find the world seed of the iconic panorama image which appeared in the background of the main menu of Minecraft between 2011 and 2018. The first phase of this project will only last a few days, and we shall update you with their progress in the coming weeks.</p><p>

<img src="https://i.imgur.com/3dyexWe.png"></p><p>

Right now, the application is quite substantial. Unlike the OpenCL applications for the Kaktwoos project, <b>if you allow BOINC to run tasks always; you may experience some stuttering or lag in your desktop environment while running these tasks</b>. These tasks do not have checkpointing support, but run in around 1 hour on an average host to mitigate the majority of lost cycles.</p><p>

<span>As always, <a href="https://minecraftathome.com/minecrafthome/prefs.php?subset=project" rel="nofollow">you can change which projects of which you decide to participate in your user preferences</a>.</span></p><p>

Let us know if you have any questions, and as always join the discussion over on <a href="https://discord.gg/xVFh9bp" rel="nofollow">the Discord server.</a>
        <br>
        <span>17 Jul 2020, 15:31:43 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=39"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Kaktwoos 2.03 and Badges!</span><br>

        You may have seen many workunits just disappear from existence today.</p><p>

<img src="https://munin.kiska.pw/munin-cgi/munin-cgi-graph/Munin-Node/Munin-Node/results_minecraftathome-pinpoint=1594193183,1594247603.png?&amp;lower_limit=&amp;upper_limit=&amp;size_x=400&amp;size_y=200"></p><p>

Worry not! We realised there were far too many workunits scanning duplicate seeds, so we've scaled back the original workunits to the correct seed ranges <span><i>(no in-progress results were touched, so none of you should have lost any credit)</i></span>.</p><p>

We have located some promising seed candidates which were missed from processing and can be used as an input to this job, so they are currently set as the highest priority.</p><p>

Also, <span><b>we now have badges</b></span>! If you view the forums, any comments in threads, or on the leaderboards; you will see the new badges.<br>
We're open to suggestions for future badges, so please leave us some comments on this thread.
        <br>
        <span>8 Jul 2020, 21:06:03 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=30"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Profile creation and OpenCL vendor pinning</span><br>

        In the last news post, I advised everyone to create a profile in order to be eligible for 'user of the day' selection.<br>
Unfortunately, there was an issue with the ReCaptcha implementation which prevented this. This issue is now resolved.</p><p>

Now, you are able to <a href="https://minecraftathome.com/minecrafthome/create_profile.php" rel="nofollow">create a profile here</a>.</p><p>

Also, good news for hosts with OpenCL capable hardware from more than one vendor <i>(e.g. an Intel iGPU and an Nvidia GPU)</i><br>
The latest update to the kaktwoos app should ensure the tasks run on the correct device.<br>
If you are a user with a multi-vendor host, please keep an eye on your results and let us know if you're having any issues.</p><p>

As always, please get involved with the conversation in the <a href="https://minecraftathome.com/minecrafthome/forum_index.php" rel="nofollow">message boards</a>, and <a href="https://discord.gg/xVFh9bp" rel="nofollow">join the Discord</a>!
        <br>
        <span>3 Jul 2020, 16:57:49 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=22"> Discuss</a>
        </span></p></div><hr>
    <p><a href="https://minecraftathome.com/minecrafthome/old_news.php">... more</a></p><p><small>
    News is available as an <a href="https://minecraftathome.com/minecrafthome/rss_main.php">RSS feed &nbsp; <img src="https://minecraftathome.com/minecrafthome/img/rss_icon.gif" alt="RSS"></a>
        </small></p></div></div>]]>
            </description>
            <link>https://minecraftathome.com/minecrafthome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895789</guid>
            <pubDate>Mon, 20 Jul 2020 08:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demo of OpenAI's GPT-3 generating tweets given a word]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23895706">thread link</a>) | @hardmaru
<br/>
July 20, 2020 | https://thoughts.sushant-kumar.com/hong%20kong | <a href="https://web.archive.org/web/*/https://thoughts.sushant-kumar.com/hong%20kong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
	<blockquote>
		<p><span>“</span>Despite common sense, HK has a population problem... thereâ€™s hardly anyone here.<span>”</span></p>
	</blockquote>

		</div></div>]]>
            </description>
            <link>https://thoughts.sushant-kumar.com/hong%20kong</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895706</guid>
            <pubDate>Mon, 20 Jul 2020 08:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why GPT-3 Matters]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 153 (<a href="https://news.ycombinator.com/item?id=23895481">thread link</a>) | @teruakohatu
<br/>
July 20, 2020 | https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/ | <a href="https://web.archive.org/web/*/https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <!-- TOC -->
        
        <p><img src="https://leogao.dev/images/gpt3/title.png" alt="Number of Parameters of GPT-3 compared to previous models. (<a href='https://www.willstats.com/'>Edited by WillStats</a>, <a href='https://arxiv.org/abs/1910.01108'>Original 1</a>, <a href='https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/'>Original 2</a>)"></p>
<p><span>The sheer scale of the new GPT-3 model</span> is hard to overstate; it’s an entire <em>order of magnitude</em> larger than Microsoft’s <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">already-massive 17B parameter Turing-NLG</a>.<sup><a href="#fn1" id="fnref1">[1]</a></sup> Loading the entire model’s weights in fp16 would take up an absolutely preposterous 300GB of VRAM, not even including the gradients. But, with massive size comes massive generalization ability: GPT-3 is competitive in many benchmarks <em>without even tuning on the target task</em>. And when I say many, I mean <em>many</em>—the full, 72-page paper contains an extensive evaluation of GPT-3 on many NLP datasets. Through the <a href="https://openai.com/blog/openai-api/" target="_blank" rel="noopener">OpenAI API</a>, a vast array of impressive demos have sprung up taking advantage of the generalization capabilities of GPT-3 to do extremely disparate tasks. Perhaps the most impressive part, though, is that even at such a massive scale, the model still scales smoothly in performance instead of plateauing, implying that still-larger models would perform <em>even better</em>. Throughout the rest of this post, my goal is to distill this massive (in multiple ways) paper down to a digestible size, and shed some light on why it matters.</p>

<p>The following table summarizes some of the largest autoregressive Transformer models of the past few years. I’ve excluded models like <a href="https://arxiv.org/abs/1906.08237" target="_blank" rel="noopener">XLNet</a> and BERT-derivatives because they don’t have the same unidirectional autoregressive training target.</p>
<table>
<thead>
    <tr><th></th>
    <th>Parameters</th>
    <th>Layers</th>
    <th>Hidden Size</th>
    <th>Attn Heads</th>
    <th>Attn Head Dimension</th>
    <th>Context Length</th>
</tr></thead>
    <tbody><tr>
        <th><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">GPT</a></th>
        <td>0.110B</td>
        <td>12</td>
        <td>768</td>
        <td>12</td>
        <td>64</td>
        <td>512</td>
    </tr>
    <tr>
        <th><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">GPT-2</a></th>
        <td>1.542B</td>
        <td>48</td>
        <td>1600</td>
        <td>25</td>
        <td>64</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM</a></th>
        <td>8.3B</td>
        <td>72</td>
        <td>3072</td>
        <td>32</td>
        <td>96</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a></th>
        <td>17B</td>
        <td>78</td>
        <td>4256</td>
        <td>28</td>
        <td>152</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noopener">GPT-3</a></th>
        <td>175.0B</td>
        <td>96</td>
        <td>12288</td>
        <td>96</td>
        <td>128</td>
        <td>2048</td>
    </tr>

</tbody></table>
<p>While GPT-3 isn’t that much deeper, its width is nearly <strong>3x</strong> that of <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a>, which—since parameter count scales approximately proportional to the square of the hidden size—explains where most of the extra parameters come from. It also has double the context size, at 2048 tokens, which is impressive (and memory-expensive!), though not the biggest context size across all models; some models have even longer contexts, like <a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener">Transformer-XL</a>, which incorporates longer contexts by passing context vectors between segments, and <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html" target="_blank" rel="noopener">Reformer</a>, which uses locality-sensitive hashing to enable sparser attention. Similarly, GPT-3 uses <a href="https://arxiv.org/abs/1904.10509" target="_blank" rel="noopener">sparse attention layers</a> in every other layer, though the exact details are left somewhat ambiguous. It’s also interesting to note that the smaller GPT-3 versions trained for comparison with GPT-2 are slightly shallower and wider, with GPT-3-XL having only 24 layers but a hidden size of 2048.<sup><a href="#fn2" id="fnref2">[2]</a></sup> GPT-3 also reuses the BPE tokenization of GPT-2. Overall, GPT-3 is essentially just a downright massive version of GPT-2.</p>

<p><img src="https://leogao.dev/images/gpt3/tdata.png" alt="Weighted Training Data (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The training data is a reweighted mix of Common Crawl, WebText2 (a larger version of the original that <a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener">also includes links sampled in the period of Jan-Oct 2018</a>), two book corpora, and English Wikipedia. Some of these components, such as Wikipedia, were seen more than 3 times during training; others, like the massive Common Crawl component, had less than half of their data seen. The authors claim that this is to help raise the overall quality of the corpus by prioritising known-good datasets. Also, in contrast to the original WebText, this new corpus is not filtered by language, but English still constitutes 93% of the dataset by words simply due to its prevalence. Altogether, the dataset is 500 billion tokens, or 700GB<sup><a href="#fn3" id="fnref3">[3]</a></sup>, after filtering and cleaning. The paper also provides a detailed description of the filtering process of the dataset, which the GPT-2 paper didn’t.</p>
<p>The authors also attempted to remove any data that overlapped with the train and test sets of the evaluations. Unfortunately, due to a bug, some were missed, so to compensate the paper provides a fairly good analysis of the impact of this leakage.</p>

<p><img src="https://leogao.dev/images/gpt3/perf-small.png" alt="Zero-, One-, and Few-shot performance of GPT-3 scaling with parameter count (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The Evaluation section of GPT-3 is very comprehensive, evaluating on a massive battery of NLP tasks in the Zero-shot (given only a natural language description in the generation context), One-shot (a single example in the generation context), or Few-shot (a small handful of examples in the generation context) settings. This setting is worth emphasizing as perhaps one of the biggest differences in ability between GPT-2 and its predecessors, because being able to <em>infer the task</em> from just one or a few examples is a massive step forward in generalization. Whereas previous models all relied on task-specific tuning, GPT-3 can be “tuned” merely by giving it instructions <em>in plain English</em>! In fact, the paper doesn’t even attempt to fine-tune on the target task, leaving that to future work.<sup><a href="#fn4" id="fnref4">[4]</a></sup> However, one crucial conclusion is that in almost all tests, performance continues to get better with larger models, even across 4 entire orders of magnitude, whereas fine-tuning only improves on one task and <a href="https://arxiv.org/pdf/1901.11373.pdf" target="_blank" rel="noopener">risks catastrophic forgetting and overfitting</a>.</p>
<p>Without going too much into the individual tests, the general result is this: on most tasks, GPT-3 achieves performance significantly worse than fine-tuned SOTA (i.e SuperGLUE, CoQA, Winograd, to name a few), but beating fine-tuned SOTA for some other tasks (i.e PhysicalQA, LAMBADA, Penn Tree Bank). GPT-3 does particularly well on PTB in particular, taking the SOTA perplexity from 35.76 down to 20.5—a massive improvement. GPT-3 can also finally do some arithmetic, something GPT-2 was unable to do well.<sup><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p><img src="https://leogao.dev/images/gpt3/newsgen-small.png" alt="People are unable to separate GPT-3 generated news articles from real ones (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>Impressively, and perhaps somewhat alarmingly, people are unable to distinguish GPT-3 generated news stories from real ones, only exacerbating the ethical concerns already raised by GPT-2. The paper analyzes the result of the release of GPT-2, and concludes that the release of GPT-2 has not led to widespread use of LMs for misinformation due to the difficulty of controlling output and variance in output quality, both among low-to-mid skill adversaries and “advanced persistent threats”—adversaries with “high skill and long-term agendas”—such as state actors. However, the paper also acknowledges that with further development, LMs will eventually become advanced enough for these adversaries.</p>
<p>The authors also investigate gender bias in GPT-3, showing that GPT-3 is male leaning; however, the authors claim that some preliminary evidence on the Winogender dataset (which tests coreference resolution on the same sentence but with different gendered pronoun) seems to suggest that larger models are more robust to bias issues. Similar issues appeared for race and religion, with the sentiment of coöccurrent terms varying significantly with race. The authors claim that this issue also got better with the larger models—although, without proper hypothesis testing, it’s difficult to draw any solid conclusions here.</p>

<p>GPT-3 has already been used for a smorgasbord of different applications through the OpenAI API. You can ask it to <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank" rel="noopener">write</a> <a href="https://twitter.com/hturan/status/1282261783147958272" target="_blank" rel="noopener">code</a>, turn <a href="http://vimeo.com/427943407/98fe5258a7" target="_blank" rel="noopener">natural language commands into shell commands</a>, and simulate <a href="https://www.aiwriter.email/" target="_blank" rel="noopener">chatting with famous people</a>. You can ask it to <a href="https://twitter.com/QasimMunye/status/1278750809094750211" target="_blank" rel="noopener">answer medical questions</a>, or <a href="https://www.gwern.net/GPT-3#navy-seal-copypasta" target="_blank" rel="noopener">write parodies of the navy seal copypasta</a>. You can ask it to <a href="https://andrewmayneblog.wordpress.com/2020/06/13/openai-api-alchemy-summarization/" target="_blank" rel="noopener">summarize passages for second graders</a>, or <a href="https://www.gwern.net/GPT-3#transformer-poetry" target="_blank" rel="noopener">write poetry</a>.</p>
<p>It’s important to remember all these are done by the <em>exact same model</em> trained <em>only</em> on modelling text; all that’s different is that it has been “asked nicely” to do different things. These apps showcase the versatility of GPT-3 across many disparate domains—something that, if it were done with GPT-2, would require days or even weeks of extensive data engineering and fine tuning, rather than 15 minutes of prompt crafting. This new paradigm of programming through crafting plain-English prompts, jokingly dubbed <a href="https://twitter.com/karpathy/status/1273788774422441984" target="_blank" rel="noopener">“Software 3.0”</a>, has achieved results that are already impressive, but even more impressive when viewed through the lens of <strong>generalization</strong>; GPT-3 wasn’t trained to do any of these things in particular, but it could still be asked<sup><a href="#fn6" id="fnref6">[6]</a></sup> to do them, and fairly well at that!</p>

<p><img src="https://leogao.dev/images/gpt3/perf_scaling_compute.png" alt="Performance continues to scale with compute. (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>But why does GPT-3 matter, if it can’t even beat SOTA across all benchmarks? Why should we care about a model so large that a small computing cluster is necessary even just to run inference at a reasonable speed?</p>
<p>One thing about GPT-3 is that it’s doing reasonably well on tasks it has <em>never even seen</em>, and sometimes tasks not even anticipated by the developers of the model. Additionally, instead of reaching a point of diminishing returns, GPT-3 shows that the trend of larger models performing better continues for at least another order of magnitude, with no signs of stopping. Even though GPT-3 is unwieldy, and even though it still doesn’t quite reach human level performance across the board, GPT-3 shows that it’s <em>possible</em> for a model to someday reach human levels of generalization in NLP—and once the impossible becomes possible, it’s only a matter of time until it becomes practical.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Back when I talked about <a href="https://leogao.dev/2019/10/27/The-Difficulties-of-Text-Generation-with-Autoregressive-Language-Models/">large Transformer language models like GPT-2, CTRL, and Megatron-LM late last year</a>, I touched briefly on the trend of Language Models getting bigger, and covered some of the issues that simply more compute might not fix. My general anticipation was that the model size arms race would soon be at a temporary standstill, with focus being diverted to better decoding strategies for text generation (perhaps via RL-based methods). I most certainly had not expected that OpenAI would be back at it so soon with such a massive model.</p>
<p>This was such a surprise that I dropped everything to read the paper and work on this post, including a more theory-oriented post that I’ve been working on for a few months now. It will probably be finished <span>soon™</span>, after I recover from GPT-3 shock. Stay tuned! <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>It’s likely that this was done for easier model parallelism—bigger matrix multiplications are much easier to parallelize than sequentially-applied layers à la <a href="https://arxiv.org/abs/1811.06965" target="_blank" rel="noopener">GPipe</a>.</p>
<p>This could have other advantages too, though. After <a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noopener">EfficientNet</a> came out, I independently ran some experiments of the same concepts to Transformer models, and the result was that for the same amount of compute, wider models had a sizeable advantage over deeper ones—which corroborates the choice here to …</p></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</a></em></p>]]>
            </description>
            <link>https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895481</guid>
            <pubDate>Mon, 20 Jul 2020 07:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video Vectorization]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23895211">thread link</a>) | @xanthine
<br/>
July 19, 2020 | https://vectorly.io/docs/technology/ | <a href="https://web.archive.org/web/*/https://vectorly.io/docs/technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

<p><img src="https://vectorly.io/docs/img/vector-graphics.png" alt="Drawing"></p>

<p>Vectorly is developing a new kind of video compression technology, which uses computer vision and vector graphics to reduce bitrates for video content by an order of magnitude (or more) compared to HEVC, while <strong>improving video</strong> quality. </p>
<p>This would be primarily effective for "vector friendly" video content, which would include animations, screen-casts, many e-learning videos and potentially 3d gaming content. </p>
<p>By leveraging existing vector-graphics rendering capabilities on all devices, this codec wouldn't require end-users, OEMs or browsers to install special software to enable playback of these videos.</p>
<p><strong>We are still in the early phases of developing this technology</strong>.</p>
<p>You can learn more about the technology in our <a href="https://files.vectorly.io/Vectorization+Whitepaper+v06.20.pdf">whitepaper</a></p>
<h2 id="the-core-idea">The Core Idea</h2>
<p>The core insight behind this project was that you could use vector-graphics based animations to simulate "videos" in a way that is indistinguishable from a traditional raster-graphics based video format such as an h264 video stream in an MP4 container.</p>
<h3 id="raster-graphics">Raster Graphics</h3>
<p>Normal videos, like the ones you see on Netflix or YouTube, are just sequences of images which get updated quickly on the screen, to create the illusion of motion. Each image is composed of "pixels" - individual dots of color. Higher resolution means more pixels, better visual quality, and bigger file sizes.</p>
<p><img alt="Pixel-Based" src="https://vectorly.io/docs/img/pixels.png"></p>
<p>Almost all video on the internet is of this format, known as "raster graphics". Video compression algorithms like h264 are just very efficient at using fewer data-points to reconstruct the pixels in any given frame, and at storing only the differences in pixels between frames of a video. </p>
<h3 id="vector-grapics-video">Vector Grapics video</h3>
<p>In contrast, we use a concept called "vector-graphics" to render video. Instead of pixels, we represent everything on the screen using shapes, lines and curves, which can be represented as mathematical equations (vector graphics).</p>
<p><img alt="Vector-Based" src="https://vectorly.io/docs/img/vector2.png"></p>
<p>Using these mathematical equations, we can re-draw any arbitrary shape on the screen - from the letter "T" to Bart Simpson's head. Furthermore, by adding information such as color, position on the screen, and how they move or change shape over time, you can create whole videos - including entire episodes of the Simpsons, with just sequences of mathematical equations.</p>
<h3 id="why-vectorization">Why vectorization?</h3>
<p>The core insight behind this project was that for a certain kind of "vector-friendly" video content, storing the video using vector graphics would be much more efficient than using raster graphics (in some cases, up to 2 orders of magnitude more efficient).</p>
<p>This idea is not substantively different from the idea of Flash based animations about 20 years ago. Why do this now?</p>
<p><strong>No need for a decoder</strong>: Most devices now support SVG, HTML5, WebGL/OpenGL and/or some form of hardware-accelerated vector-graphics rendering. That lets you render vector-graphics content on any device without require end-users, OEMs or browsers to install special software to enable playback of vector-graphics content, and to achieve native-level performance by doing so. App developers would only need to include an appropriate library or SDK in their website or app to enable playback within native or 3rd player video players.</p>
<p><strong>Computer vision</strong>: Our patented vectorization technology relies heavily on computer vision to convert raster-graphics videos to a vector format. Leveraging the advancement &amp; commoditization of Computer Vision, and the ease of running batch computer-vision heavy tasks on the cloud, it's feasible to 'vectorize' large volumes of video at scale now, in a way that wasn't possible even 5 years ago.</p>
<h3 id="vector-graphics-video-format">Vector graphics video format</h3>
<p>We are building a video-format based on existing standards (SVG, WebGL &amp; OpenGL), extending it with Javascript to enable video features such as a timeline and key-frames. We package the resulting video data within an MP4 container, which can be streamed and distributed using existing video infrastructure (such as HLS/DASH, and DRM systems).</p>
<pre><code>&lt;video src="vectorized.mp4" type="video/svg"&gt;
</code></pre>
<p>We are pragmatic, and don't want to create a standard <a href="https://xkcd.com/927/">for the sake of creating a standard</a>.  To that end, we've created libraries and SDKs that enable playback of our vector-graphics videos using standard / native interfaces like so</p>
<pre><code>&lt;script src="vectorly.js"&gt;

&lt;video src="vectorized.mp4" type="video/svg"&gt;
// This will work on all major browsers today
</code></pre>
<h2 id="demos-proof-of-concept">Demos / Proof of concept</h2>
<p><strong>Simpsons</strong></p>
<p>Our first vectorized proof of concept for animations is a 17 second clip of the Simpsons located <a href="https://files.vectorly.io/demo/v0-2-simpsons-250kbps/index.html">here</a>. Keep in mind, our technology is still at a very early stage, and this is much optimization work left to be done.</p>
<p><strong>Khan Academy</strong></p>
<p>Our technology also works very well for e-learning, and especially Khan Academy style content. You can find 30 second Khan Academy clip <a href="https://files.vectorly.io/demo/khan-20kbps/index.html">here</a></p></div></div>]]>
            </description>
            <link>https://vectorly.io/docs/technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895211</guid>
            <pubDate>Mon, 20 Jul 2020 06:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Praise of ZFS on Linux's ZED 'ZFS Event Daemon']]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23894790">thread link</a>) | @zdw
<br/>
July 19, 2020 | https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>In praise of ZFS On Linux's ZED 'ZFS Event Daemon'</h2>

	<p><small>July 19, 2020</small></p>
</div><div><p>I've written before (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSameness">here</a>) about how <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current Linux ZFS fileservers</a> work much
like <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our old OmniOS fileservers</a>.
However, not everything is quite the same between ZFS on Linux and
traditional Solaris/OmniOS ZFS. One of the most welcome differences
for us is <a href="https://zfsonlinux.org/manpages/0.8.4/man8/zed.8.html">ZED</a>,
the ZFS Event Daemon. What ZED does that is so great is that it provides
a very simple way to take action when <a href="https://zfsonlinux.org/manpages/0.8.4/man5/zfs-events.5.html">ZFS events</a> happen.</p>

<p>When a ZFS event happens, ZED looks through a directory (generally
<code>/etc/zfs/zed.d</code>) to find scripts (or programs) that should be run
in response to the event. Each script is run with a bunch of
environment variables set to describe what's going on, and it can
use those environment variables to figure out what the event is.
ZED decides what things to run based on their names; generally you
wind up with script names like <code>all-cslab.sh</code> (which is run on
all events) and <code>resilver_finish-cslab.sh</code> (which is run when a
resilver finishes).</p>

<p>Because these are just a collection of individual files, you're
free to add your own without colliding with or having to alter the
standard 'ZEDLETs' provided by ZFS on Linux. Your additions can do
anything you want them to, ranging from the simple to the complex.
For instance, our simplest ZEDLET simply syslogs all of the ZED
environment variables:</p>


<blockquote><pre>PATH=/usr/bin:/usr/sbin:/bin:/sbin:$PATH
export PATH
if [ "$ZEVENT_SUBCLASS" = "history_event" ]; then
        exit 0
fi
unset ZEVENT_TIME
unset ZEVENT_TIME_STRING
printenv | fgrep 'ZEVENT_' | sort | fmt -999 |
    logger -p daemon.info -t 'cslab-zevents'
exit 0
</pre>
</blockquote>

<p>(There's a standard 'all-syslog.sh' ZEDLET, but it doesn't syslog
all of the information in the zevents. Capturing all of the information
is especially useful if you want to write additional ZEDLETs and
aren't quite sure what they should look for or what environment
variables have useful information.)</p>

<p>It can take a bit of time and experimentation to sort out what ZFS
events are generated (and with what information available) in
response to various things happening to adn in your ZFS pools. But
once you have figured it out, ZED gives you a way to trigger and
drive all sorts of system management activities. These can be active
(like taking action if devices fail) or passive (like adding markers
in your metrics system or performance dashboards for when ZFS scrubs
or resilvers start and end, so you can correlate this with other
things happening).</p>

<p>Coming from Solaris and OmniOS, where there was no such simple
system for reacting to things happening in your ZFS pools, ZED was
a breath of fresh air for us. More than anything else, it feels
like how ZFS events should have been handled from the start, so
that system administrators could flexibly meet their own local needs
rather than having to accept whatever the Solaris Fault Management
system wanted to give them.</p>

<p>PS: Because ZFS on Linux is now OpenZFS, I believe that ZED will
probably eventually show up in FreeBSD (if it isn't already there).
Perhaps it will even some day be ported back to Illumos.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894790</guid>
            <pubDate>Mon, 20 Jul 2020 05:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Hosting Email Server]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23894411">thread link</a>) | @g-garron
<br/>
July 19, 2020 | https://www.garron.blog/posts/host-your-email-server.html | <a href="https://web.archive.org/web/*/https://www.garron.blog/posts/host-your-email-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2 id="introduction">Introduction</h2>

<p>In 1998 at my first job, I was the system administrator of the biggest Internet provider in Bolivia, it still is the biggest provider. The Internet arrived here in 1995 or 1996, so it was just starting.</p>

<p>I was in charge of BGP routers, with a satellite connection to the Internet, the whole country had just 2 mbps of connection back in those days. I was also in charge of the email server, (roble.scz.entelnet.bo), the DNS server run on a Unix machine while the email and web server on a RedHat Linux powered PC.</p>

<p>Fast forward to 2001, I started my own company, it had nothing to do with system administration, but anyway we needed email service, so I just got an on-line channel with a /28 public IP segment, and setup a CentOS server running bind, sendmail, Dovecot.</p>

<p>In 2007, I started blogging on Drupal running on that same server using Apache, PHP and MySQL <a href="https://www.garron.me/en/go2linux/fedora-centos-root-password-recovery.html">here the first post</a>. I was used to host services.</p>

<h2 id="changes">Changes</h2>

<p>But then I had less time in my hands, it was also more difficult to maintain the services running, keeping up to date with Spam filters and rules became difficult, Bind also had its problems, and Slashdot happened and Bandwidth was not enough.</p>

<p>I moved my server to a web hosting company, and then to a Linode VPS, I also outsourced the DNS service and moved the email to Google Apps.</p>

<p>I migrated my old server to Debian and used it just for:</p>

<ul>
  <li>DHCP</li>
  <li>NAT</li>
  <li>DNS Cache</li>
  <li>Squid</li>
</ul>

<p>That was in 2010 more or less, so I stopped hosting my services, only my blog was in my hands, but at that time I started using Jekyll, so it was just a VPS with Nginx.</p>

<h2 id="back-on-hosting-my-own-services">Back on Hosting my own services</h2>

<p>In April this year I started this blog, but I also enrolled in the Fediverse, and decided to <a href="https://www.garron.blog/posts/my-own-mastodon-server.html">run my own instance</a>, therefore I was hosting again, that was not just a NGINX server, then I read <a href="https://yarmo.eu/post/selfhost-email">this</a>, <a href="https://yarmo.eu/post/selfhost-email-drawbacks">this</a> and <a href="https://lazybear.io/posts/should-you-sefhost-your-email/">this</a>.</p>

<p>And the idea of running my services was in my head again. I wanted to do it different with time, it is not 1998 anymore, so I decided to learn about <a href="https://www.garron.blog/posts/dockerize-everything.html">Docker</a>. So now I have in just one Arch Linux server:</p>

<ul>
  <li>Two static sites</li>
  <li>One Wordpress Site</li>
  <li>One RSS reader (Miniflux)</li>
  <li>One password manager app (Bitwarden)</li>
  <li>One read-later app (<a href="https://www.garron.blog/posts/wallabag-review.html">Wallabag</a>)</li>
  <li>One Webmention app <a href="https://zerokspot.com/weblog/2020/06/14/setting-up-webmentiond/">Webmentiod</a></li>
</ul>

<p>All running with Docker Compose files, but there was something missing, it was email. (Mastodon has its own server -yet-)</p>

<h2 id="hosting-your-own-email-server">Hosting your own email server</h2>

<p>I wanted to run an email server on Docker, so I looked for alternatives and I have found that there are some really nice.</p>

<h3 id="posteiohttpsposteio"><a href="https://poste.io/">Poste.io</a></h3>

<p>I have not tested it, but seems really easy to deploy it has a free version that I think is enough for personal use, with two professional options with a monthly charge.</p>

<h3 id="mailuiohttpsmailuio"><a href="https://mailu.io/">Mailu.io</a></h3>

<p>It is a clone of Poste.io, but using only free, Open Source alternatives, I have installed and configured, it took me just 45 minutes to have server running for one of my domains. It has a tool that create a configuration file based on your options, and it set up everything for you, you can find it <a href="https://setup.mailu.io/1.7/">here</a>, you only need to answer a few questions, and run three or four commands and there you have a complete email server.</p>

<ul>
  <li>SMTP</li>
  <li>IMAP</li>
  <li>POP3</li>
  <li>AntiSpam</li>
  <li>AntiVirus</li>
  <li>Webmail</li>
  <li>Admin web front-end</li>
</ul>

<p>Really a great option, I recommend it to anyone.</p>

<h3 id="docker-mail-serverhttpshubdockercomrtvialdocker-mailserver"><a href="https://hub.docker.com/r/tvial/docker-mailserver">Docker Mail Server</a></h3>

<p>Then I found this one, it is also a complete suite, all Open Source, with really good documentation, and ready to deploy on a server with Docker. It is not as easy as Mailu, but I decided to use it. I followed <a href="https://github.com/tomav/docker-mailserver/wiki/Installation-examples">this guide</a>, yes I know, you still need Gmail or any other provider to send your emails, if you follow that guide. But I was not ready to jump into the pool completely.</p>

<p>So, here is my setup:</p>

<ul>
  <li>MX record points to my server, so all my email is received by my server</li>
  <li>All email is then forwarded to other accounts (Gmail accounts in this case)</li>
  <li>Gmail is configured to use those accounts as default and not the Gmail address, and uses my SMTP server to send</li>
</ul>

<p>This way I am sure I am using my domain, because we already agreed that <a href="https://www.garron.blog/posts/own-your-domain.html">everybody should own his domain</a>, right?. I am using Gmail as my email client.</p>

<p>I am doing this way, because it is easy to search emails when they are with Gmail, also because I am not sure if I may lose my server and lose some important email. I need to be sure about that, because I am hosting for my family, not only for me.</p>

<p>Also having an IMAP client on a cell phone drains the battery, because it polls the server even when there is nothing to download, or if you keep an open IMAP IDLE connection, it will also drain the battery. There is a solution for that, you need <a href="https://pushover.net/">PushOver</a>, and this <a href="https://pushover.net/">IMAP to PushOver</a> app, I have not tested yet, but I think is the way to go.</p>

<p>Edit: After reading some comments on Reddit, these three other options seems to be good ones too.</p>

<ul>
  <li>
    <p><a href="https://mailcow.email/">MailCow</a>: Is another good option also mentioned on HN comments, and this one do have official Docker documentation <a href="https://github.com/mailcow/mailcow-dockerized">here</a></p>
  </li>
  <li>
    <p><a href="https://mailinabox.email/">Mail in a Box</a>: Although there are not official instructions to install it on Docker, it should be possible, here is an <a href="https://hub.docker.com/r/mtrnord/mailinabox/">outdated attempt</a>, and here <a href="https://discourse.mailinabox.email/t/mail-in-a-box-in-docker/4588">another one</a>. But on a VPS it seems work great, and the admin pannel guides you.</p>
  </li>
  <li>
    <p><a href="https://iredmail.org/">iRedMail</a>: This one is also a good option, I have test it two months ago for a week and also works out of the box, you can find a well maintained docker instructions <a href="https://hub.docker.com/r/lejmr/iredmail">here</a></p>
  </li>
</ul>

<h2 id="things-to-consider">Things to consider</h2>

<p>If you plan to host your own email server, there are some important things you need to consider, and it is to properly configure your DNS server. Here is what you need:</p>

<h3 id="spf-record">SPF record</h3>

<p>You really need to configure a SPF record, it is not the same with all providers, but there is plenty of documentation, and it is not hard to do. This record basically tells the recipient server who is authorized to send mail on behalf of your domain. The most common configuration is that the MX server are the authorized ones, something like this.</p>

<pre><code>v=spf1 mx ~all
</code></pre>

<h3 id="dkim-record">DKIM record</h3>

<p>This one is a little bit more difficult, you need to create the DKIM key, your email server may do it, all examples above can do it, once you have it, you need to create a TXT record on your DNS and paste it there, it will look something like this:</p>

<pre><code>v=DKIM1; h=sha256; k=rsa; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEArARSBHTh32y3VpSEe+pOI7AuILCUsYw1FNL5vTu1P3Mpte50jjkvzg+pBndcSzndQDt6B6mqLBbTwWrZR/j73CTI4ejcYL+xqSXYPU8+xNwu5uwHOMsgWMl15Z/1e1QJD9Ss3Q8aOLOkvHNIgAfSCq
</code></pre>

<p>All your emails will be signed with that, DKIM key, and the receiving server can check if the signature is valid, using the info from the DNS.</p>

<h3 id="dmarc-record">DMARC record</h3>

<p>This one is optional, but is better to have it, you can generate it using on-line tools like <a href="https://mxtoolbox.com/DMARCRecordGenerator.aspx">this one</a>. What it does is to tell what to do when something fails, and who to report that, usually the server admin, well you.</p>

<h3 id="ptr-record">PTR Record</h3>

<p>You need to have a PTR DNS records, that is the reverse DNS for the IP your server is using should point to the same name the A record has. So, for example, if you have this A record</p>

<pre><code>IN A mail.server.com 192.168.0.1
</code></pre>

<p>There should also be a reverse record like this.</p>

<pre><code>IN PTR 192.168.0.1 mail.server.com
</code></pre>

<p>You need to ask to the owner of the IP to add that record for you, if you are using a VPS, you can look in the documentation about that.</p>

<h3 id="mx-record">MX record</h3>

<p>Of course you need a MX record, but you already knew about this one, otherwise maybe is not a good idea to run your own server. This basically informs al sending servers which server is receiving email for your domain.</p>

<h3 id="test">Test</h3>

<p>Once you have set-up everything, wait 24 hours for DNS to propagate and test it, <a href="https://www.mail-tester.com/">this tool</a> is great</p>

<h3 id="secondary-mail-server">Secondary mail server</h3>

<p>Edit 2:</p>

<p>After <a href="https://lobste.rs/s/iatbst/how_self_host_your_email_server#c_hc7vvv">this comment</a> I want to add this recommendation too.</p>

<p>When the main server is down, email can not be delivered, usually it just stays in the senders queue, and once your server is up again all email is delivered to it, but if the outage is long enough some email might be returned to senders and the users will lose them.</p>

<p>The way to avoid this is to have a second machine running a secondary email server, this is simplier to setup, as it will only have the function to store email while the main server is down, and send all emails to it once is up again. There are some good documentation out there, <a href="https://www.howtoforge.com/postfix_backup_mx">here</a> and <a href="https://www.linuxbabe.com/mail-server/how-to-set-up-a-backup-email-server-postfix-ubuntu">here</a>.</p>

<p>The drawback is that now you have a second email to upgrade and keep running, and Spammers ususally target at it, so if you have backups for the main server, and you consider you can have it up and running relatively fast you can avoid a second email. One should also consider who's email is being hosted at the server, and how critical is that email for them.</p>

<p>Critical email might be on an Office 365 <strong>Exchange Online (Plan 1)</strong>, once again, under your domain.</p>

<h2 id="final-words">Final words</h2>

<p>You may not need to host your email server, you can use <a href="https://www.fastmail.com/">Fastmail</a>, <a href="https://www.zoho.com/es-xl/mail/">Zoho</a>, Office 365, or Google Suite, but you <strong>must</strong> use your domain, all accounts, all bank statements should be sent to an email address at your domain, otherwise you can lose control over your accounts. Hosting your email server is not an easy task, dealing with SPAM is hard, and downtimes can be a nightmare too, but you learn one or two things while hosting your email.</p>

        </div></div>]]>
            </description>
            <link>https://www.garron.blog/posts/host-your-email-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894411</guid>
            <pubDate>Mon, 20 Jul 2020 03:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Don't Want to Be a Founder]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23894387">thread link</a>) | @kipply
<br/>
July 19, 2020 | https://carolchen.me/blog/founding-bad/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/founding-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>I had a brief run with a startup (literally a month) and was faced with the decision of going into a YC Cohort. In that fiasco, I also spent at least twelve hours trying to convince other people to go. It's been half a year, and I've had a lot more time to reflect on reasons as to why one might want to run a startup. As you might've guessed, I decided not to do it and I genuinely believe that running a startup seems like a bad idea for the majority of people I meet who want to become founders. </p>
<p>This post definitely will not apply to everyone (I'd loosely say applicable to 80% of prospective startup founders), but I'd hope there's some valuable thinking in here. Also, note that this is fairly oriented towards technical founders. </p>
<p>Edit: This post also has a very limited scope as it's based off the thinking from my decision to continue interning at Shopify or to go to YC. It's very focused on the Silicon Valley "startup" where you get a VC to give you money and get big in a year, etc etc</p>

<h3 id="commitment">Commitment<a href="#commitment" aria-label="Anchor link for: commitment"> <i></i></a>
</h3>
<p>I'm not talking about commitment to your company. I'm talking about commitment to your cofounder (if you have one, which is likely). </p>
<p>Maybe I'm too young to understand, but marriage seems frightening! My finances, my social life, personal time, and emotional wellbeing would be largely dependent on a single person and that's scary. It should be scary or should at least take a few years for it not to become scary. </p>
<p>Your cofounder is...kind of the same? In a seed-stage it's likely you <em>actually</em> live together, and if you don't, you're likely functionally living together with the amount of work involved. They're responsible for your financial well-being. They may be responsible for the quality of your social lives (most founders spend a lot of time socializing with other tech people + founders). They're tied to your life goals, your dreams, and your passions.</p>
<p>My impression was that my relationship with my cofounder would be more intense than marriage, and <em>extra</em> bad in the event of failure since there's additional loss (and it's statistically likely, but I guess so is marriage). I totally believe that there are cofounder pairs that are completely ready to go through the founder journey and pairs that maybe weren't ready but were fine anyway, but I stand by the statement that it's more intense than marriage and not enough people put care into this. </p>
<h3 id="your-vc-is-not-the-one-at-risk-here">Your VC is Not the One at Risk Here<a href="#your-vc-is-not-the-one-at-risk-here" aria-label="Anchor link for: your-vc-is-not-the-one-at-risk-here"> <i></i></a>
</h3>
<p>I often hear sentiments that resemble "wow these VCs are taking a chance on me I better commit to this!". </p>
<p>VCs are not evil people trying to take advantage of you (actually they might be, but let's assume they're not), but they are not the ones at risk. For them, 150k or a few million is not a huge risk. Seed-stage returns will be from a very small percentage of investments, thus VCs can afford to have comically high error rates as long as they get the few that matter. If you're SoftBank you can do even worse and still have so much money! They make decisions carefully, they care about your success for various reasons, and are generally caring people (in most of my experiences) but in larger abstractions, your startup means nothing to them. </p>
<p>They're not shy about it either, the entire reason they're investing in you is because they think you're more valuable than you cost. 
<img src="https://carolchen.me/blog/img/founding/paul.png" alt=""></p>
<p>Your risk is years of your life, blood, sweat, and tears. The next few years (provided your startup lasts till then) will somewhat be in service to these VCs. The VCs are your "bosses" as you answer to them (though <em>much</em> less than a regular "boss") and to the ones you hope to raise capital from in the future. </p>
<p>It's good to take a risk with increased confidence because qualified people think you have promise. However, that can morph into "I'm going to work on this startup partially in service to these people who believed in me and gave me lots of money". These additional stresses that come from meeting VC expectations and the complications of the dynamics of the relationship can cause various problems.</p>
<h3 id="sense-of-self">Sense of Self<a href="#sense-of-self" aria-label="Anchor link for: sense-of-self"> <i></i></a>
</h3>
<p>This one is the one that got to me most but I can see it being irrelevant to a lot of other people. </p>
<p>Many founders have big egos -- I don't mean they're assholes or overly self-important but they do have very powerful confidence, because that's a valuable skill to have as a founder. Not just confidence in pitching their project to others, but in their vision and their company. They need to believe their company will be successful (though I have met founders who just want to party with VC money for a few years <em>cough cough</em> Neumann). </p>
<p>My first fear was that I created an ego for myself rapidly. Practicing to sell to clients and for your YC interview involves repeating to yourself why you are <em>good</em> and self-hypnosis is fairly powerful. I love feeling good about myself, but I suddenly found myself feeling more confident in myself than what I believed was warranted. More frighteningly, I had a major character and energy change in a couple of weeks. Losing so much of my identity like that was unnerving, not to mention the ripple effects that could've occurred in my social life. </p>
<p>The other fear is coming down from that. Startup founders (especially the more eccentric ones) sometimes believe that they will build something that will change the world. Along with that, their identities start to merge with their company. There's nothing wrong with that, but I also think it's exceptionally tragic to come down from that. It's not just dealing with failure and getting back up on your feet, it's losing a part of your identity. </p>
<h3 id="school-is-generally-a-good-idea-for-prospective-dropouts">School is Generally a Good Idea (for prospective dropouts)<a href="#school-is-generally-a-good-idea-for-prospective-dropouts" aria-label="Anchor link for: school-is-generally-a-good-idea-for-prospective-dropouts"> <i></i></a>
</h3>
<p>Being a good engineer seems underrated for being a good startup founder. Not just being able to code fast, but being able to make good engineering decisions, conduct good technical interviews and attract talent. Some engineering skills can't be worked around with "I am very smart and can learn fast" and require extended time and practice. With that, I also think prospective founders also overestimate the amount of learning on the job that can be done on the engineering side, mostly because it's harder to learn when you're in a rush to release features than if you could take your time on a course project. It's true that founders will learn more than they will in school, but the technical development may not be as strong. My model is that the best schooling experience is better technical education and the best founding experience. </p>

<h3 id="something-to-own">Something to Own<a href="#something-to-own" aria-label="Anchor link for: something-to-own"> <i></i></a>
</h3>
<p>Lots of huge, ground-breaking products have been lead from within a large company. Examples include email client <code>hey.com</code>, Chromebooks, and countless amazing dev tools. </p>
<p>Starting these things in a large company has the benefit of security, resources and recruiting already done for you. Downsides include beaurocracy, not being able to recruit on your own accord and dealing with PR policy. There is also high barriers to starting something within a company, like being senior enough to do so and being at the right company at the right time. </p>
<p>The alternative is starting a project on the side. <a href="https://github.com/ziglang/zig">Ziglang</a> was started as a side project and is now a very promising programming language. The creator has since then left his job to work on Zig, but it is also possible to "own" something significant without even having to leave your job. Examples includes Julia Evan's <a href="https://jvns.ca/">blog</a> (not actually a work-side-project) and line of zines, Cassidy William's <a href="https://drop.com/buy/drop-dsa-astrolokeys-keycaps-by-sailorhg-and-cassidoo">keycap line</a>, Nick Frosst's successful and awesome <a href="https://goodkidofficial.com/">band</a> and many more. I understand that it's not the extent of "oh yeah Google? I built that", but I think the expected value is much higher in creating and owning something that isn't a startup. </p>
<h3 id="getting-rich">Getting Rich<a href="#getting-rich" aria-label="Anchor link for: getting-rich"> <i></i></a>
</h3>
<p>A lot of people claim that startups are less money, but I find for signicant number of founders, that's not true -- not because they'll definitely have a good exit, but because they're skilled in ways that allow them to raise enough money to pay themselves like they would at a big company. If that applies to you, then going to a startup probably is your best shot at getting rich! For other people, the expected value of industry (particularly joining a well-founded early-stage startup) is usually higher. </p>
<h3 id="not-being-at-school-for-prospective-dropouts">Not Being at School (for prospective dropouts)<a href="#not-being-at-school-for-prospective-dropouts" aria-label="Anchor link for: not-being-at-school-for-prospective-dropouts"> <i></i></a>
</h3>
<p>This seems like a valid reasons for the average CS student. School is a place where you answer to professors who don't always understand industry and do homework assignments that no one will care about. However, it seems like all of these problems can be significantly if not fully solved by building a better school experience for yourself. </p>
<p>A better program can improve many things, such as <a href="http://www.olin.edu/">Olin College of Engineering</a> that has a project-based curriculum, <a href="https://www.makeschool.com/">Make School</a> that is a two year applied-engineering degree program or <a href="https://devdegree.ca/">Dev Degree</a>, where you can work at Shopify and take more applied courses taught by Shopify throughout your degree. These programs are small and selective, but probably not harder than a semi-successful startup. Dev Degree also happens to be more financially sound, with Shopify paying for your tuition and a salary, and Make School tuition is 70k for the entire degree. </p>
<p>Another alternative is to just be worse at school and learn on the side and/or to morph your silly school assignments into productive skills and useful outputs. The <a href="http://coconut-lang.org/">Coconut Programming Language</a> was built by someone while they were in school. Some things like dynamic programming that are often deemed useless theoretical things can have <a href="https://thume.ca/2017/06/17/tree-diffing/">industry applications</a>. People have also taken mundane school projects like this compiler that almost every school will have you build in a compilers course and end up with <a href="https://thume.ca/2019/04/29/comparing-compilers-in-rust-haskell-c-and-python/">educational findings for engineers in general</a> (also see <a href="https://news.ycombinator.com/item?id=20192645">HackerNews thread</a>). In five weeks, my friend Maas was able to launch <a href="https://medium.com/@maaslalani/launch-5d02cc5e05f5">five relatively successful products</a> while enrolled in Dev Degree. </p>
<p>School is already a powerful environment of hardwork, fun and learning. I think it is a more cohesive …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/founding-bad/">https://carolchen.me/blog/founding-bad/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/founding-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894387</guid>
            <pubDate>Mon, 20 Jul 2020 03:21:12 GMT</pubDate>
        </item>
    </channel>
</rss>
