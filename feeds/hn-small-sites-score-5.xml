<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 25 Aug 2020 04:20:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 25 Aug 2020 04:20:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Persisting as a Solo Founder]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24251403">thread link</a>) | @vishnumohandas
<br/>
August 23, 2020 | https://vishnu.tech/posts/persistence/ | <a href="https://web.archive.org/web/*/https://vishnu.tech/posts/persistence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://sa.vishnu.tech/noscript.gif" alt="">




    



  



    
    <p><time itemprop="datePublished">August 19, 2020</time>
    </p>
    

<p>I quit my job in January 2020 to build a privacy friendly photo organizer.</p>

<p>As a 30 year old whose friends are either getting married or planning
off-springs, what I had underestimated was the difficulty involved in finding a co-founder and how that would compound the difficulty involved in
finding an investor.</p>

<p>Once I accepted the loneliness and the lack of a financial cushion I had to figure out a way to keep building without burning myself out.</p>

<p>It took me a while, but I have found a rhythm that works, and with it, a steady
source of endorphins. Here are some changes that helped me to keep things
moving.</p>

<h2 id="being-patient">Being patient</h2>

<p>Life is no longer as comfortable as it used to be and things are not always
going the way I want them to. Preseverance has been key and indirectly patience
too. Naval’s <a href="https://twitter.com/naval/status/1261481752448524289" target="_blank">take on
meditation</a> (60 minutes x
60 days), was an eye opener. I’ve stuck with it since, and I now have an easier
time identifying negative thought patterns and sitting out situations that would
otherwise overwhelm me.</p>

<p>On some level, spending the last few months locked indoors with my parents, who
are not the most rational people in the world has also helped. But I wouldn’t
recommend it.</p>

<h2 id="reducing-procrastination">Reducing procrastination</h2>

<p>Over time I’ve realized that action precedes motivation and procrastination precedes guilt.</p>

<p>Breaking down tasks into chunks that seem trivial to accomplish has helped reduce the friction in getting started on unexciting grunt work.</p>

<p>Then there are tasks which I loathe from my core, like writing out applications
to VCs explaining why what I’m doing will matter. To those I attach reinforcing
personal reasons, like, “I need the $50k to hire that college junior who I love
working with, and that will give me spare bandwidth to focus on traction channels”.</p>

<h2 id="thinking-clearer">Thinking clearer</h2>

<p>It is sub-optimal to not have a coworker to bounce ideas off and rant about problems to. A lot of times it’s these conversations that help you gain clarity.</p>

<p>It’s a luxury I do not have so every time I feel stuck, I type/scribble my thoughts out, and then question everything that was written, and then document my realizations.</p>

<p>Task tracking has also helped in clearing the path. I write down unstructured
thoughts into a diary, and once I’ve clarity, I promote them to a Notion board
(that’s divided into <em>Thinking</em>, <em>Building</em>, <em>Reading</em>, <em>Writing</em> and
<em>Adulting</em>) and every Monday within an Excel sheet I track what was done, and
what is left to be done.</p>

<h2 id="reducing-distractions">Reducing distractions</h2>

<p>I’ve reduced my information consumption to free up brain cycles. I’ve disabled all notifications on my phone barring a few contacts, and I’ve more or less stopped browsing on it. As an added bonus, this has reduced the negativity with which I perceived the world.</p>

<p>To minimize the overhead of context switches, I split tasks into a tree of checkpoints. Before taking a break I note down the next simplest checkpoint so that when I get back to work there’s little friction to resume.</p>

<p>To help me zone out I keep <a href="https://www.youtube.com/watch?v=5qap5aO4i9A" target="_blank">lofi
beats</a> or
<a href="http://github.audio/" target="_blank">github.audio</a> playing in the background. Listening to the
latter gives me a strange sense of motivation and makes me feel less alone.</p>

<h2 id="staying-grounded">Staying grounded</h2>

<p>I’m lucky to have some friends who call/text every other week. I look at them as my accountability partners and I talk to them about what I’m doing on a high level. While not all of them genuinely care, some do, and these conversations force me to reflect on how well I’m doing what I’m doing.</p>

<p>While Silicon Valley wisdom suggests that if I’m not sleeping I should be
working, failing because of a burn out would be stupid. An advantage of not
having a VC onboard so far has been the freedom to dictate my pace. So I spend
days thinking, reading, fiddling with my violin or just doing nothing when I
feel like writing code is not what I want to do.</p>

<hr>

<p>It’s been 7 months of building alone, and while this is not how I pictured things to be on my last day at work, this is the happiest I have ever been. There’s a long way to go, and the grind seems inviting.</p>

<p>This list is by no means exhaustive, for I’m still learning. If you’ve
anything to share, please join <a href="https://news.ycombinator.com/item?id=24251403" target="_blank">the discussion on HackerNews</a>.</p>

<hr>

<p>If you are curious about what I’ve been building, check out
<a href="https://ente.io/" target="_blank">ente.io</a>.</p>

    <br>
    


</div>]]>
            </description>
            <link>https://vishnu.tech/posts/persistence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251403</guid>
            <pubDate>Sun, 23 Aug 2020 12:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Clean Start for the Web]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24247362">thread link</a>) | @simantel
<br/>
August 22, 2020 | https://macwright.com/2020/08/22/clean-starts-for-the-web.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/08/22/clean-starts-for-the-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The web is in need of some reinvention right now.</p><p>The web’s evolution over the last decade has mirrored the American economy. All of the essential indicators are going “up and to the right,” a steady stream of fundamental advances reassure use that there “is progress,” but the actual experience and effects for individuals stagnates or regresses.</p><p>The crisis affects platforms, creators, and consumers alike.</p><p><em>I’m going to try and dissect and diagnose this situation, a bit. You can skip forward if you just want to read my casual, unprofessional pitch for a reboot of the web. The idea is that we could choose a new lightweight markdown format to replace HTML &amp; CSS, split the web into documents and applications, and find performance, accessibility, and fun again.</em></p><details><summary>This post uses the pedantic definition of "the web"</summary>I've discussed attempts to reinvent the "Internet" a few times. Things like dat, IPFS, and arweave are all projects to reinvent an Internet, or a transport and data-sharing layer. The web is what lies on top of that, the HTML, CSS, URLs, JavaScript, browsing experience.</details><h3 id="the-platform-collapse">The platform collapse</h3><p>The platform side is what changed last week, when <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla laid off 250 employees</a> and indicated that it would affect Firefox development. Firefox wasn’t the #2 browser - that’s Safari, mainly because of the captive audience of iPhone and iPad users. But it was the most popular browser that people <em>chose</em> to use.</p><p><img alt="Chart of browser market share, with Chrome becoming the monopoly" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-chart-of-browser-market-share-with-chrome-becoming-the-monopoly.png"></p><p><em>Chart from <a href="https://gs.statcounter.com/browser-market-share#monthly-200901-202007">statcounter</a></em></p><p>The real winner is not just Chrome, but Chrome’s engine. One codebase, <a href="https://en.wikipedia.org/wiki/KHTML">KHTML</a>, split into <a href="https://en.wikipedia.org/wiki/WebKit">WebKit</a> (Safari), and <a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)">Blink</a> (Chrome, Microsoft Edge, Opera, etc.)</p><p>This a textbook monoculture. In one sense, it’s a victory for collaboration because nobody’s ‘wasting time’ on competing implementations and web developers can expect the same features and bugs across different browsers. But in a deeper way, it threatens one of the basic principles of how the web has evolved.</p><h3 id="specs--implementations">Specs &amp; implementations</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.webp" type="image/webp"><img alt="Decline" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.jpg"></picture></p><p>The web has evolved through a combination of <em>specifications</em> and <em>implementations</em>. Organizations like the <a href="https://whatwg.org/">WHATWG</a>, <a href="https://www.w3.org/">W3C</a>, and <a href="https://www.ietf.org/">IETF</a> have been collaboration spaces for independent developers, corporations, and academics to discuss potential new features of the web. Then, browsers would test those ideas out in a variety of implementations.</p><p>This was an interesting structural piece: it reassured us all that it was <em>possible</em> to follow along, and that a multi-participant web was one of our goals. It was frustrating to pull up <a href="https://caniuse.com/">caniuse</a> and see blank spots, but the idea was that different browsers may take the lead in some areas, but everyone catches up eventually. Chrome was not always the first to jump on features, or the first to optimize.</p><p>It’s slower to collaborate than to work alone, but it was beneficial in some ways that we’ve lost now. Chrome has been moving extremely fast, adding new specifications and ideas at a startling rate, and it’s becoming one of the hardest pieces of software to replicate.</p><p>Mike Healy I think <a href="https://twitter.com/mike_hasarms/status/1296575224599556097">said it best</a>:</p><blockquote><p>Do you think the web has almost ‘priced itself out of the market’ in terms of complexity if only 1-2 organisations are capable of building rendering engines for it?</p></blockquote><p>Not only is it nearly impossible to build a new browser from scratch, once you have one the ongoing cost of keeping up with standards requires a full team of experts. Read Drew DeVault’s <a href="https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html">Web browsers need to stop</a> for that point, and keep reading all of Drew’s stuff.</p><details><summary>What about Flow?</summary>Yep, there’s a <a href="https://www.ekioh.com/flow-browser/">browser called Flow</a>, which may exist and may support a full range of web standards. If it does exist, I’ll be very excited about it, but it has been teased for almost a year now without any concrete evidence, so it could equally be vaporware.</details><h3 id="the-problem-for-creators">The problem for creators</h3><p>The web has gotten much harder to develop for.</p><p>The web has had about 25 years to grow, few opportunities to shrink, and is now surrounded by an extremely short-sighted culture that is an outgrowth of economic and career short-termism. There are lots of <a href="https://frankchimero.com/blog/2018/everything-easy/">ways to do anything</a>, and some of the most popular ways of building applications on the web are - in my opinion - <a href="https://macwright.com/2020/05/10/spa-fatigue.html">usually ghoulish overkill</a>.</p><p>The best way for folks to enter <em>web development</em> in 2020 is to choose a niche, like <a href="https://vuejs.org/">Vue.js</a> or <a href="https://reactjs.org/">React</a>, and hope that there’s a CSS and accessibility expert on their team.</p><p>For folks who just want to create a web page, who don’t want to enter an industry, there’s a baffling array of techniques, but all the simplest, probably-best ones are stigmatized. It’s easier to stumble into building your resume in React with GraphQL than it is to type some HTML in Notepad.</p><h3 id="the-problem-for-consumers">The problem for consumers</h3><p>We hope that all this innovation is <em>for the user</em>, but often it isn’t. Modern websites seem to be as large, slow, and buggy as they’ve ever been. Our computers are <a href="https://macwright.com/2019/11/15/something-is-wrong-with-computers.html">barely getting faster</a> and our internet connection speeds are stagnating (don’t even <em>try</em> to mention 5G). Webpage <a href="https://www.pingdom.com/blog/webpages-are-getting-larger-every-year-and-heres-why-it-matters/">size growth</a> is outpacing it all.</p><p>The end result is that I no longer expect pages to be fast, even with <a href="https://github.com/gorhill/uBlock">uBlock</a> installed in Firefox and a good local <a href="https://sonic.net/">fiber internet provider</a>.</p><p>I don’t want to lay all of the blame at <em>those web developers</em>, though. Here’s a story from an old job that I find kind of funny. We were collecting some data from user interactions to answer simple questions like “do people click to upload or do they drag &amp; drop?” So we enabled <a href="https://segment.com/">Segment</a>, a tool that lets you add data-collection pipelines by including a single script. The problem, though, is that Segment offered a big page of on/off switches with hundreds of data providers &amp; ad-tech companies on it. And, sure, enough, some folks closer to the business side started <em>clicking all those buttons</em>.</p><p>See, the problem with ads and data tracking is that <em>you can</em>, and who is going to say no? (In that instance, I said no, and added a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a> that would block new advertiser access at the page level.)</p><h2 id="recreating-simplicity">Recreating simplicity</h2><blockquote><p>You cannot get a simple system by adding simplicity to a complex system. - <a href="http://erlang.org/pipermail/erlang-questions/2012-March/065087.html">Richard O’Keefe</a></p></blockquote><p>Where do we go from here? Some of the smartest folks out there have been <a href="https://twitter.com/_developit/status/1296628134406692865">advocating for a major version revision</a> of the web.</p><p><em>I am in no way qualified to speculate on a whole new web from scratch, but the <a href="https://www.nytimes.com/2020/08/21/us/california-wildfires.html">air quality</a> is scary so I’m skipping my run and it’s Saturday morning so here we are.</em></p><p>How do we make the web fun, participatory, and good?</p><p>My first thought is that there are two webs:</p><h3 id="the-document-web">The document web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.webp" type="image/webp"><img alt="Illustration of web pages" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.jpg"></picture></p><p>There is the “document web”, like blogs, news, Wikipedia, Twitter, Facebook. This is basically the original vision of the web, as far as I can understand it (I was 2). Basically CSS, which we now think of as a way for designers to add brand identity and tweak pixel-perfect details, was instead mostly a way of making plain documents readable and letting the <em>readers</em> of those documents customize how they looked. This attribute actually <a href="https://twitter.com/autiomaa/status/1296755641164468224">survived for a while in Chrome, in the form of user stylesheets</a>, and <a href="https://davidwalsh.name/firefox-user-stylesheet">still works in Firefox</a>. Though it’s going to be a rough ride in the current web which has basically thrown away <a href="https://en.wikipedia.org/wiki/Semantic_HTML">semantic HTML</a> as an idea.</p><h3 id="the-application-web">The “application” web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.webp" type="image/webp"><img alt="Illustration of machines" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.jpg"></picture></p><p>Then there’s the “application web”. This started as <em>server</em> applications, built with things like <a href="https://www.djangoproject.com/">Django</a> and <a href="https://rubyonrails.org/">Ruby on Rails</a> and before them a variety of technologies that will live forever in corporations, like <a href="https://en.wikipedia.org/wiki/Jakarta_Servlet">Java Servlets</a>.</p><p><a href="https://backbonejs.org/">Backbone.js</a> demonstrated that a lot of these applications could be moved into the browser, and then <a href="https://reactjs.org/">React</a> and its many SPA-style competitors established a new order for the web – highly-interactive, quite complex, client-side applications.</p><h3 id="the-war-between-the-parts-of-the-web">The war between the parts of the web</h3><p>I posit that this dual-nature is part of what gives the web its magic. But it’s also a destructive force.</p><p>The magic is that a simple blog can be creative expression, can be beautifully interactive. This one isn’t, but I’m just saying - <a href="https://www.typewolf.com/site-of-the-day">it’s possible</a>.</p><p>The problem is that the “document web” is often plagued by application characteristics - it’s the JavaScript and animations and complexity that makes your average newspaper website an unmitigated disaster. Where document websites adopt application patterns they often accidentally sacrifice <a href="https://www.a11yproject.com/">accessibility</a>, performance, and <a href="https://en.wikipedia.org/wiki/Web_scraping">machine readability</a>.</p><p>And the “application web” is plagued by the document characteristics - interactive applications are going to great lengths to avoid most of the essential characteristics of HTML &amp; CSS and just use them as raw materials - avoiding writing any HTML directly at all, avoiding <a href="https://mxstbr.com/thoughts/css-in-js">writing any CSS directly at all</a>, avoiding <a href="https://www.react-spring.io/">default animation features</a>, replacing <a href="https://reactrouter.com/">page-based navigation with something that looks like it but works completely differently</a>. The application web uses <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, not HTML, and would like that in the browser itself, or <a href="https://svelte.dev/">Svelte</a>, instead of JavaScript, and would like that too.</p><p>When I read blog posts from ‘traditional web developers’ who are mad that HTML &amp; CSS aren’t enough anymore and that everything is complicated –&nbsp;I think this is largely that the application stack for building websites has replaced the document stack in a lot of places. Where we would use Jekyll or server-side rendering, we now use React or Vue.js. There are advantages to that, but for a lot of minimally-interactive websites, it’s throwing away decades worth of knowledge in exchange for certain performance perks that might not even matter.</p><p>The appeal of social networks is partly because they let us create <em>documents</em> without thinking about web technology, and they provide guarantees around performance, accessibility, and polish that otherwise would take up our time. You don’t have to think about whether your last Facebook post will load quickly on your friend’s phone or whether your Instagram post will be correctly cropped and resized in the timeline - those things are taken care of.</p><p>To some extent, this doesn’t <em>need</em> to be something that only social networks provide, though: standards like <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> and services like <a href="https://www.instapaper.com/">Instapaper</a> show that pleasing formatting and distribution can be done at the <em>platform level</em> and be provided on top of existing vanilla websites.</p><details><summary>These are not absolutes.</summary>Yeah, I can hear it now: but these categories are not …</details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/08/22/clean-starts-for-the-web.html">https://macwright.com/2020/08/22/clean-starts-for-the-web.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/08/22/clean-starts-for-the-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24247362</guid>
            <pubDate>Sat, 22 Aug 2020 21:22:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to update U-Boot for PostmarketOS on the Pine Phone]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24244407">thread link</a>) | @dustfinger
<br/>
August 22, 2020 | https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/ | <a href="https://web.archive.org/web/*/https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 


<!--endtoc-->

<h2 id="introduction">Introduction</h2>

<p>If you are in a hurry to update U-Boot and the SPL on your PinePhone, then please proceed directly to <a href="#write-u-boot-plus-spl-to-bootable-storage">Write U-Boot+SPL to bootable storage</a>.</p>

<p>In this article, I am going to explain what U-Boot, SoC and the SPL are. After that, I will describe the sunxi bootable storage layout as well as the PinePhone boot procedure, so you will understand what you will be updating and why. Then, I will teach you how to determine if an upgrade is required, and I will explain two different ways of upgrading U-Boot. As a special treat for the curious, I will show you the first steps to reverse engineer the U-Boot+SPL firmware blob. I hope this article peeks your curiosity and encourages you to learn more.</p>

<p>Discussed on <a href="https://news.ycombinator.com/item?id=24244407">Hacker News</a> and <a href="https://forum.pine64.org/showthread.php?tid=11099">Pine64</a>.</p>

<h2 id="what-is-u-boot">What is U-Boot?</h2>

<p>U-Boot, or rather <a href="https://en.wikipedia.org/wiki/Das%5FU-Boot">Das U-Boot</a> a.k.a <em>the Universal Boot Loader</em>, is a small program that is loaded into <em>read-only memory</em> (ROM) and is ultimately responsible for loading the Linux kernel. Designed with flexibility in mind, U-Boot now supports <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/arch">a wide variety of architectures</a> for <a href="https://gitlab.denx.de/u-boot/u-boot/-/tree/master/board">embedded boards</a>, each of which may support multiple boot methods. This article is only concerned with U-Boot as it is configured for the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/board/sunxi/README.sunxi64">Allwinner 64-bit boards</a>, specifically the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>.</p>

<h2 id="what-is-a-soc">What is a SoC?</h2>

<p>No, it does not refer to the stinky fabric covering your feet. <em>SoC</em> stands for <em>System on a Chip</em>. The PinePhone contains the <a href="https://linux-sunxi.org/A64">Allwinner A64 SoC</a>, featuring a Quad-Core <a href="https://en.wikipedia.org/wiki/ARM%5FCortex-A53">ARM Cortex-A53 ARMv8-A CPU</a> and an <a href="https://linux-sunxi.org/Mali400">ARM Mali400 MP2 GPU</a>. See the <a href="https://linux-sunxi.org/A64#Documentation">Allwinner A64 documentation</a> for more details.</p>

<h2 id="what-is-the-spl">What is the SPL?</h2>

<p>The <em>Secondary Program Loader’s</em> (SPL) primary function is to load U-Boot proper, the <em>flattened device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>Arm Trusted Firmware</em> (<a href="https://www.trustedfirmware.org/about/">ATF</a>), ultimately passing execution to the ATF. In particular, execution is passed to <em>Trusted Firmware-A</em> (<a href="https://trustedfirmware-a.readthedocs.io/en/latest/index.html">TF-A</a>), which is <a href="https://github.com/ARM-software/arm-trusted-firmware">the official reference implementation</a> used by SoCs with armv8- cores, such as <a href="https://trustedfirmware-a.readthedocs.io/en/latest/plat/allwinner.html">Allwinner Armv8-A SoCs</a>.</p>

<h2 id="what-installs-the-spl">What installs the SPL?</h2>

<p>The SPL is installed via the <code>u-boot-pinephone</code> package from the <a href="http://postmarketos1.brixit.nl/postmarketos/master/aarch64/">postmarketOS aarch64 APK repository</a>. The package is built from the <a href="https://gitlab.com/pine64-org/u-boot/">pine64 u-boot fork</a> in which they added a <a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/.gitlab-ci-pine64.yml">pine64 specific GitLab CI/CD pipeline configuration</a>. By listing the contents of the package using the <a href="https://wiki.alpinelinux.org/wiki/Alpine%5FLinux%5Fpackage%5Fmanagement#apk%5Finfo">apk info</a> command we can see where the SPL binary is actually installed to the root file system.</p>
<div><pre><code data-lang="sh">second-chance:~$ apk info -L u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone-2020.04_git20200421-r1 contains:
usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>However, this is just a convenient location to deliver the binary. The SPL must be deployed to a specific location on disk so that the BootROM can load it.</p>

<h2 id="a-bit-about-bytes">A bit about bytes</h2>

<p>I suspect that not all of those reading this article are familiar with the various standards when it comes to measuring information. Allow me to digress with a brief introduction to these standards with respect to how they both measure and represent a <em>kilobyte</em>. Many of the articles that I have linked herein use the <em><a href="https://en.wikipedia.org/wiki/JEDEC%5Fmemory%5Fstandards#Unit%5Fprefixes%5Ffor%5Fsemiconductor%5Fstorage%5Fcapacity">Joint Electron Device Engineering Council</a></em> (JEDEC) memory standards in which the unit for <em>kilobyte</em> is denoted by (<code>KB</code>), in upper case letters and represents <code>1024B</code>. This is not to be confused with the kilobyte from the <em><a href="https://en.wikipedia.org/wiki/Metric%5Fprefix/">International System of Quantities</a></em> (SI) in which <em>kilo</em> is denoted with a lower case <code>k</code>, such that <code>kB</code> means <code>1000B</code>. My preference is to use the <a href="https://en.wikipedia.org/wiki/Kibibyte">kibibyte</a> (pron. KI-BEE-BYTE), which was established by the <em><a href="https://en.wikipedia.org/wiki/International%5FElectrotechnical%5FCommission">International Electrotechnical commission</a></em> (IEC) and is recognized by all major standards organizations, including those aforementioned.</p>

<table>
<thead>
<tr>
<th>Decimal</th>
<th></th>
<th>Binary</th>
<th></th>
<th></th>
</tr>
</thead>

<tbody>
<tr>
<td>Value</td>
<td>Metric</td>
<td>Value</td>
<td>IEC</td>
<td>JEDEC</td>
</tr>

<tr>
<td>1</td>
<td>B byte</td>
<td>1</td>
<td>B byte</td>
<td>B byte</td>
</tr>

<tr>
<td>1000</td>
<td>kB kilobyte</td>
<td>1024</td>
<td>KiB kibibyte</td>
<td>KB kilobyte</td>
</tr>

<tr>
<td>1000^2</td>
<td>MB megabyte</td>
<td>1024^2</td>
<td>MiB mebibyte</td>
<td>MB megabyte</td>
</tr>

<tr>
<td>1000^3</td>
<td>GB gigabyte</td>
<td>1024^3</td>
<td>GiB gibibyte</td>
<td>GB gigabyte</td>
</tr>

<tr>
<td>1000^4</td>
<td>TB terabyte</td>
<td>1024^4</td>
<td>TiB tebibyte</td>
<td>-</td>
</tr>
</tbody>
</table>

<p>The reasoning behind my preference is two fold:</p>

<ol>
<li>The JEDEC <a href="https://www.jedec.org/document%5Fsearch?search%5Fapi%5Fviews%5Ffulltext=JESD100B01">Terms, Definitions, and Letter Symbols for Microcomputers, Microprocessors, and Memory Integrated Circuits</a> only defines the first three higher order prefixes: <em>kilo</em> (K), <em>mega</em> (M), <em>giga</em> (G), referring to them for common usage. The prefix <em>tera</em> was later added to the JEDEC terms dictionary to reflect <a href="https://www.jedec.org/standards-documents/dictionary/terms/mega-m-prefix-units-semiconductor-storage-capacity">common prefix usage for modern semiconductor storage capacity</a>.</li>
<li>IEC prefixes cannot be confused with Metric prefixes.</li>
</ol>

<p>To make matters more confusing, sometimes lowercase <code>k</code> is used to mean 1024, e.g. see <a href="https://man7.org/linux/man-pages/man1/tar.1.html#OPTIONS">tar(1) OPTIONS</a> sub section <code>Size Suffixes</code> located <a href="https://man7.org/linux/man-pages/man1/tar.1.html#RETURN%5FVALUE">above the RETURN VALUE section</a>. Understanding which system of measurement is being used is essential when calculating offsets.</p>

<h2 id="layout-of-sunxi-bootable-storage">Layout of sunxi bootable storage</h2>

<p>The first 40 plus <code>KiB</code> of bootable storage for an Allwinner based board has the <a href="https://linux-sunxi.org/Bootable%5FSD%5Fcard#SD%5FCard%5FLayout">following default layout</a>:</p>

<table>
<thead>
<tr>
<th>Start</th>
<th>Size</th>
<th>Usage</th>
</tr>
</thead>

<tbody>
<tr>
<td>0KiB</td>
<td>8KiB</td>
<td>Reserved for optional MBR or GPT</td>
</tr>

<tr>
<td>8KiB</td>
<td>32KiB</td>
<td>Initial SPL</td>
</tr>

<tr>
<td>40KiB</td>
<td>-</td>
<td>U-Boot Proper</td>
</tr>
</tbody>
</table>

<p>From the layout, one can conclude that upgrading the SPL and U-Boot for the PinePhone must involve writing the <code>u-boot-sunxi-with-spl.bin</code> to bootable storage starting at <code>8192B</code>.</p>

<h2 id="pinephone-boot-procedure">PinePhone boot procedure</h2>

<p>Bootstrapping is complicated by initial memory address space limitations. The <a href="https://linux-sunxi.org/BROM#U-Boot%5FSPL%5Flimitations">SPL is limited to 32 KiB</a>, most likely because the BootROM, or BROM, loads the SPL into <a href="https://linux-sunxi.org/A64/Memory%5Fmap">SRAM A1</a>, which is a <code>32 KiB</code> subsection. If the SPL is larger than <code>32 KiB</code> the BROM will refuse to load it. After the SPL loads U-Boot proper and passes execution to the ATF, U-Boot proper in turn runs <a href="https://gitlab.com/postmarketOS/pmaports/-/blob/master/device/community/device-pine64-pinephone/uboot-script.cmd">the Pine Phone’s u-boot command script</a>. The command script sets the default bootargs for init and calls the <a href="https://gitlab.denx.de/u-boot/u-boot/-/blob/master/cmd/booti.c">booti command</a>, which boots the Linux Kernel Image from memory given the <em>flattend device tree</em> (<a href="https://devicetree-specification.readthedocs.io/en/latest/flattened-format.html">FDT</a>) and the <em>initial ramdisk</em> (<a href="https://en.wikipedia.org/wiki/Initrd">initrd</a>), ultimately passing execution to Linux init.</p>



<div>
  
<div><pre><code data-lang="text">+-----------------------+
|        BootROM        |
+-----------.-----------+
|
|
+-----------V-----------+
|     u-boot.itb+SPL    |
+-----------.-----------+
|
|
+-----------V-----------+
|       TF-A BL31       |
+-----------.-----------+
|
|
+-----------V-----------+
| U-Boot Proper (=BL33) |
+-----------.-----------+
|
|
+-----------V-----------+
|        Linux          |
+-----------------------+</code></pre></div>
</div>

<p>You might have noticed that <code>/usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code> is much larger than <code>32KiB</code>.</p>
<div><pre><code data-lang="text">second-chance:~$ ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin
-rw-r--r--    1 root     root      486.0K Jun 20 12:41 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>That is because the SPL binary image includes a <em>Flattened uImage Tree</em> (<a href="https://gitlab.com/pine64-org/u-boot/-/blob/master/doc/uImage.FIT/source%5Ffile%5Fformat.txt">FIT image</a>) named <code>u-boot.itb</code> that contains the rest of the firmware.</p>

<h2 id="determine-which-bootable-storage-device-is-relevant">Determine which bootable storage device is relevant</h2>

<p>Before you can <a href="#how-to-determine-if-u-boot-needs-to-be-upgraded">determine if U-Boot needs to be upgraded</a>, you need to know which storage device your PinePhone is booting from. This can be easily determined by using the <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> command to list the running operating system’s current mount points. Below is the output of <a href="https://linux.die.net/man/8/lsblk">lsblk(8)</a> run on my PinePhone booted from an <code>SD</code> card:</p>
<div><pre><code data-lang="sh">second-chance:~$ lsblk --output NAME,TYPE,MOUNTPOINT</code></pre></div><div><pre><code data-lang="text">NAME         TYPE MOUNTPOINT
mmcblk0      disk
├─mmcblk0p1  part /boot
└─mmcblk0p2  part
mmcblk2      disk
├─mmcblk2p1  part
├─mmcblk2p2  part
├─mmcblk2p1  part
└─mmcblk2p2  part
mmcblk2boot0 disk
mmcblk2boot1 disk</code></pre></div>
<p>The disk corresponding to the <code>/boot</code> mountpoint is the name of the block special device that postmarketOS is currently running form. The device path to the relevant boot storage device is therefore <code>/dev/mmcblk0</code>. We will be using this device name in the next two sections to determine if an upgrade is needed and again to perform the actual upgrade if warranted. You must be careful to use the device name that is relevant to your own running environment if you are following along.</p>

<h2 id="how-to-determine-if-u-boot-needs-to-be-upgraded">How to determine if U-Boot needs to be upgraded?</h2>

<p>You can determine if an upgrade is necessary simply by comparing the version of U-Boot installed by the <code>u-boot-pinephone</code> package with the version of U-Boot that is written to <a href="#determine-which-bootable-storage-device-is-relevant">the bootable storage device which is relevant to your running environment</a>.</p>

<p>To see which version of <code>U-Boot</code> was installed by the <code>u-boot-pinephone</code> package, simply run the <code>apk policy</code> sub command as shown below:</p>
<div><pre><code data-lang="sh">second-chance:~/$ apk policy u-boot-pinephone</code></pre></div><div><pre><code data-lang="text">u-boot-pinephone policy:
  2020.04_git20200421-r1:
    lib/apk/db/installed
    etc/apk/cache
    http://postmarketos1.brixit.nl/postmarketos/master</code></pre></div>
<p>Alternatively, you can use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>strings</code> command to search the binary’s printable strings for the regex pattern <code>U-Boot [[:digit:]]</code> by piping the output through a <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>grep</code> filter. As a side note, the PinePhone uses busybox, so when you find yourself looking up command line documentation with the intention of running the command from a PinePhone shell, always check the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> man pages first.</p>
<div><pre><code data-lang="sh">second-chance:~/packages$ strings /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin | grep -E <span>'U-Boot [[:digit:]]'</span></code></pre></div><div><pre><code data-lang="text">U-Boot 2020.04 (Jun 20 2020 - 12:41:48 +0000)</code></pre></div>
<p>Similarly, to determine the version of U-Boot that is currently written to bootable storage, you can search for the same regex pattern in the printable strings of the boot disk after the first <code>8 KiB</code>. However, since the bootable storage is significantly larger than <code>u-boot-sunxi-with-spl.bin</code>, it would not be efficient to use the <code>strings</code> command as we did previously. Instead, we will use the <a href="https://linux.die.net/man/1/busybox">busybox(1)</a> <code>dd</code> command, which will allow us to control where to begin and end the search. Since we can’t easily know the exact offset of the version string, which can very from build to build, my strategy has been to simply skip the first <code>8 KiB</code> and then read the same number of <code>KiB</code> as the size of the currently installed <code>u-boot-sunxi-with-spl.bin</code>. If my search turns up nothing, then that means that the previously installed version was larger, and I can simply increase the <code>count</code> to some reasonable number of <code>KiB</code> until I find what I am looking for.</p>

<p>First, let’s determine the size of <code>u-boot-sunxi-with-spl.bin</code>.</p>
<div><pre><code data-lang="sh">ls -lh /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div><div><pre><code data-lang="text">-rw-r--r--    1 root     root      543.3K Jul 18  2020 /usr/share/u-boot/pine64-pinephone/u-boot-sunxi-with-spl.bin</code></pre></div>
<p>The binary installed to disk is about <code>5…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/">https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</a></em></p>]]>
            </description>
            <link>https://bloggerbust.ca/post/how-to-update-uboot-for-postmarketos-on-the-pinephone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244407</guid>
            <pubDate>Sat, 22 Aug 2020 14:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build tools around workflows, not workflows around tools]]>
            </title>
            <description>
<![CDATA[
Score 435 | Comments 135 (<a href="https://news.ycombinator.com/item?id=24244329">thread link</a>) | @thesephist
<br/>
August 22, 2020 | https://thesephist.com/posts/tools/ | <a href="https://web.archive.org/web/*/https://thesephist.com/posts/tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><em>This March, I spent a couple of days traveling through western Iceland.</em></p>
<p><img src="https://thesephist.com/img/iceland.jpg" alt="Iceland, part 1"></p>
<p>While I was there, I thought a lot about tools – mechanical tools, software tools, tools that last, and tools that are fragile. The somber snow-covered scenery made me think about how quickly most of the tools we use today get outdated or replaced, and I thought about the kinds of tools that I’ve been building for myself for the last few years to help organize my life.</p>
<p>I took a walk around <em>Smábátahöfnin í Keflavík</em> (a small marina nearby) that night, unraveled myself into my hotel room, and started writing this post.</p>
<p>I want to share why I build my own tools and how I think we should think about building tools for life. It’s long, so here’s a roadmap. Feel free to jump around.</p>
<ol>
<li><a href="#my-tools-today">My tools, today</a></li>
<li><a href="#workflows--tools">Workflows &gt; tools</a>
<ol>
<li><a href="#tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</a></li>
<li><a href="#tools-that-grow-with-your-workflows">Tools that grow with your workflows</a></li>
</ol>
</li>
<li><a href="#own-your-load-bearing-tools-of-life">Own your load-bearing tools of life</a></li>
<li><a href="#cost-and-other-smaller-benefits">Cost and other smaller benefits</a></li>
<li><a href="#your-tools-are-an-extension-of-you">Your tools are an extension of you</a></li>
<li><a href="#appendix-the-technical-nitty-gritty">Appendix: the technical nitty-gritty</a></li>
</ol>
<hr>

<p>For the last few years, I’ve been on a journey to replace all of the essential digital tools I use for organizing my life with tools I develop, maintain, and deploy myself.</p>
<p>What started with a single-page notes app I made in high school has grown into a constellation of home-grown productivity tools I now rely on for my day-to-day work and learning. Here’s a sample.</p>
<ul>
<li>
<p><a href="https://github.com/thesephist/polyx#ligature">Ligature</a>, for long-term notes and tasks, goals, brainstorming, project planning, and other important writing.</p>
<p><img src="https://thesephist.com/img/ligature.jpg" alt="Ligature"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/pico">Pico</a>, for more ephemeral notes and tasks that change on a daily basis. I split up my notes into two apps (Ligature and Pico) because it works better for my workflow. (More on this later.)</p>
<p><img src="https://thesephist.com/img/pico.jpg" alt="Pico"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/mira">Mira</a> for keeping track of people I know, why they’re interesting, and what we’ve talked about.</p>
<p><img src="https://thesephist.com/img/mira.png" alt="Mira"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/lovecroft">Lovecroft</a> for managing and sending emails to my <a href="https://thesephist.com/#newsletter">mailing lists</a>.</p>
<p><img src="https://thesephist.com/img/lovecroft.jpg" alt="Lovecroft"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/polyx#noct">Noct</a> for backing up and syncing all my files across computers and the cloud. Noct doesn’t have a graphical UI, just a command-line tool.</p>
</li>
<li>
<p><a href="https://thesephist.com/posts/frieden/">Frieden</a> as a public availability calendar, showing when I’m free or busy.</p>
<p><img src="https://thesephist.com/img/frieden.png" alt="Frieden"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/thingboard">Thingboard</a> for more free-form Post-its-on-the-wall style brainstorming.</p>
<p><img src="https://thesephist.com/img/thingboard.jpg" alt="Thingboard"></p>
</li>
<li>
<p><a href="https://codeframe.co/">Codeframe</a> for spinning off simple JavaScript experiments like <a href="https://thesephist.com/posts/word-experiments/#word-plotter">the word plotter</a>.</p>
<p><img src="https://thesephist.com/img/codeframe.jpg" alt="Codeframe"></p>
</li>
<li>
<p><a href="https://github.com/thesephist/draw">draw</a>, a collaborative whiteboard, best used with my iPad Pro and Apple Pencil.</p>
<p><img src="https://thesephist.com/img/draw.jpg" alt="Draw"></p>
</li>
</ul>
<p>Taken together, these apps do almost everything I need to do on my computer to keep myself organized. I don’t use any third-party notes, task management, or contacts apps, though I used to be a big fan of Simplenote and Todoist. I’ve used Notion, Dropbox Paper, Google Docs, and Airtable, but only for working in teams that centralized on them. These days, besides email and calendar, I live within a system of my own tools, and it works well for me.</p>
<p>I don’t want to imply that my tools are objectively better than the professional tools on the market like Notion and Dropbox. Those latter services have more features, and might even be more reliable today. But I think my tools fit me better for a different reason.</p>

<p>Each person’s mind works a little differently, and each person remembers and processes information a little differently. I think we all work at our best when we work with tools that fit how our minds work.</p>
<p>The Eureka moment that some of us feel when we finally find a notes app or todo system that fits our brains – that epiphany happens when the tools we use mirror the way our minds work, and how we want to move information through our lives. Good tools fit perfectly around our workflows, bad tools don’t.</p>
<p>When we resort to having other people build tools for us, the tools they build might never quite perfectly fit our workflows, because they’re not built for our individual minds. When other people build tools for us to use, they either design tools after their own workflows and mental models, or worse, they design it for a mass market of millions of people who all sort-of-but-not-really work and think in similar ways. The result is that mass-market productivity tools don’t fit the way our individual minds are predisposed to work. Instead, to use these tools, we need to bend our workflows to fit around the tools.</p>
<p>My biggest benefit from writing my own tool set is that <strong>I can build the tools that exactly conform to my workflows, rather than constructing my workflows around the tools available to me.</strong> This means the tools can truly be an extension of the way my brain thinks and organizes information about the world around me. My tools aren’t perfect yet, but as they grow and evolve, they’ll only become better reflections of my personal mental models.</p>
<p>For example, one place where my mind works differently than the tools on the market is the task/notes distinction.</p>
<h3 id="tasks-and-notes-a-false-dichotomy">Tasks and notes, a false dichotomy</h3>
<p>My workflow used to differentiate between tasks and notes. Tasks were action items that I could reference, take action on, and complete, and then erase from my list. Notes were things that were indefinitely relevant. I would take notes and then come back to reference them many times. A note by itself isn’t actionable.</p>
<p>But once I started building my own tools, I realized this distinction isn’t really the way my brain worked. For me, a huge grey area exists between actionable, completable tasks and purely encyclopedic notes. Here are some things that fall in the grey area for me, pulled from my real, actual notes I took this week.</p>
<ol>
<li>I recently learned some really useful tips about how to grow leaders within a community from the book <em><a href="https://gettogetherbook.com/">Get Together</a></em>. I definitely want to act on these learnings at some point in the communities I lead, but I don’t want them cluttering up my todo list because they’re not things I can just complete and check off quickly. I also want to remember these tips forever, even after the first time I act on them.</li>
<li>I’ve been brainstorming an idea for a side project related to <a href="https://en.wikipedia.org/wiki/Computer_algebra">symbolic mathematics</a>. I’ve been writing down my inspirations related to this project. I don’t want to tuck it away in my notes, because this is something I want to build soon, but I also don’t want to shove paragraphs of notes into a todo list item.</li>
<li>I keep a running list of ideas I have for future blog posts, but I don’t really have a “write the next blog post” task item under which I’d normally put these ideas, because I don’t write on schedule – I just write when I can. Where should these ideas go? They’re sort-of notes and sort-of tasks.</li>
</ol>
<p>You might think that these are either very clearly todo items or very clearly notes, and that’s ok. But I certainly felt differently, and I realized I was only separating things into these two buckets because my tools forced me to. Before I wrote my own tools, I had a todo app (Todoist) and I had a notes app (Simplenote), and there was nothing in between.</p>
<p>Eventually, I discovered a better mental model for my working style: I ask myself <em>how immediately</em> I need to take action on something.</p>
<p>The way that I see it, everything I learn and jot down is something for me to act on at some point in my life. If I read something that I never thought would influence the way I lived, it wouldn’t have value to me, and I simply wouldn’t write it down. Armed with this insight, these days, I have two different notes apps, and I don’t use a todo list app. These two apps are Ligature and Pico, mentioned above.</p>
<p>One is for notes that are changing often. Day-to-day tasks, things to remember for the next week, even long notes and links related to what I’m working on <em>now</em>. The other app is for notes that grow over time, like notes I take while reading books or watching talks, my annual goals, financial planning, reading list, and project outlines. <strong>My two notes apps mirror the way my brain works best – one is my short-term, working memory, the other is my long-term memory.</strong></p>
<p>I’ve had this system for a few months now, and haven’t felt any need for something better. It doesn’t have the crazy features of some notes services on the market today, but it just works the way my brain does.</p>
<p>But what if I need something different later on in life?</p>
<h3 id="tools-that-grow-with-your-workflows">Tools that grow with your workflows</h3>
<p>The other benefit of building homebrew tools is that <strong>tools you build yourself can grow and change as your workflow changes over time</strong>. So if my needs do change over time, my tools can grow to accommodate exactly what I need.</p>
<p>When I first started keeping more organized notes on the interesting people I met, I started with a document in my notes app. Over time, I noticed that these notes followed a pattern: I wrote down their name and primary contact info, how I first met them, what school they went to, and what we talked about the last time we spoke.</p>
<p>So when I built Mira, my own people-manager app, I designed it around that exact workflow I had developed. When I later realized I was also recording people’s Twitter usernames in the description field, I just added a Twitter username field to each contact.</p>
<p>This is typical of the way I <em>discover</em> my workflows. <strong>I start with a minimal, bare-bones solution, and try to pick up on patterns and tricks I create for myself. And then I encode those patterns and tricks into the tools over time.</strong></p>
<p>This way, my tools can grow organically as my workflows evolve. Neither of them gets in the way of each other most of the time, and I think that was hard to appreciate before I started relying wholly on my own tools.</p>

<p>My productivity tools, especially my notes and contacts, are the load-bearing tools of my life. If they break or disappear, it’ll take a long time and a lot of effort for me to rebuild those same workflows and tools, so it’s important that they’re reliable, and that I can depend on them working for me for a long time (measured in years and decades, not quarters).</p>
<p>I’ve written at length about <a href="https://thesephist.com/posts/ownership/">the importance of ownership</a> before. I want to own the pieces of my life that are most critical, and I want agency over how these tools change over time.</p>
<p>I want these notes and ideas and workflows to stick with me as I grow as a person through the next decades. If I had to …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesephist.com/posts/tools/">https://thesephist.com/posts/tools/</a></em></p>]]>
            </description>
            <link>https://thesephist.com/posts/tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24244329</guid>
            <pubDate>Sat, 22 Aug 2020 14:23:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rolling your own crypto gone wrong: A look at a .NET Branca implementation]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24243750">thread link</a>) | @todsacerdoti
<br/>
August 22, 2020 | https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html | <a href="https://web.archive.org/web/*/https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h3 id="introduction">Introduction</h3>

<p>Some time back, I was looking at token authentication formats to authenticate some API calls. I didn’t even attempt to look at JWT &amp; Co. for <a href="https://paragonie.com/blog/2017/03/jwt-json-web-tokens-is-bad-standard-that-everyone-should-avoid">multiple reasons</a>. I landed between <a href="https://paseto.io/">PASETO</a> and <a href="https://branca.io/">Branca</a>.</p>

<p>I chose Branca for its simplicity. I needed authenticated API calls with a shared symmetric key. Both Branca and PASETO implemented this using XChaCha20-Poly1305, but PASETO also supports asymmetric authentication, which I didn’t need. I was quite pleased by looking at how straight-forward Branca <a href="https://github.com/tuupola/branca-spec#token-format">made it</a>:</p>
<div><div><pre><code>Version (1B) || Timestamp (4B) || Nonce (24B) || Ciphertext (*B) || Tag (16B)
</code></pre></div></div>

<p>Simply construct a header and encrypt and authenticate the payload using XChaCha20-Poly1305, with the header as the AAD.</p>

<p>Back then, there was only one <a href="https://github.com/thangchung/branca-dotnet">.NET implementation</a>, which targeted .NET Core whereas I needed .NET Framework. I took a quick look: there were no test vectors and used ChaCha20-Poly1305 instead of XChaCha20-Poly1305. It was only available GitHub, so I thought it may just be a toy project for fun. I dropped it and forgot about it.</p>

<p>Fast forward a couple of days ago, I returned to find <a href="https://github.com/scottbrady91/IdentityModel">a new</a> .NET Core implementation. It was also published as a NuGet, which got my hopes up - might be a polished implementation that I could get working on .NET Framework.</p>

<p><a href="https://www.nuget.org/packages/ScottBrady.IdentityModel/">ScottBrady.IdentityModel</a> is a relatively new NuGet, with three releases in total. Its first release was at the beginning of May this year and the latest was at the beginning of this August. It uses <a href="https://www.bouncycastle.org/csharp/index.html">BouncyCastle</a> for cryptographic implementations and offers both PASETO and Branca.</p>

<p>Note: All code discussed is based on the master branch at <a href="https://github.com/scottbrady91/IdentityModel/commit/4ff8a06719bd83a4129f45d2ce92f1891a51bd01">4ff8a06</a>. I’ll also be referring to this NuGet as just IdentityModel throughout the rest of this post.</p>

<h3 id="inspection">Inspection</h3>

<h4 id="tokenssecuritytokenexception-invalid-message-authentication-code">Tokens.SecurityTokenException: Invalid message authentication code</h4>

<p>I pulled down IdentityModel in a new project and took some <a href="https://github.com/tuupola/branca-js/blob/master/test.js">test vectors</a> from the JS reference implementation, which is linked in the specification for Branca.</p>

<div><div><pre><code><span>static</span> <span>void</span> <span>TestBranca</span><span>(</span><span>string</span> <span>expectedToken</span><span>,</span> <span>string</span> <span>expectedPayload</span><span>)</span> 
<span>{</span>
    <span>var</span> <span>handler</span> <span>=</span> <span>new</span> <span>BrancaTokenHandler</span><span>();</span>
    <span>var</span> <span>key</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>"supersecretkeyyoushouldnotcommit"</span><span>);</span>

    <span>try</span>
    <span>{</span>
        <span>var</span> <span>actualToken</span> <span>=</span> <span>handler</span><span>.</span><span>CreateToken</span><span>(</span><span>expectedPayload</span><span>,</span> <span>key</span><span>);</span>
        <span>var</span> <span>actualPayload</span> <span>=</span> <span>handler</span><span>.</span><span>DecryptToken</span><span>(</span><span>expectedToken</span><span>,</span> <span>key</span><span>);</span>
    <span>}</span>
    <span>catch</span> <span>(</span><span>Exception</span> <span>e</span><span>)</span>
    <span>{</span>
        <span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"FAILED: \nexpectedToken: {0}\nexpectedPayload: {1}\nexception: {2}\n"</span><span>,</span> <span>expectedToken</span><span>,</span> <span>expectedPayload</span><span>,</span> <span>e</span><span>.</span><span>Message</span><span>);</span>
    <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>Main</span><span>(</span><span>string</span><span>[]</span> <span>args</span><span>)</span>
<span>{</span>
    <span>TestBranca</span><span>(</span><span>"870S4BYjk7NvyViEjUNsTEmGXbARAX9PamXZg0b3JyeIdGyZkFJhNsOQW6m0K9KnXt3ZUBqDB6hF4"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
    <span>TestBranca</span><span>(</span><span>"89i7YCwtsSiYfXvOKlgkCyElnGCOEYG7zLCjUp4MuDIZGbkKJgt79Sts9RdW2Yo4imonXsILmqtNb"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
    <span>TestBranca</span><span>(</span><span>"875GH234UdXU6PkYq8g7tIM80XapDQOH72bU48YJ7SK1iHiLkrqT8Mly7P59TebOxCyQeqpMJ0a7a"</span><span>,</span> <span>"Hello world!"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Running the above tests gave me:</p>

<div><div><pre><code>FAILED: 
expectedToken: 870S4BYjk7NvyViEjUNsTEmGXbARAX9PamXZg0b3JyeIdGyZkFJhNsOQW6m0K9KnXt3ZUBqDB6hF4
expectedPayload: Hello world!
exception: Invalid message authentication code

FAILED: 
expectedToken: 89i7YCwtsSiYfXvOKlgkCyElnGCOEYG7zLCjUp4MuDIZGbkKJgt79Sts9RdW2Yo4imonXsILmqtNb
expectedPayload: Hello world!
exception: Invalid message authentication code

FAILED: 
expectedToken: 875GH234UdXU6PkYq8g7tIM80XapDQOH72bU48YJ7SK1iHiLkrqT8Mly7P59TebOxCyQeqpMJ0a7a
expectedPayload: Hello world!
exception: Invalid message authentication code
</code></pre></div></div>

<p>I was already off to a good start.</p>

<h4 id="nonce-generation">Nonce generation</h4>
<p>Starting at the top of the file containing the Branca implementation, comes <code>CreateToken()</code>. The first thing is nonce generation:</p>
<div><div><pre><code><span>var</span> <span>nonce</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>24</span><span>];</span>
<span>RandomNumberGenerator</span><span>.</span><span>Create</span><span>().</span><span>GetBytes</span><span>(</span><span>nonce</span><span>);</span>
</code></pre></div></div>

<p>It uses the <a href="https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.randomnumbergenerator.getbytes?view=netcore-3.1">System.Security.Cryptography.RandomNumberGenerator.GetBytes</a> method, which is intended for cryptographic purposes, so that checks out.</p>

<h4 id="unauthenticated-ciphertext">Unauthenticated ciphertext</h4>

<p>After the nonce is generated, the header is created according to the specification. No problem there. Then comes the encryption:</p>

<div><div><pre><code><span>keyMaterial</span> <span>=</span> <span>new</span> <span>KeyParameter</span><span>(</span><span>key</span><span>);</span>
<span>var</span> <span>parameters</span> <span>=</span> <span>new</span> <span>ParametersWithIV</span><span>(</span><span>keyMaterial</span><span>,</span> <span>nonce</span><span>);</span>

<span>var</span> <span>engine</span> <span>=</span> <span>new</span> <span>XChaChaEngine</span><span>();</span>
<span>engine</span><span>.</span><span>Init</span><span>(</span><span>true</span><span>,</span> <span>parameters</span><span>);</span>
</code></pre></div></div>

<p>I’m not familiar with BouncyCastle, so I checked its source to see what <code>KeyParameter</code> and <code>ParametersWithIV</code> were doing. They were simply wrappers for the parameters.</p>

<p><code>XChaChaEngine()</code> was not from BouncyCastle however, but implemented in IdentityModel:</p>

<div><div><pre><code><span>using</span> <span>Org.BouncyCastle.Crypto.Engines</span><span>;</span>

<span>namespace</span> <span>ScottBrady.IdentityModel.Crypto</span>
<span>{</span>
    <span>public</span> <span>class</span> <span>XChaChaEngine</span> <span>:</span> <span>ChaChaEngine</span>
    <span>{</span>
        <span>public</span> <span>XChaChaEngine</span><span>()</span> <span>:</span> <span>base</span><span>(</span><span>20</span><span>)</span> <span>{</span> <span>}</span>

        <span>public</span> <span>override</span> <span>string</span> <span>AlgorithmName</span> <span>=&gt;</span> <span>"XChaCha20"</span><span>;</span>

        <span>protected</span> <span>override</span> <span>int</span> <span>NonceSize</span> <span>=&gt;</span> <span>24</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>After initializing the <code>XChaChaEngine</code>, the payload is “encrypted and authenticated”:</p>

<div><div><pre><code><span>var</span> <span>plaintextBytes</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>payload</span><span>);</span>
<span>var</span> <span>ciphertext</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>plaintextBytes</span><span>.</span><span>Length</span> <span>+</span> <span>16</span><span>];</span>

<span>engine</span><span>.</span><span>ProcessBytes</span><span>(</span><span>plaintextBytes</span><span>,</span> <span>0</span><span>,</span> <span>plaintextBytes</span><span>.</span><span>Length</span><span>,</span> <span>ciphertext</span><span>,</span> <span>0</span><span>);</span>

<span>var</span> <span>poly</span> <span>=</span> <span>new</span> <span>Poly1305</span><span>();</span>
<span>poly</span><span>.</span><span>Init</span><span>(</span><span>keyMaterial</span><span>);</span>
<span>poly</span><span>.</span><span>BlockUpdate</span><span>(</span><span>header</span><span>,</span> <span>0</span><span>,</span> <span>header</span><span>.</span><span>Length</span><span>);</span>
<span>poly</span><span>.</span><span>DoFinal</span><span>(</span><span>ciphertext</span><span>,</span> <span>plaintextBytes</span><span>.</span><span>Length</span><span>);</span>
</code></pre></div></div>

<p>This is <strong>not a XChaCha20-Poly1305 construction</strong>. There is no padding of the AAD nor the ciphertext during authentication. Neither is there any authentication of their length. All this is specified in the <a href="https://github.com/bikeshedders/xchacha-rfc">draft RFC</a> and the <a href="https://tools.ietf.org/html/rfc8439">RFC for ChaCha20-Poly1305</a>. Actually, this does not even authenticate the ciphertext since <code>DoFinal()</code> writes the current tag into <code>ciphertext</code>. The <strong>ciphertext can be modified without invalidating the token</strong>.</p>

<div><div><pre><code><span>var</span> <span>handler</span> <span>=</span> <span>new</span> <span>BrancaTokenHandler</span><span>();</span>
<span>var</span> <span>key</span> <span>=</span> <span>Encoding</span><span>.</span><span>UTF8</span><span>.</span><span>GetBytes</span><span>(</span><span>"supersecretkeyyoushouldnotcommit"</span><span>);</span>
<span>var</span> <span>actualToken</span> <span>=</span> <span>handler</span><span>.</span><span>CreateToken</span><span>(</span><span>"Test"</span><span>,</span> <span>key</span><span>);</span>
<span>var</span> <span>decoded</span> <span>=</span> <span>Base62</span><span>.</span><span>Decode</span><span>(</span><span>actualToken</span><span>);</span>
<span>decoded</span><span>[</span><span>decoded</span><span>.</span><span>Length</span> <span>-</span> <span>17</span><span>]</span> <span>^=</span> <span>1</span><span>;</span> <span>// Last byte before the Poly1305 tag</span>
<span>Console</span><span>.</span><span>WriteLine</span><span>(</span><span>"{0}"</span><span>,</span> <span>handler</span><span>.</span><span>DecryptToken</span><span>(</span><span>Base62</span><span>.</span><span>Encode</span><span>(</span><span>decoded</span><span>),</span> <span>key</span><span>).</span><span>Payload</span><span>);</span>
</code></pre></div></div>

<p>Running this will return <code>Tesu</code> instead of <code>Test</code>. Thereby, <strong>IdentityModel allows attackers to arbitrarily modify the payload of a Branca token</strong>.</p>

<p>After searching BouncyCastle, I found no XChaCha20 implementation but a ChaCha20-Poly1305, which had the following fields:</p>

<div><div><pre><code><span>private</span> <span>readonly</span> <span>ChaCha7539Engine</span> <span>mChacha20</span><span>;</span>
<span>private</span> <span>readonly</span> <span>IMac</span> <span>mPoly1305</span><span>;</span>
</code></pre></div></div>

<p>As you might have noticed, <code>ChaCha7539Engine</code> is not the same engine that is implemented by <code>XChaChaEngine</code> in IdentityModel. Turns out, IdentityModel uses the ChaCha20 variant with a 64-bit nonce, instead of the 96-bit nonce required by the IETF version of ChaCha20. Both ChaCha20-Poly1305 and XChaCha20-Poly1305 require the IETF variant of ChaCha20. Taking a look at <code>ChaChaEngine</code> from BouncyCastle, there is no HChaCha20 being used to calculate a subkey, if the nonce length is set to 24 as in <code>XChaChaEngine</code>. Therefore, all we’re left with is the original ChaCha20 from DJB, using an 8-byte nonce, meaning <code>engine.Init(true, parameters)</code> only loads 8 bytes of the 24-byte nonce that has been generated.</p>

<p>The Branca specification makes it <a href="https://github.com/tuupola/branca-spec">pretty clear</a> how to encrypt the payload:</p>
<blockquote>
  <ol>
    <li>Encrypt the user given payload with IETF XChaCha20-Poly1305 AEAD with user-provided secret key. Use the header as the additional data for AEAD.</li>
  </ol>
</blockquote>

<p>It doesn’t have to be made as complicated as the above code from IdentityModel. If one reads the draft RFC, or looks at another implementation, it eventually becomes clear that XChaCha20-Poly1305 is “just” a combination of HChaCha20 and ChaCha20-Poly1305.</p>

<h4 id="forgeable-tokens">Forgeable tokens</h4>
<p>Let’s return to the attempt of authenticating the header and ciphertext. Specifically, this line:</p>


<p><code>keyMaterial</code> is <strong>the same key</strong> that was used to initialize the <code>XChaChaEngine</code>.</p>

<blockquote>
  <p>The sender must not use crypto_onetimeauth to authenticate more than one message under the same key. Authenticators for two messages under the same key should be expected to reveal enough information to allow forgeries of authenticators on other messages.</p>
</blockquote>

<p>(From <a href="https://nacl.cr.yp.to/onetimeauth.html">NaCl</a>)</p>

<p>As NaCls documentation states, any given key used with Poly1305 may <strong>only be used once</strong> otherwise, an attacker could forge future authenticators. This is a problem since Branca might be used in contexts like authenticating API calls, where long-lived API keys are used. <strong>IdentityModel allows attackers to forge API tokens</strong>.</p>

<p>This would not be a problem in IdentityModel, had it at least used ChaCha20-Poly1305 from BouncyCastle to attempt the Branca implementation. ChaCha20-Poly1305 uses the first 32 bytes of the first keystream-block (64 bytes), of the internal ChaCha20 state, as the Poly1305 one-time key. So if a nonce is unique for every time ChaCha20-Poly1305 is used with any given key (which it <strong>MUST</strong>), the Poly1305 key will also be unique.</p>

<p>Of course, IdentityModel should use XChaCha20-Poly1305, not only because that is what the Branca specification defines, but also because it’s not safe to randomly generate nonces for ChaCha20 or ChaCha20-Poly1305 (see <a href="https://godoc.org/golang.org/x/crypto/chacha20poly1305">/x/crypto</a>). This limitation was the motivation behind XChaCha20-Poly1305 (see <a href="https://github.com/bikeshedders/xchacha-rfc/blob/master/draft-irtf-cfrg-xchacha-rfc-03.txt">draft RFC</a>).</p>

<h4 id="constant-time-mac-comparison">Constant-time MAC comparison</h4>
<p>Any decent ChaCha20-Poly1305 or XChaCha20-Poly1305 implementation will compare the Poly1305 MACs in constant-time, to not reveal information via a timing side-channel. This, unfortunately, is not the case for IdentityModel either:</p>

<div><div><pre><code><span>var</span> <span>headerMac</span> <span>=</span> <span>new</span> <span>byte</span><span>[</span><span>16</span><span>];</span>
<span>[..]</span>
<span>if</span> <span>(!</span><span>headerMac</span><span>.</span><span>SequenceEqual</span><span>(</span><span>tag</span><span>))</span> <span>throw</span> <span>new</span> <span>SecurityTokenException</span><span>(</span><span>"Invalid message authentication code"</span><span>);</span>
</code></pre></div></div>

<p>BouncyCastle uses constant-time comparison with ChaCha20-Poly1305 and provides the comparison function as a utility:</p>

<div><div><pre><code><span>if</span> <span>(!</span><span>Arrays</span><span>.</span><span>ConstantTimeAreEqual</span><span>(</span><span>MacSize</span><span>,</span> <span>mMac</span><span>,</span> <span>0</span><span>,</span> <span>mBuf</span><span>,</span> <span>resultLen</span><span>))</span>
<span>{</span>
    <span>throw</span> <span>new</span> <span>InvalidCipherTextException</span><span>(</span><span>"mac check in ChaCha20Poly1305 failed"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<h3 id="summary">Summary</h3>

<p>I’m a big fan of “rolling your own crypto” and here I’m talking about implementing known algorithms. I do it myself. I even think making it available on GitHub or similar, to ask for feedback, is good (if users are warned that no security can be expected).</p>

<p>However, a problem arises when projects that …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html">https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html</a></em></p>]]>
            </description>
            <link>https://brycx.github.io/2020/08/22/a-look-at-a-branca-implementation.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243750</guid>
            <pubDate>Sat, 22 Aug 2020 12:45:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing better Code (extension to Joel's 12 steps to better Code)]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24243656">thread link</a>) | @gerlacdt
<br/>
August 22, 2020 | https://gerlacdt.github.io/posts/writing-better-software/ | <a href="https://web.archive.org/web/*/https://gerlacdt.github.io/posts/writing-better-software/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>I</span>n Joel Spolsky’s blog post <a href="https://www.joelonsoftware.com/2000/08/09/the-joel-test-12-steps-to-better-code/" target="_blank" rel="noopener">“The Joel Test: 12 Steps to better
Code”</a>,
he describes a test composed of twelve simple yes-no questions. For a
<strong>yes</strong> you get one point. 10 points are acceptable and 12 are
perfect. If you have less than 10 points, you will get in trouble with
your software – sooner or later.</p>
<p>For a quick self-check, these are the original questions:</p>
<ol>
<li>Do you use source control?</li>
<li>Can you make a build in one step?</li>
<li>Do you make daily builds?</li>
<li>Do you have a bug database?</li>
<li>Do you fix bugs before writing new code?</li>
<li>Do you have an up-to-date schedule?</li>
<li>Do you have a spec?</li>
<li>Do programmers have quiet working conditions?</li>
<li>Do you use the best tools money can buy?</li>
<li>Do you have testers?</li>
<li>Do new candidates write code during their interview?</li>
<li>Do you do hallway usability testing?</li>
</ol>
<p>Although Joel’s Test is still an excellent indicator for good software
development and engineering, 20 years have past and many game changing
technologies have emerged like mobile apps, the public cloud and in
general better tooling is available. The success of
<a href="https://git-scm.com/" target="_blank" rel="noopener">git</a> and <a href="https://github.com/" target="_blank" rel="noopener">github</a> changed
how we develop software. In this article i want to extend Joel’s test
with contemporary questions:</p>
<ol start="13">
<li>Do you enforce a common code styleguide?</li>
<li>Do you write tests?</li>
<li>Do you conduct code reviews?</li>
<li>Do your developers write documentation?</li>
<li>Do you focus on code health?</li>
<li>Do you practice continuous integration?</li>
<li>Do you have a mentoring program?</li>
<li>Is your infrastructure reproducible?</li>
<li>Are you doing your best to keep your engineers?</li>
<li>Do you provide the best technology for your developers?</li>
<li>Do you focus on the four key metrics?</li>
<li>Do you empower your developers?</li>
</ol>
<p>The extended test consists of 24 yes-no questions. As with Joel’s
Test, for a <strong>yes</strong> you get one point. The ranking is:</p>
<ul>
<li>&lt;= 20 points, you must improve</li>
<li>21 points, you are ok</li>
<li>22 points, you are a high-performer</li>
<li>23 points, you are a high-performer</li>
<li>24 points, you are best-in-class</li>
</ul>
<p>Further I want to emphasis that <strong>sustainablity</strong> is my main intention
for the test. Many questions contribute directly or indirectly to a
sustainable and healthy codebase which is crucial for a successful
long-term software project and in general for a successful software
company. <a href="https://youtu.be/zW-i9eVGU_k?t=197" target="_blank" rel="noopener">Titus Winters</a> defines a
sustainable codebase as:</p>
<blockquote>
<p>Your organization’s codebase is sustainable when you are able to
change all of the things that you ought to change, safety, and can do
so for the lifetime of your codebase.</p>
</blockquote>
<h4 id="13-do-you-enforce-a-common-code-styleguide"><a href="#13-do-you-enforce-a-common-code-styleguide"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>13. Do you enforce a common code styleguide?</h4>
<p><strong>Consistency</strong> is one of the most important properties of a codebase.
It bolsters readability and maintainability which are essential for
sustainable code. A consistent codebase is easier to grasp and makes
onboarding new developers faster. New programmers are guided by the
prevailing style and can adapt quickly to it. Consistency is also an
indicator for coder’s discipline, clearly you don’t want to have dead
code, unused imports, wrong indentations, and other intricacies in
your codebase. The desired consistency can be achieved by a code
styleguide.</p>
<p>At best you enforce the rules of the styleguide via tooling like
static code analyzers, linters and autoformatting tools. Often these
tools are integrated into the build or are executed before a
commit. Further there are also manually measures like <a href="#codereview">code
reviews</a> to enforce a common code style.</p>
<p>A consistent code style increases productivity, e.g. linters prevent
sloppy programming errors, autoformatters leave no room for useless
(sometimes religious) discussions about indentation and formatting
rules. All code looks the same. Developer’s taste and ego take a back
seat.</p>
<h4 id="14-do-you-write-tests"><a href="#14-do-you-write-tests"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>14. Do you write tests?</h4>
<p>Writing automatic test is a major trait of a sustainable
codebase. There are many kind of tests but the best known
classification comes with the <a href="https://martinfowler.com/articles/practical-test-pyramid.html" target="_blank" rel="noopener">Test
Pyramid</a>.</p>
<ul>
<li>Unit Tests</li>
<li>Service Tests</li>
<li>User Interface Tests</li>
</ul>
<p>Particularly <strong>unit tests</strong> build the foundation and give developers
confidence to move fast and not to break existing functionality. Unit
testing is a major pillar of a fast feedback loop. This keeps
developers happy and the quality high. In general, tests act as a
safety net, prevent new bugs from being introduced and old bugs from
reoccurrence.</p>
<p>Without automatic tests your codebase will erode and only long-term
developers will be capable to make changes. Onboarding new developers
will take months or will never succeed at all. Over time developer
speed will slow down and finally come to a complete halt. Heavily
relying on manual testing before a release is a clear indicator of
missing automatic tests and extends the release cycle by days or
weeks. High performers deploy on a daily basis which is not possible
with manual testing phases. Therefore manual testing should be reduced
to a minimum or completely avoided.</p>
<p>Establishing a good testing culture is especially important. E.g.</p>
<ul>
<li>no code changes without a corresponding test</li>
<li>no bugfix without a test demonstrating the bug is indeed fixed</li>
<li>unit test should be fast, so developers run them continuously</li>
<li>unit test code coverage should be at a reasonable level like ~70%</li>
</ul>
<p>At Google, they practice the <a href="https://www.oreilly.com/library/view/software-engineering-at/9781492082781/" target="_blank" rel="noopener">Beyonce Rule “If you liked it, you
shoulda put a test on
it!"</a>
This rule inverts responsibility, e.g. if someone breaks a feature and
there was no test, the original author of the broken feature “shoulda
put a test on it!”.</p>
<h4 id="codereview"><a href="#codereview"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>15. Do you conduct code reviews?</h4>
<p>Code reviews are a critical step in your software engineering
process. Not only they prevent entering bugs into your mainline but
they are a major tool for knowledge transfer, learning and mentoring.
The code review process fosters a common understanding between
reviewers and author and offers a platform for discussions about
trade-offs and design decisions. Reviews are not only focused on
correctness but also on readability, performance and other
non-functional properties.</p>
<p>All of that will lead to better solutions. Further reviewers practice
their code reading skill which is as important as code
writing. Besides compiling, linting and running tests, code reviews
form a major step in a developers feedback loop. Code should never be
committed into mainline without a proper code review.</p>
<p>Because code reviews can conjure up heated discussions, reviewers
should comply to some <a href="https://google.github.io/eng-practices/review/reviewer/" target="_blank" rel="noopener">code review
guidelines</a>
in order to guarantee a flawless experience.</p>
<h4 id="16-do-developers-write-documentation"><a href="#16-do-developers-write-documentation"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>16. Do developers write documentation?</h4>
<p>Documentation starts with the code. Code comments or a good
description of a pull request are good examples. Thereby good
documentation focuses on <strong>why</strong> something was done. An extensive
<code>README.md</code> acts as the “front-page” of a project and should contain
its purpose and instructions for developers to set up their local
environment for development, e.g installing prerequisites, building
the project, running the tests.</p>
<p>Additionally a variety of documents with different purposes exist:</p>
<ul>
<li>Design Docs (showing alternative solutions, why was one approach
chosen over the others?)</li>
<li>Architecture Diagrams (System overview, showing coherence between
components)</li>
<li>Operational Playbooks for <a href="https://landing.google.com/sre/workbook/chapters/on-call/" target="_blank" rel="noopener">Software Reliability Engineers
(SREs)</a>
(operational instructions for fighting outages)</li>
</ul>
<p>All these documents should be written by developers, operators or
other technical people. Living, up-to-date documentation makes a
project more understandable and long-term project members are capable
of answering questions why things were done in the past – in the
majority of projects, the top answer is “this is historically grown”.
The only way to get real insights is conducting time consuming
face-to-face interviews. Documentation helps to keep an overview over
an ever-growing project, to facilitate the start for new developers
and to build a searchable knowledge base. Past decisions should be
transparent through good documentation and not hidden in people’s
heads.</p>
<h3 id="17-do-you-focus-on-code-health"><a href="#17-do-you-focus-on-code-health"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>17. Do you focus on code health?</h3>
<p>A healthy codebase is a major criteria for developer happiness. If
your developers working on a shitty codebase, they adapt to the poor
quality or leave. The existing codebase act as a <strong>role model</strong>. For
the purpose of high quality code, it is important to continuously
focus on code health. The best coders are repelled by bad code and
attracted by healthy code. But what is a healthy codebase?</p>
<p>A codebase is healthy when:</p>
<ul>
<li>you have fast builds</li>
<li>you have an easy development setup</li>
<li>you have fast and maintainable tests</li>
<li>you have clean, readable, loosely coupled and consistent code</li>
<li>you can easily debug the system</li>
<li>you continuously tackle technical debt</li>
</ul>
<p>You can find a much more exhaustive explanation of code health in
<a href="https://testing.googleblog.com/2016/08/hackable-projects.html" target="_blank" rel="noopener">Google’s Testing Blog about Code
Health</a>.</p>
<p>Signs of bad code are:</p>
<ul>
<li>complicated developer setup</li>
<li>hard to debug, missing monitoring, noisy garbage logs</li>
<li>long build times</li>
<li>inconsistent code (dead code, unused imports, different formatting
styles, no code styleguide)</li>
<li>large merge conflicts due to long running feature branches, broken mainline</li>
<li>no tests, flaky tests, hard-maintainable tests because of mocking overuse</li>
</ul>
<p>Never trade dirty code or workarounds due to time or release pressure
for code health. You will end up very badly in the long run. Worse
yet, you get in a vicious cycle because bad code slows you down and in
order to fulfil the next release you add more dirty workarounds. So
always prioritize code health, even when it looks counterintuitive at
first sight.</p>
<h3 id="18-do-you-practice-continuous-integration"><a href="#18-do-you-practice-continuous-integration"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"></path></svg></a>18. Do you practice continuous integration?</h3>
<p>Nowadays Continuous Integration is hopefully commonplace. At best, you
work with trunk-based development and your mainline is always
releasable, preferably with feature toggles. Highest priority is to
keep the mainline green and a broken build should be fixed
immediately. Small and frequent releases prevent bugs or even outages
which happen when large releases are done only intermittently.</p>
<p>CI helps to prevent tedious merge conflict resolutions because your
developers regularly commit into mainline. Additionally you will get
rid of time consuming integration problems at the end of your
implementation phases.</p>
<p>“Agile”’s main goal is to identify risks as early as possible and not
to postpone them till the end of a project. CI supports exactly</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gerlacdt.github.io/posts/writing-better-software/">https://gerlacdt.github.io/posts/writing-better-software/</a></em></p>]]>
            </description>
            <link>https://gerlacdt.github.io/posts/writing-better-software/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243656</guid>
            <pubDate>Sat, 22 Aug 2020 12:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AngelCAD: Script-based 3D solid modeller]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24243077">thread link</a>) | @app4soft
<br/>
August 22, 2020 | https://arnholm.github.io/angelcad-docs/ | <a href="https://web.archive.org/web/*/https://arnholm.github.io/angelcad-docs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <header>
        
        
        

        <p>AngelCAD - user documentation</p>

        
        <p><a href="https://github.com/arnholm/angelcad-docs">View the Project on GitHub <small>arnholm/angelcad-docs</small></a></p>
        

        

        
      </header>
      <section>

      <p><strong>AngelCAD - script based 3D solid modeller</strong></p>

<p>AngelCAD is a powerful open source 3D solid modeller based on the Constructive Solid Geometry (<a href="https://en.wikipedia.org/wiki/Constructive_solid_geometry">CSG</a>) modelling technique, expressed in the <a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html">AngelScript</a> language. The software creates 3D models in STL or other file formats.</p>



<p>The csg_wikipedia.as sample</p>

<table>
  <thead>
    <tr>
      <th>AngelCAD resources</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="http://www.angelcode.com/angelscript/sdk/docs/manual/doc_script.html" target="_blank">AngelScript language</a></td>
      <td>AngelScript language reference</td>
    </tr>
    <tr>
      <td><a href="https://arnholm.github.io/angelcad-docs/docs/annotated.html" target="_blank">AngelCAD language extension</a></td>
      <td>Language extension for 3d modelling</td>
    </tr>
    <tr>
      <td><a href="https://forum.abmesh.com/" target="_blank">AngelCAD user forum</a></td>
      <td>Discuss AngelCAD topics</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad-samples" target="_blank">angelcad-samples</a></td>
      <td>Examples repository - GitHub</td>
    </tr>
    <tr>
      <td><a href="https://youtu.be/h-qDzG9bwnQ" target="_blank">Video</a></td>
      <td>script based 3D solid modeller</td>
    </tr>
    <tr>
      <td><a href="https://github.com/arnholm/angelcad/releases" target="_blank">Downloads</a></td>
      <td>Prebuilt binaries - Windows and Linux</td>
    </tr>
  </tbody>
</table>

<p>(links above open in new tabs)</p>

<p><strong>AngelCAD IDE and Viewer</strong> - With the desktop IDE you edit/run the scripts and launch the 3d Viewer</p>

<p><img src="https://arnholm.github.io/angelcad-docs/images/angelcad_ide.png" alt="AngelCAD modeller"></p>

<p><strong>Technology</strong> - AngelCAD uses <a href="https://github.com/arnholm/xcsg" target="_blank">xcsg</a> for 3d computations. xcsg is based on the <a href="https://github.com/arnholm/carve" target="_blank">carve library</a> by Tobias Sargeant. Also used is <a href="http://angusj.com/delphi/clipper.php">Clipper</a> by Angus Johnson, qhull by C.B. Barber and libtess2 by Mikko Mononen.</p>

<p>The AngelCAD language interpreter - as_csg - is based on the <a href="http://www.angelcode.com/angelscript/" target="_blank">AngelScript language</a> by Andreas Jönsson, as_csg extends the language with 3d modelling primitives and operations for constructive solid geometry.</p>

<p>The AngelCAD IDE and Viewer applications use the <a href="https://wxwidgets.org/" target="_blank">wxWidgets cross-platform GUI library</a> to create native GUI for Windows and Linux.</p>


      </section>
      
    </div></div>]]>
            </description>
            <link>https://arnholm.github.io/angelcad-docs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24243077</guid>
            <pubDate>Sat, 22 Aug 2020 10:07:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Name Classes After Patterns. Mostly]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24241886">thread link</a>) | @allending
<br/>
August 21, 2020 | https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc | <a href="https://web.archive.org/web/*/https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="100%">
													<tbody>
														<tr>
															<td><!--[if mso]>
				<table align="left" border="0" cellspacing="0" cellpadding="0" width="100%" style="width:100%;">
				<tr>
				<![endif]--><!--[if mso]>
				<td valign="top" width="600" style="width:600px;">
				<![endif]-->
															<div>
																		<p>Good Morning/Afternoon/Evening as the case may be.</p>

																		<p>I've been hoping you are well, and thinking about naming.</p>

																		<p><em>Estimated reading time: 7 minutes, 37 seconds.</em></p>

																		<h2>A Small Digression</h2>

																		<p>You may have heard <a href="https://sender.cloudy.email/postal/click?link=92413&amp;sid=bqweifbdgjegdpzvkdzeh&amp;ck=77-9Ce-_vVHvv71PGmzvv73vv70-be-_vTvvv73UpO-_vVfvv713Bu-_vTrvv70z77-977-9RDDvv70=" target="_blank">Phil Karlton's famous saying</a>:</p>

																		<blockquote>
																		<p>There are only two hard things in Computer Science: cache invalidation and naming things.</p>
																		</blockquote>

																		<p>I first heard this as 'There are only two hard things in Computer Science: cache invalidation, naming things, and off-by-one errors.'</p>

																		<p>I passed this phrase on for many years before realizing that the 'off-by-one errors' bit was a joke.</p>

																		<p>Truth.</p>

																		<p>I am so literal that it pains me. I confess this in case it's paining you too. Puns, for example, fly right over my head, and any that I make are most likely inadvertent. I don't believe that there are any puns in the text that follows—but how would I know?</p>

																		<h2>Thoughts on Using Pattern Names in Class Names</h2>

																		<p>I've always heard that it's best to avoid using pattern names in class names. As one so often does, I've cargo-culted this rule without truly examining it. I habitually obey it myself, and teach it to folks in my OOD classes, but until recently I couldn't have articulated a convincing defense.</p>

																		<p>But then, while writing the 2nd Edition of 99 Bottles of OOP, I broke it. I created a new class whose name included the name of a pattern. I did this because it just felt right.</p>

																		<p>This put me in a pickle.</p>

																		<p>I very much believe in being guided by feelings about code, but when writing a book one can't just say, 'Okay, now do this because I, the author, <em>feel</em> like you should'. Respect for the reader requires investing sincere effort into dragging feelings about code into the light of day, and at least <em>trying</em> to justify them with convincing words.</p>

																		<p>Below I've included the excerpt from the book where I attempt just such convincing. The excerpt explains the purpose of the no-pattern-names-in-class-names rule and defends its utility.</p>

																		<p>I've built a newsletter around this rule not only because I believe that it's useful, but also because my initial attempts to explain it exposed deep holes in my understanding. This was a revelation. Had I not been writing a book, I might have hand-waved around these gaps in my knowledge forever.</p>

																		<h3>Some Context</h3>

																		<p>Before moving on to the excerpt, here's a bit of context to orient you. At this point in the book:</p>

																		<ul>
																			<li>
																			<p>The code contains a <code>CountdownSong</code> class that gets injected with a player of the <code>verse template</code> role.</p>
																			</li>
																			<li>
																			<p><code>BottleVerse</code> is the only class that plays this role. It's used as the default <code>verse template</code> in <code>CountdownSong</code>.</p>
																			</li>
																		</ul>

																		<p>So, <code>CountdownSong</code> has-a <code>verse template</code>, whose concrete implementation is supplied by <code>BottleVerse</code>.</p>

																		<ul>
																			<li>
																			<p>I'm writing tests for <code>CountdownSong</code>, and have just decided to create a new player of the <code>verse template</code> role to inject for use during these tests.</p>
																			</li>
																			<li>
																			<p>I've named this new class <code>VerseFake</code>.</p>
																			</li>
																		</ul>

																		<p>The excerpt below also mentions a <code>BottleNumber</code> class. This class wraps a number to add bottle-ish behavior.</p>

																		<h3>The Excerpt</h3>

																		<p>With that, here's a bit of chapter 9:</p>

																		<blockquote>
																		<p><em>The <code>VerseFake</code> class above is perfect for your needs, though it must be acknowledged that it unrepentantly breaks several common programming rules.</em></p>

																		<p><em>First, Chapter 8 suggested that you put domain behavior on instances. This class violates that rule; its behavior is on the class/static side.</em></p>

																		<p><em>Next, there's an as-yet-unmentioned object-oriented programming rule that prohibits the use of pattern names in class names. The word "Fake" above refers to a testing pattern, so naming this class <code>VerseFake</code> violates that rule.</em></p>

																		<p><em>Fake things first. You're probably familiar with the idea of design patterns, which are named, re-usable solutions to common software problems. Pattern names act as shortcuts to big ideas and allow programmers to communicate with speed and precision. Pattern thinking has so influenced software design that most programmers are familiar with a number of patterns. For example, you've likely heard of Decorator, Adapter, Enumerator, and so on, even if you're a bit fuzzy on the specifics of some of their definitions.</em></p>

																		<p><em>Since pattern names are so meaningful, it can be tempting to stick them in class names. For example, you might use the Decorator pattern to enclose a <code>number</code> in a new class that adds additional responsibility. Initially, <code>NumberDecorator</code> might seem like a good name for the result. The problem with including the name of a pattern in the name of a class is that this permits you the feeling of having created a useful name without actually having done so. Pattern names don't generally reflect concepts in your application. Appending them to class names pollutes your domain with programmer-y words and circumvents the search for names that add semantic meaning. Class names that include patterns are a signal that you've given up too soon on the hard problem of naming.</em></p>

																		<p><em>Class names should reflect concepts in your domain, not the patterns used to create them. Compared to <code>BottleNumber</code>, the much-richer name you gave this class in Chapter 4, <code>NumberDecorator</code> is so abstract as to be meaningless. Future readers won't care that the class was created using Decoration but they'll be grateful to know that it's a bottle-ish kind of number.</em></p>

																		<p><em>The <a href="https://sender.cloudy.email/postal/click?link=92414&amp;sid=bqweifbdgjegdpzvkdzeh&amp;ck=Uu-_ve-_ve-_vUrvv73vv73vv70x77-9aO-_vSbvv73Sm--_vS4LQu-_ve-_ve-_ve-_ve-_vXHvv70yV0A=" target="_blank">xUnit Test Patterns</a> book by <a href="https://sender.cloudy.email/postal/click?link=92415&amp;sid=bqweifbdgjegdpzvkdzeh&amp;ck=77-9BHjvv70p77-9MVzvv73vv70V77-9Ru-_vVHvv73vv71iZF0sZu-_vTdv77-977-977-977-9bA==" target="_blank">Gerard Meszaros</a> standardizes the <a href="https://sender.cloudy.email/postal/click?link=92416&amp;sid=bqweifbdgjegdpzvkdzeh&amp;ck=ae-_vW1377-9dBXvv73vv73vv73vv71WZ1Ei77-93pBlMxwh77-9NO-_ve-_ve-_vUfvv73vv73vv70O" target="_blank">pattern names</a> of a set of objects that are used to simplify testing. <code>TestDouble</code> is his generic name for all of the patterns. Within <code>TestDouble</code> he further delineates the <code>Dummy</code>, <code>Stub</code>, <code>Spy</code>, <code>Mock</code>, <code>Fake</code>, and <code>Temporary Test Stub</code> patterns.</em></p>

																		<p><em>Meszaros defines <code>Fake</code> as a <code>TestDouble</code> that provides a lightweight implementation of a collaborator that is needed by the class you are actually unit testing. A <code>Fake</code> is a regular old object; no testing magic is involved. In this case the new <code>VerseFake</code> class is a real player of the verse template role; it's called a <code>Fake</code> because it's only used during testing. <code>BottleVerse</code> plays the role of verse template in production. <code>VerseFake</code> was created to play this role during <code>Bottles</code>' unit tests.</em></p>

																		<p><em>The upshot is that <code>Fake</code> is the name of a pattern, so <code>VerseFake</code> violates the don't-include-pattern-names-in-class-names rule.</em></p>

																		<p><em>Rules exist to save money, and the two rules that <code>VerseFake</code> breaks are primarily meant to save money in production code; they might not be so applicable in code created to simplify tests. For example, the purpose of <code>VerseFake</code> is to fake the role of verse template. In this case, <code>VerseFake</code> might be the most intention-revealing name possible. If you end up needing a number of different kinds of fakes, you might need additional qualifiers in their names (<code>SimpleVerseFake</code>, <code>ComplicatedVerseFake</code>) but the word "fake" still adds meaning in the domain of your tests.</em></p>

																		<p><em>Similarly, it's important that the shape of production code not interfere with your ability to change it. The put-domain-behavior-on-instances rule serves this goal. In tests, however, you're less concerned with preserving the fake's changeability and more interested in directly communicating its responsibilities. Putting the behavior in a class or static method simplifies the code in <code>VerseFake</code> at the expense of making it less adaptable. This is a trade-off you'll happily make in code used only by the tests.</em></p>
																		</blockquote>

																		<p>I am convinced by that explanation, and I hope you are too. Now that I comprehend it, the no-pattern-names-in-class-names rule seems both simple and inevitable.</p>

																		<p>The deeper point is that I didn't really understand this rule until I had to write an explanation—believe me, my early attempts were neither brief nor convincing. The above is the result of a few days of walking around in my office, muttering, groping for insight.</p>

																		<p>It's not necessarily bad to cargo-cult a rule. Most rules that have risen to the level of cargo-cult-ability are actually pretty reasonable, and even if you don't completely understand their subtleties, following them might improve your code.</p>

																		<p>However, you'll get more value from a rule if you comprehend its underlying purpose. And even better, understanding its true purpose allows you to justify yourself when you decide to break it.</p>

																		<p>Thanks for reading. I very much hope you are safe and well.</p>

																		<p>Best,</p>

																		<p>Sandi</p>

																		<hr>
																		<h2><a href="https://sender.cloudy.email/postal/click?link=92417&amp;sid=bqweifbdgjegdpzvkdzeh&amp;ck=Je-_vWQwIWrvv711MG3vv73vv73vv71F77-977-977-9cmrvv73vv71F77-977-977-9AQ9_77-9CO-_ve-_vQ==" target="_blank">99 Bottles of OOP, 2nd Edition</a> is complete!</h2>

																		<h3>Use coupon code <strong><a href="https://sender.cloudy.email/postal/click?link=92418&amp;sid=bqweifbdgjegdpzvkdzeh&amp;ck=77-9U1kH77-9fkx_UgTvv73ajO-_ve-_ve-_ve-_ve-_ve-_ve-_vQvvv73vv71JSu-_vQpa77-9B--_vQ==" target="_blank">2ND-IS-DONE!</a></strong> through Sept 7</h3>

																		<h3>for a <a href="https://sender.cloudy.email/postal/click?link=92418&amp;sid=bqweifbdgjegdpzvkdzeh&amp;ck=77-9U1kH77-9fkx_UgTvv73ajO-_ve-_ve-_ve-_ve-_ve-_ve-_vQvvv73vv71JSu-_vQpa77-9B--_vQ==" target="_blank">25% discount</a> on the book.</h3>

																		<p>The new edition:</p>

																		<ul>
																			<li>has three new chapters (it's almost 50% longer).</li>
																			<li>comes in separate books for two programming languages (Ruby and JavaScript) and two beverages (beer and milk), with a free PHP upgrade coming this fall.</li>
																			<li>is available as an ebook only, in epub, kepub, kobi, and pdf formats.</li>
																			<li>bundles every book variant. A single purchase gets you all of the books.</li>
																		</ul>

																		<p>I am so <em>glad</em> to be done with this edition that I'm passing that good cheer on to you.</p>

																		<p><strong><em>Note:</em></strong><br>
																		<span><em>Those of you who already own the book should have recently received</em></span><span><em>your own personal upgrade coupon.</em></span></p>

							…</div></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc">https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc</a></em></p>]]>
            </description>
            <link>https://sender.cloudy.email/campaigns/paxjhchaiasjoifsiw/webversion/jdnapfbdgjegdqmdeduwc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241886</guid>
            <pubDate>Sat, 22 Aug 2020 05:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stef's Free Online Smalltalk Books]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24241561">thread link</a>) | @triyambakam
<br/>
August 21, 2020 | http://stephane.ducasse.free.fr/FreeBooks.html | <a href="https://web.archive.org/web/*/http://stephane.ducasse.free.fr/FreeBooks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
	   I started to be fed up to see all the books I like to be out of print, so I started to contact authors and 
	   collect their old books. I would like to thanks them all and their publishers as well. If you
       know an author that is willing to give to the community a book, please give
       him my email. You can support me. </p><p> Thanks in advance. 




</p><p>
You can find a lot more recent and free books at <a href="http://books.pharo.org/">http://books.pharo.org</a>: Spec, Pharo by Example Updated, Pharo with Style, Learning OOD with TDD, and many more. 
In addition most the new books around Pharo are hosted at <a href="http://github.com/SquareBracketAssociates">http://github.com/SquareBracketAssociates</a> and each project has an automatic build with the latest PDF version.


</p><p>
If you have more books and you want to get them archived and listed here please contact me.

</p><div width="95%" height="174">

	<tbody><tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/DynamicWebDevInSeaside/DynWebDevInSeaside.png" width="100"></td>
	    <td>
	      <p><a href="http://book.seaside.st/">[ Dynamic Web Development with Seaside ]</a> Stephane Ducasse, Lukas Renggli, David C. Shaffer and Rick Zaccone. Square Bracket Associates, 2009.</p>
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>
	

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PBE/PharoByExample.png" width="100"></td>
	    <td>
	      <p><a href="http://books.pharo.org/">[ Pharo by Example (original version and translation) ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz, Damien Pollet with Damien Cassou and Marcus Denker. Square Bracket Associates, 2009.</p> Pay attention there is also Pharo by Example Updated (for Pharo 50) and we are working on Pharo by Example for Pharo 80.
	     
	This book is made available under the Creative Commons Attribution-ShareAlike 3.0 license. You will be able to  buy a softcover copy from <a href="http://www.lulu.com/">lulu.com</a>. 
	    </td>
	  </tr>

	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/GNU.png" width="100"></td>
	    <td>
	     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Gnu/computer_programming_using_gnu_smalltalk.pdf">[ Computer Programming using GNU Smalltalk ]</a> Canol Gokel, free e-book. 2009. 
	   <a href="http://www.canol.info/books/computer_programming_using_gnu_smalltalk">home page of the book to have an up to date version</a>.
		</p> 
	    </td>
	  </tr> 


  	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SBE/sbe.png" width="100"></td>
	    <td>
	      <p><a href="https://hal.inria.fr/inria-00441576/document">[ Squeak by Example ]</a> Andrew P. Black, Stéphane Ducasse, Oscar Nierstrasz and Damien Pollet. Square Bracket Associates, 2007.</p> Watch out this book is old. Better read <a href="http://books.pharo.org/">Pharo by Example book</a>.
	    </td>
	  </tr>
	
	<tr>
	    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion/coversm.gif" width="100"></td>
	    <td>
	      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDesignPatternCompanion">[ Smalltalk design pattern companion book drafts ]</a> Sherman Alpert, Kyle Brown, and Bobby Woolf. Addison-Wesley,  978-02011846241998.</p>
		The chapters listed here are not in their final form but more in draft form. Buy the book it is really excellent. 
	    </td>
	  </tr>
	
	
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/byExample.gif" width="100"></td>
    <td> 
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/ByExample/">[ Smalltalk by
      Example: the Developer's Guide ]</a> Alex Sharp, McGraw Hill Text; ISBN:
      0079130364, 1997.</p>
      This book covers all kinds of issues basic level, design, testing... I
      liked it a lot. The code and the book as a single file containing everything are available. Thank again
      Lukas Renggli for his effort for converting everything from Word.
       Thanks a lot Alec and thanks McGraw-Hill <a href="http://books.mcgraw-hill.com/">http://books.mcgraw-hill.com/</a>
  They were really nice with us so think about it if you hesitate to buy
  one of their books. Not all the publishers are that open-minded. 
  </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/WithStyle.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/WithStyle/SmalltalkWithStyle.pdf">[ Smalltalk With Style ]</a> by Edward Klimas, Suzanne Skublics and David A. Thomas. 
		ISBN: 0-13-165549-3, Publisher: Prentice Hall, Copyright: 1996. A great and 
		small book that everybody should read. Thanks Ed, Suzanne and Dave to give it for free. 
		Thanks Don for the OCR!
	   </p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV1.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalk.pdf">[ Inside Smalltalk 
       (Volume One) ]</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1.
       Thanks Don for the OCR! 
	   </p>
    </td>
  </tr>
  
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkV2.png" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/InsideST/InsideSmalltalkII.pdf">[ Inside Smalltalk (Volume Two)],</a>  by LaLonde, Wilf R. and Pugh, John R., Prentice-Hall, 1990, ISBN 0-13-468414-1. Thanks Don for the OCR! </p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/littleST.jpeg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/LittleSmalltalk/ALittleSmalltalk.pdf">[ A Little Smalltalk ] </a> by Tim Budd, Addison-Wesley 1987.  
      <br>Many thanks to Tim Budd and his  publisher. Please have a look at <a href="http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html">http://www.aw.com/catalog/academic/discipline/1,4094,69948,00.html</a>. Thanks Don for the OCR!.
		</p>
    </td>
  </tr>
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Art/Art.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Art/artAdded174186187Final.pdf">[ The Art and Science of Smalltalk ]</a>  by Simon Lewis, Prentice-Hall 1995-1999.  
      <br>Many thanks to the original publishers of this book Prentice-Hall, the responsible of the HP series and Simon Lewis.</p>
    </td>
  </tr>
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/practical.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/PracticalSmalltalk/PracticalSmalltalk.pdf">[ Practical Smalltalk: Using Smalltalk/V ]</a>  by Dan Shafer and Dean A. Ritz, Springer Verlag; (July 1991).  
      <br>Many thanks to the original publishers of this book Springer Verlag,  and Dan. Thanks</p>
    </td>
  </tr>
  
  
<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/HopkinsHoran/HopkinsHoran.pdf">[ Smalltalk An Introduction to Application Development using VisualWorks ]</a> Trevor Hopkins and Bernard Horan,  Pearson Education, 1995. The answers of the exercises are at ftp://st.cs.uiuc.edu/pub/Smalltalk/books/Book_Answers.tar.gz
      <br>Many thanks to the original publishers of this book,  Pearson Education,  for permission to distribute this work, and of course the authors! </p>
    </td>
  </tr>

<tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/st-and-oo.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/STandOO/Smalltalk-and-OO.pdf"> [ Smalltalk and Object Orientation: an Introduction ] </a> Springer-Verlag, ISBN 3-540-76115-2, 1997.
</p>
      <br>This book provides a good survey of Smalltalk. Some information are now obsolete 
      but it is still worth reading. Enjoy it. Thanks John to support our request. We want to thank Springer Verlag Publishing
    for allowing us to give you this book for free.
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkVTutorial/SmalltalkVTutorial.pdf"> [ Smalltalk V Tutorial ]</a>
	   </p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/taste.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Taste/"> [ The Taste of Smalltalk ] </a> Ted Kaehler and Dave Patterson, W W Norton Co.; ISBN: 0393955052; (May 1986).</p>
      This book is for collectors. The quotes are really excellent. 
      <br>All the chapters are ready (except chap.2 for now)
    Enjoy it. (Scanned ... by Stef, Alex, Gabriela, and Lukas).
    Thanks Ted.
    </td>
  </tr>

 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Joy/">[ The Joy Of Smalltalk ]</a> Ivan
    Tomek (September 2000). 700 pages</p>
    Ivan wrote this book and he gave it to the community. It contains a lot of useful material. 
    Thanks again ivan and continue to write good books. 
    </td>
  </tr>
  
  
  
   <!--<tr>
    <td width="45%"><img src="FreeBooks/SmalltalkObjectAndDesign/SmalltalkObjectAndDesign.jpg" width=100></td>
    <td width="55%">
      <p><a href="http://books.iuniverse.com/viewbooks.asp?isbn=1583484906&page=fm1">Smalltalk,objects and design</a>
	  Liu, iUniverse books</p>
      
	  </font>
    </td>
  </tr>-->
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/BitsOfHistory.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BitsOfHistory/"> [ Smalltalk-80, Bits of History, Words of Advice] </a> By Glen Krasner, Editor
ISBN 0-201-11669-3. 344 pp. 1983</p>
      This book is for collectors. Thanks Glenn.
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/blueBook.jpg" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/BlueBook/">[ Smalltalk-80: The Language and its Implementation ]</a>
	By Adele Goldberg and DavidRobson; 		Xerox Palo Alto Research Center
	ISBN 0-201-11371-6. 344 pp. 1983</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/TheInteractiveProgrammingEnv/TheInteractiveProgrammingEnv.pdf">[ Smalltalk-80, The Interactive Programming Environment ]</a> By Adele Goldberg 
ISBN  0201113724. 560 pp. 1983</p> This book is for collectors. Thanks Adele. Thanks Don for the OCR!
    </td>
  </tr>
  
 <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/small-bluebook-cover.jpg" width="100"></td>
    <td>
    <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/CollectiveNBlueBook/">[ DRAFTS of Squeak, Open Personal Computing and Multimedia ]</a> Mirror of <a href="http://coweb.cc.gatech.edu/squeakbook/">http://coweb.cc.gatech.edu/squeakbook/</a> Edited by Mark Guzdial and Kim Rose. Prentice-Hall 2000.  It's available from Prentice-Hall.  </p>
    <br>
    </td>
  </tr>
  
  
   <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/mark1.jpg" width="100"></td>
    <td>
     <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/GuzdialBookDrafts/">[ DRAFS of Squeak: Open Personal Computing for Multimedia ]</a>
	 taken from <a href="http://www.cc.gatech.edu/~mark.guzdial/drafts/">http://www.cc.gatech.edu/~mark.guzdial/drafts/</a> 
	 Mark Guzdial, Prentice-Hall 2000. It's available from Prentice-Hall. </p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/BuchLogo.png" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/Syntax/Syntax.zip">[ (In German) Syntaxbasierte
      Programmierwerkzeuge ]</a> L. Schmitz, B.G. Teubner Stuttgart 1995.  
        1996.</p>
      <p>This book presents compilation techniques in german.
	 Lothar Schmitz is still developing a free visual compiler-compiler
	 (SIC and JACCIE).  <!-- <a
	 href="http://ist.unibw-muenchen.de/Research/Tools/SIC">http://ist.unibw-muenchen.de/Research/Tools/SIC</a> 
<a href="http://ist.unibw-muenchen.de/Research/Tools/JACCIE">http://ist.unibw-muenchen.de/Research/Tools/JACCIE</a> 
-->

</p>
    </td>
  </tr>

  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/emptyCover.gif" width="100"></td>
    <td>
      <p> <a href="http://sdmeta.gforge.inria.fr/FreeBooks/SmalltalkDE/smalltalkBuch.pdf">[ (In German) Smalltalk
      Einfuehrung in die objekt-orientierte Programmierung ]</a> Peter P. Bothner, Wolf-Michael Kaehler 1999.  
        1996.</p>
      <p>This book presents object-oriented programming in german with VisualWorks.  
<!-- <a href="http://e-books.zfn.uni-bremen.de/e-book-SMALLTALK.html</a>  
-->

</p>
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/emptyCover.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Swedish/">[  (In Swedish) Objektorienterad programmering i Smalltalk ]</a>
	  Bjoern Eiderbaeck, Per Haegglund, and Olle Baelter</p>
      <br>Thanks Bjoern Eiderbaeck.
	  
    </td>
  </tr>
  
  <tr>
    <td><img src="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/Programando.gif" width="100"></td>
    <td>
      <p><a href="http://sdmeta.gforge.inria.fr/FreeBooks/Programando/ProgramandoConSmalltalk-BORRADORFINAL07-Febrero-2006.pdf">[ (In Spanish) Programando con Smalltalk ]</a>
	  Diego Gomez Deck</p>
      <br>Thanks Diego. This book is distributed under the Creative Commons license.
	  
    </td>
  </tr>
  
</tbody></div><p>
 I added some other material because they illustrate the philosophy behind Smalltalk.

 </p></div>]]>
            </description>
            <link>http://stephane.ducasse.free.fr/FreeBooks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241561</guid>
            <pubDate>Sat, 22 Aug 2020 04:33:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Debian Janitor: 60k Lintian Issues Automatically Fixed]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24241549">thread link</a>) | @zdw
<br/>
August 21, 2020 | https://www.jelmer.uk/janitor-update-3.html | <a href="https://web.archive.org/web/*/https://www.jelmer.uk/janitor-update-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
    <div>
        <div>
            <section>
                
            </section>
            <p>The <a href="https://jelmer.uk/debian-janitor.html">Debian Janitor</a> is an automated
system that commits fixes for (minor) issues in Debian packages that can be
fixed by software. It gradually started proposing merges in early
December. The first set of changes sent out ran <a href="https://salsa.debian.org/jelmer/lintian-brush">lintian-brush</a> on sid packages maintained in
Git. This post is part of <a href="https://jelmer.uk/tag/janitor-update.html">a series</a> about the progress of the
Janitor.</p>
<div id="scheduling-lintian-fixes">
<h2>Scheduling Lintian Fixes</h2>
<p>To determine which packages to process, the  <a href="https://janitor.debian.net/">Janitor</a>  looks at the import of  <a href="https://lintian.debian.org/">lintian</a>  output across the archive that is available
in  <a href="https://wiki.debian.org/UltimateDebianDatabase/">UDD</a> <a href="#f1" id="id1">[1]</a>. It
will prioritize those packages with the most and more severe issues that it has
fixers for.</p>
<p>Once a package is selected, it will clone the packaging repository and run
<a href="https://manpages.debian.org/testing/lintian-brush/lintian-brush.1.en.html">lintian-brush</a>
on it.  Lintian-brush provides a framework for applying a set of “fixers” to a
package. It will run each of a set of “fixers” in a pristine version of the
repository, and handles most of the heavy lifting.</p>
</div>
<div id="the-inner-workings-of-a-fixer">
<h2>The Inner Workings of a Fixer</h2>
<p>Each fixer is just an executable which gets run in a clean
checkout of the package, and can make changes there. Most
of the fixers are written in Python or shell, but they
can be in any language.</p>
<p>The contract for fixers is pretty simple:</p>
<ul>
<li>If the fixer exits with non-zero, the changes are reverted and fixer is
considered to have failed</li>
<li>If exits with zero and made changes, then it should write a summary of its
changes to standard out</li>
</ul>
<p>If a fixer is uncertain about the changes it has made, it should report so on
standard output using a pseudo-header.  By default, lintian-brush will discard
any changes with uncertainty but if you are running it locally you can still
apply them by specifying <tt><span>--uncertain</span></tt>.</p>
<p>The summary message on standard out will be used for the commit message and
(possibly) the changelog message, if the package doesn’t use gbp dch.</p>
</div>
<div id="example-fixer">
<h2>Example Fixer</h2>
<p>Let’s look at an example. The package priority “extra” is deprecated since
Debian Policy 4.0.1 (released August 2 017) – see
<a href="https://www.debian.org/doc/debian-policy/ch-archive.html#priorities">Policy 2.5 "Priorities"</a>.
Instead, most packages should use the “optional” priority.</p>
<p>Lintian will warn when a package uses the deprecated “extra” value for the
“Priority”  - the associated tag is
<a href="https://lintian.debian.org/tags/priority-extra-is-replaced-by-priority-optional.html">priority-extra-is-replaced-by-priority-optional</a>.
Lintian-brush has a fixer script that can automatically replace “extra” with
“optional”.</p>
<p>On systems that have lintian-brush installed, the source for the fixer lives in
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/blob/master/fixers/priority-extra-is-replaced-by-priority-optional.py">/usr/share/lintian-brush/fixers/priority-extra-is-replaced-by-priority-optional.py</a>,
but here is a copy of it for reference:</p>
<table><tbody><tr><td><div><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13</pre></div></td><td><div><pre><span></span><span>#!/usr/bin/python3</span>

<span>from</span> <span>debmutate.control</span> <span>import</span> <span>ControlEditor</span>
<span>from</span> <span>lintian_brush.fixer</span> <span>import</span> <span>report_result</span><span>,</span> <span>fixed_lintian_tag</span>

<span>with</span> <span>ControlEditor</span><span>()</span> <span>as</span> <span>updater</span><span>:</span>
    <span>for</span> <span>para</span> <span>in</span> <span>updater</span><span>.</span><span>paragraphs</span><span>:</span>
        <span>if</span> <span>para</span><span>.</span><span>get</span><span>(</span><span>"Priority"</span><span>)</span> <span>==</span> <span>"extra"</span><span>:</span>
            <span>para</span><span>[</span><span>"Priority"</span><span>]</span> <span>=</span> <span>"optional"</span>
            <span>fixed_lintian_tag</span><span>(</span>
                <span>para</span><span>,</span> <span>'priority-extra-is-replaced-by-priority-optional'</span><span>)</span>

<span>report_result</span><span>(</span><span>"Change priority extra to priority optional."</span><span>)</span>
</pre></div>
</td></tr></tbody></table><p>This fixer is written in Python and uses the  <a href="https://salsa.debian.org/jelmer/debmutate">debmutate</a>  library to easily modify
control files while preserving formatting — or back out if it is not possible
to preserve formatting.</p>
<p>All the current fixers come with tests, e.g. for this particular fixer the
tests can be found here:
<a href="https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional">https://salsa.debian.org/jelmer/lintian-brush/-/tree/master/tests/priority-extra-is-replaced-by-priority-optional</a>.</p>
<p>For more details on writing new fixers, see the  <a href="https://salsa.debian.org/jelmer/lintian-brush#writing-new-fixers">README</a>  for
lintian-brush.</p>
<p>For more details on debugging them, see the  <a href="https://manpages.debian.org/unstable/lintian-brush/lintian-brush.1.en.html">manual page</a>.</p>
</div>


            

            

            
            <p><a href="#">Go Top</a></p>        </div>
    </div>
</div></div>]]>
            </description>
            <link>https://www.jelmer.uk/janitor-update-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241549</guid>
            <pubDate>Sat, 22 Aug 2020 04:30:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How NAT Traversal Works]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24241105">thread link</a>) | @signa11
<br/>
August 21, 2020 | https://tailscale.com/blog/how-nat-traversal-works/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/how-nat-traversal-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>We covered a lot of ground in our post about <a href="https://tailscale.com/blog/how-tailscale-works/"><em>How Tailscale
Works</em></a>.  However, we glossed over how we can get through NATs
(Network Address Translators) and connect your devices directly to
each other, no matter what’s standing between them. Let’s talk about
that now!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-intro.png">
    
    
</figure>

<p>Let’s start with a simple problem: establishing a peer-to-peer
connection between two machines. In Tailscale’s case, we want to set
up a WireGuard® tunnel, but that doesn’t really matter. The
techniques we use are widely applicable and the work of many people
over decades. For example, <a href="https://webrtc.org/">WebRTC</a> uses this bag of tricks to
send peer-to-peer audio, video and data between web browsers. VoIP
phones and some video games use similar techniques, though not always
successfully.</p>
<p>We’ll be discussing these techniques generically, using Tailscale and
others for examples where appropriate. Let’s say you’re making your
own protocol and that you want NAT traversal. You need two things.</p>
<p>First, the protocol should be based on UDP. You <em>can</em> do NAT traversal
with TCP, but it adds another layer of complexity to an already quite
complex problem, and may even require kernel customizations depending
on how deep you want to go. We’re going to focus on UDP for the rest
of this article.</p>
<p>If you’re reaching for TCP because you want a stream-oriented
connection when the NAT traversal is done, consider using QUIC
instead. It builds on top of UDP, so we can focus on UDP for NAT
traversal and still have a nice stream protocol at the end.</p>
<p>Second, you need direct control over the network socket that’s sending
and receiving network packets. As a rule, you can’t take an existing
network library and make it traverse NATs, because you have to send
and receive extra packets that aren’t part of the “main” protocol
you’re trying to speak. Some protocols tightly integrate the NAT
traversal with the rest (e.g. WebRTC). But if you’re building your
own, it’s helpful to think of NAT traversal as a separate entity that
shares a socket with your main protocol. Both run in parallel, one
enabling the other.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-deep-integration.png">
    
    
</figure>

<p>Direct socket access may be tough depending on your situation. One
workaround is to run a local proxy. Your protocol speaks to this
proxy, and the proxy does both NAT traversal and relaying of your
packets to the peer. This layer of indirection lets you benefit from
NAT traversal without altering your original program.</p>
<p>With prerequisites out of the way, let’s go through NAT traversal from
first principles. Our goal is to get UDP packets flowing
bidirectionally between two devices, so that our other protocol
(WireGuard, QUIC, WebRTC, …) can do something cool. There are two
obstacles to having this Just Work: stateful firewalls and NAT
devices.</p>
<h3 id="figuring-out-firewalls">Figuring out firewalls</h3>
<p>Stateful firewalls are the simpler of our two problems. In fact, most
NAT devices include a stateful firewall, so we need to solve this
subset before we can tackle NATs.</p>
<p>There are many incarnations to consider. Some you might recognize are
the Windows Defender firewall, Ubuntu’s ufw (using iptables/nftables),
BSD’s pf (also used by macOS) and AWS’s Security Groups. They’re all
very configurable, but the most common configuration allows all
“outbound” connections and blocks all “inbound” connections. There
might be a few handpicked exceptions, such as allowing inbound SSH.</p>
<p>But connections and “direction” are a figment of the protocol
designer’s imagination. On the wire, every connection ends up being
bidirectional; it’s all individual packets flying back and forth. How
does the firewall know what’s inbound and what’s outbound?</p>
<p>That’s where the stateful part comes in. Stateful firewalls remember
what packets they’ve seen in the past and can use that knowledge when
deciding what to do with new packets that show up.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-1a.png">
    
    
</figure>

<p>For UDP, the rule is very simple: the firewall allows an inbound UDP
packet if it previously saw a matching outbound packet. For example,
if our laptop firewall sees a UDP packet leaving the laptop from
<code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, it’ll make a note that incoming
packets from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code> are also fine. The
trusted side of the world clearly intended to communicate with
<code>7.7.7.7:5678</code>, so we should let them talk back.</p>
<p>(As an aside, some <em>very</em> relaxed firewalls might allow traffic from
anywhere back to <code>2.2.2.2:1234</code> once <code>2.2.2.2:1234</code> has communicated
with anyone. Such firewalls make our traversal job easier, but are
increasingly rare.)</p>
<h4 id="firewall-face-off">Firewall face-off</h4>
<p>This rule for UDP traffic is only a minor problem for us, as long as
all the firewalls on the path are “facing” the same way. That’s
usually the case when you’re communicating with a server on the
internet. Our only constraint is that the machine that’s <em>behind</em> the
firewall(s) must be the one initiating all connections. Nothing can
talk to it, unless it talks first.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-2.png">
    
    
</figure>

<p>This is fine, but not very interesting: we’ve reinvented client/server
communication, where the server makes itself easily reachable to
clients. In the VPN world, this leads to a hub-and-spoke topology: the
hub has no firewalls blocking access to it and the firewalled spokes
connect to the hub.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-3.png">
    
    
</figure>

<p>The problems start when two of our “clients” want to talk
directly. Now the firewalls are facing each other. According to the
rule we established above, this means both sides must go first, but
also that neither can go first, because the other side has to go
first!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-4.png">
    
    
</figure>

<p>How do we get around this? One way would be to require users to
reconfigure one or both of the firewalls to “open a port” and allow
the other machine’s traffic. This is not very user friendly. It also
doesn’t scale to mesh networks like Tailscale, in which we expect the
peers to be moving around the internet with some regularity. And, of
course, in many cases you don’t have control over the firewalls: you
can’t reconfigure the router in your favorite coffee shop, or at the
airport. (At least, hopefully not!)</p>
<p>We need another option. One that doesn’t involve reconfiguring
firewalls.</p>
<h4 id="finessing-finicky-firewalls">Finessing finicky firewalls</h4>
<p>The trick is to carefully read the rule we established for our
stateful firewalls. For UDP, the rule is: <strong>packets must flow out
before packets can flow back in.</strong></p>
<p>However, nothing says the packets must be <em>related</em> to each other
beyond the IPs and ports lining up correctly. As long as <em>some</em> packet
flowed outwards with the right source and destination, any packet that
<em>looks like</em> a response will be allowed back in, even if the other
side never received your packet!</p>
<p>So, to traverse these multiple stateful firewalls, we need to share
some information to get underway: the peers have to know in advance
the <code>ip:port</code> their counterpart is using. One approach is to
statically configure each peer by hand, but this approach doesn’t
scale very far. To move beyond that, we built a <a href="https://tailscale.com/blog/how-tailscale-works/#the-control-plane-key-exchange-and-coordination">coordination
server</a> to keep the <code>ip:port</code> information synchronized in a
flexible, secure manner.</p>
<p>Then, the peers start sending UDP packets to each other. They must
expect some of these packets to get lost, so they can’t carry any
precious information unless you’re prepared to retransmit them. This
is generally true of UDP, but especially true here. We’re <em>going</em> to
lose some packets in this process.</p>
<p>Our laptop and workstation are now listening on fixed ports, so that
they both know exactly what <code>ip:port</code> to talk to. Let’s take a look at
what happens.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5a.png">
    
    
</figure>

<p>The laptop’s first packet, from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, goes
through the Windows Defender firewall and out to the internet. The
corporate firewall on the other end blocks the packet, since it has no
record of <code>7.7.7.7:5678</code> ever talking to <code>2.2.2.2:1234</code>. However,
Windows Defender now remembers that it should expect and allow
responses from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code>.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5b.png">
    
    
</figure>

<p>Next, the workstation’s first packet from <code>7.7.7.7:5678</code> to
<code>2.2.2.2:1234</code> goes through the corporate firewall and across the
internet. When it arrives at the laptop, Windows Defender thinks “ah,
a response to that outbound request I saw”, and lets the packet
through! Additionally, the corporate firewall now remembers that it
should expect responses from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, and
that those packets are also okay.</p>
<p>Encouraged by the receipt of a packet from the workstation, the laptop
sends another packet back. It goes through the Windows Defender
firewall, through the corporate firewall (because it’s a “response” to
a previously sent packet), and arrives at the workstation.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5c.png">
    
    
</figure>

<p>Success! We’ve established two-way communication through a pair of
firewalls that, at first glance, would have prevented it.</p>
<h4 id="creative-connectivity-caveats">Creative connectivity caveats</h4>
<p>It’s not always so easy. We’re relying on some indirect influence over
third-party systems, which requires careful handling. What do we need
to keep in mind when managing firewall-traversing connections?</p>
<p>Both endpoints must attempt communication at roughly the same time, so
that all the intermediate firewalls open up while both peers are still
around. One approach is to have the peers retry continuously, but this
is wasteful. Wouldn’t it be better if both peers knew to start
establishing a connection at the same time?</p>
<p>This may sound a little recursive: to communicate, first you need to
be able to communicate. However, this preexisting “side channel”
doesn’t need to be very fancy: it can have a few seconds of latency,
and only needs to deliver a few thousand bytes in total, so a tiny VM
can easily be a matchmaker for thousands of machines.</p>
<p>In the distant past, I used XMPP chat messages as the side channel,
with great results. As another example, WebRTC requires you to come up
with your own “signalling channel” (a name that reveals WebRTC’s IP
telephony ancestry), and plug it into the WebRTC APIs. In Tailscale,
our coordination server and fleet of DERP (Detour Encrypted Routing
Protocol) servers act as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/how-nat-traversal-works/">https://tailscale.com/blog/how-nat-traversal-works/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24241105</guid>
            <pubDate>Sat, 22 Aug 2020 02:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Gentle Introduction to Zero-Knowledge Proofs with Hands-On Examples]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24240915">thread link</a>) | @mariorz
<br/>
August 21, 2020 | https://dochdoch.gitlab.io/snark_intro/snark_intro_front/ | <a href="https://web.archive.org/web/*/https://dochdoch.gitlab.io/snark_intro/snark_intro_front/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dochdoch.gitlab.io/snark_intro/snark_intro_front/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240915</guid>
            <pubDate>Sat, 22 Aug 2020 01:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bread, How Did They Make It? Part IV: Markets, Merchants and the Tax Man]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24240677">thread link</a>) | @Kednicma
<br/>
August 21, 2020 | https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>As the fourth and final part (<a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">I</a>, <a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/">II</a>, <a href="https://acoup.blog/2020/08/06/collections-bread-how-did-they-make-it-part-iii-actually-farming/">III</a>) of our look at the basic structure of food production in the pre-modern world (particularly farming grain to make bread), this week we’re going to look at how at least some of the delicious food we made in the last post might make its way into the hands of people who are <em>not</em> <a href="https://acoup.blog/2020/07/24/collections-bread-how-did-they-make-it-part-i-farmers/">farmers </a>or even<a href="https://acoup.blog/2020/07/31/collections-bread-how-did-they-make-it-part-ii-big-farms/"> farm owners</a>.</p>



<p>In the previous three posts, I have mostly just used the magic word ‘markets’ to describe how the food produced in the countryside gets to the cities and people who are not farmers.  As we’ll see in this post, that is a bit of an oversimplifying fib, both in that the phrase ‘markets’ covers a <em>lot </em>of complexity, but also (as we’ll see) some of the major drivers of moving that food from the countryside into towns doesn’t involve money <em>or</em> market interactions.  That said, we’re going to <em>start</em> with market transactions, because while they are actually the minority-type in many of these societies, they are more readily familiar and understandable, I suspect, to modern readers.  Then we’ll move to <em>extraction</em> as the other category.</p>



<p>Speaking of extraction, as always, if you like what you are reading here, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreo</a>n. And if you want updates whenever a new post appears, you can click the button below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts, as well as my occasional ancient history, foreign policy or pop-culture thoughts.</p>






<h2>Point of Sale</h2>



<p>I want to start by leaning on (with small modifications for clarity) Paul Erdkamp’s taxonomy of the various options by which food might get into the stream of commerce.  A small farmer might sell their grain (I) directly to city-dwellers, (II) indirectly, via urban middlemen and grain merchants, either in the market or (III) ‘at the gate’ (meaning selling to merchants who come out to the farm in order to buy; the difference being who transports the food to the city), (IV) to itinerant traders at periodic rural markets or (V) to other local small farmers.  As we’ll see, <em>large </em>landholders have a <em>somewhat</em> larger range of options within this taxonomy, but the fundamentals are the same.</p>



<p>While all of these sale methods certainly happened, in every society I have looked at, Option I – selling directly to city-dwellers – is fairly rare for grains and other bulk agricultural goods.  Market <em>gardeners</em>, selling fruits, vegetables (and sometimes flowers) often do sell this way, maintaining a high-intensity garden near town and a shop or stall in the town market.  Likewise, while Option V – small-scale trade between farmers – absolutely happens, it is typically non-monetary: the banqueting of neighbors discussed in the first post.  Where it is monetary, it is typically quite small scale and very short distance.  By and large, small and mid-sized farmers hadn’t the time, expertise or infrastructure to sell their goods directly.  They needed to be farming, not manning a market stall or trying to figure out how to store their goods close to the point of sale.  And of course large landowners, being rich, aren’t going to stand in the market square either (and in many cases don’t want their obvious representative doing so either,  see below).  So while I and V happen, they’re not too common or too large a portion of total trade and we may lay them aside for this discussion.</p>



<p>That leaves Options II, III and IV, all of which involve selling grain to a middle-man merchant of some sort.  The main difference is the location of sale (in town, at the gate, or at periodic rural markets).  Outside of large cities and major ports, markets were likely to be <em>periodic</em>, occurring only on certain days (typically around once per week).  In Roman Italy, these were the <em>nundinae</em> (‘ninth days,’ although it was an 8-day cycle as the Romans count inclusively); the <em>nundinae</em> were minor festivals, days of rest and merrymaking, but they were also the days when the rural markets would be open – the rest-day from agricultural labor enabled farmers to head into local towns to buy or sell whatever they needed (interestingly, at Rome, the <em>nundinae</em> were <em>dies nefasti</em> – state business couldn’t generally be conducted on them – so poor farmers hoping to use their day off to participate politically were out of luck).  Similar periodic markets are common in the Middle Ages (and even today; most ‘farmer’s markets’ in the United States are periodic, <a href="http://www.carrborofarmersmarket.com/">including my town’s</a>).  The periodic nature of these markets is an adaptation to agricultural rhythms; for a market to function there need to be a lot of people together all at once and the small towns that dotted the countryside simply didn’t have the density to do that all of the time.</p>



<figure><img data-attachment-id="4249" data-permalink="https://acoup.blog/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg" data-orig-size="2325,663" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/fresco_from_the_house_of_julia_felix_pompeii_depicting_scenes_from_the_forum_market.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:Fresco_from_the_House_of_Julia_Felix,_Pompeii_depicting_scenes_from_the_Forum_market.JPG">Via Wikipedia</a>, a fresco showing market activity, with merchants showing off wares of fabric (left) and goods in pots (center) from the House of Julia Felix at Pompeii, first century CE.  Please note: the importance of pottery in modern archaeology has given many students and the general public the idea that the ancients were always shipping pots around for sale, as if there was a vast market in pottery.  <strong>Generally, people were buying what was in the pot, not the pot itself</strong>.</figcaption></figure>



<p>But as noted, our farmers are unlikely to be selling their grain directly to customers.  Instead, they are likely to be using some sort of middle-man merchant, which brings us to:</p>



<h2>Merchants!</h2>



<p>Merchants are a bit of a break from the people we have so far discussed in that they, by definition, live in the realm of the <em>market</em> (in the economic sense, although often also in a physical sense).  As we’ve seen so much of the world of our farmers and even our millers and bakers was governed by <em>non-market</em> interactions: horizontal and vertical social ties that carried expectations that weren’t quite transactional and certainly not monetized.  By contrast, merchants work with transactions and tend to be the <em>first</em> group in any society to attempt to monetize their operations once money becomes available.  I find students are often quick to feel identity with the merchant class, because these folks are more likely to travel, more likely to use money, more likely to employ or be employed in wage-labor; they feel more like modern people.</p>



<p>It thus tends to come as something of a surprise that with <em>stunning</em> consistency, <strong>the merchant class tended to be at best cordially disliked and at worst <em>despised</em> by the broader community</strong> (although not typically to the point of suffering legal disability, as did some other jobs; see S. Bond, <em>Trade and Taboo: Disreputable Professions in the Roman Mediterranean</em> (2016) for this in Rome).  This often strikes students as strange, both because we tend to think rather better of our own modern merchants but also because the image they have of the merchant class certainly looks elite.</p>



<figure><img data-attachment-id="4257" data-permalink="https://acoup.blog/britlibaddms35166apocalypseunkfolio3sealblackhorse/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg" data-orig-size="1134,766" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="britlibaddms35166apocalypseunkfolio3sealblackhorse" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2020/08/britlibaddms35166apocalypseunkfolio3sealblackhorse.jpg 1134w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Merchant#/media/File:BritLibAddMS35166ApocalypseUnkFolio3SealBlackHorse.jpg">Via Wikipedia</a>, a manuscript illustration showing the Horseman of Famine depicted as a grain merchant (from Revalations 6:5-6), holding the scales he would use to measure out grain.</figcaption></figure>



<p>For the farmers who need to sell their crops (for reasons we will get to in a moment) and purchase the things they need that they cannot produce, the merchant feels like an adversary: always pushing his prices to his best advantage.  We expect this, but remember that our pre-modern farmers are just <em>not that exposed to market interactions</em>; most of their relationships are reciprocal, not transactional – the horizontal relationships we discussed before.  The merchant’s ‘money-grubbing’ feels like a betrayal of trust in a society where you banquet your neighbors in the good years so they’ll help you in the bad years.  <strong>The necessary function of a merchant is to transgress the ‘rules’ of village interactions which – and this <em>resounds</em> from the sources – the farmers tend to understand as being ‘cheated.’</strong></p>



<p>At the same time, <strong>while most merchant types are humble, the high-risk and potentially high-reward involved in trade meant that <em>some</em> merchants </strong>(again, a small number) <strong>could become <em>very</em> rich</strong>.  That, as you might imagine, <strong>did not go over well for the traditionally wealthy in these societies</strong>, the large landholders.  Again, the values here often strike modern readers as topsy-turvy compared to our own, but to the elite large landholders (who dominate the literary and political culture of their societies), the <em>morally correct</em> way to earn great wealth is to inherit it (or capture it in war).  The <em>morally correct</em> way to hold that wealth is with large landed estates.  Anything else is <em>morally</em> suspect, and so the idea that a successful merchant could – by a process that again, strikes the large landholder, just like the small farmer, as ‘cheating’ – leap-frog the social pyramid and skip to the top, without putting in the work at either having distinguished wealthy ancestors <em>or</em> tremendous military success was an open insult to elite values.  Often laws were put in place to limit the ability of wealthy non-aristocrats (likely merchants or successful artisans) from displaying their wealth (<a href="https://en.wikipedia.org/wiki/Sumptuary_law">sumptuary laws</a>) so as to keep them from competing with the aristocrats; at Rome, senators were forbidden from owning ships with much the same logic (Roman senators being clever, they still invested in trade through proxies while at the same time disapproving of the activity in public politics).</p>



<p>Such disdain appears, with varying justification, in the sources of every pre-modern agrarian society I’ve studied, to one degree or another.  One commonplace of Greek and Roman thinking – despite these being very active, maritime societies – was that the first production of ships and the first sailing was in some essential way a profanation of the divine realm of the sea, a space humans ought not have ever ventured into – and certainly not for anything as mean as profit (e.g. Euripides, <em>Medea</em> 1-6; Catullus. 64.1-20; Valerius Flaccus, <em>Argonautica</em> 627-632; Seneca, <em>Medea</em> 1-12; 301-379, <em>inter alia</em> – thanks to my old grad school pals <a href="https://www.usf.edu/arts-sciences/departments/world-languages/about-us/hedrick.aspx">Buddy Hedrick</a> and <a href="http://gdrsd.org/gdrhs/faculty/michael-hoffman/">Michael Hoffman </a>for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240677</guid>
            <pubDate>Sat, 22 Aug 2020 01:04:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Having Fun with Microsoft's IoC Container for .NET Core]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24240187">thread link</a>) | @sahan
<br/>
August 21, 2020 | https://sahansera.dev/dotnet-core-ioc-container/ | <a href="https://web.archive.org/web/*/https://sahansera.dev/dotnet-core-ioc-container/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The objective of this post is to configure and use Microsoft’s default dependency injection container from scratch to understand how it all hangs together when in action. There are many other great articles explaining Dependency Injection and Inversion of Control (DI &amp; IoC from now on) in ASP.NET Core out there. This article assumes that you understand those principles. So I will not be covering those.</p>
<p>We will start with a simple console application, configure an IoC container, and have some fun with it by diving into the .NET Core DI Extensions’ source code.</p>
<blockquote>
<p>💡 Follow along with the code from my <a href="https://github.com/sahan91/dotnet-ioc-example">repository</a></p>
</blockquote>
<h3>Microsoft’s IoC Container in .NET Core</h3>
<p>The .NET Core IoC container is located in <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection?view=dotnet-plat-ext-3.1">Microsoft.Extensions.DependencyInjection</a> namespace.  Let’s look at what are the steps involved in order to use this in our application.</p>
<ol>
<li>We need to add this assembly via NuGet.</li>
<li>Types must be registered with <code>ServiceCollection</code></li>
<li>Types are retrieved from <code>ServiceProvider</code></li>
</ol>
<p>We will start off with a simple console application and see how we can achieve the above steps.</p>
<h3>Setup</h3>
<p>Let’s start by creating a console application.</p>
<div data-language="bash"><pre><code>dotnet new console -n IoCTutorial
dotnet new sln
dotnet sln <span>add</span> IoCTutorial</code></pre></div>
<p>Open it up in your favourite IDE and you are ready to follow along. I won’t be using any other dependency (such as logging) just to keep this tutorial simple.</p>
<p>Let’s go ahead and add the DI assembly from NuGet.</p>
<div data-language="bash"><pre><code>dotnet <span>add</span> package Microsoft.Extensions.DependencyInjection</code></pre></div>
<p>Your project structure should now look like this.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-ioc-container-2.png" title="dotnet-core-ioc-container-2.png" src="https://sahansera.dev/static/bd5adfb1aaa6a58e14d9a6d45525a500/5a190/dotnet-core-ioc-container-2.png" srcset="https://sahansera.dev/static/bd5adfb1aaa6a58e14d9a6d45525a500/772e8/dotnet-core-ioc-container-2.png 200w,
https://sahansera.dev/static/bd5adfb1aaa6a58e14d9a6d45525a500/e17e5/dotnet-core-ioc-container-2.png 400w,
https://sahansera.dev/static/bd5adfb1aaa6a58e14d9a6d45525a500/5a190/dotnet-core-ioc-container-2.png 800w,
https://sahansera.dev/static/bd5adfb1aaa6a58e14d9a6d45525a500/84cc5/dotnet-core-ioc-container-2.png 898w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>Let’s add two classes into our project; <a href="https://github.com/sahan91/dotnet-ioc-example/blob/master/IoCTutorial/MyService.cs">MyService</a> and <a href="https://github.com/sahan91/dotnet-ioc-example/blob/master/IoCTutorial/MyDependency.cs">MyDependency</a>. Here’s what’s gonna go into those two classes.</p>
<p> <code>MyService.cs</code></p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>MyService</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>MyDependency</span> _myDependency<span>;</span>
    <span>public</span> <span>MyService</span><span>(</span><span>MyDependency</span> myDependency<span>)</span>
    <span>{</span>
        Console<span>.</span><span>WriteLine</span><span>(</span><span>"Constructed MyService"</span><span>)</span><span>;</span>
        _myDependency <span>=</span> myDependency<span>;</span>
    <span>}</span>
    
    <span>public</span> <span><span>void</span></span> <span>DoSomething</span><span>(</span><span>)</span>
    <span>{</span>
        _myDependency<span>.</span><span>DoWork</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p><code>MyDependency.cs</code></p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>MyDependency</span>
<span>{</span>
    <span>public</span> <span>MyDependency</span><span>(</span><span>)</span>
    <span>{</span>
        Console<span>.</span><span>WriteLine</span><span>(</span><span>"Constructed MyDependency"</span><span>)</span><span>;</span>
    <span>}</span>
    
    <span>public</span> <span><span>void</span></span> <span>DoWork</span><span>(</span><span>)</span>
    <span>{</span>
        Console<span>.</span><span>WriteLine</span><span>(</span><span>"Doing some work in MyDependency"</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>As we can see, <code>MyService</code> has an (aptly named 😅 ) dependency on <code>MyDependency</code>. In order to invoke our service, we need to pass an instance of the required dependency into its constructor. In our driver code (Program.cs) without any IoC stuff, we could do something like this.</p>
<div data-language="csharp"><pre><code><span><span>var</span></span> myService <span>=</span> <span>new</span> <span>MyService</span><span>(</span><span>new</span> <span>MyDependency</span><span>(</span><span>)</span><span>)</span><span>;</span>
myService<span>.</span><span>DoSomething</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>This is baaaaad 💀. Problem with this is, now we are responsible for managing the dependencies, their lifetimes (and also violates SOLID principles) etc. Let’s fix this by using the IoC container. We will simply give them a scoped lifetime.</p>
<div data-language="csharp"><pre><code>
<span><span>var</span></span> container <span>=</span> <span>new</span> <span>ServiceCollection</span><span>(</span><span>)</span><span>;</span>
container<span>.</span><span><span>AddScoped</span><span><span>&lt;</span>MyDependency<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
container<span>.</span><span><span>AddScoped</span><span><span>&lt;</span>MyService<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>


<span><span>var</span></span> provider <span>=</span> container<span>.</span><span>BuildServiceProvider</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>If you aren’t familiar with service lifetimes, it’s best if you refer to the <a href="https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection?view=aspnetcore-3.1#service-lifetimes">official documentation</a> before continuing on.</p>
<blockquote>
<p>💡 Note that you don’t have to instantiate ServiceCollection in an ASP.NET Core Web or Worker Service application. You would ideally register your services using the IServiceCollection in the Startup class.</p>
</blockquote>
<h3>The quick &amp; dirty service registration</h3>
<p>Once we have set this up, we need to call <code>BuildServiceProvider</code> method on the container. This returns us a <code>ServiceProvider</code> as a result. Remember that we first need to register our types in the container (<code>ServiceCollection</code>) and then retrieve them using the provider. Bear with me on this one as we are using the concrete implementations rather than interfaces for this initial cut.</p>
<div data-language="csharp"><pre><code>
<span><span>var</span></span> myService <span>=</span> provider<span>.</span><span><span>GetService</span><span><span>&lt;</span>MyService<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
myService<span>.</span><span>DoSomething</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>Now when we run this, it should create an instance of <code>MyDependency</code>, construct an instance of <code>MyService</code> and run the <code>DoSomething()</code> method.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-ioc-container-3.png" title="dotnet-core-ioc-container-3.png" src="https://sahansera.dev/static/52d70b184e7aa00a5b603b35eeb953b4/5a190/dotnet-core-ioc-container-3.png" srcset="https://sahansera.dev/static/52d70b184e7aa00a5b603b35eeb953b4/772e8/dotnet-core-ioc-container-3.png 200w,
https://sahansera.dev/static/52d70b184e7aa00a5b603b35eeb953b4/e17e5/dotnet-core-ioc-container-3.png 400w,
https://sahansera.dev/static/52d70b184e7aa00a5b603b35eeb953b4/5a190/dotnet-core-ioc-container-3.png 800w,
https://sahansera.dev/static/52d70b184e7aa00a5b603b35eeb953b4/0d1a4/dotnet-core-ioc-container-3.png 1036w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>Notice how we never constructed <code>MyDependency</code> because the DI framework resolved it and did the constructor injection for us. Nice!</p>
<h3>Internals of ServiceCollection and ServiceProvider</h3>
<p>Looking at our code, the <code>ServiceCollection</code> holds a bunch of <code>ServiceDescriptor</code>s and provides some utility methods to manipulate it. <code>ServiceDescriptor</code>s are really the objects that describe (type, implementation, lifetime etc.) our service registrations.</p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>ServiceCollection</span> <span>:</span> <span><span>IServiceCollection</span></span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>List<span>&lt;</span>ServiceDescriptor<span>&gt;</span></span> _descriptors <span>=</span> <span>new</span> <span>List<span>&lt;</span>ServiceDescriptor<span>&gt;</span></span><span>(</span><span>)</span><span>;</span>

    <span>public</span> <span><span>int</span></span> Count <span>=&gt;</span> _descriptors<span>.</span>Count<span>;</span>
    <span>public</span> <span><span>bool</span></span> IsReadOnly <span>=&gt;</span> <span>false</span><span>;</span>

    <span>public</span> <span>ServiceDescriptor</span> <span>this</span><span>[</span><span><span>int</span></span> index<span>]</span>
    <span>{</span>
        <span>get</span>
        <span>{</span>
            <span>return</span> _descriptors<span>[</span>index<span>]</span><span>;</span>
        <span>}</span>
        <span>set</span>
        <span>{</span>
            _descriptors<span>[</span>index<span>]</span> <span>=</span> <span>value</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>public</span> <span><span>void</span></span> <span>Clear</span><span>(</span><span>)</span> <span>{</span><span>..</span><span>.</span><span>}</span>

    <span>public</span> <span><span>bool</span></span> <span>Contains</span><span>(</span><span>ServiceDescriptor</span> item<span>)</span> <span>{</span><span>..</span><span>.</span><span>}</span>

    <span>public</span> <span><span>bool</span></span> <span>Remove</span><span>(</span><span>ServiceDescriptor</span> item<span>)</span> <span>{</span><span>..</span><span>.</span><span>}</span>

    <span><span>void</span></span> ICollection<span>&lt;</span>ServiceDescriptor<span>&gt;</span><span>.</span><span>Add</span><span>(</span><span>ServiceDescriptor</span> item<span>)</span> <span>{</span><span>..</span><span>}</span>

    
<span>}</span></code></pre></div>
<p>In the subsequent sections, we will look at how it gets utilised.</p>
<p>The <a href="https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection.servicecollectionserviceextensions.addscoped?view=dotnet-plat-ext-3.1"><code>AddScoped</code></a> (and other service registration extension methods) method just adds our service registration (as a ServiceDescriptor) into the above <code>_descriptors</code> list.</p>
<p>Looking at <a href="https://github.com/dotnet/runtime/blob/60eff3f3766631bd4e7ee256ca17619fec90e9e6/src/libraries/Microsoft.Extensions.DependencyInjection/src/ServiceCollectionContainerBuilderExtensions.cs#L49">the internals</a> of the <code>BuildServiceProvider</code> extension method, we can see that it actually instantiates a new service provider with our given service registrations. As we saw earlier these service registrations are passed in as a <code>ServiceCollection</code> and if you put debug this, you will be able to see the following: </p>
<p><span>
      <span></span>
  <img alt="dotnet-core-ioc-container-4.png" title="dotnet-core-ioc-container-4.png" src="https://sahansera.dev/static/09fda0a1f94a3578a819ea52d1ce0fdd/5a190/dotnet-core-ioc-container-4.png" srcset="https://sahansera.dev/static/09fda0a1f94a3578a819ea52d1ce0fdd/772e8/dotnet-core-ioc-container-4.png 200w,
https://sahansera.dev/static/09fda0a1f94a3578a819ea52d1ce0fdd/e17e5/dotnet-core-ioc-container-4.png 400w,
https://sahansera.dev/static/09fda0a1f94a3578a819ea52d1ce0fdd/5a190/dotnet-core-ioc-container-4.png 800w,
https://sahansera.dev/static/09fda0a1f94a3578a819ea52d1ce0fdd/c1b63/dotnet-core-ioc-container-4.png 1200w,
https://sahansera.dev/static/09fda0a1f94a3578a819ea52d1ce0fdd/29007/dotnet-core-ioc-container-4.png 1600w,
https://sahansera.dev/static/09fda0a1f94a3578a819ea52d1ce0fdd/89557/dotnet-core-ioc-container-4.png 1928w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>If you are interested, one observation I made was to get an idea of <em>when</em> it actually instantiates our types. In our Program.cs if you update it as below,</p>
<div data-language="csharp"><pre><code><span><span>var</span></span> provider <span>=</span> container<span>.</span><span>BuildServiceProvider</span><span>(</span><span>)</span><span>;</span>
Console<span>.</span><span>WriteLine</span><span>(</span><span>"-----------"</span><span>)</span><span>;</span>
<span><span>var</span></span> myService <span>=</span> provider<span>.</span><span><span>GetService</span><span><span>&lt;</span>MyService<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
Console<span>.</span><span>WriteLine</span><span>(</span><span>"-----------"</span><span>)</span><span>;</span>
myService<span>.</span><span>DoSomething</span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>Should give you,</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-ioc-container-5.png" title="dotnet-core-ioc-container-5.png" src="https://sahansera.dev/static/3f558d6bb41db8e1f1001e14345b938f/5a190/dotnet-core-ioc-container-5.png" srcset="https://sahansera.dev/static/3f558d6bb41db8e1f1001e14345b938f/772e8/dotnet-core-ioc-container-5.png 200w,
https://sahansera.dev/static/3f558d6bb41db8e1f1001e14345b938f/e17e5/dotnet-core-ioc-container-5.png 400w,
https://sahansera.dev/static/3f558d6bb41db8e1f1001e14345b938f/5a190/dotnet-core-ioc-container-5.png 800w,
https://sahansera.dev/static/3f558d6bb41db8e1f1001e14345b938f/525d3/dotnet-core-ioc-container-5.png 1090w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>See the dotted line before “Doing some work in MyDependency”? I initially thought that these types would have been constructed when we built the service provider. However, it seems that they are instantiated when we call <code>provider.GetService&lt;MyService&gt;();</code> instead. This should, however, not to be confused with service lifetimes in an ASP.NET Core web application where service lifetimes play a major role in the request pipeline.</p>
<blockquote>
<p>💡 The IoC container will instantiate our implementation types when the GetService<t>() method is called, not when the IoC container is built.</t></p>
</blockquote>
<p>Looking at the implementation of the <code>ServiceProviderEngine</code>’s code you will see that the data structure that holds all our type registrations is really a <code>ConcurrentDictionary</code>. If you drill down in the call chain of <code>GetService</code> far enough, you would come across the following class in the <a href="https://github.com/dotnet/runtime/blob/907f7da59b40c80941b02ac2a46650adf3f606bc/src/libraries/Microsoft.Extensions.DependencyInjection/src/ServiceLookup/CallSiteValidator.cs#L14">source of DI extensions</a>.</p>
<p>So, we have an idea of how we can register services in the IoC container. Nevertheless, this can still be improved by mapping interfaces rather than using concrete classes. We will look at it in the next section.</p>
<h3>Replacing Concrete Classes with Interfaces</h3>
<p>Let’s extract interfaces for <code>MyService</code> and <code>MyDependency</code></p>
<div data-language="csharp"><pre><code><span>public</span> <span>interface</span> <span>IMyService</span>
<span>{</span>
    <span><span>void</span></span> <span>DoSomething</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<div data-language="csharp"><pre><code><span>public</span> <span>interface</span> <span>IMyDependency</span>
<span>{</span>
    <span><span>void</span></span> <span>DoWork</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>Nothing interesting here. Let’s just implement these two interfaces in their corresponding classes. </p>
<p>Our <code>MyService</code> will now use the interface instead of the concrete class.</p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>MyService</span> <span>:</span> <span><span>IMyService</span></span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>IMyDependency</span> _myDependency<span>;</span>
    
    <span>public</span> <span>MyService</span><span>(</span><span>IMyDependency</span> myDependency<span>)</span>
    <span>{</span>
        Console<span>.</span><span>WriteLine</span><span>(</span><span>"Constructed MyService"</span><span>)</span><span>;</span>
        _myDependency <span>=</span> myDependency<span>;</span>
    <span>}</span>
    
    <span>public</span> <span><span>void</span></span> <span>DoSomething</span><span>(</span><span>)</span>
    <span>{</span>
        _myDependency<span>.</span><span>DoWork</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>In our Program.cs, we will update the following lines to use the abstractions instead of concrete classes,</p>
<div data-language="csharp"><pre><code>container<span>.</span><span><span>AddScoped</span><span><span>&lt;</span>IMyDependency<span>,</span> MyDependency<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
container<span>.</span><span><span>AddScoped</span><span><span>&lt;</span>IMyService<span>,</span> MyService<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>Now when we run the application, we will get the same result. However, to make things interesting, let’s add another <code>MyDependency</code> class that implements <code>IMyDependency</code> interface. Without spending too much time on a name, let’s name that <code>MyDependency2</code> and register it in the IoC container.</p>
<div data-language="csharp"><pre><code>container<span>.</span><span><span>AddScoped</span><span><span>&lt;</span>IMyDependency<span>,</span> MyDependency<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
container<span>.</span><span><span>AddScoped</span><span><span>&lt;</span>IMyDependency<span>,</span> MyDependency2<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span> 
container<span>.</span><span><span>AddScoped</span><span><span>&lt;</span>IMyService<span>,</span> MyService<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span></code></pre></div>
<p>What do we get now?</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-ioc-container-6.png" title="dotnet-core-ioc-container-6.png" src="https://sahansera.dev/static/054d62c81104ef8c756fefbacd9cee15/5a190/dotnet-core-ioc-container-6.png" srcset="https://sahansera.dev/static/054d62c81104ef8c756fefbacd9cee15/772e8/dotnet-core-ioc-container-6.png 200w,
https://sahansera.dev/static/054d62c81104ef8c756fefbacd9cee15/e17e5/dotnet-core-ioc-container-6.png 400w,
https://sahansera.dev/static/054d62c81104ef8c756fefbacd9cee15/5a190/dotnet-core-ioc-container-6.png 800w,
https://sahansera.dev/static/054d62c81104ef8c756fefbacd9cee15/0d1a4/dotnet-core-ioc-container-6.png 1036w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>It’s no longer using <code>MyDependency</code>, but using <code>MyDependency2</code> instead.</p>
<blockquote>
<p>💡 Remember, if you add multiple concrete implementations for the same interface, it will always pick up the last one that got registered, by default.</p>
</blockquote>
<h3>Unravelling why we get the last registered implementation type</h3>
<p>So, how do we register multiple implementations for the same service type? It’s not supported as you might already know or have come across this <a href="https://github.com/aspnet/DependencyInjection/issues/360">discussion on Github</a>. Looking at the internals of the <code>GetService()</code> method we can uncover why this happens.</p>
<p>If you debug the <code>ServiceCollection</code>, you will be able to see that our two implementation types for <code>IMyDependency</code> are still there.</p>
<p><span>
      <span></span>
  <img alt="dotnet-core-ioc-container-7.png" title="dotnet-core-ioc-container-7.png" src="https://sahansera.dev/static/05de134123144e9df1171d4e14229b00/5a190/dotnet-core-ioc-container-7.png" srcset="https://sahansera.dev/static/05de134123144e9df1171d4e14229b00/772e8/dotnet-core-ioc-container-7.png 200w,
https://sahansera.dev/static/05de134123144e9df1171d4e14229b00/e17e5/dotnet-core-ioc-container-7.png 400w,
https://sahansera.dev/static/05de134123144e9df1171d4e14229b00/5a190/dotnet-core-ioc-container-7.png 800w,
https://sahansera.dev/static/05de134123144e9df1171d4e14229b00/c1b63/dotnet-core-ioc-container-7.png 1200w,
https://sahansera.dev/static/05de134123144e9df1171d4e14229b00/29007/dotnet-core-ioc-container-7.png 1600w,
https://sahansera.dev/static/05de134123144e9df1171d4e14229b00/89557/dotnet-core-ioc-container-7.png 1928w" sizes="(max-width: 800px) 100vw, 800px" loading="lazy">
    </span></p>
<p>So there has to be something in the call stack which hands over the last registered implementation type to the service provider. If you start off from <code>GetService()</code> method in <code>ServiceProviderServiceExtensions</code> class, you would end up in <code>ServiceProviderEngine</code>’s <code>GetService()</code> method’s <a href="https://github.com/dotnet/runtime/blob/60eff3f3766631bd4e7ee256ca17619fec90e9e6/src/libraries/Microsoft.Extensions.DependencyInjection/src/ServiceLookup/ServiceProviderEngine.cs#L82">implementation</a>.</p>
<div data-language="csharp"><pre><code><span>internal</span> <span><span>object</span></span> <span>GetService</span><span>(</span><span>Type</span> serviceType<span>,</span> <span>ServiceProviderEngineScope</span> serviceProviderEngineScope<span>)</span>
<span>{</span>
    <span>if</span> <span>(</span>_disposed<span>)</span>
    <span>{</span>
        ThrowHelper<span>.</span><span>ThrowObjectDisposedException</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>

    <span><span>var</span></span> realizedService <span>=</span> RealizedServices<span>.</span><span>GetOrAdd</span><span>(</span>serviceType<span>,</span> _createServiceAccessor<span>)</span><span>;</span>
    _callback<span>?.</span><span>OnResolve</span><span>(</span>serviceType<span>,</span> serviceProviderEngineScope<span>)</span><span>;</span>
    DependencyInjectionEventSource<span>.</span>Log<span>.</span><span>ServiceResolved</span><span>(</span>serviceType<span>)</span><span>;</span>
    <span>return</span> realizedService<span>.</span><span>Invoke</span><span>(</span>serviceProviderEngineScope<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p><code>RealizedServices</code> is a <code>ConcurrentDictionary</code> that keeps track of our service types and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sahansera.dev/dotnet-core-ioc-container/">https://sahansera.dev/dotnet-core-ioc-container/</a></em></p>]]>
            </description>
            <link>https://sahansera.dev/dotnet-core-ioc-container/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24240187</guid>
            <pubDate>Fri, 21 Aug 2020 23:56:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing Traceroute in Go – Blog]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24239371">thread link</a>) | @rbanffy
<br/>
August 21, 2020 | https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/ | <a href="https://web.archive.org/web/*/https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><em>(<a href="https://github.com/kalbhor/tracesite">link</a> for all the code)</em></p>
<h3 id="what-is-traceroute">What is traceroute?</h3>
<p>If you’ve fiddled with networks you must be familiar with the famous <code>traceroute</code> tool. Its a script that traces the path to a host and prints info on every hop it encounters. To give an example if you run <code>traceroute kalbhor.xyz</code> you should see something like this :</p>
<pre><code>❯ traceroute kalbhor.xyz
traceroute to kalbhor.xyz (18.140.218.13), 64 hops max, 52 byte packets
 1  dlinkrouter.dlink (192.168.0.1)  2.035 ms  1.276 ms  1.097 ms
 2  10.194.0.1 (10.194.0.1)  5.985 ms  4.006 ms  3.817 ms
 3  broadband.actcorp.in (49.207.47.201)  4.320 ms  4.715 ms  4.243 ms
 4  broadband.actcorp.in (49.207.47.225)  5.115 ms  5.390 ms  4.893 ms
 5  14.142.187.85.static-delhi.vsnl.net.in (14.142.187.85)  3.789 ms  3.746 ms  4.004 ms
 6  172.31.180.57 (172.31.180.57)  40.903 ms  41.661 ms  41.531 ms
 7  * * ix-ae-4-2.tcore1.cxr-chennai.as6453.net (180.87.36.9)  177.280 ms
 8  if-ae-13-2.tcore1.svw-singapore.as6453.net (180.87.36.83)  164.288 ms  176.561 ms  82.274 ms
 9  180.87.106.5 (180.87.106.5)  81.871 ms  84.931 ms  83.477 ms
10  52.93.11.197 (52.93.11.197)  82.368 ms  84.777 ms
    52.93.11.211 (52.93.11.211)  82.945 ms
11  52.93.11.79 (52.93.11.79)  83.587 ms
    52.93.11.67 (52.93.11.67)  78.292 ms
    52.93.11.87 (52.93.11.87)  79.452 ms
12  52.93.11.80 (52.93.11.80)  82.862 ms
    52.93.11.82 (52.93.11.82)  86.355 ms
    52.93.11.72 (52.93.11.72)  88.732 ms
13  52.93.9.161 (52.93.9.161)  83.706 ms
    52.93.9.95 (52.93.9.95)  82.498 ms
    52.93.9.139 (52.93.9.139)  84.551 ms
14  203.83.223.77 (203.83.223.77)  84.500 ms
    52.93.10.95 (52.93.10.95)  79.663 ms  79.812 ms
</code></pre><p>These might differ for you but for me this is the route my computer takes to connect to <code>kalbhor.xyz</code>. A few interesting details here include <code>dlinkrouter.dlink (192.168.0.1)</code>. Yes, that looks similar! It is my routers local IP, which means my router at home is the first machine to process my request. That’s pretty obvious.</p>
<p>Next we see <code>broadband.actcorp.in (49.207.47.201)</code> which is my ISP. We can also see that my request forwards to a ISP router in Delhi (most probably a regional level ISP) and further moves through Chennai and Singapore (kalbhor.xyz is hosted on an AWS Singapore server).</p>
<p>This tool is very useful to inspect network paths and solve problems. But aside from that, this tool is extremely interesting and its actual implementation is pretty simple.</p>
<hr>
<h3 id="how-does-traceroute-work">How does traceroute work?</h3>
<p>Now that we understand what traceroute does, lets take a look under the hood. Every TCP/UDP packet that travels has a bunch of headers containing info about the packet. One such header is the <code>ttl</code> header which is the number of hops the packet travels before being dropped. So if we set this <code>ttl</code> header to 1 our packet will reach the first hop and be dropped, if we set it to 2 our packet will reach the second hop and drop, and so on.</p>
<p>Now that we know how our packets can reach any of the hops between us and our destination, how do we collect info on the hop?
When a server/router drops a packet, it returns a  <code>ICMP Time Exceeded</code> message back. Parsing this message will allow us to retrieve info on the particular hop. Once the destination is reached (last hop) we are returned a <code>ICMP Destination Unreachable</code> message.</p>
<hr>
<h3 id="implementing-traceroute">Implementing traceroute</h3>
<p>Now that we understand what’s happening under the hood, we can roughly design a way to implement traceroute.
The steps to implement it should look something like this:</p>
<ul>
<li>Open a socket connection between us and our destination and send UDP packets</li>
<li>Start from TTL=1 and keep increasing the TTL value on the UDP packets</li>
<li>Open a socket that listens for the ICMP messages and parses them</li>
</ul>
<hr>
<h3 id="writing-a-go-application-that-implements-traceroute">Writing a Go application that implements traceroute</h3>
<p>Now we know what we want and all we need to do is implement it in any language. I’m implementing this in Go. The <code>net</code> and <code>syscall</code> package will help us along the way.</p>
<p><em>Note: I will be using minimal code just to show the main implementation (so you probably wont see me handling errors, etc here). For a more refinded well developed version of this code check out <a href="https://github.com/kalbhor/tracesite">the repository</a>.</em></p>
<p>Lets start by creating the sockets we’ll use for sending and recieving data.</p>
<pre><code>sendSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM, syscall.IPPROTO_UDP)
recvSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_ICMP)
defer syscall.Close(recvSocket)
defer syscall.Close(sendSocket)
</code></pre><p>Lets create a ttl variable which we’ll iterate and a timevalue variable that defines our timeout</p>
<pre><code>ttl := 1
// For 2000Ms
tv := syscall.NsecToTimeval(1000 * 1000 * (int64)(2000)) 
</code></pre><p>Next lets set the ttl and timeout value for the packets we’ll send in the socket</p>
<pre><code>syscall.SetsockoptInt(sendSocket, 0x0, syscall.IP_TTL, ttl)
syscall.SetsockoptTimeval(recvSocket, syscall.SOL_SOCKET, syscall.SO_RCVTIMEO, &amp;tv)
</code></pre><p>At this point our sockets are ready to send and recieve data. What we need to do is find the destination address for our <code>sendSocket</code> and a network interface on our machine for our <code>recvSocket</code></p>
<pre><code>func socketAddr() ([4]byte, error) {
    socketAddr := [4]byte{0, 0, 0, 0}
    addrs, err := net.InterfaceAddrs()
    if err != nil {
        return socketAddr, err
    }

    for _, a := range addrs {
        if ipnet, ok := a.(*net.IPNet); ok &amp;&amp; !ipnet.IP.IsLoopback() {
            if len(ipnet.IP.To4()) == net.IPv4len {
                copy(socketAddr[:], ipnet.IP.To4())
                return socketAddr, nil
            }
        }
    }
    err = errors.New("Not connected to the Internet")
    return socketAddr, err
}

func destAddr(dest string) ([4]byte, error) {
    destAddr := [4]byte{0, 0, 0, 0}
    addrs, err := net.LookupHost(dest)
    if err != nil {
        return destAddr, err
    }
    addr := addrs[0]

    ipAddr, err := net.ResolveIPAddr("ip", addr)
    if err != nil {
        return destAddr, err
    }
    copy(destAddr[:], ipAddr.IP.To4())
    return destAddr, nil
}
</code></pre><p>And in our main function we use these functions the get the addresses our sockets will use</p>
<pre><code>destAddr, err := destAddr("google.com")
socketAddr, err := socketAddr()
</code></pre><p>Lets bind our <code>recvSocket</code> so that it can recieve messages and lets send a null byte to our destination through our <code>sendSocket</code>. We connect to the port 33434.</p>
<pre><code>syscall.Bind(recvSocket, &amp;syscall.SockaddrInet4{Port: 33434, Addr: socketAddr})
syscall.Sendto(sendSocket, []byte{0x0}, 0, &amp;syscall.SockaddrInet4{Port: 33434, Addr: destAddr})
</code></pre><p>Now we need to parse the messages being sent on our <code>recvSocket</code></p>
<pre><code>p := make([]byte, options.Int(56)) // The integer here is the packet size
n, from, err := syscall.Recvfrom(recvSocket, p, 0)

ip := from.(*syscall.SockaddrInet4).Addr
ipString := fmt.Sprintf("%v.%v.%v.%v", ip[0], ip[1], ip[2], ip[3])
host, err := net.LookupAddr(ipString)

fmt.Println(host)
fmt.Println(ipString)
</code></pre><p>The Recvfrom method returns a <code>Sockaddr</code> type to our <code>from</code> variable. Hence if we parse our <code>from</code> variable we can get the IP info on the hop. We can use this with <code>net.LookupAddr</code> to run a reverse search and get the hostname (domain name) through the IP.</p>
<p>We’re almost done! All we need to do is wrap this functionality in a for loop and keep updating the <code>ttl</code> variable.</p>
<pre><code>func main() {
    sendSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_DGRAM, syscall.IPPROTO_UDP)
    recvSocket, err := syscall.Socket(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_ICMP)
    defer syscall.Close(recvSocket)
    defer syscall.Close(sendSocket)

    ttl := 1
    tv := syscall.NsecToTimeval(1000 * 1000 * (int64)(2000)) // For 2000Ms

    for {
        syscall.SetsockoptInt(sendSocket, 0x0, syscall.IP_TTL, ttl)
        syscall.SetsockoptTimeval(recvSocket, syscall.SOL_SOCKET, syscall.SO_RCVTIMEO, &amp;tv)

        destAddr, err := destAddr("google.com")
        socketAddr, err := socketAddr()
        destAddrString := fmt.Sprintf("%v.%v.%v.%v", destAddr[0], destAddr[1], destAddr[2], destAddr[3]) 


        syscall.Bind(recvSocket, &amp;syscall.SockaddrInet4{Port: 33434, Addr: socketAddr})
        syscall.Sendto(sendSocket, []byte{0x0}, 0, &amp;syscall.SockaddrInet4{Port: 33434, Addr: destAddr})

        p := make([]byte, options.Int(56)) // The integer here is the packet size
        n, from, err := syscall.Recvfrom(recvSocket, p, 0)

        ip := from.(*syscall.SockaddrInet4).Addr
        ipString := fmt.Sprintf("%v.%v.%v.%v", ip[0], ip[1], ip[2], ip[3])
        host, err := net.LookupAddr(ipString)
        
        fmt.Println(host)
        fmt.Println(ipString)
        
        // We stop our loop if we reach destination or reach max value for ttl
        if ipString == destAddrString || ttl &gt;= 56 { 
                break
        }

        ttl += 1

    }

}
</code></pre><p>Note that we added an if statement block to end our for loop once we reach the destination address or exceed max value for hops.</p>
<hr>
<h3 id="conclusion">Conclusion</h3>
<p>This is definitely not the most elegant solution but it explains how simple the implementation of <code>traceroute</code> actually is. If you want to check out a more refinded version of this code that compiles well and has many options like set ttl, max hops, timeout, etc check out - <a href="https://github.com/kalbhor/tracesite">My Github Repo</a></p>
<h5 id="voila----we-just-implemented-the-traceroute-tool">Voila  💫  we just implemented the traceroute tool</h5>

      
      
      
    </div></div>]]>
            </description>
            <link>https://blog.kalbhor.xyz/post/implementing-traceroute-in-go/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239371</guid>
            <pubDate>Fri, 21 Aug 2020 22:08:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Practical Python – Python projects for beginners]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24239266">thread link</a>) | @sixhobbits
<br/>
August 21, 2020 | https://www.codewithrepl.it/python-projects-for-beginners.html | <a href="https://web.archive.org/web/*/https://www.codewithrepl.it/python-projects-for-beginners.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
        <p>
          <h2>
            Python projects for beginners
          </h2>
        </p>
        <div>
          <div>
            <h3>
              Learn to code by example
            </h3>
            <p>
              If you're learning Python, you might have asked "what should I build?" This site is for you. We walk you through 15+ projects using Python (and sometimes NodeJS). By the end, you'll not only have significantly improved your Python skills, but you'll also have some useful apps to use and put in your portfolio.
            </p>
            <p>
            Prefer offline? You can download all of the tutorials in Code with Repl.it in <a href="https://codewithrepl.it/static/code-with-replit.epub">.epub</a>, <a href="https://codewithrepl.it/static/code-with-replit.mobi">.mobi</a> or <a href="https://codewithrepl.it/static/code-with-replit.pdf">.pdf</a> formats, or access each tutorial directly below.
            </p>
            <p>
            You can follow the whole set in order, or pick the ones that look the most interesting and dive right in.
            </p>
            <p>
            Each project uses the online IDE and coding platform <a href="https://repl.it/">repl.it</a> for all examples, so all you'll need to follow along is a free account there.
            </p>
          </div>
          <div>
            <a href="https://github.com/sixhobbits/ritza/blob/master/showcase/repl.it/assets/coding-with-replit.epub?raw=true" target="_blank" rel="noreferrer noopener">
            <p><img alt="Code With Repl.it" src="https://d2sofvawe08yqg.cloudfront.net/coding-with-replit/hero?1596050711">
            </p>
          </a>
          </div>
        </div>
      </section>

      <section id="section-features">
        <div>
            <h2><a id="part1"></a>
            Part 1: Beginner Python projects and Repl.it basics
          </h2>
        </div>

        
          
      </section>

      <section id="section-lessons">
        <p>
          <h2>
            Part 2: Intermediate Python projects and advanced Repl.it
          </h2>
        </p>

        
          
      </section>
      <section id="section-features">
        <p>
          <h2>
            Part 3: Python Projects
          </h2>
        </p>

        
          
            
      </section>
    </div></div>]]>
            </description>
            <link>https://www.codewithrepl.it/python-projects-for-beginners.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239266</guid>
            <pubDate>Fri, 21 Aug 2020 21:53:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over three billion people worldwide now play video games, study reports]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 359 (<a href="https://news.ycombinator.com/item?id=24239234">thread link</a>) | @Gamermeme
<br/>
August 21, 2020 | https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/ | <a href="https://web.archive.org/web/*/https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="the-post">
			
			<p><img width="588" height="330" src="https://nintendosmash.com/wp-content/uploads/2020/08/gamers-588x330.jpg" alt="Three billion people worldwide now play video games, study reports">		</p>
	
		


			<div>

							

						
<p>
		
	
	
		
	<span><i></i>1 week ago</span>	
	<span><i></i><a href="https://nintendosmash.com/category/news/" rel="category tag">News</a></span>
	
	
</p>

			
				<div>
					
					
					
<p>By mid-2020, the number of people playing video games had grown to 3.1 billion, according to <a href="https://www.dfcint.com/product/video-game-consumer-segmentation-2/">DFC Intelligence</a>. Considering that in July the total population of the Earth exceeded 7.8 billion, just under 40% are familiar with games.</p>




<p>Analysts point out that almost half of the accounted three billion are those who play only on smartphones or mobile devices. This segment is also ahead of all others in terms of growth.</p>



<p>However, only about 250 million people are active console users who regularly buy new games for them. Although they represent only 8% of the total number of gamers, this is the group with the highest revenue per person.</p>



<p>1.5 billion are playing on PC – 48% of all gamers. However, this number includes not only regular users but also those who also enjoy video games on consoles and mobile platforms.</p>



<p>More than half of the world’s gamers live in Asia – there are 1.42 billion players there. Moreover, this region also accounts for 53% of people who play only on smartphones. The top four also include Europe (668 million), Latin America (383 million) and North America (261 million).</p>



<ul><li><figure><img src="https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user.jpg" alt="" data-id="4920" data-link="https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/smartphome-user/" srcset="https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user.jpg 510w, https://nintendosmash.com/wp-content/uploads/2020/08/smartphome-user-300x231.jpg 300w" sizes="(max-width: 510px) 100vw, 510px"></figure></li></ul>

 
















<!-- AI CONTENT END 3 -->
					
									</div><!-- .entry /-->
								
				
				 <!-- .share-post -->				
			</div><!-- .post-inner -->
		</article><section id="check-also-box">
		<a href="#" id="check-also-close"><i></i></a>

		<p>
			<h3>Check Also</h3>
		</p>

				<div>
						
			<p><a href="https://nintendosmash.com/rumor-points-to-a-new-nintendo-direct-for-next-week/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/03/direct-1-310x165.jpg" alt="Rumor points to a new Nintendo Direct for next week">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/rumor-points-to-a-new-nintendo-direct-for-next-week/" rel="bookmark">Rumor points to a new Nintendo Direct for next week</a></h2>
			<p>It seems that the rumors of Nintendo Direct continue to circulate. In the last few …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/zelda-skyword-310x165.jpg" alt="King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/king-zell-claims-that-zelda-skyward-sword-hd-is-coming-to-nintendo-switch/" rel="bookmark">King Zell claims that Zelda: Skyward Sword HD is coming to Nintendo Switch</a></h2>
			<p>In recent days, a rumor has been circulating the network that Zelda: Skyward Sword was …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/08/animal-crossing-granny-island-310x165.jpg" alt="FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/famous-granny-audie-shows-us-her-animal-crossing-new-horizons-island/" rel="bookmark">FAMOUS GRANNY AUDIE SHOWS US HER ANIMAL CROSSING: NEW HORIZONS ISLAND</a></h2>
			<p>Animal Crossing fans may remember Audrey, the 89-year-old grandmother who has famously clocked more than …</p>
		</div>
				<div>
						
			<p><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/">
					<img width="310" height="165" src="https://nintendosmash.com/wp-content/uploads/2020/04/crysis-for-the-switch-310x165.jpg" alt="Crysis Remastered Coming To PC And Consoles On September 18">					<span></span>
				</a>
			</p><!-- post-thumbnail /-->
						
			<h2><a href="https://nintendosmash.com/crysis-remastered-coming-to-pc-and-consoles-on-september-18/" rel="bookmark">Crysis Remastered Coming To PC And Consoles On September 18</a></h2>
			<p>Crytek not only announced the release date of the remaster, but also a teaser comparing …</p>
		</div>
			</section></div>]]>
            </description>
            <link>https://nintendosmash.com/over-three-billion-people-worldwide-now-play-video-games-study-reports/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239234</guid>
            <pubDate>Fri, 21 Aug 2020 21:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Dolthub SQL API]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24239129">thread link</a>) | @awmarthur
<br/>
August 21, 2020 | https://www.dolthub.com/blog/2020-08-21-dolthub-repository-apis/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-08-21-dolthub-repository-apis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p><a href="https://doltdb.com/">Dolt</a> is <a href="https://www.dolthub.com/blog/2020-03-06-so-you-want-git-for-data/">Git for data</a>,
a relational database built to create, publish and consume datasets.
<a href="https://www.dolthub.com/">DoltHub</a> hosts a growing collection of public open datasets stored as Dolt databases.
Dolthub allows you explore data through its SQL <a href="https://www.dolthub.com/repositories/Liquidata/nba-players/query/master?q=SELECT%20full_name%2C%20abbreviation%2C%20year_founded%20FROM%20%60teams%60%20LIMIT%20200%3B&amp;active=Tables">query interface</a>.
We're excited to announce that you can now query Dolthub datsets via the SQL API. </p>
<h2>How it works</h2>
<p>Dolthub's SQL API exposes repository data via an HTTP endpoint at <code>www.dolthub.com/api/v1alpha1</code>.
Query parameters are encoded in the URL in the form of:</p>
<div data-language="text"><pre><code>https://www.dolthub.com/api/v1alpha1/&lt;owner_name&gt;/&lt;repo_name&gt;/&lt;branch_name&gt;?q=&lt;sql_query&gt;</code></pre></div>
<p>The &lt;sql_query&gt; is specified as a query string keyed by "q". Any valid SQL read query is acceptable.</p>
<h2>An Example</h2>
<p>Basketball is back y'all!
The NBA bubble is fully inflated and sports fans out there are getting a much appreciated distraction from the day-to-day.</p>
<p><img src="https://www.dolthub.com/blog/2fdc8439bb19fa2e316349efbd30c89f/dame.gif" alt="It's Dame Time!"></p>
<p>The NBA hit pause on the regular season all the way back in March, so let's check out Dolthub's
<a href="https://www.dolthub.com/repositories/Liquidata/nba-players"><code>nba-players</code></a> dataset and figure out where we left off.
We'll use Python's <code>requests</code> library as a simple way to hit the API.</p>
<div data-language="python"><pre><code><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> requests
<span>&gt;&gt;</span><span>&gt;</span> owner<span>,</span> repo <span>=</span> <span>'Liquidata'</span><span>,</span> <span>'nba-players'</span>
<span>&gt;&gt;</span><span>&gt;</span> res <span>=</span> requests<span>.</span>get<span>(</span><span>'https://dolthub.com/api/v1alpha1/{}/{}'</span><span>.</span><span>format</span><span>(</span>owner<span>,</span> repo<span>)</span><span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> res<span>.</span>json<span>(</span><span>)</span>
<span>{</span>
     <span>'query_execution_status'</span><span>:</span> <span>'Success'</span><span>,</span>
     <span>'query_execution_message'</span><span>:</span> <span>''</span><span>,</span>
     <span>'repository_owner'</span><span>:</span> <span>'Liquidata'</span><span>,</span>
     <span>'repository_name'</span><span>:</span> <span>'nba-players'</span><span>,</span>
     <span>'commit_ref'</span><span>:</span> <span>'master'</span><span>,</span>
     <span>'sql_query'</span><span>:</span> <span>'SHOW TABLES;'</span><span>,</span>
     <span>'schema'</span><span>:</span> <span>[</span>
            <span>{</span><span>'columnName'</span><span>:</span> <span>'Table'</span><span>,</span><span>'columnType'</span><span>:</span> <span>'String'</span><span>,</span><span>'isPrimaryKey'</span><span>:</span> <span>False</span><span>}</span>
        <span>]</span><span>,</span> 
     <span>'rows'</span><span>:</span> <span>[</span>
            <span>{</span><span>'Table'</span><span>:</span> <span>'career_totals_allstar'</span><span>}</span><span>,</span> 
            <span>{</span><span>'Table'</span><span>:</span> <span>'career_totals_post_season'</span><span>}</span><span>,</span> 
            <span>{</span><span>'Table'</span><span>:</span> <span>'career_totals_regular_season'</span><span>}</span><span>,</span> 
            <span>.</span><span>.</span><span>.</span>
        <span>]</span>
<span>}</span></code></pre></div>
<p>The response gives some general metadata about the query as well as the schema of the query and its result rows.
A couple things to note here: &lt;branch_name&gt; and &lt;sql_query&gt; are optional parameters.
If they're not specified they default to 'master' and 'SHOW TABLES' respectively.
The nba-players dataset includes all of this season's stat totals up to the March stoppage.
Let's find out who's leading the league in scoring. </p>
<div data-language="python"><pre><code><span>&gt;&gt;</span><span>&gt;</span> owner<span>,</span> repo<span>,</span> branch <span>=</span> <span>'Liquidata'</span><span>,</span> <span>'nba-players'</span><span>,</span> <span>'master'</span>
<span>&gt;&gt;</span><span>&gt;</span> query <span>=</span> <span>'''SELECT tot.pts / tot.gp as ppg, ply.full_name as player
    FROM `season_totals_regular_season` as tot 
    JOIN `players` as ply ON tot.player_id = ply.id 
    WHERE tot.season_id = '2019-20' 
    ORDER BY ppg DESC LIMIT 10;'''</span>
<span>&gt;&gt;</span><span>&gt;</span> res <span>=</span> requests<span>.</span>get<span>(</span><span>'https://www.dolthub.com/api/v1alpha1/{}/{}/{}'</span><span>.</span><span>format</span><span>(</span>owner<span>,</span> repo<span>,</span> branch<span>)</span><span>,</span> params<span>=</span><span>{</span><span>'q'</span><span>:</span> query<span>}</span><span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> res<span>.</span>json<span>(</span><span>)</span>
<span>{</span>
    <span>'query_execution_status'</span><span>:</span> <span>'Success'</span><span>,</span>
    <span>'query_execution_message'</span><span>:</span> <span>''</span><span>,</span>
    <span>'repository_owner'</span><span>:</span> <span>'Liquidata'</span><span>,</span>
    <span>'repository_name'</span><span>:</span> <span>'nba-players'</span><span>,</span>
    <span>'commit_ref'</span><span>:</span> <span>'master'</span><span>,</span>
    <span>'sql_query'</span><span>:</span> <span>"SELECT tot.pts / tot.gp as ppg, ply.full_name as player\n\tFROM `season_totals_regular_season` as tot \n\tJOIN `players` as ply ON tot.player_id = ply.id \n\tWHERE tot.season_id = '2019-20' \n\tORDER BY ppg DESC LIMIT 10;"</span><span>,</span>
    <span>'schema'</span><span>:</span> <span>[</span>
    	<span>{</span><span>'columnName'</span><span>:</span> <span>'ppg'</span><span>,</span><span>'columnType'</span><span>:</span> <span>'Int'</span><span>,</span><span>'isPrimaryKey'</span><span>:</span> <span>False</span><span>}</span><span>,</span> 
    	<span>{</span><span>'columnName'</span><span>:</span> <span>'player'</span><span>,</span><span>'columnType'</span><span>:</span> <span>'String'</span><span>,</span><span>'isPrimaryKey'</span><span>:</span> <span>False</span><span>}</span><span>]</span><span>,</span> 
    <span>'rows'</span><span>:</span> <span>[</span>
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'34'</span><span>,</span> <span>'player'</span><span>:</span> <span>'James Harden'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'30'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Bradley Beal'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'29'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Giannis Antetokounmpo'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'29'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Trae Young'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'28'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Damian Lillard'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'28'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Luka Doncic'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'27'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Russell Westbrook'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'27'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Kyrie Irving'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'26'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Kawhi Leonard'</span><span>}</span><span>,</span> 
    	<span>{</span><span>'ppg'</span><span>:</span> <span>'26'</span><span>,</span> <span>'player'</span><span>:</span> <span>'Anthony Davis'</span><span>}</span>
    <span>]</span>
<span>}</span></code></pre></div>
<p>This is a great example of the power of the SQL API.
You can execute joins against that API rather than having to fetch all the data and compute the matches yourself.</p>
<p>Why Harden is a distant third in the MVP race... we'll never know.
Speaking of Harden getting robbed, back in December this <a href="https://www.dolthub.com/blog/3e540a6d7ace830b78359178d9eb2afe/harden.mp4">happened</a>.
Harden's dunk wasn't counted and could not be overturned with video replay. (The Rockets went on to lose in double OT.)
Thankfully Liquidata has corrected the record on a <a href="https://www.dolthub.com/repositories/Liquidata/nba-players/compare/james-harden-basket-counts/asp1h2qhi1k8otrnk5o6jv87doahqn7v">separate branch</a> within this repo.
You can choose to believe either version of history: </p>
<div data-language="python"><pre><code><span>&gt;&gt;</span><span>&gt;</span> query <span>=</span> <span>"SELECT id FROM `players` where last_name='Harden'"</span>
<span>&gt;&gt;</span><span>&gt;</span> res <span>=</span> requests<span>.</span>get<span>(</span><span>'http://www.dolthub.com/api/v1alpha1/{}/{}'</span><span>.</span><span>format</span><span>(</span>owner<span>,</span> repo<span>)</span><span>,</span> params<span>=</span><span>{</span><span>'q'</span><span>:</span> query<span>}</span><span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> res<span>.</span>json<span>(</span><span>)</span>
<span>{</span>
    <span>.</span><span>.</span><span>.</span>
    <span>'rows'</span><span>:</span> <span>[</span><span>{</span><span>'id'</span><span>:</span> <span>'201935'</span><span>}</span><span>]</span>
<span>}</span>
<span>&gt;&gt;</span><span>&gt;</span> query <span>=</span> <span>'''SELECT pts FROM `season_totals_regular_season` 
    WHERE player_id = 201935 AND season_id = '2019-20';'''</span>
<span>&gt;&gt;</span><span>&gt;</span> branch <span>=</span> <span>'master'</span>
<span>&gt;&gt;</span><span>&gt;</span> res <span>=</span> requests<span>.</span>get<span>(</span><span>'http://www.dolthub.com/api/v1alpha1/{}/{}/{}'</span><span>.</span><span>format</span><span>(</span>owner<span>,</span> repo<span>,</span> branch<span>)</span><span>,</span> params<span>=</span><span>{</span><span>'q'</span><span>:</span> query<span>}</span><span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> res<span>.</span>json<span>(</span><span>)</span>
<span>{</span>
    <span>.</span><span>.</span><span>.</span>
    <span>'rows'</span><span>:</span> <span>[</span><span>{</span><span>'pts'</span><span>:</span> <span>'2096'</span><span>}</span><span>]</span><span>}</span>
<span>}</span>
<span>&gt;&gt;</span><span>&gt;</span> branch <span>=</span> <span>'james-harden-basket-counts'</span>
<span>&gt;&gt;</span><span>&gt;</span> res <span>=</span> requests<span>.</span>get<span>(</span><span>'http://www.dolthub.com/api/v1alpha1/{}/{}/{}'</span><span>.</span><span>format</span><span>(</span>owner<span>,</span> repo<span>,</span> branch<span>)</span><span>,</span> params<span>=</span><span>{</span><span>'q'</span><span>:</span> query<span>}</span><span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> res<span>.</span>json<span>(</span><span>)</span>
<span>{</span> 
    <span>.</span><span>.</span><span>.</span>
    <span>'rows'</span><span>:</span> <span>[</span><span>{</span><span>'pts'</span><span>:</span> <span>'2098'</span><span>}</span><span>]</span>
<span>}</span></code></pre></div>
<p>And because much of Dolt's functionality is exposed via SQL, you can even query the commit log over the API:</p>
<div data-language="python"><pre><code><span>&gt;&gt;</span><span>&gt;</span> branch <span>=</span> <span>'james-harden-basket-counts'</span>
<span>&gt;&gt;</span><span>&gt;</span> query <span>=</span> <span>'SELECT committer, message FROM dolt_log'</span>
<span>&gt;&gt;</span><span>&gt;</span> res <span>=</span> requests<span>.</span>get<span>(</span><span>'https://www.dolthub.com/api/v1alpha1/{}/{}/{}'</span><span>.</span><span>format</span><span>(</span>owner<span>,</span> repo<span>,</span> branch<span>)</span><span>,</span> params<span>=</span><span>{</span><span>'q'</span><span>:</span> query<span>}</span><span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> res<span>.</span>json<span>(</span><span>)</span>
<span>{</span>
    <span>.</span><span>.</span><span>.</span>
    <span>'rows'</span><span>:</span> <span>[</span>
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Added a field goal made as well'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>"James Harden's basket counts on Dec. 3, 2019"</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Relabeled columns in per36 views as per36 instead of per_game'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Changed description of views'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Added per36 views to README'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Merged master'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Added views for per36 stats'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Andy Arthur'</span><span>,</span> <span>'message'</span><span>:</span> <span>'putting description back'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Andy Arthur'</span><span>,</span> <span>'message'</span><span>:</span> <span>'moving player name to the front of saved query'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Andy Arthur'</span><span>,</span> <span>'message'</span><span>:</span> <span>'removing where clause from save query'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Added README'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Added views for per game stats'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Added sample query'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Initial import of player data'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Made appropriate columns doubles'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Initial schema for this NBA player database'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Initial import of teams and players'</span><span>}</span><span>,</span> 
        <span>{</span><span>'committer'</span><span>:</span> <span>'Tim Sehn'</span><span>,</span> <span>'message'</span><span>:</span> <span>'Initialize data repository'</span><span>}</span>
    <span>]</span>
<span>}</span></code></pre></div>
<h2>Anything is possible</h2>
<p><img src="https://www.dolthub.com/blog/cb52dacaef9e9e2dfa9cd355efbb278c/kg.gif" alt="Anything is possible"></p>
<p>The flexibility of the SQL API allows you to do anything you want with your data.
You can use the API to fetch data for visualization or as a simple backend for web app.
The SQL API is currently in alpha.
It's shape may change over time, but the basic principle of data access through SQL will remain.
The API is built of top of Dolt's SQL engine powered by <a href="https://github.com/liquidata-inc/go-mysql-server"><code>go-mysql-server</code></a>
so it's performance and compatibility are improving on a weekly basis.
Checkout our SQL support on <a href="https://github.com/liquidata-inc/go-mysql-server">Dolthub</a>.
We're excited to see how the SQL API gets used in the wild.
If you have any questions or requests, <a href="https://www.dolthub.com/contact">reach out</a> to us!</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-08-21-dolthub-repository-apis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24239129</guid>
            <pubDate>Fri, 21 Aug 2020 21:37:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F (2006)]]>
            </title>
            <description>
<![CDATA[
Score 173 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24238846">thread link</a>) | @tosh
<br/>
August 21, 2020 | http://www.nsl.com/k/f/f.htm | <a href="https://web.archive.org/web/*/http://www.nsl.com/k/f/f.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p><a href="http://www.nsl.com/k/f/f.k">F</a> is a pure functional concatenative 
language originally designed as an extension of <a href="http://www.nsl.com/papers/false.htm">False</a>. F contains the list-operations of <a href="http://www.kx.com/">K3</a> and the <em>dip</em> combinator 
of <a href="http://www.latrobe.edu.au/philosophy/phimvt/joy.html">Joy</a>. Floating-point and symbolic datatypes are supported. One-time assignment
is enforced in syntax. A theory of function-valence and -charge is outlined. F also contains a general continuation
primitive $, and the pattern sublanguage of <a href="http://www.nsl.com/k/xy/xy.htm">XY</a>.  <a href="http://www.nsl.com/k/f/g.k">G</a> is a variant of F in which the K3 adverbs are implemented as primitives.</p>

<h2>0. Introduction</h2>

<p>F has the following properties:</p>

<blockquote>
    <ul>
        <li>The language is concatenative</li>
        <li>The language is purely functional</li>
        <li>All K verbs are implemented</li>
        <li>All primitives are denoted by single symbols</li>
        <li>Primitive symbols are as mnemonic as possible</li>
    </ul>
</blockquote>

<p><em>The language is concatenative.</em> F tokens are words,
words denote functions, and the concatenation of words denotes
the composition of functions. In classical concatenative
languages, everything is a function from stacks to stacks. In F,
everything is a function from triples of
(environment;stack;queue) to triples of
(environment;stack;queue).</p>

<p><em>The language is purely functional.</em> There are no
side-effects. F has assignment, but not reassignment. This means
that you can't use a variable to store dynamic state. F
assignment associates names with values in an environment which
is passed as an argument and returned as a value. F also has
commands for interacting with the run-time environment and the
file-system, but these operations are notationally differentiated
from the operators of F: "h", "r", &amp;c.
They are intended as debugging aids only.</p>

<p><em>All K verbs are implemented.</em> Some K verbs are
implemented as primitives, and some are derived in the F prelude.
For example, the <em>atom</em> primitive @ of K is defined as
[#ints~]; i.e. shape matches the empty integer vector. Where K
provides a pair of functions, one of which is easily defined in
terms of the other, F implements one as a primitive and derives the
other. For example, <em>and</em> is primitive (&amp;) and <em>or</em>
is derived.  The criterion for dividing related pairs is simply
this:  the derived definition must not be egregiously inefficient
when compared to the primitive it supplants.</p>

<p><em>All primitives are denoted by single symbols.</em>
Although list-notation ([x y z]) is supported, any list can be
constructed functionally with ' (<em>quote</em>) and , (<em>join</em>).</p>

<p><em>Primitive symbols are as mnemonic as possible.</em> There
are five ways the mapping of a function to a symbol can be
mnemonic:</p>

<blockquote>
    <ol>
        <li>The symbol is in common use for the mapped function
            (e.g. + for addition)</li>
        <li>The symbol is mapped to that function in K (e.g. ?
            for <em>find</em>) or False (e.g. ! for <em>unquote</em>)</li>
        <li>The name of the symbol is a homonym for the mapped
            function (e.g. ' for <em>quote</em>)</li>
        <li>A pair of related functions (inverses, or
            near-inverses) are mapped to a pair of related
            symbols (e.g. / and \ for <em>take</em> and <em>drop</em>)</li>
        <li>Where several K primitives are mapped to one symbol,
            the primitives should form an easily remembered group
            based on some common property; e.g. both <em>upgrade</em>
            and <em>enum</em> return indices based on an
            ascending relation, so both are mapped to &lt;. </li>
    </ol>
</blockquote>

<h2>1. Datatypes</h2>

<p>The initial state of the interpreter consists of an
environment containing the F words of the prelude, an empty
result stack, and a string (character-vector) to be evaluated.
The input string is tokenized and parsed to obtain the initial
queue. </p>

<p>The input queue is a K list, possibly containing integers,
floats, symbols, <em>null</em>, functions, and lists
("quotations"). The result stack is initially empty.
The environment is a K dictionary. F processes the environment,
stack, and queue repeatedly until the queue is empty. </p>

<p>If the first item on the queue is an integer, float, <em>null</em>,
the prototype symbol `, or a list, the item is pushed onto the
stack.</p>

<p>If the first item is an undefined symbol, then if it's a <em>shuffle</em>
it's applied; otherwise, a variable is created (in the environment)
having the top of the stack as the value. </p>

<p>If the first item is a defined symbol, its value is
retrieved (from the environment) and pushed onto the stack.</p>

<p>If the first item is a function, then it is applied to the
environment, stack, and queue to produce a new environment,
stack, and queue.</p>

<p>Observe that the domain of the result stack is a proper subset
of the domain of the input queue. On the queue we may find
character-atoms, such as "r", and strings, such as
"blah". But character-atoms are executed away when they
are evaluated, and no F primitive ever produces one, and strings
are comments, which are not processed.</p>

<p>The <em>trace</em> command displays the stack and queue for
selected objects in the trace list T:</p>

<blockquote>
    <pre>F&gt;[fac] "t"

F&gt;3 fac!
                                       3 ♦ fac !
                                     3 2 ♦ fac ! *
                                   3 2 1 ♦ fac ! * *
6
F&gt;

F&gt;[fac cond] "t"

F&gt;3 fac!
                                       3 ♦ fac !
       3 [1 =] [] [dup ! pred ! fac ! *] ♦ cond !
                                     3 2 ♦ fac ! *
     3 2 [1 =] [] [dup ! pred ! fac ! *] ♦ cond ! *
                                   3 2 1 ♦ fac ! * *
   3 2 1 [1 =] [] [dup ! pred ! fac ! *] ♦ cond ! * *
6
F&gt;

F&gt;[] "t"

F&gt;3 fac!
6</pre>
</blockquote>

<h2>2. Primitives</h2>

<h3>Operators (O)</h3>

<blockquote>
    <pre>09*-		int		123 -&gt; 123
09*.09*-	float		123.45 -&gt; 123.45

az.AZ*		name		myName -&gt; value or null
az*-AZ*		shuffle		10 20 ab-ba -&gt; 20 10

[..]		list		[10 + [3 a]] -&gt; [10 + [3 a]]

+		add		1 2 + -&gt; 3
-		sub		2 3 - -&gt; 1
*		mul		3 4 * -&gt; 12
%		div		5 3 % -&gt; 1.666667
^		power		2 3 ^ -&gt; 8
_		floor		3.2 _ -&gt; 3

=		equal		2 2 = -&gt; 1
&gt;		more		4 6 &gt; -&gt; 0
&amp;		and/min		4 3 &amp; -&gt; 3

~		match		[1 2][1 2] ~ -&gt; 1

#		shape		[1 2 3] # -&gt; [3]

|		reverse		[1 2 3] | -&gt; [3 2 1]

@		where		[0 1 1 0 1] @ -&gt; [1 2 4]
@		flip		[[1 2 3][4 5 6]] @ -&gt; [[1 4][2 5][3 6]]

/		take		2[1 2 3] / -&gt; [1 2]
/		reshape		[3 2][1 2 3] / -&gt; [[1 2][3 1][2 3]]

\		drop		2[1 2 3] \ -&gt; [3]
\		cut		[0 2][1 2 3] \ -&gt; [[1 2][3]]
\		rotate		[1 2 3 4] 2 \ -&gt; [3 4 1 2]

?		find		[10 20 30] 20 ? -&gt; 1
?		mod		2 [3 4 5] ? -&gt; [1 0 1]

;		unique		[10 20 10 10 30] ; -&gt; [10 20 30]
:		group		[10 20 10 10 30] : -&gt; [[0 2 3][1][4]]

&lt;		enum		3 &lt; -&gt; [0 1 2]
&lt;		upgrade		[10 30 20] &lt; -&gt; [0 2 1]

.		infra		1 2 [[2 3 +]] . 3 4 -&gt; 1 2 [5] 3 4
.		index		[[1 2 3][[1 0]]] . -&gt; [2 1]
.		monad		[[1 2 3][[1 0]][-1*]] . -&gt; [-1 -2 3]
.		dyad		[[1 2 3][[1 0]]+[3 8]] . -&gt; [9 5 3]

!		unquote		2 [3 +] ! -&gt; 5
`		dip		2 3 4 [+] ` -&gt; 5 4
'		quote		'+ -&gt; [+]

,		join  		[1][2 3] , -&gt; [1 2 3]

$		state		1 2 3 '\ $ 4 5 6 -&gt; 4 5 6 1 2 3

)		s -&gt; s		stack-&gt;stack pattern
(		s -&gt; q		stack-&gt;queue pattern

}		q -&gt; s		queue-&gt;stack pattern
{		q -&gt; q		queue-&gt;queue pattern</pre>
</blockquote>

<h3>System Functions (K)</h3>

<p>The K system functions have reserved names:</p>

<blockquote>
    <pre>type (4::)
log exp abs sqr sqrt floor dot mul inv lsq
sin cos tan asin acos atan sinh cosh tanh
draw
in lin bin binl dv dvl di vs sv</pre>
</blockquote>

<h3>Literals (L)</h3>

<p>F has nine reserved names for literals:</p>

<blockquote>
    <pre>Nan		minint (0N)
Inf		maxint (0I)

nan		NaN (0n)
inf		infinity (0i)

null		null (_n)
sym		prototype sym (`)

ints		empty integer vector (!0)
floats		empty float vector (0#0.)
syms		empty sym vector (0#`)</pre>
</blockquote>

<h3>Commands (I)</h3>

<p>F has the following interactive commands:</p>

<blockquote>
    <pre>".."		comment		1 "skip" 2	comment not processed

"b"		break		'x "b"		signal error ('x)
"c"		clear		1 2 "c" 3 4	clear, load f, prelude
"d"		defined		'foo "d"	is foo defined?
"e"		error		0 "e"		set/unset error trap (\e)
"f"		F		"f" 2 unit!	set F semantics, clear
"j"		Joy		"j" 2 unit	set Joy semantics, clear
"k"		K		1 2 "k" 3 4	exit to K
"l"		load		'x "l"		load f/x.f|x.j
"m"		measure		[10&lt;] "m"	measure time in ms
"o"		words		'map "o"	show word form
"p"		precision	3 "p"		print precision (\p)
"r"		read		1 2 "r" 3 4	read, parse, eval
"s"		store		y 'x "s"	store f/x.f|x.j
"t"		trace		null "t" 3 4	set trace-list (T)
"u"		undefine	x "u"		undefine vars in x
"v"		variables	1 2 "v" 3 4	show vars (!environment)
"x"		exit		1 2 "x" 3 4	_exit 0
"w"		write		1 2 "w" 3 4	format, write
"z"		halt		1 2 "z" 3 4	: to continue
</pre></blockquote>

<h3>Names and numbers</h3>

<p>Spaces (<em>blank</em>, <em>tab</em>, <em>return</em>) are
necessary to separate names from names and numbers from numbers,
but not names from numbers.</p>

<p>A name must begin with a letter and may contain letters, .,
or a single -.  A name containing a - is a shuffle-symbol.</p>

<p>A numerical expression must begin with either a digit or - 
followed by a digit, and must end with a digit.  A floating-point 
numerical expression must contain exactly one . which
must be flanked by digits.</p>

<h3>Operators</h3>

<p>The math, logic, and relational operators are <em>atomic
functions</em>. For example,</p>

<blockquote>
    <pre>F&gt;[1 2 3][[4 5 6] 7 8]+
[[5 6 7] 9 11]</pre>
</blockquote>

<p>In several instances, distinct K operations have been mapped
to one symbol: </p>

<blockquote>
    <pre>int &lt;			enum			!x
~atom &lt;			upgrade			&lt;x
atom &lt;			nonce

int/ints @		where			&amp;x
list @			flip			+x
			nonce

atom y ?		mod			y!x
~atom y ?		find			x?y

list atom \		rotate			y!x
atom list \		drop			x _ y
atom atom \		drop			x _(),y
list list \		cut			x _ y

1=#x .			infra
x .			index/monad/dyad	. x</pre>
</blockquote>

<h3>Iterators</h3>

<p>The False combinators <em>if</em> and <em>while</em> have been
eliminated, and <em>cond</em>, <em>if</em>, and <em>while</em>
have been defined as words in the prelude. The truth-values of F
are more general than those of K: 0 is <em>false</em>, any other
value is <em>true</em>.</p>

<h3>Assignment</h3>

<p>Assignment has the form <em>value unassigned_name</em>. An
assigned name may not be re-assigned.</p>

<p>Reserved names cannot be assigned:</p>

<blockquote>
    <pre>F&gt;12 inf
12 inf</pre>
</blockquote>

<p>Use of an assigned name (a variable) places the value assigned
to it on the stack:</p>

<blockquote>
    <pre>F&gt;10 a

F&gt;a
10
F&gt;12 a
10 12 10
F&gt;a
10 12 10 10</pre>
</blockquote>

<p>A symbol can be produced indirectly:</p>

<blockquote>
    <pre>F&gt;10 foo

F&gt;foo
10
F&gt;[foo] first!
foo
F&gt;!
10</pre>
</blockquote>

<h3>Quotation</h3>

<p>The <em>quote</em> primitive ' takes the next item on the
queue and quotes it:</p>

<blockquote>
    <pre>F&gt;'+
[+]
F&gt;
F&gt;'[1 2 3]
[[1 2 3]]
F&gt;
F&gt;''
[']</pre>
</blockquote>

<p>The <em>unquote</em> combinator ! is Joy's <em>i</em>. ! takes
the top item <em>x</em> on the stack and prepends the elements of
<em>x</em> to the queue:</p>

<blockquote>
    <pre>F&gt;2 3 '+ !
5</pre>
</blockquote>

<p>The <em>dip</em> combinator is defined as it is in Joy. `
takes the top two items <em>x</em> <em>y</em> on the stack and</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.nsl.com/k/f/f.htm">http://www.nsl.com/k/f/f.htm</a></em></p>]]>
            </description>
            <link>http://www.nsl.com/k/f/f.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238846</guid>
            <pubDate>Fri, 21 Aug 2020 21:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Purpose of Technology]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24238641">thread link</a>) | @jacobedawson
<br/>
August 21, 2020 | https://balajis.com/the-purpose-of-technology/ | <a href="https://web.archive.org/web/*/https://balajis.com/the-purpose-of-technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/the-purpose-of-technology--1-.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/the-purpose-of-technology--1-.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/the-purpose-of-technology--1-.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/the-purpose-of-technology--1-.png" alt="The Purpose of Technology">
                </figure>
                <section>
                    <div>
                        <p>If the proximate purpose of technology is to reduce scarcity, the ultimate purpose of technology is to eliminate mortality.</p><p>At first that sounds crazy. But let's start with the premise: is the proximate purpose of technology to reduce scarcity? Think about how a breakthrough is described: faster, smaller, cheaper, better. All of these words mean that with this new technology, one can do <em>more with less</em>. In the digital world, Google made information on any topic free to anyone with an Internet connection, and WhatsApp made it free to communicate with the same. In the physical world, innovations like the <a href="https://en.wikipedia.org/wiki/Haber_process">Haber Process</a> or the <a href="https://en.wikipedia.org/wiki/Norman_Borlaug#Expansion_to_South_Asia:_the_Green_Revolution">Green Revolution</a> allowed us to produce more with less. In a real sense, these technologies <em>reduced scarcity</em>.</p><p>Now for second half of the sentence, the logical implication. Is the ultimate purpose of technology to eliminate mortality? Well, mortality is the main source of scarcity. If we had infinite time, we would be less concerned with whether something was faster. The reason speed has value is because time has value; the reason time has value is because human life has value, and lifespans are finite. If you made lifespans much longer, you'd reduce the effective cost of <em>everything</em>. Thus insofar as reducing scarcity is acknowledged to be the proximate purpose of technology, eliminating the main source of scarcity – namely mortality – is the ultimate purpose of technology. <strong>Life extension is the most important thing we can invent.</strong></p><p>And it's actually feasible today. It's been shown that we can extend healthy lifespans in mammals – and even <em>reverse</em> aging to bring people back to youth. Here's <a href="https://twitter.com/davidasinclair/status/1259084270854905856">link</a> after <a href="https://www.longevity.vc/">link</a> after <a href="https://www.nature.com/articles/s41467-020-15174-3">link</a> after <a href="https://news.harvard.edu/gazette/story/2019/11/researchers-able-to-improve-reverse-age-related-diseases-in-mice/">link</a> on the topic.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Six years ago, a lifetime in the aging field, the mere suggestion that aging could be reversed was enough to have your colleagues &amp; donors screw up their noses. Tom Rando <a href="https://twitter.com/StanfordMed?ref_src=twsrc%5Etfw">@StanfordMed</a> deserves a shout out for being brave enough back then to use the word "reversal" openly 6/n</p>— David Sinclair, PhD (@davidasinclair) <a href="https://twitter.com/davidasinclair/status/1259912936602177536?ref_src=twsrc%5Etfw">May 11, 2020</a></blockquote>

</figure><p>You probably weren't aware of this, though. You probably also weren't aware of how far we've come on <a href="https://www.nature.com/articles/d41586-020-00339-3">gene therapy</a>, how much has been done in <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">regenerative medicine</a>, how advanced the latest <a href="https://www.nature.com/articles/s41586-020-2285-x">bionic eyes</a> are – or how <a href="https://twitter.com/balajis/status/1228447944287932416">deadly</a> COVID-19 was as a threat until March of 2020.</p><h2 id="a-duty-to-evangelize-technological-progress">A duty to evangelize technological progress</h2><p>That is because people with scientific and technical backgrounds have not taken it upon ourselves to write about technological progress <em>as a duty</em>. We need to take time out of our busy days to make the case, repeatedly and with high production values, that technological progress is the <em>most </em>important thing we can do for broad-based prosperity and economic growth, and for life itself.</p><p>That starts with testing, drugs, treatments, and vaccines for COVID-19. But it goes far beyond that. Put another way: we may not get life extension or the whole suite of transhumanist technologies (brain-machine interfaces, stem cells, CRISPR gene therapy, and more) unless you, personally, evangelize them online. Not just tweets, but articles. Not just articles, but videos. Not just videos, but feature films. And not just a few films, but an <a href="https://www.whats-on-netflix.com/news/how-long-would-it-take-to-watch-all-of-netflix/">entire Netflix original library's worth</a>, a parallel tech media ecosystem full of inspirational content for technological progressives. A lifetime's worth of content that makes the case for immutable money, infinite frontier, artificial intelligence, and eternal life.</p><p>This may mean less focus on the businesses and personalities of technology. After all, do we care whether the technology for reversing aging is developed by a startup, an academic lab, a scientific consortium, or a solitary biohacker in their garage? No. What we care about is the goal of transcendence. If the technology ends up being <a href="https://www.amazon.com/Patenting-Sun-Polio-Salk-Vacine/dp/0688094945">completely free</a> and open source, so much the better. A corporate vehicle is just one means to an end, not an end in itself. We may need to understand every detail of operating a business, but we can't get lost in those details.</p><p>The point of doing a startup after all is to build something you can't buy. Money can't yet buy you a trip to <a href="https://www.spacex.com/human-spaceflight/mars/">Mars</a>. Or a <a href="https://www.neuralink.com/">neural implant</a>. Or a <a href="https://tricorder.xprize.org/prizes/tricorder">medical tricorder</a>. And at one point in the not-too-distant past it could not buy you a web browser, a search engine, or a smartphone. When the iPhone did not exist, people had to invent it. And they needed to be inspired to invent it.</p><figure><blockquote data-width="550"><div lang="en" dir="ltr"><p>for iphone 1:</p><p>the original mac,<br>blade runner,<br>2001: a space odyssey,<br>sony walkman TPS-L2, <br>braun ET66, <br>the concorde, <br>massimo vignale, <br>henry dreyfuss, <br>apollo 11, <br>the beatles,<br>warp records,<br>NASA,<br>polaroid,<br>arthur c. clarke,<br>eero saarinen</p><p>among others… <a href="https://t.co/F3ayC03T3y">https://t.co/F3ayC03T3y</a></p></div>— Imran Chaudhri (@imranchaudhri) <a href="https://twitter.com/imranchaudhri/status/1092194839540584449?ref_src=twsrc%5Etfw">February 3, 2019</a></blockquote>

</figure><h2 id="a-sense-of-purpose">A sense of purpose</h2><p>Why doesn't inspirational content for technological progressives exist in abundance? Part of the reason is adverse selection. While science fiction – even dystopian science fiction – can inspire, the scientists, engineers, founders, and funders thus inspired are often more occupied with building technology than evangelizing it. But this in turn means that we aren't directly educating the next generation, or the public at large.</p><p>We need to change that. Specifically, people who know math and science, who have experience in managing and investing, who are <em>technological progressives</em> rather than technological conservatives – these people need to learn to write, report, publish, and direct. We need to consciously build a parallel tech-driven decentralized media ecosystem, and we need it to become the first point of call for anyone seeking to learn about technology.</p><p>In this we will have allies around the world. Only the very richest people can afford to be cynical about the merits of technological progress. The <a href="https://www.ben-evans.com/benedictevans/2019/5/28/the-end-of-mobile">billions</a> of people who just got their first smartphone have had their lives dramatically improved as a consequence, and are too pragmatic to romanticize the past. If you haven't already internalized this point, take two minutes to watch <a href="https://www.youtube.com/watch?v=QpvEWVVnICE">this</a>.</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/QpvEWVVnICE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>Back? OK. So, building a media ecosystem for technological progressives clearly starts with technical education. At the K-12 level, we've already got plenty of learning apps, and the next step is remote schools. And at the level of collegiate education and continuous learning, Lambda School, Fast.ai, Coursera, Udacity, Udemy, Binance Academy, and the countless GitHub tutorials are an amazing start. But our duty extends beyond education to media of all kinds, particularly visual media.</p><p>The tech ecosystem has natural advantages here. We have the domain knowledge. And the experts at hand. We're already doing content marketing, podcasts, conferences, and a tweetstorm or two. We understand search engines, social networks, and distribution. And yes, we have learned to code.</p><p>What we haven't done yet is <em>full stack narrative</em>. That is, with a <a href="https://wistia.com/series/one-ten-one-hundred">few exceptions</a>, like Elon Musk, we haven't really told story arcs with technological progress at the center. We haven't taken the pitch we use to recruit engineers and externalized it for the public. We haven't infused <a href="https://twitter.com/balajis/status/1276010131990261761">emotion</a> and meaning into our public communications. We haven't made every one of our companies a media company. We haven't set out to tell our story ourselves.</p><p>We need to correct that immediately, and start evangelizing technological progress with every word and action. To recognize that the purpose of technology is to transcend our limits, and to motivate everything we're doing with a sense of that purpose. To take the winnings from our web apps and <a href="https://www.quora.com/How-did-Elon-Musk-fund-his-businesses-from-PayPal-to-SpaceX-and-Tesla">put them towards Mars</a>, to feel no hesitation towards starting small and no shame in dreaming big, to tell the world that it actually is possible to <a href="https://www.the-scientist.com/news-opinion/rna-injection-restores-hearing-in-guinea-pigs-30855">cure the deaf</a>, <a href="https://www.nature.com/articles/s41586-020-2285-x">restore sight</a>, and <a href="http://med.stanford.edu/news/all-news/2020/03/old-human-cells-rejuvenated-with-stem-cell-technology.html">end</a> <a href="https://www.youtube.com/watch?v=9nXop2lLDa4">death</a> <a href="https://www.ldeming.com/longevityfaq">itself</a>.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/the-purpose-of-technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238641</guid>
            <pubDate>Fri, 21 Aug 2020 20:38:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Do Technical Recruiters Even Exist?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24238383">thread link</a>) | @brightstuff
<br/>
August 21, 2020 | https://scottturman.com/why-do-technical-recruiters-even-exist/ | <a href="https://web.archive.org/web/*/https://scottturman.com/why-do-technical-recruiters-even-exist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="5e947086" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="685" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="796041f" data-element_type="section">
						<div>
				<div>
				<div data-id="33d71bb" data-element_type="column">
			<div>
					<div>
				<div data-id="cfc53ed" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We’re all familiar with the suited snakes that spend every 8-to-10-hour workday calling to convince us to leave our current, steady jobs for nothing more than a few bucks more and criminally bad insurance. With that said then, why do recruiters even exist?</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;At the surface, it’s easy to imagine that the company that’s actually hiring could accomplish everything that a recruiter supposedly does. If the company is looking to get a new employee and a person is looking to be that employee, then why do we need some middleman to come in and complicate everything?</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="95ce783" data-element_type="column">
			<div>
					<div>
				<div data-id="61b8733" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><a href="https://scottturman.com/stop-getting-fcked-by-technical-recruiters?why-do">
							<img width="2048" height="1568" src="https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-2048x1568.jpg" alt="Book Cover - Stop Getting Fucked By Technical Recruiters" srcset="https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-2048x1568.jpg 2048w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-300x230.jpg 300w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-1024x784.jpg 1024w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-768x588.jpg 768w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-1536x1176.jpg 1536w" sizes="(max-width: 2048px) 100vw, 2048px" data-srcset="https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-2048x1568.jpg 2048w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-300x230.jpg 300w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-1024x784.jpg 1024w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-768x588.jpg 768w, https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-1536x1176.jpg 1536w" data-src="https://scottturman.com/wp-content/uploads/2020/02/Stop-Getting-Fucked-by-technical-recruiters-2048x1568.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">								</a>
											</p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9efbe6d" data-element_type="section">
						<div>
				<div>
				<div data-id="89f6c40" data-element_type="column">
			<div>
					<div>
				<div data-id="ef8899f" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> <span>Let’s take a look at how that would really play out: say a company is looking to hire a software developer in the greater Orlando area. Out of the 2.6 million-ish people there, it’s no stretch to suppose that at least one of them would be qualified for the job.</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> <span>Companies aren’t just looking for </span><i><span>any </span></i><span>candidate, of course. Depending on the position, they need someone with experience in specific technologies. We’ll say that this position needs someone with experience in Angular, C#, and AWS. Out of the 2.6-ish million, how many do you think would meet that?</span></p><p><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span> <span>Try 117, according to LinkedIn’s Sales Navigator tool. The pool is still pretty good, though. We only need to get the one. But out of that 117, how many of them actually need a new job? My exact keyword search was&nbsp;</span>Angular AND C# AND AWS NOT recruiter NOT director.&nbsp;<span>&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span><span>&nbsp;</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2f3c5db" data-element_type="section">
						<div>
				<div>
				<div data-id="dc3d979" data-element_type="column">
			<div>
					<div>
				<div data-id="b971d09" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="564" src="https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-1024x722.png" alt="Sales Navigator Search" srcset="https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-1024x722.png 1024w, https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-300x211.png 300w, https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-768x541.png 768w, https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch.png 1166w" sizes="(max-width: 800px) 100vw, 800px" data-srcset="https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-1024x722.png 1024w, https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-300x211.png 300w, https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-768x541.png 768w, https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch.png 1166w" data-src="https://scottturman.com/wp-content/uploads/2020/08/SalesNavSearch-1024x722.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="a72ae61" data-element_type="section">
						<div>
				<div>
				<div data-id="cd58521" data-element_type="column">
			<div>
					<div>
				<div data-id="3a1e9ca" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>In my experience, that’s going to be 7-15% of them, depending on the current job market and how much you are offering. That number goes to 80% if you offer enough money. Now we’ve only got anywhere from 8 to 17 people to pick from. We just need one out of them, of course, but the pickings are starting to get a little slim.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;That’s assuming that all (or any) of them are even employable. Just because they list it on their resume doesn’t mean they can program their way out of a paper bag.&nbsp; With numbers this low you can see that the search would probably need to be expanded state-wide or even across the country.</p><p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;So the process would start over, with the added trouble of convincing someone to relocate to boot. This goes on and on at the cost of time that most companies simply do not have.<span>&nbsp;</span><span>&nbsp; &nbsp; &nbsp;&nbsp;</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="1ac7924" data-element_type="section">
						<div>
				<div>
				<div data-id="2db97f5" data-element_type="column">
			<div>
					<div>
				<div data-id="410d9e3" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<b>&nbsp;And this is where the appeal of a recruiting company comes in.</b> They could probably reach out to 60-80% of the entire talent pool, and I would be willing to bet that they could do it in less than a week. Businesses whose main focus is not recruiting would have a very hard time matching this speed. When a company is looking at limited prospects and a lengthy process, it makes sense for them to outsource to a service that promises to deliver qualified candidates&nbsp;<i>fast</i>. It is, for this reason, I have always maintained that technical recruiters are marketing organizations, and not exactly technical ones.&nbsp;</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="71ca428" data-element_type="column">
			<div>
					<div>
				<div data-id="c1ad7fe" data-element_type="widget" data-widget_type="blockquote.default">
				<div>
					<blockquote>
			<p>
				I have always maintained that technical recruiters are marketing organizations, and not exactly technical ones.			</p>
							
					</blockquote>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="e72140f" data-element_type="section">
						<div>
				<div>
				<div data-id="9099802" data-element_type="column">
			<div>
					<div>
				<div data-id="5eed185" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>&nbsp;Most people in the industry have witnessed recruiters put the value on speed over quality. They frequently turn over people who don’t actually know how to do the job and leave everyone unhappy. <b>If companies invested the time and allocated resources to create real recruiting methods and in-house screening processes, then recruiters would lose their entire industry.</b> But until that happens, we need to keep our skills sharp, learn to play the game, learn to negotiate, and learn that we are the prize.&nbsp;</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="6bb5dbc" data-element_type="section">
						<div>
				<div>
				<div data-id="9b6089c" data-element_type="column">
			<div>
					<div>
				<div data-id="7e69e47" data-element_type="widget" data-widget_type="blockquote.default">
				<div>
					<blockquote>
			<p>
				You are the one with the skills needed to make the technology go. 
			</p>
							
					</blockquote>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				</div>
				</div></div>]]>
            </description>
            <link>https://scottturman.com/why-do-technical-recruiters-even-exist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238383</guid>
            <pubDate>Fri, 21 Aug 2020 20:05:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SF Bay Area Fire Information and Resources]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24238094">thread link</a>) | @yangtheman
<br/>
August 21, 2020 | https://listorio.com/yangtheman/sf-bay-area-fire-information-and-resources | <a href="https://web.archive.org/web/*/https://listorio.com/yangtheman/sf-bay-area-fire-information-and-resources">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>yangtheman's</p><p>SF Bay Area Fire Information and Resources</p></div><div><p><span>san jose</span><span>bay area</span><span>san francisco</span><span>fire</span><span>information</span><span>resources</span></p></div><section><div><div><p><a target="_blank" href="https://nifc.maps.arcgis.com/apps/View/index.html?appid=69fca73a82df4fefa7c0e48b66d0899d&amp;extent=-123.2395,36.6849,-119.5618,38.1032"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBHZz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--fc897f4618870dc2645be8f8bcc1eb086a699f0a/Screen%20Shot%202020-08-21%20at%207.50.23%20AM.png"></a></p><div><div>
  <p>The image may be stale. Click on the link for the most up-to-date map.Â&nbsp;</p>
</div>
</div></div></div></section><section><div><div><p><a target="_blank" href="https://www.fire.ca.gov/incidents/2020/8/18/scu-lightning-complex/"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBIZz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--5f3c3358ad22d726783b5861d0c359e3e9c35e95/Screen%20Shot%202020-08-21%20at%208.02.09%20AM.png"></a></p></div></div></section><section><div><div><p><a target="_blank" href="https://www.arcgis.com/apps/webappviewer/index.html?id=ac4e6acdd58d4afaa0b8ce0e314108e0&amp;fbclid=IwAR1RD6DxX1FX2dYv0bjE_MzXdSYW20gjzhOPM2RyMNGngl8_tOWxaB9dzQ4"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBJdz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--a2db8cd103a388a04acf8c02ac487fb8bd69c435/Screen%20Shot%202020-08-23%20at%205.38.30%20PM.png"></a></p><div><div>
  <p>The image may be stale. Click on the link for the most up-to-date map.Â&nbsp;</p>
</div>
</div></div></div></section><section><div><div><p><a target="_blank" href="https://www.windy.com/?37.672,-121.953,9"><img src="https://www.windy.com/img/socialshare3.jpg"></a></p></div></div></section><section><div><div><p><a target="_blank" href="http://google.org/crisismap/google.com/2020-bay-area-wildfires"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBIQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--dc67d3483eb077a6feea43bf7b6d0e42287b1524/Screen%20Shot%202020-08-21%20at%207.57.19%20AM.png"></a></p><div><div>
  <p>The image may be stale. Click on the link for the most up-to-date map.Â&nbsp;</p>
</div>
</div></div></div></section><section><div><div><p><a target="_blank" href="https://experience.arcgis.com/experience/8ca8296b14384a468c72e63fd6de766a?fbclid=IwAR2RhZDvr5zQJ4LwF17SYXkeavne4tvOKN0bBD3geBIxE1snzpGrKPZWZwg"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBHdz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--8ee82e87d07f4cb518bb2171b839f975f9ac968b/Screen%20Shot%202020-08-21%20at%207.52.51%20AM.png"></a></p><div><div>
  <p>The image may be stale. Click on the link for the most up-to-date map.Â&nbsp;</p>
</div>
</div></div></div></section><section><div><div><p><a target="_blank" href="https://storymaps.arcgis.com/stories/f0121f7f2f0941afb3ed70529b2cee75"><img src="https://www.arcgis.com/sharing/rest/content/items/f0121f7f2f0941afb3ed70529b2cee75/info/thumbnail/ago_downloaded.jpg/?w=400"></a></p><div><div>
  <p>The image may be stale. Click on the link for the most up-to-date map.Â&nbsp;</p>
</div>
</div></div></div></section><section><div><div><p><a target="_blank" href="https://www.sccgov.org/sites/oes/alertscc/Pages/home.aspx"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBJZz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--82fe1346b863b3b9c4811e9573411ce481e77370/Screen%20Shot%202020-08-23%20at%203.54.05%20PM.png"></a></p></div></div></section><section><div><div><p><a target="_blank" href="https://www.readyforwildfire.org/prepare-for-wildfire/get-set/wildfire-action-plan/"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBJUT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--1b127aac278d61a4d3b63f4f904503d500850c22/Screen%20Shot%202020-08-21%20at%202.34.39%20PM.png"></a></p></div></div></section><section><div><div><p><a target="_blank" href="https://defensibleapp.com/"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBJQT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--f3efc363026890b52b8437c6dc6b601fa2e07016/Screen%20Shot%202020-08-21%20at%201.58.08%20PM.png"></a></p><div><div>
  <p>The image may be stale. Click on the link for the most up-to-date map.Â&nbsp;</p>
</div>
</div></div></div></section><section><div><div><p><a target="_blank" href="https://www.fire.ca.gov/incidents/2020/8/17/lnu-lightning-complex-includes-hennessey-gamble-15-10-spanish-markley-13-4-11-16-walbridge/"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBIUT09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--142ca7234e287c4c6594a89c6a456900ae6a0013/Screen%20Shot%202020-08-21%20at%208.01.12%20AM.png"></a></p></div></div></section><section><div><div><p><a target="_blank" href="https://www.fire.ca.gov/incidents/2020/8/17/czu-lightning-complex-including-warnella-fire/"><img src="https://listorio.com/rails/active_storage/blobs/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBIdz09IiwiZXhwIjpudWxsLCJwdXIiOiJibG9iX2lkIn19--8d5fb1790754ec2b1b9f46e69899e8716bfa13fc/Screen%20Shot%202020-08-21%20at%208.02.39%20AM.png"></a></p></div></div></section></div></div></div>]]>
            </description>
            <link>https://listorio.com/yangtheman/sf-bay-area-fire-information-and-resources</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238094</guid>
            <pubDate>Fri, 21 Aug 2020 19:30:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things that are not strings]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24238007">thread link</a>) | @w1nter
<br/>
August 21, 2020 | https://frantic.im/no-strings | <a href="https://web.archive.org/web/*/https://frantic.im/no-strings">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <header>
    
    
  </header>
  <p>As programmers, we have a collective delusion that anything that can be represented as a string, is a string. This thinking causes a whole bunch of problems.</p>

<p>Let’s take SQL for example. Every API in every programming language that I’ve seen considers SQL statement a string.</p>

<div><div><pre><code>function execute(sql: string): Promise&lt;Result&gt;
</code></pre></div></div>

<p>The problem with this API is that not every string is a valid SQL (nor sometimes it is the SQL you actually want to run).</p>

<p>Here’s a classic example of the misuse:</p>

<div><div><pre><code>const query = 'SELECT * FROM posts WHERE id = '
  + params.id;
</code></pre></div></div>

<p>In this example <code>params.id</code> can be anything, including invalid or malicious SQL.</p>

<p>The root problem here is not the lack of sanitization. The problem is that SQL is treated as a string.</p>

<p>Think about JSON for another example. You could certainly implement adding an item to a hash by doing this (I hope this code makes you cringe):</p>

<div><div><pre><code>function addKeyValue(json, key, value) {
  return json.substr(0, json.length - 1)
    + ', "' + key + '": "' + value + '"}';
}
</code></pre></div></div>

<p>As with the SQL example, you could add escaping and sanitization, but it’s just hacks hiding the real problem:</p>

<p><em>A string can be a representation of a thing, but it’s not the thing itself.</em></p>

<p>And it’s not only about concatenating strings. Can you spot the problem with this function? <span onclick="event.target.innerText = 'This URL will be marked as safe by the code below https://evil.com/https://safe.com/'">(see answer)</span></p>

<div><div><pre><code>function isSafeDomain(url: string): boolean {
  return url.includes('https://safe.com/');
}
</code></pre></div></div>

<p>Or in this one? <span onclick="event.target.innerText = 'This code is prone to timing attacks'">(see answer)</span></p>

<div><div><pre><code>function checkPassword(pass: string, hash: string): boolean {
  return sha1(pass) === hash;
}
</code></pre></div></div>

<p>Strings are lower level, and thus are much more flexible than they need to be to properly implement valid operations on the higher level concepts.</p>

<p>Incomplete list of things that are not strings:</p>

<ul>
  <li>SQL</li>
  <li>HTML</li>
  <li>JSON</li>
  <li>URL</li>
  <li>File path</li>
  <li>Password</li>
</ul>

<h2 id="things-are-things">Things are… things</h2>

<p>You can save yourself a lot of headache if you stop treating everything that can be represented as a string, as a string.</p>

<p>Both OO and FP styles allow for abstracting away something as a type or a class. You can make a closed opaque structure for the thing and limit the ways it can be constructed.</p>

<p>For example, for SQL, you might want to make sure it’s only created from static string literals.</p>

<div><div><pre><code>// Allowed
new SQL('SELECT * FROM posts WHERE id = ?');

// No allowed (e.g. via a lint rule)
new SQL('SELECT * FROM posts' + filter);
</code></pre></div></div>

<p>Of course, at some point, you will need to serialize the thing into a string to pass it into an API that was designed to consume a string. Do it at the last possible moment and try to limit it to a single place in the codebase.</p>

<div><div><pre><code>function execute(sql: SQL): Promise&lt;Result&gt; {
  return unsafeExecute(sql.toString());
}
</code></pre></div></div>

<p>Strings are coming into your app from the outer world. Don’t trust them to be what they seem they are. Convert them into proper things as soon as possible, and convert them back to strings as late as possible.</p>

<p>Here’s a few libraries for inspiration of how to treat things as… things:</p>

<ul>
  <li>SQL: <a href="https://github.com/gajus/slonik">Slonik</a>, <a href="https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/basic-linq-query-operations">LINQ</a></li>
  <li>HTML: React, Elm, <a href="https://github.com/tonsky/rum">rum</a></li>
  <li>JSON: a dictionary in any programming language</li>
  <li>URL: <a href="https://docs.rs/url/2.1.1/url/">url - Rust</a></li>
  <li>File paths: <a href="https://doc.rust-lang.org/std/path/struct.Path.html">std::path::Path - Rust</a></li>
  <li>Passwords: <a href="https://github.com/myfreeweb/secstr">secstr</a>, <a href="https://hackage.haskell.org/package/securemem">securemem</a></li>
</ul>

<hr>

<p>Good discussions on <a href="https://www.reddit.com/r/programming/comments/ie3dqz/things_that_are_not_strings/">reddit</a>, <a href="https://lobste.rs/s/wjpj6n/things_are_not_strings">lobsters</a>.</p>

<p>2020-08-23: Added password library example</p>

  
  






  <div>
  <div>
    <p>Hi! My name is Alex. I’m a software engineer at Facebook, where I work on React&nbsp;Native, Oculus and Messenger. I love thinking about development experience.</p>
    <p>I write about programming, software design and side projects <a href="https://frantic.im/subscribe/" target="_blank"><svg viewBox="0 0 800 800"><path d="M493 652H392c0-134-111-244-244-244V307c189 0 345 156 345 345zm71 0c0-228-188-416-416-416V132c285 0 520 235 520 520z"></path><circle cx="219" cy="581" r="71"></circle></svg> Subscribe</a></p>
  </div>
</div>

</article></div>]]>
            </description>
            <link>https://frantic.im/no-strings</link>
            <guid isPermaLink="false">hacker-news-small-sites-24238007</guid>
            <pubDate>Fri, 21 Aug 2020 19:20:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai releases new deep learning course, libraries, and book]]>
            </title>
            <description>
<![CDATA[
Score 741 | Comments 78 (<a href="https://news.ycombinator.com/item?id=24237207">thread link</a>) | @amardeep
<br/>
August 21, 2020 | https://www.fast.ai/2020/08/21/fastai2-launch/ | <a href="https://web.archive.org/web/*/https://www.fast.ai/2020/08/21/fastai2-launch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>

<p><span>Written: 21 Aug 2020 by <i>Jeremy Howard</i></span></p><p>fast.ai is a self-funded research, software development, and teaching lab, focused on making deep learning more accessible. We make all of our software, research papers, and courses freely available with no ads. We pay all of our costs out of our own pockets, and take no grants or donations, so you can be sure we’re truly independent.</p>
<p>Today is fast.ai’s biggest day in our four year history. We are releasing:</p>
<ul>
<li><a href="https://docs.fast.ai/">fastai v2</a>: A complete rewrite of fastai which is faster, easier, and more flexible, implementing new approaches to deep learning framework design, as discussed in the peer reviewed fastai <a href="https://www.mdpi.com/2078-2489/11/2/108/htm">academic paper</a></li>
<li><a href="https://fastcore.fast.ai/">fastcore</a>, <a href="https://fastscript.fast.ai/">fastscript</a>, and <a href="https://fastgpu.fast.ai/">fastgpu</a>: Foundational libraries used in fastai v2, and useful for many programmers and data scientists</li>
<li><a href="https://course.fast.ai/">Practical Deep Learning for Coders</a> (2020 course, part 1): Incorporating both an introduction to machine learning, and deep learning, and production and deployment of data products</li>
<li><a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch: AI Applications Without a PhD</a>: A book from O’Reilly, which covers the same material as the course (including the content planned for part 2 of the course)</li>
</ul>
<p>Also, in case you missed it, earlier this week we released the <a href="https://ethics.fast.ai/">Practical Data Ethics</a> course, which focuses on topics that are both urgent and practical.</p>
<h3 id="contents">Contents</h3>
<ul id="markdown-toc">
<li><a href="#fastai-v2" id="markdown-toc-fastai-v2">fastai v2</a></li>
<li><a href="#practical-deep-learning-for-coders-the-course" id="markdown-toc-practical-deep-learning-for-coders-the-course">Practical Deep Learning for Coders, the course</a></li>
<li><a href="#deep-learning-for-coders-with-fastai-and-pytorch-the-book" id="markdown-toc-deep-learning-for-coders-with-fastai-and-pytorch-the-book">Deep Learning for Coders with fastai and PyTorch, the book</a></li>
<li><a href="#fastcore-fastscript-and-fastgpu" id="markdown-toc-fastcore-fastscript-and-fastgpu">fastcore, fastscript, and fastgpu</a> <ul>
<li><a href="#fastcore" id="markdown-toc-fastcore">fastcore</a></li>
<li><a href="#fastscript" id="markdown-toc-fastscript">fastscript</a></li>
<li><a href="#fastgpu" id="markdown-toc-fastgpu">fastgpu</a></li>
</ul>
</li>
<li><a href="#acknowledgements" id="markdown-toc-acknowledgements">Acknowledgements</a></li>
</ul>
<h2 id="fastai-v2">fastai v2</h2>
<p>fastai is a deep learning library which provides practitioners with high-level components that can quickly and easily provide state-of-the-art results in standard deep learning domains, and provides researchers with low-level components that can be mixed and matched to build new approaches. It aims to do both things without substantial compromises in ease of use, flexibility, or performance. This is possible thanks to a carefully layered architecture, which expresses common underlying patterns of many deep learning and data processing techniques in terms of decoupled abstractions. These abstractions can be expressed concisely and clearly by leveraging the dynamism of the underlying Python language and the flexibility of the PyTorch library. fastai includes:</p>
<ul>
<li>A new type dispatch system for Python along with a semantic type hierarchy for tensors</li>
<li>A GPU-optimized computer vision library which can be extended in pure Python</li>
<li>An optimizer which refactors out the common functionality of modern optimizers into two basic pieces, allowing optimization algorithms to be implemented in 45 lines of code</li>
<li>A novel 2-way callback system that can access any part of the data, model, or optimizer and change it at any point during training</li>
<li>A new data block API</li>
<li>And much more…</li>
</ul>
<figure>
<img srcset="https://www.fast.ai/images/layered.png 2w" sizes="1px" src="https://www.fast.ai/images/layered.png">
<figcaption>fastai's layered architecture</figcaption>
</figure>
<p>fastai is organized around two main design goals: to be approachable and rapidly productive, while also being deeply hackable and configurable. It is built on top of a hierarchy of lower-level APIs which provide composable building blocks. This way, a user wanting to rewrite part of the high-level API or add particular behavior to suit their needs does not have to learn how to use the lowest level.</p>
<p>To see what’s possible with fastai, take a look at the <a href="https://docs.fast.ai/quick_start.html">Quick Start</a>, which shows how to use around 5 lines of code to build an image classifier, an image segmentation model, a text sentiment model, a recommendation system, and a tabular model. For each of the applications, the code is much the same.</p>
<figure>
<img srcset="https://www.fast.ai/images/segmentation-fastai.png 2w" sizes="1px" src="https://www.fast.ai/images/segmentation-fastai.png">
<figcaption>Example of using fastai for image segmentation</figcaption>
</figure>
<p>Read through the <a href="https://docs.fast.ai/tutorial">Tutorials</a> to learn how to train your own models on your own datasets. Use the navigation sidebar to look through the fastai documentation. Every class, function, and method is documented here. To learn about the design and motivation of the library, read the <a href="https://www.mdpi.com/2078-2489/11/2/108/htm">peer reviewed paper</a>, or watch <a href="https://youtu.be/bHVqO5YyNbU">this presentation</a> summarizing some of the key design points.</p>
<p>All fast.ai projects, including fastai, are built with <a href="https://nbdev.fast.ai/">nbdev</a>, which is a full <a href="https://www.fast.ai/2019/12/02/nbdev/">literate programming environment</a> built on Jupyter Notebooks. That means that every piece of documentation can be accessed as interactive Jupyter notebooks, and every documentation page includes a link to open it directly on Google Colab to allow for experimentation and customization.</p>
<p>It’s very easy to migrate from plain PyTorch, Ignite, or any other PyTorch-based library, or even to use fastai in conjunction with other libraries. Generally, you’ll be able to use all your existing data processing code, but will be able to reduce the amount of code you require for training, and more easily take advantage of modern best practices. Here are migration guides from some popular libraries to help you on your way: <a href="https://docs.fast.ai/migrating_pytorch">Plain PyTorch</a>; <a href="https://docs.fast.ai/migrating_ignite">Ignite</a>; <a href="https://docs.fast.ai/migrating_lightning">Lightning</a>; <a href="https://docs.fast.ai/migrating_catalyst">Catalyst</a>. And because it’s easy to combine and part of the fastai framework with your existing code and libraries, you can just pick the bits you want. For instance, you could use fastai’s GPU-accelerated computer vision library, along with your own training loop.</p>
<p>fastai includes many modules that add functionality, generally through callbacks. Thanks to the flexible infrastructure, these all work together, so you can pick and choose what you need (and add your own), including: <a href="https://arxiv.org/abs/1710.09412">mixup</a> and <a href="https://arxiv.org/abs/1708.04552">cutout</a> augmentation, a uniquely flexible <a href="https://docs.fast.ai/vision.gan.html">GAN training</a> framework, a range of schedulers (many of which aren’t available in any other framework) including support for fine tuning following the approach described in <a href="https://arxiv.org/abs/1801.06146">ULMFiT</a>, mixed precision, gradient accumulation, support for a range of logging frameworks like Tensorboard (with particularly strong support for Weights and Biases, as <a href="https://app.wandb.ai/borisd13/demo_config/reports/Visualize-track-compare-Fastai-models--Vmlldzo4MzAyNA">demonstrated here</a>), <a href="http://docs.fast.ai/medical.imaging">medical imaging</a>, and much more. Other functionality is added through the <a href="https://github.com/nestordemeure/fastai-extensions-repository">fastai ecosystem</a>, such as support for <a href="https://ohmeow.github.io/blurr/">HuggingFace Transformers</a> (which can also be done manually, as shown in <a href="http://docs.fast.ai/tutorial.transformers">this tutorial</a>), <a href="https://github.com/rbracco/fastai2_audio">audio</a>, <a href="https://muellerzr.github.io/fastinference/inference/">accelerated inference</a>, and so forth.</p>
<figure>
<img srcset="https://www.fast.ai/images/medical-fastai.png 2w" sizes="1px" src="https://www.fast.ai/images/medical-fastai.png">
<figcaption>Medical imaging in fastai</figcaption>
</figure>
<p>There’s already some great learning material made available for fastai v2 by the community, such as the “Zero to Hero” series by Zach Mueller: <a href="https://muellerzr.github.io/fastblog/2020/08/20/_08_21-beginner.html">part 1</a>; <a href="https://muellerzr.github.io/fastblog/2020/08/20/_08_21-intermediate.html">part 2</a>.</p>
<h2 id="practical-deep-learning-for-coders-the-course">Practical Deep Learning for Coders, the course</h2>
<p>Previous fast.ai courses have been studied by hundreds of thousands of students, from all walks of life, from all parts of the world. Many students have told us about how they’ve become <a href="https://forums.fast.ai/t/my-first-gold-medal/54237">multiple gold medal winners</a> of <a href="https://towardsdatascience.com/my-3-year-journey-from-zero-python-to-deep-learning-competition-master-6605c188eec7">international machine learning competitions</a>, <a href="https://forums.fast.ai/t/how-has-your-journey-been-so-far-learners/6480/2">received offers</a> from top companies, and <a href="https://icml-compbio.github.io/2020/papers/WCBICML2020_paper_67.pdf">having</a> <a href="https://ui.adsabs.harvard.edu/abs/2020EGUGA..2221465A/abstract">research</a> <a href="https://arxiv.org/pdf/2004.14356.pdf">papers</a> <a href="https://pubs.rsna.org/doi/abs/10.1148/ryai.2019190113?journalCode=ai">published</a>. For instance, Isaac Dimitrovsky <a href="https://forums.fast.ai/t/thanks-ra2-dream-challenge-win/76875">told us</a> that he had “<em>been playing around with ML for a couple of years without really grokking it… [then] went through the fast.ai part 1 course late last year, and it clicked for me</em>”. He went on to achieve first place in the prestigious international <a href="https://www.synapse.org/#!Synapse:syn20545111/wiki/594083">RA2-DREAM Challenge</a> competition! He developed a <a href="https://www.synapse.org/#!Synapse:syn21478998/wiki/604432">multistage deep learning method</a> for scoring radiographic hand and foot joint damage in rheumatoid arthritis, taking advantage of the fastai library.</p>
<p><a href="https://course.fast.ai/">This year’s course</a> takes things even further. It incorporates both machine learning and deep learning in a single course, covering topics like random forests, gradient boosting, test and validation sets, and p values, which previously were in a separate machine learning course. In addition, production and deployment are also covered, including material on developing a web-based GUI for our own deep learning powered apps. The only prerequisite is high-school math, and a year of coding experience (preferably in Python). The course was recorded live, in conjunction with the <a href="https://www.usfca.edu/data-institute">Data Institute</a> at the University of San Francisco.</p>
<p>After finishing this course you will know:</p>
<ul>
<li>How to train models that achieve state-of-the-art results in:
<ul>
<li>Computer vision, including image classification (e.g.,classifying pet photos by breed), and image localization and detection (e.g.,finding where the animals in an image are)</li>
<li>Natural language processing (NLP), including document classification (e.g.,movie review sentiment analysis) and language modeling</li>
<li>Tabular data (e.g.,sales prediction) with categorical data, continuous data, and mixed data, including time series</li>
<li>Collaborative filtering (e.g.,movie recommendation)</li>
</ul>
</li>
<li>How to turn your models into web applications, and deploy them</li>
<li>Why and how deep learning models work, and how to use that knowledge to improve the accuracy, speed, and reliability of your models</li>
<li>The latest deep learning techniques that really matter in practice</li>
<li>How to implement stochastic gradient descent and a complete training loop from scratch</li>
<li>How to think about the ethical implications of your work, to help ensure that you’re making the world a better place and that your work isn’t misused for harm</li>
</ul>
<p>We care a lot about teaching, using a <a href="https://www.fast.ai/2016/10/08/teaching-philosophy/">whole game</a> approach. In this course, we start by showing how to use a complete, working, very usable, state-of-the-art deep learning network to solve real-world problems, using simple, expressive tools. And then we gradually dig deeper and deeper into understanding how those tools are made, and how the tools that make those tools are made, and so on. We always teach through examples. We ensure that there is a context and a purpose that you can understand intuitively, rather than starting with algebraic symbol manipulation. We also dive right into the details, showing you how to build all the components of a deep learning model from scratch, including discussing performance and optimization details.</p>
<p>The whole course can be completed for free without any installation, by taking advantage of the guides for the Colab and Gradient platforms, which provide free, GPU-powered Notebooks.</p>
<h2 id="deep-learning-for-coders-with-fastai-and-pytorch-the-book">Deep Learning for Coders with fastai and PyTorch, the book</h2>
<p>To understand what the new book is about, and who it’s for, let’s see what others have said about it… Soumith Chintala, the co-creator of PyTorch, said in <a href="https://www.fast.ai/2020/08/20/soumith-forward/">the foreword</a> to <a href="https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527">Deep Learning for Coders with fastai and PyTorch</a>:</p>
<blockquote>
<p>But unlike me, Jeremy and Sylvain selflessly put a huge amount of energy into making sure others don’t have to …</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.fast.ai/2020/08/21/fastai2-launch/">https://www.fast.ai/2020/08/21/fastai2-launch/</a></em></p>]]>
            </description>
            <link>https://www.fast.ai/2020/08/21/fastai2-launch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24237207</guid>
            <pubDate>Fri, 21 Aug 2020 17:51:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern benchmark between kafka pulsar and rabbitmq – kafka still dominates]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24236910">thread link</a>) | @tamale
<br/>
August 21, 2020 | https://www.confluent.io/blog/kafka-fastest-messaging-system/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/kafka-fastest-messaging-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Apache Kafka<sup>®</sup> is one of the most popular event streaming systems. There are many ways to <a href="https://www.confluent.io/kafka-vs-pulsar/">compare systems</a> in this space, but one thing everyone cares about is performance. Kafka has been known to be <a href="https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines" target="_blank" rel="noopener noreferrer">fast</a>, but how fast is it today, and how does it stack up against other systems? We decided to test Kafka’s performance on the latest cloud hardware to find out.</p>
<p>For comparisons, we chose a traditional message broker, <a href="https://www.rabbitmq.com/" target="_blank" rel="noopener noreferrer">RabbitMQ</a>, and one of the <a href="https://bookkeeper.apache.org/" target="_blank" rel="noopener noreferrer">Apache BookKeeper™</a>&nbsp;based message brokers, <a href="http://pulsar.apache.org/" target="_blank" rel="noopener noreferrer">Apache Pulsar</a>. We focused on (1) <strong>system throughput</strong> and (2) <strong>system latency</strong>, as these are the primary performance metrics for event streaming systems in production. In particular, the throughput test measures how efficient each system is in utilizing the hardware, specifically the disks and the CPU. The latency test measures how close each system is to delivering real-time messaging including tail latencies of up to p99.9th percentile, a key requirement for real-time and mission-critical applications as well as microservices architectures.</p>
<p>We found that Kafka delivers the best throughput while providing the lowest end-to-end latencies up to the p99.9th percentile. At lower throughputs, RabbitMQ delivers messages at very low latencies.</p>
<p><a href="https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles.png" rel="noopener noreferrer" target="_blank"><img src="https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles.png" alt="Throughput (MB/s) | End-to-End Latency Quantiles" width="2541" height="1000" srcset="https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles.png 2541w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-300x118.png 300w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-1024x403.png 1024w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-768x302.png 768w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-1536x604.png 1536w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-2048x806.png 2048w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-350x138.png 350w, https://cdn.confluent.io/wp-content/uploads/throughput-and-latency-quantiles-600x236.png 600w" sizes="(max-width: 2541px) 100vw, 2541px"></a></p>
<table>
<tbody>
<tr>
<td></td>
<td><strong>Kafka</strong></td>
<td><strong>Pulsar</strong></td>
<td><strong>RabbitMQ</strong><br>
<strong>(Mirrored)</strong></td>
</tr>
<tr>
<td><strong>Peak Throughput</strong><br>
<strong>(MB/s)</strong></td>
<td>605<br>
MB/s</td>
<td>305<br>
MB/s</td>
<td>38<br>
MB/s</td>
</tr>
<tr>
<td><strong>p99 Latency</strong><br>
<strong>(ms)</strong></td>
<td>5 ms<br>
(200 MB/s load)</td>
<td>25 ms<br>
(200 MB/s load)</td>
<td>1 ms*<br>
(reduced 30 MB/s load)</td>
</tr>
</tbody>
</table>
<p><em>*RabbitMQ latencies degrade significantly at throughputs higher than the 30 MB/s. Furthermore, the impact of mirroring is significant at higher throughput and better latencies can be achieved by using just classic queues without mirroring.</em></p>
<p>This blog post is structured to first walk you through the benchmarking framework we used, followed by a description of the testbed and the workloads. It will finish with an explanation of the results using the various system and application metrics. All of these are <a href="https://github.com/confluentinc/openmessaging-benchmark/" target="_blank" rel="noopener noreferrer">open source</a>, so curious readers can reproduce the results for themselves or dig deeper into the collected Prometheus metrics. As with most benchmarks, we compare performance on a setup for a specific workload. We always encourage readers to compare using their own workloads/setups, to understand how these translate to production deployments. For a deeper look at features, architecture, ecosystem, and more, read this <a href="https://www.confluent.io/kafka-vs-pulsar/">complete guide</a> comparing Kafka, Pulsar, and RabbitMQ.</p>
<h2 id="overview"><a id="overview"></a>Overview</h2>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#durability">Durability in distributed systems</a></li>
<li><a href="#benchmarking-framework">Benchmarking Framework</a>
<ul>
<li><a href="#omb-framework">Fixes to the OMB Framework</a></li>
<li><a href="#omb-kafka-driver">Fixes to the OMB Kafka driver</a></li>
<li><a href="#omb-rabbitmq-driver">Fixes to the OMB RabbitMQ driver</a></li>
<li><a href="#omb-pulsar-driver">Fixes to the OMB Pulsar driver</a></li>
</ul>
</li>
<li><a href="#testbed">Testbed</a>
<ul>
<li><a href="#disks">Disks</a></li>
<li><a href="#os-tuning">OS tuning</a></li>
<li><a href="#memory">Memory</a></li>
</ul>
</li>
<li><a href="#throughput-test">Throughput test</a>
<ul>
<li><a href="#fsync">Effect of fsync</a></li>
<li><a href="#test-setup">Test setup</a></li>
<li><a href="#throughput-results">Throughput results</a></li>
</ul>
</li>
<li><a href="#latency-test">Latency test</a>
<ul>
<li><a href="#latency-results">Latency results</a></li>
<li><a href="#latency-trade-offs">Latency trade-offs</a></li>
</ul>
</li>
<li><a href="#summary">Summary</a></li>
</ul>
<h2 id="background"><a id="background"></a>Background</h2>
<p>First, let’s discuss each of the systems briefly to understand their high-level design and architecture, looking at the trade-offs each system makes.</p>
<p><strong>Kafka</strong> is an open-source distributed event streaming platform, and one of the five most active projects of the Apache Software Foundation. At its core, Kafka is designed as a replicated, distributed, persistent commit log that is used to power event-driven microservices or large-scale stream processing applications. Clients produce or consume events directly to/from a cluster of brokers, which read/write events durably to the underlying file system and also automatically replicate the events synchronously or asynchronously within the cluster for fault tolerance and high availability.</p>
<p><strong>Pulsar</strong> is an open-source distributed pub/sub messaging system originally catered towards queuing use cases. It recently added event streaming functionality as well. Pulsar is designed as a tier of (almost) stateless broker instances that connect to a separate tier of BookKeeper instances, which actually read/write and, optionally, store/replicate the messages durably. Pulsar is not the only system of its kind as there are also other messaging systems like Apache DistributedLog and Pravega, which have been created on top of BookKeeper and aim to also provide some Kafka-like event streaming functionality.</p>
<p><strong>BookKeeper</strong> is an open-source distributed storage service that was originally designed as a write-ahead log for Apache™ Hadoop®’s NameNode. It provides persistent storage of messages in <em>ledgers</em>, across server instances called <em>bookies</em>. Each bookie synchronously writes each message to a local journal log for recovery purposes and then asynchronously into its local indexed ledger storage. Unlike Kafka brokers, bookies do not communicate with each other and it’s the BookKeeper clients that are responsible for replicating the messages across bookies using a quorum-style protocol.</p>
<p><strong>RabbitMQ</strong> is an open-source traditional messaging middleware that implements the AMQP messaging standard, catering to low-latency queuing use cases. RabbitMQ consists of a set of broker processes that host “exchanges” for publishing messages to and queues for consuming messages from. Availability and durability are properties of the various queue types offered. Classic queues offer the least availability guarantees. Classic mirrored queues replicate messages to other brokers and improve availability. Stronger durability is provided through the more recently introduced <a href="https://www.rabbitmq.com/quorum-queues.html" target="_blank" rel="noopener noreferrer">quorum queues</a> but at the <a href="https://www.rabbitmq.com/quorum-queues.html#use-cases" target="_blank" rel="noopener noreferrer">cost of performance</a>. Since this is a performance-oriented blog post, we restricted our evaluation to classic and mirrored queues.</p>
<h2 id="durability"><a id="durability"></a>Durability in distributed systems</h2>
<p>Single-node storage systems (e.g., RDBMS) depend on fsyncing writes to disk to ensure maximal durability. But in distributed systems, durability typically comes from replication, with multiple copies of the data that fail independently. Fsyncing data is just a way of reducing the impact of the failure when it does occur (e.g., fsyncing more often could lead to lower recovery time). Conversely, if enough replicas fail, a distributed system may be unusable regardless of fsync or not. Hence, whether we fsync or not is just a matter of what guarantees each system chooses to depend on for its replication design. While some depend closely on never losing data written to disk, thus requiring fsync on every write, others handle this scenario in their design.</p>
<p>Kafka’s replication protocol was carefully designed to ensure consistency and durability guarantees without the need for synchronous fsync by tracking what has been fsynced to the disk and what hasn’t. By assuming less, Kafka can handle a wider range of failures like filesystem-level corruptions or accidental disk de-provisioning and does not take for granted the correctness of data that is not known to be fsync’d. Kafka is also able to leverage the OS for batching writes to the disk for better performance.</p>
<p>We have not been able to ascertain categorically whether BookKeeper offers the same consistency guarantees without fsyncing each write—specifically, whether it can rely on replication for fault tolerance in the absence of synchronous disk persistence. This isn’t covered in the documentation or a write-up on the underlying replication algorithm. Based on our inspection and the fact that BookKeeper implements a grouped fsync algorithm, we believe it does rely on fsyncing on each write for its correctness, but we’d love to <a href="mailto:info@confluent.io" target="_blank" rel="noopener noreferrer">hear from folks</a> in the community who might know better if our conclusion is correct.</p>
<p>In any case, since this can be somewhat of a controversial topic, we’ve given results in both cases to ensure we are being as fair and complete as possible, though running Kafka with synchronous fsync is extremely uncommon and also unnecessary.</p>
<h2 id="benchmarking-framework"><a id="benchmarking-framework"></a>Benchmarking framework</h2>
<p>With any benchmark, one wonders what framework is being used and if it’s fair. To that end, we wanted to use the <a href="http://openmessaging.cloud/docs/benchmarks/" target="_blank" rel="noopener noreferrer">OpenMessaging Benchmark Framework</a> (OMB), originally authored, in large parts, by Pulsar contributors. OMB was a good starting point with basic workload specification, metrics collection/reporting for the test results, support for the three chosen messaging systems as well as a modular cloud deployment workflow tailored for each system. But of note, Kafka and RabbitMQ implementations did have some significant shortcomings that affected the fairness and reproducibility of these tests. The resulting benchmarking code including the fixes described in more detail below are available as <a href="https://github.com/confluentinc/openmessaging-benchmark" target="_blank" rel="noopener noreferrer">open source</a>.</p>
<h3 id="omb-framework"><a id="omb-framework"></a>Fixes to the OMB Framework</h3>
<p>We upgraded to Java 11 and Kafka 2.6, RabbitMQ 3.8.5, and Pulsar 2.6 (the latest releases at the time of writing). We significantly enhanced the monitoring capabilities across the three systems, with the Grafana/Prometheus monitoring stack, capturing metrics across messaging systems, JVM, Linux, disk, CPU, and network. This was critical for being able to not just report results but explain them. We have added support for producer-only tests and consumer-only tests with support for generating/draining backlogs, while also fixing an important bug with producer rate calculation when the number of topics is smaller than the number of producer workers.</p>
<h3 id="omb-kafka-driver"><a id="omb-kafka-driver"></a>Fixes to the OMB Kafka driver</h3>
<p>We fixed a critical bug in the Kafka driver that starved Kafka producers of TCP connections, bottlenecking on a single connection from each worker instance. The fix makes the Kafka numbers fair, compared to other systems—that is, all of them now use the same number of TCP connections to talk to their respective brokers. We also fixed a critical bug in the Kafka benchmark consumer driver, where offsets were being committed too frequently and synchronously causing degradation, whereas it was done asynchronously for other systems. We also tuned the Kafka consumer fetch size and replication threads to eliminate bottlenecks in message fetching at high throughputs and to configure the brokers equivalent to the other systems.</p>
<h3 id="omb-rabbitmq-driver"><a id="omb-rabbitmq-driver"></a>Fixes to the OMB RabbitMQ driver</h3>
<p>We enhanced RabbitMQ to use routing keys and configurable exchange types (<code>DIRECT</code> and <code>TOPIC</code> exchanges) and also fixed a bug in the RabbitMQ cluster setup deployment workflow. Routing keys were introduced to mimic the concept of partitions per …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/kafka-fastest-messaging-system/">https://www.confluent.io/blog/kafka-fastest-messaging-system/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/kafka-fastest-messaging-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236910</guid>
            <pubDate>Fri, 21 Aug 2020 17:22:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficiency is dangerous and slowing down makes life better]]>
            </title>
            <description>
<![CDATA[
Score 702 | Comments 300 (<a href="https://news.ycombinator.com/item?id=24236489">thread link</a>) | @joubert
<br/>
August 21, 2020 | https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>â€˜Slow down, you move too fast <em>â€¦</em>â€™ <br>â€“ â€˜The 59th Street Bridge Song (Feelinâ€™ Groovy)â€™ (1966) by Paul Simon</blockquote>
<p><strong>We worship efficiency</strong>. Use less to get more. Same-day delivery. Multitask; text on one device while emailing on a second, and perhaps conversing on a third. Efficiency is seen as good. Inefficiency as wasteful.</p>
<p>Thereâ€™s a sound rationale for thinking this way. Economists teach us that increased efficiency is the major way to improve our standard of living. If your company gives you a pay rise without becoming more efficient, it will also have to raise its prices to make up the shortfall. If all companies do the same, everyone ends up running in place â€“ youâ€™ll need your higher wages to match the higher prices of the things you buy. So, if we want to make material progress, we must become more efficient. Streamlined supply chains, just-in-time deliveries and no slack in the workforce all serve to raise efficiency. Achieve this, and all our lives will get better and better, or so weâ€™re promised.</p>
<p>For automobile manufacturers, who wish to squeeze as many miles per gallon as possible out of their car designs, air resistance and the grab of the road are the enemies of efficiency. In the world of finance, it is at the point of exchange that most friction arises. Before money, the potato farmer had to use sacks of potatoes to trade for eggs and milk. As the British historian Niall Ferguson reminds us in his <a href="https://www.penguin.co.uk/books/178/178638/the-ascent-of-money/9780141990262.html">book</a> <em>The Ascent of Money</em> (2008), the invention of money went a long way toward reducing this inefficiency, and much that has happened in the financial world over the past 200 years can be seen as a continuation of that revolution.</p>
<p>Credit, for example, meant that you could go shopping for eggs and milk even without having the money right now. Financial markets have since taken this efficiency to another level. The creation of â€˜option marketsâ€™ means that you donâ€™t have to go to the trouble of buying a stock that youâ€™re going to be selling soon anyway. You can just promise to buy it, and then sell it at a price and date specified by the option contract. And then you can trade the option rather than the underlying stock.</p>
<p>Each of these developments and many others have made it easier to do oneâ€™s business without wasted time and energy â€“ without friction. Each has made economic transactions quicker and more efficient. Thatâ€™s obviously good in some ways. But the financial crisis of 2008 suggested that maybe there could be too much of a good thing. If mortgages and other loans hadnâ€™t been transformed into tradable assets (â€˜securitiesâ€™), then bankers might have taken the time to assess the credit-worthiness of each applicant. If people had to visit a bank to withdraw cash, they might spend less and save more. This is not mere speculation â€“ for instance, <a href="https://doi.org/10.1002/(SICI)1099-0771(199909)12:3%3c183::AID-BDM318%3e3.0.CO;2-F">research</a> <a href="https://doi.org/10.1016/0167-2681(80)90051-7">reviewed</a> by the Nobel Prize-winning economist Richard Thaler shows that people will pay more for an item with a credit card than with cash. Arguably, a little friction to slow us down would have enabled both institutions and individuals to make better financial decisions.</p>
<p>A decade ago, the American psychologist Adam Grant and I argued in a journal <a href="https://journals.sagepub.com/doi/full/10.1177/1745691610393523?url_ver=Z39.88-2003&amp;rfr_id=ori:rid:crossref.org&amp;rfr_dat=cr_pub%20%200pubmed">paper</a> that this â€˜too much of a good thingâ€™ phenomenon might be a general rule. Some motivation produces excellent performance; too much motivation produces choking. Some group collaboration produces cohesion and enhances productivity; too much of it leads to staleness. Some empathy enables you to understand what another person is going through; too much could prevent you from saying and doing hard things. Similarly, in my <a href="https://www.harpercollins.com/products/the-paradox-of-choice-barry-schwartz?variant=32207920234530">book</a> <em>The Paradox of Choice</em> (2004), I argued that, whereas a life with no freedom to choose is not worth living, a life with too much choice leads to paralysis, bad decisions and dissatisfaction. Finding the right amount â€“ what Aristotle called the â€˜meanâ€™ â€“ of motivation, collaboration, empathy, choice and many other aspects of life, including efficiency, is a key challenge we face, both as individuals and as a society.</p>
<p>To be better prepared next time, we need to learn to live less efficiently in the here and now</p>
<p>But finding the mean isnâ€™t easy. As the English poet William Blake observed in <em>The Marriage of Heaven and Hell</em> (1790-93): â€˜You never know what is enough unless you know what is more than enough.â€™</p>
<p><strong>If the financial crisis</strong> taught us that we had become too efficient with our transactions, what of the COVID-19 pandemic? Why hadnâ€™t we stockpiled key supplies and machines, built up hospital capacity, or ensured the robustness of our supply chains? The reason, of course, is that it would have been seen as inefficient and profit-robbing. Money spent on masks and gowns gathering dust in a warehouse could always be put to more â€˜productiveâ€™ use in the marketplace. Likewise, employing more people than needed under â€˜ordinaryâ€™ circumstances, or making products yourself rather than relying on international supply chains, would have been seen as inefficient. One lesson, then, is that to be better prepared next time, we need to learn to live less â€˜efficientlyâ€™ in the here and now.</p>
<p>Seen in this light, at least some inefficiency is like an insurance policy. Think about your own situation. Every year that you donâ€™t get into a car accident and your house doesnâ€™t burn down and you stay healthy, you could think to yourself that you have â€˜wastedâ€™ your money on various pointless insurance products, and that youâ€™d be financially better off without all those insurance premiums to pay.</p>
<p>Most of us donâ€™t like the sense that weâ€™re wasting money on insurance. We would rather be wearing that money, or eating it, or driving it. Some years ago, with a struggle, I convinced my ageing mother to supplement her basic health insurance policy with a more comprehensive insurance product. Her resources were modest and the policy wasnâ€™t cheap. The year went by and, happily, she had no serious medical conditions that required the use of the extra cover. When the time came to renew, my mother resisted, because, indeed, the money she spent the year before had been â€˜wastedâ€™. My reply, perhaps unduly snarky, was to suggest to her that maybe the next year she would get lucky, have a really serious illness, and get her moneyâ€™s worth out of her insurance.</p>
<p>Thankfully, in many domains, government regulations protect us from our desire for ever-greater personal financial efficiency by forcing us to have insurance. Laws require that our cars be insured, and mortgagers require the same for our homes. In the United States, â€˜Obamacareâ€™ (the Affordable Care Act enacted in 2010, designed to increase the number of US citizens covered by health insurance) essentially compelled people to have health insurance, until the Supreme Court challenged this aspect of the Act as unconstitutional. I suspect that many of us are underinsured in general, but the problem would be much worse without these various, state-imposed insurance requirements.</p>
<p>One way to think about insurance, however inefficient it might feel, is that it enables us to be resilient against shocks that could befall us from a world that is radically uncertain. And the world <em>is</em> radically uncertain. As the British economists John Kay and Mervyn King point out in their <a href="https://wwnorton.com/books/9781324004776">book</a> <em>Radical Uncertainty</em> (2020), efforts to quantify risk by attaching probabilities to various unlikely future states of the world are mostly science fiction. The world is much messier than a roulette wheel or a pair of dice.</p>
<p>A little bit of friction can forestall disaster when you encounter an icy road</p>
<p><strong>What should we do</strong> in the face of this radical uncertainty? When making decisions, instead of asking ourselves which option will give us the best results, we should be asking which option will give us good-enough results under the widest range of future states of the world. Instead of trying to maximise return on investment in our retirement account, we should be setting a financial goal and then choosing investments that will allow us to achieve that goal under the widest set of future financial circumstances. Instead of looking for the â€˜bestâ€™ job, we should be looking for a job that will be good enough â€“ satisfying enough â€“ as co-workers and managers come and go, and the future economy gyrates. Instead of choosing the best college to go to, we should be choosing a college that will be good enough, even with an obnoxious roommate and a boring Bio 1 teacher.</p>
<p>The term used to describe this approach to decision-making is <em>satisficing</em>. And satisficing with an eye toward a radically uncertain future might be called <em>robust satisficing</em>. Satisficing is a form of insurance â€“ insurance against financial meltdowns, global pandemics, nasty bosses, boring teachers and crappy roommates. Insurance can seem stodgy â€“ like the guy who wears a belt <em>and</em> suspenders. Perhaps we donâ€™t need both, but what happens if we have neither?</p>
<p>I think the real flaw in capitalism revealed by the 2008 financial crisis was its unbridled, single-minded pursuit of profit and efficiency. And perhaps the real flaw revealed in our lack of readiness for the 2019-20 pandemic was a manifestation of the same thing. Capitalism neednâ€™t be either unbridled or single-minded. It isnâ€™t in other societies with high standards of living, and it hasnâ€™t been at all points in history in the US. So perhaps itâ€™s time to rekindle certain social norms that serve to slow us down. For example, if people thought about their homes less as financial investments and more as places to live, full of the friction of kids, dogs, friends, neighbours and community, there might be less property speculation with an eye toward buying and selling houses merely for profit. If companies felt the friction of being caretakers of their communities, they might look differently at streamlining their operations by eliminating jobs.</p>
<p>Weâ€™d all like a car that gets 100 miles to a gallon. The forces of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better">https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/why-efficiency-is-dangerous-and-slowing-down-makes-life-better</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236489</guid>
            <pubDate>Fri, 21 Aug 2020 16:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ammonia as a fuel for compression ignition engines]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24236204">thread link</a>) | @airstrike
<br/>
August 21, 2020 | https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/ | <a href="https://web.archive.org/web/*/https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><p>The diesel engine, also known as the compression ignition (CI) engine, has been a workhorse of the modern energy economy for more than a hundred years.&nbsp;Its role in the coming sustainable energy economy will be determined by its ability to co-evolve with climate-friendly fuels.&nbsp;Two researchers from the National Institute of Advanced Industrial Science and Technology in Japan have now examined the fit between ammonia and the CI engine.&nbsp;</p><p>Pavlos Dimitriou and Rahat Javaid arrive at a two-part conclusion in their paper, “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.sciencedirect.com/science/article/abs/pii/S0360319920300124" target="_blank">A review of ammonia as a compression ignition engine fuel</a>,” published in January in the <em>International Journal of Hydrogen Energy</em>. Part one is good news: “Ammonia as a compression ignition fuel can be currently seen as a feasible solution.”&nbsp;Part two is a dose of qualifying reality: to manage emissions of N2O, NOx, and unburnt NH3, “aftertreatment systems are mandatory for the adaptation of this technology,” which means that ammonia-fueled CI engines are likely to be feasible “only for marine, power generation and possibly heavy-duty applications where no significant space constraints exist.”</p><p>The paper provides a detailed and readable account of efforts over the last eight decades to develop a viable version of an ammonia-fueled CI engine.&nbsp;The authors state that, “to the best of [their] knowledge, this is the first review approach focusing entirely on ammonia utilisation for compression ignition.”&nbsp;A major challenge confronted by the development efforts derives from ammonia’s “poor combustion characteristics … such as high autoignition temperature, low flame speed, narrow flammability limits and high heat of vaporization.” They continue, “successful ammonia compression ignition operation could only be observed for engine designs that featured extremely high compression ratios from 35:1 to 100:1.”</p><p>To address this challenge, most researchers resorted to the expedient of co-combustion.&nbsp;With the addition of fuels like diesel, biodiesel, and dimethyl ether, “the combustion of ammonia … is a realistic conception, as the secondary fuel, with lower Autoignition temperature, can be used to trigger the combustion of the mixture.”&nbsp;Different researchers have used a variety of fuel ratios under a variety of conditions.&nbsp;Ammonia ratios as high as 95% have been achieved, but numbers in the range of 40 to 80% are more prevalent in the literature. Hydrogen has been used successfully as the complementary fuel.&nbsp;This includes hydrogen derived from on-board ammonia cracking, but the authors of one study determined that “the introduction of pure hydrogen [from an off-board source] seems to be the most promising in terms of emissions reduction and engine performance enhancement.”</p><p>The dual-fuel approach opens the door to CI for ammonia, but another challenge soon arises: when ammonia is burned as a CI fuel, it tends to produce problematic levels of nitrogen oxides and unburned ammonia. To compound the issue, NOx tends to be a product of high combustion temperatures and unburned ammonia of low temperatures – and there is no “sweet spot” temperature where neither species is a problem.&nbsp;</p><p>Contemporary researchers are attacking this problem with two methods.&nbsp;The first is with advanced fuel injection techniques.&nbsp;By injecting fuel at several points during the engine’s compression stroke, with fine control of the fuel increments, it is possible to achieve “simultaneous reduction of N2O and NH3 emissions in ammonia dual-fuel engines.”&nbsp;The second method is exhaust after-treatment.&nbsp;Selective catalytic reduction (SCR) technologies have been found that can reduce both NOx and unburned ammonia to acceptable levels, a result furthered by “the effect of ammonia in NOx reduction as observed in the modern after-treatment systems.”</p><p>The authors’ conclusion that ammonia is unlikely to become a major fuel for passenger cars will not come as a surprise to most members of the ammonia energy community.&nbsp;Ships, of course, are a different story.</p><p>Engine manufacturer MAN Energy Solutions expects to bring its dual-fueled maritime engine to market in 2024. (An <em>Ammonia Energy</em> <a href="https://www.ammoniaenergy.org/articles/man-ammonia-engine-update/">update on the MAN ammonia engine</a> appeared in January.)&nbsp;Success in the maritime realm will certainly encourage development of engines scaled for off-grid and back-up power generation.&nbsp;For other transportation applications, long the near-exclusive province of internal combustion, CI might have its hands full fighting off electrification via battery and fuel cell.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.ammoniaenergy.org/articles/review-of-ammonia-as-a-ci-fuel-published/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236204</guid>
            <pubDate>Fri, 21 Aug 2020 16:19:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How NAT Traversal Works]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24236010">thread link</a>) | @psanford
<br/>
August 21, 2020 | https://tailscale.com/blog/how-nat-traversal-works/ | <a href="https://web.archive.org/web/*/https://tailscale.com/blog/how-nat-traversal-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
<p>We covered a lot of ground in our post about <a href="https://tailscale.com/blog/how-tailscale-works/"><em>How Tailscale
Works</em></a>.  However, we glossed over how we can get through NATs
(Network Address Translators) and connect your devices directly to
each other, no matter what’s standing between them. Let’s talk about
that now!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-intro.png">
    
    
</figure>

<p>Let’s start with a simple problem: establishing a peer-to-peer
connection between two machines. In Tailscale’s case, we want to set
up a WireGuard® tunnel, but that doesn’t really matter. The
techniques we use are widely applicable and the work of many people
over decades. For example, <a href="https://webrtc.org/">WebRTC</a> uses this bag of tricks to
send peer-to-peer audio, video and data between web browsers. VoIP
phones and some video games use similar techniques, though not always
successfully.</p>
<p>We’ll be discussing these techniques generically, using Tailscale and
others for examples where appropriate. Let’s say you’re making your
own protocol and that you want NAT traversal. You need two things.</p>
<p>First, the protocol should be based on UDP. You <em>can</em> do NAT traversal
with TCP, but it adds another layer of complexity to an already quite
complex problem, and may even require kernel customizations depending
on how deep you want to go. We’re going to focus on UDP for the rest
of this article.</p>
<p>If you’re reaching for TCP because you want a stream-oriented
connection when the NAT traversal is done, consider using QUIC
instead. It builds on top of UDP, so we can focus on UDP for NAT
traversal and still have a nice stream protocol at the end.</p>
<p>Second, you need direct control over the network socket that’s sending
and receiving network packets. As a rule, you can’t take an existing
network library and make it traverse NATs, because you have to send
and receive extra packets that aren’t part of the “main” protocol
you’re trying to speak. Some protocols tightly integrate the NAT
traversal with the rest (e.g. WebRTC). But if you’re building your
own, it’s helpful to think of NAT traversal as a separate entity that
shares a socket with your main protocol. Both run in parallel, one
enabling the other.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-deep-integration.png">
    
    
</figure>

<p>Direct socket access may be tough depending on your situation. One
workaround is to run a local proxy. Your protocol speaks to this
proxy, and the proxy does both NAT traversal and relaying of your
packets to the peer. This layer of indirection lets you benefit from
NAT traversal without altering your original program.</p>
<p>With prerequisites out of the way, let’s go through NAT traversal from
first principles. Our goal is to get UDP packets flowing
bidirectionally between two devices, so that our other protocol
(WireGuard, QUIC, WebRTC, …) can do something cool. There are two
obstacles to having this Just Work: stateful firewalls and NAT
devices.</p>
<h3 id="figuring-out-firewalls">Figuring out firewalls</h3>
<p>Stateful firewalls are the simpler of our two problems. In fact, most
NAT devices include a stateful firewall, so we need to solve this
subset before we can tackle NATs.</p>
<p>There are many incarnations to consider. Some you might recognize are
the Windows Defender firewall, Ubuntu’s ufw (using iptables/nftables),
BSD’s pf (also used by macOS) and AWS’s Security Groups. They’re all
very configurable, but the most common configuration allows all
“outbound” connections and blocks all “inbound” connections. There
might be a few handpicked exceptions, such as allowing inbound SSH.</p>
<p>But connections and “direction” are a figment of the protocol
designer’s imagination. On the wire, every connection ends up being
bidirectional; it’s all individual packets flying back and forth. How
does the firewall know what’s inbound and what’s outbound?</p>
<p>That’s where the stateful part comes in. Stateful firewalls remember
what packets they’ve seen in the past and can use that knowledge when
deciding what to do with new packets that show up.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-1a.png">
    
    
</figure>

<p>For UDP, the rule is very simple: the firewall allows an inbound UDP
packet if it previously saw a matching outbound packet. For example,
if our laptop firewall sees a UDP packet leaving the laptop from
<code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, it’ll make a note that incoming
packets from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code> are also fine. The
trusted side of the world clearly intended to communicate with
<code>7.7.7.7:5678</code>, so we should let them talk back.</p>
<p>(As an aside, some <em>very</em> relaxed firewalls might allow traffic from
anywhere back to <code>2.2.2.2:1234</code> once <code>2.2.2.2:1234</code> has communicated
with anyone. Such firewalls make our traversal job easier, but are
increasingly rare.)</p>
<h4 id="firewall-face-off">Firewall face-off</h4>
<p>This rule for UDP traffic is only a minor problem for us, as long as
all the firewalls on the path are “facing” the same way. That’s
usually the case when you’re communicating with a server on the
internet. Our only constraint is that the machine that’s <em>behind</em> the
firewall(s) must be the one initiating all connections. Nothing can
talk to it, unless it talks first.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-2.png">
    
    
</figure>

<p>This is fine, but not very interesting: we’ve reinvented client/server
communication, where the server makes itself easily reachable to
clients. In the VPN world, this leads to a hub-and-spoke topology: the
hub has no firewalls blocking access to it and the firewalled spokes
connect to the hub.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-3.png">
    
    
</figure>

<p>The problems start when two of our “clients” want to talk
directly. Now the firewalls are facing each other. According to the
rule we established above, this means both sides must go first, but
also that neither can go first, because the other side has to go
first!</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-4.png">
    
    
</figure>

<p>How do we get around this? One way would be to require users to
reconfigure one or both of the firewalls to “open a port” and allow
the other machine’s traffic. This is not very user friendly. It also
doesn’t scale to mesh networks like Tailscale, in which we expect the
peers to be moving around the internet with some regularity. And, of
course, in many cases you don’t have control over the firewalls: you
can’t reconfigure the router in your favorite coffee shop, or at the
airport. (At least, hopefully not!)</p>
<p>We need another option. One that doesn’t involve reconfiguring
firewalls.</p>
<h4 id="finessing-finicky-firewalls">Finessing finicky firewalls</h4>
<p>The trick is to carefully read the rule we established for our
stateful firewalls. For UDP, the rule is: <strong>packets must flow out
before packets can flow back in.</strong></p>
<p>However, nothing says the packets must be <em>related</em> to each other
beyond the IPs and ports lining up correctly. As long as <em>some</em> packet
flowed outwards with the right source and destination, any packet that
<em>looks like</em> a response will be allowed back in, even if the other
side never received your packet!</p>
<p>So, to traverse these multiple stateful firewalls, we need to share
some information to get underway: the peers have to know in advance
the <code>ip:port</code> their counterpart is using. One approach is to
statically configure each peer by hand, but this approach doesn’t
scale very far. To move beyond that, we built a <a href="https://tailscale.com/blog/how-tailscale-works/#the-control-plane-key-exchange-and-coordination">coordination
server</a> to keep the <code>ip:port</code> information synchronized in a
flexible, secure manner.</p>
<p>Then, the peers start sending UDP packets to each other. They must
expect some of these packets to get lost, so they can’t carry any
precious information unless you’re prepared to retransmit them. This
is generally true of UDP, but especially true here. We’re <em>going</em> to
lose some packets in this process.</p>
<p>Our laptop and workstation are now listening on fixed ports, so that
they both know exactly what <code>ip:port</code> to talk to. Let’s take a look at
what happens.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5a.png">
    
    
</figure>

<p>The laptop’s first packet, from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, goes
through the Windows Defender firewall and out to the internet. The
corporate firewall on the other end blocks the packet, since it has no
record of <code>7.7.7.7:5678</code> ever talking to <code>2.2.2.2:1234</code>. However,
Windows Defender now remembers that it should expect and allow
responses from <code>7.7.7.7:5678</code> to <code>2.2.2.2:1234</code>.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5b.png">
    
    
</figure>

<p>Next, the workstation’s first packet from <code>7.7.7.7:5678</code> to
<code>2.2.2.2:1234</code> goes through the corporate firewall and across the
internet. When it arrives at the laptop, Windows Defender thinks “ah,
a response to that outbound request I saw”, and lets the packet
through! Additionally, the corporate firewall now remembers that it
should expect responses from <code>2.2.2.2:1234</code> to <code>7.7.7.7:5678</code>, and
that those packets are also okay.</p>
<p>Encouraged by the receipt of a packet from the workstation, the laptop
sends another packet back. It goes through the Windows Defender
firewall, through the corporate firewall (because it’s a “response” to
a previously sent packet), and arrives at the workstation.</p>
<figure>
    
        <img src="https://tailscale.com/blog/how-nat-traversal-works/nat-firewalls-5c.png">
    
    
</figure>

<p>Success! We’ve established two-way communication through a pair of
firewalls that, at first glance, would have prevented it.</p>
<h4 id="creative-connectivity-caveats">Creative connectivity caveats</h4>
<p>It’s not always so easy. We’re relying on some indirect influence over
third-party systems, which requires careful handling. What do we need
to keep in mind when managing firewall-traversing connections?</p>
<p>Both endpoints must attempt communication at roughly the same time, so
that all the intermediate firewalls open up while both peers are still
around. One approach is to have the peers retry continuously, but this
is wasteful. Wouldn’t it be better if both peers knew to start
establishing a connection at the same time?</p>
<p>This may sound a little recursive: to communicate, first you need to
be able to communicate. However, this preexisting “side channel”
doesn’t need to be very fancy: it can have a few seconds of latency,
and only needs to deliver a few thousand bytes in total, so a tiny VM
can easily be a matchmaker for thousands of machines.</p>
<p>In the distant past, I used XMPP chat messages as the side channel,
with great results. As another example, WebRTC requires you to come up
with your own “signalling channel” (a name that reveals WebRTC’s IP
telephony ancestry), and plug it into the WebRTC APIs. In Tailscale,
our coordination server and fleet of DERP (Detour Encrypted Routing
Protocol) servers act as …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tailscale.com/blog/how-nat-traversal-works/">https://tailscale.com/blog/how-nat-traversal-works/</a></em></p>]]>
            </description>
            <link>https://tailscale.com/blog/how-nat-traversal-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24236010</guid>
            <pubDate>Fri, 21 Aug 2020 16:04:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[But I was helping the compiler]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24235783">thread link</a>) | @aw1621107
<br/>
August 21, 2020 | https://pankajraghav.com/2020/08/16/RVO.html | <a href="https://web.archive.org/web/*/https://pankajraghav.com/2020/08/16/RVO.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Compilers are getting better with each release. Sometimes a noticeable difference can be observed in the assembly output for the same piece code in a different version of the same compiler (can be easily done via <a href="https://godbolt.org/">compiler explore</a>).</p>

<p>I have gotten into the practice of checking the assembly output lately to analyze the overhead of various implementations. Beware, sometimes it can get addictive. But I think it is a nice way of learning to read assembly and also be amazed at how clever the compilers are these days.</p>

<p>In this article, I am going to cover one such incident that happened when I was looking at the assembly output of a function during my <a href="https://github.com/Panky-codes/CHIP8">CHIP8</a> implementation.</p>

<p>But the context of the problem first!</p>

<h2 id="the-magic-of-move-semantics">The magic of move semantics</h2>
<p>Move semantics was introduced in C++11. We can think of move semantics as a way of transferring ownership of an object. If you are really new to move semantics, consider the following example:</p>

<p>So your colleague has a document that you also want. We have two options here. The first option, you take that document to a copier, take a copy of the document for yourself, and return the original document to your colleague. The second option, assuming your colleague doesn’t need the document anymore, instead of throwing it away, your colleague can give it to you, thereby, saving paper.</p>

<p>Replace the document with a memory resource in a program, then the first option is doing a copy, and the second option is doing a move, where you transfer the ownership instead of wasting the resource.</p>
<h2 id="putting-what-i-learned-in-action">Putting what I learned in action</h2>
<p>While implementing my <a href="https://github.com/Panky-codes/CHIP8">CHIP8</a> emulator, I saw an opportunity to replace an expensive copy operation into a cheap move operation (at least that is what I thought).</p>

<p>To give a bit of context: In each frame cycle, I had to return an array containing 2048 integers that will be used to draw the graphics on the screen. The pseudo-C++ code is shown below:</p>

<div><div><pre><code><span>// chip8.cpp</span>
<span>static</span> <span>constexpr</span> <span>display_size</span> <span>=</span> <span>2048</span><span>;</span>
<span>class</span> <span>Chip8</span> <span>{</span>
    <span>...</span> 
    <span>public</span> <span>:</span> 
        <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>uint8_t</span><span>,</span> <span>display_size</span><span>&gt;</span> <span>get_display_pixels</span><span>()</span> <span>{</span>
              <span>// Do some computation</span>
              <span>return</span> <span>gfx</span><span>;</span>
          <span>}</span>
    <span>...</span> 
    <span>private</span> <span>:</span> 
        <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>uint8_t</span><span>,</span> <span>display_size</span><span>&gt;</span> <span>gfx</span><span>{};</span>
<span>};</span>

<span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>

<p>This is what I assumed was going on when I did the call to <code>get_display_pixels()</code> member function:</p>
<ol>
  <li>The compiler <code>copies</code> the <code>gfx</code> private variable of the <code>Chip8</code> class to the return value of the <code>get_display_pixels()</code> member function.</li>
  <li>The compiler calls the <code>copy constructor</code> to copy the return value of the function call to the <code>disp_pixels</code> variable.</li>
</ol>

<p>So, I concluded that I could use a <code>move constructor</code> to transfer the contents to my local variable <code>disp_pixels</code> to avoid a copy in the second step as described above.</p>

<p>So I changed my code in the <code>main</code> function as follows:</p>
<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>std</span><span>::</span><span>move</span><span>(</span><span>emulator</span><span>.</span><span>get_display_pixels</span><span>());</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>

<p>Before you get furious and stop reading the article further because what I assumed was completely wrong, I realized that too, and the rest of the article is about that.</p>

<p>As soon as I used a <code>std::move</code> as shown in my previous code snippet, I observed the compiler was generating more assembly code than my initial code without a <code>std::move</code>(with std::move: <a href="https://godbolt.org/z/WulpDX">link</a>, without std::move: <a href="https://godbolt.org/z/oU8Tq4">link</a>).</p>

<p>What went wrong? Hmm….</p>
<h2 id="nrvo-to-the-rescue">NRVO to the rescue</h2>
<p>NRVO stands for Named Return Value Optimization. It is a nice trick that the compiler uses to omit unnecessary copy or move if certain conditions are met. Compilers have been using this trick for a long time. If <code>NRVO</code> takes place in our function call, then effectively we just do one copy instead of two. Let’s see how it works.</p>

<p>Even though the function signature of <code>get_display_pixels</code> indicates that it does not take any parameters, the compiler will pass one extra parameter behind the scenes from the caller (initialization call of <code>disp_pixels</code> from <code>main.cpp</code>) to the callee (<code>get_display_pixels</code> function in <code>chip8.cpp</code>). The caller will allocate the memory for the return value and pass the address of that memory to the callee. The callee will use that memory to construct the object and copy the value of the private variable <code>gfx</code> (in this case). As the memory of the caller (<code>disp_pixels</code>) was used by the callee, there is no need to copy the return value again, thereby, saving one unnecessary copy/move operation.</p>

<p>We should see the assembly output to really understand how <code>NRVO</code> is happening under the hood. The assembly code from the caller side is as follows:</p>
<div><div><pre><code><span>1</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>2</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>3</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>4</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>5</span>   <span>call</span> <span>Chip8</span><span>::</span><span>get_display_pixels</span><span>()</span>
</code></pre></div></div>
<p>Before the function call, <code>rsi</code> and <code>rdi</code> registers are loaded with upper and lower bound of the memory address of the <code>disp_pixels</code> variable. And, the trimmed assembly output from the callee side is as follows:</p>

<div><div><pre><code><span>1</span>   <span>Chip8</span><span>::</span><span>get_display_pixels</span><span>()</span><span>:</span>
<span>2</span>   <span>push</span> <span>rbp</span>
<span>3</span>   <span>mov</span>  <span>rbp</span><span>,</span> <span>rsp</span>
<span>4</span>   <span>mov</span>  <span>QWORD</span> <span>PTR</span> <span>[</span><span>rbp</span><span>-</span><span>8</span><span>],</span> <span>rdi</span>
<span>5</span>   <span>mov</span>  <span>QWORD</span> <span>PTR</span> <span>[</span><span>rbp</span><span>-</span><span>16</span><span>],</span> <span>rsi</span>
<span>...</span>
</code></pre></div></div>
<p>As seen from the callee side, the <code>rdi</code> and <code>rsi</code> values are moved to the stack, and further operations are performed with that memory address. Pretty neat!</p>

<p>A <code>simple analogy</code> for <code>NRVO</code> I like to think of is when you are asking a friend to fill in water inside a water bottle, you would give your bottle to fill water from the tap directly. It would be inefficient to first fill the water in a temporary bottle and transfer the contents again to your bottle. In the C++ context, <code>bottle</code> is the <code>memory space</code> and the <code>water</code> it holds is the <code>return value</code>.</p>

<p>If we assume that the  <code>NRVO</code> will take place, then the most efficient way of writing my function call is:</p>
<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>
<p>GCC and Clang even have an extra warning flag <code>-Wpessimizing-move</code> which detects when we are trying to use a <code>move</code> where compiler-generated NRVO is much more efficient.</p>

<p>Even though we can assume in many situations that a <code>NRVO</code> will take place, especially if optimizations are turned on, C++ standard does not guarantee <code>NRVO</code> in all situations<sup>1</sup>. But what if compiler does not perform a <code>NRVO</code>?</p>
<h2 id="lvalues-and-rvalues-and-all-other-value-categories-in-between">Lvalues and Rvalues (and all other value categories in between)</h2>
<p>Even though there are some <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p2025r0.html">proposals</a> to guarantee <code>NRVO</code>, it is not yet guaranteed by the standard. As it is not guaranteed, should we explicitly indicate a move operation to save a copy just in case the compiler doesn’t do a <code>NRVO</code>? To answer that, I added the flag <code>-fno-elide-constructors</code> that disables copy elision (the super-set of NRVO) in our code, thereby, allowing to see what the compiler does otherwise.</p>

<p>I was surprised to see that compiler was still performing a <code>NRVO</code> for <code>C++17</code> standard with <code>-fno-elide-constructors</code> enabled. But this was not the case for <code>C++14</code>, the compiler generated different assembly with <code>-fno-elide-constructors</code> enabled. If someone knows the reason why this difference occurs between <code>C++17</code> and <code>C++14</code> even though <code>NRVO</code> is not guaranteed, please email me about it. Godbolt <a href="https://godbolt.org/z/hPW3rh">link</a>.</p>

<p>Let’s use <code>C++14</code> with <code>-fno-elide-constructors</code> flag to simulate the scenario where the compiler fails to apply <code>NRVO</code> so that we can check whether we needed to do something extra to avoid superfluous copies.</p>

<p>So I added <code>-fno-elide-constructors</code> to disable any <code>NRVO</code> to the final code of the previous section. The caller generated the following assembly code:</p>

<div><div><pre><code><span>1</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>2</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>3</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>4</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>5</span>   <span>call</span> <span>Chip8</span><span>::</span><span>get_display</span><span>()</span>
<span>6</span>   <span>lea</span>  <span>rdx</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>8192</span><span>]</span>
<span>7</span>   <span>lea</span>  <span>rax</span><span>,</span> <span>[</span><span>rbp</span><span>-</span><span>16384</span><span>]</span>
<span>8</span>   <span>mov</span>  <span>rsi</span><span>,</span> <span>rdx</span>
<span>9</span>   <span>mov</span>  <span>rdi</span><span>,</span> <span>rax</span>
<span>10</span>  <span>call</span> <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>unsigned</span> <span>char</span><span>,</span> <span>32ul</span><span>&gt;::</span><span>array</span><span>(</span><span>std</span><span>::</span><span>array</span><span>&lt;</span><span>unsigned</span> <span>char</span><span>,</span> <span>32ul</span><span>&gt;&amp;&amp;</span><span>)</span>
</code></pre></div></div>

<p>As we can notice, the first 5 assembly instructions are the same as the version with NRVO enabled, and there are 5 more assembly instructions in this version as we disabled NRVO. The most important instruction we need to focus on is line number 10 where a <code>move constructor</code>(notice <code>&amp;&amp;</code> in the function signature). Wait, a <code>move constructor</code> is invoked? I did not use a <code>std::move</code> but the compiler decided to do it anyway. To really comprehend the reason, we need to understand <code>value categories</code> in C++.</p>

<p>In these two articles: <a href="https://eli.thegreenplace.net/2011/12/15/understanding-lvalues-and-rvalues-in-c-and-c">Understanding lvalues and rvalues in C and C++ </a> and <a href="http://eel.is/c++draft/basic.lval#1">basic.lval#1</a>, value categories are explained in detail<sup>2</sup>. In brief, quoting from the first article: “An lvalue (locator value) represents an object that occupies some identifiable location in memory. Rvalue is an expression that does not represent an object occupying some identifiable location in memory.”. Of course, there are more categories than just a <code>lvalue</code> and a <code>rvalue</code>. I would highly recommend reading both articles. Though you don’t need a perfect grasp of them to understand what comes later in this article. Let’s get back to our original example and analyze why the move constructor was called.</p>

<div><div><pre><code><span>// main.cpp</span>
<span>while</span> <span>(</span><span>displayOn</span><span>)</span> <span>{</span>
    <span>...</span> 
    <span>const</span> <span>auto</span> <span>disp_pixels</span> <span>=</span> <span>emulator</span><span>.</span><span>get_display_pixels</span><span>();</span>
    <span>...</span>
    <span>// Use disp_pixels to draw pixels on the screen</span>
<span>}</span>
</code></pre></div></div>
<p>In the above code snippet, the function call to <code>get_display_pixels</code> belongs to the <code>rvalue</code> (more precisely a <code>prvalue</code>) category and it generates a temporary. The compiler can now safely <code>move</code> that temporary into the <code>disp_pixels</code> variable because that temporary will be destroyed anyway after this statement. If the type that is being returned does not have a move constructor (in our case <code>std::array</code> has a move constructor), then the compiler will call the <code>copy constructor</code>.</p>

<p>In principle, if any of the <code>moveable</code> types (standard or user-defined) is returned from a function by <code>value</code>, we can safely assume either <code>NRVO</code> or <code>move operation</code> will take place resulting in no superfluous copies for standard compilers that support <code>C++11</code> and above.</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pankajraghav.com/2020/08/16/RVO.html">https://pankajraghav.com/2020/08/16/RVO.html</a></em></p>]]>
            </description>
            <link>https://pankajraghav.com/2020/08/16/RVO.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24235783</guid>
            <pubDate>Fri, 21 Aug 2020 15:41:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Dab detector – Pose recognition to detect when you dab]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24235391">thread link</a>) | @guimcaballero
<br/>
August 21, 2020 | https://caballerocoll.com/experiments/dab-detector/ | <a href="https://web.archive.org/web/*/https://caballerocoll.com/experiments/dab-detector/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><strong>Disclaimer:</strong> Don’t dab if you have epilepsy.</p>
<h2 id="dab-detector">Dab detector</h2>
<p>This is a simple experiment playing around with <a href="https://ml5js.org/" rel="nofollow noopener noreferrer" target="_blank">ml5.js</a>. It uses the PoseNet model to recognize when you <a href="https://en.wikipedia.org/wiki/Dab_(dance)" rel="nofollow noopener noreferrer" target="_blank">dab</a> and shows you a little surprise when you do.</p>
<p>To use it, make sure you are in a well <span title="💯😂👌💯">lit</span> environment, accept the camera use request, and stand up so that your whole body shows in the image.</p>
<h2 id="how-does-it-work">How does it work?</h2>
<p>It uses PoseNet, a ml5 model for Real-time Human Pose Estimation. With the data provided by the model, it preforms a really simple check to see if the pose should count as a Dab. It works by checking if the right hand is close to the left ear, and the angles of the elbows are above or under a specified threshold. Vice-versa for the left side. This is a very naive approach, and it wasn’t what I originally intended to do, but after implementing this as a prototype, I realized it worked much better than expected. You can see the function used in the code below, called <code>isPoseADab()</code>.</p>
<p>My plan was to train a simple categorization model using ml5, so it’s a bit of a shame that it doesn’t now. I intend to make some other experiment that does use that feature.</p>
<p>The video, skeleton and emojis are drawn using the <a href="https://p5js.org/" rel="nofollow noopener noreferrer" target="_blank">p5.js</a> rendering library, which works really well next to ml5.</p>
<h2 id="why">Why?</h2>
<p>Uuuhhh... Because my sense of humor got stuck a couple years ago and I non-ironically think this is funny. </p>
<p>In all seriousness, because I wanted to try something with pose recognition, and the first pose that came to mind that was interesting was a Dab.</p></div></div>]]>
            </description>
            <link>https://caballerocoll.com/experiments/dab-detector/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24235391</guid>
            <pubDate>Fri, 21 Aug 2020 14:54:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[France, UE, Covid, democracry and the research of complete stupidity]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24234839">thread link</a>) | @polote
<br/>
August 21, 2020 | https://blog.luap.info/france-ue-covid-democracry-and-the-research-of-complete-stupidity.html?hn3 | <a href="https://web.archive.org/web/*/https://blog.luap.info/france-ue-covid-democracry-and-the-research-of-complete-stupidity.html?hn3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>Everything about France work system can be understood reading one sentence : In France it is legally impossible to fire an employee who doesn't want to leave. </p>
<p>This is something I've never understood, how can we think that an employee possesses his job ? An employee is working for a salary and benefits, that's all, the rest belongs to the company, which belongs to its investors.</p>
<p>France is a touristic country which doesn't grow anymore. It is not doing worst than <a href="https://data.worldbank.org/indicator/NY.GDP.PCAP.KD.ZG?end=2019&amp;locations=FR-GB-DE-US&amp;start=1961&amp;view=chart">neighbour countries</a> but this can't be an excuse. The youngest company of the CAC40 (40 biggest companies in france) was <a href="https://twitter.com/paulg/status/650702144186662914?lang=en">founded in 1967</a>. Building a company there is tough, there are a lot of taxes (paying an 1$ to an employee requires the company to pay one other dollar to the government). The work system is outdated, people can't be fired, the work legislation is more complex (3000 pages) than building a fusion reactor. Founders are limited and will either try to sell their company as soon as it is a bit successfull or move their headquarter in the US. The EU is not a unified market, every country has its own legislation, culture, language, ... And at the end if you are successfull there will be millions of people try to explain to you that you should not be rich.</p>
<p>But the problem is not only the system, the people are also the problem (the system is the people and the people are the system I know). France political system is an oligarchy hidden behind that everyone can vote. But a country can't be smarter than its own population. France as a country doesn't have any goal, people are living in the country complaining all the time about everything, there is no wish to progress or to help people, the only goal is to preserve its own privilege. Rich people make friends with politic people to preserve their advantages, poor people try to work less, profit from employment benefits and complain about everything else. People in the middle live together and use their money to balance the failing of the {school,retiring} systems. As a result the whole system is stuck.</p>
<p>Our school system is shit, it is designed for already priviledged students to be successfull and for poor people to fail. Because, of course it is easier to educate already educated people and tell to others that it is their fault if they do not succeed.  Our retiring system is complete garbage, nobody understand how 25M people working can pay for 14M people not working, and for french people it is normal to retire at 62 years old, this is normal because it has always been like that, so why change ? But thanks to debt our country is not fucked. It is always easier to borrow money than to earn it so why bother ?</p>
<p>Our 'democracies' are not working, you can't accept that all opinions are equals, you would not choose your CEO by making everyone in the company vote. The covid crisis is a good example showing that a democracy can't handle important crisi. Everyone has become an epidemiologist, anyone knows what is a good traitment, anyone knows how to protect himself, anyone is able to read a scientific study and make its own conclusion. The more follower you have the smarter epidemiologist you are. China suggested to do a lockdown, well lets do a lockdown, some tv host suggested that we wear mask ? Well lets wear mask. Masks doesn't prevent the virus to spread ? then lets make the mask mandatory, student are going to be in class touching each other, exchanging pens and papers ? well let's take the most stupid decision ever and madate them to wear a mask? When everyone has an opinion and this opinion has to be taken seriously the opinion of no one has any value. Democracy seems to be the worst politic system when you want to achieve best performance.</p>
<p>We are trying to reach the maximum level of stupidity and everybody seems to be fine with it.</p>
<h2>How to fix that ?</h2>
<p>On the short term this is impossible, you can't change the mentality of people in the short term, you can't educate greater than 25 years old people, you can't change the work system in a few years. The only thing that can save us is education. Educate your children, force them to go to school to do their homework, tell them that they will be able to become software engineers if they study and start working with a better salary than 90% of the population. Vote for people who care about education, and vote for people who will try to improve education of unpriviledege people, the smarter 'the most stupid' people are, the smarter the country is going to be. Don't vote for a president, this is useless, they are all the same and complete garbage, the system is not designed for a competent person to be elected. Fortunately climate change is coming and is going to kill most of the population, that way the few people who will be there (if any ) to rebuilt the world will be able to make better foundations. If you want to live a pleasant life, ignore the rules, the laws, the governements and focus on doing good around you, educate your children, help the cleaning lady, dont give your money to your children when you die, give it to charity, dont take any time caring about politics dont go voting for someone linked to a party, vote for motivated people who wants to make things change.... Try to think with your brain and stop listening to what media tell you</p>
<p>Not everything is bad, look at the US and appreciate how lucky we are</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/france-ue-covid-democracry-and-the-research-of-complete-stupidity.html?hn3</link>
            <guid isPermaLink="false">hacker-news-small-sites-24234839</guid>
            <pubDate>Fri, 21 Aug 2020 13:48:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Splitgraph Data Delivery Network – query over 40k public datasets]]>
            </title>
            <description>
<![CDATA[
Score 288 | Comments 91 (<a href="https://news.ycombinator.com/item?id=24233948">thread link</a>) | @mildbyte
<br/>
August 21, 2020 | https://www.splitgraph.com/blog/data-delivery-network-launch | <a href="https://web.archive.org/web/*/https://www.splitgraph.com/blog/data-delivery-network-launch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><article><div><nav><ol><li><a href="#usage" as="#usage">Usage</a><ol><li><a href="#connecting" as="#connecting">Connecting</a></li><li><a href="#workspaces" as="#workspaces">Workspaces</a></li><li><a href="#running-queries" as="#running-queries">Running queries</a></li></ol></li><li><a href="#behind-the-scenes" as="#behind-the-scenes">Behind the scenes</a></li><li><a href="#future-and-roadmap" as="#future-and-roadmap">Future and roadmap</a></li><li><a href="#conclusion" as="#conclusion">Conclusion</a></li></ol></nav><p>Today, we are announcing the next step for Splitgraph: the <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect"><strong>Splitgraph Data Delivery Network</strong></a>.</p><p>The Splitgraph DDN is a single SQL endpoint that lets you query over 40,000 public datasets hosted on or proxied by Splitgraph.</p><p>You can connect to it from most PostgreSQL clients and BI tools <strong>without having to install anything else</strong>. It supports all read-only SQL constructs, including filters and aggregations. It even lets you run joins across distinct datasets.</p><p>In this post, we will give you a quick introduction to the DDN as well as discuss how it works behind the scenes and our plan for its future.</p><section><h3 id="usage">Usage</h3><section><h4 id="connecting">Connecting</h4><p>The endpoint is at <code>postgresql://data.splitgraph.com:5432/ddn</code>. You will need a Splitgraph API key and secret to access it.</p><p>You don't need to install anything to use the endpoint. If you go to your Splitgraph <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">account settings</a>, you can generate a pair of credentials. You can then plug them into your SQL client.</p><p>If you're already using the <a href="https://www.splitgraph.com/docs/architecture/sgr-client"><code>sgr</code> client</a> and had registered for Splitgraph before, you can check your <code>.sgconfig</code> file for the API keys. You can also upgrade your client to version 0.2.0 with <code>sgr upgrade</code> and run <code>sgr cloud sql</code> to get a libpq-compatible connection string.</p><p><a href="https://www.splitgraph.com/docs/getting-started/installation">Installing Splitgraph locally</a> will let you snapshot these datasets and use them in <a href="https://www.splitgraph.com/docs/concepts/splitfiles">Splitfiles</a>.</p><p>There are more setup methods available in <a href="https://www.splitgraph.com/docs/splitgraph-cloud/data-delivery-network">our documentation</a>. This includes connecting to Splitgraph with clients like DBeaver, BI tools like Metabase or Google Data Studio or even other databases through ODBC.</p></section><section><h4 id="workspaces">Workspaces</h4><p>When you connect to Splitgraph, your SQL client will show you some schemas. These are data repositories featured on our <a href="https://www.splitgraph.com/explore">explore page</a> as well as datasets that you upload to Splitgraph.</p><p>We call this feature "workspaces". It works by implementing the <a href="https://en.wikipedia.org/wiki/Information_schema" as="https://en.wikipedia.org/wiki/Information_schema">ANSI information schema</a> standard. We'll expand on workspaces more in the future. For example, we'll let you:</p><ul><li>bookmark repositories that you want to show up in your workspace</li><li>allow you to have multiple workspaces and manage access to them</li><li>search for Splitgraph repositories directly from your SQL client.</li></ul></section><section><h4 id="running-queries">Running queries</h4><p>You can run queries on Splitgraph images by referencing them as PostgreSQL schemata: <code>namespace/repository[:hash_or_tag]</code>. By default, we query the <code>latest</code> tag.</p><p>For example, if you want to query the <a href="https://www.splitgraph.com/cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc" as="https://www.splitgraph.com/cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"><code>cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc</code> repository</a>, proxied by Splitgraph to <a href="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-and-Deaths/naz8-j4nc" as="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-and-Deaths/naz8-j4nc">Socrata</a>, you can run:</p><pre><code metastring=""><span>SELECT</span> <span>*</span> <span>FROM</span>
    <span>"cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"</span><span>.</span>covid19_daily_cases_deaths_and_hospitalizations
</code></pre><p>We let you use SQL <code>SELECT</code> and <code>EXPLAIN</code> statements. You can use any SQL clauses, including group-bys, aggregations, filters and joins. Splitgraph pushes filters down to the origin data source.</p><p>This sample query that we used in our <a href="https://www.splitgraph.com/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals" as="/docs/ingesting-data/socrata#using-metabase-to-join-and-plot-data-from-multiple-data-portals">Metabase demo</a> runs a JOIN between two datasets:</p><pre><code metastring=""><span>SELECT</span>
    cambridge_cases<span>.</span><span>date</span> <span>AS</span> <span>date</span><span>,</span>
    chicago_cases<span>.</span>cases_total <span>AS</span> chicago_daily_cases<span>,</span>
    cambridge_cases<span>.</span>new_positive_cases <span>AS</span> cambridge_daily_cases
<span>FROM</span>
    <span>"cityofchicago/covid19-daily-cases-deaths-and-hospitalizations-naz8-j4nc"</span><span>.</span>covid19_daily_cases_deaths_and_hospitalizations chicago_cases
<span>FULL</span> <span>OUTER</span> <span>JOIN</span>
    <span>"cambridgema-gov/covid19-cumulative-cases-by-date-tdt9-vq5y"</span><span>.</span>covid19_cumulative_cases_by_date cambridge_cases
<span>ON</span>
    date_trunc<span>(</span><span>'day'</span><span>,</span> chicago_cases<span>.</span>lab_report_date<span>)</span> <span>=</span> cambridge_cases<span>.</span><span>date</span>
<span>ORDER</span> <span>BY</span> <span>date</span> <span>ASC</span><span>;</span>
</code></pre><p>This will join the data between two distinct Socrata data portals (<a href="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-Deaths-and-Hospitalizations/naz8-j4nc" as="https://data.cityofchicago.org/Health-Human-Services/COVID-19-Daily-Cases-Deaths-and-Hospitalizations/naz8-j4nc">Chicago, IL</a> and <a href="https://data.cambridgema.gov/Public-Safety/COVID-19-Cumulative-Cases-by-Date/tdt9-vq5y" as="https://data.cambridgema.gov/Public-Safety/COVID-19-Cumulative-Cases-by-Date/tdt9-vq5y">Cambridge, MA</a>).</p><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0900_splitgraph-cloud/images/sql-endpoint/2-dbeaver-join.png" alt="Splitgraph SQL endpoint JOIN query example"></p><p>We also support <a href="https://postgis.net/" as="https://postgis.net/">PostGIS</a>, letting you query and visualize geospatial data. For example, you can query the <a href="https://www.splitgraph.com/splitgraph/london_wards/" as="https://www.splitgraph.com/splitgraph/london_wards/">London ward boundary data</a> image as follows:</p><pre><code metastring=""><span>SELECT</span>
    name<span>,</span>
    gss_code<span>,</span>
    
    ST_Transform<span>(</span>ST_SetSRID<span>(</span>geom<span>,</span> <span>27700</span><span>)</span><span>,</span> <span>4326</span><span>)</span><span>,</span>
    
    ST_Area<span>(</span>ST_Transform<span>(</span>ST_SetSRID<span>(</span>geom<span>,</span> <span>27700</span><span>)</span><span>,</span> <span>3035</span><span>)</span><span>)</span> <span>/</span> <span>1000000</span> <span>AS</span> area_sqkm
<span>FROM</span>
    <span>"splitgraph/london_wards"</span><span>.</span>city_merged_2018
<span>ORDER</span> <span>BY</span> gss_code <span>ASC</span><span>;</span>
</code></pre><p><img src="https://raw.githubusercontent.com/splitgraph/splitgraph.com/master/content/docs/0900_splitgraph-cloud/images/sql-endpoint/3-dbeaver-geodata.png" alt="PostGIS data on Splitgraph DDN"></p><p>There are more sample queries on our <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">Connect page</a>.</p></section></section><section><h3 id="behind-the-scenes">Behind the scenes</h3><p>The Splitgraph Data Delivery Network is the result of all the work we've put into the <a href="https://www.splitgraph.com/docs/architecture/sgr-client"><code>sgr</code> client</a> and the <a href="https://github.com/splitgraph/splitgraph" as="https://github.com/splitgraph/splitgraph">Splitgraph Core</a> code over the past two years.</p><p>It would also have not been possible without some other open source technologies.</p><p>We use PostgreSQL foreign data wrappers. They let us perform query execution and planning across federated data sources. We wrote about <a href="https://www.splitgraph.com/blog/foreign-data-wrappers">foreign data wrappers</a> before: they're powerful and underused!</p><p>We manage connections using a fork of <a href="https://www.pgbouncer.org/" as="https://www.pgbouncer.org">pgBouncer</a>, a PostgreSQL connection pooler. Our fork lets us perform authentication outside of PostgreSQL. We can issue and revoke API keys without having to manipulate database roles. Several inbound Splitgraph users can run queries as a single PostgreSQL user.</p><p>We also use pgBouncer to transform queries on the fly. We rewrite clients' introspection queries and let them reference Splitgraph images as PostgreSQL schemata.</p><p>Each client essentially operates within its own isolated virtual database. The obvious implementation of this would be spinning up one database per client. But our query transformations let us do this at a <strong>much lower infrastructure cost</strong>. We also use this feature to inspect and drop unwanted queries on the fly.</p><p>Finally, we use our own <code>sgr</code> client to orchestrate this. Splitgraph engines power the data delivery network. They manage foreign data wrapper instantiation and querying Splitgraph images via <a href="https://www.splitgraph.com/docs/large-datasets/layered-querying">layered querying</a>. In the future, we will use Splitgraph's <a href="https://www.splitgraph.com/docs/concepts/objects">storage format</a> to snapshot remote datasets or cache frequent queries.</p></section><section><h3 id="future-and-roadmap">Future and roadmap</h3><p>There are a lot of directions we would like to pursue with Splitgraph.</p><p>You will be able to use Splitgraph to <strong>replace some of your data lake or ETL pipelines</strong> and query the data at source. This is similar to the idea of "data virtualization". But, unlike other software in this space, Splitgraph uses an open PostgreSQL procotol. This makes it immediately compatible with most of your BI tools and dashboards. It won't lock you into a proprietary query language.</p><p>We will soon have the ability to add <a href="https://www.splitgraph.com/docs/splitgraph-cloud/external-repositories">external repositories</a> to public or on-premises Splitgraph data catalogs. You will be able to query any dataset indexed in this catalog over the single SQL endpoint or our <a href="https://www.splitgraph.com/docs/splitgraph-cloud/publish-rest-api">REST API</a>. You will be able to even use these datasets in <a href="https://www.splitgraph.com/concepts/splitfiles">Splitfiles</a>. This will let you define reproducible transformations on your data, enrich it with public datasets and track lineage.</p><p>You will be able to use Splitgraph as an <strong>SQL firewall and a rewrite layer</strong>. You won't need to use views to set up access policies for your data warehouse. Data consumers won't need to manage credentials to disjoint data silos. Splitgraph can inspect proxied queries and enforce granular access policies on individual columns. It will even be able to do PII masking and access auditing.</p><p>The single SQL endpoint is well suited for a <strong>data marketplace</strong>. Data vendors currently ship data in CSV files or other ad-hoc formats. They have to maintain pages of instructions on ingesting this data. With Splitgraph, data consumers will be able to acquire and interact with data directly from their applications and clients.</p></section><section><h3 id="conclusion">Conclusion</h3><p>Today, we launched the Splitgraph Data Delivery Network. It's a seamless experience of a single database with thousands of datasets at your fingertips, compatible with most existing clients and BI tools.</p><p>If you wish to try it out, you can get credentials to access it in less than a minute: just head on to the <a href="https://www.splitgraph.com/connect" as="https://www.splitgraph.com/connect">landing page</a>.</p><p>We're also building towards a <a href="https://www.splitgraph.com/about/company/private-cloud-beta">"Splitgraph Private Cloud" product</a> that will let setup your own private Splitgraph cluster, managed by us and deployed to the cloud region of your choice. <a href="mailto:support@splitgraph.com" as="mailto:support@splitgraph.com">Contact us</a> if you're interested!</p></section></div></article></section></div>]]>
            </description>
            <link>https://www.splitgraph.com/blog/data-delivery-network-launch</link>
            <guid isPermaLink="false">hacker-news-small-sites-24233948</guid>
            <pubDate>Fri, 21 Aug 2020 11:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product-led Growth]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24233859">thread link</a>) | @yakkomajuri
<br/>
August 21, 2020 | https://posthog.com/blog/product-led-growth | <a href="https://web.archive.org/web/*/https://posthog.com/blog/product-led-growth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!-- ![PLG Banner](../images/plg-header.png) -->
<p>You will need sales, but do you need a sales team to achieve revenue?</p>
<p>Let's say you are the founder of a new tech startup.&nbsp;</p>
<p>A few months back, you and a couple of friends (all developers) built an amazing tool and have now received Seed funding.&nbsp;</p>
<p>As a result, you're under some pressure to grow. You took a few million from some VCs here and there, and they want to see some results.</p>
<p>Since the realization of needing to grow hit you, you've started to lose some sleep.&nbsp;</p>
<p>Before, you were just a group of friends working your ass off to build an amazing product, with some revenue coming in from your immediate network. Now you actually have to focus on ramping up your sales.</p>
<p>You call in a founders meeting to discuss next steps, and a conclusion is reached: you can't spend all your budget on engineers, which is what you wanted to do.&nbsp;</p>
<p>Instead, you need to hire some Sales people. Or some Marketing people. Or both. Whoever can get you some users that pay for your product. Or do you? Could you invest in engineering instead to drive more revenue, and perhaps building a better company along the way?</p>
<h2 id="getting-people-to-pay-you"><a href="#getting-people-to-pay-you" aria-label="getting people to pay you permalink"></a>Getting People to Pay&nbsp;You</h2>
<p>VC funding or not, all startups will eventually need to get paid for what they do.&nbsp;</p>
<p>Irrespective of how cool your idea is, or how helpful it may be, if you're not getting money in, you can't push it forward.&nbsp;
You need customers.</p>
<p>Traditionally, there are two ways to do this: sales and marketing. They are not mutually exclusive, but one strategy or the other generally takes the lead in generating growth.  To understand them, it's helpful to refer to a funnel:</p>
<p><span>
      <a href="https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/c211c/hogflix-funnel.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="HogFlix Example Funnel" title="HogFlix Example Funnel" src="https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/fcda8/hogflix-funnel.png" srcset="https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/12f09/hogflix-funnel.png 148w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/e4a3f/hogflix-funnel.png 295w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/fcda8/hogflix-funnel.png 590w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/efc66/hogflix-funnel.png 885w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/c83ae/hogflix-funnel.png 1180w,
https://posthog.com/static/9eb858a4ac5b01f3c783e295f0444fe1/c211c/hogflix-funnel.png 1502w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<h3 id="marketing-led-growth-"><a href="#marketing-led-growth-" aria-label="marketing led growth  permalink"></a>Marketing-led Growth&nbsp;📈</h3>
<p>The goal of marketing is to increase the number of people going through the funnel. </p>
<p>The idea is to make your business be seen. But not just that - it's also about being seen by the right people and seen in a positive light.</p>
<p>This involves a wide variety of aspects, from branding, to social media, and, of course, ads. If this is done well, the customer should come to you, so you won't need to go after them.</p>
<h3 id="sales-led-growth-🤝"><a href="#sales-led-growth-%F0%9F%A4%9D" aria-label="sales led growth 🤝 permalink"></a>Sales-led Growth&nbsp;🤝</h3>
<p>Sales, on the other hand, is about improving the conversion between steps of the funnel. </p>
<p>In some ways, it is the opposite of Marketing, as you will often go after the customer, rather than try to make them come to you. This can be done in a variety of ways, from cold calls to leveraging leads.&nbsp;</p>
<p>Essentially, the assumption is that there are people out there who are willing to pay for your product, so you need to do your best to find them and get them to pay you.</p>
<h2 id="the-underrated-alternative"><a href="#the-underrated-alternative" aria-label="the underrated alternative permalink"></a>The Underrated Alternative</h2>
<p>There are various benefits to Sales-led and Marketing-led growth strategies, and they are still widely used today.&nbsp;</p>
<p>However, a new approach has been gaining traction in the past few years, called Product-led Growth (PLG).</p>
<h3 id="let-your-product-do-the-talking"><a href="#let-your-product-do-the-talking" aria-label="let your product do the talking permalink"></a>Let your product do the&nbsp;talking</h3>
<p>With Product-led Growth, the idea is that rather than bringing users through an active sales team or aggressive marketing campaigns, you just focus on building your product - and ensure you make it great.</p>
<p>The concept is based on the assumption that if you build something that is useful and works well, the users will eventually come to you as result... with a little push, of course.</p>
<p>As such, your primary objective should be to make something truly amazing, rather than portray your product as amazing (which is what great Sales and Marketing people can do).</p>
<p>Now, following a PLG approach does not substitute having a Sales or Marketing team. It just means growth is <em>led</em> by the product, and the other teams in the organization operate in alignment with this methodology. </p>
<p>Additionally, operating a B2B company without a Sales team does become impractical at a large scale. We would know, since our founders used to close software sales deals in the seven figures.</p>
<h2 id="the-key-is-in-the-dna"><a href="#the-key-is-in-the-dna" aria-label="the key is in the dna permalink"></a>The Key is in the&nbsp;DNA</h2>
<p>While this "strategy" sounds more like common sense than a methodical approach, there's more to Product-led growth than meets the eye.</p>
<p>To truly succeed as a business that drives growth primarily through its product, this concept needs to be built into the company culture.</p>
<p>While Sales and Marketing can often work well as segregated teams that draw from the product but operate independently in practice, focusing on building a product is an organization-wide effort.</p>
<p>As <a href="https://www.productled.org/foundations/what-is-product-led-growth">PLGC</a> put it, different teams often operate in different wavelengths, but with Product-Led Growth, you need everyone to converge into one single wavelength: user experience.&nbsp;</p>
<p>At PostHog, we follow a Product-led Growth approach. And we'll tell you, this has implications for all areas of the company:</p>
<h3 id="sales"><a href="#sales" aria-label="sales permalink"></a>Sales</h3>
<p>Don't make a sale if your product is not a good fit for the customer.&nbsp;</p>
<p>From the first paragraph of <a href="https://posthog.com/handbook/growth/sales">PostHog's Handbook Sales page</a>:</p>
<blockquote>
<p>Always focus on delivering what the customer needs. Sometimes that will mean sending them to a competitor or turning them&nbsp;down.</p>
</blockquote>
<p>Yes, this is literally an official guideline for doing Sales at PostHog.</p>
<h3 id="team"><a href="#team" aria-label="team permalink"></a>Team</h3>
<p>If you're a software company, PLG might mean opting for more Engineers than Sales people, for instance. In our case, we still don't have a single person doing Sales or Marketing exclusively. Almost our entire team is made up of Engineers, including people not working day-to-day on our codebase.&nbsp;</p>
<p>More than with other approaches, you also need to make sure your hires are individuals who understand and are passionate about the product, as well as are proactive in making it better.&nbsp;</p>
<p>Your Sales people shouldn't cut corners to close a deal, and the Marketing team should focus on highlighting the product you built.</p>
<h3 id="communication"><a href="#communication" aria-label="communication permalink"></a>Communication</h3>
<p>Listen to your users on everything.</p>
<p>Built something? Get feedback. New idea? Get feedback. Launched a release? Get feedback.</p>
<p>As one of our <a href="https://twitter.com/mariusandra">core devs</a> put it following interviews with users about a new feature he built: "Your assumptions are mostly wrong. Talk to people to correct them".</p>
<p>When generating growth primarily through Sales or Marketing, the segregation between the people who are building the product and those selling it can lead to diversion between what users want and what is being offered to them.</p>
<p>When focusing on the product, you should always be touching base with your users, and be willing to drop features you love if they don't feel the same way.</p>
<h3 id="priorities"><a href="#priorities" aria-label="priorities permalink"></a>Priorities</h3>
<p>At PostHog, our methodology is:</p>
<blockquote>
<p>If we keep our team first and users second, then our investors will take care of themselves!</p>
</blockquote>
<p>Users are key and should be a top priority.</p>
<p>However, you must remember that your team consists of the first users of your product, its main advocates, and its builders!&nbsp;</p>
<p>Hence, since users are a priority, and the team takes care of the users, you need to take care of your team!</p>
<h3 id="growth"><a href="#growth" aria-label="growth permalink"></a>Growth</h3>
<p>Since you're not aggressively seeking out users with Product-Led Growth, you are likely to experience slower growth at first.&nbsp;
Later on, however, if you did truly build something great, you may benefit from a network effect that skyrockets your userbase.&nbsp;</p>
<p>Facebook and Slack are great examples of this.&nbsp;</p>
<table>
<thead>
<tr>
<th><span>
      <a href="https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/d56b5/facebook-stock.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Facebook Stock Price" title="Facebook Stock Price" src="https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/fcda8/facebook-stock.png" srcset="https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/12f09/facebook-stock.png 148w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/e4a3f/facebook-stock.png 295w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/fcda8/facebook-stock.png 590w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/efc66/facebook-stock.png 885w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/c83ae/facebook-stock.png 1180w,
https://posthog.com/static/5af23dc0fcb6241bc4469deb48ef0a9c/d56b5/facebook-stock.png 1215w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></th>
</tr>
</thead>
<tbody>
<tr>
<td><center> Facebook (FB) Stock Price - Source: <a href="https://finance.yahoo.com/chart/FB">Yahoo Finance</a></center></td>
</tr>
</tbody>
</table>
<p>Facebook, in fact, actually grew fast early on, while following a primarily PLG approach. This goes on to show that it is possible
to grow fast despite following a Product-led Growth approach, or, perhaps even because of it. When you're an industry disruptor, your product speaks for itself, since it is something new, rather than an improvement on something that already exists. As such, your product can potentially drive your growth even if you don't explicitly follow a PLG strategy.</p>
<p>Tesla is another example of a company that lets its disruptive product do the talking. They reportedly spend a <a href="https://www.forbes.com/sites/johnkoetsier/2019/05/06/tesla-spends-zero-on-ads-heres-where-bmw-toyota-ford-and-porsche-spend-digital-ad-dollars/#4a574ec911d4">whopping 0$ on advertising</a>, yet have a brand that is known worldwide, and a <a href="https://finance.yahoo.com/quote/TSLA/">stock price that seems to just keep on rising</a>. </p>
<h3 id="revenue"><a href="#revenue" aria-label="revenue permalink"></a>Revenue&nbsp;</h3>
<p>Since the initial focus is on building a product rather than selling it, you will likely make less money in the short-run.</p>
<p>With the goal not being to hit a Sales metric, you might be turning down opportunities to generate revenue if they are not perfectly aligned with what you're building.</p>
<p>As such, you need to make sure your team and investors are aligned with this. It should be understood that <a href="https://posthog.com/blog/raising-3m-for-os">it's okay to not be making money in the early stages</a>.</p>
<h2 id="one-size-doesnt-fit-all"><a href="#one-size-doesnt-fit-all" aria-label="one size doesnt fit all permalink"></a>One Size Doesn't Fit&nbsp;All</h2>
<p>Product-Led Growth is not a magic pill. It does have its shortcomings.</p>
<p>Primarily, how can you let your product speak for itself if you can't get anyone to look at it in the first place?</p>
<p>But rather than tell you when Product-led Growth might not work, let's explore some aspects that may be beneficial to it.</p>
<h3 id="funding"><a href="#funding" aria-label="funding permalink"></a>Funding</h3>
<p>It's much easier to focus almost exclusively on building a product when you're already well-funded. This is our case at PostHog.</p>
<p>To build a great product, you need a great team. And to build a great team, you need money.&nbsp;</p>
<p>Thus, if you're a company without a lot of money in the bank, you might just need to get some Sales done now, simply to fund your operations.</p>
<p>Not having funding shouldn't discourage you from trying a PLG approach, however. It can still work, just look at GitLab. They first raised money after already having 100,000 users and Sid (their CEO) <a href="https://posthog.com/blog/a-chat-with-sid">told us</a> they didn't even have a significant marketing budget until then. Wow.</p>
<h3 id="open-source-software"><a href="#open-source-software" aria-label="open source software permalink"></a>Open Source&nbsp;Software</h3>
<p>Being open source is a great characteristic for companies looking to follow a PLG approach.&nbsp;</p>
<p>This is because you can get users excited not only about the usability of your product, but also how it's built.</p>
<p>Additionally, open source software projects by default encourage community participation, since anyone is able to suggest a change, raise an issue, or even contribute code.&nbsp;</p>
<p>As such, you are more involved with your users and can gain better insight into how people feel about your product.</p>
<h3 id="breadth-of-experience"><a href="#breadth-of-experience" aria-label="breadth of experience permalink"></a>Breadth of Experience</h3>
<p>With regards to professional experience, depth refers to extensive experience in a specific field, whereas breadth can be seen as experience across fields.</p>
<p>Depth of experience is an essential characteristic of a world-class team. However, having some focus on breadth can also be beneficial. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://posthog.com/blog/product-led-growth">https://posthog.com/blog/product-led-growth</a></em></p>]]>
            </description>
            <link>https://posthog.com/blog/product-led-growth</link>
            <guid isPermaLink="false">hacker-news-small-sites-24233859</guid>
            <pubDate>Fri, 21 Aug 2020 11:07:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Development of Warajevo: ZX Spectrum Emulator Made During the Bosnian War]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24233770">thread link</a>) | @krige
<br/>
August 21, 2020 | https://worldofspectrum.net/features/warajevo/Story.html | <a href="https://web.archive.org/web/*/https://worldofspectrum.net/features/warajevo/Story.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div face="Arial" size="3">
<hr><center><div>
<center><span color="#FFFFFF" size="+1"><b>(HI)STORY ABOUT DEVELOPING OF WARAJEVO</b></span></center>
</div></center><hr>
<span size="-1"><center>Best viewed in 800x600 resolution!</center></span>

<p>
Maybe this program is not too interesting in itself, but it is a fact
that this program comes from Bosnia and Herzegovina, from the city of
Sarajevo which has been surrounded for more than three years (click at the
picture below to learn more about surrounded Sarajevo). After reading this
story, you will understand why this emulator has such strange
name "Warajevo"...
</p>
<center><a href="http://www.saray.net/SurvivalMap/Index.html">
<img src="https://worldofspectrum.net/features/warajevo/surrmap.jpg" alt="Sarajevo Survival Map">
</a></center>
<p>
Even in our secondary school days, about ten years before, we began to build an
interest in computers thanks to the ZX Spectrum. For this reason, we are a
bit sentimentally tied with this computer. This computer reminds us of all of
the times when, in our neighbourhoods, the life was nice and normal.
</p>
<center><a href="http://www.geocities.com/SunsetStrip/2280/olympic.html">
<img src="https://worldofspectrum.net/features/warajevo/olimp.jpg" alt="Sarajevo before war">
</a></center>
<center>
<span size="-2">
Sarajevo, in time of 14th Winter olympic games (1984)
<br>
Panorama from the air, with olympic mountains in the background
</span>
</center>
<p>
When we bought AT 286 computers at the end of 1990, we did not forget our
Spectrums however. We had great interest when, in June 1991, we got a
Spectrum emulator, which, without underestimating anybody's work, had very
bad characteristics (it was slow, quite incompatible with the original
machine, with unpractical emulation of the tape recorder etc.). It's origin
is unknown to us (we suppose, in according to some newspapers, that the program
is from the Slovenia Republic, and that the author is Peter Kroselj), and when
starting it displays the copyright message '(C) 1991. Roman &amp; easy inc.'. When
the war started in our country, we wanted to remove the dark thoughts from our
heads as much as possible. So, in April 1993, we started the development of our
Spectrum emulator, symbolically called 'Warajevo Spectrum emulator' which should
have much better characteristics. We should mention that we were known as quite
good programmers, especially in assembly language.
</p>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/loris.jpg" alt="Loris building">
</a>
<br>
<center>
<span size="-2">
Loris building - the first front line
<br>
(1 km far from Zeljko's house)
</span>
</center>
</td>
<td>
The program was developed in horrible conditions. The grenades fell
everywhere, there was little electrical power (at one time even the
hospitals didn't have power for two months!). When we had electricity it was
only for 2-3 hours during the night. However, we did not quit and caught
every moment when the electricity was on to develop the program. Zeljko worked at
home on his 80286/12 MHz, 1.44" floppy, 40 Mb hard disc, Hercules card and Citizen
180D printer. He used TASM assembler. It was very interesting waiting for days of
electricity. Samir worked mainly in army camp barack on 80286/16 MHz, 5,25" + 1.44"
floppy, 2400 bps modem, VGA mono monitor, WITHOUT HARD DISC because it crashed. The power
generator in the army camp was an improvised generator, with a voltage that varied from
150 V to 300 V! It was in fact car engine without carburator, connected to natural gas
pipeline. This car engine was tied with shunted electromotor giving about 30 kW for
100 rooms.
</td></tr>
</tbody></table>
<p>
It was often situation that when one user switch caffe aparat on, Samir's
computer resets itself. UPS? What is this??? As you can expect, such 'stable' voltage
distroyed Samir's hard disc...
</p>
<center>

</center>

<p>
Zeljko's task was mainly writting of the emulator kernel, and Samir's task was to write
conversion and tape file utilities. So, he used Turbo Pascal 5.5. First version of such
utility was called ZXTOOLS, and existed up to release 1.5. In this situation, we decided
that our tape file format will be compressed, as we had not enough diskettes, nor we
belived that we will ever have money for puchasing bigger hard disc.
</p>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/vijecnica_detail.jpg" alt="Vijecnica inside - detail">
</a>
<center><span size="-2">
City hall inside - detail
</span></center>
</td><td>
As Zeljko has real Spectrum 128, we made cable for transfering Spectrum software using
RS232. During times when we was free of army activities, Samir visited the last Spectrum
software pirate in Sarajevo and borrowed casettes. But, this pirate was located in one
of the most dangerous places in the city, practically on the first front line. He had to
use a river bed (instead of streets) for moving, to skip continous sniper's fire. So, Samir
risked his life to bring up Spectrum software! Later he transfered programs using RS232,
mainly in the army camp.
</td></tr></tbody></table>
<p>
The summer of 1993 was the worst period during the whole Bosnian war, 1 kg of sugar had
price of even 60 DM, and about 3000-4000 grenades fall every day on the town. This was a
period when only miracle saved Sarajevo of fall. However, we progressed very well...
</p>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/vijecnica_burning.jpg" alt="Burning Vijecnica">
</a>
<span size="-2"><center>
Burning city hall
</center></span>
</td><td>
Zeljko catched every second of presence of electrical power to finish the emulator
kernel, and Samir hed not even leave the army building during this period. While he
waited for a new battle tasks, he developed the compression algorythm. He spent more
than 30 days in developing algorythm, analysing of some archivers, optimizing
compression speed (it is still slow, but acceptable), and he worked mostly on paper,
because it was days mainly without any electric power, water and food.
Keep in mind that in this period we lost about 1 kg weekly!
<br>
</td></tr></tbody></table>
<br>
<center>

</center>
<p>
In November 1993, reading some newspapers that came from the enemy's territory, we got
some information about the emulator 'Z80', written by Gerton Lunter. The fact that we
didn't hear about Lunter's 'Z80' earlier is a fortune for today Warajevo users, because we
very probably would not even start this project if we have had information that a good
quality Spectrum emulator already exists. But, in even worse winter conditions,
we continued the development (in the rooms where we slept the water was frozen), hoping to
get this emulator to compare our program and his program.
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/tram_inside.jpg" alt="Tram inside">
</a>
<br>
<center>
<span size="-2">
Inside of a distroyed tramway
</span>
</center>
</td><td>
In 1994, one Samir's friend who worked with him in the army put his own hard disc
(40M) into the computer , and Samir developed ZXSHELL (the database program for the
emulator written in Clipper). In April 1994, the foundation Sorosh opened the first
electronic mail in Sarajevo. We sent a general request and in June 1994, we got
Lunter's emulator. From documentation we got information about many Spectrum emulators
around Europe, but we thought that our program was surely better than all the others,
except maybe Lunter's program. We think that it is a great success, considering the
conditions where the program was developed and the quality of Gerton's program. When
we contacted Gerton, he had the same opinion about it.
</td></tr></tbody></table>
</p><p>
The first public release of the Warajevo emulator was sent to the world at end of
1994 (release 1.0). Other releases made during war was 1.1 (March 1995), and 1.11
(May 1995). This was just a bugfixes of release 1.1 with slight improvements.
<br>
</p><center>

</center>
<p>
Dayton peace came (November 1995), and we was released from army. Release 1.2 was
prepared for uploading. It was 1.1 with a new design of utility ZXTOOLS. This release
was finished in December 1995. But, Samir decided to improve the emulator to be his
<a href="https://worldofspectrum.net/features/warajevo/diplom.zip">graduate thesis</a>
(Zeljko already finished study, he graduated in January 1995), and he
puchased 486SX-33 board, 4 Mb of RAM and 400 Mb hard disc. Zeljko continued development
on his old 286 machine, but Samir had now enough power to compile programs using extended
memory and we released version 1.5 (in July 1996) after Samir's graduating and getting
job. In this release, utilities ZXTOOLS and ZXSHELL are not separate tools. Instead, they
are integrated into the environment of the emulator.
</p>
<center>

</center>
<table>
<tbody><tr><td>
<a href="http://www.saray.net/Sarajevo">
<img src="https://worldofspectrum.net/features/warajevo/katedrala.jpg" alt="Cathedral">
</a>
<br>
<center>
<span size="-2">
Sarajevo cathedral
<br>
(rebuilded after the war)
</span>
</center>
</td><td>
Release 2.0 was developed in much better conditions. The war is finished, but the
economical situation is terrible. Our payments was under 50 DM. However, Zeljko
succeed to purchase faster computer, and he finally had goal to develop accurate speed
version of the Warajevo kernel. So, we worked on Pentium 133 MHz/1.2 Gb disc and Pentium
100 MHz/1.6 Gb hard disc, both
with 16 Mb of RAM, Sound Blaster cards and VGA graphic card (this is mainly our today
configuration too). First real-time release of Warajevo, release 2.0, was uploaded in
February 1998. As you can see, Warajevo 2.0 is
uploaded after a long delay (about nearly 1.5 year) from previous release. This is mainly consequence of
adaptation to post-war conditions. Finishing of the war brings a lot of new problems
which took a lot of our time, so developing of the emulator was stopped for a while...
</td></tr></tbody></table>
<p>
The last release of Warajevo is currently Warajevo 2.51. Recently, a number of new
emulators have appeared. Some of them are very good, especially X128 by James McKay,
and there are a number of emulators for the Windows platform (we want to point out ZX32
by Vaggelis Kapartzianis and MultiMachine by Paul Hodgson). However, we still think that
Warajevo 2.51. is the best emulator for pure DOS. We want to tell you that
the Warajevo emulator still does not have a good emulation of the video
system like in the ZX32 emulator (although it is much better than in release
2.0. which was a considerable improvment itself over release 1.5.), perfect
emulation of the bits 3 and 5 in the F register, emulation of the disc
interfaces, Multiface 128, AMX mouse, full emulation of the RS232 socket or
emulation of the Spectrum +3, which are supported in some other emulators.
However, we want to emphasize that Warajevo still has a lot of features which make it
unique. For more details see:
</p>
<p>
<a href="https://worldofspectrum.net/features/warajevo/Features.html">Features of the Warajevo emulator</a>
</p>
<p>
Well, what do you think, after this story, about today MS Windows programs that
require 100 Mb for relative simple task??? Obviously, the Spectrum times were the
best computer times. Nowadays, for playing a game in a PC you need a Pentium 200 MHz,
32 Mb of RAM and a fast graphic card. If you haven't got these requirements, you can`t
play the game. But, with the Spectrum everything was quite different. The Spectrum
wasn't upgradeable and the programmers had to make big efforts to develope a very good
game. And the games were also cheaper than the PC ones...
</p><center>

</center>
<center>

</center>
Between April 1995 and December 1997 we received E-MAIL messages from 28 countries, from
all 6 continents (Argentina, Australia, Austria, Canada, Czech, …</div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://worldofspectrum.net/features/warajevo/Story.html">https://worldofspectrum.net/features/warajevo/Story.html</a></em></p>]]>
            </description>
            <link>https://worldofspectrum.net/features/warajevo/Story.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24233770</guid>
            <pubDate>Fri, 21 Aug 2020 10:50:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Memory Fragmentation in Haskell]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24232809">thread link</a>) | @tirumaraiselvan
<br/>
August 21, 2020 | https://www.well-typed.com/blog/2020/08/memory-fragmentation/ | <a href="https://web.archive.org/web/*/https://www.well-typed.com/blog/2020/08/memory-fragmentation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
          <p>Recently I’ve done a bit of work for <a href="https://hasura.io/">Hasura</a>, investigating some strange memory behavior in <a href="https://github.com/hasura/graphql-engine">graphql-engine</a>. When measuring memory usage, we can ask the operating system (OS) how much memory our process is using, but we can also use the GHC runtime system’s (RTS) heap profiler. After running a <code>graphql-engine</code> benchmark, the server’s memory usage reported by the OS was much higher than the “heap residency” reported by GHC’s heap profiler. This led us down a bit of a rabbit hole of understanding memory allocation and memory fragmentation in programs compiled with GHC.</p>
<p>In this blog post, we look at memory fragmentation in the Haskell heap and how it arises. We look at how fragmentation affects the discrepancy between heap residency reported by the RTS and memory usage reported by the OS. In particular, we focus on a pathological case of a program that makes use of pinned data and transitions from high heap residency to relatively low heap residency.</p>
<!-- more -->
<h3 id="memory-metrics">Memory Metrics</h3>
<p>On Linux there are multiple ways to measure memory usage of a process, but the one we’ll focus on is <em>virtual memory resident set size</em>, <code>VmRSS</code>. This can be sampled from <code>/proc/&lt;PID&gt;/status</code> where <code>&lt;PID&gt;</code> is a process ID. We won’t get into the details of this, but suffice it to say that we consider <code>VmRSS</code> the “true” memory usage of our Haskell program.</p>
<p><em>Heap residency</em> is a measurement taken by the runtime system’s heap profiler. It measures the size of all <em>live</em> data on the Haskell heap. <code>VmRSS</code> is always higher than heap residency. The reason is that heap residency is only a measure of <em>live</em> data on the Haskell heap while <code>VmRSS</code> is “all inclusive”. <a href="https://downloads.haskell.org/~ghc/8.10.2/docs/html/users_guide/profiling.html#actual-memory-residency">The GHC user’s guide</a> gives the following reasons for a higher <code>VmRSS</code>:</p>
<ol type="1">
<li>Overhead due to a profiled build. Each heap object uses an extra 2 words that are usually not counted in the heap profile.</li>
<li>Garbage collection. The copying collector (i.e.&nbsp;the default collector) makes a copy of all live unpinned data causing a peak in memory usage.</li>
<li>Thread stacks are not counted in the heap profile by default. Profiling with the <code>-xt</code> runtime system option includes stacks in the profile.</li>
<li>The program text itself, the C stack, any “non-heap” data (e.g.&nbsp;data allocated by foreign libraries and data allocated by the RTS itself), and <code>mmap()</code>‘d memory are not counted in the heap profile.</li>
</ol>
<p>In the following section is an example program which we focus on for this blog post. We’ll dive into the details shortly, but this program exhibits much higher <code>VmRss</code> than heap residency, so let’s consider why this might be:</p>
<ul>
<li><p>We’re not using a profiled build, so point 1 does not apply.</p></li>
<li><p>In general, stack usage can be significant and you should profile with <code>-xt</code> to diagnose this. The example program has negligible stack size, so point 3 also doesn’t apply.</p></li>
<li><p>The runtime system (RTS) is written in C and has it’s own stack and non-heap data, but this is negligible compared to the large amount of data we’re allocating on the Haskell heap. The program text is small and we’re also not calling any foreign code nor <code>mmap()</code>’ing any memory, so point 4 doesn’t apply.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a></p></li>
</ul>
<p>That leaves point 2 which is certainly applicable, but there is another reason that the above list does not mention: fragmentation.</p>
<p>Another metric from the RTS is the <em>heap size</em>. Heap size is an all inclusive metric of the Haskell heap. It includes fragmentation. <code>VmRSS</code> and heap size are about equal in our example program.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> Comparing <code>VmRSS</code> and heap size is a good way to check if the memory usage is truly in the Haskell heap or if there are other issues as listed in point 4.</p>
<h4 id="kilobyte-vs-kibibyte">Kilobyte vs Kibibyte</h4>
<p>As we’re closely counting bytes, we should make clear the awkward situation that memory is sometimes reported in base 10 units (e.g.&nbsp;kilobyte (kB) = 1000 bytes) and sometimes in base 2 units (e.g.&nbsp;kibibyte (KiB) = 1024 bytes). To make it worse, the “i” used in the symbols for base 2 units (e.g.&nbsp;“KiB”) is often omitted so they look just like the base 10 counterpart (e.g.&nbsp;“KB”). Confusingly, <code>/proc/&lt;PID&gt;/status</code> says “kB” but means “KiB”. The <code>eventlog2html</code> output says “G”, “M”, and “K” but means “GB”, “MB”, “kB”. The debugging output from the <code>-Dg</code> RTS option prints “MB” but means “MiB.”<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<p>With the exception of the heap profile graphs (generated with <code>eventlog2html</code>), all numbers in the blog post will be in base 2: gibibyte (GiB) = 1024 MiB, mebibyte (MiB) = 1024 KiB, and kibibyte (KiB) = 1024 bytes.</p>
<h3 id="example">Example</h3>
<p>Let’s consider the following application that allocates a list of <code>ByteString</code>s and then retains a smaller 1/10th subset of them:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a><span>-- Main.hs</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span>{-# LANGUAGE BangPatterns #-}</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span>{-# OPTIONS_GHC -Wall #-}</span></span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span>import</span> <span>Control.Concurrent</span> (threadDelay)</span>
<span id="cb1-6"><a href="#cb1-6"></a><span>import</span> <span>Control.DeepSeq</span> (force)</span>
<span id="cb1-7"><a href="#cb1-7"></a><span>import</span> <span>Control.Monad</span> (forM_)</span>
<span id="cb1-8"><a href="#cb1-8"></a><span>import</span> <span>qualified</span> <span>Data.ByteString</span> <span>as</span> <span>BS</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span>import</span> <span>System.Mem</span> (performGC)</span>
<span id="cb1-10"><a href="#cb1-10"></a><span>import</span> <span>System.Environment</span> (getArgs)</span>
<span id="cb1-11"><a href="#cb1-11"></a></span>
<span id="cb1-12"><a href="#cb1-12"></a><span>main ::</span> <span>IO</span> ()</span>
<span id="cb1-13"><a href="#cb1-13"></a>main <span>=</span> <span>do</span></span>
<span id="cb1-14"><a href="#cb1-14"></a>  n <span>&lt;-</span> <span>read</span> <span>.</span> <span>head</span> <span>&lt;$&gt;</span> getArgs</span>
<span id="cb1-15"><a href="#cb1-15"></a></span>
<span id="cb1-16"><a href="#cb1-16"></a>  <span>-- Allocate lots of ByteStrings (ByteStrings are backed with pinned data)</span></span>
<span id="cb1-17"><a href="#cb1-17"></a>  <span>let</span> <span>!</span>superset <span>=</span> force <span>$</span> <span>take</span> n [BS.singleton x <span>|</span> x <span>&lt;-</span> <span>cycle</span> [<span>minBound</span><span>..</span><span>maxBound</span>]]</span>
<span id="cb1-18"><a href="#cb1-18"></a>  <span>putStrLn</span> <span>"1st Plateau start"</span></span>
<span id="cb1-19"><a href="#cb1-19"></a>  spin <span>3</span></span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a>  <span>-- Extract only a small subset of the superset and allow superset to be</span></span>
<span id="cb1-22"><a href="#cb1-22"></a>  <span>-- garbage collected. Specifically retain every 10th element.</span></span>
<span id="cb1-23"><a href="#cb1-23"></a>  <span>let</span> subsetFactor <span>=</span> <span>10</span><span> ::</span> <span>Int</span></span>
<span id="cb1-24"><a href="#cb1-24"></a>  <span>let</span> <span>!</span>subset <span>=</span> force <span>$</span> [x <span>|</span> (x, <span>1</span>) <span>&lt;-</span> <span>zip</span> superset (<span>cycle</span> [<span>1</span><span>..</span>subsetFactor])]</span>
<span id="cb1-25"><a href="#cb1-25"></a>  <span>putStrLn</span> <span>"2nd Plateau start"</span></span>
<span id="cb1-26"><a href="#cb1-26"></a>  spin (<span>3</span> <span>*</span> subsetFactor)</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a>  <span>-- Stop `subset` from being garbage collected by using it here.</span></span>
<span id="cb1-29"><a href="#cb1-29"></a>  <span>print</span> (<span>length</span> subset)</span>
<span id="cb1-30"><a href="#cb1-30"></a></span>
<span id="cb1-31"><a href="#cb1-31"></a><span>-- Spin and allow heap profiler to collect samples.</span></span>
<span id="cb1-32"><a href="#cb1-32"></a><span>spin ::</span> <span>Int</span> <span>-&gt;</span> <span>IO</span> ()</span>
<span id="cb1-33"><a href="#cb1-33"></a>spin i <span>=</span> forM_ [<span>1</span><span>..</span>i] (\_ <span>-&gt;</span> threadDelay <span>1</span> <span>&gt;&gt;</span> performGC)</span></code></pre></div>
<p>Compile with <code>ghc -rtsopts -eventlog -debug Main.hs</code> and run with <code>./Main 10000000 +RTS -s -Dg -hT -l --disable-delayed-os-memory-return -RTS</code>. The <code>-hT -l</code> options produce an eventlog with a memory profile that we can be visualized with <code>eventlog2html</code>. The <code>-Dg</code> option prints garbage collector statistics to standard error. The <code>--disable-delayed-os-memory-return</code> option is explained later.</p>
<p>Consider what we expect when running a heap profile. The program should allocate some memory then spin a bit. Next, <code>superset</code> is garbage collected and we’re left with <code>subset</code>. We expect heap residency to drop to 1/10 of the size. After spinning for some more time the program will exit. That’s what we expect. Here is what the heap profile shows:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/prof-heap-strip.svg"></p>
<p>The majority of memory is <code>PS</code>, <code>ARR_WORDS</code>, <code>:</code>, and <code>PlainPtr</code>. These are the type constructors found in a list of <code>ByteString</code>. <code>PS</code> is the <code>ByteString</code> constructor and <code>PlainPtr</code> and <code>ARR_WORDS</code> are internal to <code>ByteString</code>. We see that allocating <code>superset</code> results in about 1.04GiB (1.12GB) of heap residency corresponding to the first plateau in the heap profile between 27 and 39 seconds. After this, we take 1/10 of that data, <code>subset</code>, and allow the rest of <code>superset</code> to be garbage collected. Hence, we expect the heap residency to drop to about 1/10 of the size, 0.10GiB (0.11GB), but this is not what the profile shows! Heap residency decreases only to about 0.37GiB (0.4GB) and all of <code>ARR_WORDS</code> is unexpectedly retained.</p>
<p>This is not some subtle mistake in the code causing <code>ARR_WORDS</code> to be retained. This is in fact due to how the RTS handles pinned memory. Let’s look at the memory residency reported by the operating system. I sampled the <code>VmRSS</code> reported in <code>/proc/&lt;pid&gt;/status</code> every 0.01 seconds:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/prof-vmrss-strip.svg"></p>
<p>The <code>VmRSS</code> has some discrepancies with the heap profile. The OS is reporting about 1.84GiB of memory at the first plateau. That’s almost 1.8 times more than the heap profile. In synch with the heap profile, between 40 and 61 seconds, there is a second plateau where <code>VmRSS</code> is about 1.5GiB. That’s about 4 times more than the heap profile. So not only is the <code>VmRSS</code> significantly higher than heap residency on the first plateau, but the discrepancy is much worse on the second plateau.</p>
<h3 id="the-heap">The Heap</h3>
<p>In order to make sense of the memory profile we need to understand the structure of GHC’s Haskell heap, how allocation works, and a bit about garbage collection. I’ll give a simplified overview of this. In particular I’m ignoring megablock/block groups, block descriptors, and am only considering the oldest garbage collector generation. I’m also assuming that the default copying garbage collector is in use.</p>
<h4 id="megablocks-blocks-and-objects">Megablocks, Blocks, and Objects</h4>
<p>The Haskell heap is made up of 1MiB “megablocks”. Within those are 4KiB “blocks”. Within those blocks are the actual data objects. Blocks are designated as exclusively containing either pinned or unpinned data. Here is an example of what the heap might look like in virtual memory space:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/heap-legend.png"> <img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/heap-example.png"></p>
<p>This is not to scale. In reality a megablock contains many more blocks, a block typically contains many more objects, and objects can vary in size. Notice that megablocks are not necessarily contiguous within virtual memory space. We call the unused gaps between megablocks “megablock level fragmentation”:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/megablock-level-frag.png"></p>
<p>Likewise the unused gaps between blocks within megablocks is called “block level fragmentation”:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/block-level-frag.png"></p>
<p>Dead objects within blocks are called “object level fragmentation”:</p>
<p><img src="https://www.well-typed.com/blog/aux/images/memory-fragmentation/object-level-frag.png"></p>
<p>Note that some blocks have some unused space at the end because we have yet to add objects there or there was not enough space to add an object so the RTS allocated a new block instead. That extra space is called “slop” and we don’t count this as object level fragmentation. We mostly ignore slop for this post.</p>
<h4 id="pinned-data">Pinned Data</h4>
<p>What is pinned data? Thanks to referential transparency, the memory address of an object in Haskell is usually not important. This permits the RTS’s default copying garbage collector to move objects around in memory i.e.&nbsp;changing their memory location. In practice, we may want a chunk of memory that won’t be moved by the RTS. The most obvious example is when passing data to foreign code. The foreign code won’t be very happy if the RTS suddenly moves that data. As such, GHC supports the notion of “pinned” data which can be allocated via <code>GHC.Exts.newPinnedByteArray#</code> and similar variants. Pinned data is guaranteed not to be moved by the RTS. We refer to all other data as “unpinned”. …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.well-typed.com/blog/2020/08/memory-fragmentation/">https://www.well-typed.com/blog/2020/08/memory-fragmentation/</a></em></p>]]>
            </description>
            <link>https://www.well-typed.com/blog/2020/08/memory-fragmentation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232809</guid>
            <pubDate>Fri, 21 Aug 2020 07:21:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ReMarkable MicroSD (2019)]]>
            </title>
            <description>
<![CDATA[
Score 363 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24232801">thread link</a>) | @devnonymous
<br/>
August 21, 2020 | http://www.davisr.me/projects/remarkable-microsd/ | <a href="https://web.archive.org/web/*/http://www.davisr.me/projects/remarkable-microsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <p>This page discusses how I added a microSD card to my <a href="https://arstechnica.com/gadgets/2017/12/remarkable-tablet-review-the-high-price-of-getting-that-paper-feeling/">reMarkable tablet</a>. I did this because I want to develop software for my rM without wearing out the internal eMMC. I chose an external card because I want to be able to swap them easily; it also makes backups faster.<br>
</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/34.jpg" alt="Opened reMarkable tablet">




<h2><a name="opening">Opening the Case</a></h2>
<p>
The aluminum back panel is held to the plastic case with glue. I have 
not yet determined what melts this glue, or how to “properly” take the 
back off. I was able to lift it off, by starting slowly in a corner. 
Thereafter, I used a putty knife to slowly peel it away. The panel bent,
 but I was able to bend it mostly-flat again.
</p><p>
Next, there is a magnesium chassis screwed to the plastic case. 
Underneath the rubber feet are six silver screws. There are also XX 
black screws, that must be removed.
</p><p>
The epaper display is glued to the magnesium chassis; don’t try to pull 
it apart. There is also a white silicone-like substance around the edge 
of the epaper panel, which seems to disintegrate and flake off. I think 
it fills the gap, and perhaps offers a little waterproofing. This is 
non-replaceable. The screen can be pushed apart from the plastic 
chassis. It is held on the perimeter with plastic latches, so split it 
with a spudger and go slowly.
</p><p>
With the case off, the guts can be removed. There are five connectors to
 the logic board. In clockwise order starting at top-left: power button,
 touch panel, antenna, epaper display, USB daughterboard and buttons, 
and Wacom digitizer.
</p><p>
Finally, the logic board can be removed. It is held with six small 
screws and washers. Underneath the logic board is a plastic tape, a 
section of which must be removed around the SD pads.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/mmc-pads.jpg" alt="MMC solder pads">

<h2>
<a name="positioning">Positioning the Card</a>
</h2>
<p>
The bottom-right seemed like an appropriate placement for the card 
socket, because the area is already spacious. The right side was easier 
to route the cables to, because of the channels cut in the white plastic
 case. I reassembled the reMarkable 
prior to soldering, to ensure no bulges or deformities appered.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/placement.JPG" alt="Placing the microSD slot in the lower right corner">

<h2>
<a name="soldering">Soldering the Wires</a>
</h2>
<p>
Using ten 30 AWG wires and plenty of flux, I connected the board to the 
socket. The board indicates which pin is first. The board has a ninth 
pin, which is used for card-detect. This gets pulled low when a card is 
inserted.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/flatcable.JPG" alt="Wires underneath logic board">
<p>
To keep things as flat as possible, I used cellophane tape to mate the 
wires to the board. They feed out beneath the digitizer’s FFC cable in 
one beautiful ribbon. This also prevents elecrical contact to the grounded chassis.<br>
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/wires.JPG" alt="Wires on back">

<h2>
<a name="cutting">Cutting the Case</a>
</h2>
<p>
I drilled the SD slot by-hand with a rotary tool. Starting with a carving bit
 on the inside, I first hollowed out the area to give me a thin veneer, 
measured with a flashlight. Once I felt it was thin enough, I drilled 
from the front with a pointy sanding bit, and cut longitudinally.</p><p>
The magnesium chassis had a small section removed, which was easy with a
 tiny wire cutter. While it sacrifices a little
 bit of strength, it makes up for it in storage capacity.
</p><p>
After testing the fit once again, I fillited epoxy around the edge 
of the socket, gluing it down. I was careful not to get any inside the 
socket.
</p>

<img src="http://www.davisr.me/projects/remarkable-microsd/externalshot.JPG" alt="microSD slot from the outside">

<h2>
<a name="loading">Loading the Kernel</a>
</h2>
<p>The stock rM kernel doesn't enable the SDHC1 slot, which is how these
 pins are designated in the device tree file. I recommend first being 
comforable with <a href="https://github.com/torwag/remarkableflash">this remarkable-flash guide</a>, the <a href="http://www.davisr.me/projects/remarkable-microsd/i.MX_BSP_Porting_Guide_Linux.pdf">NXP porting guide for the i.MX6 processor</a>, and the <a href="http://www.davisr.me/projects/remarkable-microsd/i.MX_Yocto_Project_User%27s_Guide_Linux.pdf">i.MX Yocto user guide</a>.<br>

</p>
  <p>The rM is a mostly-vanilla i.MX6 board (many share similaries, including the <a href="http://www.davisr.me/projects/remarkable-microsd/pico-imx6ul-emmc-hobbit-reva1-hardware-manual-20160328.pdf">Hobbitboard</a>).
 As such, it shares the same SDHC interface. What the microSD slot 
connects to, and what the stock kernel does not activate, is the SDHC1 
interface. This can be enabled in the device tree, and the kernel may be
 recompiled to include support for an SD card.<br>
  </p>
<p>
By default, the sdhc1 interface is disabled in the device tree. Enabling
 this is the first step. Copy the 
<code>arch/arm/boot/dts/zero-gravitas-factory.dts</code> over 
<code>arch/arm/boot/dts/zero-gravitas.dts</code>. Then, edit it to enable the sdhc1 
interface like shown in the diff below.
</p>
<pre> &amp;usdhc1 {<br>        pinctrl-names = "default", "state_100mhz", "state_200mhz";<br>        pinctrl-0 = &lt;&amp;pinctrl_usdhc1&gt;;<br>        pinctrl-1 = &lt;&amp;pinctrl_usdhc1_100mhz&gt;;<br>        pinctrl-2 = &lt;&amp;pinctrl_usdhc1_200mhz&gt;;<br>        bus-width = &lt;4&gt;;<br>        cd-gpios = &lt;&amp;gpio4 7 GPIO_ACTIVE_LOW&gt;;<br>        disable-wp;<br>        wp-controller;<br>        keep-power-in-suspend;<br>        enable-sdio-wakeup;<br>        no-1-8-v;<br>        /*disable-wp;*/<br>-       status = "disabled";<br>+       status = "okay";<br> };
</pre>


<p>Next, <code>make zero-gravitas_defconfig</code> and edit the <code>.config</code> file produced to include the following drivers.</p><pre>CONFIG_CFG80211=y
CONFIG_MAC80211=y
CONFIG_BRCMUTIL=y
CONFIG_BRCMFMAC=y
CONFIG_RTL_CARDS=y
CONFIG_BATTERY_BQ27XXX=y
CONFIG_BATTERY_BQ27XXX_I2C=y
CONFIG_USB_ACM=y
CONFIG_USB_F_ACM=y
CONFIG_USB_U_SERIAL=y
CONFIG_USB_CDC_COMPOSITE=y
CONFIG_CRYPTO_AEAD=y
CONFIG_CRYPTO_GF128MUL=y
CONFIG_CRYPTO_NULL=y
CONFIG_CRYPTO_CCM=y
CONFIG_CRYPTO_GCM=y
CONFIG_CRYPTO_SEQIV=y
CONFIG_CRYPTO_CTR=y
CONFIG_CRYPTO_GHASH=y
CONFIG_CRYPTO_ARC4=y
</pre>
<p>
Once done, rebuild the Linux kernel with <code>make</code>. Copy the artifacts to the rM's <code>/boot</code> directory: <code>arch/arm/boot/dts/zero-gravitas.dtb</code> and <code>arch/arm/boot/zImage</code>. I have included my artifacts <a href="http://www.davisr.me/projects/remarkable-microsd/boot.tar">here</a> for posterity, but it is foolish to install a kernel that someone else compiled.<br>
</p><p>
Reboot the rM, to make sure xochitl still runs. Then, check <code>dmesg | grep
 ‘mmc0’</code> to ensure the card was detected, and double-check it with <code>fdisk 
-l</code>. Partition your card as you like, then change the /etc/fstab option 
to mount that partition at /home.
</p>
<pre>root@reMarkable:~# dmesg | grep mmc0
[    2.091218] mmc0: SDHCI controller on 2190000.usdhc [2190000.usdhc] using DMA
[    2.377570] mmc0: new high speed SDXC card at address aaaa
[    2.391939] mmcblk0: mmc0:aaaa SC200 183 GiB 
</pre>
<pre>#/dev/mmcblk1p7 /home auto defaults,nofail 1 2
/dev/mmcblk0p7 /home auto defaults,nofail 1 2
</pre>
<p>
Reboot, and bask in the increased storage capacity.
</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/storage-screen.png" alt="Storage screen showing 179 GB free">

<h2>
<a name="notes">Ending Notes</a>
</h2>
<ul>
<li>Now, the aluminum back is held on with gaffer tape. I am afraid to glue it shut, in case I want to access the guts again.
</li><li>Maybe the white stuff that came out around the bezel can be replaced with calk</li><li>I wish I had used multicolor wires, because it was difficult following them with my eyes.
</li><li>I didn’t cut close enough to the top of the plastic case, and 
so my SD slot is taller than it needs to be, but it isn't very 
noticable. I shimmed the extra vertical space with a folded up business 
card for a tighter fit.
</li><li>Before using solid-core wirewrap wire, I tried making my own 
ribbon cable with magenet wire and masking tape. This didn’t work well, 
because the enamel was hard to remove from just the ends, and the 
masking tape was too thick. The wirewrap wire turned out much nicer.
</li><li>Technically, I think the IMX needs to be changed too (and 
re-wrote over /dev/mmcblk1boot0) but I didn’t do this, and it seems to 
work alright. I'm fine using it just for the data partition so my OS updates work.
</li>
<li>I am glad this article has created encouragement from other people. I
 would like to extend an offer: if you would like a microSD card in your
 rM, and are willing to let me install one with the possibility of it 
not coming out exactly perfect (i.e. someone who finds ultimate use of 
rM in its utility, not pristine beauty) I would like to refine this 
process. One thing could be to install an internal card using quality 
flash media. I would like to know how many people could go for something
 like that, and if there could be a market doing that kind of thing. I 
will soon have installed my own CNC machine, and can practice doing this
 modification better, eventually charging for the service.<br>
</li>
</ul>

<h2><a name="images">More Images</a></h2>
<img src="http://www.davisr.me/projects/remarkable-microsd/backpanel.jpg" alt="Back panel">
<img src="http://www.davisr.me/projects/remarkable-microsd/connectors.jpg" alt="Connectors">
<img src="http://www.davisr.me/projects/remarkable-microsd/cracking-open.jpg" alt="Splitting the case open">
<img src="http://www.davisr.me/projects/remarkable-microsd/dontpullscreen.jpg" alt="Don't pull the screen like this">
<p>Don't peel the screen off!</p>
<img src="http://www.davisr.me/projects/remarkable-microsd/openback.jpg" alt="Open back">
<img src="http://www.davisr.me/projects/remarkable-microsd/split-chassis.jpg" alt="Split chassis">

</article></div>]]>
            </description>
            <link>http://www.davisr.me/projects/remarkable-microsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232801</guid>
            <pubDate>Fri, 21 Aug 2020 07:20:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Hash Tables: understanding dictionaries]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24232752">thread link</a>) | @mastro35
<br/>
August 21, 2020 | http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/ | <a href="https://web.archive.org/web/*/http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://imgs.xkcd.com/comics/password_strength.png" alt="teaser"></p>

<p>Hi guys, have you ever wondered how can Python dictionaries be so fast and reliable? The answer is that they are built on top of another technology: <strong>hash tables</strong>.</p>

<p>Knowing how Python hash tables work will give you a deeper understanding of how dictionaries work and this could be a great advantage for your Python understanding because dictionaries are almost everywhere in Python.</p>

<h2 id="hash-functions">Hash Functions</h2>

<p>Before introducing hash tables and their Python implementation you have to know what is a hash function and how it works.</p>

<p>A hash function is a function that can map a piece of data of any length to a fixed-length value, called <strong>hash</strong>.</p>

<p>Hash functions have three major characteristics:</p>

<ol>
  <li>They are <strong>fast to compute</strong>: calculate the hash of a piece of data have to be a fast operation.</li>
  <li>They are <strong>deterministic</strong>: the same string will always produce the same hash.</li>
  <li>They produce <strong>fixed-length</strong> values: it doesn’t matter if your input is one, ten, or ten thousand bytes, the resulting hash will be always of a fixed, predetermined length.</li>
</ol>

<p>Another characteristic that is quite common in hash functions is that they often are <strong>one-way functions</strong>: thanks to a voluntary data loss implemented in the function, you can get a hash from a string but you can’t get the original string from a hash. This is not a mandatory feature for every hash functions but becomes important when they have to be cryptographically secure.</p>

<p>Some popular hash algorithms are <a href="https://en.wikipedia.org/wiki/MD5">MD5</a>, <a href="https://en.wikipedia.org/wiki/SHA-1">SHA-1</a>, <a href="https://en.wikipedia.org/wiki/SHA-2">SHA-2</a>, <a href="https://it.wikipedia.org/wiki/NTLM">NTLM</a>.</p>

<p>If you want to try one of these algorithms by yourself, just point your browser to https://www.md5online.org, insert a text of any length in the textbox, click the <code>crypt</code> button and get your 128bit MD5 hash back.</p>

<h2 id="common-usages-of-hashes">Common Usages of Hashes</h2>

<p>There are a lot of things that rely on hashes, and hash tables are just one of them. Other common usages of hashes are for cryptographic and security reasons.</p>

<p>A concrete example of this is when you try to download open-source software from the internet. Usually, you find also a companion file that is the signature of the file. This signature is just the hash of the original file and it’s very useful because if you calculate the hash of the original file by yourself and you check it against the signature that the site provides, you can be sure that the file you downloaded hasn’t have tampered.</p>

<p>Another common use of hashes is to store user passwords. Have you ever asked yourself why when you forget the password of a website and you try to recover it the site usually lets you choose another password instead of giving back to you the original one you chose? The answer is that the website doesn’t store the entire password you choose, but just its hash.</p>

<p>This is done for security reasons because if some hacker got the access to the site’s database, they won’t be able to know your password but just the hash of your password, and since hash functions are often one-way functions you can be sure that they will never be able to get back to your password starting from the hash.</p>

<h2 id="the-python-hash-function">The Python <code>hash()</code> Function</h2>

<p>Python has a built-in function to generate the hash of an object, the <code>hash()</code> function.
This function takes an object as input and returns the hash as an integer.</p>

<p>Internally, this function invokes the <code>.__hash__()</code> method of the input object, so if you want to make your custom class hashable, all you have to do is to implement the <code>.__hash__()</code> method to return an integer based on the internal state of your object.</p>

<p>Now, try to start the Python interpreter and play with the <code>hash()</code> function a little bit. For the first experiment, try to hash some numeric values:</p>

<pre><code>&gt;&gt;&gt; hash(1)
1
&gt;&gt;&gt; hash(10)
10
&gt;&gt;&gt; hash(10.00)
10
&gt;&gt;&gt; hash(10.01)
230584300921368586
&gt;&gt;&gt; hash(-10.01)
-230584300921368586
</code></pre>

<p>If you are wondering why these hashes seems to have different length remember that the Python <code>hash()</code> function returns <strong>integers</strong> objects, that are always represented with 24 bytes on a standard 64 bit Python 3 interpreter.</p>

<p>As you can see, by default the hash value of an integer value is the value itself. Note that this works regardless of the type of the value you are hashing, so the integer <code>1</code> and the float <code>1.0</code> have the same hash: <code>1</code>.</p>

<p>What’s so special about this? Well, this shows what you learned earlier, that is that hash functions are often one-way functions: if two different objects may have the same hash, it’s impossible to do the reverse process starting from a hash and going back to the original object. In this case, the information about the type of the original hashed object has gone lost.</p>

<p>Another couple of interesting things you could note by hashing numbers is that decimal numbers have hashes that are different from their value and that negative values have negative hashes. But what happens if you try to hash the same number you got for the decimal value? The answer is that you get the same hash, as shown in the following example:</p>

<pre><code>&gt;&gt;&gt; hash(0.1)
230584300921369408
&gt;&gt;&gt; hash(230584300921369408)
230584300921369408
&gt;&gt;&gt; hash(0.1) == hash(230584300921369408)
True
</code></pre>

<p>As you can see, the hash of the integer number <code>230584300921369408</code> is the same as the hash of the number <code>0.1</code>. And this is perfectly normal if you think of what you learned earlier about hash functions because if you can hash any number or any string getting a fixed-length value since you can’t have infinite values represented by a fixed-length value, that implies that there must be duplicated values. They exist in fact, and they are called <strong>collisions</strong>. When two objects have the same hash, it is said that they collide.</p>

<p>Hashing a string is not much different from hashing a numeric value. Start your Python interpreter and have a try hashing a string:</p>

<pre><code>&gt;&gt;&gt; hash("Bad Behaviour")
7164800052134507161
</code></pre>

<p>As you can see a string is hashable and produce a numeric value as well but if you have tried to run this command you could see that your Python interpreter hasn’t returned the same result of the example above. That’s because starting from Python 3.3 values of strings and bytes objects are <strong>salted</strong> with a random value before the hashing process. This means that the value of the string is modified with a random value that changes every time your interpreter starts, before getting hashed. If you want to override this behaviour, you can set the <code>PYTHONHASHSEED</code> environment variable to an integer value greater than zero before starting the interpreter.</p>

<p>As you may expect this is a security feature. Earlier you learned that websites usually store the hash of your password instead of the password itself to prevent an attack to the site’s database to stole all the site passwords. If a website stores just the hash as it is calculated it could be easy for attackers to know what was the original password. They just need to get a big list of commonly used passwords (the web is full of these lists) and calculate their corresponding hash to get what is usually called <strong>rainbow tables</strong>.</p>

<p>By using a rainbow table the attacker may not be able to get <strong>every</strong> password in the database, still being able to steal a <strong>vast majority of them</strong>. To prevent this kind of attack, a good idea is to <strong>salt</strong> the password before hashing them, which is modifying the password with a random value before calculating the hash.</p>

<p>Starting from Python 3.3 the interpreter by default salt every string and bytes object before hashing it, preventing possible DOS attacks as demonstrated by Scott Crosby and Dan Wallach on <a href="https://static.usenix.org/event/sec03/tech/full_papers/crosby/crosby_html/">this 2003 paper</a>.</p>

<p>A DOS attack (where DOS stands for Denial Of Service) is an attack where the resources of a computer system are deliberately exhausted by the attacker so that the system is no longer able to provide service to the clients. In this specific case of the attack demonstrated by Scott Crosby, the attack was possible flooding the target system with a lot of data whose hash collide, making the target system use a lot more of computing power to resolve the collisions.</p>

<h2 id="python-hashable-types">Python Hashable Types</h2>

<p>So at this point, you could wonder if any Python type is hashable.
The answer to this question is no, by default, just immutable types are hashable in Python. In case you are using an immutable container (like a tuple) also the content should be immutable to be hashable.</p>

<p>Trying to get the hash of an unashable type in Python you will get a <code>TypeError</code> from the interpreter as shown in the following example:</p>

<pre><code>&gt;&gt;&gt; hash(["R","e","a","l","P","y","t","h","o","n"])
Traceback (most recent call last):
 File "&lt;stdin&gt;", line 1, in &lt;module&gt;
TypeError: unhashable type: 'list'
</code></pre>

<p>However, every custom defined object is hashable in Python and by default its hash is derived from it’s id. That means that two different instance of a same class, by default have different hashes, as shown in the following example:</p>

<pre><code>&gt;&gt;&gt; class Car():
...     velocity = 0
...     direction = 0
...     damage = 0
...
&gt;&gt;&gt; first_car = Car()
&gt;&gt;&gt; second_car = Car()
&gt;&gt;&gt; hash(first_car)
274643597
&gt;&gt;&gt; hash(second_car)
274643604
</code></pre>

<p>As you can see, two different instances of the same custom object by default have different hash values. However, this behavior can be modified by implementing a <code>.__hash__()</code> method inside the custom class.</p>

<h2 id="hash-tables">Hash Tables</h2>

<p>Now that you know what a hash function is, you can start examining hash tables. A hash table is a data structure that allows you to store a collection of key-value pairs.</p>

<p>In a hash table, the key of every key-value pair must be hashable, because the pairs stored are indexed by using the hash of their keys. Hash tables are very useful because the average number of instructions that are necessary to lookup an element of the table is independent of the number of elements stored in the table itself. That means that even if your table grows ten or ten thousand times, the overall speed to look up a specific element is not affected.</p>

<p>A hash table is typically implemented by creating a variable number of <strong>buckets</strong> that will contain your data and indexing this data by hashing their keys. The hash value of the key will determine the correct bucket to be used for that …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/">http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/</a></em></p>]]>
            </description>
            <link>http://thepythoncorner.com/dev/hash-tables-understanding-dictionaries/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232752</guid>
            <pubDate>Fri, 21 Aug 2020 07:05:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pilo: Raspberry Pi-Powered Lights-Out Remote Server Management]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24232066">thread link</a>) | @gilad
<br/>
August 20, 2020 | https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html | <a href="https://web.archive.org/web/*/https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://zach.bloomqu.ist/assets/pilo-naked.jpg" alt="Pilo board before final tape-up"> <small>The completed Pilo controller, before final installation. The USB capture card and Arduino Nano USB serial are soldered to the underside of the 3B+.</small></p> <p>Like many geeks, I have a â€œhome serverâ€� made from off-the-shelf, consumer-grade PC parts, from which I run my weekend programming projects, game servers for friends, this website, and so on. Recently, I had a power event at the house that caused the server to reboot. When the power came back on, the server booted, but it was stuck at the boot screen waiting for me to enter the disk decryption passphrase!</p> <p>Luckily, I was at home and asleep at the time. Once I woke up and realized something was amiss, I was able to plug in a keyboard and enter the passphrase. But this event got me thinking - what if I wasnâ€™t home at the time? What if I was in another country? What if someday, I move this server outside of my house and need to regularly access the physical screen and keyboard?</p> <p>In the â€œreal serverâ€� world, the solution to this is known as <a href="https://en.wikipedia.org/wiki/Out-of-band_management">â€œlights-out managementâ€� (LOM)</a>. Every major server manufacturer has their own flavor of this, such as HPâ€™s iLO (Integrated Lights-Out). There are even industry standards like <a href="https://en.wikipedia.org/wiki/Intelligent_Platform_Management_Interface">IPMI</a> that define common interfaces for LOM implementations. Commonly supported functions for LOM systems include:</p> <ul> <li>Controlling keyboard and mouse input</li> <li>Controlling power button status (so you can restart, shutdown, force offâ€¦)</li> <li>Seeing the raw video output from the motherboard (even pre-boot - even for BIOS)</li> <li>Mounting ISOs as disks</li> </ul> <p>I decided to make my own Raspberry Pi-based LOM that can do some of these things, to help decrease my stress next time I leave my house for an extended period of time. Iâ€™d like to introduce Pilo - â€œPi Lights-Outâ€�.</p> <blockquote> <p>Note: This post describes how I arrived at the final design of this system. If you just want the instructions for setting this up on your own, start reading at â€œTutorialâ€�.</p> </blockquote> <h2 id="building-the-keyboard-controller">Building the Keyboard Controller</h2> <p>When I started looking for ways to use my Pi to send keyboard commands to a computer, the problem I discovered was that all of the existing methods rely on <a href="http://www.isticktoit.net/?p=1383">using the Raspberry Pi Zero as a USB host</a>, which disables using the onboard USB port for other purposes. Additionally, this method does not work on other boards, like the Raspberry Pi 3B+. This was problematic, because I wanted to use the 3B+ due to the on-board Ethernet - that, and the fact that I had one kicking around from a previous <a href="https://pi-hole.net/">Pi-hole</a> deployment.</p> <p>A more suitable solution would be to emulate a keyboard via the GPIO pins of the Pi. This would theoretically not affect existing USB devices, and could be used on any model of Pi, not just the Pi Zero. So I started looked into trying to <a href="http://www.jargon.net/jargonfile/b/bitbang.html">â€œbit-bangâ€�</a> the USB Human Interface Device protocol via the Piâ€™s GPIO pins.</p> <p>I pretty quickly hit a dead end with that. There are <a href="https://raspberrypi.stackexchange.com/q/82850/100317">many</a>, <a href="https://www.element14.com/community/thread/38228/l/raspberry-pi-usb-output-from-gpio">many</a> existing discussions on the web about bit-banging the USB protocol on the Pi. The consensus seems to be that the Raspberry Piâ€™s GPIO is too slow to emulate USB, and even if it <em>could</em> output bits fast enough to act as a USB device, the implementation would be extremely buggy because of the non-real-time nature of the Linux OS (<a href="https://raspberrypi.stackexchange.com/a/87865/100317">read more</a>).</p> <p>But USB isnâ€™t the only way to send keypresses to a computer - almost a decade before the USB standard was a twinkle in Compaqâ€™s eye, IBM was using the <a href="https://en.wikipedia.org/wiki/PS/2_port">PS/2</a> standard (not to be confused with the <a href="https://en.wikipedia.org/wiki/PlayStation_2">PS2</a>) to connect mice and keyboards to PCs. Itâ€™s still not feasible to use the Pi to bit-bang the PS/2 protocol, but we can use an Arduino as a daughterboard, and the <a href="https://github.com/Harvie/ps2dev"><code>ps2dev</code></a> library can handle the nitty-gritty of the serial protocol for PS/2.</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-pin-jam.jpg" alt="Left: Arduino soldered up. Right: Breadboard jumpers jammed into the PS/2 port"></p> <p>So thatâ€™s what I did. The Arduino Nano pictured on the left is plugged directly into the PS/2 combo port on the back of the motherboard (ignore the unused 5V wire, red). Originally, I planned on cutting the end off of a PS/2 cable and making it all nice, but the Goodwill near me didnâ€™t have any PS/2 junk and it turns out that breadboard wires just fit oh-so-snugly into the DIN holes. So this is how itâ€™s gonna be.</p> <p>The Arduino Nano is flashed with a <a href="https://create.arduino.cc/editor/flotwig__/093ababe-c724-476f-aeb8-a76b239bf192/preview">short program</a> that makes it act as a dumb pipe which blindly shuttles bytes from the Arduinoâ€™s USB serial port to the PS/2 connection on the motherboard. This means that all of the logic for which keyboard commands should be sent has to be written on the Pi-side, which is nice, because it means that we should never have to re-flash the Arduino to update some keyboard logic.</p> <p>Note that currently, Pilo is only built to control keyboard input, since it is oriented towards server use. It would be possible to add PS/2 mouse output with no additional hardware, just 2 or 3 wires for PS/2 mouse CLK, DATA, and GND (unless using combo port). The <a href="https://github.com/Harvie/ps2dev"><code>ps2dev</code></a> library contains functions for mouse control as well.</p> <h3 id="power-control-via-ps2">Power Control via PS/2</h3> <p>Originally, I thought I was going to have to wire a relay to the motherboardâ€™s RESET pin to allow Pilo to control the computerâ€™s power. This is the approach that <a href="https://github.com/Fmstrat/diy-ipmi"><code>diy-ipmi</code></a>, another similar project, uses. However, while researching the keyboard controller, I rediscovered a long-lost secret of the PS/2 standard: the â€œACPI keysâ€�. ACPI, or the Advanced Configuration and Power Interface, is a set of power management standards for PCs. The PS/2 standards define <code>Power</code>, <a href="https://ux.stackexchange.com/q/83200/117790"><code>WakeUp</code></a>, and <code>Sleep</code> key scancodes that can be used to control the power status of the PC - just like the power button on the front of the box, a short-press of the <code>Power</code> key requests the OS to shutdown. However, on my motherboard, a long-press of <code>Power</code> does <em>NOT</em> seem to force the power off.</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-bios-s5.png" alt="A screenshot of the BIOS with the ACPI S5 Wake-On-Keyboard option selected"></p> <p>Almost all BIOS support using the ACPI keys to power the system on from a powered down state. Above is what the option looks like in my BIOS (in ACPI, the powered-off state is known as â€œS5â€�). With this option enabled, sending the <code>Power</code> scancode will boot the computer up from an off state.</p> <p>So, now the Arduino has two responsibilities in Pilo: to send regular keypresses to the computer, and to send power commands to the computer. This saves us from having to install a relay for the motherboardâ€™s RESET pin.</p> <h2 id="capturing-video-output">Capturing Video Output</h2> <p>My server has a GPU with HDMI output, so I decided to use a USB HDMI capture card to get the video feed for Pilo. I found one on <a href="https://smile.amazon.com/gp/product/B08BZ52Q65/">Amazon for about $15</a>. When connected to the Pi, it acts as a regular USB webcam, available under <code>/dev/videoX</code>.</p> <p>Before this project, I had no experience with streaming video over the web. I decided to use <a href="https://www.linux-projects.org/uv4l/"><code>uv4l</code></a> (â€œUserspace Video4Linuxâ€�)â€™s <a href="https://www.linux-projects.org/home/documentation/uv4l-server/"><code>uv4l-server</code></a> component to set up an HTTP video server. <code>uv4l</code> makes it easy to set up a simple MJPEG stream, which is the goofiest possible video stream - each frame of the stream is a full JPEG image, sent to you in real time. As you can imagine, itâ€™s not the lightest on bandwidth, but it is easy to embed - all web browsers support embedding it in an <code>&lt;img&gt;</code> tag: <code>&lt;img src="/stream.mjpeg"/&gt;</code></p> <p>I configured the <code>uv4l-server</code> to only listen on <code>localhost</code>, with the idea that I could reverse-proxy connections to the video stream to provide security.</p> <h2 id="creating-the-application">Creating the application</h2> <p>For the Pilo interface, I decided to go with a web app, instead of something like VNC, or the actual IPMI protocol. This was mostly due to my background in web development, and the fact that the app can be accessed with a web browser, something every computer has installed. Here is a short video showing the completed Pilo app in action:</p> <video controls="" autoplay="" muted="" loop="" src="https://zach.bloomqu.ist/assets/pilo-demo.webm" type="video/webm"> <p>Your browser doesn't support WEBMs. <a href="https://zach.bloomqu.ist/assets/pilo-demo.webm">Download the video instead.</a></p> </video> <p>You can find the <a href="https://github.com/flotwig/pilo">GitHub repo for Pilo here</a>. It consists of two major components:</p> <ul> <li><a href="https://github.com/flotwig/pilo/tree/master/frontend"><code>frontend</code></a> - uses vanilla HTML/CSS/JS to display the interface, translate keypresses, and communicate with the server via websockets</li> <li><a href="https://github.com/flotwig/pilo/tree/master/server"><code>server</code></a> - the HTTP server, written in Node.js. Authenticates requests using HTTP basic auth, communicates with the keyboard controller via the <code>serialport</code> library, and manages reverse-proxying of the <a href="https://www.linux-projects.org/home/documentation/uv4l-server/"><code>uv4l-server</code></a> video stream</li> </ul> <p>There are also end-to-end tests in the <a href="https://github.com/flotwig/pilo/tree/master/e2e"><code>e2e</code></a> folder which use <a href="https://cypress.io/">Cypress</a> to test the application in real web browsers. This runs against Firefox and Chrome on every commit to CI via a <a href="https://github.com/flotwig/pilo/blob/master/.github/workflows/test.yml">GitHub Actions workflow</a>.</p> <p>The <a href="https://github.com/flotwig/pilo#pilo"><code>README</code></a> contains information on building and testing the project if you are interested in contributing. Built packages are also published to <code>npm</code> for production use.</p> <h2 id="packaging-the-pilo">Packaging the Pilo</h2> <p>One of my goals when building Pilo was to make it small enough to fit inside of my server case. Check out these photos to see how it fit in:</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-in-server.jpg" alt="Left: Before Pilo. Right: After Pilo."> <small>Left: Server case before embedding the Pilo. Right: Server case after embedding the Pilo. HDMI, Ethernet, and micro-USB power are routed through the left-most PCI-E slot, while PS/2 is routed through the I/O shield in the top-right. The Pilo itself sits atop a ledge in the bottom-right of the image.</small></p> <p>Here are some pictures of how the final assembly was made:</p> <p><img src="https://zach.bloomqu.ist/assets/pilo-assembly.jpg" alt="Outer photo: Pi with USBs soldered on. Inner: Taped-up package. "> <small>Outer photo: Pi with the USB devices <a href="https://raspberrypi.stackexchange.com/a/62678/100317">soldered on to the underside</a> to save space. Inset photo: Final package taped up and ready for install, with PS/2 cable coming out. Hot glue and tape make me the solderer I ainâ€™t.</small></p> <p>The completed package fits within a bounding box only slightly larger than the Pi itself, about 88mm x 60mm x 20mm, which means the Pilo can fit conveniently into a standard 3.5â€� hard drive bay.</p> <h2 id="tutorial">Tutorial</h2> <h3 id="parts-list">Parts List</h3> <ul> <li>Raspberry Pi 3B+ ($25 at <a href="https://www.microcenter.com/product/505661/Raspberry_Pi_3_B_Plus?src=raspberrypi">MicroCenter</a>, $35 everywhere else) <ul> <li>Or other micro linux computer - even a Pi Zero could work, but youâ€™d be using WiFi, and youâ€™d need a USB hub for the Arduino serial, or set up the Arduino serial via GPIO</li> </ul> </li> <li>Arduino Nano (<a href="https://smile.amazon.com/gp/product/B015MGHH6Q/">Amazon</a> has them at $16.99 for 5 - $3.40 each) <ul> <li>Any other 5V-logic-level Arduino would work as well. Needs to be 5V or have the CLK + DATA outputs converted from 3V3 to 5V, since the PS/2 serial connection expects 5V.</li> </ul> </li> <li>USB HDMI Capture Card (<code>video4linux</code> compatible - most cards are) (<a href="https://smile.amazon.com/gp/product/B08BZ52Q65/">Amazon</a>, $13.99)</li> <li>(optional) PS/2 plug, to make a tidy connection</li> <li>Supplies: Wires, soldering iron if you need to solder, microSD card and micro-USB power supply for the Piâ€¦</li> </ul> <p>Comes out to roughly $60 if you buy everything at itâ€™s …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html">https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html</a></em></p>]]>
            </description>
            <link>https://zach.bloomqu.ist/blog/2020/08/pilo-raspberry-pi-lights-out-management.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232066</guid>
            <pubDate>Fri, 21 Aug 2020 04:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I got the French Tech Visa to start my company in France]]>
            </title>
            <description>
<![CDATA[
Score 151 | Comments 193 (<a href="https://news.ycombinator.com/item?id=24232025">thread link</a>) | @christpetron
<br/>
August 20, 2020 | https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/ | <a href="https://web.archive.org/web/*/https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://christianpetroske.com/how-i-got-the-french-tech-visa-to-start-my-company-in-france/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24232025</guid>
            <pubDate>Fri, 21 Aug 2020 04:38:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Braess' Paradox and the Price of Anarchy (2019)]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24231860">thread link</a>) | @luu
<br/>
August 20, 2020 | http://cadlag.org/posts/braess-paradox-and-the-price-of-anarchy.html | <a href="https://web.archive.org/web/*/http://cadlag.org/posts/braess-paradox-and-the-price-of-anarchy.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            <p>
    Posted on August 10, 2019
    
        by Erik Davis
    
</p>




<p>Consider the following scenario. A large number of independent agents wish to traverse a network, from some start vertex to some end vertex. Each edge they travel will take some time, which could in general depend on the number of agents traveling along the edge. For the sake of simplicity, we’ll normalize things so that <span>\(x\)</span> denotes a proportion of agents (i.e. <span>\(x\)</span> ranges from 0 to 1). In what follows, we will let <span>\(\mathcal{E}\)</span> denote the set of edges, and <span>\(c_e :
[0,1] \to \mathbb{R}\)</span> the <em>cost</em> function associated with edge <span>\(e\)</span>. A very simple example is something like the following, where <span>\(s\)</span> is the start and <span>\(d\)</span> is the destination, and edges have been labeled with their cost.</p>
<div>
<p><img src="http://cadlag.org/ancillary/braess/initial.png" alt="A simple routing network, with variable edge cost."></p><p>A simple routing network, with variable edge cost.</p>
</div>
<p>One way to summarize the entire set of paths chosen is via a <em>flow</em> <span>\(f\)</span>, which assigns to each edge the normalized proportion of agents who have chosen to travel along it. For example, if all agents chose the top route in the above network, then we would have <span>\(f_{su} = 1, f_{ud} = 1\)</span> and <span>\(f_{sv} = 0, f_{vd} =
0\)</span>. There are of course other possible flows; one could consider the flow that puts all agents along the bottom path, or another which mixes the top and bottom paths somehow. <a href="#fn1" id="fnref1"><sup>1</sup></a></p>
<p>For a general flow <span>\(f\)</span>, the <em>total cost</em> borne by the agents in navigating the network is</p>
<p><span>\[
C(f) = \sum_{e \in E} f_e c_e(f_e).
\]</span></p>
<p>In the above example, routing all traffic along the top path (or equivalently, the bottom path) has a total cost of <span>\(2\)</span>. However, if one split the traffic so that half travels along the top path and half along the bottom path, then the total cost is only <span>\(0.5 c_{su}(0.5) + 0.5 \cdot c_{ud} + 0.5 \cdot c_{sv}(0.5) +
0.5 \cdot_{vd}(0.5) = 1.5\)</span>. In this example, this turns out that this is the minimum cost flow. One could imagine that if we were benevolent dictators controlling the choices of the agents, we might opt for this as an outcome.</p>

<p>Another way of looking at this routing problem is from the agent’s point of view. Suppose that, for each path <span>\(P\)</span>, some proportion of agents choose <span>\(P\)</span> for their traversal. In other words, we may imagine that we have a distribution <span>\(g\)</span> with <span>\(g_P \geq 0\)</span> and <span>\(\sum_{P \in \mathcal{P}} g_P = 1\)</span>, where <span>\(\mathcal{P}\)</span> denotes the set of <span>\(s-d\)</span> paths through the network. Thus <span>\(g_P\)</span> is the proportion of agents choosing path <span>\(P\)</span>. We’ll call such a <span>\(g\)</span> a <em>path distribution</em>, for lack of a better name.</p>
<p>There’s nothing lost by thinking about path distributions rather than flows. Indeed, given a path distribution <span>\(g\)</span> we can recover a flow by letting <span>\(f_e =
\sum_{P : e \in P} g_P\)</span>, where the sum is over all paths containing the edge <span>\(e\)</span>. It’s not hard to show that this is an honest flow.<a href="#fn2" id="fnref2"><sup>2</sup></a></p>
<p>So, from this vantage point: which path would an agent like to pick? In general, the cost of an edge depends on hhow much traffic it gets, so the answer is really contingent on the paths chosen by the other agents.</p>
<p>To give some clarity around this, let’s introduce an assumption about behavior: an agent will choose a path only if there are no cheaper alternatives. This is both a weak assumption, in the sense that it’s hard to argue with the rationale, and a strong one, in the sense that we’re granting each agent quite a lot of information about the problem at hand (e.g. the network topology, the behavior of the other agents, and so on).</p>
<p>With this in mind, note that relative to a fixed flow <span>\(f\)</span>, the cost of a path <span>\(P\)</span> is</p>
<p><span>\[ C(P; f) = \sum_{e \in P} c_e(f_e). \]</span></p>
<p>Formally, a path distribution <span>\(g\)</span> is said to be a (pure Nash) <em>equilibrium</em> distribution if</p>
<p><span>\[ g_P &gt; 0 \text{ only if } P \text{ minimizes } C(P; f), \]</span></p>
<p>where <span>\(f\)</span> is the flow associated with <span>\(g\)</span>.</p>
<p>In other words, in an equilibrium distribution every agent takes a path that is minimal <em>with respect to the flow induced by the others</em>.</p>
<p>It’s worth mulling this over a bit. With an equilibrium distribution, there’s no incentive for any particular agent to switch paths. Each agent sees the social world around it as essentially fixed; the others have induced some flow <span>\(f\)</span>, and the best one can do is pick the path that’s cheapest relative to this.</p>
<p>In our simple network, there is only one equilibrium distribution: half of the agents take the top path, and half take the bottom. The cost of this equilibrium distribution is <span>\(1.5\)</span>, just as before.</p>

<p>To briefly recap, we’ve singled out two sorts of flows as being special.</p>
<ul>
<li>Cost-minimizing flows are the ones that we’d pick if were playing the part of a benevolent dictator.</li>
<li>Equilibrium flows (i.e. those induced by an equilibrium path distribution) are the ones that we can imagine a bunch of independent agents settling for.</li>
</ul>
<p>It was something of a coincidence that in our toy network these two ended up being the same. But they don’t have to be.</p>
<p>So what happens if we start adding edges to the network? Naively, it seems like it can only make things better. Certainly, adding an edge doesn’t increase the cost of any previous flows (since they simply do not use the new edge), and in fact it’s possible that it makes available a new, cheaper flow. So as benevolent dictators, there’s not much to lose.</p>
<p>But what happens when we think from the agent’s perspective? Surprisingly enough, adding an edge can shift the equilibrium flow to something even costlier! For an extreme example, consider adding a free edge to our previous network.</p>
<div>
<p><img src="http://cadlag.org/ancillary/braess/augmented.png" alt="A network augmented with a zero cost edge."></p><p>A network augmented with a zero cost edge.</p>
</div>
<p>With this addition, the equilibrium distribution <a href="#fn3" id="fnref3"><sup>3</sup></a> puts all of the agents on the path <span>\(suvd\)</span>, for a total cost of 2! This is <a href="https://en.wikipedia.org/wiki/Braess%27s_paradox">Braess’ paradox</a>: adding capacity to a network can actually increase the cost of an equilibrium flow.</p>
<div>
<p><img src="http://cadlag.org/ancillary/braess/equilibrium.png" alt="The new equilibrium flow."></p><p>The new equilibrium flow.</p>
</div>
<p>I’m not going to prove that this flow is equilibrium, but let me give a glimpse of the incentives: the previous distribution, which put half of the agents on the top half and half of the agents on the bottom, is now unappealing from a traveller’s vantage point: relative to that flow, the effect of an agent on <span>\(sud\)</span> switching to <span>\(suvd\)</span> is to reduce their path cost by <span>\(0.5\)</span>. And so on.</p>

<p>By definition, an equilibrium flow is at least as costly as a cost-minimizing flow. The ratio</p>
<p><span>\[ \frac{\text{maximum cost of an equilibrium flow}}{\text{cost of min cost flow}} \]</span></p>
<p>is sometimes referred to as the <a href="https://en.wikipedia.org/wiki/Price_of_anarchy">Price of Anarchy</a>. For our original network, it was <span>\(1\)</span>. After adding the edge, it was <span>\(4/3\)</span>.</p>







        </div></div>]]>
            </description>
            <link>http://cadlag.org/posts/braess-paradox-and-the-price-of-anarchy.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24231860</guid>
            <pubDate>Fri, 21 Aug 2020 04:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Did Mozilla Remove XUL Add-Ons?]]>
            </title>
            <description>
<![CDATA[
Score 388 | Comments 326 (<a href="https://news.ycombinator.com/item?id=24231017">thread link</a>) | @est31
<br/>
August 20, 2020 | https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/ | <a href="https://web.archive.org/web/*/https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>TL;DR: Firefox used to have a great extension mechanism based on the XUL and XPCOM. This mechanism served us well for a long time. However, it came at an ever-growing cost in terms of maintenance for both Firefox developers and add-on developers. On one side, this growing cost progressively killed any effort to make Firefox secure, fast or to try new things. On the other side, this growing cost progressively killed the community of add-on developers. Eventually, after spending years trying to protect this old add-on mechanism, Mozilla made the hard choice of removing this extension mechanism and replacing this with the less powerful but much more maintainable WebExtensions API. Thanks to this choice, Firefox developers can once again make the necessary changes to improve security, stability or speed.</p>

<p>During the past few days, I’ve been chatting with Firefox users, trying to separate fact from rumor regarding the consequences of the August 2020 Mozilla layoffs. One of the topics that came back a few times was the removal of XUL-based add-ons during the move to Firefox Quantum. I was very surprised to see that, years after it happened, some community members still felt hurt by this choice.</p>

<p>And then, as someone pointed out on reddit, I realized that we still haven’t taken the time to explain in-depth why we <em>had no choice</em> but to remove XUL-based add-ons.</p>

<p>So, if you’re ready for a dive into some of the internals of add-ons and Gecko, I’d like to take this opportunity to try and give you a bit more detail.</p>



<p>For a very long time, Firefox was composed of a very small core on top of which everything was implemented as extensions. Many of these extensions were written in C++, others in JavaScript and many involved the XUL interface language and the XBL binding language. C++ and JavaScript code were connected thanks to a technology called XPCOM. Whenever an extension developer wished to customize Firefox, it was simple and extremely powerful, as the exact same building blocks used to power Firefox could be used to customize it.</p>

<p>This is how Session Restore (the technology that lets you resume Firefox where you left it the last time, even in case of crash) or the Find Bar were first implemented in Firefox, among other features. This is the technology that powers Firefox and <a href="https://www.thunderbird.net/">Thunderbird</a>. This is how tools such as <a href="https://en.wikipedia.org/wiki/Songbird_(software)">Songbird</a> (an open-source iTunes competitor) or <a href="https://en.wikipedia.org/wiki/Instantbird">Instantbird</a> (a chat client) were developed. This is also how I customized Firefox to become an eBook reader a long time ago. And this is how thousands of Firefox add-ons were developed.</p>

<p>Many people call this extension mechanism “XUL-based Add-Ons”, or sometimes “XPCOM-based Add-Ons”, and I’ll use both terms in this blog entry, but I often think of this as the “Promiscuous Extension Mechanism”, for several reasons:</p>

<ul>
<li>very quickly, add-on developers realized that anything they did could break anything else in the system, including other add-ons and Firefox itself, and they often had no way to prevent this;</li>
<li>similarly, anything Firefox developers did could break add-ons, and they often had no way to prevent this;</li>
<li>also, some of the changes that Firefox needed to be as fast, as stable and as secure as possible were going to break most add-ons immediately, possibly all add-ons in the longer term;</li>
<li>oh, and by the way, since add-ons could do everything, they could very easily do anything to the operating system, from stealing passwords to pretending to be your bank.</li>
</ul>

<p>Note: Having read in comments that some users apparently do not care about security, let me add that being secure is a really, really important point for Mozilla and has been since the first day. Regardless of add-ons, <em>not</em> having security means that an exploit is eventually going to show up that will steal user’s passwords and use them to steal their bank accounts – and that exploit will get sold around and will soon show up everywhere. Firefox developers fight this threat daily by all sorts of means, including code reviews, defensive programming, crash scene investigations, several types of sandboxing, static analysis, memory-safe languages, … Consequently, for Mozilla, if a feature prevents us from achieving great security, we <em>always</em> pick security over features.</p>

<p>I’ll return to these points in more details later. For the moment, suffices to say that it had been clear to Firefox developers for a long time (at least since 2010) that this situation was untenable. So Mozilla came up with a backup plan called the <em>Firefox Jetpack</em>.</p>

<p>Firefox Jetpack was a very different manner of extending Firefox. It was much cleaner. It finally had a permissions mechanism (something that had been suggested even before Firefox was called Firefox and that was generally considered too hard to implement). Out of the box, add-ons could not break each other or Firefox (I seem to remember that it was still sometimes possible by exploiting the observer service, but you had to work hard at it), it made extensive use of async programming (which was great to achieve a feeling of high-performance) and thanks to the fact that it had a finite API, it could be tested, which meant that when Firefox developers broke add-ons, they knew about it immediately and could fix the breakages! That was several enormous steps forward. This came at the cost of a more limited API but in most cases, the tradeoff seemed worth it.</p>

<p>Unfortunately, it turned out that there was an unexpected incompatibility between the design of Jetpack and some of the major changes that were needed in Firefox. I’m not entirely clear about what this incompatibility was but this meant that we had to abandon Jetpack.
Instead, we introduced WebExtensions. Overall, WebExtensions had a similar objective as Jetpack-based add-ons, with a similarly restricted API and the added bonus that they could be made to work on both Chromium-based browsers and Firefox.</p>

<p>If you needed very advanced APIs, switching from the promiscuous extension mechanism to Jetpack or WebExtensions was not always possible, but for most extensions, the transition was simple – in my personal experience, it was even pleasant.</p>

<p>Firefox introduced WebExtensions in time for Firefox Quantum because this is when the promiscuous add-on model was scheduled to break.</p>

<p>At this stage, we’re done with the historical overview. I hope you’re ready for a more technical dive because that’s how I’m going to explain to you exactly which problems were solved as we switched from the promiscuous extension model to WebExtensions.</p>



<h2 id="how-it-started">How it started</h2>

<p>XPCOM, the Xross-Platform Component Object Model, is perhaps the feature of Firefox that can best be described as <em>the core</em> (for people who know Gecko in-depth, I’m counting XPConnect and the Cycle Collector as part of XPCOM), alongside SpiderMonkey, our JavaScript Virtual Machine.</p>

<p>XPCOM is a technology that lets you write code in two languages and have each other call the other. The code of Firefox is full of C++ calling JavaScript, JavaScript calling C++ and a long time ago, we had projects that added Python and .Net in the mix. This piece of machinery is extremely complicated because languages do not share the same definitions (what’s a 64-bit integer in JavaScript? what’s a JavaScript exception in C++?) or the same memory model (how do you handle a JavaScript object holding a reference to a C++ object that C++ might wish to <code>delete</code> from memory?) or the same concurrency model (JavaScript workers share nothing while C++ threads share everything).</p>

<p>Gecko itself was originally designed as thousands of XPCOM components that could each be implemented in C++ or in JavaScript, tested individually, plugged, unplugged or replaced dynamically and <em>it worked</em>. In addition, the XPCOM architecture made for much cleaner C++ programming than was available at the time, worked on dozens of platforms, and let us combine the convenience of writing code in JavaScript and the raw speed permitted by C++.</p>

<p>To write a XPCOM component, you typically define <a href="https://searchfox.org/mozilla-central/rev/6cc48251bb97600fdf11a5b4c5f621bfc8606d55/dom/interfaces/base/nsIFocusManager.idl">an interface</a>, then write the implementation in either C++ or JavaScript (or Rust, nowadays, and maybe soon Wasm). Some boilerplate is needed, but hey, it works.</p>

<p>When early Firefox developers decided to open the platform to extensions, XPCOM was immediately picked as the base technology for add-ons. Firefox just had to let add-on authors plug anywhere within the code and they would have tremendous power at their disposal.</p>

<p>And add-on developers (including myself) certainly did and had lots of fun with it!</p>

<h2 id="the-era-of-immutable-xpcom">…the era of immutable XPCOM</h2>

<p>Unfortunately, problems progressively started to creep up.</p>

<p>When you’re developing a large application, you need to change things, either to fix bugs or to add new features, or to improve performance. In the XPCOM world, this meant changing XPCOM components. Sometimes to add new features to a component. Sometimes to entirely remove one because this design has been replaced with a better design.</p>

<p>In the first era of the XPCOM-based extension mechanism, this was often forbiddden. If there was an XPCOM component used by add-ons, it simply <strong>could not</strong> be changed in incompatible ways. This was great for add-on developers but it quickly became a nightmare for Firefox developers. Because every single change had to be made in backwards-compatible way both externally (for web developers) and internally (for add-on developers). This meant that each XPCOM component <code>nsISomething</code> was quickly accompanied by a <code>nsISomething2</code>, which was the better component – and both needed to be made to work alongside each other - One case was even more complicated to handle by Firefox developers: XPCOM-based add-ons could replace <em>any existing XPCOM component</em>. Needless to say, this was a very good way to break Firefox in ways that puzzled Firefox crash investigators.</p>

<p>This meant that development became slower and slower as we needed to check each new feature or each improvement against not only current features, but also past/deprecated features or simply old ways to work …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/">https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</a></em></p>]]>
            </description>
            <link>https://yoric.github.io/post/why-did-mozilla-remove-xul-addons/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24231017</guid>
            <pubDate>Fri, 21 Aug 2020 01:30:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Promised Land: Religious ideology and solarpunk science fiction]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24230502">thread link</a>) | @apsec112
<br/>
August 20, 2020 | http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/ | <a href="https://web.archive.org/web/*/http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
<div>
  <p><span>Octavia Butler, the Black science fiction author to whom all others were compared until the coming of N.K. Jemisin, published the novel </span><i><span>Parable of the Sower</span></i><span> in 1993,</span> <span>first of a trilogy. In her fictional near-future, Southern California will become but one of the newly red-lined regions earmarked for a corner pocket of Hell, because the end is nigh. I’m talking, dolphins Snapchatting us, “WE OUT! NO-THANKS-FOR-THE-MERCURY-MARINATED-FISH!”-type of climatic environmental and societal collapse. No kaiju necessary. We will die of consumption after a fifty-plus year bender, drunk on neoliberal, late-stage capitalist moonshine.</span></p>
<p><em><span>[[This article appears in <a href="http://thenewmodality.com/letter-from-the-editor-newmo-issue-one/">Issue One</a> of </span></em><span>The New Modality.</span><em><span><a href="https://thenewmodality.backerkit.com/hosted_preorders"> Buy your copy or subscribe here</a>.]]</span></em></p>
<p><span>Fast forward to our present non-fiction. My day job is teaching elementary school. Yet despite the allure of two months of do-whatever-I-want-time, more and more I dread the coming of summer, because glaciers the size of islands are falling into the ocean. Is this the season when my <em>Westworld</em> kingdom is invaded by drought and famine? When Russia’s permafrost melts, releasing primeval microscopic disease-titans (</span><a href="http://www.bbc.com/earth/story/20170504-there-are-diseases-hidden-in-ice-and-they-are-waking-up"><span>they are real, 2017</span></a><span>) to gobble me up in a surprise Greek tragedy? When the floodgates of my Amazon-fueled desires are permanently clogged by natural man-made disaster? Of course, Prime will continue to deliver, but the markup would be understandably obscene.</span></p>
<p><span>Will this be the season my melanin hard-fails me?</span></p>
<p><span>I joke because I’m afraid. Not only is this specific dystopia possible, Butler seems to have predicted it twenty-seven years ago. </span><i><span>Parable of the Sower</span></i><span> is set somewhere in the 2020s during a presidential election in which the candidate’s campaign slogan is “Make America Great Again</span><i><span>.” </span></i><span>Oh yes, and California actually </span><i><span>is</span></i> <span>burning right now. This is a horrible present. I ordered the exact opposite of this nightmare. I asked for solarpunk.</span></p>
<p><b>Solarpunk: The Genre of Solutions</b></p>
<p><span>Solarpunk is the environmentally conscious speculative arts movement that best navigates the terrors ahead. Detractors label it a kind of Pollyanna utopianism full of empty calories. It’s true that the Google replicator machine will serve up a visual feast</span><span> of enforested skyscrapers and lush solar energy mushroom cities (possibly under the sea, possibly shared with amiable, buck-toothed invertebrates with ageless comedic timing). The solarpunk aesthetic will sometimes wear utopian clothing, but it’s nobody’s fault, really. Ursula K. Le Guin helped plant solarpunk seeds decades ago, in stories such as the 1972 novel </span><i><span>The Dispossessed,</span></i> <span>her 1982 essay “</span><a href="https://www.fifthestate.org/archive/382-spring-2010/non-euclidean-view-california-cold-place-1982/"><span>A Non-Euclidean View of California as a Cold Place to Be</span></a><span>,”</span> <span>and many othe</span><span>r Daoist-inspired works</span><i><span>.</span></i><span> Thus, the movement was growing long before the term was coined in 2008. So after decades of imagineering and community building, there are bound to be layers and crumbly edges. And to be fair, it is impossible to dream of Hell and not pine for its opposite.</span></p>
<p><span>In truth, solarpunk is functional AF. The primary colors of its aura are red, orange, and yellow: Courageously compassionate, creatively scientific, and awakened interdependence. In many ways, it can be more rigorous than so-called “hard science fiction.” Don’t @ the messenger; I’m quoting Kim Stanley Robinson, author of </span><i><span>New York 2140</span></i><span> among many other groundbreaking stories of eco-fiction. He takes issue with the viral over-affixation of “-punk” (Google punk genres and see how many you get). However, at Boskone 57, one of the largest science fiction conventions in the country, where he was guest of honor, Robinson described a genre full of futures to defy the Anthropocene. Stories where sacrifices are made, but in the end, we find ways to survive and become wise. I told him afterwards that it sounded like solarpunk, and he stage-whispered, “That’s because it is.”&nbsp;</span></p>
<p><span>If we focus primarily on the genre’s textual artifacts — including the discourses on the various social media platforms, but especially the genre fiction it produces — solarpunk’s better qualities become unimpeachable. I have read all the major solarpunk anthologies that have come out in the last five years. To quote Sarena Ulibarri, editor of </span><i><span>Glass and Gardens: Solarpunk Summers</span></i><span> and newly out </span><i><span>Solarpunk Winters,</span></i><span> because she’s so damn quotable, “[Solarpunk] stories depict adaptation and compromise rather than destruction and conquest… empathy over greed.” They are an antidote for the toxin, yin to counteract the damage done by the big yang motorcycle trip, and I am a believer.</span></p>
<p><span>Yet after reading and enjoying these stories, I noticed a pattern. The viewpoint characters of solarpunk stories roughly fall into categories with similar confluences; Joênia from Thomas Badlan’s “Orchidae” (in </span><i><span>Glass and Gardens: Solarpunk Winters,</span></i> <span>2020) is one among many intrepid scientists you will find in the genre, racing the clock to preserve life or help us adapt. Young makers, like Del the biotech tinkerer in D.K. Mok’s “The Spider and the Stars,” and the community that comes together to ceremonially re-create the vanished Arctic in Andrew Dana Hudson’s “Black Ice City” (both in </span><i><span>Solarpunk Summers,</span></i><span> 2018), are also well represented in solarpunk.&nbsp;&nbsp;</span></p>
<p><span>There’s some spillover from the makers into the anarchists. In T.X. Waston’s “The Boston Hearth Project” (in </span><i><span>Sunvault</span></i><i><span>,</span></i><span> a 2017 anthology edited by Wagner and Wieland), these are people who thrive on the leftmost bleeding edge of society, breaking rules that should never have been in order to shelter the homeless. But many solarpunk characters — and most salient to this conversation — are young people, often women of color, adjusting to the dangers of the new normal brought on by severe environmental changes and doing so in ways their elders did not have the foresight or perspective to do themselves. Daesha in “Fyrewall” by Stefani Cox </span><i><span>(Solarpunk Summers)</span></i><span> is one like this, gifted with responsibilities beyond her years when she must fix the wall protecting future Californians from raging wildfires. All these stories showcase new or repurposed material resources and technologies for increased sustainability.&nbsp;&nbsp;</span></p>
<p><span>Clearly these voices are necessary. But there’s something missing. The intersection with communities of faith is roped off.</span></p>
<p><b>Spirit in the Machine: The Missing Piece</b></p>
<p><span>The heroine of Butler’s </span><i><span>Parable of the Sower</span></i> <span>is</span> <span>Lauren Oya Olamina. She will be little more than a child before inevitable mayhem and metastasized, commodified suffering rolls up on her family, murders everyone, and destroys what is left of her community. She will escape with her life, but orphaned and traumatized. What is she to do?</span></p>
<p><span>Step one: Become a self-made messiah.</span></p>
<p><span>Step two: Reengineer God.</span></p>
<p><span>Step three: Save humanity.</span></p>
<p><span><span>Step four: Bong hits.</span></span></p>
<p><span>Hers is an incredibly powerful story. She very much fits the mold of solarpunk heroines with one exception: She’s a faith leader. Why aren’t there more characters like her? Where are the griots and santeras? Where are the bodhisattvas and the saints? Those who speak the languages of heaven’s heart? Where are the Lauren Oya Olaminas?</span></p>
<p><span>Her absence, given what she might represent, is understandable. Ideology (the dogmatic kind) has often been the death of free thinkers and first adopters. It has produced conservative paradigms that sustained brutal hierarchies, birthed unforgettable monsters, and poured bleach on other people’s history. But too often to ignore, the opposite has also been the case. Tibetan Buddhism and the Dalai Lama comes to mind. The Southern Christian Leadership Conference, the nonviolent Civil Rights Era organizing group whose goal was to redeem “the soul of America,” was not an aberration of history. Martin Luther King may have been a GOAT (Greatest Of All Time, for those without access to Urban Dictionary), but if time’s memory was more robust, his would not be the only spirit we commune with on special occasions.&nbsp;</span></p>
<p><span>So, whether it has been a purposeful or subconscious omission, this issue must be addressed for solarpunk to move beyond artists, and progressive secularists. We need to mainstream the radical.</span></p>
<p><b>The Intersection is Under Construction</b></p>
<p><span>There are three tenets of solarpunk orthodoxy that are relevant here. The first is that solarpunk is an overtly inclusive space. If it could be a real boy, anti-racism would be in its DNA. Keep that in mind when I tell you that the US Census <a href="https://www.brookings.edu/blog/the-avenue/2018/03/14/the-us-will-become-minority-white-in-2045-census-projects/%20">projects</a> that by the year 2045, the majority of US population will be people of color (already the case for residents under age eighteen) and the majority of us profess some kind of faith (itinerant Seon Buddhist right here).<br></span></p>
<p><span>In 2008, when last Pew Research asked the question, 95% of those surveyed reported belief in a higher power of some kind. Even among scientists, the believers were in the majority. Both numbers go up if you include the rest of the world, particularly the black and brown parts. So, for solarpunk to be properly inclusive of us in possible futures, it would be a mistake to blackbox significant guiding tenets because of an aversion to the dominant ideologies and the much-discussed potential for evil in organized religion. Evil is everywhere. Search for kittens on your favorite browser and scroll down for about thirty seconds. There be evil.&nbsp;</span></p>
</div>
</div><div>
    
<div>
    
<p><span>
  <img alt="Image" src="http://imaketheater.com/newmodality_x/wp-content/uploads/2019/09/mini_gradient_divider.png" width="69" height="6">
</span></p><blockquote>
    <div>
    <p><span>There is no greater or more fundamental technology than culture. It, and the ark of ideologies that arise from it, are more than just peer pressure from dead people. Culture is </span><i><span>software. </span></i><span>And more often than not, that includes a spiritual platform.</span></p>      </div>
  </blockquote>

<p><span>
  <img alt="Image" src="http://imaketheater.com/newmodality_x/wp-content/uploads/2019/09/mini_gradient_divider.png" width="69" height="6">
</span></p><div>
  <p><span>Claudie Arseneault, author of <i>Wings of Revival: A Solarpunk Dragon Anthology</i>, gives us the second tenet: “[Solarpunk should work] from existing technologies, from things we already know are possible.” This is key. There is no greater or more fundamental technology than culture. It, and the ark of ideologies that arise from it, are more than just peer pressure from dead people. Culture is <i>software.</i> And more often than not, that includes a spiritual platform.</span></p>
<p><span>Now, a deep dive into the Pokémon competitions …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/">http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/</a></em></p>]]>
            </description>
            <link>http://thenewmodality.com/promised-land-religious-ideology-and-solarpunk-science-fiction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24230502</guid>
            <pubDate>Fri, 21 Aug 2020 00:13:15 GMT</pubDate>
        </item>
    </channel>
</rss>
