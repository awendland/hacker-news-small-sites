<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 24 Nov 2020 20:22:38 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 24 Nov 2020 20:22:38 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Facebook Condemned for Providing Platform to Neo-Nazi Network]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25184311">thread link</a>) | @wikus
<br/>
November 22, 2020 | https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/ | <a href="https://web.archive.org/web/*/https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1222">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-jordan-5426402-e1606077190468-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h3>Facebook is facing a new wave of criticism for providing a platform for a white supremacist network with over 80,000 online followers.</h3>
<ul>
<li>Facebook only removed these pages after being contacted by large media organisation the <em>Observer</em>. The Center for Countering Digital Hate claim they were made aware of this two years ago.</li>
</ul>
<p>The Guardian reports this Neo-Nazi network also has ties to the UK far right, <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">including a student facing terrorism charges</a>. Imran Ahmed, CEO of the Center for Countering Digital Hate, said:</p>
<blockquote>
<p>&nbsp;‚ÄúFacebook‚Äôs leadership endangered public safety by letting Neo-Nazis finance their activities through Facebook and Instagram. Facebook was first told about this problem two years ago and failed to act.‚Äù</p>
</blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg" alt="" width="800" height="534" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1024x683.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-300x200.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-768x512.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-1536x1024.jpg 1536w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-2048x1365.jpg 2048w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-thought-catalog-2228555-272x182.jpg 272w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>After the <em>Observer</em> contacted Facebook, they began taking down the material with a Facebook spokesperson stating:</p>
<blockquote><p>‚ÄúWe have removed the content which violates our policies prohibiting dangerous organisations. We regularly work to improve our technology to find and remove this content faster, and, while there is more work to do, we are making progress. We‚Äôve banned over 250 white supremacist organisations from Facebook and Instagram.‚Äù</p></blockquote>
<h4>Read more of the <a href="https://www.theguardian.com/technology/2020/nov/22/facebook-condemned-for-hosting-neo-nazi-network-with-uk-links" target="_blank" rel="noopener noreferrer">full report on The Guardian</a>.</h4>
<hr>
<p><strong>Author‚Äôs Note: </strong>I highly recommend reading <a href="https://hfet.org/opinion-grading-facebooks-homework/"><strong>Grading Facebook‚Äôs Homework</strong></a>, which is an opinion piece on Facebook‚Äôs response to criticism.</p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/facebook-condemned-for-providing-platform-to-neo-nazi-network/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25184311</guid>
            <pubDate>Mon, 23 Nov 2020 07:22:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are pixie fairies behind Bitcoin's latest bubble?]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25180563">thread link</a>) | @amycastor
<br/>
November 22, 2020 | https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4780">
		<div>
		
<p>Are the pixie fairies sprinkling gold dust on bitcoin‚Äôs market again? By the looks of things, you might think so. </p>



<p>Like in the bubble days of 2017, the price of bitcoin is headed ever upward. On Wednesday morning, it surpassed $18,000 ‚Äî a number not seen since December 2017 when bitcoin, at its all-time peak, scratched $20,000.</p>



<p>Of course, the market <a href="https://www.bloomberg.com/news/articles/2018-09-12/crypto-s-crash-just-surpassed-dot-com-levels-as-losses-reach-80">crashed spectacularly</a> the following year, and retailers lost their shirts. But here we are once again, trying to unravel the mysteries of bitcoin‚Äôs latest price movements. </p>



<p>Several factors may explain it ‚Äî Tether, PayPal, and China‚Äôs crackdown on over-the-counter desks ‚Äî but before we get into that, let me reiterate how critical it is for bitcoin‚Äôs price to stay at or above a certain <em>magic number</em>.&nbsp;</p>



<p>Bitcoin miners ‚Äî those responsible for securing the bitcoin network by ‚Äúmining‚Äù the next block of transactions on the blockchain ‚Äî need to sell their newly minted bitcoins for real money, so they can pay their <a href="https://news.bitcoin.com/the-bitcoin-network-now-consumes-7-nuclear-plants-worth-of-power/#:~:text=Today%2C%20the%20CBECI%20says%20the,terawatt%2Dhours%20of%20energy%20consumption.">massive energy bills.</a>&nbsp;&nbsp;</p>



<p>Roughly $8 million to $10 million in cash gets sucked out of the bitcoin ecosystem this way every day. So, in order for the miners ‚Äî the majority of whom are in China ‚Äî to turn a profit, bitcoin needs to be priced accordingly. Otherwise, if too many miners were to decide to call it quits and unplug from the network all at once, that would leave bitcoin vulnerable to attacks. The entire system, and its current $345 billion market cap, literally depends on keeping the miners happy.</p>



<p>Now let‚Äôs jump to May 11, an important day for bitcoin. That was the day of the ‚Äúhalvening,‚Äù an event hardwired into bitcoin‚Äôs code where the block reward gets slashed in half. A halvening occurs once every four years.</p>



<p>Before May 11, miners received 1,800 bitcoin a day in the form of block rewards, which meant they needed to cash in each bitcoin for $5,000. But <em>after</em> the halvening, the network would produce only 900 bitcoins per day, so miners knew they needed to sell each precious bitcoin for at least $10,000.&nbsp;&nbsp;</p>



<p>But trouble loomed. Just months before the halvening, the price of bitcoin went into free fall. Between February and March, when the world was first gripped by the COVID crisis, bitcoin lost half its value, sliding to $5,000 ‚Äî barely enough to pay the system‚Äôs energy costs post-halvening. Miners were likely pacing, wringing their hands, wondering how they would stay in business. Who would guarantee their profits?</p>



<p>That is when Tether ‚Äî a company that produces a dollar-pegged stablecoin of the same name ‚Äî sprung into action and started issuing tethers in amounts far greater than it ever had before in its five years of existence.</p>



<p>Tethers, for the uninitiated, are the main source of liquidity for unbanked crypto exchanges, which account for most of bitcoin‚Äôs trading volume. Currently, there are $18 billion (notional value) worth of tethers sloshing around in the crypto markets. And nobody is quite sure what‚Äôs backing them.</p>



<p>Due to Tether‚Äôs lack of transparency, its failure to provide a long promised audit, and the fact that the New York Attorney General is <a href="https://www.wsj.com/articles/bitfinex-used-tether-reserves-to-mask-missing-850-million-probe-finds-11556227031">currently probing</a> the firm along with Tether‚Äôs sister company, crypto exchange Bitfinex, for fraud, a good guess is nothing. Tethers, many suspect, are being minted out of thin air.&nbsp;</p>



<p>(Tethers were initially promised as an IOU where one tether was supposed to represent a redeemable dollar. But that was long before the British Virgin Island-registered firm began issuing tethers in massive quantities. And no tethers, to anyone‚Äôs knowledge, have ever been redeemed‚Äîexcept for when Tether <a href="https://www.coindesk.com/tether-just-burned-500-million-usdt-stablecoin-tokens">burned 500 million tethers</a> in October 2018, following the <a href="https://amycastor.com/2019/04/26/new-york-attorney-general-bitfinex-is-hiding-850-million-in-losses/">seizure of $850 million</a> from its payment processor Crypto Capital.)</p>



<p>According to data from <a href="https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/blank">Nomics</a>, at the beginning of 2020, there were only $4.3 billion worth of tethers in circulation. That number remained stable through January and February and into March. But starting on March 18, just five days after bitcoin dipped below $5,000, the tether printer kicked in.</p>



<figure><img src="https://lh4.googleusercontent.com/wquSWQQ2kEfLCnshYnCiE7RZY2tuh9JtkWwPvnSsImvegfwkMzdhboJKFhSdpxqc5CtbcOh-5xqaro5F5DQAupoThjDcw6DYUf9wQTPBgfSMOV2TObswcJbuZoiOi2z46e9AR4Wg" alt=""><figcaption><em>BTC price and USDT supply. </em><a href="https://nomics.com/"><em>Image: Nomics.com</em></a></figcaption></figure>



<p>Tether minted $1.9 billion worth of tethers in March, and another $1.5 billion worth in April ‚Äî crypto‚Äôs own version of an economic stimulus package. The price of bitcoin rose in tandem back up to $10,000, just in time for the halvening. Yet the Tether printer kept printing, pushing the price of bitcoin ever skyward and giving bag holders an opportunity to cash out.&nbsp;</p>



<p>In May, June and July, Tether issued a combined total of $6 billion in tethers. In August, when the price of bitcoin reached $12,000, it spun out $2.5 billion in tethers. And in September, when BTC slid to $10,000, Tether infused the markets with another $2 billion in tethers, although, even that couldn‚Äôt lift bitcoin up to $12,000 again. It just hovered in the $10,000 range.&nbsp;</p>



<p>And then in October ‚Äî just after US prosecutors <a href="https://www.justice.gov/usao-sdny/pr/founders-and-executives-shore-cryptocurrency-derivatives-exchange-charged-violation">charged the founders of BitMEX,</a> a Seychelles-registered, Hong Kong-based bitcoin derivatives exchange, for failing to maintain an adequate anti-money laundering program ‚Äî the price of BTC started to soar. What happened?</p>



<h2><strong>Tether‚Äôs frenzied pumping</strong></h2>



<p>One theory is that Tether just kept issuing tethers, billions and billions of them, and those tethers were used to buy up bitcoin. A high demand drives up the price ‚Äî even if it‚Äôs fake money.&nbsp;</p>



<p>Only unlike in 2017, the effort to drive up bitcoin‚Äôs price is requiring a lot more tethers than ever before. (At the end of 2017, before the last bitcoin bubble popped, there were only $1.3 billion worth of tethers in circulation, a fraction of what there are today.)</p>



<p>Nicholas Weaver, a bitcoin skeptic and a researcher at the International Computer Science Institute in Berkeley, is convinced&nbsp;bitcoin‚Äôs latest price moves are 100% synthetic.</p>



<p>‚ÄúThe amount of tether flooding into the system is more than enough explanation for the price as it is well more than the amount needed to buy up all the newly minted bitcoin,‚Äù he told me. ‚ÄúIf it was organic, there would at least be some significant increase in the outstanding amount of non-fraudulent stablecoins.‚Äù</p>



<p>What he means is, if real money was behind tether, we‚Äôd be seeing a similar demand for regulated stablecoins. But that is not the case. Only one regulated stablecoin has seen substantial growth ‚Äî <a href="https://www.theblockcrypto.com/linked/81422/stablecoin-supply-has-surged-past-20-billion-driven-by-derivatives-market">Circle‚Äôs USDC</a> ‚Äî but that growth is far overshadowed by Tether, and mainly a result of the growing decentralized finance (DeFi) market ‚Äî a topic for another time.</p>



<p>Jorge Stolfi, a professor of computer science at the State University of Campinas in Brazil, who in 2016 wrote a <a href="https://www.sec.gov/comments/sr-batsbzx-2016-30/batsbzx201630-2.htm">letter to the SEC</a> advising about the risks of a bitcoin ETF, which the SEC published, agrees.</p>



<p>‚ÄúAs long as fake money can be used to buy BTC, the price can be pumped to whatever levels to keep the miners happy,‚Äù he told me. He went on to <a href="https://twitter.com/JorgeStolfi/status/1329952095286472711">explain</a> in a Twitter thread that the higher the bitcoin price, the faster real money flows out of the system ‚Äî assuming miners sell <em>all</em> their bitcoin for cash. Multiply bitcoin‚Äôs current price of $18,600 times 900, and that‚Äôs nearly $17 million a day. Investors will never get that money back, he said.</p>



<p>Klyith (not his real name) from Something Awful, a predecessor site to 4Chan, <a href="https://forums.somethingawful.com/showthread.php?noseen=0&amp;threadid=3838405&amp;perpage=40&amp;pagenumber=797#post505143737">explains Tether</a> this way:</p>



<p>‚ÄúA bunch of pixies show up and start flooding the parchment market with fairy gold, driving prices to amazing new heights. But when any of the player characters try to spend the fairy gold in other towns or to pay tithes to the king, it turns into worthless rocks.</p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg"><img loading="lazy" data-attachment-id="4784" data-permalink="https://amycastor.com/fairy/" data-orig-file="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg" data-orig-size="564,775" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fairy" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=218" data-large-file="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=564" src="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=564" alt="" width="291" height="400" srcset="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=291 291w, https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=109 109w, https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=218 218w, https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg 564w" sizes="(max-width: 291px) 100vw, 291px"></a></figure></div>



<p>‚ÄúIf you denounce the pixies to the peasants or start using dispel magic to reveal that fairy gold is rocks, the price of parchments will collapse and the peasants may stop using them altogether. But if you ignore the pixies and keep the parchment economy going, you will end up with more and more worthless rocks instead of gold. The pixies can of course tell the difference between fairy gold and real gold at a glance. So they will quickly drain all the real gold from the whole township if you don‚Äôt act. What do you do?‚Äù</p>



<p>Still, it is hard to imagine that outside events don‚Äôt have some impact on bitcoin‚Äôs price. Two other events are being talked about right now as reasons behind bitcoin‚Äôs price gains‚Äîand they are getting a lot more media attention than Tether.</p>



<h2><strong>PayPal‚Äôs shilling</strong></h2>



<p>One of the biggest companies in the world is now <a href="https://www.ft.com/content/826eedac-b0cd-4591-897a-9e83cf697060">promoting crypto</a>, giving retail buyers the impression that bitcoin is a safe investment. After all, if bitcoin were a Ponzi or a scam, why would such a well-known, respectable company embrace it? I should add that <a href="https://www.coindesk.com/microstrategy-ceo-bitcoin-better-than-antiquated-gold">MicroStrategy</a>, <a href="https://squareup.com/us/en/press/2020-bitcoin-investment">Square</a>, <a href="https://decrypt.co/48252/wall-streets-fidelity-mounts-defense-for-bitcoin">Fidelity Investment</a> and Mexico‚Äôs third-richest person, <a href="https://www.bloomberg.com/news/articles/2020-11-18/billionaire-salinas-has-10-of-liquid-portfolio-in-bitcoin">Ricardo Salinas Pliego</a>, are also currently shilling bitcoin on the internet. </p>



<p>On Oct. 21, PayPal <a href="https://newsroom.paypal-corp.com/2020-10-21-PayPal-Launches-New-Service-Enabling-Users-to-Buy-Hold-and-Sell-Cryptocurrency">announced a new service</a> for its users to buy and sell crypto for cash. And on Nov. 12, the service <a href="https://techcrunch.com/2020/11/12/paypal-says-all-users-in-u-s-can-now-buy-hold-and-sell-cryptocurrencies/">became available to U.S. customers</a>, who can now buy and sell bitcoin, bitcoin cash, ether, and litecoin via their PayPal wallet.&nbsp;</p>



<p>If you are a PayPal user, you have already gone through the process of proving you are who you say you are. And that removes the hassle of having to sign up with an crypto exchange, like Coinbase in the U.S., and take selfies of yourself holding up your driver‚Äôs license or passport.</p>



<p>Of course, there are limitations. You can‚Äôt transfer crypto into or out of your wallet, like you can on a centralized exchange. But you can pay PayPal‚Äôs 26 million merchants with crypto ‚Äî although, not really, because what they receive on their end is cash. And the transaction is subject to high fees, like <a href="https://techcrunch.com/2020/10/21/paypal-to-let-you-buy-and-sell-cryptocurrencies-in-the-us/">2.3% for anything under $100</a>, so what is the point? All you are doing is taking out a bet against PayPal that the price of bitcoin is going to rise.&nbsp;</p>



<p>Stolfi describes PayPal <a href="https://twitter.com/JorgeStolfi/status/1330207860484153347">on Twitter</a> as ‚Äúa meta-casino where you can choose to use special in-house chips with a randomly variable value.‚Äù</p>



<p>The broader point is that PayPal makes it easy to buy crypto for people who are less likely to understand how crypto really works or know about ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/">https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180563</guid>
            <pubDate>Sun, 22 Nov 2020 20:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mark Zuckerberg's Ponzi Scheme (2019)]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25180420">thread link</a>) | @annadane
<br/>
November 22, 2020 | http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/ | <a href="https://web.archive.org/web/*/http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
Mark Zuckerberg's Ponzi Scheme<br>
<span color="#A0A0A0">Congress and the FTC brought a knife to a gun fight.</span></p><div>

<p>It's already a campaign issue for the next presidential election: should we, or should we not, break up the big tech companies? Elizabeth Warren says yes. Beto O'Rourke wants "stronger regulations."  Kamala Harris would rather talk about privacy. Everyone else√¢‚Ç¨‚Äùeven Donald Trump√¢‚Ç¨‚Äùgenerally agrees that something needs to be done. But what?</p><p>There are plenty of law professors, think tanks and political consultants eager to share their ideas, but none of them are asking the right questions. In the case of Facebook, distractions are understandable when the company arguably has the worst track record of any major technology company in history (and will soon pay a record, if toothless, $5 billion fine). Yet the unspoken issue at the center of it all remains: although Wall Street, Congress and the Federal Trade Commission haven't figured it out, Mark is running a Ponzi scheme.</p><p>At this point it should come as no surprise to anyone paying attention that Mark is a bad-faith actor. He has no appreciation for the rule of law, or the role of a free press, and he has a dangerous tendency to view himself as infallible. After discovering a gaping security flaw in his product that revealed bulk information about friends of friends, exactly like Cambridge Analytica, I warned Mark in writing about the way his sloppy code would inevitably lead him to cross paths with the FTC and cause massive privacy and security concerns√¢‚Ç¨‚Äùin <a href="http://www.thinkpress.com/authoritas/timeline.pdf" target="_new">April 2005</a>. His response: problems with the "Mark Zuckerberg production" were actually someone else's responsibility and "not worth arguing about."</p><p>Clearly, Mark can no longer argue that his decisions as Facebook's CEO are immaterial (though he has <a href="https://www.vox.com/2016/11/11/13596792/facebook-fake-news-mark-zuckerberg-donald-trump" target="_new">tried</a>). Many have already lost their lives, whether through avoidable suicides or avoidable genocidal acts in Myanmar, due to his string of increasingly tone-deaf and spectacularly dishonest decisions. Now, fifteen years and approximately as many false apologizes after my classmate started a grand social experiment that first captivated the media, then locked it in a profitless box, and then played a major supporting role in bringing fascism to America, the general consensus is that the best way to handle Mark and his tech brethren is through the Sherman Anti-Trust Act. But the consensus is wrong, based on a mountain of misapprehensions.</p><p>In a nutshell, the argument in favor of anti-trust action is that in the midst of the longest economic expansion in U.S. history, it's the Progressive Era all over again. A recent New York Times op-ed penned by Mark's former roommate and co-founder, Chris Hughes, made essentially this point, relying heavily on input from the Roosevelt Institute. The Open Markets Institute agrees. In a <a href="https://www.youtube.com/watch?v=xM9GMGDsKUU&amp;t=24m40s" target="_new">talk at Harvard Law School</a>, Matt Stoller argued that Facebook, Google and Amazon were "born as monopolists."</p><p>It's a compelling story, so long as one is willing to ignore the reality on the ground. For one thing, software products are not railroads, which require significant physical capital and labor to establish. Were he determined to do so, it would take Mark a few weeks to re-build Instagram and WhatsApp, and there really isn't any way the government could stop him. For another, I know that on this particular issue, Stoller is incorrect, because I was there when The Facebook was born on my hard drive on September 19, 2003, in Lowell House. It hardly resembled a monopoly. Monopolies are what happen as the result of prolonged neglect by law enforcement. They're not born; they're nourished by years and years of perverse incentives.</p><p>The biggest problem with treating Facebook as a monopoly, as opposed to the byproduct of what Jesse Eisenger calls "The Chickenshit Club," is that it wrongly affirms Mark's infallibility and fails to see through him and his scheme, let alone the reality that he's not even in control anymore because no one is. On October 26, 2012, Mark's friend and lieutenant, Sam Lessin, wrote, "we are running out of humans (and have run-out of valuable humans from an advertiser perspective)."  At the time, it was far from clear that Facebook even had a viable business model, and according to Frontline, Sheryl Sandberg was panicking due to the company's poor revenue numbers.</p><p>How times have changed; now there's a different source of panic. Facebook now has a market capitalization approaching $600 billion, making it nominally one of the most valuable companies on earth. It's a true business miracle: a company that was out of users in 2012 managed to find a wellspring of nearly infinite and sustained growth that has lasted it, so far, half of the way through 2019. So what is that magical ingredient, that secret sauce, that "genius" trade secret, that turned an over-funded money-losing startup into one of America's greatest business success stories? It's one that Bernie Madoff would recognize instantly: fraud, in the form of fake accounts.</p><p>Old money goes out, and new money comes in to replace it. That's how a traditional Ponzi scheme works. Madoff kept his going for decades, managing to attain the rank of Chairman of the NASDAQ while he was at it. Zuckerberg's version is slightly different, but only slightly: old users leave after getting bored, disgusted and distrustful, and new users come in to replace them. Except that as Sam Lessin told us, the "new users" part of the equation was already getting to be a problem in 2012. To balance it out and keep "growth" on the rise, all Facebook had to do was turn a blind eye. And did it ever.</p><p>In <a href="https://www.plainsite.org/dockets/3bvv82ier/california-northern-district-court/singer-v-facebook-inc/" target="_new"><i>Singer v. Facebook, Inc.</i></a>√¢‚Ç¨‚Äùa lawsuit filed in the Northern District of California alleging that Facebook has been telling advertisers that it can "reach" more people than actually exist in basically every major metropolitan area√¢‚Ç¨‚Äùthe plaintiffs quote former Facebook employees, understandably identified only as Confidential Witnesses, as stating that Facebook's "Potential Reach" statistic was a "made-up PR number" and "fluff."  Also, that "those who were responsible for ensuring the accuracy √¢‚Ç¨Àúdid not give a shit.'"  Another individual, "a former Operations Contractor with Facebook, stated that Facebook was not concerned with stopping duplicate or fake accounts."</p><p>That's probably because according to its <a href="https://s21.q4cdn.com/399680738/files/doc_financials/2019/Q1/Q1-2019-Earnings-Presentation.pdf" target="_new">last investor slide deck</a> and basic subtraction, Facebook is not growing anymore in the United States, with zero million new accounts in Q1 2019, and only four million new accounts since Q1 2017. That leaves the rest of the world, where Facebook is growing fastest "in India, Indonesia, and the Philippines," according to Facebook CFO David Wehner. Wehner didn't mention the fine print on page 18 of the slide deck, which highlights the Philippines, Indonesia and Vietnam as countries where there are "meaningfully higher" percentages of, and "episodic spikes" in, fake accounts. In other words, Facebook is growing the fastest in the locations worldwide where one finds the most fraud. In other other words, Facebook isn't growing anymore at all√¢‚Ç¨‚Äùit's shrinking. Even India, Indonesia and the Philippines don't register as many searches for Facebook as they used to. Many of the "new" users on Instagram are actually old users from the core platform looking to escape the deluge of fakery.</p><p>The last time Mark suggested that Facebook's growth heyday might be behind it, in July 2018, the stock took a nosedive that ended up being the single largest one-day fall of any company's stock in the history of the United States. In about an hour, it <a href="https://www.marketwatch.com/story/facebook-stock-crushed-after-revenue-user-growth-miss-2018-07-25" target="_new">plunged 20%</a> from around $220 per share to about $165. Needless to day, the loss of about $120 billion in market capitalization in an hour provided a sufficient disincentive for Mark to avoid a repeat performance.</p><p>Having narrowly escaped the ire of Wall Street, Mark knows he cannot get off the growth treadmill he set in motion years ago. The only solution: lying to investors about growth in an attempt to convince them that everything is fine. Yet signs that Mark's fake account problem is no different than Madoff's fake account statement problem are everywhere. Google Trends shows worldwide "Facebook" queries down 80% from their November 2012 peak. (Instagram doesn't even come close to making up for the loss.)  Mobile metrics measuring use of the Facebook mobile app are down. And the company's own disclosures about fake accounts stand out mostly for their internal inconsistency√¢‚Ç¨‚Äùone set of numbers, measured in percentages, is disclosed to the SEC, while another, with absolute figures, appears on its "transparency portal."  While they reveal a problem escalating at an alarming rate and are constantly being revised upward√¢‚Ç¨‚ÄùFacebook claims that false accounts are at 5% and duplicate accounts at 11%, up from 1% and 6% respectively in Q2 2017√¢‚Ç¨‚Äùthey don't measure quite the same things, and are <a href="https://www.plainsite.org/realitycheck/facebook.html" target="_new">impossible to reconcile</a>. At the end of 2017, Facebook decided to stop releasing those percentages on a quarterly basis, opting for an annual basis instead. Out of sight, out of mind.</p><p>One could argue that SEC disclosures are subject to strict regulations under the Securities Exchange Act and that Facebook would never be so bold as to lie to investors in black and white. That's true: it qualifies its fake account disclosures with the quizzical legal phrase "significant judgment" and it chose the color orange instead of black (insert Netflix joke here) for its transparency portal graph disclaimers that read, "These metrics are in development."  And one could further argue that the transparency portal metrics are reviewed by a team of academics, known as the Data Transparency Advisory Group (DTAG), who are supposed to vouch for their validity. But the DTAG academics√¢‚Ç¨‚Äùnot one of whom is a statistician, despite Facebook's direct claim to the contrary, now erased√¢‚Ç¨‚Äùfully admit that they are paid by Facebook, and even after months of hard work, their <a href="https://law.yale.edu/system/files/area/center/justice/document/dtag_report_5.22.2019.pdf" target="_new">final report</a> released in April mentioned fake accounts only three times, and all three ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/">http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/</a></em></p>]]>
            </description>
            <link>http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180420</guid>
            <pubDate>Sun, 22 Nov 2020 19:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Month of Terraform]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 66 (<a href="https://news.ycombinator.com/item?id=25180355">thread link</a>) | @ingve
<br/>
November 22, 2020 | https://jeremywsherman.com/blog/2020/11/21/a-month-of-terraform/ | <a href="https://web.archive.org/web/*/https://jeremywsherman.com/blog/2020/11/21/a-month-of-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I took Heroku for granted, and a month into setting up my own infra, I now know how much it bought me.</p>
<p>A lot of my past work has been infrastructure-adjacent.
I often find myself filling in the Build &amp; Integration role - the person that gets continuous integration off the ground and keeps it actually continuing rather than falling flat on its face.
But often I‚Äôve just been building one of a constellation of services, so the core infrastructure was already there,
or I‚Äôve been targeting something like Heroku, where you basically pick your poison, git push, and bob‚Äôs your uncle.</p>
<p>This time, I‚Äôm putting the pieces together using the AWS toolkit.
And to smoosh them all together, I‚Äôm using Terraform,
because heck if I‚Äôm going to be hand-writing YAML or JSON and praying it‚Äôs formatted right.
Plus there‚Äôs more I want to orchestrate than just AWS, like, say, GitLab.</p>
<p>I don‚Äôt wanna talk about AWS just now.
It reminds me of learning Foundation &amp; Cocoa - you look at one piece, and it can do so much, and then you gotta put all those individually deep &amp; complex pieces together to do more stuff.
I figure if I put in the hours reading docs, learning what‚Äôs all there, and getting stabbed by the pointy bits, it‚Äôll probably all come out fine in the end.</p>
<p>So, Terraform.</p>
<h2 id="the-good">The Good</h2>
<ul>
<li>It mostly works!</li>
<li>When it doesn‚Äôt, it generally fails in a useful way, and then I can fix it and try again.</li>
<li>There are docs for most things.</li>
<li>Autoformatting works great.</li>
<li>Linting works pretty well.</li>
<li><em>Terraform: Up &amp; Running</em> is excellent, and Terragrunt makes it even easier. Huge thanks to their team for providing the <a href="https://rachelbythebay.com/w/2018/03/23/ducttape/">duct tape</a> we need. üôå</li>
</ul>
<h2 id="the-not-so-good">The Not So Good</h2>
<ul>
<li>terraform-lsp is supposed to provide autocomplete, but it mostly doesn‚Äôt, in my experience. First it flipped its lid that I dared to have a repo with multiple root modules in it, so I just aimed VS Code at the folder with a single root module. Then the language server says it‚Äôs all hunky dory AFAICT, and yet it autocompletes nothing beyond bare language syntax. As a result,  I‚Äôm manually referencing docs and writing stuff down and wasting tons of time that tools like autocomplete and integrated linting ought to be saving me from.</li>
<li>State files contain secrets in plaintext. (You might enjoy the <a href="https://github.com/hashicorp/terraform/issues/516">six-year-old GitHub issue about the plaintext secrets problem</a>.) You can mark outputs as secret, so they don‚Äôt get printed at the end of applying your infra spec, but run <code>terraform show</code> instead of <code>terraform apply</code>, and there they are, staring back at you. At least you can lock down and encrypt the S3 bucket holding the state.
<ul>
<li><a href="https://www.pulumi.com/docs/intro/concepts/config/#secrets">Pulumi‚Äôs secrets management</a> is far more satisfying. But Pulumi is even more cutting-edge than v0.whatever Terraform, and I expect Hashicorp to keep TF running for a good while, while I‚Äôm not so confident in Pulumi, so I‚Äôm using TF. (Hashicorp of course would recommend <a href="https://www.hashicorp.com/products/vault">Vault</a>.)</li>
</ul>
</li>
<li>Annoying asymmetries in the language about how you *<em>declare and reference</em> things in slightly variant ways - I trip over these over and over as a beginner:
<ul>
<li>You declare locals in a <code>locals</code> block, but you reference them as <code>local.thing</code>, not <code>locals.thing</code>.</li>
<li>You declare a variable in a <code>variable</code> block, but you reference it as <code>var.thing</code>.</li>
<li>You declare data sources as <code>data "provider_thingy" "my_name_for_this_data"</code>, and then you have to access it as <code>data.provider_thingy.my_name_for_this_data</code>. (This is actually pretty darn consistent, at least. Though, like, why the quotes around the provider thingy?)</li>
<li>You declare resources as <code>resource "provider_thingy" "my_name"</code>. But you do NOT reference them as <code>resource.provider_thingy.my_name</code>. Nope, you just reference them as bare <code>provider_thingy.my_name</code>.</li>
</ul>
</li>
<li>For that matter, there are other oddities as well. Pieces of syntax that seem like they should be orthogonal just aren‚Äôt. <code>for_each</code> stands out here:
<ul>
<li>You can generate multiple resources by just dropping a <code>for_each</code> in the block: <code>resource "provider_thing" "mine" {}</code> becomes <code>resource "provider_thing" "mine" { for_each = of_these }</code></li>
<li>But nested <em>argument</em> blocks require conversion from like <code>setting { namespace = "blah" }</code> to <code>dynamic "setting" { for_each = thingy; content { namespace = "blah" }}</code>. Have fun looking that up a few times.</li>
<li>And you can‚Äôt even use the <code>for_each</code> trick with module imports. It just isn‚Äôt supported. Sorry, sucks to be you.</li>
</ul>
</li>
<li>Annoying gaps in the docs:
<ul>
<li><strong>Required vs optional parameters</strong> are not very clearly called out and are not at all segregated. So you get to play the game of ‚Äúwhat is the minimal skeleton to declare this resource‚Äù. Actually running it a few times to see what you screwed up takes longer than just looking at the docs and puzzling it out, due to the lengthy iteration times in infra-land (see below).</li>
<li><strong>Types are not shown in the docs!!!</strong> All the outputs and arguments are typed. You have to declare those types. It‚Äôs right there in the code. But the docs don‚Äôt say what any of the types are. You just hit a type error at runtime. Fun fun!</li>
<li><strong>The HCL language is doc‚Äôd under the CLI tool, not in and of itself.</strong> It was really hard to actually find the docs since my first thought when I have syntax questions isn‚Äôt ‚Äúlet‚Äôs look at the docs for the tool.‚Äù It‚Äôd be like pulling up the manpage for GCC (carefully draw your triangle of art first) when you have a question about C syntax.</li>
</ul>
</li>
<li>Annoying asymmetries in the AWS provider:
<ul>
<li><strong>Missing links:</strong> Sometimes you get into a ‚Äúcan‚Äôt get there from here‚Äù situation. Like trying to find the zone ID for an Elastic Beanstalk environment‚Äôs CNAME so you can aim a Route 53 alias at it. (Hint, you need a completely different resource, the <code>aws_elastic_beanstalk_hosted_zone</code>.)</li>
<li><strong>Irregular naming:</strong>
<ul>
<li>Sometimes something is <code>zone_id</code>, but other times it‚Äôs maybe just <code>id</code>.</li>
<li>Sometimes you can fish stuff out by <code>arn</code>, or maybe by <code>id</code>, or maybe it‚Äôs by <code>name</code> - good luck. Keep the docs close to hand.</li>
<li>(It‚Äôs totally possible this is inherited from the AWS APIs themselves, but the whole point of an abstraction layer is to make things better and more usable, dangit.)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="the-different">The Different</h2>
<ul>
<li><strong>Iteration times are way longer than with even mobile apps.</strong> Like, ‚Äúyou‚Äôre liable to task-switch while waiting to see plan output‚Äù longer.</li>
<li><strong>Testing is a pain.</strong> I haven‚Äôt pulled in <a href="https://terratest.gruntwork.io/">Terratest</a> yet, because anyone maintaining this after me is unlikely to have Go experience, and my focus here isn‚Äôt builing reusable infra anyway - it‚Äôs building <em>this</em> infra ‚Äì so I‚Äôve just been using <code>bats</code> and Bash shell scripts (with <a href="https://github.com/koalaman/shellcheck/blob/master/README.md">shellcheck</a>, which is amazing) for some after-the-fact sanity checking using the AWS CLI. (Pro tip: Use the community-maintained fork <a href="https://github.com/bats-core/bats-core"><code>bats-core</code></a> rather than the no-longer-maintained sstephenson original.)
<ul>
<li>Policy assertions feel like a different flavor of test, but the tooling here seems to be fairly immature, with perhaps the exception of if you‚Äôre targeting Kubernetes.</li>
</ul>
</li>
</ul>
<h2 id="summary">Summary</h2>
<p>I expect I‚Äôll get used to most of the rough edges of the syntax in another month. And Terraform is stil v0, so hey, maybe some breaking changes will clear all this mess away. ü§û</p>
<p>I‚Äôm intentionally not getting sucked into hacking around the docs frustrations just now. Or even the <a href="https://github.com/gruntwork-io/terragrunt/issues/432#issuecomment-371467507">very tempting open issue about silencing all the Terragrunt logspew</a>.</p>
<p>I do plan to spend a bit of time trying to get autocomplete working for resource and data source types and their arguments/attributes from the language server, at least. That would be a huge help.</p>
<p>It still feels like magic to run a command and have infrastructure just‚Ä¶happen.
You hit return, wait a bit, and suddenly servers are serving and domains are aliasing and a whole constellation of systems are interoperating.
It kinda reminds me of the magic of home automation with blinkenlights, only without any of that messy ‚Äúhardware‚Äù stuff to break on you.</p>

    </div></div>]]>
            </description>
            <link>https://jeremywsherman.com/blog/2020/11/21/a-month-of-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180355</guid>
            <pubDate>Sun, 22 Nov 2020 19:39:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We‚Äôre Optimizing Ourselves to Death (2019)]]>
            </title>
            <description>
<![CDATA[
Score 242 | Comments 156 (<a href="https://news.ycombinator.com/item?id=25180229">thread link</a>) | @thread_id
<br/>
November 22, 2020 | https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/ | <a href="https://web.archive.org/web/*/https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h4>Burnout is the inevitable result of our endlessly accelerating pace of&nbsp;life</h4>



<figure><img data-attachment-id="552" data-permalink="https://zandercutt.com/screen-shot-2019-03-06-at-5-32-05-pm/" data-orig-file="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png" data-orig-size="564,744" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2019-03-06-at-5.32.05-pm" data-image-description="" data-medium-file="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png?w=227" data-large-file="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png?w=564" src="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png" alt=""><figcaption>Illustration: Jutta Kuss/Getty Images</figcaption></figure>



<p><strong>Author‚Äôs Note</strong>: I‚Äôve recently partnered with <a href="https://diginthere.com/">Project DigInThere</a>, an online project to help people get more out of the articles they read. <a href="https://diginthere.com/">Project DigInThere</a> enables authors (in this case, me) to create 3-4 question ‚Äúquests‚Äù that readers (in this case, you) can review prior to reading an article. Doing so primes you with what to look for in the article, and then you can take the quest at the end of the article to test your recall. If you‚Äôre interested, you can review the quest I‚Äôve built by <a href="https://diginthere.com/quests/zandercutt-2019-02-17-were-optimizing-ourselves-to-death-2447316663cd/view">clicking here</a>, then take it after reading the article and see how you do. Or you can just read the article ‚Äî it‚Äôs up to you ;).</p>



<hr>



<p><strong>pro¬∑cel¬∑er¬∑a¬∑tion</strong></p>



<p>/pr≈çÀåsel…ôÀàrƒÅSH(…ô)n/</p>



<p><em>noun</em></p>



<ol><li>The acceleration of acceleration</li></ol>



<p>‚Äî excerpt from <em>The Age of Earthquakes</em>, by Shannon Basar, Douglas Coupland, and Hans Ulrich Obrist</p>



<hr>



<p>There‚Äôs a famous thought experiment in economics known as the ‚Äúprisoner‚Äôs dilemma.‚Äù In it, two men have been caught committing a crime. Each of them is placed in a separate interrogation room and effectively has two options: confess or lie. There are three possible outcomes (the payoffs of which are illustrated in the payoff matrix below):</p>



<p><strong>Outcome 1</strong>: Both confess, and both serve eight years in prison (illustrated by payoff ‚Äú-8, -8‚Äù in Figure A).</p>



<figure><img src="https://zandernethercutt.files.wordpress.com/2019/02/cec19-1vvzfhu09tthxuusxda1zeg.png" alt=""><figcaption>Figure A: The Prisoner‚Äôs Dilemma. Credit:&nbsp;Author</figcaption></figure>



<p><strong>Outcome 2</strong>: Both men lie, and both serve one year in prison (illustrated by payoff ‚Äú-1, -1‚Äù in Figure A).</p>



<p><strong>Outcome 3</strong>: One man confesses while the other lies. The liar serves the longest possible sentence, 10 years, while the confessor goes free (illustrated by payoff ‚Äú-10, 0‚Äù in Figure A).</p>



<p>So, if both men lie, they both get off with a lighter sentence. That appears to be the full story‚Ää‚Äî‚Ääexcept it isn‚Äôt.</p>



<p>The importance of the prisoner‚Äôs dilemma is understanding that in selecting a strategy, each player should account for the effectiveness of that strategy given what the other player might do.</p>



<p>Knowing this, consider the game from the perspective of Prisoner 1. If he thinks Prisoner 2 will lie, he should confess, because serving zero years in prison is better than serving one. If he thinks Prisoner 2 will confess, he should also confess, because serving eight years in prison is better than serving 10. In this situation, confessing is both players‚Äô dominant strategy, the strategy they should play regardless of what the other player does.</p>



<p>This thought experiment illustrates how two self-interested individuals with a clear way to maximize their collective utility fail to do so. It also happens to be a fantastic way to understand our current moment. Millennials‚Ää‚Äî‚Äänot all of us, but many of us‚Ää‚Äî‚Ääare burned out, and the prisoner‚Äôs dilemma can shed light on why.</p>



<p>Unfortunately, it also sheds light on a distressing conclusion: Barring some miracle of human coordination, our quest to optimize our lives will never slow, let alone stop. If anything, it will accelerate.</p>



<hr>



<p>Imagine a two-player labor market represented by the prisoner‚Äôs dilemma matrix. Now imagine both players encountered a service that would help optimize their lives. For a real-world example (and one I use), let‚Äôs take the premade meal delivery service Freshly.</p>



<p>Freshly claims to save people approximately two hours a week in the time they don‚Äôt have to spend grocery shopping, meal prepping, or cooking. Now imagine that both players had two choices of how they could spend those hours: either on extra leisure (e.g., sleep, Netflix, a book, etc.,) or on productivity (e.g., optimization/work).</p>



<p>What would each player choose?</p>



<p>Well, if wealth is considered freedom from busyness, or freedom to spend your time as you wish, the hour would be best spent on leisure. When forming a strategy, however‚Ää‚Äî‚Äälike with the prisoner‚Äôs dilemma‚Ää‚Äî‚Ääplayers must consider those strategies in the context of what the other players in the game might do. Consider the adjusted payoff matrix below:</p>



<p><strong>Outcome 1</strong>: Both players use the time afforded by the service‚Äôs convenience to optimize/work harder and thus remain in a state of constant acceleration (illustrated by payoff ‚Äú1, 1‚Äù in Figure B).</p>



<figure><img src="https://zandernethercutt.files.wordpress.com/2019/02/92958-1qccvg4lbzz4zmcjpbuhs6w.png" alt=""><figcaption>Figure B: The Millennial Dilemma (leisure vs. work). Credit:&nbsp;Author.</figcaption></figure>



<p><strong>Outcome 2</strong>: Both players use the time afforded by the service‚Äôs convenience to relax (illustrated by payoff ‚Äú8, 8‚Äù in Figure A).</p>



<p><strong>Outcome 3</strong>: Player 1 uses the time afforded by the service‚Äôs convenience to optimize/work harder, while Player 2 uses it to relax. Player 1 reaps the benefits of being the only provider of labor in a market and corners it. Player 2 languishes as the world accelerates endlessly and leaves him behind (illustrated by payoff ‚Äú10, 0‚Äù in Figure A).</p>



<p>Borrowing earlier analysis, it‚Äôs clear that given the payoffs, both players have a dominant strategy: work. If Player 2 relaxes, Player 1 should work because a payoff of 10 is better than a payoff of 8. If the Player 2 works, Player 1 should also work because a payoff of 1 is better than a payoff of zero.</p>



<p>Now, remember, these payoffs‚Ää‚Äî‚Ääand their explanations‚Ää‚Äî‚Ääare completely made up. In the modern era, there is no reason to be convinced that torturing yourself with additional employment is associated with any improvement in your lifestyle. And yet this is exactly how most people behave.</p>



<p>Thus, we arrive at our new Nash equilibrium: Both players use a service‚Ää‚Äî‚Äämind you, a service built to supposedly make their lives easier and more relaxing‚Ää‚Äî‚Ääthat ends up making their lives more stressful and complex. Put another way, both players burn out.</p>



<hr>



<p>In a recent viral BuzzFeed article, ‚Äú<a href="https://www.buzzfeednews.com/article/annehelenpetersen/millennials-burnout-generation-debt-work" rel="noreferrer noopener" target="_blank">How Millennials Became The Burnout Generation</a>,‚Äù Anne Helen Petersen notes this seeming paradox of leisure, specifically as it pertains to freed up time. She writes:</p>



<blockquote><p>Attempts [by companies] to discourage working ‚Äúoff the clock‚Äù misfire, as millennials read them not as permission to stop working, but a means to further distinguish themselves by being available anyway.</p></blockquote>



<p>In other words: Attempts by companies like Google or Freshly to create services that save you time misfire, as millennials see them not as services that will give them more time to relax, but as services that will increase the amount of time they‚Äôre available to work.</p>



<p>As employees in a hyperproductive, work-obsessed world, we‚Äôve become acutely aware of any opportunity for optimization. Our Instagram feeds are filled with every possible combination of meal delivery service and online shopper that exists. Startups emerge daily to automate every mundane activity ever scrawled on and scratched off a legal pad.</p>



<p>The escalators I take to work are filled with the same desperate faces and vacant eyes I feel staring through me on the subway, except instead of standing still, they‚Äôre bounding up it, subconsciously aware that below their feet is yet another opportunity to optimize on an existing convenience. This, if anything, is a symptom of our current moment: People ignoring the luxury of a moving staircase in favor of whatever sprinting up it can transport them to faster.</p>



<p>There‚Äôs a kind of sick satisfaction derived from optimizing one‚Äôs own life, and there‚Äôs a good reason: Being able to do so is a status symbol. Only the most successful are free enough to spend their time finding better ways to spend their time. For those at the very top, I imagine these methods of optimization can actually exist in a vacuum; billionaires can optimize for the sake of optimizing, rather than to keep their head above water. For the rest of the world, optimization is a survival mechanism. To them, the tools that are luxuries to those at the top are good for one thing and one thing only: freeing up time that is only ever used to get more done.</p>



<hr>



<p>The one bright side to all this productivity should be that everyone makes more money, but that‚Äôs all too often not the case. The popular narrative is that we‚Äôre all working harder, but ‚Äúwages haven‚Äôt risen in 40 years,‚Äù and ‚Äúpurchasing power is lower now than any point in recent memory.‚Äù The economist in me has always struggled with this line of thinking. Wages are only truly relevant indicators of wealth in the sense that they allow you increased control over how you spend your time. If you‚Äôre earning a wage and a service comes along that saves you the time and effort you‚Äôd normally have to expend to access a certain good (read: Freshly for meals), that service effectively increases the value of your existing wage. Thus, even though you‚Äôre not earning any more money, you‚Äôre now wealthier.</p>



<p>For consumers, services like Google and Freshly do exactly this.</p>



<p>The media, though‚Ää‚Äî‚Ääand a select few politicians‚Ää‚Äî‚Ääprefer a different narrative. ‚ÄúThere‚Äôs a finite amount of money in the world,‚Äù they effectively claim, ‚Äúand since we‚Äôre making less, and tech companies are making more, it follows that tech companies are to blame for wage stagnation, which is a net bad, always.‚Äù</p>



<p>Reality, though, isn‚Äôt that simple.</p>



<p>Though companies like Google and Amazon do generate healthy‚Ää‚Äî‚Ääand yes, <a href="https://tradingeconomics.com/united-states/corporate-profits" rel="noreferrer noopener" target="_blank">quite frankly absurd</a>‚Ää‚Äî‚Ääreturns for their executive teams and shareholders, they‚Äôre valuable because people find whatever they offer to be worth more than whatever they‚Äôre being asked to pay for it. In the case of Google, that offering is time (via frictionless access to information), and its price is effectively zero. The partial rationalization I make for stagnant wages, then, is that Google and services like it allow people to get more out of the same wage.</p>



<p>In this world, Google and its contemporaries are to blame for wage stagnation, but only because they‚Äôre creating a world where wages are no longer necessarily synonymous with wealth. Ergo, wage stagnation at the hands of tech companies‚Ää‚Äî‚Ääeveryone‚Äôs favorite narrative‚Ää‚Äî‚Ääis a feature, not a bug.</p>



<p>The problem with this line of thinking, though, gets at the root of both the millennial ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/">https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/</a></em></p>]]>
            </description>
            <link>https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180229</guid>
            <pubDate>Sun, 22 Nov 2020 19:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: VimCharm, Approximating PyCharm on Vim]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25179408">thread link</a>) | @lonesword
<br/>
November 22, 2020 | https://kevinmartinjose.com/2020/11/22/vimcharm-approximating-pycharm-on-vim/ | <a href="https://web.archive.org/web/*/https://kevinmartinjose.com/2020/11/22/vimcharm-approximating-pycharm-on-vim/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-298">
		<!-- .entry-header -->

	<div>
		
<p>Disclaimer: All I‚Äôve done is write a few config files. </p>



<h3>This is for you if:</h3>



<ol><li>Your python IDE of choice is PyCharm</li><li>You wish you had a command-line replacement for PyCharm on all the places you ssh into</li><li>You wish you had access to at least <em>some</em> of the niceties of PyCharm when editing a one-off script, without having to create/import it into a new project.</li><li>You are somewhat familiar with vim and can comfortably edit a single file on vim. You also know what a <code>.vimrc</code> is</li></ol>



<figure><img data-attachment-id="372" data-permalink="https://kevinmartinjose.com/vimcharm/" data-orig-file="https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="vimcharm" data-image-description="" data-medium-file="https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png?w=300" data-large-file="https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png?w=739" src="https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png?w=1024" alt="" srcset="https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png?w=1024 1024w, https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png?w=150 150w, https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png?w=300 300w, https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png?w=768 768w, https://kevinmartinjose.files.wordpress.com/2020/11/vimcharm.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>VimCharm, featuring <a href="https://github.com/capreolus-ir/capreolus">capreolus</a></figcaption></figure>



<h3>Motivation</h3>



<p>PyCharm has worked wonderfully well for me, and the only time where I have to use something else is when I ssh into a server to put together a quick script. That something else tends to be vim, and this is an attempt to get vim as close to PyCharm as possible ‚Äì especially  the shortcuts so that I can work on vim the way I work on PyCharm (well, almost). The end result is still a far cry from PyCharm, but it makes navigating a codebase over ssh significantly less painful (at least for me) </p>



<h3>But PyCharm can work over ssh</h3>



<p>Yeah, but I don‚Äôt use PyCharm for one-off scripts. Besides, it pleases me to know that if I can ssh into the server (from an ipad, a phone, or a washing machine), I have an (approximate) IDE I can work on. </p>



<h3>List of working approximations</h3>



<ul><li>Sorta kinda uses the same colorscheme as PyCharm</li><li>Toggles a project navigation sidebar (NERDTree) using <code>alt + 1</code> . Approximates PyCharm‚Äôs <code>Ctrl+1</code> </li><li>Comment/uncomment multiple lines using <code>Ctrl+/</code>, just like PyCharm</li><li>Autocomplete</li><li>Navigate to the definition of a method/variable using <code>Ctrl + Left click</code> or <code>Ctrl + b</code>, just like PyCharm</li><li>Jump to the previous location using <code>Alt + -</code> . Approximates PyCharm‚Äôs <code>Ctrl + Alt + Left Arrow</code></li><li>Fuzzy search for files using <code>Ctrl + o</code>. Approximates PyCharm‚Äôs double shift press</li><li>Search the entire code base using <code>Alt + f</code>. Approximates PyCharm‚Äôs <code>Ctrl + Shift + f</code></li><li>Edits made in the search results window are reflected on to the underlying file, just like PyCharm</li><li>Syntax and linter errors show up as you type, just like PyCharm</li><li>If you are editing files that are part of a git repository, there are indicators on the gutter to show added, modified and subtracted lines, just like PyCharm</li><li>Pressing <code>F12</code> brings up a terminal. Approximates PyCharm‚Äôs <code>Alt + F12</code></li><li> Code folding using the minus (i.e <code>-</code>) key. Approximates PyCharm‚Äôs <code>Ctrl+-</code> and <code>Ctrl + +</code></li><li>Automatic file saves, just like PyCharm</li><li>Rename methods/variables and automatically fix imports e.t.c across files, just like PyCharm</li></ul>



<h3>Why not just use python-mode?</h3>



<p>I simply could not figure out the shortcuts that <a href="https://github.com/python-mode/python-mode">python-mode</a> used. I thought it would be easier and more flexible if I install and configure the plugins myself.</p>



<h3>Prerequisites</h3>



<ul><li>vim 8</li><li>A Python virtualenv (or a conda environment). There‚Äôs some <code>pip install</code> involved, though this is optional</li><li>Patience</li></ul>



<h3>TL;DR</h3>



<p>Go <a href="https://github.com/kevinmartinjos/vimcharm">here</a> for the <code>.vimrc</code></p>



<h3>Let‚Äôs start from a blank .vimrc</h3>



<p>If you need a project-specific <code>.vimrc</code>, see <a href="https://andrew.stwrt.ca/posts/project-specific-vimrc/">this</a>. If not, everything goes into your <code>~/.vimrc</code></p>



<p>Let us begin by being able to see line numbers and some sort of syntax highlighting everywhere. Put these on your <code>.vimrc</code>:</p>


<pre title="">" Some basic stuff
set number
set showmatch
syntax on
imap jj &lt;Esc&gt;
</pre>


<p>The <code>set showmatch</code> is for highlighting matching parentheses ‚Äì that‚Äôs useful. The last line maps double pressing the <code>j</code> key in insert mode to <code>&lt;Esc&gt;</code> ‚Äì no more reaching for that far away Escape key using your pinky!</p>



<h3>NERDTree for the sidebar</h3>



<p>We‚Äôll start our plugin-hoarding with <a href="https://github.com/preservim/nerdtree">NERDTree</a>. With Vim 8, we can simply copy over a plugin directory to a certain place and Vim would just ‚Äúpick it up‚Äù ‚Äì there‚Äôs no need to use a  plugin manager for achieving VimCharm. Create the necessary directory structure and clone NERDTree:</p>


<pre title="">mkdir ~/.vim/pack/vimcharm/start/ -p
git clone https://github.com/preservim/nerdtree.git ~/.vim/pack/vimcharm/start/nerdtree
</pre>


<p>Open some file (any file) on vim and type <code>:NERDTreeToggle</code> ‚Äì you should see the sidebar. Executing the same command again would close the NERDTree. PyCharm by default opens/closes the sidebar using <code>Ctrl + 1</code> . However, the terminal (and consequently Vim) cannot differentiate between 1 and <code>Ctrl + 1</code>, so we‚Äôll map this to <code>Alt + 1</code> instead. Before we do that, we need to determine what characters are sent by the terminal when we press the key combo. Simply run <code>cat</code> without any arguments, and press <code>Alt + 1</code>. You should see something like this:</p>



<figure><img data-attachment-id="307" data-permalink="https://kevinmartinjose.com/alt1/" data-orig-file="https://kevinmartinjose.files.wordpress.com/2020/11/alt1.png" data-orig-size="287,71" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="alt1" data-image-description="" data-medium-file="https://kevinmartinjose.files.wordpress.com/2020/11/alt1.png?w=287" data-large-file="https://kevinmartinjose.files.wordpress.com/2020/11/alt1.png?w=287" src="https://kevinmartinjose.files.wordpress.com/2020/11/alt1.png?w=287" alt="" srcset="https://kevinmartinjose.files.wordpress.com/2020/11/alt1.png 287w, https://kevinmartinjose.files.wordpress.com/2020/11/alt1.png?w=150 150w" sizes="(max-width: 287px) 100vw, 287px"></figure>



<p>You would also see that <code>1</code> and <code>Ctrl+1</code> produces the same character on <code>cat</code> ‚Äì as far as I know, there‚Äôs no way around this.</p>



<p>We need to map the character sequence for <code>Alt + 1</code> to <code>:NERDTreeToggle</code> on our <code>.vimrc</code>:</p>


<pre title="">set &lt;A-1&gt;=^[1
nmap &lt;A-1&gt; :NERDTreeToggle&lt;CR&gt;

</pre>


<p><strong>Take care not to simply copy paste the character sequence on to your <code>.vimrc</code>! </strong>That won‚Äôt work. You should open your <code>.vimrc</code> on Vim, go to <code>insert</code> mode, and press <code>Ctrl+v</code> ‚Äì this would put a caret under your cursor ‚Äì now press <code>Alt + 1</code> and it should fill in the necessary characters there. Restart vim, and <code>Alt+1</code> should now open and close NERDTree.</p>



<h3>Making it <em>look</em> like PyCharm</h3>



<p><a href="https://github.com/morhetz/gruvbox">Gruvbox</a> looks like the default PyCharm theme, kinda, so let‚Äôs get that:</p>


<pre title="">git clone https://github.com/morhetz/gruvbox.git ~/.vim/pack/vimcharm/start/gruvbox

</pre>


<p>According to the <a href="https://github.com/morhetz/gruvbox/wiki/Installation">installation</a> page, we need to add this to our <code>.vimrc</code>:</p>


<pre title="">autocmd vimenter * ++nested colorscheme gruvbox
</pre>


<h3>Commenting and Uncommenting lines using Ctrl + /</h3>



<p>We are going to use <a href="https://github.com/preservim/nerdcommenter">NERDCommenter</a> for this. Clone it into the right directory, just as before:</p>


<pre title=""> git clone https://github.com/preservim/nerdcommenter ~/.vim/pack/vimcharm/start/nerdcommenter

</pre>


<p><code>Ctrl+/</code> cannot be directly mapped on your <code>.vimrc</code>. So just like before, we insert the correct escaped character sequence into our <code>.vimrc</code> by going into insert mode, pressing <code>Ctrl+v</code>, and then pressing the desired keycombo (<code>Ctrl + /</code> in this case).</p>


<pre title="">" The part after "=" in the below line should be inserted using Ctrl+v while in insert mode and then pressing Ctrl+/
set &lt;F13&gt;=^_
noremap &lt;F13&gt; :call NERDComment(0,"toggle")&lt;CR&gt;

" So that NERDCommenter can automatically decide how to comment a particular filetype
filetype plugin on

</pre>


<p>We are telling Vim to map the character sequences that <code>Ctrl + /</code> produces to the <code>F13</code> key, which probably does not exist on your keyboard, and then we map <code>F13</code> to the appropriate command to toggle comments. Restart Vim, open (or create) a python file and try <code>Ctrl + /</code> while in normal mode ‚Äì it should comment/uncomment the line.</p>



<h3>Autocomplete</h3>



<p>Autocomplete on Vim does not feel as ‚Äúfluid‚Äù as on PyCharm  ‚Äì for example, I haven‚Äôt managed to get it to work on imports ‚Äì but it is still besser als nichts. Get <a href="https://github.com/davidhalter/jedi-vim">jedi-vim</a>:</p>


<pre title=""> git clone https://github.com/davidhalter/jedi-vim ~/.vim/pack/vimcharm/start/jedi-vim

</pre>


<p>Restart vim, and <code>Ctrl + space</code> should already be giving you autocomplete suggestions. IMHO, jedi-vim displays too much information (what even is that bar thing that comes up on  top?) ‚Äì all I wanted was a simple autocomplete prompt. Put this on your <code>.vimrc</code> to Make Autocomplete Great Again:</p>


<pre title="">let jedi#show_call_signatures = 0
let jedi#documentation_command = ""
autocmd FileType python setlocal completeopt-=preview

</pre>


<h3>Go-to definition using Ctrl+click</h3>



<p>This is something that jedi-vim already does ‚Äì all we need are some <code>.vimrc</code> entries:</p>


<pre title="">set mouse=a
let g:jedi#goto_command = "&lt;C-LeftMouse&gt;"
map &lt;C-b&gt; &lt;C-LeftMouse&gt;

</pre>


<p>The above lines enable mouse support on Vim, sets <code>Ctrl + left click</code> as the combination for jedi‚Äôs goto command, and then recursively maps <code>Ctrl+b</code> (which is also what PyCharm uses by default) to <code>Ctrl + left click</code> as a keyboard-friendly alternative.</p>



<p>I also prefer the goto command to open a new tab when navigating to a different file. Here‚Äôs how to enable that, along with <code>Shift+j</code> and <code>Shift+k</code> to move between tabs:</p>


<pre title="">let g:jedi#use_tabs_not_buffers = 1
nnoremap J :tabp&lt;CR&gt;
nnoremap K :tabn&lt;CR&gt;
</pre>


<h3>Jump to previous location using Alt + minus</h3>



<p>If you end up navigating multiple tabs away using <code>Ctrl+b</code>, you can press <code>Ctrl+</code>o repeatedly to jump back to your original position.  Press <code>Ctrl+i</code> to go in the other direction. These would come in handy if you have to quickly <code>gg</code> to the beginning of the file to add an import ‚Äì you can then press <code>Ctrl+o</code> to go back to the line you were editing. I believe in PyCharm the default mappings for this are <code>Ctrl + Alt + Left arrow</code> and <code>Ctrl + Alt + right arrow</code> respectively.  I remapped these to <code>Alt + -</code> and <code>Alt + Shift + -</code> (that would be in fact <code>Alt + _</code> ):</p>


<pre title="">set &lt;A--&gt;=^[-
noremap &lt;A--&gt; &lt;C-O&gt;
set &lt;A-_&gt;=^[_
noremap &lt;A-_&gt; &lt;C-I&gt;

</pre>


<p>Remember that copy-pasting these won‚Äôt work and you will have to enter insert mode and press <code>Ctrl+v</code> and then <code>Alt + -</code></p>



<h3>Fuzzy file search</h3>



<p>Fuzzy file search is what PyCharm does when you press the Shift key twice. </p>



<p>Download <a href="https://github.com/kien/ctrlp.vim">CtrlP</a>:</p>


<pre title="">git clone https://github.com/kien/ctrlp.vim.git ~/.vim/pack/vimcharm/start/ctrlp
</pre>


<p>By default pressing <code>Ctrl+p</code> should bring up the search prompt. We can‚Äôt map this to double shift (as in PyCharm) since vim can‚Äôt recognize <code>Shift</code> key presses (unless it‚Äôs combined with a printable character). I decided to map this to <code>Ctrl + </code>o instead (‚Äúo‚Äù for open), though this is not any better than the default setting. On your <code>.vimrc</code>:</p>


<pre title="">let g:ctrlp_map='&lt;C-O&gt;'
let g:ctrlp_cmd='CtrlPMixed'
</pre>


<p>The second line above specifies that the search should be over files, buffers, tags e.t.c ‚Äì you may omit it if you do not want buffers to show up on your search. <code>ctrl+t</code> on a search result will open it in a new tab. </p>



<h3>Search everywhere and replace</h3>



<p>One of the most useful features in PyCharm is the ‚Äúsearch in project‚Äù dialog that <code>Ctrl + Shift + f</code> brings up. For example, if  I delete/rename a hard-coded string literal, this is the dialog that I would bring up to look for all occurrences of that string literal so that I can rename/delete all of them ‚Äì right from the search window.</p>



<p>Instead of using the built-in <a href="https://vim.fandom.com/wiki/Find_in_files_within_Vim">vimgrep</a> or making an external call to the ubiquitous grep, we are going to use <a href="https://beyondgrep.com/why-ack/">ack</a> because it excludes annoying things like gitignore and binaries from the search results by ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kevinmartinjose.com/2020/11/22/vimcharm-approximating-pycharm-on-vim/">https://kevinmartinjose.com/2020/11/22/vimcharm-approximating-pycharm-on-vim/</a></em></p>]]>
            </description>
            <link>https://kevinmartinjose.com/2020/11/22/vimcharm-approximating-pycharm-on-vim/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25179408</guid>
            <pubDate>Sun, 22 Nov 2020 17:54:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Makes a Great Product Manager]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25179296">thread link</a>) | @laybak
<br/>
November 22, 2020 | https://informedpm.com/posts/great-product-manager | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/great-product-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>What sets great product managers apart from merely good ones? </span></p> <p><span>It is a difficult question to answer because there are so many things that "great" product managers do. And because the discipline itself is changing very quickly. There is no universal answer. But it is a question worth asking.</span></p> <p><span>I tackled this question by interviewing industry leaders, drawing on my own experience, and research. </span></p> <p><span>Here are the top traits, principles, and tactics I collected, that great product managers tend to share.</span></p>  <p><h3><span>Data + Intuition</span></h3></p> <p><span>As product managers, we face many decisions every day. But what does "effective decision making" mean?</span></p> <p><span>Being "data-driven" is a good start. But the term is so overused that it has lost its meaning. It also has its blind spots. </span></p> <p><span>Here is how </span> <a href="https://twitter.com/trevin" target="_blank"><span>Trevin Chow</span></a> <span>, Director of Product at Nike, put it:</span></p> <div><blockquote><span>Great product managers are able to find the right balance between data and intuition at any given moment to inform and drive their decision making. This could be something as small a bug fix, or something much larger such as which features to include in a v1 vs what to cut.

The best product managers I've worked with are able to do this very well, balancing all sorts of inputs of "data" and combining it with their intuition to find the right balance of any given moment on what to index on.</span></blockquote></div>  <p><h3><span>Truth-Seeking</span></h3></p> <p><span>Both scientists and product managers play a truth-seeking game ‚Äî scientists test their ideas in the natural world; product managers test theirs in the market.</span></p> <p><span>Ôªø</span> <a href="https://www.linkedin.com/in/danielfalabella" target="_blank"><span>Daniel Falabella</span></a> <span>, Director of Product at Duolingo, believes that "90% of a Product Manager‚Äôs job is to find 'truth'". And this is one reason why Daniel thinks that entrepreneurs make the best PMs. He added,</span></p> <div><blockquote><span>Lots of PMs go through the motions: they talk to teammates, become familiar with vanity metrics, talk to 2 users, or assume that their managers are right. They give the illusion of having the right inputs, only to pay up the price when it's time to discuss outputs.</span></blockquote></div>  <p><h3><span>Adaptable</span></h3></p> <p><span>Product managers are responsible for the success of their products. But the path to get there is rarely straight-forward.  </span></p>  <div><blockquote><span>Great PMs are adaptable. They know when to go into execution mode, and when to step back and work on strategy. They make everyone around them feel heard. At the end of the day, they make their customers and business successful, and their teams and cross functional partners want to work with them over and over again.</span></blockquote></div>   <div><blockquote><span>Underrated skill for founders: Altitude shifting. 

People are often either good at high-level strategy or atomic-level execution, but rarely both.

It's the ability to zoom out &amp; paint the 5 yr vision, and then drop down into the weeds of day-to-day, &amp; see how the two connect.</span></blockquote></div>  <p><h3><span>First Principles</span></h3></p> <p><span>Ôªø</span> <a href="https://blackboxofpm.com/" target="_blank"><span>Brandon Chu</span></a> <span>, VP Product &amp; GM of Platform at Shopify, </span> <a href="https://blackboxofpm.com/the-first-principles-of-product-management-ea0e2f2a018c" target="_blank"><span>wrote in an article</span></a> <span> that some of the best PMs he knows make their decisions based on first principles. He explained,</span></p> <div><blockquote><span>First principle thinking helps PMs because as companies scale, communicating the rationale behind historical, current, and future decisions can be simplified in a way that their team and stakeholders can rally around. </span></blockquote></div> <div><blockquote><span>This enables people around the PM to move quickly in the same direction, decouple, and make smart trade offs without their presence.</span></blockquote></div>    <p><h3><span>Deep Understanding of the Problem</span></h3></p> <p><span>It is tempting, especially for the technically-minded folks, to start with an idea for a solution and run with it. But building a great product requires understanding the problem, and understanding the person behind the problem.</span></p>  <div><blockquote><span>If you get on the ground and hear what people are suffering from, then you can have a deeper understanding of what needs to be done. It‚Äôs not just empathy. It‚Äôs being specific and zoning in on the areas of improvement based on people‚Äôs real experiences."</span></blockquote></div>  <p><span>Ôªø</span> <a href="https://twitter.com/lissijean" target="_blank"><span>Melissa Perri</span></a> <em>, </em> <span>CEO and founder of Produx Labs, </span> <a href="https://roadmunk.com/blog/melissa-perri/" target="_blank"><span>said in an interview</span></a> <span> that "
what sets a decent product manager apart from a really great product manager, is really the way they think and approach problems". She continued,</span></p> <div><blockquote><span>To me, thinking like a product manager is about problem solving. It‚Äôs about synthesizing a lot of information, understanding the system, trying to piece together what is the problem, breaking it down into small manageable chunks so you can analyze it, and then figuring out what is the right solution from there.</span></blockquote></div>  <p><h3><span>Humble and Coachable</span></h3></p> <p><span>Being humble/coachable is what Daniel (from earlier) considers the other important trait of a great product manager.</span></p> <p><span>Related to the truth-seeking point, you will be wrong a lot throughout your career. This may be a tough pill to swallow for the smart and ambitious ones. But it is an important part of growing as a person and learning to make better decisions over time.</span></p>  <p><h3><span>Evangelize</span></h3></p> <p><span>Your work isn't done when the requirements are defined, or even when the product gets shipped. </span></p>  <div><blockquote><span>If you‚Äôre not sick of saying it, you probably aren‚Äôt saying it enough. Constant communication might feel like ‚Äúfluff,‚Äù but it isn‚Äôt. Evangelism is a critical part of the role‚Äîand it‚Äôs your job to make sure the organization is aligned and swimming in the same direction.</span></blockquote></div> <p><span>And that,</span></p> <div><blockquote><span>For you [product managers], communication&nbsp;</span> <em>is</em> <span>&nbsp;a primary ‚Äúoutput,‚Äù and it should be exceptional.</span></blockquote></div>  <p><h3><span>Resourceful</span></h3></p> <p><span>There are always more things to build than there is time for. And often, you don't get as many people working on your product as you would like.</span></p> <p><span>Mastering the art of stretching resources given a tight budget is valuable.</span></p> <p><span>This could mean finding cheaper technical workarounds. This could mean ruthlessly focusing on the small number of things that will really move the needle.</span></p>  <p><h3><span>Love of Making Things</span></h3></p> <p><span>Ôªø</span> <a href="https://www.ellenchisa.com/" target="_blank"><span>Ellen Chisa</span></a> <span>, Co-founder of Dark and former VP of Product at Lola, </span> <a href="https://mokriya.com/blog/the-new-product-manager-a-conversation-with-ellen-chisa/" target="_blank"><span>said in an interview</span></a> <span> that, "You have to really love making things, but you have to be okay with not being the person actually making the thing."</span></p> <p><span>Having a genuine love for making things is powerful. This intrinsic motivation can keep you going, especially when things get difficult.</span></p> <p><span>This genuine interest also translates to you noticing other cool products in your life and building things outside of work.</span></p>  <p><h3><span>At the End of the Day</span></h3></p> <p><span>Ultimately, your responsibility as a product manager to ship successful products. To help your business and customers succeed. </span></p> <p><span>Being on top of things. Delivering results. These are attributes of a great PM that few would disagree.</span></p>  <p><h3><span>Further Readings</span></h3></p>  <p><span>Ôªø</span> <a href="https://blackboxofpm.com/the-first-principles-of-product-management-ea0e2f2a018c" target="_blank"><span>The First Principles of Product Management</span></a> <span> by Brandon Chu. It boils down product management to maximizing impact to the mission given a set of inputs and accomplishing everything through others.&nbsp;</span></p>  <p><span>Ôªø</span> <a href="https://www.lewis-lin.com/blog/2019/4/11/introducing-the-esteem-method" target="_blank"><span>ESTEEM Method</span></a> <span> by Lewis C. Lin: Execution, Superior communication skills, Tactical awareness, Extraordinary mental toughness, Exceptional team builder, Moonshot vision.</span></p>        
          
          
          <p><em>Each week, I send out a newsletter with the latest product learnings and insights.</em></p>
          <p><em>Enter your email below to subscribe.</em></p>

          
        </div></div>]]>
            </description>
            <link>https://informedpm.com/posts/great-product-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-25179296</guid>
            <pubDate>Sun, 22 Nov 2020 17:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Opinion: On Google‚Äôs ReCAPTCHA Privacy Nightmare]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25179248">thread link</a>) | @wikus
<br/>
November 22, 2020 | https://hfet.org/google-recaptcha-privacy-nightmare/ | <a href="https://web.archive.org/web/*/https://hfet.org/google-recaptcha-privacy-nightmare/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	<h2>Opinion ‚Äì Google ReCAPTCHA</h2>
<p>You‚Äôre no doubt familiar with clicking on a box declaring that you are not a robot, that looks something like this:</p>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/e62.gif" alt="" width="383" height="102"></p>
<p>For most people, this only takes a few seconds, validates, and lets them continue on their way. However, if you‚Äôre not signed into your Google Account, don‚Äôt use Google Chrome and have any kind of tracking protection in your browser, there‚Äôs a good chance you‚Äôll be <em>treated</em> with the opportunity of helping train Google‚Äôs Machine Learning image recognition algorithms:</p>
<figure id="attachment_395" aria-describedby="caption-attachment-395"><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-1024x707.png" alt="" width="800" height="552" srcset="https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-1024x707.png 1024w, https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-300x207.png 300w, https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-768x530.png 768w, https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue.png 1200w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-395"><a href="https://www.digitalinformationworld.com/2019/06/internet-users-unite-to-speak-up-against-the-inconveniences-caused-by-recaptcha.html">Image Source</a></figcaption></figure>
<p>Google has a history of mass-outsourcing free labour to the global population of internet users, with ReCAPTCHA v2, they employed the involuntarily help of millions to <a href="https://www.techradar.com/news/captcha-if-you-can-how-youve-been-training-ai-for-years-without-realising-it" target="_blank" rel="noopener noreferrer">transcribe scanned books</a>, which lead to <a href="https://www.wired.com/2013/11/google-books-2/" target="_blank" rel="noopener noreferrer">large copyright cases</a>.</p>
<p>With ReCAPTCHA v3, or the <em>I‚Äôm not a robot</em> checkbox, <a href="https://developers.google.com/recaptcha/docs/v3" target="_blank" rel="noopener noreferrer">Google tracks your usage around the website</a> it is embedded on before you even get to the Captcha form.</p>
<h3>You agree to Google‚Äôs Privacy Policy</h3>
<p>Ever clicked <em>I‚Äôm not a robot</em>? In doing so, you agree to Google‚Äôs Terms of Service and Privacy Policy.</p>
<p>Perhaps you‚Äôre thinking it‚Äôs easy to avoid, but let me assure you it isn‚Äôt ‚Äì once you start paying attention to every place using Google ReCAPTCHA v3, you‚Äôll be shocked!</p>
<p>I choose to use Firefox and DuckDuckGo, and to avoid Google services as much as possible. But if I want to do something like track a package, I have to agree to Google‚Äôs Privacy Policy.</p>
<p>Google‚Äôs tracking code is <a href="https://w3techs.com/technologies/details/ta-googleanalytics" target="_blank" rel="noopener noreferrer">on more websites than any other</a>, including Facebook.</p>
<h3>Alternatives</h3>
<p>In my opinion, Google clearly holds monopolies in many areas least of all this, and needs to be broken up. Failing this, ReCAPTCHA needs to be redesigned such that it doesn‚Äôt serve as tracking and free labour for image recognition, and instead purely serves as a validation tool. A good start to this would be making the code FOSS, and allowing webmasters to self host it, rather than relying on Google‚Äôs black box proprietary cloud services.</p>
<p><strong>If you‚Äôre a website owner and looking to replace Google ReCAPTCHA, here is a <a href="https://switching.software/replace/google-recaptcha/" target="_blank" rel="noopener noreferrer">fantastic guide</a>.<br>
</strong></p>
<p>Additionally, <a href="https://www.hcaptcha.com/" target="_blank" rel="noopener noreferrer">hCaptcha</a> is a much more privacy friendly, drop in replacement for Google ReCAPTCHA.</p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div></div>]]>
            </description>
            <link>https://hfet.org/google-recaptcha-privacy-nightmare/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25179248</guid>
            <pubDate>Sun, 22 Nov 2020 17:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The dubiousness of digitized signature services]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25177349">thread link</a>) | @Edmond
<br/>
November 22, 2020 | https://blog.certisfy.com/2020/11/the-dubiousness-of-digitized-signature.html | <a href="https://web.archive.org/web/*/https://blog.certisfy.com/2020/11/the-dubiousness-of-digitized-signature.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>
The dubiousness of digitized signature services
</h3>
</div><div>
<div id="post-body-8553362812323687543">
<div><p>Notice I referred to "digitized" instead of digital, this is a very important distinction. These services essentially offer ways to transport handwritten scribbles into digital processes. They can be anything from attaching a Microsoft paint scribble or a scan of one written on a piece of paper, to custom font generation that makes&nbsp; your signature look like you are a former president of the united states. </p><p>I wont mention any such services by name but if you've purchased a house or engaged in any sort of contract paperwork activity (leases..etc) you have likely encountered these services. Last I checked, one of these companies is worth north of $40B, no doubt reflecting the size of the market for such services.</p><p>First, what is the purpose of any signature? as the name suggests, it is primarily to ascribe provenance to something, be it an abstract thing such as a legal agreement expressed in writing or a physical object such as a painting. We also use the notion of signature to refer to a manifestation that serves as a tell-tale sign of some fact (or the truthfulness thereof) without necessarily observing the actual manifestation of the fact itself.</p><p>What is the purpose of signing a paper then? Well, it is suppose to first, attest to the fact that the entity whose identity is associated with the document is consenting to whatever it is that the paper implies. Second, your scribbles are supposed to be unique, such that someone could not forge them and fool others into accepting an agreement that the identified entity is in fact not a party to.</p><p>Hand written signatures even in the days of king Henry were more of an intellectual pretense than an effective mechanism for genuine projection of trust. That they have persisted into the 21st century is more than distressing. </p><p>We now have even the democratic franchise of voting citizens tethered to matching variations of such scribbles. My handwritten signature varies based on what I had for breakfast, so the idea that anyone would want to judge the authenticity of any document based on it would be hilarious if it weren't such a serious matter.</p><p>The entire edifice of affixing handwritten scribbles (or their digital imitations) to documents is quite mindless if the aim of signatures as described above is to be achieved.</p><p>Obviously the need for entities to affirmatively agree to conditions and to have that recorded in a way that is tamper-proof and indisputable has not gone away. However, given the purpose of signatures, it is clear that scribbles on paper or their digitized cousins are certainly not an answer. At best one can consider these services as ceremonial, in as far as they facilitate the continuation of the pre-digital processes that demand handwritten signatures.</p><p>What then is the solution to signatures in the digital era? The answer is simple and well understood (hard to believe perhaps), PKI certificates. Given that Certisfy is about leveraging PKI for trust on the internet, this is a self-serving answer but it is also a true answer.</p><p>A digital signature (not a digitized one) of a document, along with the certificate whose private key was used to generate such a signature is all that is needed to achieve the intended goal of handwritten signatures. </p><p>From a purely technical requirement perspective, you would need to add no more than two new entries to your data model to support this, a field to store the cryptographic signature and a field to store the cryptographic certificate-chain that can verify that signature. If a dispute were to emerge a century from now, you wouldn't need to hire medieval forensic experts to authenticate the document, you would simply run the signature and document through the appropriate cryptographic verification function to authenticate it.</p><p>There are of course legitimate arguments to make against PKI (some favor blockchain contracts..etc), but when the alternative is handwritten scribbles, such arguments diminish towards meaninglessness.</p></div>
</div>

</div></div>]]>
            </description>
            <link>https://blog.certisfy.com/2020/11/the-dubiousness-of-digitized-signature.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177349</guid>
            <pubDate>Sun, 22 Nov 2020 13:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When science was the best show in America]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 151 (<a href="https://news.ycombinator.com/item?id=25177334">thread link</a>) | @CapitalistCartr
<br/>
November 22, 2020 | http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>O</span>n May 29, 1810, Katherine Fritsch, a sister in the Moravian Church, boarded a coach in Lititz, Pennsylvania, along with a group of her friends and began the 75-mile trek to Philadelphia. Fritsch noted in her diary the one city site she most wished to see: Peale‚Äôs Museum. On the grounds of the museum, whose two buildings sat on State House Square, with rows of trees and manicured lawns, Fritsch passed through a menagerie that included a large cage with a live eagle sitting ‚Äúright majestically on his perch‚Äîabove his head a placard with this petition on it: feed me daily for 100 years.‚Äù</p><figure data-alt="Dugatkin_BREAKER-1"><img src="http://static.nautil.us/17940_1221132d8390ea66832cf2eabd8eb668.png" width="733" alt=""><figcaption><span><strong>THE MET OF ITS TIME:</strong> Charles Willson Peale painted this self-portrait to celebrate his pioneering museum. Its goal, he wrote his friend Thomas Jefferson, was to collect subjects in nature and ‚Äúenlighten the minds of my countrymen.‚Äù</span><span>Charles Willson Peale; <i>The Artist in His Museum</i>, 1822; Oil on canvas; Courtesy of the Pennsylvania Academy of the Fine Arts, Philadelphia.&nbsp;Gift of Mrs. Sarah Harrison (The Joseph Harrison, Jr. Collection), 1878.1.2</span></figcaption></figure><p>From the yard, Fritsch went into the Peale Museum proper, through a door with ‚ÄúWhoso would learn Wisdom, let him enter here!‚Äù posted above. Fritsch walked past a turnstile that rang chimes to announce visitors. She walked up the stairs and into the Quadruped Room, which included a moose, llama, bear, bison, prong-horned antelope, hyena, and a jackal. She explored the Marine Room, overflowing with fish, amphibians, lizards, sponges, and corals. In the Long Room, glass cases were filled with hundreds of birds set against backdrops matching their natural environments; she saw insect cases in which the specimens could be rotated under a microscope. Fritsch didn‚Äôt get to see the museum‚Äôs mammoth skeleton, but noted in her diary that ‚Äúall our talk was of how delightful had been our visit to the museum.‚Äù<br></p><p>Fritsch was not the only one who felt that way. From the time Peale‚Äôs Museum had opened its doors in 1786, annual attendance had averaged more than 10,000 people. Born both of science and art, it was the first true museum in the fledgling United States and the first must-see attraction not only for Philadelphians but for visitors from around the U.S. and the world. The museum‚Äôs creator, Charles Willson Peale, saw the museum as a national good. The ‚Äúvery sinews of government are made strong by a diffused knowledge of this science,‚Äù he wrote. The museum‚Äôs success made Peale a proud man for many years. It embodied the age of Enlightenment in the new world. After a visit, the French philosopher Comte de Volney proclaimed the museum housed ‚Äúnothing but truth and reason.‚Äù But national funding for truth and reason foundered on the shore of politics. And then the circus came to town.</p><p><span>P</span>eale was born in Maryland in 1741. When he was 9, his father, a schoolteacher, died, leaving the family in poverty. Peale was apprenticed to a saddler at age 13, but spent almost as much time tinkering with mechanical devices of all sorts as he did saddling. His other interest lay in paint brushes and sketching pads. Ambitious as could be, Peale became the Colony‚Äôs most famous portrait painter. In 1771, Peale met Martha Washington and convinced her that Colonel Washington should sit for him‚Äîthe first of 25 portraits, miniatures, mezzotints, or sculptures he would do of the soon-to-be general. Peale also painted portraits of Thomas Jefferson, Benjamin Franklin, and Alexander Hamilton. He named most of his 17 children after famous painters, including Rembrandt, Rubens, and Titian.</p><p>A true autodidact, Peale saw himself as a naturalist and scientist. And any self-respecting deist of the Enlightenment should have a museum. Fortunately, Peale knew all the right people. Robert Patterson, professor of mathematics at the University of the State of Pennsylvania, gave Peale his first specimen for the museum, ‚Äúa curious fish called the paddle fish caught in the Allegheny River,‚Äù Peale wrote. Ben Franklin sent his friend the body of an angora cat that Madame Helv√©tius had given him when he departed Paris, and Washington sent the body of a just-deceased golden pheasant from the aviary of Louis XVI that the general had received as a gift from the Marquis de Lafayette. Other specimens soon came flooding in.</p><blockquote><p>Peale wrote that society raised roadblocks to women, which didn‚Äôt allow them to pursue science.</p> </blockquote><p>In a letter to Jefferson, Peale explained that his goal for the museum was to bring together ‚Äúa variety of interesting subjects of Nature ‚Ä¶ collected in one view as would enlighten the minds of my countrymen, and, demonstrate the importance of diffusing a knowledge of the wonderful and various beauties of Nature, more powerful to humanize the mind, promote harmony, and aid virtue than any ‚Ä¶ yet imagined.‚Äù<br></p><p>Peale, a former member of the Philadelphia Militia, was a true-blooded patriot. He created an effigy of a double-faced model of Benedict Arnold in a carriage, dressed in a red coat and holding a letter to Beelzebub with the devil standing behind him shaking a purse full of money. When it came to his museum, he had no intent of curating the sort of European hall that catered only to ‚Äúparticular classes of society only, or open at such turns or at such portions of time, as effectually to debar the mass of society, from participating in the improvement, and the pleasure resulting from a careful visitation,‚Äù he wrote. His museum would be open to all‚Äî‚Äúthe unwise as well as the learned.‚Äù</p><p>Peale held progressive views on women and children, and because he knew that a family-friendly venue would attract more visitors, he reached out to bring women and children into his museum. Women were not only encouraged to visit the museum, Peale wanted them to contribute to the enterprise, sending in samples and sharing ideas. Society, he believed, raised roadblocks to women ‚Äúwhich allow no time for them to devote in the arduous pursuits of science,‚Äù but, he was quick to point out, ‚Äúwhen females have devoted themselves to these pursuits they have given every demonstration of the intensity and depth of their intellectual powers.‚Äù He wanted to tap into those powers to better the museum and the plight of women.</p><figure data-alt="Dugatkin_BREAKER"><img src="http://static.nautil.us/17932_bbc90218e55a81732f0f78c16cbf2b6f.png" width="733" alt=""><figcaption><span><strong>TOM THUMB‚ÄôS BLUES:</strong> Charles Stratton (right) was a child when P.T. Barnum (left) first hired him to perform in his museum. Barnum publicized Stratton as ‚ÄúGeneral Tom Thumb,‚Äù a character who became a major attraction for the circus impresario for decades.</span><span>Wikimedia</span></figcaption></figure><p>Reverend Manasseh Cutler, a respected naturalist of the day, who had gained fame for his bravery as a chaplain during the Revolution, was an early visitor to Peale‚Äôs Museum in 1787 and was struck by the exhibits ‚Äúarranged in a most romantic and amusing manner.‚Äù He describes two dioramas‚Äîa mound with trees and an artificial pond, each the result of Peale having spent many a morning ‚Äúdressing the museum in moss.‚Äù The pond was stocked with fish, geese, ducks, cranes, and herons, ‚Äúall having the appearance of life, for their skins were admirably preserved.‚Äù On the beach around the pond Cutler was dazzled by an assortment of ‚Äúshells of different kinds, turtles, frogs, toads, lizards, water snakes, etc.‚Äù Cutler‚Äôs diary ends: ‚ÄúMr. Peale‚Äôs animals reminded me of Noah‚Äôs Ark, into which was received every kind of beast and creeping thing in which there was life. But I can hardly conceive that even Noah could have boasted of a better collection.‚Äù<br></p><p>From the outset, the museum was meant to be a collaborative effort. Jefferson, Hamilton, James Madison, Gouverneur Morris, famed astronomer David Rittenhouse, and naturalists Benjamin Smith Barton and William Barton, sat on the museum‚Äôs board of directors. But this museum was not to be some highfalutin society club. Peale turned more often to his fellow citizens than to his board of directors to contribute what they could, be it specimen or knowledge. Each year, he would publish dozens of newspaper advertisements that included not just a call for specimens, but lists of new specimens received of late, information about new exhibits, changes to museum hours of operation, and perhaps strangest to our eyes, praise or admonitions of the way the public was responding to activities at the museum.</p><p>A few years after it opened, in a series of parades, young boys (and older men) moved all the exhibits to the museum‚Äôs new home in the American Philosophical Society‚Äôs Philosophical Hall. Peale and his family moved their own home to the basement of the museum, so as to better manage the ever-growing enterprise. Soon, the museum outgrew even Philosophical Hall and moved to the State House (what we now call Independence Hall), above the rooms where the Declaration of Independence were signed, and below where a soon to be rather famous bell rang each day.</p><p><span>I</span>n 1801, Peale and a team undertook the first major paleontological excavation in the U.S. Near Newburgh, New York they dug up, and then painstakingly reconstructed, the complete skeleton of a mammoth (technically, it was a mastodon, but that distinction did not yet exist). It was quite the sight and caught the fancy of locals. ‚ÄúEvery farmer with his wife and children, for twenty miles round in every direction flocked to see the operation,‚Äù wrote Peale‚Äôs son Rembrandt. The <i>Mercantile Advertiser</i> soon ran tantalizing headlines like ‚ÄúBones of a Mammoth or some other Wonderful Animal,‚Äù titillating readers with tales of ‚Äúa monster so vastly disproportionate to every creature; as to induce a momentary suspension of every animal faculty but admiration and wonder.‚Äù</p><blockquote><p>Ben Franklin sent his friend the body of an angora cat and George Washington sent a golden pheasant.</p> </blockquote><p>In <i>Skeleton of the Mammoth</i>, a broadside that Peale posted across Philadelphia in 1802, he informed readers that though ‚Äúnumerous have been the attempts of scientific characters of all nations to procure a satisfactory collection of bones,‚Äù he and his museum had at last done just that. Peale even had one of the museum employees distribute the broadside throughout the city while on horseback ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america">http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177334</guid>
            <pubDate>Sun, 22 Nov 2020 13:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sengi ‚Äì A FLOSS multi-account Mastodon and Pleroma desktop client]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25177330">thread link</a>) | @blindm
<br/>
November 22, 2020 | https://nicolasconstant.github.io/sengi/ | <a href="https://web.archive.org/web/*/https://nicolasconstant.github.io/sengi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>

            <p>
                    Sengi will let you use all your accounts<br> easily and seamlessly<br>
                </p>

        </section>

        

        <section>
            <h2>Quick Overview</h2>

            <video controls="">
                <source src="https://nicolasconstant.github.io/sengi/videos/Quick_overview.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </section>

        

        <section>
            <h2>Main Functionalities</h2>

            <h4>Seamless account switch</h4>
            <div>
                <p>
                        Just click on the account's avatar, <br>
                        and all your next actions will be performed by it.
                    </p>
                <p>
                    <video width="326" height="260" controls="">
                        <source src="https://nicolasconstant.github.io/sengi/videos/Clip_account_switch.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </p>
            </div>

            <h4>All instances timelines in one place</h4>
            <div>
                <p>
                        Add timelines and lists from all your accounts in the same
                        interface.
                    </p>
                <p><img src="https://nicolasconstant.github.io/sengi/images/timelines.png">
                </p>
            </div>

            <h4>Don't lose your focus</h4>
            <div>
                <p>
                        Opening a profile, thread, hashtag or even just replying to someone will always take place in the
                        current Timeline.
                    </p>
                <p>
                    <video width="326" height="260" controls="">
                        <source src="https://nicolasconstant.github.io/sengi/videos/Clip_timelines.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </p>
            </div>

            <h4>Labels</h4>
            <div>
                <p>
                        Get a quick insight if a status is part of a thread, has replies, is from a bot, is old, is
                        cross-posted (limited to local TL) or is remotely fetched.<br>
                        <a href="https://github.com/NicolasConstant/sengi/wiki/Labels">more details</a>
                    </p>
                <p><img src="https://nicolasconstant.github.io/sengi/images/labels.png">
                </p>
            </div>

            <h4>Auto-remove Thread's Content-Warnings</h4>
            <div>
                <p>
                        Easily remove all CW from a thread<br>
                        with one single click!
                    </p>
                <p>
                    <video width="326" height="260" controls="">
                        <source src="https://nicolasconstant.github.io/sengi/videos/Clip_cw_button.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </p>
            </div>

            <h4>And many more!</h4>

            <p>
                    There is a lot more things to discover<br> and more to come too!
                </p>

        </section>
        
    </div></div>]]>
            </description>
            <link>https://nicolasconstant.github.io/sengi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177330</guid>
            <pubDate>Sun, 22 Nov 2020 13:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a roam-like, networked, heavily-customized realtime editor, part 1]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25177290">thread link</a>) | @namiheike
<br/>
November 22, 2020 | https://namiwang.github.io/2020/11/12/building-a-roam-like-networked-heavily-customized-realtime-editor-part-1.html | <a href="https://web.archive.org/web/*/https://namiwang.github.io/2020/11/12/building-a-roam-like-networked-heavily-customized-realtime-editor-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        
        <time datetime="2020-11-12T12:21:42+00:00">November 12, 2020</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section itemprop="text">
        
        

<blockquote>
  <p>I can build this.</p>

  <p>‚Äî <cite>every developer at least once</cite></p>
</blockquote>

<p>Knowledge is hard to manage, as mind is hard to materialize and visualize.</p>

<p>Bi-directional networked tools like <code>roam-research</code> and <code>obsidian</code> are on the trend for a while now. <a href="https://en.wikipedia.org/wiki/Knowledge_graph">The idea behind them</a> is not brand new, yet the much evolved web-based tech makes them possible.</p>

<h2 id="what-i-want-to-build">what I want to build</h2>

<p>I record my building of <code>fiber-note</code> in this series of dev posts, what I want to build is:</p>

<ul>
  <li>tag-based bi-directional networked note-taking</li>
  <li>web-based real-time experience
    <ul>
      <li>constantly auto-saving</li>
      <li>real-time reactive interface
        <ul>
          <li>updating components other than the editor (related notes, navigation, tags network, calendar, etc.)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>a highly-customized editor
    <ul>
      <li>enforce a custom schema to control the layout of the documents
        <ul>
          <li>say everything is a list item, there may be only text and tags in a paragraph, etc.</li>
        </ul>
      </li>
      <li>handle meta-data like tags, assigning unique ids for the block</li>
      <li>complex UI like inline drop-down menu</li>
      <li>‚Ä¶</li>
    </ul>
  </li>
  <li>visualize data as a network and a calendar</li>
  <li>open-sourced and self-hosted</li>
</ul>

<h2 id="code--demo">code &amp; demo</h2>

<p><a href="https://github.com/namiwang/fiber-note" target="_blank">
  <img src="https://namiwang.github.io/assets/images/fiber-note.gif" width="480" alt="fiber note screenshot">
</a></p>

<p>I placed the source <a href="https://github.com/namiwang/fiber-note">here</a>, which could be hosted by yourself. There‚Äôs even a configured deploy-to-heroku button for one-click hosting.</p>

<p>I also put up a public demo running at <a href="https://fiber-note-demo.herokuapp.com/session/new">fiber-note-demo.herokuapp.com</a> (password is <code>password</code>).</p>

<h2 id="naming-the-project">naming the project</h2>

<p>I always use rails as my first choice for web projects, and the first code name for this project is <code>roam-on-rails</code>, which is a bad joke since I‚Äôve already got a project called <a href="https://github.com/ruby-on-rust/ruby-on-rust">ruby on rust</a>.</p>

<p>I‚Äôm bad at this, so I just picked the word <code>fiber</code> as a synonym for <code>network</code> from the thesaurus.</p>



<h2 id="a-prototype-on-paper">a prototype on paper</h2>

<p><a href="https://namiwang.github.io/assets/images/fiber-note-series/fiber-note-diagram.png" target="_blank">
  <img src="https://namiwang.github.io/assets/images/fiber-note-series/fiber-note-diagram.png" alt="fiber note data structure">
</a></p>

<h2 id="a-data-structure-in-mind">a data structure in mind</h2>

<p>The whole database is structured as a directed graph. The basic unit is a <code>block</code>, a node in the graph, representing a paragraph, bearing data like its content and optional tags.</p>

<p>Every block-node may have one parent. Thus a note, spawning from the root (a parent-free block-node), forms a tree and the whole database forms a forest.</p>

<p>There‚Äôre some edge cases to consider</p>

<ul>
  <li>have to avoid cycles in the graph</li>
  <li>a tag may points to the same note</li>
</ul>

<h2 id="a-data-structure-on-disk">a data structure on disk</h2>

<p>Apparently we need to maintain a graph, yet I didn‚Äôt choose a graph-oriented database like <code>neo4j</code>. Using good old SQL to simulate one is good enough for now.</p>

<p>There‚Äôre both plugins to do graph on database level (<a href="https://www.postgresql.org/about/news/announcing-age-a-multi-model-graph-database-extension-for-postgresql-2050/">AGE</a> for postgresql), and rails level (like <a href="https://github.com/jackc/edge">edge</a>). For the initial implementation, I chose to hand-written everything from the grounded up for faster iteration because I was constantly changing things.</p>



<p>This is gonna be a front-end-heavy project, I have to choose an editor as one of the first steps.</p>

<h2 id="requirements">requirements</h2>

<ul>
  <li>restrict the doc to a special set of content types
    <ul>
      <li>e.g. allow list, list item, and inline tags; disallow individual paragraphs or images</li>
    </ul>
  </li>
  <li>render existing data into the editor</li>
  <li>inspect and manipulate input from the user
    <ul>
      <li>enforce input rules like properly wrapping/indenting list items</li>
      <li>assign unique ids to created blocks</li>
    </ul>
  </li>
  <li>implement drop-down menu to auto-complete tags</li>
  <li>send updated content to the server</li>
  <li>features we may need in the future
    <ul>
      <li>copy-and-paste, drag-and-drop, image, etc.</li>
    </ul>
  </li>
</ul>

<h2 id="comparision">comparision</h2>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>trix</th>
      <th>quill</th>
      <th>prose-mirror</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>integrating</td>
      <td>easy</td>
      <td>moderate</td>
      <td>moderate-to-high</td>
    </tr>
    <tr>
      <td>customization</td>
      <td>minimal</td>
      <td>moderate</td>
      <td>high</td>
    </tr>
    <tr>
      <td>custom schema</td>
      <td>no</td>
      <td>no</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>plugins</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>themes</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
    </tr>
    <tr>
      <td>docs</td>
      <td>minimal</td>
      <td>detailed</td>
      <td>detailed</td>
    </tr>
    <tr>
      <td>typescript</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>scenario</td>
      <td>adding rich-text editing to your rails app in 10 minutes</td>
      <td>building editor email client with some cool features like markdown syntax</td>
      <td>building editor for an collaborative encyclopaedia with custom schema.</td>
    </tr>
  </tbody>
</table>

<p>I tried a few options. At the end I settled with <a href="https://prosemirror.net/">prose-mirror</a> to build fiber-note due to thorough guides and references, up-to-date maintaining, and <a href="https://discuss.prosemirror.net/">a friendly forum</a>.</p>

<h2 id="trix">trix</h2>

<p>As a rails user, my first thought are <code>actiontext</code> and <a href="https://trix-editor.org/">trix</a>. Trix is perfect for adding out-of-box rich-text editing to a normal rails app, like rails, it just works.</p>

<p>It‚Äôs just hard to tweak for more custom features.</p>

<ul>
  <li>it completely intertwined with rails‚Äô components like <code>actionview</code> (rendering) and <code>activestorage</code> (image uploading), it‚Äôs hard to mutate the saved content without hacking into hidden methods.</li>
  <li>it saves content as raw HTML fragment, which is bad because
    <ul>
      <li>unique content have multiple legit representations</li>
      <li>it‚Äôs slow to parse and manipulate the content (say tags detection, image processing, table mutation, etc.)</li>
    </ul>
  </li>
  <li>it doesn‚Äôt come with detailed docs/specs about the format of generated HTML docs, which is not reliable when you system relies on processing the content on-the-fly.</li>
  <li>minimal events not enough to compose complex logic around the user‚Äôs operation</li>
</ul>

<h2 id="quill">quill</h2>

<p><a href="https://quilljs.com/">quill</a> is another competitive  candidate, regarding elaborated docs, data format specs, themes, and typescript support.</p>

<p>It‚Äôs easy to integrate the library, tweak some configurations, and apply different themes. You can add markdown syntax support in like 10 minutes.</p>

<p>It‚Äôs not easy to limit what kind of content is allowed in the document, or what would happen if a special formatted text is pasted.</p>

<p>It‚Äôs hard to pragmatically control the mutation of the data to manually implement functions like ‚Äúcreate another list item with the same indent when <em>return</em> is pressed and current cursor on the end of a list item, including the end of an inline span of a list item‚Äù.</p>

<p>It‚Äôs not impossible, yet it will get over-complicated if you need many mutations like this.</p>

<h2 id="prose-mirror">prose-mirror</h2>

<p><code>prose-mirror</code> has the most complicated structure.  You have to import <strong>at least ten packages</strong> to build a simple demo, each managing a single aspect of the editor (model, view, schema definitions, keymaps, etc.).</p>

<p>There‚Äôs a starter kit kind of package (<code>prosemirror-example-setup</code>) which makes the journey a little bit easier. I‚Äôd recommend that kit to users who demand only basic features, while for complex functions you‚Äôll have to compose each part and piece them together for better control. It‚Äôs like how advanced users almost never want the pre-set default preferences or <code>rails scaffold</code>.</p>

<p>Verbosity and redundancy means total control and vice versa, it just have to be like this. You posses the ability to custom the schema, listen to each key press, oversee every transaction of the model, and to arrange how to create (also parse, and wrap, and truncate during drag-n-drop, etc.) different kind of element.</p>

<p>You‚Äôll spend a lot of time jumping between the <a href="https://prosemirror.net/docs/guide/">guides</a>, the <a href="https://prosemirror.net/docs/ref/">references for individual packages</a>, and even the source code. I can promise you that the guide will be a great read about the designing of a complicated modular system.</p>



<p>Thanks for reading. In the next post, I‚Äôll discuss how I built and tweaked the editor.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://namiwang.github.io/2020/11/12/building-a-roam-like-networked-heavily-customized-realtime-editor-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177290</guid>
            <pubDate>Sun, 22 Nov 2020 13:31:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting from a vinyl record]]>
            </title>
            <description>
<![CDATA[
Score 832 | Comments 140 (<a href="https://news.ycombinator.com/item?id=25177045">thread link</a>) | @ruik
<br/>
November 22, 2020 | http://boginjr.com/it/sw/dev/vinyl-boot/ | <a href="https://web.archive.org/web/*/http://boginjr.com/it/sw/dev/vinyl-boot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://boginjr.com/it/sw/dev/vinyl-boot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177045</guid>
            <pubDate>Sun, 22 Nov 2020 12:51:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[S230 is a censorship law masquerading as a friend of free speech]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25177003">thread link</a>) | @mikerthomsen
<br/>
November 22, 2020 | https://mikethomsen.github.io/posts/2020/11/16/s230-the-two-faced-free-speech-law | <a href="https://web.archive.org/web/*/https://mikethomsen.github.io/posts/2020/11/16/s230-the-two-faced-free-speech-law">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mikethomsen.github.io/posts/2020/11/16/s230-the-two-faced-free-speech-law</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177003</guid>
            <pubDate>Sun, 22 Nov 2020 12:44:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swizzle Clogging]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25176931">thread link</a>) | @mkj
<br/>
November 22, 2020 | https://apple.github.io/foundationdb/testing.html | <a href="https://web.archive.org/web/*/https://apple.github.io/foundationdb/testing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://apple.github.io/foundationdb/testing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176931</guid>
            <pubDate>Sun, 22 Nov 2020 12:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Applications Performance: Introduction (2019)]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25176637">thread link</a>) | @todsacerdoti
<br/>
November 22, 2020 | http://unixism.net/2019/04/linux-applications-performance-introduction/ | <a href="https://web.archive.org/web/*/http://unixism.net/2019/04/linux-applications-performance-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://unixism.net/2019/04/linux-applications-performance-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176637</guid>
            <pubDate>Sun, 22 Nov 2020 11:29:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much is YouTube worth today?]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 154 (<a href="https://news.ycombinator.com/item?id=25176451">thread link</a>) | @elephant_burger
<br/>
November 22, 2020 | https://mannhowie.com/youtube-valuation | <a href="https://web.archive.org/web/*/https://mannhowie.com/youtube-valuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p><strong>How much is YouTube worth today?</strong>
<img src="https://images.ctfassets.net/vwq10xzbe6iz/6LQGeFMMp2z9YMRiOurO4g/9489b18efefac13f387cdc116c7b5ff1/IMG_CB7ACB71DC8B-1.jpeg" alt="howmuchyoutubeworth"></p>
</blockquote>
<p>Google acquired YouTube for US$1.6 billion back in 2006. We estimate YouTube to be worth up to US$170 billion in 2020, delivering Google a +100x return in under 15 years.
<img src="https://images.ctfassets.net/vwq10xzbe6iz/6YrHqLoRpqCr5w4JwDJvtI/b5a86d3af5149953770bf1814a9c473c/IMG_18657804259D-1.jpeg" alt="youtube-valuation-comparison"></p>
<p>This article will cover in-depth how we arrive at this valuation and the steps you can follow to build your own model for YouTube and to value any technology company:</p>
<p><strong>Key Sections:</strong></p>
<ol>
<li><a href="#1">5 key questions to understand YouTube‚Äôs business model</a></li>
<li><a href="#2">Building a YouTube financial forecast model</a></li>
<li><a href="#3">Preparing a final YouTube valuation</a></li>
</ol>
<p>Skip to the following links for a valuation checklist and complete financial model:</p>
<ul>
<li><a href="#4">6 Step Valuation Checklist</a></li>
<li><a href="#5">Download Free YouTube Valuation Model</a></li>
<li><a href="#alphabet">Alphabet SOTP Valuation</a></li>
</ul>
<h2><a name="1"></a>5 Key Questions to Answer</h2>
<p>To reach a valuation for YouTube, we must firstly answer 5 questions about the business:</p>
<ol>
<li><strong>Industry</strong>: What industry does it compete in?</li>
<li><strong>Customer</strong>: Who are its customers and how does it deliver them value?</li>
<li><strong>Revenue</strong>: What is its revenue model and key drivers?</li>
<li><strong>Costs</strong>: What are its major costs and how are they managed?</li>
<li><strong>Growth</strong>: What is the growth thesis?</li>
</ol>
<h3>1. What industry does YouTube compete in?</h3>
<p>YouTube is the world‚Äôs largest online video service and competes for user viewership in order to compete for digital advertising spend from businesses. YouTube‚Äôs parent is Google/ Alphabet and operates globally except China where Google is banned.</p>
<p>Global ad spend (ex China) is over half a trillion dollars annually, of which half is spent on digital (web and mobile). The lion‚Äôs share of this is dominated by Google and Facebook which capture over 80% of digital ad spend.</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/4kzjexfgsxFPhJOyyo2jS0/9b06d17b7cc5d7e0a6b080ec5beb7bf2/globaladshare.png" alt="globaladshare"></p>
<p>Splitting up Google and Facebook‚Äôs major ad platforms we reveal YouTube is the 5th largest digital ad platform with 6% share, behind Google Search, Facebook, Google Display and Instagram.</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/2EbkvWiatOFXQYBVoqNlE5/03b1f3088e0b11f783116028d2682985/globaladfbyoutube.png" alt="globaladbyproduct"></p>
<p>Future growth of the digital ad market is any oracle‚Äôs guess. But if we assume digital remains a dominant advertising medium industry, then digital spend could reach over half a trillion by 2030 (assumes 7% annual growth).</p>
<blockquote>
<p>When looking at the industry a company operates in, focus on how the company generates revenue and compare against competitors and alternative mediums. Research industry statistics and competitor annual reports to get a rough estimate of how large the current industry is.</p>
</blockquote>
<h3>2. Who are YouTube‚Äôs customers and how do they deliver them value?</h3>
<p>YouTube is an online video platform that allows content creators (individuals and businesses) to publish videos for users to watch. YouTube sells ads to businesses placed within video content and shares the revenue with publishers.</p>
<p>YouTube delivers value to 3 key stakeholders:</p>
<ul>
<li><strong>Creators</strong>: monetize their video content on the platform with the widest reach. Allows creators to focus on producing quality content and outsource hosting and marketing costs to YouTube</li>
<li><strong>Users</strong>: free, targeted and relevant video content and entertainment (for better or worse)</li>
<li><strong>Advertisers</strong>: brand impressions and targeted reach across a global audience</li>
</ul>
<p>YouTube ultimately competes for global viewership and monetizes this by selling ads to businesses. YouTube has over 2 billion monthly active users and is the second largest social media platform in the world. The chart below compares the monthly active users across major ad supported social media platforms and video platforms:</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/yQISXiQ5Gh5jgiQWcYKLu/61903f1edd297535079c73c0d7b17d22/mausocial.png" alt="mausocial"></p>
<p>Whilst each player competes for viewership, their target audience and monetization models differ:</p>
<ul>
<li>Facebook, Snapchat, Instagram and Twitter  sell ads placed in a user‚Äôs social media feed of images, video, news, articles</li>
<li>Netflix sells subscription services to users for its original and purchased content</li>
<li>TikTok is early in its monetization strategy</li>
</ul>
<blockquote>
<p>When understanding how a company generates revenue, ask yourself: Who is the customer and why would they pay for the offering? For technology platform companies, understand the ecosystem of stakeholders and the benefit each of them receive from using the platform.</p>
</blockquote>
<h3>3. What is YouTube‚Äôs revenue model and key drivers?</h3>
<p>YouTube has two primary revenue streams:</p>
<ul>
<li><strong>Ad sales</strong> (90% revenue): YouTube sells targeted ads within video content across its 2 billion monthly active users. It shares ad revenue with content publishers via a 45/55 split in favour of publishers; and</li>
<li><strong>Subscription</strong> (10% revenue): YouTube premium offers an ad free video experience and music service offered at ~$10 per month. There are currently 20 million premium subscribers representing ~1% of YouTube‚Äôs total monthly active user base</li>
</ul>
<p>YouTube‚Äôs key revenue driver is its ability to monetize its monthly active user base. We can assess its performance vs peers by comparing the average annual ad spend generated by each provider divided by its monthly active user base.</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/5SzsrFRvxXSiFttWKHFSxm/596bb1ecbda955f39031a46059e20178/arputitle.png" alt="arpu"></p>
<p>Facebook currently generates 2x higher ad revenue per active user than YouTube across both Facebook and Instagram platforms. This could be explained by Facebook‚Äôs greater variety of ad formats and granular audience targeting (interests, age, behaviour, lookalike audience) and being further along its journey of ad monetization.</p>
<p>The biggest driver of revenue for YouTube will likely be its ability to drive higher ad spend to its already large audience via product innovation (e.g. new ad formats, improved targeting) rather than growing its audience. YouTube is also earlier in its monetization strategy and has also invested significant resources to clean up the quality of content published.</p>
<blockquote>
<p>The key to understanding any revenue model is to identify the key revenue drivers: 1) volume (e.g. customers, users, businesses), 2) pricing (ARPU, new products, upsell) and 3) churn (% customers leaving each month, non-renewals). Try and understand the narrative of how the company can influence these drivers.</p>
</blockquote>
<h3>4. What are YouTube‚Äôs biggest cost drivers?</h3>
<p>YouTube‚Äôs major costs can be separated across 3 categories:</p>
<ul>
<li><strong>Cost of Revenue</strong>: variable costs associated with delivery of services and revenue. Includes ad share revenue paid to creators and data-centre operation and hosting costs;</li>
<li><strong>Operating Costs</strong>: largely staff and support related costs to drive platform and product development (R&amp;D), revenue growth and creator support (Sales &amp; Marketing), content moderation, finance, admin (General &amp; Admin); and</li>
<li><strong>Capex &amp; Acquisitions</strong>: investments in data-centre infrastructure, acquisitions of businesses and supporting tech. These are cash outflows not captured in the income statement</li>
</ul>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/7yjEplwqk3bj6K9lfULGQm/2fa7a97f21a0ff6821ead4e0fb0a5918/opextitle.png" alt="youtubeopex"></p>
<p><strong>Cost of Revenue</strong>
YouTube‚Äôs largest cost base is the revenue it shares with content publishers. It splits ad and subscription revenue attached to content viewership in the ratio 45/ 55% in the favour of publishers.</p>
<p>YouTube‚Äôs other major variable costs are the delivery and data-centre operation costs for the 500 hours of video content that gets uploaded every minute. These costs largely include depreciation charges following major upfront capex investments in data-centres. We estimate 7% in line with Alphabet‚Äôs overall depreciation charge as % of revenue.</p>
<p><strong>Operating Costs</strong>
Alphabet does not publicly disclose YouTube‚Äôs other operating expenses so we will need to estimate.</p>
<p>YouTube‚Äôs major fixed costs are its operating costs which are largely staff related and associated with sales and marketing, supporting creators, research &amp; development (software and product roles), content moderation (outsourced contractors), finance, admin and support.</p>
<p>We can estimate YouTube‚Äôs opex margins by comparing against peers. Netflix has a total opex/ revenue of 20% and Facebook at ~35-45%. We can estimate that YouTube may currently operate within the range at 35% opex/ revenue. We can assume given scale benefits that this will lower over time in line with Netflix at 20% opex as % of revenue.</p>
<p>This analysis highlights that YouTube‚Äôs profitability is lower than other social media platforms and Google‚Äôs other ad businesses. This is largely due to YouTube‚Äôs reliance on ad sharing with content publishers.</p>
<p><strong>Capex &amp; Acquisitions</strong>
Alphabet does not separate YouTube‚Äôs cashflow financials so we must estimate capex figures.</p>
<p>In our methodology, depreciation is already accounted for in the operating expenses hence we must estimate the incremental net capital expenditure (e.g. capex less depreciation) in order to estimate the total cash outflows associated with investment in infrastructure.</p>
<p>We will adopt the Godfather of Valuation‚Äôs (Aswath Damodaran) approach of using the <a href="https://www.informit.com/articles/article.aspx?p=2928207&amp;seqNum=5">sales to capital ratio</a> to estimate the required net capex to support revenue growth. This is calculated as the net change in revenue divided by the net capex of each year.</p>
<p>Alphabet has an average sales to capital ratio of 1.9x (annual change in revenue divided by change in invested capital (debt + equity less cash)). This implies that for every $100 of incremental revenue Alphabet generates each year it reinvests $50 as capital to support growth.</p>
<blockquote>
<p>When estimating costs, identify the major drivers across cost of revenue, operating costs and capex costs. Go through annual financial reports to identify the major line items and review notes to understand what is included and not included and understand the main drivers.</p>
</blockquote>
<h3>5. What is the growth thesis for YouTube?</h3>
<p>Based on our above analysis and understanding we can base our growth thesis for YouTube on two key drivers: ad monetization and stable user growth.</p>
<p><strong>Ad Monetization</strong>
YouTube is early in its monetization strategy and has largely relied on ad revenue from high quality in-video ad formats driven by impressions. It has begun to experiment with new formats including direct response display ads within homepage recommendation feeds and direct text search ads. These new formats support greater ability to sell more ads to its user base.</p>
<p>We can estimate that YouTube over the next 10 years will increase its ad monetization from $8 ARPU to $23 ARPU in line with Facebook currently.</p>
<p><strong>Stable User Growth</strong>
YouTube shares a majority of ad revenue to content publishers which is negative for gross profit margins but positive for supporting high quality content creation. This will likely attract amateur and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mannhowie.com/youtube-valuation">https://mannhowie.com/youtube-valuation</a></em></p>]]>
            </description>
            <link>https://mannhowie.com/youtube-valuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176451</guid>
            <pubDate>Sun, 22 Nov 2020 10:44:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Books for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25176423">thread link</a>) | @nickyvanurk
<br/>
November 22, 2020 | https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/ | <a href="https://web.archive.org/web/*/https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="penci-post-entry-inner">
			
<p>Most programmers I know started programming out of sheer curiosity and joy. Joy is what keeps one motivated to keep up with the changing landscape of technology. It‚Äôs what keeps one happy. That is why I am recommending these 10 best books for programmers, books I really enjoyed reading. These are the books that I keep picking up and coming back to or have fond memories of. These are also the books that I hardly see recommended elsewhere, except for a few classics that are certainly worth repeating. And now I would like to share these books with you.</p>



<p><em>This post contains affiliate links where applicable. If you‚Äôre planning to buy any of these books yourself you can support this blog by buying it with the links</em> provided in the titles.</p>



<div><div>
<h2><a href="https://amzn.to/36ALozx" target="_blank" rel="noreferrer noopener nofollow">The Pragmatic Programmer<br></a><sub>Your Journey to Mastery, 20th Anniversary Edition</sub></h2>



<div><figure><img loading="lazy" width="230" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-pragmatic-programmer-230x300.jpg" alt=""></figure></div>



<p>I would recommend any programmer to read this book. It contains a lot of wisdom, tips, and advice. Most of it is pretty basic but therein lies the beauty. The first edition released in 1999 and was getting pretty dated. Despite it being old it was still highly recommended. To my surprise they released a new edition 20 years later, all up-to-date! Now you‚Äôve got no excuses left to not read this book. A wonderful book that you surely will be referring back to over and over again, I know I do.</p>




</div></div>



<div><div>
<h2><a href="https://www.learninpublic.org/" target="_blank" rel="noreferrer noopener nofollow">The Coding Career Handbook<br></a><sub>Guides, Principles, Strategies, and Tactics ‚Äì from Code Newbie to Senior Dev</sub></h2>



<div><figure><img src="https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook-196x300.jpg" alt="" width="200" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook-196x300.jpg 196w, https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook.jpg 311w" sizes="(max-width: 196px) 100vw, 196px"></figure></div>



<p>Similar to the The Pragmatic Programmer, I consider this book a must-read. It focuses on the bigger picture and your career, not just about writing code. This book is the reason I started this blog in the first place! A great book for any ambitious programmer and want to take your career to the next level.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/36ulPQI">Apprenticeship Patterns<br></a><sub>Guidance for the Aspiring Software Craftsman</sub></h2>



<div><figure><img loading="lazy" width="229" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns-229x300.jpeg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns-229x300.jpeg 229w, https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns.jpeg 260w" sizes="(max-width: 229px) 100vw, 229px"></figure></div>



<p>If you‚Äôre new to programming, making the same mistakes as the programmers that have gone before you can be costly and detrimental for your career. Let this book guide you on avoiding these same mistakes. This book is similar to the ones mentioned above and makes for a nice addition. It‚Äôs split up into smaller sections that can be read in any order you‚Äôd like, this makes it a fun and easy read.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3prQVAU">Beginning C++ Through Game Programming</a></h2>



<div><figure><img loading="lazy" width="243" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming-243x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming-243x300.jpg 243w, https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming.jpg 405w" sizes="(max-width: 243px) 100vw, 243px"></figure></div>



<p>This is the book that taught me how code and was the first book I read on the subject of programming. It made learning new programming languages that much easier. Ever since I read this book it seems I‚Äôve always been one step ahead of the herd. This book is about learning the fundamentals of programming and C++ and less about games. It merely uses games as an example to reinforce programming concepts. This book was a lot of fun to read and because it uses games as a theme it keeps one motivated.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/35sQDSE" target="_blank" rel="noreferrer noopener nofollow">Programming Game AI by Example</a></h2>



<div><figure><img loading="lazy" width="201" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example-201x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example-201x300.jpg 201w, https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example.jpg 335w" sizes="(max-width: 201px) 100vw, 201px"></figure></div>



<p>To be honest I have not read this book in it‚Äôs entirety yet as I currently lack the time to do so. But I am really excited about this one and can‚Äôt wait to read it in combination with learning a new programming language: Rust. This book makes use of C++ but I‚Äôd figure these languages are similar enough as to implement the same ideas in Rust. I‚Äôve put this book on this list because of the pure excitement it makes me feel. I would recommend to at least peruse this book to see if it resonates with you.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3nrDlfj" target="_blank" rel="noreferrer noopener nofollow">The Phoenix Project<br></a><sub>A Novel about IT, Devops, and Helping Your Business Win</sub></h2>



<div><figure><img loading="lazy" width="201" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project-201x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project-201x300.jpg 201w, https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project.jpg 334w" sizes="(max-width: 201px) 100vw, 201px"></figure></div>



<p>This is a book I got recommended, I read it, I loved it. I recommended it to a friend, and he loved it. And now I recommend it to you! It‚Äôs a really fun read and I could hardly put it down. This book really is written like a novel and packed with great lessons. Go read it! There is also a part two of sorts: The Unicorn Project. I hear it contains much of the same lessons, only told with a different story. I have yet to read it but will certainly do so in the near future.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3ktXAae" target="_blank" rel="noreferrer noopener nofollow">Designing Data-Intensive Applications<br></a><sub>The Big Ideas Behind Reliable, Scalable, and Maintainable Systems</sub></h2>



<div><figure><img loading="lazy" src="https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications-229x300.jpg" alt="" width="229" height="300" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications-229x300.jpg 229w, https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications.jpg 381w" sizes="(max-width: 229px) 100vw, 229px"></figure></div>



<p>So you‚Äôve learned how to code and now can write decent software. It‚Äôs time to focus on the bigger picture and learn about systems architecture and scaling, where do you start? This book is the answer. It will teach you all about designing data-intensive applications and serves as a great resource to prep for your systems design interviews.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/2UqPpRg" target="_blank" rel="noreferrer noopener nofollow">Game Programming Patterns</a></h2>



<div><figure><img loading="lazy" width="244" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns-244x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns-244x300.jpg 244w, https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns.jpg 406w" sizes="(max-width: 244px) 100vw, 244px"></figure></div>



<p>I adore this book. It‚Äôs a book I keep coming back to over and over. It‚Äôs about programming patterns with a game theme once again. Note that the patterns here are not only for games! Some of them are game specific but most of them aren‚Äôt. It‚Äôs a fun read with beautiful hand drawn diagrams. Bob Nystrom clearly has put a lot of love in his book. You can read the web version for free <a href="https://gameprogrammingpatterns.com/contents.html" target="_blank" rel="noreferrer noopener nofollow">here</a>!</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/35s2hgo" target="_blank" rel="noreferrer noopener nofollow">The Web Application Hacker‚Äôs Handbook<br></a><sub>Finding and Exploiting Security Flaws</sub></h2>



<div><figure><img loading="lazy" width="241" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook-241x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook-241x300.jpg 241w, https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook.jpg 402w" sizes="(max-width: 241px) 100vw, 241px"></figure></div>



<p>You‚Äôre a back-end developer and are responsible for fending of hackers? This is the book for you. It will arm you with the knowledge of how hackers actually hack your web applications and what you can do about it! And if you ever want to make a career switch to become a <a href="https://en.wikipedia.org/wiki/Bug_bounty_program" target="_blank" rel="noreferrer noopener nofollow">Bug Bounty Hunter</a>, this is the #1 book recommendation within that field.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3ly5xfO" target="_blank" rel="noreferrer noopener nofollow">Cracking the Coding Interview<br></a><sub>189 Programming Questions and Solutions</sub></h2>



<div><figure><img loading="lazy" width="211" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview-211x300.jpeg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview-211x300.jpeg 211w, https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview.jpeg 243w" sizes="(max-width: 211px) 100vw, 211px"></figure></div>



<p>A classic for coding interview prep. I‚Äôve read this book after seeing it recommended everywhere and I must say I‚Äôm glad I did. It teaches you all about data-structures and has a ton of example coding interview questions and their answers. This is a must-read for any programmer.</p>




</div></div>
			
			
			
					</div>
	</div></div>]]>
            </description>
            <link>https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176423</guid>
            <pubDate>Sun, 22 Nov 2020 10:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Birth of Unix with Brian Kernighan]]>
            </title>
            <description>
<![CDATA[
Score 329 | Comments 56 (<a href="https://news.ycombinator.com/item?id=25176318">thread link</a>) | @rodrigo975
<br/>
November 22, 2020 | https://corecursive.com/058-brian-kernighan-unix-bell-labs/ | <a href="https://web.archive.org/web/*/https://corecursive.com/058-brian-kernighan-unix-bell-labs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>When you work on your computer, there are so many things you take for granted: operating systems, programming languages, they all have to come from somewhere. </span></p><p><span>In the late 1960s and 1970s, that somewhere was Bell Labs, and the operating system they were building was UNIX. </span></p><p><span>They were building more than just an operating system though. They were building a way to work with computers that had never existed before.&nbsp; </span></p><p><span>In today‚Äôs episode I talk to Brian Kernighan about the history of Unix.</span></p><h3><b>Quotes</b></h3><p><em><span>‚ÄúIf you wanted, you could go sit in your office and think deep thoughts or program, or write on your own blackboard or whatever, but then come back to the common space when you wanted to.‚Äú&nbsp;</span></em></p><p><em><span>‚ÄúI found it easier to program when I was trying to figure out the logic for myself rather than trying to figure out where in the infinite stack of documentation was the function I needed. So for me, programming is more like creating something rather than looking it up, and too much of today‚Äôs programming is more like looking it up.‚Äù</span></em></p><p><em><span>‚ÄúIf what I find challenging or hard or whatever is also something that other people find hard or challenging or whatever, then if I do something that will improve my lot, I‚Äôm perhaps improving their lot at the same time.‚Äù</span></em></p><h2><b>Transcript:</b></h2><p><i><span>Note:&nbsp; This podcast is designed to be heard. If you are able, we strongly encourage you to listen to the audio, which includes emphasis that‚Äôs not on the page.&nbsp; The podcast page for</span></i><a href="https://corecursive.com/brian-kernighan-unix-bell-labs/" target="_blank" rel="noopener noreferrer"><i><span> this episode is here</span></i></a></p><p><strong>Adam:&nbsp;</strong></p><p><span>When you work on your computer, there are so many things you take for granted: operating systems, programming languages, they all have to come from somewhere. In the 1960s, that somewhere was Bell Labs, and the operating system they were building was Unix. They were building more than just an operating system though. They were building a way to work with computers that had never existed before. To find out more, I reached out to this guy.</span></p><p><strong>Brian:&nbsp;</strong></p><p><span>I‚Äôm Brian Kernighan, and at the moment, I teach computer science at Princeton University.</span></p><p><strong>Adam:&nbsp;</strong></p><p><span>He‚Äôs the K in K&amp;R, the famous book about C that still tops most recommended book lists. He was part of this computer science research group at Bell Labs for 30 years. He‚Äôs going to share the story of the creation of Unix, and hopefully, I‚Äôm going to try to figure out some of their secrets to being so impactful. Along the way, we‚Äôre going to have to learn about the Unix philosophy and printing patent applications, but we‚Äôre also going to have to learn about 10-kilo chocolate bars and fake demos to the CIA, and of course, British satirical magazines.</span></p><p><strong>Adam:</strong></p><p><span>The story of Unix is a story about Bell Labs, so let‚Äôs start at the beginning when Brian is a grad student and he gets an internship to work there for the summer.</span></p><p><strong>Brian:</strong></p><p><span>Bell Labs is a very big building, a sequence of connected buildings, and probably 3,000 people working over these long multi-story buildings. The thing that I remember most clearly about the first day, and I think it was the first day of the first internship, so call it the summer of 1967, and I got an office, and if I recall correctly, I had an office to myself. So this is something that‚Äôs unheard of in the modern era.</span></p><p><strong>Brian:</strong></p><p><span>But I had an office to myself, and I was sitting there in my office at probably 11:00 or something like that in my first morning, I wondered, ‚ÄúWhat the heck do I do? I have no idea what‚Äôs going on.‚Äù And this older gentleman came past my office and he said, ‚ÄúHi, I‚Äôm Dick‚Ä¶ Let‚Äôs go to lunch.‚Äù I thought, ‚ÄúWell, okay.‚Äù I went off to lunch with Dick‚Ä¶, whose name I hadn‚Äôt caught. We had a good lunch, he was an interesting kind of curmudgeonly, but intriguing guy. Then after lunch, he went off somewhere else.</span></p><p><strong>Brian:</strong></p><p><span>I snuck past my office to his office on the same corridor to see who the heck he was because everybody had name tags on the doors. It turns out it was Dick Hamming, the inventor of error-correcting codes.</span></p><p><strong>Adam:</strong></p><p><span>Dick Hamming is aka Richard Hamming. His Wikipedia page is huge. He worked on the Manhattan project programming computers to calculate the equations needed to develop nuclear weapons. One year after this lunch with Brian, he would win the Turing Award, the so-called Nobel Prize of Computing for his work on error-correcting codes. Hamming is also famous for this talk he gave on the secret to having impact in your professional life.</span></p><p><strong>Brian:</strong></p><p><span>The talk was called You and Your Research, and it was basically a retrospective on his career, thinking whether there were general lessons that would help other people in some way to have a better career. He was very, very interesting, and I think a good example of somebody with clearly lots of talent, but not a super genius type, who made the most of what he had. Who in every way, amplified so that he compounded his effect on the world. The other thing that‚Äôs maybe is appropriate for today, he used to say that he would reserve Friday afternoons for thinking great thoughts.</span></p><p><strong>Brian:</strong></p><p><span>He would sit in his office, he would put his feet on the desk, and he would think great thoughts, whatever that might be. It was usually introspection on himself or on where was the field going, or what might happen in the future? What might you do to take advantage of that or deal with it in some way or other? This is Friday morning when we‚Äôre talking, and I don‚Äôt get that luxury on Friday afternoons very often, but it‚Äôs a useful way to think of it. You say, ‚ÄúI‚Äôm going to stop and do it regularly to take stock of what‚Äôs going on, and in some way, think about, ‚ÄòWhat could I be doing that in some way would be better, that would be more useful for me or my family or the world or whatever?'‚Äù</span></p><p><strong>Brian:</strong></p><p><span>He did that quite religiously, you went in after lunch on Friday, you‚Äôd find him sitting in his office thinking great thoughts. So he‚Äôs fun.</span></p><p><strong>Adam:</strong></p><p><span>I love this advice, it presupposes that if I just had my Fridays free, and I wrote thinking great thoughts on my calendar, I would upgrade thoughts. I mean, maybe that‚Äôs the case, I‚Äôll give it a try. There‚Äôs one concept though that Hamming is most famous for, and that is about how you choose what to work on.</span></p><p><strong>Brian:</strong></p><p><span>The way he told it to me and probably lots of others was that he used to eat with some group of people like chemists, I think the specific thing was, and he would eat at their table at lunchtime, big cafeteria setting. He would sit down with chemists and talk to them and he would ask them what they were working on, and whether what they‚Äôre working on could possibly lead to a Nobel Prize. The answer was often no, not a chance, and that was the point where he‚Äôd say, ‚ÄúWell, then why are you working on it? Because if it couldn‚Äôt at least potentially lead to a Nobel Prize, it isn‚Äôt important. Why are you wasting your time on something that isn‚Äôt important?‚Äù</span></p><p><strong>Adam:</strong></p><p><span>Whether intentionally or not, Brian followed this advice. When he returned to Princeton to work on his thesis, he was working on graph partitioning, which we now know is in some sense, equivalent to the traveling salesman problem. You have to find an optimum route that the salesman would travel from city to city minimizing travel distance. To complete his thesis, Brian had to work on the computers of Princeton at the time. Computers today are a lot different than they were in 1967 and ‚Äô68 at Princeton. At the time, computers were all about Fortran and punch cards.</span></p><p><strong>Brian:</strong></p><p><span>Fortran was designed in a card environment very definitely, and I assume the cards came before Fortran, but in my mind, they‚Äôre very strongly linked. And so yes, it was basically one statement per line, which was, therefore, one physical card. And so, when you wrote a program, you had to punch it on these punch cards, and then make sure you kept them in order and things like that and then you handed them to somebody who operated a very big, expensive machine. And a while later, back would come to your results, very often where it‚Äôs just something like there was a syntax error somewhere, and you had to find the cards that were wrong, replace them with new cards that were right and repeat the process, but with a very, very long latency that could be often measured in hours or sometimes even days.</span></p><p><strong>Brian:</strong></p><p><span>It‚Äôs not exactly like an instant compilation. And Fortran itself is a kind of clunky language as well in part reflecting those early days in computing, and partly just the fact that we didn‚Äôt understand a lot, and the computers themselves were not particularly sophisticated. Then finally, Fortran was intended for scientific computing. It was not intended for, let‚Äôs say, general-purpose system programming or anything like that. All of those things meant that although the program was a lot of fun, it‚Äôs not the same as it became five or 10 years later, and it has continued to evolve.</span></p><p><strong>Adam:</strong></p><p><span>I had to watch a couple of YouTube videos to get a sense of this punch card world. A punch card is like an index card, but it‚Äôs wider because it has 80 columns. And each of these columns corresponds to a single character. You punch holes in that column to indicate what letters should go there, and so each punch card represents one line of Fortran code. People build the programs this way, punching these cards, putting them into big boxes in order that they would carry around, then you take someplace to give them to a computer operator who would give them to the computer that would read all this in and run the program.</span></p><p><strong>Adam:</strong></p><p><span>So if you had a 1,000-line program, you would have 1,000 cards. There were no screens, no interactive output. You gave your cards to the computer operator and waited for your printout that was the result of your program. Computers were expensive and giant, so they wanted to maximize the throughput. Your program might be doing expensive mathematical calculations, but you could also just be doing word processing. One card might say, ‚ÄúIn bold, print my thesis,‚Äù and the next would say, ‚ÄúPrint, by Brian Kernighan,‚Äù and so on. It‚Äôs like a verbose way of using a typewriter, except the advantage is you could change the cards around and have it reprinted.</span></p><p><strong>Brian:</strong></p><p><span>T‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corecursive.com/058-brian-kernighan-unix-bell-labs/">https://corecursive.com/058-brian-kernighan-unix-bell-labs/</a></em></p>]]>
            </description>
            <link>https://corecursive.com/058-brian-kernighan-unix-bell-labs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176318</guid>
            <pubDate>Sun, 22 Nov 2020 10:14:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Israeli Queues]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25176282">thread link</a>) | @arpitbbhayani
<br/>
November 22, 2020 | https://arpitbhayani.me/blogs/israeli-queues | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/israeli-queues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>A queue is a data structure that holds up elements for a brief period of time until a peripheral processing system is ready to process them. The most common implementation of a queue is a FIFO queue - First In First Out - that evicts the element that was inserted the first i.e. it evicts the one that has spent the most time in the queue. There are other variations of Queues one of which is called Priority Queue.</p>
<p>In Priority Queue, every element is associated with a priority, usually provided by the user during enqueueing; This associated priority is used during eviction where the element with the highest priority is evicted first during dequeuing.</p>
<p>In this essay, we take a detailed look into a variation of Priority Queue, fondly called Israeli Queues, where the priority of the element is defined by the affinity of it with one of its "friends" in the queue. Israeli Queues were first introduced in the paper <a href="https://pure.tue.nl/ws/files/2152975/632939.pdf">Polling with batch service</a> by Boxma, O. J., Wal, van der, J., &amp; Yechiali, U in the year 2007.</p>

<p>Queues in Israel are usually unorganized, due to which people tend to find their friends, who are already waiting, and instead of adhering to the usual protocol of joining at the back end, they cut through and directly join their friends. Israeli Queues mimic this behavior and hence get this <a href="https://www.tandfonline.com/doi/abs/10.1080/15326340802427497">punny name</a>.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/99894937-fddc4380-2cac-11eb-8a73-a4dc5c490d2b.png" alt="https://user-images.githubusercontent.com/4745789/99894937-fddc4380-2cac-11eb-8a73-a4dc5c490d2b.png"></p>
<p>Israeli Queues are a variation of <a href="https://en.wikipedia.org/wiki/Priority_queue">Priority Queues</a> where instead of associating priority with the element to be enqueued, the priority is implicitly derived using the "friend" element and it joins right at the back end of the group that the friend belongs to. The function signature of the enqueue operation is as shown below, while other operations like <code>dequeue</code> and <code>peek</code> remains fairly similar.</p>
<pre><code>

<span><span>void</span> <span>enqueue</span><span>(israeli_queue * q, element * e, element * f)</span></span>;
</code></pre>
<h2>How could this help?</h2>
<p>Every Data Structures is designed to solve a niche use case efficiently and Israeli Queues are no different as they prove to be super-efficient where one could batch and process similar elements or where the <em>set-up</em> cost for a task is high.</p>
<p>Consider a system where a queue is used to hold up heterogeneous tasks and there is a single machine taking care of processing. Now if some of these tasks are similar and have a high <em>set-up or preparation cost</em>, for example downloading large metafiles, or spinning up a parallel infrastructure, or even setting up persistent connections with device farms, queuing them closer and processing them sequentially or in batch helps in reducing redundant processing and computation by promoting reuse.</p>
<h2>Issue of starvation</h2>
<p>By enqueuing elements in between Israeli Queues reduces redundant processing, but by doing that it makes itself vulnerable to the classical case of starvation. Elements stuck at the rear end of the list could potentially starve for longer durations if elements having "friends" in the queue keep coming in at high frequency.</p>
<p>The original implementation of Israeli Queues suggests batch processing where instead of processing tasks one at a time, it processes a batch (a group of friends) in one go. This proves to be super-handy when the time required to processes a single task is much lower than the set-up cost for it.</p>
<h2>Implementation Guidelines</h2>
<p>The best way to implement Israeli Queues is by using a <a href="https://en.wikipedia.org/wiki/Doubly_linked_list">Doubly Linked List</a> with a bunch of pointers pointing to the head and tail of groups within it. Insertion to an existing group happens at the tail of it while if the element has no friend element, then it goes at the tail end of the list and forms its own group.</p>
<p>A constraint that could be added during implementation is that the friend element should always be the leader (head) element of the group. Details of the implementation could be tweaked so long the core concept remains unaltered.</p>

<p>Israeli Queues were the outcome of a problem statement dealing with Polling Systems. Polling System usually contains <code>N</code> queues <code>Q1</code>, <code>Q2</code>, ..., <code>Qn</code> where the processing unit visits each queue in cyclic order processing one element at a time i.e. <code>Q1</code>, <code>Q2</code>, ..., <code>Qn</code>, <code>Q1</code>, <code>Q2</code>, ..., <code>Qn</code>, etc.</p>
<p>When the server attends a queue instead of processing just one element from it, it processes the entire batch present in the queue utilizing the setup-cost efficiently assuming that time to process an element from a queue is much lesser than the set-up cost.</p>

<ul>
<li><a href="https://pure.tue.nl/ws/files/2152975/632939.pdf">Polling with batch service</a></li>
<li><a href="http://www.math.tau.ac.il/~uriy/Papers/IQ-with-Priorities.pdf">The Israeli Queue with priorities</a></li>
<li><a href="https://rapidapi.com/blog/israeli-queues-exploring-a-bizarre-data-structure/">Israeli Queues: Exploring a bizarre data structure</a></li>
</ul>
</div></div><div><p>
          If my work adds value, consider supporting me
        </p>  <p><a href="https://www.buymeacoffee.com/arpitbhayani" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee"></a></p> <br></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              700+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> üëá
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/israeli-queues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176282</guid>
            <pubDate>Sun, 22 Nov 2020 10:05:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Having Fun with Signal Handlers]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25175911">thread link</a>) | @edward
<br/>
November 22, 2020 | https://www.giovannimascellani.eu/having-fun-with-signal-handlers.html | <a href="https://web.archive.org/web/*/https://www.giovannimascellani.eu/having-fun-with-signal-handlers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>As every C and C++ programmer knows far too well, if you dereference a
pointer that points outside of the space mapped on your process'
memory, you get a segmentation fault and your programs crashes. As far
as the language itself is concerned, you don't have a second chance
and you cannot know in advance whether that dereferencing operation is
going to set a bomb off or not. In technical terms, you are invoking
<em>undefined behaviour</em>, and you should never do that: you are
responsible for knowing in advance if your pointers are valid, and if
they are not you keep the pieces.</p>
<p>However, turns out that most actual operating system give you a second
chance, although with a lot of fine print attached. So I tried to
implement a function that tries to dereference a pointer: if it can,
it gives you the value; if it can't, it tells you it couldn't. Again,
I stress this should never happen in a real program, except possibly
for debugging (or for having fun).</p>
<p>The prototype is</p>
<div><pre><span></span><code><span>word_t peek(word_t *addr, int *success);</span>
</code></pre></div>

<p>The function is basically equivalent to <code>return *addr</code>, except that if
<code>addr</code> is not mapped it doesn't crash, and if <code>success</code> is not NULL it
is set to <code>0</code> or <code>1</code> to indicate that <code>addr</code> was not mapped or
mapped. If <code>addr</code> was not mapped the return value is meaningless.</p>
<p>I won't explain it in detail to leave you some fun. Basically the idea
is to install a handler for <code>SIGSEGV</code>: if the address is invalid, the
handler is called, which basically fixes everything by advancing a
little bit the instruction pointer, in order to skip the faulting
instruction. The dereferencing instruction is written as hardcoded
Assembly bytes, so that I know exactly how many bytes I need to skip.</p>
<p>Of course this is very architecture-dependent: I wrote the <code>i386</code> and
<code>amd64</code> variants (no <code>x32</code>). And I don't guarantee there are no bugs
or subtelties!</p>
<p>Another solution would have been to just parse <code>/proc/self/maps</code>
before dereferencing and check whether the pointer is in a mapped
area, but it would have suffered of a
<a href="https://en.wikipedia.org/wiki/Time-of-check_to_time-of-use">TOCTTOU</a>
problem: another thread might have changed the mappings between the
time when <code>/proc/self/maps</code> was parsed and when the pointer was
dereferenced (also, parsing that file can take a relatively long
amount of time). Another less architecture-dependent but still not
pure-C approach would have been to establish a <code>setjmp</code> before
attempting the dereference and <code>longjmp</code>-ing back from the signal
handler (but again you would need to use different <code>setjmp</code> contexts
in different threads to exclude race conditions).</p>
<p>Have fun! (and again, don't try this in real programs)</p>
<div><pre><span></span><code><span>#define</span><span> </span><span>_GNU_SOURCE</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>stdint</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>signal</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>assert</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>stdlib</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>stdio</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>ucontext</span><span>.</span><span>h</span><span>&gt;</span><span></span>

<span>#ifdef</span><span> </span><span>__i386__</span><span></span>
<span>typedef</span><span> </span><span>uint32_t</span><span> </span><span>word_t</span><span>;</span><span></span>
<span>#define</span><span> </span><span>IP_REG</span><span> </span><span>REG_EIP</span><span></span>
<span>#define</span><span> </span><span>IP_REG_SKIP</span><span> </span><span>3</span><span></span>
<span>#define</span><span> </span><span>READ_CODE</span><span> </span><span>__asm__</span><span> </span><span>__volatile__</span><span>(</span><span>".byte 0x8b, 0x03\n"</span><span>  </span><span>/* mov (%ebx), %eax */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>".byte 0x41\n"</span><span>        </span><span>/* inc %ecx */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>:</span><span> </span><span>"=a"</span><span>(</span><span>ret</span><span>),</span><span> </span><span>"=c"</span><span>(</span><span>tmp</span><span>)</span><span> </span><span>:</span><span> </span><span>"b"</span><span>(</span><span>addr</span><span>),</span><span> </span><span>"c"</span><span>(</span><span>tmp</span><span>));</span><span></span>
<span>#endif</span><span></span>

<span>#ifdef</span><span> </span><span>__x86_64__</span><span></span>
<span>typedef</span><span> </span><span>uint64_t</span><span> </span><span>word_t</span><span>;</span><span></span>
<span>#define</span><span> </span><span>IP_REG</span><span> </span><span>REG_RIP</span><span></span>
<span>#define</span><span> </span><span>IP_REG_SKIP</span><span> </span><span>6</span><span></span>
<span>#define</span><span> </span><span>READ_CODE</span><span> </span><span>__asm__</span><span> </span><span>__volatile__</span><span>(</span><span>".byte 0x48, 0x8b, 0x03\n"</span><span>  </span><span>/* mov (%rbx), %rax */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>".byte 0x48, 0xff, 0xc1\n"</span><span>  </span><span>/* inc %rcx */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>:</span><span> </span><span>"=a"</span><span>(</span><span>ret</span><span>),</span><span> </span><span>"=c"</span><span>(</span><span>tmp</span><span>)</span><span> </span><span>:</span><span> </span><span>"b"</span><span>(</span><span>addr</span><span>),</span><span> </span><span>"c"</span><span>(</span><span>tmp</span><span>));</span><span></span>
<span>#endif</span><span></span>

<span>static</span><span> </span><span>void</span><span> </span><span>segv_action</span><span>(</span><span>int</span><span> </span><span>sig</span><span>,</span><span> </span><span>siginfo_t</span><span> </span><span>*</span><span>info</span><span>,</span><span> </span><span>void</span><span> </span><span>*</span><span>ucontext</span><span>)</span><span> </span><span>{</span><span></span>
<span>    </span><span>(</span><span>void</span><span>)</span><span> </span><span>sig</span><span>;</span><span></span>
<span>    </span><span>(</span><span>void</span><span>)</span><span> </span><span>info</span><span>;</span><span></span>
<span>    </span><span>ucontext_t</span><span> </span><span>*</span><span>uctx</span><span> </span><span>=</span><span> </span><span>(</span><span>ucontext_t</span><span>*</span><span>)</span><span> </span><span>ucontext</span><span>;</span><span></span>
<span>    </span><span>uctx</span><span>-&gt;</span><span>uc_mcontext</span><span>.</span><span>gregs</span><span>[</span><span>IP_REG</span><span>]</span><span> </span><span>+=</span><span> </span><span>IP_REG_SKIP</span><span>;</span><span></span>
<span>}</span><span></span>

<span>struct</span><span> </span><span>sigaction</span><span> </span><span>peek_sigaction</span><span> </span><span>=</span><span> </span><span>{</span><span></span>
<span>    </span><span>.</span><span>sa_sigaction</span><span> </span><span>=</span><span> </span><span>segv_action</span><span>,</span><span></span>
<span>    </span><span>.</span><span>sa_flags</span><span> </span><span>=</span><span> </span><span>SA_SIGINFO</span><span>,</span><span></span>
<span>    </span><span>.</span><span>sa_mask</span><span> </span><span>=</span><span> </span><span>0</span><span>,</span><span></span>
<span>}</span><span>;</span><span></span>

<span>word_t</span><span> </span><span>peek</span><span>(</span><span>word_t</span><span> </span><span>*</span><span>addr</span><span>,</span><span> </span><span>int</span><span> </span><span>*</span><span>success</span><span>)</span><span> </span><span>{</span><span></span>
<span>    </span><span>word_t</span><span> </span><span>ret</span><span>;</span><span></span>
<span>    </span><span>int</span><span> </span><span>tmp</span><span>,</span><span> </span><span>res</span><span>;</span><span></span>
<span>    </span><span>struct</span><span> </span><span>sigaction</span><span> </span><span>prev_act</span><span>;</span><span></span>

<span>    </span><span>res</span><span> </span><span>=</span><span> </span><span>sigaction</span><span>(</span><span>SIGSEGV</span><span>,</span><span> </span><span>&amp;</span><span>peek_sigaction</span><span>,</span><span> </span><span>&amp;</span><span>prev_act</span><span>);</span><span></span>
<span>    </span><span>assert</span><span>(</span><span>res</span><span> </span><span>==</span><span> </span><span>0</span><span>);</span><span></span>

<span>    </span><span>tmp</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span></span>
<span>    </span><span>READ_CODE</span><span></span>

<span>    </span><span>res</span><span> </span><span>=</span><span> </span><span>sigaction</span><span>(</span><span>SIGSEGV</span><span>,</span><span> </span><span>&amp;</span><span>prev_act</span><span>,</span><span> </span><span>NULL</span><span>);</span><span></span>
<span>    </span><span>assert</span><span>(</span><span>res</span><span> </span><span>==</span><span> </span><span>0</span><span>);</span><span></span>

<span>    </span><span>if</span><span> </span><span>(</span><span>success</span><span>)</span><span> </span><span>{</span><span></span>
<span>        </span><span>*</span><span>success</span><span> </span><span>=</span><span> </span><span>tmp</span><span>;</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>return</span><span> </span><span>ret</span><span>;</span><span></span>
<span>}</span><span></span>

<span>int</span><span> </span><span>main</span><span>()</span><span> </span><span>{</span><span></span>
<span>    </span><span>int</span><span> </span><span>success</span><span>;</span><span></span>
<span>    </span><span>word_t</span><span> </span><span>number</span><span> </span><span>=</span><span> </span><span>22</span><span>;</span><span></span>
<span>    </span><span>word_t</span><span> </span><span>value</span><span>;</span><span></span>

<span>    </span><span>number</span><span> </span><span>=</span><span> </span><span>22</span><span>;</span><span></span>
<span>    </span><span>value</span><span> </span><span>=</span><span> </span><span>peek</span><span>(</span><span>&amp;</span><span>number</span><span>,</span><span> </span><span>&amp;</span><span>success</span><span>);</span><span></span>
<span>    </span><span>printf</span><span>(</span><span>"%d %d\n"</span><span>,</span><span> </span><span>success</span><span>,</span><span> </span><span>value</span><span>);</span><span></span>

<span>    </span><span>value</span><span> </span><span>=</span><span> </span><span>peek</span><span>(</span><span>NULL</span><span>,</span><span> </span><span>&amp;</span><span>success</span><span>);</span><span></span>
<span>    </span><span>printf</span><span>(</span><span>"%d %d\n"</span><span>,</span><span> </span><span>success</span><span>,</span><span> </span><span>value</span><span>);</span><span></span>

<span>    </span><span>value</span><span> </span><span>=</span><span> </span><span>peek</span><span>((</span><span>word_t</span><span>*</span><span>)</span><span>0x1234</span><span>,</span><span> </span><span>&amp;</span><span>success</span><span>);</span><span></span>
<span>    </span><span>printf</span><span>(</span><span>"%d %d\n"</span><span>,</span><span> </span><span>success</span><span>,</span><span> </span><span>value</span><span>);</span><span></span>

<span>    </span><span>return</span><span> </span><span>0</span><span>;</span><span></span>
<span>}</span><span></span>
</code></pre></div>
  </div><p><em>Comment will be manually reviewed before being published.</em></p></div>]]>
            </description>
            <link>https://www.giovannimascellani.eu/having-fun-with-signal-handlers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25175911</guid>
            <pubDate>Sun, 22 Nov 2020 08:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loopy C Puzzle (2011)]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25175769">thread link</a>) | @susam
<br/>
November 21, 2020 | https://susam.in/blog/loopy-c-puzzle/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/loopy-c-puzzle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 01 Oct 2011</p>
<h2 id="integer-underflow"><a href="#integer-underflow">Integer Underflow</a></h2>
<p>
Let us talk a little bit about integer underflow and undefined behaviour
in C before we discuss the puzzle I want to share in this post.
</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    int i;
    for (i = 0; i &lt; 6; i--)
        printf(".");
    return 0;
}</code>
</pre>

<p>
This code invokes undefined behaviour. The value in variable
<code>i</code> decrements to <code>INT_MIN</code> after
<code>|INT_MIN| + 1</code> iterations. In the next iteration, there is a
negative overflow which is undefined for signed integers in C. On many
implementations though, <code>INT_MIN - 1</code> wraps around to
<code>INT_MAX</code>. Since <code>INT_MAX</code> is not less than
<code>6</code>, the loop terminates. With such implementations, this
code prints <code>|INT_MIN| + 1</code> dots. With 32-bit integers,
that amounts to 2147483649 dots. Here is one such example output:
</p>

<pre><samp>$ <kbd>gcc -std=c89 -Wall -Wextra -pedantic foo.c &amp;&amp; ./a.out | wc -c</kbd>
2147483649</samp>
</pre>

<p>
It is worth noting that the above behaviour is only one of the many
possible ones. The code invokes undefined behaviour and the ISO standard
imposes no requirements on a specific implementation of the compiler
regarding what the behaviour of such code should be. For example, an
implementation could also exploit the undefined behaviour to turn the
loop into an infinite loop. In fact, GCC does optimize it to an infinite
loop if we compile the code with the <code>-O2</code> option.
</p>

<pre><samp><kbd># This never terminates!</kbd>
$ <kbd>gcc -O2 -std=c89 -Wall -Wextra -pedantic foo.c &amp;&amp; ./a.out</kbd>
</samp></pre>


<h2 id="puzzle"><a href="#puzzle">Puzzle</a></h2>
<p>
Let us take a look at the puzzle now.
</p>

<div>
<p>
Add or modify exactly one operator in the following code such that it
prints exactly 6 dots.
</p>

<pre><code>for (i = 0; i &lt; 6; i--)
    printf(".");</code>
</pre></div>

<p>
An obvious solution is to change <code>i--</code> to <code>i++</code>.
</p>

<pre><code>for (i = 0; i &lt; 6; i++)
    printf(".");</code>
</pre>

<p>
There are a few more solutions to this puzzle. One of the solutions is
very interesting. We will discuss the interesting solution in detail
below.
</p>


<h2 id="solutions"><a href="#solutions">Solutions</a></h2>
<p>
<em><strong>Update on 02 Oct 2011:</strong> The puzzle has been solved
in the <a href="https://susam.in/blog/loopy-c-puzzle/comments/">comments</a> section. We will discuss the
solutions now. If you want to think about the problem before you see the
solutions, this is a good time to pause and think about it. There are
spoilers ahead.</em>
</p>

<p>
Here is a list of some solutions:
</p>

<ul>
  <li>
    <code>for (i = 0; i &lt; 6; i++)</code>
  </li>
  <li>
    <code>for (i = 0; i &lt; 6; ++i)</code>
  </li>
  <li>
    <code>for (i = 0; -i &lt; 6; i--)</code>
  </li>
  <li>
    <code>for (i = 0; i + 6; i--)</code>
  </li>
  <li>
    <code>for (i = 0; i ^= 6; i--)</code>
  </li>
</ul>

<p>
The last solution involving the bitwise XOR operation is not immediately
obvious. A little analysis is required to understand why it works. 
</p>


<h2 id="generalization"><a href="#generalization">Generalization</a></h2>
<p>
Let us generalize the puzzle by replacing \( 6 \) in the loop with an
arbitrary positive integer \( n. \) The loop in the last solution now
becomes:
</p>

<pre><code>for (i = 0; i ^= n; i--)
    printf(".");</code>
</pre>

<p>
If we denote the value of the variable <code>i</code> set by the
execution of <code>i ^= n</code> after \( k \) dots are printed as
\( f(k), \) then

\[
  f(k) =
    \begin{cases}
      n                       &amp; \text{if } n = 0, \\
      n \oplus (f(k - 1) - 1) &amp; \text{if } n &gt; 1
    \end{cases}
\]

where \( k \) is a nonnegative integer, \( n \) is a positive integer,
and the symbol \( \oplus \) denotes bitwise XOR operation on two
nonnegative integers.

Note that \( f(0) \) represents the value of <code>i</code> set by the
execution of <code>i ^= n</code> when no dots have been printed yet.
</p>

<p>
If we can show that \( n \) is the least value of \( k \) for which \(
f(k) = 0, \) it would prove that the loop terminates after printing
\( n \) dots.
</p>

<p>
We will see in the next section that for odd values of \( n, \)

\[
f(k) =
\begin{cases}
n &amp; \text{if } k \text{ is even}, \\
1 &amp; \text{if } k \text{ is odd}.
\end{cases}
\]

Therefore there is no value of \( k \) for which \( f(k) = 0 \) when \(
n \) is odd. As a result, the loop never terminates when \( n \) is odd.
</p>

<p>
We will then see that for even values of \( n \) and
\( 0 \leq k \leq n, \)

\[
f(k) = 0 \iff k = n.
\]

Therefore the loop terminates after printing \( n \) dots when \( n \)
is even.
</p>


<h2 id="lemmas"><a href="#lemmas">Lemmas</a></h2>
<p>
We will first prove a few lemmas about some interesting properties of
the bitwise XOR operation. We will then use it to prove the claims made
in the previous section.
</p>

<!-- Lemma 1 -->
<p>
<strong>Lemma 1.</strong>
<em>
For an odd positive integer \( n, \)

\[
n \oplus (n - 1) = 1
\]

where the symbol \( \oplus \) denotes bitwise XOR operation on two
nonnegative integers.
</em>
</p>

<p>
<em>Proof.</em>
Let the binary representation of \( n \) be \( b_m \dots b_1 b_0 \)
where \( m \) is a nonnegative integer and \( b_m \) represents the most
significant nonzero bit of \( n. \) Since \( n \) is an odd number,
\( b_0 = 1. \)

Thus \( n \) may be written as

\[ b_m \dots b_1 1. \]

As a result \( n - 1 \) may be written as

\[ b_m \dots b_1 0. \]

The bitwise XOR of both binary representations is \( 1. \)
</p>

<!-- Lemma 2 -->
<p>
<strong>Lemma 2.</strong>
<em>
For a nonnegative integer \( n, \)

\[
n \oplus 1 =
  \begin{cases}
    n + 1 &amp; \text{if } n \text{ is even}, \\
    n - 1 &amp; \text{if } n \text{ is odd}.
  \end{cases}
\]

where the symbol \( \oplus \) denotes bitwise XOR operation on two
nonnegative integers.
</em>
</p>

<p>
<em>Proof.</em>
Let the binary representation of \( n \) be \( b_m \dots b_1 b_0 \)
where \( m \) is a nonnegative integer and \( b_m \) represents the most
significant nonzero bit of \( n. \)
</p>
<p>
If \( n \) is even, \( b_0 = 0. \) In this case, \( n \) may be written
as \( b_m \dots b_1 0. \) Thus \( n \oplus 1 \) may be written as \( b_m
\dots b_1 1. \) Therefore \( n \oplus 1 = n + 1. \)
</p>

<p>
If \( n \) is odd, \( b_0 = 1. \) In this case, \( n \) may be written
as \( b_m \dots b_1 1. \) Thus \( n \oplus 1 \) may be written as \( b_m
\dots b_1 0. \) Therefore \( n \oplus 1 = n - 1. \)
</p>

<p>
Note that for odd \( n, \) lemma 1 can also be derived as a corollary of
lemma 2 in this manner:

\[
k \oplus (k - 1)
= k \oplus (k \oplus 1)
= (k \oplus k) \oplus 1
= 0 \oplus 1
= 1.
\]
</p>


<!-- Lemma 3 -->
<p>
<strong>Lemma 3.</strong>
<em>
If \( x \) is an even nonnegative integer and \( y \) is an odd positive
integer, then \( x \oplus y \) is odd, where the symbol \( \oplus \)
denotes bitwise XOR operation on two nonnegative integers.
</em>
</p>

<p>
<em>Proof.</em>
Let the binary representation of \( x \) be \( b_{xm_x} \dots b_{x1}
b_{x0} \) and that of \( y \) be \( b_{ym_y} \dots b_{y1} b_{y0} \)
where \( m_x \) and \( m_y \) are nonnegative integers and \( b_{xm_x}
\) and \( b_{xm_y} \) represent the most significant nonzero bits of \(
x \) and \( y, \) respectively.
</p>

<p>
Since \( x \) is even, \( b_{x0} = 0. \) Since \( y \) is odd,
\( b_{y0} = 1. \)
</p>

<p>
Let \( z = x \oplus y \) with a binary representation of \( b_{zm_z}
\dots b_{z1} b_{z0} \) where \( m_{zm_z} \) is a nonnegative integer and
\( b_{zm_z} \) is the most significant nonzero bit of \( z. \)
</p>

<p>
We get \( b_{z0} = b_{x0} \oplus b_{y0} = 0 \oplus 1 = 1. \) Therefore
\( z \) is odd.
</p>


<h2 id="theorems"><a href="#theorems">Theorems</a></h2>

<!-- Theorem 1 -->
<p>
<strong>Theorem 1.</strong>
<em>
Let \( \oplus \) denote bitwise XOR operation on two nonnegative
integers and

\[
  f(k) =
    \begin{cases}
      n                        &amp; \text{if } n = 0, \\
      n \oplus (f(n - 1) - 1)  &amp; \text{if } n &gt; 1.
    \end{cases}
\]

where \( k \) is a nonnegative integer and \( n \) is an odd positive
integer. Then

\[
  f(k) =
    \begin{cases}
      n &amp; \text{if } k \text{ is even}, \\
      1 &amp; \text{if } k \text{ is odd}.
    \end{cases}
\]
</em>
</p>

<p>
<em>Proof.</em>
This is a proof by mathematical induction. We have \( f(0) = n \) by
definition. Therefore the base case holds good.
</p>

<p>
Let us assume that \( f(k) = n \) for any even \( k \) (induction
hypothesis). Let \( k' = k + 1 \) and \( k'' = k + 2. \)
</p>

<p>
If \( k \) is even, we get

\begin{align*}
f(k')  &amp; = n \oplus (f(k) - 1)  &amp;&amp; \text{(by definition)} \\
       &amp; = n \oplus (n - 1)     &amp;&amp; \text{(by induction hypothesis)} \\
       &amp; = 1                    &amp;&amp; \text{(by lemma 1)},\\
f(k'') &amp; = n \oplus (f(k') - 1) &amp;&amp; \text{(by definition)} \\
       &amp; = n \oplus (1 - 1)     &amp;&amp; \text{(since \( f(k') = 1\))} \\
       &amp; = n \oplus 0 \\
       &amp; = n.
\end{align*}
</p>

<p>
Since \( f(k'') = n \) and \( k'' \) is the next even number after
\( k, \) the induction step is complete. The induction step shows that
for every even \( k, \) \( f(k) = n \) holds good. It also shows that as
a result of \( f(k) = n \) for every even \( k, \) we get \( f(k') = 1
\) for every odd \( k'. \)
</p>

<!-- Theorem 2 -->
<p>
<strong>Theorem 2.</strong>
<em>
Let \( \oplus \) denote bitwise XOR operation on two nonnegative
integers and

\[
  f(k) =
    \begin{cases}
      n                        &amp; \text{if } n = 0, \\
      n \oplus (f(n - 1) - 1)  &amp; \text{if } n &gt; 1.
    \end{cases}
\]

where \( k \) is a nonnegative integer, \( n \) is an even positive
integer, and \( 0 \leq k \leq n. \) Then

\[
  f(k) = 0 \iff k = n.
\]
</em>
</p>

<p>
<em>Proof.</em>
We will first show by the principle of mathematical induction that for
even \( k, \) \( f(k) = n - k. \) We have \( f(0) = n \) by definition,
so the base case holds good. Now let us assume that \( f(k) = n - k \)
holds good for any even \( k \) where \( 0 \leq k \leq n \) (induction
hypothesis).
</p><p>
Since \( n \) is even (by definition) and \( k \) is even (by induction
hypothesis), \( f(k) = n - k \) is even. As a result, \( f(k) - 1 \) is
odd. By lemma 3, we conclude that \( f(k + 1) = n \oplus (f(k) - 1) \)
is odd.
</p>

<p>
Now we perform the induction step as follows:

\begin{align*}
f(k + 2) &amp; = n \oplus (f(k + 1) - 1)
                 &amp;&amp; \text{(by definition)} \\
         &amp; = n \oplus (f(k + 1) \oplus 1)
                 &amp;&amp; \text{(by lemma 2 for odd \( n \))} \\
         &amp; = n \oplus ((n \oplus (f(k) - 1)) \oplus 1)
                 &amp;&amp; \text{(by definition)} \\
         &amp; = (n \oplus n ) \oplus ((f(k) - 1) \oplus 1)
                 &amp;&amp; \text{(by associativity of XOR)} \\
         &amp; = 0 \oplus ((f(k) - 1) \oplus 1) \\
         &amp; = (f(k) - 1) \oplus 1 \\
         &amp; = (f(k) - 1) - 1
                 &amp;&amp; \text{(from lemma 2 for odd \( n \))} \\
         &amp; = f(k) - 2 \\
         &amp; = n - k - 2
                 &amp;&amp; \text{(by induction hypothesis).}
\end{align*}

This completes the induction step and proves that \( f(k) = n - k \)
for even \( k \) where \( 0 \leq k \leq n. \)
</p>

<p>
We have shown above that \( f(k) \) is even for every even \( k \) where
\( 0 \leq k \leq n \) which results in \( ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://susam.in/blog/loopy-c-puzzle/">https://susam.in/blog/loopy-c-puzzle/</a></em></p>]]>
            </description>
            <link>https://susam.in/blog/loopy-c-puzzle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25175769</guid>
            <pubDate>Sun, 22 Nov 2020 07:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Minimum Loveable Product]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25175220">thread link</a>) | @grwthckrmstr
<br/>
November 21, 2020 | https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You've validated your micro-SaaS idea and are ready to start building the product.</p><p>The obvious next questions are</p><ol start="" role="list"><li>Which features should the product include in its first version?</li><li>How long should you take to build it?</li></ol><p>Through this post, I provide you with a framework to identify your initial product features, how to decide what to include or exclude from the first versions, and continue building upon it.</p><p>Before jumping into MLP, let's first understand what MVP&nbsp;is and why it's not enough in today's times.</p><h2>What is a Minimum Viable Product (MVP)?</h2><p><a href="https://twitter.com/ericries" target="_blank">Eric Ries</a> popularized the term <a href="https://en.wikipedia.org/wiki/Minimum_viable_product" target="_blank">minimum viable product</a> in his book <a href="http://theleanstartup.com/" target="_blank">The Lean Startup</a> as that version of a new product that is just usable enough by early customers who can then provide feedback to the team. This feedback should help the team generate validated learnings and guide them on future product development and features.</p><h4>When MVP still works</h4><p>MVP is not dead though. It still works, given the right kind of problem statements.</p><p>Suppose you're building something that simply doesn't exist in the world, and it's something that people really want and have no alternative to getting it except from you.</p><p>At this time, people will accept a textbook MVP, simply because they have no frame of reference to compare it with. Or better yet, because they have no alternative to replace your MVP with.</p><h4>Why MVP&nbsp;is not enough in 2021</h4><p>Over the past few years as smartphone penetration boomed, products matured, product design and user experience matured, people's expectations have increased.</p><p>No longer does a quickly thrown together prototype cut it. People expect a minimum level of good UX and ease-of-use, else they'll leave your app before even giving it a proper try.</p><p>In fact, in 2021 great UX might be one strong reason people pick your product over incumbents. That's what happened with <a href="https://transistor.fm/" target="_blank">Transistor.fm</a>, who made podcast hosting simple and easy.</p><p>People expect good aesthetics that make a first impression, simply because that's what they have become used to from the plethora of beautiful and well-designed apps out there in the world.</p><p>People expect products to be fully functional as advertised. Buggy products are not acceptable, and in fact people might quickly take to Twitter or social media to let others know that a product is unreliable.</p><p>The MVP mindset intensely focuses on building the bare minimum, and that often leaves users frustrated and drives them to seek alternative solutions. Stiffer competition means that people WILL compare your product to alternatives in the market, it's inevitable. And unless you provide something unique and valuable that nobody else does, people are likely to leave.</p><p>All these reasons and more make MVP&nbsp;a dated concept, especially in the context of SaaS products. But above all, I think the MVP mindset makes product builders think too heavily about the "minimum" and often so at the cost of "viable".</p><p>That's a common pitfall and to avoid that, I propose the MLP framework.</p><h2>What is a Minimum Loveable Product (MLP)?</h2><p>A great new concept that I've fallen in love with and personally follow in every product I build is MLP, or Minimum Loveable Product.</p><p>The term MLP was first coined by Brian de Haaff, the co-founder of Aha!, in his book <a href="https://www.aha.io/lovability" target="_blank">Lovability</a>.</p><p>Its definition is an extension of what Eric Ries already introduced to the world with MVP. With MLP though, you are trying to build the minimum "loveable" product, with a focus on no matter how small or feature-stripped the first version of your product is, it is sufficient to deliver a delightful experience to your user.</p><h4>Minimum Viable Product and the burnt pizza analogy</h4><p><a href="https://www.linkedin.com/in/jiaona/" target="_blank">Jiaona Zhang</a>, who is currently VP&nbsp;of Product at Webflow (this blog is built using Webflow) introduced the <a href="https://firstround.com/review/dont-serve-burnt-pizza-and-other-lessons-in-building-minimum-lovable-products/" target="_blank">burnt pizza analogy</a> to her students at Stanford.</p><p>‚Äú<em>Say you‚Äôre trying to test whether people like pizza. If you serve them burnt pizza, you‚Äôre not getting feedback on whether they like pizza. You only know that they don‚Äôt like burnt pizza. Similarly, when you‚Äôre only relying on the MVP, the fastest and cheapest functional prototype, you risk not actually testing your product, but rather a poor or flawed version of it.</em>"</p><p>A great practical example of Minimum Loveable Product is the Apple iPad. All the tablets that came before Apple's tablet were MVPs.</p><h2>MLP vs MVP</h2><p>If you're new to all these terminologies, I understand that it can be confusing. Bear with me, you'll wrap your head around it soon enough.</p><p>Build an MLP when you are solving a problem that's already understood by people, and an MVP when people don't easily understand a problem.</p><p>Build an MLP when you can clearly define and understand a market and you are trying to stand out from the existing tools. Build an MVP when you're trying to gauge if there even exists a market to serve.</p><p>An&nbsp;MLP can be built when you know exactly what customers want. An MVP is when you don't know what customers want, and therefore you want to throw things at the wall as quickly as possible and see what sticks.</p><p>An MLP is necessary if you are building in a market where several large and well-known alternatives already exist. An MVP is the right approach for a new market with barely any alternatives, or those solutions are not yet known by the masses.</p><p>While building an MLP, you make a dedicated effort to succeed with that idea. With MVP, you are trying to determine quickly whether the idea can succeed or whether it will fail.</p><p>Building an&nbsp;MVP means you're ready for failure and also ready to pivot quickly as you learn more about the market. Which means you should make tech and architecture decisions that help you move fast above anything else. Scalability or good architecture design is a concern to pay attention to while building an MLP.</p><p>Finally, the end goal of an MLP is that the customers who use it find it sufficient in functionality and experience to be able to "love" it. With an MLP, you're building just enough that a customer with (hopefully) a real pain point would "tolerate" and continue using your product while you validate your assumptions.</p><h2>Minimum Marketable Product, Minimum Remarkable Product, Minimum Launchable Product</h2><p>The what?</p><p>I know, I know. I came across these terms for the first time today while researching to write this post. And I went through the literature so that I can tell you to safely ignore it.</p><p>If you understand and embody the concept of MLP, you don't need to think about any other frameworks or terminologies that you may discover while researching on Google.</p><h2>How to build an MLP for your Micro SaaS idea</h2><p>Alright, let's put aside theory and dive right in.</p><p>Here are the steps you should loosely follow to building an MLP.</p><h4>1. Understand the #1 problem you're trying to solve</h4><p>What's the #1 reason someone would want to use your Micro SaaS product over existing alternatives?</p><p>Is it that existing options have poor UX?&nbsp;Great, create a well designed and easy-to-use product. You'd be surprised to know how often people switch to an easier to use tool, simply because they are fed up of the poor UX that they encounter repeatedly.</p><p>Is it that existing alternatives are very expensive?&nbsp;Carve out a minimum set of features that people are paying a lot of money for and charge 1/10th for your v1 product. This might not work for very large customers, but vast majority of customers who are small or mid-sized are always looking for affordable alternatives.</p><p>It might not just be raw quantum of pricing, but certain companies targeting Enterprise customers have very complicated pricing slabs and tiers that are designed to give their sales person more room. In such a case, coming out with a competitor product which has a simple, easy-to-understand pricing is how you attract customers.</p><p>Are existing alternatives lacking certain features that leaves a subset of users very dissatisfied?&nbsp;Great, your MLP should specifically address that problem by building functionality that attracts these dissatisfied users. Side note - This is perhaps one of the best ways to go about building a new product.</p><p>In all cases, it involves understanding the problem you are solving and the exact reason why someone would use your product.</p><h4>2. Design a simple product that solves the top customer needs satisfactorily</h4><p>Once you have identified the #1 reason, it's time to decide on a feature set for your product that solves your customer's top pain points satisfactorily.</p><p><strong>Let's take an example</strong> - People want to add a feedback tracking tool inside their product, so that they can collect user feedback automatically. However, the existing solutions don't allow them to embed the feedback tracker within their tool.</p><p>That's your entry point into providing value that customers seek, but are not getting as of today.</p><p>Having understood the #1 problem, you also have to understand other requirements that fall under the "minimum" set of things you need to do to build a "loveable" product.</p><p>These could be:</p><ul role="list"><li>existing solutions are all well designed and aesthetically pleasing =&gt;&nbsp;your minimum loveable product needs to be well designed too</li><li>existing solutions are affordably priced with a easy to understand pricing structure =&gt; your MLP also needs a simple pricing structure that's affordable</li></ul><p>In general, you want to analyze your competitors and understand </p><ol start="" role="list"><li>What they are doing well</li><li>What users value from among those things</li></ol><p>In your MLP, you need to cover the intersection of (what they are doing well) x (what users value from among those).</p><h4>3. Set a short timeline for building your MLP</h4><p>No matter what you build, building in isolation for too long is dangerous. The main reason for that is - you get to know too late whether your assumptions about what the user really values are on point or off course.</p><p><strong>"But Preetam, you just told me to build a Minimum Loveable Product. And now you're saying I got to build it quickly?"</strong></p><p>Yes, that's exactly what I'm saying.</p><p>Short timeframe depends on what you are building, and the size of your team.</p><p>For example - with SuperLemon (WhatsApp plugin for Shopify), Sankalp and I built a MLP in 2 weeks time.</p><p>How?</p><p>We identified precisely the way we could do better - ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas">https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25175220</guid>
            <pubDate>Sun, 22 Nov 2020 05:40:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Abandoned Mansion in NYC Raises Questions]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25174361">thread link</a>) | @new_guy
<br/>
November 21, 2020 | https://www.hooch.net/an-abandoned-mansion-in-nyc-raises-questions | <a href="https://web.archive.org/web/*/https://www.hooch.net/an-abandoned-mansion-in-nyc-raises-questions">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.hooch.net/an-abandoned-mansion-in-nyc-raises-questions</link>
            <guid isPermaLink="false">hacker-news-small-sites-25174361</guid>
            <pubDate>Sun, 22 Nov 2020 02:23:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Python's Bisect Module]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25174048">thread link</a>) | @kaunta
<br/>
November 21, 2020 | https://johnlekberg.com/blog/2020-11-21-stdlib-bisect.html | <a href="https://web.archive.org/web/*/https://johnlekberg.com/blog/2020-11-21-stdlib-bisect.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://johnlekberg.com/blog.html">Return to Blog
</a></p><p>By John Lekberg on November 21, 2020.
</p><hr>
<p><a href="https://news.ycombinator.com/item?id=25174048">Hacker News discussion.</a></p>
<hr>
<p>This week's post is about Python's <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module. You will learn:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Data_binning">Statistical data binning</a> with <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>.</li>
<li>Adding new data to a sorted list with <a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a>.</li>
</ul>
<p>The goal of the <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module is to allow you to efficiently search and
update sorted lists. To this end, it provides:</p>
<ul>
<li>A <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a> implementation, <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>.</li>
<li>An "insert" -- as in <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a> -- implementation, <a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a>.</li>
</ul>

<p>In <a href="https://en.wikipedia.org/wiki/Data_binning">statistical data binning</a>, you have data that you want to group into "bins". E.g.</p>
<ul>
<li>You have data on different fruits and want to group "lemon" and "orange" into
"citrus".</li>
<li>You have data on students' grades and want to group scores between 80 and 90
into "B", scores between 90 and 100 into "A", etc.</li>
</ul>
<p>To me, a straightforward approach is to write a function that computes the bin.
E.g., binning fruits:</p>
<blockquote>
<pre><code>def bin_fruit(fruit):
    if fruit in ["lemon", "orange"]:
        return "citrus"
    elif fruit in ["apple", "pear"]:
        return "malinae"


import random

data = random.choices(
    ["lemon", "orange", "apple", "pear"], k=10
)
data
</code></pre>
</blockquote>
<pre><code>['lemon',
 'lemon',
 'apple',
 'apple',
 'apple',
 'lemon',
 'apple',
 'apple',
 'lemon',
 'pear']
</code></pre>
<blockquote>
<pre><code>[bin_fruit(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['citrus',
 'citrus',
 'malinae',
 'malinae',
 'malinae',
 'citrus',
 'malinae',
 'malinae',
 'citrus',
 'malinae']
</code></pre>
<p>E.g., turning test scores into <a href="https://en.wikipedia.org/wiki/Academic_grading_in_the_United_States">letter grades</a>:</p>
<blockquote>
<pre><code>def bin_score(score):
    if 90 &lt;= score &lt;= 100:
        return "A"
    elif 80 &lt;= score &lt; 90:
        return "B"
    elif 70 &lt;= score &lt; 80:
        return "C"
    elif 60 &lt;= score &lt; 70:
        return "D"
    elif score &lt; 60:
        return "F"


import random

data = [random.randint(50, 100) for _ in range(10)]
data
</code></pre>
</blockquote>
<pre><code>[78, 87, 93, 78, 53, 92, 64, 70, 75, 60]
</code></pre>
<blockquote>
<pre><code>[bin_score(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['C', 'B', 'A', 'C', 'F', 'A', 'D', 'C', 'C', 'D']
</code></pre>
<p>For a dataset of <var>n</var> records and <var>m</var> bins, the <a href="https://en.wikipedia.org/wiki/Time_complexity">time
complexity</a> of this approach tends to be</p>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Big_O_notation">O</a>(<var>m</var><var>n</var>)</p>
</blockquote>
<p>Because binning one record takes O(<var>m</var>) time -- O(<var>m</var>)
if-statements are checked -- and <var>n</var> records need to be binned.</p>
<p>If the number of bins <var>m</var> is constant, then the overall time
complexity is simply O(<var>n</var>).</p>
<p>But what if the number of bins <var>m</var> is large enough that the
straightforward approach is too slow?</p>
<ul>
<li>
<p>For <a href="https://en.wikipedia.org/wiki/Continuous_or_discrete_variable">discrete data</a>, you can use <a href="https://docs.python.org/3/library/stdtypes.html#mapping-types-dict">dictionaries</a>. E.g., binning
fruits:</p>
<blockquote>
<pre><code>bins = {
    "lemon": "citrus",
    "orange": "citrus",
    "apple": "malinae",
    "pear": "malinae",
}

def bin_fruit(fruit):
    return bins[fruit]


import random

data = random.choices(
    ["lemon", "orange", "apple", "pear"], k=10
)
data
</code></pre>
</blockquote>
<pre><code>['lemon',
 'pear',
 'lemon',
 'lemon',
 'apple',
 'orange',
 'apple',
 'orange',
 'pear',
 'apple']
</code></pre>
<blockquote>
<pre><code>[bin_fruit(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['citrus',
 'malinae',
 'citrus',
 'citrus',
 'malinae',
 'citrus',
 'malinae',
 'citrus',
 'malinae',
 'malinae']
</code></pre>
<p>Binning one record this way takes O(1) time -- regardless of the number of
bins <var>m</var> -- because <a href="https://docs.python.org/3/library/stdtypes.html#mapping-types-dict">dictionaries</a> are implemented using
<a href="https://en.wikipedia.org/wiki/Hash_table">hash tables</a>. And creating the <a href="https://docs.python.org/3/library/stdtypes.html#mapping-types-dict">dictionary</a> take O(<var>m</var>) time --
one entry for each bin. Thus, the overall time complexity, for <var>n</var>
records and <var>m</var> bins, is</p>
<blockquote>
<p>O(<var>m</var> + <var>n</var>).</p>
</blockquote>
</li>
<li>
<p>And, for <a href="https://en.wikipedia.org/wiki/Continuous_or_discrete_variable">continuous data</a>, you can use <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>. E.g., turning
test scores into <a href="https://en.wikipedia.org/wiki/Academic_grading_in_the_United_States">letter grades</a>:</p>
<blockquote>
<pre><code>score_bins = [60, 70, 80, 90]
score_letters = ["F", "D", "C", "B", "A"]

import bisect


def bin_score(score):
    i = bisect.bisect(score_bins, score)
    return score_letters[i]


import random

data = [random.randint(50, 100) for _ in range(10)]
data
</code></pre>
</blockquote>
<pre><code>[60, 100, 88, 98, 55, 52, 52, 94, 71, 85]
</code></pre>
<blockquote>
<pre><code>[bin_score(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['D', 'A', 'B', 'A', 'F', 'F', 'F', 'A', 'C', 'B']
</code></pre>
<p>Binning one record this way takes O(log√Ç&nbsp;<var>m</var>) time, because
<a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a> uses <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a> to navigate <code>score_bins</code>. And
creating <code>score_bins</code> takes O(<var>m</var>) time. Thus, the overall time
complexity, for <var>n</var> records and <var>m</var> bins, is</p>
<blockquote>
<p>O(<var>m</var> + <var>n</var> log <var>m</var>)</p>
</blockquote>
<p>NOTE: If you are able to use 3rd-party libraries, such as <a href="https://numpy.org/">NumPy</a> or
<a href="https://pandas.pydata.org/">Pandas</a>, then look at these functions: <a href="https://numpy.org/doc/stable/reference/generated/numpy.digitize.html">numpy.digitize</a>,
<a href="https://numpy.org/doc/stable/reference/generated/numpy.searchsorted.html#numpy.searchsorted">numpy.searchsorted</a>, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.searchsorted.html">pandas.Series.searchsorted</a>, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html#pandas.qcut">pandas.qcut</a>,
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html">pandas.cut</a>.</p>
</li>
</ul>

<p>In this scenario, you have a sorted list of data and you want to:</p>
<ul>
<li>Compute <a href="https://en.wikipedia.org/wiki/Order_statistic">order statistics</a> (e.g. compute the <a href="https://en.wikipedia.org/wiki/Median">median</a>).</li>
<li>Add new data.</li>
</ul>
<p>For example, you can imagine having a temperature sensor that regularly reports
the temperature. You want to regularly report the median temperature, as well
as be able to incorporate new temperature data as it arrives.</p>
<p>To me, a straightforward approach is to use <a href="https://docs.python.org/3/library/stdtypes.html#mutable-sequence-types">list.append</a> and
<a href="https://docs.python.org/3/library/statistics.html#statistics.median">statistics.median</a>. E.g., monitoring temperatures:</p>
<blockquote>
<pre><code>def add_new_measurement(data, temperature):
    data.append(temperature)


def median(data):
    return statistics.median(data)


import random
import statistics

data = [random.randint(93, 100) for _ in range(10)]
data
</code></pre>
</blockquote>
<pre><code>[98, 94, 97, 94, 94, 98, 98, 94, 94, 95]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>94.5
</code></pre>
<blockquote>
<pre><code>add_new_measurement(data, 97)
data
</code></pre>
</blockquote>
<pre><code>[98, 94, 97, 94, 94, 98, 98, 94, 94, 95, 97]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>95
</code></pre>
<p>For a dataset of <var>n</var> records, the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> of this approach
tends to be</p>
<ul>
<li><strong>Computing median:</strong> O(<var>n</var>) or O(<var>n</var> log <var>n</var>) --
depending on how the median is computed.</li>
<li><strong>Adding new data:</strong> O(1).</li>
</ul>
<p>So if the workload requires frequently adding new data and infrequently
computing the median, this approach works well.</p>
<p>But what if the workload is inverted? For example, if temperature measurements
are received every couple of minutes, but the median must be computed every
couple of seconds.</p>
<p>In that scenario, I think we would be better suited by speeding up computing
the median, even at the expense of slowing down adding new data.</p>
<p>Computing order statistics can be done in O(1) time if the data is already
sorted. So a straightforward way to handle this workload would be to sort the
data after appending and use the fact that the data is sorted to efficiently
compute the median:</p>
<blockquote>
<pre><code>def add_new_measurement(data, temperature):
    data.append(temperature)
    data.sort()


def median(data):
    n = len(data)
    if n % 2 == 0:
        return (data[(n // 2) - 1] + data[n // 2]) / 2
    else:
        return data[n // 2]


import random

data = sorted(random.randint(93, 100) for _ in range(10))
data
</code></pre>
</blockquote>
<pre><code>[93, 94, 94, 96, 96, 97, 98, 99, 100, 100]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>96.5
</code></pre>
<blockquote>
<pre><code>add_new_measurement(data, 97)
data
</code></pre>
</blockquote>
<pre><code>[93, 94, 94, 96, 96, 97, 97, 98, 99, 100, 100]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>97
</code></pre>
<p>For a dataset of <var>n</var> records, the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> of this approach
tends to be</p>
<ul>
<li><strong>Computing median:</strong> O(1).</li>
<li><strong>Adding new data:</strong> O(<var>n</var> log <var>n</var>).</li>
</ul>
<p>But I think that the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> for adding new data can further be
improved by using <a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a>, which runs in</p>
<blockquote>
<p>O(<var>n</var>)</p>
</blockquote>
<p>Here's Python code that does that:</p>
<pre><code>import bisect


def add_new_measurement(data, temperature):
    bisect.insort(data, temperature)
</code></pre>
<p>Doing this changes the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> of adding new data from</p>
<blockquote>
<p>O(<var>n</var> log <var>n</var>)</p>
</blockquote>
<p>to</p>
<blockquote>
<p>O(<var>n</var>)</p>
</blockquote>

<p>In this week's post you learned how to use the <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module for
statistical data binning and adding new data to sorted lists.</p>
<p>For further reading:</p>
<ul>
<li>Algorithms that process input piece-by-piece -- like the temperature sensor
scenario -- are called <a href="https://en.wikipedia.org/wiki/Online_algorithm">online algorithms</a>.</li>
<li><a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a> can be used to implement an <a href="https://en.wikipedia.org/wiki/Insertion_sort">Insertion sort</a>. Insertion
sort is an <a href="https://en.wikipedia.org/wiki/Online_algorithm">online algorithm</a> and -- along with Python's built-in
<a href="https://en.wikipedia.org/wiki/Timsort">timsort</a> -- is an <a href="https://en.wikipedia.org/wiki/Adaptive_sort">adaptive sorting algorithm</a> because it takes
advantage of data that is partially sorted.</li>
</ul>
<p>My challenge to you:</p>
<blockquote>
<p>The <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module provides "left"- and "right"-variants of
<a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a> and <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>: <a href="https://docs.python.org/3/library/bisect.html#bisect.insort_left">bisect.insort_left</a>,
<a href="https://docs.python.org/3/library/bisect.html#bisect.insort_right">bisect.insort_right</a>, <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect_left">bisect.bisect_left</a>, <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect_right">bisect.bisect_right</a>.</p>
<p>Read the documentation and figure out what the difference between the "left"-
and "right"-variants is.</p>
</blockquote>
<p>If you enjoyed this week's post, share it with your friends and stay tuned for
next week's post. See you then!</p>

<hr>
<p>(If you spot any errors or typos on this post, contact me via my
<a href="https://johnlekberg.com/contact.html">contact page</a>.)
</p></div></div>]]>
            </description>
            <link>https://johnlekberg.com/blog/2020-11-21-stdlib-bisect.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25174048</guid>
            <pubDate>Sun, 22 Nov 2020 01:20:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Delaware license plates tell us about social status signalling]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25173952">thread link</a>) | @Bologo
<br/>
November 21, 2020 | https://www.psychnewsdaily.com/what-delaware-license-plates-tell-us-about-social-status-signalling/ | <a href="https://web.archive.org/web/*/https://www.psychnewsdaily.com/what-delaware-license-plates-tell-us-about-social-status-signalling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.psychnewsdaily.com/what-delaware-license-plates-tell-us-about-social-status-signalling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25173952</guid>
            <pubDate>Sun, 22 Nov 2020 01:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pianists for Alternatively Sized Keyboards]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 211 (<a href="https://news.ycombinator.com/item?id=25173522">thread link</a>) | @spekcular
<br/>
November 21, 2020 | http://paskpiano.org/about/ | <a href="https://web.archive.org/web/*/http://paskpiano.org/about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="30" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="6b7c51e" data-element_type="section">
						
		</section>
				<section data-id="0db4fdb" data-element_type="section">
						<div>
							<div>
					<div data-id="89500ce" data-element_type="column">
			<div>
							<div>
						<section data-id="02b9628" data-element_type="section">
						<div>
							<div>
					<div data-id="c6a8384" data-element_type="column">
			<div>
							<div>
						<div data-id="39c182b" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>PASK ‚Äì Pianists for Alternatively Sized Keyboards ‚Äì is an international movement committed to achieving change in relation to piano keyboard size.</p><p>Specifically, PASK aims to convince piano manufacturers to begin producing piano keyboards in three standard sizes. Purchasers of new pianos will then have a choice of keyboard size. In addition to the current ‚Äòlarge‚Äô size, we need two additional sizes with <u>narrower keys</u>.&nbsp;&nbsp;</p><p>The current piano keyboard has prevailed since the 1880‚Äôs and was not designed for the physical capabilities of the population at large. It has been assumed that the current size is suitable for all, whereas in fact it is isn‚Äôt. The keys are too wide for the majority of pianists, considering men, women and children of all nationalities and across all age groups.</p><p>The current keyboard size and key width suits people with large hands, generally adult males with average to above average spans. However, for those with smaller hands, today‚Äôs piano increases technical difficulties and learning time. It limits musical expression and prevents access to a large amount of the piano repertoire. Worst of all, it can cause debilitating pain and injury.</p><p>A simple analogy illustrates the point. Does it make sense that all men in an athletics race should have to wear the same size shoes? And that female athletes have to run in the same size shoes as the men? And that children have to run in the same size shoes as adults?</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="86f8594" data-element_type="column">
			<div>
							<div>
						<div data-id="93ab53a" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="290" height="300" src="http://paskpiano.org/wp-content/uploads/2019/03/Square-logo-2-290x300.jpg" alt="" srcset="http://paskpiano.org/wp-content/uploads/2019/03/Square-logo-2-290x300.jpg 290w, http://paskpiano.org/wp-content/uploads/2019/03/Square-logo-2-768x796.jpg 768w, http://paskpiano.org/wp-content/uploads/2019/03/Square-logo-2-989x1024.jpg 989w, http://paskpiano.org/wp-content/uploads/2019/03/Square-logo-2.jpg 1145w" sizes="(max-width: 290px) 100vw, 290px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="be5765d" data-element_type="section">
						<div>
							<div>
					<div data-id="6591610" data-element_type="column">
			<div>
							<div>
						<section data-id="721b21b" data-element_type="section">
						<div>
							<div>
					<div data-id="77af1a3" data-element_type="column">
			<div>
							<div>
						<div data-id="b67b3fe" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="763" height="1024" src="http://paskpiano.org/wp-content/uploads/2019/03/Kristen1-Nov-2014-763x1024.jpg" alt="" srcset="http://paskpiano.org/wp-content/uploads/2019/03/Kristen1-Nov-2014-763x1024.jpg 763w, http://paskpiano.org/wp-content/uploads/2019/03/Kristen1-Nov-2014-224x300.jpg 224w, http://paskpiano.org/wp-content/uploads/2019/03/Kristen1-Nov-2014-768x1031.jpg 768w, http://paskpiano.org/wp-content/uploads/2019/03/Kristen1-Nov-2014.jpg 1216w" sizes="(max-width: 763px) 100vw, 763px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				<div data-id="bdfaffa" data-element_type="column">
			<div>
							<div>
						<div data-id="984bedd" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="720" height="960" src="http://paskpiano.org/wp-content/uploads/2019/03/Students-at-SMU-Institute-for-Young-Pianists.jpg" alt="" srcset="http://paskpiano.org/wp-content/uploads/2019/03/Students-at-SMU-Institute-for-Young-Pianists.jpg 720w, http://paskpiano.org/wp-content/uploads/2019/03/Students-at-SMU-Institute-for-Young-Pianists-225x300.jpg 225w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="d469830" data-element_type="section">
						
		</section>
				<section data-id="6326091" data-element_type="section">
						<div>
							<div>
					<div data-id="cb76b18" data-element_type="column">
			<div>
							<div>
						<div data-id="25d103d" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>The<strong> long term goal of PASK </strong>is for acoustic and digital piano manufacturers to offer a choice of three standard keyboard sizes in accordance with the DS standards. These are: DS5.5¬Æ (7/8) and the DS6.0¬Æ (15/16) as well as the current ‚Äòlarge‚Äô DS6.5<em>&nbsp;</em>keyboard. They need to be&nbsp;mass-produced and marketed worldwide in such a way that the new alternative sizes are readily available and naturally accepted options for all pianists and teachers.&nbsp;</p><p>For this to happen, we need to focus on both building the demand from the piano world as well as encouraging supply from manufacturers. Clearly, these are interdependent.&nbsp;</p><p>Pianists with smaller hands must create a united voice and demand access to keyboards with narrower keys. Piano teachers, universities and conservatoriums need to recognise their benefits. Competitions and concert venues should provide a choice of keyboard for performers.</p><p>Alternatively sized keyboards are currently only available from a limited number of sources, are expensive and often involve long wait times for customers. The major piano manufacturers need to take up this challenge.&nbsp;A key factor in creating change will be public support from prominent pianists, academics and teachers around the world.</p><p>There are three main strategies required to achieve this goal:</p><p>1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Raising awareness of the benefits of reduced size keyboards for those with smaller hands.</p><p>2.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Creating opportunities for pianists to experience the difference in playing on narrower keys.</p><p>3.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Breaking down barriers and resistance to change.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="8b8c474" data-element_type="section">
						<div>
							<div>
					<div data-id="0033df0" data-element_type="column">
			<div>
							<div>
						<div data-id="dea7d2a" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>PASK structure and founders</h2>		</p>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="c7ddbd5" data-element_type="section">
						<div>
							<div>
					<div data-id="3edd0c6" data-element_type="column">
			<div>
							<div>
						<div data-id="925cf88" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>PASK is not a formally constituted organisation, but a network of people working towards a common goal.

There are three founders of PASK:

Ms Erica Booker from Sydney, Australia ‚Äì Graduate of the New South Wales Conservatorium of Music, pianist and piano teacher. Erica is also a Suzuki teacher trainer and leading advocate for alternatively sized piano keyboards:<a href="https://ericabookerpiano.com/%E2%80%8B" target="_blank" rel="noopener">&nbsp;</a>&nbsp;<a href="https://ericabookerpiano.com/" target="_blank" rel="noopener">https://ericabookerpiano.com</a>

Dr Carol Leone from Dallas, Texas ‚Äì Chair of Keyboard Studies at SMU Meadows School of the Arts in Dallas, internationally recognized performing artist, teacher, lecturer, and author. Carol is one of the world‚Äôs leading researchers and proponents of ergonomic piano keyboards to promote a pianist‚Äôs wellness:&nbsp;<a href="http://www.carolleone.com/" target="_blank" rel="noopener">www.carolleone.com</a>

Ms Rhonda Boyle from Melbourne, Australia ‚Äì Former government policy analyst/strategic planner with qualifications in physics, environmental science and urban planning. Rhonda is a pianist, independent researcher and author of peer-reviewed articles relating to hand size and piano playing:
<a href="http://www.linkedin.com/pub/rhonda-boyle/30/931/352" target="_blank" rel="noopener">www.linkedin.com/pub/rhonda-boyle/30/931/352</a>

<span>These three founders have no financial connections with any piano or keyboard manufacturers.</span>

The PASK network is gradually growing and now includes many others around the world who support the PASK goals and who are actively engaged in encouraging change.

If you would like to be an active member of PASK or be kept up to date on developments, please be in touch: <a href="mailto:info@paskpiano.org">info@paskpiano.org</a></p>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="d757218" data-element_type="section">
						
		</section>
				<section data-id="c8bb5bb" data-element_type="section">
						<div>
							<div>
					<div data-id="e92354b" data-element_type="column">
			<div>
							<div>
						<div data-id="759652a" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>The term ESPK (ergonomically scaled piano keyboard) is now mostly used in the academic community when referring to keyboards smaller than the current ‚Äòstandard‚Äô size i.e., with 6.5 inch octave. The term ‚Äòreduced-size keyboard‚Äô has also been used in some literature. &nbsp;Also note that the DS5.5¬Æ<em>&nbsp;</em>is often referred to as the ‚Äò7/8 keyboard‚Äô as the key widths are close to (but not exactly) 7/8 of the ‚Äòstandard‚Äô keyboard. Likewise, the DS6.0¬Æ<em>&nbsp;</em>is often referred to as the 15/16 keyboard. ESPK is a generic term that also includes keyboards of other sizes, i.e. that do not conform to the DS standards.&nbsp;</p><p>The ‚ÄòDS‚Äô abbreviation stands for Donison-Steinbuhler. (Chris Donison and David Steinbuhler pioneered the introduction of piano keyboards with narrower keys for acoustic pianos, mainly in North America.) &nbsp;The PASK movement (Pianists for Alternatively Sized Keyboards) generally uses the term ‚Äòalternative sizes‚Äô to avoid confusion as ‚Äòreduced size‚Äô could imply fewer than 88 keys.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section data-id="41a669e" data-element_type="section">
						<div>
							<div>
					<div data-id="2e65a40" data-element_type="column">
			<div>
							<div>
						<div data-id="3ee7b0a" data-element_type="widget" data-widget_type="wp-widget-sfsi-widget.default">
				<div>
					<div data-position="widget">
			
			<div><div><p><a data-effect="" target="_blank" href="https://www.youtube.com/channel/UCdiQ0iwCWFsGjZ1QI41KSBg/playlists" id="sfsiid_youtube"><img data-pin-nopin="true" alt="YouTube" title="YouTube" src="http://paskpiano.org/wp-content/plugins/ultimate-social-media-icons/images/icons_theme/default/default_youtube.png" width="40" height="40" data-effect=""></a></p></div><div><p><a data-effect="" target="_blank" href="http://instagram.com/paskpianos" id="sfsiid_instagram"><img data-pin-nopin="true" alt="Instagram" title="Instagram" src="http://paskpiano.org/wp-content/plugins/ultimate-social-media-icons/images/icons_theme/default/default_instagram.png" width="40" height="40" data-effect=""></a></p></div></div>			
		</div>
			</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>http://paskpiano.org/about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25173522</guid>
            <pubDate>Sat, 21 Nov 2020 23:28:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid Vaccine Delays ‚Äì Why?]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25172930">thread link</a>) | @ishmandoo
<br/>
November 21, 2020 | http://blog.benwiener.com/economics/2020/11/19/vaccine-delays.html | <a href="https://web.archive.org/web/*/http://blog.benwiener.com/economics/2020/11/19/vaccine-delays.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>I keep hearing about small delays in the vaccine development process that I don‚Äôt understand given how urgent the need is. I read a perfect example today. <a href="https://www.nytimes.com/2020/11/18/health/pfizer-covid-vaccine.html">A New York Times article</a> sharing good news about the effectiveness of the Pfizer vaccine mentioned that the company would be applying for emergency use authorization ‚Äúwithin days‚Äù. <a href="https://www.nytimes.com/2020/11/16/health/Covid-moderna-vaccine.html%22">A similar article</a> cited a period of weeks for the Moderna vaccine. This progress is great news. It made me wonder, though, why not today? What prevented these companies from being ready to file with the FDA right away?</p>

<p>By all accounts, the rapid progress of COVID-19 vaccine candidates has been miraculous. Still, I‚Äôm confused by the apparent lack of urgency in certain parts of the process. Most of the vaccine development work is probably difficult to speed up. For example, it isn‚Äôt possible to speed up the rate at which trial participants get exposed to the virus so that effectiveness can be proven<sup id="fnref:hcc" role="doc-noteref"><a href="#fn:hcc">1</a></sup>. But what prevents Pfizer and Moderna from pre-writing their application to the FDA while the trial is running and netting a few days or weeks? Even just a few days has serious value. Of course, the data is still coming in so there would be some uncertainty about what should be written in the application. But they must have a pretty good sense of how the trial is going. They could even pre-write two or three versions to cover the most likely scenarios. And of all possible trial outcomes, why would these companies both be unprepared for best-case scenarios where their vaccines are proving to be highly effective?</p>

<p>Getting a bit more speculative, why aren‚Äôt scientists at Pfizer and Moderna already in conversation with decision makers at the FDA so that the evaluation process can be started based on preliminary data? Then they could be possibly be ready to issue emergency use authorization immediately once the trial concludes. If there is an unexpected change in the latest data regulators should of course be prepared to reassess. To be clear, I am not suggesting that the approval process be less rigorous. I just want it happening in parallel with the trial as much as it can. Given how ridiculously destructive this pandemic is, I sure hope COVID vaccines are the FDA‚Äôs top priority.</p>

<p>This possibility reminds me of the mechanics of my thesis defense. My adviser, the main decision maker, was already very familiar with my work. Little information was actually transmitted to him that day. He already knew what he needed to know to make his decision. In fact, we wouldn‚Äôt have even gone forward with the defense if he wasn‚Äôt ready to pass me. He didn‚Äôt take a month after the defense to closely read my thesis, consider all the arguments, check the math, and then deliberate. That process occurred while the data was coming in. Maybe some parallelization of the approval process like this is happening for the COVID vaccines, but I‚Äôve never read anything that gives the sense that it is.</p>

<h3 id="possible-answers-to-my-own-questions">Possible answers to my own questions:</h3>
<h4 id="why-werent-the-eua-applications-ready">Why weren‚Äôt the EUA applications ready?</h4>

<p>Maybe a document like this is <em>way</em> more complicated than I‚Äôm imagining and the drug companies are writing them as fast as possible. This sort of suggests that writing the application is a similar challenge to developing the vaccine. I hope that‚Äôs not right.</p>

<p>Maybe the drug companies <em>are</em> already working with the FDA, and the timing of the application isn‚Äôt important. As I mentioned above, I‚Äôve never seen anything that suggests this.</p>

<p>Maybe these companies aren‚Äôt incentivized to actually get the vaccine to market as fast as they can. Off the bat this didn‚Äôt seem right to me, but could the advance purchase agreements that Moderna and Pfizer signed with governments eliminate their urgency?</p>

<h4 id="why-arent-the-drug-companies-working-with-the-fda">Why aren‚Äôt the drug companies working with the FDA?</h4>

<p>Maybe this just isn‚Äôt the way the FDA usually works and they weren‚Äôt able to adapt to this extraordinary situation.</p>

<p>Obviously scientific integrity is important here. Maybe the scientists are intentionally kept separate from other parts of Pfizer and from the FDA to prevent some kind of academic dishonesty. I wonder about the relative dangers involved, but I could imagine an explanation like this.</p>

<h3 id="answers-that-other-people-have-suggested">Answers that other people have suggested:</h3>

<p>Commenters on Hacker News and Reddit have suggested that the things I want to happen are already happening. I‚Äôve looked into this a little bit, and I‚Äôm unsure. Both Moderna and Pfizer have been granted the FDA‚Äôs <a href="https://www.fda.gov/patients/fast-track-breakthrough-therapy-accelerated-approval-priority-review/fast-track">Fast Track status</a>. This sounds great. It apparently means these companies have the opportunity for closer collaboration with the FDA, at least on clinical trial design. Some have suggested that the companies would also already be sharing advance results from their studies, but I haven‚Äôt found any reference saying that.</p>

<p>Fast Track also gives them the opportunity to participate in Rolling Review, which allows them to submit sections of their applications as they become ready. The references I‚Äôve found discussing this are mostly <a href="https://www.pfizer.com/news/press-release/press-release-detail/pfizer-and-biontech-submit-emergency-use-authorization">press releases by the companies</a> or closely based on them. They discuss participation in Rolling Review in Europe and elsewhere, but I haven‚Äôt seen that they are doing this in the US.</p>



  </div></div>]]>
            </description>
            <link>http://blog.benwiener.com/economics/2020/11/19/vaccine-delays.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25172930</guid>
            <pubDate>Sat, 21 Nov 2020 21:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Best of NeXT Collection]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25172693">thread link</a>) | @mpweiher
<br/>
November 21, 2020 | http://www.kevra.org/TheBestOfNext/index.html | <a href="https://web.archive.org/web/*/http://www.kevra.org/TheBestOfNext/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">
    <!-- Start container -->

    <!-- End sidebar wrapper -->

    <div id="contentContainer">
      <!-- Start main content wrapper -->

      <div id="content">
        <!-- Start content -->

        <p><img alt="KeyFobHeader6" src="http://www.kevra.org/TheBestOfNext/files/page0_1.jpg" width="604" height="197">
        <br></p>

        <p><span>After Steve Jobs was forced out of Apple
        in 1985, everyone wanted to know what Steve would do
        next.... so NeXT was what he did.
        <p>
        
        In 1988 his NeXT team launched a new kind of computer for
        it's time, built on standards with a Unix core but with a
        user experience "my grandma could understand". It was well
        ahead of it's time, so naturally, it was not embraced by
        main stream consumers... a classic "Crossing the Chasm"
        issue. But many saw it for what it was, a breakthrough
        product as innovative as today's iTunes, iPod and iPhone.
        </p><p>
        
        Building upon NeXT's hardware and more importantly, their
        software development environment, many third party NeXT
        developers added their own magic dust to create
        revolutionary products, like the world's first web browser,
        or a new form of spread sheet, Lotus Improv or WebObjects,
        the foundation upon which the iTune store is built, to name
        only a few. Some of these ground breaking products may
        never be repeated. Most contained innovations embraced by
        future applications, with a clear lineage back to NeXTSTEP.
        </p><p>
        
        During the relatively short time of NeXT ascendency
        (1985-1996), Apple was bleeding red ink from repeated
        financial losses and two hugely expensive attempts to
        create a follow on Operating System. Apple's third
        president since Steve's departure, Gil Amelio saw the
        merits of Steve, his team and their technology. In December
        1996 Apple bought Next. Then the Next team took over Apple.
        The result is their hugely successful Mac OS X, built on
        the foundations of the NeXTSTEP OS.
        </p><p>
        
        While NeXT is no more, as a product or a stand alone
        company, it's impact on the industry will be felt for years
        to come. We should remember it, perhaps even study it. In
        decades to come, it will be understood as a watershed of
        innovation. Current Mac and iPhone users will be astonished
        to see how many of their beloved Mac OS X innovations had
        their roots in NeXTSTEP. There are many lessons about
        product innovation, market acceptance, and the creative
        people involved, that have yet to be uncovered.
        </p><p>
        
        This web site details part of our unique collection of NeXT
        related products and assorted items which grew up around
        NeXT Computer ecosystem, including of course NeXT hardware
        but also those rare items such as dealer sales kits, logo'd
        clothing, NeXT jewelry, banners, training tapes for
        servicing NeXT computers and printers, developer guides,
        plus third party software and hardware products.
        </p><p>
        
        While the site describes only part of the actual
        collection, the site does cover over 800 NeXT and third
        party products, many with multipage brochures and white
        papers. If you were to print all the html and PDF documents
        it would be over 3,000 pages.
        </p><p>
        
        This site describes what may well be the most extensive
        NeXT related collection available today.
        </p><p>
        
        It's history worth preserving.
        </p></span></p>

        
      </div><!-- End content -->

      <!-- End Footer -->
    </div><!-- End main content wrapper -->
  </div></div>]]>
            </description>
            <link>http://www.kevra.org/TheBestOfNext/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25172693</guid>
            <pubDate>Sat, 21 Nov 2020 20:55:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FTC commissioner met with Apple regarding Facebook‚Äôs iOS 14 complaints]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25171707">thread link</a>) | @aeromusek
<br/>
November 21, 2020 | https://www.myhealthyapple.com/etc-apple-facebook-ios14/ | <a href="https://web.archive.org/web/*/https://www.myhealthyapple.com/etc-apple-facebook-ios14/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://www.myhealthyapple.com/wp-content/uploads/FTC_Apple_Facebook_Meetings.jpg" data-caption=""><img width="696" height="416" src="https://www.myhealthyapple.com/wp-content/uploads/FTC_Apple_Facebook_Meetings-696x416.jpg" srcset="https://www.myhealthyapple.com/wp-content/uploads/FTC_Apple_Facebook_Meetings-696x416.jpg 696w, https://www.myhealthyapple.com/wp-content/uploads/FTC_Apple_Facebook_Meetings-300x179.jpg 300w, https://www.myhealthyapple.com/wp-content/uploads/FTC_Apple_Facebook_Meetings-768x459.jpg 768w, https://www.myhealthyapple.com/wp-content/uploads/FTC_Apple_Facebook_Meetings-702x420.jpg 702w, https://www.myhealthyapple.com/wp-content/uploads/FTC_Apple_Facebook_Meetings.jpg 926w" sizes="(max-width: 696px) 100vw, 696px" alt="FTC-Apple-Facebook-iOS14" title="FTC_Apple_Facebook_Meetings"></a></p><p>In a<span>&nbsp;</span>letter sent to the Ranking Digital Rights organization, Apple‚Äôs Jane Horvath, senior director of global privacy, reiterated that the company believes that<strong> ‚Äúprivacy is a fundamental human right.‚Äù</strong></p><p>Horvath explains that Apple <span>delayed the App Tracking Transparency (ATT) feature</span> to give developers more time to prepare for the changes.</p><h2><strong>Facebook‚Äôs complaints about Apple‚Äôs App Tracking Transparency (ATT)</strong></h2><p>Facebook has criticized the App Tracking Transparency feature and said it <span>could cause ad revenue to&nbsp;drop as much as 40%</span>.</p><p>Facebook has reportedly met with advertising partners to discuss the impact the change has on advertising when users have the ability to easily opt-out of cross-platform tracking.</p><p>The company also announced the following <a href="https://www.facebook.com/business/news/preparing-our-partners-for-ios-14-launch/" target="_blank" rel="noopener noreferrer nofollow">in a press release</a> on Sept 10th.</p><blockquote><p>‚ÄúWe, along with the rest of the business community, continue to await final policy details from Apple.‚Äù</p><p>Given Apple‚Äôs delayed implementation of the user permission requirement, we will continue collecting IDFA on iOS 14 in an attempt to reduce unnecessary disruption to our customers‚Äô businesses.‚Äù</p></blockquote><p>We checked in with FTC to see if they were looking into some of the claims made by FaceBook against Apple‚Äôs iOS 14.</p><figure id="attachment_1004628" aria-describedby="caption-attachment-1004628"><img loading="lazy" src="https://www.myhealthyapple.com/wp-content/uploads/FTC-investigating-Facebooks-claim-against-Apple.jpg" alt="FTC looking into Facebook's complaints against Apple" width="977" height="511" srcset="https://www.myhealthyapple.com/wp-content/uploads/FTC-investigating-Facebooks-claim-against-Apple.jpg 977w, https://www.myhealthyapple.com/wp-content/uploads/FTC-investigating-Facebooks-claim-against-Apple-300x157.jpg 300w, https://www.myhealthyapple.com/wp-content/uploads/FTC-investigating-Facebooks-claim-against-Apple-768x402.jpg 768w, https://www.myhealthyapple.com/wp-content/uploads/FTC-investigating-Facebooks-claim-against-Apple-696x364.jpg 696w, https://www.myhealthyapple.com/wp-content/uploads/FTC-investigating-Facebooks-claim-against-Apple-803x420.jpg 803w" sizes="(max-width: 977px) 100vw, 977px"><figcaption id="caption-attachment-1004628">Email send by FTC commissioner on Aug 28th (Source: myHealthyApple.com)</figcaption></figure><p>It appears, based on the reports under our FOIA filing, that Noah Philips, FTC commissioner reached out to Kate Adams from <strong>Apple on 28th August</strong> to understand some of the details around Facebook‚Äôs complaints.</p><p>A meeting was subsequently scheduled between Apple‚Äôs team and FTC attorneys around the first week of September.</p><figure id="attachment_1004629" aria-describedby="caption-attachment-1004629"><img loading="lazy" src="https://www.myhealthyapple.com/wp-content/uploads/FTC-meeting-with-Apple-about-IOS-14.jpg" alt="FTC Meeting with Apple on iOS 14" width="967" height="650" srcset="https://www.myhealthyapple.com/wp-content/uploads/FTC-meeting-with-Apple-about-IOS-14.jpg 967w, https://www.myhealthyapple.com/wp-content/uploads/FTC-meeting-with-Apple-about-IOS-14-300x202.jpg 300w, https://www.myhealthyapple.com/wp-content/uploads/FTC-meeting-with-Apple-about-IOS-14-768x516.jpg 768w, https://www.myhealthyapple.com/wp-content/uploads/FTC-meeting-with-Apple-about-IOS-14-696x468.jpg 696w, https://www.myhealthyapple.com/wp-content/uploads/FTC-meeting-with-Apple-about-IOS-14-625x420.jpg 625w" sizes="(max-width: 967px) 100vw, 967px"><figcaption id="caption-attachment-1004629">Source: MyHealthyApple.com</figcaption></figure><p>Given the timing of Apple‚Äôs announcement today, it is clear that the company has good cause to take this position following meetings with FTC.</p><p>According to the letter today, Apple continues to emphasize that advertising that protects user privacy is possible.</p><p>You can read today‚Äôs complete Apple‚Äôs letter posted by Chance Miller at <a href="https://9to5mac.com/2020/11/19/apple-privacy-letter-ios-14-facebook/" target="_blank" rel="noopener noreferrer nofollow">9to5Mac</a>.</p><p><em>As an Amazon Associate MyHealthyApple may earn commissions from qualifying purchases using our links</em></p></div></div>]]>
            </description>
            <link>https://www.myhealthyapple.com/etc-apple-facebook-ios14/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25171707</guid>
            <pubDate>Sat, 21 Nov 2020 18:41:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: WireGuard vs. OpenVPN, a 2.5x Difference]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25170710">thread link</a>) | @vpnintel
<br/>
November 21, 2020 | https://vpnintel.com/insights/one-month-of-speedtest-data-shows-wireguard-is-2.5x-faster-than-openvpn | <a href="https://web.archive.org/web/*/https://vpnintel.com/insights/one-month-of-speedtest-data-shows-wireguard-is-2.5x-faster-than-openvpn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      

      <p>
        WireGuard has gained traction over the past few years due, in part, to its high performance. We wondered how fast it really is, and realized that since we're already tracking VPN performance metrics for our <a href="https://vpnintel.com/unit-prices">VPN unit price index</a>, we could use the same data to answer the question, <strong>"how much faster is WireGuard than OpenVPN?"</strong>
      </p>

      <p>
        We focused on Windscribe, Mullvad, and NordVPN, three providers that support both WireGuard and OpenVPN, and built a <a href="https://vpnintel.com/wireguard-vs-openvpn">dashboard</a> to visualize their comparative download speeds. We've embedded the charts for the week ending November 20, 2020 below along with some commentary.
      </p>

      <p>
        Note that all data on this page represent speedtests between U.S.-based speedtest servers and VPNs. Our methodology section below has more on this.
      </p>
    </div>

    <p>
      <h2>Windscribe</h2>
    </p>
    <p>
      For the week ending November 20, 2020, Windscribe's average download speed over OpenVPN was <span>134 Mbps</span> and its average download speed over WireGuard was <span>363 Mbps</span>. This means that by simply toggling the WireGuard option, Windscribe users can get a free 2.7x speed boost!
    </p>
    <p><img src="https://vpnintel.com/assets/news-dfd25285653d0eb57e648315d449e97092408746e1412f7bc9b4ed13395df2ab.svg">
       As of November 24, 2020, our 7-day Windscribe averages are 341 Mbps for WireGuard and 145 Mbps for OpenVPN.
    </p>

    
    <p>
        Windscribe's Wireguard speeds are almost always in the 300-400 Mbps ranges. Dig deeper into performance and pricing info on our dedicated pages for <a href="https://vpnintel.com/windscribe-wireguard">Windscribe WireGuard</a> and <a href="https://vpnintel.com/windscribe">Windscribe OpenVPN</a>.
      </p>

    <p>
      <h2>Mullvad</h2>
    </p>
    <p>
      Mullvad was one of WireGuard's earliest commercial supporters. For the week ending November 20, 2020, Mullvad's average download speed over OpenVPN was <span>258 Mbps</span> and its average download speed over WireGuard was <span>672 Mbps</span> ‚Äì a free 2.6x performance boost for Mullvad's WireGuard users!
    </p>
    <p><img src="https://vpnintel.com/assets/news-dfd25285653d0eb57e648315d449e97092408746e1412f7bc9b4ed13395df2ab.svg">
       As of November 24, 2020, our 7-day Mullvad averages are 676 Mbps for WireGuard and 275 Mbps for OpenVPN.
    </p>

    
    <p>
        Mullvad's WireGuard speeds consistently land in the 600-700 Mbps range. Take a closer look at the pricing and performance data on our dedicated pages for <a href="https://vpnintel.com/mullvad">Mullvad WireGuard</a> and <a href="https://vpnintel.com/mullvad-openvpn">Mullvad OpenVPN</a>.
      </p>

    <p>
      <h2>NordVPN</h2>
    </p>
    <p>
        NordVPN launched support for WireGuard via its NordLynx product in Spring 2020. For the week ending November 20, 2020, Mullvad's average download speed over OpenVPN was <span>395 Mbps</span>. If the only number you remember from this page is NordVPN's average WireGuard download speed, you'll have the idea: a ridiculously fast <span>777 Mbps</span>, a 1.9x boost over its OpenVPN service.
      </p>
    <p><img src="https://vpnintel.com/assets/news-dfd25285653d0eb57e648315d449e97092408746e1412f7bc9b4ed13395df2ab.svg">
       As of November 24, 2020, our 7-day NordVPN averages are 781 Mbps for WireGuard and 419 Mbps for OpenVPN.
    </p>

    
    <p>
        You can see that NordVPN actually exceeds gigabit speeds on occasion. Its WireGuard speeds have a bit more variance than the other providers, but is uniformly well above 500 Mbps. For a deeper dive into NordLynx pricing and performance, check out our dedicated pages for <a href="https://vpnintel.com/nordvpn-wireguard">NordVPN WireGuard/NordLynx</a> and <a href="https://vpnintel.com/nordvpn">NordVPN OpenVPN</a>.
      </p>

    <p>
      <h2>Conclusions</h2>
    </p>
    <div>
      <p>
        For the week ending November 20, 2020, our global average download speed over OpenVPN was <span>251 Mbps</span> and <span>583 Mbps</span> over WireGuard ‚Äì WireGuard outperformed OpenVPN by an incredible 230%!
      </p>
      <p>
        All the more incredible is that customers of these services get this speed boost for free simply by selecting the WireGuard option.
      </p>
      <p>
        NordVPN's 1.9x ratio is a little lower than the other providers', but it still has a massive raw speed advantage. If NordVPN can get its WireGuard speeds up to the 2.5x+ ratios held by Windscribe and Mullvad, then it will be consistently serving gigabit speeds.
      </p>
      <p>
        That's it for now! We think this stuff is interesting, so we'll probably make this a monthly or quarterly report. If you'd like to know when we launch new tools and publish reports like this, please join our newsletter:
      </p>

      <div><p>
        Be the first to hear about new tools and reports
        </p><!-- Begin Mailchimp Signup Form -->
        
        <!--End mc_embed_signup-->
      </div>
    </div>
    <p><img src="https://vpnintel.com/assets/news-dfd25285653d0eb57e648315d449e97092408746e1412f7bc9b4ed13395df2ab.svg">
       As of November 24, 2020, WireGuard clocks in at 599 Mbps to OpenVPN's 289 Mbps, a 2.1x speed boost.
    </p>

    <div>
      <h2>Methodology</h2>
      <p>
        Our system is fully automated which lets us take thousands of readings a day. The data on this page represents speedtests conducted between servers based in the U.S. and VPN servers also based in the U.S. ‚Äì the speeds shown here are likely to be faster than what you would experience at home.
      </p>

      <p>
        All speedtests are done over UDP with the native OpenVPN and WireGuard Linux clients except for NordVPN's NordLynx/WireGuard service which uses the NordVPN Linux client since NordVPN does not provide WireGuard configuration files.
      </p>

      <p>
        At least as of November 20, 2020, you'll see some lumps shared across the three charts which may reflect resource usage patterns for our own hosting provider. We will report back on this.
      </p>
    </div>

    
  </div></div>]]>
            </description>
            <link>https://vpnintel.com/insights/one-month-of-speedtest-data-shows-wireguard-is-2.5x-faster-than-openvpn</link>
            <guid isPermaLink="false">hacker-news-small-sites-25170710</guid>
            <pubDate>Sat, 21 Nov 2020 16:44:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Production-Oriented Development]]>
            </title>
            <description>
<![CDATA[
Score 184 | Comments 137 (<a href="https://news.ycombinator.com/item?id=25170547">thread link</a>) | @kiyanwang
<br/>
November 21, 2020 | https://paulosman.me/2019/12/30/production-oriented-development.html | <a href="https://web.archive.org/web/*/https://paulosman.me/2019/12/30/production-oriented-development.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
          <p><span></span> read
          </p>
          <a name="topofpage"></a>
          <p>Throughout my career, I‚Äôve developed some <em>opinions</em>. Some have worn particularly deep ruts,
reinforced by years of experience. I tried to figure out what these
had in common, and it‚Äôs
the idea that <strong>code in production is the only code that matters</strong>. Staging doesn‚Äôt
matter, code on your laptop doesn‚Äôt matter, QA doesn‚Äôt matter,
only production matters. Everything else is debt.</p>

<p>This perspective probably comes from years sitting in between
operations and product development. I strongly
believe that teams should optimize for getting code to production as quickly as
possible as well as responding to incidents in production.</p>

<p>This idea, and a lot of the practices it implies, can be
counter-intuitive or controversial, so I want to dive into them a little
further. What follows is a set of practices and principles I believe are true,
considering my underlying belief that code working in production is the only
code that matters.</p>

<h2 id="engineers-should-operate-their-code">1. Engineers should operate their code.</h2>

<p><strong>Engineers are the subject matter experts for the code they write and should be
responsible for operating it in production</strong>. In this context, ‚Äúoperating‚Äù means
deploying, instrumenting, and monitoring code as well as helping to resolve
incidents related to or impacting that code. The responsibility of operating
code aligns incentives‚Ää-‚Ääit encourages engineers to write code that is
observable and easy to debug, and connects them to what customers really care
about. It encourages them to be curious about how their code is performing in
production. Importantly, engineers should be on-call for their code‚Ää-‚Ääbeing
on-call creates a positive feedback loop and makes it easier to know if their
efforts in writing production-ready code are paying off. I‚Äôve heard people
complain about the prospect of being on-call, so I‚Äôll just ask this: if you‚Äôre
not on-call for your code, who is?</p>

<p>If you‚Äôre not currently on-call for your code but want to be, and can help
influence this decision, there are some things you can do. Set up PagerDuty (or
similar) schedules for each group of engineers responsible for specific
services or parts of your code. A good schedule has 6‚Äì8 engineers. There are
plenty of variations, but a typical template is to have one-week rotations,
where you‚Äôll be on-call for secondary for a week and then primary for a week.
Configuring alerts is a separate topic, which probably deserves it‚Äôs own blog
post entirely, but focus on things that impact your customers (see:
Symptom-based alerting) and remember that you‚Äôre ultimately responsible for how
you respond to alerts, which means you can change them.</p>

<p>There are two talks I‚Äôd recommend watching that touch on the topic of
configuring alerts: Liz Fong-Jones talks about SLOs in <a href="https://www.youtube.com/watch?v=MT4jbUzEVL0">Cultivating Production Excellence</a> and Aditya Mukerjee does a great job talking about techniques for
managing alerts in <a href="https://vimeo.com/274820572">Warning: This Talk Contains Content Known to the State of California to Reduce Alert Fatigue</a>.</p>

<h2 id="buy-almost-always-beatsbuild">2. Buy Almost Always Beats&nbsp;Build</h2>

<p><strong>If you can avoid building something, you should.</strong> Code is the most expensive
way to solve a problem that isn‚Äôt addressing a core area of your business. For
most small to mid-sized companies, there are open source or better yet, hosted
solutions that solve a wide range of common problems. I mean things like git
repository hosting (Github, Gitlab, Bitbucket, etc), observability tooling
(Honeycomb, Lightstep, etc), managed databases (Amazon RDS, Confluent Kafka,
etc), alerting (PagerDuty, OpsGenie, etc) and a whole host of other commodity
technologies. This even applies to your infrastructure‚Ää-‚Ääif you can help
it, don‚Äôt roll your own Kubernetes clusters (side note: do you even need to use
Kubernetes?), don‚Äôt roll your own load balancers if you can use Amazon ELB or
ALBs.</p>

<p>Unfortunately, <a href="https://en.wikipedia.org/wiki/Not_invented_here">NIH</a> syndrome is very real and some companies get burned badly by
this. I‚Äôve seen teams light time and money on fire reinventing components when
better, more battle-tested alternatives exist in the market. Those same teams
almost always end up spending years contending with the resulting technical
debt. If you‚Äôre on such a team and have the will and ability to impact change,
start rolling back these decisions one by one. Migrate your databases to a
managed provider, migrate your feature flagging system to a SaaS tool (i.e.
LaunchDarkly). Keep going until the only software you maintain yourselves is
the software that delivers value to your customers. You‚Äôll be much, much better
off for it.</p>

<h2 id="make-deployseasy">3. Make Deploys&nbsp;Easy</h2>

<p>Deploying should be a frequent and unexciting activity. <strong>Engineers should be
able to deploy with minimal manual steps and it should be easy to see if the
deploy is successful</strong> (this requires instrumenting your code for observability,
which‚Ää-‚Äätada‚Ää-‚Ääis covered above), and it should be easy to roll back a deploy
if something doesn‚Äôt go well. Deploying frequently implies that
deploys are smaller, and smaller deploys are generally easier, faster and
safer.</p>

<p>Many teams implement periods where deploys are forbidden‚Ää-‚Ääthese can be
referred to as code freezes, or deploy policies like ‚ÄúDon‚Äôt deploy on Fridays‚Äù.
Having such blackout periods can lead to a pile-up of changes, which increases
the overall risk of something going very wrong.</p>

<p>If you‚Äôre on a team that fears deploys, dedicate a percentage of your
engineering time to improvements in your deployment pipeline until the fear is
gone. On a recent team I worked with, we were able to improve deploy times from
3 hours to 30 minutes, which drastically improved the teams‚Äô confidence in the
deploy process. A natural side effect of this was that engineers started
deploying much more frequently instead of waiting for changes to pile up enough
to warrant a ‚Äúrelease‚Äù (which was synonymous with a deploy).</p>

<p>The book
<a href="https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339">Accelerate</a>
has been getting a lot of attention. If you haven‚Äôt read it, I‚Äôd recommend it.
The team behind it also publishes the <a href="https://cloud.google.com/devops/">State of DevOps</a>
reports, which are full of well-researched information about what various
companies in the industry are doing. It‚Äôs not a coincidence that two of the
four key metrics that the book focuses on are directly related to this (Deploy
Frequency, Change Lead Time). Shipping is <a href="https://www.heavybit.com/library/podcasts/o11ycast/ep-12-speed-of-deployment-with-rich-archbold-of-intercom/">your company‚Äôs heartbeat</a>.</p>

<h2 id="trust-the-people-closest-to-theknives">4. Trust the People Closest to the&nbsp;Knives</h2>

<p><strong>The people who work with a system are the ones who understand it best.</strong> This
applies to any part of the socio-technical systems within which we all work. In
the case of software systems, the engineers who deploy every day and are
on-call for critical services understand the level of risk they operate in. A
sad trend is that managers tend to overestimate their teams‚Äô progress on
certain transitions‚Ää-‚Ääi.e. cloud-native, DevOps, etc. The higher up the
management chain, the larger this overestimation tends to be. Engineers who
deploy and get paged when things break know where the bodies are buried and
they know what needs the most work. They should, therefore, be the primary
stakeholders responsible for prioritizing technical work.</p>

<p>Another manifestation of this principle applies to platform or services teams.
If you‚Äôre responsible for building some shared component that‚Äôs used within
your organization (i.e. a messaging system, ci/cd infrastructure, shared
libraries or services) there‚Äôs an uncomfortable truth lurking for you: the
people who use your work know more about it than you do in many cases. They
understand implicitly how it serves customers and they know what contortions or
hoops they have to jump through to get it to work. Listen to them for
clues on how to improve the UX of your services and tools.</p>

<h2 id="qa-gates-make-qualityworse">5. QA Gates Make Quality&nbsp;Worse</h2>

<p>Many teams have a manual QA step that gets performed before deploys. The idea,
I guess, is to have someone run automated or manual tests to verify that a set
of changes are ready to be released. This sounds like a comforting
idea‚Ää-‚Äähaving a human being (or team of human beings) ‚Äúverify‚Äù a release before
it goes out‚Ää-‚Ää<strong>but it falls victim to several false assumptions and creates
some misalignments that do more harm than good.</strong></p>

<p>First of all, if there‚Äôs manual work that needs to be done before a deploy can
go out, that creates a bottleneck‚Ää-‚Ääif you‚Äôre making deploys easy, and
deploying small changes frequently, no QA team is going to be able to keep up
testing every deploy, and will inevitably block teams from deploying. That‚Äôs no
good. If you have manual tests, automate them and build them into your CI
pipeline (if they do deliver value).</p>

<p>Secondly, the teams doing QA often lack context and are under time pressure.
They may end up testing ‚Äúeffects‚Äù instead of ‚Äúintents‚Äù. For example, I‚Äôve seen
QA teams burn time testing that when something happens in a UI, something
related happens in a database. What happens when an engineer refactors that UI
component and changes the underlying data model? The functionality works, but
the test breaks. Because two teams are involved, this takes coordination and
time to fix. Similarly, I‚Äôve seen QA teams block deploys because of failing
tests when caching was introduced at the CDN layer‚Ää-‚Ääa TTL of 5 seconds on an
activity feed may not ever be noticed by a user but it might break QA tests
causing unnecessary conflicts between product and QA engineers.</p>

<p>Luckily, solving this one is easy. Instead of having a dedicated QA team work
on creating manual and automated test cases that run in a fictitious QA
environment, reassign that team to work on continuous testing in production.
Instead of being a gate for deploys, a QA team could continuously verify that
production is working as expected. QA teams are also well situated to lead
Chaos Engineering initiatives, where faults are intentionally injected in
production. QA engineers could also work on making the CI/CD pipeline more
reliable, so that deploys are no longer a nightmare.</p>

<h2 id="boring-technology-isgreat">6. Boring Technology is&nbsp;Great.</h2>

<p>With thanks to <a href="https://mcfunley.com/choose-boring-technology">Dan McKinley</a>,
always <strong>strive for boring tech when possible</strong>. Systems are inherently
unpredictable, and you want a wide ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulosman.me/2019/12/30/production-oriented-development.html">https://paulosman.me/2019/12/30/production-oriented-development.html</a></em></p>]]>
            </description>
            <link>https://paulosman.me/2019/12/30/production-oriented-development.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25170547</guid>
            <pubDate>Sat, 21 Nov 2020 16:25:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Winding down my Debian involvement (2019)]]>
            </title>
            <description>
<![CDATA[
Score 178 | Comments 199 (<a href="https://news.ycombinator.com/item?id=25170312">thread link</a>) | @ecliptik
<br/>
November 21, 2020 | https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/ | <a href="https://web.archive.org/web/*/https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
  
  <details>
    <summary>Table of contents</summary>
    <nav>
<ul>
<li>
<ul>
<li><a href="#what-does-this-mean">What does this mean?</a></li>
<li><a href="#why">Why?</a>
<ul>
<li><a href="#change-process-in-debian">Change process in Debian</a></li>
<li><a href="#fragmented-workflow-and-infrastructure">Fragmented workflow and infrastructure</a></li>
<li><a href="#old-infrastructure-package-uploads">Old infrastructure: package uploads</a></li>
<li><a href="#old-infrastructure-bug-tracker">Old infrastructure: bug tracker</a></li>
<li><a href="#old-infrastructure-mailing-list-archives">Old infrastructure: mailing list archives</a></li>
<li><a href="#debian-is-hard-to-machine-read">Debian is hard to machine-read</a></li>
<li><a href="#complicated-build-stack">Complicated build stack</a></li>
<li><a href="#developer-experience-pretty-painful">Developer experience pretty painful</a></li>
<li><a href="#i-have-more-ideas">I have more ideas</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </details>
  

<p>This post is hard to write, both in the emotional sense but also in the ‚ÄúI would
have written a shorter letter, but I didn‚Äôt have the time‚Äù sense. Hence, please
assume the best of intentions when reading it‚Äîit is not my intention to make
anyone feel bad about their contributions, but rather to provide some insight
into why my frustration level ultimately exceeded the threshold.</p>

<p>Debian has been in my life for well over 10 years at this point.</p>

<p>A few weeks ago, I have visited some old friends at the Z√ºrich Debian meetup
after a multi-year period of absence. On my bike ride home, it occurred to me
that the topics of our discussions had remarkable overlap with my last visit. We
had a discussion about the merits of systemd, which took a detour to respect in
open source communities, returned to processes in Debian and eventually
culminated in democracies and their theoretical/practical failings. Admittedly,
that last one might be a Swiss thing.</p>

<p>I say this not to knock on the Debian meetup, but because it prompted me to
reflect on what feelings Debian is invoking lately and whether it‚Äôs still a good
fit for me.</p>

<p>So I‚Äôm finally making a decision that I should have made a long time ago: I am
winding down my involvement in Debian to a minimum.</p>

<h2 id="what-does-this-mean">What does this mean?</h2>

<p>Over the coming weeks, I will:</p>

<ul>
<li>transition packages to be team-maintained where it makes sense</li>
<li>remove myself from the <code>Uploaders</code> field on packages with other maintainers</li>
<li>orphan packages where I am the sole maintainer</li>
</ul>

<p>I will try to keep up best-effort maintenance of the
<a href="https://manpages.debian.org/">manpages.debian.org</a> service and the
<a href="https://codesearch.debian.net/">codesearch.debian.net</a> service, but any help
would be much appreciated.</p>

<p>For all intents and purposes, please treat me as permanently on vacation. I will
try to be around for administrative issues (e.g. permission transfers) and
questions addressed directly to me, permitted they are easy enough to answer.</p>

<h2 id="why">Why?</h2>

<p>When I joined Debian, I was still studying, i.e. I had luxurious amounts of
spare time. Now, over 5 years of full time work later, my day job taught me a
lot, both about what works in large software engineering projects and how I
personally like my computer systems. I am very conscious of how I spend the
little spare time that I have these days.</p>

<p>The following sections each deal with what I consider a major pain point, in no
particular order. Some of them influence each other‚Äîfor example, if changes
worked better, we could have a chance at transitioning packages to be more
easily machine readable.</p>

<h3 id="change-process-in-debian">Change process in Debian</h3>

<p>The last few years, my current team at work conducted various smaller and larger
refactorings across the entire code base (touching thousands of projects), so we
have learnt a lot of valuable lessons about how to effectively do these
changes. It irks me that Debian works almost the opposite way in every regard. I
appreciate that every organization is different, but I think a lot of my points
do actually apply to Debian.</p>

<p>In Debian, packages are nudged in the right direction by a document called the
<a href="https://www.debian.org/doc/debian-policy/">Debian Policy</a>, or its programmatic
embodiment, lintian.</p>

<p>While it is great to have a lint tool (for quick, local/offline feedback), it is
even better to not require a lint tool at all. The team conducting the change
(e.g. the C++ team introduces a new hardening flag for all packages) should be
able to do their work transparent to me.</p>

<p>Instead, currently, all packages become lint-unclean, all maintainers need to
read up on what the new thing is, how it might break, whether/how it affects
them, manually run some tests, and finally decide to opt in. This causes a lot
of overhead and manually executed mechanical changes across packages.</p>

<p>Notably, the <strong>cost of each change</strong> is distributed onto the package maintainers in
the Debian model. At work, we have found that the opposite works better: if the
team behind the change is put in power to do the change for as many users as
possible, they can be significantly more efficient at it, which reduces the
total cost and time a lot. Of course, exceptions (e.g. a large project abusing a
language feature) should still be taken care of by the respective owners, but
the important bit is that the default should be the other way around.</p>

<p>Debian is <strong>lacking tooling for large changes</strong>: it is hard to programmatically
deal with packages and repositories (see the section below). The closest to
‚Äúsending out a change for review‚Äù is to open a bug report with an attached
patch. I thought the workflow for accepting a change from a bug report was too
complicated and started <a href="https://michael.stapelberg.ch/posts/2016-07-17-mergebot/">mergebot</a>, but only Guido
ever signaled interest in the project.</p>

<p>Culturally, reviews and reactions are slow. There are no deadlines. I literally
sometimes get emails notifying me that a patch I sent out a few years ago (!!)
is now merged. This turns projects from a small number of weeks into many years,
which is a huge demotivator for me.</p>

<p>Interestingly enough, you can see artifacts of the slow online activity manifest
itself in the offline culture as well: I don‚Äôt want to be discussing systemd‚Äôs
merits 10 years after I first heard about it.</p>

<p>Lastly, changes can easily be slowed down significantly by holdouts who refuse
to collaborate. My canonical example for this is rsync, whose maintainer refused
my patches to make the package use debhelper purely out of personal preference.</p>

<p>Granting so much personal freedom to individual maintainers prevents us as a
project from raising the abstraction level for building Debian packages, which
in turn makes tooling harder.</p>

<p>How would things look like in a better world?</p>

<ol>
<li>As a project, we should strive towards more unification. Uniformity still
does not rule out experimentation, it just changes the trade-off from easier
experimentation and harder automation to harder experimentation and easier
automation.</li>
<li>Our culture needs to shift from ‚Äúthis package is my domain, how dare you
touch it‚Äù to a shared sense of ownership, where anyone in the project can
easily contribute (reviewed) changes without necessarily even involving
individual maintainers.</li>
</ol>

<p>To learn more about how successful large changes can look like, I recommend <a href="https://www.youtube.com/watch?v=TrC6ROeV4GI">my
colleague Hyrum Wright‚Äôs talk ‚ÄúLarge-Scale Changes at Google: Lessons Learned
From 5 Yrs of Mass Migrations‚Äù</a>.</p>

<h3 id="fragmented-workflow-and-infrastructure">Fragmented workflow and infrastructure</h3>

<p>Debian generally seems to prefer decentralized approaches over centralized
ones. For example, individual packages are maintained in separate repositories
(as opposed to in one repository), each repository can use any SCM (git and svn
are common ones) or no SCM at all, and each repository can be hosted on a
different site. Of course, what you do in such a repository also varies subtly
from team to team, and even within teams.</p>

<p>In practice, non-standard hosting options are used rarely enough to not justify
their cost, but frequently enough to be a huge pain when trying to automate
changes to packages. Instead of using GitLab‚Äôs API to create a merge request,
you have to design an entirely different, more complex system, which deals with
intermittently (or permanently!) unreachable repositories and abstracts away
differences in patch delivery (bug reports, merge requests, pull requests,
email, ‚Ä¶).</p>

<p>Wildly diverging workflows is not just a temporary problem either. I
participated in long discussions about different git workflows during DebConf
13, and gather that there were similar discussions in the meantime.</p>

<p>Personally, I cannot keep enough details of the different workflows in my
head. Every time I touch a package that works differently than mine, it
frustrates me immensely to re-learn aspects of my day-to-day.</p>

<p>After noticing workflow fragmentation in the Go packaging team (which I
started), I tried fixing this with the <a href="https://go-team.pages.debian.net/workflow-changes.html">workflow changes
proposal</a>, but did not
succeed in implementing it. The lack of effective automation and slow pace of
changes in the surrounding tooling despite my willingness to contribute time and
energy killed any motivation I had.</p>

<h3 id="old-infrastructure-package-uploads">Old infrastructure: package uploads</h3>

<p>When you want to make a package available in Debian, you upload GPG-signed files
via anonymous FTP. There are several batch jobs (the queue daemon, <code>unchecked</code>,
<code>dinstall</code>, possibly others) which run on fixed schedules (e.g. <code>dinstall</code> runs
at 01:52 UTC, 07:52 UTC, 13:52 UTC and 19:52 UTC).</p>

<p>Depending on timing, I estimated that you might wait for over 7 hours (!!)
before your package is actually installable.</p>

<p>What‚Äôs worse for me is that feedback to your upload is asynchronous. I like to
do one thing, be done with it, move to the next thing. The current setup
requires a many-minute wait and costly task switch for no good technical
reason. You might think a few minutes aren‚Äôt a big deal, but when all the time I
can spend on Debian per day is measured in minutes, this makes a huge difference
in perceived productivity and fun.</p>

<p>The last communication I can find about speeding up this process is <a href="https://lists.debian.org/debian-project/2008/12/msg00014.html">ganneff‚Äôs
post</a> from 2008.</p>

<p>How would things look like in a better world?</p>

<ol>
<li>Anonymous FTP would be replaced by a web service which ingests my package and
returns an authoritative accept or reject decision in its response.</li>
<li>For accepted packages, there would be a status page displaying the build
status and when the package will be available via the mirror network.</li>
<li>Packages should be available within a few minutes after the build completed.</li>
</ol>

<h3 id="old-infrastructure-bug-tracker">Old infrastructure: bug tracker</h3>

<p>I dread interacting with the Debian bug
tracker. <a href="https://en.wikipedia.org/wiki/Debbugs">debbugs</a> is a piece of software
(from 1994) which is only used by Debian and the GNU project these days.</p>

<p>Debbugs processes emails, which is to say it is asynchronous and cumbersome to
deal with. Despite running on the fastest machines we ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/">https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/</a></em></p>]]>
            </description>
            <link>https://michael.stapelberg.ch/posts/2019-03-10-debian-winding-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25170312</guid>
            <pubDate>Sat, 21 Nov 2020 15:53:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I got rich on the other hand (2019)]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25170030">thread link</a>) | @damir
<br/>
November 21, 2020 | https://sive.rs/richand | <a href="https://web.archive.org/web/*/https://sive.rs/richand">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2019-10-30</small>
<audio src="https://m.sive.rs/sive.rs.richand.mp3" preload="none" controls="controls"></audio></header>

<p>
I don‚Äôt usually talk about money, but a friend asked me what it was like to get rich, and he wanted to know specifics, so I told him my story.
</p><p>
I had <a href="https://sive.rs/xn">a day job</a> in midtown Manhattan paying $20K per year ‚Äî about minimum wage.
On weekends I would earn $150 per day performing circus shows for kids, though I‚Äôd spend about $50 in bus fare to get to the gigs.
I was sharing a three-bedroom apartment with two other roommates in Queens, so our rent was $333 per month each.
I made peanut butter sandwiches for three meals a day, and at night maybe some eggs.
I never ate out, and never took a taxi.
<strong>
My cost of living was about $1000/month, and I was earning $1800/month.
I did this for two years, and saved up $12,000.
</strong>
I was 22 years old.
</p><p>
Once I had $12,000 I could quit my job and become a full-time musician.
I knew I could get a few gigs per month to pay my cost of living.
So I was free.
<a href="https://sive.rs/nq">I quit my job</a> a month later, and never had a job again.
</p><p>
When I finished telling my friend this story, he asked for more.
I said no, that was it.
He said, ‚ÄúNo, what about when you sold your company?‚Äù
</p><p>
I said no, that didn‚Äôt make a big difference in my life.
That was just more money in the bank.
The difference happened when I was 22.
</p><p>
It‚Äôs not how much you have.
<strong>
It‚Äôs the difference between what you have and what you spend.
</strong>
If you have more than you spend, you‚Äôre rich.
If you spend more than you have, you‚Äôre not.
If you live cheaply, it‚Äôs easy to be free.
</p><p>
Magicians wave one hand around to get your attention, while the other hand does the trick.
To be smart, watch the other hand.
</p>
<img src="https://sive.rs/images/magichands.jpg">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/richand</link>
            <guid isPermaLink="false">hacker-news-small-sites-25170030</guid>
            <pubDate>Sat, 21 Nov 2020 14:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interpretation of confidence intervals and Bayesian credible intervals]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25169595">thread link</a>) | @jwb133
<br/>
November 21, 2020 | https://thestatsgeek.com/2020/11/21/interpretation-of-frequentist-confidence-intervals-and-bayesian-credible-intervals/ | <a href="https://web.archive.org/web/*/https://thestatsgeek.com/2020/11/21/interpretation-of-frequentist-confidence-intervals-and-bayesian-credible-intervals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>This post was prompted by a tweet by Frank Harrell yesterday asking:</p>



<figure></figure>



<p>In this post I'll say a little bit about trying to answer Frank's question, and then a little bit about an alternative question which I posed in response, namely, how does the interpretation change if the interval is a Bayesian credible interval, rather than a frequentist confidence interval.</p>



<h2>Frequentist confidence intervals</h2>



<p>A frequentist 95% confidence interval is constructed such that if the model assumptions are correct, if you were to (hypothetically) repeat the experiment or sampling many many times, 95% of the intervals constructed would contain the true value of the parameter. I made a short video last year which performs a simulation in R to demonstrate this definition/idea:</p>



<figure><p><span><iframe width="1125" height="633" src="https://www.youtube.com/embed/IGXg6L98lJM?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span>
</p></figure>



<p>Frank asked how one interprets a particular realised confidence interval (0.72,0.91). The difficulty (as he is well aware!) is that all a frequentist can say is that this particular realised interval either does or does not contain the true parameter value, and they cannot tell you if it does or doesn't. All they can say is that if modelling assumptions are correct, in hypothetical repetitions 95% of the intervals constructed using this procedure contain the true value.</p>



<h2>Bayesian credible intervals</h2>



<p>Let‚Äôs now suppose that we‚Äôve done a Bayesian analysis. We‚Äôve specified a prior distribution for the parameter, based on prior evidence, our subjective beliefs about the value of the parameter, or perhaps we used a default ‚Äònon-informative‚Äô prior built into our software package. We use the same model as before, and Bayes theorem gives us the posterior distribution. A Bayesian posterior credible interval is constructed, and suppose it gives us some values. For the sake of simplicity, I‚Äôll assume the interval is again 0.72 to 0.91, but this is not done to suggest a Bayesian analysis credible interval will generally be identical to the frequentist's confidence interval.</p>



<p>How should we interpret this credible interval? A Bayesian would I think say say something like it is an interval for which there is a 95% chance or probability the true parameter lies. At this point we must ask, what do they mean by 95% probability?</p>



<p>We could interpret it as a classical long run frequentist probability, but this means interpreting it like a confidence interval. In fact Bayesian procedures often have good frequentist properties. For example see <a rel="noreferrer noopener" href="https://cdn1.sph.harvard.edu/wp-content/uploads/sites/343/2013/03/large-sample.pdf" target="_blank">Wang and Robins 1998</a> for an analysis of the frequentist properties of multiple imputation for missing data, or <a rel="noreferrer noopener" href="https://doi.org/10.1177%2F0962280216667764" target="_blank">Bartlett and Keogh 2018</a> for a simulation investigation of the frequentist properties of Bayesian approaches for handling covariate measurement error. In fact, under certain conditions, Bayesian procedures achieve the same frequentist properties of maximum likelihood methods when the sample size gets large - see Chapter 4 of Gelman <em>et al</em>'s excellent<a href="http://www.stat.columbia.edu/~gelman/book/" target="_blank" rel="noreferrer noopener"> Bayesian Data Analysis book</a>.</p>



<p>But conceptually we do not choose to do a Bayesian analysis simply as a means to performing frequentist inference. We choose it because it (hopefully) answers more directly what we are interested in (see Frank Harrell's '<a rel="noreferrer noopener" href="https://www.fharrell.com/post/journey/" target="_blank">My Journey From Frequentist to Bayesian Statistics</a>' post). Namely, it enables us to make probability statements about the unknown parameter given our model, the prior, and the data we have observed. So what is the interpretation of the 95% chance or probability for a credible interval? </p>



<p>I don't know the no doubt large literature on this topic well at all, but the Bayesian's interpretation or definition of probability isn't that clear to me. The Wikipedia entry on <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Bayesian_probability" target="_blank">Bayesian probability</a> says:</p>



<blockquote><p>Broadly speaking, there are two interpretations of Bayesian probability. For objectivists, who interpret probability as an extension of logic, probability quantifies the reasonable expectation that everyone (even a "robot") who shares the same knowledge should share in accordance with the rules of Bayesian statistics, which can be justified by Cox's theorem.[2][8] For subjectivists, probability corresponds to a personal belief.[3] Rationality and coherence allow for substantial variation within the constraints they pose; the constraints are justified by the Dutch book argument or by decision theory and de Finetti's theorem.[3] The objective and subjective variants of Bayesian probability differ mainly in their interpretation and construction of the prior probability.</p><cite>Wikipedia entry on Bayesian probability</cite></blockquote>



<p>Section 1.5 'Probability as a measure of uncertainty' of <a href="http://www.stat.columbia.edu/~gelman/book/" target="_blank" rel="noreferrer noopener">Bayesian Data Analysis</a> talks about the way Bayesian analysis uses probability as a measure of uncertainty, but to my mind it doesn't really define the concept. This is not a criticism. As Gelman et al say earlier in their book:</p>



<blockquote><p>Rather than argue the foundations of statistics‚Äîsee the bibliographic note at the end of this chapter for references to foundational debates‚Äîwe prefer to concentrate on the pragmatic advantages of the Bayesian framework, whose flexibility and generality allow it to cope with complex problems.</p></blockquote>



<p>If part of the appeal of Bayesian inference is that it answers the question we really want (i.e. conditional on what we've seen, what do we know / believe about the parameter(s)), it seems to me that the interpretation or definition of prior/posterior probabilities should be relatively straightforward and clear to us. But for me at least, it isn't. I am quite confident (whatever I mean by that!) that this reflects my ignorance on the topic. Part of my motivation for writing this post is the hope that people will help me understand better how to unambiguously define what is meant by a Bayesian prior/posterior probability. Please write a comment if you can help in this regard.</p>



<p>The above does not mean I don't like Bayesian methods. Indeed much of the last 10 years I have been working with and using methods like multiple imputation for missing data whose development take place in the Bayesian paradigm. For me this is fine because I know that methods like multiple imputation have good frequentist properties, and while there are definitely interpretational issues with things confidence intervals, I at least think I understand what they claim to do/be.</p>



<h2>22nd November 2022 postscript</h2>



<p>This evening there was further discussion of this topic on Twitter. As part of this Frank Harrell offered an interpretation for the Bayesian credible interval as follows:</p>



<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Under data model F and prior P, [0.72, 0.91] is the shortest interval such that the probability the unknown OR generating our data is in that interval is 0.95 (highest posterior density interval).</p>‚Äî Frank Harrell (@f2harrell) <a href="https://twitter.com/f2harrell/status/1330633833713111040?ref_src=twsrc%5Etfw">November 22, 2020</a></blockquote>
</div></figure>



<p>I followed up with him as to the nature of the probability being referred to here, since it is clear that the probability notion being invoked is broader or distinct than the relative frequency notion of probability. Frank helpfully pointed me in the direction of the entry for 'probability' in his course glossary of terms, which can be <a rel="noreferrer noopener" href="https://hbiostat.org/doc/glossary.pdf" target="_blank">accessed here</a>. Part of this entry says:</p>



<blockquote><p>The&nbsp;meaning&nbsp;attached to the metric known as a probability is up to the user; it can represent long-run relative frequency of repeatable observations, a degree of belief, or a measure of veracity or plausibility.</p><cite>https://hbiostat.org/doc/glossary.pdf</cite></blockquote>



<p>and</p>



<blockquote><p>There are other schools of probability that do not require the notion of replication at all. For example, the school of&nbsp;subjective&nbsp;probability (associated with the&nbsp;Bayesian&nbsp;school) ‚Äúconsiders probability as a measure of the degree of belief of a given subject in the occurrence of an event or, more generally, in the veracity of a given assertion‚Äù (see P. 55 of5). de Finetti defined subjective probability in terms of wagers and odds in betting. A risk-neutral individual would be willing to wager $P&nbsp;that an event will occur when the payoff is $1 and her subjective probability is&nbsp;P&nbsp;for the event.</p><cite>https://hbiostat.org/doc/glossary.pdf</cite></blockquote>



<p>As I wrote in the original post, I do not know the extensive literature on this topic well at all. But what Frank has summarised here is really useful in aiding my understanding of what the interpretation should be of the 95% probability statement attached to a 95% credible interval. It seems to me the notion of probability being invoked when interpreting a 95% credible interval has to be the subjective probability / degree of belief one described in the previous quote. Whether this definition/interpretation meets the criterion of being 'exact', as required by Frank in his tweet at the top of this post when asking for the exact interpretation of a particular realised frequentist confidence interval, I leave readers to decide.</p>
		</div></div>]]>
            </description>
            <link>https://thestatsgeek.com/2020/11/21/interpretation-of-frequentist-confidence-intervals-and-bayesian-credible-intervals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25169595</guid>
            <pubDate>Sat, 21 Nov 2020 13:21:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mastering TorchScript: Tracing vs. Scripting, Device Pinning, Graph Modification]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25169493">thread link</a>) | @briggers
<br/>
November 21, 2020 | https://paulbridger.com/posts/mastering-torchscript | <a href="https://web.archive.org/web/*/https://paulbridger.com/posts/mastering-torchscript">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  <h5>October 29, 2020</h5>



  
  
  

  


  <h2 id="intro">
  Intro
  <a href="#intro">#</a>
</h2>
<p>TorchScript is one of the most important parts of the Pytorch ecosystem, allowing portable, efficient and nearly seamless deployment. With just a few lines of <code>torch.jit</code> code and some simple model changes you can export an asset that runs anywhere <code>libtorch</code> does. It‚Äôs an important toolset to master if you want to run your models outside the lab at high efficiency.</p>
<p>Good <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html">introductory material</a> is already available for starting to work with <a href="https://pytorch.org/docs/stable/jit.html">TorchScript</a> including <a href="https://pytorch.org/tutorials/advanced/cpp_export.html">execution in the C++ <code>libtorch</code> runtime</a>, and <a href="https://pytorch.org/docs/stable/jit_language_reference.html">reference material</a> is also provided. This article is a collection of topics going beyond the basics of your first export.</p>
<h2 id="tracing-vs-scripting">
  Tracing vs Scripting
  <a href="#tracing-vs-scripting">#</a>
</h2>
<p>Pytorch provides two methods for generating TorchScript from your model code ‚Äî tracing and scripting ‚Äî but which should you use? Let‚Äôs recap how they work:</p>
<ul>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html"><strong>Tracing.</strong></a> When using <code>torch.jit.trace</code> you‚Äôll provide your model and sample input as arguments. The input will be fed through the model as in regular inference and the executed operations will be traced and recorded into TorchScript. Logical structure will be frozen into the path taken during this sample execution.</p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/generated/torch.jit.script.html"><strong>Scripting.</strong></a> When using <code>torch.jit.script</code> you‚Äôll simply provide your model as an argument. TorchScript will be generated from the static inspection of the <code>nn.Module</code> contents (recursively).</p>
</li>
</ul>
<p>It‚Äôs not obvious from the tutorial documentation, but choosing which method to use is a fairly simple and fluid choice:</p>
<h3 id="use-scripting-by-default">
  Use Scripting by Default
  <a href="#use-scripting-by-default">#</a>
</h3>
<p>Because <code>torch.jit.script</code> captures both the operations and full conditional logic of your model, it‚Äôs a great place to start. If your model doesn‚Äôt need any <a href="https://pytorch.org/docs/stable/jit_unsupported.html">unsupported Pytorch functionality</a> and has logic restricted to the <a href="https://pytorch.org/docs/stable/jit_builtin_functions.html#python-built-in-functions">supported subset of Python functions</a> and <a href="https://pytorch.org/docs/stable/jit_python_reference.html">syntax</a>, then <code>torch.jit.script</code> should be all you need.</p>
<p>One major advantage of scripting over tracing is that an export is likely to either fail for a well-defined reason ‚Äî implying a clear code modification ‚Äî or succeed without warnings.</p>
<blockquote>
  <p><strong>Unlike Python, TorchScript is Statically Typed</strong></p>
<p>You will need to be consistent about container element datatypes, and be wary of implicit function signatures. A useful practice is to use type hints in method signatures.</p>

</blockquote>

<p>Despite TorchScript‚Äôs ability to capture conditional logic it does not allow you to run arbitrary Python within <code>libtorch</code> ‚Äî a popular misconception.</p>
<h3 id="use-tracing-if-you-must">
  Use Tracing if You Must
  <a href="#use-tracing-if-you-must">#</a>
</h3>
<p>There are a few special cases in which <code>torch.jit.trace</code> may be useful:</p>
<ul>
<li>If you are unable to modify the model code ‚Äî because you do not have access or ownership ‚Äî you may find scripting the model simply will not work because it uses unsupported Pytorch/Python functionality.</li>
<li>In pursuit of performance or to bake in architectural decisions the logic freezing behavior of tracing might be preferable ‚Äî similar to inlining C/C++ code.</li>
</ul>
<blockquote>
  <p><strong>Pay Close Attention to Tracer Warnings</strong></p>
<p>Due to how tracing can simplify model behavior, each warning should be fully understood and only then ignored (or fixed). Also, be sure to trace in eval mode if you are exporting a model for production inference!</p>

</blockquote>

<h3 id="use-both-together">
  Use Both Together
  <a href="#use-both-together">#</a>
</h3>
<p>Scripted and traced code can be freely mixed, and this is often a great choice. See the existing <a href="https://pytorch.org/">pytorch.org</a> documentation for <a href="https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting">details</a> and <a href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#mixing-scripting-and-tracing">examples</a>.</p>
<h2 id="device-pinning">
  Device Pinning
  <a href="#device-pinning">#</a>
</h2>
<p>If you find yourself using <code>torch.jit.trace</code> on some code, you‚Äôll have to actively deal with some of the gotchas or face performance and portability consequences. Besides addressing any warnings Pytorch emits, you‚Äôll also need to keep an eye out for device pinning. Just like <code>torch.jit.trace</code> records and freezes conditional logic, it will also trace and make constant the values resulting from this logic ‚Äî this can include device constants.</p>
<p>Using this sample code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>))</span></code></pre></div>
<p>If we trace while executing on CPU or GPU we get this TorchScript (scroll to the right on mobile):</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<p>You can see that <code>torch.device("cpu")</code> has been inserted as a constant into the generated TorchScript. If we try to get clever with this code:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>X</span><span>.</span><span>size</span><span>(</span><span>0</span><span>),</span> <span>device</span><span>=</span><span>X</span><span>.</span><span>device</span><span>)</span></code></pre></div>
<p>Tracing will now result in TorchScript that is pinned to the tracing device. When traced on GPU, we see this:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span>
    <span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>ops</span><span>.</span><span>prim</span><span>.</span><span>NumToTensor</span><span>(</span><span>torch</span><span>.</span><span>size</span><span>(</span><span>X</span><span>,</span> <span>0</span><span>))</span>
  <span>_1</span> <span>=</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>annotate</span><span>(</span><span>number</span><span>,</span> <span>_0</span><span>),</span> <span>dtype</span><span>=</span><span>None</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cuda:0"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>)</span>
  <span>return</span> <span>_1</span></code></pre></div>
<!-- raw HTML omitted -->
<blockquote>
  <p><strong>Tensors Created During Tracing Will Have Their Device Pinned</strong></p>
<p>This can be a significant performance and portability problem.</p>

</blockquote>

<h3 id="performance-and-portability">
  Performance and Portability
  <a href="#performance-and-portability">#</a>
</h3>
<p>If we later deserialize and run this TorchScript in <code>libtorch</code> the <code>arange</code> tensor will always be created on the device that is pinned ‚Äî <code>torch.device("cpu")</code> or <code>torch.device("cuda:0")</code> in the examples above. If the rest of the model is running on a different device this can result in costly memory transfers and synchronization.</p>
<p>This device pinning issue extends to multi-GPU scenarios as well. If you have traced and exported a model on <code>cuda:0</code> and then run it on <code>cuda:1</code> you‚Äôll see transfers and synchronization between the devices. Not good. Perhaps even worse, if such a model is run in an environment without any CUDA-capable device it will fail since <code>cuda:0</code> doesn‚Äôt exist.</p>
<blockquote>
  <p><strong>Replace Tensors Created During Execution With Parameters</strong></p>
<p>Tensors created in the execution path while tracing will have their device pinned. Depending on model logic, these can often be turned into Parameters created during construction.</p>

</blockquote>

<p>An example of the problem looks like this in Nsight Systems:</p>








<a href="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices.png">
    <figure>
        <img src="https://paulbridger.com/posts/mastering-torchscript/images/pinned_devices_hub20c76c57b334a1bd11edec46dac0166_414004_896x580_fill_box_top_2.png" width="896" height="580">
        <figcaption><small></small></figcaption>
    </figure>
</a>

<h3 id="tensor-subscript-mask-and-indexing-will-pin-devices">
  Tensor Subscript Mask and Indexing Will Pin Devices
  <a href="#tensor-subscript-mask-and-indexing-will-pin-devices">#</a>
</h3>
<p>Unlike their more explicit counterparts (<code>masked_select</code> and <code>index_select</code>), using tensor subscripting will pin the mask or indexes to the tracing device:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>[</span><span>X</span> <span>&gt;</span> <span>1</span><span>]</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>to</span><span>(</span><span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>),</span> <span>dtype</span><span>=</span><span>11</span><span>,</span> <span>layout</span><span>=</span><span>0</span><span>,</span> <span>device</span><span>=</span><span>torch</span><span>.</span><span>device</span><span>(</span><span>"cpu"</span><span>),</span> <span>pin_memory</span><span>=</span><span>False</span><span>,</span> <span>non_blocking</span><span>=</span><span>False</span><span>,</span> <span>copy</span><span>=</span><span>False</span><span>,</span> <span>memory_format</span><span>=</span><span>None</span><span>)</span>
  <span>_1</span> <span>=</span> <span>annotate</span><span>(</span><span>List</span><span>[</span><span>Optional</span><span>[</span><span>Tensor</span><span>]],</span> <span>[</span><span>_0</span><span>])</span>
  <span>return</span> <span>torch</span><span>.</span><span>index</span><span>(</span><span>X</span><span>,</span> <span>_1</span><span>)</span></code></pre></div>
<!-- raw HTML omitted -->
<p>Whereas:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>):</span>
    <span>return</span> <span>X</span><span>.</span><span>masked_select</span><span>(</span><span>X</span> <span>&gt;</span> <span>1</span><span>)</span></code></pre></div>
<p>Generates this TorchScript:</p>
<div><pre><code data-lang="python"><span>def</span> <span>forward</span><span>(</span><span>X</span><span>:</span> <span>Tensor</span><span>)</span> <span>-&gt;</span> <span>Tensor</span><span>:</span>
  <span>_0</span> <span>=</span> <span>torch</span><span>.</span><span>masked_select</span><span>(</span><span>X</span><span>,</span> <span>torch</span><span>.</span><span>gt</span><span>(</span><span>X</span><span>,</span> <span>1</span><span>))</span>
  <span>return</span> <span>_0</span></code></pre></div>
<!-- raw HTML omitted -->
<p>The same pattern holds for <code>tensor[indexes]</code> and <code>tensor.index_select(0, indexes)</code>. This device pinning carries the same performance and portability risks as noted above.</p>
<blockquote>
  <p><strong>Replace Tensor Subscripting With <code>masked_select</code> and <code>indexed_select</code></strong></p>
<p>Subscript-based masking and indexing will always pin the tracing device into generated TorchScript. :(</p>

</blockquote>

<h2 id="direct-graph-modification">
  Direct Graph Modification
  <a href="#direct-graph-modification">#</a>
</h2>
<p>Once we‚Äôve used <code>torch.jit.script</code> or <code>torch.jit.trace</code> to generate a ScriptModule or ScriptFunction we can use <code>.graph</code>, <code>.inlined_graph</code> or <code>.code</code> to understand exactly what TorchScript has been generated. Though it has an entirely undocumented interface it is possible (and fun) to access and modify the generated TorchScript AST directly via the <code>.graph</code> method.</p>
<p>The most useful parts of the API are defined in <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/python/python_ir.cpp">torch/csrc/jit/python/python_ir.cpp</a>. As you can see, all the basic functionality is present for finding and changing the graph nodes you want. If you change nodes or arguments and then persist the module your subsequent TorchScript load and inference will reflect your changes, though modules cannot be changed recursively in this way (<code>torch.jit.freeze</code> can be useful here).</p>
<p>An example of the kind of graph modification that is possible:</p>
<div><pre><code data-lang="python"><span>def</span> <span>undevice</span><span>(</span><span>tsc</span><span>):</span>
    <span># use ::to variant which does not hardcode device</span>
    <span>for</span> <span>to_node</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'aten::to'</span><span>):</span>
        <span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>layout</span><span>,</span> <span>device</span><span>,</span> <span>pin_mem</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span> <span>=</span> <span>list</span><span>(</span><span>to_node</span><span>.</span><span>inputs</span><span>())</span>
        <span>to_node</span><span>.</span><span>removeAllInputs</span><span>()</span>
        <span>for</span> <span>a</span> <span>in</span> <span>[</span><span>i</span><span>,</span> <span>dtype</span><span>,</span> <span>non_blocking</span><span>,</span> <span>copy</span><span>,</span> <span>mem_format</span><span>]:</span>
            <span>to_node</span><span>.</span><span>addInput</span><span>(</span><span>a</span><span>)</span>

    <span>for</span> <span>constant</span> <span>in</span> <span>tsc</span><span>.</span><span>graph</span><span>.</span><span>findAllNodes</span><span>(</span><span>'prim::Constant'</span><span>):</span>
        <span>if</span> <span>not</span> <span>constant</span><span>.</span><span>hasUses</span><span>():</span>
            <span>constant</span><span>.</span><span>destroy</span><span>()</span></code></pre></div>
<p>The above code will modify a traced graph, changing <code>aten::to</code> to use an overload which doesn‚Äôt change memory location.</p>
<p>But what is this really useful for? As an undocumented API you‚Äôd be unwise to use this capability in a production pipeline unless you like maintenance coding. I would only recommend it for research, as in the above example which I used to understand and profile the transfer/synchronization behavior of tensor subscripting.</p>
<blockquote>
  <p><strong>Don‚Äôt Bother With Direct Graph Modification</strong></p>
<p>For legitimate production use-cases you can almost always find a way to modify your model code to generate the TorchScript you want.</p>

</blockquote>

<h2 id="rewrite-for-onnxtensorrt-export">
  Rewrite for ONNX/TensorRT Export
  <a href="#rewrite-for-onnxtensorrt-export">#</a>
</h2>
<p>You can get some <a href="https://paulbridger.com/posts/video-analytics-deepstream-pipeline/#stage-3-hacked-deepstream-mdash-80-tensorrt-20-torchscript">awesome results with TensorRT</a> but exporting a model from Pytorch to TensorRT is far from a sure thing. The export path to ONNX and then to TensorRT can fail due to missing or incompatible operations at either step and this can be frustrating.</p>
<p>After the obligatory Google search, I‚Äôve found a reasonable hail-mary approach is to rewrite your tensor processing code to avoid unsupported operators. I can‚Äôt give general advice for this but let me show you an example of how this can be possible: <code>repeat_interleave</code>.</p>
<div><pre><code data-lang="python"><span>class</span> <span>RI</span><span>(</span><span>torch</span><span>.</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>X</span><span>,</span> <span>repeat</span><span>):</span>
        <span>return</span> <span>X</span><span>.</span><span>repeat_interleave</span><span>(</span><span>repeat</span><span>,</span> <span>dim</span><span>=</span><span>0</span><span>)</span>

<span>inputs</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>),</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>3</span><span>))</span>
<span>torch</span><span>.</span><span>onnx</span><span>.</span><span>export</span><span>(</span><span>RI</span><span>(),</span> <span>inputs</span><span>,</span> <span>'please_work.onnx'</span><span>,</span> <span>opset_version</span><span>=</span><span>11</span><span>)</span></code></pre></div>
<p>Doesn‚Äôt work:</p>
<div><pre><code data-lang="bash">RuntimeError: Exporting the operator repeat_interleave to ONNX opset version <span>11</span> is not supported. Please open a bug to request ONNX <span>export</span> support <span>for</span> the missing operator.</code></pre></div>
<p>However, the behavior of <code>repeat_interleave</code> with a fixed <code>dim</code> argument can be replicated in a form that will export to ONNX ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulbridger.com/posts/mastering-torchscript">https://paulbridger.com/posts/mastering-torchscript</a></em></p>]]>
            </description>
            <link>https://paulbridger.com/posts/mastering-torchscript</link>
            <guid isPermaLink="false">hacker-news-small-sites-25169493</guid>
            <pubDate>Sat, 21 Nov 2020 13:05:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Be Great? Just Be Good, Repeatably]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25169061">thread link</a>) | @marconey
<br/>
November 21, 2020 | https://blog.stephsmith.io/how-to-be-great/ | <a href="https://web.archive.org/web/*/https://blog.stephsmith.io/how-to-be-great/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.stephsmith.io/content/images/size/w300/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 300w,
                            https://blog.stephsmith.io/content/images/size/w600/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 600w,
                            https://blog.stephsmith.io/content/images/size/w1000/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 1000w,
                            https://blog.stephsmith.io/content/images/size/w2000/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.stephsmith.io/content/images/size/w2000/2019/06/Screen-Shot-2019-06-01-at-6.19.20-PM-3.png" alt="How to Be Great? Just Be Good, Repeatably">
</figure>
<section>
<div>
<p><em>Edit: Thank you to the 80k people who have read this piece. It looks like many people are struggling with the concept of "greatness". Let's continue to support one another on the journey there. </em></p><p>Over the years, we‚Äôve all encountered our fair share of successes and failures. As I‚Äôve acquired more of both under my name, I‚Äôve started to contemplate which experiences were truly ‚Äúgreat‚Äù and why.</p><p>Interestingly enough, I realized that it was not the sporadic highs that were exceptional, but instead the long hauls; the sequences of events that seemed minimal at each juncture, but compounded into major gains. This led me to think further about what <em>greatness</em> truly means. I‚Äôve come to learn that it‚Äôs not about overnight successes or flashes of excellence, but periods of repeatable habits.</p><blockquote><em><strong>Perhaps ‚Äúgreat‚Äô, is just ‚Äúgood‚Äù, but repeatable. </strong></em></blockquote><h2 id="consider-this">Consider This</h2><p>Before stepping into the bulk of this article, I want to clarify two things:</p><ul><li>Greatness is not instantaneous</li><li>Greatness is earned</li></ul><p>The first step in becoming great is recognizing that you‚Äôre likely not already great. In fact, it comes from recognizing that there is no such thing as greatness at a specific instance in time. Greatness is instead a reflection of a period of effort, since greatness in a single instance can be reduced to luck. </p><p>Moreover, being ‚Äúgreat‚Äù is not about being better than someone else. It is about being dependable and disciplined, and ultimately it is earned. </p><p>Many people, in theory, want to be ‚Äúgreat‚Äù. In fact, each month 1000 people search ‚Äúhow to be great‚Äù, 260 people search ‚Äúhow to become perfect‚Äù, and 2400 people search ‚Äúhow to be the best‚Äù, looking for discrete answers on how to get from 0 to 1. Yet, many people in life realistically do not want to put in the effort over a sustained period of time to actually get to 1. They are looking for the ‚Äúsecrets to success‚Äù that in many ways, do not exist. You know what brings success? Hard work brings success. </p><p>So before proceeding forward in this article, I implore each of you to consider that if greatness truly is a reflection of non-instantaneous, earned effort, ask yourself if that‚Äôs the life you‚Äôd like to live. Ask yourself whether you‚Äôd like to spend your days, weeks, months, and years in a constant uphill battle. </p><p>If you ultimately find that you don‚Äôt want to do that, that‚Äôs fine! It doesn‚Äôt make you less of a person. At least you‚Äôve broken from the holding pattern of thinking you want to do X but not understanding why you haven‚Äôt gotten there yet. And if that‚Äôs the case, go enjoy your Netflix and chill completely guilt-free.</p><p>With that in mind, let‚Äôs dive into what truly makes someone ‚Äúgreat‚Äô. </p><h2 id="it-s-hard-to-be-consistent">It‚Äôs Hard to be Consistent</h2><p>There‚Äôs a false impression that success or notoriety comes with being flashy. This notion comes from the media focusing on outliers, whether it be events or personalities which diverge from the norm. Not only can this encourage people to aim for notoriety just for the sake of it (think Elizabeth Holmes), but it makes the rest of us believe that correlation (of those outliers) is causation; in other words, success of those individuals is due to their offbeat ways. But here‚Äôs another storyline: the most sure and therefore the <em>best</em> way to ‚Äúsuccess‚Äù is through consistency.</p><blockquote><em>‚ÄúUntil you work as hard as those you admire, don‚Äôt explain away their success as luck.‚Äù</em> - James Clear, <a href="https://amzn.to/31t6vQZ">Atomic Habits</a></blockquote><p>To be clear, consistency isn‚Äôt necessarily the easiest way to success, but one that can be achieved with a higher level of certainty, rather than hoping for a lottery win or someone to ‚Äúdiscover‚Äù you. Continuous effort is a more thoughtful approach that leads to greatness when the following statements are true:</p><ol><li>Inputs are consistent over time</li><li>Intentional inputs lead to expected outputs</li></ol><h3 id="consistency">Consistency<br></h3><blockquote><em>‚ÄúNo one who can rise before dawn three hundred sixty days a year fails to make his family rich‚Äù</em> - <a href="https://amzn.to/2Fcnn4K">Outliers</a></blockquote><p>There is a famous saying from Napolean Hill which says, <em>‚ÄúIf you cannot do great things, do small things in a great way‚Äù</em>. I would actually argue the quote should be, <em>‚ÄúIf you cannot do great things, do small things a great number of times‚Äù.</em></p><p>If you don‚Äôt have the opportunity to ‚Äúdo great things‚Äù, focus on consistently achieving small wins. These small things in fact do not need to be done in a great way, but a good way, repeatably. In fact, I would advise not to focus on perfection, as it is often the enemy of the successful. </p><p>There‚Äôs glimmer and hoopla around unpredictability, but in reality, it‚Äôs much more difficult and therefore impressive, to be predictably good. For example:</p><ul><li>It‚Äôs easy to wake up whenever you ‚Äúfeel like it‚Äù. </li><li>It‚Äôs hard to stick to a routine of getting up at 6AM.</li><li>It‚Äôs easy to pivot from side project to side project, focusing on the new shiny object of the month.</li><li>It‚Äôs hard to stick with a side project for years, many of which may not be profitable for a long while. </li><li>It‚Äôs easy to give up on someone when you hit a roadblock or the next potential partner becomes available. </li><li>It‚Äôs hard to be faithful and invest in a relationship for decades.</li></ul><p>We normally set out in life with good intentions. We <em>intend</em> to set a morning routine or work on a business until it's profitable or to ‚Äúlove someone forever‚Äù. We imagine that as we invest in something, we will naturally continue to move in the right direction. If anything, things will get easier, right?</p><figure><img src="https://lh4.googleusercontent.com/NQV_7RXfM2ZYDJsT4E4JAaAW2i9KphrB7-fE8XveJlrW-Msf1aIot9ayls-wSCWIroq155Fzdz6vE3d8br71E6Tc5sTQRyhnT0Zb6EJCUoV41B5EoZSczjtWcHo9KV-T9c6s16Cb"></figure><p>The described trajectory is what we perceive on the left. Predictable, linear, and a direct reflection of effort put in. </p><p><strong>Rarely does success in anything look like that.</strong> Life is a series of tiny nodes that tend to look more like the right hand side. There two key elements worth calling out in the more realistic graph on the right:</p><ul><li>Compounding is always present. The earlier steps in any process will be more strenuous, yet it‚Äôs difficult to imagine the potential compounding that comes later on. </li><li>With the ups, there are always downs. This seems obvious, but we often forget this when we are in periods of down. We quit at these local minimums (the highlighted sections in red above), because we cannot see the next peak right around the corner. </li></ul><figure><blockquote><div lang="en" dir="ltr"><p>a friend just emailed me this note in response to my 'burn out' video. wanted to share;</p><p>'the addiction to having success is what makes you feel unsuccessful at the times when you're not feeling the immediate dopamine hit of your work 'succeeding' at that precise moment.'</p></div>‚Äî Casey Neistat (@Casey) <a href="https://twitter.com/Casey/status/1093520669286064133?ref_src=twsrc%5Etfw">February 7, 2019</a></blockquote>

</figure><figure><blockquote><p lang="en" dir="ltr">We have lost our ability to appreciate delayed gratification and, some of us who struggle with perfectionism, can either create repeatedly until we ‚Äòget it right‚Äô never truly feeling fulfilled with our work, or, we avoid creating all together in fear of failing.</p>‚Äî Marcio Novelli (@MarcioNovelli) <a href="https://twitter.com/MarcioNovelli/status/1093522120536150017?ref_src=twsrc%5Etfw">February 7, 2019</a></blockquote>

</figure><p>The local minima are especially psychologically taxing due to something called the <a href="https://en.m.wikipedia.org/wiki/Hedonic_treadmill">Hedonic treadmill</a> or hedonic adaptation. Essentially, as someone achieves new successes in various aspects of their lives, their baseline shifts to reflect that new level and therefore, their expectations and desires are re-established as well. There is no net gain in happiness and thus, it becomes even more difficult to stay ‚Äúlevel-headed‚Äù during these down moments. </p><p>That is exactly why a specific search for success can be problematic and instead of looking for unsustainable shortcuts in life, it‚Äôs much more effective (and healthy) to aim for continuous habits that bring you success as a byproduct, not as the end goal.</p><blockquote><em>‚ÄúThe only way to become excellent is to be endlessly fascinated by doing the same thing over and over. You have to fall in love with boredom.‚Äù - <a href="https://amzn.to/31t6vQZ">Atomic Habits</a>, James Clear</em></blockquote><p>On your journey to greatness, you need to fall in love with the process which includes many local minima and maxima. Staying consistent and pushing through both of these continuously is what will truly differentiate you from those that are simply ‚Äúgood‚Äù and isolate you as one of the few that are ‚Äúgreat‚Äô.</p><h3 id="inputs-outputs">Inputs ‚Üí Outputs</h3><p>The second important aspect of achieving greatness is acting with intention. Your actions and results will not always reflect your intentions, but as you move towards ‚Äúgreatness‚Äù, you should have a better idea of what inputs actually deliver output. You‚Äôll still make mistakesÔπ£as we all doÔπ£but you‚Äôll have a better grasp on what is more likely to work out. For example, your success rate may be 30%, versus someone flying blind with a 5% success rate. </p><p>Let‚Äôs look at a simple example:</p><p>Imagine company X has two sales people. Salesperson A happens to land a $1M deal in his first week. However, he struggles to land anything substantial for the next 6 months. Meanwhile, salesperson B manages to develop a process over the first month, bringing in only $100k which he‚Äôs able to scale up and double month over month.</p><p>After six months, this will be the revenue generated by each party.</p><figure><img src="https://blog.stephsmith.io/content/images/2019/05/image-5.png"></figure><p>You‚Äôre probably thinking‚Ä¶ "So what? That‚Äôs just a classic example of compounding." </p><p>Yes! That‚Äôs exactly the point. The best things in life often aren‚Äôt miracles, but well-thought out approaches that are sustainable. The same thing is true with businesses, marriages, and just about anything with repeatable elements. If you invest time into solving for what leads to success continuously, you will reap those benefits for years to come. <em>So even in the least quantifiable situations, reflect back on what could‚Äôve made a previous loss a future win. </em></p><p>Consider the best companies over time. None of them emerged overnight, nor was there a single inflection point that determined the success or notoriety of these companies. The line of separation between the ‚Äúgreat‚Äù companies of all time and the ‚Äúnot so great‚Äù, is their ability to stand the test of time. </p><p>Would you rather be Juicero that <a href="https://www.crunchbase.com/organization/juicero">raised $100M</a> and <a href="https://techcrunch.com/2017/09/01/rip-juicero-the-400-venture-backed-juice-machine/">went bankrupt</a> within a year of its Series C, or Zoom, which <a href="https://www.crunchbase.com/organization/zoom-video-communications/funding_rounds/funding_rounds_list#section-funding-rounds">took almost 8 years to take on more funding than $30M</a> and is now one of the most profitable and highly sought after ‚Äúunicorns‚Äù in the valley?</p><p>On top of consistency, greatness comes from asking the right questions and iterating to learn what ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephsmith.io/how-to-be-great/">https://blog.stephsmith.io/how-to-be-great/</a></em></p>]]>
            </description>
            <link>https://blog.stephsmith.io/how-to-be-great/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25169061</guid>
            <pubDate>Sat, 21 Nov 2020 11:17:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Miss Working from the Office]]>
            </title>
            <description>
<![CDATA[
Score 563 | Comments 467 (<a href="https://news.ycombinator.com/item?id=25168589">thread link</a>) | @sysoleg
<br/>
November 21, 2020 | https://www.roguelazer.com/2020/11/i-miss-working-from-the-office/ | <a href="https://web.archive.org/web/*/https://www.roguelazer.com/2020/11/i-miss-working-from-the-office/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <section id="main-content" role="main">
	<article>
		


		<div><p>I went into my office yesterday for the first time in a few months to pick some stuff up. We got notified
a couple of days ago to get any personal property out of the office before Thanksgiving or else it'd be
thrown out, so I guess we're moving out of the office<sup id="fnref:moving-out"><a href="#fn:moving-out">1</a></sup>. It was a pretty eerie place to be; even now, 8
months later, most people haven't been back and it kind of looks like the entire office was abducted by aliens in
early March.</p>

<p>Despite how weird it is, I still miss working out of the office.</p>
<!-- more -->

<p>I miss having a clean delineation between "work" and "home".</p>
<p>I miss having copious desk space and a big monitor<sup id="fnref:house"><a href="#fn:house">2</a></sup>.</p>
<p>I miss the 48" TVs on the wall showing Grafana dashboards with key metrics so there was always ambient knowledge of
what was going on with the product.</p>
<p>I miss having meetings in conference rooms where you can see other people and have a giant whiteboard to sketch on.</p>
<p>I miss casual collaboration. Video chat is a poor substitute and Slack is a deeply irritating tool that combines the
worst aspects of synchronous and asynchronous communication.</p>
<p>I miss productivity! Our engineering productivity has fallen through the floor since COVID despite everyone
working longer and harder; I fundamentally do not think remote teams can <em>ever</em> be as productive as in-person teams.</p>
<p>I miss having my employer pay for electricity and heat and fast symmetric multi-gigabit Internet access instead of
shifting those costs to me.</p>
<p>I miss having a plethora of convenient and delicious options for take-out lunch! I miss the gyros and french fries
at <a href="https://www.ayolagreek.com/">Ayola</a>. I miss the chicken pesto sandwich at <a href="https://working-girls-cafe.square.site/">Working Girls'
Cafe</a>. I miss the chow mein and pork buns from <a href="https://yanksing.com/">Yank Sing</a>. I
miss the katsu curry from <a href="http://www.muraccis.com/">Muracci's</a>. I miss the curry burritos from <a href="https://www.curryupnow.com/">Curry Up
Now</a>. I miss the croque monsieur from <a href="https://cafemadeleinesf.com/">Cafe Madeline</a>. I
miss the $5 lunch specials from <a href="http://www.mehfilindian.com/">Mehfil</a>.</p>
<p>I miss the succession of friendly baristas at our <a href="https://www.yelp.com/biz/hermanos-coffee-juice-san-francisco">favorite coffee shop</a> who always knew our orders and put up with our banter.</p>
<p>I miss occasional after-work drinks at the <a href="https://sf.eater.com/2019/4/25/18516128/skydeck-spirits-in-the-sky-rooftop-bar-san-francisco">sky bar</a> with the $18 well drinks that we always convinced management to pay for.</p>
<p>Hell, I miss <a href="https://www.bart.gov/">BART</a> in all its loud and smelly glory.</p>
<p>Look, I know, it's not all bad. It's a lot easier taking care of a baby while working from home than it would be if
I were commuting 45 minutes each way every day. I'm spending a lot less money on food and coffee and BART. And I'm
not arguing that we should be in the office now; not a single one of those things I listed above is worth the health
risk of jamming 150 people<sup id="fnref:deniers"><a href="#fn:deniers">3</a></sup> into an open-plan office with a quasi-functional ventilation
system<sup id="fnref:ventilation"><a href="#fn:ventilation">4</a></sup>. But I
really hope that office-work isn't a permanent victim of this pandemic, that all the companies pushing for
permanent WFH to save a few bucks on rent reconsider their stances, and that there comes a time when I can go back to
work again.</p>
</div>
<hr>
<h2>Comments</h2>


	</article>
    </section>
</div></div>]]>
            </description>
            <link>https://www.roguelazer.com/2020/11/i-miss-working-from-the-office/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25168589</guid>
            <pubDate>Sat, 21 Nov 2020 08:58:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Donald Knuth ‚Äì The Patron Saint of Yak Shaves (2015)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25168451">thread link</a>) | @beefhash
<br/>
November 21, 2020 | https://yakshav.es/the-patron-saint-of-yakshaves/ | <a href="https://web.archive.org/web/*/https://yakshav.es/the-patron-saint-of-yakshaves/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>In 2015, I gave a talk in which I called <a href="https://speakerdeck.com/skade/tex-the-ultimate-yakshave">Donald Knuth the Patron Saint of Yak Shaves</a>. The reason is that Donald Knuth achieved the most perfect and long-running yak shave: TeX.</p>
<p>I figured this is worth repeating.</p>
<h2 id="how-to-achieve-the-ultimate-yak-shave">How to achieve the ultimate Yak Shave</h2>
<p>The ultimate yak shave is the combination of improbable circumstance, the privilege to be able to shave at your hearts will and the will to follow things through to the end. Here‚Äôs the way it was achieved with TeX. The recount is purely mine, inaccurate and obviously there for fun. I‚Äôll avoid the most boring facts that everyone always tells, such as <a href="https://en.wikipedia.org/wiki/Knuth_reward_check">why Knuth‚Äôs checks have their own Wikipedia page</a>.</p>
<p>So, let‚Äôs get things started.</p>
<h2 id="the-pre-shave">The Pre-Shave</h2>
<p>TeX was invented to typeset a book. No plural. It was invented to typeset the second edition of ‚ÄúThe Art of Computer Programming‚Äù. The second edition had to be typeset again, as ‚Äúhot type‚Äù typesetting, which was used for the first edition, was not available anymore. Being unimpressed by the available options, Knuth decided to write his own system, which later ended up as TeX.</p>
<p>But ‚ÄúThe Art of Computer Programming‚Äù is an impressive book in its own right: it is still unfinished, currently spanning 3.5 volumes (yes, the fourth is unfinished, but the first chapters are released). It was called a book of the century by <a href="https://web.archive.org/web/20080820030403/http://www.americanscientist.org/bookshelf/pub/100-or-so-books-that-shaped-a-century-of-science">American scientist writers</a>.</p>
<p>Yak shave -2: Write a book of the century</p>
<p>Digging deeper into TAOCP, it already shows the works of a yak shaver destined for greater things. All programs in this book refer to a common assembly language: MIX. Which was invented for the book.</p>
<p>Yak shave -1: Invent your own computer for illustration purposes</p>
<h2 id="implementation">Implementation</h2>
<p>The first version of TeX was implemented using the <a href="https://en.wikipedia.org/wiki/SAIL_(programming_language)">SAIL</a> programming language. It was later replaced by WEB. What‚Äôs WEB? It‚Äôs a programming language, invented by‚Ä¶ You‚Äôll have guessed it by now, Donald Knuth. It transpiles to PASCAL. Knuth transpiled the WEB before it was cool.</p>
<p>Yak shave 1: Somewhere along the road, implement your own programming language‚Ä¶</p>
<p>WEB is a special language: in WEB, any bare text is just text. It‚Äôs interleaved with marked pieces of code, which are later used for the program code. The documentation can be run through a special program to produce‚Ä¶ a TeX file. The concept is called ‚Äúliterate programming‚Äù and was introduced by‚Ä¶ Donald Knuth.</p>
<p>Yak shave 2: Invent your own programming paradigm for it</p>
<p>But, what does TeX do? Mainly, it does text layout and a couple of other things. Knuth being known for research on algorithms couldn‚Äôt do without coming up with his own algorithm, later published together with Michael Plass. What does the algorithm do? It finds a visually pleasing way to lay out a paragraph on a page without making line breaks look jarring (for example by adjusting the ‚Äúglue‚Äù, the whitespace between words). Here‚Äôs a <a href="https://www.ugrad.cs.ubc.ca/~cs490/2015W2/lectures/Knuth.pdf">nice explanation</a>.</p>
<p>It‚Äôs still considered good and has a huge factor in the recognisable look of TeX documents.</p>
<p>Yak shave 3: Invent your own layout algorithm for it</p>
<p>Which brings us to the next problem: <em>what</em> does this thing lay out? Generically speaking: objects and clusters of objects of varying sizes. Interestingly, that‚Äôs what TeX deals with, it has no concept of a character other then dimensions.</p>
<p>Nevertheless, these are usually characters and characters are provided by fonts. Fonts must usually be licensed at a fee and free fonts weren‚Äôt so available in the 70s.</p>
<p>Another very recognisable feature of TeX documents that they are often set in a font called ‚ÄúComputer Modern‚Äù.</p>
<p>I‚Äôm trying to make this whole thing a bit more thrilling, so I will let you guess who created that one.</p>
<p>Yak shave 4: Design a font</p>
<p>Fonts need to be authored. Usually, they are described in some vector description, often B√©zier curves. This is fairly standard and not an innovation of Knuth. <em>But</em>, he wrote a description language for that, along with an interpreter to turn this descriptions into proper font files. This is <a href="https://en.wikipedia.org/wiki/Metafont">METAFONT</a>. It‚Äôs not strictly part of TeX, it‚Äôs just that the Yak happened to stand close.</p>
<p>Yak shave 5: Write an authoring tool for fonts</p>
<p>As a side-note, METAFONT was later evolved into METAPOST for generic vector drawings, which has the one feature I still miss from many modern graphics description languages: the ability to describe an (addressable) point as the intersection between two other primitives.</p>
<p>Another side-note: both TeX and METAFONT still see releases, at a slow pace. TeX is currently at version 3.14159265, METAFONT at 2.7182818. Yep, TeX is slowly converging towards pi, while METAFONT towards e. Take that, semantic versioning advocates!</p>
<p>Yak shave 6: Come up with your own versioning scheme<br>
Yak shave 7: Avoid adoption of it for greater good</p>
<p>We‚Äôre not done yet. We can layout text (and other things), but where do we convert it to? Now, everyone knows the horror printers invoke, so no one wants to deal with those directly. Classic TeX instead converts things to <a href="https://en.wikipedia.org/wiki/Device_independent_file_format">DVI</a>, the ‚Äúdevice independent‚Äù format. I don‚Äôt know many details about it, except what‚Äôs on the wiki page, which feels the need to specifically point out that ‚ÄúDVI is not a document encryption format‚Äù. It is again a stack-based language (in contrast to PostScript not turing complete), which can then be interpreted through a driver, which would then send that to whatever target (a printer, PDF or such). It was designed by‚Ä¶</p>
<p>David R. Fuchs, Knuth just wrote the implementation.</p>
<p>Yak shave 8: Implement a custom language for printable documents</p>
<p>Note that I haven‚Äôt mentioned that TeX is an‚Ä¶ interesting‚Ä¶ language by itself, but I don‚Äôt consider that a yak shave, this was just the implementation.</p>
<p>That makes most of the initial implementation complete. Which means, in orderly fashion, you should give matters in the hand of the community.</p>

<p>Since the release of TeX, the community has been busy working on using it as a platform. If you ever downloaded the full TeX distribution, please bear in mind that you are downloading the amassed work of over 40 years, to make sure that each and every TeX document ever written builds. We‚Äôre talking about documents here.</p>
<p>But mostly, two big projects sprung out of that. The first is LaTeX by Leslie Lamport. Lamport is a very productive researcher, famous for research in formal methods through TLA+ and also known laying groundwork for many distributed algorithms. LaTeX is based on the idea of seperating presentation and content. It is based around the idea of document classes, which then describe the way a certain document is layed out. Think Markdown, just much more complex. The second is ConTeXt, which is far more focused on fine grained layout control.</p>
<p>Both share a common property:</p>
<p>Community yak shave 1: Create not one, but two programs that are very ungoogleable‚Ä¶ Before Google is invented.</p>
<p>Being active in a language that has lingo built around ‚ÄúRust‚Äù, ‚ÄúCargo‚Äù and ‚Äúmanifests‚Äù, I feel right at home.</p>
<p>Now, the community also wants to evolve TeX: a lot has changed over the years in technology, so, for example, you‚Äôd like to use modern font formats, directly write to modern output formats or use this new UTF-8 thingy. For that, there are specialised TeX interpreters, such as <code>pdf(la)tex</code>, <code>lua(la)tex</code> and <code>xe(la)tex</code>. There‚Äôs a problem here: you are not allowed to change TeX and distribute <a href="https://en.wikipedia.org/wiki/TeX#License">it under that name</a>. The thinking here is that if you have a <code>tex</code> binary, you can compile any valid TeX from the past and from the future.</p>
<p>The first issue on that road is that WEB isn‚Äôt really a popular programming language, neither is PASCAL and running it on modern systems is a bit of a pain. Which means‚Ä¶</p>
<p>Community yak shave 2: Transpile WEB to C and work from there</p>
<p>This is just the start of a great endeavour‚Ä¶</p>
<p>Community yak shave 3: Build a lot of tooling around that</p>
<h2 id="the-moral-of-the-story">The Moral of the Story</h2>
<p>Whenever you feel like ‚Äúcan‚Äôt we just replace this whole thing, it can‚Äôt be so hard‚Äù when handling TeX, don‚Äôt forget how many years of work and especially knowledge were poured into that system. Typesetting isn‚Äôt the <em>most</em> popular knowledge around programmers. Especially see it in the context of the space it is in: they can‚Äôt remove legacy. Ever. That would break documents.</p>
<p>TeX is also not a programming language. It might resemble one, but mostly, it should be approached as a typesetting system first. A lot of its confusing lingo gets much better then. It‚Äôs not programming lingo.</p>
<p>By approaching TeX with an understanding for its history, a lot of things can be learned from it. And yes, a replacement would be great, but it would take ages.</p>
<p>In any case, I hope I thoroughly convinced you why Donald Knuth is the Patron Saint of Yak Shaves.</p>

<p>This comes out of a enjoyable discussion with <a href="https://lambdaisland.com/">Arne from Lambda Island</a>, who listened and said ‚Äúyou should totally turn this into a talk‚Äù.</p>

      <p><a href="https://yakshav.es/">top</a>
    </p></div></div>]]>
            </description>
            <link>https://yakshav.es/the-patron-saint-of-yakshaves/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25168451</guid>
            <pubDate>Sat, 21 Nov 2020 08:09:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mvp.css ‚Äì build your landing page with only semantic HTML]]>
            </title>
            <description>
<![CDATA[
Score 312 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25167928">thread link</a>) | @rahimnathwani
<br/>
November 20, 2020 | https://andybrewer.github.io/mvp/ | <a href="https://web.archive.org/web/*/https://andybrewer.github.io/mvp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <hr>
        <section>
            <header>
                <h2>Simple, reusable components</h2>
                <p>For a clean looking design that doesn't get in the way</p>
            </header>
            
            
            
        </section>
        <hr>
        <section id="testimonials">
            <blockquote>
                <img alt="Quote" src="https://andybrewer.github.io/mvp/img/icon-quote.svg" height="80"><br>
                "By far the easiest stylesheet I've ever used. It integrates easily into <s>one</s> all of my
                startup&nbsp;projects."
                
            </blockquote>
        </section>
        <hr>
        <section id="features">
            <header>
                <h2>Flexibility without complexity</h2>
                <p>A few, clean styling options without all the bells and whistles</p>
            </header>
            <table>
                <thead>
                    <tr>
                        <th></th>
                        <th>MVP.css</th>
                        <th>No CSS</th>
                        <th>Custom CSS</th>
                    </tr>
                </thead>
                <tbody><tr>
                    <td>Mobile friendly</td>
                    <td><b>‚úì</b></td>
                    <td>‚úì</td>
                    <td>‚úì</td>
                </tr>
                <tr>
                    <td>Works out of the box</td>
                    <td><b>‚úì</b></td>
                    <td>‚úì</td>
                    <td>‚àÖ</td>
                </tr>
                <tr>
                    <td>Easy to customize</td>
                    <td><b>‚úì</b></td>
                    <td>‚úì</td>
                    <td>‚àÖ</td>
                </tr>
                <tr>
                    <td>Only semantic HTML</td>
                    <td><b>‚úì</b></td>
                    <td>‚úì</td>
                    <td>‚àÖ</td>
                </tr>
                <tr>
                    <td>No class names</td>
                    <td><b>‚úì</b></td>
                    <td>‚úì</td>
                    <td>‚àÖ</td>
                </tr>
                <tr>
                    <td>Perfect for an MVP</td>
                    <td><b>‚úì</b></td>
                    <td>‚àÖ</td>
                    <td>‚àÖ</td>
                </tr>
            </tbody></table>
        </section>
        <hr>
        <div id="figure">
            <header>
                <h2>A decent MVP in no time</h2>
                <p>More building and less designing with "set and forget" styling.</p>
            </header>
            <figure>
                <img alt="Stock photo" src="https://andybrewer.github.io/mvp/img/stock.jpg">
                <figcaption><i>"Uber for X" brainstorming session</i></figcaption>
            </figure>
        </div>
        <hr>
        <article id="docs">
            <h2>Docs</h2>
            <h3 id="html">HTML Reference</h3>
            
            <p>MVP.css works with the following HTML elements:</p>
            <ul>
                <li><code>&lt;a&gt;</code> <small>‚Äî text links</small>
                    <ul>
                        <li><code>&lt;a&gt;&lt;b&gt;</code>, <code>&lt;a&gt;&lt;strong&gt;</code> <small>‚Äî solid
                                link buttons</small>
                        </li>
                        <li><code>&lt;a&gt;&lt;em&gt;</code>, <code>&lt;a&gt;&lt;i&gt;</code> <small>‚Äî outlined
                                link buttons</small>
                        </li>
                    </ul>
                </li>
                <li><code>&lt;article&gt;</code> <small>‚Äî content area with normal styling</small>
                    <ul>
                        <li><code>&lt;article&gt;&lt;aside&gt;</code> <small>‚Äî text callout</small>
                        </li>
                    </ul>
                </li>
                <li><code>&lt;blockquote&gt;</code> <small>‚Äî quote callout</small>
                    <ul>
                        <li><code>&lt;blockquote&gt;&lt;footer&gt;</code> <small>‚Äî quote attribution</small>
                        </li>
                    </ul>
                </li>
                <li><code>&lt;body&gt;</code> <small>‚Äî default parent element</small></li>
                <li><code>&lt;button&gt;</code> <small>‚Äî form buttons</small></li>
                <li><code>&lt;code&gt;</code> <small>‚Äî inline code highlighting</small></li>
                <li><code>&lt;details&gt;</code> <small>‚Äî default expandable content section</small>
                    <ul>
                        <li><code>&lt;details&gt;&lt;summary&gt;</code> <small>‚Äî expandable heading</small></li>
                    </ul>
                </li>
                <li><code>&lt;div&gt;</code> <small>‚Äî unstyled element</small></li>
                <li><code>&lt;figure&gt;</code> <small>‚Äî image callouts</small>
                    <ul>
                        <li><code>&lt;figure&gt;&lt;figcaption&gt;</code> <small>‚Äî image callout captions</small>
                        </li>
                    </ul>
                </li>
                <li><code>&lt;footer&gt;</code> <small>‚Äî footer area</small></li>
                <li><code>&lt;form&gt;</code> <small>‚Äî small form area</small>
                    <ul>
                        <li><code>&lt;form&gt;&lt;input&gt;</code> <small>‚Äî short input field</small></li>
                        <li><code>&lt;form&gt;&lt;label&gt;</code> <small>‚Äî form field labels</small></li>
                        <li><code>&lt;form&gt;&lt;select&gt;</code> <small>‚Äî dropdown options container</small>
                            <ul>
                                <li><code>&lt;form&gt;&lt;select&gt;&lt;option&gt;</code> <small>‚Äî dropdown option
                                        items</small></li>
                            </ul>
                        </li>
                        <li><code>&lt;form&gt;&lt;textarea&gt;</code> <small>‚Äî large input field</small></li>
                    </ul>
                </li>
                <li><code>&lt;header&gt;</code> <small>‚Äî content area with centered styling</small></li>
                <li><code>&lt;h1&gt;</code>, <code>&lt;h2&gt;</code>, <code>&lt;h3&gt;</code>, <code>&lt;h4&gt;</code>,
                    <code>&lt;h5&gt;</code>, <code>&lt;h6&gt;</code> <small>‚Äî headings</small></li>
                <li><code>&lt;hr&gt;</code> <small>‚Äî horizontal rule (divider)</small></li>
                <li><code>&lt;main&gt;</code> <small>‚Äî main content area</small></li>
                <li><code>&lt;mark&gt;</code> <small>‚Äî text highlighting</small></li>
                <li><code>&lt;nav&gt;</code> <small>‚Äî top navigation</small>
                    <ul>
                        <li><code>&lt;nav&gt;&lt;ul&gt;</code> <small>‚Äî nav links container</small></li>
                        <li><code>&lt;nav&gt;&lt;ul&gt;&lt;li&gt;</code> <small>‚Äî nav link items</small></li>
                        <li><code>&lt;nav&gt;&lt;ul&gt;&lt;li&gt;&lt;ul&gt;</code> <small>‚Äî nav dropdown
                                container</small></li>
                        <li><code>&lt;nav&gt;&lt;ul&gt;&lt;li&gt;&lt;ul&gt;&lt;li&gt;</code> <small>‚Äî nav dropdown
                                link items</small></li>
                    </ul>
                </li>
                <li><code>&lt;ol&gt;</code> <small>‚Äî numbered list container</small>
                    <ul>
                        <li><code>&lt;ol&gt;&lt;li&gt;</code> <small>‚Äî numbered list items</small></li>
                    </ul>
                </li>
                <li><code>&lt;p&gt;</code> <small>‚Äî paragraph tag</small></li>
                <li><code>&lt;pre&gt;</code> <small>‚Äî preformatted text</small>
                    <ul>
                        <li><code>&lt;pre&gt;&lt;code&gt;</code> <small>‚Äî code block</small></li>
                        <li><code>&lt;pre&gt;&lt;samp&gt;</code> <small>‚Äî computer output block</small></li>
                    </ul>
                </li>
                <li><code>&lt;samp&gt;</code> <small>‚Äî inline computer output</small></li>
                <li><code>&lt;section&gt;</code> <small>‚Äî content area for centered / special content</small>
                    <ul>
                        <li><code>&lt;section&gt;&lt;aside&gt;</code> <small>‚Äî content card</small></li>
                    </ul>
                </li>
                <li><code>&lt;small&gt;</code> <small>‚Äî smaller text</small></li>
                <li><code>&lt;sup&gt;</code> <small>‚Äî raised text (notification bubbles)</small></li>
                <li><code>&lt;table&gt;</code> <small>‚Äî data table</small>
                    <ul>
                        <li><code>&lt;table&gt;&lt;td&gt;</code> <small>‚Äî data table cell</small></li>
                        <li><code>&lt;table&gt;&lt;th&gt;</code> <small>‚Äî data table header cell</small></li>
                        <li><code>&lt;table&gt;&lt;thead&gt;</code> <small>‚Äî data table header section</small>
                        </li>
                        <li><code>&lt;table&gt;&lt;tr&gt;</code> <small>‚Äî data table row</small></li>
                    </ul>
                </li>
                <li><code>&lt;ul&gt;</code> <small>‚Äî unordered list container</small>
                    <ul>
                        <li><code>&lt;ul&gt;&lt;li&gt;</code> <small>‚Äî unordered list item</small></li>
                    </ul>
                </li>
            </ul>
            <br>
            <h3 id="variables">Modifying the CSS variables</h3>
            <p>MVP.css includes a list of CSS variables. Editing these variables will change the styles globally.</p>
            <pre>                <code>
:root {
    --border-radius: 5px;
    --box-shadow: 2px 2px 10px;
    --color: #118bee;
    --color-accent: #118bee0b;
    --color-bg: #fff;
    --color-bg-secondary: #e9e9e9;
    --color-secondary: #920de9;
    --color-secondary-accent: #920de90b;
    --color-shadow: #f4f4f4;
    --color-text: #000;
    --color-text-secondary: #999;
    --font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen-Sans, Ubuntu, Cantarell, "Helvetica Neue", sans-serif;
    --hover-brightness: 1.2;
    --justify-important: center;
    --justify-normal: left;
    --line-height: 150%;
    --width-card: 285px;
    --width-card-medium: 460px;
    --width-card-wide: 800px;
    --width-content: 1080px;
}
                </code>
            </pre>

            <p>Custom styles can be added below the <code>/* Custom styles */</code> comment at the end of the file.</p>
        </article>
        <hr>
        <article id="faq">
            <h2>Frequently Asked Questions</h2>
            <details>
                <summary>Why would I use this?</summary>
                <p>If you just want to launch already.</p>
                <p><sup>PRO TIP</sup> An MVP is a temporary site, it doesn't have to be <i>and shouldn't be</i> perfect.
                </p>
            </details>
            <details>
                <summary>What skills will I need?</summary>
                <p>Mostly HTML, maybe a hint of CSS if you want to get fancy.</p>
                <p><i>CSS</i>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <progress max="100" value="5">5</progress></p>
                <p><i>Design</i>&nbsp;&nbsp; <progress max="100" value="0">0</progress></p>
                <p><i>HTML</i>&nbsp;&nbsp;&nbsp;&nbsp; <progress max="100" value="100">100</progress></p>
            </details>
            <details>
                <summary>Is there a minified version?</summary>
                <p>No, you don't need one for an MVP.</p>
            </details>
            <details>
                <summary>How can I improve my design?</summary>
                <p>Here are some helpful resources:</p>
                <ul>
                    <li>Emojis - <a href="https://www.emojicopy.com/" target="_blank">Emojicopy
                            ‚Üó</a></li>
                    <li>Icons - <a href="https://www.toptal.com/designers/htmlarrows/" target="_blank">HTML Entities
                            List by TopTal
                            ‚Üó</a></li>
                    <li>Icons - <a href="https://thenounproject.com/" target="_blank">TheNounProject
                            ‚Üó</a></li>
                    <li>Illustrations - <a href="https://gallery.manypixels.co/" target="_blank">Manypixels
                            ‚Üó</a></li>
                    <li>Illustrations - <a href="https://undraw.co/illustrations" target="_blank">Undraw ‚Üó</a>
                    </li>
                    <li>Logo - <a href="https://www.namecheap.com/logo-maker/app/" target="_blank">Namecheap Logo
                            Maker ‚Üó</a></li>
                    <li>Product Shots - <a href="https://www.screely.com/" target="_blank">Screely ‚Üó</a></li>
                    <li>Stock Photos - <a href="https://www.pexels.com/" target="_blank">Pexels ‚Üó</a></li>
                    <li>Stock Photos - <a href="https://unsplash.com/" target="_blank">Unsplash ‚Üó</a></li>
                </ul>
            </details>
            <details>
                <summary>What if I don't like the default styles?</summary>
                <p>Most styles are editable through <em>CSS variables</em>. You can also add your own styles
                    inline, at the end of MVP.css or in a new stylesheet.</p>
                <p><sup>PRO TIP</sup> If there are two conflicting CSS styles, the last one will take precedence.</p>
                <pre>                    <code>
:root {
    --color: #118bee;
}

/* Lower in the CSS, or in a 2nd stylesheet */

:root {
    --color: green; /* This will take precedence */
}
                    </code>
                </pre>
            </details>
            <details>
                <summary>What if I still don't like it?</summary>
                <p>That's OK, you probably shouldn't love your MVP. The goal of MVP.css is to help you
                    feel <i>slightly</i> less embarrased about it.</p>
                <p><span>üëâ</span> If you
                    want a CSS framework with more features check out <a href="https://bulma.io/" target="_blank">Bulma
                        ‚Üó</a> or <a href="https://tailwindcss.com/" target="_blank">Tailwind ‚Üó</a>.</p>
            </details>
        </article>
        <hr>
        <section id="ideas">
            <header>
                <img alt="Idea" src="https://andybrewer.github.io/mvp/img/idea.svg" height="200">
                <h2>What can you build with MVP.css?</h2>
                <p>Free ideas below ‚Üì</p>
            </header>
            
        </section>
    </div></div>]]>
            </description>
            <link>https://andybrewer.github.io/mvp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25167928</guid>
            <pubDate>Sat, 21 Nov 2020 04:49:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Jupystar ‚Äì Run any Jupyter notebook in the browser]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25167906">thread link</a>) | @protoduction
<br/>
November 20, 2020 | https://starboard.gg/jupystar | <a href="https://web.archive.org/web/*/https://starboard.gg/jupystar">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://starboard.gg/jupystar</link>
            <guid isPermaLink="false">hacker-news-small-sites-25167906</guid>
            <pubDate>Sat, 21 Nov 2020 04:40:08 GMT</pubDate>
        </item>
    </channel>
</rss>
