<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 06 Aug 2020 16:19:07 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 06 Aug 2020 16:19:07 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[On the Road to 7-Figure Income with the Indie Founder of DropInBlog]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24058315">thread link</a>) | @theradicalone
<br/>
August 5, 2020 | https://indiediary.com/indie-founder-jesse-schoberg/ | <a href="https://web.archive.org/web/*/https://indiediary.com/indie-founder-jesse-schoberg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-301"> <div><p>Jesse Schoberg, CEO &amp; indie founder of DropInBlog, went from $1k per month, to now towards a 7-figure income. Jesse and his team currently faces the decision of “how big they want to grow”.</p><h2>About This Indie Interview</h2><div><p> This is the <code><span><strong>#2nd</strong></span></code> installment of our <a href="https://indiediary.com/hub/interviews/indiefounders/" title="interviews with indie founders">Indie Interviews</a> series to help <strong>aspiring indie founders &amp; indie entrepreneurs</strong> to get inspired by listening from those successful indie founders who are already highly involved on the startup scene and *being there* taming the waves &amp; surfing better than ever to achieve their dream – seeking financial freedom, working on projects that matters to them, getting a sense of accomplishment (in their own eyes) and working on their own schedule.</p><div><p> It is also an opportunity for new indie founders to get to know other like-minded indie entrepreneurs. </p><p>I hope you will derive as much fun to read my interviews as I’m having by interviewing those awesome indie founders, entrepreneurs &amp; businesses.</p></div><hr></div><h2>And Now the Interview With the Indie Founder</h2><h3>### Spotlight on our today’s indie person</h3><h4><a name="tell_us"></a>&gt;&gt; Please tell us about yourself + what your workstation looks like + any productivity tools you use?</h4><p>Hi. I’m <strong>Jesse Schoberg</strong>, CEO and Co-Founder of <strong><em>DropInBlog</em></strong>. I’ve been working on internet stuff since 2001 when I learned “web design” as it was called at the time. I taught myself HTML, CSS, and PHP.</p><p>I just started building websites for small businesses. That eventually turned into an agency with remote staff.</p><p>Learning to find global talent was huge for me. Once you learn how to source a team of freelancers, your journey becomes a lot faster. The agency did well enough that I made a good living. But I knew scaling an agency was a nightmare. The real path to freedom was with my own projects.</p><p>I started a variety of side projects over the years with varying success. Some failed, some eventually had moderate 6 figure exits.</p><p>I’ve done a bunch of things, but here are a few: vacation rental directory, white label hotel booking engine, white label SMS marketing SaaS, form processing SaaS, franchise directory, and eventually DropInBlog (a SaaS that adds a blog to sites not built in <a href="https://indiediary.com/wordpress/">WordPress</a>).</p><p>My experience running the agency and knowing how to code helped immensely. It helped me hire, helped me manage staff, helped me manage projects efficiently, Etc.</p><p><strong>My workstation</strong> – I’m a minimalist and a nomad so I don’t have a big desk setup.</p><p><strong>The tools I (we) use daily to keep things organised &amp; productiv</strong>e:</p><p>We use&nbsp;<strong>Freedcamp</strong>&nbsp;for our primary PM tool, and we’ve been delighted with it. They are always responsive to issues and seem to have a great team.</p><p>I keep my “today’s focus” just in a simple text doc that runs in its own space.&nbsp;I have a few little apps I like:</p><div><div><ul><li><strong>TripMode</strong>&nbsp;– limits which apps can connect to the internet, great for coffee shops, Etc</li><li><strong>Micro Snitch</strong>&nbsp;– notifies you anytime an app turns on your mic or camera</li><li><strong>Droplr</strong>&nbsp;– screenshots / screencasts / code snippets</li><li><strong>Migadu</strong>&nbsp;– email hosting based on usage, not domains/accounts</li></ul><h4><a name="routine"></a>&gt;&gt; Do you have a routine to start your day off &nbsp;or do you take it as it comes?</h4><p>I’m more of a night guy. I don’t feel my real energy kicking in until the afternoon. So I take my mornings slow. I do personal stuff – catch up with friends, life admin, reading, Etc.</p><p>You gotta follow your energy, and work when your brain is most “on”. This is different for everyone. I don’t use an alarm, I only eat 2 meals/day, and breakfast is not one of them. I love a good latte to start my day. I like to do a bit of callisthenics.</p><p>That said if I’m deep into a project, all that goes out the window. I’ll wake up and go straight to smashing keys as my brain won’t turn off until the task is finished. Sometimes that’s days or a week. Follow your energy.</p><h4><a name="motivation"></a>&gt;&gt; How do you keep yourself motivated to achieve your goals?</h4><p>I value freedom a lot. I also love building stuff. So ultimately that’s what keeps me motivated.</p><p>Internet businesses and the money they generate creates incredible freedom that most people can’t even wrap their head around if structured correctly.</p><p>Aside from that, I love the satisfaction of creating things and the excitement that can come with the hustle.</p><p>If my motivation is low, I try to step away from the keyboard. I walk, listen to podcasts (that are often not about business), play the guitar, or explore whatever city I’m dwelling in.</p><p>For me, motivation comes in large waves – I’ve learned it’s better not to force it.</p><h3>### The Indie Person as an Indie Founder/Entrepreneur</h3><h4><a name="change_world"></a>&gt;&gt; What change are you seeking to make to the world?</h4><p>Since <strong>DropInBlog</strong> has taken off, I’ve done my best to keep side projects to a minimum. But there is one we’re pursuing that is about impact and awareness.</p><p>That project is about alternative protein sources. It turns out we’re running out of resources on this earth place. We got interested in bug protein (crickets specifically) and are working on that project over at <strong>Crickets.org</strong>.</p><h4><a name="books"></a>&gt;&gt; The books or material you recommend?</h4><p>I know everyone talks about it, but if you are new in your journey, you should read <strong>The Four Hour Work Week</strong>. While the industry has dramatically evolved since its publication, it is a good starting point for mindset — precisely, <em><strong>the Dreamline exercise</strong></em>.</p><p>For personal growth and also an understanding of other humans, my all-time favourite book is <strong>The Happiness Hypothesis <em>by Jonathan Haidt</em></strong>. (Also see his follow-up <strong>The Righteous Mind</strong>.)</p><h4><a name="difference"></a>&gt;&gt; According to you, what is the difference between a founder &amp; an entrepreneur? And which one are you?</h4></div></div><p>That is an interesting question. I’ve never really thought about it.</p><p>I guess in my mind, all founders are entrepreneurs, but all entrepreneurs are not founders.</p><p>I feel like I’ve been an entrepreneur my whole life. I didn’t feel like a founder until I was focused on certain projects or companies and leading a vision.</p><p>If you hustle hot dogs on the street side or flip widgets on ebay, you’re an entrepreneur, if you take those to the next level with process, vision and longevity you are a founder.</p><h4><a name="habit"></a>&gt;&gt; What ONE habit played an important part for you as an indie founder?</h4><p><strong>Consistency</strong>. Success is a long game, and you’ve got to show up (albeit not&nbsp;<em>every</em>&nbsp;day).</p><h3>### The SaaS Business of the indie person</h3><div><p> Claim your (free) 30%-off coupon to unlock 100+ deals on tools/services to supercharge your startup journey! (worth up to $50,000)</p><p> Get practical insights from successful indie founders – Learn from their mistakes, save time knowing what actually works! </p><p> Get top hand-picked delivery of personal growth, startup &amp; business resources to nourish your entrepreneurial mind. </p><p> <a href="https://indiediary.substack.com/subscribe">JOIN INDIE DIARY</a></p></div><h4><a name="your_biz"></a>&gt;&gt; Tell us about your indie business: the beginning + how you come up with the naming?</h4><p>We have built (and are still building) a full-fledged blog platform. However, it’s a different use case than WordPress or Medium or other platforms.</p><p>It allows you to embed a blog into your existing site, using your current template or theme. Some might call it a “headless blog platform”. So that could be your hand-coded HTML site, something built in Webflow or Kartra, a Shopify store, a Thinkific site, Etc.</p><p><strong>It’s called DropInBlog</strong>. Because, well.. it lets you “drop” a blog into your website. We didn’t overthink it too much. Simple, brandable, and we could secure the .com and related social profiles.</p><p><strong>Our niche</strong> is people with websites that are not built in WordPress that want to have a blog.</p><h4><a name="aha"></a>&gt;&gt; When exactly did you get that “aha moment“ for your business/project? Tell us the story behind..</h4><p>It was quite a long time ago. Before WordPress took the world by storm, we were building sites for our clients using basic HTML, and some PHP includes.</p><p>Then clients started asking for blogs. We would install WordPress in a folder and then create a custom theme to match the existing site.</p><p>It was a tedious process, and then clients were frustrated because WordPress was a bit convoluted when using it “just” as a blog.</p><p>So with that, I thought – “why couldn’t we build a basic CMS that was just a blog that plugged into any existing site?”</p><h4><a name="biz_model"></a>&gt;&gt; What is your business model – how are you generating revenue &amp; making it profitable?</h4><p>It’s a SaaS. There are two plans, and both of them are paid-plans. There is a free trial but no free-plan.</p><p>We’ve never done well with freemium.</p><h4><a name="success"></a>&gt;&gt; In the context of this indie business, what does success mean to you?</h4><p>I want <strong>DropInBlog</strong> to become the “household name” when it comes to the pain point we solve.</p><h4><a name="income"></a>&gt;&gt; Can you share your revenue stats &amp; journey towards your 7-figure income?</h4><p>The first few years we had it as a little side project it was only making like $1k / month.</p><p>Then we had a bunch of things kind of fall into place early 2019. That’s when we saw the potential.</p><p><strong>We blew past six figures once we started focusing on it, now on the road to 7-figures </strong>– around which point we’ll have to make some serious decisions about how big we want to take this thing.</p><h4><a name="research"></a>&gt;&gt; How do you do your market research?</h4><p>Mostly we watch our signups. If there is a community like <strong><em>Kartra</em></strong> or <strong><em>Webflow</em></strong> we see using our product a lot, we start to lean into that community more and cater our content &amp; product to their needs a bit.</p><p>Once we identify things we want to target, our favourite tool is <strong>Ahrefs</strong> for sure.</p><p>But we also use <strong>Hotjar</strong> for user experience stuff and many tools from <strong><a href="https://indiediary.com/baremetrics" target="_blank" rel="noreferrer noopener nofollow ugc">Baremetrics</a></strong> to engage our customers and keep an eye on how our numbers are doing.</p><h4><a name="trust"></a>&gt;&gt; How are you building trust to attract customers + Your promotion strategies?</h4><p>We do a fair amount of content marketing. I’m active on twitter as the founder (<strong><a href="https://twitter.com/JesseSchoberg" target="_blank" rel="noreferrer noopener nofollow ugc">@JesseSchoberg</a></strong>), and occasionally I speak at conferences.</p><p>We’re mostly organic but are also testing some paid channels. We drive some traffic from some Facebook groups related to the platforms we are popular with as well.</p><h4><a name="tech"></a>&gt;&gt; What tech stack, infrastructure &amp; tools are you using to power your business?</h4><p>We’re <em>LAMP</em> programmers by trade. Our original code was written in <strong>Symfony</strong>. However, we’re now working on a rewrite using <strong>Laravel</strong>.</p><p>We use <strong>Amazon</strong> for the full stack including <strong>E2 &amp; S3</strong> along with <strong>Cloudflare</strong> for cache and routing. Once things got a bit larger, we hired a <em>DevOps</em> team to get our ducks in a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://indiediary.com/indie-founder-jesse-schoberg/">https://indiediary.com/indie-founder-jesse-schoberg/</a></em></p>]]>
            </description>
            <link>https://indiediary.com/indie-founder-jesse-schoberg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24058315</guid>
            <pubDate>Wed, 05 Aug 2020 07:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bayes Theorem: A Framework for Critical Thinking]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24058247">thread link</a>) | @neilkakkar
<br/>
August 5, 2020 | https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html | <a href="https://web.archive.org/web/*/https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Have you ever noticed how you can be fuming with anger one second, and absolutely calm the next?</p>

<p>An asshole driver cuts you off on the highway, and you’re raging. A moment later, you notice him pull into the hospital and your anger melts away. “Yeah, maybe he has a patient in the car with him. Or, maybe someone close is dying. I guess he’s not an asshole after all.”</p>

<p>An obscure rule from Probability Theory, called Bayes Theorem, explains this very well. This 9,000 word blog post is a complete introduction to Bayes Theorem and how to put it to practice. In short, Bayes Theorem is a framework for critical thinking. By the end of this post, you’ll be making better decisions, realise when you’re being unreasonable, and also understand why some people believe in UFOs.</p>

<p>It’s a hefty promise, and there’s a good chance of failure. Implementing these ideas will take emotional effort, but it’s worth it.</p>

<p>Thinking the driver is an asshole is normal. Bayes Theorem expects the same. The difference between Bayes and us is the intensity with which we believe. Most times, the seething anger isn’t warranted. This is probably why we feel stupid about all that anger. It melts away so quickly! This is calibration - aligning our emotions to the intensity of the situation - which we’ll cover as well.</p>

<!-- One way to check = If you're flip flopping between beliefs very quickly, you're probably miscalibrated. -->





<p>There’s no fancy math in this guide. We’re using Probability Theory, but aren’t going into the derivation, nor are we solving probability problems from school textbooks. These things are tedious without understanding the why. Instead, we’ll understand why Bayes Theorem matters, and how to apply it.</p>

<p>To begin with, let’s play a game. Throughout this game, <em>notice</em> how you feel about your decisions. Notice what decisions you’re making, and notice how you find the answer.</p>

<nav>

  <h4>Table of Contents</h4>

<ul id="markdown-toc">
  <li><a href="#the-246-game" id="markdown-toc-the-246-game">The 2,4,6 game</a></li>
  <li>
<a href="#bayes-explanation" id="markdown-toc-bayes-explanation">Bayes Explanation</a>    <ul>
      <li><a href="#bayes-theorem" id="markdown-toc-bayes-theorem">Bayes Theorem</a></li>
      <li><a href="#being-late-example" id="markdown-toc-being-late-example">Being Late Example</a></li>
    </ul>
  </li>
  <li><a href="#grinding-the-gears" id="markdown-toc-grinding-the-gears">Grinding the Gears</a></li>
  <li>
<a href="#the-4-rules-for-being-a-good-bayesian" id="markdown-toc-the-4-rules-for-being-a-good-bayesian">The 4 Rules for being a good Bayesian</a>    <ul>
      <li><a href="#probability-is-a-map-of-your-understanding-of-the-world" id="markdown-toc-probability-is-a-map-of-your-understanding-of-the-world">Probability is a map of your understanding of the world</a></li>
      <li><a href="#update-incrementally" id="markdown-toc-update-incrementally">Update incrementally</a></li>
      <li><a href="#seek-disconfirming-evidence" id="markdown-toc-seek-disconfirming-evidence">Seek disconfirming evidence</a></li>
      <li><a href="#remember-your-priors" id="markdown-toc-remember-your-priors">Remember your priors</a></li>
    </ul>
  </li>
  <li><a href="#destroying-cognitive-biases" id="markdown-toc-destroying-cognitive-biases">Destroying cognitive biases</a></li>
  <li><a href="#seeking-disconfirming-evidence-for-bayes" id="markdown-toc-seeking-disconfirming-evidence-for-bayes">Seeking disconfirming evidence for Bayes</a></li>
  <li><a href="#the-246-game-revisited" id="markdown-toc-the-246-game-revisited">The 2,4,6 Game Revisited</a></li>
  <li><a href="#the-being-late-example-revisited" id="markdown-toc-the-being-late-example-revisited">The Being Late Example Revisited</a></li>
  <li>
<a href="#getting-stronger" id="markdown-toc-getting-stronger">Getting stronger</a>    <ul>
      <li><a href="#improve-your-priors" id="markdown-toc-improve-your-priors">Improve your priors</a></li>
      <li><a href="#become-a-master-hypothesis-builder" id="markdown-toc-become-a-master-hypothesis-builder">Become a master hypothesis builder</a></li>
      <li><a href="#learn-the-math" id="markdown-toc-learn-the-math">Learn the Math</a></li>
    </ul>
  </li>
  <li>
<a href="#putting-it-all-together-in-practice" id="markdown-toc-putting-it-all-together-in-practice">Putting it all together in practice</a>    <ul>
      <li><a href="#hypotheses-with-frequencies" id="markdown-toc-hypotheses-with-frequencies">Hypotheses with frequencies</a></li>
      <li><a href="#growing-the-disk" id="markdown-toc-growing-the-disk">Growing the disk</a></li>
      <li><a href="#switching-hypotheses" id="markdown-toc-switching-hypotheses">Switching hypotheses</a></li>
      <li><a href="#strong-opinions-weakly-held" id="markdown-toc-strong-opinions-weakly-held">Strong Opinions, Weakly Held?</a></li>
    </ul>
  </li>
  <li><a href="#this-seems-very-different-to-what-i-learned-in-school" id="markdown-toc-this-seems-very-different-to-what-i-learned-in-school">This seems very different to what I learned in school</a></li>
  <li><a href="#epilogue-the-end-is-the-beginning" id="markdown-toc-epilogue-the-end-is-the-beginning">Epilogue: The End is the Beginning</a></li>
  <li><a href="#appendix-more-good-examples" id="markdown-toc-appendix-more-good-examples">Appendix: More Good Examples</a></li>
</ul>

</nav>

<!-- works only once jQuery is loaded -->


<h2 id="the-246-game">The 2,4,6 game</h2>

<p>There’s a black box with a formula inside for generating 3 numbers. Your job is to try and guess this formula. The input box below is connected to the black box. If you give it 3 numbers, it’s going to tell you whether they follow the formula or not. Separate each number with a comma.</p>

<p>To start you off, (2,4,6) follows the pattern. Try it out!</p>





<p>Did you figure it out? Write down your answer in here:</p>

<h2 id="bayes-explanation">Bayes Explanation</h2>

<p>Most people try some sequence of: (4,6,8), (1,2,3) … and end up with either increasing numbers, or increasing numbers that are even. Notice how you’re pretty confident in your answer by the time you write it down. You’ve tried a few examples, and <strong>all</strong> of them made sense!</p>

<p>But perhaps you didn’t think to try (-1,2,10) or (4,2,6).</p>

<p>If my comment made your confidence waver, go ahead and try the input box again. See if you can find a pattern that works. The answer is at the bottom of this section, but don’t skip ahead. Every sentence before that is setting up an important idea.</p>

<h3 id="bayes-theorem">Bayes Theorem</h3>

<p>If you’ve heard of Bayes theorem before, you know this formula:</p>

<p>\[ P(H \mid E) = \frac{P(E \mid H) * P(H)}{P(E)} \]</p>

<p>Indeed, that’s all there is to it. I bet you’ve also heard the famous formula: \(E = mc^2 \). That’s all there is to mass-energy equivalence. However, figuring out how to harness nuclear energy is still a hard problem. The formula made it possible, but implementing it still took 40 years.</p>

<p>It’s the same with Bayes Theorem. The formula is exciting because of what it implies. We’re discovering the nuclear energy version of Bayes Theorem.</p>

<p>Translated to English, the formula goes like this:</p>

<blockquote>
  <p>To form accurate beliefs, you always start from the information you already have. You update beliefs. You don’t discard everything you know.</p>
</blockquote>

<!-- This is Bayes Theorem. Start from a pre-existing belief, a prior, then use the new information you get to update that belief, and finally land at your new belief. -->

<!-- It's wrong to form your beliefs using just the new piece of information you see. -->

<p>The first key component is a hypothesis (H) - the belief we’re talking about.</p>

<p>The second key component is the evidence (E) - what data do we have to support / reject the hypothesis.</p>

<p>The third key component is probability (P) of the above two. This probability is our confidence in the belief.</p>

<p>If you’re familiar with probability theory, you learned this in school. If not, don’t worry, there are <a href="https://arbital.com/p/bayes_rule/?l=1zq" target="_blank" rel="noopener">excellent mathematical introductions</a> to explain it to you. We’ll skip the math, and focus on how to use it.</p>

<p>Our point of interest, and where bayes truly shines is where we compare two hypotheses. Instead of uncovering the absolute probabilities, which is hard, this focuses on how much more likely one hypothesis is, compared to another. Most reasoning in our mind takes this form.</p>

<!-- does it? - This is what makes contrast so valuable. -->

<p>In this case, the formula looks like:</p>

<p>\[ Posterior \hspace{2mm} Odds = Prior \hspace{2mm} Odds * Likelihood \hspace{2mm} Odds \]</p>

<p>Posterior odds measure how likely a hypothesis is compared to another one.</p>

<p>Prior odds measure how likely it was before we had any new evidence.</p>

<p>Likelihood odds measure how well the evidence explains the current hypothesis, compared to the other one. We’ll explore what this means with the help of examples.</p>

<p>\[ \text{Likelihood Odds} = \frac{ \text{Probability of evidence assuming hypothesis is true}}{\text{ Probability of evidence assuming competing hypothesis is true}}\]</p>

<p>We’ll start with the 2,4,6 game to show how qualitatively, math and intuition agree. Then we’ll get into a simpler example where we’re miscalibrated and do the math.</p>

<p>I’m going to choose my path through the 2,4,6 game, but I hope yours was similar enough. If not, try doing this on your own!</p>

<p>I have a hypothesis I want to test, \(H_{3even}\) = 3 even numbers in increasing order. It’s implicit here, but the hypothesis I’m testing this against is \(H_{not-3even}\), or that the formula <strong>is not</strong> 3 even numbers in increasing order.</p>

<p>I input (4,6,8) and the black box says “Yes”. My confidence in 3 even numbers rises. In Bayesian-speak, my posterior odds have increased, because the likelihood odds have increased. And the likelihood odds have increased, since the probability of (4,6,8) saying “Yes” is higher when the formula is \(H_{3even}\).</p>

<p>You’ll notice how <em>you feel</em> every new number that matches your hypothesis makes your belief stronger.</p>

<!-- This corresponds to a likelihood odds of greater than 1, since the belief you're testing is getting stronger. -->

<!--Too many ideas: A question to ponder here: Can (4,6,8) be acceptable in a world where \\(H_{not-3even}\\) is true? That is, the formula is not 3 even increasing numbers? This is seeking disconfirming evidence -->

<p>I try (1,2,3) next. “Yes”. What? I expected “No”!</p>

<p>Everything tumbles, like it should, when you find something that doesn’t follow the pattern. The probability of (1,2,3) saying “Yes” is higher with \(H_{not-3even}\), since (1,2,3) are not all even. The likelihood odds are in favour of \(H_{not-3even}\) now, which means we discard \(H_{3even}\). In this case, one small piece of evidence was enough to completely flip the scales.</p>

<p>Then, which new hypothesis should you try? The clues usually lie in how you disproved the previous hypothesis.</p>

<p>I tried (1,2,3) which said “Yes”, when I expected it to say “No”. My new hypothesis thus became “3 increasing numbers”.</p>

<p>Just like in the previous case, (4,2,6) saying “Yes” killed this hypothesis. My new hypothesis thus became “3 positive numbers”.</p>

<p>I tried (-1,2,3), which said “No”! This was all I needed to become reasonably confident in “3 positive numbers”. The more negative numbers I tried, the more confident I got.</p>

<p>3 positive numbers is indeed correct.<sup id="fnref:6"><a href="#fn:6">1</a></sup></p>

<p>Graphically, this is what’s happening with the 3 hypotheses:</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/bayes/bayes_246_confidence.jpg" alt="">
    
    
    
        <figcaption>   
            <p>confidences not calibrated</p>

        </figcaption>
    
</figure>

<div role="alert">
  <p><i></i><b>Blue Box on Can we prove something to be true with Bayes?</b><br>
No matter how much data you have, you can never say something is true. This is the problem of induction.</p>

  <blockquote>
    <p>“No amount of observations of white swans can allow the inference that all swans are white, but the observation of a single black swan is sufficient to refute that conclusion.”</p>
  </blockquote>

  <p>However, after a certain level of confidence, you live your life believing it’s true. Once you start believing is when you must pay close attention to evidence that doesn’t fit.</p>
</div>

<p>Calibration is key. What we’ve just shown is our thinking process, and how Bayes theorem is mostly aligned with it when we’re thinking well. Bayes theorem updates beliefs in the same direction our brains do, but what changes is how much each piece of evidence influences us!</p>

<p>With this next example, let’s get into the basic math. We’ll revisit the 2,4,6 game in a bit.</p>

<h3 id="being-late-example">Being Late Example</h3>

<p>Your colleague is sometimes late to work. They’ve been on time 4 times, and late 3 times the past week. How many more times would it take you to start believing they’re “always” late?</p>

<p>In my experience, just a few more times does the trick. But let’s use Bayes to calibrate.</p>

<p>Since there’s no good reason to expect tardiness over punctuality, let’s say the prior odds are 1:1.<sup id="fnref:13"><a href="#fn:13">2</a></sup> The alternative hypothesis, the one we’re testing against is “not always being late”. To make this more concrete, let’s say this means they’re late only 10% of the time.<sup id="fnref:2"><a href="#fn:2">3</a></sup></p>

<p>We’ll use the data we have to calculate the likelihood of being late. We want to contrast
<span>the data<span>being late thrice, and on time 4 times</span></span>
with us believing that they’re almost always on time, or almost always late. Remember, to figure this out, we imagine believing the first hypothesis, then judge how likely the data is. Then, we imagine believing the second hypothesis, and judge how likely the data is.</p>

<figure>
    
    <img src="https://neilkakkar.com/assets/images/bayes/bayes_likelihood_calc.jpg" alt="">
    
    
    
</figure>

<p>There are several ways to mathematically represent this data, from a binomial function to a beta distribution. However, we’re not getting into that yet. Today is more about an intuitive explanation, one which you’re more likely to use …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html">https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html</a></em></p>]]>
            </description>
            <link>https://neilkakkar.com/Bayes-Theorem-Framework-for-Critical-Thinking.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24058247</guid>
            <pubDate>Wed, 05 Aug 2020 07:45:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Should You Not Use Rails?]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24057715">thread link</a>) | @luu
<br/>
August 4, 2020 | http://codefol.io/posts/when-should-you-not-use-rails/ | <a href="https://web.archive.org/web/*/http://codefol.io/posts/when-should-you-not-use-rails/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <!-- .post-header -->
            <div>
                  
<figure>
    <p><img src="http://codefol.io/img/chimp_keyboard_aside_216_135.png" alt="A chimpanzee in a white coat types at a keyboard lit by glowing LEDs." width="216" height="135" title="He's gorgeous, yes. But is his talent natural&amp;hellip; or is it Ruby on Rails?">
    </p>

      <figcaption>
        He's gorgeous, yes. But is his talent natural… or is it Ruby on Rails?
        
        
      </figcaption>
</figure>

                <p>I was <a href="https://www.codewithjason.com/rails-with-jason-podcast/noah-gibbs-3/">recently on Jason Swett’s podcast again</a>. He’s a great interviewer and I always have fun with him.</p>

<p>By Twitter request we talked about… When would you <strong><em>not</em></strong> use Rails? It’s a great question.</p>

<p>For the entertaining version, <a href="https://www.codewithjason.com/rails-with-jason-podcast/noah-gibbs-3/">listen to the podcast</a>. For the just-the-facts extra-complete version, I’m writing this post.</p>

<h2>When Is Rails the Wrong Choice?</h2>

<p>I’ll start with a few simple, obvious times you wouldn’t use Rails, and then I’ll talk about some technically interesting times.</p>

<p>First, and most important, is team familiarity. If your team doesn’t already know Rails and isn’t especially interested in learning it then Rails is the wrong choice. This should be obvious, but it still deserves first billing.</p>

<p>Second, when you know some other framework fits better. I’ll talk more below about when that is. But sometimes you have a specific concern that trumps everything else. If you need to use a Java-language machine learning library and you don’t want to use JRuby for some reason, Rails isn’t your framework. If you’re writing a WordPress plugin, you’ll be doing it in PHP. Often there’s one specific compatibility concern that overrides everything else.</p>

<p>You can also think of it as: use it where Rails’ good points hold and its bad points don’t. So we’ll also talk about the good and bad points.</p>

<p>Separately: you’d normally only use Rails as an HTTP server, so some tasks just aren’t Rails-shaped.</p>

<h2>When is Rails Too Much?</h2>

<figure>
    <a href="https://rubymadscience.com/img/assistant_pirate_with_sphere_bigthumb.png">
      <img src="https://rubymadscience.com/img/assistant_pirate_with_sphere_bigthumb.png" alt="A pirate puppet with an eyepatch, safety goggles and a huge scraggly mustache watches over a purple crystal ball at his feet.'" title="He's too much lab assistant for your lab.">
    </a>
        <figcaption>He’s too much lab assistant for your lab.</figcaption> 
</figure>

<p>Some places not to use Rails can include:</p>

<p><strong>Really Small Tasks that Won’t Grow</strong>: if a server does very little, Rails is often too much. Not going to touch a database? Then the DB setup isn’t helping you, is it? Just a tiny low-traffic intermediate server with no caching? A lot of Rails is more trouble than it’s worth.</p>

<p>Be careful with tasks that grow, though — making a tiny server scale up to do a lot more can be ugly. If you’re already serving HTTP pages to a human with a web browser, consider that you may have to add features to it later. Something like <strong><em>that</em></strong> is already fairly large from the word “go”.</p>

<p><strong>When It’s ‘Just’ an API Server</strong>: Rails has less to offer an API server that speaks JSON over the wire. A lot of its HTTP security doesn’t matter for that case (e.g. SQL injection safeguards, XSS prevention.) While ActiveRecord can be nice for some database use cases, Rails really shines when you’re building an HTML site that talks to browsers. Very small projects that mostly speak a structured format read by machines will often get less from Rails.</p>

<p>Related to that is when you’re doing in-browser rendering and Rails is ‘just’ serving JSON. It’s a weird kind of in-between case. A lot of Rails security and convenience functions no longer help you, but you’re still doing things where internal libraries (ActiveRecord, ActiveJob, ActionMailer) can be highly useful. But if you’re never rendering HTML on the server and you’re very sure you never will, Rails will probably help you less.</p>

<h2>When Is Rails Not Enough?</h2>

<p>Rails is also designed for a small team and a medium-sized codebase. A huge team (lots of programmers) or a huge codebase (lots of controllers, models and/or lines of code) will tend to drag down the standard Rails-app structure.</p>

<p>Ruby allows for a <strong><em>lot</em></strong> of <a href="https://en.wikipedia.org/wiki/Side_effect_(computer_science)">non-local effects</a>. Whether that’s monkeypatching, writing to a database or creating new types at runtime, Ruby isn’t designed for a team of 200 programmers where you don’t trust some of them. There are too many ways for them to cause you trouble. You can use <a href="https://sorbet.org/">good tooling</a> to scale Ruby to larger teams, but even that will <a href="https://sorbet.org/docs/troubleshooting#escape-hatches">tend to have exceptions and difficulties</a>. That’s not really Ruby’s sweet spot.</p>

<p>In most cases you can cut up a large project into smaller projects. If one Rails app is too big, you can often separate it into multiple apps, or a thinner app with more back-end services, or an app and a separate microservice, or… One way or another there is usually a way to separate out smaller pieces. Ruby strongly encourages that, as do I.</p>

<p>There are also not-quite-Rails structures that can scale better. Avdi Grimm’s (now retired) <a href="https://www.goodreads.com/book/show/13481927-objects-on-rails">Objects on Rails</a> was an attempt in that direction, as is <a href="https://medium.com/@vsavkin/hexagonal-architecture-for-rails-developers-8b1fee64a613">the Hexagonal architecture for Rails</a>, which in turn has a lot in common with the older and more general <a href="https://en.wikipedia.org/wiki/Multitier_architecture">N-tier architecture</a>.</p>

<p>But at some point you might want to consider a different framework. <a href="https://hanamirb.org/">Hanami</a> is an obvious choice, designed to be less quick and nimble than Rails for getting a tiny app off the ground, but more scalable if you want to use the same code with a lot more contributors.</p>

<p>I’d still start out in Rails, personally. If you’re building something quickly to see if anybody cares, I know of no framework that comes close to its productivity. Wait to rewrite (in a more rigid framework) until you’re successful and you can afford the drag on your development speed.</p>

<p>The other worry here can be performance. If you’re rewriting a project that is already as large as the current Basecamp… then you’re <a href="https://m.signalvnoise.com/only-15-of-the-basecamp-operations-budget-is-spent-on-ruby/">actually fine for performance</a>. Rails still scales <strong><em>great</em></strong> for them. But if you’re looking at something a hundred times larger (which by definition means B2C, not B2B) then you might have a situation where your server costs are substantially greater than your engineering payroll. In that case it can make sense to slow down your engineers to pay lower server costs. To check this, see what your EC2-or-equivalent costs are <strong><em>just for your application servers</em></strong>, which are what run Rails. And check your payroll <strong><em>just for web engineers</em></strong>, which is who writes in Rails. Normally the engineering payroll is much larger and you should stick with trading cheap machine time for expensive engineering time. But at some point the balance may tip and you should consider raising your engineering payroll to cut your server costs.</p>

<h2>When Does Rails Have the Wrong Assumptions?</h2>

<figure>
    <a href="https://rubymadscience.com/img/dr_bear_microscope_bigthumb.png">
      <img src="https://rubymadscience.com/img/dr_bear_microscope_bigthumb.png" alt="A pirate, a bear and a chimp sit at a wicker table. The bear looks into a very old-fashioned microscope as the other two look on." title="They're checking the microscope for real-world use cases where Rails might be wrong.">
    </a>
        <figcaption>They’re checking the microscope for real-world use cases where Rails might be wrong.</figcaption> 
</figure>

<p>Before checking if Rails’ assumptions are right for you, we should see what those assumptions actually are.</p>

<p>Before you take my word for it, I recommend taking <a href="https://rubyonrails.org/doctrine/">David Heinemeier Hansson’s word for it</a> in the form of The Rails Doctrine. It’s a great document and it covers a lot of ground.</p>

<p>Indeed, if you want to better understand why Rails isn’t amazing for large, low-trust teams, you should read <a href="https://rubyonrails.org/doctrine/#provide-sharp-knives">“Provide Sharp Knives”</a> in the Rails Doctrine several times. A lot of Rails’ tradeoffs are entirely by design.</p>

<p>Rails also has some simpler assumptions: it assumes you’re writing an interactive app with server-rendered HTML. It assumes that security is vital (Rails trades a lot for security) but that you don’t want to build your own custom security system in most cases. And it assumes that you either have a small, excellent team doing prototyping work (“Provide Sharp Knives”) or that you have a possibly-mediocre team that needs powerful built-in guidelines (<a href="https://rubyonrails.org/doctrine/#omakase">“The Menu is Omakase.”</a>)</p>

<p>Rails also assumes you want high developer velocity at a cost of technical debt. In other words, it’s designed for building very quickly. That makes sense when <strong><em>technical execution is not your biggest risk</em></strong>. For instance: if you’re building a small startup, and you’re pretty sure you can build the site but people may not buy your product, you are dominated by market risk. That’s when Rails is perfect. You want to build very quickly. And even if you build perfectly, you’re probably going to have to throw away the result for nontechnical reasons, like “people don’t want to buy it.”</p>

<p>As part of “high dev velocity, technical debt is okay” Rails assumes things like, “you’ll want to use a lot of gems” and “dependencies that work are fine if they speed you up.”</p>

<p>Rails assumes you don’t mind scaling out application servers horizontally (by bringing more of them online.) It’s designed to scale well <strong><em>if</em></strong> you can do that. Rails assumes CPU is fairly cheap and it’s usually right about that. Relatedly, Rails assumes that the database is usually your most serious performance bottleneck, which is how web applications usually work.</p>

<p>Rails also assumes you’ll have some calculation or data transformation in your application. It assumes that it’s okay to use some CPU because you’ll be doing that anyway.</p>

<p>(When does that last assumption matter? Let’s talk about Evented Servers and see.)</p>

<h2>What Isn’t Rails Good At?</h2>

<figure>
    <a href="http://codefol.io/posts/when-should-you-not-use-rails/node_js_logo.png">
      <img src="http://codefol.io/posts/when-should-you-not-use-rails/node_js_logo.png" alt="The Node.js logo." title="Sometimes you need it, or something like it.">
    </a>
        <figcaption>Sometimes you need it, or something like it.</figcaption> 
</figure>

<p>While Rails is great at a lot of things, there’s one particular task that it’s not amazing for: shim servers.</p>

<p>By “shim servers” I mean servers that do very little calculation but integrate answers from a few other back-end services and relay the result. Imagine a server that queries two JSON services and combines the result with simple string-manipulation, for instance. It does very little calculation, but it juggles a lot of events.</p>

<p>And that’s the relevant word: “events.”</p>

<p>There is a specific kind of app architecture embodied by Node.js and its relatives called “Evented” programming. It can support many thousands, or even millions, of simultaneous connections with a tiny amount of server resources. It can be both high-throughput and low-latency. Its benchmark numbers are matchless… for the cases where it works.</p>

<p>Rails can’t match Evented programming at what Evented programming is good at. Basically no framework can. There are Evented frameworks for Ruby (e.g. <a href="https://github.com/eventmachine/eventmachine">EventMachine</a>, <a href="https://github.com/socketry/async">Async</a>.) Rails is built differently.</p>

<p>If Evented is so much better, why don’t we use it for everything? Because it doesn’t work for everything. I emphasise calculation per-request because an Evented server will fall down and die if you try to make it do very much calculation per-request. Having one server handle a million connections is no good if each connection …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://codefol.io/posts/when-should-you-not-use-rails/">http://codefol.io/posts/when-should-you-not-use-rails/</a></em></p>]]>
            </description>
            <link>http://codefol.io/posts/when-should-you-not-use-rails/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24057715</guid>
            <pubDate>Wed, 05 Aug 2020 06:03:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fundamental Axiom of Floating Point Arithmetic]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24057293">thread link</a>) | @johnbcoughlin
<br/>
August 4, 2020 | http://www.johnbcoughlin.com/posts/floating-point-axiom/ | <a href="https://web.archive.org/web/*/http://www.johnbcoughlin.com/posts/floating-point-axiom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
            

            

<p>If you’ve been a software engineer for long enough, it is very likely that you’ve seen this example of floating point perfidy:</p>
<div><pre><code data-lang="python">&gt;&gt;&gt; <span>3.0</span> / <span>10</span>
<span>0.3</span>
&gt;&gt;&gt; <span>0.1</span> * <span>3</span>
<span>0.30000000000000004</span>
</code></pre></div><p>We understand that this is due to the fact that floating point numbers, stored
with only 64 bits of precision, cannot represent the entire real number line.
Moreover, when we perform operations with these floating point numbers, the
errors inherent in their representation can accumulate and multiply. The moral
of the story is, never use a floating point number to represent money.</p>
<p>At least, that is the moral for financial applications. At Square, we used a
<code>long amount_cents</code>, and we got along with our lives. However, for most
applications that have a good reason to use floating point, this can’t be the
end of the story. If floating point were the unpredictable, unreliable thing
that I once believed it to be, we wouldn’t be able to numerically solve
differential equations, or linear systems, or land on the moon. Rather, there is
a science of floating point error, forming part of a science of numerical errors
in general, which seeks to tame and understand what happens to errors as they
flow through our calculations. In general, numerical error is something that can
be rather precisely quantified, as we’ll see. Along the way we’ll look at the
Fundamental Axiom of Floating Point Arithmetic, which, at the very least, sounds
way cooler than “10 things every developer should know about floating point
numbers”.</p>
<h2 id="machine-epsilon">Machine Epsilon</h2>
<p>Fundamentally, error in floating point is due to the problem of “roundoff”. Just as in base 10, we cannot represent the
number \(1/3\) without rounding it off somewhere:</p>
<p>\begin{equation*}
\frac{1}{3} = 0.33333333333333 \dots \approx 0.33333333,
\end{equation*}</p>
<p>in base 2, we cannot represent many numbers without rounding. Of course, some numbers we <em>can</em> represent exactly. The
number 1, for example. Or any integer in the range \((-2^{53}, 2^{53})\). Also notably, many fractions can be exactly
represented:</p>
<p>\begin{align*}
\frac{1}{2} &amp;= 0.1_2 \\\<br>
\frac{3}{4} &amp;= 0.11_2 \\\<br>
\frac{17}{8} &amp;= 10.001_2 \\\<br>
&amp;\vdots
\end{align*}</p>
<p>However, a number like \(1/10\), just like \(1/3\) in base 10, must be truncated to fit in the 24 or 53 bits of the
<a href="https://en.wikipedia.org/wiki/Significand">mantissa</a>. When we enter <code>0.1</code> in a console or in source code, the value that is <em>actually stored</em> is very slightly
different than <code>0.1</code>. According to this excellent <a href="https://www.exploringbinary.com/floating-point-converter/">IEEE-754 Floating Point Converter</a>, the floating point number that is
actually stored (for 64-bit floating point) is</p>
<p>\begin{align*}
&amp;(0.0001100110011001100110011001100110011001100110011001101)_2 = \\\<br>
&amp;(0.1000000000000000055511151231257827021181583404541015625)_{10}
\end{align*}</p>
<p>So the initial input to our calculation was flawed! We weren’t calculating <code>0.1 * 3</code>, we were actually calculating</p>
<div><pre><code data-lang="python"><span>0.1000000000000000055511151231257827021181583404541015625</span> * <span>3</span>
</code></pre></div><p>How much of an error is this? We can get an idea by counting the zeros in between the significant
digits, \(0.100\dots 00055\). In this case, there are 16. So in simply entering a number which is not representable
exactly in floating point, we have incurred a relative error of roughly \(10^{-16}\).</p>
<p>Indeed, in <em>all</em> cases we can expect to incur a relative error of
roughly \(10^{-16}\). This magnitude is called machine epsilon, often
written \(\epsilon_{\text{machine}}\). It comes from the relative difference
between two successive floating point numbers. For every representable floating
point number \(x\), there is a <em>next</em> floating point number, and it is
approximately \(x + \epsilon_{\text{machine}} x\). So for an arbitrary real
number \(x_0\), it falls between two floating point values \(x\)
and \(x + \epsilon x\) (leaving off the subscript of \(\epsilon\) for conciseness). When we
represent \(x_0\) in floating point, we will get one of these two values. Let’s denote
the floating point representation of \(x_0\) by \(\text{fl}(x_0)\). The absolute
error incurred just by representing \(x_0\) in floating point is</p>
<p>\begin{equation*}
e_{\text{abs}} = |\text{fl}(x_0) - x_0| \leq \max(|x_0 - x|, |x_0 - (x + \epsilon x)|) \leq |\epsilon x|.
\end{equation*}</p>
<p>The relative error, then, i.e. the absolute error divided by the true value, is</p>
<p>\begin{equation*}
e_{\text{rel}} = \frac{e_{\text{abs}}}{x_0} \leq \frac{|\epsilon x|}{x_0} \approx \epsilon.
\end{equation*}</p>
<p>Cool! So we’ve seen that the worst we can do, in relative terms, when representing a floating point number, is
approximately \(10^{-16}\). This is, for almost all practical purposes, <em>very good</em>. Because remember, we’re speaking of
a relative error. That means we’re able to represent even very small values, very accurately. Here’s the nearest floating point
number to \(10^{-20}\):</p>
<p>\begin{equation*}
0.000000000000000000009999999999999999451532\dots
\end{equation*}</p>
<p>If you’re curious, I invite you to count the 9’s. There are 16 of them. Even when dealing with extremely small numbers,
we maintain the same relative precision.</p>
<h2 id="the-fundamental-axiom-of-floating-point-arithmetic">The Fundamental Axiom of Floating Point Arithmetic</h2>
<p>Now you might be thinking, wait! It’s all good and well that we can get excellent relative accuracy when <em>representing</em>
floating point numbers, but what about when we go to <em>do</em> something with them? Here we’ve got two floating point
numbers, both of which are inexact, and we’re about to multiply them! Who knows what might happen?</p>
<p>This concern is well-founded, because the algorithms of floating point arithmetic must be implemented with finite
precision. If we are asked to multiply two large numbers with pen and paper, the algorithm that most
of us will use is the one we learned in school, which involves lots of addition, carrying, sub-multiplications, and so
on. If all of those intermediate steps are using some kind of binary representation, then the intermediate products may
be losing precision as we go along! This seems like a recipe for disaster. Fortunately, there is a property that we can
require of a floating point implementation, one which is satisfied by IEEE-754 and most other popular floating point
standards, that will save us from total anarchy. This is what Trefethen and Bau, <em>Numerical Linear Algebra</em>, refer to
as the <strong>Fundamental Axiom of Floating Point Arithmetic</strong>:</p>
<blockquote>
<p>All floating point arithmetic operations are exact up to a relative error of \(\epsilon_{\text{machine}}\).</p>
</blockquote>
<p>This means that for any two floating point numbers, say \(x\) and \(y\), any operation involving them will give a floating
point result which is within a factor of \(1 + \epsilon_{\text{machine}}\) of the true result. This is easiest to
understand if we use a special notation to represent the floating point version of, say, \(+\). Let’s write \(\oplus\) to
denote floating point addition, and \(+\) to denote exact addition. Then the Fundamental Axiom tells us,</p>
<p>\begin{equation*}
\frac{|(x \bigoplus y) - (x + y)|}{x + y} \leq \epsilon_{\text{machine}}.
\end{equation*}</p>
<p>Remember, \(x\) and \(y\) are exactly representable as floating point numbers, but of course they are also, mathematically,
just real numbers. So \(x + y\) is a real number (point on the number line), which <em>may not be exactly representable in
floating point</em>. The Fundamental Axiom is telling us that the floating point operation \(\oplus\) can do no worse than
simply trying to represent the number \(x + y\) as a floating point value directly, assuming our computer had access to the
mathematical, infinite precision object \(x + y\).</p>
<p>Put another way, we incur no extra error by going through floating point
arithmetic than we would by using a magical computer to do exact arithmetic on
our floating point values and then casting back to floating point. In
mathematical terms,</p>
<p>\begin{equation*}
\frac{\left|(\text{fl}(a) \oplus \text{fl}(b)) - (a + b)\right|}{a + b} \approx \frac{\left|\text{fl}(\text{fl}(a) + \text{fl}(b)) - (a + b)\right|}{a + b} \approx \epsilon_{\text{machine}}.
\end{equation*}</p>
<p>Recall that \(\text{fl}(a)\) is the mathematical number we actually represent when
we try to represent \(a\) in floating point. So the first fraction gives the
relative error from performing \(\oplus\) on the floating point representations
of \(a\) and \(b\), and the second fraction gives the relative error from performing
the exact arithmetic operation, \(+\), on the floating point representations
of \(a\) and \(b\), then casting the result to floating point.</p>
<h2 id="error-analysis">Error Analysis</h2>
<p>The Fundamental Axiom of Floating Point Arithmetic allows us to analyze the numerical error that may be incurred by even
complex arithmetic operations. To see an idea of how this works, let’s consider the problem of computing the length of a
2D vector, \([x, y]\). Mathematically, this has the form</p>
<p>\begin{equation*}
d = \sqrt{x^2 + y^2}.
\end{equation*}</p>
<p>There are several stages to the computation, and at each one we will incur a little bit of numerical error:</p>
<ul>
<li>Enter the numbers \(x\) and \(y\) into the computer, incurring roundoff error.</li>
<li>Compute \(x^2\) and \(y^2\), using floating point multiplication.</li>
<li>Compute \(x^2 + y^2\), using floating point addition.</li>
<li>Compute \(\sqrt{x^2 + y^2}\), using the floating point square root operation.</li>
</ul>
<p>At each step, the result we get will be equal to the true result, times some error factor \((1 + \epsilon)\), where
each \(\epsilon\) is very small, on the order of \(\epsilon_\text{machine}\). Each operation may have a different
error \(\epsilon\), but we’ll use the same symbol for all of them. We don’t care so much about the exact value
of \(\epsilon\), only that it is very small.</p>
<p>We’re going to carry these \(\epsilon\) through the computation to see how they
affect the final result. To make that easier, we can use special rules of arithmetic to manipulate \(\epsilon\):</p>
<ul>
<li>\(\epsilon^2 = 0\). If \(\epsilon \approx 10^{-16}\), then \(\epsilon^2 \approx 10^{-32}\), which is so small that we just
decide to completely ignore it.</li>
<li>\((1 + \epsilon)^2 = 1 + 2\epsilon + \epsilon^2 = 1 + 2\epsilon\).</li>
<li>\(\sqrt{1 + \epsilon} = 1 + \frac{\epsilon}{2} - …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.johnbcoughlin.com/posts/floating-point-axiom/">http://www.johnbcoughlin.com/posts/floating-point-axiom/</a></em></p>]]>
            </description>
            <link>http://www.johnbcoughlin.com/posts/floating-point-axiom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24057293</guid>
            <pubDate>Wed, 05 Aug 2020 04:41:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Insurers are putting the lives of sick and disabled at risk during COVID-19]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24056932">thread link</a>) | @Abishek_Muthian
<br/>
August 4, 2020 | https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This is about Insurance companies in India, their behaviour with customers with preexisting illness. Incase you are not from India, you might still find this content useful as almost all of these companies are in tie-up with a major international insurer whom you might have your policy with.</p><p>I’m suffering from what could be best summarised in simple terms as <strong><em>Bone related diseases</em></strong>, I had a <a href="https://abishekmuthian.com/i-was-told-i-would-become-quadriplegic-68c0371e6f05/" target="_blank">major surgery in July 2018</a> for ailments which has since been successfully addressed. I’ve been very open about my health condition to raise awareness and to support others facing such ailments.</p><p>Like many others during this COVID-19 pandemic, I applied for a health insurance top-up plan as my current base plan(subscribed ~5 years ago, much before 2018 surgery) doesn’t have the necessary coverage to compensate for the amount of money private hospitals are charging for COVID-19 treatment.</p><p><amp-accordion id="MAX-healthcare-accordian" disable-session-states=""><section><h5>How much a private hospital in India charges for COVID-19 treatment?(Click to see the .jpg)</h5><amp-img alt="How much money a private hospital in India charges for COVID-19 treatment?" src="/images/covid-19-treatment-charges.jpg" width="720" height="1034" layout="responsive"></amp-img></section><section><h5>After the above picture went viral on social networks and received widespread criticism, the hospital released the following tweet.(Click to see the .jpg)</h5><amp-twitter width="375" height="472" layout="responsive" data-tweetid="1271412049042534400"></amp-twitter></section></amp-accordion></p><p>Since I’m an independent professional, I’m not covered under any corporate health insurance and so I had to apply for a personal health insurance policy.</p><p>I approached the <a href="https://www.livemint.com/insurance/news/choose-from-india-s-best-health-policies-1569141812779.html" target="_blank">top health insurance providers in the country</a> <a href="http://archive.is/DbkXk" target="_blank">[archive]</a>, as I believed they would be following government’s guidelines regarding preexisting diseases for health insurance. I was proven wrong.</p><h3 id="irdai-guidelines-on-preexisting-diseases">IRDAI Guidelines on preexisting diseases</h3><p>Insurance Regulatory and Development Authority(IRDAI) is Indian government’s regulatory body for insurance and re-insurance industries in India.</p><p>IRDAI had released several advisories regarding how the health insurance companies should treat customers with preexisting illness.</p><ul><li>Preexisting diseases (PED) means any condition <strong><em>“that is/are diagnosed by a physician within 48 months prior to the effective date of the policy issued by the insurer or its reinstatement, or for which medical advice or treatment was recommended by, or received from, a physician within 48 months prior to the effective date of the policy issued by the insurer or its reinstatement.”</em></strong> - <a href="https://www.irdai.gov.in/ADMINCMS/cms/whatsNew_Layout.aspx?page=PageNo4048&amp;flag=1" target="_blank">Amendments_guidelines_excl_std20200210.pdf</a> <a href="http://archive.is/fl97m" target="_blank">[archive]</a>.</li></ul><p>So what happens when you have preexisting disease while applying for a health insurance?</p><ul><li>The PED are excluded during the waiting period(maximum of 4 years). Some PEDs can be permanently excluded from the coverage of the policy - <a href="https://www.irdai.gov.in/ADMINCMS/cms/whatsNew_Layout.aspx?page=PageNo3916&amp;flag=1" target="_blank">Guidelines on standardization of exclusions in HI Contracts.pdf</a> <a href="http://archive.vn/fkoEg" target="_blank">[archive]</a>.</li></ul><p><em>Note: Even permanent exclusion means those diseases are excluded from the coverage of the insurance policy and doesn’t mean you should be denied the policy itself.</em></p><h3 id="insurance-providers-are-not-following-irdai-guidelines">Insurance providers are not following IRDAI guidelines</h3><p>In spite of advertising waiting period for PEDs on their websites, I found out that these insurers are blatantly disregarding the IRDAI guidelines w.r.t PEDs even when they advertise ‘<em>waiting period</em>’ on their websites.</p><p>The following insurers denied me the insurance policy citing my preexisting illness, even after I pointed out the IRDAI guidelines and raised a complaint with IRDAI’s grievances cell.</p><p>Some went took extraordinary measures to deny me the policy, even after conducting a thorough medical test in which their own doctor certified me as healthy for the policy. Some, didn’t even bother to conduct an underwriter call and denied me the policy from my stated PEDs in the application after receiving the premium payment.</p><p>It is to be noted that, to the best of my knowledge the diseases I suffer from isn’t even permanently excluded according to IRDAI’s guidelines and even if it was the insurers are supposed to exclude it from coverage and provide me with the insurance policy.</p><h3 id="insurer-behaviour-towards-preexisting-diseases">Insurer behaviour towards preexisting diseases</h3><h4 id="royal-sundaram-general-insurance">Royal Sundaram General Insurance</h4><hr><p>After I applied for a health insurance quote on their website, Royal Sundaram’s agent called me over phone. I told him about my health condition several times, I was told that I would be given a policy with waiting period and utmost I would be required to take a medical test to show my current health condition.</p><p>The agent ensured that I applied for the policy by calling me repeatedly until one day I finally applied for the policy through their website.</p><p><amp-accordion id="Royal_Sundaram_Application-accordian" disable-session-states=""><section><h5>I did my best to state the preexisting disease in their limited text input section (Click to see the .gif)</h5><amp-img alt="Royal Sundaram health insurance preexisting disease" src="/images/RoyalSundaram_Health_Insurance_Preexisting_Disease-1.gif" width="1047" height="961" layout="responsive"></amp-img></section></amp-accordion></p><p><em>Note: The diseases I mention in the preexisting diseases column are what mentioned in my discharge summary of my 2018 surgery.</em></p><p><amp-accordion id="Royal_Sundaram_Application-accordian" disable-session-states=""><section><h5>Selected the relevant options related to my health condition(Click to see the .gif)</h5><amp-img alt="Royal Sundaram health insurance preexisting disease" src="/images/RoyalSundaram_Health_Insurance_Preexisting_Disease-2.gif" width="1047" height="961" layout="responsive"></amp-img></section></amp-accordion></p><p>After couple of days I received a call from the underwriter doctor from Royal Sundaram, I explained clearly my sickness and answered specific Yes/No questions in the call. After the call, I remembered that I’m taking treatment for Osteoporosis (Yearly single zoledronic acid inject and monthly Vitamin D tablets); So, I called the doctor again and informed him about my <em>osteoporosis</em> treatment.</p><p>A day later I was told by another representative of Royal Sundaram that I have to undergo medical tests, which I promptly agreed. My only concern was that I have to travel, visit a hospital when there was increasing number of COVID-19 cases in my city.</p><p>During the medical tests initiated by Royal Sundaram, I underwent -</p><ul><li>Blood Test</li><li>Urine Test</li><li>Thread Mill Test</li><li>Examination by Doctor</li></ul><p>During the examination by the doctor, I clearly explained my health history, I was asked to email the discharge summary of my surgery which I promptly did.</p><p>Few days later I received a mail from Royal Sundaram’s medical team to submit my discharge summary, follow-up medical checkups regarding my surgery.</p><p><amp-accordion id="Royal_Sundaram_follow-up-details-accordian" disable-session-states=""><section><h5>Letter asking for further documents regarding my 2018 surgery(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram Letter asking for futher documents regarding my 2018 surgery" src="/images/PC08491910_Add info pending_20200703013125.jpg" width="1240" height="1754" layout="responsive"></amp-img></section></amp-accordion></p><p>I promptly mailed them my discharge summary along with the latest follow-up report in which the <strong><em>doctor has mentioned that my implant status as good</em></strong>.</p><p><em>Note: I had also sent my discharge summary to the doctor who examined me at the hospital where the medical tests were conducted.</em></p><p><amp-accordion id="Royal_Sundaram_follow-up-report-accordian" disable-session-states=""><section><h5>Latest follow-up report regarding my surgery(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram Letter asking for futher documents regarding my 2018 surgery" src="/images/Follow-up-report-Abishek_Muthian -surgery.jpg" width="1799" height="2730" layout="responsive"></amp-img></section></amp-accordion></p><p>After couple of days, I was greeted with this letter in email from Royal Sundaram - (Markings in RED are mine)</p><p>I requested them several times to follow the IRDAI guidelines in providing me a waiting period regarding preexisting disease and to remove the diseases I don’t suffer from. They maintained that they have the right to reject my application and <strong>didn’t use the term <em>‘waiting period’</em> in any of their communication to me after rejection of my insurance proposal.</strong></p><p>I had no choice but to raise a complaint with IRDAI on Royal Sundaram through their <a href="https://www.irdai.gov.in/ADMINCMS/cms/NormalData_Layout.aspx?page=PageNo225&amp;mid=14.2" target="_blank">grievances cell</a>.</p><p>Through that complaint I requested Royal Sundaram for the following -</p><ul><li>To provide me a policy with waiting period(if necessary) in accordance with IRDAI’s guidelines.</li><li>Fix the misrepresentation of my diseases.</li><li>Provide me with the medical report of the tests conducted by Royal Sundaram.</li></ul><p>After escalation, numerous calls to the IRDAI’s grievances cell, I was provided with the medical tests report from Royal Sundaram.(Markings in RED are mine)
<amp-img alt="Royal Sundaram medical test report - doctor statement" src="/images/PC08491910-doctor-report-2.jpg" width="1127" height="1686" layout="responsive"></amp-img></p><p><em>Note: I noticed the wrong height mentioned in the medical test report only at the time writing this. So I didn’t raise this in my conversations with Royal Sundaram team.</em></p><p><amp-accordion id="Royal_Sundaram_blood-urine-tmt-report-accordian" disable-session-states=""><section><h5>Their Blood test report shows I'm healthy(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram blood test report" src="/images/PC08491910-blood-test-report.jpg" width="1275" height="2100" layout="responsive"></amp-img></section><section><h5>Their Urine test report shows I'm healthy(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram blood test report" src="/images/PC08491910-urine-test-report.jpg" width="1275" height="2100" layout="responsive"></amp-img></section><section><h5>Their Thread Mill test report shows I'm(my heart is) healthy(Click to see the .jpg)</h5><amp-img alt="Royal Sundaram blood test report" src="/images/PC08491910-TMT-test-report.jpg" width="2100" height="1275" layout="responsive"></amp-img></section></amp-accordion></p><p>Royal Sundaram never specifically answered why they denied me the policy even after their own doctor certified me to be healthy, But they sent me a revised rejection letter correcting one of the wrong diseases.</p><p>Open questions regarding the revised rejection letter -</p><ul><li>Why are the same diseases duplicated with different terms, Is this intentional misrepresentation to increase the number of Reason/s?</li><li>There is no cure for Achondroplasia, it is not a life threatening disease and it is not even part of permanent exclusion of coverage according to IRDAI’s guidelines on exclusions.</li></ul><p>In spite of repeatedly asking these questions through IRDAI’s grievances cell, Royal Sundaram’s grievances team sent me the same reply referring me to the revised rejection letter.</p><p>IRDAI grievances cell has told me that, there’s nothing else they can do about this, they asked me to take Royal Sundaram Insurance to the court mentioning this complaint token number, in spite of repeatedly agreeing to me over the calls that the Insurer is obliged to provide me a with an insurance policy with appropriate waiting period.</p><p><amp-accordion id="Royal_Sundaram_irdai-complaint-history-accordian" disable-session-states=""><section><h5>IRDAI complaint history on Royal Sundaram(Click to see the .png)</h5><amp-img alt="IRDAI complaint history on Royal Sundaram" src="/images/Royal-Sundaram-IRDAI-Complaint-History.png" width="1031" height="748" layout="responsive"></amp-img></section></amp-accordion></p><h4 id="icici-lombard-general-insurance">ICICI Lombard General Insurance</h4><hr><p>The events with ICICI Lombard cannot be told without the huge payment related hassle I had with it.</p><p>But first, lets see what it says about preexisting illness on its website -</p><p>Of course it claims to cover preexisting illness after the waiting period of 2 years, not only that it has loads of articles on preexisting illness like this with the header <em>‘Avail Health Insurance even with Pre-Existing Condition’</em>.</p><p>I applied for the <em>health booster</em> top-up insurance policy on the ICICI Lombard website after declaring my preexisting illness and made my payment through their ‘Guest’ login option.</p><p><strong><em>No policy proposal number was generated after the payment.</em></strong></p><p><amp-accordion id="ICICI-Lombard-health-insurance-application-accordian" disable-session-states=""><section><h5>Declaring preexisting illness in the application at ICICI Lombard website(Click to see the .gif)</h5><amp-img alt="Declaring preexisting illness in the application at ICICI Lombard website" src="/images/ICICI-Lombard-preexisting-illness-application-website.gif" width="1419" height="971" layout="responsive"></amp-img></section><section><h5>Making payment at ICICI Lombard website as Guest(Click to see the .png)</h5><amp-img alt="Making payment at ICICI Lombard website as Guest" src="/images/ICICI-Lombard-payment-website.png" width="1289" height="572" layout="responsive"></amp-img></section><section><h5>ICICI Lombard health insurance no proposal number generated(Click to see the .png)</h5><amp-img alt="ICICI Lombard health insurance no proposal number generated" src="/images/ICICI-Lombard-No-Proposal-No.png" width="1419" height="971" layout="responsive"></amp-img></section></amp-accordion></p><p>I wrote to the customer support of ICICI Lombard attaching the email I received from them after payment, asking why no proposal number was generated for my policy.</p><p>After several calls and emails they told me that they were unable to find my payment and asked me to send the bank transaction details, which I did.</p><p>After couple of days, <strong>they wanted my complete bank statement</strong>!</p><p>I asked them, why they needed my complete bank statement in spite …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/">https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/</a></em></p>]]>
            </description>
            <link>https://abishekmuthian.com/insurers-are-putting-the-lives-of-sick-and-disabled-at-risk-during-covid-19-pandemic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24056932</guid>
            <pubDate>Wed, 05 Aug 2020 03:14:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Functional Programming with Bananas, Lenses, Envelopes and Barbed Wire]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24056901">thread link</a>) | @behnamoh
<br/>
August 4, 2020 | https://research.utwente.nl/en/publications/functional-programming-with-bananas-lenses-envelopes-and-barbed-w | <a href="https://web.archive.org/web/*/https://research.utwente.nl/en/publications/functional-programming-with-bananas-lenses-envelopes-and-barbed-w">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-content" role="main">
        
    <div>
        <section data-stickyheader="">
            
        


<div>
    <div>
        <div>
            
            <p>Erik Meijer, J. Hughes (Editor), M.M. Fokkinga, Ross Paterson</p>
            
            <p><span>Research output<span>: </span></span><span>Contribution to conference<span> › </span></span><span>Paper</span></p>
        </div>

        











    <div>
        
            <div>
                
                    <div>
                        
                            <p><span>306</span>
                                
                                <span>Citations
(Scopus)</span>
                            </p>
                        
                        
                            <p><span aria-label="Total downloads for this work">4183</span>
                                <span>Downloads
(Pure)</span>
                            </p>
                        
                    </div>
                
                
                    
                
            </div>
        
    </div>


    </div>

</div>


    
        </section>

        <div id="main-content">
            
        <section>
            <div>
                <div>
                    <div>
                        
                            <h3>Abstract</h3>
                        <div><p>We develop a calculus for lazy functional programming based on recursion operators associated with data type definitions. For these operators we derive various algebraic laws that are useful in deriving and manipulating programs. We shall show that all example functions in Bird and Wadler's "Introduction to Functional Programming" can be expressed using these operators.</p></div>
                        
                        


                        

                    </div>

                    
                </div>
            </div>
        </section>
        

        
        <section>
            <div>
                <div>
    <h2>Cite this</h2>
    <ul role="tablist" aria-label="Cite this">
        
            <li role="tab" id="tab-0" aria-controls="#cite-apa" tabindex="0" aria-selected="true">
            <span>APA</span>
            </li>
        
            <li role="tab" id="tab-1" aria-controls="#cite-author" tabindex="-1" aria-selected="false">
            <span>Author</span>
            </li>
        
            <li role="tab" id="tab-2" aria-controls="#cite-BIBTEX" tabindex="-1" aria-selected="false">
            <span>BIBTEX</span>
            </li>
        
            <li role="tab" id="tab-3" aria-controls="#cite-harvard" tabindex="-1" aria-selected="false">
            <span>Harvard</span>
            </li>
        
            <li role="tab" id="tab-4" aria-controls="#cite-standard" tabindex="-1" aria-selected="false">
            <span>Standard</span>
            </li>
        
            <li role="tab" id="tab-5" aria-controls="#cite-RIS" tabindex="-1" aria-selected="false">
            <span>RIS</span>
            </li>
        
            <li role="tab" id="tab-6" aria-controls="#cite-vancouver" tabindex="-1" aria-selected="false">
            <span>Vancouver</span>
            </li>
        
    </ul>
    
</div>

            </div>
        </section>
        
        
        



    
    
    
    
    
    

    
        
        
        
    
    




    
        </div>
    </div>

    
    
    </div></div>]]>
            </description>
            <link>https://research.utwente.nl/en/publications/functional-programming-with-bananas-lenses-envelopes-and-barbed-w</link>
            <guid isPermaLink="false">hacker-news-small-sites-24056901</guid>
            <pubDate>Wed, 05 Aug 2020 03:07:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DeGoogle My Life]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24055955">thread link</a>) | @app4soft
<br/>
August 4, 2020 | https://homehack.nl/degoogle-my-life/ | <a href="https://web.archive.org/web/*/https://homehack.nl/degoogle-my-life/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>According to Wikipedia to DeGoogle is the act of removing Google from your life. As the growing market share of the internet giant creates monopolistic power for the company in digital spaces, increasing numbers of journalists have noted the difficulty to find alternatives to the company’s products. This is my experience to purge my life of Google and I can assure you it’s difficult but if we don’t act soon it will become impossible.</p><div>
		
<p>It’s been 1.5 years since Google+ closed and <a href="https://homehack.nl/category/social/page/2/">I started dipping my toes</a> into the Fediverse and other distributed social networks. It also kicked off my search to get rid of everything Google. To <a href="https://en.wikipedia.org/wiki/DeGoogle">DeGoogle</a> is easier said than done because Google is everywhere from search to fonts, from the video platform YouTube to the file storage and synchronisation service Google Drive, and from blog publishing service Blogger to the Google mobile operating system Android. And the list goes on. So chances are you’re using a lot of these services and most of them require a <a href="https://en.wikipedia.org/wiki/Google_Account">Google account</a>, a devious move from Google. It’s for this reason that it’s very hard to get rid of this o so convenient account.</p>



<figure><img data-attachment-id="1493" data-permalink="https://homehack.nl/degoogle-my-life/google_shattered/" data-orig-file="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?fit=692%2C261&amp;ssl=1" data-orig-size="692,261" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Google_shattered" data-image-description="" data-medium-file="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?fit=300%2C113&amp;ssl=1" data-large-file="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?fit=692%2C261&amp;ssl=1" src="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?w=840&amp;ssl=1" alt="Shattered Google logo illustrates that we need to break the power of Google on the web." srcset="https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?w=692&amp;ssl=1 692w, https://i0.wp.com/homehack.nl/wp-content/uploads/2020/05/Google_shattered.png?resize=300%2C113&amp;ssl=1 300w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px" data-recalc-dims="1"><figcaption>The shattered Google logo (that I made in Inkscape) illustrates that we need to break the power of Google on the web.</figcaption></figure>



<p>To get a more comprehensive view take a look at <a href="https://en.wikipedia.org/wiki/List_of_Google_products">this article</a>. Below I’ve compiled a list of the most important Google services and products that I replaced with something else.</p>



<h2>Google Search</h2>



<p>Search was perhaps the easiest to replace (or is it). While Google search is by far the largest search engine in the world DuckDuckGo (DDG) is becoming <a href="https://duckduckgo.com/traffic">increasingly popular</a>. I’ve  used DDG to great satisfaction and only had to use Google search a couple of times. The only gripe that I have is that DDG isn’t free and open source software (FLOSS) let alone distributed. In that respect I’ve read some good things about <a href="https://searx.me/">Searx</a> and I may give that a try in the future.</p>



<h2>Chrome</h2>



<p>The Chrome browser of Google has become very popular with an <a href="https://en.wikipedia.org/wiki/Google_Chrome#Market_share">estimated market share of approximately 70%</a>. A large portion of the Chrome’s source code is based on Chromium, the open source browser project from Google,  however Chrome is proprietary freeware because it contains large blobs of proprietary code. The Spyware Watchdog considers <a href="https://spyware.neocities.org/articles/chrome.html">Chrome’s Spyware level extremely high</a> this due to multiple spyware features that are built-in such as Google Account and Navigation Assistance. Another threat come from the earlier mentioned market share. This gets even worse when we include the <a href="https://en.wikipedia.org/wiki/Chromium_(web_browser)#Active">other browsers that are based on Chromium</a> such as Microsoft Edge, Opera and Vivaldi.  I currently use <a href="https://www.mozilla.org/en-US/firefox/new/">Firefox</a>. It’s perhaps not the most privacy minded browser around but it’s FLOSS, it has a reasonable market share which is important for support of web developers and development of Firefox is very active. </p>



<h2>YouTube</h2>



<p>Next is YouTube which BTW is becoming more and more annoying with all these ads and the recommendations with the sole purpose to keep the user as long as possible on YouTube (and serve even more ads). I invested a lot in YouTube in the past with over 70 video made about 3D CAD, 3D printing and electronics so replacing it is not easy. The solution that I found is two-fold. I remastered (part) of my existing videos and uploaded them to both <a href="https://joinpeertube.org/">PeerTube</a> and YouTube. If I want to watch YouTube videos I use <a href="https://www.invidio.us/">Invidious</a> in the browser of <a href="https://newpipe.schabi.org/">NewPipe</a> on my Smartphone (still Android sadly).  </p>



<h2>Google Drive</h2>



<p>Over the years I got dependant on Google Drive e.g to store the CAD files that I wanted to share after I published a project either in blog or a video. I want readers and viewers to be able to reproduce the project. Since I didn’t want to self-host a solution <s>such as <a href="https://nextcloud.com/">Nextcloud</a> wasn’t for me</s> (see edit below). I started looking for a paid service. I currently have a contract with Strato, a German hosting company that also hosts my websites. Strato offers HiDrive, it’s not FLOSS unfortunately but it offers 100% storage in the EU and (paid) end-to-end encryption is possible although only in the HiDrive desktop program for Windows (which is a bummer but I don’t need encryption for this purpose anyway).</p>



<h2>Google Maps</h2>



<p>Instead of Google maps I started using <a href="https://www.openstreetmap.org/">OpenStreetMap</a> and products based on OpenStreetMap such as <a href="https://osmand.net/">OsmAnd</a> (on Android) and <a href="https://wiki.openstreetmap.org/wiki/Komoot">Komoot</a> both on Android and the web browser. Komoot is excellent for hiking and cycling but unfortunately it isn’t FLOSS. These alternatives have proven to be good enough for me since I haven’t used Google Maps any more. </p>



<h2>Gmail</h2>



<p>I somehow started using Gmail. I don’t know exactly why because I already had very good email services. I also fail to understand why it’s so popular because every other email service does about the same. My own ISP comes with a very good email service and so is the web hosting company that I’m using. To stop using Gmail takes some preparation most importantly to list and notify all the people and organisations that send you email to your Gmail address. Also list all online services that use your Gmail address. Now replace this Gmail address with another email address.</p>



<p>You may want to delete your Gmail completely but it’s possible that it’s linked to your Google account. If this is the case you can either <a href="https://www.wikihow.com/Change-Your-Email-Address-on-Google">use a different email address </a>for this account or more radical <a href="https://www.lifewire.com/how-to-delete-your-gmail-account-1172073">delete your Google account</a> completely. In case you choose the latter remember that lots of Google services are couples to your Google account and can’t be accessed any more. Having said that if you start to purge Google from your life the Google account becomes less and less important with every Google service that you delete. So at a certain point deleting the Google account will be painless.</p>



<h2>Android</h2>



<p>Although Android is Free and Open Source software most Android phones come with proprietary software and services that prevent users from using the phone the way they seem fit. The easy way to free the software on your phone is to install <a href="https://f-droid.org/">FDroid</a>. For most users the Google Play Store is the only way to install software on their phone. FDroid is an alternative software store that enables the user to easily install and maintain Free and Open Source software on their Android device. BTW installing FDroid and replacing proprietary apps is what I have done thus far and it’s a good start.</p>



<p>Even better is to replace the Google infested Android with a free version of Android like <a href="https://lineageos.org/">LineageOS</a>. LineageOS is a FLOSS version of Android that can be used without a Google account and that comes without the proprietary Google apps (and perhaps other junk from the phone manufacturer). Make sure to check if your phone is supported before trying to install in on your phone.</p>



<h2>Fonts</h2>



<p>Yes I know, I have Google fonts in my blog. That came with the choice of the WordPress theme and I didn’t realize that at the time. That’s just another example how Google infested the web and how difficult it is to DeGoogle my life but rest assured fonts will be next.</p>



<h2>Conclusion</h2>



<p>To get Google out of your digital life is hard, very hard. This tells us how much Google is integrated into our lives and probably for the most part without being aware of it. Luckily we still have choice (other than just say goodbye to the web), choice that gives us freedom to use the web without being used. The freedom to control our data and not being exploited. </p>



<p>E<em>dit: As someone on Mastodon pointed out it’s not necessary to self-host NextCloud. Examples of cloud service providers running Nextcloud are <a href="https://disroot.org/en/services/nextcloud">Disroot</a>, <a href="https://www.owncube.com/index_en.php">OwnCube</a> and <a href="https://operationtulip.com/">Operationtulip.com</a> (currently in beta). </em></p>


<div>
	<p><img alt="" src="https://secure.gravatar.com/avatar/a90a46e04d18b0f85b8b54368a30dfe4?s=42&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/a90a46e04d18b0f85b8b54368a30dfe4?s=84&amp;d=mm&amp;r=g 2x" height="42" width="42">	</p><!-- .author-avatar -->

	<div>
		

		<p>
			I’m an #privacy, #opensource, #opendata and #openstandards advocate. I’m holding a grudge against Big Tech, big IP holders and authoritharian governments. Furthermore I’m a #3Ddesigner, #3Dprinter, #webdesigner and overall #DIY guy.

But most of all I’m a free man.			<a href="https://homehack.nl/author/eribuijs/" rel="author">
				View all posts by eribuijs			</a>
		</p><!-- .author-bio -->
	</div><!-- .author-description -->
</div><!-- .author-info -->
	</div></div>]]>
            </description>
            <link>https://homehack.nl/degoogle-my-life/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24055955</guid>
            <pubDate>Wed, 05 Aug 2020 00:23:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My favorite product management templates]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24055448">thread link</a>) | @jcs87
<br/>
August 4, 2020 | https://www.lennyrachitsky.com/p/my-favorite-templates-issue-37?linkedin | <a href="https://web.archive.org/web/*/https://www.lennyrachitsky.com/p/my-favorite-templates-issue-37?linkedin">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hello and welcome to the<strong>&nbsp;free monthly edition&nbsp;</strong>of my weekly newsletter. I’m&nbsp;<a href="https://twitter.com/lennysan">Lenny</a>, and each week I humbly tackle reader questions about product, growth, working with humans, and anything else that’s stressing you out at the office.</p><p>If you’re not a paid subscriber, here’s what you missed this month:</p><ol><li><p><a href="https://www.lennyrachitsky.com/p/crafting-an-seo-strategy-issue-34">Winning at SEO</a>﻿</p></li><li><p><a href="https://www.lennyrachitsky.com/p/autonomy-vs-direction-issue-35">As a leader, choosing autonomy vs. direction</a></p></li><li><p><a href="https://www.lennyrachitsky.com/p/how-todays-fastest-growing-b2b-startups">How today's fastest-growing B2B startups turned their early users into paying customers</a></p></li></ol><p>Consider&nbsp;subscribing if you haven’t already 👇</p><p><a target="_blank" href="https://cdn.substack.com/image/fetch/c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F39598850-5c8f-4928-90bd-d56799dba39b_6016x4016.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F39598850-5c8f-4928-90bd-d56799dba39b_6016x4016.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/39598850-5c8f-4928-90bd-d56799dba39b_6016x4016.jpeg&quot;,&quot;height&quot;:972,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2561865,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p>Now I do!</p><p>Below are all of my favorite templates and frameworks that I rely on. As a bonus, I <a href="https://twitter.com/lennysan/status/1287862995268206592">asked the wonderful people of Twitter</a> to share their favorites, from which I picked my favorites and included. Enjoy!</p><h4>✍️ 1-Pagers / PRDs</h4><ol><li><p><a href="https://docs.google.com/document/d/1541V32QgSwyCFWxtiMIThn-6n-2s7fVWztEWVa970uo/edit">My personal 1-Pager template</a> — How I start every project</p></li><li><p><a href="https://docs.google.com/document/d/1mEMDcHmtQ6twzNlpvF-9maNlAcezpWDtCnyIqWkODZs/edit">Kevin Yien’s PRD template</a> (PM at Square) — Love this whole template, particularly the “Non-Goals” section, and the step-by-step flow</p></li><li><p><a href="https://docs.google.com/document/d/1W46cmPfPwXIIH2mNNbbQ5EdjnhQFqGxGhT5iAijmJjc/edit#heading=h.cqt1a4hrfy8u">Asana’s project brief template</a> — Also love this whole template, particularly the problem statement framework</p></li><li><p><a href="https://s3.amazonaws.com/marketing.intercomcdn.com/assets/Intercom-Job-Story-template.pdf">Intercom’s story template</a> — Love the simplicity, while still having everything you need to get started</p></li><li><p><a href="https://docs.google.com/document/d/1yrU5F6Gxhkfma91wf_IbZfexw8_fahbGQLW3EvwdfQI/edit">Product Hunt’s PRD template</a> — Love the way it begins (Who, Why, What), though a bit long</p></li><li><p><a href="https://docs.google.com/document/d/1A__mJX33zn5fmAj6DtYv1P19aI6R4Gtcc13fGZv377k/edit">Adam Waxman’s PRD template</a> (Design at SeatGeek) — Love 1-Pager summary section before it dives deep</p></li><li><p><a href="https://docs.google.com/document/d/1BeNK9BYd3-8pAqVYR_B0Gzp7kGNtWdPFHJKIXI52_84/edit?ts=5f264700#heading=h.6jynaot9cbnq">Steve Morin’s 1-pager template</a> (EM at Asana) — Love the focus on success criteria and risks</p></li><li><p><a href="https://coda.io/@yuhki/figmas-approach-to-product-requirement-docs/prd-name-of-project-1">Figma’s PRD template</a> — A super comprehensive plug-and-play template </p></li><li><p><a href="https://docs.google.com/document/d/1B3GEUwgEIIQVgRp85l4DKLZOTzgGZmBIAjR06p4wuwY/edit#">Adam Thomas’ initiative template</a> — A reminder of how valuable it is to keep these to one page, at least to start</p></li></ol><h4>🤔 Strategy</h4><ol><li><p><a href="https://docs.google.com/document/d/1JI73WrGplrhNE46aLyRD_B74gEynI77EPgXn1ic6WeQ/edit?usp=drive_web&amp;ouid=111613335789441259753">My business strategy template</a></p></li><li><p><a href="https://docs.google.com/document/d/1RQWuvWDgcAv1ylksFXtiwhuTbHLcL1byIcoXsbCQfic/edit#heading=h.b2dsyhbkdvd1">My team strategy template</a></p></li><li><p><a href="https://www.salesforce.com/blog/2013/04/how-to-create-alignment-within-your-company.html">V2MOM template</a> by Marc Benioff</p></li><li><p><a href="https://www.linkedin.com/pulse/working-backwards-press-release-template-example-ian-mcallister/">Amazon working backwards PR template</a> by Ian McAllister</p></li><li><p><a href="https://medium.com/@gibsonbiddle/2-the-dhm-model-6ea5dfd80792">How to define your product strategy</a> by Gibson Biddle</p></li></ol><h4>🤩 Vision</h4><ol><li><p><a href="https://www.romanpichler.com/blog/tips-for-writing-compelling-product-vision/">Product Vision Board</a> by Roman Pichler</p></li><li><p><a href="https://gist.github.com/JoshSmith/2041454">Geoffrey Moore's positioning framework</a> by Josh Smith</p></li><li><p><a href="https://medium.com/@kit_ulrich/a-surprisingly-simple-technique-for-a-rockstar-product-vision-the-ladder-of-needs-ae624d81ca6b">The Ladder of Needs</a> by Catherine (Kit) Ulrich</p></li></ol><h4>📢 <strong>Go-To-Market</strong></h4><ol><li><p><a href="https://docs.google.com/document/d/1Y4NwrsoucPqNFqIkhwNgKpPzf0wqnrN6tcKF2g4nVoM/edit">Launch strategy template</a> by Pratik Mehta</p></li><li><p><a href="https://chatbotsmagazine.com/marketing-plan-and-chill-75f7e3d63358#.kgoqx0ahk">Marketing plan template</a> by Michael Taylor</p></li><li><p><a href="https://docs.google.com/presentation/d/1idjXAJDUn8EOMnzE5B0ZtR3BcQAdN3YteFGBoPkUUEI/edit#slide=id.p">GTM plan template</a> by The Product Folks</p></li></ol><h4>👌 <strong>Other templates</strong></h4><ol><li><p><a href="https://docs.google.com/spreadsheets/d/1zlx3RuidNOW40Zf7gh07p2SqoR53Ungv9JFT-PhHwxI/edit#gid=184965050">Roadmap template</a></p></li><li><p><a href="https://docs.google.com/document/d/1SXO4eH8ZvpuONpdlxpu6y1ufDS0n6vbciV4IJzpm-sc/edit">Performance review template</a></p></li><li><p><a href="https://docs.google.com/spreadsheets/d/1RTMr9vGCYEhWYA2dKG8EYLDFEtQ1E33W8uDEhmEd8QQ/edit?usp=drive_web&amp;ouid=111613335789441259753">Planning timeline template</a></p></li></ol><h4>🤤 <strong>Additional goodness</strong></h4><ol><li><p><a href="https://coda.io/@gokulrajaram/gokuls-spade-toolkit">Gokul's S.P.A.D.E. decision-making framework</a></p></li><li><p><a href="https://medium.com/@barmstrong/how-we-make-decisions-at-coinbase-cd6c630322e9">How we make decisions at Coinbase</a></p></li><li><p><a href="https://medium.com/lessons-from-mckinsey/the-pyramid-principle-f0885dd3c5c7">The Pyramid Principle</a></p></li><li><p><a href="https://uxdesign.cc/8-things-to-use-in-jobs-to-be-done-framework-for-product-development-4ae7c6f3c30b">“Jobs to Be Done” framework</a></p></li><li><p><a href="https://coda.io/@shishir/eigenquestions-the-art-of-framing-problems/">Eigenquestions: The Art of Framing Problems</a></p></li><li><p><a href="https://medium.com/@stewart/we-dont-sell-saddles-here-4c59524d650d">We Don’t Sell Saddles Here</a></p></li><li><p><a href="https://sriramk.com/strategy">Business strategy concepts</a></p></li><li><p><a href="https://www.notion.so/High-Output-Founders-Library-48742928f9f149b8a777e11a1409ce0a">High Output Founders' Library</a></p></li></ol><p>If you have any other amazing templates or frameworks that you regularly use, across product, marketing, eng, or design <em>please</em> <a href="https://twitter.com/lennysan">shoot them over</a>. I’ll use this post as a living document of the best product development templates.</p><p>That’s it for this week!</p><p>🙏 Thank you to these fine folks for sharing many of these templates: <a href="https://twitter.com/ajwaxman/status/1261470324824121345">Adam</a>, <a href="https://twitter.com/amanik/status/1287868945920221184">Aman</a>, <a href="https://www.linkedin.com/in/dennisyang/">Dennis</a>, <a href="https://twitter.com/satoshisayswhat/status/1287901497976651776">Chris</a>, <a href="https://twitter.com/phil_huot/status/1288141112180445186">Philippe</a>, <a href="https://twitter.com/PratikkCMehta/status/1287956996986028032">Pratik</a>, <a href="https://twitter.com/robsicat/status/1287895839851966466">Rob</a>, <a href="https://twitter.com/tatopane/status/1287863498383400960">Tato</a>, <a href="https://twitter.com/satyap">Satya</a>, <a href="https://productivegrowth.substack.com/">Steve</a>, <a href="https://twitter.com/lennysan/status/1287862995268206592">Sree</a>, <a href="https://twitter.com/vindytalks">Vindhya</a>. Photo by&nbsp;<a href="https://unsplash.com/@joannakosinska?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Joanna Kosinska</a> 🙏</p><h2>🔥 Job opportunities</h2><ul><li><p>Product: <a href="https://angel.co/company/kudo-meeting/jobs/913705-product-manager">KUDO</a>, <a href="https://jobs.all-hands.us/companies/uptime2020/jobs/product-manager-2-5943a3d1-9819-417b-aee9-fc6a563b276e">Uptime2020</a></p></li><li><p>Growth: <a href="https://boards.greenhouse.io/cerebral/jobs/4076601003">Cerebral</a>, <a href="https://jobs.lever.co/outschool/4f18d9fe-516b-4285-a5df-357f6cff5b92">Outschool</a></p></li><li><p>Design: <a href="https://www.cascade.io/jobs/analytical-product-designer">Cascade</a>, <a href="https://jobs.lever.co/pachama/f4f49853-9d59-4dcc-9d0b-143ca63a53d2">Pachama</a>, <a href="https://www.notion.so/Founding-Designer-San-Francisco-d1296f25efcc43a7833fd28ea3952b39">Primer</a>, <a href="https://sourcetable.com/jobs#contract-designer">Sourcetable</a></p></li><li><p>Engineering lead: <a href="https://boards.greenhouse.io/cerebral/jobs/4076598003">Cerebral</a>, <a href="https://jobs.lever.co/snackpass/00505223-bc85-4c28-8e4b-31217d05c2de">Snackpass</a></p></li><li><p>Frontend engineer: <a href="https://www.cascade.io/jobs/front-end-product-engineer">Cascade</a>, <a href="https://www.notion.so/levelshealth/Join-Levels-Remote-Developer-58454f0db7e3466692f7b75db6237ddf">Levels</a>, <a href="https://www.notion.so/Founding-Frontend-Engineer-San-Francisco-783c2072b9c047a88cb884babb47ef04">Primer</a>, <a href="https://transformdata.io/careers/">Transform</a></p></li><li><p>Backend engineer: <a href="https://sourcetable.com/jobs#backend-engineer">Sourcetable</a>, <a href="https://transformdata.io/careers/">Transform</a></p></li><li><p>Fullstack engineer: <a href="https://www.notion.so/Software-Developer-e7cad269968e4d5aaeb1f6da9e282626">Centered</a>, <a href="https://jobs.lever.co/snackpass/7c3bb72b-70d3-45ca-9dea-eea57ed5333d">Snackpass</a>, <a href="https://projectwren.com/careers/software-engineer">Wren</a></p></li><li><p>iOS engineer: <a href="https://www.notion.so/Lead-iOS-Developer-ba18577b6ba44ad68e45b8e7a957353c">Pairplay</a></p></li><li><p>Sales/BD: <a href="https://boards.greenhouse.io/cerebral/jobs/4105169003">Cerebral</a>, <a href="https://angel.co/company/kudo-meeting/jobs/649855-vice-president-of-sales">KUDO</a>, <a href="https://jobs.lever.co/pachama/996cdde4-737b-4794-ad0f-d726448c3dfb">Pachama</a>, <a href="https://angel.co/company/swayable/jobs/808347-director-of-sales">Swayable</a></p></li><li><p>Community: <a href="https://jobs.lever.co/outschool/449fa54a-1778-4255-a95d-a65dc28194c7">Outschool</a></p></li><li><p>Security: <a href="https://angel.co/company/kudo-meeting/jobs/592999-cybersecurity-compliance-program-manager">KUDO</a></p></li></ul><h2><strong>🧠 Inspiration for the week ahead</strong></h2><ol><li><p><strong>Read</strong>: <a href="https://li.substack.com/p/unbundling-work-from-employment">Unbundling Work from Employment</a> by Li Jin</p></li><li><p><strong>Watch</strong>: Japanese skateboarder Isamu Yamamoto (via <a href="https://mikeplewis.substack.com/">Mike Lewis</a>)</p></li></ol><ol start="3"><li><p><strong>Watch</strong>: <a href="https://vimeo.com/429924982">Transfiguration</a> (via <a href="https://thebrowser.com/">The Browser</a>)</p></li></ol><p id="vimeo-429924982" data-attrs="{&quot;videoId&quot;:&quot;429924982&quot;}"><iframe src="https://player.vimeo.com/video/429924982?autoplay=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><strong>If you’re finding this newsletter valuable, consider&nbsp;<a href="https://www.lennyrachitsky.com/">sharing it with friends</a>, or subscribing if you aren’t already.</strong></p><p>Sincerely,</p><p>Lenny 👋</p></div></div>]]>
            </description>
            <link>https://www.lennyrachitsky.com/p/my-favorite-templates-issue-37?linkedin</link>
            <guid isPermaLink="false">hacker-news-small-sites-24055448</guid>
            <pubDate>Tue, 04 Aug 2020 23:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[License Zero: Comments on “The Truth Is Paywalled but the Lies Are Free”]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24054522">thread link</a>) | @joelellis
<br/>
August 4, 2020 | https://blog.licensezero.com/2020/08/03/truth-paywall.html | <a href="https://web.archive.org/web/*/https://blog.licensezero.com/2020/08/03/truth-paywall.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  
  
  <p>On the off chance there’s anyone out there who still believes open software’s “funding” problems reflect something special about software, have a read through <a href="https://www.currentaffairs.org/2020/08/the-truth-is-paywalled-but-the-lies-are-free/">Nathan Robinson’s recent editor’s note, “The Truth Is Paywalled But The Lies Are Free”</a>.  Perhaps we can see in another what’s so hard to see in ourselves.</p>

<p>In my reading, the problem here is evident: black-and-white, either-or thinking.  Nathan begins his essay:</p>

<blockquote>
  <p>Paywalls are justified, even though they are annoying. … I try not to grumble about having to pay for content online, because I run a magazine and I know how difficult it is to pay writers what they deserve.</p>
</blockquote>

<p>But by the end, he’s regressed to an insoluble-sounding conflict-of-goals again:</p>

<blockquote>
  <p>Creators must be compensated well.  But at the same time we have to try to keep things that are important and profound from getting locked away where few people will see them.  The truth needs to be free and universal.</p>
</blockquote>

<p>To this I would respond, not just to Nathan, but to everyone stuck at this impasse:  Don’t worry.  You’re not stuck.  None of the above is true.</p>

<p>Creators needn’t be compensated well just because they are creators.  Creators of valuable works—works valued by others—ought to be compensated.  Creators of highly and broadly valued works ought to be compensated well.  I deserve, and shall assuredly receive, no compensation whatever for the bad musical improvizations, repetitive doodles, or unfunny, dead-end software libraries I churn out from time to time.  Everyone, including me, should be fine with this.</p>

<p>Neither must useful works of every kind cost nothing to everyone.  Even the greatest works remain manifestly irrelevant to the vast majority of people.  And there are myriad, happier mediums between $0, expensive, and exclusive, in one dimension, and effortless, inconvenient, and inaccessible, in the other.</p>

<p>I happen to believe that in most areas of creative work, and in most adjacent industries, giving more away for $0 online would improve outcomes for most players, overall.  Our business instincts and well-worn patterns haven’t quite kept up with the times, and never do.  But there is nothing inherently worse about paying a fee you can afford than enduring an inconvenience you have the time to manage.  When the works we need or want come readily available at affordable costs that we can pay, and paying is easy, there’s no great harm to access or progress or truth.  That cost many not be great.  But if a great many pay it, the results can be.</p>

<p>For those interested in economics, intellectual property, and history in the news industry specifically, I heartily recommend <a href="https://www.sup.org/books/title/?id=29452">Will Slauter’s <em>Who Owns the News?</em></a>.  You might also read up a bit on stalwart news institutions, <a href="https://en.wikipedia.org/wiki/Associated_Press">like the Associated Press</a>.  What you find might surprise you.</p>

</article></div>]]>
            </description>
            <link>https://blog.licensezero.com/2020/08/03/truth-paywall.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24054522</guid>
            <pubDate>Tue, 04 Aug 2020 21:09:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Magnasanti: The Largest and Most Terrifying SimCity (2010)]]>
            </title>
            <description>
<![CDATA[
Score 251 | Comments 91 (<a href="https://news.ycombinator.com/item?id=24052413">thread link</a>) | @riboflavin
<br/>
August 4, 2020 | https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/ | <a href="https://web.archive.org/web/*/https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					

					

					<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg"><img data-attachment-id="2960" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg" data-orig-size="600,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=300" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=600" title="magna" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=150 150w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna.jpg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>This picture  may appear to be a collection of color fields without meaning or  purpose, but there is a ton of math and evil genius behind this image.</p>
<p><strong>This is a view of Magnasanti, the metropolis that pushes SimCity to its population limits. </strong></p>
<p><strong><span id="more-2933"></span></strong>Here is a closer view:</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg"><img data-attachment-id="2942" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna1/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg" data-orig-size="600,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna1" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=300" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=600" title="magna1" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=150 150w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna1.jpeg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>Vincent Oscala, a 22-year old architecture student from the Philippines, spent years decoding the formula for success in Sim City 3000.</p>
<p>Sounds like lunacy…but his insane investment of effort into “beating” SimCity raises interesting questions about the urban landscapes we inhabit, and the ways in which they can go horribly wrong.</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg"><img data-attachment-id="2944" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna2-2/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg" data-orig-size="600,825" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna2" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=218" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=600" title="magna2" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=109 109w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna21.jpg?w=218 218w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>After a massive amount of planning and a great deal of trial and error, he was able to create a city with over six million inhabitants.</p>
<p>Moreover, the city he created was remarkably stable, with no abandoned buildings and no wasted space. There are no roads — all transit is mass transit. An omniscient police force has eliminated all crime in the city. Magnasanti’s water and power needs are supplied by neighboring cities, eliminating the need for much of the related infrastructure.</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg"><img data-attachment-id="2945" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magna3/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg" data-orig-size="600,450" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magna3" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=300" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=600" title="magna3" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg 600w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=150 150w, https://rumorsontheinternets.files.wordpress.com/2010/10/magna3.jpg?w=300 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p><strong>In SimCity </strong><strong>terms</strong><strong>, it is a masterpiece.</strong></p>
<p><strong>But at the “street level,” so to speak, it looks like a horrifying dystopia. </strong></p>
<p>Unemployment is high, air pollution is stifling, education is largely absent, medical care and fire response are non-existent. Citizens do not live to reach retirement age. The police state has essentially eliminated free will and allowed the city to maximize its size while reducing quality of life to a minimum — and still maintaining total control over the citizens.</p>
<p>Every person living in Magnasanti spends his life working and residing in one small, massively efficient block of space, until death around age 50.</p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg"><img data-attachment-id="2946" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magnachart/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg" data-orig-size="422,438" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magnachart" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=289" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=422" title="magnachart" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg 422w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=145 145w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnachart.jpg?w=289 289w" sizes="(max-width: 422px) 100vw, 422px"></a></p>
<p><a href="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg"><img data-attachment-id="2947" data-permalink="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/magnalife/" data-orig-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg" data-orig-size="424,440" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="magnalife" data-image-description="" data-medium-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=289" data-large-file="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=424" title="magnalife" src="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=630" alt="" srcset="https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg 424w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=145 145w, https://rumorsontheinternets.files.wordpress.com/2010/10/magnalife.jpg?w=289 289w" sizes="(max-width: 424px) 100vw, 424px"></a></p>
<p>Here is a video that explains some of the development process for Magnasanti, including two smaller cities that served as development prototypes for Oscala’s final achievement:</p>
<p><span><iframe width="630" height="355" src="https://www.youtube.com/embed/NTJQTc-TqpU?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>As the soundtrack indicates, Oscala was highly influenced by the art film <a href="http://en.wikipedia.org/wiki/Koyaanisquatsi" target="_blank">Koyaanisquatsi</a>, or “Life out of Balance,” directed by Godfrey Reggio with music by Philip Glass.</p>
<p>Koyaanisquatsi is a non-narrative work that examines and explores the contrasts between the form and pace of nature and modern human life. Ultimately, the film confronts us with the fact that our species is living a life out of balance with nature, for better or for worse.</p>
<p>It’s a really cool movie that is highly recommended. Here’s a teaser:</p>
<p><span><iframe width="630" height="355" src="https://www.youtube.com/embed/LFBijDU8PpE?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
<p>Now, you may be asking, what in the world does a game of SimCity — in an obsolete version, no less — have to teach us about a “life out of balance”?</p>
<p>Magnasanti is, first and foremost, a study in how to game SimCity to a maximum-population win condition.</p>
<p>However, I do think it raises some intriguing questions.</p>
<p>Oscala <a href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/" target="_blank">comments</a>:</p>
<blockquote>
<p><strong>The film presented the world in a way I never really looked at before  and that captivated me. Moments like these compel me to physically  express progressions in my thought, I have just happened to do that  through the form of creating these cities in <em>SimCity 3000.</em> I  could probably have done something similar – depicting the awesome  regimentation and brutality of our society – with a series of paintings  on a canvas, or through hideous architectural models.</strong></p>
<p><strong>But it wouldn’t be  the same as doing it in the game, for the reason that I wanted to  magnify the unbelievably sick ambitions of egotistical political  dictators, ruling elites and downright insane architects, urban planners  and social engineers.</strong></p>
</blockquote>
<p>Australian architecture blog <a href="http://supercolossal.ch/2010/10/07/pay-to-click-get-rich-quick-urbanism-and-the-ideal-simcity/" target="_blank">Super Colossal discusses</a> some of the issues provoked by Magnasanti (link <a href="http://m.ammoth.us/blog/2010/10/magnasanti/" target="_blank">via</a>):</p>
<blockquote>
<p>This is the kind of archiporn that I am a sucker for; gamespace urbanism  exploited to its extreme condition. Can you ‘win’ urbanism? Is this  even urbanism? If not, can we take anything from its construction? The  primary move that the city makes is to remove cars altogether and base  transport purely on subways. I suspect this is a method to exploit the  space otherwise taken up by roads for real estate allowing for an  increased population per tile, however, it is a strategy that many  cities—Sydney included—are seriously looking into. Remove motor  vehicles, increase public transport. Seems like a sound idea.</p>
</blockquote>
<p>It is interesting to see a world in which the lack of cars exists alongside a lack of freedom, and indeed may even be symptomatic of it. Oscala has created a system so “sustainable” that citizens are chained to their city blocks; they’re able to access the rest of the city through mass transit, but in effect have been relieved of the need to do so by the ruthless efficiency of their cookie-cutter “neighborhoods.”</p>
<p>Maybe — all right, probably — this is effective because the game engine is warped. Super Colossal concludes that “Ultimately, Magnasanti has little to do with urban design and everything to do with gaming systems for maximum&nbsp;reward.”</p>
<p>I can’t help but think that Magnasanti represents a semi-realistic dark side of centralized urban planning: the tools of modern construction and city planning as wielded by a despotic madman bent on maximizing population at any cost. Creativity, vibrancy and nature itself are cast away as a focus on efficiency and the bottom line are elevated to a religion and a science.</p>
<p>And of course, the police force are ever-present, just in case disorder begins to stir.</p>
<p>As Oscala <a href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/" target="_blank">explained in an interview with Viceland</a>, Magnasanti represents a “cage” in which he has imprisoned six million “economic slaves”. He <a href="http://images.shareapic.net/images7/022530174.jpg" target="_blank">utilized the geometry</a> of the Buddhist Wheel of Life and Death as further symbolic comment on the topic.</p>
<blockquote><p><strong>Technically, no one is leaving or coming into the  city. Population growth is stagnant. Sims don’t need to travel long  distances, because their workplace is just within walking distance. In  fact they do not even need to leave their own block. Wherever they go  it’s like going to the same place. </strong></p>
<p><strong>There are a lot of other problems in the city hidden under the  illusion of order and greatness: Suffocating air pollution, high  unemployment, no fire stations, schools, or hospitals, a regimented  lifestyle – this is the price that these sims pay for living in the city  with the highest population. It’s a sick and twisted goal to strive  towards. </strong></p>
<p><strong>The ironic thing about it is the sims in Magnasanti tolerate  it. They don’t rebel, or cause revolutions and social chaos. No one  considers challenging the system by physical means since a  hyper-efficient police state keeps them in line. They have all been  successfully dumbed down, sickened with poor health, enslaved and  mind-controlled just enough to keep this system going for thousands of  years. 50,000 years to be exact. They are all imprisoned in space and  time.</strong></p></blockquote>
<p>The <a href="http://m.ammoth.us/blog/2010/10/magnasanti/" target="_blank">Mammoth blog</a> calls Magnasanti “An intentionally hellish vision which exploits the game’s internal logic as commentary.”</p>
<p>Oscala <a href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/" target="_blank">adds </a>that “if we make maximizing profits the absolute objective, we fail to take  into consideration the social and environmental consequences.”</p>
<p><strong>At the very least, it’s delicious food for thought for would-be urban planners and simulation gamers.</strong></p>
<p>Further reading and sources:<strong><br>
</strong></p>
<p>Viceland: <a title="Permanent Link to The Totalitarian Buddhist Who Beat Sim City" rel="bookmark" href="http://www.viceland.com/blogs/uk-games/2010/05/10/the-totalitarian-buddhist-who-beat-sim-city/">The Totalitarian Buddhist Who Beat Sim City</a><br>
Mammoth: <a href="http://m.ammoth.us/blog/2010/10/magnasanti/#" target="_blank">Magnasanti</a><br>
Super Colossal: <a rel="bookmark" href="http://supercolossal.ch/2010/10/07/pay-to-click-get-rich-quick-urbanism-and-the-ideal-simcity/" target="_blank">Pay to Click Get Rich Quick: Urbanism and the Ideal SimCity<br>
</a>Imperar’s Millionaire Experiment: <a href="http://imperar.blogs.linkbucks.com/who-is-imperar/" target="_blank">Who is Imperar?</a></p>
<p>Mildly related: <a href="http://en.wikipedia.org/wiki/The_Power_Broker" target="_blank">The Power Broker</a> and <a href="http://en.wikipedia.org/wiki/The_Death_and_Life_of_Great_American_Cities" target="_blank">The Death and Life of Great American Cities</a></p>
			
			
			
					
					<!--
					<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/"
    dc:identifier="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/"
    dc:title="Magnasanti: The Largest and Most Terrifying&nbsp;SimCity"
    trackback:ping="https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/trackback/" />
</rdf:RDF>					-->

				</div></div>]]>
            </description>
            <link>https://rumorsontheinternets.org/2010/10/14/magnasanti-the-largest-and-most-terrifying-simcity/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24052413</guid>
            <pubDate>Tue, 04 Aug 2020 17:34:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laissez Faire Leadership for Startups]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24052230">thread link</a>) | @stewartma
<br/>
August 4, 2020 | https://blog.cadencework.com/3-benefits-of-laissez-faire-leadership-for-startups/ | <a href="https://web.archive.org/web/*/https://blog.cadencework.com/3-benefits-of-laissez-faire-leadership-for-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-235">
	

	<div>
		
<p>Laissez Faire Leadership is a form of leadership that offers many benefits for startups. In fact, if you currently work at a startup, you’re likely practicing a laissez-faire management style without even realizing it! In this article, we’ll briefly cover what laissez-faire leadership is and three benefits that it can bring to your startup.</p>



<h3><strong>What is Laissez Faire Leadership?</strong></h3>



<p>Laissez-faire leadership is a hands-off management style based on trust and is the direct opposite of micromanagement. Laissez-faire managers set clear visions and give their direct reports autonomy to make decisions in whatever way they best see fit.</p>



<p><em>Fun fact: </em><a href="https://www.paulallen.com/"><em>Paul Allen</em></a><em>, co-founder of </em><a href="https://www.microsoft.com/"><em>Microsoft</em></a><em>, is known for taking a hands-off, or laissez-faire, approach to management. Other famous laissez-faire leaders include <a href="https://en.wikipedia.org/wiki/Warren_Buffett">Warren Buffett</a>, founder of Berkshire Hathaway, and <a href="https://www.businessoffashion.com/community/people/donna-karan-4">Donna Karan</a>, founder of DKNY.&nbsp;&nbsp;</em></p>



<p>Before we cover the advantages of laissez-faire leadership for startups, it’s worth mentioning why some are opposed to this leadership style. Those who oppose it prefer a hands-on, involved approach and wish to be closely involved in project implementations. Others find that a laissez-faire approach leads to time mismanagement, especially when there is a lack of accountability amongst team members.</p>



<p>Although those qualms are valid, we still believe that most startups would benefit from laissez-faire leadership. Next, we’ll cover the 3 biggest benefits laissez-faire leadership brings to startups.</p>



<h3><strong>Benefit 1: Empowers employee creativity</strong></h3>



<figure><img src="https://blog.cadencework.com/wp-content/uploads/2020/08/blue-lemon.jpg" alt="Blue Lemon Creativity" srcset="https://blog.cadencework.com/wp-content/uploads/2020/08/blue-lemon.jpg 640w, https://blog.cadencework.com/wp-content/uploads/2020/08/blue-lemon-300x200.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>Laissez-faire leaders bestow trust and autonomy onto employees and give them free reign to learn through trial and error. In other words, they give their teammates goals and freedom to achieve those goals.</p>



<p>When given the freedom to make decisions, employees tend to be more creative because they aren’t simply handed a “right answer”. Creativity is important and is increasingly <a href="https://www.ideou.com/blogs/inspiration/why-creativity-is-more-important-than-ever">a competitive advantage</a> for startups, especially as they battle large incumbents like Google and Amazon. </p>



<p>Ambitious startups thrive on innovation, rapid iteration, and new ideas, making laissez-faire leadership a great fit for any fast-growing company.</p>



<h3><strong>Benefit 2: Attracts employees who thrive in fast-paced, dynamic environments</strong></h3>



<p>Paul Graham <a href="http://www.paulgraham.com/growth.html">famously notes</a> that “a startup is a company designed to grow fast.” Employees who effectively deal with ambiguity and who are fast learners are more likely to thrive in the dynamic, fast-paced nature of startups.&nbsp;Such employees likely chose to work at startups because they thrive in unpredictable environments and wouldn’t do well with overly-prescriptive management styles.</p>



<p><a href="https://blog.cadencework.com/daily-standups-asynchronous-communication/">Micromanagement has no place</a> in an environment like a startup, where growth and changes are the only constants. In such environments, micromanagers would be bottlenecks to growth, as work would be inhibited unless their directives were given. Instead, startups value resourcefulness and autonomy, two values that laissez-faire leaders encourage.</p>



<h3><strong>Benefit 3: Is </strong>suitable<strong> for remote work</strong></h3>



<figure><img src="https://blog.cadencework.com/wp-content/uploads/2020/08/yellow.jpg" alt="Remote work keyboard" srcset="https://blog.cadencework.com/wp-content/uploads/2020/08/yellow.jpg 640w, https://blog.cadencework.com/wp-content/uploads/2020/08/yellow-300x205.jpg 300w" sizes="(max-width: 640px) 100vw, 640px"></figure>



<p>As a result of the coronavirus pandemic, most companies have implemented <a href="https://www.forbes.com/sites/zackfriedman/2020/07/27/google-amazon-facebook-microsoft-twitter/#bce4cb235c8b">work-from-home policies until 2021</a>. As these companies work remotely, many realize that given different working hours and timezones, it’s no longer realistic to equate online presence with productivity. Rather, the more productive approach is to focus on output and results. </p>



<p>Laissez-faire leaders empower remote teams to thrive because they don’t need to force employees to install intrusive tracking software in order to feel confident that work is getting done. Instead, they delegate, set tangible milestones, unblock teammates as necessary, and trust that they will accomplish those goals. This allows employees to execute on their current projects in whatever way works best for them.</p>



<h3><strong>Laissez-Faire Leadership is Great for Startups</strong></h3>



<p>Ultimately, laissez-faire leadership empowers employee creativity, attracts employees who thrive in fast-paced environments, and is suitable for remote work. Startups looking to differentiate themselves and stay competitive should consider implementing this style of leadership.</p>
	</div>

</article></div>]]>
            </description>
            <link>https://blog.cadencework.com/3-benefits-of-laissez-faire-leadership-for-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24052230</guid>
            <pubDate>Tue, 04 Aug 2020 17:20:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Better Visual Object Tracking]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24051700">thread link</a>) | @elbelcho
<br/>
August 4, 2020 | https://teleidoscope.com/blog/better-visual-object-tracking/ | <a href="https://web.archive.org/web/*/https://teleidoscope.com/blog/better-visual-object-tracking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>Better Visual Object Tracking</h2><p><em>Balancing speed, accuracy, and robustness</em></p><p>July 28, 2020</p><p>Visual Object Tracking, or <strong>tracking</strong> for short, is a fundamental component of autonomous vision systems. It allows machines to follow regions of interest through a series of images. </p><p>Because of their resource efficiency Region Of Interest Trackers (KCF, CSRT, THOR, RAD, etc) have become a very popular approach to visual object tracking.</p><p><strong>Many modern trackers prioritize speed and accuracy at the expense of robustness.</strong></p><p><img src="https://teleidoscope.com/assets/drawing1-75.png" alt="drawing" width="70%"></p><p>At Teleidoscope, we’ve developed our own tracker (RAD) that attempts to address all three.</p><p><iframe data-src="https://player.vimeo.com/video/442186954?autoplay=1&amp;muted=1&amp;loop=1&amp;quality=720p" title="Bounding Box" frameborder="0" allow="autoplay;" allowfullscreen="" data-expand="-140"></iframe></p><p><strong>Note:</strong> Performance in video above is impacted by visualization view rendering. See videos below for more accurate representation.</p><h2>The Balanced Tracker</h2><p>A balanced tracker balances the following attributes:</p><ol><li><strong>Speed</strong> - <em>How <strong>fast</strong> can it produce an estimate</em></li><li><strong>Accuracy</strong> - <em>How <strong>precisely</strong> it estimates the location of the object for a wide variety of objects</em></li><li><strong>Robustness</strong> - <em>How <strong>reliably</strong> it handles difficult conditions without losing the objects</em></li></ol><p>The impact one attribute has on the others varies by implementation but in general the following is often true.</p><ul><li><strong>Speed</strong> can be traded for <strong>Accuracy</strong> or visa-versa</li><li><strong>Accuracy</strong> can be traded for <strong>Robustness</strong> or visa-versa</li></ul><p>It makes sense that speed and accuracy are prioritized considering that’s what trackers are usually supplementing. But it doesn’t explain why robustness is hurt in the process.</p><p>The impact to robustness lies in how trackers determine whether or not they’re still tracking an object. Most trackers take a pass/fail approach and compare a confidence score to some fixed threshold to determine if their object is <strong>tracked (pass) or lost (failed).</strong></p><p>This approach can lead to problems because the range of possible scores differs between objects. This forces many trackers to choose between a <strong>high threshold which increases spurious failures</strong> or a <strong>low threshold</strong> <strong>which increases the chance of drifting</strong>.</p><p>The latter is usually chosen because it allows a wider variety of objects to be tracked accurately with this approach. However, this assumption can cause issues in unexpected ways, as demonstrated below.</p><p><iframe data-src="https://player.vimeo.com/video/441419592?autoplay=1&amp;muted=1&amp;loop=1&amp;quality=720p" title="Bounding Box" frameborder="0" allow="autoplay;" allowfullscreen="" data-expand="-140"></iframe></p><p><strong>Speed <em>and</em> Accuracy and Robustness</strong></p><p>In the video above, the combination of rapid scaling and background perspective change resulted in CSRT scaling incorrectly and not realizing it had drifted.</p><p>Many autonomous systems (e.g drones) rely on correct status reporting to determine if they need to perform more computationally expensive recovery tasks such as detection. If the tracker fails to often (high threshold), resources are wasted and if it doesn’t detect true failures (low threshold), drifting occurs. The latter can have severe affects on autonomous systems because they won’t know anything is wrong.</p><p>This make it clear that robustness is equally important as speed and accuracy. This of course makes the task of balancing a tracker very difficult.</p><p><strong>This is where Teleidoscope’s RAD (Relocalizable Adaptive Discriminative) Tracker comes in.</strong></p><p>RAD auto-calibrates to each object instead of using fixed implementation specific thresholds allowing it to report when tracking becomes unstable and recover itself when it does.</p><p>This allows RAD to track and recover, even in situations where there is very little scene detail.</p><p><iframe data-src="https://player.vimeo.com/video/441420068?autoplay=1&amp;muted=1&amp;loop=1&amp;quality=720p" title="Bounding Box" frameborder="0" allow="autoplay;" allowfullscreen="" data-expand="-140"></iframe></p><br><h3>Teleidoscope’s Visual Object Tracking Framework</h3><p>The RAD tracker is at the core of Teleidoscope’s visual tracking framework which was designed with these issues in mind. Recovery and self-diagnostics are just some of the features that set RAD apart. Designation options for RAD can be seen in the below diagram and will be covered in a future post.</p><p><img src="https://teleidoscope.com/assets/drawing.png" alt="drawing" width="100%"></p><p> For more information, please reach out to <a href="mailto:contact@teleidoscope.com">contact@teleidoscope.com</a>.</p><hr><ul><li></li><li><a rel="next" href="https://teleidoscope.com/blog/better-target-designation-tracking-for-uavs/">Better Target Designation &amp; Tracking for UAVs<!-- --> →</a></li></ul></div></div></div>]]>
            </description>
            <link>https://teleidoscope.com/blog/better-visual-object-tracking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051700</guid>
            <pubDate>Tue, 04 Aug 2020 16:38:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You may finally use JSHint for evil]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24051655">thread link</a>) | @catacombs
<br/>
August 4, 2020 | http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/ | <a href="https://web.archive.org/web/*/http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

<p><strong>This is the first essay in <a href="http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/">a four-part series about relicensing the JSHint
software project</a>.</strong></p>

<p>The process of relicensing JSHint took seven years. That’s far longer than
anyone expected, but seeing this through wasn’t just a matter of endurance. As
I worked with people around the world to move to the MIT Expat license, I
regularly experienced how non-free licensing (even as seemingly trivial as
“Good, not Evil”) poisons the well of free software.</p>

<p>Some numbers might help here. The following graph shows how many times JSHint
has been downloaded from <a href="https://docs.npmjs.com/">npm</a> each week over the past
five years:</p>

<p><img src="http://mikepennisi.com/blog/jshint-watching-the-ship-sink-graph-1.png" alt="JSHint downloads over time"></p>

<p>We had a dip last year, but we’ve since recovered and then some. Over half a
million downloads per week sure sounds impressive, doesn’t it?</p>

<p>It <em>was</em> impressive in 2015. The fact is, npm’s usage has exploded over the
past half decade. Holding steady in this space is actually falling behind. Take
a look at the same statistic for <a href="https://eslint.org/">ESLint</a>, a truly open
source project with the same purpose and target audience as JSHint:</p>

<p><img src="http://mikepennisi.com/blog/jshint-watching-the-ship-sink-graph-2.png" alt="JSHint and ESLint downloads over time"></p>

<p>Suddenly that dip in 2019 doesn’t seem so important. How did JSHint go from
being the most popular tool in this space to one that most developers today
consider antiquated? There are many explanations, but in this essay, I’ll focus
on the effects of non-free licensing.</p>

<h3 id="for-license-sensitive-users">For license-sensitive users</h3>

<p>JSHint was partly licensed under <a href="https://www.gnu.org/licenses/license-list.html#JSON">the JSON
license</a>. It is nearly
identical to the widely-used MIT Expat license, but it includes one additional
clause:</p>

<blockquote>
<p>The Software shall be used for Good, not Evil.</p>
</blockquote>

<p>Because of this clause, folks who respect the practice of software licensing
simply could not use JSHint.</p>

<p>If you’re not versed in legal matters, that probably seems like an odd
restriction. By rejecting JSHint, are people admitting that they want to do
evil? And is that clause actually enforceable, anyway?</p>

<p>The answer to the second question is “no,” and that helps answer the first
question. Legally-conscious objectors aren’t betraying their own dastardly
motivations; they’re refusing to enter into an ambiguous contract. Put
differently: they’re not saying, “I’m an evildoer,” they’re saying, “I don’t
understand what you want.” This consideration disqualified JSHint from
inclusion in all sorts of contexts.</p>

<p>First, there were legally-conscious software repositories. Developers from the
<a href="https://www.debian.org/">Debian</a> and <a href="https://getfedora.org/">Fedora</a>
GNU/Linux distributions independently concluded that they could not include
JSHint due to licensing concerns. That’s why <a href="https://ubuntu.com/">Ubuntu</a>
users can’t download JSHint via <code>sudo apt-get install jshint</code>.</p>

<p>Even in less discerning package managers, folks built tools to empower
developers to make similar decisions on their own. For instance, JSHint has
been available on <a href="https://docs.npmjs.com/">npm</a> since its initial release, but
<a href="https://spdx.org/">SPDX</a> (along with tools like
<a href="https://github.com/ironSource/license-report"><code>license-report</code></a> and
<a href="https://classic.yarnpkg.com/en/docs/cli/licenses">Yarn</a>) has since been
designed to help folks understand the legal requirements of their dependencies.
This seemed like an encouraging trend toward conscientious code sharing, so <a href="https://github.com/jshint/jshint/pull/2420">we
did our part by adopting SPDX in
JSHint</a>.</p>

<p>More recently, an instructor at a US university wrote to the JSHint team asking
for permission to use JSHint in their course. I replied,</p>

<blockquote>
<p>By all means, you are welcome to use the project and its website in your
courses. Please note, however, that the source code is partially
published under the JSON license. The FSF does not recognize this as <a href="http://www.gnu.org/licenses/license-list.html">a
free software license</a> nor
does the Open Source Initiative recognize it as <a href="https://opensource.org/licenses/alphabetical">an open source
license</a>. This detail does not
effect most people in practice, but you may want to verify with your legal
team before relying on the code base.</p>
</blockquote>

<p>Honesty may be the best policy, but it also means fewer people are going to use
your bizarrely-encumbered JavaScript linter.</p>

<p>Finally, programming platforms that “repackaged” JSHint have reconsidered that
practice because of the license issue. There was a time when the popular
content management system <a href="https://wordpress.org/">WordPress</a> repackaged JSHint
in this way. Once they learned of the JSON license, <a href="https://core.trac.wordpress.org/ticket/42850">they replaced JSHint in a
matter of weeks</a>.</p>

<h3 id="for-feature-craving-users">For feature-craving users</h3>

<p>Plenty of people don’t give a fig about free software. Whatever their reason,
they couldn’t care less about the legal terms that are bundled with
publicly-available source code. The “Good, not Evil” clause also pushed them
away, even if they didn’t realize it.</p>

<p>It began with the decline in license-sensitive users. The word “user” is a bit
too passive in the context of open source tooling because folks who use the
software are particularly empowered to contribute back to it. The “user-base”
is directly correlated to the “contributor-base.” When a project like JSHint
loses users, it also loses contributors.</p>

<p>This slows the addition of new features and the correction of bugs. Timeliness
is important for these things, and people perceive delays very negatively. The
best example of this comes from JSHint’s delayed support for async functions.</p>

<p>(The async function is a JavaScript language feature which was <a href="https://tc39.es/ecma262/#sec-intro">introduced in
2017</a>. It’s very popular among developers
but also very difficult for parsers to implement correctly. <a href="https://jshint.com/blog/2019-02-05/release-2-10-0/">It took us over a
year to support it in
JSHint.</a>).</p>

<p>Some expressed their dissatisfaction with the delay in <a href="https://github.com/jshint/jshint/issues/2604#issuecomment-342173639">calm (though somewhat
impatient)
terms</a>:</p>

<blockquote>
<p>Async/await has been at stage 4 for over a month now (and baked into Node and
many mainstream browsers for longer), but jshint has yet to add support.</p>
</blockquote>

<p>…but others were more emotional:</p>

<ul>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-329704124">“You just lost my interest in jshint. Sorry, to [sic]
slow.”</a></li>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-331985362">“Thank you JSHint. It was good while it lasted. Switched to
ESLint.”</a></li>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-340112372">“RIP
Jshint”</a></li>
<li><a href="https://github.com/jshint/jshint/issues/2604#issuecomment-455643712">“Seems like we waited enough. Bye JSHint. It was a good
time.”</a></li>
<li>“I know that you get a lot of complaints about this, but… if you can’t find
a way to include support for async/await, jshint is useless to me. I’m
switching to just using <code>node -c &lt;filename&gt;</code>” (via e-mail)</li>
</ul>

<p>The Internet has a way of surfacing the loudest and angriest perspectives, but
it seems safe to assume there was a substantial group of less vocal developers
who came to a similar conclusion.</p>

<p>A dwindling user/contributor-base is a vicious cycle. Though the movement may
have started with license-conscious folks, everyone felt the pain of the
release cycle equally, and their exodus exacerbated the problem.</p>

<p>This isn’t just a story of open-source “market” forces, though. My own
management decisions contributed to JSHint’s dissatisfying release cycle.</p>

<p>You see, many people express their dependency on software using a range of
versions. They don’t say, “give me Firefox at version 67.02.3” because they
don’t really care about that particular release. What they want is the software
to be familiar but also secure. They’re more likely to say, “give me the latest
version of Firefox 67.” With this statement, they’re trusting the maintainers
of Firefox to provide a program that looks and acts a certain way (i.e. not
exactly like version 65 or version 68) but that also has the latest bug fixes
(so 67.02.4 is preferable to 67.02.3).</p>

<p>This practice generally benefits users and developers alike. In my case,
though, I had a conflicting personal goal: I wanted the relicensed version of
JSHint to reach as many people as possible.</p>

<p>If we made drastic improvements to JSHint, we’d have to release a new major
version. The relicensing effort could continue with the new version, but many
people would continue to use the old version. For all the obsessing I’ve done
about JSHint over the years, I haven’t forgotten that most people aren’t
particularly concerned with the release schedule of their JavaScript linter.
When and if we succeeded, the users of the old version would be cut off from
our success (not to mention the improvements we made from that point forward).</p>

<p>This consideration made me averse to drastic changes in JSHint. Pretty
antithetical for a project maintainer.</p>

<h3 id="software-freedom-matters">Software freedom matters</h3>

<p>For many people, licensing is an esoteric part of software development. It’s a
relatable opinion: the legal frameworks are intimidating, and most
considerations can be addressed by simply defaulting to well-known
free/open-source licenses.</p>

<p>The trouble is that not all software is distributed under well-known
free/open-source licenses. My hope is that the particulars of JSHint’s decay
help folks understand why licensing matters.</p>

<p>After reading the drudgery of JSHint’s slow decline, you might be wondering why
we didn’t just give up. A sinking ship is only tragic if you value the ship. If
<a href="https://eslint.org/">a newer, faster, similarly-named ship</a> sails by, then
maybe it’s time to put down the bailer. It’ll take <a href="http://mikepennisi.com/blog/2020/jshint-dug-in/">another
essay</a> to address that fully.</p>
<ul>
  
</ul>

    </section></div>]]>
            </description>
            <link>http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051655</guid>
            <pubDate>Tue, 04 Aug 2020 16:35:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's build a full-text search engine]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24051229">thread link</a>) | @elorant
<br/>
August 4, 2020 | https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/ | <a href="https://web.archive.org/web/*/https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        

        


        <p>Full-Text Search is one of those tools people use every day without realizing it. If you ever googled "golang coverage report" or tried to find "indoor wireless camera" on an e-commerce website, you used some kind of full-text search.</p>
<p>Full-Text Search (FTS) is a technique for searching text in a collection of documents. A document can refer to a web page, a newspaper article, an email message, or any structured text.</p>
<p>Today we are going to build our own FTS engine. By the end of this post, we'll be able to search across millions of documents in less than a millisecond. We'll start with simple search queries like "give me all documents that contain the word <em>cat</em>" and we'll extend the engine to support more sophisticated boolean queries.</p>
<div>
<p>Note</p>
<p>Most well-known FTS engine is <a href="https://lucene.apache.org/" target="_blank">Lucene</a> (as well as <a href="https://github.com/elastic/elasticsearch" target="_blank">Elasticsearch</a> and Solr built on top of it).</p>
</div>
<div id="why-fts">
<h3>Why FTS<a href="#why-fts" title="Permalink to this headline"> #</a></h3>
<p>Before we start writing code, you may ask "can't we just use <em>grep</em> or have a loop that checks if every document contains the word I'm looking for?". Yes, we can. However, it's not always the best idea.</p>
</div>
<div id="corpus">
<h3>Corpus<a href="#corpus" title="Permalink to this headline"> #</a></h3>
<p>We are going to search a part of the abstract of English Wikipedia. The latest dump is available at <a href="https://dumps.wikimedia.org/enwiki/latest/enwiki-latest-abstract1.xml.gz" target="_blank">dumps.wikimedia.org</a>. As of today, the file size after decompression is 913 MB. The XML file contains over 600K documents.</p>
<p>Document example:</p>
<pre><code><span>&lt;title&gt;</span>Wikipedia: Kit-Cat Klock<span>&lt;/title&gt;</span>
<span>&lt;url&gt;</span>https://en.wikipedia.org/wiki/Kit-Cat_Klock<span>&lt;/url&gt;</span>
<span>&lt;abstract&gt;</span>The Kit-Cat Klock is an art deco novelty wall clock shaped like a grinning cat with cartoon eyes that swivel in time with its pendulum tail.<span>&lt;/abstract&gt;</span></code></pre>
</div>
<div id="loading-documents">
<h3>Loading documents<a href="#loading-documents" title="Permalink to this headline"> #</a></h3>
<p>First, we need to load all the documents from the dump. The built-in <span>encoding/xml</span> package comes very handy:</p>
<pre><code><span>import</span> <span>(</span>
    <span>"encoding/xml"</span>
    <span>"os"</span>
<span>)</span>

<span>type</span> <span>document</span> <span>struct</span> <span>{</span>
    <span>Title</span> <span>string</span> <span>`xml:"title"`</span>
    <span>URL</span>   <span>string</span> <span>`xml:"url"`</span>
    <span>Text</span>  <span>string</span> <span>`xml:"abstract"`</span>
    <span>ID</span>    <span>int</span>
<span>}</span>

<span>func</span> <span>loadDocuments</span><span>(</span><span>path</span> <span>string</span><span>)</span> <span>([]</span><span>document</span><span>,</span> <span>error</span><span>)</span> <span>{</span>
    <span>f</span><span>,</span> <span>err</span> <span>:=</span> <span>os</span><span>.</span><span>Open</span><span>(</span><span>path</span><span>)</span>
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>
    <span>defer</span> <span>f</span><span>.</span><span>Close</span><span>()</span>

    <span>dec</span> <span>:=</span> <span>xml</span><span>.</span><span>NewDecoder</span><span>(</span><span>f</span><span>)</span>
    <span>dump</span> <span>:=</span> <span>struct</span> <span>{</span>
        <span>Documents</span> <span>[]</span><span>document</span> <span>`xml:"doc"`</span>
    <span>}{}</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>dec</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>dump</span><span>);</span> <span>err</span> <span>!=</span> <span>nil</span> <span>{</span>
        <span>return</span> <span>nil</span><span>,</span> <span>err</span>
    <span>}</span>

    <span>docs</span> <span>:=</span> <span>dump</span><span>.</span><span>Documents</span>
    <span>for</span> <span>i</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>docs</span><span>[</span><span>i</span><span>].</span><span>ID</span> <span>=</span> <span>i</span>
    <span>}</span>
    <span>return</span> <span>docs</span><span>,</span> <span>nil</span>
<span>}</span></code></pre>
<p>Every loaded document gets assigned a unique identifier.
To keep things simple, the first loaded document gets assigned ID=0, the second ID=1 and so on.</p>
</div>
<div id="first-attempt">
<h3>First attempt<a href="#first-attempt" title="Permalink to this headline"> #</a></h3>
<div id="searching-the-content">
<h4>Searching the content<a href="#searching-the-content" title="Permalink to this headline"> #</a></h4>
<p>Now that we have all documents loaded into memory, we can try to find the ones about cats. At first, let's loop through all documents and check if they contain the substring <em>cat</em>:</p>
<pre><code><span>func</span> <span>search</span><span>(</span><span>docs</span> <span>[]</span><span>document</span><span>,</span> <span>term</span> <span>string</span><span>)</span> <span>[]</span><span>document</span> <span>{</span>
    <span>var</span> <span>r</span> <span>[]</span><span>document</span>
    <span>for</span> <span>_</span><span>,</span> <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>if</span> <span>strings</span><span>.</span><span>Contains</span><span>(</span><span>doc</span><span>.</span><span>Text</span><span>,</span> <span>term</span><span>)</span> <span>{</span>
            <span>r</span> <span>=</span> <span>append</span><span>(</span><span>r</span><span>,</span> <span>doc</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<p>On my laptop, the search phase takes 103ms - not too bad.
If you spot check a few documents from the output, you may notice that the function matches <em>caterpillar</em> and <em>category</em>, but doesn't match <em>Cat</em> with the capital <em>C</em>. That's not quite what I was looking for.</p>
<p>We need to fix two things before moving forward:</p>
<ul>
<li><p>Make the search case-insensitive (so <em>Cat</em> matches as well).</p></li>
<li><p>Match on a word boundary rather than on a substring (so <em>caterpillar</em> and <em>communication</em> don't match).</p></li>
</ul>
</div>
<div id="searching-with-regular-expressions">
<h4>Searching with regular expressions<a href="#searching-with-regular-expressions" title="Permalink to this headline"> #</a></h4>
<p>One solution that quickly comes to mind and allows implementing both requirements is <em>regular expressions</em>.</p>
<p>Here it is - <span><span>(?i)\bcat\b</span></span>:</p>
<ul>
<li><p><span><span>(?i)</span></span> makes the regex case-insensitive</p></li>
<li><p><span>\b</span> matches a word boundary (position where one side is a word character and another side is not a word character)</p></li>
</ul>
<pre><code><span>func</span> <span>search</span><span>(</span><span>docs</span> <span>[]</span><span>document</span><span>,</span> <span>term</span> <span>string</span><span>)</span> <span>[]</span><span>document</span> <span>{</span>
    <span>re</span> <span>:=</span> <span>regexp</span><span>.</span><span>MustCompile</span><span>(</span><span>`(?i)\b`</span> <span>+</span> <span>term</span> <span>+</span> <span>`\b`</span><span>)</span> <span>// Don't do this in production, it's a security risk. term needs to be sanitized.
</span>    <span>var</span> <span>r</span> <span>[]</span><span>document</span>
    <span>for</span> <span>_</span><span>,</span> <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>if</span> <span>re</span><span>.</span><span>MatchString</span><span>(</span><span>doc</span><span>.</span><span>Text</span><span>)</span> <span>{</span>
            <span>r</span> <span>=</span> <span>append</span><span>(</span><span>r</span><span>,</span> <span>doc</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<p>Ugh, the search took more than 2 seconds. As you can see, things started getting slow even with 600K documents. While the approach is easy to implement, it doesn't scale well. As the dataset grows larger, we need to scan more and more documents. The time complexity of this algorithm is linear - the number of documents required to scan is equal to the total number of documents. If we had 6M documents instead of 600K, the search would take 20 seconds. We need to do better than that.</p>
</div>
</div>
<div id="inverted-index">
<h3>Inverted Index<a href="#inverted-index" title="Permalink to this headline"> #</a></h3>
<p>To make search queries faster, we'll preprocess the text and build an index in advance.</p>
<p>The core of FTS is a data structure called <em>Inverted Index</em>.
The Inverted Index associates every word in documents with documents that contain the word.</p>
<p>Example:</p>
<pre><code><span>documents</span> <span>=</span> <span>{</span>
    <span>1</span><span>:</span> <span>"a donut on a glass plate"</span><span>,</span>
    <span>2</span><span>:</span> <span>"only the donut"</span><span>,</span>
    <span>3</span><span>:</span> <span>"listen to the drum machine"</span><span>,</span>
<span>}</span>

<span>index</span> <span>=</span> <span>{</span>
    <span>"a"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"donut"</span><span>:</span> <span>[</span><span>1</span><span>,</span> <span>2</span><span>],</span>
    <span>"on"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"glass"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"plate"</span><span>:</span> <span>[</span><span>1</span><span>],</span>
    <span>"only"</span><span>:</span> <span>[</span><span>2</span><span>],</span>
    <span>"the"</span><span>:</span> <span>[</span><span>2</span><span>,</span> <span>3</span><span>],</span>
    <span>"listen"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
    <span>"to"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
    <span>"drum"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
    <span>"machine"</span><span>:</span> <span>[</span><span>3</span><span>],</span>
<span>}</span></code></pre>
<p>Below is a real-world example of the Inverted Index. An index in a book where a term references a page number:</p>
<p><img alt="" src="https://artem.krylysov.com/images/2020-fts/book-index.png">
</p></div>
<div id="text-analysis">
<h3>Text analysis<a href="#text-analysis" title="Permalink to this headline"> #</a></h3>
<p>Before we start building the index, we need to break the raw text down into a list of words (tokens) suitable for indexing and searching.</p>
<p>The text analyzer consists of a tokenizer and multiple filters.</p>
<p><img alt="" src="https://artem.krylysov.com/images/2020-fts/text-analysis.png">
</p></div>
<div id="tokenizer">
<h3>Tokenizer<a href="#tokenizer" title="Permalink to this headline"> #</a></h3>
<p>The tokenizer is the first step of text analysis. Its job is to convert text into a list of tokens. Our implementation splits the text on a word boundary and removes punctuation marks:</p>
<pre><code><span>func</span> <span>tokenize</span><span>(</span><span>text</span> <span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>return</span> <span>strings</span><span>.</span><span>FieldsFunc</span><span>(</span><span>text</span><span>,</span> <span>func</span><span>(</span><span>r</span> <span>rune</span><span>)</span> <span>bool</span> <span>{</span>
        <span>// Split on any character that is not a letter or a number.
</span>        <span>return</span> <span>!</span><span>unicode</span><span>.</span><span>IsLetter</span><span>(</span><span>r</span><span>)</span> <span>&amp;&amp;</span> <span>!</span><span>unicode</span><span>.</span><span>IsNumber</span><span>(</span><span>r</span><span>)</span>
    <span>})</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>tokenize</span><span>(</span><span>"A donut on a glass plate. Only the donuts."</span><span>)</span>

<span>[</span><span>"A"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"Only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>]</span></code></pre>
</div>
<div id="filters">
<h3>Filters<a href="#filters" title="Permalink to this headline"> #</a></h3>
<p>In most cases, just converting text into a list of tokens is not enough. To make the text easier to index and search, we'll need to do additional normalization.</p>
<div id="lowercase">
<h4>Lowercase<a href="#lowercase" title="Permalink to this headline"> #</a></h4>
<p>In order to make the search case-insensitive, the lowercase filter converts tokens to lower case. <em>cAt</em>, <em>Cat</em> and <em>caT</em> are normalized to <em>cat</em>.
Later, when we query the index, we'll lower case the search terms as well. This will make the search term <em>cAt</em> match the text <em>Cat</em>.</p>
<pre><code><span>func</span> <span>lowercaseFilter</span><span>(</span><span>tokens</span> <span>[]</span><span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>r</span> <span>:=</span> <span>make</span><span>([]</span><span>string</span><span>,</span> <span>len</span><span>(</span><span>tokens</span><span>))</span>
    <span>for</span> <span>i</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>tokens</span> <span>{</span>
        <span>r</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>strings</span><span>.</span><span>ToLower</span><span>(</span><span>token</span><span>)</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>lowercaseFilter</span><span>([]</span><span>string</span><span>{</span><span>"A"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"Only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>})</span>

<span>[</span><span>"a"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>]</span></code></pre>
</div>
<div id="dropping-common-words">
<h4>Dropping common words<a href="#dropping-common-words" title="Permalink to this headline"> #</a></h4>
<p>Almost any English text contains commonly used words like <em>a</em>, <em>I</em>, <em>the</em> or <em>be</em>. Such words are called <em>stop words</em>. We are going to remove them since almost any document would match the stop words.</p>
<p>There is no "official" list of stop words. Let's exclude the top 10 by the <a href="https://en.wikipedia.org/wiki/Most_common_words_in_English" target="_blank">OEC rank</a>. Feel free to add more:</p>
<pre><code><span>var</span> <span>stopwords</span> <span>=</span> <span>map</span><span>[</span><span>string</span><span>]</span><span>struct</span><span>{}{</span> <span>// I wish Go had built-in sets.
</span>    <span>"a"</span><span>:</span> <span>{},</span> <span>"and"</span><span>:</span> <span>{},</span> <span>"be"</span><span>:</span> <span>{},</span> <span>"have"</span><span>:</span> <span>{},</span> <span>"i"</span><span>:</span> <span>{},</span>
    <span>"in"</span><span>:</span> <span>{},</span> <span>"of"</span><span>:</span> <span>{},</span> <span>"that"</span><span>:</span> <span>{},</span> <span>"the"</span><span>:</span> <span>{},</span> <span>"to"</span><span>:</span> <span>{},</span>
<span>}</span>

<span>func</span> <span>stopwordFilter</span><span>(</span><span>tokens</span> <span>[]</span><span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>r</span> <span>:=</span> <span>make</span><span>([]</span><span>string</span><span>,</span> <span>0</span><span>,</span> <span>len</span><span>(</span><span>tokens</span><span>))</span>
    <span>for</span> <span>_</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>tokens</span> <span>{</span>
        <span>if</span> <span>_</span><span>,</span> <span>ok</span> <span>:=</span> <span>stopwords</span><span>[</span><span>token</span><span>];</span> <span>!</span><span>ok</span> <span>{</span>
            <span>r</span> <span>=</span> <span>append</span><span>(</span><span>r</span><span>,</span> <span>token</span><span>)</span>
        <span>}</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>stopwordFilter</span><span>([]</span><span>string</span><span>{</span><span>"a"</span><span>,</span> <span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"a"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"the"</span><span>,</span> <span>"donuts"</span><span>})</span>

<span>[</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donuts"</span><span>]</span></code></pre>
</div>
<div id="stemming">
<h4>Stemming<a href="#stemming" title="Permalink to this headline"> #</a></h4>
<p>Because of the grammar rules, documents may include different forms of the same word.
Stemming reduces words into their base form. For example, <em>fishing</em>, <em>fished</em> and <em>fisher</em> may be reduced to the base form (stem) <em>fish</em>.</p>
<p>Implementing a stemmer is a non-trivial task, it's not covered in this post. We'll take one of the <a href="https://github.com/kljensen/snowball" target="_blank">existing</a> modules:</p>
<pre><code><span>import</span> <span>snowballeng</span> <span>"github.com/kljensen/snowball/english"</span>

<span>func</span> <span>stemmerFilter</span><span>(</span><span>tokens</span> <span>[]</span><span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>r</span> <span>:=</span> <span>make</span><span>([]</span><span>string</span><span>,</span> <span>len</span><span>(</span><span>tokens</span><span>))</span>
    <span>for</span> <span>i</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>tokens</span> <span>{</span>
        <span>r</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>snowballeng</span><span>.</span><span>Stem</span><span>(</span><span>token</span><span>,</span> <span>false</span><span>)</span>
    <span>}</span>
    <span>return</span> <span>r</span>
<span>}</span></code></pre>
<pre><code><span>&gt;</span> <span>stemmerFilter</span><span>([]</span><span>string</span><span>{</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donuts"</span><span>})</span>

<span>[</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donut"</span><span>]</span></code></pre>
<div>
<p>Note</p>
<p>A stem is not always a valid word. For example, some stemmers may reduce <em>airline</em> to <em>airlin</em>.</p>
</div>
</div>
</div>
<div id="putting-the-analyzer-together">
<h3>Putting the analyzer together<a href="#putting-the-analyzer-together" title="Permalink to this headline"> #</a></h3>
<pre><code><span>func</span> <span>analyze</span><span>(</span><span>text</span> <span>string</span><span>)</span> <span>[]</span><span>string</span> <span>{</span>
    <span>tokens</span> <span>:=</span> <span>tokenize</span><span>(</span><span>text</span><span>)</span>
    <span>tokens</span> <span>=</span> <span>lowercaseFilter</span><span>(</span><span>tokens</span><span>)</span>
    <span>tokens</span> <span>=</span> <span>stopwordFilter</span><span>(</span><span>tokens</span><span>)</span>
    <span>tokens</span> <span>=</span> <span>stemmerFilter</span><span>(</span><span>tokens</span><span>)</span>
    <span>return</span> <span>tokens</span>
<span>}</span></code></pre>
<p>The tokenizer and filters convert sentences into a list of tokens:</p>
<pre><code><span>&gt;</span> <span>analyze</span><span>(</span><span>"A donut on a glass plate. Only the donuts."</span><span>)</span>

<span>[</span><span>"donut"</span><span>,</span> <span>"on"</span><span>,</span> <span>"glass"</span><span>,</span> <span>"plate"</span><span>,</span> <span>"only"</span><span>,</span> <span>"donut"</span><span>]</span></code></pre>
<p>The tokens are ready for indexing.</p>
</div>
<div id="building-the-index">
<h3>Building the index<a href="#building-the-index" title="Permalink to this headline"> #</a></h3>
<p>Back to the inverted index. It maps every word in documents to document IDs.
The built-in <span>map</span> is a good candidate for storing the mapping.
The key in the map is a token (string) and the value is a list of document IDs:</p>
<pre><code><span>type</span> <span>index</span> <span>map</span><span>[</span><span>string</span><span>][]</span><span>int</span></code></pre>
<p>Building the index consists of analyzing the documents and adding their IDs to the map:</p>
<pre><code><span>func</span> <span>(</span><span>idx</span> <span>index</span><span>)</span> <span>add</span><span>(</span><span>docs</span> <span>[]</span><span>document</span><span>)</span> <span>{</span>
    <span>for</span> <span>_</span><span>,</span> <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> <span>{</span>
        <span>for</span> <span>_</span><span>,</span> <span>token</span> <span>:=</span> <span>range</span> <span>analyze</span><span>(</span><span>doc</span><span>.</span><span>Text</span><span>)</span> <span>{</span>
            <span>ids</span> <span>:=</span> <span>idx</span><span>[</span><span>token</span><span>]</span>
            <span>if</span> <span>ids</span> <span>!=</span> <span>nil</span> <span>&amp;&amp;</span> <span>ids</span><span>[</span><span>len</span><span>(</span><span>ids</span><span>)</span><span>-</span><span>1</span><span>]</span> <span>==</span> <span>doc</span><span>.</span><span>ID</span> <span>{</span>
                <span>// Don't add same ID twice.
</span>                <span>continue</span>
            <span>}</span>
            <span>idx</span><span>[</span><span>token</span><span>]</span> <span>=</span> <span>append</span><span>(</span><span>ids</span><span>,</span> <span>doc</span><span>.</span><span>ID</span><span>)</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
    <span>idx</span> <span>:=</span> <span>make</span><span>(</span><span>index</span><span>)</span>
    <span>idx</span><span>.</span><span>add</span><span>([]</span><span>document</span><span>{{</span><span>ID</span><span>:</span> <span>1</span><span>,</span> <span>Text</span><span>:</span> <span>"A donut on a glass plate. Only the donuts."</span><span>}})</span>
    <span>idx</span><span>.</span><span>add</span><span>([]</span><span>document</span><span>{{</span><span>ID</span><span>:</span> <span>2</span><span>,</span> <span>Text</span><span>:</span> <span>"donut is a donut"</span><span>}})</span>
    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>idx</span><span>)</span>
<span>}</span></code></pre>
<p>It works! Each token in the map refers to IDs of the documents that contain the token:</p>
<pre><code>map[donut:[1 2] glass:[1] …</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/">https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/</a></em></p>]]>
            </description>
            <link>https://artem.krylysov.com/blog/2020/07/28/lets-build-a-full-text-search-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24051229</guid>
            <pubDate>Tue, 04 Aug 2020 15:59:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gone Phishing]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24050912">thread link</a>) | @danso
<br/>
August 4, 2020 | https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>here he was, smiling on the <a href="https://www.zinio.com/za/forbes-africa/june-2016-i18106">cover of <em>Forbes Africa</em> magazine</a>, dollar bills raining like confetti. It was June 2016, and Obinwanne Okeke, then 28, was on top of the world; he had just landed a coveted spot on the magazine’s prestigious 30 under 30 list of African entrepreneurs. In the article, he was one of many whiz kids described as “Africa’s bright young things.”</p>



<p>The 17th child of a polygamous father whose mother was the fourth wife, Okeke’s father died when he was 16, and his mother, a teacher, worked multiple jobs to put him and his siblings through school. Growing up in Ukpor, a village in southeastern Nigeria, was tough, and luxuries like sneakers or a Game Boy were hard to come by, he said in a <a href="https://www.bbc.co.uk/sounds/play/p065dtt3">2018 BBC interview</a>. </p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Nigeria-40x48.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Nigeria-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/Nigeria-400x477.png 400w, https://restofworld.org/wp-content/uploads/2020/07/Nigeria-600x715.png 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>But he persevered, he said, studying in South Africa and Australia, earning a master’s degree in international relations and counter-terrorism at Monash University. He started his business in Nigeria in 2013. That business — which, as he has alluded to in other interviews, involved low-cost housing and green homes — expanded into South Africa, Botswana, and Zambia, with a potential addition in Uganda. His interests were worth almost $10 million, <a href="https://iono.fm/e/303518">he said</a>.</p>



<p>Okeke named his business Invictus, after the <a href="https://www.poetryfoundation.org/poems/51642/invictus">poem</a> by William Ernest Henley about resilience in the face of adversity. It was said to be <a href="http://www.openculture.com/2013/12/morgan-freeman-masterfully-recites-nelson-mandelas-favorite-poem-invictus.html">Nelson Mandela’s favorite poem</a>.</p>



<p>“Invictus is in construction, agriculture, oil and gas, telecoms and real estate. He has 28 permanent and 100 part-time employees across nine companies,”<em> Forbes Africa</em> wrote in Okeke’s entry.</p>



<p>But that much-lauded business empire existed alongside Okeke’s criminal enterprises, the FBI later wrote in an August 2019 <a href="https://www.courtlistener.com/recap/gov.uscourts.vaed.450919/gov.uscourts.vaed.450919.5.0_1.pdf">affidavit</a>. Turns out, Okeke had been involved in a string of sophisticated online scams since at least 2015 — including when he was gracing that glossy <em>Forbes Africa</em> cover. He <a href="https://www.thecable.ng/fbi-arrested-invictus-obi-at-dulles-international-airport-just-before-escaping-us">was arrested</a> at Dulles International Airport, Virginia, on August 6, 2019, for defrauding a company of nearly $11 million. He <a href="https://www.justice.gov/usao-edva/pr/nigerian-businessman-pleads-guilty-11-million-fraud-scheme">pleaded guilty</a> to conspiracy to commit wire fraud on June 18, 2020, and now faces up to 20 years in prison at his sentencing in October. Okeke’s rapid ascent as a supposedly successful entrepreneur —&nbsp;and his subsequent defenestration — reflects a growing trend in online scamming known as <a href="https://www.trendmicro.com/vinfo/us/security/definition/business-email-compromise-(bec)">business email compromise (BEC)</a>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/h_15244337-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/h_15244337-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/h_15244337-400x272.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/h_15244337-600x408.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/h_15244337-1600x1088.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/h_15244337-2800x1903.jpg 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="A cyber cafe in Lagos, Nigeria, on April 18, 2019. These cafes are frequented by scammers who refer to themselves as " yahoo="" boys,"="" a="" nod="" to="" the="" online="" chat="" service="" messenger="" where="" love="" scams="" gained="" traction="" nearly="" 20="" years="" ago.="" renee="" holland="" sent="" her="" facebook="" friend="" thousands="" of="" dollars.="" she="" became="" entwined="" in="" global="" fraud="" that="" social="" network="" and="" united="" states="" military="" appear="" helpless="" stop.="" (the="" new="" york="" times)"="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>The tale of</strong> the Nigerian online scammers <a href="https://republic.com.ng/august-september-2019/yahoo-yahoo-naija/">stretches back to the 1990s</a>, when cybercafes sprung up across the country as internet access became increasingly widespread. Young men popularly known as “<a href="https://theconversation.com/meet-the-yahoo-boys-nigerias-undergraduate-conmen-60757">Yahoo boys</a>” became famous for conning their unsuspecting victims out of money by posing as romantic interests — typically American soldiers based in active conflict zones in the Middle East —&nbsp;or as wealthy royals in need of help getting a relative’s money out of some bureaucratic logjam. Their notoriety is now mainstream enough that they’ve become a pop-culture joke. In an <a href="https://www.vulture.com/2016/01/black-ish-recap-season-2-episode-12.html">episode from the second season</a> of the TV show “Black-ish<em>,</em>” a concerned sibling chastised her brother about his potential love interest, convinced he was being duped by a scammer. “This is a middle-aged Nigerian man who wants your money or your kidney,” she told him. The youngest sibling added, “I’m trusting to a fault, and even I know this screams Nigerian scam.”&nbsp;</p>



<p>Okeke’s case reflects how much has changed since then.<strong> </strong>Rather than settling for petty romance schemes, some scammers are now targeting the email accounts of executives at Western<strong> </strong>companies, tricking their companies into sending wire transfers to supposed overseas suppliers who then fraudulently transfer those funds into the scammers’ bank accounts. The stakes involved in BECs are high in nearly every possible way: they target wealthy and prominent victims and use complex tools to defraud them, and if the plot succeeds, it results in a windfall. Whereas the targets of online romance scams are usually older Americans or other lonely Westerners desperate for affection (or the occasional naïf fooled into going into business with a <a href="https://www.popsci.com/story/technology/nigerian-prince-scam-social-engineering/">seemingly sweet-talking African prince</a>), email compromise focuses on businesses ranging from small-sized enterprises to multinational corporations. Scammers typically single out high-level executives, usually the CEO, CFO, or COO, “the real decision-makers who have the power to sign checks and grant approval,” Eniola Fadare, a Lagos-based computer security expert, told <em>Rest of World</em>. The goal, after gaining control of these decision-makers’ email accounts, is to authorize wire payments of money that will largely end up in accounts controlled by the scammers.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_4316-e1595879129282-40x82.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_4316-e1595879129282-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_4316-e1595879129282-400x818.png 400w, https://restofworld.org/wp-content/uploads/2020/07/IMG_4316-e1595879129282-600x1227.png 600w, " sizes="300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>In contrast to romance scams, where the guys — and they’re almost always guys — find their marks on Facebook, Instagram, or any number of dating apps, email compromise is a “patient scam,” Fadare said, that involves quietly shadowing a company or its executives for months, to determine the types of businesses they’re involved in and the vendors who will need to be paid. The operational costs of pulling off one of these scams often add up to millions of naira, but the payoff can be worth it. While romance scammers may make off with anywhere from $350 to $3,000, BEC scammers can potentially rake in much more. Olalekan Jacob Ponle, who also went by the name Mr. Woodbery, was arrested on June 10, 2020, in Dubai for allegedly <a href="https://www.justice.gov/usao-ndil/pr/nigerian-national-expelled-united-arab-emirates-face-cyber-fraud-charge-chicago">stealing $15.2 million</a> in a scam targeting a Chicago-based company.</p>



<p>BEC involves a high degree of sophistication and collaboration between masterminds and co-conspirators, who provide services like designing fake landing pages for hijacking email accounts and harvesting passwords. There are also money mules who provide accounts, sometimes referred to as “houses,” to park the proceeds of the scams. A 24-year-old Lagos-based scammer, who spoke to <em>Rest of World</em> through an intermediary to preserve his anonymity, said that romance scams are “easier and cheaper to do” than BEC scams. But they’re not the sure bet they once were, because of how widespread they are. “People are getting educated and enlightened,” Fadare said.</p>



<p>Business-related scams involve individuals spread around the world, requiring authorities to cooperate across borders; Mr. Woodbery was extradited to the United States after being captured by Dubai police. Last year, 281 individuals, <a href="https://www.justice.gov/opa/pr/281-arrested-worldwide-coordinated-international-enforcement-operation-targeting-hundreds">including 167 in Nigeria</a>, were arrested for their involvement in BEC schemes as part of an international raid called Operation reWired. Arrests were also made in Turkey, Japan, Italy, and elsewhere. The cases are being tried across several jurisdictions in the U.S., because the victims are American.</p>



<p>In a statement from the U.S. Attorney’s Office for the Central District of California on the arrest of Hushpuppi, a <a href="https://www.instagram.com/hushpuppi/">flamboyant Instagram</a> celebrity with 2.5 million followers, U.S. Attorney Nick Hanna <a href="https://www.justice.gov/usao-cdca/pr/nigerian-national-brought-us-face-charges-conspiring-launder-hundreds-millions-dollars">described</a> BEC as “one of the most difficult cybercrimes we encounter as they typically involve a coordinated group of con artists scattered around the world who have experience with computer hacking and exploiting the international financial system.” Paul Delacourt, the assistant director in charge of the FBI’s Los Angeles Field Office, claimed that the FBI recorded $1.7 billion lost to BEC schemes in 2019.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/courtdocs-40x27.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/courtdocs-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/courtdocs-400x267.png 400w, https://restofworld.org/wp-content/uploads/2020/07/courtdocs-600x401.png 600w, https://restofworld.org/wp-content/uploads/2020/07/courtdocs-1600x1068.png 1600w, https://restofworld.org/wp-content/uploads/2020/07/courtdocs-2800x1869.png 2800w, " sizes="(max-width: 640px) 100vw, calc(100vw - 40px)" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>The crime that</strong> got Okeke arrested began on April 1, 2018, making it perhaps the most lucrative prank ever pulled on April Fool’s Day. The victim was Unatrac Holding Ltd, the export sales office of a dealer for Caterpillar, a heavy industrial and farm equipment company. The company is based in Slough, a town about 45 minutes outside of London. According to the FBI statement, Unatrac’s CFO received an email containing a login link for his Microsoft Office 365 account and entered his login details, believing it to be real. Instead, it was a spoof website crafted by Okeke and unnamed associates to gain access to the CFO’s email. </p>



<p>After they did, the hackers sent invoices from an email address intended to mimic that of a legitimate vendor to the CFO’s email, using invoice templates and logos found within the compromised account to lend an air of legitimacy to the documents. Minutes later, those fake invoices were forwarded to Unatrac’s finance team from the CFO’s email. Because the finance staff had no reason to doubt the provenance of the wire transfer requests, they processed about 15 payments between April 11 and April 19, 2018. The company that allegedly submitted the invoices, Pak Fei Trade Ltd, was sent at least three payments that totaled more than $3 million, with the payments going to overseas accounts. In total, almost $11 million was stolen from Unatrac.&nbsp;</p>



<p>About the same time the scam was underway, Okeke <a href="https://guardian.ng/news/nigerian-investment-expert-to-speak-at-lse-africa-summit-in-london/">was an invited speaker</a> at the London School of Economics’s Africa Summit, alongside luminaries like Ghanaian President Nana Akufo-Addo and many other prominent African businesspeople. He also partook in that BBC interview, telling tales of growing up poor and how he was introducing low-income housing to a Nigerian property market saturated with expensive homes.</p>



<p>By the time the company realized it had been hoodwinked, it was too late to cancel the transactions, and little of the funds were recovered, according to the FBI statement. To avoid detection, the hackers set up email filters that immediately intercepted legitimate emails to and from the CFO, marked them as read, and moved them to another folder outside the inbox.</p>



<p>Fadare, the security expert, explained that, in conjunction with setting up email filters, scammers do not work “at active hours when they know the CEO is awake or busy.”</p>



<p>Additionally, “they clear the emails from the boxes as soon as they’re received. The real CEO, when he logs into his email, is not going to see anything,” he added. Fadare said scammers bank on people not carefully scrutinizing messages …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/">https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/how-a-forbes-cover-star-stole-millions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050912</guid>
            <pubDate>Tue, 04 Aug 2020 15:27:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Planning for My Kidnapping]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 96 (<a href="https://news.ycombinator.com/item?id=24050837">thread link</a>) | @polote
<br/>
August 4, 2020 | https://blog.luap.info/planning-for-my-kidnapping.html | <a href="https://web.archive.org/web/*/https://blog.luap.info/planning-for-my-kidnapping.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		  <div role="main">
	<article>

		


		<p>Imagine tomorrow you go shopping and, for whatever reason, you never come back. Maybe be someone killed you, maybe someone kidnapped you, maybe you had an accident ... Now imagine you are travelling alone in Thailand and you die. How people who know you are going to find out what happen ? if you are being kidnaped how the police will do to find you, if you got lost how people will find you ? If you die how your family is going to find your papers ?</p>
<p>I wanted to find a way to answer all those questions, basically we can sum up the issues in 3 points :
- In case of being kidnaped or getting lost send as much information on your last location, and following locations, your last activity, all your digital information to someone who is going to help liberating you
- In case of dying, sending all your documents (passwords, friends list, legal documents, ...) to your family
- Not sending those documents by mistakes if you are not on the situations above</p>
<h2>First step : collect your position, your activity, your documents, ...</h2>
<p>The first step is to be sure that you have the data that you want to send, on my part, the data are:</p>
<ol>
<li>My current position and recent history</li>
<li>My last know activity and a recent history</li>
<li>The list of my credentials</li>
<li>The list of my legal documents (id, passport, health insurance, work papers, ...)</li>
</ol>
<p>I've written an <a href="https://blog.luap.info/how-i-track-my-life.html">article</a> explaining how I'm doing 1. and 2. (position in real time, and last activity), so this is fixed.</p>
<p>For my credentials, I use <a href="https://keepassxc.org/">keepassXC</a> with a keyfile + a master password, the keyfile and the password db is synced using <a href="https://syncthing.net/">syncthingd</a> with a server that I rent</p>
<p>My legal documents are all tied in one folder on my laptop which is also synced on the same server</p>
<p>So basically we have all the needed documents which are synced in real time on the same server</p>
<h2>Second step : Choose how to trigger the sharing of documents</h2>
<p>The biggest problem is you want the alert to react quickly but not fire because you have been sleeping for 8 hours. So I chose to rely on the time since I last changed of activity. Currently after 24h without changing activity a first notification is sent to my own email so that if this is a mistake I can stop the system before it is too late. And if 6 hours later I've still haven't changed of activity then a mail is sent to my parents.</p>
<p>So basically if something happens to me my parents will be notified maximum 30h after the event, this is not so great but this is a good beginning. In the future I should try to have an adaptive delay depending on the last activity, for example if my last activity is eating, then I won't eat for 24 hours, so I can trigger the alert after for example 4 hours.</p>
<h2>Last step : What to put inside the notification</h2>
<p>So my parents will receive an email after 30 hours of inactivity. In this email there is a link to a page which will allow them to retrieve all the documents.
<img alt="email" src="https://blog.luap.info/static/kidnap/email.png"></p>
<p>The link is random generated link available only 6 hours, this is important to be safe as you don't want anyone to be able to access all your passwords ...</p>
<p>And the page, there are explanations of that page is about, like, "maybe I was kidnaped, maybe I'm lost, check my last time active on whatsapp, contact xxxx to see if he knows anything"
You can also view the current position of my phone and a small location history, that way you can see if I'm still moving, or if the last point if 30 hours old, you can also see my last activity and when it started</p>
<p>And finally you can get the list of all my passwords, for that purpose I created a form, with 6 facts on my life, that only my parents can know all of them, like what was the color of my first car ..., then there you can submit your answer, there is a rate limit on the number of requests you can make to prevent a brute force. If the 6 answers are true, the backend will decode the keepassxc archive and return a json of the archive, containing all of my credentials, including the ssh password to connect on the server to get all the paper documents.</p>
<h2>Conclusion</h2>
<p>I know that all of that is far from being perfect. I check every few months that the alerting is working, by decreasing the delay to trigger the alert, but the server can go down, ton of things can happen to make the system not working, so that's why I tried to keep everything as simple as possible, postgresql + django + cron. Someone should create a service to manage that at a bigger scale, or maybe that's something that 1password or others could include in their offer</p>	

	</article>


		  </div>	

		  

	  </div></div>]]>
            </description>
            <link>https://blog.luap.info/planning-for-my-kidnapping.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24050837</guid>
            <pubDate>Tue, 04 Aug 2020 15:20:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unlearn rotation matrices as rotations]]>
            </title>
            <description>
<![CDATA[
Score 247 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24049593">thread link</a>) | @dosshell
<br/>
August 4, 2020 | https://kodkodgames.gitlab.io/rotation_matrices/ | <a href="https://web.archive.org/web/*/https://kodkodgames.gitlab.io/rotation_matrices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <main id="main">
        




<i data-feather="calendar"></i> <time datetime="2020-06-12">2020-06-12</time>

<p>– Hey, Markus! What format is this head-rotation representation in?</p>
<p>– It is a rotation matrix, I answer. Right handed, z forward through the nose and x through the left ear. Our young newly graduated colleague nods his/her head.</p>
<p>After about 10 minutes I hear my name again.</p>
<p>– Markus…. Eh, what order is it?</p>
<p>– Oh no! You have opened Wikipedia? Haven’t you? I answer in despair from my desk.</p>
<p>It happens time to time that a newly graduated engineer (or summer intern) asks me exactly this question. Almost always with the Wikipedia page open at the screen, which I think is horrible (or even worse, some “Learn OpenGL” tutorial).</p>
<p>I <s>steal</s> take a chair to sit down beside the person. This will take a few minutes, we are going to do something that is harder than learning: we are going to unlearn.</p>
<p>It is interesting, I get no questions, or only very short questions, on Euler angels, Rodriguez rotations and actually only one recurrent question on quaternions. But very often I get questions on rotation matrices. I think it is a bit odd since rotation matrices are very simple in comparison to many other rotation representations. I think a big reason for this is the Wikipedia page. It looks something like this:</p>
<p>
\[
R_x(\theta) =
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; \cos \theta &amp;  -\sin \theta \\
0 &amp; \sin \theta  &amp;  \cos \theta
\end{bmatrix}
\]
\[
R_y(\theta) =
\begin{bmatrix}
\cos \theta &amp; 0 &amp; \sin \theta \\
0 &amp; 1 &amp; 0 \\
-\sin \theta &amp; 0 &amp; \cos \theta
\end{bmatrix}
\]
\[
R_z(\theta) =
\begin{bmatrix}
\cos \theta &amp;  -\sin \theta &amp; 0 \\
\sin \theta &amp;   \cos \theta &amp; 0\\
0 &amp; 0 &amp; 1\\
\end{bmatrix}
\]
\[
R =
\begin{bmatrix}
\cos\alpha\cos\beta &amp; \cos\alpha\sin\beta\sin\gamma - \sin\alpha\cos\gamma &amp; \cos\alpha\sin\beta\cos\gamma + \sin\alpha\sin\gamma \\
\sin\alpha\cos\beta &amp; \sin\alpha\sin\beta\sin\gamma + \cos\alpha\cos\gamma &amp; \sin\alpha\sin\beta\cos\gamma - \cos\alpha\sin\gamma \\
-\sin\beta &amp; \cos\beta\sin\gamma &amp; \cos\beta\cos\gamma \\
\end{bmatrix}
\]
</p>
<p>It talks about rotations. Rotation around different axes and their relation to Euler angles. This can be a bit confusing when working with for example a head pose. You can of course think about rotation matrices as if the head rotates around different axes in different order, but it becomes kind of hard to interpret:</p>
<p>
\[
\begin{bmatrix}
 -0.9987820 &amp; 0.0348782 &amp; -0.0348995 \\
  0.0283128 &amp; 0.9844193 &amp;  0.1735424 \\
  0.0404086 &amp; 0.1723429 &amp; -0.9842078
\end{bmatrix}
\]
</p>
<p>So to interpret this we need to solve the following equation system:</p>
<p>
\[
\begin{cases}
-\sin(\beta) &amp; = 0.0404086 \\
\cos(\beta)\sin(\gamma) &amp; = 0.1723429 \\
\cos(\alpha)\cos(\beta) &amp; = -0.9987820
\end{cases}
\]
</p>
<p>and then we get an <em>“intrinsic rotation whose Tait–Bryan angles are α, β, γ, about axes z, y, x”</em> to visualize in our head.</p>
<p>Its sad because I think rotation matrices are one of the easiest representation to interpret.</p>
<p>Don’t think of them as rotations, think of them as a unit vectors of a new coordinate systems.</p>
<p><img src="https://kodkodgames.gitlab.io/post/matrix_cs.png#center" alt="plot of the coordinate system"></p>
<p>We describe where the coordinate system is located related to another coordinate system (where we rotate from), for example from the camera’s coordinate system perspective (z forward, y upwards). The first column of the rotation matrix is the new x-axis expressed in the old coordinate system, the second column is the y-axis and so on. An identity matrix would yield in no rotation since all unit vectors would be the same as the previous coordinate system.</p>
<p>
\[
R =
\begin{bmatrix}
  X_x &amp; Y_x &amp; Z_x \\
  X_y &amp; Y_y &amp;  Z_y \\
  X_z &amp; Y_z &amp; Z_z
\end{bmatrix}
\]
</p> 
<p>Lets go back to the example with the head expressed in the camera coordinate system and assume the head position is atfront of the camera. So by interpret the previous matrix, we can look at the new z-axis:</p>
<p>
\[
Z_{axis} = 
\begin{bmatrix}
Z_x \\
Z_y \\
Z_z
\end{bmatrix}
=
\begin{bmatrix}
-0.0348995 \\
0.1735424 \\
-0.9842078
\end{bmatrix}
\]
</p>
<p>(Remember that z-axis is where the head’s nose is pointing)</p>
<p>We can quickly see that z-part of the z-axis is almost -1. This means the nose is pointing at the opposite direction as the camera, eg. towards the camera if the person is sitting at front of it.</p>
<p>We can also se that the persons head is rotated a little bit up (positive y component of the z-axis) and is pointing a little bit to the right of the camera (negative x component).</p>
<p>And that’s it! Rotation matrices just describe the unit vectors of a new coordinate system.</p>
<p>…</p>
<p>– Hey, Markus! How come this matrix is 4x4?</p>
<p>// Markus</p>
<p><a href="https://news.ycombinator.com/item?id=24049593">HN discussion</a></p>




      </main>
    </div></div>]]>
            </description>
            <link>https://kodkodgames.gitlab.io/rotation_matrices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049593</guid>
            <pubDate>Tue, 04 Aug 2020 13:12:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crux SQL]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24049349">thread link</a>) | @yogthos
<br/>
August 4, 2020 | https://juxt.pro/blog/crux-sql | <a href="https://web.archive.org/web/*/https://juxt.pro/blog/crux-sql">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="preamble">
<div>
<p>We were pleased when <a href="https://opencrux.com/">Crux</a> was included in the
ThoughtWorks
<a href="https://www.thoughtworks.com/radar/platforms/crux">technology radar</a>
with a recommendation to <strong>assess</strong>:</p>
<div>
<blockquote>
<p>Crux is an open-source document database with bitemporal graph
queries…​ it’s currently in alpha and lacks SQL support, but you can
use a Datalog query interface for reading and traversing
relationships.</p>
</blockquote>
<p>
— ThoughtWorks Technology Radar
</p>
</div>
<p>We are fans of <a href="https://en.wikipedia.org/wiki/Datalog">Datalog</a> and the
power it gives. Although it’s not directly compatible and may drift
out further, we’ve based our Datalog query API on
<a href="https://docs.datomic.com/on-prem/query">Datomic’s</a>, where Datalog
is represented as a pattern-matching declarative data-structure.</p>
<p>Datalog is easy to construct and parse and it is natural to make use
of custom predicates and rules as part of the logical pattern
matching.</p>
<p>We love Datalog, but it’s also fair to say that a sizeable chunk of
potential users will want to use SQL. Be it for users who want to run
ad-hoc SQL queries without needing to know Datalog, or for integration
between systems where SQL is the lingua franca, it’s important that we
support it.</p>
</div>
</div>
<div>
<h2 id="_code_crux_sql_code"><a href="#_code_crux_sql_code"></a><code>crux-sql</code></h2>
<div>
<p>We have created a new <code>crux-sql</code> module in Crux which makes use of the
<a href="https://calcite.apache.org/">Apache Calcite</a> SQL query planning engine. Calcite
is a powerful library for exposing SQL queries against arbitrary data-sources
and has been integrated with a variety of DBMSs such as Cassandra, Mongo and
Elastic, as well as Big Data systems like Hive, Drill, Flink and Dremio.</p>
<p>Calcite has been around for a long while and is still very
active. We’re grateful for the work the Calcite team have put into
this tool and the power it gives, as well as the friendly community that
has built up around it.</p>
<p>We run Calcite in-process as part of a Crux node, so there’s no need
to set up any additional infrastructure. Rather you just need to add
the <code>crux-sql</code> module dependency:</p>
<div>
<div>
<pre><code data-lang="clojure">[juxt/crux-sql "RELEASE"]]</code></pre>
</div>
</div>
<p>We have integrated Calcite such that SQL queries are translated to
efficient Datalog queries, including sorts and inner joins.</p>
<p>You can avoid the relatively small overhead of preparing queries by
using PreparedStatements.</p>
<p>Please visit the
<a href="https://github.com/juxt/crux/blob/master/crux-sql/README.adoc">module
README</a> for how to get going with some simple steps, or please watch
this video:</p>
<div>
<p>
<iframe src="https://www.youtube.com/embed/HEBL_ue2wbw?rel=0" frameborder="0" allowfullscreen=""></iframe>
</p>
</div>
<p>The <code>crux-sql</code> module allows for both in-process SQL queries and for
remote JDBC queries using
<a href="https://calcite.apache.org/avatica/">Avatica</a>. This is covered in the
docs.</p>
</div>
</div>
<div>
<h2 id="_next_up"><a href="#_next_up"></a>Next Up</h2>
<div>
<p>See the <code>crux-sql</code>
<a href="https://github.com/juxt/crux/tree/master/crux-sql">README</a> for more
details.</p>
<p>Stay tuned for another blog and video on how to write Crux SQL
bitemporal queries.</p>
<p>As ever, if you have queries about Crux, please ping the team:</p>

<p><em>Image credit: Oliver Hine</em></p>
</div>
</div></div></div>]]>
            </description>
            <link>https://juxt.pro/blog/crux-sql</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049349</guid>
            <pubDate>Tue, 04 Aug 2020 12:45:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your calendar should be an allowlist, not a blocklist]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24049260">thread link</a>) | @mcrittenden
<br/>
August 4, 2020 | https://critter.blog/2020/08/03/your-calendar-should-be-an-allowlist-not-a-blocklist/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/03/your-calendar-should-be-an-allowlist-not-a-blocklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-549">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Does your company have a culture of letting everyone see each other’s calendars? Do people often schedule meetings whenever there are openings, without asking?</p>



<p>If so, your calendar is a blocklist. The only time that isn’t available for someone to steal is time that’s already spoken for. This is a problem. A time slot that isn’t currently booked shouldn’t be free real estate. That’s my TIME! You can’t just take it without asking.</p>



<p>Instead, your calendars should be an allowlist. You should say “if you want to talk to me, this is when you can” instead of “this is when you CAN’T.” You shouldn’t have to defend our time like it’s gold and your coworkers are pirates. You should just assume that it’s yours to spend how you see fit.</p>



<p>Some people block time off to try to protect their calendars. They create big “GTD” blocks on their calendar and hope that nobody books meetings on top of them. I’ve even heard of people creating fake or vague meeting titles in hopes that others will assume there’s a real meeting at that time. This is a crappy workaround, and it isn’t enough. </p>



<p>The solution should be office hours. You should be able to say say “I’m free for meetings from 2-5pm on Tuesdays and Thursdays, and if you want to talk to me then that’s when you can.” In most companies, doing that would make you an annoyance. Those companies don’t respect Deep Work. </p>



<p>Scheduling meetings should be a little bit painful. You should have to really want it. You should be forced to question yourself. <em>Is this actually worth me going to the trouble of figuring out how to schedule this meeting? Or could it instead be an asynchronous discussion? </em>Office hours and calendars-as-allowlists have this added benefit.</p>



<p>Is your calendar an allowlist or a blocklist?</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/03/your-calendar-should-be-an-allowlist-not-a-blocklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049260</guid>
            <pubDate>Tue, 04 Aug 2020 12:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Continuous PostgreSQL backups using WAL-G]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24049087">thread link</a>) | @kiwicopple
<br/>
August 4, 2020 | https://supabase.io/blog/2020/08/02/continuous-postgresql-backup-walg | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/08/02/continuous-postgresql-backup-walg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Have you ever wanted to restore your database's state to a particular moment in time? This post explains how, using WAL-G.</p><h2>Introduction</h2><p><a href="https://github.com/wal-g/wal-g" target="_blank" rel="noopener noreferrer">WAL-G</a> is an <a href="https://www.citusdata.com/blog/2017/08/18/introducing-wal-g-faster-restores-for-postgres/" target="_blank" rel="noopener noreferrer">open-source continuous archiving tool</a> used to easily set up and recover from <a href="https://supabase.io/blog/2020/07/17/postgresql-physical-logical-backups" target="_blank" rel="noopener noreferrer">physical backups</a> in Postgres. It mainly handles the storage and retrieval of physical backups and WAL archives to and from a chosen cloud storage provider. In this post, we will walk you through on how to effortlessly set up WAL-G for your database as well as guide you on what to do if and when disaster strikes.</p><h2>Prerequisites</h2><p>For this tutorial, we will be using two instances running Postgres databases on <a href="https://releases.ubuntu.com/18.04/" target="_blank" rel="noopener noreferrer">Ubuntu 18.04</a>. One instance will act as your main database, the other is your recovery database. If you’re using another operating system some file paths may vary.</p><h3>Installations</h3><p>Make sure the below packages are installed in your instances. Alternatively, you can spin up the <a href="https://github.com/supabase/postgres/releases/tag/v0.13.0" target="_blank" rel="noopener noreferrer">latest version</a> of <a href="https://github.com/supabase/postgres" target="_blank" rel="noopener noreferrer">Supabase Postgres</a> which would already have everything configured and installed, along with other <a href="https://github.com/supabase/postgres#features" target="_blank" rel="noopener noreferrer">goodies</a>. It is readily available in either the <a href="https://aws.amazon.com/marketplace/pp/B08915TCJ2?qid=1595854723755&amp;sr=0-1&amp;ref_=srh_res_product_title" target="_blank" rel="noopener noreferrer">AWS</a> or <a href="https://marketplace.digitalocean.com/apps/supabase-postgres" target="_blank" rel="noopener noreferrer">Digital Ocean</a> marketplaces and only takes <a href="https://supabase.io/docs/postgres/postgres-intro" target="_blank" rel="noopener noreferrer">a few minutes</a> to get running.</p><h4>Postgres 12</h4><p>A quick installation guide can be found <a href="https://www.postgresql.org/download/linux/ubuntu/" target="_blank" rel="noopener noreferrer">here</a>.</p><h4>envdir</h4><p><a href="http://manpages.ubuntu.com/manpages/bionic/man8/envdir.8.html" target="_blank" rel="noopener noreferrer">envdir</a> allows us to run other programs with a modified environment based on the files in the provided directory. This can be installed through the <a href="https://cr.yp.to/daemontools.html" target="_blank" rel="noopener noreferrer">daemontools</a> package:</p><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> </span><span>apt-get</span><span> </span><span>install</span><span> -y daemontools</span></p></div></div></div></div><h4>WAL-G</h4><div><div><div tabindex="0"><div><p><span>$ </span><span>wget</span><span> https://github.com/wal-g/wal-g/releases/download/v0.2.15/wal-g.linux-amd64.tar.gz</span></p><p><span>$ </span><span>tar</span><span> -zxvf wal-g.linux-amd64.tar.gz</span></p><p><span>$ </span><span>mv</span><span> wal-g /usr/local/bin/</span></p></div></div></div></div><h3>AWS credentials and resources</h3><p>When storing backups, WAL-G has numerous <a href="https://github.com/wal-g/wal-g#configuration" target="_blank" rel="noopener noreferrer">cloud storage provider options</a> for us to choose from. For this tutorial, we will be using AWS. Have the following prepared:</p><ul><li>AWS Access &amp; Secret keys.</li><li>An S3 bucket.</li></ul><h2>Setting it up</h2><h3>1. Configure environment variables</h3><p>The directory <code>/etc/wal-g.d/env</code> is created and contains files that stores environment variables. It would later be used in WAL-G commands via envdir.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>umask</span><span> </span><span>u</span><span>=</span><span>rwx,g</span><span>=</span><span>rx,o</span><span>=</span><span></span></p><p><span>$ </span><span>mkdir</span><span> -p /etc/wal-g.d/env</span></p><p><span>$ </span><span>echo</span><span> </span><span>'secret-key-content'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_SECRET_ACCESS_KEY</span></p><p><span>$ </span><span>echo</span><span> </span><span>'access-key'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_ACCESS_KEY_ID</span></p><p><span>$ </span><span>echo</span><span> </span><span>'s3://backup-bucket/project-directory'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/WALG_S3_PREFIX</span></p><p><span>$ </span><span>echo</span><span> </span><span>'db password'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/PGPASSWORD</span></p><p><span>$ </span><span>chown</span><span> -R root:postgres /etc/wal-g.d</span></p></div></div></div></div><h3>2. Enable WAL archiving</h3><p>Here, we enable <a href="https://www.postgresql.org/docs/12/continuous-archiving.html" target="_blank" rel="noopener noreferrer">WAL archiving</a> and instruct Postgres to store the archives in the specified S3 bucket via WAL-G. </p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"archive_mode = yes"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p><p><span>$ </span><span>echo</span><span> </span><span>"archive_command = 'envdir /etc/wal-g.d/env /usr/local/bin/wal-g wal-push %p'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p><p><span>$ </span><span>echo</span><span> </span><span>"archive_timeout = 60"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p></div></div></div></div><h3>3. Restart the database</h3><p>The database is restarted to let the changes in the configuration to take effect.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> /etc/init.d/postgresql restart</span></p></div></div></div></div><h3>4. Create your first physical backup</h3><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> -su postgres envdir /etc/wal-g.d/env /usr/local/bin/wal-g backup-push /var/lib/postgresql/12/main</span></p></div></div></div></div><p>At this point, if you were to check the S3 path that you provided, the following two newly created and populated directories would be observed:</p><p><img src="https://dev-to-uploads.s3.amazonaws.com/i/lai1mxg62kffyd2khmtm.png" alt="Alt Text"></p><p>From then on, subsequent physical backups would be found in the directory <code>basebackups_005</code> and any WAL archives would be sent to the directory <code>wal_005</code>.</p><h3>5. [Optional] Schedule regular physical backups</h3><p>A CRON job can then be set to schedule physical backups to be performed everyday:</p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"0 0 * * * postgres /usr/bin/envdir /etc/wal-g.d/env /usr/local/bin/wal-g backup-push /var/lib/postgresql/12/main"</span><span> </span><span>&gt;</span><span> /etc/cron.d/pg_backup</span></p></div></div></div></div><p>Here, the instance has been instructed to back up the database at the start of each day at midnight. By physically backing up your instance regularly, overall recovery time could be faster. Restoring from a physical backup from yesterday would lead to fewer WAL archive files to be replayed as compared to restoring from one from a month ago.</p><hr><h2>Disaster strikes</h2><p>Something goes wrong with the database or instance. We will now use what available physical backups we have in the S3 bucket to recover and restore all of our data on to a new instance.</p><h3>1. Configure environment variables</h3><p>The configuration should be the <strong>same</strong> as the original instance. For recovery and restoration, we would not need the variable <code>PGPASSWORD</code>.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>umask</span><span> </span><span>u</span><span>=</span><span>rwx,g</span><span>=</span><span>rx,o</span><span>=</span><span></span></p><p><span>$ </span><span>mkdir</span><span> -p /etc/wal-g.d/env</span></p><p><span>$ </span><span>echo</span><span> </span><span>'secret-key-content'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_SECRET_ACCESS_KEY</span></p><p><span>$ </span><span>echo</span><span> </span><span>'access-key'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/AWS_ACCESS_KEY_ID</span></p><p><span>$ </span><span>echo</span><span> </span><span>'s3://backup-bucket/project-directory'</span><span> </span><span>&gt;</span><span> /etc/wal-g.d/env/WALG_S3_PREFIX</span></p><p><span>$ </span><span>chown</span><span> -R root:postgres /etc/wal-g.d</span></p></div></div></div></div><h3>2. Stop the database</h3><div><div><div tabindex="0"><div><p><span>$ </span><span>sudo</span><span> /etc/init.d/postgresql stop</span></p></div></div></div></div><h3>3. Switch to the user <code>postgres</code></h3><h3>4. Prepare the database for recovery</h3><h4>Set restore_command</h4><p>Through <a href="https://www.postgresql.org/docs/12/continuous-archiving.html#:~:text=must%20specify%20is%20the%20restore_command,%20which%20tells%20PostgreSQL%20how%20to%20retrieve%20archived%20WAL%20file%20segments" target="_blank" rel="noopener noreferrer">restore_command</a>, we instruct Postgres to pull all WAL archives from our S3 bucket to use during recovery.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"restore_command = '/usr/bin/envdir /etc/wal-g.d/env /usr/local/bin/wal-g wal-fetch </span><span>\"</span><span>%f</span><span>\"</span><span> </span><span>\"</span><span>%p</span><span>\"</span><span> &gt;&gt; /tmp/wal.log 2&gt;&amp;1'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p></div></div></div></div><h4>[Optional] Achieve Point in Time Recovery (PITR)</h4><p>If we want to restore the database only up to a certain point in time (eg. right before the disaster), we can do so by setting both <a href="https://www.postgresql.org/docs/12/runtime-config-wal.html#:~:text=recovery_target_time%20(timestamp)" target="_blank" rel="noopener noreferrer">recovery_target_time</a> and <a href="https://www.postgresql.org/docs/12/runtime-config-wal.html#:~:text=recovery_target_action%20(enum)" target="_blank" rel="noopener noreferrer">recovery_target_action</a>. Do note that the timezone would need to match that of the original instance. This is usually at the UTC (+00) timezone.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>echo</span><span> </span><span>"recovery_target_time = '2020-07-27 01:23:00.000000+00'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p><p><span>$ </span><span>echo</span><span> </span><span>"recovery_target_action = 'promote'"</span><span> </span><span>&gt;&gt;</span><span> /etc/postgresql/12/main/postgresql.conf</span></p></div></div></div></div><h3>5. Restore from physical backup</h3><p>The current data directory is deleted and is replaced with the latest version of the physical backup from the S3 bucket.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>rm</span><span> -rf /var/lib/postgresql/12/main</span></p><p><span>$ envdir /etc/wal-g.d/env /usr/local/bin/wal-g backup-fetch /var/lib/postgresql/12/main LATEST</span></p></div></div></div></div><h3>6. Create a <code>recovery.signal</code> file</h3><p>This file <a href="https://www.postgresql.org/docs/12/continuous-archiving.html#:~:text=Set%20recovery%20configuration%20settings%20in%20postgresql.conf%20(see%20Section%2019.5.4)%20and%20create%20a%20file%20recovery.signal%20in%20the%20cluster%20data%20directory" target="_blank" rel="noopener noreferrer">instructs</a> Postgres that the database should undergo recovery mode upon start.</p><div><div><div tabindex="0"><div><p><span>$ </span><span>touch</span><span> /var/lib/postgresql/12/main/recovery.signal</span></p></div></div></div></div><h3>7. Log out of <code>postgres</code> and start the database</h3><div><div><div tabindex="0"><div><p><span>$ </span><span>exit</span><span></span></p><p><span>$ </span><span>sudo</span><span> /etc/init.d/postgresql start</span></p></div></div></div></div><p>Once Postgres finishes starting up and completes recovery mode, all data or data up to the specified point in time would have been successfully restored on to the new instance. Disaster averted.</p></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/08/02/continuous-postgresql-backup-walg</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049087</guid>
            <pubDate>Tue, 04 Aug 2020 12:03:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Former Producer: Why I’m now leaving MSNBC]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24049074">thread link</a>) | @JumpCrisscross
<br/>
August 4, 2020 | https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc | <a href="https://web.archive.org/web/*/https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.12.3"><div dir="ltr"><div><div id="viewer-a77ug"><div><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc" data-pin-media="https://static.wixstatic.com/media/184124_757ebdc8f58e426980cca18975e93103~mv2.jpg/v1/fit/w_2852,h_2819,al_c,q_80/file.png" src="https://static.wixstatic.com/media/184124_757ebdc8f58e426980cca18975e93103~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-9reau">“Just quit.”</p><p id="viewer-cqtr">﻿That’s the advice Alec gave a year and a half ago when I expressed concerns about my job. </p><p id="viewer-dur7n">“You just quit.  It’s that simple.”</p><p id="viewer-8vmcf">“Stay at MSNBC at least until the midterms,” Jeffrey said a couple years back.  He advised to watch and see what happens.</p><p id="viewer-ekaih">“Hang in there… you’re needed,” Elizabeth recommended last winter.  “I was in your shoes when I was younger but I stuck it out.”</p><p id="viewer-bvvpg">A year and a half ago, simply quitting my job without knowing my next step sounded pretty radical.  So I stuck it out a bit longer until we were in the middle of a pandemic to make a truly radical move.  </p><p id="viewer-dj9sj">July 24th was my last day at MSNBC.  I don’t know what I’m going to do next exactly but I simply couldn’t stay there anymore.  My colleagues are very smart people with good intentions.  The problem is the job itself.  It forces skilled journalists to make bad decisions on a daily basis.  </p><p id="viewer-fl8l2">You may not watch MSNBC but just know that this problem still affects you, too.  All the commercial networks function the same – and no doubt that content seeps into your social media feed, one way or the other.</p><p id="viewer-4g127">It’s possible that I’m more sensitive to the editorial process due to my background in public radio, where no decision I ever witnessed was predicated on how a topic or guest would “rate.”  The longer I was at MSNBC, the more I saw such choices — it’s practically baked in to the editorial process – and those decisions affect news content every day.  Likewise, it’s taboo to discuss how the ratings scheme distorts content, or it’s simply taken for granted, because everyone in the commercial broadcast news industry is doing the exact same thing.  </p><p id="viewer-9c0ji">But behind closed doors, industry leaders will admit the damage that’s being done.</p><p id="viewer-5n5uh">“We are a cancer and there is no cure,” a successful and insightful TV veteran said to me.  “But if you could find a cure, it would change the world.”</p><p id="viewer-39g2k">As it is, this cancer stokes national division, even in the middle of a civil rights crisis.  The model blocks diversity of thought and content because the networks have incentive to amplify fringe voices and events, at the expense of others… all because it pumps up the ratings. </p><p id="viewer-a2lh5">This cancer risks human lives, even in the middle of a pandemic.  The primary focus quickly became what Donald Trump was doing (poorly) to address the crisis, rather than the science itself.  As new details have become available about antibodies, a vaccine, or how COVID actually spreads, producers still want to focus on the politics.  Important facts or studies get buried.</p><p id="viewer-d6q8h">This cancer risks our democracy, even in the middle of a presidential election.  Any discussion about the election usually focuses on Donald Trump, not Joe Biden, a repeat offense from 2016 (Trump smothers out all other coverage).  Also important is to ensure citizens can vote by mail this year, but I’ve watched that topic get ignored or “killed” numerous times.</p><p id="viewer-k0ik">Context and factual data are often considered too cumbersome for the audience.  There may be some truth to that (our education system really should improve the critical thinking skills of Americans) – but another hard truth is that it is the job of journalists to teach and inform, which means they might need to figure out a better way to do that.  They could contemplate more creative methods for captivating an audience.  Just about anything would improve the current process, which can be pretty rudimentary (think basing today’s content on whatever rated well yesterday, or look to see what’s trending online today).</p><p id="viewer-a360v">Occasionally, the producers will choose to do a topic or story without regard for how they think it will rate, but that is the exception, not the rule.  Due to the simple structure of the industry – the desire to charge more money for commercials, as well as the ratings bonuses that top-tier decision-makers earn – they always relapse into their old profitable programming habits.</p><p id="viewer-3haev">I understand that the journalistic process is largely subjective and any group of individuals may justify a different set of priorities on any given day.  Therefore, it’s particularly notable to me, for one, that nearly every rundown at the network basically is the same, hour after hour.  And two, they use this subjective nature of the news to justify economically beneficial decisions.  I’ve even heard producers deny their role as journalists.  A very capable senior producer once said: “Our viewers don’t really consider us the news.  They come to us for comfort.”</p><p id="viewer-a1lqp">Again, personally, I don’t think the people need to change.  I think the job itself needs to change.  There is a better way to do this.  I’m not so cynical to think that we are absolutely doomed (though we are on that path).  I know we can find a cure.  If we can figure how to send a man to the moon, if Alex Trebek can defy the odds with stage 4 pancreatic cancer, and if Harry Reid can actually overcome pancreatic cancer (he’s now cancer free), then we can fix this, too. </p><p id="viewer-2jvfe">“Not everything that is faced can be changed, but nothing can be changed until it is faced.”</p><p id="viewer-evref">I know James Baldwin wasn’t thinking about MSNBC when he wrote that line in 1962, but those words spoke loudly to me in the summer of 2020.  Unfortunately, many of the same ailments are still at stake today.  Now maybe we can’t really change the inherently broken structure of broadcast news, but I know for certain that it won’t change unless we actually face it, in public, and at least try to change it. </p><p id="viewer-9pbe9">Through this pandemic and the surreal, alienating lockdown, I’ve witnessed many people question their lives and what they’re doing with their time on this planet.  I reckon I’m one of those people, looking for greater meaning and truth.  As much as I love my life in New York City and really don’t want to leave, I feel fortunate to be able to return to Virginia in the near term to reconnect with family, friends, and a community of independent journalists.  I’m both nervous and excited about this change.  Thanks to COVID-19, I’m learning to live with uncertainty. </p><p id="viewer-2bttl">And so very soon, I’m going to be seeking you out, any one of you who also may sense that the news is fundamentally flawed and is frustrated by it.  This effort will start informally but I hope to crystallize a plan for when better, safer days are upon us.  On that front, feel free to reach out anytime if you would like to discuss any of this – whether in agreement or not.  More than ever, I’m craving a full and civil discourse. </p><p id="viewer-ei74m">Until next time, thank you for reading.  I wish you all well.</p><p id="viewer-56pls">Ariana</p></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.arianapekary.net/post/personal-news-why-i-m-now-leaving-msnbc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24049074</guid>
            <pubDate>Tue, 04 Aug 2020 12:02:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rogue Wave of Enterprise SaaS]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24048714">thread link</a>) | @chesterarthur
<br/>
August 4, 2020 | https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://staysaasy.com/assets/rogue-wave/freakwave.jpg" alt="Freak wave"></p>

<p>During the pandemic, I’ve done my civic duty and spent lockdown reading a ton of random stuff on the internet. In the midst of a Wikipedia binge, I went down a rabbit hole on <a href="https://en.wikipedia.org/wiki/Rogue_wave">rogue waves</a>: massive waves that occur in the middle of the ocean, endangering ships and generating <a href="https://www.youtube.com/watch?v=pu4ogCy5d4k">kickass Youtube content</a>.</p>

<p>The concept of a rogue wave reminded me of a particularly challenging stage in the life of many venture-backed enterprise SaaS startups. Similar to how a rogue wave forms, during this phase many Small Problems coincide and create a Big Problem. Also like rogue waves, this moment in the life of a high-growth enterprise SaaS business is uncommon – it seems to occur around $5-20 million ARR, which relatively few companies reach, and can seem almost mythical. And finally, the effects of both rogue waves and this challenging startup stage are predictable: if you spend long enough on the high seas, they’re waiting for you.</p>

<p>I’ve seen this phenomenon both in-person as an operator and as an observer of other companies, and I do believe it’s real. I’m writing this essay in order to:</p>

<ul>
  <li>Share what I’ve seen</li>
  <li>Provide some opinions on what you can do about it</li>
</ul>

<p>Hopefully I can be the crusty old mariner bringing back tales that others find useful.</p>

<h2 id="hitting-the-wall">Hitting the Wall</h2>

<p><img src="https://staysaasy.com/assets/rogue-wave/boat.jpg" alt="Big boat, bigger wave">
Startups can be stressful</p>

<p>The rogue wave typically seems to hit between $5M and $20M in ARR. If you’re operating with a common venture-backed SaaS model of <a href="https://www.saastr.com/how-to-figure-out-your-competitors-revenues-in-about-70-seconds/">$1-200k ARR per employee</a>, this is around where you’ll hit the <a href="https://www.bbc.com/future/article/20191001-dunbars-number-why-we-can-only-maintain-150-relationships">Dunbar number</a> of ~150 people: the point where you can no longer operate as a large family, and need to start acting like a corporation. <em>(Note that the post linked is from 2012 – SaaS has since exploded, and more companies are raising huge rounds and hiring more on less revenue)</em></p>

<p>Crossing the 150-person barrier is both operationally and emotionally difficult:</p>

<ul>
  <li>Operational: We have so many teams, we need regular status reports!</li>
  <li>Emotional: Why do I need to send <em>you</em> a status report all of a sudden, I thought we were all friends here?!</li>
</ul>

<p>This transition point is also when many leaders who excelled in scrappy startup mode <a href="https://staysaasy.com/scaling/2020/06/27/hardest-part-of-startup-scale-yourself.html">struggle to level up</a> in a larger organization. Some successfully scale themselves (slow, painful) and others will leave the company (fast, but often even more painful).</p>

<p>Many of the first contracts that you closed post-traction come up for renewal around this point (in the enterprise – SMB SaaS has less predictable growth profiles). If you’re following a <a href="https://www.battery.com/powered/helping-entrepreneurs-triple-triple-double-double-double-to-a-billion-dollar-company/">triple-triple-double-double-double</a> growth path, you’ll be at roughly your second triple. There will be too many customers for the founding team to personally visit and retain everyone.</p>

<p>At this point you’ll need to renew “real” customers, not just friends who took a flyer on your infant product. These aren’t the earliest adopters who will be with you through thick and thin and are really closer to partners. These are real live paying customers who will leave if your product is screwed up. As these renewals approach, a mature post-sales motion becomes essential.</p>

<p>The expectations around your revenue also become more real at this stage. Under about $10M ARR, your revenue projections can be a mild shitshow. But the expectation that you’ll have at least some semblance of predictability steadily increases.</p>

<p>And through it all you need to continue to scale the product. Your code is no longer a series of never-ending green fields rolling off into the distance, and non-trivial parts of your product will need to be meaningfully restructured. You’re burdened by decisions made years ago, often by people who are no longer on the team.</p>

<p>This is especially true for enterprise SaaS. Enterprise products are much more unwieldy than jewel-box consumer products, as they have to support many more users and workflows. Consumer products are like Chipotle: a small, carefully curated set of menu items, built for elegance and efficiency. Enterprise products are like the Cheesecake Factory: you can get steak, pasta, a milkshake and 4 kinds of margarita in the same meal. You need to level up how your team builds products.</p>

<h2 id="cresting-the-wave">Cresting the Wave</h2>

<p>I’m writing about this phenomenon because if you haven’t seen or heard about it, there isn’t really a good way to realize that it might be coming. Even if it isn’t preventable, it’s better to know what’s on the horizon. After all, being able to see around corners is why many companies hire experienced operators.</p>

<p>I won’t claim to be an expert on how to react, but I can share a few things that I think work well and a few that don’t, and what I would do if I had to go through this phase again.</p>

<h3 id="the-crew">The Crew</h3>

<p>First, I would do my best to get the right team in place in advance. In particular, I would make sure that I had very strong functional heads for the functions that will be strained the most: Product, Engineering, Marketing, Sales, Support, and Customer Success. You don’t need every role covered, but it saves headaches to know that some parts of the team are bulletproof. This isn’t the time for unforced errors.</p>

<p><img src="https://staysaasy.com/assets/rogue-wave/pirate-crew.jpg" alt="Pirates of the Caribbean crew">
You want a senior crew. You can tell that Sharkman here has experience and won’t freak out when the database goes down or a large account churns.</p>

<p>I also recommend hiring senior team members who can help see around corners and anticipate issues. This is a taxing time period because it’s so damn busy, and raw, well-directed horsepower tends to carry the day in those situations. More importantly, seasoned operators have typically seen challenging times before, and have the composure to handle them calmly because they know that things are always on fire.</p>

<p>It’s tempting during these busy times to make very junior hires such as new college graduates or coding bootcamp grads just to put butts in seats. These folks can be excellent hires in calmer times, but the chaos caused by too many inexperienced employees is very difficult while you’re cresting the wave.</p>

<h3 id="steering-the-ship">Steering the Ship</h3>

<p>Startups are generally fairly stressful, and that’s heightened in this time period. When operational problems strike in stressful times, it’s common to blame the people involved rather than processes – in reality, bad processes or incentives are usually the root cause.</p>

<p>Generally speaking, the faster you’re growing, the more lightweight your processes should be. When you’re in rapid scaling mode your operational tempo is constantly changing, so there’s no point boiling the ocean to create a perfect process when next month so much will have changed.</p>

<p>For example: when confronting a startup rogue wave, I would not choose to reinvent a completely new system for launching new features. Instead, use 20% of the time to set up a simple, predictable process that gives you 80% of the value. Example: set up a recurring check-in meeting where upcoming releases are discussed by PMs and Tech Leads + a Slack thread where all new releases are announced when they go-live. It won’t be perfect, but you can get this up and running in 15 minutes.</p>

<h3 id="commit">Commit</h3>

<p>This is not the time to hedge your decisions or waffle on strategy.</p>

<p>For example: in general, I prefer to give people a generous window of time to grow into stretch roles. Promoting from within builds continuity, leads to a more invested team, and motivates others by demonstrating that you’re creating strong career paths. But in this phase it’s especially important that you commit to keeping or replacing leaders fast, as there’s just too much going on.</p>

<p>If you’re 30% of the way up a 100 foot wall of water and decide to adjust course, you’re going to get slammed.</p>

<h3 id="keeping-calm">Keeping Calm</h3>

<p>Whatever you do, <em>don’t freak out</em>. When it feels like shit is hitting the fan everywhere, it’s easy to want to react and search for magic solutions. Hire a new Head of X! Spend less! No wait, spend <em>more</em>! Pause development and focus on tech debt! Actually our largest customer needs more features, cancel all tech debt projects!</p>

<p>In reality, to take a line from The Sopranos, <a href="https://www.youtube.com/watch?v=_po7So0MKq4">it won’t be cinematic</a>. Life isn’t a movie. There are no magic fixes – this challenging phase gets resolved by showing up and executing in an unflashy way for months. Magic fixes never really exist, and that’s especially true since this crucible stems from several medium-sized problems amplifying one another.</p>

<p>Searching for a unified solution to your troubles risks distraction. The road is reasonably straightforward and the challenges are tractable: there are just a lot of them. Just like an actual rogue wave, you can’t flee or dodge the factors that make crossing these rogue waves so difficult. You succeed by pointing your boat right at the problem and hitting the gas. Keeping calm doesn’t mean being stubborn or refusing to change, but it does mean that you can’t second guess your decisions – especially when it feels like you’re climbing a wall of water.</p>

<h2 id="takeaways">Takeaways</h2>

<p>Not everyone makes it over the wave – of the roughly 10 cases that I’ve observed, roughly half had their growth stunted for at least several years after hitting this stage. In my opinion this SaaS rogue wave should be taken seriously.</p>

<p>But the good news is that once you’ve crossed the wave, you can speed up again. As you’re rising up the wall everything goes into slow motion; but once you’ve crested the top, your acceleration can increase again as you’ve set yourself up with a more stable operating model and a hardened team.</p>

<p>This is a wonderful time, as there’s so much opportunity. Your team is still in place. The market opportunity is there, and people are buying. And once you’re over the top, the water is much calmer towards the horizon.</p>

<p>In conclusion:</p>

<ul>
  <li>Many challenging situations tend to arise simultaneously when high growth enterprise SaaS companies hit roughly $5-20 million ARR.</li>
  <li>The good news is that after this phase things get easier – the bad news is that it’s not easily avoidable.</li>
  <li>The best way to move forward is to focus on executing – and don’t be overly reactive.</li>
</ul>

    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/scaling/2020/07/29/the-rogue-wave-of-enterprise-saas.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048714</guid>
            <pubDate>Tue, 04 Aug 2020 11:05:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SIMD Everywhere: 0.5.0]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 53 (<a href="https://news.ycombinator.com/item?id=24048562">thread link</a>) | @lelf
<br/>
August 4, 2020 | https://simd-everywhere.github.io/blog/announcements/release/2020/06/21/0.5.0-release.html | <a href="https://web.archive.org/web/*/https://simd-everywhere.github.io/blog/announcements/release/2020/06/21/0.5.0-release.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>I’m pleased to announce the availability of the first release of <a href="https://github.com/simd-everywhere/simde">SIMD
Everywhere</a> (SIMDe),
<a href="https://github.com/simd-everywhere/simde/releases">version 0.5.0</a>,
representing more than three years of work by over a dozen developers.</p>

<p>SIMDe is a permissively-licensed (MIT) header-only library which
provides fast, portable implementations of
<a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a> intrinsics for platforms
which aren’t natively supported by the API in question.</p>

<p>For example, with SIMDe you can use
<a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a> on
<a href="https://en.wikipedia.org/wiki/ARM_architecture">ARM</a>,
<a href="https://en.wikipedia.org/wiki/IBM_POWER_instruction_set_architecture">POWER</a>,
<a href="https://webassembly.org/">WebAssembly</a>, or almost any platform with a
C compiler.  That includes, of course, x86 CPUs which don’t support
the ISA extension in question (<em>e.g.</em>, calling AVX-512F functions on a
CPU which doesn’t natively support them).</p>

<p>If the target natively supports the SIMD extension in question there
is no performance penalty for using SIMDe.  Otherwise, accelerated
implementations, such as NEON on ARM, AltiVec on POWER, WASM SIMD on
WebAssembly, etc., are used when available to provide good
performance.</p>

<p>SIMDe has already been used to port several packages to additional
architectures through either upstream support or distribution
packages, <a href="https://wiki.debian.org/SIMDEverywhere">particularly on
Debian</a>.</p>

<p>If you’d like to play with SIMDe online, you can do so <a href="https://simde.netlify.app/godbolt/demo">on Compiler
Explorer</a>.</p>

<h2 id="what-is-in-050">What is in 0.5.0</h2>

<p>The 0.5.0 release is SIMDe’s first release.  It includes complete
implementations of:</p>

<ul>
  <li>MMX</li>
  <li>SSE</li>
  <li>SSE2</li>
  <li>SSE3</li>
  <li>SSSE3</li>
  <li>SSE4.1</li>
  <li>AVX</li>
  <li>FMA</li>
  <li>GFNI</li>
</ul>

<p>We also have rapidly progressing implementations of many other
extensions including NEON, AVX2, SVML, and several AVX-512 extensions
(AVX-512F, AVX-512BW, AVX-512VL, etc.).</p>

<p>Additionally, we have an extensive test suite to verify our
implementations.</p>

<h2 id="what-is-coming-next">What is coming next</h2>

<p>Work on SIMDe is proceeding rapidly, but there are a lot of functions
to implement… x86 alone has about 6,000 SIMD functions, and we’ve
implemented about 2,000 of them.  We will keep adding more functions
and improving the implementations we already have.</p>

<p>Our NEON implementation is being worked on very actively right now
by Sean Maher and Christopher Moore, and is expected to continue
progressing rapidly.</p>

<p>We currently have two Google Summer of Code students working on the
project as well; <a href="https://masterchef2209.wordpress.com/2020/06/17/guide-to-intel-sse4-2-crc-intrinisics-implementation-for-simde/">Hidayat
Khan</a>
is working on finishing up AVX2, and <a href="https://medium.com/@himanshi18037">Himanshi
Mathur</a> is focused on SVML.</p>

<p>If you’re interested in using SIMDe but need some specific functions
to be implemented first, please <a href="https://github.com/simd-everywhere/simde/issues/new">file an
issue</a> and we may
be able to prioritize those functions.</p>

<h2 id="getting-involved">Getting Involved</h2>

<p>If you’re interested in helping out please get in touch.  We have <a href="https://gitter.im/simd-everywhere/community">a
chat room on Gitter</a>
which is fairly active if you have questions, or of course you can
just dive right in on <a href="https://github.com/simd-everywhere/simde/issues">the issue
tracker</a>.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://simd-everywhere.github.io/blog/announcements/release/2020/06/21/0.5.0-release.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048562</guid>
            <pubDate>Tue, 04 Aug 2020 10:36:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Royalty-Free SVG Illustrations and Animations]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24048508">thread link</a>) | @andyydao
<br/>
August 4, 2020 | https://www.pixeltrue.com/free-illustrations | <a href="https://web.archive.org/web/*/https://www.pixeltrue.com/free-illustrations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<!-- End Facebook Pixel Code -->


<!-- Global site tag (gtag.js) - Google Analytics -->










<div><div data-collapse="medium" data-animation="default" data-duration="400" role="banner"><div><p><a href="https://www.pixeltrue.com/illustrations"><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard.png" srcset="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard-p-500.png 500w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard-p-800.png 800w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5e3aa42df0539d7ca0cc413e_Artboard.png 969w" sizes="(max-width: 991px) 120px, (max-width: 1919px) 130px, 200px" alt=""></a></p></div></div></div><div><div><div><p>To be the first to know about upcoming free illustrations consider signing up to our <a href="#newsletter">newsletter</a> <a target="_blank" href="http://bit.ly/popupcheck"><strong></strong></a>.</p><p>These <strong>Free SVG Illustrations</strong> AND <strong>Lottie Animations</strong> are available for free for personal and commercial use (MIT License). In other words: <strong>you can do whatever you want with them.</strong></p></div></div></div><div><div role="list"><div role="listitem"><p>robot error settings broken repair</p><a href="https://www.pixeltrue.com/free/error-monochrome" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FError%20BW.zip?alt=media&amp;token=a45f1df1-2a6d-4197-8708-95a6881eb3ad" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div><div role="listitem"><p>robot error settings broken repair</p><a href="https://www.pixeltrue.com/free/error-colour" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FError%20-%20Colour.zip?alt=media&amp;token=ed6065b8-f5cd-4348-9f91-2da69a82f6e8" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div><div role="listitem"><p>success health fitness celebration finish marathon</p><a href="https://www.pixeltrue.com/free/success-monochrome" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FSuccess%20BW.zip?alt=media&amp;token=0a501d4a-66d4-4dda-8f7b-dbf32ee138f9" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div><div role="listitem"><p>success health fitness celebration finish marathon</p><a href="https://www.pixeltrue.com/free/success-colour" target="_blank"></a><p><a href="https://firebasestorage.googleapis.com/v0/b/illustrations-membership.appspot.com/o/Free%20Illustrations%2FSuccess%20Colour.zip?alt=media&amp;token=95783604-14b8-40eb-b4a5-6fc36adefb95" data-gatrack="free illustrations,download button,User clicked download button">DOWNLOAD</a></p></div></div></div><div id="newsletter"><div><p>Get new free illustrations every week emailed to you<br></p><p>Plus nothing but quality pixels in your inbox every week!<br></p><div><div><p>Success! Stay tuned for some exciting content 🔥</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->
 



















<!-- Start Infinite Scroll -->



<!-- End Infinite Scroll -->





</div>]]>
            </description>
            <link>https://www.pixeltrue.com/free-illustrations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048508</guid>
            <pubDate>Tue, 04 Aug 2020 10:25:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Myth and Monolith – The Nine Elms Cold Store]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24048477">thread link</a>) | @yummypaint
<br/>
August 4, 2020 | https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/ | <a href="https://web.archive.org/web/*/https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div>
<p><strong>A new skyscraper –</strong> <strong>or two – thrusts itself up into the skies of Vauxhall-Nine Elms every year, it seems. It may be hard to imagine now, writes Andrew Rogers, but for the final third of the last millennium, the area’s skyline hardly changed at all. </strong></p>



<figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon.png" alt="" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon.png 939w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon-300x218.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Richard-Gallon-768x559.png 768w" sizes="(max-width: 939px) 100vw, 939px"><figcaption><em>Nine Elms Cold Store. Photograph by Richard Gallon.</em></figcaption></figure>



<p>For 35 years between 1964 and 1999 almost every view of Vauxhall was dominated by one building – the Nine Elms Cold Store. And it wasn’t even the tallest.</p>



<p>Even when the much taller (88m) Market Towers<span id="easy-footnote-1-9140"></span><span><a href="#easy-footnote-bottom-1-9140" title="Since demolished in preparation for the ‘landmark’ (what – another one?) One Nine Elms development featuring residential, office, hotel and retail space."><sup>1</sup></a></span> came along in 1975, it barely succeeded in distracting the eye from the cold store. This giant, concrete, windowless, and for years redundant, monolith was very much Vauxhall’s landmark and a symbol of SW8’s almost dystopian-looking late-industrial landscape.</p>



<p>For most of its life it stood empty, or if not quite empty then abandoned by its owners. It was often emphatically not empty. According to legend it was used as a cruising ground, a performance space, a recording studio, and a temple for devil worship. Some say people died in there, and that it featured in an episode of <em>The Sweeney</em>.<span id="easy-footnote-2-9140"></span><span><a href="#easy-footnote-bottom-2-9140" title="‘In From the Cold’. Season 3 Episode 2."><sup>2</sup></a></span> Can these things possibly be true?’ Urban myths surely.</p>



<p>But we’re getting ahead of ourselves. Let’s start almost at the beginning.</p>



<h2>1964–1979: The Chill Years</h2>



<p>The Nine Elms Cold Store stored cold things for less than half of its life. It held meat, fish, butter and cheese for 15 years then nothing for 20.</p>



<p>It opened on 30 November 1964<span id="easy-footnote-3-9140"></span><span><a href="#easy-footnote-bottom-3-9140" title="‘£1M. Cold Store Opened’, <em>The Times.</em> Tuesday, 1 December 1964."><sup>3</sup></a></span> on land previously occupied by the <a href="https://vauxhallhistory.org/gas/">South Metropolitan Gas Works</a> which in turn had been built on the site of <a href="https://vauxhallhistory.org/candles/">Price’s Patent Candle Company</a>‘s Belmont works. The current occupant is the St George Tower and the green-glass, wing-topped St George Wharf apartments. Were these to be pitted against the derelict cold store in an ugliness competition it’s difficult to say who would win.</p>



<p>Anyway, the cold store was built, filling in Vauxhall Creek – the last vestige of the river Effra – in the process.<span id="easy-footnote-4-9140"></span><span><a href="#easy-footnote-bottom-4-9140" title="Jon Newman (2016), <em>River Effra: South London’s Secret Spine</em>. Oxford: Signal Books."><sup>4</sup></a></span></p>



<p>The opening merited a mention in <em>The Times</em> which reported that ‘Europe’s most modern cold store’ had cost its owners London Cold Storage Co (one of the Associated Fisheries Group of Companies) more than £1 million to build. With a capacity of two million cubic feet it could hold more than 16,000 tons of food<span id="easy-footnote-5-9140"></span><span><a href="#easy-footnote-bottom-5-9140" title="<em>The Times</em>, ibid."><sup>5</sup></a></span> and goods could be loaded and unloaded there faster and more efficiently than at any other cold store in Europe.<span id="easy-footnote-6-9140"></span><span><a href="#easy-footnote-bottom-6-9140" title="<em>Refrigeration and Air Conditioning</em>, Volume 68, Nos. 802–807."><sup>6</sup></a></span> Its purpose was to store produce for frozen-food processors and distributors.<span id="easy-footnote-7-9140"></span><span><a href="#easy-footnote-bottom-7-9140" title="‘Quick Turn-round at New London Cold Store’, <em>Commercial Motor</em>, 11 Dec 1964."><sup>7</sup></a></span></p>



<p>But why here? Why Nine Elms?</p>



<p>One reason was that the site was available. The gas works had disappeared in 1956 and the site was being used as a coach park. <a rel="noreferrer noopener" href="http://svsfilm.com/nineelms/bruns.htm" target="_blank">According to one account</a>, ‘Here a thieves’ market thrived, carefully observed and recorded by police officers watching from the top floor windows of <a href="https://vauxhallhistory.org/brunswick-house/">Brunswick House</a>.’</p>



<figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton.png" alt="Monochrome shot of Nine Elms Cold Store from the north side of the Thames. Copyright Martin Picton" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton.png 939w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton-300x212.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/Nine-Elms-Cold-Store-Martin-Picton-768x541.png 768w" sizes="(max-width: 939px) 100vw, 939px"><figcaption><em>The Cold Store seen from the north bank of the Thames. Photograph by Martin Picton.</em></figcaption></figure>



<p>The location had excellent transport connections – river, road, and rail. Two barges could be unloaded simultaneously at the Cold Store’s 90ft Thames jetty<span id="easy-footnote-8-9140"></span><span><a href="#easy-footnote-bottom-8-9140" title="<em>Refrigeration and Air Conditioning</em>, Vol. 68, Nos. 802–807."><sup>8</sup></a></span> and eight lorries at a time could use the four covered loading bays, according to a report in <em>Commercial Motor</em>.<span id="easy-footnote-9-9140"></span><span><a href="#easy-footnote-bottom-9-9140" title="‘Quick Turn-round at New London Cold Store’, <em>Commercial Motor</em>, 11 Dec 1964."><sup>9</sup></a></span> ‘Hydraulic dock levellers are used at the lorry bays and electric pallet trucks and other mechanical aids are widely used,’ swooned the periodical in its report on the opening of the cold store.</p>



<p>In 1965 most of Nine Elms (including the site of the New Covent Garden Market and the since-shunted flower market) was occupied by railway yards. Today, the area’s railway history is all but forgotten but for 10 years from 1838 the area boasted its very own and quite grand railway terminus which was the end of the line for trains coming in from Woking and later Southampton. <a href="https://vauxhallhistory.org/nine-elms-station/">Nine Elms Station</a> stood at the end of Nine Elms Lane (then just called Nine Elms) which at that time emerged onto the Wandsworth Road roughly opposite the end of Miles Street (not Parry Street, as now). In 1848 the line was diverted before it reached the station to the new terminus at Waterloo via a new station at Vauxhall. The now-sidelined (literally) Nine Elms area became a massive railway yard and for over 120 years served variously as a carriage and wagon works, a goods depot and a locomotive depot.</p>



<div><figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall.png" alt="" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall.png 418w, https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall-296x300.png 296w, https://vauxhallhistory.org/wp-content/uploads/2020/04/map-of-vauxhall-75x75.png 75w" sizes="(max-width: 418px) 100vw, 418px"></figure><p>When it was built in 1965 the Cold Store was served by lines which reached it by crossing Nine Elms Lane, as this map from around 1967 shows.</p></div>



<p>At this point, Nine Elms Lane still met the Wandsworth Road just north of Miles Street. It was presumably rerouted to its current position (opposite Parry Street) in the early 1970s when New Covent Garden flower market was built.</p>



<p>Sadly the Cold Store’s triple-transport-threat status was short-lived – the railway yard closed just two years later, in 1967.</p>



<h2>1979–1999: The Wilderness Years</h2>



<p>In 1979, 15 years after it opened, the Nine Elms Cold Store closed. Why?</p>



<p>Advances in refrigeration, the increase in air transportation, the demise of river-based haulage seem likely factors. And Associated Fisheries’ cold storage business had been badly affected by the UK’s 1973–75 recession.<span id="easy-footnote-10-9140"></span><span><a href="#easy-footnote-bottom-10-9140" title="‘Associated Fisheries declines’, <em>The Times</em>, 9 July 1981."><sup>10</sup></a></span> But the value of the site must have played a significant role. In fact, the Chairman of Associated Fisheries suggested so much as far back as 1973 when the Cold Store had been open for less than a decade:</p>



<blockquote><p>Giving news to shareholders of Associated Fisheries […] Mr P. M. Tapscott, chairman refers to the proposed development of the Thames frontage on the south side of Vauxhall Bridge and the fact that AF’s Nine Elms cold store, a site of 1.6 acres, adjoins this development. Possibilities of re-development are, therefore, being closely examined.<span id="easy-footnote-11-9140"></span><span><a href="#easy-footnote-bottom-11-9140" title="‘Chairmen&amp;#8217;s Reports’, <em>The Times</em>, 28 Nov 1973."><sup>11</sup></a></span></p></blockquote>



<p>London Cold Storage divested itself of the site pretty quickly after the Cold Store closed. In November 1980, <em>The Times</em> reported that contracts had been exchanged on the sale of the cold store and other property for £1.67 million cash with completion due on February 5.<span id="easy-footnote-12-9140"></span><span><a href="#easy-footnote-bottom-12-9140" title="&amp;#8216;Associated Fisheries’, <em>The Times</em>, 21 Nov 1980."><sup>12</sup></a></span></p>



<p>Which is when things begin to get really interesting at the Nine Elms Cold Store.</p>



<h2>Development Hell</h2>



<p>Why did it take 20 years for the Cold Store to be demolished? There’s probably a whole book to be written about it if there’s an audience for property development horror porn. Suffice to say that in the early days it involved Ronald Lyon, who could be described as a colourful property developer with an interesting business past.</p>



<p>Lyon got his hands on the Cold Store after the first proposal for the Effra site (which included land on both sides of the bridgefoot) fell apart.</p>



<div><figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant.png" alt="architect's image of never built green giant at nine elms" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant.png 443w, https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant-300x296.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/green-giant-75x75.png 75w" sizes="(max-width: 443px) 100vw, 443px"></figure><p><a href="http://www.skyscrapernews.com/buildings.php?id=4248">The extraordinary 150m ‘Green Giant’ project</a> designed by architects Abbott Howard would have included 100 luxury apartments, 30,000 square metres of office space earmarked for Esso, and a gallery to hold the Tate’s sculpture collection.</p></div>



<p>Then along came Lyon, whose Arunbridge company was granted a controversial Special Development Order from the then Secretary of State for the Environment, Michael Heseltine. This SDO would essentially allow Arunbridge’s office scheme to run roughshod over normal planning procedures. Despite this unfair advantage, Lyon failed to find the funding and the scheme collapsed. The Swiss Bank Julius Baer &amp; Co was holding the site as security against a loan and they sold it to Samuel Properties<span id="easy-footnote-13-9140"></span><span><a href="#easy-footnote-bottom-13-9140" title="‘Samuel Properties plans 1,000 flats on Green Giant site’, <em>The Times</em>, 8 May 1985."><sup>13</sup></a></span> who in turn sold it to a Middle Eastern consortium, who then… well, you get the picture. One of the ongoing barriers to development seems to have been the Borough of Lambeth’s objection to swanky residential schemes of the kind it now welcomes with open arms.</p>



<p>Quite how it took two decades to knock the Cold Store down isn’t clear but one factor seems to have been the cost of demolition. One person involved in a government scheme to build a new Home Office on the Effra site recalls that the Cold Store was to be addressed late in the scheme due to <a rel="noreferrer noopener" href="http://svsfilm.com/nineelms/bruns13.jpg" target="_blank">the cost of demolishing it</a>.</p>



<p>After a long, lingering decline, the Nine Elms Cold Store was finally put out of its misery in (I think) 1999. Thankfully Jonathan Bell was around to record the event for posterity.</p>



<figure><img src="https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms.png" alt="" srcset="https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms.png 939w, https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms-300x220.png 300w, https://vauxhallhistory.org/wp-content/uploads/2020/04/demolition-of-the-cold-store-vauxhall-nine-elms-768x564.png 768w" sizes="(max-width: 939px) 100vw, 939px"><figcaption><em>The demolition of the Cold Store, photographed by Jonathan Bell.</em></figcaption></figure>



<p>But until then, the Cold Store could hardly be described as empty…</p>



<h2>Screen Appearances</h2>



<p>London film makers in search of ‘bleak industrial landscape bordering on dystopian’ needed to look no further than Nine Elms – even before it was abandoned. Less hackneyed, less iconic, and more alien than Battersea Power Station, the Cold Store made fleeting background appearances in films such as <em>Villain</em> (1971), a crime film starring Richard Burton, and <em>The Optimists of Nine Elms</em> (1973) with Peter Sellers. But the most thrilling use of it must surely be the 1976 episode of cop series <em>The Sweeney</em> called ‘In From the Cold’, which featured this exchange on the very roof of the Cold Store.</p>



<figure><p>
<iframe title="The Sweeney Season 3 Episode 2 In From the Cold" width="500" height="375" src="https://www.youtube.com/embed/Ct-eRE5TRm0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<h2>Cruising to Casualty</h2>



<p>After the closure of the Cold Store in 1979 its most frequent visitors were gay men, who adopted it as a night-time cruising ground, handy for rounding off a night out at the nearby Royal Vauxhall Tavern or the Market Tavern which was housed in the Market Towers high-rise. The Cold Store was a bedroom and playroom to many liaisons over the years but was notorious for providing pleasure and danger in almost equal measure – sometimes with fatal consequences.</p>



<p>One visitor who narrowly escaped death but lived to tell the tale is John (not his real name):</p>



<p>“The Nine Elms Cold Store was where you went after a night at the Market Tavern if you didn’t get lucky. You crossed Nine Elms Lane via the footbridge (pedestrians were made to navigate all the Vauxhall Cross main roads that way back then) to a gate just to the left of the wall which still shelters Brunswick House from Nine Elms Lane today. The steel gate was 10 feet high, padlocked, and there was barbed wire across the top, but a gap had been forced open at one side through which you could squeeze to get in to the grounds of the cold store. There was no such thing as site security in those days.</p>



<p>“It was about a …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/">https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/</a></em></p>]]>
            </description>
            <link>https://vauxhallhistory.org/myth-and-monolith-the-nine-elms-cold-store/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048477</guid>
            <pubDate>Tue, 04 Aug 2020 10:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Tolerating Complexity]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24048078">thread link</a>) | @leostera
<br/>
August 4, 2020 | https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html | <a href="https://web.archive.org/web/*/https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <section>
          <h2>AM010</h2>

<p>It was late at night when I realized it was about to happen again.</p>
<p>The existing publishing tools I had at hand weren't particularly good to
showcase what I had in mind, but they were convenient enough that I could just
write and leave the problem of actually reading them to whoever happened to
land on that blog.</p>
<p>I mean, it was just a blog. Starting out with 8 patrons, the traffic it got was
mostly friends. They could bear with it.</p>
<p>But the unfortunate reality is that I can't quite stand watching something
being done poorly. It just broils in my gut the feeling that <em>we can do
better</em>. Editing could be simpler. Publishing could be faster. Thinking could
be easier.</p>
<p>I will try to best it, even if the end result ends up being worse, and while
I'll be the first to admit that perhaps it isn't the most attractive of
qualities, it always teaches me something new. Every now and then I do
manage to do it better. The world around me is a little better for it.</p>
<p>This time I had to sit down and write something. I didn't quite know what yet,
but I knew that how I had been writing was getting in the way of what I wanted
to write. So I took a step back and asked around how are the <em>cool kids</em> doing
it this days.</p>
<p>Many seem to like tools like <a href="https://nextjs.org/">Next.js</a>, <a href="https://gatsbyjs.com/">Gatsby</a>, or
<a href="https://gohugo.io/">Hugo</a>. They all provide some sort of structure or template you fit your
content into, a couple of ways to do theming and navigation, and the
possibility to run the whole shebang as a static or dynamically generated
service.</p>
<p>I just needed some static files, and I needed them in the structure they were
already in, so from the choices I was offered it looked like the winner was in
fact Next.js. It came with a few interesting features that I dismissed as
<a href="http://wiki.c2.com/?BellsWhistlesAndGongs">whistles &amp; bells</a>, and frowned at the requirement that
my pages would have to be translated into React components.</p>
<p>Surely a tool with such an emphasis on the "Developer Experience" would
consider the many formats my data could be in, and accommodate for it. But I
nonetheless decided to translate an essay into some Javascript code, and I
finally felt like I could start writing.</p>
<p>Until I had to embed some code.</p>
<p>Suddenly I was somehow recommended to go down the rabbit of hole of finding
good Javascript component libraries that would do the highlighting for me, that
worked with Next, from withing my own writing, which was now no longer just
text but in fact <em>a computer program posing as an essay</em>.</p>
<p>A quick look under the hood showed me there were over 100,000 lines of
Javascript code to turn my untranscendental words into a god damned website.</p>
<p><em>I sighed</em>.</p>
<p>There is a tolerable amount of complexity involved in doing our every day work.
I use <code>vim</code> and, on my computer, it runs on the Linux kernel. I tolerate the
many millions of lines of code from there down to the hardware it runs.
<strong>Tolerance</strong> here is the key word. They afford me things. Not physical things
like food, but the affordance that your thinking gains when you discover a new
idea.</p>
<p>When I first learned about <code>git</code> I suddenly had a new tool to think. I wasn't
familiar with branching models of Subversion or other versioning tools, but
<code>git</code>'s branches, merges, and code history extended my thinking. I have a vague
understanding of the internals of <code>git</code>, but I <strong>tolerate</strong> this complexity
because of what it affords me.</p>
<p>What was this tool really affording me with this complexity? I already had to
pay the cost of translating my content into the format it wanted of me, what
else is there? Hot reloading of assets. Great. My assets are stylesheet files,
the occasional image, and one or two embedded scripts. I can already refresh
a browser with a keypress. What else is there?</p>
<p>From the looks of it, this tools just doesn't support my use-case very well.
How can something so enormously popular and complicated as Next.js not support
my so seemingly simple use-case? I had to be wrong. Where is all this
complexity heading that I can't leverage it without bringing in even more of
it?</p>
<p>Some complexity exists because the underlying problem is in fact complex. It
needs to be dealt with and it cannot be reduced any further. We tend to call
this <a href="http://worrydream.com/refs/Brooks-NoSilverBullet.pdf"><em>Essential Complexity</em></a>. Did all the complexity
in Next exist only to justify <strong>making me feel productive</strong>?</p>
<p>I started wondering what really was so essentially complex about what I needed
to do, but it didn't take long to put a list of the things that seemed the most
independent from each other:</p>
<ul>
<li>I'd like my Markdown files to be compiled into their corresponding HTML
files, respecting their existing structure</li>
<li>I'd like them to be optionally templated, to share some framing information</li>
<li>I'd like to only do work that needs to be done</li>
<li>I'd like my files to be served in a browser fast, and</li>
<li>I'd like my files to be updated automatically in the browser</li>
</ul>
<p>There were them. 5 requirements that this problem could be broken into.  It
shouldn't take more than a couple of days to explore each one of them in enough
depth to understand whether I was looking at massive Essential Complexity, or
not.</p>
<p>I decided to build this tool.</p>
<h4>1. Compiling Markdown to HTML</h4>
<p><a href="https://daringfireball.net/2004/03/introducing_markdown">Markdown</a> was introduced as a more humane way to write HTML. It has
evolved from a rather moving target of inconsistent syntaxes into a series of
standards, some describing a fairly complex format with plenty of features.</p>
<p>To build a Markdown to HTML compiler I'd have to be clear about <em>which</em>
Markdown format I'd be supporting. Since my content was currently written
mostly following <a href="https://github.github.com/gfm">Github Flavored Markdown</a>, that
seemed like the Markdown to target.</p>
<p>Every compiler has a series of stages that take the initial source code, or a
similar specification of a program, and turns into another language. Some
compilers turn this source code into machine language, some others just turn it
into another high-level language.</p>
<p>Whichever your target is, chances are the compiler will read some binary
strings (sometimes this is just UTF-8 text, sometimes its actual binary encoded
data), and transform them into something that it can operate on. Then it
proceeds to transform these data structures into something that more closely
resembles the desired output, maybe making some checks along the way.</p>
<p>In my case, I designed it to have 3 stages:</p>
<ul>
<li>Parsing of Markdown text — a parsing phase would require a Markdown
parser that would deal with the quirks of GFM, and the CommonMark spec it
builds on.</li>
<li>Transformation between Markdown structures and an HTML tree — this
would take data structures like <code>Paragraph { content: String }</code> or <code>List { elements: Vec&lt;ListElement&gt; }</code> and turn them into the appropriate HTML tree.</li>
<li>Writing out the HTML tree — which would take an <code>DomNode { tag: DomTag, attributes: Vec&lt;DomAttribute&gt;, children: Vec&lt;DomNode&gt; }</code> and turn it into a
String that can be written into a file.</li>
</ul>
<p>You can imagine some scaffolded code for this to look like:</p>
<pre><code>enum MarkdownNode {
  Heading1(Vec&lt;MarkdownNode&gt;), // corresponding to a #
  Heading2(Vec&lt;MarkdownNode&gt;), // corresponding to a ##
  Blockquote(Vec&lt;MarkdownNode&gt;), // corresponding to series of &gt;
  // ...
}

struct MarkdownDoc { nodes: Vec&lt;MarkdownNode&gt; }

enum HtmlTag { P, H1, /* ... */ }
struct HtmlAttribute { key: String, value: String }
enum HtmlNode {
  Tagged { 
    tag: HtmlTag,
    attributes: Option&lt;Vec&lt;HtmlAttribute&gt;&gt;,
    children: Option&lt;Vec&lt;HtmlNode&gt;&gt;
  },
  Literal {
    child: String
  }
}

fn string_to_markdown(input: String) -&gt; Result&lt;MarkdownNode, Error&gt; {}

fn markdown_to_html(md: MarkdownDoc) -&gt; Result&lt;HtmlNode, Error&gt; {}

fn html_to_string(html: HtmlNode) -&gt; String {}
</code></pre>
<p>It took me about an hour of reading the specification to realize that
implementing a parser for the entire syntax would easily take me over a week,
and I don't have that kind of time. It would likely be a very error prone
process as well.</p>
<p>A very fun thing to work on, for sure, but after understanding this specific
problem better, I can <em>tolerate</em> the complexity of bringing in a 3rd party
Markdown compiler into the table.</p>
<h4>2. Templating</h4>
<p>Templating can take many shapes and forms. From full blown programming language
support in the style of <a href="https://www.stuartellis.name/articles/erb">ERB (Embedded RuBy)</a>, to string
matching and replacing in more mundane forms.</p>
<p>Considering I do not need to perform any specific logic, my templating needs
are closer to a string-matching followed by some splitting and joining.</p>
<p>I have a <code>template.html</code> file that somewhere in the middle has a keyword that I
want replaced with the actual content of the essay I'm writing.</p>
<p>In pseudocode, this should be enough to achieve my goal:</p>
<pre><code>do_template(template, content) do
  [before, after] = template.split_at_word("$$document")
  return [before, content, after]
end
</code></pre>
<p>How exactly we are finding the word to be replaced by the content is less
important, but from the vast bibliography out there I keep a copy of <a href="https://users.dcc.uchile.cl/~gnavarro/FPMbook">Flexible
Pattern Matching in Strings</a> that is a good resource to
implement some of these algorithms.</p>
<p>Once you know where to split the template to inject your content, the rest is
just string concatenation.</p>
<p>Thankfully, modern programming languages excel at providing us with string
manipulation tools, so putting it together took almost as much code as the
pseudocode:</p>
<pre><code>// assume content and template are strings already
let compiled = template.replace("$$document", content);
</code></pre>
<p>For my use-case, the complexity of having an entire incrementally-rendering
component framework like React, to reuse components across pages that would
achieve the same effect, is simply <strong>not tolerable</strong>.</p>
<h4>3. Only doing work that needs to be done</h4>
<p>A lot of the tools we work with do the same thing over and over again.
Sometimes that is okay. Sometimes that is mandatory.</p>
<p>For my use-case, because I'd like to keep the output of the compilation
versioned, the compilation process should only redo the work that needs to be
done.</p>
<p>This has the side-benefit that recompiling these documents should be relatively
fast, since I tend to work on a single document at a time. Occasionally a
change in a template file would trigger only the recompilation of the documents
using it, …</p></section></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html">https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html</a></em></p>]]>
            </description>
            <link>https://abstractmachines.dev/posts/am010-on-tolerating-complexity.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24048078</guid>
            <pubDate>Tue, 04 Aug 2020 09:04:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shipshape RenderMan Art Challenge]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24047731">thread link</a>) | @mariuz
<br/>
August 4, 2020 | https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html | <a href="https://web.archive.org/web/*/https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
    <article>

            
            <span>July 31, 2020 
                 | Tags: 
                     
                        Art
                      
                </span>

            <section>
                <div>

  <p>Last year, I <a href="https://blog.yiningkarlli.com/2019/11/woodville-renderman-challenge.html">participated in one of Pixar’s RenderMan Art Challenges</a> as a way to learn more about RenderMan <a href="https://dl.acm.org/citation.cfm?id=3182162">(Christensen et al. 2018)</a> and as a way to get some exposure to tools outside of my normal day-to-day toolset (Disney’s Hyperion Renderer professionally, Takua Render as a hobby and learning exercise).
I had a lot of fun, and wound up doing better in the “Woodville” art challenge contest than I expected to!
Recently, I entered another one of <a href="https://renderman.pixar.com/news/renderman-shipshape-art-challenge">Pixar’s RenderMan Art Challenges, “Shipshape”</a>.
This time around I entered just for fun; since I had so much fun last time, I figured why not give it another shot!
That being said though, I want to repeat the main point I made in my post about the previous “Woodville” art challenge: I believe that for rendering engineers, there is enormous value in learning to use tools and renderers that aren’t the ones we work on ourselves.
Our field is filled with brilliant people on every major rendering team, and I find both a lot of useful information/ideas and a lot of joy in seeing the work that friends and peers across the field have put into commercial renderers such as RenderMan, Arnold, Vray, Corona, and others.</p>

  <p>As usual for the RenderMan Art Challenges, Pixar <a href="https://renderman.pixar.com/shipshape-pup-asset">supplied some base models</a> without any uvs, texturing, shading, lighting or anything else, and challenge participants had to start with the base models and come up with a single compelling image for a final entry.
I had a lot of fun spending evenings and weekends throughout the duration of the contest to create my final image, which is below.
I got to explore and learn a lot of new things that I haven’t tried before, which this post will go through.
To my enormous surprise, this time around my entry <a href="https://renderman.pixar.com/news/renderman-shipshape-art-challenge-final-results">won first place in the contest</a>!</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/shipshape_full_4k.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/preview/shipshape_full.jpg" alt="Figure 1: My entry to Pixar's RenderMan Shipshape Art Challenge, titled &quot;Oh Good, The Bus is Here&quot;. Click for 4K version. Base ship, robot, and sextant models are from Pixar; all shading, lighting, additional modeling, and environments are mine. Ship concept by Ian McQue. Robot concept by Ruslan Safarov. Models by Cheyenne Chapel, Aliya Chen, Damian Kwiatkowski, Alyssa Minko, Anthony Muscarella, and Miguel Zozaya © Disney / Pixar - RenderMan &quot;Shipshape&quot; Art Challenge."></a></p>

  <p><strong>Initial Explorations</strong></p>

  <p>For this competition, Pixar provided five models: a futuristic scifi ship based on an Ian McQue concept, a robot based on a Ruslan Safarov concept, an old wooden boat, a butterfly, and a sextant.
The fact that one of the models was based on an Ian McQue concept was enough to draw me in; I’ve been a big fan of Ian McQue’s work for many years now!
I like to start these challenges by just rendering the provided assets as-is from a number of different angles, to try to get a sense of what I like about the assets and how I will want to showcase them in my final piece.
I settled pretty quickly on wanting to focus on the scifi ship and the robot, and leave the other three models aside.
I did find an opportunity to bring in the sextant in my final piece as well, but wound up dropping the old wooden boat and the butterfly altogether.
Here are some simple renders showing what was provided out of the box for the scifi ship and the robot:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/scifiship_base.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/scifiship_base.jpg" alt="Figure 2: Scifi ship base model provided by Pixar, rendered against a white cyclorama background using a basic skydome."></a></p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/robot_base.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/robot_base.jpg" alt="Figure 3: Robot base model provided by Pixar, rendered against a white cyclorama background using a basic skydome."></a></p>

  <p>I initially had a lot of trouble settling on a concept and idea for this project; I actually started blocking out an entirely different idea before pivoting to the idea that eventually became my final image.
My initial concept included the old wooden boat in addition the scifi ship and the robot; this initial concept was called “River Explorer”.
My initial instinct was to try to show the scifi ship from a top-down view, in order to get a better view of the deck-boards and the big VG engine and the crane arm.
I liked the idea of putting the camera at roughly forest canopy height, since forest canopy height is a bit of an unusual perspective for most photographs due to canopy height being this weird height that is too high off the ground for people to shoot from, but too low for helicopters or drones to be practical either.
My initial idea was about a robot-piloted flying patrol boat exploring an old forgotten river in a forest; the ship would be approaching the old sunken boat in the river water.
With this first concept, I got as far as initial compositional blocking and initial time-of-day lighting tests:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_012.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/preview/progress_012.jpg" alt="Figure 4: Initial &quot;River Explorer&quot; concept, daylight lighting test."></a></p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_013.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/preview/progress_013.jpg" alt="Figure 5: Initial &quot;River Explorer&quot; concept, dusk lighting test."></a></p>

  <p>If you’ve followed my blog for a while now, those pine trees might look familiar.
They’re actually the same trees from <a href="https://blog.yiningkarlli.com/2018/10/bidirectional-mipmap.html">the forest scene I used a while back</a>, ported from Takua’s shading system to RenderMan’s PxrSurface shader.</p>

  <p>I wasn’t ever super happy with the “River Explorer” concept; I think the overall layout was okay, but it lacked a sense of dynamism and overall just felt very static to me, and the robot on the flying scifi ship felt kind of lost in the overall composition.
Several other contestants wound up also going for similar top-down-ish views, which made me worry about getting lost in a crowd of similar-looking images.
After a week of trying to get the “River Explorer” concept to work better, I started to play with some completely different ideas; I figured that this early in the process, a better idea was worth more than a week’s worth of sunk time.</p>

  <p><strong>Layout and Framing</strong></p>

  <p>I had started UV unwrapping the ship already, and whilst tumbling around the ship unwrapping all of the components one-by-one, I got to see a lot more of the ship and a lot more interesting angles, and I suddenly came up with a completely different idea for my entry.
The idea that popped into my head was to have a bunch of the little robots waiting to board one of the flying ships at a quay or something of the sort.
I wanted to convey a sense of scale between the robots and the flying scifi ship, so I tried putting the camera far away and zooming in using a really long lens.
Since long lenses have the effect of flattening perspective a bit, using a long lens helped make the ships feel huge compared to the robots.
At this point I was just doing very rough, quick, AO render “sketches”.
This is the AO sketch where my eventual final idea started:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_015.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_015.jpg" alt="Figure 6: Rough AO render &quot;sketch&quot; that eventually evolved into my final idea."></a></p>

  <p>I’ve always loved the idea of the mundane fantastical; the flying scifi ship model is fairly fantastical, which led me to want to do something more everyday with them.
I thought it would be fun to texture the scifi ship model as if it was just part of a regular metro system that the robots use to get around their world.
My wife, Harmony, suggested a fun idea: set the entire scene in drizzly weather and give two of the robots umbrellas, but give the third robot a briefcase instead and have the robot use the briefcase as a makeshift umbrella, as if it had forgotten its umbrella at home.
The umbrella-less robot’s reaction to seeing the ship arriving provided the title for my entry- “Oh Good, The Bus Is Here”.
Harmony also pointed out that the back of the ship has a lot more interesting geometric detail compared to the front of the ship, and suggested placing the focus of the composition more on the robots than on the ships.
To incorporate all of these ideas, I played more with the layout and framing until I arrived at the following image, which is broadly the final layout I used:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_019.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_019.jpg" alt="Figure 7: Rough AO render &quot;sketch&quot; of my final layout."></a></p>

  <p>I chose to put an additional ship in the background flying away from the dock for two main reasons.
First, I wanted to be able to showcase more of the ship, since the front ship is mostly obscured by the foreground dock.
Second, the background ship helps fill out and balance the right side of the frame more, which would otherwise have been kind of empty.</p>

  <p>In both this project and in the previous Art Challenge, my workflow for assembling the final scene relies heavily on Maya’s referencing capabilities.
Each separate asset is kept in its own .ma file, and all of the .ma files are referenced into the main scene file.
The only the things the main scene file contains are references to assets, along with scene-level lighting, overrides, and global-scale effects such as volumes and, in the case of this challenge, the rain streaks.
So, even though the flying scifi ship appears in my scene twice, it is actually just the same .ma file referenced into the main scene twice instead of two separate ships.</p>

  <p>The idea of a rainy scene largely drove the later lighting direction of my entry; from this point I basically knew that the final scene was going to have to be overcast and drizzly, with a heavy reliance on volumes to add depth separation into the scene and to bring out practical lights on the ships.
I had a lot of fun modeling out the dock and gangway, and may have gotten slightly carried away.
I modeled every single bolt and rivet that you would expect to be there in real life, and I also added lampposts to use later as practical light sources for illuminating the dock and the robots.
Once I had finished modeling the dock and had made a few more layout tweaks, I arrived at a point where I was happy to start with shading and initial light blocking.
Zoom in if you want to see all of the rivets and bolts and stuff on the dock:</p>

  <p><a href="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_032.jpg"><img src="https://blog.yiningkarlli.com/content/images/2020/Jul/shipshape/progress_032.jpg" alt="Figure 8: AO render of my layout going into shading and lighting. Check out all of the crazy detail on the dock that I modeled!"></a></p>

  <p><strong>UV Unwrapping</strong></p>

  <p>UV unwrapping the ship took a ton of time.
For the last challenge, I relied on a combination of manual UV unwrapping by hand in Maya and using <a href="https://www.sidefx.com/tutorials/houdini-game-dev-tools-auto-uvs/">Houdini’s Auto UV SOP</a>, but I found that the Auto UV SOP didn’t work as well on this challenge due to the ship and robot having a lot of strange geometry with really complex topology.
On the treehouse in the last challenge, everything was more or less some version of a cylinder or a rectangular prism, with some morphs and warps and extra bits and bobs applied.
Almost every piece of the ship aside from the floorboards are very complex shapes that aren’t easy to find good seams for, so the Auto UV SOP wound up making a lot of choices for UV cuts that I didn’t like.
As a result, I basically manually UV unwrapped this entire challenge in Maya.</p>

  <p>A lot of the complex undercarriage type stuff around the back thrusters on the ship was really insane to unwrap.
The muffler manifold and mechanical parts of the crane arm were difficult too.
Fortunately though, the models came with subdivision creases, and a lot of the subd crease tags wound up proving to be useful hints towards good places to place UV edge cuts.
I also found …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html">https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html</a></em></p>]]>
            </description>
            <link>https://blog.yiningkarlli.com/2020/07/shipshape-renderman-challenge.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047731</guid>
            <pubDate>Tue, 04 Aug 2020 08:02:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The best Parts of Visual Studio Code are proprietary]]>
            </title>
            <description>
<![CDATA[
Score 418 | Comments 263 (<a href="https://news.ycombinator.com/item?id=24047638">thread link</a>) | @ingve
<br/>
August 4, 2020 | https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-08-03</small><!-- RSS:2020-08-03T07:25:00Z -->
<p>I've been very surprised and delighted over a number of years now by Microsoft's strong efforts in open
    source. I understand the skeptics, I was on Slashdot when they tried to sue Linux out of existence and I think only
    time will tell. I figure MS contributing is better than them hunting Linux distributions for sport. So I was mostly
    onboard for Microsofts efforts and I've especially found Visual Studio Code useful.</p>
<p>To settle a few things. When I tweeted on this subject I only got the response that I should use vim. Thanks. Great.
    I can and do on use vim. That misses a number of points. Visual Studio Code is an immensely popular editor and
    likely the most common recommendations to new developers. The primary reason I've used Visual Studio Code is
    that it has an incredibly compelling solution for remote pairing in the form of LiveShare. I've used that for a
    while with great success mentoring, coaching and generally working with other developers of varying experience and
    editor preferences. Most programmers can handle a "normal" editor like VS Code while something like Emacs
    or Vim depends a lot more on what they've learned.</p>
<p>I also ended up enjoying the Remote series of extensions for developing effectively inside remote servers or local
    containers.</p>
<h2>These things are proprietary</h2>
<p>At some point I read a piece of license that said that LiveShare could only be used with the Visual Studio family of
    products. "Huh, that sounds weird, VS Code is open source right?"</p>
<p>Sure enough. VS Code is fully MIT. The binary distribution has a separate license to allow telemetry and protect
    Microsoft trademarks and stuff. Nothing particularly weird, I can't really get worked up about telemetry, I know
    some can. But the extensions.. These extensions are in my book core differentiators that makes VS Code compelling.
    For me it is definitely part of what pushes it beyond the much leaner Sublime (paid, closed source) I was using
    before.</p>
<p>These extensions have a license limiting them and their online service parts to only be used with the Visual Studio
    family of products. This is the <a href="https://microsoftdocs.github.io/live-share/license/eula.html" title="License for LiveShare">license for LiveShare</a> and this is the <a href="https://code.visualstudio.com/preview-license" title="License for Remote">license for Remote</a>.</p>
<p>For me LiveShare is the most important thing. Google Docs style collaborative code editing, terminal sharing, port
    sharing and a bunch more features. I know Atom had an extension like this, I haven't checked the licensing there
    or tried it recently.</p>
<p>Remote is a very strong extension as well for anyone working on a server over SSH or in a container. It helps by
    installing extensions on the destination to allow language servers and such. I've seen it do terrible things to
    servers sometimes but it is very useful and generally works well.</p>
<p>It makes me uneasy to accept VS Code as an "open" project in any wider meaning of the word when compelling
    features are legally locked to only work inside the family of Visual Studio products. It makes me less certain that
    this isn't the Extend in Embrace, Extend, Extinguish. It also frustrates me that this prevents someone from
    building a compatible plugin for VIM or any other editor. This would be much more powerful if it could be in all the
    IntelliJs as well.</p>
<p>You'll find a repo for <a href="https://github.com/MicrosoftDocs/live-share" title="LiveShare on GitHub">LiveShare on GitHub</a> but it is only for documentation and issue tracking. There
    is no code. Same for <a href="https://github.com/microsoft/vscode-remote-release" title="Remote on GitHub">Remote</a>.</p>
<h2>The entire marketplace is proprietary</h2>
<p>Some additional salt in this particular wound is that the use of the Marketplace of VS Code extensions is also
    proprietarily licensed. So all these open source developers are shoving their extensions into a competitive
    advantage for one of the world's largest tech firms. And they disallow other uses of the marketplace. Even if
    the letter of open source is followed there is none of the openness, collaborative or community essence that I think
    exemplifies open source and free software projects.</p>
<p>What does this mean in practice? I guess it protects from the competition. Such as the <a href="https://github.com/VSCodium/vscodium" title="VS Codium">VS Codium</a> project which provides VS Code
    binaries without the proprietary parts. But also, as a consequence of this, without the Marketplace of extensions.
    There is an open source alternative called <a href="https://open-vsx.org/" title="Open VSX">Open VSX</a>, but since
    it isn't the canonical one it is missing a bunch of extensions and the big Liveshare and Remote ones are still
    not allowed.</p>
<p>This also blocks the <a href="https://github.com/cdr/code-server" title="code-server">code-server editor</a> that
    allows running VS Code in the browser from using it which otherwise would have been perfect for me to do development
    on an iPad Pro. I can still use that but a lot of packages are not in Open VSX.</p>
<h2>What about lock-in?</h2>
<p>Visual Studio Code is marketed with LiveShare and Remote as powerful extensions. VS Code is also marketed as open
    source. It is easy to use the editor, install the extensions and be under the impression that you are using an open
    source software suite where Microsoft simply hosts the peering service for identifying and connecting you and your
    collaborator.</p>
<p>But the peering service is not the only closed part. The extensions are not open source projects as far as I can find
    and they are licensed during distribution in a way that disallows using them with anything but Visual Studio
    products.</p>
<p>This leaves me with a sour taste in my mouth. I wasn't sold on having an Electron-based editor to begin with but
    VS Code was substantially leaner than Atom so I've been mostly accepting it.</p>
<p>If you have good suggestions for strong collaborative development tools that are open source, please let me know at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. If you want to follow my writing the RSS feed is
    right below. If you want more of my writing I have a tracking-free newsletter that I'd love for you to sign up for,
    also below.</p></div></div>]]>
            </description>
            <link>https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047638</guid>
            <pubDate>Tue, 04 Aug 2020 07:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Test-First Machine Learning]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24047573">thread link</a>) | @frag
<br/>
August 4, 2020 | https://codingossip.github.io/2020/test-first-machine-learning/ | <a href="https://web.archive.org/web/*/https://codingossip.github.io/2020/test-first-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>  <article itemscope="" itemtype="http://schema.org/BlogPosting">  <div itemprop="articleBody"> <p><img src="https://codingossip.github.io/assets/images/testing.jpg" alt=""></p> <p>Testing software is one of the most complex tasks in software engineering. While in traditional software engineering there are principles that define in a non-ambiguous way how software should be tested, the same does not hold for machine learning, where testing strategies are not always defined. In this post, I elucidate a testing approach that is not only highly influenced by one of the most recognized testing strategies in software engineering - that is test-driven development. But also seems to be an approach that is agnostic from the family of machine learning models under testing, and adapts very well to the typical production environments that lead to the large scale AI/ML services of today.</p> <p>After reading this post, you will learn how to set up a testing strategy that works for machine learning models with production in mind. <em>Production in mind</em> means that the team you are operating in is heterogeneous, the project under testing is developed together with other data scientists, data engineers, business customers, developers, and testers. The goals of a good testing strategy are to achieve production readiness and improve code maintainability.</p> <p>An appropriate name of the approach is <em>Test-First</em> machine learning, in short TFML, because everything starts from writing tests, rather than models.</p> <h2 id="steps-of-tfml">Steps of TFML</h2> <p>A characteristic of TFML is to start from writing tests, instead of machine learning models. The approach is based on mocking whatever is not yet available so that different actors involved in the project can proceed with their tasks anyway. It is known that data scientists and data engineers run at a different pace. Mocking a particular aspect of the world that is not yet available not only mitigates such difference but also reduces blockers within larger teams. This, in turn, increases efficiency. Below are the five essential steps of a TFML approach.</p> <h3 id="1-write-a-test">1. Write a test</h3> <p>As the name suggests, Test-First in TFML indicates that everything starts with writing a test. Even for a feature that does not yet exist. Such a test is usually very short and should stay so. Larger and more complex tests should be broken down to their essential and testable components. A test can be written after understanding the feature’s specs and requirements that are usually discussed earlier during requirement analysis (e.g. use cases and user stories).</p> <h3 id="2-validate-a-test">2. Validate a test</h3> <p>A working test will fail or pass for the right reasons. This is the step in which such reasons are defined. Defining the happy path is essential to defining what should be observed and considered a success.</p> <h3 id="3-write-the-code">3. Write the code</h3> <p>In this step, the code that leads to the happy path is actually written. This code will cause the test to pass. No other code, beyond the test’s happy path, should be provided. For example, if a machine learning model is expected to return 42, one can just return 42 and force the test to succeed here. If time constraints are needed, adding <code>sleep(milliseconds)</code> is also acceptable. Such mocked values will provide engineers with visible constraints such that they can proceed with their tasks as if the model was complete and working.</p> <h3 id="4-run-tests">4. Run tests</h3> <p>Adding new tests should never break the previous ones. Having tests that depend on each other is considered an anti-pattern in software engineering.</p> <h3 id="5-add-functionality--cleanup--refactor">5. Add functionality (+ cleanup + refactor)</h3> <p>When values are mocked, success conditions are defined and tests are running, it’s time to show that the ML model under testing is training and performing predictions. Related to the example above, some questions that should find an answer in this step are:</p> <ul> <li>Is the test breaking the constraints we set previously?</li> <li>Is our ML model returning 84 rather than 42?</li> <li>How about time constraints?</li> </ul> <p>Traditionally, in this step developers perform code cleanup, deduplication, and refactoring (whenever it applies), to improve both readability and maintainability. This strategy should be applied to ML developers too.</p> <hr> <p>Falling in the trap of <em>alternative</em> approaches is easier in machine learning due to its nature and the enthusiasm of data scientists who <code>connect-train-analyze</code> data in no time.</p> <p>The most common approach in the data science community is probably the <em>Test-Last</em> approach a.k.a. <em>code now, test later</em>. This approach can be extremely risky in ML model development, since even for a trivial linear regression there might be just too many moving parts, compared with traditional software (e.g. UI, API calls, data streams, databases, preprocessing steps, etc.) As a matter of fact, the <strong>Test-First</strong> approach encourages and forces developers to put the minimum amount of code into modules depending on such moving parts (e.g. UIs and databases) and to implement the logic that should belong to the testable section of the codebase.</p> <p>One important pitfall to avoid is <em>developer bias</em>. Tests created in a Test-First environment are usually created by the same developer who is writing the code being tested. This can be a problem e.g. if a developer does not consider certain input parameters to be checked. In that case, neither the test nor the code will verify such parameters. There is a reason why in traditional software development, testing engineers and developers are usually not the same individuals.</p> <h2 id="tfml-anti-patterns">TFML anti-patterns</h2> <p>Below are some anti-patterns in TFML.</p> <h3 id="test-dependence">Test dependence</h3> <p>Tests should be standalone. Tests that depend on others can lead to cascading failures or success out of the developer’s control.</p> <h3 id="test-model-precisely">Test model precisely</h3> <p>As in traditional software engineering, testing precise execution behavior, timing or performance can lead to test failure. In machine learning, it is even more important to consider soft constraints because models can be probabilistic. Moreover, the ranges of output variables and input data can change. Such a dynamic and sometimes loosely defined behavior is the norm rather than the exception in ML.</p> <h3 id="test-models-mathematical-details">Test model’s mathematical details</h3> <p>Testing model implementation details such as statistical and mathematical soundness are not part of the TFML strategy. Such details should be tested separately and are specific to the family of the model under consideration.</p> <h3 id="large-testing-unit">Large testing unit</h3> <p>The testing surface should always be minimal for the functionality under test. Keeping the testing unit small gives more control to the developer. Larger testing units should be broken down into smaller tests, specialized in one particular aspect of the models to be tested.</p> <h2 id="conclusion">Conclusion</h2> <p>The TFML approach forces developers to spend initial time defining the testing strategy for their models. This in turn facilitates the integration of such models in the bigger picture of complex engineering systems where larger teams are involved. It has been observed that programmers who write more tests tend to be more productive. Testing code is as important as developing software core functionality. Testing code should be produced and maintained with the same rigor as production code. In ML all this becomes even more critical, due to the heterogeneity of the systems and the people involved in ML projects.</p>  </div> </article>  </div></div>]]>
            </description>
            <link>https://codingossip.github.io/2020/test-first-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24047573</guid>
            <pubDate>Tue, 04 Aug 2020 07:28:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Incrementally Improving the DOM]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24046932">thread link</a>) | @todsacerdoti
<br/>
August 3, 2020 | https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html | <a href="https://web.archive.org/web/*/https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Introduction</h2>
<p><a href="http://blog.functorial.com/posts/2018-03-12-You-Might-Not-Need-The-Virtual-DOM.html">Last time</a>, I tried to convince you that you might not need the virtual DOM, and that many common UI patterns can be reproduced with a completely <em>static</em> page, with changes only happening at the leaves of the tree - attributes and text nodes. For some trickier UI patterns, I added back a limited form of dynamic behavior, by allowing elements with dynamic lists of children.</p>
<p>It is perhaps not terribly surprising that this is possible, since it is, after all, what we used to do before React popularized the virtual DOM (using things like Mustache templates).</p>
<p>The static DOM approach has some limitations of its own, however:</p>
<ul>
<li>Dynamic arrays are optimized for modification at the <em>end</em> of the array. Modifications in the middle of an array can trigger a cascade of updates to nodes at the end of the array. In practice, this is not a big problem, but for large arrays it can become a performance issue. One solution to this problem is to create an alternative structure for looping, where the inner template does either not have access to its index, or where the indices do not correspond to the position of the element in the parent array.</li>
<li>In order to trigger a UI change, however small, we need to construct a new model for the entire static DOM component. Again, in practice, this is not a big problem, but it does make it harder to do certain things. For example, if we wanted to send model changes to the server for evaluation, we would have a hard time.</li>
<li>Every change is potentially observed by every node in the static DOM. We can use tricks like filtering out duplicate events from our event streams, but this takes unnecessary time and CPU cycles. Recall, the motivation for the static DOM was that we intuitively <em>knew</em> which elements should receive the events for small model changes such as changing a single text node. The challenge is to convince the machine that this connection between submodels and elements is obvious!</li>
</ul>
<p>In this post, I'd like to suggest a different approach, which solves these problems but keeps the benefits of the static DOM approach.</p>
<h2>Enter the Incremental Lambda Calculus</h2>
<p>The paper <a href="https://arxiv.org/abs/1312.0658">"A Theory of Changes for Higher-Order Languages"</a> by Cai, Giarrusso, Rendel and Ostermann states the following in its abstract:</p>
<blockquote>
<p>If the result of an expensive computation is invalidated by a small change to the input, the old result should be updated incrementally instead of reexecuting the whole computation.</p>
</blockquote>
<p>This sounds a lot like it applies to our problem! Once we've computed the initial state of the DOM, a small change to the model should result in a small change to the DOM.</p>
<p>In fact, as we'll see, the incremental lambda calculus will provide a solution to all three of the problems listed above.</p>
<p>"A Theory of Changes..." proceeds by interpreting the types and terms of the lambda calculus in a new context where each type is augmented with a <em>change structure</em>.</p>
<p>For our purposes, a change structure is equivalent to a monoid acting on the values of the type. I implement change structures using the following type class:</p>
<pre><code>class Monoid m &lt;= Patch a m | a -&gt; m where
  patch :: a -&gt; m -&gt; a
</code></pre>
<p>This declaration states that there is a functional relationship between carrier types <code>a</code> and change structures <code>m</code>, which must be <code>Monoid</code>s. I use a functional dependency to express the change structure as a function of the carrier type. In practice, this means using newtypes in quite a few more places, but makes type inference more pleasant.</p>
<p>For example, the <code>Last a</code> monoid acts on values of the type <code>a</code> via the newtype <code>Atomic a</code>:</p>
<pre><code>import Data.Maybe.Last

newtype Atomic a = Atomic a

instance patchAtomic :: Patch (Atomic a) (Last a) where
  patch (Atomic a) (Last m) =
    case m of
      Nothing _ -&gt; Atomic a
      Just b    -&gt; Atomic b
</code></pre>
<p><code>mempty</code> does nothing, keeping the current value, and when composing several <code>Last a</code> values, the last one wins. <code>Atomic a</code> is a value of type <code>a</code> with a trivial change structure, where the value is either not changed at all, or changed completely.</p>
<p>The paper also defines change structures for tuples (in which the two components can change independently), functions, and other structures such as <em>bags</em> (sets with duplicate elements permitted).</p>
<p>By interpreting each type and term former in this context, the paper is able to interpret any term of the simply-typed lambda calculus as as <em>incremental</em> function. An incremental function is one which can either be evaluated normally, or given a change to the input, can produce a change to the output.</p>
<h2>An Embedded DSL</h2>
<p>In my <a href="https://github.com/paf31/purescript-incremental-functions"><code>purescript-incremental-functions</code></a> library, I use a different approach, keeping the change structure concept, but implementing incremental functions using an <em>embedded DSL</em>. In particular, I use an approach based on <em>higher-order abstract syntax</em>, in which incremental functions are represented using regular PureScript functions.</p>
<p>It should perhaps not be surprising (if you've read my <a href="http://blog.functorial.com/posts/2017-10-08-HOAS-CCCs.html">other blog post</a>, anyway) that it is possible to give an embedding of incremental lambda calculus in terms of higher-order abstract syntax, but the embedding I use here is in fact <em>not</em> the one I describe in that blog post - it is much simpler.</p>
<p>The key data structure we'll need is a <code>Jet</code>:</p>
<pre><code>type Jet a =
  { position :: a
  , velocity :: Change a
  }
</code></pre>
<p>A <code>Jet</code> is a value of type <code>a</code>, paired with a change of type <code>Change a</code>, where <code>Change a</code> is the change structure acting on <code>a</code>. I say "<em>the</em> change structure", since the functional dependency on <code>Patch</code> makes it unique.</p>
<p><code>Change</code> is defined using something like an <em>associated type</em>. In PureScript, unlike in GHC Haskell, we don't have associated types, but we can make a crude approximation by packaging up the (unique) type under a fundep as an abstract data type and using <code>unsafeCoerce</code> to construct values (safely!):</p>
<pre><code>data Change a

fromChange :: forall a da. Patch a da =&gt; Change a -&gt; da
fromChange = unsafeCoerce

toChange :: forall a da. Patch a da =&gt; da -&gt; Change a
toChange = unsafeCoerce
</code></pre>
<p>We should think of the value <code>Jet { position: x, velocity: dx }</code> as being positioned currently at <code>x</code>, and <em>about to move</em> by the amount <code>dx</code>. This might be reminiscent of dual numbers, from automatic differentiation, in which we pair a number with its rate of change.</p>
<p>Given the definition of <code>Jet</code>, the encoding of incremental functions is simple: an incremental function from <code>a</code> to <code>b</code> (with their associated change structures) is represented by a function from <code>Jet a</code> to <code>Jet b</code>.</p>
<p>Here is a simple example - an incremental function from <code>Atomic</code> values of type <code>a</code> to <code>Atomic</code> values of type <code>b</code>, constructed from a regular function from <code>a</code> to <code>b</code>:</p>
<pre><code>mapAtomic :: forall a b. (a -&gt; b) -&gt; Jet (Atomic a) -&gt; Jet (Atomic b)
mapAtomic f { position, velocity } =
  { position: Atomic (f (un Atomic position))
  , velocity: toChange (map f (fromChange velocity))
  }
</code></pre>
<p>Here, the result will change only when the input changes.</p>
<p>This is a simple example, but we can create incremental versions of many standard functions: maps, folds, <code>filter</code>, <code>zip</code>, and so on. <code>purescript-incremental-functions</code> defines a small standard library of incremental data structures such as arrays, maps and records, and incremental functions like these.</p>
<p>To illustrate an important point, here is another example - an API for an incremental map data structure and a function to <code>map</code> a function over it:</p>
<pre><code>data IMap k a

data MapChange a da
  = Insert a
  | Remove
  | Update da

type MapChanges k a da = Map k (MapChange a da)
-- ^ a potential change for each key

map
  :: forall k a da b db
   . Ord k
  =&gt; Patch a da
  =&gt; Patch b db
  =&gt; (Jet a -&gt; Jet b)
  -&gt; Jet (IMap k a)
  -&gt; Jet (IMap k b)
</code></pre>
<p>Note that jet functions are used here to construct a <em>higher-order incremental function</em>, since the (incremental) function being mapped is being passed in as an argument.</p>
<p>Since jet functions are just regular functions, we can compose them like functions, use lambda abstraction to form new functions, and so on. We are propagating changes by passing them from one function to the next. For example:</p>
<pre><code>mapAtomic (_ + 1)
  :: Jet Int -&gt; Jet Int

map (mapAtomic (_ + 1))
  :: Jet (Imap k Int)
  -&gt; Jet (IMap k Int)

\f -&gt; map (map f)
  :: (Jet a -&gt; Jet b)
  -&gt; Jet (IMap k1 (IMap k2 a))
  -&gt; Jet (IMap k1 (IMap k2 b))
</code></pre>
<p>If we squint enough to see through the <code>Jet</code> type constructors, this DSL is very close to plain old functions, but where our data structures have been switched out for their incremental equivalents. Of course, we're limited to those basic functions which we can write incrementally as jet functions.</p>
<h2>Laws for Incremental Functions</h2>
<p>Every incremental function can be represented as a jet function, but not every jet function is a valid incremental function. We require the following condition to hold for a jet function <code>f :: Jet a -&gt; Jet b</code>:</p>
<pre><code>patch (lower f a) db = lower f (patch a da)
</code></pre>
<p>where</p>
<pre><code>lower :: (Jet a -&gt; Jet b) -&gt; a -&gt; b
lower f a = (f { position: a, velocity: mempty }).position
</code></pre>
<p>and</p>
<pre><code>db = (f { position: a, velocity: da }).velocity
</code></pre>
<p>That is, if we <code>lower</code> the function <code>f</code> to a function on regular (non-changing) values, and apply it to a <code>patch</code>ed value, we should get the same result as applying the <code>lower</code>ed function, and patching the result with a patch generated by the jet function.</p>
<p>Note, however, that the following condition, which might seem intuitively obvious, <em>does not</em> hold in general:</p>
<pre><code>(f { position: a, velocity: mempty }).velocity == mempty
</code></pre>
<p>That is, jet functions are not required to take constant jets to constant jets. The reason is that a jet function might close over some already-changing value from its environment, in which case changes in the result would already be "baked in" to that jet function.</p>
<h2>Change Structures as Models for Mutation</h2>
<p>Change structures tell us how changes act on values, as pure functions, but we can use those pure functions to model impure changes to the real world.</p>
<p>For example, the paper talks about how incremental lambda calculus could be used to model <em>self-maintaining database views</em>. In this case, our values would represent <em>relations</em> and changes would represent updates on those …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html">https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html</a></em></p>]]>
            </description>
            <link>https://blog.functorial.com/posts/2018-04-08-Incrementally-Improving-The-DOM.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24046932</guid>
            <pubDate>Tue, 04 Aug 2020 05:26:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learn Functional Programming Design from Redux]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24046631">thread link</a>) | @daiyanze
<br/>
August 3, 2020 | https://pitayan.com/posts/redux-fp-design/?ref=hackernews | <a href="https://web.archive.org/web/*/https://pitayan.com/posts/redux-fp-design/?ref=hackernews">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Before I set my eyes on the Redux source code, I naively thought OOP is superior than FP(Functional Programming) as a programming paradigm. But this is not right. As we know that FP is dedicated to forming a easy to understand and clear workflow without those obscure abstracted objects and relations. It's much closer to human's procedural mode of thinking.</p><p>Now <code>React</code> has already got hooks which can handle the "states" properly event without <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>. The demand for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> could be declining but its code base is still worth learning. Especially for those who wants to enlighten themselves in functional programming. So, I guess it's never a bad idea to learn from a good example even though it is "obsolete" (not at all).</p><p>When I started reading the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> source code, I immediately felt the power of this unfamiliar usage of my familiar programming language. It feels like exploring an acient cave with a torch lighting up the paintings and found the great secret.</p><p>In order to know more about what Redux benefits from FP, I researched the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> source code and created a mini version of it.</p><blockquote><p>Never be afraid of reinventing the wheel.</p></blockquote><p><strong>Contents:</strong></p><ul><li><a href="#recap-how-redux-works">Recap How Redux Works</a></li><li><a href="#redux-approach-comparison-fp-vs-oop">Redux Approach Comparison: FP vs OOP</a></li><li><a href="#wonderful-redux-fp-design">Wonderful Redux FP Design</a><ul><li><a href="#createstore">createStore</a></li><li><a href="#combinereducers">combineReducers</a></li><li><a href="#applymiddleware">applyMiddleware</a></li></ul></li><li><a href="#redux-middlewares">Redux Middlewares</a><ul><li><a href="#redux-thunk">Redux Thunk</a></li><li><a href="#redux-logger">Redux Logger</a></li></ul></li><li><a href="#a-demo-app">A demo app</a></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#references">References</a></li></ul><h2 id="recap-how-redux-works"><a href="#recap-how-redux-works">Recap How Redux Works</a></h2><p>There are 4 basic key points for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>:</p><ol><li>Create a store for data and let the view subscribe to it</li><li>The view dispatches an action to submit the changs</li><li>The reducer changes the state based on the action type</li><li>Finally return the new state and triggers the view to change</li></ol><p>This is the classic diagram explaining how <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> works:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg" width="1088" alt="redux diagram" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1088 573' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-7e552fcbb64e466973e8c4226e516330'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-7e552fcbb64e466973e8c4226e516330)' width='1088' height='573' xlink:href='data:image/jpeg%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAiCAYAAADvVd%2bPAAAACXBIWXMAAAsSAAALEgHS3X78AAAEqklEQVRo3tWZ2U7sMAyG%2b/5vgcQ1V4C4AIkbQCAh9n3f931fc/RFco8n0zZOGEBEstppUrv%2bYzu2p3h5eXFvb2/u4%2bPDRO/v7453Xl9fy2sVhWus/KEY7yo5ufwLlL%2b5uXGnp6fu/PzcnZ2dVRJzrLm6uvKAWT5QwH18fIzy13IsAOv55%2bfnKF9NT09P5fsFyi8sLLjd3V23vb3dSKxZWlryHwmSMQuQ%2bdXVVbexseF2dnai/FnL/efnpwkALBLeFv7Mb25uehliyQU7g2DrQHkYMSwuwO4j0Dp4j/UAwM5aLGxxcdGlDDZRrLhAIdBhgEqT7zOOj489YDzjA2Wn6%2bjh4cGtrKyYfJNxd3fnAbDwl3kUAhBAa%2bLPPHosLy//BwCfEABkUTh4Js9PTk7c0dFRy/o6koF5VvENZTDu7%2b%2b9mVr4C2jwRyHNp44/77RYQAgAg127vLx019fX/l7PHR4eusnJSX/FFbCGOmJ%2bcHDQjY%2bPlx8BH3gTe25vb/2O4yYykDcxMeEODg6i/Pf29tzIyIgbGhpqUxbLFhkaFBMACMdMMEXu9Y6i%2bMzMjI%2bm3GMNIfEcV%2bEDu7q63OjoaPlhmCB8Cbx8CP5LHNIAADDPmvhDrOnp6XG9vb1tloqMtbU1737iviYAYiYUukDMp7/iAk0xqckF6tzYDECTMAmCEqVjQRCFJAhq362SIQDkBEEUCuOD5i0EqG0ApByDev13HIMolXoMolD2MUhmNz8/73cWfxfCzDF3/Yw1vMzVkgjJlXeIB/it5hcSMjHn9fV1MwDsKBZGwAz5I5OrPOfKM%2bJOmQiBBCAgHMVYROTs7%2b933d3dPkpLUGPNxcVFciqMWQv/GAG6KG5NhUltq/hwmqAw93oOqyxTYUFR/EWCydzcnBsbG/P3uljKKYZSiq1OFUNYENYEmGFMaCmGdN4ugQUlQQp/5z4MRqHwWC0QC5RVlGIBdTxwDayvak1pAVVMQWx/f9%2bbj/i6dUd%2bm8IiDACaXLaoehkAJJD8JQDCHQ4BqNKhqKqtUVpSTXGBFL/8LeXlqvMDgnhVg6bWArgyOBkgCYJ/xQLk%2byVtl991G1iERxaIkRcQQTEhzuSULtBPBsG6I3Fra8t/O7kBgRAdqDEaLUAmWMgJAAjS/dGRNMckwzQ1VuLmuJt2YUl6KNokh9FtMJMLSOLTZD7WRAhQJbO0JEI5FhDmBIBJNYjiZheQKww4BiGd8uZYgERjCi6CahMhD3O19gRjOUGYB0QtQOcB4TGYG5A60RPMjT3JeUAIADtSlQmmkABg7QlKOfxVudoCsgBAeXzS0ptrIoRLdVfXs9NNDD5Yym1AyJXLIAZ8yQJmZ2fLElJigpWkFOVImpqaauvKSL%2bOXdZz/B4YGHDDw8NlSZsiX9ZyRa6u/MwAiO/qOjqHiPzs5vT0dIuSXDmjqTjhr%2beQ39fX55up0qPIkQ0IFHNhXIgCkPt/W12bCz6pLiB/vDT1BFP/x6yjIrXETM3mdBBs6tl9RxAMdTFbQCfz8u/sCXaCip%2bozviPgaCke/pVhM/TEpc2%2bp8GIOwJStPTEjh/svz%2bEQuQYsgSNHOLoVz6Bye%2b7fLOqLjeAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg" data-srcset="https://d33wubrfki0l68.cloudfront.net/d23ede7d66304da8179f8bd5b5cb30d1a54c39df/29340/assets/static/redux.82a2fbd.ff6f3365031ebcab6ddfefc3aadeb376.jpg 480w, https://d33wubrfki0l68.cloudfront.net/b1117a23634125a8e2195b0dfc8fc1a29c511fac/3f628/assets/static/redux.b474ba6.ff6f3365031ebcab6ddfefc3aadeb376.jpg 1088w"></p><p>From the diagram above, it's easy to find the keywords: <code>action</code><code>store</code><code>reducer</code><code>view</code><code>subscribe</code> and <code>dispatch</code>. And the next is to handle the relations among these keywords.</p><h2 id="redux-approach-comparison-fp-vs-oop"><a href="#redux-approach-comparison-fp-vs-oop">Redux Approach Comparison: FP vs OOP</a></h2><p>Example usage of <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a></p><pre><code><span>const</span> store <span>=</span> <span>createStore</span><span>(</span>
  <span>combineReducers</span><span>(</span><span>{</span>
    one<span>:</span> oneReducer<span>,</span>
    two<span>:</span> twoReducer
  <span>}</span><span>)</span><span>,</span>
  <span>applyMiddleware</span><span>(</span><span>ReduxThunk</span><span>,</span> <span>ReduxLogger</span><span>)</span>
<span>)</span><span>;</span></code></pre><p>Imagine if we do this in OOP, it may look like this:</p><p>(The following is just my imagination. Not how older <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> behaves)</p><pre><code><span>const</span> store <span>=</span> <span>new</span> <span>Store</span><span>(</span><span>)</span>
store<span>.</span><span>setReducers</span><span>(</span><span>{</span>
  one<span>:</span> oneReducer<span>,</span>
  two<span>:</span> twoReducer
<span>}</span><span>)</span>
store<span>.</span><span>setMiddlewares</span><span>(</span><span>{</span>
  <span>ReduxThunk</span><span>,</span>
  <span>ReduxLogger</span>
<span>}</span><span>)</span></code></pre><p>So, what are the differences? Both are good approaches IMO.</p><p>FP does a good job on combining the functions together without side-effects. The return value is consistent which made the program returnings foreseeable during or after the execution.</p><p>OOP made a solid structure which defined all the attributes a data model should contain. It makes it easy to modify or configure the data model.</p><p>In <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a>, the <code>reduers</code> and <code>middlewares</code> are usually defined only once. It means, we don't need the ability to update these properties and we don't hope them to be altered during the runtime. As for FP approach, it utilizes the <code>closure</code> technique that kills the possbility of exposing the internal properties. With some fantastic FP techniques (curry, compose, pipe), it's even making the program much more human-readable than OOP.</p><p>I would say FP should be the best fit for such scenario. Of course, the FP I'm talking about here is far from the real functional programming like Haskell. But at least the idea of utilizing FP techniques in Javascript is something to follow.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg" width="1024" alt="haskell functional programming" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1024 576' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-52e08e1070b234d120b65ac6e29a8487'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-52e08e1070b234d120b65ac6e29a8487)' width='1024' height='576' xlink:href='data:image/jpeg%3bbase64%2c/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAkAEADASIAAhEBAxEB/8QAGwAAAgMBAQEAAAAAAAAAAAAAAAQCAwUGAQj/xAAwEAABBAEDAQYCCwAAAAAAAAABAAIDEQQSITFRBRMiQWFxJKEGFBUyQlKCkrHB8P/EABYBAQEBAAAAAAAAAAAAAAAAAAABAv/EABkRAQEBAAMAAAAAAAAAAAAAAAABERIhQf/aAAwDAQACEQMRAD8A%2bqSQASdgEvj5uLki8fIilHVjgf8AcFMEWCFz0oyIJ5ceETuhvTqPeucQR%2ba6vc8enRBuwzxTAGJ7XAixSsWFJmZ0DmiKLVDVNLoJHPqq8Vedp77R0yujdj5biDVtgdp46%2baUPoN0aFlUwTiV8je7kZoNW9tA%2b3VXEAgggEHyQcl2J9O%2bzO04JXd3kxSQl3eMEZk00au2WCPboVt9mdt4Pac7ocN0zntbrOqF7BV1y4BOY%2bLj44Ax4IogBpGhgbQ5rZXLVs8Hj70Oq7ralh4WaYXPgnleckGu7kna43WwsNA6LdSpzCL%2bHm29Bv8ANZGXDLKdDpZpmt2IrJa675/D0NrQfJDHGwPy5ACDTjyfkifID2lrsfII33Ya49QVWC173fD5Zo1es1x5eLhXlaupsxe9Z4M7KIIq2uA/rlMwwGN5cZpX7VTyK9%2bEnqD374uYC3TvrIu/1b15qyGNkkztUWSw/etzzp59/RXesQ8hQjibGXab8Rs2bU1kCX%2bpYodqGPFq330jzQhDQMLFHGPF%2b0dK/jZWxRRwgiJjWAmyGirKEIJoQhAIQhB//9k=' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg" data-srcset="https://d33wubrfki0l68.cloudfront.net/2c16467debebdf254444700dab6213bb45ece8a2/b30b3/assets/static/haskell.82a2fbd.82d9f5b0912290333a547a32e17d3642.jpg 480w, https://d33wubrfki0l68.cloudfront.net/66984ccd5661fa81bc4c1806c64e980181165a7d/88b43/assets/static/haskell.cbab2cf.82d9f5b0912290333a547a32e17d3642.jpg 1024w"></p><h2 id="wonderful-redux-fp-design"><a href="#wonderful-redux-fp-design">Wonderful Redux FP Design</a></h2><p>In Redux, there is no class at all (In the earlier versions, it was once based on <code>Class</code>). All of its core APIs return either value or function (function factory). And this is exactly what FP expects a function to behave:</p><blockquote><p>Pure with no side effects.</p></blockquote><ul><li><strong>createStore</strong>: returns new <code>Object</code> { getState, dispatch, subscribe }</li><li><strong>combineReducers</strong>: returns new <code>Function</code></li><li><strong>applyMiddleware</strong>: returns new <code>Function</code></li></ul><p>To explain the <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> design in an easy way, I implemented only the very core part of the APIs above. Since the latest version's core concept hasn't changed much, I wrote the source code based on very primitive version of <a href="https://github.com/reduxjs/redux/tree/v1.0.1/src" target="_blank" rel="nofollow noopener noreferrer">Redux v1.0.1</a>. Because I believe the very first related version would be the most comprehensive one to look at.</p><p>Let's have a look.</p><h4 id="createstore"><a href="#createstore">createStore</a></h4><p><code>createStore</code> defines those APIs that can be used within components. It's more like <code>setter</code> and <code>getter</code></p><ul><li>getState</li><li>dispatch</li><li>subscribe</li></ul><pre><code><span>export</span> <span>default</span> <span>function</span> <span>createStore</span> <span>(</span><span>reducer<span>,</span> enhancer</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>enhancer<span>)</span> <span>{</span>
    <span>return</span> <span>enhancer</span><span>(</span>createStore<span>)</span><span>(</span>reducer<span>)</span><span>;</span>
  <span>}</span>

  <span>let</span> currentState<span>;</span>
  
  
  <span>let</span> currentListeners <span>=</span> <span>[</span><span>]</span><span>;</span>

  <span>function</span> <span>getState</span> <span>(</span><span>)</span> <span>{</span>
    <span>return</span> currentState<span>;</span>
  <span>}</span>

  
  <span>function</span> <span>subscribe</span> <span>(</span><span>listener</span><span>)</span> <span>{</span>
    currentListeners<span>.</span><span>push</span><span>(</span>listener<span>)</span><span>;</span>

    <span>return</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      
      <span>const</span> index <span>=</span> currentListeners<span>.</span><span>indexOf</span><span>(</span>listener<span>)</span><span>;</span>
      currentListeners<span>.</span><span>splice</span><span>(</span>index<span>,</span> <span>1</span><span>)</span><span>;</span>
    <span>}</span><span>;</span>
  <span>}</span>

  <span>function</span> <span>dispatch</span> <span>(</span><span>action</span><span>)</span> <span>{</span>
    currentState <span>=</span> <span>reducer</span><span>(</span>currentState<span>,</span> action<span>)</span><span>;</span>
    
    currentListeners<span>.</span><span>forEach</span><span>(</span><span>listener</span> <span>=&gt;</span> <span>listener</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  
  <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>"MY-MINI-REDUX"</span> <span>}</span><span>)</span><span>;</span>

  <span>return</span> <span>{</span>
    getState<span>,</span>
    dispatch<span>,</span>
    subscribe
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="combinereducers"><a href="#combinereducers">combineReducers</a></h4><p>Returns a new function that can return the new state. Can't be any purer.</p><pre><code>
<span>function</span> <span>mapValues</span><span>(</span><span>obj<span>,</span> fn</span><span>)</span> <span>{</span>
  <span>return</span> <span>Object</span><span>.</span><span>keys</span><span>(</span>obj<span>)</span><span>.</span><span>reduce</span><span>(</span><span>(</span><span>result<span>,</span> key</span><span>)</span> <span>=&gt;</span> <span>{</span>
    result<span>[</span>key<span>]</span> <span>=</span> <span>fn</span><span>(</span>obj<span>[</span>key<span>]</span><span>,</span> key<span>)</span><span>;</span>
    <span>return</span> result<span>;</span>
  <span>}</span><span>,</span> <span>{</span><span>}</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>default</span> <span>function</span> <span>combineReducers</span> <span>(</span><span>reducers</span><span>)</span> <span>{</span>
  <span>return</span> <span>function</span> <span>combination</span> <span>(</span><span>state <span>=</span> <span>{</span><span>}</span><span>,</span> action</span><span>)</span> <span>{</span>
    
    
    <span>return</span> <span>mapValues</span><span>(</span>reducers<span>,</span> <span>(</span><span>reducer<span>,</span> key</span><span>)</span> <span>=&gt;</span> <span>reducer</span><span>(</span>state<span>[</span>key<span>]</span><span>,</span> action<span>)</span><span>)</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="applymiddleware"><a href="#applymiddleware">applyMiddleware</a></h4><p>I personally think the <code>applyMiddleware</code> API is the most amazing part of Redux. It provides an optimal solution to apply 3rd party plugins.</p><p>The FP <code>compose</code> in the source code is corresponding to Math's <a href="https://en.wikipedia.org/wiki/Associative_property" target="_blank" rel="nofollow noopener noreferrer">associative law</a> in my understanding.</p><blockquote><p>( <em>x</em> ∗ ( <em>y</em> ∗ <em>z</em> ) ) = <em>x</em> ∗ <em>y</em> ∗ <em>z</em></p></blockquote><p>The usage of <code>applyMiddleware</code> is actually a form of a <code>pipe</code> that allows us to inject enhancement functions that returns the store Object. It's pretty similar to <code>Aspect Oriented Programming</code> which the most typical example is the annotation / decorator.</p><pre><code>

<span>function</span> <span>compose</span><span>(</span><span><span>...</span>funcs</span><span>)</span> <span>{</span>
  <span>return</span> funcs<span>.</span><span>reduceRight</span><span>(</span><span>(</span><span>composed<span>,</span> f</span><span>)</span> <span>=&gt;</span> <span>f</span><span>(</span>composed<span>)</span><span>)</span><span>;</span>
<span>}</span>

<span>export</span> <span>default</span> <span>function</span> <span>applyMiddleware</span><span>(</span><span><span>...</span>middlewares</span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>(</span><span>reducer<span>,</span> initialState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>next</span><span>(</span>reducer<span>,</span> initialState<span>)</span><span>;</span>
    <span>let</span> dispatch <span>=</span> store<span>.</span><span>dispatch</span><span>;</span>
    <span>const</span> middlewareAPI <span>=</span> <span>{</span>
      getState<span>:</span> store<span>.</span><span>getState</span><span>,</span>
      <span>dispatch</span><span>:</span> <span>action</span> <span>=&gt;</span> <span>dispatch</span><span>(</span>action<span>)</span>
    <span>}</span><span>;</span>
    <span>const</span> chain <span>=</span> middlewares<span>.</span><span>map</span><span>(</span><span>middleware</span> <span>=&gt;</span> <span>middleware</span><span>(</span>middlewareAPI<span>)</span><span>)</span><span>;</span>

    
    dispatch <span>=</span> <span>compose</span><span>(</span><span>...</span>chain<span>,</span> store<span>.</span><span>dispatch</span><span>)</span><span>;</span>

    <span>return</span> <span>{</span>
      <span>...</span>store<span>,</span>
      dispatch
    <span>}</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h2 id="redux-middlewares"><a href="#redux-middlewares">Redux Middlewares</a></h2><p>There are some famous middlewares for <a href="https://redux.js.org/" target="_blank" rel="nofollow noopener noreferrer">Redux</a> like <a href="https://github.com/reduxjs/redux-thunk" target="_blank" rel="nofollow noopener noreferrer">redux-thunk</a> and [redux-logger(<a href="https://github.com/LogRocket/redux-logger" target="_blank" rel="nofollow noopener noreferrer">https://github.com/LogRocket/redux-logger</a>). These are the good examples using <code>applyMiddleware</code> API to enhance the functionalities. Furthermore, their code base is astonishingly small. The core part has only a few lines of code.</p><p>All of the middlewares are <code>curry</code> functions.</p><blockquote><p>funcA =&gt; funcB =&gt; funcC</p><p>funcB = funcA()</p><p>funcC = funcB()</p></blockquote><p> This is extremly helpful when I need other contexts to use within the code block. As of the examples, it's easy to find that <code>next</code> and <code>action</code> are passed in as context to help handle some complex cases.</p><h4 id="redux-thunk"><a href="#redux-thunk">Redux Thunk</a></h4><p><code>redux-thunk</code> allows to use function as <code>dispatch</code> parameter so that I could do something right before "dispatching".</p><pre><code>
<span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'action'</span><span>,</span> payload<span>:</span> <span>'value'</span> <span>}</span><span>)</span>



<span>dispatch</span><span>(</span><span>function</span> <span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>{</span>
  <span>console</span><span>.</span><span>log</span><span>(</span><span>'redux-thunk'</span><span>)</span>
  <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'action'</span><span>,</span> payload<span>:</span> <span>'value'</span> <span>}</span><span>)</span>
<span>}</span><span>)</span></code></pre><p>Here is the core:</p><pre><code>
<span>export</span> <span>default</span> <span>function</span> <span>thunk</span><span>(</span><span><span>{</span> dispatch<span>,</span> getState <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>action</span> <span>=&gt;</span> <span>{</span>
    <span>if</span> <span>(</span><span>typeof</span> action <span>===</span> <span>"function"</span><span>)</span> <span>{</span>
      <span>return</span> <span>action</span><span>(</span>dispatch<span>,</span> getState<span>)</span><span>;</span>
    <span>}</span>

    <span>return</span> <span>next</span><span>(</span>action<span>)</span><span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h4 id="redux-logger"><a href="#redux-logger">Redux Logger</a></h4><p>It's easy to guess what this middleware does. It simply outputs the state changes.</p><pre><code>
<span>export</span> <span>default</span> <span>function</span> <span>logger</span><span>(</span><span><span>{</span> getState <span>}</span></span><span>)</span> <span>{</span>
  <span>return</span> <span>next</span> <span>=&gt;</span> <span>action</span> <span>=&gt;</span> <span>{</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"======== Redux Logger ========"</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Action Type: "</span><span>,</span> action<span>.</span><span>type</span><span>)</span><span>;</span>
    <span>const</span> prevState <span>=</span> <span>getState</span><span>(</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Prev: "</span><span>,</span> prevState<span>)</span><span>;</span>

    <span>const</span> returnValue <span>=</span> <span>next</span><span>(</span>action<span>)</span><span>;</span>

    <span>const</span> nextState <span>=</span> <span>getState</span><span>(</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"Next: "</span><span>,</span> nextState<span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>"=============================="</span><span>)</span><span>;</span>
    <span>return</span> returnValue<span>;</span>
  <span>}</span><span>;</span>
<span>}</span></code></pre><h2 id="a-demo-app"><a href="#a-demo-app">A demo app</a></h2><p>I implemented mini version of redux and a small counter application to demostrate the functions. The application will do four arithmetic operations: <strong>plus</strong>, <strong>minus</strong>, <strong>multiply</strong> and <strong>divide</strong>. The number will change after clicking the operation button. Meanwhile, <code>multiply</code> and <code>divide</code> will have 300ms' delay which is enabled by a custom middleware (a mini redux-thunk).</p><p><strong>Repository link of "mini-redux":</strong></p><p><a href="https://github.com/daiyanze/mini-redux" target="_blank" rel="nofollow noopener noreferrer">https://github.com/daiyanze/mini-redux</a></p><p><strong>Demo App link:</strong></p><p><a href="https://daiyanze.com/mini-redux/build/index.html" target="_blank" rel="nofollow noopener noreferrer">https://daiyanze.com/mini-redux/build/index.html</a></p><p><img src="https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png" width="1078" alt="app" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 1078 586' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-b8a33714e79343718b882b0853556166'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-b8a33714e79343718b882b0853556166)' width='1078' height='586' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAjCAYAAAAkCQwqAAAACXBIWXMAABYlAAAWJQFJUiTwAAACzElEQVRo3u1YSWsyQRD1v/oHAgoKinqQHDyIHrwIKl7MRYRcvAsJiBcPbkRcEpO4JcZdca2PV9BhvmGci84YRxuKnunu6aGqX79aTKRR2%2b/3v/12u%2bVeKrvd7lfkc9JvtW4mLTc/RgE9lNfUAEKBn58fSqfT1Ov1aD6fs%2bC5Wq1SoVDgfjKZ0HQ65bnX11caj8eXjwBAG61cLpPVaqV4PE6BQIAeHh7o%2bfmZYrEYeTwecjqdFIlEyO/385pcLkcvLy//7XHRCFiv18wBo9GIOp0OIwKy2Wz4xDEOBLTbbR6H0pi7cYBROEDO/FKWFzCXzxnGCygZRShVLBZ1vetnNYAcDWilUok9gBQFekJfdwQcUlBvyJ8dAUqKqxno4g0gJTa4w%2bVyyYEOXB3eF4sFB0GGNoDocdf7/T69vb1xfAAjwPcjMlRChaEQgIYTh9JCeem78ASGJ8G/EPxoYgAlV6cU2KjJRSFAfreVIjr5s9KctC5wKCpUiiZPZSyT1rDWau9T/ftoBMCt1Wo1ZnK4M4S3w%2bGQMzwwPtZ1u12O/N7f32m1WnFWCMFpfnx88PPn5yfV63X2Cs1mk/eGu/z6%2buJ9sB/WYy%2bQ59kRIFgbSrlcLrLb7eTz%2bcjhcJDFYqFgMEg2m40ymQw9PT2R1%2bul%2b/t7ikajvNZsNtPj4yOlUimWRCLBa7LZLH%2bfTCYpHA5zLcHtdtPd3R2FQiGuGcDoZzeA1LUhr8dJiaoPEp3v72%2bu%2bOBkkfNDcKJAh/D9oh4A5KAegG%2bwZjAY8BrMYQw95vP5PLVarZO6zD/LAXr9%2byRe4BBTH2JzafqrxvhqVeQ/gYBjokJAWZDdOZGkezYoTh88cRX1ALWrcihyNCwC1MbPdQ10zwYRCCGoERkgXOBV1QNAfpVK5TcNbjQaHCtcTT1AVICEAWazGY/d6gFk0KKoYesBRmk3A1y7Af4BkCyMSb7bRvcAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-src="https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png" data-srcset="https://d33wubrfki0l68.cloudfront.net/6cd10d41d4c5361482bb8734550719faaa7f13e9/0e513/assets/static/app.82a2fbd.42e70fdda76e9bc70c1818fe62939d86.png 480w, https://d33wubrfki0l68.cloudfront.net/9dc95481270c7b145b30a963ce578c185d75a44c/06bfe/assets/static/app.28b8b81.42e70fdda76e9bc70c1818fe62939d86.png 1078w"></p><p>The app has one child component: <code>MiniReduxComp</code>. In my mini-redux, I didn't create a context provider to trigger updates. Instead, I subscribe to the store changes within the component and  do <code>forceUpdate</code> to react to changes.</p><p>I also applied the custom middlewares <code>redux-thunk</code> and <code>redux-logger</code> to enrich the functions.</p><pre><code><span>import</span> <span>React</span><span>,</span> <span>{</span> <span>Component</span> <span>}</span> <span>from</span> <span>'react'</span><span>;</span>
<span>import</span> store <span>from</span> <span>'../store'</span>

<span>export</span> <span>default</span> <span>class</span> <span>MiniReduxComp</span> <span>extends</span> <span>Component</span> <span>{</span>

  <span>componentDidMount</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>unsubscribe</span> <span>=</span> store<span>.</span><span>subscribe</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>this</span><span>.</span><span>forceUpdate</span><span>(</span><span>)</span><span>)</span><span>;</span>
  <span>}</span>

  <span>componentWillUnmount</span><span>(</span><span>)</span> <span>{</span>
    <span>this</span><span>.</span><span>unsubscribe</span> <span>&amp;&amp;</span> <span>this</span><span>.</span><span>unsubscribe</span><span>(</span><span>)</span><span>;</span>
  <span>}</span>

  <span>plus</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>"PLUS"</span> <span>}</span><span>)</span>

  <span>minus</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'MINUS'</span> <span>}</span><span>)</span>

  <span>multiply</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'MULTIPLY'</span> <span>}</span><span>)</span>
    <span>}</span><span>,</span> <span>300</span><span>)</span>
  <span>}</span><span>)</span>

  <span>divide</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> store<span>.</span><span>dispatch</span><span>(</span><span>(</span><span>dispatch<span>,</span> getState</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>setTimeout</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> <span>{</span>
      <span>dispatch</span><span>(</span><span>{</span> type<span>:</span> <span>'DIVIDE'</span> <span>}</span><span>)</span>
    <span>}</span><span>,</span> <span>300</span><span>)</span>
  <span>}</span><span>)</span>

  <span>render</span><span>(</span><span>)</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span><span><span>&lt;</span>div</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>h4</span><span>&gt;</span></span><span>Plus / Minus 1</span><span><span><span>&lt;/</span>h4</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>store<span>.</span><span>getState</span><span>(</span><span>)</span><span>.</span><span>count</span><span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>plus</span><span>}</span></span><span>&gt;</span></span><span>+1</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>minus</span><span>}</span></span><span>&gt;</span></span><span>-1</span><span><span><span>&lt;/</span>button</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>
        </span><span><span><span>&lt;</span>br</span> <span>/&gt;</span></span><span>

        </span><span><span><span>&lt;</span>h4</span><span>&gt;</span></span><span>Multiply / Divide 2 (0.3s delay)</span><span><span><span>&lt;/</span>h4</span><span>&gt;</span></span><span>
        </span><span><span><span>&lt;</span>p</span><span>&gt;</span></span><span>{</span>store<span>.</span><span>getState</span><span>(</span><span>)</span><span>.</span><span>double</span><span>}</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>

        </span><span><span><span>&lt;</span>button</span> <span>onClick</span><span><span>=</span><span>{</span><span>this</span><span>.</span><span>mult…</span></span></span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pitayan.com/posts/redux-fp-design/?ref=hackernews">https://pitayan.com/posts/redux-fp-design/?ref=hackernews</a></em></p>]]>
            </description>
            <link>https://pitayan.com/posts/redux-fp-design/?ref=hackernews</link>
            <guid isPermaLink="false">hacker-news-small-sites-24046631</guid>
            <pubDate>Tue, 04 Aug 2020 04:33:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Profitably Unemployed]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24045529">thread link</a>) | @hackernewsreadr
<br/>
August 3, 2020 | https://blogofjake.com/2020/08/03/profitably-unemployed/ | <a href="https://web.archive.org/web/*/https://blogofjake.com/2020/08/03/profitably-unemployed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong><u>A Money Mystery</u></strong></p>



<p>I have been unemployed for 10 months now and my net worth is greater today than it was when I quit my job. The purpose of this piece is to explain how that has happened.</p>



<p>First, I want to be clear about a few ways in which I did not make money. I did not receive any government money through unemployment nor from the stimulus checks. Unemployment money is not for people who quit their jobs voluntarily and the stimulus checks were not for people who made more than $99,000 in 2019. I have not had any paid job at any point in the last 10 months. I did not start a profitable business at any point during that time. I have not made any money from this blog. My only material source of income has been through the appreciation of investments that I have made on my own, but that is not the part the matters most.</p>



<p><strong><u>The Water Bucket Analogy</u></strong></p>



<p>What matters most is how I have kept from losing money.</p>



<p>To explain, let me introduce a simple analogy. Think about a bucket of water with a hose that fills it and a hole near the bottom where the water leaks out. The water in the bucket represents your money and the speed at which it leaks out of the hole is the speed at which your money is spent. Most people have a paying job. That’s the hose.</p>



<p>People want to increase their net worth over time and so naturally they think about how they can get more water faster from the hose. The better place to start, however, is to focus on limiting the leakage. People’s general focus on the hose rather than the hole is well demonstrated by the fact that anyone you ask will be able to tell you how much money they make by some unit of time but almost no one will be able to tell you the same in terms of their costs. They probably know the cost of their rent or mortgage payments and a number of other standalone expenses (by varying units of time) but very few will be able to tell you how much money they spend on an average day including their monthly, annual, and other periodic expenses spread out over the course of the respective period. I certainly could not have answered that question myself a year ago but doing so seemed like the sensible place to start.</p>



<p><strong><u>Base Burn Rate</u></strong></p>



<p>I knew when I quit my job in banking that in order to keep my cash burn in check I would need to get my expenses in order. I had turned the hose off so I needed to manage the hole. I started with my subscriptions (monthly and annual payments). I looked at the recurring expenses on my credit card and bank statements. I cancelled almost all of them. I had to add one significant one, health insurance, which my employer had been paying previously. I went with the second cheapest plan I could find from Horizon Blue Cross Blue Shield for $287/month. Next time I would instead go with the second cheapest plan from Oscar for $293/month because I like newer companies in broken industries and they tend to offer a better customer experience.</p>



<p>My next largest recurring payment was my phone bill. I went into the Verizon store and asked what the differences were between my current plan and the cheapest one I could possibly have. The only difference of any significance was the inability with the lower plan to use a hotspot. That infrequently used function was not nearly worth the ~$80/month difference in plans. I cut my phone bill in half to $78/month.</p>



<p>Below are the rest of my monthly and annual expenses as they stand today. As you will see, if I didn’t actively spend any money, these passive expenses alone would result in only a $15/day average burn. I call this my <strong><em>base burn rate</em></strong>. <em>Note: this figure was closer to $60 when I was living in New York pre-covid (+ rent, WiFi, utilities) and between $30-$60 when I was traveling in Europe and Asia (+ hostels/Airbnbs), but right now I am fortunate to be living with my family for free</em>.</p>



<figure><img data-attachment-id="1253" data-permalink="https://blogofjake.com/image-2-4/" data-orig-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png" data-orig-size="515,213" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-2" data-image-description="" data-medium-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=300" data-large-file="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=515" src="https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=515" alt="" srcset="https://theblogofjake.files.wordpress.com/2020/08/image-2.png 515w, https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=150 150w, https://theblogofjake.files.wordpress.com/2020/08/image-2.png?w=300 300w" sizes="(max-width: 515px) 100vw, 515px"></figure>



<p>Not bad right? It gets better…</p>



<p><strong><u>Passive Income</u></strong></p>



<p>I think about my investments in terms of three categories – crypto, stocks, and real estate. Real estate is unique among the three in that it pretty predictably generates cash flows each month. This is because our monthly rents collected from tenants are more than enough to cover the monthly mortgage payments, the cost of our property manager (10% of rent), and any necessary maintenance and/or repairs that she facilitates on our behalf over the course of a given month. Subtracting those expenses from the total rent collected each month and splitting the balance with my good friend and co-owner Kyle leaves me to expect $319/month (assuming the average amount of monthly repairs) which comes out to about $10/day. This is a far cry from the passive income of a real estate magnate but it is solid for a first property and not insignificant for me when it is the only dependable income that I have. Most importantly, this passive income offsets two-thirds of my base burn rate at the moment.</p>



<p>With my base burn rate and passive income figured out, I can calculate what I call my <strong><em>net base burn rate</em></strong> which in this case is equal to $5/day,</p>



<p><strong><u>3 Basic Principles</u></strong></p>



<p>After minimizing my base burn rate and estimating my passive income to calculate my net base burn rate, the next category I considered was comprised of the regularly re-occurring but variable expenses that cost me the most. This includes food, drinks, transportation, and entertainment. I came up with a few principles to help myself spend less in these areas. That said, I believe one of the best things money can buy is the ability not to have to worry about money so rather than force any hard rules upon myself I mostly just keep these principles in mind and try to be reasonable most of the time. <em>Note: these principles were most applicable when I was traveling and then living in New York pre-covid.</em></p>



<ol type="1"><li>Food – don’t drink a lot at restaurants. You are there for the food and the company.</li><li>Drinks – drink less and mostly at yours or friends’ places. The lower your tolerance, the cheaper the fun.</li><li>Transportation – walk when you can. Subways are usually quicker and always cheaper than cars.</li></ol>



<p><strong><u>Exceeding Expectations</u></strong></p>



<p>The goal is not to be watching your wallet all the time. It is to figure it out, then forget about it. Knowing my net base burn rate of $5/day leads to an annual burn of less than $2,000 allows me to live and spend confidently because I know if I ever want to slow my burn I can basically do so simply by doing nothing (therefore slowing my active spending). I don’t <em>need</em> to drink alcohol or go golfing and I could easily eat for a few dollars per day if I was willing to eat less healthfully and not go out for a while. Fortunately, I have not had to sacrifice any of these things. If I did have to, I know that I could, but I would probably just go and get a job at that point and realistically well before that point ever came.</p>



<p>In order to quit my job in the first place, I had to be willing to endure some level of burn in exchange for the freedom of time that I was buying for myself. I was confident that I could offset some of it with my investments in crypto and stocks, and the non- cash flow part of my real estate investment (the appreciation of the value of my equity in the property). Never would I have anticipated what has happened to date. I am pleased to say that between Bitcoin’s surge this week, Amazon’s last month, the appreciation of my Kentucky property’s value, and some other smaller stock and crypto investments along the way, my investments have now offset the entirety of my burn over the last 10 months. My net worth is slightly greater today than it was the day I quit my job, and it is not because I’ve been a hermit or lived a miserably frugal life. Quite the contrary. I traveled the world for a few months, had a four-month lease in New York City and stayed in a couple hotels before that, got a month-long Airbnb in Georgia with Lauren, have eaten well, been golfing a lot lately, and the list goes on. Not every day is roses. I would be skeptical of anyone who says that is the case. But I have not often if ever but rarely felt restrained moneywise. I have been enjoying my time quite a bit.</p>



<p>When I quit my job, I figured I would burn a good chunk of my savings in a few months and expected I would feel the need to get a job after several if not before then. I thought it would be well worthwhile to burn that money in exchange for the time that I would buy for myself to do whatever I wanted. I was right in the sense that this time has proven valuable to me but wrong in another. It hasn’t cost me a dime.</p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-08-03T16:13:48-04:00">August 3, 2020</time><time datetime="2020-08-03T16:17:10-04:00">August 3, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://blogofjake.com/2020/08/03/profitably-unemployed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045529</guid>
            <pubDate>Tue, 04 Aug 2020 01:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Harry Potter and the Mnemonic Major System]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24045475">thread link</a>) | @krisfris
<br/>
August 3, 2020 | https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html | <a href="https://web.archive.org/web/*/https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  <div itemprop="articleBody">
    <p>As most reasonable people are familiar with the Harry Potter books,
their content serves as ideal material for building a mnemonic system.
The mnemonic major system, in particular, is used to memorize number sequences.</p>

<p>In order to implement the steps outlined in this post you need the content of the Harry Potter books (or other book(s) if you prefer).
In a previous post I showed you how to
<a href="https://darkshadow.io/2020/06/29/building-a-fantasy-book-db.html">download fantasy books and extract their text</a>.
Among the downloaded data were the Harry Potter books which I will use in this post.</p>

<h3 id="step-1-learn-the-sound-number-mapping">Step 1: Learn the sound-number mapping</h3>

<p>In the mnemonic major system each number from 0 to 9 is associated with one or more
consonant sounds. Use the following table as a reference.</p>

<table>
  <thead>
    <tr>
      <th>Number</th>
      <th>Sounds (IPA)</th>
      <th>Letters with example words</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>0</td>
      <td>s, z</td>
      <td>s (see), c (city), z (zero), x (xylophone)</td>
    </tr>
    <tr>
      <td>1</td>
      <td>t, d, ð, θ</td>
      <td>t (tee), d (dad), th (though), th (think)</td>
    </tr>
    <tr>
      <td>2</td>
      <td>n, ŋ</td>
      <td>n (nail)</td>
    </tr>
    <tr>
      <td>3</td>
      <td>m</td>
      <td>m (monster)</td>
    </tr>
    <tr>
      <td>4</td>
      <td>r</td>
      <td>r (right), l (colonel)</td>
    </tr>
    <tr>
      <td>5</td>
      <td>l</td>
      <td>l (left)</td>
    </tr>
    <tr>
      <td>6</td>
      <td>ʤ, ʧ, ʃ, ʒ</td>
      <td>ch (cheese), j (juice), g (ginger), sh (shell), c (cello, special),<br> cz (czech), s (tissue, vision), sc (fascist), sch (eschew),<br>t (ration), tsch (putsch), z (seizure)</td>
    </tr>
    <tr>
      <td>7</td>
      <td>k, ɡ</td>
      <td>k (kid), c (cake), q (quarter), g (good), ch (loch)</td>
    </tr>
    <tr>
      <td>8</td>
      <td>f, v</td>
      <td>f (face), ph (phone), v (alive), gh (laugh)</td>
    </tr>
    <tr>
      <td>9</td>
      <td>p, b</td>
      <td>p (power), b (baby)</td>
    </tr>
  </tbody>
</table>

<p>In English, letters are pronounced in different ways depending on the context,
that’s why some letters are repeated in different rows. But in the end,
only the sound matters, not the spelling.</p>

<p>Here are a few examples for words, their IPA representation and the number they encode.</p>

<table>
  <thead>
    <tr>
      <th>Word</th>
      <th>IPA</th>
      <th>Number</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>action</td>
      <td>ækʃən</td>
      <td>762</td>
    </tr>
    <tr>
      <td>muddy</td>
      <td>mədi</td>
      <td>31</td>
    </tr>
    <tr>
      <td>midday</td>
      <td>mɪddeɪ</td>
      <td>311</td>
    </tr>
    <tr>
      <td>accept</td>
      <td>æksɛpt</td>
      <td>7091</td>
    </tr>
    <tr>
      <td>fax</td>
      <td>fæks</td>
      <td>870</td>
    </tr>
    <tr>
      <td>exam</td>
      <td>ɪgzæm</td>
      <td>703</td>
    </tr>
    <tr>
      <td>anxious</td>
      <td>æŋkʃəs</td>
      <td>2760</td>
    </tr>
    <tr>
      <td>luxury</td>
      <td>ləgʒəri</td>
      <td>5764</td>
    </tr>
    <tr>
      <td>pizza</td>
      <td>pitsə</td>
      <td>910</td>
    </tr>
    <tr>
      <td>ghost</td>
      <td>goʊst</td>
      <td>701</td>
    </tr>
    <tr>
      <td>enough</td>
      <td>inəf</td>
      <td>28</td>
    </tr>
    <tr>
      <td>fear</td>
      <td>fɪr</td>
      <td>84</td>
    </tr>
  </tbody>
</table>

<p>To familiarize yourself with the IPA notation, try to read the following excerpt.</p>

<figure><pre><code data-lang="html">Sorting Hat: həm, dɪfəkəlt. vɛri dɪfəkəlt. plɛnti əv kərɪʤ, aɪ si.
             nɑt ə bæd maɪnd, iðər. ðɛrz tælənt, oʊ jɛs. ənd ə θərst tɪ pruv jʊrsɛlf.
             bət wɛr tɪ pʊt ju?
Harry:       nɑt slɪðərɪn. nɑt slɪðərɪn.
Sorting Hat: nɑt slɪðərɪn, ɛ? ər ju ʃʊr? ju kʊd bi greɪt, ju noʊ. ɪts ɔl hir ɪn jʊr hɛd.
             ənd slɪðərɪn wɪl hɛlp ju ɔn ðə weɪ tɪ greɪtnəs, ðɛrz noʊ daʊt əbaʊt ðət. noʊ?
Harry:       pliz, pliz. ɛniθɪŋ bət slɪðərɪn, ɛniθɪŋ bət slɪðərɪn.
Sorting Hat: wɛl ɪf jʊr ʃʊr, bɛtər bi... grɪfɪndɔː!</code></pre></figure>

<p>Consider the same lines converted to number sequences.</p>

<figure><pre><code data-lang="html">Sorting Hat: 3 18751 84 18751 9521 8 746 0 21 91 321 14 140 1521 0 21 8401 1 948 4058 91 4 1 91
Harry:       21 05142 21 05142
Sorting Hat: 21 05142 4 64 71 9 741 2 10 5 4 2 4 1 21 05142 5 59 2 1 1 74120 140 2 11 91 11 2
Harry:       950 950 282 91 05142 282 91 05142
Sorting Hat: 5 8 4 64 914 9 74821</code></pre></figure>

<p>I’m going to show you how to write a training program to internalize
the concept of mapping sounds to numbers in Step 4. But first, you need the ability
to convert text automatically to numbers. This happens in 2 steps. First, the text is converted
to IPA. Then, the IPA is converted to numbers.</p>

<h3 id="step-2-converting-ipa-to-numbers">Step 2: Converting IPA to numbers</h3>

<p>The process of converting IPA to numbers is very simple. I iterate through the IPA chars
and if there is a number associated with the char I append the number to the result.</p>

<figure><pre><code data-lang="python"><span># Mapping from number to sounds
</span><span>num_to_phones</span> <span>=</span> <span>{</span><span>0</span><span>:</span> <span>[</span><span>'s'</span><span>,</span> <span>'z'</span><span>],</span> <span>1</span><span>:</span> <span>[</span><span>'t'</span><span>,</span> <span>'d'</span><span>,</span> <span>'ð'</span><span>,</span> <span>'θ'</span><span>],</span> <span>2</span><span>:</span> <span>[</span><span>'n'</span><span>,</span> <span>'ŋ'</span><span>],</span> <span>3</span><span>:</span> <span>[</span><span>'m'</span><span>],</span> <span>4</span><span>:</span> <span>[</span><span>'r'</span><span>],</span>
                 <span>5</span><span>:</span> <span>[</span><span>'l'</span><span>],</span> <span>6</span><span>:</span> <span>[</span><span>'ʤ'</span><span>,</span> <span>'ʧ'</span><span>,</span> <span>'ʃ'</span><span>,</span> <span>'ʒ'</span><span>],</span> <span>7</span><span>:</span> <span>[</span><span>'k'</span><span>,</span> <span>'g'</span><span>],</span> <span>8</span><span>:</span> <span>[</span><span>'f'</span><span>,</span> <span>'v'</span><span>],</span>
                 <span>9</span><span>:</span> <span>[</span><span>'p'</span><span>,</span> <span>'b'</span><span>]}</span>

<span># Reverse mapping from sound to number
</span><span>phone_to_num</span> <span>=</span> <span>{</span><span>x</span><span>:</span> <span>k</span> <span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>num_to_phones</span><span>.</span><span>items</span><span>()</span> <span>for</span> <span>x</span> <span>in</span> <span>v</span><span>}</span>

<span>def</span> <span>major_decode_from_ipa</span><span>(</span><span>ipa</span><span>):</span>
    <span>"""Convert IPA to number sequence."""</span>
    <span>result</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>char</span> <span>in</span> <span>ipa</span><span>:</span>
        <span>if</span> <span>(</span><span>num</span> <span>:</span><span>=</span> <span>phone_to_num</span><span>.</span><span>get</span><span>(</span><span>char</span><span>))</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>result</span><span>.</span><span>append</span><span>(</span><span>num</span><span>)</span>
    <span>return</span> <span>result</span></code></pre></figure>

<p>For example, <code>major_decode_from_ipa('dɪfəkəlt')</code> yields <code>[1, 8, 7, 5, 1]</code>.</p>

<p>Additionally, I define a couple functions for converting number sequences to and from strings.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>numseq_to_str</span><span>(</span><span>numseq</span><span>):</span>
    <span>"""Convert number sequence to string."""</span>
    <span>return</span> <span>''</span><span>.</span><span>join</span><span>(</span><span>str</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>numseq</span><span>)</span>

<span>def</span> <span>str_to_numseq</span><span>(</span><span>s</span><span>):</span>
    <span>"""Convert string to number sequence."""</span>
    <span>return</span> <span>[</span><span>int</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>s</span> <span>if</span> <span>x</span><span>.</span><span>isdigit</span><span>()]</span></code></pre></figure>

<p>For example, <code>numseq_to_str([1, 8, 7, 5, 1])</code> yields <code>'18751'</code>.</p>

<h3 id="step-3-converting-text-to-ipa">Step 3: Converting text to IPA</h3>

<p>In order to automatically convert text to IPA (and then to numbers) you need to use an IPA
dictionary.</p>

<p>Python’s <a href="https://pypi.org/project/eng-to-ipa/">eng-to-ipa</a> package is able to convert text to
IPA using the <em>Carnegie-Mellon University Pronouncing Dictionary</em>.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>eng_to_ipa</span>

<span>s</span> <span>=</span> <span>'“I’ll bring up some sandwiches.”'</span>  <span># Sentence from the HP books
</span><span>ipa</span> <span>=</span> <span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>s</span><span>,</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>)</span>
<span>print</span><span>(</span><span>ipa</span><span>)</span></code></pre></figure>

<p>This yields:</p>

<figure><pre><code data-lang="html">['“i’ll* brɪŋ əp səm sandwiches.”*']</code></pre></figure>

<p>According to the docs, eng-to-ipa will reprint words that cannot be found in the CMU dictionary
with an asterisk. Thus, <code>“i’ll</code> and <code>sandwiches.”</code> have not been found. Clearly, the punctuation is the issue.
I preprocess the text in order to ease the conversion to IPA.</p>

<figure><pre><code data-lang="python"><span># Punctuation including unicode chars
</span><span>punctuation</span> <span>=</span> <span>''</span><span>.</span><span>join</span><span>(</span><span>chr</span><span>(</span><span>i</span><span>)</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>sys</span><span>.</span><span>maxunicode</span><span>)</span>
                      <span>if</span> <span>unicodedata</span><span>.</span><span>category</span><span>(</span><span>chr</span><span>(</span><span>i</span><span>)).</span><span>startswith</span><span>(</span><span>'P'</span><span>))</span>

<span>def</span> <span>preprocess</span><span>(</span><span>text</span><span>):</span>
    <span>"""Strip punctuation between words, normalize space, lowercase, replace unicode apostrophe."""</span>
    <span>return</span> <span>' '</span><span>.</span><span>join</span><span>(</span><span>x</span><span>.</span><span>strip</span><span>(</span><span>punctuation</span><span>).</span><span>lower</span><span>().</span><span>replace</span><span>(</span><span>'’'</span><span>,</span> <span>'</span><span>\'</span><span>'</span><span>)</span>
                    <span>for</span> <span>x</span> <span>in</span> <span>text</span><span>.</span><span>split</span><span>())</span>
                    
<span>print</span><span>(</span><span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>preprocess</span><span>(</span><span>s</span><span>),</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>))</span></code></pre></figure>

<p>And…</p>

<figure><pre><code data-lang="html">['aɪl brɪŋ əp səm sæmwɪʧɪz', 'aɪl brɪŋ əp səm sændwɪʧɪz', 'aɪl brɪŋ əp səm sænwɪʧɪz']</code></pre></figure>

<p>As you can see, there are 3 ways to pronounce this sentence depending on whether you like
to pronounce <code>sandwich</code> with <code>m</code>, <code>n</code> or <code>nd</code>. In order to use the major system effectively,
you should use the version that sounds most natural to you.</p>

<p>Let’s look at another example.</p>

<figure><pre><code data-lang="python"><span>print</span><span>(</span><span>eng_to_ipa</span><span>(</span><span>preprocess</span><span>(</span><span>'Well, if you’re sure — better be GRYFFINDOR!'</span><span>),</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span>
                 <span>keep_punct</span><span>=</span><span>False</span><span>,</span> <span>stress_marks</span><span>=</span><span>False</span><span>))</span></code></pre></figure>

<figure><pre><code data-lang="html">['wɛl ɪf jur ʃʊr bɛtər bi gryffindor*', 'wɛl ɪf jʊr ʃʊr bɛtər bi gryffindor*']</code></pre></figure>

<p>The word <code>gryffindor</code> was not found in the CMU dictionary, which can be expected.
After a quick search for the word’s pronunciation I found <a href="https://youglish.com/pronounce/gryffindor/english">YouGlish</a>
which uses YouTube videos to find IPAs. While their API is not free, a limited number of IPA’s can be scraped
for our purpose.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>time</span><span>,</span> <span>random</span><span>,</span> <span>requests</span><span>,</span> <span>lxml</span><span>.</span><span>html</span><span>.</span><span>soupparser</span>

<span>def</span> <span>ipa_from_youglish</span><span>(</span><span>word</span><span>):</span>
    <span>"""Scrape IPA for word from youglish.com."""</span>
    <span>url</span> <span>=</span> <span>f'https://youglish.com/pronounce/</span><span>{</span><span>word</span><span>}</span><span>/english?'</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>print</span><span>(</span><span>f'Scraping word "</span><span>{</span><span>word</span><span>}</span><span>" from youglish...'</span><span>,</span> <span>end</span><span>=</span><span>''</span><span>,</span> <span>flush</span><span>=</span><span>True</span><span>)</span>
        <span>response</span> <span>=</span> <span>requests</span><span>.</span><span>get</span><span>(</span><span>url</span><span>)</span>
        <span>if</span> <span>'Usage limit exceeded'</span> <span>in</span> <span>response</span><span>.</span><span>text</span><span>:</span>
            <span>raise</span> <span>Exception</span><span>(</span><span>'YouGlish usage limit exceeded'</span><span>)</span>
        <span>root</span> <span>=</span> <span>lxml</span><span>.</span><span>html</span><span>.</span><span>soupparser</span><span>.</span><span>fromstring</span><span>(</span><span>response</span><span>.</span><span>text</span><span>)</span>
        <span>if</span> <span>root</span><span>.</span><span>xpath</span><span>(</span><span>'//div[@class="g-recaptcha"]'</span><span>):</span>
            <span>print</span><span>(</span><span>'RECAPTCHA'</span><span>)</span>
            <span>input</span><span>(</span><span>f'Open </span><span>{</span><span>url</span><span>}</span><span>, submit CAPTCHA challenge, press enter to continue.'</span><span>)</span>
        <span>else</span><span>:</span>
            <span>break</span>
    <span>time</span><span>.</span><span>sleep</span><span>(</span><span>random</span><span>.</span><span>random</span><span>()</span> <span>*</span> <span>3</span><span>)</span>
    <span>d</span> <span>=</span> <span>root</span><span>.</span><span>xpath</span><span>(</span><span>'//div[@id="phoneticPanel"]/div/ul[@class="transcript"]'</span>
                  <span>'/li/span[contains(text(), "Traditional IPA")]'</span>
                  <span>'/following-sibling::text()'</span><span>)</span>
    <span>if</span> <span>d</span><span>:</span>
        <span>print</span><span>(</span><span>'SUCCESS'</span><span>)</span>
        <span>return</span> <span>d</span><span>[</span><span>0</span><span>].</span><span>strip</span><span>(</span><span>' ˈ'</span><span>)</span>
    <span>print</span><span>(</span><span>'FAILED'</span><span>)</span></code></pre></figure>

<p>As you can see, this function is semi-interactive. Without user intervention it will
get stuck on a CAPTCHA. Even then, you’ll eventually reach their daily usage limit
and won’t be able to continue. For our purpose this shall be good enough though.</p>

<figure><pre><code data-lang="python"><span>&gt;</span> <span>ipa_from_youglish</span><span>(</span><span>'gryffindor'</span><span>)</span>
<span>Scraping</span> <span>word</span> <span>"gryffindor"</span> <span>from</span> <span>youglish</span><span>...</span><span>SUCCESS</span>
<span>grɪfɪndɔː</span></code></pre></figure>

<p>I have shown that for many words there are several possible pronunciations, from which you need to choose
your preferred one, and that some words are not in the CMU dictionary and
require scraping the IPA from another source or are not available at all.
For these 2 reasons, you will need to build your own personal IPA dictionary.</p>

<p>I’m going to build my IPA dictionary by iterating through the words of the Harry Potter books
and adding each word and the corresponding IPA to my dictionary.</p>

<p>First, I define
some functions for managing my dictionary (a simple JSON file in this case).</p>

<figure><pre><code data-lang="python"><span>import</span> <span>os</span><span>,</span> <span>glob</span><span>,</span> <span>json</span>

<span>ipa_dict_path</span> <span>=</span> <span>'data/ipa-dict.json'</span>

<span>def</span> <span>load_json_file_or_dict</span><span>(</span><span>filename</span><span>):</span>
    <span>"""Load data from json file if exists otherwise return empty dict."""</span>
    <span>if</span> <span>os</span><span>.</span><span>path</span><span>.</span><span>isfile</span><span>(</span><span>filename</span><span>):</span>
        <span>with</span> <span>open</span><span>(</span><span>filename</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
            <span>return</span> <span>json</span><span>.</span><span>load</span><span>(</span><span>f</span><span>)</span>
    <span>return</span> <span>dict</span><span>()</span>

<span>def</span> <span>save_to_json_file</span><span>(</span><span>data</span><span>,</span> <span>filename</span><span>):</span>
    <span>"""Save data to json file."""</span>
    <span>with</span> <span>open</span><span>(</span><span>filename</span><span>,</span> <span>'w'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>json</span><span>.</span><span>dump</span><span>(</span><span>data</span><span>,</span> <span>f</span><span>)</span>

<span>def</span> <span>load_ipa_dict</span><span>():</span>
    <span>"""Load IPA dict from json file."""</span>
    <span>return</span> <span>load_json_file_or_dict</span><span>(</span><span>ipa_dict_path</span><span>)</span>

<span>def</span> <span>save_ipa_dict</span><span>(</span><span>ipa_dict</span><span>):</span>
    <span>"""Save IPA dict to json file."""</span>
    <span>save_to_json_file</span><span>(</span><span>ipa_dict</span><span>,</span> <span>ipa_dict_path</span><span>)</span></code></pre></figure>

<p>Next, I iterate through the words of the books and enter
each word and whatever is returned by <em>eng-to-ipa</em> into my dictionary.</p>

<figure><pre><code data-lang="python"><span>def</span> <span>harry_potter_text</span><span>():</span>
    <span>"""Return entire content of the Harry Potter books in a single string."""</span>
    <span>data</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>filename</span> <span>in</span> <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'data/json/Harry Potter*'</span><span>):</span>
        <span>with</span> <span>open</span><span>(</span><span>filename</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
            <span>data</span><span>.</span><span>append</span><span>(</span><span>json</span><span>.</span><span>load</span><span>(</span><span>f</span><span>)[</span><span>'text'</span><span>])</span>
    <span>return</span> <span>' '</span><span>.</span><span>join</span><span>(</span><span>data</span><span>)</span>
    
<span>def</span> <span>populate_ipa_dict_from_text</span><span>(</span><span>text</span><span>):</span>
    <span>"""Get all IPA information from eng_to_ipa and save to ipa_dict."""</span>
    <span>ipa_dict</span> <span>=</span> <span>load_ipa_dict</span><span>()</span>
    <span>words</span> <span>=</span> <span>preprocess</span><span>(</span><span>text</span><span>).</span><span>split</span><span>()</span>
    <span>for</span> <span>word</span> <span>in</span> <span>set</span><span>(</span><span>words</span><span>)</span> <span>-</span> <span>set</span><span>(</span><span>ipa_dict</span><span>.</span><span>keys</span><span>()):</span>
        <span>ipa</span> <span>=</span> <span>eng_to_ipa</span><span>.</span><span>convert</span><span>(</span><span>word</span><span>,</span> <span>retrieve_all</span><span>=</span><span>True</span><span>,</span> <span>keep_punct</span><span>=</span><span>False</span><span>,</span>
                                 <span>stress_marks</span><span>=</span><span>False</span><span>)</span>
        <span>ipa_dict</span><span>[</span><span>word</span><span>]</span> <span>=</span> <span>ipa</span>
    <span>save_ipa_dict</span><span>(</span><span>ipa_dict</span><span>)</span>
    
<span>populate_ipa_dict_from_text</span><span>(</span><span>harry_potter_text</span><span>())</span></code></pre></figure>

<p>Each value in the dictionary is now a list of possible IPAs as that is what
<em>eng-to-ipa</em> returned. Before the dictionary can be used, we need to ensure
that each word …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html">https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html</a></em></p>]]>
            </description>
            <link>https://darkshadow.io/2020/07/09/harry-potter-and-the-mnemonic-major-system.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24045475</guid>
            <pubDate>Tue, 04 Aug 2020 01:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Physical attractiveness bias in the legal system (2017)]]>
            </title>
            <description>
<![CDATA[
Score 392 | Comments 377 (<a href="https://news.ycombinator.com/item?id=24044409">thread link</a>) | @simonebrunozzi
<br/>
August 3, 2020 | https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system | <a href="https://web.archive.org/web/*/https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="siteWrapper">

      

      

      
        
          
            
              
                
              
            
          
        
      


      
      
      

      <main id="page" role="main">
        
        <!--
        --><!--
        --><div id="content" data-content-field="main-content" data-collection-id="5817e1ff3e00be2eafd0dec4" data-edit-main-image="">
         <div>

  
  <article id="article-58c757b5e4fcb5bd2d9613d5" data-item-id="58c757b5e4fcb5bd2d9613d5">

    

    <div>
      
        <div data-layout-label="Post Body" data-type="item" data-updated-on="1489459192059" id="item-58c757b5e4fcb5bd2d9613d5"><div><div><div data-block-type="2" id="block-yui_3_17_2_3_1489466160916_36894"><div><blockquote><p><a href="http://bit.ly/2m8beq4" target="_blank">[Download for PDF/printable version of this article]</a><br></p></blockquote><p>When I started looking into this subject, I predicted a person’s physical attractiveness would only have minor advantages. I was wrong.</p><p>In fact, I was so wrong, that in one study, the effects of physical attractiveness on judges were so influential, they fined unattractive criminals 304.88% higher than attractive criminals.</p><p>Surprising, I know.</p><p>Before we proceed, I want to address a few concerns of mine. Firstly, the information that you will read may cause some readers to feel unsettled. This is not my intention. Yes, it is disheartening. But the purpose of this article is to inform lawyers and other decision makers so that they can use the attractiveness bias to their advantage or to counter it.</p><p>A second concern of mine is that I don’t want to over-emphasise the attractiveness bias. Judges and jurors are affected by all kinds of cognitive distortions, such as emotive evidence, time of day, remorse of the defendant, socioeconomic status, race, gender, anchoring effect, and the contrast bias.</p><p>In the first section of this article, I give a ‘straight-to-the-point’ summary of the research conducted by 27 studies. Next, I enter into greater depth on the attractiveness bias and its effects on judges, jurors, and lawyers. Lastly, I provide research on the attractiveness bias in everyday life. Arguably, the last section is the most interesting.</p><p>Enjoy!</p><p>* * *</p><ol data-rte-list="default"><li><p>Physical Attractiveness had a significant influence on judges sentencing. The more unattractive the criminal, the higher the sentence. Or conversely, the more attractive the criminal, the lower the sentence. The results of three studies show a minimum increase of 119.25% and a maximum increase of 304.88%.<br></p></li><li><p>Attractiveness had little to no effect on a judge’s verdict of guilt. Attractive and unattractive criminals were convicted equally.<br></p></li><li><p>Mock jurors generally sentenced unattractive criminals significantly higher than attractive criminals. However, as jurors do not determine sentencing in real court cases, these results are not directly applicable.<br></p></li><li><p>Attractiveness had minor effects on mock juror’s verdicts. Some studies reported minor effects and some studies reported no effects.<br></p></li><li><p>Generally, attractive people are perceived as more intelligent, more socially skilled, more appealing personalities, more moral, more altruistic, more likely to succeed, more hirable as managers, and more competent. Attractive people tend to have better physical health, better mental health, better dating experiences, earn more money, obtain higher career positions, chosen for jobs more often, promoted more often, receive better job evaluations, and chosen as business partners more often, than unattractive people.<br></p></li><li><p>I believe that the attractiveness bias is rarely conscious. I do not think people are consciously disfavouring unattractive people. I also do not place moral blame on the typical person for their unconscious bias.</p></li></ol><p>* * *</p><h2><strong>REAL JUDGES: SENTENCING</strong></h2><p><strong>THE MISDEMEANOUR STUDY </strong><em>[1]</em></p><p>The first study we will observe is the research conducted by Downs and Lyons.</p><p>The purpose of this study was to find a link between a criminal’s attractiveness and sentencing outcomes.</p><p>They gathered a group of police officers and students to rate the attractiveness of over 2000 criminals. A scale of 1 - 5 was used and their ratings were mostly similar.</p><p>Then, the judges sentencing decisions were divided into two main categories: misdemeanors and felonies. Misdemeanors were separated into to 3 classes, related to the severity of the crime.</p><p><em>The Results &amp; Key Takeaways</em></p><p>For misdemeanours, the judges fined unattractive criminals significantly more than attractive criminals. The fine incrementally increased as the attractiveness decreased.</p><p>1.&nbsp;&nbsp;&nbsp;&nbsp; Minor Misdemeanours = +224.87%</p><p>2.&nbsp;&nbsp;&nbsp;&nbsp; Moderate Misdemeanours = +304.88%</p><p>3.&nbsp;&nbsp;&nbsp;&nbsp; Serious Misdemeanours = + 174.78%</p><p>The results are graphed below.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_48500"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg" data-image-dimensions="1047x619" data-image-focal-point="0.5,0.5" alt="Image test 1.jpg" data-load="false" data-image-id="58c89366f7e0ab29642796d9" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489539944610-FD8SUJ05P7WIZRNN1AYU/ke17ZwdGBToddI8pDm48kJTwxz64trr3drbHr6lHJk8UqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcrARKSnFMgvt0aSzcObof0G5Q2td9bvxksMtgDYlbDbROWDvDtu6PEW58QOEcShy6/Image+test+1.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_48699"><div><p>Curiously, felony fines had no correlation with the attractiveness of the criminal. The study does not make it clear why this is the case.</p><p><em>Answers to Possible Objections</em></p><ul data-rte-list="default"><li><p>The judges varied in gender and race.</p></li><li><p>There was no correlation between sentencing outcomes and age, gender, and race.</p></li></ul><p><em>Weaknesses</em></p><p>For privacy reasons, the specific crime was not documented.</p><p>The direction of causation is not known. I enter into more depth in the section entitled ‘causation’.</p><p><strong>THE PENNSYLVANIAN STUDY<em> </em></strong><em>[2]</em></p><p>In Pennsylvanian and Philadelphian courts, the researcher’s gathered data on 67 defendants. The defendants were a mix of black, Hispanic, and white and there were 15 real judges in total.</p><p><em>Results &amp; Key Takeaways</em></p><p>On average (mean), criminals of low attractiveness were sentenced to 4.10 years in prison and criminals of high attractiveness were sentenced to 1.87 years in prison. This equals a 119.25% increase.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_71526"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png" data-image-dimensions="1095x642" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75991e6f2e16d0cb71613" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459602430-G7OV3RYZPYB7CFDC7Y1E/ke17ZwdGBToddI8pDm48kB9PP1roaCoWCcB5PDMLLBcUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcJDPzuPFQMkDrmP7vOugYmF8e3iX03QqVmRfNUMP65OVoNHPxvCYY7HSGytwWF1ph/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_71724"><div><p><em>Weaknesses</em></p><p>All observers were white.</p><p><strong>THE SECOND PENNSYLVANIAN STUDY</strong> <em>[3]</em></p><p>This study was similar to the previous study. The researchers recorded data from real court cases in Pennsylvania. They detailed the physical attractiveness of 60 defendants and their neatness, cleanliness, and quality of clothing. Then, they recorded the judge’s decisions.</p><p>The criminals were charged with a range of felonies, including ‘murder; manslaughter; rape; kidnapping; armed robbery; aggravated assault; indecent assault; arson; burglary; conspiracy to sell/delver heroin, cocaine, hashish, and other elicit drugs; extortion; fraud; theft; and firearms violation.’</p><p>They were also a mix of white, Hispanic and black.&nbsp;</p><p><em>Results &amp; Key Takeaways</em></p><p>The unattractive defendants were punished higher than the attractive defendants.</p><p><em>Weaknesses</em></p><p>The study did not give specific results. This is a major disappointment.</p><p><strong>CONCLUSIONS</strong></p><p>Unattractive criminals were punished higher than attractive criminals in three studies. The lowest increase was at 119.25% and the highest increase was at 304.88%.</p><h2><strong>REAL JUDGES: VERDICT, GUILTY OR NOT-GUILTY</strong></h2><p>There was no association between the defendant’s physical attractiveness and the judge’s verdict. Attractive and unattractive criminals were found guilty at equal rates. Zebrowitz and McDonald [4]&nbsp;also found that the plaintiff’s attractiveness had little to no effects on a judge’s verdict.</p><p><strong>THE BABY-FACED STUDY </strong><em>[5]</em></p><p>The following study is not directly related to physical attractiveness but it is related to physical appearance.</p><p>Zebrowitz and McDonald measured the effects of defendants with a ‘baby-face’ and the judge’s verdict decisions. This is a strange characteristic to measure, however, the results were significant enough to warrant attention.</p><p>‘Baby-faced adults tend to have larger eyes, thinner, higher eyebrows, a large forehead and a small chin, and a curved rather than an angular face.’<em>[6]</em>&nbsp;A team of participants sat in 421 cases in ‘6 branches of the Commonwealth of Massachusetts small claims courts. 3 judges heard 51% of the cases and the remaining 49% of the cases were presided over by 22 additional judges.’ ‘62% of the plaintiffs and 78% of the defendants were male. 96% of both plaintiffs and defendants were white, and 81% were between the ages of 21 and 50.’</p><p><em>Results &amp; Key Takeaways</em></p><p>The more baby-faced an adult was, the less likely he/she was found to be guilty for ‘intentional actions’ in civil claims. Observe the graph below.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_6_1489459079955_91414"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg" data-image-dimensions="2500x2137" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75a7ed482e9a66b47537e" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489459840849-7GP7F5ASMZM4ZYP8VK7K/ke17ZwdGBToddI8pDm48kND1NDuHF9nqrgeclEdLoeR7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z4YTzHvnKhyp6Da-NYroOW3ZGjoBKy3azqku80C789l0qN_-Z3B7EvygvPOPmeOryWYMQ3pkjXJ5SX4aMqPMuK4PimCRlyu3R6yKl-KltrlZA/image-asset.jpeg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_6_1489459079955_91612"><div><p>Interestingly, baby-faced adults had no effects in claims of negligent actions.</p><h2><strong>MOCK JURY: SENTENCING</strong></h2><p>Before I present the following research, I need to address a major limitation. Jurors do not decide upon sentencing, thus, the following results may not have direct application.</p><p><strong>THE META-ANALYSIS STUDY </strong><em>[7]</em></p><p>A meta-analysis examined 25 studies on the effects of physical attractiveness on mock jurors. They found that mock jurors gave higher sentences to unattractive criminals than attractive criminals. This was only for crimes of rape, robbery, and negligent homicide. For swindle, the punishment was equal. The physical attractiveness of the victim also had no effects on the jurors.</p><p><strong>THE BURGLARY STUDY </strong><em>[8]</em></p><p>In this study, the participants were given a burglary scenario along with an image of the criminal. Some received the unattractive criminal and others received the attractive criminal. 10 psychology students rated the attractiveness of the criminals prior to the study to determine attractiveness.</p><p>Then, they were asked to suggest a 1, 5, 10, 15, or 20 years imprisonment.</p><p>‘[The] participants consisted of 40 Euro-American men, 40 Euro-American women, 40 African- American men, and 40 African-American women.’ A strength of this study is the participants ranged in race, gender, and age.</p><p><em>Results &amp; Key Takeaways</em></p><p>The attractive criminal was given an average sentence of 9.7 years, and the unattractive criminal was given 14.7 years. That’s an increase of 51.55%.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_8_1489459079955_11521"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png" data-image-dimensions="1098x643" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="58c75b829de4bb5cb740f698" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5817bb2746c3c4a605334446/1489460099397-DVHCYTA21L18OEBFO2Z5/ke17ZwdGBToddI8pDm48kAd5GqBagiRmFFXdPSaeu6AUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcxXf4uRSJSWTC3Ffy6OHbvGAonPHpqoLXAI0RDTapQcSqK99-n2msqdbGF6fjDgYG/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_8_1489459079955_11721"><div><p><em>Weaknesses</em></p><p>The researchers measured more items than simply attractiveness. This means that the 160 participants were not all measured on attractiveness. As they measured 8 different items and only two of them on attractiveness, I infer …</p></div></div></div></div></div></div></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system">https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system</a></em></p>]]>
            </description>
            <link>https://www.thelawproject.com.au/insights/attractiveness-bias-in-the-legal-system</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044409</guid>
            <pubDate>Mon, 03 Aug 2020 22:50:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go vs. Rust: Writing a CLI Tool]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24044043">thread link</a>) | @JeremyMorgan
<br/>
August 3, 2020 | https://cuchi.me/posts/go-vs-rust | <a href="https://web.archive.org/web/*/https://cuchi.me/posts/go-vs-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><img src="https://gist.githubusercontent.com/cuchi/59255d61717e2d469263eb86cf083067/raw/6ef1a42f335022adf481fb84cabc32ac47f18679/go-vs-rust.png" alt="Go vs. Rust"></p>
<p>This text is about my adventure writing a small CLI application (twice) using
two languages I had little experience with.</p>
<p>If you are eager to jump right into the code and compare it yourself, check it
out the <a href="https://github.com/cuchi/hashtrack/tree/master/cli-go">Go source</a> and
the <a href="https://github.com/cuchi/hashtrack/tree/master/cli-rust">Rust source</a>.</p>
<hr>
<h2>About the Project</h2>
<p>I have a <em>pet project</em> called Hashtrack, which is a full-stack web application I
wrote for a technical interview. This project is rather small and it is simple
to use:</p>
<ol>
<li>You authenticate - considering you already created your account</li>
<li>You input hashtags you want to track</li>
<li>You wait for the <em>captured</em> tweets to show on your screen</li>
</ol>
<p><a href="https://hashtrack.herokuapp.com/">Check it out here.</a></p>
<p>After my interview, I kept improving this project just for fun, and I noticed
that it could be a perfect place to test my skills by implementing a CLI tool. I
already had the server, so I just needed to pick a language to implement a small
set of features under my project's API.</p>
<h2>Features</h2>
<ul>
<li><code>hashtrack login</code> - Creates a session token and store it in the local
filesystem in a config file.</li>
<li><code>hashtrack logout</code> - Remove the locally stored session token.</li>
<li><code>hashtrack track &lt;hashtag&gt; [...]</code> - Tracks one or more hashtags.</li>
<li><code>hashtrack untrack &lt;hashtag&gt; [...]</code> - Untracks one or more previously tracked
hashtags.</li>
<li><code>hashtrack tracks</code> - Displays the hashtags you are tracking.</li>
<li><code>hashtrack list</code> - Displays the latest 50 captured tweets.</li>
<li><code>hashtrack watch</code> - Stream and display the captured tweets in real-time.</li>
<li><code>hashtrack status</code> - Displays who you are, if logged in.</li>
<li>Should have an <code>--endpoint</code> option to point the CLI to another server.</li>
<li>Should have a <code>--config</code> option to load a custom config file.</li>
<li>This config file could also share the <code>endpoint</code> property.</li>
</ul>
<p>What we have to know beforehand:</p>
<ul>
<li>The CLI should use the project's API, which is GraphQL under HTTP +
WebSockets.</li>
<li>The CLI should use the filesystem to store a config file.</li>
<li>The CLI should parse positional arguments and flags.</li>
</ul>
<h2>How did I end up using Go and Rust?</h2>
<p>There is a large set of languages you can use to write CLI tools.</p>
<p>In this case, I wanted a language I had little or no prior experience with, I
also wanted one that could easily compile to a native executable, which is a
nice perk to have on a CLI tool.</p>
<p>My first obvious choice was Go, maybe because a lot of CLI tools I use are
implemented using it. But I also had little experience with Rust, and I saw it
could also be a good fit for this project.</p>
<p>So... why not both? Since my main objective here is to learn, could be a great
opportunity to implement this project twice and find what are the <em>pros and
cons</em> of each one from my point of view.</p>
<blockquote>
<p>Honorable mentions to <a href="https://crystal-lang.org/">Crystal</a> and
<a href="https://nim-lang.org/">Nim</a>, those were very promising options too. I'm looking
forward to learn about them in another pet project.</p>
</blockquote>
<h2>Local environment</h2>
<p>The first thing I look when using a new toolset is whether it has an easy way to
make it available for my user, without using the distribution package manager to
install it system-wide. We are talking about version managers, they make our
life easier by installing the tools in a user-wide manner instead of
system-wide. <a href="https://github.com/nvm-sh/nvm">NVM</a> for Node.js does it very well.</p>
<p>When using Go, there is the <a href="https://github.com/moovweb/gvm">GVM</a> project which
handles the local install &amp; version management, and it is easy to setup:</p>
<pre><code>gvm install go1.14 -B
gvm use go1.14
</code></pre>
<p>There are also two environment variables we need to know, they are <code>GOROOT</code> and
<code>GOPATH</code> -- You can read more about them
<a href="https://www.jetbrains.com/help/go/configuring-goroot-and-gopath.html">here</a>.</p>
<p>The first <em>problem</em> I found using Go, was when I was figuring out how the module
resolution worked along with the <code>GOPATH</code>, it became quite frustrating to
set up a project structure with a functional local development environment.</p>
<p>In the end, I just used <code>GOPATH=$(pwd)</code> in my project's directory, the main perk
was to have a per-project dependency setup, like a <code>node_modules</code>. It worked
well.</p>
<blockquote>
<p>After finishing my project, I found out that
<a href="https://github.com/GetStream/vg">virtualgo</a> existed and would solve my problems
with <code>GOPATH</code>.</p>
</blockquote>
<p>Rust has an official project called <a href="https://rustup.rs/">rustup</a>, which manages
the Rust installation, also known as <em>toolchain</em>. It can be easily set up with a
one-liner. Also, there is a set of optional components using <code>rustup</code>,
such as the <a href="https://github.com/rust-lang/rls">rls</a> and
<a href="https://github.com/rust-lang/rustfmt">rustfmt</a>.
Many projects require a <em>nightly</em> version of the Rust toolchain, with <code>rustup</code>
there was no problem switching between the versions.</p>
<h3>Editor Support</h3>
<p>For both of the languages, editor tooling was flawless, as a VSCode user, I can
find extensions for both Go and Rust in the marketplace.</p>
<p>When debugging with Rust, I had to install the
<a href="https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb">CodeLLDB</a>
extension after following
<a href="https://www.forrestthewoods.com/blog/how-to-debug-rust-with-visual-studio-code/">this tutorial</a>.</p>
<h2>Package management</h2>
<p>Go doesn't have a package manager or even an official registry. Instead, its
module resolution works in a way you can import them from external URLs.</p>
<p>For dependency management, Rust uses the Cargo, which downloads and compiles
dependencies from <a href="https://crates.io/">crates.io</a>, which is the official
registry for Rust packages. Packages inside the Crates ecosystem can also have
their documentation available in <a href="https://docs.rs/">docs.rs</a></p>
<h2>Libraries</h2>
<p>My first objective was to see how easy could be to implement a simple GraphQL
query/mutation over HTTP.</p>
<p>For the Go language, I found some libraries, like
<a href="https://github.com/machinebox/graphql">machinebox/graphql</a> and
<a href="https://github.com/shurcooL/graphql">shurcooL/graphql</a>, the second one uses
structs for (un) marshaling the data, that is what made me stick to it.</p>
<blockquote>
<p>I used a fork of shurcooL/graphql, because I needed to set the
<code>Authorization</code> header in the client, the changes are in
<a href="https://github.com/shurcooL/graphql/pull/48">this pull request</a>.</p>
</blockquote>
<p>This is the Go example of an GraphQL mutation call:</p>
<pre><code><span>type</span> creationMutation <span>struct</span> {
    CreateSession <span>struct</span> {
        Token graphql.String
    } <span>`graphql:"createSession(email: $email, password: $password)"`</span>
}

<span>type</span> CreationPayload <span>struct</span> {
    Email    <span>string</span>
    Password <span>string</span>
}

<span><span>func</span> <span>Create</span><span>(client *graphql.Client, payload CreationPayload)</span> <span>(<span>string</span>, error)</span></span> {
    <span>var</span> mutation creationMutation
    variables := <span>map</span>[<span>string</span>]<span>interface</span>{}{
        <span>"email"</span>:    graphql.String(payload.Email),
        <span>"password"</span>: graphql.String(payload.Password),
    }
    err := client.Mutate(context.Background(), &amp;mutation, variables)

    <span>return</span> <span>string</span>(mutation.CreateSession.Token), err
}

</code></pre>
<p>In Rust, I had to use two libraries to make GraphQL calls. That is because
<code>graphql_client</code> is protocol-agnostic, it only focuses on code generation for
serializing and deserializing data. So I needed a second library (<code>reqwest</code>) to
take care of the HTTP requests.</p>
<pre><code><span>#[derive(GraphQLQuery)]</span>
<span>#[graphql(
    schema_path = <span>"graphql/schema.graphql"</span>,
    query_path = <span>"graphql/createSession.graphql"</span>
)]</span>
<span><span>struct</span> <span>CreateSession</span></span>;

<span>pub</span> <span><span>struct</span> <span>Session</span></span> {
    <span>pub</span> token: <span>String</span>,
}

<span>pub</span> <span><span>type</span> <span>Creation</span></span> = create_session::Variables;

<span>pub</span> <span>async</span> <span><span>fn</span> <span>create</span></span>(context: &amp;Context, creation: Creation) -&gt; <span>Result</span>&lt;Session, api::Error&gt; {
    <span>let</span> res = api::build_base_request(context)
        .json(&amp;CreateSession::build_query(creation))
        .send()
        .<span>await</span>?
        .json::&lt;Response&lt;create_session::ResponseData&gt;&gt;()
        .<span>await</span>?;
    <span>match</span> res.data {
        <span>Some</span>(data) =&gt; <span>Ok</span>(Session {
            token: data.create_session.token,
        }),
        _ =&gt; <span>Err</span>(api::Error(api::get_error_message(res).to_string())),
    }
}
</code></pre>
<p>Neither of the libraries for Go and Rust had any implementation for GraphQL via
WebSocket protocol.</p>
<p>In fact, <code>graphql_client</code> for Rust supports <em>Subscriptions</em>, but since it is
protocol-agnostic, I had to implement the whole GraphQL WebSocket communication
on my own,
<a href="https://github.com/cuchi/hashtrack/blob/b5a75f4368837cd51c621b6560a03e1835ec4e5b/cli-rust/src/tweet.rs#L90">check it out</a>.</p>
<p>To use WebSockets in the Go version, the library should be modified to support
the protocol. Since I was already using a fork of the library, I didn't feel
like doing it. Instead, I used a poor man's way of "watching" the new tweets,
which was to request the API every 5 seconds to retrieve them,
<a href="https://github.com/cuchi/hashtrack/blob/b5a75f4368837cd51c621b6560a03e1835ec4e5b/cli-go/src/hashtrack/tweets/tweets.go#L65">I'm not proud of it</a>.</p>
<p>Using Go, there is the <code>go</code> keyword to spawn a lightweight thread, also called
<em>goroutine</em>. In contrast, Rust uses operating system threads by calling a
<code>Thread::spawn</code>. Besides that, both implementations use channels to transfer
objects between their threads.</p>
<h2>Error handling</h2>
<p>In Go, errors are treated just like any other value. The common way to handle
errors in Go is to just check if they are present.</p>
<pre><code><span><span>func</span> <span>(config *Config)</span> <span>Save</span><span>()</span> <span>error</span></span> {
	contents, err := json.MarshalIndent(config, <span>""</span>, <span>"    "</span>)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}

	err = ioutil.WriteFile(config.path, contents, <span>0</span>o644)
	<span>if</span> err != <span>nil</span> {
		<span>return</span> err
	}

	<span>return</span> <span>nil</span>
}
</code></pre>
<p>Rust has the <code>Result&lt;T, E&gt;</code> enum, which can encapsulate an <code>Ok(T)</code> for success,
or an <code>Err(E)</code> for errors. It also has the <code>Option&lt;T&gt;</code> enum, with <code>Some(T)</code> or
<code>None</code>. If you are familiar with Haskell, you may recognize
those as the <code>Either</code> and the <code>Maybe</code> monads.</p>
<p>There is also a syntactic sugar for error propagation (the <code>?</code> operator) that
resolves the value from the <code>Result</code> or <code>Option</code> structure, automatically
returning <code>Err(...)</code> or <code>None</code> when something goes bad.</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>save</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; io::<span>Result</span>&lt;()&gt; {
    <span>let</span> json = serde_json::to_string(&amp;<span>self</span>.contents)?;
    <span>let</span> <span>mut</span> file = File::create(&amp;<span>self</span>.path)?;
    file.write_all(json.as_bytes())
}
</code></pre>
<p>The code above is the equivalent of</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>save</span></span>(&amp;<span>mut</span> <span>self</span>) -&gt; io::<span>Result</span>&lt;()&gt; {
    <span>let</span> json = <span>match</span> serde_json::to_string(&amp;<span>self</span>.contents) {
        <span>Ok</span>(json) =&gt; json,
        <span>Err</span>(e) =&gt; <span>return</span> <span>Err</span>(e.into())
    };
    <span>let</span> <span>mut</span> file = <span>match</span> File::create(&amp;<span>self</span>.path) {
        <span>Ok</span>(file) =&gt; file,
        <span>Err</span>(e) =&gt; <span>return</span> <span>Err</span>(e.into())
    };
    file.write_all(json.as_bytes())
}
</code></pre>
<p>Rust has:</p>
<ul>
<li>monadic constructs (<code>Option</code> &amp; <code>Result</code>)</li>
<li>the error propagation operator</li>
<li>the <code>From</code> trait, to automatically convert errors on propagation</li>
</ul>
<p>The combination of the three features above makes up the best error handling
solution I saw in a language, being simple, sound, and maintainable at the same
time.</p>
<h2>Compilation time</h2>
<p>Go is built with fast compilation time as a critical requirement, let's see:</p>
<pre><code>&gt; time go get hashtrack 
go get hashtrack  1,39s user 0,41s system 43% cpu 4,122 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,80s user 0,12s system 152% cpu 0,603 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,19s user 0,07s system 400% cpu 0,065 total

&gt; time go build -o hashtrack hashtrack 
go build -o hashtrack hashtrack  0,94s user 0,13s …</code></pre></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cuchi.me/posts/go-vs-rust">https://cuchi.me/posts/go-vs-rust</a></em></p>]]>
            </description>
            <link>https://cuchi.me/posts/go-vs-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24044043</guid>
            <pubDate>Mon, 03 Aug 2020 22:08:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One year of automatic DB migrations from Git]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 39 (<a href="https://news.ycombinator.com/item?id=24043987">thread link</a>) | @awinter-py
<br/>
August 3, 2020 | https://abe-winter.github.io/2020/08/03/yr-of-git.html | <a href="https://web.archive.org/web/*/https://abe-winter.github.io/2020/08/03/yr-of-git.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>For the last year-plus, for most of my solo work, I’ve used a tool called <a href="https://github.com/abe-winter/automigrate">automig</a> to automatically turn my SQL schema changes into deltas that can be applied to a DB
(plug – I wrote it).</p>

<p>I hate writing migrations because it feels like work a computer should know how to do,
and because in general there’s no guarantee that the migrations produce something equivalent to your ‘schema.sql’ or ORM definition.</p>

<p>(SQLAlchemy’s alembic has an <a href="https://alembic.sqlalchemy.org/en/latest/autogenerate.html">autogenerate feature</a> which compares a running DB to your ORM spec;
having a running DB in the loop for migration generation creates a different set of tradeoffs than automig, which analyzes the sql files directly).</p>

<p>This article is a pros and cons retrospective on that year.</p>

<ul id="markdown-toc">
  <li><a href="#pros" id="markdown-toc-pros">Pros</a></li>
  <li><a href="#cons" id="markdown-toc-cons">Cons</a></li>
</ul>

<h2 id="pros">Pros</h2>

<p><strong>I haven’t written a migration in 1+ years</strong>.
And I don’t love writing migrations.
My process to add a column has fewer steps.
This is a win.</p>

<p><strong>Simple and readable source of truth</strong>.
As long as you trust that the tool knows what it’s doing,
you can open up the <code>schema.sql</code> file (or whatever you choose to name yours) and get a schema that is <em>both</em>
a readable doc of what the database should have
and a reliable indicator of what the database actually has.</p>

<p><strong>Standard tool across different languages</strong>.
I’ve used automig on different python and golang projects and it doesn’t care.
It’s not linked to any design or tool decision inside the codebase.
Automig isn’t a standard tool, but if it were, it would be a portable skillset.</p>

<p><strong>No cluttered migrations dir</strong>.
More of a personal hygiene decision than a legit gripe, but migration directories aren’t my favorite; hundreds of files that do very little good.
Automig is also faster at reinitialization because you can start from git HEAD rather than applying hundreds of changes from the last 36 months.</p>

<p><strong>Turns something complicated into something simple and almost as good</strong>.
There are cons (see below) but there’s a bunch of migration-related work that I no longer think about.
I no longer dread adding a DB column or an index.
If my capabilities are less because the tool is simpler and declarative, that’s a tradeoff, but it’s one that I’ve lived with happily.</p>

<h2 id="cons">Cons</h2>

<p><strong>Data migrations not supported</strong>.
Automig is good at schema migrations but doesn’t have an easy way to transform columns or run code on your DB.
The tool has an answer to this in the roadmap.
For my own needs I’ve been able to work around this by doing two-step migrations with default values.</p>

<p>For larger users, data migrations involve lots of design (see for example github’s GH-OST tool).
In the future I think migrations should be a native feature in the DB –
you should upload a schema and specify whether migrations run up-front or on read.
And we shouldn’t tie type to storage locality.</p>

<p><strong>When something goes wrong, I have to fix it</strong>.
This is 50% a gripe about using a tool that I maintain and am the only user of.
But 50% a legit point that a ‘declarative diffing’ tool has more logic in it than migrations that you write yourself in SQL.
Running arbitrary SQL gives you a lot of flexibility and gives you infinite freedom to choose incompatible dialects.</p>

<p><strong>Extra lifting to integrate with ORMs</strong>.
Automig can generate SQLAlchemy definitions from your schema.sql, but that’s it.
If you use a single language / framework, defining your DB in an ORM is probably more useful than having it specified using SQL.</p>

<p><strong>Dialect support is no picnic</strong>.
When I switched from postgres to sqlite for some projects, it was a pain to support the different dialects.
I ran into things like different support for transactional DDL.</p>

<p>(Since I first wrote this I’ve seen comments from the skeema and migra committers.
Both of these tools support <em>only one</em> DB: mysql and postgres respectively, and rely on the DB to do the heavy lifting.
There are a lot of positives to this approach).</p>

<p><strong>Branch conflict issues + rebasing</strong>.
Any nonlinear git history can be a source of errors.
Automig has an <code>--opaque</code> switch to work around these, but manually-specified migrations are likely better at branches, especially if you need to support out-of-order changes.
I haven’t encountered these problems because I’m in solo codebases, but I can see there being issues in big teams who sometimes deploy from non-main branches.</p>

<p><strong>Migrating production involves up-front work</strong>.
If you use your main backend language / framework to run migrations, life is easy.
Automig has extra requirements: it needs to bundle the <code>.git</code> folder (i.e. whole history).
When I ran this on lambda, I had to also bundle a git binary, and my ubuntu binary <em>didn’t work</em>.
I spent a whole day learning how to build git statically before I realized I could just grab the centos one.
The good news is that this work only has to be done once per platform.</p>

<p><strong>Testing is annoying</strong>.
Because automig only works on committed changes, I sometimes have to do a few rounds of <code>git commit --amend</code> before things work.</p>

<p><strong>Column order</strong>.
Automig doesn’t guarantee column order (it does <code>add column</code> but not <code>add column b after a</code>).
This has caused issues with backup / restore.
It’s a problem with the tool but not necessarily with the approach of using git + sql as the source of truth.</p>

<p><strong>Weird parser</strong>.
My parser library is easily confused, especially by uppercase / lowercase and names that look like keywords.
And it’s multi-layer (I use python sqlparse and then wrap it), i.e. janky.
This isn’t an issue with the approach so much as the specific tools I use, but it causes problems.</p>






  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://abe-winter.github.io/2020/08/03/yr-of-git.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043987</guid>
            <pubDate>Mon, 03 Aug 2020 22:02:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Improve On-Call with Better Practices and Tools]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24043949">thread link</a>) | @hannahblameless
<br/>
August 3, 2020 | https://www.blameless.com/blog/how-to-improve-on-call-with-better-practices-and-tools | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/how-to-improve-on-call-with-better-practices-and-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the era of reliability, where mere minutes of downtime or latency can cost hundreds of thousands of dollars, 24x7 availability and on-call coverage to respond to incidents has become a requirement for the vast majority of organizations. But setting up an on-call system that drives effective incident response while minimizing the stress placed on engineers isn’t a trivial task. Establishing equitable on-call rotations, putting the right guardrails and automation in place, and regular incident practice are key. In this blog, we’ll share key tools and practices to ensure your on-call engineers are set up for success.</p><h3>On-call practices and policies</h3><p>When setting up your on-call system, it is important to define clear and consistent policies and practices. When taking on on-call responsibilities, engineers shouldn’t need to reinvent the wheel when the pager goes off; ideally, the planning around severity, incident playbooks, and more should take place during peacetime. The team should work together to create rules that dictate when and how on-call escalations happen. Make sure you have the following worked out before implementing an on-call system.<br></p><h4><strong>Creating Rotation Schedules</strong><br></h4><p>First, you’ll need to build your on-call schedule. Work out which engineers would need to be available for different system areas where incidents could occur, by looking at where each engineer has ownership and domain expertise. Create teams to maximize diversity and coverage, allowing for each time to respond effectively to many different types of incidents. Fill out a calendar with these teams, making sure every shift is covered for your rotation period.<br></p><p>During all of this, consult with your engineers to ensure that your schedules are reasonable and fair. How long should an on-call shift last? How frequently should a team go on-call? What should the procedure be if an engineer has to change shifts? To keep morale high and teams responding effectively, make sure every engineer has a fair say in these choices.<br></p><p>Be prepared to change your rotation schedule frequently, even after implementation. The reality of working on-call shifts is often very different than predicted, so look at on-call data to uncover whether certain individuals are overburdened with off-hours interruptions or critical incidents, and load balance accordingly. Be flexible in hearing out people’s concerns as they develop. External business changes and stages in development cycles can also drastically change the nature of on-call shifts, so be prepared to reflect those with adjustments to shift lengths and rotation frequencies.<br></p><p>Because of these constant changes, it’s important to keep the rotation schedule up-to-date. Make sure it’s kept in a place where it’s convenient to make changes, automated and easy to integrate with different systems, and accessible to anyone. Many on-call platforms also offer scheduling tools to make this process easier and more robust.</p><h4><strong>Defining Escalation and Response Policies</strong><br></h4><p>The next set of policies you need to define is to decide when your on-call teams are actually contacted and how they respond. To combat alert fatigue, you’ll want to be judicious about when your teams are notified, but also ensure that critical incidents are not overlooked.<br></p><p>You should have a system to <a href="https://www.blameless.com/blog/incident-classification">classify incidents</a>, sorting them based on severity and affected area into established classifications. These classifications will determine who is alerted and what response is necessary. This response should also include timelines for when incidents of severity need to be resolved before you violate <a href="https://www.blameless.com/blog/service-level-objectives-slos-lessons-learned">SLOs or SLAs</a>.<br></p><p>You can determine severity by looking at the <a href="https://www.blameless.com/resources/webinar-modern-metrics">business impact</a> of an incident — issues preventing customers from using services or violating SLAs require a much faster and larger response than a small component loading slightly slower than usual.&nbsp;<br></p><p>You’ll also need to prepare a defined response to each category of incidents. Engineers should be equipped with tools like <a href="https://www.blameless.com/blog/runbook-automation-best-practices">runbooks</a> to begin tackling an incident as soon as they’re alerted. These runbooks can also include checks for triggering further escalation. Make sure your on-call engineers are familiar with these runbooks, and confident about executing them when the time comes. Schedule regular review sessions to update runbooks based on incident retrospectives.</p><h4><strong>Cultivating On-Call Culture</strong><br></h4><p>Between being called out of bed in the wee hours, having to handle incidents with fewer teammates and resources than normal, and facing extreme pressure to restore service as business reputation is on the line, on-call can be an extremely stressful experience. Being overwhelmed by on-call responsibilities, believing that on-call duties are assigned unfairly, or generally feeling under-appreciated can quickly destroy engineers’ morale and accelerate burnout.&nbsp;<br></p><p>Combat these challenges by cultivating an empathetic on-call culture that puts people first.<br></p><p>Involve engineers in setting schedules and other policies. Hear out their experiences, celebrating their successes and addressing their struggles. Make sure you hear these concerns blamelessly; instead of attributing setbacks or miscommunications to individuals, look at the systems behind them. Protect against a ‘hero’ culture, and embrace sustainable on-call through eliminating single points of failure, and embracing smaller and more frequent changes, distributed rotations, and continuous learning.<br></p><blockquote>Reframe incidents from failures and setbacks to investments in future reliability — every incident, when properly addressed, makes the response to each future incident better. Likewise, each on-call shift is an investment in making future on-call shifts better. When there’s challenges in load balancing, having effective responses prepared, or proper escalation, embrace them as opportunities to refine and grow.<br></blockquote><p>For more tips on how to implement empathetic and effective on-call practices, check out our top 5 on-call practices <a href="https://www.blameless.com/blog/our-top-5-on-call-practices">here</a>.</p><h3>On-call Software</h3><p>Implementing on-call practices is a complicated process, but fortunately there are great paid as well as free on-call tools and platforms to help. The most popular tools include PagerDuty, OpsGenie, VictorOps, Cabot, and LinkedIn On-Call (open source)<br></p><p>When selecting an on-call tool, some important requirements to consider include:</p><ul role="list"><li>Alerting through phone, SMS, Hipchat, or email</li><li>Breadth of integrations across the tech stack, from cloud monitoring to source control</li><li>Alert grouping, filtering, and de-duplication</li><li>Team-based management</li><li>Simple visualization of teams’ statuses across the calendar</li><li>Rock-solid reliability</li></ul><p>On-call is an essential component of a reliable system. To take your on-call and reliability practice to the next level, you’ll need to codify context into guardrails and automation, minimize toil, and foster a culture that is inclined toward curiosity instead of blame. Blameless can help you get more out of your on-call and broader reliability efforts&nbsp; by integrating valuable data from SLOs, incident checklists, , postmortems, follow-up action items, and much more. To find out how to empower your SRE solution with Blameless, join us for a <a href="https://www.blameless.com/schedule-demo">demo</a>!</p></div></div>]]>
            </description>
            <link>https://www.blameless.com/blog/how-to-improve-on-call-with-better-practices-and-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043949</guid>
            <pubDate>Mon, 03 Aug 2020 21:58:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PP-YOLO Surpasses YOLOv4 – State-of-the-art object detection techniques]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24043812">thread link</a>) | @rocauc
<br/>
August 3, 2020 | https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/ | <a href="https://web.archive.org/web/*/https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              <div><p>Baidu publishes PP-YOLO and pushes the state of the art in object detection research by building on top of YOLOv3, the PaddlePaddle deep learning framework, and cutting edge computer vision research.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-1.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-1.png 600w, https://blog.roboflow.ai/content/images/2020/08/image-1.png 692w"><figcaption><a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO</a> evaluation shows faster inference (x-axis) with better accuracy (y-axis)</figcaption></figure><p>PP-YOLO evaluation metrics show improved performance over <a href="https://blog.roboflow.ai/a-thorough-breakdown-of-yolov4/">YOLOv4</a>, the incumbent state of the art object detection model. Yet, the Baidu authors write:</p><figure><pre><code>This paper is not intended to introduce a novel object detecotor. 
It is more like a recipe, which tell you how to build a better detector step by step.</code></pre><figcaption>Mysterious introduction in the <a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO paper</a></figcaption></figure><p>Let's unpack that.</p><h2 id="yolo-development-history">YOLO Development History</h2><p>YOLO was originally authored by Joseph Redmon to detect objects. Object detection is a computer vision technique that localizes and tags objects by drawing a bounding box around them and identifying the class label that a given box belongs too. Unlike massive NLP transformers, YOLO is designed to be tiny, enabling realtime inference speeds for deployment on device. &nbsp;</p><p>YOLO-9000 was the second "YOLOv2" object detector published by Joseph Redmon, improving the detector and emphasizing the detectors ability to generalize to any object in the world.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-2.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-2.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-2.png 1000w, https://blog.roboflow.ai/content/images/size/w1600/2020/08/image-2.png 1600w, https://blog.roboflow.ai/content/images/2020/08/image-2.png 1810w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://github.com/PaddlePaddle/PaddleDetection/blob/release/0.4/docs/tutorials/Custom_DataSet.md">PP-YOLO</a> is being trained to identify different fruit flies in this photo.</figcaption></figure><p>YOLOv3 made further improvements to the detection network and began to mainstream the object detection process. We began to publish tutorials on <a href="https://blog.roboflow.ai/releasing-a-new-yolov3-implementation/">how to train YOLOv3 in PyTorch</a>, <a href="https://blog.roboflow.ai/training-a-yolov3-object-detection-model-with-a-custom-dataset/">how to train YOLOv3 in Keras</a>, and <a href="https://blog.roboflow.ai/yolov3-versus-efficientdet-for-state-of-the-art-object-detection/">compared YOLOv3 performance to EfficientDet </a>(another state of the art detector).</p><p>Then Joseph Redmon stepped out of the object detection game due to ethical concerns. </p><p>Naturally, the open source community picked up the baton and continues to move YOLO technology forward. </p><p>YOLOv4 was published recently this spring by Alexey AB in his for of the YOLO Darknet repository. YOLOv4 was primarily an ensemble of other known computer vision technologies, combined and validated through the research process. See here for a <a href="https://blog.roboflow.ai/a-thorough-breakdown-of-yolov4/">deep dive on YOLOv4</a>. The YOLOv4 paper reads similarly to the PP-YOLO paper, as we will see below. We put together some great training tutorials on <a href="https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/">how to train YOLOv4 in Darknet</a>.</p><p>Then, just a few months ago <a href="https://blog.roboflow.ai/yolov5-is-here/">YOLOv5 was released</a>. YOLOv5 took the Darknet (C based) training environment and converted the network to PyTorch. Improved training techniques pushed performance of the model even further and created a great, easy to use, out of the box object detection model. Ever since, we have been encouraging developers using Roboflow to direct their attention to YOLOv5 for the formation of their custom object detectors via this <a href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/">YOLOv5 training tutorial</a>.</p><p>Enter PP-YOLO.</p><h2 id="what-does-pp-stand-for">What Does PP Stand For?</h2><p>PP is short for PaddlePaddle, a deep learning framework written by Baidu. </p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-9.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-9.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-9.png 1000w, https://blog.roboflow.ai/content/images/size/w1600/2020/08/image-9.png 1600w, https://blog.roboflow.ai/content/images/2020/08/image-9.png 1634w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.paddlepaddle.org.cn/">PaddlePaddle</a> distributions provided on their website.</figcaption></figure><p>If PaddlePaddle is new to you, then we are in the same boat. Primarily written in Python, PaddlePaddle seems akin to PyTorch and TensorFlow. A deep dive into the PaddlePaddle framework is intriguing, but beyond the scope of this article. </p><h2 id="pp-yolo-contributions">PP-YOLO Contributions</h2><p>The PP-YOLO paper reads much like the YOLOv4 paper in that it is a compilation of techniques that are known to work in computer vision. The novel contribution is to prove that the ensemble of these technologies improves performance, and to provide an ablation study of how much each step helps the model along the way.</p><p>Before we dive into the contributions of PP-YOLO, it will be useful to review the YOLO detector architecture.</p><h3 id="anatomy-of-the-yolo-detector">Anatomy of the YOLO Detector</h3><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image.png 1376w" sizes="(min-width: 720px) 720px"><figcaption>A graphical depiction of the <a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO</a> object detection network</figcaption></figure><p>The YOLO detector is broken into three main pieces.</p><p><strong>YOLO Backbone</strong> - The YOLO backbone is a convolutional neural network that pools image pixels to form features at different granularities. The Backbone is typically pretrained on a classification dataset, typically ImageNet.</p><p><strong>YOLO Neck - </strong>The YOLO neck (FPN is chosen above) combines and mixes the ConvNet layer representations before passing on to the prediction head.</p><p><strong>YOLO Head</strong> - This is the part of the network that makes the bounding box and class prediction. It is guided by the three YOLO loss functions for class, box, and objectness. </p><h2 id="now-let-s-dive-into-the-pp-yolo-contributions-">Now let's dive into the PP YOLO Contributions.</h2><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-10.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-10.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-10.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-10.png 1136w" sizes="(min-width: 720px) 720px"><figcaption>Marginal mAP accuracy performance increase from each technique in PP-YOLO</figcaption></figure><h3 id="replace-backbone">Replace Backbone</h3><p>The first PP YOLO technique is to replace the YOLOv3 Darknet53 backbone with the Resnet50-vd-dcn ConvNet backbone. Resnet is a more popular backbone, more frameworks are optimized for its execution, and it has fewer parameters than Darknet53. Seeing a mAP improvement by swapping this backbone is a huge win for PP YOLO. </p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-12.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-12.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-12.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-12.png 1422w" sizes="(min-width: 720px) 720px"><figcaption>Graphical depiction in <a href="https://arxiv.org/pdf/1603.05027.pdf">ResNet</a></figcaption></figure><h3 id="ema-of-model-parameters">EMA of Model Parameters</h3><p>PP YOLO tracks the Exponential Moving Average of network parameters to maintain a shadow of the models weights for prediction time. This has been shown to improve inference accuracy.</p><h3 id="larger-batch-size">Larger Batch Size</h3><p>PP-YOLO bumps the batch size up from 64 to 192. Of course, this is hard to implement if you have GPU memory constraints.</p><h3 id="dropblock-regularization">DropBlock Regularization</h3><p>PP YOLO implements DropBlock regularization in the FPN neck (in the past, this has usually occurred in the backbone). DropBlock randomly removes a block of the training features at a given step in the network to teach the model to not rely on key features for detection.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-16.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-16.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-16.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-16.png 1050w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://arxiv.org/pdf/1810.12890.pdf">Drop Block</a> regularization technique - features are hidden in blocks (c) not randomly (b)</figcaption></figure><h3 id="iou-loss">IoU Loss</h3><p>The YOLO loss function does not translate well to the <a href="https://blog.roboflow.ai/what-is-mean-average-precision-object-detection/">mAP metric</a>, which uses the Intersection over Union heavily in its calculation. Therefore, it is useful to edit the training loss function with this end prediction in mind. This edit was also present in YOLOv4.</p><h3 id="iou-aware">IoU Aware</h3><p>The PP-YOLO network adds a prediction branch to predict the model's estimated IOU with a given object. Including this IoU awareness when making the decision to predict an object or not improves performance.</p><h3 id="grid-sensitivity">Grid Sensitivity</h3><p>The old YOLO models do not do a good job of making predictions right around the boundaries of anchor box regions. It is useful to define box coordinates slightly differently to avoid this problem. This technique is also present in YOLOv4.</p><h3 id="matrix-nms">Matrix NMS </h3><p>Non-Maximum Suppression is a technique to remove over proposals of candidate objects for classification. Matrix NMS is a technique to sort through these candidate predictions in parallel, speeding up the calculation. </p><h3 id="coordconv">CoordConv</h3><p>CoordConv was motivated by the problems ConvNets were having with simply mapping (x,y) coordinates to a one-hot pixel space. The CoordConv solution gives the convolution network access to its own input coordinates. CoordConv interventions are marked with yellow diamonds above. More details are available in <a href="https://arxiv.org/pdf/1807.03247.pdf">the CordConv paper</a>.</p><h3 id="spp">SPP</h3><p>Spatial Pyramid Pooling is an extra block after the backbone layer to mix and pool spatial features. Also implemented in YOLOv4 and YOLOv5.</p><h3 id="better-pretrained-backbone">Better Pretrained Backbone</h3><p>The PP YOLO authors distilled down a larger ResNet model to serve as the backbone. A better pretrained model shows to improve downstream transfer learning as well. </p><h2 id="is-pp-yolo-state-of-the-art"><br>Is PP-YOLO State of the Art?</h2><p>PP-YOLO outperforms the results <a href="https://arxiv.org/pdf/2004.10934.pdf">YOLOv4 published</a> on April 23, 2020.</p><p>In fairness, the authors note this may be the wrong question to be asking. The authors' intent appears to not simply "introduce a new novel detector," rather to show the process of carefully tuning an object detector to maximize performance. Quoting the paper's introduction here:</p><blockquote>The focus of this paper is how to stack some effective tricks that hardly affect efficiency to get better performance... This paper is not intended to introduce a novel object detector. It is more like a recipe, which tell you how to build a better detector step by step. We have found some tricks that are effective for the YOLOv3 detector, which can save developers’ time of trial and error. <strong>The final PP-YOLO model improves the mAP on COCO from 43.5% to 45.2% at a speed faster than YOLOv4</strong></blockquote><p><em>(emphasis ours)</em></p><p>The PP-YOLO contributions reference above took the YOLOv3 model from 38.9 to 44.6 mAP on the COCO object detection task and increased inference FPS from 58 to 73. These metrics are shown in the paper to beat the currently published results for YOLOv4 and EfficientDet. </p><p>In benchmarking PP-YOLO against <a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5</a>, it appears <a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5</a> still has the fastest inference time-to-accuracy performance (AP vs FPS) tradeoff on a V100. However, a YOLOv5 paper still remains to be released. Furthermore, it has been shown that training the YOLOv4 architecture on the YOLOv5 Ultralytics repository outperforms YOLOv5 and, transitively, YOLOv4 trained using YOLOv5 contributions would outperform the PP-YOLO results posted here. These results are still to be formally published but can be traced to <a href="https://github.com/ultralytics/yolov5/issues/6">this GitHub discussion</a>.</p><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-14.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-14.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-14.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-14.png 1354w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://arxiv.org/pdf/2007.12099.pdf">PP-YOLO evaluation</a> on COCO dataset on V100 GPU (note AP_50 column)</figcaption></figure><figure><img src="https://blog.roboflow.ai/content/images/2020/08/image-15.png" alt="" srcset="https://blog.roboflow.ai/content/images/size/w600/2020/08/image-15.png 600w, https://blog.roboflow.ai/content/images/size/w1000/2020/08/image-15.png 1000w, https://blog.roboflow.ai/content/images/2020/08/image-15.png 1304w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://blog.roboflow.ai/yolov5-improvements-and-evaluation/">YOLOv5 evaluation</a> on COCO dataset on V100 GPU (note AP_50 column)</figcaption></figure><p>It is worth noting that many of the techniques (such as architecture search and data augmentation) that were used in YOLOv4 were not used in PP YOLO. This means that there is still room for the state of the art in object detection to grow as more of these techniques are combined and integrated together. </p><p>Needless to say, is an exciting time to be implementing computer vision technologies.</p><h2 id="should-i-switch-from-yolov4-or-yolov5-to-pp-yolo">Should I Switch from YOLOv4 or YOLOv5 to PP-YOLO?</h2><p>The PP-YOLO model shows the promise of state of the art object detection, but the improvements are incremental over other object detectors and it is written in a new framework. At this stage, the best thing to do is to develop your own empirical result by training PP-YOLO on your own dataset. (To be notified when you can easily use PP-YOLO on your dataset, <a href="https://roboflow.us5.list-manage.com/subscribe?u=26126ade12b1dd890dbd7b07e&amp;id=3e926cf19a">subscribe to our newsletter</a>.)</p><p>In the meantime, I recommend checking out the following YOLO tutorials to get your object detector off the ground:</p><ul><li><a href="https://blog.roboflow.ai/training-yolov4-on-a-custom-dataset/">How to Train YOLOv4 in Darknet</a></li><li><a href="https://blog.roboflow.ai/how-to-train-yolov5-on-a-custom-dataset/">How to Train YOLOv5 in PyTorch</a></li></ul><p>As always - happy training! </p></div>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://blog.roboflow.ai/pp-yolo-beats-yolov4-object-detection/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043812</guid>
            <pubDate>Mon, 03 Aug 2020 21:43:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parts of vs Code Are Proprietary]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24043448">thread link</a>) | @jerodsanto
<br/>
August 3, 2020 | https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<small>2020-08-03</small><!-- RSS:2020-08-03T07:25:00Z -->
<p>I've been very surprised and delighted over a number of years now by Microsoft's strong efforts in open
    source. I understand the skeptics, I was on Slashdot when they tried to sue Linux out of existence and I think only
    time will tell. I figure MS contributing is better than them hunting Linux distributions for sport. So I was mostly
    onboard for Microsofts efforts and I've especially found Visual Studio Code useful.</p>
<p>To settle a few things. When I tweeted on this subject I only got the response that I should use vim. Thanks. Great.
    I can and do on use vim. That misses a number of points. Visual Studio Code is an immensely popular editor and
    likely the most common recommendations to new developers. The primary reason I've used Visual Studio Code is
    that it has an incredibly compelling solution for remote pairing in the form of LiveShare. I've used that for a
    while with great success mentoring, coaching and generally working with other developers of varying experience and
    editor preferences. Most programmers can handle a "normal" editor like VS Code while something like Emacs
    or Vim depends a lot more on what they've learned.</p>
<p>I also ended up enjoying the Remote series of extensions for developing effectively inside remote servers or local
    containers.</p>
<h2>These things are proprietary</h2>
<p>At some point I read a piece of license that said that LiveShare could only be used with the Visual Studio family of
    products. "Huh, that sounds weird, VS Code is open source right?"</p>
<p>Sure enough. VS Code is fully MIT. The binary distribution has a separate license to allow telemetry and protect
    Microsoft trademarks and stuff. Nothing particularly weird, I can't really get worked up about telemetry, I know
    some can. But the extensions.. These extensions are in my book core differentiators that makes VS Code compelling.
    For me it is definitely part of what pushes it beyond the much leaner Sublime (paid, closed source) I was using
    before.</p>
<p>These extensions have a license limiting them and their online service parts to only be used with the Visual Studio
    family of products. This is the <a href="https://microsoftdocs.github.io/live-share/license/eula.html" title="License for LiveShare">license for LiveShare</a> and this is the <a href="https://code.visualstudio.com/preview-license" title="License for Remote">license for Remote</a>.</p>
<p>For me LiveShare is the most important thing. Google Docs style collaborative code editing, terminal sharing, port
    sharing and a bunch more features. I know Atom had an extension like this, I haven't checked the licensing there
    or tried it recently.</p>
<p>Remote is a very strong extension as well for anyone working on a server over SSH or in a container. It helps by
    installing extensions on the destination to allow language servers and such. I've seen it do terrible things to
    servers sometimes but it is very useful and generally works well.</p>
<p>It makes me uneasy to accept VS Code as an "open" project in any wider meaning of the word when compelling
    features are legally locked to only work inside the family of Visual Studio products. It makes me less certain that
    this isn't the Extend in Embrace, Extend, Extinguish. It also frustrates me that this prevents someone from
    building a compatible plugin for VIM or any other editor. This would be much more powerful if it could be in all the
    IntelliJs as well.</p>
<p>You'll find a repo for <a href="https://github.com/MicrosoftDocs/live-share" title="LiveShare on GitHub">LiveShare on GitHub</a> but it is only for documentation and issue tracking. There
    is no code. Same for <a href="https://github.com/microsoft/vscode-remote-release" title="Remote on GitHub">Remote</a>.</p>
<h2>The entire marketplace is proprietary</h2>
<p>Some additional salt in this particular wound is that the use of the Marketplace of VS Code extensions is also
    proprietarily licensed. So all these open source developers are shoving their extensions into a competitive
    advantage for one of the world's largest tech firms. And they disallow other uses of the marketplace. Even if
    the letter of open source is followed there is none of the openness, collaborative or community essence that I think
    exemplifies open source and free software projects.</p>
<p>What does this mean in practice? I guess it protects from the competition. Such as the <a href="https://github.com/VSCodium/vscodium" title="VS Codium">VS Codium</a> project which provides VS Code
    binaries without the proprietary parts. But also, as a consequence of this, without the Marketplace of extensions.
    There is an open source alternative called <a href="https://open-vsx.org/" title="Open VSX">Open VSX</a>, but since
    it isn't the canonical one it is missing a bunch of extensions and the big Liveshare and Remote ones are still
    not allowed.</p>
<p>This also blocks the <a href="https://github.com/cdr/code-server" title="code-server">code-server editor</a> that
    allows running VS Code in the browser from using it which otherwise would have been perfect for me to do development
    on an iPad Pro. I can still use that but a lot of packages are not in Open VSX.</p>
<h2>What about lock-in?</h2>
<p>Visual Studio Code is marketed with LiveShare and Remote as powerful extensions. VS Code is also marketed as open
    source. It is easy to use the editor, install the extensions and be under the impression that you are using an open
    source software suite where Microsoft simply hosts the peering service for identifying and connecting you and your
    collaborator.</p>
<p>But the peering service is not the only closed part. The extensions are not open source projects as far as I can find
    and they are licensed during distribution in a way that disallows using them with anything but Visual Studio
    products.</p>
<p>This leaves me with a sour taste in my mouth. I wasn't sold on having an Electron-based editor to begin with but
    VS Code was substantially leaner than Atom so I've been mostly accepting it.</p>
<p>If you have good suggestions for strong collaborative development tools that are open source, please let me know at
    <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. If you want to follow my writing the RSS feed is
    right below. If you want more of my writing I have a tracking-free newsletter that I'd love for you to sign up for,
    also below.</p></div></div>]]>
            </description>
            <link>https://underjord.io/the-best-parts-of-visual-studio-code-are-proprietary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043448</guid>
            <pubDate>Mon, 03 Aug 2020 21:09:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your calendar should be a whitelist, not a blacklist]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24043175">thread link</a>) | @mcrittenden
<br/>
August 3, 2020 | https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/ | <a href="https://web.archive.org/web/*/https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-549">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Does your company have a culture of letting everyone see each other’s calendars? Do people often schedule meetings whenever there are openings, without asking?</p>



<p>If so, your calendar is a blocklist. The only time that isn’t available for someone to steal is time that’s already spoken for. This is a problem. A time slot that isn’t currently booked shouldn’t be free real estate. That’s my TIME! You can’t just take it without asking.</p>



<p>Instead, your calendars should be an allowlist. You should say “if you want to talk to me, this is when you can” instead of “this is when you CAN’T.” You shouldn’t have to defend our time like it’s gold and your coworkers are pirates. You should just assume that it’s yours to spend how you see fit.</p>



<p>Some people block time off to try to protect their calendars. They create big “GTD” blocks on their calendar and hope that nobody books meetings on top of them. I’ve even heard of people creating fake or vague meeting titles in hopes that others will assume there’s a real meeting at that time. This is a crappy workaround, and it isn’t enough. </p>



<p>The solution should be office hours. You should be able to say say “I’m free for meetings from 2-5pm on Tuesdays and Thursdays, and if you want to talk to me then that’s when you can.” In most companies, doing that would make you an annoyance. Those companies don’t respect Deep Work. </p>



<p>Scheduling meetings should be a little bit painful. You should have to really want it. You should be forced to question yourself. <em>Is this actually worth me going to the trouble of figuring out how to schedule this meeting? Or could it instead be an asynchronous discussion? </em>Office hours and calendars-as-allowlists have this added benefit.</p>



<p>Is your calendar an allowlist or a blocklist?</p>

		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://critter.blog/2020/08/03/your-calendar-should-be-a-whitelist-not-a-blacklist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24043175</guid>
            <pubDate>Mon, 03 Aug 2020 20:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Tencent PCG Uses Apache Kafka to Handle 10T+ Messages per Day]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24042525">thread link</a>) | @rmoff
<br/>
August 3, 2020 | https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/ | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>As one of the world’s biggest internet-based platform companies, Tencent uses technology to enrich the lives of users and assist the digital upgrade of enterprises. An example product is the popular WeChat application, which has over one billion active users worldwide. The Platform and Content Group (PCG) is responsible for integrating Tencent’s internet, social, and content platforms. PCG promotes the cross-platform and multi-modal development of IP, with the overall goal of creating more diversified premium digital content experiences. Since its inception, many major products—from the well-known QQ, QZone, video, App Store, news, and browser, to relatively new members of the ecosystem such as live broadcast, anime, and movies—have been evolving on top of consolidated infrastructure and a set of foundational technology components.</p>
<h2><a id="kafka-at-tencent-png"></a>Apache Kafka<sup>®</sup> at Tencent PCG</h2>
<p>At our center stands the real-time messaging system that connects data and computing. We have proudly built many essential data pipelines and messaging queues around Apache Kafka. Our application of Kafka is similar to other organizations: We build pipelines for cross-region log ingestion, machine learning platforms, and asynchronous communication among microservices. The unique challenges come from stretching our architecture along multiple dimensions, namely scalability, customization, and SLA. Here are some of the notable requirements:</p>
<ul>
<li><strong>Workload.</strong> It takes close and continuous observation to fully grasp the dynamics of data in complex apps. In a highly seasonal and eventful environment of consumer internet with over a billion monthly active users, product promotion and large-scale experimentations often cause volume to burst up 20x from one day to another. At the peak, our pipeline needs to transfer 4 million messages per second (or 64 gigabytes/second) for a single product. Our ops team, therefore, is challenged with managing and optimizing clusters with more than a thousand physical nodes in total.</li>
<li><strong>Low latency and high SLA.</strong> As the organization moves quickly toward leveraging real-time analytics for driving business decisions, the requirements of data accuracy and timeliness become more rigid than before. Imagine when a video-consuming event is fed to the recommendation algorithm or when discovering hot trends that guide the incentivisation of content supply—it is desirable that the data can be used within a few seconds since its emission and with an end-to-end loss rate as low as 0.01%.</li>
<li><strong>Flexibility.</strong> Nowadays real-time data processing architectures are componentized and configurable. Consequently, the messaging system needs to handle frequent changes in the number of consumers, access pattern, and topic distribution without impacting performance. We cannot simply optimize the system for a static topology as a traditional ingestion pipeline.</li>
</ul>
<p>Ideally, we need a multi-tenant, gigantic pub/sub system to satisfy all these requirements. At peak time, it should reliably support data transfer at hundreds of gigabits per second. It should be provisioned almost instantly without disrupting existing workload; it also needs to tolerate single-node and cluster failure. Considering interface concerns, we want it to be compatible with the Kafka SDK as much as possible. After exploring the limitations of a single Kafka cluster, we’ve moved forward with a series of developments.</p>
<h2 id="federated-kafka-design"><a id="federated-kafka-design"></a>Federated Kafka design</h2>
<p>We chose to develop in the Kafka ecosystem for its maturity, rich set of clients and connectors, as well as superb performance among alternatives. On the other hand, there are a few gaps in using Apache Kafka to meet the requirements above. For instance, more than expected, we found during heavy usage that multiple disk failures caused insufficient replica or even cluster-level reliability problems. Moreover, expanding the capacity of a cluster (i.e., adding brokers) requires significant data rebalancing, often imposing hours of operational latency. Without fully automated capacity management, this greatly limits how we can support a large business.</p>
<p>Given that we decided to focus our initial enhancement on scalability and failure tolerance, we started off building a proxy layer that federates multiple Kafka clusters and provides compatible interfaces to both providers and consumers. The proxy layer presents logical topics to Kafka clients and internally maps them to distinct physical topics in each Kafka cluster. In the figure below, a logical topic with eight partitions (<code>P0–P7</code>) is distributed to two physical clusters each with four partitions (<code>P0–P3</code>).</p>
<p><img src="https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic.png" alt="P0-P7 | P0-P3" width="1999" height="522" srcset="https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic.png 1999w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-300x78.png 300w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-1024x267.png 1024w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-768x201.png 768w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-1536x401.png 1536w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-350x91.png 350w, https://cdn.confluent.io/wp-content/uploads/kafka-logical-topic-600x157.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"></p>
<p>The extra layer of abstraction of logical topics allows us to achieve the following, desirable behavior. First, we can expand the capacity of the data pipeline with little (re)synchronization overhead. In case two clusters at their maximum size cannot handle the predicted peak volume, we can easily deploy two additional clusters without shuffling any existing data. Second, fault tolerance is easier to manage with smaller clusters, as we can provision extra capacity at fine granularity and redirect traffic at a low cost. Lastly, in the (not-so-rare) event of physical cluster migration, the transparent proxy eliminates the need for any code and configuration change on the application side. We would only need to set the old clusters in read-only mode before it is completely drained, while associating the proxy with the new clusters. Such maintenance is not visible from the perspective of logic topics.</p>
<h2 id="key-components-and-workflows"><a id="key-components-and-workflows"></a>Key components and workflows</h2>
<p>In this section, we get into more details of the new components we built and how they interact in essential scenarios, as shown in the figure below. Two proxy services, one for the producer (<code>pproxy</code>) and another for the consumer (<code>cproxy</code>), implement the core protocols of the Kafka broker. They are also responsible for mapping logical topics to their physical incarnation. The application uses the same Kafka SDK to connect directly to the proxy, which acts as a broker.</p>
<p>In order to address the set of proxy brokers, we built a lightweight name service that maintains this relationship between client ID and the collection of proxy servers. The SDK will request the list of proxy brokers using client ID once at the beginning of the communication. Internally, the most complicated and bulky part of our implementation involves managing the metadata of the federated cluster, including both the state of the topics as well as the lifecycle of the proxy nodes. We extract the logic of the Kafka controller node (such as topic metadata) into a separate service, which is also called “the controller,” but it is different from Kafka’s own controller functionality. This service is responsible for collecting the metadata of physical clusters, composing the partition information logical topics, and then publishing it to the proxy brokers.</p>
<p><img src="https://cdn.confluent.io/wp-content/uploads/kafka-name-service.png" alt="Name service" width="1999" height="639" srcset="https://cdn.confluent.io/wp-content/uploads/kafka-name-service.png 1999w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-300x96.png 300w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-1024x327.png 1024w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-768x245.png 768w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-1536x491.png 1536w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-350x112.png 350w, https://cdn.confluent.io/wp-content/uploads/kafka-name-service-600x192.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"></p>
<p>We see some examples of interactions among these components and the Kafka clusters underneath during the most common operations:</p>
<ul>
<li><strong>Logical topic metadata retrieval</strong><br>
<img src="https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval.png" alt="Logical topic metadata retrieval" width="1999" height="635" srcset="https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval.png 1999w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-300x95.png 300w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-1024x325.png 1024w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-768x244.png 768w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-1536x488.png 1536w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-350x111.png 350w, https://cdn.confluent.io/wp-content/uploads/logical-topic-metadata-retrieval-600x191.png 600w" sizes="(max-width: 1999px) 100vw, 1999px"><br>
1. Controller reads the mapping between logical topic and physical topic from the config database.<br>
2. Controller scans metadata of all physical topics from each Kafka cluster.<br>
3. Controller finds the list of available <code>pproxy</code> from heartbeat message.<br>
4. Controller composes the metadata for the logical topics.<br>
5. Controller pushes both the topic mapping and topic metadata to proxy brokers.<br>
6. The metadata is sent to the Kafka SDK.</li>
</ul>

<h2 id="federated-kafka-in-practice"><a id="federated-kafka-in-practice"></a>Federated Kafka in practice</h2>
<p>Over the past year, we have gradually onboard many products in Tencent PCG to use the federated Kafka solution. Alongside the cluster, we have also been developing better monitoring and automated management tools. Our design principles have been quickly validated by many critical business use cases such as real-time analytics, feature engineering, and more. Up to now, we have deployed a few hundreds of clusters of various sizes, which collectively handle more than 10 trillion messages every day. The following table summarizes our typical setup and operational benchmarks.</p>
<table>
<tbody>
<tr>
<td>Average time to initialize a federated cluster</td>
<td>10 minutes</td>
</tr>
<tr>
<td>Average time to scaling up a federated cluster<br>
(add one physical cluster)</td>
<td>2 minutes</td>
</tr>
<tr>
<td>Metadata refresh latency</td>
<td>~1 second</td>
</tr>
<tr>
<td>Maximum physical clusters per logical cluster</td>
<td>60</td>
</tr>
<tr>
<td>Brokers per physical cluster</td>
<td>10</td>
</tr>
<tr>
<td>Total number of brokers provisioned</td>
<td>~500</td>
</tr>
<tr>
<td>Max cluster bandwidth (CPU ~40%)</td>
<td>240 Gb/s</td>
</tr>
<tr>
<td>Proxy overhead</td>
<td>Same as Kafka broker</td>
</tr>
</tbody>
</table>
<p>There are two notable limitations of the first design composed of cluster federation with a proxy layer. First, the distribution of logical partitions is not transparent to clients who use a hash key to specify the partition when producing a message. Consequently, when we add a new cluster, messages with identical keys might be delivered to different partitions and hence get out of order. This did not turn out to be a blocker for our current use cases for two reasons. First, we surveyed the product teams and found that they only use keyed messages occasionally. Furthermore, when they face the trade-off between application-level fault tolerance and scalability, they typically prefer the latter and sometimes settle with a mechanism to briefly halt production when cluster membership is updated.</p>
<p>A more fundamental limitation is that we have to frequently evolve the interface of the proxy broker as more functionalities need to be exposed and as native Kafka evolves. This leads to unnecessary code duplication and makes the whole system harder to manage. In the future, we will explore implementing similar semantics inside Kafka, as described in the next section.</p>
<h2 id="next-steps"><a id="next-steps"></a>Next steps</h2>
<p>As we explained above, Tencent is one of the largest Kafka users in the world, processing trillions of messages every day. This also means that to power our many use cases, we have successfully pushed some of Kafka’s boundaries. We are aware of the ongoing development and proposals within the Kafka community, and we further find that some of our ideas, such as abstracting out the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/">https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/tencent-kafka-process-10-trillion-messages-per-day/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24042525</guid>
            <pubDate>Mon, 03 Aug 2020 19:52:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V OS using Rust: Graphics]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24041869">thread link</a>) | @azhenley
<br/>
August 3, 2020 | https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM–with what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, “hey, here’s the RAM that we’re going to use to store pixel information.”</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn’t strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don’t want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won’t rehash the general virtio protocol. However, the device-specific structures are a bit different, so we’ll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we’re going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you’re a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren’t pure white. Instead, you can see bits of red, blue, and green. That’s because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920×1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640×480, which only requires \(640\times 480\times 4=1,228,800\) bytes–a bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I’ll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 “GPU Device”. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another–4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I’ll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we’re really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	…</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/07/24/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041869</guid>
            <pubDate>Mon, 03 Aug 2020 18:58:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Technical Introduction to Reinforcement Learning]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24041852">thread link</a>) | @idavidrein
<br/>
August 3, 2020 | https://www.notion.so/idavidrein/A-Technical-Introduction-to-Reinforcement-Learning-90e4b5a21c9344c38b44890f4c8622a9 | <a href="https://web.archive.org/web/*/https://www.notion.so/idavidrein/A-Technical-Introduction-to-Reinforcement-Learning-90e4b5a21c9344c38b44890f4c8622a9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/idavidrein/A-Technical-Introduction-to-Reinforcement-Learning-90e4b5a21c9344c38b44890f4c8622a9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041852</guid>
            <pubDate>Mon, 03 Aug 2020 18:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A gentle intro to assembly with Rust]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24041675">thread link</a>) | @lfn3
<br/>
August 3, 2020 | https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/ | <a href="https://web.archive.org/web/*/https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<div>
  
  <p><span>Aug 3 2020</span></p><p>One of the things I’ve wanted to do for a while is really dig into
assembly and get into the weeds of how programs actually run.
A rework of the <code>asm</code> macro has <a href="https://blog.rust-lang.org/inside-rust/2020/06/08/new-inline-asm.html">recently landed</a> in nightly rust
so it seemed like a good time.</p>

<p>And compared to some other ways I’ve tried to approach this there’s a lot less
setup we need to do if we just use the <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018">rust playground</a> to
do all the heavy lifting.</p>

<p>My process for figuring things out has been pretty simple.
I write a tiny bit of rust code, look at the assembly output
and try to figure out what’s going on (with lots of googling).
I’m going to walk you through what I did, and what I figured
out.</p>

<p>Let’s start with the simplest possible thing I can think of:</p>

<pre><code>fn main() {
    1 + 2;
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=9500bb2bc3f638a4dd89e81fecafac0e">playground link</a></p>

<p>You can get the assembly output for this by clicking the three dots next to
<code>run</code> and selecting <code>asm</code> from the dropdown. You will probably also want
to change the flavour (often referred to as syntax elsewhere) of assembly to intel (rather than at&amp;t) <sup id="fnref:1"><a href="#fn:1">1</a></sup>
if it isn’t already, by clicking the toggle under the <code>config</code> menu.</p>

<p>The assembly output from this in debug mode is far more massive than you’d expect -
I get 157 lines. And most of it isn’t our program. The code we’ve written should
be fairly easy to find though, as the compiler helpfully labels all of the functions
with their crate and function names. In this case since we’re in the playground,
the create is implicitly <code>playground</code>, so we can find our code by searching with
<code>ctrl-f</code> for <code>playground::main</code>. Doing this gets me to:</p>

<pre><code>playground::main: # @playground::main
# %bb.0:
    ret
                                        # -- End function
</code></pre>

<p>So even though this is a debug build, evidently there’s still some optimization going on,
since there’s no numbers or anything that looks like it’s adding them together.
All that’s happening here is we’re returning (<code>ret</code>) back to the function that called <code>playground::main</code>.
Everything prefixed with <code>#</code> is a comment, and therefore ignored when we run this code.</p>

<p>The only other point of interest is the label <code>playground::main:</code> - anything suffixed with <code>:</code>
is a label we can jump to with various commands, and indeed if we continue searching for <code>playground::main</code>
we can find a rather indirected call to it in <code>main</code>. Hopefully by the end of this we’ll be understand that!</p>

<h3 id="avoiding-optimizations">Avoiding optimizations</h3>

<p>For now, let’s try and evade whatever’s doing the optimization:</p>

<pre><code>fn add() -&gt; usize {
    1 + 2
}

fn main() {
    add();
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=e06e9c1a6771d850be5e06abc6f70243">playground link</a></p>

<p>Again, searching for <code>playground::main</code> get us to:</p>

<pre><code>playground::add: # @playground::add
# %bb.0:
    mov eax, 3
    ret
                                        # -- End function

playground::main: # @playground::main
# %bb.0:
    push    rax
    call    playground::add
# %bb.1:
    pop rax
    ret
                                        # -- End function
</code></pre>

<p>So we’ve got a bit more progress here. Still some optimization going on, since we don’t see 1 or 2 in the code,
just 3. We can see that being moved (<code>mov</code>) into the <code>eax</code> register in <code>playground::add</code>.
This must be how we’re returning the value back up to <code>main</code>.</p>

<p>And indeed, inside <code>main</code> we can see <code>push rax</code> - saving the value in the register <code>rax</code> to the stack, then a
call to our <code>add</code> function, then we <code>pop rax</code> off the stack. The <code>push call pop</code> sequence is to preserve
whatever values are in the registers used in <code>add</code>. It also just throws away the value we saved in <code>eax</code> in <code>add</code>,
because <code>eax</code> and <code>rax</code> are the same register. The table <a href="https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture#General-Purpose_Registers_(GPR)_-_16-bit_naming_conventions">here</a>
shows how ‘skinnier’ registers overlap with their ‘wider’ counterparts.</p>

<h3 id="avoiding-optimizations-take-2">Avoiding optimizations, take 2</h3>

<p>So how can we make this actually do some math? Let’s try again:</p>

<pre><code>fn add(i: usize) -&gt; usize {
    1 + i
}

fn main() {
    add(2);
}
</code></pre>

<p><a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=0d821a33f2375ecaf3671c825a415c83">playground link</a></p>

<p>So we’ve got a lot more going on this time:</p>

<pre><code>playground::add: # @playground::add
# %bb.0:
    sub rsp, 24
    mov qword ptr [rsp + 16], rdi
    add rdi, 1
    setb al
    test al, 1
    mov qword ptr [rsp + 8], rdi # 8-byte Spill
    jne .LBB8_2
# %bb.1:
    mov rax, qword ptr [rsp + 8] # 8-byte Reload
    add rsp, 24
    ret

.LBB8_2:
    lea rdi, [rip + str.0]
    lea rdx, [rip + .L__unnamed_2]
    mov rax, qword ptr [rip + core::panicking::panic@GOTPCREL]
    mov esi, 28
    call rax
    ud2
                                        # -- End function

playground::main: # @playground::main
# %bb.0:
    push rax
    mov edi, 2
    call playground::add
# %bb.1:
    pop rax
    ret
                                        # -- End function
</code></pre>

<p>The thing we were actually trying to produce is finally in there!
We can see <code>add rdi, 1</code> in the output, surrounded by a pile of other
stuff. So what is all this other code?</p>

<p>Let’s start from the top of the call stack in <code>main</code>.
First we can see <code>2</code> is stored in the <code>edi</code> register
before we call <code>playground::add</code>, so we know our argument must be in
the <code>edi</code> register. Again, we can see the <code>push</code>, <code>pop</code> on <code>rax</code>, so that
must be the return value.</p>

<h3 id="looking-inside-the-function">Looking inside the function</h3>

<p>Now, looking into <code>playground::add</code> we first see <code>sub rsp, 24</code>. <code>rsp</code> is
the register that holds the stack pointer, so this is growing the stack
(since the stack grows downwards in x86<sup id="fnref:2"><a href="#fn:2">2</a></sup>). Further down we can see
we shrink the stack by the corresponding amount with <code>add rsp, 24</code>.</p>

<p>Then we have <code>mov qword ptr [rsp + 16], rdi</code>. This is copying the
value from <code>rdi</code> onto the stack at <code>rsp + 16</code> - the top of the region we just grew the stack by.
The <code>qword ptr</code> (quadword (i.e. 64bit) pointer) bit is a hint to disambiguate the argument.
Why is that pushed that onto the stack? I <em>think</em> this is just to make it easier to debug,
since we don’t ever access that value again.</p>

<p>In any case, we then proceed on to actually adding 1 to <code>rdi</code>.
The value is stored back in <code>rdi</code>, and importantly for what comes next,
we may set some of the <a href="https://en.wikibooks.org/wiki/X86_Assembly/X86_Architecture#EFLAGS_Register">flags</a>.</p>

<p>Then it gets complicated again - we’ve got <code>setb al</code>. All of the <code>set*</code>
<a href="https://github.com/HJLebbink/asm-dude/wiki/SETcc">instructions</a>
deal with the flag register. The flag register is possibly the most magical
of registers, since it’s manipulated by a bunch of instructions as a side effect.</p>

<p>The last instruction we ran was <code>add</code>, which sets 6 of the the flags:
<a href="https://en.wikipedia.org/wiki/Carry_flag">carry</a>, <a href="https://en.wikipedia.org/wiki/Parity_flag">parity</a>,
<a href="https://en.wikipedia.org/wiki/Adjust_flag">adjust (aka auxiliary carry)</a>, <a href="https://en.wikipedia.org/wiki/Zero_flag">zero</a>,
<a href="https://en.wikipedia.org/wiki/Sign_flag">sign</a> and <a href="https://en.wikipedia.org/wiki/Overflow_flag">overflow</a></p>

<p>In this case we’re checking if the carry bit is set, and then setting the <code>al</code>
register to 1 if that’s the case. What is this actually doing though?
The carry bit gets set to 1 if there is a <code>carry</code> from the two numbers we add,
meaning the resulting number is too big to be stored in the register.
What should we do in that case? Let’s read on to find out.</p>

<p>Then in the next line (<code>test al, 1</code>) we’re checking if the value in <code>al</code> is equal to one.
(<code>test</code> does a a bitwise and operation on the two arguments - like <code>&amp;</code> in rust.)
This sets some more flags, notably the <code>zero</code> flag, which is then read by the following <code>jne</code> instruction.</p>

<p><code>jne</code> stands for jump if not equal (and again there’s a series of
<a href="https://en.wikibooks.org/wiki/X86_Assembly/Control_Flow#Jump_Instructions">other</a>
<code>j*</code> instructions). Since it uses flags, it just takes a single argument: where to jump to.</p>

<p>Looking at where that jumps to gives us a big hint about the intent of the
logic above: <code>core::panicking::panic@GOTPCREL</code> really gives it away.
Basically all of this chunk of assembly from <code>setb</code> to <code>jne</code> is checking if we’ve overflowed
the register and panicking if we have.</p>

<p>The one bit we didn’t discuss is <code>mov qword ptr [rsp + 8], rdi # 8-byte Spill</code>.
As the comment implies this is “spilling” the value from the <code>rdi</code> register
onto the stack, since the code we’re possibly about to jump to might
overwrite that register - immediately after the <code>jne</code> we load the value back off
the stack.</p>

<p>Finally we shuffle the stack pointer back to it’s starting point, and <code>ret</code>
back to the caller. <code>ret</code> uses the last value on the stack (which is pushed by <code>call</code>)
to figure out where to jump back to, so moving the stack pointer back is <em>very</em> important.</p>

<p>So maybe at this point we’ve seen enough to take a stab at replacing the guts of the <code>add</code>
function with the <code>asm!</code> macro. Since we’re interested in performance,
we’ll ignore those pesky overflow checks, and just assume that we’re within the bounds of <code>u64</code>.</p>

<p>The biggest new thing we’ll have to deal with here is specifying the <code>in</code> and <code>out</code> registers.
The <a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#guide-level-explanation">rfc</a>
has a very approachable explaination of these, so I’d recommend reading that.
There’s a skeleton you can start with <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=d511cf5e95ba5cdfbcffaebaf5f72300">here</a>,
if you want to have a go yourself.</p>

<p>The version I’ve cooked up looks like <a href="https://play.rust-lang.org/?version=nightly&amp;mode=debug&amp;edition=2018&amp;gist=669b4155a1d818cc5c73b117b9454d48">this</a>.
This is probably the “fanciest” possible version of this, since we’re using as many features of the asm macro as possible:</p>

<ul>
<li>we’re letting the rust compiler pick the register we use, and then writing it in using the
<a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#inputs-and-outputs"><code>format</code> string behaviour</a> of the <code>asm</code> macro.</li>
<li>we’re also using <a href="https://github.com/Amanieu/rfcs/blob/inline-asm/text/0000-inline-asm.md#late-output-operands"><code>inlateout</code></a> to
hint that we can just use a single register.</li>
</ul>

<p>This seems like a reasonable point at which to break. We’ve covered a reasonable chunk of the instruction set in x64 assembly,
and seen examples of most of the classes of instructions. There’s tons more we can explore, like:</p>

<ul>
<li>How do loops work?</li>
<li>What happens when we use values that don’t just fit in registers?</li>
<li>How do we make a syscall?</li>
</ul>

<p>Hopefully the resources I’ve linked to from here are sufficent for you to continue digging in if you want,
and maybe I’ll manage to follow this up.</p>

</div>

      </div></div>]]>
            </description>
            <link>https://lfn3.net/2020/08/03/a-gentle-intro-to-assembly-with-rust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041675</guid>
            <pubDate>Mon, 03 Aug 2020 18:44:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing UFCS for C++ in Clang]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24041376">thread link</a>) | @foxhill
<br/>
August 3, 2020 | https://dancrn.com/2020/08/02/ufcs-in-clang.html | <a href="https://web.archive.org/web/*/https://dancrn.com/2020/08/02/ufcs-in-clang.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        
        <p> 2020/08/02 </p>
        
<p>tldr; Unified function calling syntax (UFCS) is useful and elegant. I’ve implemented a variant of UFCS that resembles C#’s “extension methods”, in Clang, which you can check out at <a href="https://github.com/dancrn/llvm-project">https://github.com/dancrn/llvm-project</a>.</p>

<h2 id="outline">Outline</h2>
<p>Proposals for UFCS in C++ has been a somewhat perennial discussion (<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2004/n1585.pdf">N1585</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4165.pdf">N4165</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2014/n4174.pdf">N4174</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/n4474.pdf">N4474</a>, <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2015/p0079r0.pdf">P0079R0</a>), with seemingly positive discussion from many, including both Herb Sutter and Bjarne Stroustrup. C# has a take on UFCS called extension methods, and personally, I’ve found them to be overwhelmingly useful. If you’re unfamiliar C#’s extension methods, they look something like this:</p>

<div><div><pre><code><span>public</span> <span>static</span> <span>class</span> <span>Extensions</span>
<span>{</span>
  <span>public</span> <span>static</span> <span>string</span> <span>ValueOrDefault</span><span>(</span><span>this</span> <span>string</span> <span>input</span><span>,</span> <span>string</span> <span>defaultValue</span><span>)</span>
  <span>{</span>
    <span>return</span> <span>String</span><span>.</span><span>IsNullOrWhiteSpace</span><span>(</span><span>input</span><span>)</span> <span>switch</span> <span>{</span>
      <span>true</span> <span>=&gt;</span> <span>defaultValue</span><span>,</span>
      <span>false</span> <span>=&gt;</span> <span>input</span>
    <span>};</span>
  <span>}</span>
<span>}</span>

<span>public</span> <span>string</span> <span>GetValue</span><span>(</span><span>string</span> <span>str</span><span>)</span>
<span>{</span>
  <span>return</span> <span>str</span><span>.</span><span>ValueOrDefault</span><span>(</span><span>"No value provided"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Extension methods, when invoked, look like first class methods on the type they are defined on. The example provided doesn’t have much benefit over the existing free-form call (i.e. <code>Extensions.ValueOrDefault(str, "nothing")</code> - and this still is also a valid way of calling that method). However, static extension methods come into their own when viewed as generic approaches to extending already existing classes that cannot be modified. One such C# library is <a href="https://github.com/louthy/language-ext">LanguageExt</a>, which provides functional extensions to the base <code>IEnumerable</code> interface (amongst <em>many</em> other things), although there are a lot of other examples that extend other commonly used libraries.</p>

<p>Unfortunately, whilst proposals resurface every once in a while, activity on unified call syntax seem to have stagnated. I want to see what it takes to implement it, and who knows, if enough people like and use UFCS, it might make it into.. C++30, maybe?</p>

<h2 id="ufcs-models">UFCS models</h2>
<p><a href="https://brevzin.github.io/c++/2019/04/13/ufcs-history/">Revzin</a> has an excellent couple of articles that describe UFCS more generally. Essentially, UFCS can be split into two categories of behaviors: “candidate set” functionality describes which functions are considered for a particular invocation style, and “overload resolution” approaches that describe how to determine which member or function should be chosen when there is more than one candidate. Without repeating those descriptions, this model can be considered to be CS4 - the addition of syntax to indicate UFCS candidacy - and OR2 - perform overload resolution as normal with all candidates. I wont spend too much time going into why I’ve made these choices, but briefly:</p>

<h2 id="choice-of-cs4">Choice of CS4</h2>
<p>Whilst not strictly the “most pure” decision, I think that it’s sensible to allow users to specify which functions they intend to be used in overload resolution. And, whilst not <em>strictly</em> speaking a priority, keeping the candidate set as small as possible would be beneficial from the perspective of compilation times. It also allows UFCS to be backward compatible with existing code, means that I think this is the most sensible approach to take.</p>

<h3 id="ufcs-syntax-additions">UFCS syntax additions</h3>
<p>There are two obvious ways of using the <code>this</code> keyword to indicate UFCS candidacy, as a parameter qualifier, or as a parameter name - for anyone familiar with C#, it’s clear that CS4, along with a <code>this</code> parameter qualifier was style chosen when implementing its idea of UFCS. There are many sensible choices for syntax additions, but these where two I considered. These both look like:</p>

<div><div><pre><code><span>// 1. 'this' parameter name</span>
<span>int</span> <span>func</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>this</span><span>);</span>

<span>// 2. 'this' qualifier</span>
<span>int</span> <span>func</span><span>(</span><span>this</span> <span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>param</span><span>);</span>
</code></pre></div></div>

<p>There are some drawbacks to option 1.:</p>
<ul>
  <li>The implicit <code>this</code> value generally has access to private &amp; protected members of a class, members that UFCS functions would not have access to.</li>
  <li>The parameter type was chosen to demonstrate an inconsistency: <code>this</code>, when used in a member function is generally considered to be a pointer, i.e., we use <code>this-&gt;value</code> rather than <code>this.value</code>. What should we accept for UFCS functions?</li>
</ul>

<p>The alternative has a couple of (admittedly smaller) issues:</p>
<ul>
  <li>UFCS candidacy is most easily seen as a is a property of a function, not a parameter - why change the parameter?</li>
  <li><code>this</code> is a keyword that generally represents a value, and whilst C++ has repurposed keywords before - <code>auto</code> - this might not be desirable.</li>
</ul>

<p>In the end, the first option seemed to present more questions than it answered, so I opted for the second alternative.</p>

<h3 id="choice-of-or2">Choice of OR2</h3>
<p>I think the worst case scenario for UFCS would be one where the member functions of a class change, masking a UFCS call in a another part of the code that interacts with values of that type. For instance, consider the following case:</p>

<div><div><pre><code><span>// from include &lt;some/library.h&gt;,</span>
<span>// context is defined with a single "read from file" function.</span>
<span>class</span> <span>context</span> <span>{</span>
<span>public:</span>
  <span>int</span> <span>read_from_fd</span><span>(</span><span>int</span> <span>fd</span><span>);</span>
<span>};</span>

<span>// and in consuming code, has the following extension defined</span>
<span>int</span> <span>read_from_file</span><span>(</span><span>this</span> <span>context</span><span>&amp;</span> <span>ctx</span><span>,</span> <span>FILE</span> <span>*</span><span>fp</span><span>);</span>
</code></pre></div></div>

<p>Now, the library is updated to a later version, which includes its own <code>read_from_file</code> method:</p>

<div><div><pre><code><span>// from include &lt;some/library.h&gt;,</span>
<span>class</span> <span>context</span> <span>{</span>
<span>public:</span>
  <span>int</span> <span>read_from_fd</span><span>(</span><span>int</span> <span>fd</span><span>);</span>
  <span>int</span> <span>read_from_file</span><span>(</span><span>FILE</span> <span>*</span><span>fp</span><span>);</span>
<span>};</span>

<span>// this function can only be used with regular function call syntax</span>
<span>int</span> <span>read_from_file</span><span>(</span><span>this</span> <span>context</span><span>&amp;</span> <span>ctx</span><span>,</span> <span>FILE</span> <span>*</span><span>fp</span><span>);</span>
</code></pre></div></div>

<p>Preferring member calls over UFCS calls in this case would silently change behaviour of this code, without any obvious change to the <code>read_from_file</code> method. Broadly speaking, I don’t think it’s sensible to prefer one type of call over the other, so this would seem to rule out any form of overload resolution that has preference for one type of call over the other. Therefore OR1 and OR2+ don’t seem like the best approaches, and the choice of CS4 rules out OR3 from being an option. In my implementation, any ambiguity between calls is treated as an error, as it is now.</p>

<p>It should be noted that the choice of OR2 is in contrast with C#’s extension methods, where, in the case of ambiguity between a UFCS candidate and a member function, the member function is always chosen (i.e., C# uses OR2+).</p>

<h2 id="ufcs-for-c">UFCS for C++</h2>
<p>In summary, the following is what I’m going to be implementing:</p>

<ol>
  <li><code>this</code> precedes the declaration specifiers (<code>const</code>, <code>volatile</code>, etc.) of a file/namespace scoped function’s first parameter.</li>
  <li>Class methods cannot be defined to be UFCS candidates (although that could probably be relaxed for non-instance methods).</li>
  <li>Calls of the form <code>x.f(y)</code>, in addition to performing member lookup, also perform name lookup for functions of name <code>f</code>, and overload resolution with arguments <code>x</code>, and <code>y</code>.</li>
  <li>Overload resolution proceeds as normal, i.e., if the candidate set contains a class method and a UFCS candidate, then there is no preferential treatment of either, and this is an error.</li>
</ol>

<h3 id="an-example">An example</h3>
<p>In summary, we will be able to define functions that appear to be methods defined on a class as such:</p>

<div><div><pre><code><span>class</span> <span>foo</span> <span>{</span>
  <span>private:</span>
  <span>std</span><span>::</span><span>string</span> <span>m_bar</span><span>;</span>

  <span>public:</span>
  <span>foo</span><span>(</span><span>const</span> <span>std</span><span>::</span><span>string</span><span>&amp;</span> <span>bar</span><span>)</span><span>:</span>
  <span>m_bar</span><span>(</span><span>bar</span><span>)</span>
  <span>{</span> <span>}</span>

  <span>std</span><span>::</span><span>string</span> <span>get_bar</span><span>()</span>
  <span>const</span> <span>noexcept</span>
  <span>{</span> <span>return</span> <span>m_bar</span><span>;</span> <span>}</span>
<span>};</span>

<span>int</span> <span>get_bar_length</span><span>(</span><span>this</span> <span>const</span> <span>foo</span><span>&amp;</span> <span>val</span><span>)</span> <span>{</span>
  <span>return</span> <span>val</span><span>.</span><span>get_bar</span><span>().</span><span>length</span><span>();</span>
<span>}</span>
</code></pre></div></div>

<p>And using these methods looks like:</p>

<div><div><pre><code><span>void</span> <span>f1</span><span>()</span>
<span>{</span>
  <span>auto</span> <span>val</span> <span>=</span> <span>foo</span><span>(</span><span>"pasta"</span><span>);</span>

  <span>// the two calls are semantically identical</span>
  <span>assert</span><span>(</span><span>val</span><span>.</span><span>get_bar_length</span><span>()</span> <span>==</span> <span>get_bar_length</span><span>(</span><span>val</span><span>));</span>
<span>}</span>
</code></pre></div></div>

<h2 id="clang">Clang</h2>
<p>I’ll forgo an introduction to Clang here - I expect any readers will be familiar with it. I’ve been motivated to start with Clang rather than GCC primarily because of Saar Raz’s story on getting behind Clang’s <a href="https://www.youtube.com/watch?v=Y1o4rc9P1FQ">implementation of concepts</a>. In any case, Clang seems like a suitable basis for implementation:</p>

<ol>
  <li>Clang is actively maintained with hundreds of contributers,</li>
  <li>code quality in Clang is widely regarded to be clean and consistent,</li>
  <li>acceptance into Clang, if it were to happen, may encourage discussion on UFCS, and</li>
  <li>it could be fun :)</li>
</ol>

<h3 id="implementation">Implementation</h3>
<p>I started UFCS in clang “for real” in around April of this year, although I had been reading and thinking about it on and off probably since September of 2019. In general I thought the code quality in Clang was decent, and whilst the learning curve was probably the steepest I’ve ever encountered, I was impressed with how little you needed to fully understand to make something work - the code is truly quite modular. That said, getting something working versus something that is complete requires understanding very large regions of code. Parsing C++ is what a lot of people would consider to be exotic, and so small changes in one place can have effects in places that you would not expect.</p>

<p>As it stands, I have a working implementation that passes all the tests in <code>make clang-test</code>. Of course, ‘Parse’ and ‘SemaCXX’ tests have been added, <code>cxx-ufcs.cpp</code> and <code>unified-call-syntax.cpp</code> respectively. I’ve added appropriate additional diagnostic messages (albeit as parser errors, rather than semantic analysis errors), though there are some others that I would like to add in. I’ve tested my custom version of Clang on a few projects, and it seems to work as expected, too. Overall, I’m quite satisfied with how it’s turned out, and I (naively) hope someone other than myself will give it a go :)</p>

<h3 id="using-ufcs">Using UFCS</h3>
<p>If you want to try UFCS, then you can checkout and build Clang from <a href="https://github.com/dancrn/llvm-project">here</a>, there’s nothing extra to configure (although I recommend you don’t install it in the default prefix!). To enable UFCS, you’ll need to pass an additional argument to Clang when invoking it, <code>-fufcs</code>. The front end driver hasn’t been changed at all, so you’ll most likely need to pass it through to the compiler manually:</p>

<div><div><pre><code> $ /path/to/clang -Xclang -fufcs file.cpp
</code></pre></div></div>

<p>Again, given the design of this implementation, there shouldn’t be any issues with compiling existing code. If this is not a case, then feel free to create an issue on GitHub!</p>

<h2 id="remaining-work">Remaining Work</h2>
<p>Whilst I’m moderately confident that my changes work as intended, I do not consider this to be “done”. There are a few things that feel not quite right, and, even if this is never merged into clang (which …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dancrn.com/2020/08/02/ufcs-in-clang.html">https://dancrn.com/2020/08/02/ufcs-in-clang.html</a></em></p>]]>
            </description>
            <link>https://dancrn.com/2020/08/02/ufcs-in-clang.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041376</guid>
            <pubDate>Mon, 03 Aug 2020 18:21:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eight Years at Roblox]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24041338">thread link</a>) | @nabla9
<br/>
August 3, 2020 | https://zeux.io/2020/08/02/eight-years-at-roblox/ | <a href="https://web.archive.org/web/*/https://zeux.io/2020/08/02/eight-years-at-roblox/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span>

02 Aug 2020

</span></p><p>I joined Roblox at the end of 2012 as a rendering engineer; I had just spent more than a year working on various titles from FIFA franchise after years of console game development and was becoming a bit tired of the “big game development”. My work on FIFA was as a contractor and I got an offer for a full-time position, but I also had a friend who worked at Roblox reach out and offer me to move to California and work on Roblox. I knew absolutely nothing about Roblox, but California was nice and my friend told me it would be awesome. The platform was so different (and so strange!) that I decided to take a chance - here I am, 8 years later, still working at Roblox and enjoying it. I started on my first full time job in April 2007 so at this point I’ve worked for 13 years in game development and 8 of them were at Roblox.</p>

<!--more-->

<p>My memory works in interesting ways. I remember my interview pretty well, I remember having lunch at some place in San Mateo downtown near the Roblox HQ - a few people were at lunch including Roblox CEO David Baszucki and I remember him asking many questions about my thoughts about the engines and rendering, and distinctly remember not finishing most of my lunch because I talked most of the time. However I don’t really remember what was going through my head in regards to my perception of Roblox - why did I join besides just thinking I want to do something else for a change? Who knows, but I am glad I did.</p>

<p>I don’t really understand why Roblox is so successful - you can invent all sorts of reasons in retrospect but it’s hard to validate them, and if you came to anybody back in 2012 and asked for an investment to build a platform where all games are user generated and run on a custom engine with a custom toolset and all users participate in a giant virtual economy and …, I think you’d have gotten a blank stare.</p>

<p>But I do understand that I found the perfect place for me, especially at that point in my career - I enjoy working on game technology but I never liked working on actual games, and Roblox maximizes the number of developers who can use the technology you work on while maintaining a good autonomy and a very wide range of problems you’d need to solve. It’s very hard to get bored here.</p>

<p>I think I could talk for hours about Roblox - it somehow became a huge part of my life. I was very fortunate to join at the time when I did and witness the growth of our technology and business. I am really unsure of what the future holds but it’s hard to imagine what, if anything, comes after Roblox - I certainly don’t intend to leave any time soon…</p>

<p>So I thought it might be fun to do what I’ve planned to do for a year or more now, and to go over all decently sized projects I’ve ever worked on at Roblox. This is based on resummarizing and reliving the source control history, which tells me I’ve had 2752 changes that made it to our main branch, with merge commits counting as one, so, uh, this blog might be on a larger side. Hopefully this will be fun!</p>

<p>Before we begin, I just want to conclude this by saying that I’m very grateful to the Roblox leadership for treating me well, for all the friends and colleagues I made along the way, and for the wonderful Roblox community. The reason why I still enjoy what I do is because whenever I write about a new big thing I’m working on or a small feature or even a bug fix, it’s usually met with excitement which keeps me going. Thank you all from the bottom of my heart. I don’t think I could have done it without you and I hope this continues for as long as possible despite the current trying and uncertain times.</p>



<p>Notably including half-pixel offset fixes for Direct3D9 which I guess is a rite of passage for rendering engineers. The rendering code back then was based on OGRE rendering engine, so I had to learn that, and this was also my first time using OpenGL professionally - prior to that I’ve used Direct3D 9 and proprietary console APIs, and Direct3D 10/11 as a hobby.</p>



<p>Initially added for “100 player” project, in October it evolved to render all parts and continued to be used as part renderer until the introduction of instancing in 2018. Otherwise known as “featherweight parts”. This was further optimized and deployed around November 2012. Most of this code survived to this day but evolved over time, and is still used when instancing doesn’t apply.</p>

<p>The core idea in this system was to dynamically batch meshes together, for characters this would be based on the character model hierarchy, and for everything else the grouping is spatial. This allowed us to reduce the number of draw calls, which was a big concern due to both driver overhead and inefficiencies in OGRE.</p>

<p>This would pave the way for what eventually turned out to be a complete, but gradual, rewrite of the rendering stack. The main motivation for this was always performance - what we ended up let us port to mobile (the old rendering code was nowhere near fast enough even for relatively simple scenes), and break new grounds on the number of objects we could render in a frame.</p>



<p>One of a few OGRE upgrades we’ve needed to do, this one was to get better GLES support. It was pretty painful to do those, just like any other big middleware update is. Read further to learn what happened to OGRE eventually…</p>

<p>One thing I remember from doing these is that documentation in source code makes the upgrade process that much more painful. I had scripts that changed the copyright years in headers back to whatever they were in our tree just to make merging less painful, but there was some OGRE upgrade where 70% of the changes were documentation, and this was very hard to get through.</p>

<p>The reason why these were challenging in general is that whenever we did an upgrade we had to a) merge our plentiful changes with the new code, b) gate dangerous parts of the upgrade with flags. We’ve used the same system of feature flags (we call them fast flags) since I joined Roblox which allows us to dynamically disable parts of the release based on metrics, but this requires actually isolating changes behind if statements selectively - which for OGRE was sometimes necessary as we didn’t know what the impact of some low level change in OpenGL code would be.</p>



<p>Before this we had hand-translated shaders, which started to be painful to maintain. The first version of the pipeline used hlsl2glsl and glsl-optimizer (same as Unity back in the day). We are using version 3 today, see below!</p>

<p>Since this was done at the point where we used OGRE, the compiler would take HLSL files, preprocess and translate them to optimized GLSL, and save the resulting GLSL back to disk - which would then be loaded by OGRE directly through the material definition file. Eventually we replaced this with a binary shader pack that could store GLSL code for OpenGL and shader bytecode for other APIs, but back then we shipped HLSL and GLSL source and compiled HLSL code on device!</p>



<p>Our equivalent of “Steam Hardware Survey” that went through SQL databases and coalesced various system information bits to help us understand the hardware at the time. This was during my era of obsession with F#, so it was written in F# instead of something like Python. We don’t use this anymore and don’t even have the SQL database in question!</p>

<p>We never published the resulting data, and I’m not sure how often we used it to make decisions, but it was fun to look at the number of graphics cards from various vendors or amount of RAM or resolution a typical Roblox user has.</p>



<p>Although I was hired as a rendering engineer, I had a lot of really deep low-level systems experience and as a consequence ended up engaging in both optimization work and security related work from the very beginning. I don’t do this anymore these days but I was often involved in the security work for the first 3 or 4 years. Now we fortunately have people who can do this full time and better than I could :)</p>



<p>A second part of “100 player project”, necessary to render every character in one draw call (these were really expensive for us back in the day!). A side effect included some resolution sacrifices on character items that shirt creators aren’t fond of. The new system managed the atlas texture memory, rebaking humanoids far away to smaller textures to conserve texture memory. The compositor survived with minor changes to this day, although we’re now working on a new one.</p>

<p>The compositor was built in a very configurable fashion, allowing the high level code to specify the layout to bake, and managing all the complex asynchronous processing and budgeting by itself. This allowed us to switch the composit layout completely years later for R15.</p>



<p>At the end of 2012 we were actively working on the mobile port. Since then we’ve had to do a lot of work in a lot of different parts of the engine to make data structures smaller and algorithms - faster. Of course you’re never done with optimizations so we do this to this day. Curiously, our minimum spec on iOS stayed the same since the initial launch in 2012!</p>

<p>A fun fact is that even though we started with iPad 2 as the min. spec we discussed adding support to iPad 1 after launch. At the time there were a lot of people who couldn’t play Roblox on iOS on older hardware. However the performance characteristics of those devices were just… not good enough. You could touch the screen with the finger and pan the camera, and during panning you lost 30% of a single available core to the OS processing the touch. We decided to not add support for this, and 8 years later it seems like a great decision for sure :D</p>



<p>It was very hard to use Xcode Instruments to profile frame spikes on an iPad; to try to figure out how to get our performance to a better place on mobile, I wrote some ad-hoc code to dump all internal log events to a binary stream, and a desktop UI tool in F# and WPF to visualize it. This included a Lua profiler as well that could display profiles of Lua code in a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zeux.io/2020/08/02/eight-years-at-roblox/">https://zeux.io/2020/08/02/eight-years-at-roblox/</a></em></p>]]>
            </description>
            <link>https://zeux.io/2020/08/02/eight-years-at-roblox/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041338</guid>
            <pubDate>Mon, 03 Aug 2020 18:18:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A super quick rundown on SEO]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24041239">thread link</a>) | @entreprenerd
<br/>
August 3, 2020 | https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial | <a href="https://web.archive.org/web/*/https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The two primary ways for people to find you on the internet are paid ads and search engines. We discussed paid ads <a href="https://www.entreprenerd.blog/live-streams/marketing-month-week-2">a few weeks ago</a>, now let's talk about search engines.</p><p>"SEO" is Search Engine Optimization - it's how Google and Bing and other search engines can tell whether or not your website should come up when someone searches for something.</p><p>The two main pieces of SEO are:</p><ul role="list"><li>Keywords / Content</li><li>Backlinks</li></ul><p>Keywords are just words and phrases you want to rank for - meaning you show up when someone googles them. For instance, I personally want to rank for words like "entrepreneurship" and phrases like "how to become an entrepreneur." So, if my website is full of articles and videos and information about those words and phrases, I'm more likely to pop up when someone types them into google.</p><p>So, how do you find keywords? I use a tool called <a href="https://ahrefs.com/">ahrefs</a> - it's not free, but it's close. They have "$7 for 7 Days" trial periods, and in order to assemble a solid list of keywords you can use for the next year, you'll really only need those 7 days. (Plus, you can always sign up for more trials using different emails in the future - just REMEMBER TO CANCEL your subscription)</p><p>After you sign up, go to "Keyword explorer" and start typing ideas in. Use each of the tabs on the left under "Keywords Ideas" - and create a list to add any keywords you find that make sense for your brand. Usually, I filter by "KD" (Keyword Difficulty) to anything lower than 25. Beyond 25, unless you're producing an incredible amount of content, you're going to have a lot of trouble.</p><p>After you compile a big fat list of keywords you like, go to the list page and export it to excel so you can use it after your trial period expires. Now you know what to target.</p><p>The next thing is content, and this is where things get to be a black box. Content is just articles and written posts on your website that contain the keywords we compiled. If a big keyword for me is "how to become an entrepreneur" then you bet I'm going to write an article with that title. However, I've talked to a good number of SEO professionals, and the best advice they can give is "Write well." It's tough to know what exactly you should put in your content that makes it rank higher, so the best thing you can do is use proper grammar, make it readable, and do what the title suggests the article will say.</p><p>A few tools I've seen that tend to help content get written well are <a href="http://grammarly.com/">Grammarly</a> and <a href="https://www.dashword.com/">Dashword</a>. Grammarly just helps you use proper grammar - it's free and awesome. Dashword is a new tool I found on ProductHunt that seems to help you position keywords nicely in your content so it ranks higher - though I haven't tested it and it is quite expensive.</p><p>So now you're writing content with the right keywords - but there's more you can do. You can use "backlinks" - links from other successful websites - to boost how well your website overall ranks. Basically, if google sees Entrepreneur Magazine (which ranks well in terms of "entrepreneurship" keywords) has an article or two that link to my website, then google will think my website is more important, and rank me higher. </p><p>So, we want other websites to suggest our website as a resource. We can do that by looking up the keywords we want to rank for - just type them in google - and see if any blogs pop up. If you find blogs or websites that rank well, use a simple email finder like <a href="https://hunter.io/">Hunter.io</a> to find whoever is in charge and reach out to them to ask to write a guest blog post. They get free content, and in the article you get to put a backlink to your website. Some blogs will even have a form just to submit guest post requests.</p><p>Lastly, you can use question-answer websites like <a href="https://www.quora.com/">Quora</a> to help push traffic in your direction. If, while you're googling your keywords, you find a few questions on Quora or WikiHow that you think you can answer, do it. For instance, if someone asks "what podcasts are great for learning entrepreneurship?" I might answer and reference my live stream content. That provides a backlink on a ranking question, and if people like that answer, they can also find you directly through it.</p><p>Beware, all of this sounds pretty great, but google takes anywhere between 4 to 6 months to actually see what you've created. If you post a bit of content now, you'll have to wait a while for the benefit to actually kick in, and for people to find your website through it. SEO is a long-term investment, so plan accordingly.</p><p>That's pretty much the basics. There are a lot more nuances like making sure your website is structured the right way and how to build your sitemap, but this should be all you need to know to get started!</p><p>If this was helpful at all, a retweet would be amazing. It really helps me spread the word - but of course, no pressure at all! :)</p></div></div>]]>
            </description>
            <link>https://www.entreprenerd.blog/live-streams/the-quickest-seo-tutorial</link>
            <guid isPermaLink="false">hacker-news-small-sites-24041239</guid>
            <pubDate>Mon, 03 Aug 2020 18:11:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I've compiled a list of books on cryptocurrencies]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24040928">thread link</a>) | @vhpoet
<br/>
August 3, 2020 | https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn | <a href="https://web.archive.org/web/*/https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.readthistwice.com/lists/best-cryptocurrency-books?s=hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24040928</guid>
            <pubDate>Mon, 03 Aug 2020 17:47:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Art of Not Thinking]]>
            </title>
            <description>
<![CDATA[
Score 511 | Comments 152 (<a href="https://news.ycombinator.com/item?id=24039887">thread link</a>) | @tmatthe
<br/>
August 3, 2020 | http://tiffanymatthe.com/not-thinking | <a href="https://web.archive.org/web/*/http://tiffanymatthe.com/not-thinking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>03.08.2020</time> — <a href="http://tiffanymatthe.com/tags/productivity">Productivity</a> — <span>5<!-- --> min read</span></p><section><img src="http://tiffanymatthe.com/static/d758a9afd33cefb9ce3dc7bb83cc213d/a6c62/not-thinking.jpg"><p><em>After years of feeling guilty about not wanting to do everything, I realized I don't need motivation to get things done. Below, I describe how I use the concept of not thinking instead.</em></p><hr><p>It took me five years to get in the habit of exercising. I just didn't want to do it. I followed Youtube workouts, hopeful that the energetic trainer on the screen would help me get fitter. I swam laps in my pool. I followed my brother on 3K runs. And afterwards, I felt great! On top of the world. And then the next day came, and I remembered I had to do it all over again. I had to be sweaty, push through the pain, and breathe like I had an asthma attack.</p><p>So every morning, I woke up and inevitably started dreading my exercise. It would slink around in my thoughts, casting a dark mood until I got it done. At one point, I would dread exercising enough to stop, and a wave of relief would wash over me. This feeling of calm usually lasted a few months, and then my disappointment in my poor levels of fitness would take over. And the cycle would restart.</p><p><strong>Everyone has things they don't want to do.</strong> It's not limited to exercising. It can be anything from studying everyday for the entire school year to vacuuming the floor. Unless you can avoid that activity with no guilt or regrets, you usually have to do it. You know it will help in the long run, to study to prepare for finals and to have clean floors, but even with that in mind, it can still be incredibly hard to do those activities.</p><p>I realized that the hardest part of doing things I don't want to do is usually not the activity itself, but getting started. Once I get started, I get into a flow and rationalize that since I'm already doing it, I might as well finish.</p><h3>How much motivation do we need?</h3><p>I like to describe the amount of energy I need for a task I don't want to do as an exothermic reaction. In this reaction, the reactants (me) need a minimum activation energy (motivation) for the reaction (task) to occur. After the reaction is complete, the products then settle down into a lower energy state (since no more energy is needed to do the task or worry about it).</p><p><span>
      <span></span>
  <img alt="Motivation Energy Reaction" title="Motivation Energy Reaction" src="http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/18e3b/exothermic.jpg" srcset="http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/46946/exothermic.jpg 240w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/55489/exothermic.jpg 480w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/18e3b/exothermic.jpg 960w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/60e21/exothermic.jpg 1440w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/69b48/exothermic.jpg 1920w,http://tiffanymatthe.com/static/45c003a7d8906347afa290a5d3bc064d/e1761/exothermic.jpg 3273w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p><p>So how can we get this minimum activation energy? Well, if we don't want to do the activity, it is nearly impossible to gain enough motivation to do it. The good news is that we can avoid the need for such a high activation energy.</p><p>How is this possible? A simple answer: <strong>don't try to find motivation</strong>.</p><p>When you look for motivation, you usually start by reminding yourself about the advantages of getting the task done. But your brain is a stubborn toddler. If you strongly drag it towards one direction, it will fiercely pull you to the other side. The brain thinks there's a choice, and thus a possibility to argue. It will start pointing out all the disadvantages and instant gratification alternatives.</p><p>Since humans instinctively reach for easier things, now you have not only dredged up all the negative points about your task, but also discovered easier alternatives that require an additional amount of energy to resist. In short, you have increased the minimum activation energy required to start the task.</p><p>You will also remember this awful internal debate, and associate these negative feelings with the task itself. Naturally, this does not bode well in the long run.</p><p>On the other hand, if you don't think about the task, you can avoid the entire process of arguing with yourself and making decisions that you will feel guilty about. Instead, just do it. <strong>Become a mindless robot</strong> and don't think twice<sup id="fnref-1"><a href="#fn-1">1</a></sup>.</p><p>This is, of course, easy to say and a bit more difficult to do. It's hard to think about not thinking, because you'll inadvertently wonder what it is you were trying to not think about, and bam, you've failed. Not thinking is a process, and just like any other skill you learn, it improves with time and practice. Here are a few tips.</p><h3>Make the decision in advance</h3><p>If you are temporally removed from the thing you don't want to do, it's easier to make a rational decision. By making the decision beforehand, you remove the effort needed to choose before doing your task. This reduces friction and removes one factor that could have led you to think about your task when you start it.</p><p>There are a few ways of making decisions in advance. There's the two-minute rule, where you decide that for anything that takes less than two minutes, you do it. No thinking, no arguing, just swift action. For example, you see a pile of clothes on your bed. It takes less than two minutes to organize then in your drawer, so you do it. Here, you just avoided the trap of thinking about your clothes, feeling unmotivated to put them in order, and giving yourself the terrible alternative of doing it later.</p><p>Another method is planning out your days in advance. This does not always work, but it's a good idea to try it out. The night before, you plan out all of your activities to the minute. And, of course, as you're temporally distanced from these activities, you make rational decisions. Then when the morning comes, you can mindlessly follow the schedule you have made for yourself.</p><h3>Do a small part first</h3><p>Quickly pick a random small part of the activity you were dreading. And commit to only doing that one part. This helps you avoid overthinking by giving your brain a smaller task to easily execute<sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p><p>For example, if you need to complete a scholarship application and hate writing about yourself, tell yourself to just write bullet points of topics you might include in the application. Most of the time, after you have invested those first five minutes into the activity, you enter a flow and continue working.</p><p>After implementing these strategies, where I tell myself that I have to exercise every other day for a mere 5 minutes, I now consistently exercise for at least 15 minutes without overthinking it.</p><p>So next time you find yourself not wanting to do something, make yourself a clear rule of when to do it and do the easiest part first. That way, you can avoid making too many decisions and associating the internal turmoil that stems from that process to the activity itself.</p><p>Note, not thinking works wonderfully if your sole purpose is doing an activity you don't want to do. However, unless you don't have any goals to pursue, this is not the best way to go about everything in life. Make sure to take the time to reflect on the overall purpose of the activity and if it brings you closer to where you want to be. If the answer is yes, then feel free to become a mindless robot for any activities that have passed the reflection stage.</p><p>At the small risk of being sued by Nike, just do it.</p></section></div></div>]]>
            </description>
            <link>http://tiffanymatthe.com/not-thinking</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039887</guid>
            <pubDate>Mon, 03 Aug 2020 16:34:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don't Tell Your Data Team's ROI Story]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039794">thread link</a>) | @barrald
<br/>
August 3, 2020 | https://hex.tech/blog/data-team-roi | <a href="https://web.archive.org/web/*/https://hex.tech/blog/data-team-roi">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I’m fortunate to be involved in a few awesome data-focused communities. Like clockwork, every few months a Data leader will pop up asking for advice on how to calculate the return-on-investment for their team. The question is usually in the context of a budget decision, where they need to justify expanding headcount or purchasing a new tool.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The name has been changed to protect the innocent" title="The name has been changed to protect the innocent" src="https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png" srcset="https://hex.tech/static/833b16929966b847168439d6df34e764/44569/slack-message.png 175w,
https://hex.tech/static/833b16929966b847168439d6df34e764/f8bcd/slack-message.png 350w,
https://hex.tech/static/833b16929966b847168439d6df34e764/cf20c/slack-message.png 493w" sizes="(max-width: 493px) 100vw, 493px" loading="lazy">
  </a>
    </span>
    <figcaption>The name has been changed to protect the innocent</figcaption>
  </figure>
<p>While there’s a subtle irony in the team responsible for quantification struggling to quantify their work, calculating a true “ROI” can be challenging because of the way data teams typically operate.</p>
<p>In some cases, the data team has a top-or-bottom-line impact that can be directly measured. For example, if the company sells data as their product, the Data team has a clearer, more obvious connection to value creation.</p>
<p>But for most teams, their impact is created indirectly: they are partners, acting in support of functions like Marketing, Operations, or Engineering to affect company performance.</p>
<p>In organizations like these, efforts for the Data team to come up with a standalone ROI will be underwhelming and unconvincing. Calculating a crisp “return” on an analysis project or model is difficult, and it’s even harder for infrastructure investments: how do you quantify the impact of a better schema, or a more reliable pipeline? An improvement in data quality can be objectively beneficial, but also quickly taken for granted.</p>
<p>The truth is that if you’re trying to quantify your impact by yourself, you have already lost. <strong>Instead, the best way to tell the ROI story is for other people to tell it.</strong></p>
<p>If your Data team is truly providing value, the leaders of other functions should be lining up to sing your song. Limitations or reductions in Data team headcount should elicit howls from functional stakeholders; the VP Marketing and Head of Ops should be the ones fighting for more Data resources.</p>
<p><strong>If your partners aren’t willing to go to bat for you like this, then it’s time to take a step back to rethink how you’re operating.</strong> Are other teams actually benefiting from your work, or are you detached from business outcomes? Is your team in the trenches with other functions, or only providing input from afar?</p>
<p>There are 3 key areas to examine:</p>
<h3>Organization</h3>
<p>Too many data teams operate in a centralized, siloed manner. “Ivory Tower” teams may be doing brilliant, insightful work, but they’re too far from the business to make a tangible impact.</p>
<p>I once worked with the “Advanced Analytics Group” at a major CPG company. They all sat together, in one area of one floor of one building, far from the teams they were supposed to be supporting. While they were all intelligent, earnest people, their work was academic at best, and they struggled to justify their existence. This “Center of Excellence” model rarely works, especially as a team grows.</p>
<p>There are other ways to organize a data team. <a href="https://medium.com/@djpardis/models-for-integrating-data-science-teams-within-organizations-7c5afa032ebd" target="_blank" rel="nofollow">Pardis Noorzad has an amazing overview here</a>, and I agree that the "Product Data Science" model is a strong option for most teams. <a href="https://medium.com/@itunpredictable/data-as-a-product-vs-data-as-a-service-d9f7e622dc55" target="_blank" rel="nofollow">Justin Gage's "Data as a Service" model</a> also provides a useful lens - is your Data team just providing data, or useful input to decisions? <strong>If not, stakeholder partners are unlikely to stand up and support your team’s ROI story.</strong></p>
<figure>
    <span>
      <a href="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/07220/justin-DaaS-image.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="From Justin Gage's 'Data as a Product vs. Data as a Service'" title="From Justin Gage's 'Data as a Product vs. Data as a Service'" src="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/a27c6/justin-DaaS-image.png" srcset="https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/44569/justin-DaaS-image.png 175w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/f8bcd/justin-DaaS-image.png 350w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/a27c6/justin-DaaS-image.png 700w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/dd14e/justin-DaaS-image.png 1050w,
https://hex.tech/static/c59ed26e6df11e11d595e3c492161d0b/07220/justin-DaaS-image.png 1156w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
    <figcaption>From Justin Gage's 'Data as a Product vs. Data as a Service'</figcaption>
  </figure>
<p>Re-organization away from a centralized Data team model can be painful, and may feel like a loss of control or prestige. But it’s critical to keep an open mind — and set ego aside — if you want your stakeholders to feel the impact of your team, and advocate on your behalf.</p>
<h3>Planning</h3>
<p>Next, integrate your planning process. If your organization uses a system like OKRs, explicitly tie the Data objectives to support the goals of your stakeholders. This makes it clear exactly how your team is impacting functional outcomes.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="All together now" title="All together now" src="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png" srcset="https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/44569/OKRs-for-blog.png 175w,
https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/f8bcd/OKRs-for-blog.png 350w,
https://hex.tech/static/cdf4bad6b8a6f357d2890e6d9548047b/a27c6/OKRs-for-blog.png 700w" sizes="(max-width: 700px) 100vw, 700px" loading="lazy">
  </a>
    </span>
    <figcaption>All together now</figcaption>
  </figure>
<p>Infrastructure-level objectives — like implementing a new data warehouse — can live separately, but should still have explicit callouts for how those investments are supporting the higher-level objectives.</p>
<p>Data Leaders should also push for their teams to be involved with other teams’ granular planning cycles. If the Marketing team has a weekly planning meeting or daily stand-ups, the Data analysts supporting that team should be in the room (or Zoom, or whatever).</p>
<p>If your team has its own planning cycles and sprints, involve stakeholders in an explicit prioritization exercise. This will give them more insight into Data activities, and when it comes time to speak to ROI they will already have thought through the upside and tradeoffs around your team’s time.</p>
<p>As a side benefit, by aligning priorities with the business, Data teams <strong>avoid the dreaded “find novel insights” mandate</strong>. If an Analyst is deeply embedded with the Marketing team, partnering on their hardest problems, it’s harder for the CFO to distract them with a one-off wild goose chase.</p>
<h3>Tools</h3>
<p>Even if they are well-integrated into the rest of the organization, <strong>the Data team’s work will underwhelm if it’s not actually useful for others</strong>. Today’s tools are a mixed bag here.</p>
<p>BI platforms are great for enabling self-serve and building dashboards. But they also have relatively low ceilings, and aren’t a medium where data scientists can do their most interesting work.</p>
<p>On the other hand, Code notebooks are amazing for deeper exploration and model iteration, but are single-player, hard to share, and inaccessible for less-technical folks. Even if a Data Scientist has developed something interesting, there’s no easy way to productize it or make it useful for the rest of the organization.</p>
<p>So Data teams often wind up screenshotting charts, exporting CSVs, and sharing through slide decks, spreadsheets, and Slack. While these tools meet stakeholders where they are, they’re severed from source data and have short half-lives; when a PM wants to update an assumption, they need to ping the analyst, who re-runs, re-exports, and re-sends.</p>
<figure>
    <span>
      <a href="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="We can do better" title="We can do better" src="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png" srcset="https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/44569/screenshot_hell.png 175w,
https://hex.tech/static/4f1996f86e4ec2907331c83ad39d3be7/7101e/screenshot_hell.png 257w" sizes="(max-width: 257px) 100vw, 257px" loading="lazy">
  </a>
    </span>
    <figcaption>We can do better</figcaption>
  </figure>
<p>This gap in sharing and collaboration not only wastes Data teams’ time, but acts as a drag on their impact. Delivering a forecast model to the Finance team as a live, interactive data app is way more useful than a once-weekly static PDF; the CFO themself will understand the ROI every time they open it to run a new scenario.</p>
<p>I’m excited to see a new crop of tools emerge (disclaimer: <a href="https://hex.tech/" target="_blank" rel="nofollow">I’m working on one</a>) to help data teams more easily share their work, and create clearer, more tangible impact with the rest of the organization.</p>
<hr>
<p>It’s an exciting time in the Data world. Thousands of new people are entering the space as Data Scientists and Analysts. It’s easier than ever to source, transform, and store data. And the ML explosion is unlocking possibilities for insight and inference.</p>
<p>But gaining the budget and support needed to take advantage of all of this is an uphill battle without advocacy from functional stakeholders. By re-evaluating team organization, planning, and tooling, Data teams can ensure their impact is obvious and clear.</p>
<p>Done right, it means the next time a Data leader is asked to justify ROI, they won’t have to. They can sit back, and let others tell the story for them.</p></div></div>]]>
            </description>
            <link>https://hex.tech/blog/data-team-roi</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039794</guid>
            <pubDate>Mon, 03 Aug 2020 16:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You May Finally Use JSHint for Evil]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039470">thread link</a>) | @jugglinmike
<br/>
August 3, 2020 | http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/ | <a href="https://web.archive.org/web/*/http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      
  
  <article>

    <header>
      <p>
          
        POSTS
      </p>
      
      
      <time datetime="2020-08-03T00:00:00Z">August 3, 2020</time>      
      
      
      
      
    </header>

    <section><p><a href="https://jshint.com/">JSHint</a> is a software tool designed to help developers
write JavaScript code. Since its creation in 2011, it has been encumbered by a
license which includes the following clause:</p>

<blockquote>
<p>The Software shall be used for Good, not Evil.</p>
</blockquote>

<p>That stipulation <a href="https://www.gnu.org/licenses/license-list.html#JSON">disqualifies JSHint from the distinction of “free”
software</a> and <a href="https://opensource.org/faq#evil">“open
source” software</a>.</p>

<p>Today, with a release 7 years in the making, we’re removing the clause. Support
for Evil is a new feature but not a breaking change, so in keeping with
<a href="http://semver.org/">Semantic Versioning</a>, we’ve incremented JSHint’s minor
version. <a href="https://jshint.com/blog/2020-08-02/release-2-12-0/">JSHint version
2.12.0</a> is licensed under
the terms of the MIT Expat license.</p>

<p>In this series of essays, I’ll discuss why this matters for the project, why it
matters to me personally, and how a large group of people came together to make
this possible.</p>

<ol>
<li><a href="http://mikepennisi.com/blog/2020/jshint-watching-the-ship-sink/">Watching the Ship Sink</a> - how
the license hurt JSHint</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-dug-in/">Dug In</a> - why I stuck with JSHint and the
relicensing effort</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-asking-nicely/">Asking Nicely</a> - our inability to
relicense solely via contributor consent</li>
<li><a href="http://mikepennisi.com/blog/2020/jshint-wrestling-it-free/">Wrestling it Free</a> - our success in
relicensing through rewriting code</li>
</ol>

<p>Whether or not you care about any of that, the result is the same: JSHint is
now irrevocably free software.</p>

<p>Many thanks to <a href="https://github.com/jshint/jshint/graphs/contributors"><strong>all the people who’ve contributed to
JSHint</strong></a> for making this
project worth liberating and for enthusiastically participating in that
process. Thanks especially to <a href="https://anton.kovalyov.net/"><strong>Anton
Kovalyov</strong></a>, without whom there would be no JSHint
to relicense. <strong>Ethan Dorta</strong>, <a href="http://alexkritchevsky.com/"><strong>Alex
Kritchevsky</strong></a>, <a href="https://mattsurabian.com/"><strong>Matt
Surabian</strong></a>, and <strong><a href="http://tkellen.com/">Tyler
Kellen</a></strong> masterfully reimplemented code that they
couldn’t see. It’s tough to overstate the difficulty of the challenge and the
shrewdness required to overcome it. <a href="https://tbranyen.com/"><strong>Tim Branyen</strong></a>,
<strong>Isaac Carter</strong>, and <strong>Timon Lukas</strong> also volunteered time and energy toward
this end. <strong>Rick Waldron</strong> and <strong>Caitlin Potter</strong> gladly accepted the burden of
CLA enforcement in addition to their more traditional maintenance duties. The
relicensing effort was dead in the water until <strong>Simon Kaegi</strong> discovered the
free software version of JSLint; thank you, Simon, for catalyzing the campaign.
<strong>Joel Kinney</strong> and <strong>Steven M. Ayr</strong> provided much-needed legal perspective
(to be clear: <em>not</em> legal advice) when this all started, and they did so with
eagerness and passion that would make you think we’d paid them (to be clear: we
didn’t). When things seemed hopeless, <a href="https://pault.ag/"><strong>Paul
Tagliamonte</strong></a>, <a href="https://nadiaeghbal.com/"><strong>Nadia Eghbal</strong></a>
and <a href="http://punkrocklawyer.com/"><strong>Karen Sandler</strong></a> offered much-needed
encouragement and perspective. In addition to introducing me to Ethan, <a href="https://fsf.org/"><strong>the
Free Software Foundation</strong></a> continues to sponsor writing and
conferences that reinforce the importance of software freedom. By researching
legal concerns regarding software rewriting, <strong>Russell Hoover</strong> and <a href="https://kendraalbert.com/"><strong>Kendra
Albert</strong></a> at <a href="https://cyber.harvard.edu/teaching/cyberlawclinic"><strong>the Harvard Law School Cyberlaw
Clinic</strong></a> demonstrated
expertise and altruism. <a href="https://joryburson.com/"><strong>Jory Burson</strong></a>, <a href="https://www.lyza.com/"><strong>Lyza
Gardner</strong></a>, and <a href="https://matmarquis.com/"><strong>Mat
Marquis</strong></a> all helped me make sense of this story. The
warmth and dedication of these people can’t be overstated!</p>
<ul>
  
</ul>

    </section>

    

  </article>

    </div></div>]]>
            </description>
            <link>http://mikepennisi.com/blog/2020/you-may-finally-use-jshint-for-evil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039470</guid>
            <pubDate>Mon, 03 Aug 2020 16:04:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SentiLink is first company in US to do real-time SSN verifications]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24039393">thread link</a>) | @vivekahuja
<br/>
August 3, 2020 | https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c | <a href="https://web.archive.org/web/*/https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.sentilink.com/@press_51526?source=post_page-----2f71da5f280c----------------------" rel="noopener"><img alt="SentiLink" src="https://miro.medium.com/fit/c/96/96/2*kOctpPGgHUJshvf2fwu0pQ.png" width="48" height="48"></a></p></div></div></div></div><p id="1247"><em>By Naftali Harris, CEO</em></p><p id="ac29">All of us at SentiLink are extremely excited to announce that this Friday evening at 6:48pm PT, SentiLink became the first organization to go live with eCBSV! The first application in history was from a consumer who applied for a mortgage with one of our 20 eCBSV partners. The consumer consented to sharing their information with SentiLink, our partner, and the Social Security Administration, SentiLink submitted a request to the SSA, and the SSA determined that the information matched. This expedited the approval process for the consumer and the lender and saved them from having to fill out and sign a paper form.</p><p id="6f08">eCBSV (“Electronic Consent Based SSN Verification”) is a new service being offered by the SSA that allows permitted entities to electronically obtain consent from consumers and in real-time verify name/DOB/SSN combinations directly with the SSA. Until this evening, requests for SSA validation required a completed SSA89 form and a wet signature and took hours or even days to process, significantly limiting their use. eCBSV digitizes and dramatically expedites this process. While the stream of eCBSV requests we’re now processing are only the beginning, we believe that within several years there will be tens or hundreds of millions of requests, and eCBSV will be accepted as a major component in KYC and identity verification processes.</p><p id="21fe">The entire team at SentiLink has worked very hard to make eCBSV available for our partners and their customers. This includes getting up before 3:00AM last July in order to submit one of the <a target="_blank" rel="noopener" href="https://blog.sentilink.com/sentilink-and-ecbsv-5501d1db6360">first pilot applications</a> to the SSA, implementing all of the OIDC corner cases in the integration, doing <a href="https://research.sentilink.com/sentilink-ecbsv-whitepaper" target="_blank" rel="noopener">original research on match rates against the SSA’s source-of-truth Numindent file</a>, designing <a target="_blank" rel="noopener" href="https://blog.sentilink.com/the-ecbsv-product-guide-use-cases-f674b9905123">implementations and potential use-cases</a> with our financial institution partners, and <a target="_blank" rel="noopener" href="https://blog.sentilink.com/the-ecbsv-product-guide-consent-requirements-4fc897e87d44">working closely with the SSA to iron out the consent requirements</a>. I’d like to thank the entire team at SentiLink for sweating and hustling to push this over the line. I’d also like to thank our initial 20 partners; no first time implementation is perfect, and we’re lucky to work with 20 innovative, forward-thinking organizations whose feedback has been and continues to be critical to the success of this program. And lastly all of us would like to thank the SSA, whose hard work and late nights standing up eCBSV has made everything possible.</p><p id="02b5">We don’t believe eCBSV will be perfect or a stand-alone solution, but it is certainly a big step forward and a very useful new tool for financial services companies. We are humbled to help open a new chapter in identity verification in the United States.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.sentilink.com/sentilink-makes-history-as-first-ecbsv-provider-2f71da5f280c</link>
            <guid isPermaLink="false">hacker-news-small-sites-24039393</guid>
            <pubDate>Mon, 03 Aug 2020 15:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What RN is missing in order to be the default framework to build apps]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24038136">thread link</a>) | @oscar_franco13
<br/>
August 3, 2020 | https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/ | <a href="https://web.archive.org/web/*/https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I was trying to develop app that runs on ALL platforms (iOS, android, windows, mac), I was encouraged by the announcement that react-native recently added support to macOS thanks to the guys at microsoft (facebook has now jumped on the bandwagon), so after a couple of months of development I have to call quits, there is just too much friction, I’m a one man team developing this on my freetime and I have rarely encountered so much problems developing a simple app.</p>

<p>React native promises this utopia, we’re you write once and gets executed everywhere, which is true when everything works, however when it doesn’t the pain starts, with the current jump into desktop environments there is a lot more friction than the more mature mobile counterparts.</p>



<p>I had assumed that despite it’s young age microsoft wouldn’t announce a “release” if the product was not ready, and I was willing to go the extra mile cutting slack here and there, ignoring the rough edges, I even patched some libraries myself, with my barely passable knowledge about the macOS toolchain, swift, obj-c and cocoapods, but I reached the point of break when trying to draw vector graphics.</p>

<p>Currently if you want to draw vector graphics on react-native the default choice is react-native-svg, surprise surprise it’s not supported on macos (or windows), support might come someday, but you are at the mercy of the react-native community until someone takes the time to port it to each platform, and let me tell you the react-native community does not have a great track record of producing well maintained software.</p>

<p>And this is a story that keeps repeating itself for me (and not only on macOS) I’ve been working with RN for some years now and everytime I reach the point where libraries are abandoned left and right, new functionality or patching requires deep knowledge of the platform and build systems.</p>

<p>Another current paint point React-navigation? you are stuck with version 2.X, which has no native dependencies and has been deprecated for years already, other libraries like camera, location, etc… you can forget them for a few months/years, it’s incredibly bold of microsoft to claim their “store” app is built with react-native, it’s basically a bunch of webviews cobled together, and it is basically a app that consists of some lists, if that is all your app will need, then you can safely use react-native on desktop.</p>



<p>Current windows and macos ports are being developed with the idea that all supported platforms should have 1 to 1 feature parity, this also includes behavior parity.</p>

<p>On the surface this sounds reasonable, <strong>it’s not</strong>, because mobile and desktop do not behave the same, the way you interact with an app using keyboard and mouse is not the same as with mobile, on desktop keyboard shortcut support is a must, being able to detect key combinations is a must, RN does not support any of this, even some of the default behavior with a digital keyboard does not translate well to physical machine, another thing is app lifecycle (focus/blur) are bound to different rules as on mobile</p>

<p>At best you will end up with an app that feels weird to use on desktop (UI not withstanding, just talking about UX here), so far my workaround has been to attach listeners on the native sides and transmit events to the rn side… you can imagine this is time consuming to get right, and sometimes you will just not get it right no matter what</p>

<h2 id="its-open-source">It’s open source!</h2>

<p>You want to patch this yourself? here are some of the problems in the order that I found them as I went along:</p>
<ul>
  <li>I barely learned Swift, I cannot justify learning obj-c, guess what rn is written in obj-c</li>
  <li>You have to learn the macOS specific APIs, most of the content in the internet is written for the iOS APIs</li>
  <li>Apple’s documentation is one of the worst I have seen so far</li>
  <li>You have to start digging into the more hardcore parts of the APIs, CoreGraphics?</li>
  <li>If somehow you manage to do all of that, repeat it for other platforms Android, Windows?</li>
  <li>Once you have your piece of native code you have to use the RN bridge, did you know it is also slow? now you have to do TurboModules, which is c++… also no (usable) documentation</li>
  <li>Oh yeah, add one more platform, react-native-web</li>
  <li>Don’t forget about each platform build system, I still don’t fully grasp everything Gradle does to build an Android app</li>
</ul>

<p>Now to be completely fair, some of these problems are not unique to react-native, the problem is… there is already a solution out there to run code on every architecture/machine that does not require you to learn a new API every 2 days or so, it’s called a web browser</p>



<p>As for react-native, besides the corporations with big pockets taking over the job the community is currently trying to fill, I see no good solution, the disparity of libraries, APIs, platforms makes this a really challenging problem to tackle in the typical OSS manner, and in the end, we are all re-creating chrome with a lesser memory footprint and some performance gains (which I still would debate)</p>

<p>As for my and my project I think the best path forward is web, I can still use react and the web APIs are good enough for what I need to do, electron gets a lot of flak for the size of installation and memory consumption, but chrome is an OS by itself, so much of this small details have been abstracted away and solved by a well paid cohesive team and with webassembly the possibilities are greater than ever, not saying it is perfect, but it sure beats holding your breath for the OSS community and a menage of companies/team (all with different incentives) to catch up</p>

<p>Creating shallow native apps that heavily use embedded webviews seems a good compromise when truly native functionality is needed, I remember I saw a couple of videos of the guys at basecamp, they have tiny native teams that only write small container apps but the bulk of the work is in the web and that can be reused inside the shallow containers, that seems to be the most reasonable thing (even if you have to learn the basic of each OS to create a container app, which you end up doing anyways with RN)</p>

  </div></div>]]>
            </description>
            <link>https://ospfranco.github.io/post/2020/08/03/what-react-native-is-missing-to-become-the-default-framework-to-build-apps-on-all-platforms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24038136</guid>
            <pubDate>Mon, 03 Aug 2020 14:26:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Email got us $5k in AWS Credits]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24037963">thread link</a>) | @CoreSet
<br/>
August 3, 2020 | https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits | <a href="https://web.archive.org/web/*/https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We recently went through the <a href="https://stripe.com/atlas">Stripe Atlas</a> program and <a href="https://formcake.com/blog/our-experience-with-stripe-atlas">loved it</a>.</p>
<p>But the one sour note was that we only got $1,000 AWS credits when <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">the copy seemed to promise $5,000</a>. Our <a href="https://formcake.com/blog/why-we-chose-a-marketing-and-app-monorepo">entire application infrastructure is on AWS</a> so those credits are pretty much straight-up cash to us. We don't have much of a digital footprint either, so $5,000 goes a long way.</p>
<p>That's why this weekend was such a surprise.</p>
<h3 id="the-email">The Email</h3>
<p>Here's how the timeline went.</p>
<ol>
<li><p>First <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">we posted an article</a> politely noticing that we hadn't been able to secure the full $5,000 and kinda wondering out loud why.</p>
</li>
<li><p><a href="https://formcake.com/blog/the-founders-guide-to-stripe-atlas">Stripe contacted us</a> and explained that the credit amount was more of a lifetime cap and that it was ultimately up to AWS what we got.</p>
</li>
<li><p>We send <em>one more</em> email just 'cause, even though it seems clear AWS only offers $1,000 for bootstrapped startups. The email is simple and amounts to: "Is there any way we could get the full five thousand in credits?"</p>
</li>
</ol>
<p>Stripe responds to this chain of events with yet another email, this one even kinder and more politely worded.</p>
<section>
Hey David,

<p>Thank you for sharing the details here. It sounds like we should be able to get this sorted out so that you receive the $5K in AWS credits for Stripe Atlas users.  </p>
<p>I believe it may be the case that you applied for AWS credits with a different link than the one shared for Stripe Atlas users to activate. We do not typically see users needing to answer the question regarding funding sources. I did check in with AWS on this and it sounds like they're currently processing your most recent application that you submitted through the Stripe Atlas link. They've let me know that they will email you directly with next steps, which may take up to 4 weeks. </p>
<p>Hopefully this will all soon be sorted! If you do have any questions on this or anything else, please feel free to reach out! I'll check back in a couple weeks on the AWS front, or feel free to share any updates as well!</p>
<p>Warm regards,
Taylor</p>
</section> 

<p>It looks like the funded/bootstrapped question indicated the process had gotten miffed somewhere and <em>Stripe reached out to AWS on our behalf</em> to make sure things got cleared up.</p>
<p>This weekend we saw $5,000 in credits enter our AWS account. Keep in mind that's actually <strong>in addition</strong> to the $1,000 we've already received, bringing out total up to $6,000 in AWS credits through the Stripe Atlas program.</p>
<p>For us this is a big injection. It basically funds our full application operations and lets us play around with putting money elsewhere - or just continuing to build features and mature without any kind of pressure.</p>
<h3 id="conclusion">Conclusion</h3>
<p>A couple of takeaways from the entire affair.</p>
<h4 id="1-send-that-one-last-email">1. Send that one last email</h4>
<p>Even if it seems like a bit much, or things are settled, just be sure you ask and give the other person a chance to help you in ways you can't predict. A hail mary "Is there anything I'm missing?" can sometimes land.</p>
<h4 id="2-stripe-is-truly-wonderful">2. Stripe is truly wonderful</h4>
<p>Stripe monitored the developer community enough to see our initial posts, proactively reached out to us, and then worked with AWS to ultimately get us a greater-than-even-promised payout. When people say Stripe is a company for developers, they often mean its great API or clear documentation, but this is I think one of the greatest testaments to their dev-first culture.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037963</guid>
            <pubDate>Mon, 03 Aug 2020 14:10:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Add video subtitles on the fly from plain text]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24037288">thread link</a>) | @011-video
<br/>
August 3, 2020 | https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/ | <a href="https://web.archive.org/web/*/https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2182">
	
	

	

	<div>
		<p><iframe title="How to Burn video subtitles on the fly from a plain text file" width="576" height="324" src="https://www.youtube.com/embed/voruErQe4JA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p><em><strong>How to add permanent subtitles into video without using SRT file ?</strong></em></p>
<ol>
<li>
<h6>If you opt for a big font size make sure&nbsp; to choose a larger screen&nbsp; <img src="https://011.video/wp-content/uploads/2020/01/pixel.png" alt="">&nbsp; to display the whole phrase every time you turn the mouse wheel</h6>
</li>
<li>
<h6>Upload a video&nbsp; <img src="https://011.video/images/uploadV2.png" alt="">&nbsp; from your device</h6>
</li>
<li>
<h6>Copy subtitles from any text editor.</h6>
</li>
<li><span><em>Notice that to be processed as subtitles the text must start with&nbsp; a star&nbsp; ‘&nbsp; *&nbsp; ‘&nbsp; and each phrase must end with a punctuation character&nbsp; &nbsp;:&nbsp; &nbsp;‘&nbsp; !&nbsp; ‘&nbsp; &nbsp;or&nbsp; &nbsp;‘ ?&nbsp; ‘&nbsp; or&nbsp; ‘&nbsp; . ‘</em></span></li>
<li>
<h6>Double click inside the canvas. As you can only move the subtitles vertically make sure to click on the left far if your text got long phrases</h6>
</li>
<li>
<h6>paste the subtitles text&nbsp; <img src="https://011.video/images/text.gif"> inside the input text field</h6>
</li>
<li>
<h6>Change the text color&nbsp; <img src="https://011.video/wp-content/uploads/2019/10/color.png" alt="" width="207" height="22"></h6>
</li>
<li>
<h6>Click few times on&nbsp; <img src="https://011.video/wp-content/uploads/2019/09/effet.png" alt="" width="35" height="35">&nbsp; to make the text size bigger.</h6>
</li>
<li>
<h6>Start to record&nbsp; <img src="https://011.video/images/on2.png" alt="">&nbsp; &nbsp; your video</h6>
</li>
<li>
<h6>As soon as the video begin turn the mouse wheel&nbsp; <img src="https://011.video/images/mouse.png"> &nbsp;before the speech start and you should see the message “Ready to display… Turn wheel again “</h6>
</li>
<li>
<h6>Turn the mouse wheel and you should see&nbsp; “let’s Add subtitles” message displayed.</h6>
</li>
<li>
<h6>Continue to turn the mouse wheel to display each phrase on the fly, one by one.</h6>
</li>
<li>
<h6>To make the subtitles easier to read try to move the cursor vertically close to the video character who speak</h6>
</li>
<li>
<h6>When the speech is over pause&nbsp; <img src="https://011.video/images/pause.png" alt=""> and download <img src="https://011.video/images/d2.png" alt=""> your video</h6>
</li>
</ol>
<p><em>Here is a “French video clip song subtitled with English lyrics translation”</em></p>
<p><iframe title="French video clip song subtitled with English lyrics translation" width="576" height="324" src="https://www.youtube.com/embed/hDV0GrTlYSA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<!-- Rate my Post Plugin -->			</div><!-- .entry-content -->
</article></div>]]>
            </description>
            <link>https://011.video/2020/08/03/burn-video-subtitles-on-the-fly-from-a-plain-text-file/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037288</guid>
            <pubDate>Mon, 03 Aug 2020 13:11:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[LakeFS – atomic, versioned data lake on object storage]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24037127">thread link</a>) | @pauldix
<br/>
August 3, 2020 | https://lakefs.io/2020/08/03/introducing-lakefs/ | <a href="https://web.archive.org/web/*/https://lakefs.io/2020/08/03/introducing-lakefs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1" itemtype="https://schema.org/CreativeWork" itemscope="itemscope"><div><div itemprop="text"><div><div><p><strong>TL;DR: </strong>we worked with an object-storage based data lake,  it’s an excellent data architecture but you have no systematic way of:</p><ul><li>Communicating between writers and readers (if you are thinking MetaStore as a solution, keep reading).</li><li>Avoiding the data Swamp everybody is warning you about.</li><li>Creating data pipelines that are resilient to changes in data and code</li></ul></div></div><p>We identified a way to provide a systematic solution for those pains by providing a data versioning schema over the data lake (if you are thinking Hudi or Delta lake, then no, we are not a format).</p><p><strong>The long version </strong>starts when we* finished a migration of our on-prem Hadoop clusters to AWS in mid 2017. Our architecture included a Kafka based ingest process of over hundreds of different sources, managed by the data collection group.  The data was saved to S3 and partitioned by arrival time. We had 4 different engineering groups on the consuming side:</p><ul><li><strong>Data science:</strong> converting raw data into estimations. The group consisted of data scientists, data engineering and DevOps teams to support a DAG of almost 1000 jobs running daily to produce our production data.</li><li><strong>Web application: </strong>mainly consuming the output of the data science group.</li><li><strong>Business intelligence:</strong> BI engineers and analysts, running counts on the amount of data we ingested by device, application, country, etc’,</li><li><strong>Professional services:</strong> analysts providing ad hoc reports to customers based on any data set that supports their analysis.</li></ul><p>We were happy. Finally throughput was not a problem, cost effectiveness of the storage (S3) was high, and with some <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/optimizing-performance.html">tweaks on prefixes</a>, throughput on read was satisfactory.</p><p>In retrospect we still think we made the right choice with this architecture. Before the migration we were dealing with “this is not feasible” issues and afterwards transitioned to the “this is not manageable” kind. And when data is your product, “this is not manageable” means production issues due to error prone operations.</p><figure><img src="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png" alt="" width="819" height="461" srcset="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png 960w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-300x169.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-768x432.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-24x14.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-36x20.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-48x27.png 48w" sizes="(max-width: 819px) 100vw, 819px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png" data-srcset="https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2.png 960w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-300x169.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-768x432.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-24x14.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-36x20.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Architecture-Slides-2-48x27.png 48w"><figcaption><em><span>Data Architecture </span></em></figcaption></figure><p>Here are some examples of the “this is not manageable” problem space:</p><h3>Fragile Writers and Readers: how to signal consumers the data is ready?</h3><p>Pain Point 1: The data science group starts running its <a href="https://airflow.apache.org/docs/stable/concepts.html#dags">DAG</a> only after data from several different sources (that were written independently) were complete. There’s no simple way for the writing teams to signal the completion of all writes to the reading teams. To work around this, we used time-based synchronization. At midnight, readers start consuming the data. Of course, this neglected late arrivals and in-flight writes. It was good enough most of the time, but a real pain when trying to reproduce results.</p><p>Pain Point 2: Consider the DAG of 1000 Spark jobs. Each job depends on several ancestor jobs’ output as its input. Basically the same as pain point #1, only with Airflow orchestrating a DAG of spark jobs. We used Spark SUCCESS files as a hook for Airflow. This doesn’t work in case the success file fails, or if for some reason someone intervenes manually.</p><p>Pain Point 3: In certain instances, correctness of the readers depends on a synchronization of several collections. For example, sometimes we needed the same data in two storage formats. ORC for AWS Athena, and Parquet for Spark. Another example: the professional services group have permission to access any data set serving their current ad hoc analysis. How do you make sure everything they access is synchronized to the same time/other parameters to maintain consistency? We used <a href="https://cwiki.apache.org/confluence/display/Hive/Home">Hive Metastore </a>as a workaround. Each write process updates the Metastore when completed, and the reader waiting on those inputs would wait until all updates were announced. In some cases it meant trading consistency for availability, but we weren’t the first to encounter this tradeoff :-).</p><p>A word about the workarounds: every time we introduce new data or analysis the solution needs to be implemented again. If you neglect to do so, you will suffer the consequences. There was no one systematic and easy solution for all these use-cases. In addition, each solution failed sometimes, causing a correctness issue later in the data pipeline.&nbsp;</p><h3>Data Swamp: how to ensure visibility and governance?</h3><p>Pain point 1: Many organizations avoid limiting data access using permissions as they want to democratize the data in the organization, and as long as regulation permits, allow data consumers to generate as much value as possible from the data. We hold this philosophy. The challenge is that there’s no systematic way to ensure isolation, i.e., to ensure no one changes the data while you’re using it. This is why copying is so common in object storage. The copy you create yourself usually has a very meaningful name, such as “Einat_final_final_V2”, or better yet “Prodcution_temp”. You don’t have lineage capabilities that indicate which data is behind that name, unless you enforce naming conventions…Good luck with that 🙂</p><p>Over time, your lake becomes a swamp, cost increases and you have no real control over your data from a compliance standpoint.</p><p>Pain point 2: If you are working to avoid the swamp, you’re probably running retention jobs to ensure stuff doesn’t get out of hand. Consider a home grown retention job running periodically over the lake. If it has a bug and  deletes valuable data, according to some logic it will start to spread across many collections. Although you have backups of all the objects in the lake,&nbsp; you don’t have a snapshot of the lake to revert to. Recovering fully from such an error may take weeks. Amazon’s S3 object-level versioning will not save you here.</p><h3>The need for Data CI/CD: how to ensure data quality?</h3><p>Pain point: Data is useless, unless it’s trustworthy. When your delivery is data, it is not enough to ensure the correctness of the code. It’s also critical to protect the properties of the data that you assumed you had when you developed the code. Now, remember the 1000 spark jobs orchestrated by Airflow that run every day?&nbsp; These run an algorithm, so each job includes assumptions on the data. If those assumptions are no longer valid, jobs may fail, or worse, the quality of the output data will decrease dramatically. Why is the second scenario worse? Because it’s harder to detect.&nbsp;</p><p>If we could run a job in isolation, test the results, and merge back automatically only after validating schema and data correctness, then it would be possible to identify issues earlier, putting us in a much better position to deliver quality data.</p><h3>We were thinking: Git interface with MVCC capabilities</h3><p>While each one of these challenges may have a workaround we can use, or a homegrown solution we can develop, there is no <strong><em>conceptual</em></strong> solution that simply makes the work manageable and hence resileant. We want a concept and a language that provides a solution for all of those challenges, and for the challenges that are yet to come.</p><p>On the one hand, database systems use transactions to provide systematic guarantees over the data. This is usually implemented using <a href="https://en.wikipedia.org/wiki/Multiversion_concurrency_control">Multi-Version Concurrency Control</a>.</p><p>On the other hand, there is a standard for code versioning. The Git terminology is a common language for developers to deal with versions of things. So we were thinking, if we build an MVCC management layer for Data Lakes, using a Git-like interface, we will have an intuitive way of getting the guarantees we want for our data lake, in the performance and reliability we need. The name “lakeFS” followed soon after.</p><h3>Introducing lakeFS: manageable and resilient data lake</h3><p><a href="http://www.lakefs.io/">lakeFS</a> is an open source platform that delivers resilience and manageability to your existing object-storage based data lake. With lakeFS you can build repeatable, atomic and versioned data lake operations – from complex ETL jobs to data science and analytics.</p><figure><img src="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png" alt="" width="743" height="258" srcset="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png 1024w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-300x104.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-768x267.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-24x8.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-36x12.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-48x17.png 48w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05.png 1161w" sizes="(max-width: 743px) 100vw, 743px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png" data-srcset="https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-1024x355.png 1024w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-300x104.png 300w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-768x267.png 768w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-24x8.png 24w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-36x12.png 36w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05-48x17.png 48w, https://lakefs.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-03-at-9.29.05.png 1161w"><figcaption><em><span>Resilience and manageability layer for object-storage based data lakes</span></em></figcaption></figure><p>Main features include:</p><ul><li><strong>Cross-Lake Isolation </strong>– Creating a lakeFS branch provides you with a snapshot of the entire lake at a given point in time (no copying involved). Guaranteeing that all reads from that branch will always return the same results.</li><li><strong>Object-level Consistency</strong> – Ensuring all operations within a branch are strongly consistent (read-after-write, list-after-write, read-after-delete, etc).</li><li><strong>Cross-collection Consistency</strong> – Branches provide writers consistency guarantees across different logical collections. Merging to “main” is only done after several datasets are created successfully.</li><li><strong>Versioning</strong> – Retain commits for a configurable duration, so readers can query data from the latest commit or any other point in time. Writers can atomically and safely rollback changes to previous versions.</li><li><strong>Data CI/CD</strong> – Define automated rules and tests mandatory to pass before committing or merging changes to data.</li></ul><p><span><a href="http://docs.lakefs.io/">Try it out</a>!  It will solve the challenges you have now, and will prevent you from running into undesired issues in the future. </span></p><p><em>* referring to the amazing R&amp;D team at <a href="https://www.similarweb.com/">SimilarWeb</a></em>. <em>We are proud to have been a part of before embarking on the lakeFS adventure</em></p></div><!-- .entry-content .clear --></div></article></div>]]>
            </description>
            <link>https://lakefs.io/2020/08/03/introducing-lakefs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24037127</guid>
            <pubDate>Mon, 03 Aug 2020 12:56:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analytics couldn’t get past 2013, it’s time to change that- A Manifesto]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24036653">thread link</a>) | @hockeystack
<br/>
August 3, 2020 | https://hockeystack.com/manifesto | <a href="https://web.archive.org/web/*/https://hockeystack.com/manifesto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hey founders,</p><p>I am sorry to talk harsh but someone&nbsp;<b>had</b>&nbsp;to do it.</p><p>We are hustlers. We love freedom and passionate about our businesses.</p><p>We are doing everything we can to solve a problem, make people happy, and earn their trust.</p><p>We are in this to <b>make a difference</b>, to <b>leave a legacy behind</b>, and <b>to be happy</b>.</p><p>Thanks to our businesses, thousands of people are solving a problem, a problem that has been a pain point before us.</p><p>I am so grateful for this amazing community, to the things I learned from it, and to the friends I made.</p><p>To grow our businesses we hustle a lot which is invaluable from my perspective.</p><p>Aside from all the hustle, we have to use analytics to grow and scale our businesses. But the world of user analytics is built upon false premises and unfullfilled assurances my hustler friends:</p><p><b>Hey google analytics users,</b> it’s 2020 and you still need to manually ga(‘send’) everything</p><p><b>Hey fathom/plausible/simple-analytics users</b>, it’s 2020 and you can only see your referrers on your dashboard</p><p><b>Hey everyone who needs analytics,</b> it’s 2020 and you still have to do everything manually. The tools you pay for don’t give you enough data or make you work for it. The tools you don’t pay for harvest each data point and send it to 3rd parties.</p><p>Huh, in the age of artificial intelligence and literal flying cars, Mixpanel can still write that 10-30 hours of development time to track 60 events is a huge achievement, and funnily, get away with it.</p><p>HockeyStack is an analytics tool <b>delivered to you by another hustler</b> who struggled to understand his data with other tools. Let me tell you the differences between other tools and HockeyStack in two parts:</p><p>HockeyStack is different from simple data tools because they don't analyze your data <b>in-depth</b>. It is the main reason why they call themselves 'simple'.</p><p>On the other hand, we call our dashboard <b>easy to understand</b> because we present an in-depth analysis of your data on an easy-to-understand dashboard.</p><p>Tools like Mixpanel, Hotjar are great. However, you need to set up .track() functions and need coding skills to analyze your data.</p><p>Then you also need to spend a lot of time on your dashboard to understand what is going on there.</p><p>I hope you find HockeyStack useful and each one of you can achieve the <b>surging growth</b> with it.</p><p>Greetings to all hustlers,</p><p><em>Michael</em></p><p><a href="https://hockeystack.com/">Get Started</a></p></div></div>]]>
            </description>
            <link>https://hockeystack.com/manifesto</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036653</guid>
            <pubDate>Mon, 03 Aug 2020 12:08:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dan Ariely and Irrational Comparison]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 40 (<a href="https://news.ycombinator.com/item?id=24036403">thread link</a>) | @brendancahill
<br/>
August 3, 2020 | https://brendancahill.io/brensblog/danariely | <a href="https://web.archive.org/web/*/https://brendancahill.io/brensblog/danariely">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-124866fbd20ff6e682de"><div><h4>Who is Dan Ariely?</h4><p>Dan Ariely is a Professor of Psychology and Behavioral Economics at Duke University whose writing merges psychology with economics. His book <a href="https://amzn.to/33pw3lh"><em>Predictably Irrational</em></a> explores why most of the smart decisions we think we make are actually quite irrational. Modern economics is based on the theory that the average person makes logical decisions. Ariely happily points out how wrong that notion is. </p><h4>Why Now?</h4><p>Comparison has always fascinated me. I grew up in Airmont, NY two minutes over the state line with Upper Saddle River, NJ. Since I didn’t like paying .50 more cents for gas, nor pumping it, I always got gas in NJ. Upper Saddle River is one of the wealthiest towns not only in America, but on the planet. The second you crossed the NY/NJ line it was like you were transported into an alternate reality where the worst car anyone drove was a BMW, every home a mansion and even the air smelled better (just kidding but I did wonder, if any town had the money to endlessly pump fabreeze into the air, they did). </p><p>When I crossed the NY/NJ state line back to my neighborhood of 3 bedroom raised ranches I felt poor by comparison. Then as a US Peace Corps Volunteer living in Ukraine in an ex-Soviet country, ridden with corruption, and the average salary being less than $100/mo I suddenly felt rich. Ukrainians were shocked that we owned two cars. That we had roads that worked. And that everyone was rich <em>to them. </em></p><h4>Why Comparison?</h4></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1596450590223_8104"><div><p>Ariely uses this illustration to make his point about comparison. Which orange circle <em>appears</em> bigger? You’d likely say the one on the right, at least at first. But, both circles are the same size. The only thing that’s changed is what you’re comparing them to. Comparison depends on context. </p><blockquote><p>“…we are always looking at the things around us in relation to others…We always compare jobs with jobs, vacations with vacations, lovers with lovers and wines with wines.”</p></blockquote><p>Comparison is a survival skill that’s served us well our first 50 million years as a species: You need to know your status in the tribe compared to others’ to ensure your own safety. You need to compare how deadly a particular tiger looks compared to other live tigers you’ve seen in wild to assess your threat level. You need to compare how someone looks to other angry people you’ve seen to avoid a bar fight. You need to compare a date to other people you’ve dated in the past to evaluate how they might be as a future spouse for you. You need to know how to compare how fast your car is going relative to all the other cars on the street to stay within the speed limit. </p><p><strong>Comparison does hijack our rationality, however. </strong></p><h4>The Economist</h4><p>Ariely was trying to figure out what decision people made when given these three options for a subscription to <em>The Economist</em>: </p><ul data-rte-list="default"><li><p>59/yr online only</p></li><li><p>125/yr print only</p></li><li><p>125/yr print and online together</p></li></ul><p>Out of 100 people here is how many chose which options:</p><ul data-rte-list="default"><li><p>59/yr online only (16)</p></li><li><p>125/yr print only (0)</p></li><li><p>125/yr print and online together (84)</p></li></ul><p>But, when Ariely removed the print only option, here is what people chose:</p><ul data-rte-list="default"><li><p>59/yr online only (68)</p></li><li><p>125/yr print and online together (32)</p></li></ul><p><em>As a business, you want to nudge as many people to the high-end of your sales as possible. So why were people opting for the online only? </em></p><p>It turns out it is easier to compare things that are alike than are not alike. By presenting people with not one but <em>two</em> print options, you’ve now made it easier for them to compare two options that you, as a business, want them to focus on. The mind has now written-off the online only option because that is the hardest option to compare to the other two. </p><p>Inside the mind of your potential customer is now a simple question: What’s better? Print only or print AND an online subscription? Everyone in the first experiment opted for the “print + online” because isn’t print plus a little something extra better? </p><p><strong>We Can’t Make Decisions In A Vacuum</strong></p><p>The second case study Ariely looks at is <a href="https://journals.sagepub.com/doi/pdf/10.2307/41166755">Williams-Sonoma’s inability to sell a $275.00 bread baker</a>. Their marketing team finally figured out that if they created a second, bigger and even more expensive bread baker placed <em>next to</em> the $275.00 dollar one, their sales would take off. And they did. </p><blockquote><p>“…people didn’t have to make their decision in a vacuum. They could say: “Well, I don’t know much about bread makers, but I do know that if I were to buy one, I’d rather have the smaller one for less money.”</p></blockquote><p>Ariely then goes on to joke that if you want to have better luck socially finding someone to date you, you should find a decoy friend of similar physical characteristics but who is slightly less attractive than you. Although the morality of this is questionable. </p><p>If you are a business, the takeaway is simple: to make more profit, create a favorable context for the product you want your customer to buy. Create an ultra-premium ridiculously high-priced product that when placed next to the product you really want to sell, makes its price not seem so bad. </p><p>Tesla knows not everyone is paying $100K + for their Cyber Truck, but they do know that by having their ridiculous premium products, it makes the $60K price tag for their “lower models” not seem so crazy. </p><p><strong>Place vs. Person</strong></p><p>I have some of the best friendships I’ve had from my former football teammates. We go through experiences, games, high and lows like few others friend groups might. But would we all have been friends were it not for football? How about military veterans who are bonded together in combat - were it not for that experience, would they have chosen to be friends? </p><p>Ariely uses the example of meeting a fellow American in a foreign place and finding an uncanny connection in an airport. He met one fellow American overseas:</p><blockquote><p>…as cultural outsiders we were each other’s best alternative for companionships. But once we returned home to our beloved American families and friends, thebasis for comparison switched back to “normal” mode. </p></blockquote><p>Would that foreign exchange student you dates in high school have been as “cool” or “exotic” had they been from Germantown, PA instead of Germany? Was that experience teaching overseas in Peace Corps really <em>that</em> cool or am I just assigning extra romanticism to it because I was an “outsider” in a foreign land?</p><h4>Takeaways</h4><p>We’re very smart, but we’re also very irrational as people. We’d like to think logic and rationality governs most of our lives but Ariely has a knack for showing us just how reliant we are upon split second and irrational comparisons to the available yet limited information we have around us. </p><p>Morally speaking, as a business owner or person you have a duty to make decisions now with this comparison fallability in mind. While yes, you can structure your products in a way to extract <em>more</em> profit than normal from your customers, you need to do this only when you truly feel like that high-end product you’re directing them to is actually giving them more value. </p><p>Personally, don’t find the most repulsive personality to take out on a double date hoping that it makes you look good. This might even back fire since your double date might end up <em>comparing you</em> to the company you hang out with and irrationally judge you just as repulsive. </p><p>Comparison is a force of nature that can’t always be controlled, but it can be guided. Ariely shows us how. </p><p>Bren</p><p>P.S. Here is a fun video by Dan at a Ted Talk</p></div></div></div>]]>
            </description>
            <link>https://brendancahill.io/brensblog/danariely</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036403</guid>
            <pubDate>Mon, 03 Aug 2020 11:29:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL beginner guide]]>
            </title>
            <description>
<![CDATA[
Score 236 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24036132">thread link</a>) | @lukasbar
<br/>
August 3, 2020 | https://knowledgepill.it/posts/postgresql-basics-guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql-basics-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2 id="configure-remote-access---listen-address">Configure remote access - listen address</h2>
<p>By default after installation and creating database cluster PostgreSQL will listen only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP’s available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>##------------------------------------------------------------------------------</span>
<span>## CONNECTIONS AND AUTHENTICATION</span>
<span>##------------------------------------------------------------------------------</span>

<span>## - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span>## what IP address(es) to listen on;</span>
                                        <span>## comma-separated list of addresses;</span>
                                        <span>## defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span>## systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div><h2 id="configure-remote-access---pg_hbaconf">Configure remote access - pg_hba.conf</h2>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span>## TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span>## "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span>## IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span>## IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don’t want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h3 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h3>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span>## Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div><h2 id="connecting-to-postgresql">Connecting to PostgreSQL</h2>
<h3 id="local-from-server">Local from server</h3>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h3 id="remote-machine">Remote machine</h3>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span><span>##</span>
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h3 id="check-connected-database">Check connected database</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-current-user">Check current user</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-postgresql-version">Check PostgreSQL version</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-connection-info">Check connection info</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div><h2 id="executing-commands-from-shell">Executing commands from shell</h2>
<h3 id="execute-single-command-from-shell">Execute single command from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="exacute-sql-script-from-shell">Exacute sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h3 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>
<h3 id="check-all-available-metacommands">Check all available metacommands</h3>
<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h3 id="list-objects-in-psql">List objects in psql</h3>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql-basics-guide/">https://knowledgepill.it/posts/postgresql-basics-guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql-basics-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24036132</guid>
            <pubDate>Mon, 03 Aug 2020 10:40:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The UX of Lego Interface Panels]]>
            </title>
            <description>
<![CDATA[
Score 396 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24035866">thread link</a>) | @george_cave
<br/>
August 3, 2020 | https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/ | <a href="https://web.archive.org/web/*/https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

   
   <time>August 2020</time>

   

   

   <p>Piloting an <a href="https://www.lego.com/en-de/product/ocean-exploration-ship-60266">ocean exploration ship</a> or <a href="https://www.lego.com/en-de/product/mars-research-shuttle-60226">Martian research shuttle</a> is serious business. Let’s hope the control panel is up to scratch. Two studs wide and angled at 45°, the ubiquitous “2x2 decorated slope” is a LEGO minifigure’s interface to the world.</p>

<p>These iconic, low-resolution designs are the perfect tool to learn the basics of physical interface design. Armed with 52 different bricks, let’s see what they can teach us about the design, layout and organisation of complex interfaces.</p>

<p>Welcome to the world of LEGO UX design.</p>

<p><img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/interfaces.jpg" alt="LEGO interfaces"></p>

<h2 id="organised-chaos">Organised chaos</h2>

<p>At a glance, the variety of these designs can be overwhelming, but it’s clear that some of these interfaces look far more chaotic than others. Most interfaces in our world contain a blend of digital screens and analog inputs like switches and dials. These LEGO panels are no different.</p>

<p>Plotting the panels across these two axes reveals a few different clusters. Screens with an accompanying row of buttons sit in the top left. A small cluster of very organised switch panels lies to the far right. The centre bottom is occupied by some wild concepts that are hard to understand, even after several glances.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/positioning.jpg" alt="Design positioning with LEGO, in LEGO">
    <figcaption>Design positioning with LEGO, in LEGO</figcaption>
  </figure>

<p>Designing a complex machine interface is a juggling act of many different factors from ergonomics to engineering. But we can break down the problem into two key questions:</p>

<ol>
  <li>How can we <em>differentiate</em> between the function of different inputs?</li>
  <li>How can we <em>organise</em> the many inputs and outputs so that we understand how they relate to each other?</li>
</ol>

<p>Let’s take a deeper look at tackling these two challenges in LEGO.</p>

<h2 id="differentiating-inputs">Differentiating inputs</h2>

<p>What could cause 400 WWII pilots to raise the landing gear on their B-17 bomber just before touchdown? Catastrophic pilot error, or something more fundamental?</p>

<p>It was the psychologist Alphonsis Chapanis who first suggested that the high rate of crash landings might be the fault of poor interface design. The adjacent landing gear and flap control knobs were identically shaped. The pilots never stood a chance.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/landing.jpg" alt="B-17 belly landing, and the shape coding that helped to irradiate the problem. Source: Wikipedia">
    <figcaption>B-17 belly landing, and the shape coding that helped to irradiate the problem. Source: Wikipedia</figcaption>
  </figure>

<p>His temporary solution was to glue differently shaped strips of rubber to each switch, enabling blind operation by touch alone. This gave rise to the idea of shape coding and a system of differentiation still being followed in aircraft cockpits today.</p>

<p>We can compare the three interfaces below to see this in action. Ignore the overall layout, it’s the differences between individual switches that matter here. Imagine trying to feel for one of these buttons without looking. The left panel (“Slope 45 2 x 2 with 12 Buttons”) would require careful hand-eye co-ordination. The right panel (“Aircraft Multiple Flight Controls”) clearly distinguishes between the throttle (large, linear vertical movement), toggle switches (round vertical flick) and the push buttons (square push-in).</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/differentiation.jpg" alt="Left to right: terrible, poor and better input differentiation">
    <figcaption>Left to right: terrible, poor and better input differentiation</figcaption>
  </figure>

<p>Differentiation like this is a still a very real problem today. In 2015, <a href="https://money.cnn.com/2015/01/06/autos/ford-push-button-ignition-recall/index.html">Ford recalled 13,500 Lincoln SUVs</a> because drivers speeding down the motorway were mistakenly shutting off the engine when they tried to activate sport mode. See if you can spot why:</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/ford-lincoln.jpg" alt="Ford Lincoln MKC before the Engine start/stop button was moved. Source: CNN">
    <figcaption>Ford Lincoln MKC before the Engine start/stop button was moved. Source: CNN</figcaption>
  </figure>

<p>Shape coding is one approach to differentiation, but there are many others. Colour coding is perhaps the only one to break into our everyday vocabulary, but we can add four more: size, texture, position and operation coding. Together these six are our allies in the design of error-proof interfaces.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/codings.jpg" alt="The 6 basic codings. Notice that many of these examples actually combine multiple codings in one.">
    <figcaption>The 6 basic codings. Notice that many of these examples actually combine multiple codings in one.</figcaption>
  </figure>

<p>Size, shape and colour-coding are the fundamentals: quick-wins that can fix a lot of interface problems. Texture is also a great differentiator for blind operation, particularly on small dials requiring precise control.</p>

<p>Position-coding is seemingly straightforward but is often under used. Products with a clear default ergonomic position (like binoculars or a gaming console) can exploit the natural position of the hand to differentiate between primary and secondary actions.</p>

<p>Finally, operation-coding ascribes different types of movements (like a twist or vertical slide) to different inputs. This can be immensely powerful when the switch motion reinforces the operation behind it, e.g. a crane lever which raises the crane when the lever is raised.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/lego-codings.jpg" alt="The six different codings in use in the LEGO interfaces: size, shape, colour, texture, position, operation">
    <figcaption>The six different codings in use in the LEGO interfaces: size, shape, colour, texture, position, operation</figcaption>
  </figure>

<p>Differentiation is a good first step that will avoid confusion between adjacent switches. But its only with organisation that we can create a clear and accurate mental model of the interface for the user.</p>

<h2 id="organising-inputs">Organising inputs</h2>

<p>Compare the three panels below. Identical layouts, but the blue one is much clearer than the white. This is the <a href="https://www.usertesting.com/blog/gestalt-principles">gestalt principles</a> at work, identifying related items with a common region.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/gestalt.jpg" alt="Basic differentiation by clustering">
    <figcaption>Basic differentiation by clustering</figcaption>
  </figure>

<p>Easy. But how are you going to decide which inputs to cluster together?</p>

<p>I like to use <a href="http://blog.presentandcorrect.com/27986-2">Soviet control panels</a> as a starting point. These beautiful walls of nonsensical dials and levers are brought to life when arranged in a giant factory schematic.  It would be hard to find a more literal organisation of the information.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/soviet-control-panels.jpg" alt="Soviet control panels in action. Source: Present and Correct">
    <figcaption>Soviet control panels in action. Source: Present and Correct</figcaption>
  </figure>

<p>These panels are what I’d called a consolidated interface. Every piece of input and feedback has been moved onto the same panel. This is the approach that <a href="https://www.thedrive.com/news/33847/the-defunct-dyson-evs-steering-wheel-looks-like-it-was-made-by-vacuum-cleaner-people">Dyson took with their car</a>. Now imagine the opposite, moving each of those lights and switches to the actual location of that valve in the factory. Sounds ludicrous, but these <a href="https://deeptread.com/blog/2016/11/21/audi-tt-air-vent-design">air vents in the Audi TT</a> show that this distributed approach can also be a great win for user experience. I wrote a lot more about these <a href="https://www.designedbycave.co.uk/2018/Interfaces/">distributed interfaces last year</a>.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/distributed.jpg" alt="Lego vehicle dashboard: distributed (left) vs. consolidated (right)">
    <figcaption>Lego vehicle dashboard: distributed (left) vs. consolidated (right)</figcaption>
  </figure>

<p>Back to the Soviet factories. Those interface panels were great for answering the question “does this valve let water into tank Б?”. But they’re very poor for answering “are all water valves closed?” or “where are all the switches I need to prepare for the shift changeover?”.</p>

<p>LEGO use the Soviet schematic approach for their <a href="https://www.bricklink.com/catalogItemIn.asp?P=3298pb005&amp;in=S">fantasy</a> <a href="https://www.bricklink.com/catalogItemIn.asp?P=3298px10&amp;in=S">orientated</a> designs, because schematics are superb at providing a mental model of the inner workings of an alien system. However for everyday use, there are some other approaches that work better.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/alien-interfaces.jpg" alt="LEGO Insectoid and UFO interfaces. I wonder what these buttons actually do?">
    <figcaption>LEGO Insectoid and UFO interfaces. I wonder what these buttons actually do?</figcaption>
  </figure>

<p><strong>Feature</strong> based organisation is the most common, perhaps even the “default” design philosophy. Group together all the inputs and outputs for each product feature. This <a href="https://www.cambridgeconsultants.com/press-releases/building-life-saving-ventilator-lightning-speed">COVID-19 ventilator from Cambridge Consultants</a> is a wonderful example but we also see this a lot in cars, with a cluster of switches for the airflow control and all of the lights on one control stick.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/covid-ventilator.jpg" alt="COVID-19 ventilator by Cambridge Consultants with clear feature-based organisation. Source: Cambridge Consultants">
    <figcaption>COVID-19 ventilator by Cambridge Consultants with clear feature-based organisation. Source: Cambridge Consultants</figcaption>
  </figure>

<p>Organising by <strong>operation</strong> means putting all the switches that function in a certain way in the same place. I’ve no idea what all the valves in the picture below do, but I bet they don’t all open things that relate to each other. Anytime you see a row of switches that look and function the same, but control disparate parts of the system, you’ve come across organisation by operation.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/valves.jpg" alt="Source: Twitter @aglushko">
    <figcaption>Source: Twitter @aglushko</figcaption>
  </figure>

<p>Today most interfaces are effectively <a href="https://en.wikipedia.org/wiki/Fly-by-wire">fly-by-wire</a>, but historically the levers that you pulled in, say, a tractor cabin would literally move the hydraulic pistons beneath the seat to a new position. Routing all these different electrical, mechanical and hydraulic systems efficiently can severely compromise your interface clustering, leading to organisation by <strong>technology</strong>.</p>

<p>The modern equivalent of this is surprisingly common. Any touchscreen with buttons by the side exhibits this technology-based split. In a <a href="https://www.chrisharrison.net/index.php/Research/PneumaticDisplays">future</a> <a href="https://vimeo.com/343640141">world</a>, SpaceX might embed <a href="https://www.space.com/spacex-crew-dragon-touchscreen-astronaut-thoughts.html">these physical controls</a> right inside the screen next to the information they affect, but for now they sit awkwardly by the side as if nothing is wrong.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/spacex-dragon.jpg" alt="Bob and Doug in the SpaceX Dragon capsule. Source: SpaceX">
    <figcaption>Bob and Doug in the SpaceX Dragon capsule. Source: SpaceX</figcaption>
  </figure>

<p>In LEGO we find the feature based organisation in the “Monitor with -19° pattern”. Two clear clusters, perhaps one for temperature control and another for vital signs monitoring. In the second panel below, I don’t know what all those switches do, but they seem to be clustered based on their operation, not because of what they will operate.</p>

<p>There are many LEGO panels with a technology split like the SpaceX Dragon capsule, but I like to imagine that this early 90s police control unit was forced to divide the audio and video playback because the newer tape reel technology was incompatible with the older analog phone line system. This is organisation by technology in action.</p>

<figure>
    <img src="https://www.designedbycave.co.uk/images/posts/2020-08-LEGO-Interface-UX/organisation.jpg" alt="L-to-R: organisation by feature, operation, technology and use case">
    <figcaption>L-to-R: organisation by feature, operation, technology and use case</figcaption>
  </figure>

<p>All of our approaches so far: organisation by features, operation or technology, have been grounded in properties of the system, not of the user. Organisation by <strong>use-case</strong> is the antidote to this, a clustering based on the daily routines and tasks of the user.</p>

<p>Imagine arriving for work each day at the LEGO body scanner factory. Grouping the switches by task (prepare machine, load body, process scan…) would mean splitting up the radiation and scanner buttons into many different regions. More complex for the computer, but more streamlined for the operator. As the designer, only you and your users will be the judge of what works best.</p>

<h2 id="but-george-which-is-the-best-interface">But George, which is the best interface?</h2>

<p>I often say there’s no such thing as the best interface, but …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/">https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/</a></em></p>]]>
            </description>
            <link>https://www.designedbycave.co.uk/2020/LEGO-Interface-UX/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035866</guid>
            <pubDate>Mon, 03 Aug 2020 09:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Interactive JavaScript Slide Rule]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24035379">thread link</a>) | @lebski88
<br/>
August 3, 2020 | https://adit.co.uk/sliderulev2.html | <a href="https://web.archive.org/web/*/https://adit.co.uk/sliderulev2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="dvText">
        <p>
            The rule cursor and central slide can be positioned using a mouse. Fine adjustment can be achieved using the keyboard left and right arrow buttons.
            The keyboard keys move the cursor or slide depending upon which had last been clicked or adjusted.
        </p>
        <p>
            The left hand display below the rule (“A on B” etc) shows the slide position. The central display shows the cursor position over each of the slide scales.
        </p>
        <p>
            Why is the cursor window a bit yellow? To find out, <a href="https://javascriptfunandgames.blogspot.com/2020/06/my-interactive-slide-rule.html" target="_blank">check my blog where some of the design decisions</a> that went into constructing this rule are described. Thats also
            a good place to comment if you come across any gross bugs (bugs are likely of course but so are edge cases that maybe should be treated kindly).
        </p>
        <h3>The Calculator</h3>
        <p>
            You can try using the virtual calculator just like a normal one although the choice of functions and the absence of plus and minus buttons might be a 
            little eccentric. Please remember though that calculations performed on a slide rule will not always be as accurate as those performed on an electronic 
            calculator. Results can and will differ.
        </p>
        <p>
            You can enter values using the “buttons” or from your keyboard (including the numeric keypad if “Num Lock” is set. The sum is executed by the virtual 
            slide rule and the result read back from the slide rule. The division function is executed in two stages with a 1.5 second delay between them. 
            An experienced slide rule user would probably skip the second stage as the result can be read from the end of the slider.
        </p>
        <p>
            You can calculate the tangent of angles (in degrees) between 6° and 84°. The S (sine) scale is also used to calculate cosines – both in the range 1° to 90°.
        </p>
        <h3>Background</h3>
        <p>
            I was looking through some bits and bobs that came from a draw in my Father’s house when it was being cleared for sale.
            One of the items was a slide rule and it was found alongside the early “Sinclair Executive” calculator that replaced it.
            It is small (nominally 6" probably) and pretty similar to the one I remember buying with my first student grant money in
            the very late 1960s when they were still pretty much the state of the art for calculators. Around that time though, I did
            come into contact with an <a href="https://en.wikipedia.org/wiki/Sumlock_ANITA_calculator" target="_blank">electronic Anita calculator</a> but they were staggeringly expensive and you could hardly slip one
            in your pocket or even carry one very far.
        </p>
        <p>
            The Sinclair Executive calculator came out in 1972 and cost £79.95 (over £1000 in 2020 money) and I probably paid £5 or £6 for the
            slide rule three or four years before that (still an appreciable cost that needed some internal debate to justify).
        </p>
        <p>
            The slide rule was invented sometime between 1620 and 1630 with new functions developed and added over time until the device became the tool
            of choice for the developing field of engineering.
        </p>
        <p>
            How do they work? It is pretty easy to see how two rulers could be used to do simple addition and subtraction. We can try adding 3 and 8.
        </p>
        <p><img src="https://adit.co.uk/Images/add3to8.png"></p><p>
            We position the start on the lower ruler’s scale at one of the two values (in this case 3) and read off the sum of 3 and 8 on the scale of the upper ruler (see the red line).
            It should also be obvious that the same positioning could be used to calculate 11 minus 8 or any other pair of values on the two ruler scales.
        </p>
        <div><p>
            Now such a simple mechanical device for adding two numbers together would not be terribly useful even if they were decimal fractions such as 3.4 and 8.7
            which would be easy to do with the rulers shown above. However being able to multiply (say) 1.65 by 3.45 would be more challenging mental arithmetic for most.
            When I was at school, we used logarithms for such calculations.
            </p><p>
            The logarithm (base 10) of a number is the number expressed as a power of 10.
            </p><p>
            1.65 = 10<sup>0.2175</sup>  so log(1.65) = 0.2175
            <br>
            3.45 = 10<sup>0.5378</sup> so log(3.45) = 0.5378
            <br>
            0.5378 + 0.2175 = 0.7553 (sum the logs)
            <br>
            10<sup>0.7553</sup> = 5.6925 which is the product of 1.65 and 3.45.
            </p><p>
            Thus simple addition can be used to multiply two decimal fractions expressed as logarithms.
        </p></div>
        <p>
            Fortunately, when I was at school, we did not need to calculate these powers of 10 – we were issued with books of tables for looking them up. 
            The tables included a host of trigonometric tables as well as the vital “antilogarithms” needed to establish that 10<sup>0.7553</sup> was 5.69 
            (which was about as accurate as the ones I had could get.
        </p>
        <p>
            If instead of having pages of tables we were to draw a logarithmic scale on a pair or rulers instead of the linear scale illustrated above we could 
            use them to multiply two values by adding the logs. Indeed we could also do division by subtracting one logarithmic scale position from another. 
            So, what does a logarithmic scale look like in action?
        </p>
        <p><img src="https://adit.co.uk/Images/logRules.png"></p><p>
            You will notice that as the values increase (from 1 to 10 in this instance) the distance between the log of those values decreases. 
            You can probably also see that two rules with logarithmic scales can be used to make our calculation (1.65 x 3.45). Slide rules were fast and accurate enough for most purposes.
        </p>
        <p>
            Why does the log scale start at 1? Well ten to the power of zero is 1 and zero is a good place to start. In fact any number to the power of zero is 1.
        </p>
    </div></div>]]>
            </description>
            <link>https://adit.co.uk/sliderulev2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035379</guid>
            <pubDate>Mon, 03 Aug 2020 08:39:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[United Airlines plans to resume service on more than 25 international routes]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 44 (<a href="https://news.ycombinator.com/item?id=24035215">thread link</a>) | @cockpitherald
<br/>
August 3, 2020 | https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-scaled.jpeg" data-caption="Photo: United Airlines"><img width="696" height="463" src="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-696x463.jpeg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-696x463.jpeg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-300x200.jpeg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1024x682.jpeg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-768x511.jpeg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1536x1022.jpeg 1536w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-2048x1363.jpeg 2048w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1068x711.jpeg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-1920x1278.jpeg 1920w, https://kokpitherald.com/wp-content/uploads/2020/08/28D38206-5358-4F26-B2C3-3F765BFECCB3-631x420.jpeg 631w" sizes="(max-width: 696px) 100vw, 696px" alt="" title="United Airlines Boeing 777-300"></a><figcaption>Photo: United Airlines</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p>United Airlines today announced it plans to resume service on nearly 30 international routes in September, including flights to Asia, India, Australia, Israel and Latin America and to continue to add ways to visit popular vacation destinations in the Caribbean, Hawaii and Mexico. The <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">airline</a> intends to fly 37% of its overall schedule in September as compared to the same period last year and is a 4% increase in capacity compared to what is planned for August 2020. United is also extending its waiver of change fees and award redeposit fees for reservations through August 31.&nbsp;</p>



<p>“We continue to be realistic in our approach to building back our international and domestic schedules by closely monitoring customer demand and flying where people want to go,” said Patrick Quayle, United’s vice president of International Network and Alliances. “In September, we’re adding even more options for leisure travelers or those who want to visit friends and relatives, whether that’s within the United States or around the world.”&nbsp;</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p>Domestically, United intends to fly 40% of its schedule. The airline plans to add more than 40 daily flights on 48 routes to locations including Austin, Texas; Colorado Springs, Colorado; and Santa Barbara, California. Additionally, United plans to resume service between the U.S. mainland and Hilo and Kauai and increase flying to Honolulu, Kona and Maui in the Hawaiian Islands.</p>



<p>Internationally, <a href="https://hub.united.com/2020-07-31-united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september-2646851493.html" target="_blank" aria-label="United  (opens in a new tab)" rel="noreferrer noopener">United </a>intends to fly 30% of its schedule as compared to September 2019, which is a 5-point increase compared to August. The airline expects to resume service on 20 routes in Latin America and the Caribbean, including to popular vacation destinations like Cabo San Lucas and Puerto Vallarta in Mexico and to San Jose and Liberia in Costa Rica. United intends to begin new nonstop service between Chicago and Tel Aviv and resume eight routes in the Atlantic and Pacific, including the return of European service from Houston with flights to Amsterdam and Frankfurt.</p>



<p><strong>U.S. Domestic&nbsp;</strong></p>



<p>Travelers in search of more socially distant vacation options like beach, mountain and national park destinations will continue to see opportunities for leisure travel including:&nbsp;</p>



<ul><li>Increasing opportunities to connect to more than 800 flights from United’s mid-continental hubs in Chicago, Denver and Houston.&nbsp;</li><li>Adding more than 40 daily flights on more than 48 routes across the United States.&nbsp;</li><li>Resuming service between the U.S. mainland and Hilo and Kauai in Hawaii&nbsp;</li><li>Increasing service between the U.S. mainland and Honolulu, Kona and Maui.</li></ul>



<p><strong>Atlantic</strong></p>



<p>Internationally, United is scheduled to fly 30% of its schedule in September compared to the same period in 2019. Across the Atlantic, United plans to offer customers more opportunities to get to Europe and beyond from Chicago, Houston, New York/Newark, and San Francisco. Highlights include:&nbsp;</p>



<ul><li>Launching brand-new service between Chicago and Tel Aviv&nbsp;<em>(subject to government approval)</em></li><li>Resuming service between Chicago and Amsterdam.&nbsp;</li><li>Resuming service between Houston and Amsterdam and Frankfurt.&nbsp;</li><li>Resuming service between San Francisco and Munich.&nbsp;</li><li>Increasing to daily service between Chicago and Frankfurt, and between San Francisco and London.&nbsp;</li><li>Continuing service between the United States and Delhi and Mumbai&nbsp;<em>(subject to government approval)</em>.&nbsp;</li></ul>



<p><strong>Pacific</strong></p>



<p>Across the Pacific in September, United plans to re-start three-times-weekly service between Los Angeles and Sydney and passenger service between Chicago and Hong Kong&nbsp;<em>(subject to government approval).</em></p>



<p><strong>Latin America/Caribbean</strong></p>



<p>Throughout Latin America and the Caribbean, United is expanding across each region by adding 20 new routes for September. Highlights of United’s schedule include:&nbsp;</p>



<ul><li>Starting new service between San Juan, Puerto Rico and Chicago and Washington-Dulles.&nbsp;</li><li>Resuming service from Houston to Aguascalientes, Tampico and Veracruz in Mexico.&nbsp;</li><li>Starting new service between New York/Newark and St. Thomas.&nbsp;</li><li>Resuming service between Costa Rica and Houston and New York/Newark.&nbsp;</li><li>Adding more ways to get to Puerto Vallarta, Mexico, including resuming service from Chicago, Denver and Los Angeles.&nbsp;</li><li>Resuming service between Denver and Cabo San Lucas.&nbsp;</li><li>Increasing the number of flights between Houston and Quito, Ecuador.</li></ul>



<figure><img src="https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1024x681.jpg" alt="united airlines" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1024x681.jpg 1024w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-300x199.jpg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-768x510.jpg 768w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-696x463.jpg 696w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-1068x710.jpg 1068w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner-632x420.jpg 632w, https://kokpitherald.com/wp-content/uploads/2020/08/United-Airlines-Boeing-787-Dreamliner.jpg 1500w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>The <a href="https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">airline</a> intends to fly 37% of its overall schedule in September as compared to the same period last year and is a 4% increase in capacity compared to what is planned for August 2020. United is also extending its waiver of change fees and award redeposit fees for reservations through August 31.&nbsp;Photo: United Airlines</figcaption></figure>



<h2>United Airlines Committed to Ensuring a Safe Journey</h2>



<p>United is committed to putting health and safety at the forefront of every customer’s journey, with the goal of delivering an industry-leading standard of cleanliness through its United CleanPlus program. United has teamed up with Clorox and Cleveland Clinic to redefine cleaning and health safety procedures from check-in to landing and has implemented more than a dozen new policies, protocols and innovations designed with the safety of customers and employees in mind, including:</p>



<ul><li>Requiring all travelers – including crew members – to wear face coverings and potentially revoking travel privileges for customers who do not follow these requirements, as underscored in a&nbsp;<a target="_blank" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2872972-1&amp;h=4181856673&amp;u=https%3A%2F%2Fwww.dropbox.com%2Fsh%2Fj9pc7ehab8xontd%2FAAAJJtjzuejK3-hhWY9DP50qa%2FScott%2520Kirby%2520Mask%2520Message%2F16x9%3Fdl%3D0%26preview%3D2020-06-17_UA_ScottMaskMessage_16x9_v2020-06-25-1_CP-ONLY_SRT.mp4%26subfolder_nav_tracking%3D1&amp;a=recent+video" rel="noreferrer noopener">recent video</a>&nbsp;from United CEO Scott Kirby.&nbsp;</li><li>Using state-of-the-art high-efficiency (HEPA) filters on most United mainline aircraft to circulate air and remove up to 99.97% of airborne particles.&nbsp;</li><li>Using electrostatic spraying on all mainline aircraft before departure for enhanced cabin sanitation.&nbsp;</li><li>Adding a step to the check-in process, based on a recommendation from the Cleveland Clinic, requiring customers to acknowledge they do not have symptoms for COVID-19 and agree to follow our policies, including wearing a mask on board.&nbsp;</li><li>Offering customers a touchless baggage check-in experience at more than 200 airports across the United States; United is the first and only U.S. airline to make this technology available.</li></ul>



<p>For more details on all the ways United is helping keep customers safe during their journey, please visit&nbsp;<a target="_blank" href="https://c212.net/c/link/?t=0&amp;l=en&amp;o=2872972-1&amp;h=1790932703&amp;u=https%3A%2F%2Fwww.united.com%2Fual%2Fen%2Fus%2Ffly%2Ftravel%2Funited-cleanplus.html&amp;a=united.com%2Fcleanplus" rel="noreferrer noopener">united.com/cleanplus</a>.</p>



<h3>About United Airlines</h3>



<p>United’s shared purpose is “Connecting People. Uniting the World.” For more information, visit united.com, follow @United on Twitter and Instagram or connect on Facebook. The common stock of United’s parent, United Airlines Holdings, Inc., is traded on the Nasdaq under the symbol “UAL”.</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035215</guid>
            <pubDate>Mon, 03 Aug 2020 08:08:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[KLM to Lay Off 5k Employees Due to Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 88 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24035132">thread link</a>) | @cockpitherald
<br/>
August 3, 2020 | https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/ | <a href="https://web.archive.org/web/*/https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg" data-caption="A total of 4,500 to 5,000 positions in the entire KLM Group will cease to exist.

Photo: KLM
"><img width="500" height="375" src="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B.jpeg 500w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-300x225.jpeg 300w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-80x60.jpeg 80w, https://kokpitherald.com/wp-content/uploads/2020/08/51225945-56BB-4A94-A791-264925C3315B-265x198.jpeg 265w" sizes="(max-width: 500px) 100vw, 500px" alt="" title="KLM pliots and cabin crew"></a><figcaption>A total of 4,500 to 5,000 positions in the entire KLM Group will cease to exist.

Photo: KLM
</figcaption></figure></div>
            <!-- content -->
 <!-- A generated by theme --> 



 <!-- end A --> 


<p><strong>KLM is in the throes of a crisis of unprecedented magnitude. Since the outbreak of the COVID-19 virus at the start of 2020, numerous measures have already been taken to deal with the current circumstances. Expectations are that the road to recovery will be long and fraught with uncertainty. This means that KLM’s structure and size must be rigorously adjusted even further in the years ahead. Consequently, a total of 4,500 to 5,000 positions in the entire KLM Group (expressed in FTEs) will cease to exist.</strong></p>



<p>In the wake of the coronavirus outbreak, KLM gradually began reducing the size of its network in February to operate less than 10% of its original number of <a href="https://kokpitherald.com/united-airlines-plans-to-resume-service-on-more-than-25-international-routes-in-september/">flights</a> by the start of April. In the second quarter, only 15% of the original number of flights were operated. In July, 30% of the original flights were operated and load factors are lagging behind. As a result, while the network is again being gradually and carefully expanded, revenues are lagging far behind.</p>
 <!-- A generated by theme --> 



 <!-- end A --> 





<p>Prospects for the airline industry – and KLM in particular – are uncertain. Different countries are now beginning to tighten their more relaxed travel restrictions. This is making customers more cautious when it comes to booking a ticket. In all scenarios, demand is only expected to recover by 2023 or 2024 at the earliest. The degree and speed of recovery will depend on a number of factors including the development of the virus, economic recovery and customer travel behaviour.</p>



<h2>KLM Adjusting to the New Reality</h2>



<p>Government support in the form of a direct state loan and guaranteed bank credit facilities amounting to a maximum of €3.4 billion will enable KLM to navigate the crisis in the forthcoming period. <a href="https://news.klm.com/klm-adapts-organisation-further-due-to-covid-19-crisis/" target="_blank" aria-label="KLM (opens in a new tab)" rel="noreferrer noopener">KLM</a> is extremely grateful for this support provided by means of the loan. In order to guarantee KLM’s existence in the longer term, the airline must adapt its size to the new reality. KLM therefore finds itself compelled to reduce its workforce down to the number needed for the planned operation in 2021/2022. Of the current total of 33,000 FTEs in the entire KLM Group, the workforce must be reduced by 4,500 to 5,000 FTEs to 28,000 FTEs in the course of 2021.</p>



<p>KLM’s size is already becoming smaller – and will continue to be reduced – based on the current measures, which include the non-renewal of temporary contracts (1,500 FTEs) and the Voluntarily Departure Scheme (2,000 FTEs). Additionally, natural attrition (500 FTEs) through retirement and the like in 2020 and 2021 will also contribute to the reduction needed.</p>



<p>Hence, despite the measures already taken, even fewer people will be needed at KLM in the years ahead. Additionally, for positions on the ground we also need to deal with some mismatch in functional skills and capabilities.</p>



<p>Unfortunately, for this reason and taking into account the mismatch, alternative solutions will have to be found for ca. 1,500 positions. This relates to up to 500 ground positions, 300 cabin crew positions and 300 cockpit positions and approximately 400 positions at KLM subsidiaries and Air France-KLM group functions.</p>



<p>Given the high level of uncertainty, KLM keeps open the possibility of further reductions in case the production levels will be revised further down for 2021/2022 than the -20% planned now.</p>



<figure><img src="https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew.jpg" alt="KLM" srcset="https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew.jpg 500w, https://kokpitherald.com/wp-content/uploads/2020/08/klm_crew-300x169.jpg 300w" sizes="(max-width: 500px) 100vw, 500px"><figcaption>KLM crew in Sydney Photo: KLM</figcaption></figure>



<h3>KLM to Cooperate with Trade unions and Works Council</h3>



<p>KLM’s reorganisation plans tie in with organisation-wide changes at Air France KLM. In the forthcoming period, KLM will be cooperating closely with the trade unions to draft a social plan for each collective labour agreement domain and subsidiary, as well as maintaining close consultation with the Works Council about further defining the reorganisation. This will include a more detailed specification of the conditions set by the Dutch government on issuing the financing package. Expectations are that this will be finished in its entirety in the course of October.“</p>



<blockquote><p><em>A great deal has already been done in recent months with respect to adjusting the size of our company in the face of a new reality. Unfortunately, more measures are needed in the short term to guarantee KLM’s continued existence in the future. For this reason, we are elaborating the reorganisation plan to emerge from this crisis in a stronger position, while retaining as many jobs as we can in a responsible manner and repaying the loans as quickly as possible.</em></p><p><em>KLM employees are loyal, professional and hard working. They are always ready to serve our customers, one another, the company and society at large. Recent developments have again served to prove that this is true. It is incredibly difficult and sad for KLM to now have to bid farewell to valuable, committed colleagues. Certainly in view of how much we have succeeded in achieving together in recent years. The forthcoming period will be devoted to saying goodbye to colleagues who have to leave with due care and to reconstructing KLM.</em></p></blockquote>



<p>KLM President-directeur &amp; CEO Pieter Elbers</p>

 <!-- A generated by theme --> 



 <!-- end A --> 

        </div></div>]]>
            </description>
            <link>https://kokpitherald.com/klm-to-lay-off-5000-employees-due-to-covid-19-crisis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24035132</guid>
            <pubDate>Mon, 03 Aug 2020 07:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT3 → Dataset → Task Model?]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24034542">thread link</a>) | @dsr12
<br/>
August 2, 2020 | https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc | <a href="https://web.archive.org/web/*/https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/GPT3-Dataset-Task-Model-b97a267d6f5f44e688ba4f7ec85c00cc</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034542</guid>
            <pubDate>Mon, 03 Aug 2020 05:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MNT Reform open source laptop with trackball]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24034502">thread link</a>) | @brian_herman
<br/>
August 2, 2020 | https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html | <a href="https://web.archive.org/web/*/https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <date>Published: 2020-05-08 Updated: 2020-05-22 21:36:37 +0200</date>
        

<p><a href="https://mntre.com/media/reform_v2_images/product-mnt-reform.jpg"><img src="https://mntre.com/media/reform_v2_images/product-mnt-reform.jpg" alt="MNT Reform in 2020"></a></p>

<p>This page serves as a link index to all Reform content, both historical and recent.</p>

<p>On 2020-05-08, MNT Research launched the MNT Reform open source mobile computer:</p>

<p><strong><a href="https://www.crowdsupply.com/mnt/reform">→ Go to the Crowd Supply Campaign</a></strong></p>

<h2 id="mnt-reform-final-version">MNT Reform Final Version</h2>

<p>Internally called MNT Reform 2.0, this is a version with many improvements, full aluminum enclosure, HD display and NXP i.MX8MQ module.</p>

<ul>
<li>2020-05-22: <a href="https://mntre.com/reform2-handbook/system.html">MNT Reform Interactive System Diagram and Interactive PCBs</a>, first version, published.</li>
<li>2020-05-08: <a href="https://www.crowdsupply.com/mnt/reform">Crowd supply campaign is launched</a>, running until 2020-06-18.</li>
<li>2020-05-08: <a href="https://www.crowdsupply.com/mnt/reform/updates/the-campaign-is-live">Launch Announcement</a> of the campaign.</li>
<li>8 Beta versions (D-3 / D-4) were sold in late 2019/early 2020 and are shipped in May 2020.</li>
<li>2020-01-18: <a href="https://mntre.com/media/reform_md/2020-01-18-finishing-reform.html">Finishing Reform</a></li>
<li>2019-05-20: <a href="https://mntre.com/media/reform_md/2019-05-20-reintroducing-reform.html">Re-Introducing Reform</a></li>
<li>Handbook not yet available</li>
<li><a href="https://source.mntmn.com/MNT/reform">Sources of Reform 2.0 (KiCAD, various)</a></li>
</ul>

<h2 id="mnt-reform-prototype-version-s-internally-called-mnt-reform-0-1-1-0">MNT Reform Prototype Version(s) (internally called MNT Reform 0.1 - 1.0)</h2>

<p>This was the original version of Reform, based on NXP i.MX6QP.</p>

<ul>
<li>2019-01-14: <a href="https://mntre.com/media/reform_md/2019-01-14-status_update_on_reform.html">Status Update on MNT Reform</a></li>
<li><a href="https://mntre.com/media/reform_md/reform-1-handbook.pdf">Handbook for Reform 1.0 (PDF, historical)</a></li>
<li><a href="https://source.mntmn.com/MNT/reform/src/branch/master/historic-reform1">Sources of Reform 1.0 (KiCAD, various, historical)</a></li>
<li>10 prototype versions were shipped to early supporters in late 2018. 13 exist in total.</li>
<li><a href="https://mntre.com/media/reform_md/reform-historic/reform-beta-1.html">MNT Reform: The Original Story</a></li>
</ul>

<h2 id="talks-appearances">Talks / Appearances</h2>

<ul>
<li><a href="https://media.ccc.de/v/34c3-9257-lightning_talks_day_3#t=3512">Reform Lightning Talk from 34c3</a></li>
<li><a href="https://media.ccc.de/v/dg-90">Longer Reform talk in German from CCCB Datengarten 90</a></li>
</ul>

<h2 id="irc-channel">IRC Channel</h2>

<ul>
<li>Chat in #reform on irc.freenode.net</li>
</ul>



<ul>
<li><a href="https://mastodon.social/@mntmn">Mastodon</a></li>
<li><a href="https://twitter.com/mntmn">Twitter</a></li>
</ul>

<h2 id="crowdfunding-campaign">Crowdfunding Campaign</h2>

<p><strong><a href="https://www.crowdsupply.com/mnt/reform">→ Go to the Crowd Supply Campaign</a></strong></p>

      </section></div>]]>
            </description>
            <link>https://mntre.com/media/reform_md/2020-05-08-the-much-more-personal-computer.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034502</guid>
            <pubDate>Mon, 03 Aug 2020 05:34:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Autodesk criticised by architects]]>
            </title>
            <description>
<![CDATA[
Score 298 | Comments 375 (<a href="https://news.ycombinator.com/item?id=24034211">thread link</a>) | @nsoonhui
<br/>
August 2, 2020 | http://extranetevolution.com/2020/07/autodesk-criticism-extends/ | <a href="https://web.archive.org/web/*/http://extranetevolution.com/2020/07/autodesk-criticism-extends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
                
                    
                                        
                    <div id="content-main">
                    
	
		
		        
<div id="post-14835">
		
	<div>
    	
                    	<p>
            	<span>Jul</span>
                <span>31</span>
                	                <span>2020</span>
                            </p>
            
		        
		
			    <ul>
	    		        <li>
	        	By  in <span><a href="http://extranetevolution.com/category/aec/">AEC</a>, <a href="http://extranetevolution.com/category/bim/">BIM</a>, <a href="http://extranetevolution.com/category/businessfinancial/">Business/Financial</a>, <a href="http://extranetevolution.com/category/collaboration/">Collaboration</a>, <a href="http://extranetevolution.com/category/digital-transformation/">Digital transformation</a>, <a href="http://extranetevolution.com/category/functionality/">Functionality</a>, <a href="http://extranetevolution.com/category/future/">Future</a>, <a href="http://extranetevolution.com/category/vendors/">Vendors</a></span>	        </li>
	        	        <li>
	        	<p><em>31 July 2020</em></p>	        </li>
	        	        <li>
	        	        <span>
            <i></i>
        </span>
    	        </li>
	        	    </ul>
    		
				<div>
							
										
						<div itemscope="" itemtype="http://schema.org/BlogPosting"><p><em><strong>Architectural unrest about Autodesk and its support for the industry’s design businesses is growing. Discontent has been simmering for a decade or more, and has led to calls for EU action.</strong></em></p>
<p><a href="https://www.autodesk.co.uk/"><img src="http://extranetevolution.com/files/2013/11/autodesk.logo2013.jpg" alt="autodesk logo" width="181" height="31"></a>The recent <a href="https://letters-to-autodesk.com/" target="_blank" rel="noopener noreferrer">open letter to Autodesk</a> from 17 named members of a 25-strong group of leading architects (28 July 2020: <a href="http://extranetevolution.com/2020/07/design-firms-demand-change-at-autodesk/"><em>Design firms demand change at Autodesk</em></a>) has been supported by more firms. They extend the geographical reach of those prepared to publicly criticise the US AEC software vendor over its support for architectural design businesses – many of them heavily reliant upon Autodesk’s Revit design software. An additional 18 practices now stand alongside the original letter’s signatories, bringing the total to 35. A further 10 practices are supportive, but have not gone public. In total, more than 50 firms have therefore backed the group’s grievances.</p>
<p><img src="http://extranetevolution.com/files/2020/07/Revit_2014_branding-150x150.png" alt="Autodesk Revit_2014_branding" width="150" height="150" srcset="http://extranetevolution.com/files/2020/07/Revit_2014_branding-150x150.png 150w, http://extranetevolution.com/files/2020/07/Revit_2014_branding-300x300.png 300w, http://extranetevolution.com/files/2020/07/Revit_2014_branding-160x160.png 160w, http://extranetevolution.com/files/2020/07/Revit_2014_branding.png 316w" sizes="(max-width: 150px) 100vw, 150px">The new signatories are: BC Architects and SAOTA (both from South Africa); Cooper Carry, Portman Architects, Idesign-solutions, Studio 3 Architecture, Goody Clancy, SGA, Bohlin, Cywinski, Jackson, and Workshop Collaborative (all from the US), Atelier Tisso (France),&nbsp;CGL,&nbsp;Shepheard Epstein Hunter, and PDPLondon (all from the UK); Vibes (Netherlands); MIZA (Canada); Oslo works (Norway); and Mochly-Eldar Architects (Israel).</p>
<p>It is clear that Iain Godwin has tapped into a growing sense of unease, though, to be fair, rumblings of discontent have been heard many times over the past decade or so from a variety of software commentators and end-users. For example:</p>
<ul>
<li><a href="https://www.worldcadaccess.com/blog/2009/12/solidworks-accuses-autodesk-of-attempting-to-monopolize-use-of-dwg-as-file-extension.html" target="_blank" rel="noopener noreferrer"><em><strong>SolidWorks accuses Autodesk of attempting to monopolize use of .dwg as file extension</strong></em></a> (Ralph Grabowski – WorldCADAccess, December 2009)</li>
<li><a href="https://gfxspeak.com/2011/04/28/is-the-european-commission-investigating-autodesk/" target="_blank" rel="noopener noreferrer"><em><strong>Is the European Commission investigating Autodesk?</strong></em></a> (Randall Newton – GraphicSpeak, April 2011)</li>
<li><a href="https://www.cadnauseam.com/2017/07/26/autodesk-confirms-its-own-unconscionable-conduct/" target="_blank" rel="noopener noreferrer"><em><strong>Autodesk confirms its own unconscionable conduct</strong></em></a> (Steve Johnson – CAD Nauseum, July 2017)</li>
<li><a href="http://debunkthebim.blogspot.com/2018/04/here-is-why-autodesks-monopoly-over.html" target="_blank" rel="noopener noreferrer"><em><strong>Here is why Autodesk’s monopoly over the Global AEC is not good, not even for Autodesk</strong></em></a> (Zolna Murray – Debunk the BIM, February 2018)</li>
<li><a href="https://www.linkedin.com/pulse/avoiding-carillions-mistakes-joining-autodesks-monopoly-john-ford/" target="_blank" rel="noopener noreferrer"><em><strong>Avoiding Carillion`s Mistakes of Joining Autodesk’s Monopoly Unnecessarily</strong></em></a> (John Ford – LinkedIn Pulse, May 2018)</li>
<li><a href="http://mes100.com/blog/the-state-of-bim-software-and-autodesk/" target="_blank" rel="noopener noreferrer"><em><strong>The state of BIM software and Autodesk</strong></em></a> (MES – MES blog, July 2018)</li>
<li><a href="https://thinkmoult.com/why-revit-is-shit.html" target="_blank" rel="noopener noreferrer"><em><strong>Why Revit is shit</strong></em></a> (Dion Moult – ThinkMoult, December 2018)</li>
</ul>
<p>Concerns about some software vendors’ monopolistic positions have also been raised internationally by industry organisations, including the <a href="http://www.fiec.eu/" target="_blank" rel="noopener noreferrer">European Construction Industry Federation (FIEC</a>).</p>
<h3>FIEC position paper</h3>
<p><a href="http://www.fiec.eu/"><img src="http://extranetevolution.com/files/2020/07/FIEC-logo-300x117.jpg" alt="FIEC logo" width="300" height="117" srcset="http://extranetevolution.com/files/2020/07/FIEC-logo-300x117.jpg 300w, http://extranetevolution.com/files/2020/07/FIEC-logo-160x62.jpg 160w, http://extranetevolution.com/files/2020/07/FIEC-logo.jpg 443w" sizes="(max-width: 300px) 100vw, 300px"></a>On 24 February 2020, the FIEC published a position paper on the relationship between users and software companies/ editors/ service providers (<em><a href="http://extranetevolution.com/files/2020/07/2020-02-24-FIEC_position_on_software_companies-Final.pdf" target="_blank" rel="noopener noreferrer">download</a></em>). No vendors are named, but, from the similarity of the claims, Autodesk is clearly one of the software providers that FIEC is sufficiently concerned about to urge the European Commission to review competition and data management regulations. Its paper discusses challenges and makes recommendations under four headings:</p>
<ol>
<li><strong>The dominant position of a few software companies/editors/providers raises major concerns.</strong> – The FIEC urges the European Commission to target competition issues relating to software user contracts</li>
<li><strong>The non-EU origin of these suppliers and their infrastructure is exacerbating the lack of autonomy in software capability in the EU.</strong> – The FIEC says EU software users should be allowed to decide where their data is stored (“EU companies should be able to have their data hosted on EU territory, by EU servers/companies, under EU legislation”), calls for the creation of a secure European Cloud, and says software services “should be required to meet EU standards for interoperability and open access”.</li>
<li><strong>Contracting authorities must remain software-neutral and promote open standards</strong>. – The FIEC calls for enforcement of EU public procurement rules, and urges promotion of open standards for data, protocols and file formats in public procurement.</li>
<li><strong>Rules need to be established for multiple-user-access platforms such as BIM models.</strong> – Similarly, the FIEC urges EU measures aimed at protecting the data owner while ensuring appropriate data access rights for other users.</li>
</ol>
<h3>Autodesk not alone in hosting, US dominance, interoperability issues</h3>
<p>Some of these issues are already familiar. Where project data is hosted has been a concern ever since Software-as-a-Service applications began to be deployed in the 1990s, and as use of construction collaboration platforms expanded in the early 2000s, most leading vendors have responded by creating localised hosting centres to serve different operational regions. Hosting&nbsp; project data in the United States, for example, has been resisted by most clients based in Europe and other parts of the world (eg: the Middle East, southeast Asia, etc; read <em>EE</em> August 2014 post <a href="http://extranetevolution.com/2014/08/no-saas-safe-harbor/"><em>No SaaS ‘Safe Harbor’</em></a>).</p>
<p>Concentration of large portions of the construction software industry through merger and acquisition activity has resulted in an increasingly dominant position for US software giants. By gobbling up strong players in Europe, Australasia and elsewhere, Autodesk, Bentley, Oracle and Trimble have assembled strong AEC software portfolios, while some of the more generic US software providers such as Microsoft and IBM have also developed applications, services and relationships that give them an increasingly strong foothold in the AEC space.</p>
<p>And software interoperability has been a perennial issue that <em>EE</em> has covered since it started in 2005 (eg: <a href="http://extranetevolution.com/2005/09/new_roi_return_/"><em>New ROI: Return on Interoperability</em></a>, September 2005). BuildingSmart (formerly the International Alliance for Interoperability) started out as an Autodesk initiative in the mid-1990s, but, over 25 years later, global shifts towards open standards are still proceeding almost glacially slowly, with Autodesk’s leading BIM authoring product “widely ridiculed” for its IFC import/export capabilities.</p>
<h3>Autodesk responds on key themes</h3>
<p><strong><a href="https://adsknews.autodesk.com/views/reply-to-open-letter-on-revit"><img src="http://extranetevolution.com/files/2020/07/Autodesk-reply-300x205.jpg" alt="Autodesk reply" width="400" height="273" srcset="http://extranetevolution.com/files/2020/07/Autodesk-reply-300x205.jpg 300w, http://extranetevolution.com/files/2020/07/Autodesk-reply-590x403.jpg 590w, http://extranetevolution.com/files/2020/07/Autodesk-reply-768x524.jpg 768w, http://extranetevolution.com/files/2020/07/Autodesk-reply-160x109.jpg 160w, http://extranetevolution.com/files/2020/07/Autodesk-reply.jpg 1157w" sizes="(max-width: 400px) 100vw, 400px"></a>Autodesk’s initial response</strong> (<a href="http://extranetevolution.com/2020/07/design-firms-demand-change-at-autodesk/"><em>see update to earlier EE post</em></a>) to the Godwin group’s open letter <strong>did not mention interoperability</strong> at all. However, a <a href="https://adsknews.autodesk.com/views/reply-to-open-letter-on-revit" target="_blank" rel="noopener noreferrer">follow-up blog post by Amy Bunzsel</a> published today (31 July 2020) addresses the main themes, and on openness and interoperability says: “<strong>We continue to invest in supporting IFC</strong> and based on customer feedback we’ve <strong>recently increased development for new industry requirements, focusing on IFCv4 certification</strong>.”</p>
<p>Bunzsel continues:</p>
<p>“Looking to the future, we believe that ways of working will evolve, from the direct modeling of today to outcome-based design driven by analysis…, to the convergence of manufacturing and construction, and that <strong>data needs to be unlocked from native formats and flow more readily throughout Autodesk and non-Autodesk products</strong>.”</p>
<h3>No more software silos</h3>
<p><a href="https://3drepo.com/"><img src="http://extranetevolution.com/files/2017/03/3DRepo-300x102.png" alt="" width="150" height="51" srcset="http://extranetevolution.com/files/2017/03/3DRepo-300x102.png 300w, http://extranetevolution.com/files/2017/03/3DRepo.png 385w" sizes="(max-width: 150px) 100vw, 150px"></a>Jozef Dobos is CEO and founder of London, UK-based technology vendor, <a href="https://3drepo.com/" target="_blank" rel="noopener noreferrer"><strong>3DRepo</strong></a>&nbsp;(which has been <a href="https://3drepo.com/4670-2/" target="_blank" rel="noopener noreferrer">a supporter of Open BIM since 2017</a>), and recently argued&nbsp;<a href="https://www.bimplus.co.uk/analysis/making-case-fair-competition-software-use/" target="_blank" rel="noopener noreferrer"><em>The case for fair competition in software use</em></a>, in a <em>BIM+</em> article. He writes:</p>
<p><img src="http://extranetevolution.com/files/2020/07/Jozef-Dobos-271x300.png" alt="Jozef Dobos" width="271" height="300" srcset="http://extranetevolution.com/files/2020/07/Jozef-Dobos-271x300.png 271w, http://extranetevolution.com/files/2020/07/Jozef-Dobos-145x160.png 145w, http://extranetevolution.com/files/2020/07/Jozef-Dobos-363x400.png 363w, http://extranetevolution.com/files/2020/07/Jozef-Dobos.png 502w" sizes="(max-width: 271px) 100vw, 271px">“<strong>All the issues raised by the FIEC must be addressed to enable the genuine digitisation of the construction industry</strong>.</p>
<p>3D Repo was created to enable the construction industry to work better together and to create better buildings. This is why projects like the&nbsp;<strong><a href="https://www.bimplus.co.uk/news/project-explores-faster-bim-data-transfer-between-/" target="_blank" rel="noopener noreferrer">AEC Delta Mobility</a></strong> [open-source] initiative in collaboration with BuroHappold Engineering and Speckle Systems are so important, creating a new standard for designers, integrators and fabricators to improve the flow of data.</p>
<p>The current method of sharing information as files of entire 3D models can hinder collaboration. Tracking changes can also be problematic and inefficient for design communication. AEC Delta Mobility breaks down the file barriers to enable small design changes, known as ‘Deltas’, to be shared faster, more openly and more efficiently.</p>
<p><strong>This is how the software industry should be working with the construction industry. Real solutions that involve working with customers and providing them with tools they will not want to walk away from, based on commercial terms that actually promote the collaborative behaviours we want to see, not divide us into software silos</strong>.”</p>
</div>								</div>
		
			    
    	</div>

</div>


<p><span><strong>Permanent link to this article: </strong><span>http://extranetevolution.com/2020/07/autodesk-criticism-extends/</span></span></p>











	
    

            
  

                </div><!-- #content-main -->
        
            
<!-- #sidebar1 -->        
        
    </div></div>]]>
            </description>
            <link>http://extranetevolution.com/2020/07/autodesk-criticism-extends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034211</guid>
            <pubDate>Mon, 03 Aug 2020 04:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web apps aren't tech. They're “tech”]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24034040">thread link</a>) | @AlchemistCamp
<br/>
August 2, 2020 | https://questinglog.com/web-apps-arent-tech | <a href="https://web.archive.org/web/*/https://questinglog.com/web-apps-arent-tech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><blockquote><p>I do hear sometimes from programmers who are kind of sad that they don't have the opportunity to write game engines from scratch like I did and have it matter or make an impact...</p> <p>-John Carmack</p></blockquote> <p>I was definitely a programmer who felt like I'd missed a golden era of opportunity. I didn't <em>really</em> start programming until my 30s. Just like many devs hoping to have an impact on the industry, it's sometimes felt like the golden era has already passed.</p> <p>Surveying the market from a more entreprenurial mindset and looking for a potential niche to fill with a SaaS app (or worse, a social network), the situation appears even more dire! News aggregators have been done and Reddit is thoroughly dominant. The professional social network is done and LinkedIn owns it. Market after market is done. <a href="https://questinglog.com/everything-is-done">Everything in tech is done.</a></p> <h2 id="technology-doesn-t-stay-technology"><a href="#technology-doesn-t-stay-technology">#</a> Technology doesn't stay technology</h2> <p>Part of the problem is the word "tech". There are two different—but overlapping—ideas that are both commonly referred to as "tech".</p> <p>By its literal definition, techonology is anything that involves <em>applying scientific knowledge for practical purposes</em>. In a literal sense, we're surrounded by tech. Some, such as the spoon are ancient and others, like the Kinesis keyboard I'm typing on are much newer.</p> <p>But people don't talk about ancient inventions like the fire bow, or Clovis points as "technology", outside of a historical context. Most people don't even call somewhat modern inventions like light bulbs, refrigerators or microwaves as technology either. When we call something technology, we generally mean something invented recently... <em>or</em> we mean something related to computers.</p> <p>Douglas Adams summed it up into three rules:</p> <ol><li>Anything that is in the world when you’re born is normal and ordinary and is just a natural part of the way the world works.</li> <li>Anything that's invented between when you’re fifteen and thirty-five is new and exciting and revolutionary and you can probably get a career in it.</li> <li>Anything invented after you're thirty-five is against the natural order of things.</li></ol> <p>Having a musician turned firmware hacker and then programmer for an uncle, I'm a bit more optimistic about aging and see the boundary as more about whether a given technology has been widespread for a decade or not.</p> <p>Cassette tapes and microwave ovens used to be fantastic new technologies in the late 60s and early 70s. Now they aren't. DVDs, the web and 3D video games used to be amazing technologies in the 90s. Now they're taken for granted. Smart phones were incredible in the late aughts. Now they're just phones.</p> <h2 id="when-pundits-say-tech-they-generally-mean-computing"><a href="#when-pundits-say-tech-they-generally-mean-computing">#</a> When pundits say "tech" they generally mean computing</h2> <p>The rapid advances in personal computing during the 80s, 90s and early 2000s was nothing short of breathtaking. Computers were gaining new powers every year or two and PCs were deprecating nearly 50% per year! The web took the boom to an exponentially growing number of users. [<a href="#1">1</a>]</p> <p>It's entirely natural that computer software dominated the discussion of technology for a generation. First journalists, and now many of us are referring to everything from web SaaS apps to mobile productivity apps as "tech".[<a href="#2">2</a>] Since the wider meaning of tech hasn't been abandoned, this makes it very easy to conflate the two.</p> <p>But not all technology is computing and not all computing is technology anymore.</p> <h2 id="where-is-the-edge"><a href="#where-is-the-edge">#</a> Where is the edge?</h2> <p>To an ambitious engineer looking for a market opportunity in "tech", things look crowded. Advances in programming languages, frameworks, open source collaboration, dev ops, visual site-building tools and more have made it <em>dramatically</em> easier to create both web apps and mobile apps than it was a decade ago. This has lead to a flood of competition and an increased importance of marketing and other skills an engineer might not have.</p> <p>But web apps aren't (necessarily) tech. They're "tech".</p> <p>But not all is lost for the aspiring engineer.</p> <p>There are newer technologies, closer to the frontier that aren't common in in 2020 but will be in 2030. Some of them are still wide open to people with more learning power than earning power. Bio-tech, blockchain, and VR <em>are</em> tech and the technical challenges to be solved are real. It's a lot harder to ship a product in those areas than to build yet another SaaS targeting small to medium sized businesses. But that's a <em>good</em> thing if technical skills are your strength.</p> <p>For those whose strengths lean more to the marketing, sales or design sides, the B2B SaaS may represent a better goal. This is good for everyone. There's vast landscape for different people with different comparative advantages to find their niches.</p> <h2 id="you-are-not-too-late"><a href="#you-are-not-too-late">#</a> You are not too late</h2> <blockquote><p>...here's where some perspective really helps - I can remember when I was a teenager, I thought I had missed the Golden Age of 8-bit Apple 2 gaming, that I was never going to be Richard Garriott...time went by, and I got to make my own marks in things after that. And, in that time, I also see so many opportunities that have come by.</p> <p>The 90s PC wave was great - I was happy to be there, and I'm glad I took a swing and knocked one out of the park with that. But since then, we've seen mobile games, and web games, and free-to-play games, the Steam revolution...and now virtual reality. And all of these are amazing!</p> <p>So, yeah, the opportunities that I had aren't there for people today - but there are new and better ones. And personally, I'm more excited about these than anything that's come before. So, thank you very much for this honor, but I'm just getting started.</p> <p>-John Carmack (BAFTA acceptance speech)</p></blockquote> <p>The speech John Carmack gave when accepting his BAFTA fellowship filled me more professional optimism than I've felt in quite a while. Even he felt like it was "too late" because of missing all the opportunities of the 80s.</p> <p>In retrospect, that seems crazy. The web was huge and just around the corner.</p> <h3 id="notes"><a href="#notes">#</a> Notes</h3> <p><a name="1">[1]</a> Well more of an S-curve, but it looked exponential then.</p> <div><p><a name="2">[2]</a> As one commenter on HN </p><a href="https://news.ycombinator.com/item?id=24034703" target="_blank" rel="noopener noreferrer">pointed out</a><p>, it's a spectrum. In Uber's early days, its technology was crucial to its business. Over time, they'll gradually become less of a tech company if they coast and stop innovating.
</p></div>  <br> <hr> <p><a href="https://news.ycombinator.com/item?id=24034040" target="_blank" rel="noopener noreferrer">Discussion on HN</a></p></div></div>]]>
            </description>
            <link>https://questinglog.com/web-apps-arent-tech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24034040</guid>
            <pubDate>Mon, 03 Aug 2020 03:49:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Email Got Us $5k AWS Credits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24033037">thread link</a>) | @webappsecperson
<br/>
August 2, 2020 | https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits | <a href="https://web.archive.org/web/*/https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>We recently went through the <a href="https://stripe.com/atlas">Stripe Atlas</a> program and <a href="https://formcake.com/blog/our-experience-with-stripe-atlas">loved it</a>.</p>
<p>But the one sour note was that we only got $1,000 AWS credits when <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">the copy seemed to promise $5,000</a>. Our <a href="https://formcake.com/blog/why-we-chose-a-marketing-and-app-monorepo">entire application infrastructure is on AWS</a> so those credits are pretty much straight-up cash to us. We don't have much of a digital footprint either, so $5,000 goes a long way.</p>
<p>That's why this weekend was such a surprise.</p>
<h3 id="the-email">The Email</h3>
<p>Here's how the timeline went.</p>
<ol>
<li><p>First <a href="https://formcake.com/blog/stripe-atlas-includes-five-thousand-credits-this-is-what-we-got">we posted an article</a> politely noticing that we hadn't been able to secure the full $5,000 and kinda wondering out loud why.</p>
</li>
<li><p><a href="https://formcake.com/blog/the-founders-guide-to-stripe-atlas">Stripe contacted us</a> and explained that the credit amount was more of a lifetime cap and that it was ultimately up to AWS what we got.</p>
</li>
<li><p>We send <em>one more</em> email just 'cause, even though it seems clear AWS only offers $1,000 for bootstrapped startups. The email is simple and amounts to: "Is there any way we could get the full five thousand in credits?"</p>
</li>
</ol>
<p>Stripe responds to this chain of events with yet another email, this one even kinder and more politely worded.</p>
<section>
Hey David,

<p>Thank you for sharing the details here. It sounds like we should be able to get this sorted out so that you receive the $5K in AWS credits for Stripe Atlas users.  </p>
<p>I believe it may be the case that you applied for AWS credits with a different link than the one shared for Stripe Atlas users to activate. We do not typically see users needing to answer the question regarding funding sources. I did check in with AWS on this and it sounds like they're currently processing your most recent application that you submitted through the Stripe Atlas link. They've let me know that they will email you directly with next steps, which may take up to 4 weeks. </p>
<p>Hopefully this will all soon be sorted! If you do have any questions on this or anything else, please feel free to reach out! I'll check back in a couple weeks on the AWS front, or feel free to share any updates as well!</p>
<p>Warm regards,
Taylor</p>
</section> 

<p>It looks like the funded/bootstrapped question indicated the process had gotten miffed somewhere and <em>Stripe reached out to AWS on our behalf</em> to make sure things got cleared up.</p>
<p>This weekend we saw $5,000 in credits enter our AWS account. Keep in mind that's actually <strong>in addition</strong> to the $1,000 we've already received, bringing out total up to $6,000 in AWS credits through the Stripe Atlas program.</p>
<p>For us this is a big injection. It basically funds our full application operations and lets us play around with putting money elsewhere - or just continuing to build features and mature without any kind of pressure.</p>
<h3 id="conclusion">Conclusion</h3>
<p>A couple of takeaways from the entire affair.</p>
<h4 id="1-send-that-one-last-email">1. Send that one last email</h4>
<p>Even if it seems like a bit much, or things are settled, just be sure you ask and give the other person a chance to help you in ways you can't predict. A hail mary "Is there anything I'm missing?" can sometimes land.</p>
<h4 id="2-stripe-is-truly-wonderful">2. Stripe is truly wonderful</h4>
<p>Stripe monitored the developer community enough to see our initial posts, proactively reached out to us, and then worked with AWS to ultimately get us a greater-than-even-promised payout. When people say Stripe is a company for developers, they often mean its great API or clear documentation, but this is I think one of the greatest testaments to their dev-first culture.</p>
</div></div>]]>
            </description>
            <link>https://formcake.com/blog/how-an-email-got-us-five-thousand-aws-credits</link>
            <guid isPermaLink="false">hacker-news-small-sites-24033037</guid>
            <pubDate>Mon, 03 Aug 2020 00:39:42 GMT</pubDate>
        </item>
    </channel>
</rss>
