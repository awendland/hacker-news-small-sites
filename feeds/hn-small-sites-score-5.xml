<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 12 Jan 2021 01:50:19 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 12 Jan 2021 01:50:19 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[CTO day 2: downsizing the team]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25712771">thread link</a>) | @delebe
<br/>
January 10, 2021 | https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/ | <a href="https://web.archive.org/web/*/https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="entry-summary">On your first day as newly appointed CTO you are working on your hiring strategy, the second day your organization asks you to downsize the team.</p><div><p>A very important project that was a done deal, and that will secure the organization’s future for the next five years, failed to happen.</p><p>Not winning this project meant that the organization was forced to <em>“focus”</em> and reduce costs.</p><p>It never crossed my mind that one of the first things that I would be asked to do as an inexperienced CTO would be to fire part of the team.</p>
<p>when such bad news becomes public, host an open door day where the team can openly talk about the situation, share their feelings, see each other, feel connected, and be listened to. It would not stop the gossiping but it will help.</p><h2>Cuts and team principles</h2><p>The Dev team slice of the <em>“focus”</em> meant cutting cost by 10 to 15%. In human terms, firing two to four people (out of 17).</p><p>After some failed attempts to approach this task, this is what worked for me.</p><p>I started by listing some principles: </p>
<ul>
  <li>For each product, we need to cover the following disciplines: Frontend, Backend, Architecture, Operations, Mobile, UX, Design, QA, Leadership, and Product Management.</li>
  <li>There are broadly 3 experience levels:
  <ul>
    <li>Senior: creates the plan.</li>
    <li>Mid-level: follows the plan.</li>
    <li>Junior: needs to be taught to follow the plan.</li>
  </ul></li>
  <li>No number of junior people can do some work a senior person can do.</li>
  <li>Not having a senior person in a discipline will mean that the product quality will suffer:
  <ul>
    <li>If a senior creates a plan, a team of mid-level+juniors can follow the plan for some time (2-3 years?) before the product becomes a big mess.</li>
    <li>To get out of a big mess, we need senior people.
    <ul>
      <li>We are already in a big mess with Product A and Product B.</li>
      <li>With the current team, it feels Product A is getting out of the mess.</li>
    </ul></li>
  </ul></li>
  <li>Independent (cross-functional) teams are more efficient:
  <ul>
    <li>More focus.</li>
    <li>No handoffs, faster feedback.</li>
    <li>No shared “resource” contention.</li>
  </ul></li>
  <li>People working in multiple products/teams are less efficient.</li>
  <li>Multidisciplinary (generalist) people:
  <ul>
    <li>Can cover the need for several of the disciplines.</li>
    <li>They can be junior in one discipline and senior in another.</li>
    <li>Allow focusing on any priority, without creating artificially important work for single-disciplined members.</li>
  </ul></li>
  <li>Max team size: 2 pizza teams 6-8.</li>
</ul><p>The ideal team would be one that has all disciplines covered at a senior level with multidisciplinary people working in just one team, and with enough overlap to avoid a <a href="https://en.wikipedia.org/wiki/Bus_factor">bus factor</a> of one. Additional people will bring additional capacity.</p><h2>Inverse Conway’s maneuver</h2><p>We have been working on bringing three of the products together for some time. They were already under the same product manager, but they were still three teams working on their own priorities. Merging them into one team, in a classic <a href="https://danlebrero.com/2020/01/08/do-i-need-a-gateway-api-team-dynamics/#content">inverse Conway’s maneuver</a> would hopefully accelerate the integration between the products.</p><p>One of the other products was small enough that for this task I decided to temporarily ignore it.</p><p>Following the principles above and the product considerations, the plan was to move the previous team setup from:</p><p><img src="https://danlebrero.com/images/blog/cto/day2/old-team-structure.jpg" alt="old team structure"> </p><p>To something like (boxes represent skills, not people):</p><p><img src="https://danlebrero.com/images/blog/cto/day2/new-team-structure.jpg" alt="new team structure"> </p><p>So two products, two cross-functional teams. Platforms and design teams will be reshuffled inside those two teams.</p><h2>Which parent do you love most? A computer will tell</h2><p>With a clear plan for the team, the next step was to <em>“just”</em> pick up who will work on each team, and who we will need to let go. The most painful decision in my career. </p>
<blockquote><p><a href="https://danlebrero.com/2019/11/27/becoming-a-technical-leader-book-notes/#content">People with a strong technical background can convert any task into a technical task, thus avoiding work they don’t want to do.</a> <cite>Jerry Weinberg, Becoming a Technical Leader</cite></p>
</blockquote><p>And I didn’t want to do the task so, consciously ignoring Mr. Weinberg, I transformed the ordeal into an optimization problem, for which I wrote an application to help me with.</p><h3>The app</h3><p>The application took as input the amount of $$$ to cut, the list of people, their salary, and the skill level on each discipline mentioned above, and outputted the possible two teams that would be within budget and match the minimum requirements, sorted by a scoring system.</p><p>The minimum requirements and scoring system configuration looked like:</p>
<pre><code>{
"FE" [at-least-senior sum-skills]
"PM" [senior-plus-somebody-else (fix-points 5)]
"Design" [two-mid-or-senior (senior-better 6 2)]
...
}
</code></pre><p>The first function filters out invalid teams while the second scores the valid ones.</p><p>In the example we say that the team has to have:</p>
<ul>
  <li>At least one senior FE developer. The more FE developers, the better team score.</li>
  <li>At least one senior product manager and one mid or junior one. Only one senior is not enough. No matter how many PMs the team has, the score for this discipline is 5. A team with loads of FE devs will score higher than one with loads of PMs.</li>
  <li>At least a senior designer or two mid-level designers, but we prefer one senior designer (6 points) instead of two mid-level ones (2 points).</li>
</ul><h3>The result</h3><p>As heartless as this may seem:</p>
<ul>
  <li>It removed some bias. There is still bias on the skill level evaluation and in the team scoring system.</li>
  <li>I was part of the people on that list. To be honest, little consolation here. Big bias.</li>
  <li>It forced me to be very very precise on what a “functioning team” meant.</li>
  <li>It allowed me to see what different scoring systems would output.</li>
  <li>I noticed some people would never show in the output, and had to dig into why. It was enlightening.</li>
  <li>It allowed me to analyze tens of thousands of different team combinations, with different scoring systems.</li>
  <li>Programming gave me a respite from the task. This was the first time, but now I embrace more regularly “keep my sanity” programming days.</li>
</ul><p>Most important, the application gave me a few starting points. Of those, I still had to consider the team dynamics, existing teams, personalities, seniority, potential, personal situation, future needs, …</p>
<p>yes, I still have the code. No, I am not going to share it publicly. It would kill me to find there is a bug.</p><h2>Delivering the bad news</h2><p>Once the decision was made, it was time to swallow the last bitter pill.</p><p>Some tips:</p>
<ul>
  <li>Ensure that the people affected are the first ones to know.</li>
  <li>Warn beforehand:
  <ul>
    <li>Do not use your regular one-to-one meeting slot.</li>
    <li>In your message, give a strong hint: “HR person will be in the meeting”, “Really bad news”.</li>
    <li>Give them time to get ready for the meeting.</li>
  </ul></li>
  <li>You don’t need to do it alone. Our HR manager was present and was a huge support for both of us.</li>
  <li>Treat people like adults.</li>
  <li>At the meeting, follow Nadia van der Vlies’ <a href="https://danlebrero.com/2020/04/01/no-nonsense-leadership-summary/#bad-news">advice</a>:
  <ul>
    <li>Deliver the blow:
    <ul>
      <li>Go straight to the bad news.</li>
      <li>Give one or two reasons.</li>
    </ul></li>
    <li>Manage the reaction:
    <ul>
      <li>Be understanding. Do not justify yourself.</li>
      <li>Give space. Do not fill silences.</li>
    </ul></li>
    <li>Solution, explanation, follow-up appointment:
    <ul>
      <li>Wait for the employee to be ready. When she starts asking “why” or “what now”.</li>
      <li>Reiterate reasons.</li>
    </ul></li>
  </ul></li>
  <li>In a couple of days follow up with another more informal meeting. The news would have sunk, and the conversation would be more forward-thinking and productive.</li>
</ul>
<hr><p>A slap in the face to awaken me from the dream that a CTO role is mostly about technology.</p></div></div>]]>
            </description>
            <link>https://danlebrero.com/2020/12/02/cto-diary-downsizing-team-firing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712771</guid>
            <pubDate>Sun, 10 Jan 2021 09:27:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Noise Planets (Generative Art)]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25712767">thread link</a>) | @atulvi
<br/>
January 10, 2021 | https://avinayak.github.io/art/2021/01/09/noise-planets.html | <a href="https://web.archive.org/web/*/https://avinayak.github.io/art/2021/01/09/noise-planets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://avinayak.github.io/uploads/erporydxmaarwcd.png" alt=""></p>

<p>I recently found this piece of art (LINES 2A (2017)) created by <a href="https://twitter.com/tylerxhobbs">Tyler Hobbs</a>. This picture kinda looked very hand drawn, but it’s completely generative. Something about this drawing and it’s texture kind of resonated with me, so I wanted to try to study and replicate (or make something inspired by this work) using p5js.</p>

<p>I started out by plotting a bunch of random points within a circle like so.</p>

<div><div><pre><code>w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4');
}

function draw() {
  x = random(w)
  y = random(w)
  if (pow(w/2 - x, 2) + pow(w/2 - y, 2) &lt; 7e4) {
    point(x,y)
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-25.png" alt=""></p>

<p>This is a painfully slow process to generate random points in a circle. I found a better way to do this later. What I wanted to do next was to generate flow fields, but restricted to the circular region.</p>

<p>It’s super easy to generate flow field patterns using perlin noise.</p>

<ol>
  <li>Choose a random point <code>&lt;x,y&gt;</code></li>
  <li>Plot <code>&lt;x,y&gt;</code></li>
  <li>Calculate <code>n = noise(x,y)</code></li>
  <li>Do <code>x+=cos(n * 2 * PI)</code> and <code>y+=sin(n * 2 * PI)</code></li>
  <li>Repeat 2.</li>
</ol>

<p>We’re going to plot flow fields inside the circle. Let’s try this.</p>

<div><div><pre><code>const is_in_circle = (x, y) =&gt; 
  (pow(w / 2 - x, 2) + pow(w / 2 - y, 2) &lt; 7e4)

function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y)) {
      n = noise(x, y)
      x += sin(n * TAU)
      y += cos(n * TAU)
      point(x, y)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-28.png" alt=""></p>

<p>OK, not very good. The noise at this level is pretty rough. we’re going to zoom in to the noise function (by dividing the <code>x,y</code> inputs by some constant value) and probably use <code>circle(x ,y ,0.3)</code> to plot points instead if point function, because I feel it looks way smoother. Also, I’m adding a <code>random() &gt; 0.01</code> condition in the loop so that we also get short lines that are not trimmed away by the edge of the circle.</p>

<div><div><pre><code>function draw() {
  if (is_in_circle(x = random(w), y = random(w)))
    while (is_in_circle(x, y) &amp;&amp; random() &gt; 0.01) {
      n = noise(x / 500, y / 500)
      x += sin(n * TAU)
      y += cos(n * TAU)
      circle(x, y, .3)
    }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/download-27.png" alt=""></p>

<p>Actually.. not bad. I think we manage almost replicate the original texture. The inverted version also looks pretty good.</p>

<p><img src="https://avinayak.github.io/uploads/download-19.png" alt=""></p>

<p><img src="https://avinayak.github.io/uploads/ppanets.png" alt=""></p>

<p>I went ahead and made a つぶやきProcessing version of this.</p>

<blockquote><p lang="en" dir="ltr">function setup(){createCanvas(w=1e3,w),background("<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a>")}function draw(){if(g(x=random(w),y=random(w)))for(;g(x,y)&amp;&amp;random()&gt;.01;)n=noise(x/500,y/500),x+=sin(n_TAU),y+=cos(n_TAU),circle(x,y,.3)}g=((n,o)=&gt;pow(w/2-n,2)+pow(w/2-o,2)&lt;w*w/16); <a href="https://t.co/iVZTMtCn3i">pic.twitter.com/iVZTMtCn3i</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347903013042622467?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="going-further-animations">Going Further: Animations</h2>

<p>The code we wrote right now technically is animated. The animation however is not very smooth.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_03-52-31.mp4" type="video/mp4"> </video>

<p>To make smooth animations, we need to generate new points in the circle, keep track of these points outside the <code>draw()</code> function. I found this neat <a href="https://stackoverflow.com/a/50746409">technique</a>, to find random points in a circle where a random radius <code>r</code> and angle <code>theta</code> are chosen and the <code>x,y</code> points are obtained as <code>x = centerX + r * cos(theta)</code> and <code>y = centerY + r * sin(theta)</code></p>

<p>Let’s try that first.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

function setup() {
  createCanvas((w = 1e3), w);
  background(255)
  k = w / 2
  m = (Array(w).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    circle(x, y, .3);
  }
}
</code></pre></div></div>

<p><img src="https://avinayak.github.io/uploads/screenshot-from-2021-01-10-04-51-20.png" alt=""></p>

<p>and now we apply flow fields and try to move these points.</p>

<div><div><pre><code>function random_point() {
  r = random(w / 4)
  t = random(TAU)
  return [
    w/2 + cos(t) * r, 
    w/2 + sin(t) * r
  ]
}

const w = 1000
function setup() {
  createCanvas(w, w);
  background('#F9F8F4')
  k = w / 2
  points = (Array(k).fill(0)).map(random_point)
}

function draw() {
  for (i = k; --i;) {
    [x, y] = m[i]
    x += sin(n = noise(x / 400, y / 400) * TAU) * h
    y += cos(n) * h
    stroke(i%255)
    circle(x, y,.3)
    if (pow(k - x, 2) + pow(k - y, 2) &lt; 7e4)  // if point is in circle
      points[i] = [x, y, t]
    else points[i] = random_point() // replace with new point if not
  }
}
</code></pre></div></div>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_04-56-11.mp4" type="video/mp4"> </video>

<p>And a つぶやきProcessing version of course..</p>

<blockquote><p lang="cy" dir="ltr">t=0,p=i=&gt;\[k+(r=random(w/4))_cos(t+=.1),k+r_sin(t)\],setup=i=&gt;{createCanvas(w=1e3,w),m=Array(k=w/2).fill(0).map(p)},draw=r=&gt;{for(i=k;--i;)\[x,y\]=m\[i\],x+=sin(n=noise(x/k,y/k)_TAU),y+=cos(n),stroke(i%4_85),point(x,y),k_w+x_x+y_y-w_(x+y)&lt;7e4?m\[i\]=\[x,y\]:m\[i\]=p()};//<a href="https://twitter.com/hashtag/%E3%81%A4%E3%81%B6%E3%82%84%E3%81%8DProcessing?src=hash&amp;ref_src=twsrc%5Etfw">#つぶやきProcessing</a> <a href="https://t.co/xVhCBNUltL">pic.twitter.com/xVhCBNUltL</a></p>— yakinavault (@yakinavault) <a href="https://twitter.com/yakinavault/status/1347930637227855874?ref_src=twsrc%5Etfw">January 9, 2021</a></blockquote>


<h2 id="adding-colors">Adding Colors</h2>

<p>There are many strategies to colorizing this sketch. One is by just giving each particle a random initial color.</p>

<p><img src="https://avinayak.github.io/uploads/download-21.png" alt=""></p>

<p>However, I found that maintaining the initial x or y position in the particle array and using that to derive the hue information gives us some nice Jupiter/gaseous planet vibes.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-18-19.mp4" type="video/mp4"> </video>

<p>The fringing at the sides can be avoided by moving 50% of the points in the reverse direction.</p>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_05-28-03.mp4" type="video/mp4"> </video>

<video loop="" autoplay="" muted=""> <source src="https://avinayak.github.io/uploads/simplescreenrecorder-2021-01-10_08-43-25.mp4" type="video/mp4"> </video>

<p>More color variations</p>

<p><img src="https://avinayak.github.io/uploads/untitled.png" alt=""></p>

<p>And that’s it. Hope this was educational!</p>

</div></div>]]>
            </description>
            <link>https://avinayak.github.io/art/2021/01/09/noise-planets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712767</guid>
            <pubDate>Sun, 10 Jan 2021 09:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blocks Courtesy of Konrad Zuse (2014)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25712727">thread link</a>) | @todsacerdoti
<br/>
January 10, 2021 | https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse | <a href="https://web.archive.org/web/*/https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apparently, I've got a theme going of Weird Syntax. Let's run with it.</p>

<p>Konrad Zuse was an early pioneer in computer science, although his name is perhaps somewhat less well-known than others. Zuse holds the honor of having built the first programmable computer—-the Z3—-back in the 40's, as well as several other computing firsts<sup id="fnref:1"><a href="#fn:1" rel="nofollow">1</a></sup>. Of particular interest to this blog post is his early unimplemented programming language, Plankalkül.</p>

<p>Plankalkül was, like the Z3, in many respects ahead of its time. Zuse's explicit goal was to be able to describe programs at a high level, which meant he included control structures and datatype definitions<sup id="fnref:2"><a href="#fn:2" rel="nofollow">2</a></sup> and other high-level constructs that were often missing in languages of the early years of computing. Zuse was working on Plankalkül at a time when his machines were not useable, which meant that his language work was more theoretical than it was technical, and consequently he allowed features that he wasn't entirely sure how to program. Despite his notes on it having been written in the mid-40's, they were not published until the 70's, and it was not implemented until the year 2000.</p>

<p>One thing that struck me, as I read programs in this notation that had been set down on a typewriter<sup id="fnref:3"><a href="#fn:3" rel="nofollow">3</a></sup>, is that certain kinds of grouping were handled by explicit indication of scope: not via matched delimiters as in ALGOL-style languages, or via indentation in languages such as Python and Haskell, but by formatting the code so that a line bordered on the left of the scoped parts of the code:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-01.png" alt=""></p>

<p>This is meant to capture the way grouping works in the hand-written or typeset notation, with brackets spanning multiple lines:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-02.png" alt=""></p>

<p>I think this is notationally interesting: it's like Python's significant whitespace, but not, uh, whitespace. It would be incredibly tedious to type out, but still entirely compatible with current programming notation:</p>

<pre><code>class Tet
 | @staticmethod
 | def new_tet()
 |  | n = randint(0, len(Tet.Tets) - 1)
 |  | for p in Tet.Tets[n]
 |  |  | if p in Board.permanent
 |  |  |  | Game.lose()
 |  | Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 |
 | def __init__(self, points, color)
 |  | self.points = points
 |  | self.color = color
</code></pre>

<p>and would be entirely amenable to beautifying via judicious application of Unicode:</p>

<pre><code>class Tet
 ┃ @staticmethod
 ┃ def new_tet()
 ┃  ┃ n = randint(0, len(Tet.Tets) - 1)
 ┃  ┃ for p in Tet.Tets[n]
 ┃  ┃  ┃ if p in Board.permanent
 ┃  ┃  ┗  ┗ Game.lose()
 ┃  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ┃
 ┃ def __init__(self, points, color)
 ┃  ┃ self.points = points
 ┃  ┗ self.color = color
</code></pre>

<p>Looking at this notation, however, an interesting possibility struck me: a programmer could explicit annotate information about the <em>kind of scope</em> involved in a given line. In this Python-like example, I could, for example, distinguish class scope using double lines, function scope with thick lines, and control structure scope with thin lines:</p>

<pre><code>class Tet
 ║ @staticmethod
 ║ def new_tet()
 ║  ┃ n = randint(0, len(Tet.Tets) - 1)
 ║  ┃ for p in Tet.Tets[n]
 ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
 ║  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ║
 ║ def __init__(self, points, color)
 ║  ┃ self.points = points
 ║  ┗ self.color = color
</code></pre>

<p>One advantage of this scheme is that a handful of lines, viewed in isolation, still give you a clear view of what surrounds them. For example, I can view these two lines in isolation and still tell that they are within a control structure used within a function declared within a class:</p>

<pre><code> ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
</code></pre>

<p>You could also imagine a hypothetical language in which choice of scope delimiter is important. In Python, <code>for</code> and <code>if</code> do not form a new lexical scope. What if instead we could stipulate the kind of scope they form by this notational convention?</p>

<pre><code>def okay()
 ┃ if True
 ┃  └ n = 5   # n is declared in function scope
 ┗ return n   # n leaks out of the if-scope

def not_okay()
 ┃ if True
 ┃  ┗ n = 5   # n is declared in the if's scope
 ┗ return n   # error: no n in scope here
</code></pre>

<p>That being said, there are a number of reasons that this notation is in inferior to existing notations:</p>
<ul><li>It makes refactoring code <em>much</em> more difficult.</li>
<li>It requires that the programmer <em>pay attention</em> to the sequence of enclosing scopes on a <em>line-by-line</em> basis, which is generally too pedantic and not particularly useful for a programmer.</li>
<li>The ability to select “which kind of scope” is by no means only expressible by this notation, as other syntactic features such as keywords and delimiters could express the same thing.</li>
<li>There are only so many line-like characters which can serve as a scope marker, so this scheme is not very extensible.</li>
<li>It complicates parsing (especially by introducing an entirely new class of parse errors in which adjacent lines feature incompatible sequences of delimiting lines), and so it also...</li>
<li>Complicates parse <em>error messages</em>, which are an important part of a language's UI and should be considered seriously.</li></ul>

<p>So, as in my previous post on <a href="https://journal.infinitenegativeutility.com/2014/8/noun-case" rel="nofollow">grammatical case in programming languages</a>, I urge readers <em>not</em> to use this notation as the concrete syntax for a programming language. This is merely an entertaining peek through the looking glass at a curious notational convention which was never adopted.</p>

<p>That said: this makes a very nice notation for <em>viewing</em> code, where the programmer does not have to explicitly draw ASCII art around their code; indeed, it bears more than a passing similarity to the graphical interface used in <a href="http://scratch.mit.edu/" rel="nofollow">Scratch</a>, and Sean McDirmid's <a href="http://research.microsoft.com/en-us/projects/liveprogramming/typography.aspx" rel="nofollow">Experiments in Code Typography</a> features this very convention as an interactive ornament on code in a Python-like language.</p>

</div></div>]]>
            </description>
            <link>https://journal.infinitenegativeutility.com/blocks-courtesy-of-konrad-zuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712727</guid>
            <pubDate>Sun, 10 Jan 2021 09:21:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top Ranked Tweets on Hacker News 2020]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25712499">thread link</a>) | @hgarg
<br/>
January 10, 2021 | https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/ | <a href="https://web.archive.org/web/*/https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <ul>
<li>Data curated from <a target="_blank" rel="noopener" href="http://explorehackernews.xyz/?ref=harishgarg.com">Hacker News Front Page Explorer</a></li>
</ul>
<p>1.Every Google result now looks like an ad </p><p>2.macOS unable to open any non-Apple application </p><p>3.John Conway has died </p><p>4.iOS14 reveals that TikTok may snoop clipboard contents every few keystrokes </p><p>5.This electrical transmission tower has a problem </p><p>6.Apple does not keep the 30% commission on a refund </p><p>7.AWS forked my project and launched it as its own service </p><p>8.Google no longer providing original URL in AMP for image search results </p><p>9.Guido van Rossum joins Microsoft </p><p>10.When a customer refunds your paid app, Apple refunds its 30% cut </p>
<p>Get the Full list (162 records) <a target="_blank" rel="noopener" href="https://gum.co/hacker-news-tweets-2020">here for FREE</a></p>
<p>Want to run this and other kind of analysis on your own? Get the Full Database <a target="_blank" rel="noopener" href="http://explorehackernews.xyz/?ref=harishgarg.com">here</a></p>

  </div></div>]]>
            </description>
            <link>https://harishgarg.com/writing/hacker-news-front-page-tweets-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712499</guid>
            <pubDate>Sun, 10 Jan 2021 08:52:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Breakthrough in Measuring the Building Blocks of Nature]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25712475">thread link</a>) | @CapitalistCartr
<br/>
January 10, 2021 | http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<figure data-alt=""><img src="http://static.nautil.us/18082_ad5db5924e3e97ed8a387a499efa9fa0.jpg" width="733" alt=""><figcaption><span><i>An artistic rendering of the quarks and gluons that make up a proton.</i></span><span>Illustration by D. Dominguez / CERN</span></figcaption></figure><p><span>I</span>n a recent experiment done at the Max Planck Institute for Quantum Optics, in Germany, physicist Alexey Grinin and his colleagues came a step closer to resolving one of the more significant puzzles to have arisen in particle physics over the past decade. The puzzle is this: Ordinarily, when you set about measuring the size of something, you’d expect to get the same answer no matter what you use to measure it—a soda can has the diameter it does whether you measure it with a tape measure or callipers (provided these are properly calibrated, of course). Something must be amiss if your attempts to measure the can return different answers depending on the equipment, yet this is precisely what’s happened over multiple attempts to measure the spatial extent of a proton. What’s potentially at stake is our understanding of the building blocks of reality: the <a href="https://science.sciencemag.org/content/370/6520/1061.abstract" target="_blank">differing measurements</a> could be heralding the existence of new forces or particles.</p><p>What does it mean for a subatomic particle to have a measurable “size”? Mathematically, fundamental particles are idealized as point particles, which is to say that, as far as we can tell, they have no meaningfully discernible spatial extent, or substructure, at all. True, all fundamental particles are associated with a quantum mechanical wave packet, which does have a spatial extent that depends on the energy of the particle. Yet these basic bits of Lego are entities whose wave packets you can, in principle, pack into as small a region as you’d like before the very notion of continuum geometry starts, at the Planck scale, to lose meaning. Fundamental particles organize into something analogous to a mini periodic table—consisting of the various force carrying particles, such as photons and gluons (the carrier particles of the strong nuclear force), along with three generations of quarks and leptons and the mass-generating Higgs boson—and can stack together in different combinations to form a zoo of so-called composite particles.</p><blockquote><p>There is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p> </blockquote><p>Perhaps the most familiar and ubiquitous of these is the proton. With at least one in every kind of element, it’s made up of two up quarks and a down quark that dance around each other in a tightly bound orbit maintained by exchanging gluons. This exchange process is so energetic that most of the mass of the proton (or for that matter, most of the material that makes us up) derives from the energy contained in these gluons—a consequence, as Einstein informed us, of <i>E</i> being equal to <i>mc</i><sup>2</sup>.&nbsp;<br></p><figure data-alt=""><img src="http://static.nautil.us/18083_78b8d6620afcd434a4b7fb41b22e595b.png" width="733" alt=""><figcaption><span><i>Fundamental particles organize into something analogous to a mini periodic table (above).</i></span><span>CERN</span></figcaption></figure><p>So it’s not meaningless to ask what the “size” of the proton is. The study by Grinin’s team highlights the fact that defining this notion remains a rather tricky affair. And, as we’ll see, their results serve to sharpen the mystery as to why other measurement methods researchers have used previously disagree.<br></p><p>A physicist can reasonably infer a proton’s size from the “charge radius”—roughly the averaged spatial extent of quark orbits inside. This quantity is probed in slightly different ways by electrons and muons (another sort of fundamental particle), when you probe their orbital configurations as they form “bound states” with the proton—atomic hydrogen in the case of electrons, muonic hydrogen in the case of muons. Because muons are about 200 times heavier than electrons, their lowest energy orbital configurations are much more tightly bound around the proton than are electrons in atomic hydrogen. Consequently, the differences in the energies of various orbitals in muonic hydrogen are much more sensitive to the proton’s size as well as being more “high pitched” than that of regular atomic hydrogen.&nbsp;</p><p>In other words, similar to how plucking a guitar string at a given tension produces a much higher note were we to fret it open, or at 1/200th its open length, the typical frequencies of the radiation emitted by transitions in muonic hydrogen are about 200 times higher than that in atomic hydrogen. These frequencies relate to something called the Rydberg constant—the tension of the guitar string in the analogy—which appears to be one of the potentially more significant sources of uncertainty proton size-wise. Orbital energy levels depend on both this constant and the charge radius of the proton.</p><p>Proton-size measurements didn’t conflict for decades. Different methods—like measuring the radius by observing electrons orbit within hydrogen atoms, or by scattering energetic electrons off of unbound protons—had converged on a value of 0.875 (give or take 0.006) femtometers. That’s a little less than a trillionth of a millimeter. That convergence was disrupted in 2010, when a paper came out titled, “The size of the proton.” As the researchers reported, <a href="http://www.quantum.physik.uni-potsdam.de/teaching/ss2015/pqt/Pohl2010.pdf" target="_blank">measurements</a> involving orbital configurations in muonic hydrogen returned a value of 0.842, give or take 0.001 femtometers. This may not seem like much of a difference, but it’s the accompanying error bars that matter. The measurements are, individually, so precise that their disagreement is over seven standard deviations—there is less than one in about a trillion chance that the discrepancy could be a statistical fluke.</p><p>There are only two possibilities for the anomalous result if the equipment used in the experiments and their calibrations all check out after careful scrutiny. Either some combination of physical constants, which researchers assume in order to experimentally infer the proton charge radius, isn’t known as accurately as we thought, or there is something different about the way muons interact with protons, compared to electrons, that renders particle physics incomplete.</p><p>The latter possibility, if substantiated, would, of course, cause a flurry of excitement among theoretical physicists to say the least, as it could imply the existence of new forces and particles. Not only would it reshape our understanding of the universe, it would represent a throwback to the days when physicists discovered particles (<a href="https://timeline.web.cern.ch/anderson-and-neddermeyer-discover-muon" target="_blank">such as the muon itself</a>) using equipment that could fit on a proverbial tabletop.</p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div><p>Over the past few years, various teams have been attempting to get to the bottom of the matter by looking at different orbital transitions in atomic hydrogen that are sensitive to different combinations of the Rydberg constant and the charge radius. A 2019 <a href="https://science.sciencemag.org/content/365/6457/1007" target="_blank">measurement</a> by a group of researchers at York University in Canada looked at a particular orbital transition that was independent of the value of this constant, finding a value of 0.833 ± 0.010 femtometers, consistent with the smaller value obtained in muonic hydrogen.&nbsp;</p><p>Grinin’s team went a step further. They used a technique known as frequency comb spectroscopy. It involves pulses of laser light that are a superposition of equally spaced frequencies—a ruler in frequency space if you will—that allowed them to look at two different orbital transitions in atomic hydrogen sensitive to two different combinations of the proton size and the Rydberg constant. This permitted them to determine both with unprecedented accuracy. The technique reduced, to only about one part in ten trillion, the observational uncertainties in the frequency of light these transitions emitted—a staggering degree of accuracy by any standard.&nbsp;</p><p>Not only did Grinin’s team find a value for the charge radius of the proton consistent with the value obtained in muonic hydrogen, they inferred a much more precise value for the Rydberg constant. This accounted for some part of the discrepancy seen in other measurements in atomic hydrogen (which presumed a less accurate value).</p><p>It thus appears that the experimental value of the proton charge radius Grinin’s team obtained in atomic hydrogen is converging on the smaller values for the proton charge radius other researchers initially obtained in muonic hydrogen. The smaller value has by now even been adopted as the <a href="https://physics.nist.gov/cgi-bin/cuu/Value?rp" target="_blank">official value</a> on the National Institute of Standards and Technology <a href="https://www.nist.gov/programs-projects/codata-values-fundamental-physical-constants" target="_blank">CODATA</a> list of recommended physical constants—the official almanac for nuclear and atomic chemists and physicists.&nbsp;</p><p>Although this convergence, based on the continued refinement of experimental techniques, did not deliver the new physics some may have been hoping for, even the most despondent theoretical physicist can acknowledge the experimental artistry that seems to be bringing the matter closer to conclusion. What remains unresolved is the reason why measurements, relying on different spectroscopic methods in atomic hydrogen, return different values for the charge radius of the proton. The mystery, and along with it, the diminishing hope of particle physicists, endures for the time being.&nbsp;</p><p>This was enough motivation for a team of theoretical physicists, led by Cliff Burgess at the Perimeter Institute, in Canada, to systematically catalogue all possible sources of theoretical uncertainty in atomic spectroscopy over a <a href="https://inspirehep.net/literature?sort=mostrecent&amp;size=25&amp;page=1&amp;q=find%20a%20burgess,%20c%20and%20a%20zalavari" target="_blank">series of papers</a>. By isolating the ways in which new forces and particles might leave a tell-tale signature, they’ve thrown the gauntlet firmly back to the experimentalists. Future experiments, as always, will be the ultimate arbiter in this matter.&nbsp;</p><p><i>Subodh Patil is an assistant professor at the Lorentz Institute for Theoretical Physics at Leiden University. He tweets on occasion at @_subodhpatil.</i></p>

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/blog/a-breakthrough-in-measuring-the-building-blocks-of-nature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25712475</guid>
            <pubDate>Sun, 10 Jan 2021 08:48:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A guide to SQL interview questions]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25709870">thread link</a>) | @data4lyfe
<br/>
January 9, 2021 | https://www.interviewquery.com/blog-sql-interview-questions/ | <a href="https://web.archive.org/web/*/https://www.interviewquery.com/blog-sql-interview-questions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p><strong>Table of Contents</strong></p><!--kg-card-begin: html-->
<!--kg-card-end: html--><h3 id="introduction">Introduction</h3><p>SQL is the good old friend that has always worked. It’s something you always come back to, even as Pandas, Julia, Spark, Hadoop, and NoSql attempt to dethrone and replace SQL as the new de-facto data tool.</p><p>Eventually though, they all fail in the face of the consistently reliable SQL. And that's why SQL continues to get asked in interviews. </p><blockquote><strong>A note before we start...</strong></blockquote><blockquote>This guide should be used for anyone who is preparing for an interview in which they know SQL will show up. This guide<strong> is not</strong> a search engine optimized listacle (top 50 sql questions for 2021...really?).</blockquote><blockquote>Rather, this is <strong>real advice and REAL interview questions and exercises </strong>gathered from hundreds of data scientists, engineers, and analysts. We sprinkle exercises throughout this post after learning concepts. Be sure to try attempting the questions first before we walk through solving them. &nbsp;</blockquote><blockquote>Lastly, if you enjoy this article, <strong>please give us a share</strong> and check out our <a href="https://www.interviewquery.com/courses/data-science-course">SQL course</a> that goes a little deeper with more exercises and problems. </blockquote><h2 id="1-why-does-sql-show-up-on-the-interview">1. Why does SQL show up on the interview?</h2><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-6.png" alt="" srcset="https://blog.interviewquery.com/content/images/2021/01/image-6.png 600w"></figure><p>SQL allows data scientists and engineers to do a couple of important things.</p><p>One is to <strong>effectively store and retrieve information at scale for analytics</strong>. Even though Google Sheets allows users to easily manipulate and visualize data, it cannot store and scale like a SQL database can. Other popular programs –namely Hadoop and Spark– can scale much further than SQL, but still don’t have a clean and easy-to-use language like SQL to retrieve data efficiently.</p><p>Another great thing about SQL is that understanding the fundamentals bridges the gap between <strong>engineering and data science</strong>. Knowing SQL well gives you a competitive edge over any other candidate, whether you're competing for a position as a product manager, software engineer, or even as a business analyst. Having the skillset to write and pull your own queries is like being a magician that can come up with analyses out of thin air. </p><p>And at the end of the day, you could just be really good at SQL if you wanted to and make tons of money creating ETL jobs or pulling dashboards with efficiency. That's how valued SQL is. </p><h3 id="how-often-does-sql-show-up-in-interviews">How often does SQL show up in interviews?</h3><p>One prevailing question is how often SQL shows up in interviews. </p><p>At Interview Query, we analyzed a dataset of Glassdoor data science interview experiences and responses submitted by our users. The analysis came back that SQL was asked:</p><ul><li><a href="https://www.interviewquery.com/interview-experiences/facebook/data-scientist" rel="nofollow">70% of the time during Facebook’s data science interviews</a></li><li><a href="https://www.interviewquery.com/interview-experiences/Amazon/business-analyst" rel="nofollow">94% of the time during Amazon’s business intelligence and analyst interviews</a></li></ul><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image-7.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image-7.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image-7.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image-7.png 1262w" sizes="(min-width: 720px) 720px"><figcaption><a href="https://www.interviewquery.com/interview-experiences/facebook/data-scientist">Skills tested in Facebook's Data Science Interview as of 2021</a></figcaption></figure><p>Due to its nature in being able to get and manipulate your own data, this is by far the most important skill now towards nabbing a data science position. And while pandas and other languages are useful, note that <a href="https://www.interviewquery.com/blog-why-your-data-scientist-interviewer-wont-ask-pandas-questions/" rel="nofollow">SQL will always be the one that matters</a>.</p><h2 id="2-strategies-for-the-live-sql-interview">2. Strategies for the live SQL interview</h2><p>Let's go over the common strategies when tackling SQL interview questions. </p><p><strong>1.Repeat the problem statement</strong></p><p>When presented with a SQL question, listen carefully to the problem description and repeat back what you think the crux of the problem is. The interviewer can then help verify if your understanding is correct.</p><p><strong>2. Understand the edge cases</strong></p><p>If time permits, write out a base case and an edge case to show that you understand the problem. For example: if the interviewer asks you to pull the average number of events per user per day, write out an example scenario where you're verifying this metric. </p><p>Do duplicate events matter? Are we looking at distinct users? These are questions we need to clarify. </p><p><strong>3. Try working backwards if the problem is tricky</strong></p><p>Sketching out what the output of the SQL question will look like is a great strategy towards solving the problem. Usually, if I know what the end output table is supposed to look like, I can work backwards from there on what functions need to be applied before. </p><p>For example, if the output looks like this:</p><pre><code>date        | average events per user
------------+-----------------------
2021-12-01  |  3.5
2021-12-02  |  4.0</code></pre><p>I know that the table before this aggregation would have to look something like this.</p><pre><code>date       | event | user_id
-----------+-------+--------
2021-12-01 | click | 1
2021-12-01 | view  | 1
......</code></pre><p>And then, I can figure out what functions I should use to get to my desired output!</p><p><strong>4. Pattern match to different functions</strong></p><p>As you practice more and more SQL exercises, what you'll find is that many SQL problems follow similar patterns. There are techniques we can use in SQL, like utilizing <code>HAVING</code> on aggregations, self-joins and cross-joins, and applying window functions. But, additionally, we'll see problems that run in a similar vein. </p><p>For example, writing a query to get the second highest salary or writing a query to isolate every fifth purchase by a user utilizes the same <code>RANK</code> function in SQL. </p><p>Understanding the commonalities between questions will help you understand the first step to solving SQL questions faster because you can re-use similar code and stitch together techniques on top of each other. </p><p><strong>5. Start writing SQL</strong></p><p>Finally, it's important to just start writing SQL. It's better to start writing an imperfect solution vs trying to perfectly understand the problem or trying to perfect the solution on the first try. </p><p>Verbalize your assumptions and what you're doing as you write SQL and your interviewer can then be put on the same page as you. </p><h2 id="3-the-7-different-sql-interview-questions">3. The 7 different SQL interview questions</h2><p>SQL questions asked during interviews can vary widely across companies, but even more so across positions. You won't see data scientists asked the same SQL questions as software engineers, and that's because data scientists have to write different types of queries compared to software engineers. </p><p>Generally, each SQL interview question can be bucketed into these categories:</p><ul><li>Definition based SQL questions</li><li>Basic SQL questions</li><li>Reporting and metrics SQL questions</li><li>Analytics SQL questions</li><li>ETL SQL questions</li><li>Database design questions</li><li>Logic based SQL questions</li></ul><p>In this next section, we'll go over which types of SQL questions are expected for different roles and what those different kinds of SQL questions are in detail. </p><h2 id="4-sql-questions-for-data-scientists-and-analysts">4. SQL questions for data scientists and analysts</h2><p>SQL interview questions for data scientists and data analysts will likely show up in three parts of the interview process: the technical round, the take-home challenge, and the onsite interview. </p><p>The technical round and take-home challenge will usually consist of SQL questions <strong>designed to filter out candidates</strong>. Since SQL is commonly used as a filter mechanism for data scientists, it's important to perform well on this part of the interview in order to demonstrate competence. </p><p>Depending on what type of data science role you're interviewing for, you'll find that most SQL questions will be split into these three types:</p><ul><li>Basic SQL Interview Questions</li><li>Reporting and Metrics SQL Interview Questions</li><li>Analytics SQL Interview Questions</li></ul><h3 id="basic-sql-interview-questions">Basic SQL Interview Questions</h3><p>Basic SQL questions are what they sound like. These questions will be generally easy and focus on assessing if you know the basics. </p><p><strong>Definition based SQL questions </strong>are grouped into this category because they're super easy to learn. All you have to do is study a list of definitions of SQL terms and applications. These questions will include understanding the differences between joins, what kinds of aggregations exist, and knowing the basic functions like <code>CASE WHEN</code> or <code>HAVING</code>. </p><p>Basic SQL interview questions that involve a user actually writing a query are slightly different. These will involve getting the <code>COUNT</code> of a table, knowing what the <code>HAVING</code> clause does, and figuring out how to utilize <code>LEFT JOIN</code> versus <code>INNER JOIN</code> to give you the values that you need.</p><blockquote>Read more on the the <a href="https://www.interviewquery.com/blog-three-sql-questions-you-must-know-to-pass/">basic concepts you need to know to pass your data science interview</a> here. </blockquote><figure><a href="https://www.interviewquery.com/blog-three-sql-questions-you-must-know-to-pass/"><div><p>Three SQL Concepts for your Data Scientist Interview</p><p>I’ve interviewed a lot of data scientist candidates and have found there are a a lot of SQL interview questions for data science that eventually boil down to three generalized types of conceptual understandings.</p><p><img src="https://blog.interviewquery.com/favicon.ico"><span>Interview Query Blog</span></p></div><p><img src="https://blog.interviewquery.com/content/images/2020/02/sql_join.jpeg"></p></a></figure><p><strong>Basic SQL Concepts to Review</strong></p><ul><li>What's the difference between a <code>LEFT JOIN</code> and an <code>INNER JOIN</code>?</li><li>When would you use <code>UNION</code> vs <code>UNION ALL</code>? What if there were no duplicates?</li><li>What's the difference between <code>COUNT</code>and <code>COUNT DISTINCT</code>?</li><li>When would you use a <code>HAVING</code> clause versus a <code>WHERE</code> clause?</li></ul><p><strong>Basic SQL Question Example:</strong></p><figure><img src="https://blog.interviewquery.com/content/images/2021/01/image.png" alt="" srcset="https://blog.interviewquery.com/content/images/size/w600/2021/01/image.png 600w, https://blog.interviewquery.com/content/images/size/w1000/2021/01/image.png 1000w, https://blog.interviewquery.com/content/images/2021/01/image.png 1306w" sizes="(min-width: 720px) 720px"></figure><blockquote><em>We're given two tables, a <code>users</code> table with demographic information and the neighborhood they live in and a <code>neighborhoods</code> table.</em></blockquote><blockquote><em>Write a query that returns all of the neighborhoods that have 0 users.</em></blockquote><p>Try answering this question with our <a href="https://www.interviewquery.com/questions/empty-neighborhoods">interactive SQL editor</a>.</p><p><strong>Here's a hint:</strong></p><p><em>Our predicament is to find all the neighborhoods without users that live in them. This means we have to introduce a <strong>concept of existence of a field in one table, while not existing in another.</strong></em></p><p><em>For example, let's say we generate some fake data of user's and the neighborhoods they live in. We would expect it to look something like this. </em></p><pre><code>neighborhoods.name  | users.id
____________________|__________
castro              | 1
castro              | 2
cole valley         | null
castro heights      | 3
sunset heights      | 4</code></pre><p><em>We see each user from one to four is appropriately placed in their respective neighborhood except for the neighborhood of Cole Valley. That's the neighborhood we're targeting for returning in our query. </em></p><p><em>Strategies: whenever the question asks about finding values with 0 something (users, employees, posts, etc..), immediately think of the concept of <strong><code>LEFT JOIN</code></strong>! An inner join finds any values that are in both tables, <strong>a left join keeps only the values in the left table</strong>.</em></p><p><em>Our predicament is to find all the neighborhoods without users. To do this, we must do a left join from the <code>neighborhoods</code> table to the <code>users</code> table.</em></p><p><em>If we then add in a where condition of <strong><code>WHERE users.id IS NULL</code></strong>, we will get every single neighborhood …</em></p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.interviewquery.com/blog-sql-interview-questions/">https://www.interviewquery.com/blog-sql-interview-questions/</a></em></p>]]>
            </description>
            <link>https://www.interviewquery.com/blog-sql-interview-questions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25709870</guid>
            <pubDate>Sun, 10 Jan 2021 04:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Platform Is the Enemy]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25708099">thread link</a>) | @nomdep
<br/>
January 9, 2021 | https://danielbmarkham.com/the-platform-is-the-enemy/ | <a href="https://web.archive.org/web/*/https://danielbmarkham.com/the-platform-is-the-enemy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div id="post-body">
        <p>The premise of the movie "Idiocracy" is simple: in the future mankind has de-evolved into morons. Technology does so much for everybody that nobody knows how it all works anymore. &nbsp;If we can't fix it, we're all going to die.</p><p>One character asks the other what he likes, The answer is money.</p><p>"I can't believe you like money too!" the first character says without irony, "We should hang out!"</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/JRJcXbeoSOlkRRzbC7HJ_idiocracy.jpg" alt=""></figure><p>The gag here is that of course, most everybody likes money. If you reduce all of your life enough, it's just food, sex, money, and looking cool. But who would want to do that? Over the centuries, humans have created massively-complex societies because everybody has different things they like doing and thinking about, but all of that complexity can be reduced to, well, an idiocracy if you try hard enough.</p><p>The movie, however, is just a joke, right? We would never allow that to happen, of course, because that's not the goal of technology. Technology's goal is to make us better, not dumber.</p><p>Wait one. Is that true? What <em>is</em> the goal of technology, anyway? Has anybody ever clearly stated it?</p><p>Recently I've heard two goals:</p><ol><li>The goal of technology is to become a <strong>brain extension</strong>, <em>helping you to decide what to do</em> and then helping you get it done.</li><li>The goal of technology is to become a <strong>hand-held power tool</strong>, helping you accomplish the things you've <em>already decided to do</em></li></ol><p>That's not the same thing. It turns out the difference is critical.</p><p>The old goal was much simpler: make something people want. I like that goal! It boils down the job of creating technology to the most important parts, need and ability. But was that sustainable? At the end of the day, don't we always end up making some combination of stuff that either helps us <em>make decisions</em> or helps us <em>implement decisions</em> we've already made? And aren't the two fundamentally incompatible in a future society?</p><p>Yelp tells you which restaurant to go to. Your GPS automatically takes you there. These are not just different problems, they're different <em>kinds of problems</em>. Getting from point A to point B is a matter of math and geometry. Which restaurant is the best tonight? You could spend hours debating that with friends.</p><p>If you reduce anything down enough it becomes idiotic. Each piece of technology we deploy can have the goal of helping us do what we've already decided or helping us decide what to do. The first option leaves the thinking up to us. The second option "helps" us think.</p><figure><iframe width="267" height="200" src="https://www.youtube.com/embed/sZHCVyllnck?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><p>You like money too? Wow! I like money! We should hang out!</p><p>Human brains are not computers. Brains are designed to help us survive and pass on our genes using the minimum amount of energy available. If the GPS takes me where I'm going, I don't need to know how to use maps anymore. So I stop knowing how to use maps. Dump those neurons, they're not needed. If Yelp picks the restaurants for me enough, I stop having nuanced preferences about restaurants. That energy expenditure is no longer needed for survival and reproduction. Dump those neurons. Over time people stop caring about the tiny details of what the difference is between a good and a great restaurant. Yelp handles that.</p><p>For some folks, who cares? It's food. Go eat it. For other folks, picking the right place can be a serious undertaking, worthy of heavy thought and consideration. But if over the years apps like Yelp boil all of that down to four or five stars, then our collective brain is not going to bother with it. Human brains are not computers. If computers do the work for us, we turn off those neurons and save energy.</p><p>Meanwhile, on social media there's currently this huge discussion. One bunch of folks says that social media is being overbearing in its censorship of fringe and sometimes hateful opinions. The other bunch of folks says social media is a festering sore full of people who are ugly, hateful, and abusive to those weakest among us. The community has to set standards.</p><p>There doesn't have to be a right and wrong here. I think the crucial thing to to understand that both sides can be entirely correct. We are dealing with the same kind of question.</p><p>All three of these topics -- whether humanity is becoming idiots or not, what the ultimate goal of technology is or should be, and how social media should work -- are intricately related. They're related because of this: <em>the platform is the enemy</em>.</p><p>The minute we create a platform for something, whether it's rating movies, tracking projects, or chatting with friends about work, as that platform takes over mindshare, <em>the assumption becomes that this is a solved problem</em>.</p><p>The telephone was great. Once we had the telephone, people didn't have to worry about how to talk to people far away anymore. Just pick up the phone. Solved problem.</p><p>Facebook is great. Once we had Facebook, people didn't have to worry about how to interact with their friends in a social setting anymore. Just click on the little FB notification (Which seems to be always flashing for some reason to get my attention) Solved problem?</p><p>But these are entirely different things! With the phone, I know who I want to call and why. I push buttons and we are connected. The tech helps me do what I've already decided to do. With Facebook, on the other hand, they get paid to show me things in a certain order. The premise is that I'm waiting (or "exploring" if you prefer) until I find something to interact with. The phone is a tool for me to use. I am the tool Facebook is using. I am no longer acting. I am reacting.</p><p>And even if they weren't paid, interacting with friends socially is an extremely complex affair. What kind of mood are they in? What's their life history? What things are bad to bring up? How does their body language look? Facebook's gimmick is "Hey, we've reduced all of this to bits and bytes, and we'll even show you what bits and bytes to look at next!"</p><p>Solved problem.</p><p>Many, many people do not use the internet, the internet uses them. And this percentage is constantly growing.</p><figure><img src="https://cdn.danielbmarkham.com/2021/01/9EBNeUmSy6TMDUpKTLL6_terminator-robot.jpg" alt=""></figure><p>Just like the restaurant example, maybe that's fine. I have friends, I have opinions, who cares? It's all idle chat anyway.</p><p>That logic can be true for a bunch of things, but can't be true for <em>everything</em>. Otherwise, at some point 100 years from now, we're comparing our life values and end up saying something like "I like money too". Everything can't all be reduced down to the lowest common denominator. If it does, we all die.</p><p>Life is not a bit or byte, a number to be optimized. It's meaning we define ourselves, in ways we should not quantize.</p><p>Platforms, by their very nature, constantly send out the subtle message: <em>This is a solved problem. No further effort on your part is required here. No thinking needed.</em> Platforms resist change. They resist their own evolution by subtly poisoning the discussion before it even starts.</p><p>Are restaurant choices more or less important than which movie to watch tonight? There's no right or wrong answer to these questions. We have nice categories like restaurants and movies because currently people consider those things to be different kinds of choices. But why? If the algorithm is king, why shouldn't an algorithm determine both of those things for me? And if it does, why should I bother with worrying about which category is which?</p><p>Human brains are not computers. Let the platform decide. Energy not needed. Dump those neurons.</p><p>This is the more important point. It's not that the platforms turn what might be complex things into simple numbers, or even that they monetize attention. It's that by turning everything into numbers, over time they destroy the distinction between the categories entirely. Platforms are the enemy because they resist analysis in the areas they dominate.</p><p>Platforms turn into settled fact things that should be open for debate, like whether or not Taco Bell is a Mexican restaurant, or whether Milo is an artist with something useful to tell us. (I'm going with "no" and "no" for both of these.) More dangerously, they do the work of deciding <em>what categories various things go into</em>. This category over here is important. That category over there is not. We all make these decisions, and they're all different, and the categories each of us pays careful attention to and loves obsessing about are all different, and because we all have different viewpoints and priorities humankind advances in thousands of directions simultaneously. We survive. We evolve.</p><p>Twitter has to decide whether PERSON_X can speak or not because on the Twitter platform, that question has to have a yes or no answer based on the person. Twitter's category for deciding who can speak is "who is that?" Is that the right category for social conversations? For political conversations? For conversations about philosophy? Math? Who knows? Who cares? Twitter has decided. Solved problem.</p><p>Everybody has different things they like doing and thinking about. Different conversations and audiences have different criteria. Some problems should never be solved. Or rather more directly, some problems should never have a universal answer.</p><p>An aside: We see the same thing in programming. One bunch of folks creates various platforms in order to do the thinking for another bunch of folks. Sometimes these platforms take off and become industry standards. That's quite rare, however. Most of the time we end up training morons who can weakly code against the platform but can't reason effectively about the underlying architecture or reason for the platform to exist in the first place. In our desire to help, we harm the very people we're trying to assist -- by subtly giving them the impression that this is a solved problem. Programmers are just a decade or so ahead of the rest of us.</p><p>Popular platforms aren't just a danger economically because they control commerce. They're not just a danger politically because they selectively control and amplify political discourse. They're an extinction-level, existential danger to humans because they prevent people from seriously considering what kinds of categories are important in …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danielbmarkham.com/the-platform-is-the-enemy/">https://danielbmarkham.com/the-platform-is-the-enemy/</a></em></p>]]>
            </description>
            <link>https://danielbmarkham.com/the-platform-is-the-enemy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25708099</guid>
            <pubDate>Sun, 10 Jan 2021 02:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Podcast on innovation systems, with Ben Reinhardt]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25707442">thread link</a>) | @willbobaggins
<br/>
January 9, 2021 | https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/ | <a href="https://web.archive.org/web/*/https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1985">

                    
                    <div>
                        
<p>In this episode, we talk with Ben Reinhardt about different innovation systems, how to create more sci-fi technology a reality, and why our research institutions are not as effective as they used to be. You can check out Ben’s work at https://benjaminreinhardt.com/about/.</p>



<div><p>Some things mentioned in the episode: </p><p><a href="https://slatestarcodex.com/2020/05/12/studies-on-slack/">Studies on Slack</a></p></div>



<p><a href="https://en.wikipedia.org/wiki/Donald_Braben">Don Braben</a></p>



<p><a href="https://en.wikipedia.org/wiki/DARPA">DARPA</a></p>



<p>Ben’s <a href="https://twitter.com/ben_reinhardt?lang=en">Twitter</a></p>



<figure></figure>
                                            </div>

                </article></div>]]>
            </description>
            <link>https://narrativespodcast.com/2020/12/21/21-innovation-systems-with-ben-reinhardt/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25707442</guid>
            <pubDate>Sun, 10 Jan 2021 01:30:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blocks Courtesy of Konrad Zuse (2014)]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25705391">thread link</a>) | @Tomte
<br/>
January 9, 2021 | https://blog.infinitenegativeutility.com/2014/9/blocks-courtesy-of-konrad-zuse | <a href="https://web.archive.org/web/*/https://blog.infinitenegativeutility.com/2014/9/blocks-courtesy-of-konrad-zuse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Apparently, I've got a theme going of Weird Syntax. Let's run with it.</p>

<p>Konrad Zuse was an early pioneer in computer science, although his name is perhaps somewhat less well-known than others. Zuse holds the honor of having built the first programmable computer—-the Z3—-back in the 40's, as well as several other computing firsts<sup id="fnref:1"><a href="#fn:1" rel="nofollow">1</a></sup>. Of particular interest to this blog post is his early unimplemented programming language, Plankalkül.</p>

<p>Plankalkül was, like the Z3, in many respects ahead of its time. Zuse's explicit goal was to be able to describe programs at a high level, which meant he included control structures and datatype definitions<sup id="fnref:2"><a href="#fn:2" rel="nofollow">2</a></sup> and other high-level constructs that were often missing in languages of the early years of computing. Zuse was working on Plankalkül at a time when his machines were not useable, which meant that his language work was more theoretical than it was technical, and consequently he allowed features that he wasn't entirely sure how to program. Despite his notes on it having been written in the mid-40's, they were not published until the 70's, and it was not implemented until the year 2000.</p>

<p>One thing that struck me, as I read programs in this notation that had been set down on a typewriter<sup id="fnref:3"><a href="#fn:3" rel="nofollow">3</a></sup>, is that certain kinds of grouping were handled by explicit indication of scope: not via matched delimiters as in ALGOL-style languages, or via indentation in languages such as Python and Haskell, but by formatting the code so that a line bordered on the left of the scoped parts of the code:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-01.png" alt=""></p>

<p>This is meant to capture the way grouping works in the hand-written or typeset notation, with brackets spanning multiple lines:</p>

<p><img src="https://blog.infinitenegativeutility.com/static/zuse-02.png" alt=""></p>

<p>I think this is notationally interesting: it's like Python's significant whitespace, but not, uh, whitespace. It would be incredibly tedious to type out, but still entirely compatible with current programming notation:</p>

<pre><code>class Tet
 | @staticmethod
 | def new_tet()
 |  | n = randint(0, len(Tet.Tets) - 1)
 |  | for p in Tet.Tets[n]
 |  |  | if p in Board.permanent
 |  |  |  | Game.lose()
 |  | Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 |
 | def __init__(self, points, color)
 |  | self.points = points
 |  | self.color = color
</code></pre>

<p>and would be entirely amenable to beautifying via judicious application of Unicode:</p>

<pre><code>class Tet
 ┃ @staticmethod
 ┃ def new_tet()
 ┃  ┃ n = randint(0, len(Tet.Tets) - 1)
 ┃  ┃ for p in Tet.Tets[n]
 ┃  ┃  ┃ if p in Board.permanent
 ┃  ┃  ┗  ┗ Game.lose()
 ┃  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ┃
 ┃ def __init__(self, points, color)
 ┃  ┃ self.points = points
 ┃  ┗ self.color = color
</code></pre>

<p>Looking at this notation, however, an interesting possibility struck me: a programmer could explicit annotate information about the <em>kind of scope</em> involved in a given line. In this Python-like example, I could, for example, distinguish class scope using double lines, function scope with thick lines, and control structure scope with thin lines:</p>

<pre><code>class Tet
 ║ @staticmethod
 ║ def new_tet()
 ║  ┃ n = randint(0, len(Tet.Tets) - 1)
 ║  ┃ for p in Tet.Tets[n]
 ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
 ║  ┗ Game.current = Tet(Tet.Tets[n], Tet.TetColors[n])
 ║
 ║ def __init__(self, points, color)
 ║  ┃ self.points = points
 ║  ┗ self.color = color
</code></pre>

<p>One advantage of this scheme is that a handful of lines, viewed in isolation, still give you a clear view of what surrounds them. For example, I can view these two lines in isolation and still tell that they are within a control structure used within a function declared within a class:</p>

<pre><code> ║  ┃  │ if p in Board.permanent
 ║  ┃  └  └ Game.lose()
</code></pre>

<p>You could also imagine a hypothetical language in which choice of scope delimiter is important. In Python, <code>for</code> and <code>if</code> do not form a new lexical scope. What if instead we could stipulate the kind of scope they form by this notational convention?</p>

<pre><code>def okay()
 ┃ if True
 ┃  └ n = 5   # n is declared in function scope
 ┗ return n   # n leaks out of the if-scope

def not_okay()
 ┃ if True
 ┃  ┗ n = 5   # n is declared in the if's scope
 ┗ return n   # error: no n in scope here
</code></pre>

<p>That being said, there are a number of reasons that this notation is in inferior to existing notations:</p>
<ul><li>It makes refactoring code <em>much</em> more difficult.</li>
<li>It requires that the programmer <em>pay attention</em> to the sequence of enclosing scopes on a <em>line-by-line</em> basis, which is generally too pedantic and not particularly useful for a programmer.</li>
<li>The ability to select “which kind of scope” is by no means only expressible by this notation, as other syntactic features such as keywords and delimiters could express the same thing.</li>
<li>There are only so many line-like characters which can serve as a scope marker, so this scheme is not very extensible.</li>
<li>It complicates parsing (especially by introducing an entirely new class of parse errors in which adjacent lines feature incompatible sequences of delimiting lines), and so it also...</li>
<li>Complicates parse <em>error messages</em>, which are an important part of a language's UI and should be considered seriously.</li></ul>

<p>So, as in my previous post on <a href="https://blog.infinitenegativeutility.com/2014/8/noun-case" rel="nofollow">grammatical case in programming languages</a>, I urge readers <em>not</em> to use this notation as the concrete syntax for a programming language. This is merely an entertaining peek through the looking glass at a curious notational convention which was never adopted.</p>

<p>That said: this makes a very nice notation for <em>viewing</em> code, where the programmer does not have to explicitly draw ASCII art around their code; indeed, it bears more than a passing similarity to the graphical interface used in <a href="http://scratch.mit.edu/" rel="nofollow">Scratch</a>, and Sean McDirmid's <a href="http://research.microsoft.com/en-us/projects/liveprogramming/typography.aspx" rel="nofollow">Experiments in Code Typography</a> features this very convention as an interactive ornament on code in a Python-like language.</p>

</div></div>]]>
            </description>
            <link>https://blog.infinitenegativeutility.com/2014/9/blocks-courtesy-of-konrad-zuse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705391</guid>
            <pubDate>Sat, 09 Jan 2021 22:08:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: JavaScript Program Synthesis]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25705059">thread link</a>) | @coolvision
<br/>
January 9, 2021 | https://grgv.xyz/inductive_program_synthesis/ | <a href="https://web.archive.org/web/*/https://grgv.xyz/inductive_program_synthesis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Any compiler or transpiler is doing some form of program synthesis. But “proper” program synthesis usually means generation of high level programs from scratch, given only high level problem descriptions.</p>
<p>This post is about one of the most simple and straightforward methods of automatic program synthesis: inductive synthesis based on <strong>input-output examples</strong> specification and <strong>brute-force enumerative</strong> search.</p>
<h3>Synthesis task specification</h3>
<p>Let's start with a simple example. Suppose that we want to automatically generate a program that reverses an array.</p>
<p>How to formulate this task for the automatic program generator? One option is to just describe it in natural language. But it would be quite hard to automatically parse and understand. A simpler way is to provide examples of inputs and expected outputs:</p>
<p>[1, 2, 3, 4, 5, 6] → [6, 5, 4, 3, 2, 1]</p>
<p>[5, 2, 7, 6] → [6, 7, 2, 5]</p>
<p>It's similar to a programmer working on a task using test-driven development, with a set of self-explanatory tescases.</p>
<h3>Brute-force search</h3>
<p>How to find a program that satisfies some input-output examples? There are several possible search strategies, but the simplest one is just with a brute force enumeration.</p>
<p>The idea is to generate all programs (within some size liimts and a limited language subset), and pick the first one that works correctly for all specified examples.</p>
<p>This is probably the least efficient approach of all, but with some additional optimizations and heuristics for reducing the search space it can actually be practical.</p>
<p>For example, an algorithm that won last year's synthesis competition <a href="https://sygus.org/comp/2019/">SyGuS-Comp 2019</a> in programming-by-examples track, is based on brute-force enumerative search strategy. As well as some previous years winners (<a href="#examples" id="ref1">EUSOLVER, Enumerative CEGIS Solver</a>). There are even some practical applications, for example brute-force search can be used for <a href="http://dl.acm.org/citation.cfm?id=2462174">synthesising distributed systems protocols</a>.</p>
<h3>Generating Javascript</h3>
<p>For generating and manipulating programs, code has to be represented as a data structure. This is not a problem in homoiconic languages like Lisp, but in Javascript it’s harder.</p>
<p>One simple idea (used, for example in miniMAL project <a href="https://github.com/kanaka/miniMAL">https://github.com/kanaka/miniMAL</a>), is to use JSON for representing programs. In this case, JSON arrays are serving as an analog of Lisp s-expressions.</p>
<p>Similar to an s-expression, each JavaScript expression is represented as a JSON array. First element is a function name, and the rest of elements are for function arguments.</p>
<p>For example:</p>
<table>
  <thead>
  <tr>
   <td><strong>Javascript</strong></td>
   <td><strong>JSON</strong></td>
  </tr>
  </thead>
  <tbody><tr>
   <td>Math.pow(x, 2)</td>
   <td>["Math.pow", "x", 2]</td>
  </tr>
  <tr>
   <td>Math.pow(Math.sin(x), 2)</td>
   <td>[“Math.pow”, [“Math.sin”,  “x”], 2]</td>
  </tr>
</tbody></table>
<p>For operators, can use prefix notation:</p>
<table>
  <tbody><tr>
   <td>x = 2 + 2</td>
   <td>["=", x, ["+", 2, 2]]</td>
  </tr>
</tbody></table>
<p>There are some special expressions formats: control flow, variables declaration.</p>
<table>
  <tbody><tr>
   <td><strong>Javascript</strong>
   </td>
   <td><strong>JSON</strong>
   </td>
  </tr>
  <tr>
   <td>let x = 1
   </td>
   <td> ["let", "x", 1]
   </td>
  </tr>
  <tr>
   <td>for (let i = 0; i &lt; 10; i += 1) { console.log(i) }
   </td>
   <td>["for”, ”i”, ”0”, ”10”, ”1”,["block", [“console.log”, “i”]]]
   </td>
  </tr>
  <tr>
   <td>if (i &gt; 1) { i = 1; }
   </td>
   <td>["if", [“&gt;“, “i”, 1], ["block", [“=“, “i”, 1]]]
   </td>
  </tr>
</tbody></table>
<p>Also need syntax conventions for calling methods, accessing properties, and indexing arrays:</p>
<table>
  <tbody><tr>
   <td>let a = new Array(0, 1, 2)
   </td>
   <td>["let", "a", ["new Array", 0, 1, 2]]
   </td>
  </tr>
  <tr>
   <td>a.shift()
   </td>
   <td>[".shift", "a"]
   </td>
  </tr>
  <tr>
   <td>let n1 = a.length
   </td>
   <td>["let",  "n1", [".length_", "a"]]
   </td>
  </tr>
  <tr>
   <td>let n2 = a[1]
   </td>
   <td>["let",  "n2", ["get_index", a, 1]
   </td>
  </tr>
  <tr>
   <td>a[1] = 2
   </td>
   <td>["set_index", a, 0, 0]
   </td>
  </tr>
</tbody></table>
<p>This allows to represent a wide range of possible JavaScript expressions, and covers all language features needed for a simple demo.</p>
<p>Code for transforming from JSON representation to Javascript is fairly simple. It just has to traverse arrays, print out expressions elements in correct order, and deal with code formatting.</p>
<h3>Simple DSL</h3>
<p>For brute-force search to be feasible, search space has to be limited to some restricted domain-specific language subset, which depends on the kind of the target problem.</p>
<p>For example, can design a simple DSL targeted for simple array processing. It should have functions for array access and manipulation, simple arithmetics, and control flow functions.</p>
<table>
  <tbody><tr>
   <td><strong>function</strong>
   </td>
   <td><strong>Javascript</strong>
   </td>
   <td><strong>JSON</strong>
   </td>
  </tr>
  <tr>
   <td>subtract
   </td>
   <td>number = number?? - number??
   </td>
   <td>["-", "number??", "number??", "number"]
   </td>
  </tr>
  <tr>
   <td>add
   </td>
   <td>number = number?? + number??
   </td>
   <td>["+", "number??", "number??", "number"]
   </td>
  </tr>
  <tr>
   <td>greater than
   </td>
   <td>boolean = number?? &gt; number??
   </td>
   <td>["&gt;", "number??", "number??", "boolean"]
   </td>
  </tr>
  <tr>
   <td>less than
   </td>
   <td>boolean = number?? &lt; number??
   </td>
   <td>["&lt;", "number??", "number??", "boolean"]
   </td>
  </tr>
  <tr>
   <td>equal
   </td>
   <td>boolean = number?? == number??
   </td>
   <td>["==", "number??", "number??", "boolean"]
   </td>
  </tr>
  <tr>
   <td>array length
   </td>
   <td>number = array??.length
   </td>
   <td>[".length_", "array??", "number"]
   </td>
  </tr>
  <tr>
   <td>get array element at index
   </td>
   <td>number = array??[number??]
   </td>
   <td>["get_index", "array??", "number??", "number"]
   </td>
  </tr>
  <tr>
   <td>set array element at index
   </td>
   <td>array??[number??] = number
   </td>
   <td>["set_index", "output", "number??", "number??", ""]
   </td>
  </tr>
  <tr>
   <td>for loop
   </td>
   <td>for (let i in array??) { ?? }
   </td>
   <td>["for", "i", ["block", "??"], "in", "array??", ""]
   </td>
  </tr>
  <tr>
   <td>If condition
   </td>
   <td>if (boolean??) { ?? }
   </td>
   <td>["if", "boolean??", ["block", "??"], ""],
   </td>
  </tr>
</tbody></table>
<p>In the DSL description, "??" stands for an undefined value, that can be replaced with an expression or a variable. This notation is taken from <a href="#sketch" id="ref2">SKETCH language</a>, where "??" represents a <em>hole,</em> a placeholder that the synthesizer can replace with an integer constant.</p>
<p>Some undefined values have annotated types. For example "number??" means that the argument should be replaced with an expression that has "number" return value. This allows for additional limitations on the search space.</p>
<h3>Algorithm for program generation</h3>
<p>How to generate all programs that can be represented with the DSL? The algorithm is fairly simple: start with some undefined values, and iteratively replace them with all possible options picked from the list of DSL expressions. Selected and pasted expressions would contain some undefined values of their own, so the process is repeated until all the options are used, or until expressions tree depth reaches some limit.</p>
<p>It’s like iterative template rewriting, and it’s easier to demonstrate with an example:</p>
<table>
<tbody><tr>
	<td>1. Start with an empty/undefined program </td>
	<td>["??", "??", "??", "??"] </td>
</tr>
<tr>
	<td>2. Traverse the expressions tree, and pick the first occurring undefined value </td>
	<td>[<span>"??"</span>, "??", "??", "??"] </td>
</tr>
<tr>
	<td>3. List all options for replacing this value (expressions that have an empty return type) </td>
	<td><span>["set_index", "output", "number??", "number??", ""]</span><br>
		["if", "boolean??", ["block", "??"], ""]<br>
		["if", "boolean??", ["block", "??"], ""]
	</td>
</tr>
<tr>
	<td>4. Repace undefined value with the first option </td>
	<td>[<span>["set_index", "output", "number??", "number??", ""]</span>, "??", "??" ,"??"] </td>
</tr>
</tbody></table>
<p>Steps 2-4 are repeated iteratively. Expressions tree is traversed depth-first, and each found leaf corresponds to a unique program. Press “next” button in the demo below, to see next iterations.</p>


<div id="demo2">

	<p>
		Demo: iterative program generation
	</p>

	<p>step</p>
	<p>reset</p>

	
</div>

<p>Generated programs are verified with the given input-output examples:</p>
<ol>
<li>Translate from JSON represenation to Javascript</li>
<li>Fill pre-defined input array variable with an example</li>
<li>Evaluate the program with eval()</li>
<li>Check if contents of the pre-defined output variable correspond to the output example.</li>
</ol>
<p>The demo below shows program generation for "array reversal" problem. Press “generate” button to see continuous generation, or use “next” to see generation steps. It generates and checks around a million of short programs per minute, and is able so solve the problem in ~10-20s. I tweaked the DSL to have a bare minimum of available expressions, for search to be faster. Size of the program is also limited by number of used varialbes (limited to 4). It would still work with larger more generic DSL, just would take more time.</p>

<div id="demo5">

	<p>
		Demo: generate a program for reversing an array.
	</p>

	<p>step</p>
	<p>generate</p>
	<p>stop</p>
	<p>reset</p>

	<div>

		<div>

			<p>Input/output examples</p>
			

			<p>Generated program</p>
			

			<p>Evaluation result</p>
			
		</div>

		

	</div>
</div>

<p>Some more examples are show below. They also have custom DSLs tuned for each problem, so that it does not take too much time (~10-20s).</p>


<h3> Example: generate a program that finds sum of array elements</h3>

<div id="demo3">

	<p>
		Demo: generate a program that finds sum of array elements
	</p>

	<p>step</p>
	<p>generate</p>
	<p>stop</p>
	<p>reset</p>

	<div>

		<div>

			<p>Input/output examples</p>
			

			<p>Generated program</p>
			

			<p>Evaluation result</p>
			
		</div>

		

	</div>
</div>



<h3> Example: generate a program that finds max element in an array</h3>

<div id="demo4">

	<p>
		Demo: generate a program that finds max element in an array
	</p>

	<p>step</p>
	<p>generate</p>
	<p>stop</p>
	<p>reset</p>

	<div>

		<div>

			<p>Input/output examples</p>
			

			<p>Generated program</p>
			

			<p>Evaluation result</p>
			
		</div>

		

	</div>
</div>

<h2>Refenences &amp; links</h2>
<p>(book) <a href="https://rishabhmit.bitbucket.io/papers/program_synthesis_now.pdf">Program Synthesis</a><br>
Sumit Gulwani, Oleksandr Polozov, Rishabh Singh</p>
<p>(course materials) Introduction to Program Synthesis<br>
<a href="http://people.csail.mit.edu/asolar/SynthesisCourse/Lecture2.htm">http://people.csail.mit.edu/asolar/SynthesisCourse/Lecture2.htm</a></p>
<h3>Papers</h3>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.367.9604&amp;rep=rep1&amp;type=pdf">Dimensions in Program Synthesis</a><br>
Sumit Gulwani</p>
<p><a href="http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=7EC748B93DCDCE0DABC810450BD07AE1?doi=10.1.1.180.1237&amp;rep=rep1&amp;type=pdf">Inductive Programming (A Survey of Program Synthesis Techniques)</a><br>
Emanuel Kitzelmann</p>
<p><span id="examples"><a href="#ref1">↑</a></span><br>
Scaling Enumerative Program Synthesis via Divide and Conquer<br>
Rajeev Alur, Arjun Radhakrishna, and Abhishek Udupa</p>
<p>CVC4SY for SyGuS-COMP 2019<br>
Andrew Reynolds, Haniel Barbosa, Andres Nötzli, Clark Barrett, Cesare Tinelli</p>
<p><span id="sketch"><a href="#ref2">↑</a></span><br>
The Sketching Approach to Program Synthesis<br>
Armando Solar-Lezama</p>
<h3>Blog posts</h3>
<p><a href="https://thegradient.pub/p/577a122d-df49-4e1f-8dc3-324f5c784236/">Software that writes software: on program synthesis</a><br>
Adithya Ganesh</p>
<p><a href="https://barghouthi.github.io/2017/04/24/synthesis-primer/">A Program Synthesis Primer </a><br>
Aws Albarghouthi</p>
<p><a href="https://alexpolozov.com/blog/program-synthesis-2018/">Program Synthesis in 2017-18</a><br>
Alex Polozov</p>
<p><a href="https://www.cs.cornell.edu/~asampson/blog/minisynth.html">Program Synthesis is Possible</a><br>
Adrian Sampson</p>
<p><a href="https://blog.sigplan.org/2020/03/25/homoiconicity-lisp-and-program-synthesis/">Homoiconicity, Lisp, and Program Synthesis</a><br>
Rajesh Jayaprakash</p>
<p><a href="https://blog.sigplan.org/2019/07/31/program-synthesis-in-2019/">Program Synthesis in 2019</a><br>
<a href="https://www.cs.utexas.edu/~bornholt/post/synthesis-explained.html">Program Synthesis Explained</a><br>
<a href="https://www.cs.utexas.edu/~bornholt/post/building-synthesizer.html">Building a Program Synthesizer</a><br>
<a href="https://blog.sigplan.org/2019/11/26/building-your-first-program-synthesizer/">Building Your First Program Synthesizer</a><br>
James Bornholt</p>


			</div></div>]]>
            </description>
            <link>https://grgv.xyz/inductive_program_synthesis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25705059</guid>
            <pubDate>Sat, 09 Jan 2021 21:38:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a runtime reflection system for Rust (Part 3)]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25704707">thread link</a>) | @lukastyrychtr
<br/>
January 9, 2021 | https://www.osohq.com/post/runtime-reflection-pt-3 | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/runtime-reflection-pt-3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2><strong>Part 3: <code>dyn Method</code></strong></h2>
<h3>Introduction</h3>
<p>Welcome to the third and final installment of our series on how we implemented a runtime reflection system in Rust.</p>
<p>So far, we've shown how we came up with a fairly simple <code>Class</code> and <code>Instance</code> model for thinking about runtime Rust classes. In <a href="https://www.osohq.com/post/rust-reflection-pt-1">Part 1</a>, we used these for type checking, and in <a href="https://www.osohq.com/post/runtime-reflection-pt-2">Part 2</a> we added support for reading attributes off of a struct.</p>
<p>In this post, we pick up where we left off with attribute getters, and expand into <strong>method calls</strong>. In some ways, the same techniques we used for attributes work just as well here. We can store a map from method name to functions implementing them. However, there's a curveball: the Rust <code>Fn*</code> traits. We'll talk through the wrong turns we took, and the tidbits of Rust knowledge we picked up along the way.</p>
<h2>Method Calls</h2>
<p>Now that we have classes, instances, and attributes, the next obvious step is to add methods.</p>
<p>In oso policies, it is possible to call both class and instance methods, with and without arguments.</p>
<p>So given the struct:</p>
<pre><code>struct Cat;

impl Cat {
    /// A class method (note lack of `self`).
    fn meow() -&gt; String {
       "meowww".to_string()
    }

    /// An instance method.
    fn feed(&amp;self, food: &amp;str) -&gt; String {
        if food == "tuna" { "purr".to_string() } else { Self::meow() }
    }
}
</code></pre>

<p>We should be able to write policy logic:</p>
<pre><code>favourite_food(cat: Cat, food) if cat.feed(food) != Cat.meow();
</code></pre>

<p>Which says that the input <code>food</code> is the cat's favourite food if the result of feeding the cat is not the same as the result of the cat meowing.</p>
<h3>Step 1: Zero arguments</h3>
<p>Let's start with a simple implementation for methods that take <em>zero</em> arguments. The approach for implementing zero-argument methods is extremely similar to how we'd implement attribute getters, and we've actually done this already in Part 2:</p>
<pre><code>/// Class definitions
struct Class {
    ...

    /// Map from attribute name to the attribute lookup
    methods: HashMap&lt;&amp;'static str, InstanceMethod&gt;
}

struct InstanceMethod(Arc&lt;dyn Fn(&amp;Instance) -&gt; PolarValue);
</code></pre>

<p>Similarly, we need to add a method onto our <code>ClassBuilder</code> struct to allow us to register new methods:</p>
<pre><code>pub fn add_method&lt;F, R&gt;(mut self, name: &amp;'static str, f: F) -&gt; Self
where
    F: Fn(&amp;T) -&gt; R,
    R: crate::ToPolar,
{
    self.class.methods.insert(name, InstanceMethod::new(f));
    self
}
</code></pre>

<p>Super easy! End of blog post. See you next time 😎 </p>
<p>But wait, what about methods with multiple arguments?</p>
<h3>Step 2: Multiple Arguments and the <code>Fn*</code> traits</h3>
<p>Let's take what we have above and add in support for multiple arguments.</p>
<pre><code>struct InstanceMethod(Arc&lt;dyn Fn(&amp;Instance, Vec&lt;PolarValue&gt;) -&gt; PolarValue&gt;);
</code></pre>

<p>This mostly works for what we need! Polar doesn't care about method arities (how many arguments the method accepts) – it will send over however many arguments it has as a vector. Polar supports both variable number of arguments (varargs) and keyword arguments (kwargs). The latter is only supported for host languages that also have that concept, and Rust does not.</p>
<p>But this isn't the end of the story. The crucial part of the <code>AttributeGetter</code> interface was that you could pass in any method or closure for the attribute getter, and the <code>AttributeGetter::new</code> method handled all the type-conversions transparently. This hid the messy, error-prone details from the user and kept the interface clean.</p>
<p>So let's do the same for <code>InstanceMethod</code>!</p>
<pre><code>impl InstanceMethod {
    pub fn new&lt;T, F, ???&gt;(f: F) -&gt; Self
    where
        F: Fn(&amp;T, ???)
        F::Result: ToPolarResult,
        T: 'static,
    {
        Self(Arc::new(
            move |receiver: &amp;Instance, args: Vec&lt;PolarValue&gt;| {
                let receiver = receiver
                    .downcast()
                    .map_err(|e| e.invariant().into());
                // ermm.... what next?
            },
        ))
    }
}
</code></pre>

<p>We've hit our first problem.</p>
<p>The input to an attribute getter never accepted any arguments, and we only needed it to work for all <code>Fn(&amp;T)</code>. In order to support <em>multiple arguments</em>, we now need to cover <code>Fn(&amp;T)</code>, <code>Fn(&amp;T, A)</code>, <code>Fn(&amp;T, A, B)</code>, and so on.</p>
<p>The first problem is how to convert <code>A</code>, <code>B</code>, etc. into <code>PolarValue</code>s.</p>
<p>The second problem is that these are all <em>completely distinct traits</em>. There is no trait capturing "functions of arity 2, 3, 4...". –&nbsp;at least not until the feature is available in stable Rust. In the future, this <em>might</em> be represented with the syntax <code>Fn&lt;Args, Output=T&gt;</code>, but right now using this syntax results in:</p>
<pre><code>error[E0658]: the precise format of `Fn`-family traits' type parameters is subject to change
 --&gt; src/main.rs:2:14
  |
2 |     where F: Fn&lt;(u32,), Output=u32&gt; {
  |              ^^^^^^^^^^^^^^^^^^^^^^ help: use parenthetical notation instead: `Fn(u32) -&gt; u32`
  |
  = note: see issue #29625 &lt;https://github.com/rust-lang/rust/issues/29625&gt; for more information
</code></pre>

<p>We could opt to use Rust nightly to get these features, but it's not a huge stretch to implement them ourselves.</p>
<h3>Implementing our own <code>Method</code> trait</h3>
<p>This is where as the writer it's tempting to unveil my newly-created trait, perfectly matching what we needed, and make it look like I just put fingers to keyboard to get to the definition.</p>
<p>In reality, we spent a sizeable chunk of our engineering effort for this project on this one trait. We made mistakes. We wrote code that we threw out. And a lot of that is because we didn't understand some of the nuances of Rust functions and the trait resolution system. Instead of papering over all of that, we thought it would be more interesting to show you what we tried. </p>
<p><strong>Attempt #1</strong></p>
<p>The first thing we tried was, in hindsight, a little greedy. Why not just skip straight to writing a trait to encapsulate precisely what we need?</p>
<pre><code>pub trait Method {
   fn invoke(&amp;self, receiver: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue;
}
</code></pre>

<p>This looks great, let's try implementing it for one of our <code>Fn</code> variants:</p>
<pre><code>impl&lt;F, T, R&gt; Method for F
where
   F: Fn(&amp;T) -&gt; R,
   T: 'static,
   R: ToPolarValue,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;T&gt;().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Results in:</p>
<pre><code>impl&lt;F, T, R&gt; Method for F
        ^ unconstrained type parameter
the type parameter `T` is not constrained by the impl trait, self type, or predicates

impl&lt;F, T, R&gt; Method for F
           ^ unconstrained type parameter
the type parameter `R` is not constrained by the impl trait, self type, or predicates
</code></pre>

<p>It's likely that most people have hit some variation of this error in their Rust adventures! What is going on here? <code>T</code> and <code>R</code> <em>look</em> pretty constrained to me? They are right there inside the definition of <code>F: Fn(&amp;T) -&gt; R</code>. </p>
<p>Our mistake was reading those trait bounds as: <code>F</code> is a function from <code>&amp;T</code> to <code>R</code>, whereas in reality this is a regular old trait bound with slightly different syntax for the trait itself. And one function might implement multiple of these trait bounds.</p>
<p>E.g.</p>
<pre><code>// do nothing
fn ident&lt;T&gt;(t: T) -&gt; T { t }

let _ = &amp;ident as &amp;dyn Fn(u32) -&gt; u32;
let _ = &amp;ident as &amp;dyn Fn(String) -&gt; String;
</code></pre>

<p>So which trait should we use for the implementation of <code>Method</code> for <code>ident</code>?</p>
<p>Here's another way of looking at this problem. Suppose instead we decided to exhaustively implement our <code>Method</code> trait for all types we care about:</p>
<pre><code>impl&lt;F&gt; Method for F
where
   F: Fn(&amp;u32) -&gt; u32,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;u32&gt;().unwrap();
        self(receiver).to_polar()
    }
}

impl&lt;F&gt; Method for F
where
   F: Fn(&amp;String) -&gt; String,
{
    fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast::&lt;String&gt;().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Ignoring for now just how bad an idea this is, it doesn't even work! We get:</p>
<pre><code>conflicting implementations of trait `Method`:
</code></pre>

<p>Look back to <code>ident</code>. That one function implements both <code>Fn(String) -&gt; String</code> and <code>Fn(u32) -&gt; u32</code> traits. Similarly, in the above case, a function that implements both <code>Fn(&amp;String) -&gt; String</code> and <code>Fn(&amp;u32) -&gt; u32</code> would have two possible implementations for <code>Method</code>. So we get conflicting implementations.  </p>
<p><em>Actually</em>, it goes even further than that. Implementing a blanket trait implementation over <em>any</em> two function trait bounds results in conflicting implementations. Even though such a function couldn't exist:</p>
<pre><code>trait Test {}

impl&lt;F: Fn()&gt; Test for F { }
impl&lt;F: Fn(String) -&gt; String&gt; Test for F { }
</code></pre>

<p>Results in:</p>
<pre><code>error[E0119]: conflicting implementations of trait `Test`:
  |
4 | impl&lt;F: Fn()&gt; Test for F { }
  | ------------------------ first implementation here
5 | impl&lt;F: Fn(String) -&gt; String&gt; Test for F { }
  | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ conflicting implementation
</code></pre>

<p>One day (or today, if you're on Rust nightly), Rust might let you implement <code>Fn</code> for your own types, support variadic functions (what do you mean Rust already supports <a href="https://doc.rust-lang.org/nomicon/ffi.html#variadic-functions">variadic functions</a>?), and do all kinds of fun things of the sort. But for now we're not going to get much farther with this approach.</p>
<p><strong>Attempt #2</strong></p>
<p>This <code>Method</code> trait looks too convenient to throw away entirely at the first sign of complication. Let's try something different. If our original mistake was thinking of <code>Fn</code> as a function instead of a trait, perhaps we can heed the wisdom of the Rust docs and use <code>fn</code> instead.</p>
<p><img alt="Building%20a%20runtime%20reflection%20system%20for%20Rust%20(Par%20e9d46e4c771847e7ba119df92cf2a8b9/Untitled.png" src="https://images.osohq.com/runtime-reflection-pt-3/Building%20a%20runtime%20reflection%20system%20for%20Rust%20%28Par%20e9d46e4c771847e7ba119df92cf2a8b9/Untitled.png"></p>
<p>Based on the docs, we can use <code>fn</code> with both regular functions and closures! Great, let's do just that:</p>
<pre><code>impl&lt;T, R&gt; Method for fn(&amp;T) -&gt; R
where
    T: 'static,
    R: ToPolarValue,
{
     fn invoke(&amp;self, instance: Instance, args: Vec&lt;PolarValue&gt;) -&gt; PolarValue {
        debug_assert!(args.is_empty());
        let receiver = instance.downcast().unwrap();
        self(receiver).to_polar()
    }
}
</code></pre>

<p>Works fine! Let's try it out:</p>
<pre><code>let clone = |receiver: &amp;String| -&gt; String { receiver.clone() };
let clone_method: Box&lt;dyn Method&gt; = Box::new(clone);
let …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.osohq.com/post/runtime-reflection-pt-3">https://www.osohq.com/post/runtime-reflection-pt-3</a></em></p>]]>
            </description>
            <link>https://www.osohq.com/post/runtime-reflection-pt-3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25704707</guid>
            <pubDate>Sat, 09 Jan 2021 21:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is happening to Lazada is happening to all companies acquired by Alibaba]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25703505">thread link</a>) | @7d7n
<br/>
January 9, 2021 | https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/ | <a href="https://web.archive.org/web/*/https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://thelowdown.momentum.asia/what-is-happening-to-lazada-is-happening-to-all-companies-acquired-by-alibaba/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703505</guid>
            <pubDate>Sat, 09 Jan 2021 19:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Making of Counterstrike's Dust]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25703171">thread link</a>) | @sillysaurusx
<br/>
January 9, 2021 | https://www.johnsto.co.uk/design/making-dust/ | <a href="https://web.archive.org/web/*/https://www.johnsto.co.uk/design/making-dust/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
		

<p>For many FPS players Dust - and the later Dust 2 - are the quintessential Counter-Strike maps. They’ve been featured in nearly every major Counter-Strike tournament, and been responsible for countless millions virtual deaths, bomb detonations and defusals. But these maps actually owe their existence to Team Fortress 2 - a game that was released eight years <em>after</em> Dust became a staple of the Counter-Strike map rotation.</p>

<h2 id="time-travelling">Time Travelling</h2>

<p>It started in the summer of 1999, Suffolk, England. I was 16 years old, recuperating from end-of-year exams and enjoying my newfound freedom from school work. Half-Life was only a few months old, yet was scooping up more ‘Game of the Year’ awards than there were game magazines, leaving gamers desperate to know what Valve Software were going to make next.</p>

<p>Thankfully, news broke that Valve had hired the team behind ‘Team Fortress’, a free mod for Quake that added class-based team multiplayer to the game. Like any responsible teenager, I’d spent more hours sat staring into a screen zooming around dodging rockets, slinging grenades and capturing the flag than I had with my head stuck in schoolwork, much to the chagrin of my parents. Their next project? A sequel, excitingly titled ‘Team Fortress 2’.</p>

<p>It seemed that whilst I had been busy ambushing my future educational prospects, behind closed doors Valve had been hammering away at updating and upgrading Team Fortress for a new generation of hardware. News of Team Fortress 2 was rare and sporadic, but occasionally a tidbit here or a screenshot there would nervously peer out to an excited but nervous audience of TF fans.</p>

<p>Before too long, a <a href="http://wiki.teamfortress.com/wiki/Promotional_images">handful of screenshots</a> started their steady journey around the gaming websites of the late nineties. Two particular screenshots leapt out at me:</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_01_thumb.jpg" alt="Team Fortress 2"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_02_thumb.jpg" alt="Team Fortress 2"></a></span></p>
</div>
	<figcaption>Two early screenshots of Team Fortress 2.</figcaption>
</figure>


<p>The seed had been sown.</p>

<p>Meanwhile, a new Half-Life modification known as ‘Counter-Strike’ had been picking up a steady stream of players. In the autumn of 1999, Minh ‘gooseman’ Le and Jess Cliffe released its second beta - and it supplanted Team Fortress to become my new addiction. It came with a texture pack of urban textures (‘cstrike.wad’) that, upon discovery, I set about making a map with - this became ‘<a href="https://www.johnsto.co.uk/blog/a-little-wad-the-story-of-cs_tire/">cs_tire</a>’, a hostage rescue map set in (of all places) a retirement home. Surprisingly, this map was deemed good enough to be included in the third beta release of Counter-Strike, and Jess subsequently asked me if I’d be interested in making a map for the fourth beta. He was very keen to hook me up with their texture artist to help me make something absolutely and completely original.</p>

<p>Jess introduced me to artist Chris ‘MacMan’ Ashton - the same artist behind the urban texture set used in my retirement home map - and we got to work creating a new, totally original Counter-Strike map. Unfortunately it was too late to save me from TF2’s influence and I asked for these instead:</p>

<figure>
	<p><span><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2-textures.jpg" alt="Team Fortress 2 texture selection"></span></p>
	<figcaption>Team Fortress 2 screenshots were used to create a core texture set</figcaption>
</figure>


<p>Undeterred by my complete lack of originality, Chris quickly got back to me with beautiful lookalikes. While not exact replicas, I selfishly became completely infatuated with them, just like I had the screenshots they were based on . I quickly bundled them all together into my own texture pack and called it “cs_dest.wad” - shorthand for “Destiny”.</p>

<p>With these TF2-alike textures I could finally make a map and pretend I was playing Team Fortress 2, but something was wrong. I felt guilt - TF2 wasn’t even out yet and I was already trying to sap all the effort Valve had been putting into it. It was akin to snatching a duckling from under its mothers beak. “But surely”, I thought, “Valve wouldn’t mind one me making one small map for one small mod for their one and only published game? A map that maybe only a handful of people would ever play?”</p>

<p>I marched on.</p>

<h2 id="copy-and-paste">Copy and Paste</h2>

<p>Starting the map was the easy bit - the first area boasted a long road flanked by buildings, leading to an archway and a wall dividing it in two, just like I’d seen in the screenshots. I decorated every building and wall with ornate trims along the top or bottom, again aping TF2, as I tried my hardest to evoke the same sense of place, desolation, and scale. These features would go on to define the underlying architectural style of Dust.</p>

<p>My effort wasn’t <em>quite</em> identical to the map featured in those coveted TF2 screenshots, but it was close enough, and - somewhat more importantly - it was a start.</p>

<p>The arched doorways became a hallmark of the Dust theme - a Dust map is simply not Dust without at least two or three arches dividing the map into distinct zones. Creating the first one was at the time a great test of my technical mapping ability, and I struggled for a little while before landing on a technique that worked. My design eschewed the Reuleaux triangle shape of the TF2 arches for a simpler semi-circle, partly because it was simpler, but primarily to ease player passage through them. I extruded the arches from their adjoining wall - lifted straight from the screenshots.</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/start_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/start_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/start_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/start_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>The first  incarnation of what became the CT spawn</figcaption>
</figure>


<p>I considered against copying the screenshots verbatim for fear of upsetting Valve, and so started guessing how the rest of the area should look. I’d already created a raised platform, and had decided that this could be the area that the Counter-Terrorist team would spawn in at the start of the match. This necessitated defensive measures to protect their spawn area, so I made some windows:</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/early_windows_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/early_windows_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/early_windows_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/early_windows_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>The view from inside a building next to the CT spawn</figcaption>
</figure>


<p>Not only did they look hideous, but the windows didn’t give the defensively-advantageous views I wanted the CT team to have. Nor did they fit with the intended gameplay. I didn’t want to encourage the CTs to hold back, and removed them - although in all honestly, at this point I really didn’t know where the map was going.</p>

<h2 id="under-the-influence">Under the Influence</h2>

<p>Side-by-side, the TF2 ‘influence’ is plain to see:</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_01_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>Side-by-side, the influence of TF2 on the design of the CT spawn area is apparent.</figcaption>
</figure>


<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tf2compare_02_thumb.jpg" alt="Early CT spawn area"></a></span></p>
</div>
	<figcaption>TF directly influenced building placement and the design of the arches.</figcaption>
</figure>


<p>In many respects, the TF2 screenshot looks nicer to me - smoother and softer than the harsh edges of the Dust buildings. I was far more comfortable working with standard geometric shapes, 90 degree corners and 45 degree angles, which is why Dust looks far boxier in comparison to the TF2 screenshot it was based on.</p>

<p>That was the easy part done - after all, Valve had already created this much of the map for me and all I’d had to do was copy it. But what I had wasn’t much - it was barely enough for a one-on-one deathmatch, let alone two teams of eight players gunning it out. Worse still, there were no more screenshots to use for ‘inspiration’ - I had to make the rest of the map off my own back and imagination.</p>



<p>Having nailed down the design of the first area, producing the rest of the map was merely a case of extrapolating it into a complete, playable environment. However this was much easier said than done - the next section of the map proved rather more challenging.</p>

<p>I had created a T-junction out of the CT spawn, but struggled to know what to do with it. My past mapping experience was mostly creating tight interiors rather than not vast exteriors, and so I was feeling very lost. Desperate, I shoe-horned a bend in the road leading to a downward slope, and at the end of it - an underground cavern.</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/underground_01.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/underground_01_thumb.jpg" alt="An underground chamber"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/underground_02.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/underground_02_thumb.jpg" alt="An underground chamber"></a></span></p>
</div>
	<figcaption>The underpass originally descended into a vast underground facility, but this was scrapped the moment I played it.</figcaption>
</figure>


<p>It didn’t work, of course. While the CT spawn area was light and airy, this giant room was gloomy, boxy and felt dead compared to the sunny exterior I’d already made. Observing it also lacked any gameplay potential, I swiftly deleted it. Dust would be an outdoor map.</p>

<p>I was still stuck. It’s at times like these where working without an initial design can prove extremely difficult. You look at what you’ve got, and struggle to see where to take it, knowing that a step in one direction is a step away from a solution in another direction - and you don’t know which will turn out better. It can be very tough and incredibly tempting to just scrap  <em>everything</em> and start again. I’d made all my previous maps one room at a time, making it up as I go along with precious little pre-planning, and they had gone reasonably well. I had to hope I could do the same again.</p>

<p>Mercifully, that’s exactly what happened.</p>

<figure>
	<div><p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/tspawn.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/tspawn_thumb.jpg" alt="Terrorist spawn"></a></span></p>

<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/underpass.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/underpass_thumb.jpg" alt="Underpass"></a></span></p>
</div>
	<figcaption>The Terrorist spawn area, and shallow decline into the underpass.</figcaption>
</figure>


<p>Within just a few hours - and seemingly out of nowhere - the Terrorist spawn area was complete. I was far happier with this side of the map, perhaps a product of becoming comfortable with the visual and architectural style. The shallow decline into the underpass is perhaps one of my favourite aspects, both aesthetically and as a player who spent many hours armed with a Steyr Scout at the crest popping off opponents’ heads.</p>

<p>At one point I planned an alleyway from the Terrorist side of the underpass that fed around to the CT ‘sniper nest’, but this path seemed like it would be too long, too linear, and simply too <em>dull</em>. I just blocked it up with crates instead, still visible in the original version of the map (and the screenshot above.)</p>

<p>Dust’s central hallway was pivotal in tying all these pieces together. Unfortunately, I can recollect very little about its creation, bar my explicit efforts to ensure players couldn’t see all the way through it from one end to the other. Every crate found in the intersection was strategically positioned to cut off lines-of-sight and improve performance. It was in this corridor that each team would typically meet, and so it needed to be fair, and balanced, with a slight defensive bias.</p>

<figure>
	<p><span><a href="https://www.johnsto.co.uk/i/design/making-dust/corridor.jpg"><img src="https://www.johnsto.co.uk/i/design/making-dust/corridor_thumb.jpg" alt="A screenshot of the central corridor"></a></span></p>
	<figcaption>The central corridor, Terrorists approached from the top, Counter-Terrorists from the bottom. Note the stack …</figcaption></figure></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnsto.co.uk/design/making-dust/">https://www.johnsto.co.uk/design/making-dust/</a></em></p>]]>
            </description>
            <link>https://www.johnsto.co.uk/design/making-dust/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25703171</guid>
            <pubDate>Sat, 09 Jan 2021 18:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Which smartphone, laptop and tablet brands break down the most?]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25702727">thread link</a>) | @vanpythonista
<br/>
January 9, 2021 | https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A CBC Marketplace survey that asked more than 3,200 Canadians about smartphone, laptop and tablet breakdowns and repairs&nbsp;revealed that an overwhelming majority of them are dealing with broken technology that is too difficult or too expensive to repair.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5861152.1609866490!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/jason-bolduc.jpg"></p></div><figcaption>Jason Bolduc holds a 14-day-old Samsung S20 Galaxy Plus with a hairline crack.<!-- --> <!-- -->(Stephanie Matteis/CBC)</figcaption></figure><p><span><p>Of the electronic devices used in Canada, LG smartphones top the list of devices Canadians said have broken the most over the last five years, according to an investigation by CBC's<em> Marketplace</em>.&nbsp;</p>  <p>An online survey that asked 3,201 Canadians&nbsp;about smartphone, laptop and tablet breakdowns and repairs&nbsp;revealed that an overwhelming majority of them are dealing with broken technology that is too difficult or too expensive to repair. The survey was&nbsp;conducted&nbsp;between Aug. 6 and Aug. 20 by Leger Marketing on behalf of <em>Marketplace.</em></p>  <p>Sixty-five per cent of respondents said they had multiple devices break down within the past five years.&nbsp;&nbsp;</p>  <p>Gay Gordon-Byrne, the head of the Repair Association, a consumer advocacy group in the United States established to hold manufacturers of electronic devices more accountable for reparability, said that in general, manufacturers want a consumer to have to return to the store to repair an item, which in turn may entice them into buying the newest products.&nbsp;</p>  <p>"We literally have to go buy new ones and throw away the old ones because we're not allowed either by design or by policy to fix them," she told <em>Marketplace</em>.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/gay-gordon-byrne.jpg 300w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/gay-gordon-byrne.jpg 460w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/gay-gordon-byrne.jpg 620w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gay-gordon-byrne.jpg 780w,https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/gay-gordon-byrne.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5861144.1609799082!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/gay-gordon-byrne.jpg"></p></div><figcaption>Gay Gordon-Byrne of The Repair Association at the border at Derby Line, Vermont.<!-- --> <!-- -->(Stephanie Matteis/CBC)</figcaption></figure></span></p>  <p>For the survey, people across the country shared their stories about lifespan, reparability and the brand and type of device that broke down more than others in the last five years.&nbsp;</p>  <h2>4-month fight to fix LG smartphone</h2>  <p>Laurie Hood of Canmore, Alta., recently purchased LG's G8 Thin Q smartphone. Not long after, she said it started having problems.</p>  <p>"I just bought the phone, and I'm not blaming myself, but that's really a drag," Hood said.</p>  <p>"I wish I'd done my research before. I didn't."&nbsp;</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/laurie-hood.jpg 300w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/laurie-hood.jpg 460w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/laurie-hood.jpg 620w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/laurie-hood.jpg 780w,https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/laurie-hood.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5863229.1609951856!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/laurie-hood.jpg"></p></div><figcaption>Laurie Hood of Canmore, Alta., began having problems with her LG G8 Thin Q smartphone not long after she purchased it.<!-- --> <!-- -->(Dave Rae/CBC)</figcaption></figure></span></p>  <p>Both a certified LG repair shop and LG told her she would have to pay for a repair for the nearly new phone, which retails for about $1,250.</p>  <p>She estimated it took four months and, "fair to say about 20 hours of emails and on the phone,"&nbsp; but after persistent fighting for a fix, the phone eventually was returned to her repaired at no cost.</p>  <p>LG declined requests for on-camera interviews.</p>  <p><em>Marketplace </em>told the company about Hood's experience and a spokesperson for the company wrote that they'll look into it.</p>  <p>To understand which brands experienced more breakdowns than others based on the survey data, David Bellhouse, a professor emeritus of statistical and actuarial sciences at&nbsp;Western University, calculated the percentage share of breakdowns for each brand using market share data.</p>  <p>According to Bellhouse's analysis, LG smartphones had a disproportionately higher percentage of breakdowns than the company's percentage of the Canadian smartphone market and were the devices that broke down most&nbsp;over the last five years when compared with other brands in the survey and when market share was taken into account.</p>  <p>When <em>Marketplace </em>told the company about its position in the survey analysis, the company said in a statement that it stands behind the quality of its devices, claimed LG doesn't limit parts for phone repairs&nbsp;and said it is trying to make it easier for its customers to get their phones fixed.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/marketplace/the-people-vs-the-tech-giants-1.5865424">Read more about how <em>Marketplace </em>conducted the survey and how companies responded</a></strong></li>  </ul>  <h2>Top breakdown issues identified</h2>  <p>The vast majority of respondents (96 per cent) had an identified problem with their device. They indicated "it became slow or buggy" (40 per cent) or had "a weak/dead battery" (26 per cent).&nbsp;</p>  <p>Other problems included the device wouldn't turn on, had a cracked or broken screen, would not charge or overheated.</p>  <p>According to Gordon-Byrne, tech companies generally don't want a consumer&nbsp;to repair a&nbsp;device&nbsp;and get "another two years of life out of it."</p>  <h2>Apple vs. Samsung smartphones</h2>  <p>Apple dominates the smartphone market, followed by Samsung.&nbsp;</p>  <p>Bellhouse's survey analysis showed Samsung smartphones experience more breakdowns relative to market share than Apple iPhones.</p>  <p>The survey received 563 reports about Samsung phones of the 1,922 reports about smartphones overall.</p>  <p>Data also showed that smartphones break down more than any other device.</p>  <p><em><strong>WATCH | Between Apple and Samsung, here's the phone brand Canadians tell us broke more than others:</strong></em></p>  <p><span><span><div><div title="Apple vs. Samsung: Which phone brand breaks down the most?" role="button" tabindex="0"><div><div aria-labelledby="1842063427989-metadata-" title="Apple vs. Samsung: Which phone brand breaks down the most?"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/569/595/APPLE_vs_SAMSUNG_horizontal.png" alt="" loading="lazy"></p></div></div></div></div></div><span>Here is the top smartphone brand that breaks down the most based on a CBC Marketplace survey and market share analysis.<!-- --> <!-- -->1:42</span></span></span></p>  <p>Jason Bolduc owns a Samsung S20 Galaxy Plus 5G that sells for $1,875, but he paid $1,280.&nbsp;</p>  <p>The phone immediately had problems, including overheating, which he said resulted in a hairline crack on the back glass.</p>  <p>It was still under warranty, and Telus, which sold it to him, has a 15-day return policy, so Bolduc attempted to return it to the store in Bracebridge, Ont., where he purchased it.</p>  <p>In a written statement to <em>Marketplace</em>, Telus said that it couldn't help Bolduc because he didn't buy an extended care warranty and the issues with the phone had to be addressed by the manufacturer.</p>  <p>He also approached Samsung, which wanted to charge him for repairs.</p>  <p>"I still have to be out of pocket costs because they are claiming that it's the [user's] fault," he said, though he noted the company had no evidence of that.</p>  <p>Samsung was also asked for an on-camera interview but instead provided a statement that its Galaxy products are some of the industry's "most durable." The company also said it will look into Bolduc's situation.</p>  <h2>Seeking repairs</h2>  <p>Almost three out of four survey respondents have had at least one device break down in the past five years. And 65 per cent have had multiple device breakdowns in that time.</p>  <p>Half (51 per cent) of devices taken to the manufacturer weren't repaired because the survey respondents said it would be too costly or the manufacturer couldn't fix the device.</p>  <p>Ricardo Borja owns a three-year-old Apple iPhone 7 but the audio only worked if connected to Bluetooth. As a result, he was in his car often to make or receive phone calls.</p>  <p>"I will be talking through the microphone of my car. So this is a pretty expensive headset," he said.</p>  <p>The battery also drained quickly, he said.</p>  <p>Borja sought repairs with both the manufacturer and a certified Apple repair shop where he lives in Montreal. He said both times he was told he could pay $400 and trade in the phone.&nbsp;</p>  <p>But the Quebecker didn't want to contribute to growing e-waste&nbsp;and as a product designer, couldn't understand why there wasn't a solution that allowed a repair.</p>  <p>"That is something that kind of sucks as a pattern as a whole if you look at consumer electronics. It's that they're making them less and less repairable at home."</p>  <h2>Apple replaces customer's iPhone, thanks to Quebec law</h2>  <p>Weeks after meeting with <em>Marketplace</em>, Borja sent a message to say he had gotten his iPhone 7 replaced for free with the same model from Apple.</p>  <p>He had researched Quebec's consumer protection laws, which say if a product doesn't last as long as another just like it, the manufacturer might have to repair it at no cost, replace it or provide a refund.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_300/ricardo-borja.png 300w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_460/ricardo-borja.png 460w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_620/ricardo-borja.png 620w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_780/ricardo-borja.png 780w,https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_1180/ricardo-borja.png 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5861159.1609799963!/fileImage/httpImage/image.png_gen/derivatives/original_780/ricardo-borja.png"></p></div><figcaption>Ricardo Borja in Montreal with the iPhone 7 he only uses in his vehicle for calls. <!-- --> <!-- -->(Stephanie Matteis/CBC)</figcaption></figure></span></p>  <p>Right to repair advocates told <em>Marketplace </em>that of anywhere in Canada, the law may be strongest in Quebec. But even still, Borja wasn't told about it.</p>  <p>"If we don't know our rights, then they don't tell us that we're entitled to have a replacement phone at no charge, and I would have paid $400," he said of his experience with Apple.</p>  <p>Apple declined <em>Marketplace </em>requests for an on-camera interview about Borja's experience and the survey analysis, but in a statement told <em>Marketplace </em>the company has a new repair program that is making it easier to get phones fixed.&nbsp;</p>  <h2>Rating laptops: Acer vs. Apple&nbsp;versus HP</h2>  <p>When it comes to laptops, Acer, Apple and HP&nbsp;are Canada's top sellers.</p>  <p>Of those brands, Bellhouse's analysis looking at market share in households relative to breakdowns from the survey found that Canadians have experienced more breakdowns with HP over the last five years.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/acer-and-hp-graphic.jpg 300w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/acer-and-hp-graphic.jpg 460w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/acer-and-hp-graphic.jpg 620w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/acer-and-hp-graphic.jpg 780w,https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/acer-and-hp-graphic.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5866933.1610144339!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/acer-and-hp-graphic.jpg"></p></div><figcaption>Acer and HP are among Canada's top selling laptops.<!-- --> <!-- -->(David Abrahams/CBC)</figcaption></figure></span></p>  <p>HP declined <em>Marketplace</em>'s request for an interview, but wrote that in the past five years, its line of notebooks "have realized a 30 per cent reduction in&nbsp;[failure] rates as measured by the industry standard metric of Annualized Failure Rates (AFR)."</p>  <p>And by that same metric, the failure rate is "the lowest it has been in the company's history."</p>  <p>As for repairability, the company noted that some of its products are highly rated on iFixit's reparability scale. The California company is a well-known advocate for the right to repair.</p>  <h2>Tablets are a 'bad investment,' says expert</h2>  <p>When it comes to tablets, Gordon-Byrne said people should save their money.&nbsp;</p>  <p>She said they're often made with a lot of glue, which makes them difficult to take apart and repair. Add to that, right to repair advocates say manufacturers usually don't grant consumers and most repair shops, other than certified dealers,&nbsp;access to parts, repair instructions and software. Both impede successful repair, making them "a bad investment," Gordon-Byrne said.</p>  <p>When it comes to market share of tablets, Apple dominates the market at more than 75 per cent of sales, followed by Samsung at 17 per cent.</p>  <p>Bellhouse said iPads have broken down the least compared to all other brands.</p>  <p>The survey, which has a 1.7 per cent margin of error 19 out of 20 times, also had 201 respondents from Canada's North, which is also one of the toughest spots …</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881">https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881</a></em></p>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/smartphone-survey-marketplace-1.5860881</link>
            <guid isPermaLink="false">hacker-news-small-sites-25702727</guid>
            <pubDate>Sat, 09 Jan 2021 18:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Readable Bash Scripts]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25702062">thread link</a>) | @mooreds
<br/>
January 9, 2021 | https://brianschiller.com/blog/2021/01/07/readable-bash-scripts | <a href="https://web.archive.org/web/*/https://brianschiller.com/blog/2021/01/07/readable-bash-scripts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
      <div>
        <article>
          <p>I really love the feeling of writing a bash pipeline. It’s fun to string commands together, peek at the output, add another couple pipes to massage the data closer to my goal. I even gave a short class on them: <a href="https://github.com/bgschiller/shell-challenges">bgschiller/shell-challenges</a>.</p>

<p>But it’s easy to find that a pipeline that was delightful to write is painful to maintain. Even if you’re the one reading it a month later, it’s difficult to remember what the purpose of each piece is. This is a trick I learned to break pipelines into intermediate files for more readable scripts.</p>

<h3 id="the-task">The task</h3>

<p>The product I’m working on has a list of “Alarms”—conditions that the end user needs to be alerted to. We also have a localization file for each supported language that maps Alarm names to human-readable names, descriptions, etc. There are a lot of alarms, enough to make it difficult to keep track of which ones are already translated. This calls for a script!</p>

<p>The Alarms file looks something like this:</p>

<div><div><pre><code><span>&lt;!-- Alarms.xml --&gt;</span>
<span>&lt;?xml version="1.0" encoding="utf-8"?&gt;</span>
<span>&lt;config</span> <span>name=</span><span>"AlarmConfig"</span><span>&gt;</span>
   <span>&lt;AlarmList</span> <span>name=</span><span>"IngredientAlarms"</span> <span>version=</span><span>"1.0"</span><span>&gt;</span>
      <span>&lt;Alarm</span> <span>name=</span><span>"MozzarellaTooWarm"</span><span>&gt;</span>
        <span>&lt;!-- some alarm-specific stuff here --&gt;</span>
      <span>&lt;/Alarm&gt;</span>
      <span>&lt;Alarm</span> <span>name=</span><span>"PizzaTooCold"</span><span>&gt;</span>
      <span>&lt;/Alarm&gt;</span>
      <span>&lt;!-- ... --&gt;</span>
</code></pre></div></div>

<p>And the localization something like this:</p>

<!-- prettier-ignore -->
<div><div><pre><code><span>[{</span> <span>stringId</span><span>:</span> <span>"</span><span>alarm_id_MozzarellaTooWarm</span><span>"</span><span>,</span>
   <span>localString</span><span>:</span> <span>"</span><span>MozzarellaTooWarm</span><span>"</span> <span>},</span>
 <span>{</span> <span>stringId</span><span>:</span> <span>"</span><span>alarm_title_MozzarellaTooWarm</span><span>"</span><span>,</span>
   <span>localString</span><span>:</span> <span>"</span><span>Mozzarella Too Warm</span><span>"</span> <span>},</span>
 <span>{</span> <span>stringId</span><span>:</span> <span>"</span><span>alarm_description_MozzarellaTooWarm</span><span>"</span><span>,</span>
   <span>localString</span><span>:</span> <span>"</span><span>The mozzarella has become too warm and must be used within the next five minutes</span><span>"</span> <span>},</span>
  <span>//...</span>
<span>]</span>
</code></pre></div></div>

<h3 id="make-a-plan">Make a plan</h3>

<ol>
  <li>Extract the alarms names from Alarms.xml using <code>xpath</code>.</li>
  <li>Each alarm needs to be prefixed with <code>alarm_id_</code>, <code>alarm_title_</code>, <code>alarm_description_</code>, <code>alarm_operator_actions_</code> in order to match the localization file. Figure out some way to do that.</li>
  <li>Extract the <code>"stringId"</code> from each entry in the localization file. Oh, but there are other entries for things that need to be localized, and aren’t alarms at all. Figure out a way to filter those out. Probably use <code>jq</code> for that.</li>
  <li>Use <code>diff</code> to compare the expected keys with the actual keys.</li>
</ol>

<p>This isn’t a post on how to make bash pipelines, so I’ll gloss over that piece. Here’s what I came up with:</p>

<div><div><pre><code>diff <span>\</span>
  &lt;<span>(</span><span>join</span> <span>-j</span> 99999 <span>\</span>
    &lt;<span>(</span><span>echo</span> <span>'alarm_id_
alarm_title_
alarm_description_
alarm_operator_actions_'</span><span>)</span> <span>\</span>
    &lt;<span>(</span>xpath <span>-q</span> <span>-e</span> config/AlarmList/Alarm/@name Alarms.xml |
      <span>cut</span> <span>-d</span><span>=</span> <span>-f2</span> | <span>tr</span> <span>-d</span> <span>'"'</span><span>)</span> <span>\</span>
    | <span>tr</span> <span>-d</span> <span>' '</span> | <span>sort</span><span>)</span> <span>\</span>
  &lt;<span>(</span>jq <span>'.[] | select(.stringId | startswith("alarm_")) |
        .stringId '</span> i18n/en.json | <span>sort</span><span>)</span>
</code></pre></div></div>

<p>It’s convoluted and kinda impressive in that way. But not code you’d be happy to maintain.</p>

<h3 id="one-step-at-a-time">One step at a time</h3>

<p>The prior step accomplished what we needed, but it was pretty difficult to see what was going on. In my opinion, that’s because</p>

<ul>
  <li>Nothing has a name. Because each process substitution is fed directly into a parent, nothing ever receives a name. We need to name our intermediates!</li>
  <li>No comments. It’s difficult to add comments because every line ends in a backslash, meaning “continue this line as if I hadn’t pressed enter”. Bash doesn’t allow you to say “continue this line” and also add a comment.</li>
</ul>

<p>Let’s see if we can tease out each part using intermediate files.</p>

<div><div><pre><code><span>cat</span> <span>&gt;</span> alarm_attrs <span>&lt;&lt;</span> <span>EOF</span><span>
alarm_id_
alarm_title_
alarm_description_
alarm_operator_actions_
</span><span>EOF

</span>xpath <span>-q</span> <span>-e</span> config/AlarmList/Alarm/@name Alarms.xml |
  <span>cut</span> <span>-d</span><span>=</span> <span>-f2</span> | <span>tr</span> <span>-d</span> <span>'"'</span> <span>&gt;</span> expected_alarm_names

<span>join</span> <span>-j</span> 999 alarm_attrs expected_alarm_names |
  <span>tr</span> <span>-d</span> <span>' '</span> | <span>sort</span> <span>&gt;</span> expected_localization_keys

jq <span>-r</span> <span>'.[] | select(.stringId | startswith("alarm_")) |
       .stringId'</span> en.json | <span>sort</span> <span>&gt;</span> actual_localization_keys
</code></pre></div></div>

<p>This is better! Each piece can be understood in isolation, and the dependencies between steps are explictly tracked with named files. All that’s left is to add comments and some error checking, and clean up our intermediate files.</p>

<p>Cleaning up after ourselves is a little tricky. Ideally, we’d like to avoid leaving the intermediate results files laying around regardless of whether the script exits normally, crashes, or is cancelled with ctrl-c. We can use <code>trap</code> to handle this. <code>trap</code> sets up a command to run when a “signal” occurs. We’ll put all our intermediate files into a directory and use <code>trap</code> to delete that directory when a signal that indicates our script is ending fires.</p>

<div><div><pre><code><span>#!/bin/bash</span>

<span>set</span> <span>-ef</span> <span>-o</span> pipefail

<span>readonly </span><span>script_name</span><span>=</span><span>`</span><span>basename</span> <span>"</span><span>$0</span><span>"</span><span>`</span>
usage<span>()</span> <span>{</span>
  <span>cat</span> <span>&gt;</span>&amp;2 <span>&lt;&lt;</span> <span>EOF</span><span>
Usage: </span><span>$script_name</span><span> &lt;path-to-Alarms.xml&gt; &lt;path-to-en.json&gt;

  Compare the alarms specified in Alarms.xml against the
  localizations keys provided in a [language-code].json file
  (eg, en.json). Warn if any keys are missing or unexpected.
</span><span>EOF
</span>  <span>exit </span>2
<span>}</span>

<span>if</span> <span>[[</span> <span>$# </span><span>!=</span> 2 <span>]]</span><span>;</span> <span>then
   </span><span>echo</span> <span>"error: expected 2 arguments, received $#"</span> 1&gt;&amp;2
   usage
<span>fi

</span><span>readonly </span><span>ALARM_CONFIG_XML</span><span>=</span><span>$1</span>
<span>if</span> <span>[[</span> <span>${</span><span>ALARM_CONFIG_XML</span>:<span> -4</span><span>}</span> <span>!=</span> <span>".xml"</span> <span>||</span> <span>!</span> <span>-e</span> <span>$ALARM_CONFIG_XML</span> <span>]]</span><span>;</span> <span>then
   </span><span>echo</span> <span>"error: unable to find XML file at </span><span>$ALARM_CONFIG_XML</span><span>"</span> 1&gt;&amp;2
   usage
<span>fi
</span><span>readonly </span><span>LOCALIZATION_JSON</span><span>=</span><span>$2</span>
<span>if</span> <span>[[</span> <span>${</span><span>LOCALIZATION_JSON</span>:<span> -5</span><span>}</span> <span>!=</span> <span>".json"</span> <span>||</span> <span>!</span> <span>-e</span> <span>$LOCALIZATION_JSON</span> <span>]]</span><span>;</span> <span>then
   </span><span>echo</span> <span>"error: unable to find JSON file at </span><span>$LOCALIZATION_JSON</span><span>"</span> 1&gt;&amp;2
   usage
<span>fi</span>

<span># Make a directory for intermediate results</span>
<span>tmpdir</span><span>=</span><span>$(</span><span>mktemp</span> <span>-d</span> <span>-p</span> .<span>)</span>
<span># ensure it's removed when this script exits</span>
<span>trap</span> <span>"rm -rf </span><span>$tmpdir</span><span>"</span> EXIT HUP INT TERM
<span># note: when debugging, turn off that `trap` line to keep</span>
<span># intermediate results around</span>

<span># The plan is ultimately to use diff to compare names between</span>
<span># Alarms.xml and en.json. diff will tell us if any names</span>
<span># appear in one file but are missing in the other (checks</span>
<span># both directions for a mismatch).In pursuit of this, we need</span>
<span># to create a couple of temporary files:</span>
<span>#  1) all the alarm names we expect to find (based on Alarms.xml)</span>
<span>#  2) all the names actually present in the localization file.</span>
<span># A complication: the location file uses a flat format to</span>
<span># store the id, title, description, and operator_actions:</span>
<span>#   { "stringId": "alarm_id_MozzarellaTooWarm", ... },</span>
<span>#   { "stringId": "alarm_title_MozzarellaTooWarm", ... },</span>
<span>#   { "stringId": "alarm_description_MozzarellaTooWarm", ... },</span>
<span>#   { "stringId": "alarm_operator_actions_MozzarellaTooWarm", ... },</span>
<span># We want to check that *all* of these keys are present, so</span>
<span># we use a cross product of (alarm names) X (those attributes)</span>

<span>cat</span> <span>&gt;</span> <span>$tmpdir</span>/alarm_attrs <span>&lt;&lt;</span> <span>EOF</span><span>
alarm_id_
alarm_title_
alarm_description_
alarm_operator_actions_
</span><span>EOF

</span>xpath <span>-q</span> <span>-e</span> config/AlarmList/Alarm/@name <span>$ALARM_CONFIG_XML</span> |
 <span>cut</span> <span>-d</span><span>=</span> <span>-f2</span> | <span>tr</span> <span>-d</span> <span>'"'</span> <span>&gt;</span> <span>$tmpdir</span>/expected_alarm_names

<span># trick to compute cross product: use `join` with a join</span>
<span># field that doesn't exist (999). since both files lack a</span>
<span># field at 999, they will compare equal for every key, and</span>
<span># each line of the left file will be joined with each line</span>
<span># of the right file--a cross product.</span>
<span>join</span> <span>-j</span> 999 <span>$tmpdir</span>/alarm_attrs <span>$tmpdir</span>/expected_alarm_names |
<span>tr</span> <span>-d</span> <span>' '</span> | <span>sort</span> <span>&gt;</span> <span>$tmpdir</span>/expected_localization_keys

jq <span>-r</span> <span>'.[] | select(.stringId | startswith("alarm_")) |
       .stringId'</span> <span>$LOCALIZATION_JSON</span> |
  <span>sort</span> <span>&gt;</span> <span>$tmpdir</span>/actual_localization_keys

<span>if </span>diff <span>$tmpdir</span>/expected_localization_keys <span>$tmpdir</span>/actual_localization_keys<span>;</span> <span>then
   </span><span>echo</span> <span>"Success! Found all"</span> <span>$(</span><span>wc</span> <span>-l</span> <span>$tmpdir</span>/expected_localization_keys<span>)</span> <span>"expected localization keys"</span>  1&gt;&amp;2
<span>else
   </span><span>echo</span> <span>"Failure. Found discrepancies between expected alarm names and actual localization keys"</span> 1&gt;&amp;2
   <span>exit </span>1
<span>fi</span>
</code></pre></div></div>

        </article>

        
        
        
        

      </div>
    </div></div>]]>
            </description>
            <link>https://brianschiller.com/blog/2021/01/07/readable-bash-scripts</link>
            <guid isPermaLink="false">hacker-news-small-sites-25702062</guid>
            <pubDate>Sat, 09 Jan 2021 17:03:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Marxist Analysis of the iPhone (2019)]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25702019">thread link</a>) | @moigagoo
<br/>
January 9, 2021 | http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html | <a href="https://web.archive.org/web/*/http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span><b>Workers who make iPhones in the 21st century</b>, are twenty-five times more exploited than textile workers in England in the 19th century. Based on a marxist analysis, the current&nbsp;<i>rate of exploitation </i>is&nbsp;2458%.</span></p><div>
<p><span><span><b>W</b></span></span>e are interested in looking at the production
of the iPhone – a commodity – through the
framework of a Marxist analysis. We are interested not in being angry at Apple and Foxconn
alone, but in being able to measure how much
workers are exploited to produce this commodity. In other words, we are interested in measuring <b>the rate of exploitation</b>.</p><p>

The rate of exploitation is one of the most
important concepts in Marx’s theory. This
measurement allows us to show how much the
worker contributes to the increase of value in
the production process. It shows that even if the
worker is paid more, by the special magic of
mechanisation and of efficient management of
the production process, the rate of exploitation
increases. The rate expresses quantitatively the
contradictory interests of the capitalists and of
the workers. There is a radical politics implicit in
the analysis of the rate of exploitation. It enables workers to see how much of the share of
the value produced is appropriated from them
by the capitalists, and to therefore make the
case for a different way to organise production
and to end exploitation.</p><p>

To understand the rate of exploitation, we have
to first grasp what Marx means by the commodity itself and what he means by value, a key term
in the Marxist system of economic thought.</p><p><a href="https://1.bp.blogspot.com/-C5uknsT1Qo8/XZCEHtKcdVI/AAAAAAAAFRU/ske4yAP-_xY8lyclVj_QI14X31w008uqQCLcBGAsYHQ/s1600/book2.png" imageanchor="1"><img data-original-height="536" data-original-width="542" height="316" src="https://1.bp.blogspot.com/-C5uknsT1Qo8/XZCEHtKcdVI/AAAAAAAAFRU/ske4yAP-_xY8lyclVj_QI14X31w008uqQCLcBGAsYHQ/s320/book2.png" width="320"></a></p>
<p>
What is a commodity? Marx begins his epic
work Capital (1867) with a discussion of the
commodity. ‘A commodity’, he notes, ‘is an object outside us, a thing that by its properties
satisfies human wants of some sort or another.
The nature of such wants, whether, for instance,
they spring from the stomach or from fancy,
makes no difference. Neither are we concerned
to know how the object satisfies these wants,
whether directly as a means of subsistence, or
indirectly as means of production’. The commodity is a useful object. But it is more than a
useful thing that serves a purpose to a consumer. It is also something that can be sold – something that enables the person who has it made
to realise a profit. Inside the commodity, then, is
both <b>use value</b> and <b>value</b>.</p><p>

The use value of the commodity is merely its
utility, something that is left to the consumer.
An iPhone is a good example, because it can
be used for many things: to make a phone call,
to watch a video, to use as a compass, to hold
onto when you are feeling awkward (or even to
improve your image).</p><p><a href="https://1.bp.blogspot.com/-XSTB0AJ3dE8/XZCEcFG4l8I/AAAAAAAAFRc/zQgbE9cGZ20opRyyiarpiQQVm8vlXer2QCLcBGAsYHQ/s1600/values.png" imageanchor="1"><img data-original-height="595" data-original-width="465" src="https://1.bp.blogspot.com/-XSTB0AJ3dE8/XZCEcFG4l8I/AAAAAAAAFRc/zQgbE9cGZ20opRyyiarpiQQVm8vlXer2QCLcBGAsYHQ/s1600/values.png"></a></p>
<p>
The expression of the value of the commodity
(i.e. exchange value) is the price of the commodity. We are aware that there is a rich and
long debate amongst Marxists over the relationship between prices and the value of a
commodity. This debate is known as the transformation problem – namely the problem of the
transformation of values to prices of production. Nevertheless, for our iPhone example, we
believe that this level of concreteness need not
detain us. We are still able to capture something
significant. In the case of the iPhone X, the expression of its value is $999. The value is merely
what the commodity is able to command in
the market. But behind that price is a mass of
crystallised values, which can be grouped into
three parts of the total value: <b>constant capital</b>,
<b>variable capital,</b> and <b>surplus value</b>. These are
key concepts for Marxist analysis.</p><p>

<b><span>Constant capital</span></b></p><p>

Various raw materials are brought on to the
factory floor that are to be transformed by the
actions of labour and machines into commodities. These raw materials – and other auxiliary
materials, including the instruments of labour
(machines, tools, etc.) – have already been
fashioned from nature elsewhere. Inside these
raw materials, which are not really ‘raw’ any
longer, is embodied labour. The values of the
various raw materials and instruments of labour
are quantitatively fixed in terms of their labour
content. This fixed amount of value is now
transferred to the newly produced commodities
in the process of production. Its value enters
into the new commodities. Karl Marx calls the
values of the raw materials and the instruments
of labour <b>constant capital</b>.</p><p>

The constant capital for the iPhone includes
all of those minerals and metals that appear on the assembly line as well as the depreciated
parts of machines that work those raw materials.
These are then collectively transformed into
the iPhone. In the process of transformation,
the minerals, metals, and machines do not
alter their value. Their value is preserved in the
iPhone. The value remains constant.</p><p>

At the end of the process of production, the
total transferred value of those means of production – the raw materials, the machines, the
buildings – cannot be more than what they
originally contained in themselves. Their value,
which remains constant, is preserved in the
iPhone.</p><p><a href="https://1.bp.blogspot.com/-Q_pB4fCgz5I/XZCFCPeC69I/AAAAAAAAFRo/PocXIl65lesBDVnMU7IPnoRo6THryPOjwCLcBGAsYHQ/s1600/capital.png" imageanchor="1"><img data-original-height="579" data-original-width="378" src="https://1.bp.blogspot.com/-Q_pB4fCgz5I/XZCFCPeC69I/AAAAAAAAFRo/PocXIl65lesBDVnMU7IPnoRo6THryPOjwCLcBGAsYHQ/s1600/capital.png"></a></p>
<p>

<b><span>Variable capital.</span></b></p><p>

The capitalist firm makes an initial investment in
the production process:</p><ul>
<li>Wages and salaries for workers.</li>
<li>Expenses on all non-human inputs, notably
tools, machinery, buildings, energy, and so
on.</li>
</ul><p>
The latter expense – the expense on all non-human inputs – is known as <b>constant capital</b>, as
explained above.</p><p>

The former expense – the expense on wages
and salaries – is known as variable capital.
To simplify our calculation, we assume that all
workers are productive in the Marxist sense
(namely, that they produce surplus value and
do not merely distribute surplus value – as do
‘unproductive’ workers, such as those who are
involved in trade).</p><p>

In the capitalist system, people are ‘free’ in two
ways. They are free from bondage and free to
starve. The freedom from bondage and from
the means to feed themselves forces people to sell their capacity to labour to those with capital
(land or money). What the person sells is not
themselves (since they are free from bondage),
but they sell their labour power in exchange
for wages. The wages correspond to a certain
amount of money – representing a certain
amount of value – that is necessary to satisfy the
consumption needs of the workers.</p><p>

Marx called labour power <i>a peculiar commodity</i>. Like other commodities, this one must have
two aspects – a use value and a value. Wages
are the <b>exchange value</b> of labour power,
whereas labour is the use value of labour power. This distinction between the use value of
labour power and the exchange value of labour
power is fundamental to a Marxist understanding of surplus value and its production.</p><p>

In a given working day, workers transform
their capacity to labour into an act of labour.
Their various skills are utilised to transform raw materials and machines into commodities.</p><blockquote>
 Workers produce more value than they are paid in wages. This extra value is called&nbsp;<b>surplus value</b>.</blockquote><p>
During the working day and given the conditions of work, the total amount of value produced by the workers exceeds what is needed
for their own consumption and reproduction.
The value they require for their consumption
and reproduction – represented in wages – is
only a part of the value that they make during
the working day.</p><p>

Workers produce more value than they are
paid in wages. This extra value is called
<b>surplus value</b>. If the management of labour
changes or if the machines work at a different
speed, then either more or less value is produced in a day, which means that the surplus
value can be increased (or decreased). The fact
that labour power – this peculiar commodity –
has the quality of producing an extra amount of
value than what is needed for its own reproduction makes it <b>variable capital</b>.</p><p>

<b><span>Surplus Value</span></b></p><p>

The various raw materials that are on the assembly line, the machines, and the electricity that
help fashion the raw materials, would all be idle
without the necessary work of the labour power
put into the system by the workers. The workers
take the raw materials and the tools and shape
them into a commodity. It is the input of the
labour power that is crucial. Unlike any other
commodity, the labour power purchased from
the worker has to produce these new values.
When the workers tire, they go home and reproduce their labour power to be sold again.</p><p><a href="https://1.bp.blogspot.com/-JPwsXDRUiDU/XZCFarXi6jI/AAAAAAAAFRw/luib4DD_tPkBGGIdJ0FOfSFmS-HNhJOmACLcBGAsYHQ/s1600/SV.png" imageanchor="1"><img data-original-height="595" data-original-width="566" src="https://1.bp.blogspot.com/-JPwsXDRUiDU/XZCFarXi6jI/AAAAAAAAFRw/luib4DD_tPkBGGIdJ0FOfSFmS-HNhJOmACLcBGAsYHQ/s1600/SV.png"></a></p>
<p>
The workers sell their labour power for a set
amount of money. When they start to work on
the production of commodities, it takes them
only a fraction of their working day to make
enough commodities to cover their own wages.
Marx called that the <b>necessary labour time</b>. It
was ‘necessary’ because in different epochs and in different countries it takes different amounts
of goods and services to reproduce the worker’s depleted labour power. In some countries,
the standard of living is lower than that of
others, which means the necessary labour time
is also shorter. The remainder of the working
day – after the necessary labour time – is the
<b>surplus labour time</b>. It is the time that the
worker spends producing commodities that are
above and beyond the amount needed to be
produced to pay the wage bill of the worker.</p><p>

<b><span>Rate of Surplus Value</span></b></p><p>

Marx’s concept – the rate of exploitation – is
measured by using the categories of variable
capital and surplus value. Variable capital is
the share of the values produced in the process of production that goes to the workers.
Surplus value, on the other hand, is the share
of the values that goes to the capitalist. The ratio of surplus value to variable capital – or
s/v – can be seen as a quantitative expression
of the exploitation of workers, also called the
<b>rate of surplus value</b>.</p><p>

Take a hypothetical commodity whose total
value is $1,000. The constant capital is worth
$500. That capital – raw material, tools and energy – goes into the process of production and
remerges in a different form but with the value
intact. There is no change in its value. The variable capital – what the worker earns – is $250.
The surplus value – what the capitalist appropriates – is the amount of value created during
the surplus labour time, which in …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html">http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html</a></em></p>]]>
            </description>
            <link>http://www.socialisteconomist.com/2019/09/a-marxist-analysis-of-iphone.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25702019</guid>
            <pubDate>Sat, 09 Jan 2021 16:59:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chinese FM welcomes Elon Musk statement praising Chinese government]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25701603">thread link</a>) | @jimmy2020
<br/>
January 9, 2021 | https://www.globaltimes.cn/page/202101/1212242.shtml#.X_nTsdClAgQ.twitter | <a href="https://web.archive.org/web/*/https://www.globaltimes.cn/page/202101/1212242.shtml#.X_nTsdClAgQ.twitter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
          <p>Elon Musk's praise of China's government for being 'very responsible' to its people's needs and happiness is objective: Chinese FM</p>
          
          
        </div><div>
          <div> <center><img src="https://www.globaltimes.cn/Portals/0/attachment/2021/2021-01-08/acc29ac0-e6f1-4707-acc9-d248a6631a80.jpeg"></center>
<p>Elon Musk. Photo: VCG</p><p>Chinese FM said the praise from Elon Musk to China's government for being "very responsible" to its people's needs and happiness is objective, and it is a conclusion that reflects the real situation, adding that China welcomes more foreign friends to visit and get a comprehensive, correct impression of the nation.&nbsp;</p><p>The remarks came after Elon Musk hailed China as "more responsible" than the US in an interview with Business Insider, according to express.co.uk on January 4.&nbsp;</p><p>Musk said he had a positive experience when talking to Chinese government officials during his visits to the country and said they could "possibly" be "more responsible" to their people's happiness than the US.</p><p>Anyone who is unbiased and hopes to understand the real China objectively will come to such a conclusion, which reflects the reality of China's development history over the past 100 years, and the rapid changes that are currently taking place across Chinese land, Hua Chunying, spokesperson of China's Foreign Ministry, said on Friday.&nbsp;&nbsp;</p><p>We welcome more foreign friends to visit China and gain an accurate impression of the country through close contact with Chinese people, she added.&nbsp;&nbsp;</p><p>Hua noted that, during the fight against the pandemic, everyone has also seen that the Chinese government insisted on putting people and their livelihoods first and spared no effort in protecting everyone's life, health, value and dignity.</p><p>We have also implemented the largest and most powerful battle against poverty in human history and successfully lifted 850 million people out of poverty, she added.</p><p>"This year, we have embarked on a new journey of building a modern socialist country in an all-round way. I think our Chinese people's growing needs or yearning for a better life will be further satisfied," Hua said.&nbsp;</p></div>
        </div></div>]]>
            </description>
            <link>https://www.globaltimes.cn/page/202101/1212242.shtml#.X_nTsdClAgQ.twitter</link>
            <guid isPermaLink="false">hacker-news-small-sites-25701603</guid>
            <pubDate>Sat, 09 Jan 2021 16:20:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Next Gen Static Blogging]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 168 (<a href="https://news.ycombinator.com/item?id=25701053">thread link</a>) | @mmackh
<br/>
January 9, 2021 | https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging | <a href="https://web.archive.org/web/*/https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://inoads.com/articles/2020-01-09-Next-Gen-Static-Blogging</link>
            <guid isPermaLink="false">hacker-news-small-sites-25701053</guid>
            <pubDate>Sat, 09 Jan 2021 15:25:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Holiday Hacking – Tracking my heart rate while playing Call of Duty]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25700872">thread link</a>) | @lukastyrychtr
<br/>
January 9, 2021 | https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/ | <a href="https://web.archive.org/web/*/https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span>04 Jan 2021</span></p><p>Over the holidays, I got a <a href="https://www.polar.com/us-en/products/accessories/oh1-optical-heart-rate-sensor">Polar OH1+</a> as a Christmas present. Its an optical heart rate monitor with similar tech to those found in smart watches (including my Garmin running watch), but much more accurate (at least for running) due to being smaller &amp; lighter, as well as fitting against the fleshier upper arm:</p>

<p><img src="https://jcdav.is/public/oh1-small.jpg" alt="Polar OH1"></p>

<p>Like any modern gadget these days, it supports Bluetooth (specifically Bluetooth Low Energy, or BLE/BTLE) for talking to your phone and/or smart watch. Which got me wondering, will it pair with a computer?</p>

<p><img src="https://jcdav.is/public/bluetooth.jpg" alt="It pairs"></p>

<p>This piqued my curiosity. I had long been at least somewhat curious about tracking my heart rate while say playing video games, if nothing else for curiosity. So how easy is it to grab data from this thing? As with the last few years, I had spent a bit of December doing a bunch of <a href="https://adventofcode.com/">Advent of Code</a> in rust, only to forget and have to re-learn everything the next year. So figured I could maybe try my hand at a “real” project.</p>

<p>Some quick googling later, I found the promising-looking <a href="https://crates.io/crates/btleplug">btleplug</a> crate. Lets dump data from all nearby devices…</p>

<div><div><pre><code><span>extern</span> <span>crate</span> <span>btleplug</span><span>;</span>

<span>use</span> <span>std</span><span>::</span><span>thread</span><span>;</span>
<span>use</span> <span>std</span><span>::</span><span>time</span><span>::</span><span>Duration</span><span>;</span>

<span>#[cfg(target_os</span> <span>=</span> <span>"linux"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>bluez</span><span>::{</span><span>adapter</span><span>::</span><span>ConnectedAdapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>#[cfg(target_os</span> <span>=</span> <span>"windows"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>winrtble</span><span>::{</span><span>adapter</span><span>::</span><span>Adapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>#[cfg(target_os</span> <span>=</span> <span>"macos"</span><span>)]</span>
<span>use</span> <span>btleplug</span><span>::</span><span>corebluetooth</span><span>::{</span><span>adapter</span><span>::</span><span>Adapter</span><span>,</span> <span>manager</span><span>::</span><span>Manager</span><span>};</span>
<span>use</span> <span>btleplug</span><span>::</span><span>api</span><span>::{</span><span>UUID</span><span>,</span> <span>Central</span><span>,</span> <span>Peripheral</span><span>};</span>

<span>#[cfg(any(target_os</span> <span>=</span> <span>"windows"</span><span>,</span> <span>target_os</span> <span>=</span> <span>"macos"</span><span>))]</span>
<span>fn</span> <span>get_central</span><span>(</span><span>manager</span><span>:</span> <span>&amp;</span><span>Manager</span><span>)</span> <span>-&gt;</span> <span>Adapter</span> <span>{</span>
    <span>let</span> <span>adapters</span> <span>=</span> <span>manager</span><span>.adapters</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>adapters</span><span>.into_iter</span><span>()</span><span>.nth</span><span>(</span><span>0</span><span>)</span><span>.unwrap</span><span>()</span>
<span>}</span>

<span>#[cfg(target_os</span> <span>=</span> <span>"linux"</span><span>)]</span>
<span>fn</span> <span>get_central</span><span>(</span><span>manager</span><span>:</span> <span>&amp;</span><span>Manager</span><span>)</span> <span>-&gt;</span> <span>ConnectedAdapter</span> <span>{</span>
    <span>let</span> <span>adapters</span> <span>=</span> <span>manager</span><span>.adapters</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>let</span> <span>adapter</span> <span>=</span> <span>adapters</span><span>.into_iter</span><span>()</span><span>.nth</span><span>(</span><span>0</span><span>)</span><span>.unwrap</span><span>();</span>
    <span>adapter</span><span>.connect</span><span>()</span><span>.unwrap</span><span>()</span>
<span>}</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>manager</span> <span>=</span> <span>Manager</span><span>::</span><span>new</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>let</span> <span>central</span> <span>=</span> <span>get_central</span><span>(</span><span>&amp;</span><span>manager</span><span>);</span>

    <span>central</span><span>.start_scan</span><span>()</span><span>.unwrap</span><span>();</span>
    <span>thread</span><span>::</span><span>sleep</span><span>(</span><span>Duration</span><span>::</span><span>from_secs</span><span>(</span><span>2</span><span>));</span>

    <span>for</span> <span>per</span> <span>in</span> <span>&amp;</span><span>central</span><span>.peripherals</span><span>()</span> <span>{</span>
        <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>per</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>(Note that though this part should work cross-platform, I couldn’t get bluetooth working from WSL, so this was all done natively on Windows).</p>

<p>Sure enough, among the shockingly large list of nearby devices is my new toy:</p>

<div><div><pre><code>A0:9E:1A:XX:XX:XX properties: PeripheralProperties { address: A0:9E:1A:XX:XX:XX, address_type: Public, local_name: Some("Polar OH1 XXXXXXXX"), tx_power_level: Some(-64), manufacturer_data: Some([]), discovery_count: 6, has_scan_response: true }, characteristics: {}
</code></pre></div></div>

<p>Let’s see what characteristics it supports:</p>

<div><div><pre><code>    <span>let</span> <span>ohr</span> <span>=</span> <span>central</span><span>.peripherals</span><span>()</span><span>.into_iter</span><span>()</span><span>.find</span><span>(|</span><span>p</span><span>|</span> <span>{</span>
        <span>p</span><span>.properties</span><span>()</span><span>.local_name</span><span>.map</span><span>(|</span><span>n</span><span>|</span> <span>n</span><span>.starts_with</span><span>(</span><span>"Polar OH1"</span><span>))</span>
            <span>.unwrap_or</span><span>(</span><span>false</span><span>)</span>
    <span>})</span><span>.unwrap</span><span>();</span>

    <span>ohr</span><span>.connect</span><span>();</span>
    <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>ohr</span><span>.discover_characteristics</span><span>()</span><span>.unwrap</span><span>());</span>
</code></pre></div></div>

<p>Turns out..a lot?</p>

<div><div><pre><code>[Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:00:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:01:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:04:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:A6:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:05:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:29:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:24:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:25:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:27:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:26:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:28:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:23:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:51:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE_WITHOUT_RESPONSE | WRITE | NOTIFY },
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:52:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:53:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE_WITHOUT_RESPONSE | WRITE },
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:37:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 00:00:2A:19:00:00:10:00:80:00:00:80:5F:9B:34:FB, properties: READ | NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:21:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:22:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:26:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 62:17:FF:4C:C8:EC:B1:FB:13:80:3A:D9:86:70:8E:2D, properties: READ }, 
Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: 62:17:FF:4D:91:BB:91:D0:7E:2A:7C:D3:BD:A8:A1:F3, properties: WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:81:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: READ | WRITE | INDICATE }, Characteristic { start_handle: 0, end_handle: 0, value_handle: 0, uuid: FB:00:5C:82:02:E7:F3:87:1C:AD:8A:CD:2D:8D:F0:C8, properties: NOTIFY }]
</code></pre></div></div>

<p>Which of these do I want? The <a href="https://btprodspecificationrefs.blob.core.windows.net/assigned-values/16-bit%20UUID%20Numbers%20Document.pdf">Bluetooth UUID specifications</a> lists a bunch of different potentially interesting IDs, but they are all 16 bits, whereas are 128 bit. Making matters more confusing, <code>btleplug</code> ‘s UUID definition seems to allow for either:</p>

<div><div><pre><code><span>pub</span> <span>enum</span> <span>UUID</span> <span>{</span>
    <span>B16</span><span>(</span><span>u16</span><span>),</span>
    <span>B128</span><span>([</span><span>u8</span><span>;</span> <span>16</span><span>]),</span>
<span>}</span>
</code></pre></div></div>

<p>However it seems like a lot of them seem to only differ in the 3rd and 4th bytes <sup><a href="#suff1">1</a></sup>, and those to roughly correspond to GATT Characteristic Ids, and in there is a <code>2A:37</code>, which represents Heart Rate Measurement - sounds promising. Lets see if we can listen &amp; dump that data:</p>

<div><div><pre><code>    <span>let</span> <span>mut</span> <span>bytes</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>16</span><span>]</span> <span>=</span> <span>[</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x2A</span><span>,</span><span>0x37</span><span>,</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x10</span><span>,</span><span>0x00</span><span>,</span><span>0x80</span><span>,</span><span>0x00</span><span>,</span><span>0x00</span><span>,</span><span>0x80</span><span>,</span><span>0x5F</span><span>,</span><span>0x9B</span><span>,</span><span>0x34</span><span>,</span><span>0xFB</span><span>];</span>
    <span>bytes</span><span>.reverse</span><span>();</span>
    <span>let</span> <span>uuid</span> <span>=</span> <span>UUID</span><span>::</span><span>B128</span><span>(</span><span>bytes</span><span>);</span>
    <span>let</span> <span>chars</span> <span>=</span> <span>ohr</span><span>.discover_characteristics</span><span>()</span>
        <span>.expect</span><span>(</span><span>"Couldn't discover characteristics"</span><span>);</span>
    <span>let</span> <span>hr_char</span> <span>=</span> <span>chars</span><span>.iter</span><span>()</span><span>.find</span><span>(|</span><span>c</span><span>|</span> <span>c</span><span>.uuid</span> <span>==</span> <span>uuid</span><span>)</span>
        <span>.expect</span><span>(</span><span>"couldn't find HR characteristic"</span><span>);</span>

    <span>ohr</span><span>.on_notification</span><span>(</span><span>Box</span><span>::</span><span>new</span><span>(|</span><span>not</span><span>|</span> <span>{</span>
        <span>println!</span><span>(</span><span>"{:?}"</span><span>,</span> <span>not</span><span>.value</span><span>);</span>
    <span>}));</span>
    <span>ohr</span><span>.subscribe</span><span>(</span><span>hr_char</span><span>)</span><span>.expect</span><span>(</span><span>"Couldn't subscribe"</span><span>);</span>
    <span>loop</span> <span>{</span>
    <span>}</span>
</code></pre></div></div>

<p>Endianness issues out of the way this….seems to be working?</p>

<div><div><pre><code>C:\Users\jackson\Dev\hroverlay&gt;cargo run
    Finished dev [unoptimized + debuginfo] target(s) in 0.14s
     Running `target\debug\hroverlay.exe`
[0, 59]
[0, 58]
[0, 58]
[0, 59]
[0, 60]
[0, 61]
[0, 62]
</code></pre></div></div>

<p>At least that second number sure looks like a heart rate reading. To confirm this, I hopped over to the technical specifications for the Heart Rate Service (downloadable <a href="https://www.bluetooth.com/specifications/gatt/">here</a>). Sure enough, byte 0 represents various flags and byte 1 is a heart rate measurement. The spec authors have even figured out support for heart rates &gt;255 on off chance you ever slap one of these bad boys on a hummingbird:</p>

<blockquote>
  <p>3.1.1.2Heart Rate Measurement Value Field</p>

  <p>The Heart Rate Measurement Value field shall be included in the Heart Rate Measurement characteristic. While most human applications require support for only 255 bpm or less, special applications (e.g. animals) may require support for higher bpm values. If the Heart Rate Measurement Value is less than or equal to 255 bpm a UINT8 format should be used for power savings. If the Heart Rate Measurement Value exceeds 255 bpm a UINT16 format shall be used. See 3.1.1.1.1for additional requirements on the Heart Rate Value format change.</p>
</blockquote>

<p>Other potentially interesting bit flags include a way to indicate if the sensor thinks it has lost skin contact.</p>

<h2 id="displaying-things">Displaying things</h2>

<p>Now its time to figure out a UI. Faced with a <a href="https://www.areweguiyet.com/">large number of different options</a>, I ended up settling on the not-even-listed-there <a href="https://crates.io/crates/native-windows-gui">native-windows-gui crate</a> , throwing cross-platform support into the wind on the suspicion I would need easy access to the underlying win32 APIs, since it is largely just a series of nice convenience abstractions over those. Using the associated native-windows-derive macro crate, I had a basic UI setup working fairly quickly:</p>

<div><div><pre><code><span>#[derive(Default,</span> <span>NwgUi)]</span>
<span>pub</span> <span>struct</span> <span>BasicApp</span> <span>{</span>
    <span>#[nwg_control(size:</span> <span>(</span><span>300</span><span>,</span> <span>115</span><span>),</span> <span>flags:</span> <span>"WINDOW|VISIBLE"</span><span>)]</span>
    <span>#[nwg_events(OnWindowClose:</span> <span>[</span><span>BasicApp::exit]</span><span>)]</span>
    <span>window</span><span>:</span> <span>nwg</span><span>::</span><span>Window</span><span>,</span>

    <span>#[nwg_layout(parent:</span> <span>window)]</span>
    <span>grid</span><span>:</span> <span>nwg</span><span>::</span><span>GridLayout</span><span>,</span>

    <span>#[nwg_control(text:</span> <span>"--"</span><span>,</span> <span>readonly:</span> <span>true</span><span>)]</span>
    <span>#[nwg_layout_item(layout:</span> <span>grid,</span> <span>row:</span> <span>0</span><span>,</span> <span>col:</span> <span>0</span><span>)]</span>
    <span>hr</span><span>:</span> <span>nwg</span><span>::</span><span>TextInput</span><span>,</span>

    <span>#[nwg_control(parent:</span> <span>window,</span> <span>interval:</span> <span>500</span><span>,</span> <span>stopped:</span> <span>false</span><span>)]</span>
    <span>#[nwg_events(OnTimerTick:</span> <span>[</span><span>BasicApp::draw_hr]</span><span>)]</span>
    <span>timer</span><span>:</span> <span>nwg</span><span>::</span><span>Timer</span><span>,</span>
<span>}</span>

<span>impl</span> <span>BasicA…</span></code></pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/">https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/</a></em></p>]]>
            </description>
            <link>https://jcdav.is/2021/01/04/Holiday-Hacking-COD-HR/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700872</guid>
            <pubDate>Sat, 09 Jan 2021 15:03:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ray Tracing in pure CMake]]>
            </title>
            <description>
<![CDATA[
Score 272 | Comments 142 (<a href="https://news.ycombinator.com/item?id=25700038">thread link</a>) | @networked
<br/>
January 9, 2021 | https://64.github.io/cmake-raytracer/ | <a href="https://web.archive.org/web/*/https://64.github.io/cmake-raytracer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    
    

    <div>
      <p>Without further ado, I present: a basic whitted ray tracer, complete with multicore rendering, written in 100% pure CMake. If you don't care about the details, and just want to see the code, you can <a href="https://github.com/64/cmake-raytracer">find it here</a>.</p>
<figure>
    <img src="https://github.com/64/cmake-raytracer/raw/master/render.png">
    <figcaption><i>Rendered in 7m23s on a i5-10210U, 8 processes</i> </figcaption>
</figure>
<p>At this point, those familiar with CMake may have some questions, so keep reading to find out how it all works.</p>

<p><strong>Good news:</strong> CMake has a <a href="https://cmake.org/cmake/help/latest/command/math.html?highlight=math"><code>math</code></a> command. <strong>Bad news:</strong> it only supports integers. If you've written a ray tracer before, you probably did it with floating point numbers. So how do you go from representing signed integers to representing something-resembling-floating-point numbers? One answer is to use <a href="https://en.wikipedia.org/wiki/Fixed-point_arithmetic"><strong>fixed-point arithmetic</strong></a>.</p>
<p>The basic idea with fixed point is simple. We define some large integer to represent the number 1.0; let's choose <strong>1000</strong>. Then we can represent 2.0 as 2000, 0.5 as 500, -3.0 as -3000 etc. When we want to add two numbers, we simply add their fixed-point representations. Here's how that looks in CMake:</p>
<pre><span>function(add a b res)
    math(EXPR tmp </span><span>"(${</span><span>a</span><span>}) + (${</span><span>b</span><span>})"</span><span>)
    set(</span><span>"${</span><span>res</span><span>}" "${</span><span>tmp</span><span>}" </span><span>PARENT_SCOPE)
endfunction()
</span></pre>
<p>This takes two values <code>a</code> and <code>b</code> to be added and stored in the variable <code>res</code>. I use <code>PARENT_SCOPE</code> so that the variable we create is actually visible from the calling function, otherwise CMake will destroy it when the function ends.</p>
<p>To multiply two numbers, we simply multiply their fixed-point representations, and then divide by the thing we chose to represent 1.0:
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn><mo>×</mo><mn>4.0</mn><mo>↦</mo><mfrac><mrow><mn>1500</mn><mo>×</mo><mn>4000</mn></mrow><mn>1000</mn></mfrac><mo>=</mo><mn>6000</mn><mo>↦</mo><mn>6.0</mn></mrow><annotation encoding="application/x-tex">1.5 \times 4.0 \mapsto \frac{1500 \times 4000}{1000} = 6000 \mapsto 6.0</annotation></semantics></math></span></span></span></p>
<p>Division is similar:
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1.5</mn><mo>÷</mo><mn>4.0</mn><mo>↦</mo><mfrac><mrow><mn>1500</mn><mo>×</mo><mn>1000</mn></mrow><mn>4000</mn></mfrac><mo>=</mo><mn>375</mn><mo>↦</mo><mn>0.375</mn></mrow><annotation encoding="application/x-tex">1.5 \div 4.0 \mapsto \frac{1500 \times 1000}{4000} = 375 \mapsto 0.375</annotation></semantics></math></span></span></span>
We could have multiplied by 1000 after doing the division, but as integer division rounds towards zero this would wipe out all our precision (as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1500</mn><mn>4000</mn></mfrac><mo>×</mo><mn>1000</mn><mo>=</mo><mn>0</mn><mo>×</mo><mn>1000</mn><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\frac{1500}{4000}\times 1000 = 0 \times 1000 = 0</annotation></semantics></math></span></span>). Multiplying first gives us better results, as long as the dividend isn't too huge (which would cause overflow).</p>
<p>CMake's <code>math</code> command only supports basic integer arithmetic. For more complicated operations, like square root, we use <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton-Raphson iteration</a>. You can read more about this <a href="https://en.wikipedia.org/wiki/Methods_of_computing_square_roots#Babylonian_method">here</a>, but the basic idea is to make a 'guess' as to what the output should be then iteratively refine the guess towards the answer. This gives a surprisingly accurate result within only three or four iterations, subject to the quality of the initial guess:</p>
<pre><span>function(sqrt x res)
    div_by_2(${x} guess)

    </span><span>foreach</span><span>(counter RANGE 4)
        </span><span>if</span><span>(${guess} EQUAL 0)
            set(</span><span>"${</span><span>res</span><span>}" </span><span>0 PARENT_SCOPE)
            return()
        </span><span>endif</span><span>()

        div(${x} ${guess} tmp)
        add(${tmp} ${guess} tmp)
        div_by_2(${tmp} guess)
    </span><span>endforeach</span><span>()

    set(</span><span>"${</span><span>res</span><span>}" "${</span><span>guess</span><span>}" </span><span>PARENT_SCOPE)
endfunction()

</span><span># sqrt(123) = 11.09072626, actual answer is 11.0905365064
</span></pre>
<p>I also implemented a similar function for computing <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><msqrt><mi>x</mi></msqrt></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{x}}</annotation></semantics></math></span></span> separately as I found that it lead to better numerical stability, as opposed to computing the square root as above and then doing the reciprocal. This comes in handy when we need to normalize vectors.</p>
<p>Almost everything in computer graphics is done with vectors, so I started implementing vector operations: <code>vec3_add</code>, <code>vec3_mul</code>, <code>vec3_div</code>, <code>vec3_dot</code> etc. These make use of CMake built-in lists, which are pretty horrible, but save me from having to use three separate variables to keep track of the individual components of each vector. For example, here's what the dot product looks like:</p>
<pre><span>function(vec3_dot x y res)
    list(GET ${x} 0 x_0)
    list(GET ${x} 1 x_1)
    list(GET ${x} 2 x_2)
    list(GET ${y} 0 y_0)
    list(GET ${y} 1 y_1)
    list(GET ${y} 2 y_2)
    mul(${x_0} ${y_0} z_0)
    mul(${x_1} ${y_1} z_1)
    mul(${x_2} ${y_2} z_2)
    add(${z_0} ${z_1} tmp)
    add(${tmp} ${z_2} tmp)
    set(</span><span>"${</span><span>res</span><span>}" </span><span>${tmp} PARENT_SCOPE)
endfunction()
</span></pre>
<p>And here's how we'd use it to normalize a vector:</p>
<pre><span>function(vec3_normalize x res)
    vec3_dot(${x} ${x} x_2)
    rsqrt(${x_2} one_over_length)
    vec3_mulf(${x} ${one_over_length} tmp)
    set(</span><span>"${</span><span>res</span><span>}" </span><span>${tmp} PARENT_SCOPE)
endfunction()
</span></pre>
<p>As well a few other bits and bobs, like <code>clamp</code> and <code>truncate</code>, that's all the arithmetic that's needed.</p>

<p>If you're new to ray tracing, I'd refer you to <a href="https://twitter.com/peter_shirley">Peter Shirley's</a> wonderful book series '<a href="https://raytracing.github.io/">Ray Tracing in One Weekend</a>', which my code is loosely based on. The general intuition is to trace rays out from the camera into the scene and see what they intersect. Since we represent all our scene geometry and rays as mathematical objects, computing intersections between rays and geometry is just a case of solving equations. Once we have found an intersection, we compute the color of the point we intersected with, which may itself be computed by tracing rays towards light sources or towards other scene geometry.</p>
<figure>
    <img src="https://developer.nvidia.com/sites/default/files/pictures/2018/RayTracing/ray-tracing-image-1.jpg">
    <figcaption><i>The ray tracing algorithm.</i>  Credit: <a href="https://developer.nvidia.com/discover/ray-tracing">https://developer.nvidia.com</a></figcaption>
</figure> 
<p>To keep it simply I went with a simple scene consisting of a sphere sitting atop an infinite plane in a checkerboard color. I also ended up faking the shadow underneath the sphere, simply drawing a black circle (well done if you spotted it from the image). I had implemented whitted ray tracing and even path tracing at one point, but they were much more complicated and performed a lot worse for the same result. In theory, though, there's no reason why I couldn't do it properly, it would just require some additional effort and patience.</p>
<p>Here's what the main 'trace' function looks like, with some of the unnecessary bits stripped out for clarity:</p>
<pre><span># Traces a ray into the scene, computes the color returned along the ray
</span><span>function(trace ray_origin ray_dir depth color)
    </span><span># Base case for recursion
    </span><span>if</span><span>(${depth} GREATER_EQUAL 3)
        return()
    </span><span>else</span><span>()
        math(EXPR depth </span><span>"${</span><span>depth</span><span>} + 1"</span><span>)
    </span><span>endif</span><span>()

    </span><span># Calculate intersection points with the sphere and plane
    </span><span>sphere_intersect(${ray_origin} ${ray_dir} hit_t_1 hit_point_1 hit_normal_1)
    plane_intersect(${ray_origin} ${ray_dir} hit_t_2 hit_point_2 hit_normal_2)

    </span><span># Did we hit the sphere?
    </span><span>if</span><span>(${hit_t_1} GREATER ${ray_epsilon})
        </span><span># Calculate reflected ray direction
        </span><span>offset_origin(hit_point_1 hit_normal_1 new_origin)
        vec3_dot(hit_normal_1 ${ray_dir} scalar)
        mul_by_2(${scalar} scalar)
        vec3_mulf(hit_normal_1 ${scalar} refl_a)
        vec3_sub(${ray_dir} refl_a new_dir)

        </span><span># Recursively trace the new ray into the scene
        </span><span>trace(new_origin new_dir ${depth} traced_col)

        </span><span># Calculate contribution from lights
        </span><span>set(col 0 0 0)
        light_contrib(hit_point_1 hit_normal_1 light1_pos light1_col out_col1)
        light_contrib(hit_point_1 hit_normal_1 light2_pos light2_col out_col2)
        vec3_add(col out_col1 col)
        vec3_add(col out_col2 col)
        vec3_add(col traced_col col)

        set(base_col ${sphere_color})
        vec3_mul(base_col col col)

    </span><span># Did we hit the plane?
    </span><span>elseif</span><span>(${hit_t_2} GREATER ${ray_epsilon})
        </span><span># ...snip: Use equation of a circle to fake shadow, if we're within range
        # ...snip: Calculate checkerboard pattern
    </span><span>else</span><span>()
        </span><span># We hit nothing, return black
        </span><span>set(col 0 0 0)
    </span><span>endif</span><span>()

    set(</span><span>"${</span><span>color</span><span>}" </span><span>${col} PARENT_SCOPE)
endfunction()
</span></pre>
<p>When I started, I wouldn't sure if it would be possible to do in pure CMake, but with a little trickery we can manage it.</p>
<p>For <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> processes, the basic plan is to divide up the image vertically and let each sub-process render a few rows. We can invoke sub-processes with the <a href="https://cmake.org/cmake/help/v3.0/command/execute_process.html"><code>execute_process</code></a> command, passing arguments (such as the worker index) via <code>-D</code>. Each process then spits their row data into a text file, which gets merged together by the master process once they've all finished.</p>
<p>One subtlety is that as we need all the sub-processes to run in parallel, we can't simply call <code>execute_process</code> <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> times, as it would run them sequentially. Luckily, we can specify multiple processes to run simultaneously in one command (I think this is intended to be used for long chains where one program is piped into the next), but in order to avoid hardcoding <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span></span> we have to programmatically construct the call to <code>execute_process</code> with CMake's <a href="https://cmake.org/cmake/help/git-stage/command/cmake_language.html"><code>EVAL CODE</code></a> feature (thanks to <a href="https://github.com/martty/vuk">martty</a> for this idea):</p>
<pre><span>message(STATUS </span><span>"Launching ray tracer with ${</span><span>num_procs</span><span>} processes, ${</span><span>image_width</span><span>}x${</span><span>image_height</span><span>} image..."</span><span>)

set(exec_command </span><span>"execute_process(</span><span>\n</span><span>"</span><span>)
</span><span>foreach</span><span>(worker_index RANGE 1 ${num_procs})
    set(exec_command </span><span>"${</span><span>exec_command</span><span>}COMMAND cmake . -Wno-dev -Dworker_index=${</span><span>worker_index</span><span>} -Dimage_width=${</span><span>image_width</span><span>} -Dimage_height=${</span><span>image_height</span><span>} -Dnum_procs=${</span><span>num_procs</span><span>}</span><span>\n</span><span>"</span><span>)
</span><span>endforeach</span><span>()
set(exec_command </span><span>"${</span><span>exec_command</span><span>} )"</span><span>)

</span><span># Begin the worker processes
</span><span>cmake_language(EVAL CODE ${exec_command})

message(STATUS </span><span>"Finished ray tracing, gathering results..."</span><span>)
</span></pre>
<p>As per <a href="https://raytracing.github.io/">Ray Tracing in One Weekend</a>, I use the <a href="https://en.wikipedia.org/wiki/Netpbm#PPM_example">PPM image format</a>. This is a really simple text-based format which is perfect for my purposes as I don't have to bother with compression. Once we're done rendering we simply read all the data that the workers have spat out, write the PPM header, and print everything to <code>stderr</code>:</p>
<pre><span>set(image_contents </span><span>"P3 ${</span><span>image_width</span><span>} ${</span><span>image_height</span><span>}</span><span>\n</span><span>255</span><span>\n\n</span><span>"</span><span>)

</span><span>foreach</span><span>(worker_index RANGE 1 ${num_procs})
    file(READ </span><span>"worker-${</span><span>worker_index</span><span>}.txt" </span><span>file_contents)
    set(image_contents </span><span>"${</span><span>image_contents</span><span>}${</span><span>file_contents</span><span>}"</span><span>)
</span><span>endforeach</span><span>()

message(</span><span>"${</span><span>image_contents</span><span>}"</span><span>)
</span></pre>
<p>The division of work among the worker processes is pretty sub-optimal as the rows towards the top of the image are mostly empty whereas the rows at the bottom are entirely full, which means that some processes finish very fast while others take much longer. Fixing this problem is left as an exercise to the reader.</p>

<p>If you made it this far, thanks for reading! Feel free to create issues, send pull requests or star <a href="https://github.com/64/cmake-raytracer">the code on GitHub</a>.</p>

    </div>

    
    

    

    
        
            
              
        
    
</article></div>]]>
            </description>
            <link>https://64.github.io/cmake-raytracer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25700038</guid>
            <pubDate>Sat, 09 Jan 2021 13:04:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Authoritarianism Through Coding: Signal]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25699993">thread link</a>) | @m3rcury
<br/>
January 9, 2021 | https://www.oyd.org.tr/en/articles/signal/ | <a href="https://web.archive.org/web/*/https://www.oyd.org.tr/en/articles/signal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">
  <article>
    
     
      
    <p>This isn’t a theoretical piece about freedom and digital technologies. This is a real ongoing trend that is at best observed around secure messaging application Signal by Open Whisper Systems and it’s founder Moxie Merlinspike. His view and management of Signal reflects a wider trend that jepordises world’s freedom.</p>
<p>Signal is a secure messaging software that has changed the field a lot. Signal is built upon propriety software Textsecure and RedPhone applications that had been developed by Merlinspike and his co-founder Stuart Anderson. When Twitter acquired Whisper Systems, it releases both software under free software licenses. Merlinspike left Twitter acquired Whisper Systems, founded Open Whisper Systems and merged -once the private property of himself- TextSecure and Redphone into Signal.</p>
<p>Signal is free software. “Free as in freedom”, their client and server code is licenced under GPLv3 and AGPLv3. This makes the code and only the code itself pro-freedom. Just because the code it self free does not necessarily make the coder “free” as well and that is the problem we face today!</p>
<p>Open Whisper Systems led by Moxie Merlinspike, who is behind Signal, is and was never behind freedom. This has been seen in the light of LibreSignal (<a href="https://github.com/LibreSignal/LibreSignal/issues/37#issuecomment-217211165">https://github.com/LibreSignal/LibreSignal/issues/37#issuecomment-217211165</a>) debate where a fork of Signal client is build without unfree dependencies and published on the F-droid free software repository on Android. After much debate about federation, the claimed server resources and freedom, followed by legal trademark threats Libresignal has been removed from F-droid and so was anybody’s chance of using Signal as a secure messenger who doesn’t use Google services. <a href="https://wire.com/en/blog/axolotl-proteus-encryption-protocols/">Wire</a> case is just another example.</p>
<p>This approach is not only a threat to free software it is a recurring threat to human kind!</p>
<p>To prove this bold claim one needs to look at one recent blog post from Open Whisper Systems and a presentation made in 36C3 by Merlinspike.</p>
<p><a href="https://signal.org/blog/the-ecosystem-is-moving/">Signal’s blog post</a>
<a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">Matrix’s blog Post</a></p>
<p>The main points of his claims can be listed as follows:</p>
<ul>
<li>Decentralized systems are harder to build</li>
<li>Decentralized systems are harder to evolve</li>
<li>Decentralized systems are harder to secure</li>
<li>Decentralized systems are becoming concentrated in predominant provider anyways</li>
<li>If users don’t trust their app provider they have the freedom to use something else</li>
</ul>
<p>While his claims are true up to a certain point they are only superficial. Through these points Merlinspike claims that, centralized services are superior in modern times!</p>
<p><a href="https://matrix.org/blog/2020/01/02/on-privacy-versus-freedom/">anyone who is interested in the depth of this debate can start reading Martix’s answer to Merlinspike at the link here</a></p>
<p>It is really unnecessary to explain in depth why this type of thinking is dangerous when a simple change in words can tell more than 1000 page work. Let’s rename the object and compare his digital dystopia with one that has occured several times through-out analog human history and which once again recures today;</p>
<ul>
<li>Democracies are harder to build</li>
<li>Democracies are harder to improve</li>
<li>Democracies are harder to secure</li>
<li>In democracies power is becoming concentrated in predominant hands anyways</li>
<li>If people do not like their democracy provider (country) they have the freedom to leave and go another provider.</li>
</ul>
<p>One doesn’t need to think hard to see what Merlinspike is advising. He claims democracies suck because of the hardships of human organization and proposes autocracy to manage the world in favour of the helpless people occupying it. Why? Because democracies are inefficient and people don’t want that!</p>
<p>If he had given the same statement about democracies and governmental politics as he gave about federative systems it would have provoked outrage! People died for freedom, they are still dying and struggling around the globe. Then someone comes and stomps over every ideal which human society ever build up until this point in history and proclaims themselves the world leader! Think about it!</p>
<p>The example given is bad but why are Merlinspike’s claims about decentralized systems not considered bad as well? Because digital freedom has not yet been lost and won by blood or are we still asleep? Just because code is free, it doesn’t necessarily mean that the coders mind is also free! Freedom is not just a license, it is an ideal in any condition that we must stand for!</p>

    
        <hr>



    
  </article>
  
</div></div>]]>
            </description>
            <link>https://www.oyd.org.tr/en/articles/signal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699993</guid>
            <pubDate>Sat, 09 Jan 2021 12:56:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Haskell is a Bad Programming Language (2020)]]>
            </title>
            <description>
<![CDATA[
Score 331 | Comments 286 (<a href="https://news.ycombinator.com/item?id=25699574">thread link</a>) | @fpoling
<br/>
January 9, 2021 | https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#👾 | <a href="https://web.archive.org/web/*/https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#👾">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://blog.shitiomatic.tech/post/haskell-is-a-bad-programming-language/#👾</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699574</guid>
            <pubDate>Sat, 09 Jan 2021 11:40:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep neck flexor exercises – Back and neck]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 110 (<a href="https://news.ycombinator.com/item?id=25699510">thread link</a>) | @whereistimbo
<br/>
January 9, 2021 | https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html | <a href="https://web.archive.org/web/*/https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mainContent">
	<div>
        <div id="leftCol_normal">

<h2>Deep neck flexor exercises</h2>
<br>
<h3>Why train them?</h3>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_1.jpg"></p><p>The deep neck flexor muscles sit deep in the front of the neck, behind the trachea (windpipe). Because of their close proximity to the vertebrae (spine) and their short length, they have an important role in providing stability to the neck. People with a history of neck or upper back injury, such as whiplash, can show great improvement in pain and function if they strengthen these muscles. Those with postural neck pain often have weakness in these muscles and overuse in the muscles on the top of the shoulders. They too can show a great response to retraining the deep neck flexor muscle group.
</p><br>

<h3>How do I exercise them?</h3>
<h5>Exercise 1</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_2.jpg"></p><ul>
<li>Lie on your back with knees comfortably bent. Find your neutral spine position, as explained by your physiotherapist. Use a small rolled towel under the head if needed.</li>
<li>Lift your head off the towel and feel the muscles on the front of the neck. These are NOT the deep neck flexor muscles - these muscles often overwork to try and help with stability, they are not designed for this purpose.</li>
<li>Perform a small nodding movement, as if to look towards your toes. Don't lift your head up. You should not feel the muscles on the front of the neck moving, but rather you should be using the muscles deep behind them.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 2</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_3.jpg"></p><ul>
<li>Position as above.</li>
<li>Place your hand on the side of your head and provide gentle resistance, as if you are bending your head to one side.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
<li>Use hand to resist small rotation movement.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 3</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_4.jpg"></p><ul>
<li>Lie on your tummy with hands supporting the forehead.</li>
<li>Perform the small nodding movement and float the head and breastbone off the floor.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 4a:</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_5.jpg"></p><ul>
<li>Stand with your back to the wall and your feet slightly in front, hip width apart. Perform the small nodding movement, while sliding the base of the skull up the wall. You should feel the neck lengthen.</li>
<li>Hold for 5 seconds. Repeat 10 times.</li>
</ul>
<h5>Exercise 4b:</h5>

<ul>
<li>Same as exercise above.</li>
<li>From the lengthened position, move your head away from the wall so that you're looking at the floor.</li>
<li>Then return to the starting position.</li>
<li>Do not allow your chin to poke forward through either movement.</li>
</ul>

<h5>Exercise 4c:</h5>
<p>
<img src="https://www.sprintphysio.co.uk/images/patient-exercises/deep_neck_8.jpg"></p><ul>
<li>Sitting in a chair, look up at the ceiling.</li>
<li>When returning the head back to the neutral position, do not let the chin poke forward.</li>
<li>Curl forward one level at a time, starting from the top.</li>
<li>Do not allow your chin to poke forward.</li>
</ul>
<br>

<h3>Where do I go from here?</h3>
<p>
Once you have mastered these exercises, you should feel more aware of your neck posture and how to position yourself correctly. You can use this knowledge:</p>
<ul>
<li>When sitting at your desk/computer or on the couch.</li>
<li>Performing any weights in the gym or doing exercise classes.</li>
</ul>

<p>

Please <a href="https://www.sprintphysio.co.uk/contact-us/index.html">contact us</a> to book an appointment or for more information on any of the services available at our clinic in Kensington.</p>
<p>
<a href="#top" title="Back To Top">↑ Back To Top</a></p>






        </div>
        
		



				
				<p><b>Insurance providers...</b></p><p><img src="https://www.sprintphysio.co.uk/images/insurance-logos.png">
				</p>
				<br>


	</div>
</div><div id="jumpsContainer">
	<div>
			<div id="j1">
				<p><a>Physiotherapy</a></p><p><a href="https://www.sprintphysio.co.uk/services/physiotherapy.html"><img src="https://www.sprintphysio.co.uk/images/physiotherapy-jump.jpg" alt="Physiotherapy" title="Physiotherapy"></a></p>
				<div><p>
					Our physiotherapists specialise in restoring your normal function and movement patterns so you can get on with everyday life. </p></div>
				<p>Read more »</p>
			</div>
			<div id="j2">
 				<p><a>Pilates</a></p><p><a href="https://www.sprintphysio.co.uk/services/pilates.html"><img src="https://www.sprintphysio.co.uk/images/pilates-jump.jpg" alt="Pilates" title="Pilates"></a></p>
				<div><p>
					Pilates focuses on building the body???s core strength and improving posture through a series of low repetition, low impact stretching and conditioning exercises. </p></div>
				<p>Read more »</p>
			</div>

            <div id="j3">
            	<p><a>Sports injuries</a></p><p><a href="https://www.sprintphysio.co.uk/services/sports-assessments.html"><img src="https://www.sprintphysio.co.uk/images/sports-injuries-jump.jpg" alt="Sports injuries" title="Sports injuries"></a></p>
				<div><p>
					At Sprint Physiotherapy we are experts at treating a variety of sporting injuries, including; swimming, running, golfing, etc.</p></div>
				<p>Read more »</p>
			</div>

            <div id="j4">
				<p><a>Massage Therapy</a></p><p><a href="https://www.sprintphysio.co.uk/services/massage.html"><img src="https://www.sprintphysio.co.uk/images/massage-therapy-jump.jpg" alt="Massage Therapy" title="Massage Therapy"></a></p>
				<div><p>
					Our massage therapists specalise in a range of massage techniques; remedial, sports, pregnancy, etc.</p></div>
				<p>Read more »</p>
			</div>
			

	</div>
</div></div>]]>
            </description>
            <link>https://www.sprintphysio.co.uk/patient-exercises/back-and-neck/deep-neck-flexor-exercises.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25699510</guid>
            <pubDate>Sat, 09 Jan 2021 11:27:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: DevBooks – Help Developers find indy books]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25698707">thread link</a>) | @simon-holdorf
<br/>
January 9, 2021 | https://thesmartcoder.dev/books/ | <a href="https://web.archive.org/web/*/https://thesmartcoder.dev/books/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div data-app="true" id="app" data-v-8b44678a=""><div> <main data-v-8b44678a=""><div><div data-v-405cec28="" data-v-8b44678a=""><div><div data-v-405cec28=""><div data-v-405cec28=""><div> <p data-v-405cec28="">
        Find the best books for developers.
      </p></div></div></div></div></div> <div data-v-8b44678a=""><div data-v-58ecdbbb="" data-v-8b44678a=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><h2>What is DevBooks?</h2> <p>DevBooks helps developers to find the best books for developers and authors to showcase their amazing work. </p></div></div> </div> <div data-v-58ecdbbb=""><div data-v-58ecdbbb=""><div xs="12"><div> <div><h2>
        A React Developer’s Guide to Hooks
      </h2> <p>by Sebastien Castiel</p> <p>
        React Hooks are awesome, but they are not easy to use every day.
In my experience with React and hooks, I have faced a lot of issues, spent some time debugging to understand where these issues came fr...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Test Automation
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn the principles behind test-driven development (TDD) and behavior-driven development (BDD) and see how Jasmine, RSpec and Cucumber can be used to your advantage. This book examines some of the le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Jest Handbook
      </h2> <p>by Hugo Di Francesco</p> <p>
        Learn Advanced JavaScript Testing patterns with Jest.

Take your JavaScript testing to the next level by learning the ins and outs of Jest, the top JavaScript testing library.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Bootstrap
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Learn to use one of the most popular CSS frameworks and build mobile-friendly web pages. Used for numerous websites and applications, Bootstrap is a key tool for modern web development.
      </p></div>  </div></div><div xs="12"><div> <div><h2>
        The Coding Career Handbook
      </h2> <p>by Shawn Swyx Wang</p> <p>
        10 hours of audio. 40 chapters. 450+ pages. 1,400+ links to original sources curated over 3 years. Priceless insights from dozens of developers at the top of their fields. Proven ideas, tested by pers...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Tech Resume Inside Out
      </h2> <p>by Gergely Orosz</p> <p>
        What a good developer resume looks like, and how to write one. I've reviewed hundreds of developer resumes at tech companies like Microsoft, Skype, and Uber. This guide helps you craft a developer res...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Code Your Way Up
      </h2> <p>by Greg Thomas</p> <p>
        Code Your Way Up is the book for new developers looking to get started in software and asks the hard questions on growth, delivery, and initiative and what you need to think of in order to succeed.  I...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Lean from the Trenches
      </h2> <p>by Henrik Kniberg</p> <p>
        You know the Agile and Lean development buzzwords, you’ve read the books. But when systems need a serious overhaul, you need to see how it works in real life, with real situations and people. Lean fro...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How to Get a Job in Web Development
      </h2> <p>by RealToughCandy</p> <p>
        "How to Get a Job in Web Development" is designed for junior web developers. 
In this book, you will learn how to:

• Expertly craft the ‘holy clover’ of application materials: your resume, cover lett...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Master HTML &amp; CSS
      </h2> <p>by Panos Matsinopoulos</p> <p>
        Want to become a Web developer? HTML and CSS are a must for your foundation. And this book takes you from zero to advanced level. From classical hello world things to how you can position elements on ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Letters To a New Developer
      </h2> <p>by Dan Moore</p> <p>
        Learn what you need to succeed as a developer beyond the code. The lessons in this book will supercharge your career by sharing lessons and mistakes from real developers. 

Wouldn’t it be nice to lear...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        How To Host, Secure, and Deliver Static Websites on Amazon Web Services
      </h2> <p>by Kyle Galbraith</p> <p>
        "How To Host, Secure, and Deliver Static Websites on Amazon Web Services" is a book and video course that cuts through the sea of information to accelerate your learning of AWS. Giving you a learning ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to GraphQL
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to GraphQL is your personal journey to master pragmatic GraphQL in JavaScript. The book is full with applications you are going to build along the way with React.js and Node.js. Afterward, yo...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Portfolio Surgery
      </h2> <p>by RealToughCandy</p> <p>
         In Portfolio Surgery, you'll start with a massive upgrade of the look and feel of your portfolio. You'll learn about common pitfalls, dos and don'ts, and portfolio optimization techniques. Then, in t...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Pure React
      </h2> <p>by Dave Ceddia</p> <p>
        Learning new skills is one of the best ways to invest in yourself.

Knowing React can be the deciding factor in getting hired for a new job, or set you up for a promotion at your current one.

You cou...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Good Parts of AWS
      </h2> <p>by Daniel Vassallo</p> <p>
        This is a book by Daniel Vassallo and Josh Pschorr. Between us, we have worked with AWS for 15 years, including 11 years working inside AWS. We have worked on all sorts of web applications, from small...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Practical Vavr
      </h2> <p>by Alexandre Grison</p> <p>
        Practical Vavr is all about making you want to use Vavr in your day to day Java programming.

If you want to improve the quality of your code by using a well-thought and beautifully designed functiona...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Your First Year in Code
      </h2> <p>by Isaac Lyman</p> <p>
        Starting a career in programming can be intimidating. Whether you're switching careers, joining a boot camp, starting a C.S. degree, or learning on your own, Your First Year in Code can help, with pra...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Building an Effective Dev Portfolio
      </h2> <p>by Josh Comeau</p> <p>
        I got so many replies! A couple hundred developers were willing to share their portfolios with me, and I went through as many as I could over the next couple of weeks. I found I kept giving the same f...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        PHP Mentors - Advice from PHP Experts around the world
      </h2> <p>by Flávio Silveira</p> <p>
        Answers from PHP masters around the world for your questions.
Code, Career, Team work, Working environment, Logs, Tests, Future and much more.

PHP Mentors Book is a set of questions with topics that ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Case of IBM 386 PC: A Detective Story for Techies
      </h2> <p>by Jim Grep</p> <p>
        Take a break, have some fun reading a tech mystery story on programming--a first of its kind. A nostalgic story from the early days of IBM PC when some programmers get together to play detective and h...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Freelance Newbie
      </h2> <p>by RealToughCandy</p> <p>
        Are you ready to jump-start your freelance web development career? Freelance Newbie has you covered! In this book, you’ll learn practical, actionable steps you can start using TODAY to get your first ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        14 Habits of Highly  Productive Developers
      </h2> <p>by Zeno Rocha</p> <p>
        You can learn the most popular frameworks, use the best programming languages, and work at the biggest tech companies, but if you cultivate bad habits, it will be hard for you to become a top develope...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Content for Developers
      </h2> <p>by Maedah Batool</p> <p>
        A whole new workflow to Write. Publish. Market. Authentic &amp; professional content writing meant for developers. Zero bull-shit and to-the-point tips to improve your technical content writing skills. Le...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        A Smart Guide for Your Career as a Software Engineer
      </h2> <p>by Mike Nikles</p> <p>
        I started my software engineer career 20 years ago. Since then, I have interviewed hundreds of candidates and reviewed even more resumes. This book is a guide for your own career, whether you are new ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Outstanding Developer
      </h2> <p>by Sebastien Castiel</p> <p>
        Being a developer is not only about writing code. And improving as a developer is not only about improving in writing code. This book explores how to become an outstanding developer through several ax...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        5 Little Potions
      </h2> <p>by Mark Wilbur</p> <p>
        In 5 Little Potions, you'll begin your journey into Elixir programming by creating increasingly complex games.

You'll start with a simple guessing game. Next you'll work with Elixir Structs in a boar...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Distributed Systems with Node.js
      </h2> <p>by Thomas Hunter II</p> <p>
        In this hands-on guide, author Thomas Hunter II proves that Node.js is just as capable as traditional enterprise platforms for building services that are observable, scalable, and resilient. Intermedi...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Data Analysis with Rust Notebooks
      </h2> <p>by Dr. Shahin Rostami</p> <p>
        A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.

- All code examples in Rust,
- Rust (Jupyter) Notebooks for each Section,
...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Python re(gex)?
      </h2> <p>by Sundeep Agarwal</p> <p>
        This book will help you learn Python Regular Expressions, a mini-programming language for all sorts of text processing needs.

The book heavily leans on examples to present features of regular express...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to React
      </h2> <p>by Robin Wieruch</p> <p>
        In "The Road to React" you will learn about all the fundamentals of React.js with Hooks while building a full-blown React application step by step. While you create the React application, every chapte...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        Cloud Native Web Development
      </h2> <p>by Mike Nikles</p> <p>
        In this book, we will walk through the end-to-end process of developing a cloud-native web application. You will learn technologies, processes, tips &amp; tricks and gain hands-on experience. You will fin...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Road to Firebase
      </h2> <p>by Robin Wieruch</p> <p>
        The Road to React with Firebase is your personal journey to master advanced React for business web applications in JavaScript whereas Firebase is used to replace everything that you would want from a ...

        <span>more</span></p></div>  </div></div><div xs="12"><div> <div><h2>
        The Standout Developer
      </h2> <p>by Randall Kanna</p> <p>
        If you’re tired of the endless job search and feeling like your resume isn’t being seen, this book will help you craft a great resume that stands out and get it seen by the companies you want. I’ll sh...

 …</p></div></div></div></div></div></div></div></div></div></div></div></main></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thesmartcoder.dev/books/">https://thesmartcoder.dev/books/</a></em></p>]]>
            </description>
            <link>https://thesmartcoder.dev/books/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25698707</guid>
            <pubDate>Sat, 09 Jan 2021 08:43:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over: Board – Raspberry Pi CM4 ITX Motherboard]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25697993">thread link</a>) | @todsacerdoti
<br/>
January 8, 2021 | https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/ | <a href="https://web.archive.org/web/*/https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3401">

	

	<div>
		
<p>The Over:Board is an IO board for the Raspberry Pi Compute Module 4. It is designed to use a standard PC ATX power connector and features a full size PCI-E 16x slot although its only running at 1x bandwidth and unfortunately it is not compatible with a GPU.   <br></p>



<figure><img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201%201'%3E%3C/svg%3E" data-src="https://c0.iggcdn.com/indiegogo-media-prod-cld/image/upload/c_fill,w_762,g_center,q_auto:best,dpr_1.6,f_auto,h_506/fjlirebv3qpqd7xdlsek" alt="The Over:Board" data-old-src="https://c0.iggcdn.com/indiegogo-media-prod-cld/image/upload/c_fill,w_762,g_center,q_auto:best,dpr_1.6,f_auto,h_506/fjlirebv3qpqd7xdlsek" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The Over:Board</figcaption></figure>



<p><br>It breaks out the following ports: <br></p>



<ul><li>24-pin ATX Power</li><li>40-pin GPIO</li><li>Full Size PCI-E @ 1x bandwidth</li><li>SATA Controller (Powered by USB)</li><li>Front Panel Header</li><li>CPU Fan Header</li><li>UART Header</li><li>Micro USB</li><li>RS232 Com Port</li><li>2x USB 2.0 Ports</li><li>Micro SD card slot</li><li>3.5mm Audio</li></ul>



<p>The Over:Board costs £199 for an early prototype or £99 for the Final Production board and is available to back now on indiegogo. <br></p>



<div><p>Whilst £99 is expensive for a IO board this is likely down to the limited production and it is likely still the cheapest ARM based ITX motherboard on the market even when factoring in the cost of a RPI CM4. </p><p>You can back the Over:Board on indiegogo <a rel="noreferrer noopener" href="https://www.indiegogo.com/projects/over-board-raspberry-pi-4-mini-itx-motherboard#/" target="_blank">here</a></p><p>For another ARM IO board with SATA check out my Nano Pi Neo2 NAS review <a rel="noreferrer noopener" href="https://blog.jmdawson.co.uk/nano-pi-neo2-nas-enclosure-a-small-linux-home-server-nas/" target="_blank">here</a></p><p>The project currently has £1654 in backing from 11 backers. With 28 days left it is looking likely to hit its £5000 target. </p><p>Ross Nicoholls is leading the campaign: </p></div>



<blockquote><p>I’ve lost count exactly how many, but this will be about my 35th commercial electronics PCB to be manufactured, so I am no stranger to getting these things to market. That said however, this will be the first of my own venture so represents my most exciting project to date and something I feel very passionate about.</p><cite>Ross has lots of experience in this field</cite></blockquote>



<p>I wish Ross good luck and hope to see the Over:Board available soon! </p>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>https://blog.jmdawson.co.uk/overboard-raspberry-pi-cm4-itx-motherboard/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25697993</guid>
            <pubDate>Sat, 09 Jan 2021 06:31:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer vaccine appears effective against mutation in new coronavirus variants]]>
            </title>
            <description>
<![CDATA[
Score 629 | Comments 227 (<a href="https://news.ycombinator.com/item?id=25696577">thread link</a>) | @awnird
<br/>
January 8, 2021 | https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5852149.1608672062!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/covid-vaccinations-toronto.jpg"></p></div><figcaption>A nurse prepares a dose of the Pfizer-BioNTech COVID-19 vaccine for care home workers at St. Michael’s Hospital in Toronto on Dec. 22, 2020.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p>  <p>The study by Pfizer and scientists from the University of Texas Medical Branch, which has not yet been peer-reviewed, indicated the vaccine was effective in neutralizing virus with the so-called N501Y mutation of the spike protein.</p>  <p>The mutation could be responsible for greater transmissibility and there had been concern it could also make the virus escape antibody neutralization elicited by the vaccine, said Phil Dormitzer, one of Pfizer's top viral vaccine scientists.</p>  <p>The first results of tests on the variants offer a glimmer of hope while more studies are carried out as Britain and other countries try to tame the more infectious variants that&nbsp;authorities believe are driving a surge in infections that could overwhelm health-care systems.</p>  <p>The Pfizer-BioNTech study was conducted on blood taken from people who had been given the vaccine. Its findings are limited because it does not look at the full set of mutations found in either of the new variants of the rapidly spreading virus.</p>  <p>Dormitzer said it was encouraging that the vaccine appears effective against the mutation, as well as 15 other mutations the company has previously tested against.</p>  <p>"So we've now tested 16 different mutations, and none of them have really had any significant impact. That's the good news," he said. "That doesn't mean that the 17th won't."</p>  <p><em><strong>WATCH | What scientists know about the new coronavirus variant:</strong></em></p>  <p><span><span><div><div title="What scientists know about the new coronavirus variant" role="button" tabindex="0"><div><div aria-labelledby="1842141251676-metadata-" title="What scientists know about the new coronavirus variant"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/643/819/COVID-VARIANT-SCI-BIRAK-080121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>The B1-17 coronavirus variant, first discovered in the U.K., is now in at least 40 countries, including Canada. It has 23 mutations, including one that attaches to healthy cells like a key going into a lock.<!-- --> <!-- -->1:56</span></span></span></p>  <p>Dormitzer said another mutation found in the South African variant, called the E484K mutation, was also concerning.</p>  <p>The researchers plan to run similar tests to establish whether the vaccine is effective against other mutations found in the British and South African variants and hope to have more data within weeks.</p>  <p>The variants are said by scientists to be more transmissible than previously dominant ones, but they are not thought to cause more serious illness.</p>  <p>The virus's spikes act as a key that must unlock our cells to cause the infection.&nbsp;The variant first identified in the U.K. has a mutation that appears to make it easier for the coronavirus to grab hold of the lock more tightly, scientists say.</p>    <p>Scientists said the results of the study would help calm concerns that people will not be protected by vaccines being given to millions of people around the world in the fight against the pandemic, which has killed more than 1.8 million people and roiled economies.</p>  <p>But they cautioned that more clinical tests and data are still needed to come to a definitive conclusion.</p>  <p>"This is good news, mainly because it is not bad news," said Stephen Evans, professor of pharmacoepidemiology at the&nbsp;London School of Hygiene &amp; Tropical Medicine.</p>  <p>"So, yes this is good news, but it does not yet give us total confidence that the Pfizer (or other) vaccines will definitely give protection."</p>  <h2>AstraZeneca, Moderna, CureVac testing against variants</h2>  <p>AstraZeneca, Moderna and CureVac are also testing whether their shots work against the fast-spreading variants. They have said they expect them to be effective, but the timing of those studies is not known.</p>  <p>A senior British lawmaker expressed concerns in an interview on Friday that COVID-19 vaccines might not work properly against the South African variant. He was not responding to questions about Friday's data.</p>  <p>The Pfizer-BioNTech vaccine and the one from Moderna Inc., which use synthetic messenger RNA technology, can be quickly tweaked to address new mutations of a virus if necessary. Scientists have suggested the changes could be made in as little as six weeks.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-new-variants.jpg 300w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-new-variants.jpg 460w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-new-variants.jpg 620w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg 780w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-new-variants.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg"></p></div><figcaption>Graphic shows a diagram of the COVID-19 virus.<!-- --> <!-- -->(AP)</figcaption></figure></span></p>  <p>Some other vaccines to protect against COVID-19 also use the spike protein to show our immune system what the enemy looks like.</p>  <p>Canadian microbiologist Benjamin tenOever, a professor at the&nbsp;Icahn School of Medicine at Mount Sinai in New York,&nbsp;said our immune system learns to recognize and attack the viral attachment protein at many different sites.</p>  <p>"It would require many many mutations to render our vaccines non-effective,"&nbsp;tenOever&nbsp;said.</p>  <p>The variant is also not the first of the pandemic to emerge and Eleanor Riley, professor of immunology and infectious disease at the University of Edinburgh, said these types of studies&nbsp;will be needed as they appear.</p>  <p>"It may be necessary to tweak the vaccine over time," she said.</p>  <p>Dr. Theresa Tam, Canada's chief public health officer, said Friday that 14 cases of the variant first reported in the U.K. have been reported in Canada.</p>  <p>Researchers in Ontario have developed a faster test to identify variants.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696577</guid>
            <pubDate>Sat, 09 Jan 2021 03:48:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an iRacing SDK Implementation in F#]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25696493">thread link</a>) | @sanesmith
<br/>
January 8, 2021 | https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>In my <a href="https://markjames.dev/2021-01-04-why-learning-fsharp-2021/">previous post</a>, I discussed how I’ve decided to learn F# in 2021 for a number of reasons. Around the same time, I also happened to setup my Sim Racing rig so that I could continue to play <a href="https://www.iracing.com/" target="_blank">iRacing</a> with my VR headset (HTC Vive). Its been several years since I’ve last played, but with COVID-related curfews being implemented here in Montreal tomorrow, I’ve been increasingly taking up home-based pursuits which I didn’t always have the time for pre-lockdown. Since the last time I played iRacing, I’m running a PC with a much better processor, motherboard, and only SSDs. The VR performance has been a huge leap forward since I used to play with my old machine and I was quite impressed. After spending a couple of hours setting up, here’s what my current humble racing setup looks like:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/racing-rig.jpg" width="650" height="488" alt="Photo of my current iRacing VR setup"></p>

<p>Having a dedicated table really helps, as in my old apartment it was fairly difficult to setup a station with limited space, but now I can fortunately just jump in. Despite the past limitations, I was able to get fairly competitive and still remember the thrill of my first win agaisnt a field of real racers in a Mazda MX-5:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/iracing-win.jpg" width="500" height="279" alt="Photo of my iRacing first win certificate"></p>

<p>Inspired by setting everything up and doing some laps to practice for an eventual return to comeptition, I started thinking about how I once experimented with using the <a href="https://github.com/kutu/pyirsdk" target="_blank">Python implementation</a> of the iRacing SDK to connect to an arduino and display a speedometer readout in realtime on a small screen. In reminiscing about the experience, I thought about how I could look into writing an F# implementation of the SDK as a learning project. In addition to learning through the project, it also has the benefit of being of use in a future project involving an iRacing stats tracker web app that I’ve been thinking about writing as a project for my upcoming <a href="https://markjames.dev/2020-12-09-back-to-school/">cloud computing courses</a>.</p>

<h2 id="getting-started">Getting Started</h2>

<p>I tend to learn best when projects are slightly outside of my comfort zone, and this would be both my first time writing a library, as well as writing one in a functional language! Having used an array of libraries at this point, I had some confidence in choosing an organizational structure, and the Python implementation is only <a href="https://github.com/kutu/pyirsdk/blob/master/irsdk.py" target="_blank">739 lines of code</a> which felt doable compared to some of the larger libraries out there.</p>

<p>Moreover, the python implementation of the SDK has the ability to:</p>

<ul>
  <li>Get session data (WeekendInfo, SessionInfo, etc…)</li>
  <li>Get live telemetry data (Speed, FuelLevel, etc…)</li>
  <li>Broadcast messages (camera, replay, chat, pit and telemetry commands)</li>
</ul>

<p>and I figured that this would be a good featureset to aim for in the final version of the F# SDK. Out of these features, the session data and live telemetry data would be the ones I plan to implement first.</p>

<h2 id="creating-the-library">Creating the Library</h2>

<p>After coming up with some desired features, the first step was to create a new FSharp solution called iRacingFSharp. Inside the solution, I created two projects. One was our actual library, called iRacingFSharp, and the other was a basic console app called SDKReader (located in the Examples Folder) to test the functionality of the library as I worked on it. Note, if you’d like to see the full codebase you can <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">here on github</a>.</p>

<h2 id="the-first-function">The First Function</h2>

<p>Starting small, I decided that a good first function would be to find out the state of the simulator. Fortunately, the iRacing SDK allows you to check if the sim is running using the following URL which points to a localhost server:</p>

<div><div><pre><code>http://127.0.0.1:32034/get_sim_status?object=simStatus
</code></pre></div></div>
<p>Getting this URL in Postman returns a JSON object which looks like this:</p>

<div><div><pre><code>var simStatus={
   running:0 // 1 if the sim is running
};
</code></pre></div></div>

<p>I decided to make use of the <a href="https://fsharp.github.io/FSharp.Data/library/Http.html" target="_blank">F# Data HTTP library</a> in order to download the response and so I installed it from NuGet at this point.</p>

<p>Next, inside my iRacingFSharp project I created a file called Irsdk.fs and wrote the following code:</p>

<div><div><pre><code><span>namespace</span> <span>IrsdkFS</span>

<span>open</span> <span>FSharp</span><span>.</span><span>Data</span>

<span>///&lt;summary&gt;F# implementation of the iRacing SDK.&lt;/summary&gt;</span>
<span>module</span> <span>IrsdkFS</span> <span>=</span>

    <span>///&lt;summary&gt;Returns the simStatus in string format&lt;/summary&gt;</span>
    <span>let</span> <span>SimStatus</span><span>()</span> <span>=</span>
        <span>let</span> <span>simStatusURL</span> <span>=</span> <span>"http://127.0.0.1:32034/get_sim_status?object=simStatus"</span>
        <span>let</span> <span>simStatusObject</span> <span>=</span> <span>Http</span><span>.</span><span>RequestString</span><span>(</span><span>simStatusURL</span><span>)</span>
        <span>simStatusObject</span>
</code></pre></div></div>

<p>In the above code, I’ve created a module which contains a function called SimStatus that takes no parameters. It then binds the JSON response to simStatusURL and passes it to the HTTP library via Http.RequestString(). Finally, simStatusObject is returned in string format which can be parsed further by another function in a later step.</p>



<p>With this simple function in place, the next step was to create SDKReader.fs inside my SDKReader console app. This file contained code to call the SimStatus() function and print the output:</p>

<div><div><pre><code><span>[&lt;</span><span>EntryPoint</span><span>&gt;]</span>
<span>let</span> <span>main</span> <span>argv</span> <span>=</span>
    <span>let</span> <span>test</span> <span>=</span> <span>IrsdkFS</span><span>.</span><span>SimStatus</span><span>()</span>
    <span>printf</span> <span>"%s"</span> <span>test</span>
    <span>0</span> <span>// return an integer exit code</span>
</code></pre></div></div>

<p>Running dotnet build inside the SDKReader folder displayed the following output while iRacing was running:</p>

<div><div><pre><code><span>"var simStatus={
   running:1
};
"</span><span>
</span></code></pre></div></div>

<p>Success! With this method working, we now have the very beginnings of an F# implementation of the iRacing SDK! Although it is a small step, we were also able to create and structure the project. Lastly, I also setup a a basic .NET build through Github Actions for CI.</p>



<p>iRacing’s API telemetry comes in three variations; data written to a .ibt file 60 times a second, live data exposed to the telemetry API 60 times per second, and a session string in YAML format that contains more or less static information about the session. The YAML string is appended to the end of the .ibt file but only a small portion of that data is exposed. This means that going forward, I’ll need to look into parsing the YAML as well as mapping more of the API endpoints. The iRacing API appears to be nonstandard and so it may take a little more work than just a typical REST API.</p>

<p>Stay tuned for Part Two where I plan to implement some telemetry functions and look into parsing the aforementioned YAML. In addition, be sure to follow along with the <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">Github Repo here</a> if you’re interested in seeing how to project progresses (or would like to contribute)!</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696493</guid>
            <pubDate>Sat, 09 Jan 2021 03:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ad-Tech Is a Bezzle]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25695482">thread link</a>) | @freediver
<br/>
January 8, 2021 | https://pluralistic.net/2021/01/04/how-to-truth/#adfraud | <a href="https://web.archive.org/web/*/https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1719">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
reviews, damon knight, science fiction, statistics, statistical literacy, gift guide,books, uk, dsa, democratic socialists of america, elections, california, ads, at-tech, fraud, google, labor, unions, alphabet, alphabet workers union, cwa,

Summary:
Ad-tech is a bezzle; Google's unionizing; The Data Detective; Damon Knight's Why Do Birds is back; Endorsing the Forward 43 slate

URL:
https://pluralistic.net/2021/01/04/how-to-truth/

Title:
Pluralistic: 04 Jan 2021

Bullet:
🎬

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Ken Snider (https://twitter.com/orenwolf), Slashdot (https://slashdot.org/), Margo Rowder (https://twitter.com/margorowder).

--><br>
<a href="https://pluralistic.net/2021/01/04/how-to-truth/"><img src="https://i0.wp.com/craphound.com/images/04Jan2021.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/04Jan2021.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">Ad-tech is a bezzle</a>: The subprime attention crisis is upon us.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#awu">Google's unionizing</a>: Solidarity vs worker misclassification.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#harford">The Data Detective</a>: How to truth with statistics.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#an-oval">Damon Knight's Why Do Birds is back</a>: Reviving a grand master's comic masterpiece.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#fwd-43">Endorsing the Forward 43 slate</a>: For my California comrades.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#retro">This day in history</a>: 2016
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2021/01/04/how-to-truth/#bragsheet">Colophon</a>: Recent publications, upcoming/recent appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="adfraud"></a><br>
<img src="https://i1.wp.com/craphound.com/images/ad-3242595_960_720.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/ad-3242595_960_720.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>There are lots of problems with ad-tech:</p>
<ul>
<li>being spied on all the time means that the people of the 21st century are less able to be their authentic selves;
</li>
<li>
<p>any data that is collected and retained will eventually breach, creating untold harms;</p>
</li>
<li>
<p>data-collection enables for discriminatory business practices ("digital redlining");</p>
</li>
<li>
<p>the huge, tangled hairball of adtech companies siphons lots (maybe even most) of the money that should go creators and media orgs; and</p>
</li>
<li>
<p>anti-adblock demands browsers and devices that thwart their owners' wishes, a capability that can be exploited for even more nefarious purposes;</p>
</li>
</ul>
<p>That's all terrible, but it's also <em>ironic</em>, since it appears that, in addition to everything else, ad-tech is a fraud, a bezzle.</p>
<p>Bezzle was John Kenneth Galbraith's term for "the magic interval when a confidence trickster knows he has the money he has appropriated but the victim does not yet understand that he has lost it." That is, a rotten log that has yet to be turned over.</p>
<p>Bezzles unwind slowly, then all at once. We've had some important peeks under ad-tech's rotten log, and they're increasing in both intensity and velocity. If you follow Aram Zucker-Scharff, you've had a front-row seat to the fraud.</p>
<p><a href="https://twitter.com/Chronotope/status/1078003966863200256">https://twitter.com/Chronotope/status/1078003966863200256</a></p>
<p>Time and again, everything in the ad-tech stack has been demonstrated to be fraudulent: fake audiences firing fake clicks at fake videos on fake sites that suck real dollars out of advertisers' accounts.</p>
<p>This was masterfully elucidated in Tim Hwang's short 2020 book SUBPRIME ATTENTION CRISIS, whose thesis is: we must deflate the ad-tech bubble intentionally, lest we get a messy rupture that destroys many of the good things the parasite has colonized.</p>
<p><a href="https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost">https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost</a></p>
<p>The ad-tech fraud is many-layered. On the surface, there's the counting frauds: fake clicks, fake sites, fake videos, etc. But there's a deeper fraud, a theory fraud, the fraud that with enough surveillance data and machine learning, ad-tech can sell anyone anything.</p>
<p>That is: even if we count accurately, ads are still overvalued and underperforming. This is also a lesson whose examples are coming with increasing tempo, as when Ebay simply stopped buying Google search ads and saw <em>no</em> decrease in sales.</p>
<p><a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</a></p>
<p>In a piece for Forbes, marketer-turned-antifraud-auditor Dr Augustine Fou rounds up some of the grossest things festering under the ad-tech log.</p>
<p><a href="https://www.forbes.com/sites/augustinefou/2021/01/02/when-big-brands-stopped-spending-on-digital-ads-nothing-happened-why/?sh=5a4f9c9a1166">https://www.forbes.com/sites/augustinefou/2021/01/02/when-big-brands-stopped-spending-on-digital-ads-nothing-happened-why/?sh=5a4f9c9a1166</a></p>
<p>Like that time in 2018 when Procter and Gamble – inventors of "brand marketing" – turned off $200m worth of ad-tech buys and saw no change to their sales. Or when Chase killed 95% of its advertising and kept all of its business.</p>
<p>Most interesting is the tale of how Uber allowed itself to be defrauded of $150m/year, for years, by ad-tech intermediaries. It's a story told in detail by former Uber head of "performance marketing" Kevin Frisch on the Marketing Today podcast:</p>
<p><a href="https://www.marketingtodaypodcast.com/194-historic-ad-fraud-at-uber-with-kevin-frisch/">https://www.marketingtodaypodcast.com/194-historic-ad-fraud-at-uber-with-kevin-frisch/</a></p>
<p>It starts with the revelation that $50m of its annual spend on customer acquisitions – money paid when an ad leads to a new Uber customer downloading the app, entering payment details and taking their first ride – was fraudulent.</p>
<p>Here's how that worked: scummy marketers fielded low-quality apps (like battery monitors) that requested root access. These apps spied on every app you installed. If you installed Uber, they "fired a click" to the system to report you as having been "converted" by an ad.</p>
<p>After clearing $50m of fraud, Frisch continued to dig into the system. In the end, about $120m of the $150m was being stolen, pocketed for fake clicks on fake sites by fake users.</p>
<p>In a fascinating turn, Frisch describes how his colleagues were indifferent or actively hostile to his efforts. Uber was in "growth mode," trying to beef up its numbers prior to the IPO where suckers would relieve its Saudi royal investors.</p>
<p>Uber is a company that will never, ever be profitable. It, too, is a bezzle. It only "works" if outside investors – marks – can somehow be convinced to buy the insiders' stock, which requires the appearance of growth – AKA "A pile of shit this big <em>must</em> have a pony under it!"</p>
<p>So execs like Frisch were required to "spend to budget" – to maintain the appearance of growth, including (especially) the growth of its "precision analytics" marketing, where ad-tech spends turned into directly attributable customer acquisitions.</p>
<p>This is the story that keeps on giving, because it all starts with Sleeping Giant's campaign to force Uber to stop advertising on Breitbart, and Uber's inability to get its ad-tech "partners" to definitively switch off Breitbart ads.</p>
<p><a href="https://twitter.com/nandoodles/status/1345774768746852353">https://twitter.com/nandoodles/status/1345774768746852353</a></p>
<p>The system's layers of misdirection – there to hide the fraud – meant that it behaved nondeterministically and couldn't fulfil simple requests, which triggered the search.</p>
<p>There's a theory that the reason Big Tech spies on us so much is that they're really good at turning data into sales (and, by extension, influence, as in elections, referenda, etc). But it is increasingly apparent that Big Tech's spying is part of a bezzle.</p>
<p>That is, we're being surveilled, doxed, placed under automated suspicion and digitally discriminated against all to put on a show that separates marks from their dollars.</p>
<p>This is the theme of my 2020 book HOW TO DESTROY SURVEILLANCE CAPITALISM:</p>
<p><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
<p>Namely, that we are under constant surveillane because monopolies can get away with obviously fraudulent and dangerous conduct by mobilizing their monopoly profits to buy political outcomes that serve their ends.</p>
<p>This is also what happened with California's Proposition 22, the most expensive ballot initiative in US history: Uber didn't spearhead a $200m campaign to legalize worker misclassification to become profitable.</p>
<p>Uber will never be profitable.</p>
<p>All that money was spent to maintain the fiction, the fraud, the bezzle – it was an appeal to rescue the wholly fictional pony underneath that gigantic pile of shit.</p>
<hr>
<p><a name="awu"></a><br>
<img src="https://i1.wp.com/craphound.com/images/Homestead_Strike_-_Mob_attacking_Pinkerton_men-1-1-9.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/Homestead_Strike_-_Mob_attacking_Pinkerton_men-1-1-9.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Google workers have announced their intention to form a union, under the auspices of CWA Local 1440. The union is called The Alphabet Workers Union (Google maintains the legal and accounting fiction that it is a division of a holding company called "Alphabet").</p>
<p>Speaking of legal fictions, the union is opening membership to "TVCs" – temps, vendors and contractors – employees who have been deliberately misclassified so as to avoid paying them benefits or extending normal workplace protections to them.</p>
<p>It's a bold move, a countermeasure to thwart the other commercial advantage from worker misclassification: by creating multiple categories of workers, bosses can pit employees against one another, by dangling privileges in front of one group but not the other.</p>
<p>But it comes at a high price: to gain official legal recognition, more than 50% of eligible workers must join the union. By including more workers, the union is setting a higher bar for official status.</p>
<p><a href="https://www.vice.com/en/article/3an5q9/google-workers-publicly-launch-union">https://www.vice.com/en/article/3an5q9/google-workers-publicly-launch-union</a></p>
<p>But the union has momentum: a series of high-profile googler uprisings – driven by official tolerance for sexual misconduct, complicity in US military drone programs, secret collaboration with Chinese surveillance and censorship, and more – show how radicalized googlers are.</p>
<p>Google's management – who cultivated an air of participatory, cuddly collaboration – have arrived at a point where the contradictions between their "values" and the company's profits can no longer be reconciled.</p>
<p>In Dec 2020, Google fired Timnit Gebru, an eminent Black AI scientist who refused to retract a paper critical of its profitable Big Data research. Management compounded their sins by making false claims about Gebru's dismissal.</p>
<p>The unionization drive is under the CWA's #CODE (Coalition to Organize Digital Employees) project. Though CODE is no stranger to conflict, Google represents a serious challenge, thanks to its partnership with notorious union-busters IRI Consultants.</p>
<p>(IRI's tactics pale in comparison to the mercenaries that Amazon has hired to bust its unions: the Pinkerton company, who have spilled rivers of workers' blood in their murderous history):</p>
<p><a href="https://www.vice.com/en/article/5dp3yn/amazon-leaked-reports-expose-spying-warehouse-workers-labor-union-environmental-groups-social-movements">https://www.vice.com/en/article/5dp3yn/amazon-leaked-reports-expose-spying-warehouse-workers-labor-union-environmental-groups-social-movements</a></p>
<p>For important context on the drive, check out Collective Action in Tech's article on the announcement, which explains why googlers have formed a "non-contract union" that does not yet have official recognition.</p>
<p><a href="https://collectiveaction.tech/2021/the-abcs-of-googles-new-union/">https://collectiveaction.tech/2021/the-abcs-of-googles-new-union/</a></p>
<p>"Non-contract unions embody the idea that worker power does not come from legal processes, but rather through building power through solidarity."</p>
<hr>
<p><a name="harford"></a><br>
<img src="https://i0.wp.com/craphound.com/images/data-detective.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/data-detective.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Publishing works on long schedules, which means that long-planned books can be overtaken by events…like covid.</p>
<p>2020 was tough for those of us with books in trail, especially nonfiction. But for a few lucky writers, covid imparted a terrible salience to their books.</p>
<p>One such writer is Tim Harford, host of BBC Radio 4's More or less, which is hands-down the greatest statistical literacy program in the world, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2021/01/04/how-to-truth/#adfraud">https://pluralistic.net/2021/01/04/how-to-truth/#adfraud</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2021/01/04/how-to-truth/#adfraud</link>
            <guid isPermaLink="false">hacker-news-small-sites-25695482</guid>
            <pubDate>Sat, 09 Jan 2021 02:19:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archive of 43k+ Donald Trump Twitter Screenshots]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25693054">thread link</a>) | @soheilpro
<br/>
January 8, 2021 | https://pikaso.me/blog/donald-trump-twitter-archive | <a href="https://web.archive.org/web/*/https://pikaso.me/blog/donald-trump-twitter-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>


    <section>
      <p>
        <h2>Donald Trump Twitter Screenshot Archive</h2>
      </p>
      
        
      

      <div><p>Donald Trump loves to tweet and everyone knows that.
Twitter is his favorite medium to express his ideas and to communicate with the world.
He has been an active Twitter user since 2009. Much longer than many other world leaders.</p>
<p>Last month (May 2020) he tweeted 845 times â€” that's 28 tweets per day on average!</p>
<center>
  <a href="https://twitter.com/realDonaldTrump/status/491324429184823296"><img src="https://pikaso.me/blog/files/pikaso.me-realDonaldTrump-20140721_205046-491324429184823296.png" alt="Trump Tweet" width="500" height="244"></a>
</center>
<p>A while ago we received a request from one of our users who was looking for a way to screenshot all Donald Trump tweets.
We realized that's a good opportunity to put <a href="https://pikaso.me/">Pikaso</a> into test and see if it can perform such a task without any problems.
It went smoothly and there was only an issue with one of his tweets which included a deleted image.</p>
<p>Today, we are releasing the resulting files to the public.
This archive contains screenshots of 43,475 Donald Trump tweets from May 2009 to May 2020.
Whether you are pro- or anti- Trump, this is an important part of Internet history that we believe should be preserved.</p>
<h3 id="download">Download</h3>
<p>The Donald Trump Twitter Screenshot Archive can be downloaded through the following links:</p>
<ul>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.zip">trump_twitter_archive_v1.zip</a> (Direct download, 2.6 GB)</li>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.torrent">trump_twitter_archive_v1.torrent</a> (Torrent download, 28.2 KB)</li>
</ul>
<h3 id="howthiswasmade">How This Was Made?</h3>
<p>To create this archive, we first extracted all tweet ids from the realDonaldTrump.csv file that was provided to us.
That file only contained Donald Trump tweets up to March 29, 2020. To get the later tweets, we used <a href="http://trumptwitterarchive.com/">trumptwitterarchive.com</a>.</p>
<p>We then used the <a href="https://pikaso.me/api">Pikaso API</a> to screenshot each individual tweet.</p>
<h3 id="updates">Updates</h3>
<p>We have no plans to keep this archive up to date after the initial release.
However, if you are interested in doing so, you can use <a href="https://pikaso.me/">Pikaso</a>.
You can even <a href="https://pikaso.me/automate">automate</a> it so that each time he tweets, an automatic screenshot is taken.</p>
<h3 id="credit">Credit</h3>
<p>All the tweets are copyright https://twitter.com/realdonaldtrump.<br>
All the media embedded in tweets are copyright their respective owners.<br>
Original tweets data provided by <a href="https://twitter.com/twentysox">@twentysox</a>.</p>
<h3 id="copyrightlicense">Copyright &amp; License</h3>
<p>Copyright © 2020 https://pikaso.me.<br>
This work by https://pikaso.me is licensed under <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a>.</p>
<h3 id="contact">Contact</h3>
<p>If you have any feedback or questions regarding this work, please <a href="https://pikaso.me/contact">contact us</a>.</p></div>
    </section>

    

    
      <section>
        <h2>More from the Blog</h2>

        
      </section>
    

      </div>
  
</div></div>]]>
            </description>
            <link>https://pikaso.me/blog/donald-trump-twitter-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-25693054</guid>
            <pubDate>Sat, 09 Jan 2021 00:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Semantic Web, Syllogism, and Worldview (2003)]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25691623">thread link</a>) | @cratermoon
<br/>
January 8, 2021 | https://www.karmak.org/archive/2004/06/semantic_syllogism.html | <a href="https://web.archive.org/web/*/https://www.karmak.org/archive/2004/06/semantic_syllogism.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.karmak.org/archive/2004/06/semantic_syllogism.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691623</guid>
            <pubDate>Fri, 08 Jan 2021 22:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[States with private prisons put more people in prison for longer]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25690796">thread link</a>) | @mike_h
<br/>
January 8, 2021 | https://academictimes.com/states-with-private-prisons-put-more-people-in-prison-for-longer/ | <a href="https://web.archive.org/web/*/https://academictimes.com/states-with-private-prisons-put-more-people-in-prison-for-longer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="articleBody"><p dir="ltr">U.S. states that rely on private prisons incarcerate more people for longer periods of time, according to a first-of-its-kind study that establishes a causal connection between private prisons and incarceration.Â&nbsp;</p><p dir="ltr">The <a href="https://www.sciencedirect.com/science/article/abs/pii/S0927537120301123">paper</a>, published in the December issue of <em>Labour Economics</em>, adds to researchersâ€™ understanding of financial incentives in the criminal justice system, according to authors Gregmar Galinato and Ryne Rohla, both economists at Washington State University.</p><p dir="ltr">The researchers found that states that opened private prisons saw a 4% jump in prison population, or an average of between 6 and 37 extra prisoners per million residents, based on a review of data from 1989 to 2008. Incarcerating those extra people cost states an extra $1.9 million to $10.6 million per year if all additional prisoners were housed in private prisons.</p><p dir="ltr">Galinato and Rohla found that the growth in prison population experienced by states with private prisons was caused by an increase in the number of people being sent to prison, as well as judges handing down longer sentences for particular crimes.Â&nbsp;</p><p dir="ltr">Specifically, a 1% increase in private prison beds per capita will increase sentencing lengths for regulatory offenses by 29 days, weapons offenses by 13 days, drug offenses by 7 days and fraud offenses by 2 days, the researchers found.Â&nbsp;</p><p dir="ltr">However, those figures might underestimate the actual amount of time incarcerated people spend in private prisons, the researchers added, pointing to a 2019 <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2523238">paper</a> by Wisconsin School of Business professor Anita Mukherjee that found that private prison inmates in Mississippi served a full three months longer than people convicted of the same crimes who were sent to public prisons. Mukherjee attributed the lengthier time served to the fact that conduct violations, which can tack extra time onto prisonersâ€™ sentences, are more common in private prisons than in public ones.Â&nbsp;</p><p dir="ltr">While Galinato and Rohla found that people convicted of weapons and drug offenses saw harsher sentences in states with more private prison beds, sentencing for other crimes such as murder did not change.Â&nbsp;</p><p dir="ltr">â€œThat was a good marker for us, because that showed that this wasnâ€™t random noise going on or some correlation,â€� said Galinato of the fact that only some crimes saw a sentencing difference.Â&nbsp;</p><p dir="ltr">In order to establish a causal relationship, the researchers created an instrument called â€œprivatization knowledgeâ€� that indicated academic support for privatization by state from 1989 to 2008. That instrument, which was partially based on the use of words like â€œneoliberalismâ€� in academic journals, corresponded only to the proliferation of private prisons -- not the incarceration rate, the researchers said. Â&nbsp;</p><p dir="ltr">Galinato said that finding an instrument to establish causality was one of the most difficult parts of the project, as the connection between private prisons and incarceration can be self-perpetuating. Developing and using the â€œprivatization knowledgeâ€� instrument took years.Â&nbsp;</p><p dir="ltr">Galinato came up with the idea in 2015, and Rohla began compiling data shortly thereafter. It took about one year to get permission to use Department of Justice data, he said.Â&nbsp;</p><p dir="ltr">In addition to establishing a causal relationship between private prisons and incarceration, Galinato and Rohla also examined two factors that could lead authorities to hand down more and harsher sentences in the first place.Â&nbsp;</p><p dir="ltr">Political corruption could lead politicians to enact stricter laws and cause judges to hand down harsher sentences, the researchers said, pointing to the 2008 â€œkids for cashâ€� <a href="https://nypost.com/2014/02/23/film-details-teens-struggles-in-state-detention-in-payoff-scandal/">scandal</a> in which Pennsylvania judges received kickbacks in exchange for giving juvenile offenders harsher prison sentences.Â&nbsp;</p><p dir="ltr">Judges may also consider prison capacity when sentencing people, Galinato added. â€œIf you have a crowded public system, the judge will say, â€˜OK, this is a marginal person, weâ€™ll probably put them on probation because we donâ€™t want to overcrowd the prison.â€™â€�Â&nbsp;</p><p dir="ltr">However, the researchers did not find a strong enough link to claim that either factor has definitively led to higher incarceration rates at private prisons.Â&nbsp;</p><p dir="ltr">â€œThe best we can say is thereâ€™s a hint,â€� said Galinato. â€œThere could be more mechanisms [affecting incarceration rates] out there.â€�Â&nbsp;</p><p dir="ltr">Rebecca Riddell, the co-director of New York University Law Schoolâ€™s Human Rights and Privatization Project, <a href="https://twitter.com/Rebecca_Riddell/status/1305884832153718785">praised</a> the study on Twitter.</p><p dir="ltr">â€œIt's appalling that private prisons increase incarceration levels,â€� said Riddell. â€œBut should we be surprised? Or is this a foreseeable outcome of creating a powerful industry that profits from every [additional] incarcerated person, takes in billions in taxpayer [dollars] and spends millions lobbying?â€�Â&nbsp;</p><p dir="ltr">Galinato told <em>The Academic TimesÂ&nbsp;</em>that the link between private prisons and incarceration must factor into government policy.Â&nbsp;</p><p dir="ltr">â€œThere is this potential link, and this link becomes more significant if thereâ€™s more corruption and you donâ€™t have oversight,â€� he said, adding that policymakers donâ€™t typically consider that choosing private prisons over public ones increases overall incarceration.Â&nbsp;</p><p dir="ltr">Galinato, who typically works as a natural resource and development economist, said he was inspired to conduct the study when watching an episode of the television show â€œElementary,â€� in which a prison warden murders an inmate in order to appease the owner of a private prison who wants to influence a lobby group.Â&nbsp;</p><p dir="ltr">The idea of private prison companies influencing governments to set harsher sentences initially â€œmade me laugh a little bit in terms of how ludicrous it was,â€� Galinato said.Â&nbsp;</p><p dir="ltr">â€œI wasnâ€™t really aware of private prisons in the U.S.,â€� he added. â€œI come from the Philippines. We don't have them.â€�Â&nbsp;</p><p dir="ltr">His experience studying corruption in relation to natural resources came in handy when examining the criminal justice system, he added.</p><p dir="ltr">In terms of further research, Galinato said he was interested in examining the relationship between private prisons and private halfway houses, which are often owned by the same companies. The owners of halfway houses can set house rules that, if violated, send residents back to prison. That could incentivize halfway houses to set overly harsh rules in order to make more money.Â&nbsp;</p><p dir="ltr">Galinato is also interested in examining private prisonsâ€™ incentive structures, which currently involve significant moral hazard. Private prisons are paid based on how many prisoners they house on a given day, potentially leading them to push for unjustly harsh punishments.Â&nbsp;</p><p dir="ltr">â€œThat kind of contract incentivizes more prisoners and increases the length of stay,â€� said Galinato. â€œWhat if the payment would be based on when they came out of jail and became a better member of society, then the private prison would get a bonus?â€�</p><p dir="ltr"><em>The paper, titled â€œDo privately-owned prisons increase incarceration rates?â€� was first published in the December issue of Labour Economics.Â&nbsp;</em><em>The authors were Gregmar Galinato of Washington State University and Ryne Rohla, who earned a PhD from Washington State University and now works for the Washington State Attorney General's Office. Galinato was lead author.Â&nbsp;</em></p></div></div></div>]]>
            </description>
            <link>https://academictimes.com/states-with-private-prisons-put-more-people-in-prison-for-longer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690796</guid>
            <pubDate>Fri, 08 Jan 2021 21:32:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby 3, Concurrency and the Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 235 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25690212">thread link</a>) | @ksec
<br/>
January 8, 2021 | https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/ | <a href="https://web.archive.org/web/*/https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>06 Jan 2021</span></p><p>With the <a href="http://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/" target="\_blank">Ruby 3.0 release</a>, there’s been a lot of chatter about concurrency, parallelism, and async IO.</p>

<p>For my own reflection, I wanted to write down what that means for performance and capacity/costs of apps, and what would be the impact on the Ruby ecosystem.</p>

<p>I will assume that the audience already knows the difference between <a href="https://en.wikipedia.org/wiki/Thread_(computing)#Threads_vs._processes_pros_and_cons" target="\_blank">threads vs processes model in UNIX</a> and the <a href="https://en.wikipedia.org/wiki/Little%27s_law" target="\_blank">Little’s law</a>.</p>

<p>
Updated on Jan 9, 2021: thanks to the feedback from <a href="https://github.com/ioquatix" target="_blank">Samuel Williams</a>, I’ve revised the post with findings from <a href="https://github.com/socketry/falcon" target="_blank">Falcon</a>, the async web server written in Ruby.</p>

<h2 id="learning-from-python">Learning from Python</h2>

<p>It’s always good to take learnings from other languages. There’s an excellent <a href="http://calpaterson.com/async-python-is-not-faster.html" target="\_blank">write-up “Async Python is not faster” by Cal Paterson</a>.</p>

<p>It argues that process-based (aka forking) web servers <strong>show better latencies for web requests</strong> when they are compared to async IO-powered servers.</p>

<p>But why? That’s because async IO brings co-operative scheduling, which means that the execution is only yielded upon language keywords like <code>await</code>.</p>

<p>Quoting the author, this means that execution time is not distributed “fairly” and one thread can inadvertently starve another of CPU time while it is working. This is why latency is more erratic.</p>

<blockquote>
  <p>In contrast, traditional sync webservers use the pre-emptive multi-processing of the kernel scheduler, which works to ensure fairness by periodically swapping processes out from execution. This means that time is divided more fairly and that latency variance is lower.</p>
</blockquote>

<h2 id="learning-from-falcon">Learning from Falcon</h2>

<p>
(added on Jan 9, 2021)
</p>

<p><a href="https://github.com/socketry/falcon">Falcon</a> is a multi-process, multi-fiber HTTP server written in Ruby that is already utilizing async IO.</p>

<p>It has a great <a href="https://github.com/socketry/falcon-benchmark">set of benchmarks</a> that let us compare Falcon’s async IO with other non-async web servers like Passenger, Puma and Unicorn. Those benchmarks have been showing that <strong>async IO-powered server like Falcon</strong> provides better latencies on web requests.</p>

<p>Interestingly, that’s a very different story than Python! Looking at Python, I’ve expected that the thread driven server should be more “balanced” but it turns out the opposite.</p>

<p>Falcon’s authors explain that the fiber scheduler naturally scales according to load much better than the worker pool implementation in Puma. When fibers are busy handling requests, they don’t call <code>accept</code> so the requests are naturally picked up by other workers who are less busy.</p>

<h3 id="what-does-that-mean-for-us-ruby-developers">What does that mean for us Ruby developers?</h3>

<p>Scheduling threads and fibers is nuanced, and you can see that similar approaches demonstrate different results on Python and Ruby/Falcon examples.</p>

<p>In the first revision of this post, I’ve argued that async IO may often increase the latency. Thanks to the data <a href="https://github.com/socketry/falcon-benchmark">shown</a> by Samuel Williams, we can see that’s not the case.</p>

<p>One of the benefits of async IO is that concurrency is archived by the <code>yield</code>/<code>await</code> instruction, not by the constant interrupt of threads. Every interrupt causes the context switch - and it’s nice to reduce context switching where we can because scheduler switching from one task to another always adds a little overhead. Since that happens thousands of times every second, <strong>less context switching would mean fewer CPU cycles wasted</strong>.</p>

<h2 id="where-does-ractor-fit-in">Where does Ractor fit in?</h2>

<p>The Ractor pattern allows parallel execution (which wasn’t possible in Ruby before) of more than one Ruby thread by limiting the shared state of a block of code that you want to execute in parallel. Those “blocks of code” (aka “actors”) can also talk to each other through messages. This is the <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a> used in other languages.</p>

<p>There are two ways we could leverage Ractors for modern apps: from the top (wrap every worker into a Ractor) and from the bottom (selectively use Ractors within existing code to parallelize CPU-intensive work).</p>

<p>While I see more to be gained from the top way, it seems like there’s so much shared and mutable state in Ruby libraries that it’s going to be quite tricky, although not impossible. It will likely take some efforts and at least a year of work from the community to push libraries towards less shared state. For the next year, we’ll mostly see Ractor maturing and getting adopted in the “bottom” use cases.</p>

<h2 id="impact-on-the-ruby-ecosystem">Impact on the Ruby ecosystem</h2>

<p><strong>By itself, async IO will help to use CPU more efficiently by reducing context switching.</strong></p>

<p>Better support for async IO in Ruby 3.0 will increase community’s adoption of async web servers like Falcon, and will hopefully give birth to async background job systems.</p>

<p>Having Sidekiq execute jobs concurrently through the async IO and event loop instead of threads could increase the throughput and save CPU work, especially for IO-bound workloads like webhook delivery.</p>

<p><strong>We’ll need to push the Ruby ecosystem to have less shared state to fully leverage the Ractor pattern.</strong> That will take us some time.</p>

<p>If you’ve enjoyed reading this, I highly recommend to read <em><a href="http://wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html" target="\_blank">Ruby 3.0 and the new FiberScheduler interface</a></em> by Wander Hillen.</p>

<p>Thanks to Samiel Williams and to Julik Tarkhanov for providing early feedback on this post.</p>

<p>I’m looking forward to hearing your thoughts on this in the comments!</p>

</div></div>]]>
            </description>
            <link>https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690212</guid>
            <pubDate>Fri, 08 Jan 2021 20:44:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smooth Voxel Terrain, Part 2 (2012)]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25690189">thread link</a>) | @fanf2
<br/>
January 8, 2021 | https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/ | <a href="https://web.archive.org/web/*/https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://0fps.wordpress.com/2012/07/10/smooth-voxel-terrain-part-1/">Last time</a> we formulated the problem of isosurface extraction and discussed some general approaches at a high level.&nbsp; Today, we’re going to get very specific and look at meshing in particular.</p>
<p>For the sake of concreteness, let us suppose that we have approximated our potential field <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f"> by sampling it onto a cubical grid at some fixed resolution.&nbsp; To get intermediate values, we’ll just interpolate between grid points using the standard <a href="http://paulbourke.net/miscellaneous/interpolation/">trilinear interpolation</a>.&nbsp; This is like a <img src="https://s0.wp.com/latex.php?latex=C%5E0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="C^0" title="C^0"> generalization of Minecraft-style voxel surfaces.&nbsp; Our goal in this article is to figure out how to extract a mesh of the implicit surface (or zero-crossings of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f">).&nbsp; In particular, we’re going to look at three different approaches to this problem:</p>
<h2>Marching Cubes</h2>
<p>By far the most famous method for extracting isosurfaces is the <a href="http://en.wikipedia.org/wiki/Marching_cubes">marching cubes</a> algorithm. &nbsp;In fact, it is so popular that the term `marching cubes’ is even more popular than the term `isosurface’ (at least according to Google)!&nbsp;&nbsp; It’s quite a feat when an algorithm becomes more popular than the problem which it solves!&nbsp; The history behind this method is very interesting.&nbsp; It was originally <a href="http://dl.acm.org/citation.cfm?id=37422">published back in SIGGRAPH 87</a>, and then summarily patented by the Lorensen and Cline. &nbsp;This fact has caused a lot of outrage, and is been widely cited as one of the classic examples of patents hampering innovation.&nbsp; Fortunately, the patent on marching cubes expired back in 2005 and so today you can freely use this algorithm in the US with no fear of litigation.</p>
<p>Much of the popularity of marching cubes today is due in no small part to a famous article written by <a href="http://paulbourke.net/">Paul Bourke</a>. &nbsp;Back in 1994 he made a webpage called <a href="http://paulbourke.net/geometry/polygonise/">“Polygonizing a Scalar Field”</a>, which presented a short, self-contained reference implementation of marching cubes (derived from some earlier work by Cory Gene Bloyd.)&nbsp; That tiny snippet of a C program is possibly <strong><em>the most copy-pasted code of&nbsp;<span>all time</span></em></strong>. &nbsp;I have seen some variation of Bloyd/Bourke’s code in <strong>every</strong> implementation of marching cubes that I’ve ever looked at, without exception.&nbsp; There are at least a couple of reasons for this:</p>
<ol>
<li>Paul Bourke’s exposition is really good. &nbsp;Even today, with many articles and tutorials written on the technique, none of them seem to explain it quite as well.&nbsp; (And I don’t have any delusions that I will do any better!)</li>
<li>Also their implementation is very small and fast. &nbsp;It uses some clever tricks like a precalculated edge table to speed up vertex generation.&nbsp; It is difficult to think of any non-trivial way to improve upon it.</li>
<li>Finally, marching cubes is incredibly difficult to code from scratch.</li>
</ol>
<p>This last point needs some explaining, &nbsp;Conceptually, marching cubes is rather simple. &nbsp;What it does is sample the implicit function along a grid, and then checks the sign of the potential function at each point (either +/-). &nbsp;Then, for every edge of the cube with a sign change, it finds the point where this edge intersects the volume and adds a vertex (this is just like ray casting a bunch of tiny little segments between each pair of grid points).&nbsp; The hard part is figuring out how to stitch some surface between these intersection points.&nbsp; Up to the position of the zero crossings, there are&nbsp;<img src="https://s0.wp.com/latex.php?latex=2%5E8+%3D+256&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^8 = 256" title="2^8 = 256"> different possibilities, each of which is determined by the sign of the function at the 8 vertices of the cube:</p>
<p><a href="http://en.wikipedia.org/wiki/File:MarchingCubes.svg"><img loading="lazy" data-attachment-id="561" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/marchingcubes/" data-orig-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png" data-orig-size="501,236" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="marchingcubes" data-image-description="<p>Some of the marching cubes special cases.  (c) WIkipedia, created by Jean-Marie Favreau.</p>
" data-medium-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=501" title="marchingcubes" alt="" src="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141" height="141" width="300" srcset="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141 300w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=150&amp;h=71 150w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png 501w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>Some of the marching cubes special cases. &nbsp;(c) Wikipedia, created by Jean-Marie Favreau.</p>
<p>Even worse, some of these cases are ambiguous!&nbsp; The only way to resolve this is to somewhat arbitrarily break the symmetry of the table based on a case-by-case analysis. What a mess!&nbsp; Fortunately, if you just download Bloyd/Bourke’s code, then you don’t have to worry about any of this and everything will just work. &nbsp;No wonder it gets used so much!</p>
<h2>Marching Tetrahedra</h2>
<p>Both the importance of isosurface extraction and the perceived shortcomings of marching cubes motivated the search for alternatives. &nbsp;One of the most popular was the <a href="http://search.ieice.org/bin/summary.php?id=e74-d_1_214">marching tetrahedra</a>, introduced by Doi and Koide.&nbsp; Besides the historical advantage that marching tetrahedra was not patented, it does have a few technical benefits:</p>
<ol>
<li>Marching tetrahedra does not have ambiguous topology, unlike marching cubes.&nbsp; As a result, surfaces produced by marching tetrahedra are always manifold.</li>
<li>The amount of geometry generated per tetrahedra is much smaller, which might make it more suitable for use in say a geometry shader.</li>
<li>Finally, marching tetrahedra has only <img src="https://s0.wp.com/latex.php?latex=2%5E4+%3D+16&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^4 = 16" title="2^4 = 16"> cases, a number which can be further reduced to just 3 special cases by symmetry considerations. &nbsp;This is enough that you can work them out by hand.</li>
</ol>
<p><strong>Exercise:&nbsp; </strong>Try working out the cases for marching tetrahedra yourself. &nbsp;(It is really not bad.)</p>
<p>The general idea behind marching tetrahedra is the same as marching cubes, only it uses a tetrahedral subdivision. &nbsp;Again, the standard reference for practical implementation is Paul Bourke (<a href="http://local.wasp.uwa.edu.au/~pbourke/geometry/polygonise/">same page as before</a>, just scroll down a bit.) &nbsp;While there is a lot to like about marching tetrahedra, it does have some draw backs. &nbsp;In particular, the meshes you get from marching tetrahedra are typically about 4x larger than marching cubes. &nbsp;This makes both the algorithm and rendering about 4x slower. &nbsp;If your main consideration is performance, you may be better off using a cubical method. &nbsp;On the other hand, if you really need a manifold mesh, then marching tetrahedra could be a good option. &nbsp;The other nice thing is that if you are obstinate and like to code everything yourself, then marching tetrahedra may be easier since there aren’t too many cases to check.</p>
<h2>The Primal/Dual Classification</h2>
<p>By now, both marching cubes and tetrahedra are quite old. &nbsp;However, research into isosurface extraction hardly stopped in the 1980s.&nbsp; In the intervening years, many new techniques have been developed. &nbsp;One general class of methods which has proven very effective are the so-called `dual’ schemes. &nbsp;The first dual method, surface nets, was proposed by Sarah Frisken Gibson in 1999:</p>
<p>S.F. Gibson, (1999) “<a href="http://www.merl.com/papers/docs/TR99-24.pdf" target="_blank">Constrained Elastic Surface Nets</a>”&nbsp; Mitsubishi Electric Research Labs, Technical Report.</p>
<p>The main distinction between dual and primal methods (like marching cubes) is the way they generate surface topology.&nbsp; In both algorithms, we start with the same input: a volumetric mesh determined by our samples, which I shall take the liberty of calling a&nbsp;<em>sample complex</em> for lack of a better term.&nbsp; If you’ve never heard of the word&nbsp;<a href="http://www.inperc.com/wiki/index.php?title=Cell_complex">cell complex</a>&nbsp;before, you can think of it as an n-dimensional generalization of a triangular mesh, where the `cells’ or facets don’t have to be simplices.</p>
<p>In the sample complex, vertices (or 0-cells) correspond to the sample points; edges (1-cells) correspond to pairs of nearby samples; faces (2-cells) bound edges and so on:</p>
<p><img loading="lazy" data-attachment-id="534" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/samplecomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="samplecomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=533" title="samplecomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>Here is an illustration of such a complex. &nbsp;I’ve drawn the vertices where the potential function is negative black, and the ones where it is positive white.</p>
<p>Both primal and dual methods walk over the sample complex, looking for those cells which cross the 0-level of the potential function. &nbsp;In the above illustration, this would include the following faces:</p>
<p><img loading="lazy" data-attachment-id="535" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/boundarycells/" data-orig-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="boundarycells" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=533" title="boundarycells" alt="" src="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/boundarycells.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h3>Primal Methods</h3>
<p>Primal methods, like marching cubes, try to turn the cells crossing the bounary into an isosurface using the following recipe:</p>
<ul>
<li>Edges crossing the boundary become vertices in the isosurface mesh.</li>
<li>Faces crossing the boundary become edges in the isosurface mesh.</li>
<li>…</li>
<li>n-cells crossing the boundary become (n-1)-cells in the isosurface mesh.</li>
</ul>
<p>One way to construct a primal mesh for our sample complex would be the following:</p>
<p><img loading="lazy" data-attachment-id="536" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png" data-orig-size="533,424" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=533" title="primalcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238" height="238" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238 300w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=150&amp;h=119 150w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>This is pretty nice because it is easy to find intersection points along edges. &nbsp;Of course, there is some topological ambiguity in this construction.&nbsp; For non-simplicial cells crossing the boundary it is not always clear how you would glue the cells together:</p>
<p><img loading="lazy" data-attachment-id="537" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcell/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcell.png" data-orig-size="929,198" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcell" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=640" title="primalcell" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=63" height="63" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=296&amp;h=63 296w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=591&amp;h=126 591w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=150&amp;h=32 150w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=64 300w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>As we have seen, these ambiguities lead to exponentially many special cases, and are generally a huge pain to deal with.</p>
<h3>Dual Methods</h3>
<p>Dual methods on the other hand use a very different topology for the surface mesh.&nbsp; Like primal methods, they only consider the cells which intersect the boundary, but the rule they use to construct surface cells is very different:</p>
<ul>
<li>For every edge crossing the boundary, create an (n-1) cell.&nbsp; (Face in 3D)</li>
<li>For every face crossing the boundary, create an (n-2) cell. (Edge in 3D)</li>
<li>…</li>
<li>For every d-dimensional cell, create an (n-d) cell.</li>
<li>…</li>
<li>For every n-cell, create a vertex.</li>
</ul>
<p>This creates a much simpler topological structure:</p>
<p><img loading="lazy" data-attachment-id="538" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png" data-orig-size="537,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=537" title="dualcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234" height="234" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234 300w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=150&amp;h=117 150w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png 537w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>The nice thing about this construction is that unlike primal methods, the topology of the dual isosurface mesh is completely determined by the sample complex (so there are no ambiguities).&nbsp; The disadvantage is that you may sometimes get non-manifold vertices:</p>
<p><img loading="lazy" data-attachment-id="465" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualmesh/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png" data-orig-size="589,245" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualmesh" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=589" title="dualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300&amp;h=124" height="124" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=298&amp;h=124 298w, https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=150&amp;h=62 150w, https://0fps.files.wordpress.com/2012/07/dualmesh.png 589w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h2>Make Your Own Dual Scheme</h2>
<p>To create your own dual method, you just have to specify two things:</p>
<ol>
<li>A sample complex.</li>
<li>And a rule to assign vertices to every n-cell intersecting the boundary.</li>
</ol>
<p>The second item is the tricky part, and much of the research into dual methods has focused on exploring the possibilities. &nbsp;It is interesting to note that this is the opposite of primal methods, where finding vertices was pretty easy, but gluing them together consistently turned out to be quite hard.</p>
<h3>Surface Nets</h3>
<p>Here’s a neat puzzle: what happens if we apply the dual recipe to a regular, cubical grid&nbsp;(like we did in marching cubes)? &nbsp;Well, it turns out that you get the same boxy, cubical meshes that you’d make in a Minecraft game (topologically speaking)!</p>
<p><a href="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png"><img title="exampledualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png?w=150&amp;h=145" height="145" width="150"></a><a href="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png"><img title="spheresmoothed" alt="" src="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png?w=150&amp;h=138" height="138" width="150"></a></p>
<p>Left: A dual mesh with vertex positions snapped to integer coordinates.&nbsp; Right: A dual mesh with smoothed vertex positions.</p>
<p>So if you know how to <a href="https://0fps.wordpress.com/2012/06/30/meshing-in-a-minecraft-game/">generate Minecraft meshes</a>, then you already know how to make smooth shapes! &nbsp;All you have to do is squish your vertices down onto the isosurface somehow. &nbsp;How cool is that?</p>
<p>This technique is called “surface nets” (remember when we mentioned them before?) &nbsp;Of course the trick is to figure out where you place the vertices. &nbsp;In Gibson’s original paper, she formulated the process of vertex …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</a></em></p>]]>
            </description>
            <link>https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690189</guid>
            <pubDate>Fri, 08 Jan 2021 20:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Europol launched an innovative decryption platform]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25690151">thread link</a>) | @tmkbry
<br/>
January 8, 2021 | https://www.europol.europa.eu/newsroom/news/europol-and-european-commission-inaugurate-new-decryption-platform-to-tackle-challenge-of-encrypted-material-for-law-enforcement | <a href="https://web.archive.org/web/*/https://www.europol.europa.eu/newsroom/news/europol-and-european-commission-inaugurate-new-decryption-platform-to-tackle-challenge-of-encrypted-material-for-law-enforcement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This week Europol launched an innovative decryption platform, developed in close cooperation with the <a href="https://ec.europa.eu/info/departments/joint-research-centre_en" target="_blank">European Commission's Joint Research Centre</a>. It will significantly increase Europol’s capability to decrypt information lawfully obtained in criminal investigations.</p>
<p>The launch of the new decryption platform marks a milestone in the fight against organised crime and terrorism in Europe. In full respect of fundamental rights and without limiting or weakening encryption, this initiative will be available to national law enforcement authorities of all Member States to help keep societies and citizens safe and secure. A virtual inauguration ceremony brought together senior representatives from Europol, the <a href="https://www.europarl.europa.eu/portal/en" target="_blank">European Parliament</a>, the <a href="https://www.consilium.europa.eu/en/" target="_blank">Council of the EU</a> and the <a href="https://ec.europa.eu/info/index_en" target="_blank">Commission</a>.</p>
<p>The event highlighted strong organisational cooperation within the EU and the considerable potential in innovation, research and development of the EU innovation hub for internal security.</p>
<p><strong>Ylva Johansson, EU Commissioner for Home Affairs</strong> said:</p>
<blockquote><p>This decryption platform will help police to investigate terrorism and serious and organised criminality. It will be important in the fight against online child sexual abuse. National police forces can now send lawfully obtained evidence to Europol for decryption.</p>
</blockquote>
<p>Addressing the event, <strong>Europol’s Executive Director Catherine De Bolle</strong> said:</p>
<blockquote><p>Today marks the end of a three-year-long journey. We have made a significant step forward in combating the criminal abuse of encryption with the aim of keeping our society and citizens safe while fully respecting fundamental rights. The new Europol Decryption Platform, funded by the European Commission, will allow us to further enhance our support for Member State investigations. This is the result of successful inter-organisational collaboration within the EU and shows the potential for further joint work and support for the EU innovation hub for internal security. I would like to express my gratitude to the Joint Research Centre for their strong partnership in this project.</p>
</blockquote>
<p>
Europol’s <a href="https://www.europol.europa.eu/about-europol/european-cybercrime-centre-ec3">European Cybercrime Centre (EC3)</a> will operate the platform and leverage its in-house expertise in providing the most effective support to national Member State investigations.<br>
EC3 is dedicated to strengthening the law enforcement response to cybercrime in the EU and focuses on cybercrime committed by organised crime groups, which generate large profits (online fraud), seriously harm victims (online child sexual exploitation) or impact critical infrastructure and information systems in the EU, including through cyber-attacks.</p>
<hr><p>Headquartered in The Hague, the Netherlands, Europol supports the 27 EU Member States in their fight against terrorism, cybercrime and other serious and organised forms of crime. We also work with many non-EU partner states and international organisations. From its various threat assessments to its intelligence-gathering and operational activities, Europol has the tools and resources it needs to do its part in making Europe safer.</p>
</div></div>]]>
            </description>
            <link>https://www.europol.europa.eu/newsroom/news/europol-and-european-commission-inaugurate-new-decryption-platform-to-tackle-challenge-of-encrypted-material-for-law-enforcement</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690151</guid>
            <pubDate>Fri, 08 Jan 2021 20:40:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four levels of maturity that bridge the AppSec / engineering divide]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25688143">thread link</a>) | @pabloest
<br/>
January 8, 2021 | https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p><em>This is a guest post authored by <a href="https://jacobian.org/" target="_blank" rel="noopener">Jacob Kaplan-Moss</a>, co-creator of Django.</em></p>
<h3>Introduction</h3>
<p>I’ve spent a good deal of my career with my feet in two different worlds. I came up as a web developer and helped create a popular web framework (Django). And I’ve spent a sizable chunk of my career working in information security.
Unfortunately, I’ve seen these two roles clash far too often. Engineering often sees Security as standing in the way of delivery, or as creating meaningless busywork. Security thinks Engineering is irresponsible, willing to ship broken or vulnerable code.</p>
<p>I’ve spent more than a decade trying to bridge this gap. There’s no silver bullet. But, over and over, I’ve seen one practice be quite effective: automated security tests — and particularly integrating security checks and tests into an existing CI pipeline.</p>
<h3>Bringing Security along on the CI/CD journey</h3>
<p>Engineers have largely embraced CI as a critical part of quality assurance, and that a robust test suite that runs on every commit is a huge enabler of velocity. We can be bold about making changes, knowing that the test suite will catch us if we’ve messed up. A mature CI/CD pipeline is a reliable litmus test for good software.</p>
<p>Historically, though, Security has been left out of this CI/CD journey. We’ve relied on manual security assessments; hands-on exercises like threat modelling and threat hunting; and bespoke penetration tests. These are important activities that will always have a place in a mature product security lifecycle, but they increasingly are difficult to integrate into an agile delivery model that relies on incremental changes and automated tests. Much of the friction between modern engineering and security teams can come down to this impedance mismatch.</p>
<p>So, to get Security and Engineering playing well together, one massively useful tool is getting security work integrated into continuous delivery. When done right, Security and Engineering work together to produce automated checks that cover security issues in the same test suite that’s already in CI. This maintains delivery cadence, gives confidence about the security of the product, and — most importantly — gives a place where Security and Engineering collaborate, rather than conflict, to produce secure code.</p>
<p>How does this look in practice? Each organization is different, but there’s a typical progression of maturity that Security and Engineering orgs go through as they build a continuous integration and automation pipeline:</p>
<ul>
<li>Level 1: Security finds problems; Engineering fixes them</li>
<li>Level 2: Security and Engineering collaborate to produce test cases and remediations</li>
<li>Level 3: After the issue is fixed, Security and Engineering collaborate to find systemic fixes and develop checks</li>
<li>Level 4: Security and Engineering now also proactively look for new classes of issues and create systemic checks before an actual problem occurs</li>
</ul>
<p>For the rest of this post, I’ll walk through each of these phases with a specific example about a team that systemically fixed an issue with logging sensitive tokens.</p>
<h3>Level 1: Security finds problems; Engineering fixes them</h3>
<p>This is (unfortunately) how many organizations operate. Nobody really works together: Security is off in one corner looking for vulnerabilities (or, worse, waiting for a breach and then responding!). When they find one, they tell Engineering, who (hopefully) fixes the problem.</p>
<p>Let’s begin the example and see how this could shake out in practice. A few months ago, Nathan Brahams <a href="https://r2c.dev/blog/2020/fixing-leaky-logs-how-to-find-a-bug-and-ensure-it-never-returns/" target="_blank" rel="noopener">wrote about systemically fixing an issue around accidentally logging sensitive tokens</a>. His article illustrates the steps a quite mature security/engineering organization would take, but I’ll use this issue as a jumping-off-point to imagine how teams earlier in their journey might approach discovering a similar issue.</p>
<p>So, imagine a budding team has found this security issue: SQLAlchemy debug logging is turned on and sensitive tokens are being logged. The issue is fixed with a clever technique that uses a custom <code>ObfuscatedString</code> column that prevents SQLAlchemy from logging the token's value. So, we just swap in <code>ObfuscatedString</code> for the token column. Problem solved, right?</p>
<p>Well, while this does fix the issue, it has many problems:</p>
<ul>
<li><strong>Verification</strong>: If Engineering just rolls out this fix, how do we verify that the issue is actually fixed? Usually at this level of maturity, the Security team will manually verify the fix, but that’s error-prone. It’s also slow; if the fix didn’t work or is incomplete, the cycle has to repeat itself.</li>
<li><strong>Regression</strong>: If another engineer, some time later, doesn’t understand this <code>ObfuscatedString</code>, it could get reverted or modified in a way that re-introduces the issue. How would we know if this happens? (Spoiler alert: with an automated test, which we’ll discuss in the next section.)</li>
<li>Is this a one-off issue, or <strong>is it a systemic issue</strong>? Are there other sensitive values elsewhere that might be logged?</li>
<li><strong>Conflict</strong>: Most importantly, this workflow sets up conditions ripe for conflict between Security and Engineering. It creates a dynamic where it’s easy for Engineering to feel like Security’s just creating work for them, and where Security can feel ignored or powerless to fix problems. I’ve never seen this model produce a really healthy relationship; just ones with varying levels of dysfunction. Even when Security helps write the fix, the lack of any sort of robust verification or systemic analysis means it’s very likely they’ll need to come back later with this issue or a similar one again, which both parties will resent.</li>
</ul>
<h3>Level 2: automated tests</h3>
<p>The next rung on the maturity ladder is one that’s becoming increasingly common: instead of just fixing a security issue, Security and Engineering will collaborate on producing a test case (and often the fix). Following along with the example above, we might write a test case that sets up a test model with an <code>ObfuscatedString</code> column, captures some logs, and verifies that the value is correctly obfuscated.</p>
<p>This relatively simple addition fixes a bunch of problems we had before:</p>
<ul>
<li><strong>Verification</strong>: If the test case passes, we can be confident the security issue is fixed.</li>
<li><strong>Regression</strong>: Because this test case is part of our test suite, if it ever regresses the test case will fail, and we won’t risk re-introducing it to production.</li>
<li><strong>Collaboration</strong>: Security and Engineering are now working more closely together, increasing the chances both teams will see this as “our issue” and “our fix”, not “their problem”.</li>
</ul>
<p>But: we still lack any sort of understanding of whether this issue occurs elsewhere, or any sort of holistic fix for the entire class of issues. In the case of logging sensitive tokens, it’s easy to imagine this issue occurring elsewhere. So when — inevitably — a similar issue occurs elsewhere, we’re likely to be bitten again. And this, in turn, will continue to produce the kind of resentment that can be so damaging to Security/Engineering working well together.</p>
<h3>Level 3: systemic fixes and checks</h3>
<p>The next step, then, is for Security and Engineering to work together to find systemic problems and fixes. Things start out as above — it’s important to fix the specific vulnerability first, before getting fancy! But after the specific fix is in, Security and Engineering come together to figure out if this is a systemic problem. If so, they work to develop a check or a fix.</p>
<p>Sometimes this can be a fairly simple holistic fix. For example, <a href="https://r2c.dev/blog/2020/understanding-and-preventing-dos-in-web-apps/" target="_blank" rel="noopener">I wrote about ReDoS last time</a>. Discovery of a ReDoS vulnerability might lead to discovering other similar potential problems. That in turn could lead to the decision to switch to <a href="https://github.com/google/re2" target="_blank" rel="noopener">re2</a>, which isn’t vulnerable to ReDoS.</p>
<p>But much of the time, the systemic fix is more complex — there isn’t a simple drop-in replacement that eliminates a class of vulnerabilities. That’s true of this sensitive-logging issue: we don’t have any sort of logging module that can magically know when variables are sensitive, and obfuscate them.</p>
<p>This is where code scanning tools like Semgrep come in. They are a terrifically important part of a mature product security workflow. Traditional testing practices — unit tests, integration tests, etc — are great for reproducing specific security issues, and ensuring that they’re fixed and won’t regress. But they struggle to discover whole classes of security issues, and this is what code scanners enable. Traditional code linters (e.g., Flake8, RuboCop) help to ensure code consistency and find some common issues, but since they have to apply generally to all kinds of projects, they tend to only provide a one-size-fits-all best-practices check. Tools that understand code semantically, like Semgrep, can be used to write tests for <em>your unique codebase</em> and find whole classes of security issues — including, most importantly, new instances of a problem that might be added after the check has been written.</p>
<p>And indeed, that’s what Nathan and his team did: they wrote a Semgrep rule that finds columns with names suggesting they’re sensitive (e.g., containing “token”, “secret”, “key”, etc), and issues a warning.</p>
<p>At this point, we’re in a pretty good spot. New code is continually scanned for this issue, and when found, they are fixed robustly. We have a workflow and tooling that ensures that the original, specific issue is fixed and that it stays fixed, and we ensure that similar issues — present and future — are discovered and fixed. Security and Engineering collaborate on this work, which is now well-automated. There’s still (of course) room for teams to not get along, but we’ve removed some of the most common pain points (verification, regression, conflict between teams).</p>
<p>If suddenly blocking builds with new checks will only increase conflict in your organization, you could softly roll out checks that do not block Engineering and only notify Security. For issues that arise, Security can begin conversations with Engineering to collaborate on both specific and systemic fixes. Once the check is satisfactory to both …</p></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/">https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/</a></em></p>]]>
            </description>
            <link>https://r2c.dev/blog/2021/four-levels-of-maturity-that-bridge-the-app-sec-engineering-divide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25688143</guid>
            <pubDate>Fri, 08 Jan 2021 18:40:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Cultural Purge Is Now in Overdrive]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25688127">thread link</a>) | @StuntPope
<br/>
January 8, 2021 | https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/ | <a href="https://web.archive.org/web/*/https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/#comments">
			21 <span></span>
		</a></p>
		
		
				<p><img loading="lazy" src="https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake.jpg" alt="" width="600" height="437" srcset="https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake.jpg 600w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-300x219.jpg 300w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-150x109.jpg 150w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-65x47.jpg 65w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-220x160.jpg 220w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-137x100.jpg 137w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-358x261.jpg 358w, https://outofthecave.io/wp-content/uploads/2021/01/burned_at_the_stake-549x400.jpg 549w" sizes="(max-width: 600px) 100vw, 600px"></p>
<p>Four years ago, after the unthinkable happened and the wrong guy won the US election of 2016. <a href="https://easydns.com/blog/2017/02/24/the-cultural-purge-will-not-be-televised/">I wrote an article</a> about how I had feared a type of “cultural purge” from within the corporate media, Big Tech and cancel culture spheres. Like everybody else, I didn’t expect Trump to win (like most other Libertarians, I was holding my nose and pulling for Gary Johnson, whose running mate, Bill Weld, endorsed Hillary Clinton <em>during the election campaign).</em></p>
<p>What I expected then, after Trump would have unceremoniously lost the 2016 election,&nbsp; was a type of cultural purge against anybody and everybody who enabled his run or supported him. What surprised me was that after he won the cultural purge proceeded anyway. In retrospect it seems obvious, at the time it blindsided me.<span id="more-1501"></span></p>
<p>For the next four years we watched any (remaining) semblance of objectivity and impartiality wither away from the mainstream media. Even more troubling, was that it was also happening within<em>&nbsp;</em>Big Tech. Everything polarized and all judgement calls became characteristically asymmetrical. As I noted on occasion, that compared to the post 9/11 era when the Neocons controlled the narrative and the word “liberal” was a slur, everything flipped. Now it was the word “conservative” that was unusable and being a single micron to the right of centre was equated with being “literally Hitler”.</p>
<p>I could list the countless examples of deplatformings, cancellations, character assassinations and careers destroyed in the intervening time. It became so ridiculous, so devoid of any attempt at a claim to due process or fairness that an entire counter-culture has formed around criticizing or ridiculing it. <a href="https://easydns.com/blog/2019/10/22/unassailable-the-book-that-protects-you-from-cancel-culture-and-deplatform-attacks/">I wrote a book</a> about <a href="https://easydns.com/blog/2019/10/22/unassailable-the-book-that-protects-you-from-cancel-culture-and-deplatform-attacks/">defending from deplatform attacks</a>, which I started <a href="https://axisofeasy.com/aoe/the-missing-manual-for-defending-yourself-against-deplatforming-and-cancel-culture/">giving away for free</a> in April when Big Tech started deplatforming deviant reporting on the COVID-19 crisis. Babylon Bee sprang into existence and quickly rivalled The Onion, <a href="https://babylonbee.com/news/op-ed-anyone-who-claims-cancel-culture-is-real-is-a-bigot-who-should-lose-his-job">riffing on cancel culture</a> and hitting headwinds on multiple occasions when their scathing satire <a href="https://news.yahoo.com/twitter-apologizes-mistakenly-suspending-babylon-154401646.html">was indistinguishable from the reality</a> they were lampooning.</p>
<div id="attachment_1511"><p><a href="https://babylonbee.com/news/op-ed-anyone-who-claims-cancel-culture-is-real-is-a-bigot-who-should-lose-his-job"><img aria-describedby="caption-attachment-1511" loading="lazy" src="https://outofthecave.io/wp-content/uploads/2021/01/oped-e1610129919714.png" alt="" width="800" height="745"></a></p><p id="caption-attachment-1511">TL,DR: Cancel culture is a right-wing conspiracy promulgated by Qanon Incels</p></div>
<p>More than once I thought “This is it, this has to be Peak Outrage”, and then somebody else’s career or business would be destroyed, sometimes for imagined transgressions that may or may not have taken place years ago or even before the target even started a position they’d just been canceled from having (David Collum’s section on cancel culture, featuring his own cancelation, lays many of these out in his famous Year In Review series, <a href="https://www.peakprosperity.com/dave-collum-2020-year-in-review-part-2/#cancelculture">the 2020 issue</a>).</p>
<p>Once the 2020 election was finally in the rear-view mirror and it appeared likely the administration had changed I thought, once again, that the worst was over. The world was mired in lockdown fatigue, we’re not even dealing with the economic fallout of COVID yet, and “ding dong the witch is dead”. Surely cancel culture and social justice extremism would taper off, if only out of exhaustion.</p>
<blockquote>
<p dir="ltr" lang="en">i’m fucking exhausted <a href="https://t.co/gjmsQtgBFh">pic.twitter.com/gjmsQtgBFh</a></p>
<p>— Jordan Lancaster (@jordylancaster) <a href="https://twitter.com/jordylancaster/status/1316065323595034628?ref_src=twsrc%5Etfw">October 13, 2020</a></p></blockquote>

<h2>Boy am I wrong, again.</h2>
<p>The ignominy with which TheDonald has chosen to close out his term, the lack of humility, of which is he likely congenitally incapable of, will instead reignite the flames of the culture wars and propel them to new heights. As investing legend (and Fed critic) Bill Fleckinstein observed in his subscriber note yesterday, there is a right way and a wrong way to go out, even if you feel like you got shafted:</p>
<blockquote><p>On the subject of yesterday’s violence, although it is unlikely to have long-lasting economic impacts and thus is largely in the realm of politics, which I tend to avoid, I think there is a worthwhile lesson to point out. Obviously, Trump’s worst qualities, which stem from his being a petulant egomaniac, have been on display since he lost the election and I’m reminded of a very valuable lesson I learned from my investment business mentor, who told me that when you get fired by a client (yes, that happens), rather than be upset and act petulantly what you should say is, “How can I make the transition easier for you?”</p>
<p>In other words, you turn a loss into a bit of a victory by being a class act. I can’t tell you how many times over my investment career when that lesson and corollaries to it have been quite useful, and no matter what, trying to comport yourself in such a manner pays big dividends over time in my opinion.</p></blockquote>
<p>Like Fleck, I don’t even want to get into the gory details of the events of Jan 6, the storming of the capital, the riots, other than to say that when we talk about the twilight of the nation state and the rise of the Network State <a href="https://axisofeasy.com/salon">in our #AxisOfEasy podcasts,</a> these are the sort of disorderly episodes we fear punctuating or worse, defining, this oncoming societal shift.</p>
<p>We certainly seem to be <a href="https://www.goodreads.com/book/show/670089.The_Fourth_Turning">into The Fourth Turning now</a>, a book I have been rereading and was just finishing up listening to the day of the DC riots. Their prescience is creepy, especially as they outlined the “climax” phase of the Crisis period, which, by their reckoning started around… 2020 and would last another 6 to 10 years:</p>
<div>
<blockquote><p>One or both of today’s dominant parties could go the way of the Whigs…History warns that when a crisis catalyzes, a previously dominant political party or regime can find itself perceived or blamed for direct mistakes that led to the national emergency.</p>
<p>Whoever holds power when the Fourth Turning arrives could find themselves joining the ranks of the 14th century Lancastrians, circa 15th century Catholics, circa 1680 Stewarts, circa 1770 Tories, circa 1860 Democrats, and circa 1929 Republicans. That party could find itself out of power for a generation.</p>
<p>Key persons associated with it could find themselves defamed, stigmatized, harassed, economically ruined, or even personally punished”</p></blockquote>
<p>Since that day, Big Tech and corporate media moved at a new speed that I found dizzying. Twitter pile-ons are ugly enough spectacles and that’s just watching end-users gang up on the sacrificial deviant of the day. But <a href="https://www.theverge.com/2021/1/7/22218776/shopify-trump-store-disable-campaign-ecommerce-sites-capitol">watching&nbsp;<em>Shopify</em></a> of all companies, pile on to Facebook and Twitter’s deplatforming of a sitting president (which at this moment he is, like it or not), <a href="https://www.cnn.com/2021/01/07/media/josh-hawley-book-canceled/index.html">Simon and Schuster canceling their contract</a> to publish Sen Josh Hawley’s book <em>on Big Tech censorship</em> (which I wanted to read) and I’m sure the list will go on after I’m done writing, this is just fucking crazy.</p>
<p>(I paused writing this to take a meeting, an hour later I come back to finishing it off and a friend, who fled Chicago this past summer because of the complete breakdown of civil order there, among other US cities at that time, <a href="https://chicago.suntimes.com/politics/2021/1/7/22219360/trump-rally-capitol-tank-noodle-insight-studios-properties">sent me this story</a>. It outlines numerous other firings and cancelations of Chicagoans who attended the DC rally (but not necessarily involved in the violence), and businesses who even commented in social media about it.</p>
<div id="attachment_23289"><p><img aria-describedby="caption-attachment-23289" loading="lazy" src="https://axisofeasy.com/wp-content/uploads/2021/01/properties-1024x374.png" alt="" width="1024" height="374"></p><p id="caption-attachment-23289">Translation: a social media mob demanded we cancel one of our employees with zero due process or time to consider, so we did. <strong>Who do you want us to fire next?</strong></p></div>
<h2><strong><em>Think it through people.</em> </strong></h2>
<p>Do you want to live in a society where Facebook and Twitter decide not only what is <em>permissible</em> to say but even <em>which narratives can be explored</em> and which ones can’t?</p>
<p>Yes I know, “private companies, their own AUP, blah blah blah” – I’m a libertarian and a tech company CEO, so I know all this. I’ll preempt these objections with what I said in my book, which is that when tech companies base platform/deplatform decisions on something that is happening&nbsp;<em>outside&nbsp;</em>of their platforms, they are in effect, exercising jurisprudence and adjudicating international law. All any company can competently assess is what is happening on within their respective platforms, how their employees are fulfilling their roles and serving the businesses customers <em>and nothing else.</em></p>
<p>Would you be ok with your employer firing you if enough strangers who don’t know you, don’t do business with your company and have no first hand knowledge of events or what your circumstances are scream at your boss to cut you loose?</p>
<p>Do you want contracts to be subject to negation by&nbsp; public sentiment of events 2 or 3 or more degrees separated from the contracted parties?</p>
<p>Do you want to have every aspect of your life scrutinized by somebody else’s measure of moral and ideological purity before you can say anything online? How about before you can book a hotel room? Fill up your car with gas? Go shopping? Get on a plane?</p>
<p>After all, we have big data and AI now, <em>so this is all doable.&nbsp;</em></p>
<p>Do you really want to live within the constraints of a type of societal social credit system where your every action, <em>your very thoughts</em> are bounded by external and ever shifting, subjective and <a href="https://outofthecave.io/articles/merriam-webster-modifies-word-definition-after-left-manufactures-offensive-meaning-for-it/">revisionist social mores</a>? Many of them defined by the most oversensitive, self-absorbed hysterics on social media?</p>
<p>Be very careful if you think this is a good thing, because sooner or later, you’re going to be on the wrong side of it. By then it’ll be too late.</p>


</div>
<p><a href="#" rel="nofollow" onclick="window.print(); return false;" title="Printer Friendly, PDF &amp; Email"><img src="https://cdn.printfriendly.com/buttons/printfriendly-button.png" alt="Print Friendly, PDF &amp; Email"></a></p>
			</div></div>]]>
            </description>
            <link>https://outofthecave.io/articles/the-cultural-purge-is-now-in-overdrive/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25688127</guid>
            <pubDate>Fri, 08 Jan 2021 18:40:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to try CLIP: OpenAI's new universal zero-shot image classifier]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687532">thread link</a>) | @yeldarb
<br/>
January 8, 2021 | https://blog.roboflow.com/how-to-use-openai-clip/ | <a href="https://web.archive.org/web/*/https://blog.roboflow.com/how-to-use-openai-clip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div>
                <div><p>Earlier this week, OpenAI dropped a bomb on the computer vision world: two new groundbreaking models that hint at what's to come as massive GPT3-esque Transformer models encroach on the vision domain. While <a href="https://openai.com/blog/dall-e/">DALL-E</a> (a model that can generate images from text prompts) has garnered much of the attention this week, this post focuses on <a href="https://openai.com/blog/clip/">CLIP</a>: a zero-shot classifier which is arguably even more consequential.</p><p>Until now, <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">classifying images</a> has involved collecting a custom dataset of hundreds, thousands, or even millions of labeled images that suitably represent your targeted classes and using it to train a supervised classification model (usually a convolutional neural network). This approach (and extensions of it like <a href="https://blog.roboflow.com/object-detection/">object detection</a>) has led to the rapid proliferation of computer vision over the past decade (powering everything from <a href="https://blog.roboflow.com/self-driving-car-dataset-missing-pedestrians/">self driving cars</a> to <a href="https://blog.roboflow.com/designing-augmented-reality-computer-vision-apps/">augmented reality</a>).</p><p>The downside of supervised training is that the resultant models do not generalize particularly well. If you show them an image from a different domain, they usually do no better than randomly guessing. This means you need to curate a wide variety of data that is sufficiently representative of the exact task your model will perform in the wild.</p><h2 id="enter-openai-clip">Enter OpenAI CLIP</h2><p>The recent introduction of <a href="https://openai.com/blog/clip/">CLIP</a> (Contrastive Language-Image Pre-training) has disrupted this paradigm. It's a zero-shot model, meaning it can identify an enormous range of things it has never seen before.</p><figure><img src="https://blog.roboflow.com/content/images/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png 600w, https://blog.roboflow.com/content/images/size/w1000/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png 1000w, https://blog.roboflow.com/content/images/2021/01/Screen-Shot-2021-01-08-at-12.55.41-PM.png 1367w" sizes="(min-width: 720px) 720px"><figcaption>CLIP is like the best AI caption writer. It's able to say what is in an image from 32,768 sampled captions. Image credit: <a href="https://openai.com/blog/clip/">OpenAI</a></figcaption></figure><p>In traditional classifiers, the meaning of the labels is ignored (in fact, they're often simply discarded and replaced with integers internally). By contrast, CLIP creates an encoding of its classes and is pre-trained on over 400 million text to image pairs. This allows it to leverage transformer models' ability to extract semantic meaning from text to make image classifications out of the box without being fine-tuned on custom data.</p><p><strong>All you need to do is define a list of possible classes, or descriptions, and CLIP will make a prediction for which class a given image is most likely to fall into based on its prior knowledge. Think of it as asking the model "which of these captions best matches this image?"</strong></p><p>In this post, we will walk through a demonstration of how to test out CLIP's performance on your own images so you can get some hard numbers and an intuition for how well CLIP actually does on various use case. <strong>We found that CLIP does better than <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">our custom trained ResNet classification models</a> on a <a href="https://public.roboflow.com/classification/flowers_classification">flower classification</a> task. </strong>It also does surprisingly well over a range of more obscure and challenging tasks (including identifying mushroom species in pictures from our camera roll and <a href="https://public.roboflow.com/object-detection/oxford-pets/2">identifying breeds of dogs and cats</a>).</p><p>Resources in this tutorial:</p><ul><li><a href="https://public.roboflow.com/classification/flowers_classification">Public flower classification dataset</a></li><li><a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">CLIP benchmarking Colab notebook</a></li><li><a href="https://github.com/openai/CLIP">CLIP repo</a></li><li>Corresponding YouTube</li></ul><figure><iframe width="356" height="200" src="https://www.youtube.com/embed/8o701AEoZ8I?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><h2 id="assembling-your-dataset">Assembling Your Dataset</h2><p>To try out CLIP, you will need to bring a dataset of images that you want classified, partitioned into the classes that you would like to see. </p><p>If you do not already have a dataset, and would like to just try out the new technology, take a look at Roboflow's <a href="https://public.roboflow.com/">public computer vision datasets</a>.</p><p>In this post, we'll be benchmarking CLIP on the public <a href="https://public.roboflow.com/classification/flowers_classification">flower classification dataset</a>. If using your own data, <a href="https://docs.roboflow.com/adding-data/classification">uploading your data to Roboflow</a> is easy and free (up to 1000 images), and then you can follow the same flow in this blog.</p><figure><img src="https://blog.roboflow.com/content/images/2021/01/image-9.png" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/01/image-9.png 600w, https://blog.roboflow.com/content/images/size/w1000/2021/01/image-9.png 1000w, https://blog.roboflow.com/content/images/size/w1600/2021/01/image-9.png 1600w, https://blog.roboflow.com/content/images/2021/01/image-9.png 1690w" sizes="(min-width: 720px) 720px"><figcaption>The example flowers classification dataset used in this post</figcaption></figure><p>Once you've assembled your dataset, it's on to the <a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">CLIP benchmarking Colab notebook</a>.</p><h2 id="installing-clip-dependencies">Installing CLIP Dependencies</h2><p>To try CLIP out on your own data, make a copy of the notebook in your drive and make sure that under Runtime, the GPU is selected (Google Colab will give you a free GPU for use). Then, we make a few installs along with cloning the CLIP Repo. </p><h2 id="downloading-your-dataset-into-colab">Downloading Your Dataset into Colab</h2><p>The next step is to download your classification dataset into Colab. </p><figure><img src="https://blog.roboflow.com/content/images/2021/01/image-8.png" alt="" srcset="https://blog.roboflow.com/content/images/size/w600/2021/01/image-8.png 600w, https://blog.roboflow.com/content/images/2021/01/image-8.png 858w" sizes="(min-width: 720px) 720px"><figcaption>Downloading classification data into the notebook</figcaption></figure><p>If you made a dataset in Roboflow, this is achieved by hitting <code>Generate</code>, then <code>Download</code> in the <code>OpenAI CLIP Classification</code> format. This will put all of your test images in a folder called <code>test</code> with separate subdirectories of images for each class in your dataset and give you a <code>_tokenization.txt</code> file that lets you experiment with "Prompt Engineering" which can drastically improve or degrade the model's performance.</p><p>We've also created a converter for object detection datasets which will create a textual description from the bounding boxes present. We had mixed results with these but they are certainly interesting to play with.</p><p>Additionally, we have made all of <a href="https://public.roboflow.com/">our open source datasets</a> available to download for free in the CLIP format.</p><h2 id="inferring-class-labels-with-clip">Inferring Class Labels with CLIP</h2><p>The final step is to pass your test images through a predictions step. </p><p>CLIP takes an image and a list of possible class captions as inputs. You can define the class captions as you see fit in the <code>_tokenization.txt</code> file. Be sure to make sure they stay in the same order as the alphabetically sorted <code>class_names</code> (defined by the folder structure).</p><p><a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">The notebook</a> contains code to iterate over each of the class folders in the test set and pass the relevant images through a prediction step. </p><h3 id="experimenting-with-ontologies-and-results">Experimenting with Ontologies and Results</h3><p>When you use CLIP for your classification task, it is useful to experiment with different class captions for your classification ontology, and remember that CLIP was trained to differentiate between image captions.</p><p>On the flowers dataset, we tried the following ontologies and saw these results:</p><ul><li><code>"daisy" vs "dandelion"]</code> &nbsp;--&gt; 46% accuracy (worse than guessing)</li><li><code>"daisy flower" vs "dandelion flower"</code> --&gt; 64% accuracy</li><li><code>"picture of a daisy flower" vs "picture of a dandelion flower"</code> --&gt; 97% accuracy</li></ul><p><strong>97% accuracy is higher than any <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">other classification model</a> that we have trained on this dataset. </strong></p><p>These results show the importance of providing the right class descriptions to CLIP and express the richness of the pretraining procedure, a feature that is altogether lost in traditional, binary classification. OpenAI calls this process "prompt engineering".</p><h2 id="flipping-the-script">Flipping the Script</h2><p>CLIP may have many additional use cases including ranking images against a target query string, or sorting images among their uniqueness.</p><p>In <a href="https://colab.research.google.com/drive/1LXla2q9MCRRI_kTjpvag2Vz-7EGLnki5#scrollTo=lOF3Feb7jrnu">the notebook</a>, you'll see code defining two variables <code>image_features</code> and <code>text_features</code>. The cosine similarity between any pair of these features represents their semantic distance - and from our experience thus far, it is strikingly accurate. These are the early days... </p><h2 id="conclusion">Conclusion</h2><p>If you find that CLIP's performance is not as high as you would like, you may still want to consider <a href="https://blog.roboflow.com/custom-resnet34-classification-model/">training a custom image classification model with supervision</a>.</p><p>For more on CLIP research, consider reading <a href="https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language_Supervision.pdf">the paper</a> and checking out <a href="https://openai.com/blog/clip/">OpenAI's blog post</a>. And we'd love to hear if you discover anything interesting when playing around with the model! Be sure to <a href="https://twitter.com/roboflowai">drop us a line on twitter</a>.</p><p>As always, happy inferencing!</p></div>
                
              </div>
            </div></div>]]>
            </description>
            <link>https://blog.roboflow.com/how-to-use-openai-clip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687532</guid>
            <pubDate>Fri, 08 Jan 2021 17:56:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baldur's Gate 2 reincarnated in the browser using WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25687261">thread link</a>) | @yuri91
<br/>
January 8, 2021 | https://browser-games.itch.io/baldursgate2 | <a href="https://web.archive.org/web/*/https://browser-games.itch.io/baldursgate2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="header"><p><img alt="Baldur's Gate 2 Demo (Web Edition)" src="https://img.itch.zone/aW1nLzMzOTMyMDYuanBn/original/ymT9Bf.jpg"></p></div><div id="view_html_game_page_16144"><div id="html_embed_widget_81194"><div data-height="800" data-width="1000"></div></div><div><div><div><p>Link to Discord community:&nbsp;<a href="https://discord.gg/zUSZ3T8" rel="nofollow noopener">https://discord.gg/zUSZ3T8</a></p></div><div><div><span>More information<svg height="6" width="12" role="img" aria-hidden="" viewBox="0 0 37 20" version="1.1"><path d="m2.0858 0c-1.1535 0-2.0858 0.86469-2.0858 1.9331 0 0.5139 0.21354 1.0183 0.38704 1.1881l18.113 16.879 18.112-16.879c0.174-0.1696 0.388-0.674 0.388-1.1879 0-1.0684-0.932-1.9331-2.086-1.9331-0.577 0-1.111 0.23008-1.49 0.57992l-14.924 13.894-14.925-13.893c-0.3777-0.34998-0.9134-0.581-1.4902-0.581z"></path></svg></span></div><div><div><table><tbody><tr><td>Updated</td><td><abbr title="08 January 2021 @ 18:16"><span></span> 3 days ago</abbr></td></tr><tr><td>Status</td><td><a href="https://itch.io/games/released">Released</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/games/html5">HTML5</a></td></tr><tr><td>Author</td><td><a href="https://browser-games.itch.io/">browser games</a></td></tr><tr><td>Genre</td><td><a href="https://itch.io/games/genre-rpg">Role Playing</a></td></tr></tbody></table></div></div></div><div><h2 id="comments">Leave a comment</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fbrowser-games.itch.io%2Fbaldursgate2" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_widget_19128"></div></div></div><div><p><a href="https://img.itch.zone/aW1nLzMzNTc4NzIuanBn/original/Eh%2FX49.jpg" target="_blank" data-image_lightbox="true"><img src="https://img.itch.zone/aW1nLzMzNTc4NzIuanBn/347x500/O3hTpf.jpg"></a></p></div></div></div><div id="view_game_footer"><a href="https://itch.io/"><svg height="17" width="20" role="img" aria-hidden="" viewBox="0 0 262.728 235.452" version="1.1"><path d="M31.99 1.365C21.287 7.72.2 31.945 0 38.298v10.516C0 62.144 12.46 73.86 23.773 73.86c13.584 0 24.902-11.258 24.903-24.62 0 13.362 10.93 24.62 24.515 24.62 13.586 0 24.165-11.258 24.165-24.62 0 13.362 11.622 24.62 25.207 24.62h.246c13.586 0 25.208-11.258 25.208-24.62 0 13.362 10.58 24.62 24.164 24.62 13.585 0 24.515-11.258 24.515-24.62 0 13.362 11.32 24.62 24.903 24.62 11.313 0 23.773-11.714 23.773-25.046V38.298c-.2-6.354-21.287-30.58-31.988-36.933C180.118.197 157.056-.005 122.685 0c-34.37.003-81.228.54-90.697 1.365zm65.194 66.217a28.025 28.025 0 0 1-4.78 6.155c-5.128 5.014-12.157 8.122-19.906 8.122a28.482 28.482 0 0 1-19.948-8.126c-1.858-1.82-3.27-3.766-4.563-6.032l-.006.004c-1.292 2.27-3.092 4.215-4.954 6.037a28.5 28.5 0 0 1-19.948 8.12c-.934 0-1.906-.258-2.692-.528-1.092 11.372-1.553 22.24-1.716 30.164l-.002.045c-.02 4.024-.04 7.333-.06 11.93.21 23.86-2.363 77.334 10.52 90.473 19.964 4.655 56.7 6.775 93.555 6.788h.006c36.854-.013 73.59-2.133 93.554-6.788 12.883-13.14 10.31-66.614 10.52-90.474-.022-4.596-.04-7.905-.06-11.93l-.003-.045c-.162-7.926-.623-18.793-1.715-30.165-.786.27-1.757.528-2.692.528a28.5 28.5 0 0 1-19.948-8.12c-1.862-1.822-3.662-3.766-4.955-6.037l-.006-.004c-1.294 2.266-2.705 4.213-4.563 6.032a28.48 28.48 0 0 1-19.947 8.125c-7.748 0-14.778-3.11-19.906-8.123a28.025 28.025 0 0 1-4.78-6.155 27.99 27.99 0 0 1-4.736 6.155 28.49 28.49 0 0 1-19.95 8.124c-.27 0-.54-.012-.81-.02h-.007c-.27.008-.54.02-.813.02a28.49 28.49 0 0 1-19.95-8.123 27.992 27.992 0 0 1-4.736-6.155zm-20.486 26.49l-.002.01h.015c8.113.017 15.32 0 24.25 9.746 7.028-.737 14.372-1.105 21.722-1.094h.006c7.35-.01 14.694.357 21.723 1.094 8.93-9.747 16.137-9.73 24.25-9.746h.014l-.002-.01c3.833 0 19.166 0 29.85 30.007L210 165.244c8.504 30.624-2.723 31.373-16.727 31.4-20.768-.773-32.267-15.855-32.267-30.935-11.496 1.884-24.907 2.826-38.318 2.827h-.006c-13.412 0-26.823-.943-38.318-2.827 0 15.08-11.5 30.162-32.267 30.935-14.004-.027-25.23-.775-16.726-31.4L46.85 124.08c10.684-30.007 26.017-30.007 29.85-30.007zm45.985 23.582v.006c-.02.02-21.863 20.08-25.79 27.215l14.304-.573v12.474c0 .584 5.74.346 11.486.08h.006c5.744.266 11.485.504 11.485-.08v-12.474l14.304.573c-3.928-7.135-25.79-27.215-25.79-27.215v-.006l-.003.002z"></path></svg></a><p><a href="https://itch.io/">itch.io</a><span>·</span><a href="https://browser-games.itch.io/">View all by browser games</a><span>·</span>Report<span>·</span>Embed<span>·</span></p><p>Updated <abbr title="08 January 2021 @ 18:16"> 3 days ago</abbr></p><div><p><a href="https://itch.io/games">Games</a> › <a href="https://itch.io/games/genre-rpg">Role Playing</a> › <a href="https://itch.io/games/free">Free</a></p></div></div></div></div></div>]]>
            </description>
            <link>https://browser-games.itch.io/baldursgate2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687261</guid>
            <pubDate>Fri, 08 Jan 2021 17:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a three-player chess website]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25687228">thread link</a>) | @Smlep
<br/>
January 8, 2021 | https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html | <a href="https://web.archive.org/web/*/https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="context">Context</h2>

<p>Around the end of 2019, as we were going through our few last months of
engineering school, we ended up having a quite consequent amount of free
time due to the highly irregular organisation of courses throughout the year.</p>

<p>Daniel, a friend of mine from school who has
been a huge fan of chess for a while now told us one night about how he read 
about this chess variant with three players and how he thought it would be
interesting to build a game engine for it.</p>

<p>Since I had time to <del>waste</del> spend building something <del>funny</del> meaningful,
I was interested in getting involved in this project to make it grow and be
something more than only a game engine (which I thought nobody would use
anyway, since playing chess through command line on a single computer does not
seem that appealing).</p>

<p>That’s how, Daniel, Vincent (another friend from school with whom I had
worked on many side projects), and I decided that we were going to build a
website so that people could come and play chess with two of their
friends.</p>

<h2 id="what-is-three-player-chess">What is three-player chess?</h2>

<p>Some might wonder what really is 3-player chess, do the rules change
when introducing a third player, and if they do, how?</p>

<p>Even though 3-player chess seems like a simple and precise concept, there are many variations
with light differences and not one set of rules for 3-player chess. These different
variations come in variants with different names (Trichess, Chess for three, Three-Player
Chess, Yalta chess…) but not every mention of one variant describes the same rules and
there is a huge lack of norm here.</p>

<p>The variation of chess played on <a href="https://yalta-chess.com/">yalta-chess.com</a> can be
considered as a unique variant, but mostly inspired by <strong>Yalta Chess</strong> (not much suspense
here) from which we tried to follow the rules as much as possible, but once again, the rules
differed depending on the articles.</p>

<p>On our website, you’ll play on a 96-cell board (32 for each player, just like usual chess).</p>

<p><img src="https://smlep.github.io/assets/yalta-animation4.gif" alt="Yalta board"></p>

<p>The moves are the same as classic chess, but it can take some time to get used to the
moves around the center or the board when starting to play <strong>Yalta Chess</strong>. The only real difference
with 2-player chess is how winners and losers are handled.</p>

<p>The winner is the first player to checkmate another player, meaning that there are one
winner and two losers. This makes the game more interesting, rewarding aggressive strategies
since playing too defensive might end up in a loss where one of the other players checkmated
the third player.</p>

<h2 id="early-development">Early development</h2>

<p>Our initial goal was pretty simple and seemed easy to accomplish, the
tasks which needed to be done could have been summed up as:</p>

<ul>
  <li>Building a game engine, implementing every rule and move.</li>
  <li>Having a game page on which 3 players could play together with a decent user
experience.</li>
  <li>Having a basic matchmaking system, so that players could join games easily.</li>
</ul>

<p>It looked easy and fast, the game engine was the main challenge since the special
shape of the board made the classic 2-player chess implementation unsuitable for
our needs and we needed to come up with a smart way to handle the board. Once the
game engine was out of the way, the only remaining thing would be to build a simple
website with basic functionalities.</p>

<p>Two of us already had some web development knowledge which we acquired through previous
side-projects, I would not say that we were <strong>amazing</strong> (or good) web developers,
but we were at least decent. Well, for the backend at least, our UI/UX level was (and
still is, but those who saw the website already know that) pretty bad.</p>

<p>Since we weren’t looking for high performances in our game engine because a few
milliseconds were not going to impact the user experience, building the engine was
actually pretty fast. One of us focused on it, and after a few days we had a game engine
implementing the rules and about everything we needed except <em>promotions</em>, <em>castling</em>, and
<em>en passant</em> which came later.</p>

<p>Our implementation relied on the fact that instead of using one 8x8 board as in 2-player
chess, we considered the board as 3 distinct 4x8 sub-boards, each sub-board filled with a
different color on the example below: 
<img src="https://smlep.github.io/assets/yalta-subboards.png" alt="Yalta debug mode"></p>

<p>The website, on the other hand, was way more complicated than we anticipated, handling
concurrent plays with real-time information transfer between the players (without
refreshing after each move) and implementing a decent user experience was much more
challenging than we expected.</p>

<p>Our first playable version looked like this:</p>

<p><img src="https://smlep.github.io/assets/yalta-debug.gif" alt="Yalta debug mode"></p>

<p>With the three boards representing the three sides of the board as explained above.</p>

<p>This first version allowed us to check that our engine worked as intended, but
required us to refresh a page to see the other players’ moves and wasn’t very user friendly.</p>

<p>That’s when we really became aware that the website part of the project would require
an amount of work strongly higher than the game engine implementation.</p>

<h2 id="a-basic-project">A basic project</h2>

<p>The more we implemented new features on our website, the more features we thought about
which seemed to be required to have a decent user experience on the website. Some of these features
were not necessary but seemed like good ideas/interesting to implement so we implemented some of them
and the others were listed and put aside for later.</p>

<p>After a few weeks, we had a decent result for the play part of the website; three players could
play on the same page, moving by selecting a piece and moving it to its location and seeing the actions’
results in real-time.</p>

<p>Our first <em>matchmaking</em> system was fairly basic, there was a list of created games, and any player
could join any game, if the user was the third player to join a game, it would start, and if there were
3 players already in the game, the user would be considered as a spectator. On top of that, any user
could create a new game.</p>

<p>At this time we had already spent way more time on this project than we thought we were going to,
even though we had only implemented the features we thought were necessary to have a good time
playing the game. The website’s current state was enough to send the link to some friends and play
games with them if we wanted to, the global design of the website wasn’t nice, but playing stayed pretty intuitive.</p>

<p><img src="https://smlep.github.io/assets/yalta-landing-1.png" alt="Landing page"></p>

<h2 id="not-so-basic-anymore">Not so basic anymore</h2>

<p>When we started this project, we did not define the real scope of users who would use it,
the more we worked on it and the more features we started implementing, the more we started to
want to make it public so that everyone could come and play.</p>

<p>As we started having less free time due to school projects and then the real jobs we got
after graduating, we spent way less time developing this project the following months but we kept working
on it and added a lot of new sfeature. Some of those being necessary for a public release,
some that we felt were a really nice addition for users and some which might just be
really useless (Hello, in-game chat). Among these extra-features are:</p>

<ul>
  <li>A custom game system to play with friends with custom settings</li>
  <li>A public queue system to play with random unknown players</li>
  <li>A training mode to play against bots in different difficulties</li>
  <li>A profile system with ranks, elo, skins, themes, and statistics</li>
  <li>Game timers</li>
  <li>A board rotation system, to see the board as one of your opponents</li>
  <li>An in-game chat</li>
  <li>The possibility to show replays of games</li>
  <li>A documentation section to explain the website and the game rules</li>
  <li>A landing page to explain to new users what happens here</li>
  <li>A new implementation of the game engine with improved performances
and a graph system (replacing the 3x4x8 sub-boards implementation)</li>
</ul>

<p>And of course, a landing page to welcome new players to our website.
The old matchmaking system based on a game list was removed, since the public
queue and private game system fully replaced the need for it.</p>

<p><img src="https://smlep.github.io/assets/yalta-ways-to-play.png" alt="Ways to play"></p>

<h2 id="costs-and-revenues">Costs and revenues</h2>

<p>As we added new features and new services which started to increase potential costs, we had to
consider the <em>business</em> aspect of the website. We were not fully against trying to monetize it but
we did not want this to impact the user experience, driving potential users away because of
<em>aggressive advertising</em> or <em>pay-to-win</em> systems.</p>

<p>We considered <strong>ads</strong>, but generic ads (such as adsense) would require to have a huge 
amount of traffic to really generate money and they usually don’t fit well into a website. We did
not want our website to get significantly less enjoyable for users just to win a few euros every month (or year).</p>

<!--
Another thing we considered was to bring premium content to the website, allowing users to purchase
differents assets such as skin. The issue with this solution is that it is really hard to find good
content which will not impact the other users impact experience.
We did implement a skin system, so that players could update the apparences of their pieces, so that
we could set up a system where the users would be able to buy these apparences. But the impact on the
other players which were just trying to focus would be too high, who wants to start a game and be
matched again a player with flashy purple pieces?
There are options to prevent this scenario such as adding a button to hide every opponents skin, but
players won't buy skins if the other players can't see it.
-->

<p>We considered some other solutions than ads but in the end, <strong>we did not find an adequate business model</strong>.
Not being able to generate revenue is not currently an issue, since the goal never was to quit our jobs and
start working on this project every day of the week. Nevertheless, we did not anticipate when we started this
project (before we decided to add many unexpected features) that there were gonna be real costs to run
the website.</p>

<p>Indeed, the website now runs using many different services and tools which come with a cost, meaning
that we cannot sustain with this business model (which is not one, since we generate no revenue) if
our user count grows too much.</p>

<p>As long as our monthly costs stay under a few dozen of euros, it is
fine, I’d say that we are happy to pay for it if some people are happy to play on
<a href="https://www.yalta-chess.com/">yalta-chess.com</a>. But if this website became too popular, we would have
to scale up the different services we pay for (hosting, Redis, database…), resulting in hundreds of
euros bills.</p>

<p>Hence, if too many people end up enjoying our website, at some point we will have to <strong>shut it
down</strong> (or strongly restrict traffic) if we still cannot generate revenue.</p>

<p>This is really <strong>unlikely</strong> to happen since we don’t plan on doing real advertising for this project,
and we are not so presumptuous as to think that this website is good enough to deserve this much 
success. But we still have to consider this scenario, and if it happens we will still try to consider
ways to generate revenue, we are not fully closed to ads, but we feel like right now nothing …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html">https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html</a></em></p>]]>
            </description>
            <link>https://smlep.github.io/jekyll/update/2020/12/26/yaltachess.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687228</guid>
            <pubDate>Fri, 08 Jan 2021 17:34:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Beam for Search: Getting Started by Hacking Time]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25686936">thread link</a>) | @clandry94
<br/>
January 8, 2021 | https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time | <a href="https://web.archive.org/web/*/https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>To create relevant search, processing clickstream data is key: you frequently want to promote search results that are being clicked on and purchased, and demote those things users don’t love.</p>
<p>Typically search systems think of processing clickstream data as a batch job run over historical data, perhaps using a system like Spark. But on Shopify’s Discovery team, we ask the question: What if we could auto-tune relevance in real-time as users interact with search results—not having to wait days for a large batch job to run?</p>
<p>At Shopify—this is what we’re doing! We’re using streaming data processing systems that can process both real-time and historic data to enable real-time use cases ranging from simple auto boosting or down boosting of documents, to computing aggregate click popularity statistics, building <a href="https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/core-concepts.html#judgments-expression-of-the-ideal-ordering" target="_blank" rel="nofollow noopener noreferrer">offline search evaluation sets</a>, and on to more complex reinforcement learning tasks.</p>
<p>But this article is introducing you to the streaming system themselves. In particular, to Apache Beam. And the most important thing to think about is <em>time</em> with those streaming systems. So let’s get started!</p>
<h2>What Exactly is Apache Beam?</h2>
<p><a href="https://beam.apache.org/" target="_blank" title="Apache Beam" rel="nofollow noopener noreferrer">Apache Beam</a> is a unified batch and stream processing system. This lets us potentially unify historic and real-time views of user search behaviors in one system. Instead of a batch system, like Spark, to churn over months of old data, and a separate streaming system, like Apache Storm, to process the live user traffic, Beam hopes to keep these workflows together.</p>
<p>For search, this is rather exciting. It means we can build search systems that both rely on historic search logs while perhaps being able to live-tune the system for our users’ needs in various ways.</p>
<p>Let’s walk through an early challenge everyone faces with Beam: that of <strong><em>time!</em></strong> Beam is a kind of time machine that has to reorder events in their right spot after getting annoyingly delayed by lots of intermediate processing and storage step. This is one of the core complications of a streaming system - how long do we wait? How do we deal with late or out of order data?</p>
<p>So to get started with Beam, the first thing you’ll need to do is Hack Time!</p>
<h2>The Beam Time Problem</h2>
<p>At the core of Apache Beam are <a href="https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline" target="_blank" rel="nofollow noopener noreferrer">pipelines</a>. They connect a source through various processing steps to finally a sink.&nbsp;&nbsp;</p>
<p>Data flowing through a pipeline is timestamped. When you consider a streaming system, this makes sense. We have various delays as events flow from browsers, through APIs, and other data systems. Finally the events arrive at our Beam pipeline. They can easily be out-of-order or delayed. Beam source APIs, like the one for <a href="https://beam.apache.org/releases/javadoc/2.5.0/org/apache/beam/sdk/io/kafka/KafkaIO.html" target="_blank" rel="nofollow noopener noreferrer">Kafka</a>, maintain a moving view of the event data to emit well-ordered events known as a <a href="https://beam.apache.org/documentation/programming-guide/#watermarks-and-late-data" target="_blank" rel="nofollow noopener noreferrer">watermark</a>.</p>
<p>If we don’t give our Beam source good information on how to build a timestamp, we’ll drop events or receive them in the wrong order. But even more importantly for search, we likely must combine different streams of data to build a single view on a search session or query, like below:</p>
<figure><img alt="combine different streams of data to build a single view on a search session or query, like below" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718"></figure>
<p>Joining (a Beam topic for another day!) needs to look back over each source’s watermark and ensure they’re aligned in time before deciding that sufficient time has elapsed before moving on. But before you get to the complexities of streaming joins, replaying with accurate timestamps is the first milestone on your Beam-for-clickstream journey.</p>
<h2>Configuring the Timestamp Right at the Source</h2>
<p>Let’s set up a simple Beam pipeline to explore Beam. Here we’ll use Kafka in Java as an example. You can see the full source code <a href="https://gist.github.com/geekigirl/738ead73033ae673483ab9690452f10f" target="_blank" title="Timestamp policy example with Kafka source with Apache BEAM" rel="nofollow noopener noreferrer">in this gist</a>.</p>
<p>Here we’ll set up a Kafka source, the start of a pipeline producing a custom SearchQueryEvent stored in a search_queries_topic.</p>

<p>You’ll notice we have information on the topic/servers to retrieve the data, along with how to deserialize the underlying binary data. We might add further processing steps to transform or process our SearchQueryEvents, eventually sending the final output to another system.</p>
<p>But nothing about <strong>time</strong> yet. By default, the produced SearchQueryEvents will use Kafka <em>processing</em> time. That is, when they’re read from Kafka. This is the least interesting for our purposes. We care about when users actually searched and clicked on results.</p>
<p>More interesting is when the event was created in a Kafka client. Which we can add here:</p>
<p><code>.withCreateTime(Duration.<em>standardMinutes</em>(5))</code></p>
<p>You’ll notice above, when we use create time below, we need to give the source’s Watermark a tip for how out of order event times might be. For example, below we instruct the Kafka source to use create time, but with a possible 5 minutes of discrepancy.&nbsp;</p>
<h2>Appreciating The Beam Time Machine</h2>
<p>Let’s reflect on what such a 5 minute possible delay actually means from the last snippet. Beam is kind of a time machine… How Beam bends space-time is where your mind can begin to hurt.</p>
<p>As you might be picking up, <em>event time </em>&nbsp;is quite different from <em>processing time</em>! So in the code snippet above, we’re *not* telling the computer to wait for 5 minutes of execution time for more data. No, the event time might be replayed from historical data, where 5 minutes of event time is replayed through our pipeline in mere milliseconds. Or it could be event time is really now, and we’re actively streaming live data for processing. So we DO indeed wait 5 real minutes!&nbsp;</p>
<p>Let’s take a step back and use a silly example to understand this. It’s really crucial to your Beam journey.&nbsp;</p>
<p>Imagine we’re super-robot androids that can watch a movie at 1000X speed. Maybe like Star Trek The Next Generation’s Lt Commander Data. If you’re unfamiliar, he could process input as fast as a screen could display! Data might say “Hey look, I want to watch the classic 80s movie, The Goonies, so I can be a cultural reference for the crew of the Enterprise.”&nbsp;</p>
<p>Beam is like watching a movie in super-fast forward mode with chunks of the video appearing possibly delayed or out of order relative to other chunks in movie time. In this context we have two senses of time:</p>
<ul>
<li>Event Time: the timestamp in the actual 1h 55 minute runtime of The Goonies aka movie time.</li>
<li>Processing Time: the time we actually experience The Goonies (perhaps just a few minutes if we’re super-robot androids like Data).</li>
</ul>
<p>So Data tells the Enterprise computer “Look, play me The Goonies as fast as you can recall it from your memory banks.” And the computer has various hiccups where certain frames of the movie aren’t quite getting to Data’s screen to keep the movie in order.&nbsp;</p>
<p>Commander Data can tolerate missing these frames. So Data says “Look, don’t wait more than 5 minutes in *movie time* (aka event time) before just showing me what you have so far of that part of the movie. This lets Data watch the full movie in a short amount of time, dropping a tolerable number of movie frames.</p>
<p>This is just what Beam is doing with our search query data. Sometimes it’s replaying days worth of historic search data in milliseconds, and other times we’re streaming live data where we truly must wait 5 minutes for reality to be processed. Of course, the right delay might not be 5 minutes, it might be something else appropriate to our needs.&nbsp;</p>
<p>Beam has other primitives such as <a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/transforms/windowing/Window.html" target="_blank" rel="nofollow noopener noreferrer">windows</a> which further inform, beyond the source, how data should be buffered or collected in units of time. Should we collect our search data in daily windows? Should we tolerate late data? What does subsequent processing expect to work over? Windows also work with the same time machine concepts that must be appreciated deeply to work with Beam.</p>
<h2>Incorporating A Timestamp Policy</h2>
<p>Beam might know a little about Kafka, but it really doesn’t know anything about <strong>our</strong> data model. Sometimes we need even more control over the definition of time in the Beam time machine.</p>
<p>For example, in our previous movie example, movie frames perhaps have some field informing us of how they should be arranged in movie time. If we examine our SearchQueryEvent, we also see a specific timestamp embedded in the data itself:</p>
<p><code>public class SearchQueryEvent {</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final String queryString;</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final Instant searchTimestamp;</code></p>
<p><code>…</code></p>
<p><code>}</code></p>
<p>Well Beam sources can often be configured to use a custom event time like our searchTimestamp. We just need to make a TimestampPolicy. We simply provide a simple function-class that takes in our record (A key-value of Long-&gt;SearchQueryEvent) and returns a timestamp:</p>

<p>We can use this to create our own timestamp policy:</p>

<p>Here, we’ve passed in our own function, and we’ve given the same allowed delay (5 minutes). This is all wrapped up in a factory class TimestampPolicyFactory SearchQueryTimestampPolicyFactory (now if that doesn’t sound like a Java class name, I don’t know what does ;) )</p>
<p>We can add our timestamp policy to the builder:</p>
<p><code>.withTimestampPolicyFactory(new SearchQueryTimestampPolicyFactory())</code></p>
<h2>Hacking Time!</h2>
<p>Beam is about hacking time, I hope you’ve appreciated this walkthrough of some of Beam’s capabilities. If you’re interested in joining me on building Shopify’s future in search and discovery, please check out these great job postings!</p>
<p>Doug Turnbull is a Sr. Staff Engineer in Search Relevance at Shopify. He is known for writing the book “Relevant Search”, contributing to “AI Powered Search”, and creating relevance tooling for Solr and Elasticsearch like Splainer, Quepid, and the Elasticsearch Learning to Rank plugin. Doug’s team at Shopify helps Merchants make their products and brands more discoverable. If you’d like to work with Doug, send him a Tweet at <a href="https://twitter.com/softwaredoug" target="_blank" title="Doug Turnbull on Twitter" rel="nofollow noopener noreferrer">@softwaredoug</a>!</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686936</guid>
            <pubDate>Fri, 08 Jan 2021 17:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yeti Foods is a Facebook-Free business]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25686437">thread link</a>) | @shafyy
<br/>
January 8, 2021 | https://blog.yeticheese.com/yeti-is-a-facebook-free-business/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/yeti-is-a-facebook-free-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Yeti will not use any of Facebook's products from today onwards.</p><p>Why?</p><p>Facebook controls some of the most used apps such as WhatsApp, Instagram, Messenger, and of course, Facebook. They have shown time over time that they don't care about their users' privacy and are willing to do anything to maximize their stronghold and power.</p><p>It's clear that consumers and society always lose when one company becomes too big. That's why there are monopoly and anti-trust laws that try to prevent and regulate such cases.</p><p>Tech companies such as Facebook and Google have new business models and therefore have managed to evade those laws. Luckily, this is changing, as governments are introducing more laws that aim at breaking up and regulating these companies to protect consumers.</p><p>But we can't only rely on our governments to take action. Every single consumer's decisions also matter. If enough people stop using Facebook's products, their power will diminish.</p><p>This is easier said than done, because these products have network effects. That means that the value of the product to the user increases exponentially for every additional user. For example, you wouldn't use WhatsApp if none of your friends were on it. At the same time, it's much harder for you to switch to a different messaging app like Signal because you need to convince all your friends to join, too.</p><p>It's hard but not impossible.</p><p>From today onwards, we pledge that Yeti will not use any products by Facebook. As stated in <a href="https://m.signalvnoise.com/become-a-facebook-free-business/">Basecamp's blog post</a>, which inspired our decision, this means:</p><ol><li>We do not buy advertisement on Facebook, Messenger, Instagram, or WhatsApp.</li><li>We do not use Facebook, Messenger, Instagram, or WhatsApp to promote or represent our business or to communicate with our customers.</li><li>We do not assist Facebook in its data collection regime through use of Facebook social Like buttons or by offering Facebook logins.</li></ol><p>This was not an easy decision. For example, Instagram and Facebook are important platform for us to stay in touch with current and prospective consumers. It's clear that by taking this decision, we will lose customers and money. However, it is the right thing to do and this is something that's more important than financial success.</p><p>As a customer, you can be assured that none of the money you spend with us goes to Facebook.</p><p>Now, go and <a href="https://yeticheese.com/product/yeti-no-1">buy our cheese</a> so we can make up for the lost revenue 😝</p>
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/yeti-is-a-facebook-free-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686437</guid>
            <pubDate>Fri, 08 Jan 2021 16:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India could get nasal vaccine against Covid-19 soon]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25685187">thread link</a>) | @jangid
<br/>
January 8, 2021 | https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07 | <a href="https://web.archive.org/web/*/https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>A nasal Covid-19 vaccine could be a reality in India soon with Bharat Biotech, the Indian vaccine maker, all set to start phase 1 and 2 trials of a nasal vaccine at Gillurkar Multi Speciality Hospital in Nagpur.</p><p>Bharat Biotech’s head Dr Krishna Ella said on Thursday, "We are working on a nasal vaccine and have partnered with the Washington University School of Medicine. We are working on a single dose vaccine compare to two-dose inactivated vaccine. Research has proven that the nasal vaccine is the best choice. Coronavirus also attacks through the nose."</p><p>"We are <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank">all set to host the trials for the nasal Covaxin in the next two weeks</a>. Enough scientific evidence is available that vaccines given through nasal route are more effective than injected ones. Bharat Biotech is in the process to submit a proposal to the DCGI shortly," said Dr Chandrashekar Gillurkar.</p><p>The trials will be conducted on at least 30-45 healthy volunteers above the age of 18 till the age of 65 years at four trial sites in the country -- Bhuvneshwar, Pune, Nagpur and Hyderabad.</p><p>Presently, Bharat Biotech is working on two intranasal vaccines -- one with US-based vaccine maker FluGen and scientists from the University of Wisconsin Madison and the other with the University of Washington School of Medicine.</p><p>Experts say that the nasal variant of the Covid-19 vaccine, which is currently under trial in the US, could play a major role in stopping transmission of the virus.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/confused-about-covid-19-vaccines-this-is-for-you-1756786-2021-01-07" target="_blank" title="Confused about Covid-19 vaccines? This is for you">Confused about Covid-19 vaccines? This is for you</a></strong></em></p><h3><span><strong>WHAT IS NASAL VACCINE?</strong></span></h3><p>Unlike other Covid-19 vaccines that are administered intramuscularly (or through the muscles), this one is delivered via the nose, which is also an initial point of infection in humans.</p><p>A study done by the University of Washington School of Medicine in St Louis found that the nasal delivery route created a strong immune response throughout the body, but it was particularly effective in the nose and respiratory tract, preventing the infection from taking hold in the body.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07" target="_blank" title="Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></em></p><h3><span><strong>ARE NASAL VACCINES BETTER THAN INJECTIONS?</strong></span></h3><p>Experts say the nasal Covid-19 vaccine has the potential to become a game-changer because injecting the vaccine intramuscularly only protects the lower lung. A nasal vaccine can protect both the upper and lower lung and can prevent transmission of the virus as well as an infection.</p><p>Dr Samiran Panda, senior epidemiologist at Indian Council of Medical Research said nasal vaccine provides benefits such as faster absorption, lesser volume and no use of syringes.</p><p> <img data-src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" alt=""></p><p>"There are two arms of the immune system in the body - one is antibody or protein and one is cellular immunity. <a href="https://www.indiatoday.in/coronavirus-outbreak/story/mucosal-immunity-prevent-covid-outbreak-1745369-2020-11-30" target="_blank">The mucosal immunity is created</a> when administered a nasal vaccine against those infections that enter our body through the nose or respiratory tract. Coronavirus impacts the respiratory tract the most. Therefore, the nasal vaccine is much better. Antibodies will be secreted directly into the nasal mucous membrane, where you need more concentration of the antibody because it is where the infection begins from."</p><p><strong>Faster absorption:</strong></p><p>When administered orally or nasally, the antigen is presented to the mucous membrane, the absorption is much better and it quickly goes to the lymph nodes. There is an effective presentation of the viral antigen directed at the infection.</p><p><strong>Lesser volume:</strong></p><p>Earlier rabies vaccine used to be given in the subcutaneous fat and now is being given intra-dermal injection route (through the skin). A similar immune response can be generated with a much smaller dose.</p><h3><span><strong>INTERNATIONAL TRIALS</strong></span></h3><p>An influenza vaccine called FLUmist, delivered via the nose, uses the weakend form of live influenza virus but can’t be administered to certain groups including those whose immune systems are compromised by cancer, HIV and diabetes.</p><p>In contrast, the new coronavirus intranasal vaccine does not use a live virus capable of replication, presumably making it safer.</p><p>The United Kingdom's Medicines and Healthcare Products Regulatory Agency (MHRA), has approved Open Orphan and Codagenix to conduct a phase 1 study of its nasal Covid-19 vaccine in the country.</p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank" title="Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine">Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/video/covishield-covaxin-vaccines-will-be-available-in-india-soon-health-minister-harsh-vardhan-1756772-2021-01-07">Covishield, Covaxin vaccines will be available in India soon: Health minister Harsh Vardhan</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></p></div></div>]]>
            </description>
            <link>https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07</link>
            <guid isPermaLink="false">hacker-news-small-sites-25685187</guid>
            <pubDate>Fri, 08 Jan 2021 14:45:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing Clean Code. A function main role is avoid duplicated code? No, it's more]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25684158">thread link</a>) | @relu_mesaros
<br/>
January 8, 2021 | https://flawless-bits.com/blog/clean-code-functions-and-methods | <a href="https://web.archive.org/web/*/https://flawless-bits.com/blog/clean-code-functions-and-methods">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://flawless-bits.com/blog/clean-code-functions-and-methods</link>
            <guid isPermaLink="false">hacker-news-small-sites-25684158</guid>
            <pubDate>Fri, 08 Jan 2021 12:54:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: A lean HTML editor with instant preview]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25683798">thread link</a>) | @mg
<br/>
January 8, 2021 | https://no-gravity.github.io/html_editor/ | <a href="https://web.archive.org/web/*/https://no-gravity.github.io/html_editor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://no-gravity.github.io/html_editor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25683798</guid>
            <pubDate>Fri, 08 Jan 2021 12:06:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Where is the “average” person in each US state?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25682905">thread link</a>) | @marwahaha
<br/>
January 8, 2021 | https://marwahaha.github.io/ca-center/viewer | <a href="https://web.archive.org/web/*/https://marwahaha.github.io/ca-center/viewer">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://marwahaha.github.io/ca-center/viewer</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682905</guid>
            <pubDate>Fri, 08 Jan 2021 09:00:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: That Dothraki Horde, Part IV: Screamers and Howlers]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25682359">thread link</a>) | @Illniyar
<br/>
January 7, 2021 | https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the fourth part of a four part (<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">I</a>, <a href="https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">II</a>, <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">III</a>) look at the Dothraki from George R. R. Martin’s <em>A Song of Ice and Fire</em> and HBO’s <em>Game of Thrones</em>.  We’re looking at, in particular, if Martin’s claim that the Dothraki are “an amalgam of a number of steppe and plains cultures” can be sustained in the face of even basic knowledge about historical Steppe and Great Plains nomadic peoples.</p>



<p>Last week, we <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">concluded </a>that the vast majority of Dothraki culture, social organization, economic practices and family structure are effectively completely untethered from the historical realities of effectively any of the literally dozens of historical Great Plains Native Americans or Steppe nomads.  This week, we’re going to close out our look by discussing Dothraki warfare.  We’ll start with the visual – weapons and armor – and then move to the conceptual – strategy, operations and tactics.</p>



<p>And as always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>Finally, as a reminder both of what we are investigating, <strong>the key statement we are really assessing here is <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">this one by George R.R. Martin</a>:</strong></p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also Alans, Sioux, Cheyenne, and various other Amerindian tribes… seasoned with a dash of pure fantasy.</p></blockquote>



<p>It is not the <em>existence</em> of a fantasy culture which draws our attention, but the explicit declaration that this fantasy culture is not merely inspired, but ‘fashioned as an amalgam’ of real cultures, which both existed in the past <em>and still exist today</em>, with only ‘a dash of pure fantasy.’  That line is important, to be clear, <strong>because it presents the fictional Dothraki as a statement on historical Native American and Eurasian nomads</strong> and – when combined with Martin’s statements that he relies on history to inform his work – that this statement is based in some sort of historical reality.</p>



<p>Which it isn’t.  But we’re getting ahead of ourselves.</p>



<h2>Where There’s a Whip…</h2>



<p>The Dothraki are described as having three main weapons: <strong>bows </strong>(<em>AGoT</em>, 86, 555, 558, 597, 669), <strong>whips </strong>(<em>AGoT</em>, 86, 194, 493, 555, 596, 669) and a <strong>curved sword called an <em>arakh</em></strong> (<em>AGoT</em> 85, 86, 327, 493, 555, 556, 559, 560, 596, 597, 669, 674); <strong>of these, the <em>arakh</em> is clearly the most prominent</strong> (I am sure I have missed a reference to a weapon here or there, but I hope the citations here give some sense of the relative weight each is given – the <em>arakh</em> is the most frequently mentioned by some distance).  When a Dothraki warrior enters <em>Vaes Dothrak</em>, each, “unbelted his <em>arakh</em> and handed it to a waiting slave, and any other weapons he carried as well” – after the <em>arakh</em>, the other weapons are seemingly afterthoughts (<em>AGoT</em>, 327).  The prominence of the <em>arakh</em> in the narrative is underscored by the fact that it is the only one of these weapons whose name we learn in Dothraki, or which is described in terms of its shape or special function (<em>AGoT</em>, 85), while the bows and whips remain just bows and whips (ironic, as it was Steppe <em>bows</em>, not Steppe swords, which were unusual).</p>



<p>We might dismiss this as simply an accident of Daenerys’ perspective – that, being Westerosi, she focuses on the weapon most meaningful to the Westerosi – but that’s clearly not true.  After all, the <strong>offering of an <em>arakh</em> is how Daenerys’ loyal followers demonstrate their fealty to her</strong>, in a ceremony that is clearly Dothraki, not Westerosi (<em>AGoT</em>, 674).  It is also, I should note,<a href="https://awoiaf.westeros.org/index.php/Arakh"> the only weapon we see <em>non</em>-Dothraki using that is clearly identified as being foreign and typical of the Dothraki</a>.  It remains special through the eyes of multiple point-of-view characters, including military men.</p>



<p>(And, as an aside, now that we are this far in, it seems obvious but worth saying that the fact that Martin has no Dothraki viewpoint characters in his narrative is hardly a saving grace; it merely intensifies the ‘view of a savage culture from outside’ effect.  As we’ll see, this makes perfect sense given what seem to be the actual inspirations for his depiction.)</p>



<p><strong>The prominence of a curved iron (or steel) sword lets us rule out a Great Plains Native American inspiration for this kit right out</strong>; the sword was never a significant part of Plains Native American armament (the lack of tool-metal production in the Americas prior to European contact means that there was no indigenous sword-making tradition, although the <a href="https://en.wikipedia.org/wiki/Macuahuitl"><em>maquahuitl</em> </a>represents a clever sort of ‘sharpened club’ design).  Even after contact, it’s hard to avoid the conclusion that the expense of trading for a sword wouldn’t have been justified by its utility over a steel axe which might also double as a tool (on axes, see W. Lee, “The Military Revolution of Native North America: Firearms, Forts and Politics” in <em>Empires and Indigenes</em> (2011), 62-3).  <strong>So we must turn to the Eurasian Steppe</strong>.</p>



<p><strong>And immediately we run into problems</strong>, not that any of these weapons are <em>wrong</em> per se, but <strong>that their proportion and prominence is all mixed up and that there are other, far more important weapons missing.</strong></p>



<p><strong>For a Steppe nomad, by far, above and away, the most important weapon was the bow.</strong>  The Armenians literally called the Mongols “the nation of archers” (May, <em>Mongol Art of War</em>, 43).  Nomads spent the most time learning the bow (May, <em>op. cit.</em> 42-49) and it was the one indispensable weapon.  Indeed, so indispensable that nomads were generally required to have several; the <em>Liao Shi</em> records that Khitan nomad warriors were required to possess four bows and 400 arrows, while John de Plano Carpini reports that the Mongols all needed to have 2-3 bows and three larger quivers (May, <em>op. cit. </em>49-50).  <strong>The Steppe bow itself would also have looked unusual in both shape and construction</strong> to a Westerosi observer either strung or unstrung – they were composite bows, made with a wood core, a backing of horn and a rigid end-piece (called a <em>siyah</em> in Arabic) and were generally drawn with the use of a thumb-ring to reduce strain on the thumb (May, <em>op. cit.</em>, 50-1).  This unique construction allowed these bows to reach draw weights and launch energies equivalent to the far larger yew longbows of England and Wales and still be compact enough to use from horseback.</p>



<div><figure><img data-attachment-id="5819" data-permalink="https://acoup.blog/ilkhanidhorsearcher-2/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg" data-orig-size="450,350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ilkhanidhorsearcher" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" src="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg 450w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300 300w" sizes="(max-width: 450px) 100vw, 450px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:IlkhanidHorseArcher.jpg">Via Wikipedia</a>, a 13th century Mongol horse archer.  Lightly armored, he carries a bow (and a fancy hat) but no sword.</figcaption></figure></div>



<p>(I should note that the bow was <em>also</em> the paramount weapon for the Native American horse-borne nomads of the Great Plains, at least until it came into competition with firearms, though my understanding is that Native American bows were not as powerful as Steppe bows).</p>



<div><figure><img loading="lazy" data-attachment-id="5821" data-permalink="https://acoup.blog/minolta-dsc/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;DiMAGE A1&quot;,&quot;caption&quot;:&quot;Minolta DSC&quot;,&quot;created_timestamp&quot;:&quot;1118415959&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;12.91796875&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0003125&quot;,&quot;title&quot;:&quot;Minolta DSC&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Minolta DSC" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" src="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" alt="" width="596" height="795" srcset="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=596 596w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=1192 1192w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=113 113w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225 225w" sizes="(max-width: 596px) 100vw, 596px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Naadam_women_archery.jpg">Via Wikipedia</a>, a modern Mongolian woman taking part in an archery contest.  You can see here the unique shape and multi-part construction of the Steppe bow (notice how the material on the tips, the belly and the spine of the bow are all different) which allows it so much power in such a small frame.<br>Also, notice the very nice and colorful traditional Mongolian clothing – not leather and rough furs!</figcaption></figure></div>



<p><strong>But even after the bow, the sword is not first.  Or even close to first.</strong>  Or, indeed, <em>even on the list</em>!  The Khitan regulations I mentioned included four bows, two spears (one ‘long’ and one ‘short’), a club, an axe and a halberd, but no sword.  John de Plano Carpini describes the full kit as two or three bows with quivers, an axe, ropes, and swords <em>only for the wealthy</em> (May. <em>op. cit.</em>, 50).  Speaking more broadly, May notes that spears (used as lances from horseback) seem universal in accounts of the Mongols, but “accounts are contradictory regarding whether these [swords] were universally used” (May, <em>op. cit.</em>, 52).  While May supposes that the <em>ughurgh-a</em>, the Mongolian lasso, might have been used in combat – and it may well have – we have no definitive evidence of it.  If it was ever a weapon, it doesn’t seem to have been an important one.</p>



<p><strong>In short, while the Dothraki’s weapons are an <em>arakh</em>-sword, a whip, and a bow in that order, the Mongol’s chief weapons were his bow, followed by his backup bow, followed by his <em>other </em>backup bow, followed by his spear, and then his axe and only then followed by a sword, should he have one, which he might well not</strong>.  The reason for preferring an axe or a spear for the humble nomad should not be too surprising – iron in quantity could be hard to get on the Steppe.  Spears and axes are not only weapons, but also useful hunting and survival tools; swords are generally weapons only.  <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">Nomads generally cannot do their own metal working</a>, so swords would have to be imported.  Moreover, even in a melee, the first recourse would be to a spear, <a href="https://acoup.blog/2020/05/08/collections-the-battle-of-helms-deep-part-ii-total-warg/">whose reach on horseback was a huge advantage</a>,<strong> making a sword an expensive imported foreign luxury <em>backup</em> weapon with no additional utility</strong>.  Nevertheless, it’s clear that Steppe nomads, once successful and moving into agrarian areas, liked to acquire swords – swords are effective weapons! – but the sword was about the furthest thing from the core of Mongol culture the way the <em>arakh</em> is practically the <em>symbol</em> of Dothraki culture.</p>



<figure><img data-attachment-id="5816" data-permalink="https://acoup.blog/langshiming_mao/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg" data-orig-size="1920,1118" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="langshiming_mao" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Langshiming_mao.JPG">Via Wikipedia</a>, a relatively late Mongol soldier (c. 1755) nevertheless shows nearly the full kit, including mail body defense, a long spear for use on horseback, arrows (the bow in its bow-case would have been on the other side) and, this being the 1700s, a musket.</figcaption></figure>



<p><strong>The other issue, of course, is the <em>arakh</em> itself.</strong>  Martin describes the weapons as “long razor-sharp blades, half sword and half scythe” (<em>AGoT</em>, 85) and goes back to that scythe analogy (e.g. <em>ASoS</em>, 245).  It seems generally asserted that what Martin means by this is something close to a scimitar (I have to confess, I haven’t found anywhere that Martin says …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682359</guid>
            <pubDate>Fri, 08 Jan 2021 07:10:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 100 Scientists and Doctors Call for Increased Vitamin D to Combat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 110 (<a href="https://news.ycombinator.com/item?id=25680282">thread link</a>) | @kpfleger
<br/>
January 7, 2021 | https://vitamindforall.org/letter.html | <a href="https://web.archive.org/web/*/https://vitamindforall.org/letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>#VitaminDforAll </span><span>(for questions or fact checking assistance, contact press@vitaminDforAll.org)</span></p><p id="h.mjz6soj7f435"><span>Over 100 </span><span>Scientists, Doctors, &amp; Leading Authorities</span><span>&nbsp;Call For </span><span>Increased</span><span>&nbsp;Vitamin D Use To Combat COVID-19</span></p><p><span>[Residents of the USA: Text “VitaminDforAll” to 50409 to send this to your state’s governor.]</span></p><p><span>Research shows low vitamin D levels almost certainly promote COVID-19 infections, hospitalizations, and deaths. Given its safety, </span><span>w</span><span>e call for immediate widespread increased vitamin D intakes</span><span>.</span></p><p><span>Vitamin D modulates thousands of genes and many aspects of immune function, both innate and adaptive. The scientific evidence</span><span>1</span><span>&nbsp;shows that:</span></p><p><span>Vitamin D is well known to be essential, but most people do not get enough. Two common definitions of inadequacy are deficiency &lt; 20ng/ml (50nmol/L), the target of most governmental organizations, and insufficiency &lt; 30ng/ml (75nmol/L), the target of several medical societies &amp; experts.</span><span>2</span><span>&nbsp;Too many people have levels below these targets. </span><span>Rates of vitamin D deficiency &lt;20ng/ml exceed 33% of the population in most of the world, and most estimates of insufficiency &lt;30ng/ml are well over 50% (but much higher in many countries).</span><span>3</span><span>&nbsp;Rates are even higher in winter, and several groups have notably worse deficiency: the overweight, those with dark skin (especially far from the equator), and care home residents. These same groups face increased COVID-19 risk.</span></p><p><span>It has been shown that 3875 IU (97mcg) daily is required for 97.5% of people to reach 20ng/ml, and 6200 IU (155mcg) for 30ng/ml,</span><span>4</span><span>&nbsp;intakes far above all national guidelines. Unfortunately, the report that set the US RDA included an admitted statistical error in which required intake was calculated to be ~10x too low.</span><span>4</span><span>&nbsp;Numerous calls in the academic literature to raise official recommended intakes had not yet resulted in increases by the time SARS-CoV-2 arrived. Now, many papers indicate that vitamin D affects COVID-19 more strongly than most other health conditions, with increased risk at levels &lt; 30ng/ml (75nmol/L) and severely greater risk &lt; 20ng/ml (50nmol/L).</span><span>1</span></p><p><span>Evidence to date </span><span>suggests </span><span>the possibility that the COVID-19 pandemic sustains itself in large part &nbsp;through infection of those with low vitamin D, and that deaths are concentrated largely in those with deficiency. The mere possibility that this is so should compel urgent gathering of more vitamin D data. </span><span>Even without more data</span><span>, </span><span>the </span><span>preponderance </span><span>of evidence indicates that </span><span>increased vitamin D would help reduce infections, hospitalizations, ICU admissions, &amp; deaths</span><span>.</span></p><p><span>Decades of safety data show that vitamin D has very low risk: </span><span>Toxicity would be extremely rare with the recommendations here. The risk of insufficient levels far outweighs any risk from levels that seem to provide most of the protection against COVID-19, and this is notably different from drugs. Vitamin D is much safer than steroids, such as dexamethasone, the most widely accepted treatment to have also demonstrated a large COVID-19 benefit. Vitamin D’s safety is more like that of face masks. </span><span>There is no need to wait for further clinical trials to increase use of something so safe, </span><span>especially when remedying high rates of deficiency/insufficiency should already be a priority</span><span>.</span></p><p><span>Therefore, we call on all governments, doctors, and healthcare workers worldwide to immediately recommend and implement efforts appropriate to their adult populations to increase vitamin D, at least until the end of the pandemic. Specifically to:</span></p><p><span>Many factors are known to predispose individuals to higher risk from exposure to SARS-CoV-2, such as age, being male, comorbidities, etc., but </span><span>inadequate</span><span>&nbsp;v</span><span>itamin D is by far the most easily and quickly </span><span>modifiable</span><span>&nbsp;risk factor with abundant evidence to support a large effect</span><span>. Vitamin D is inexpensive and has negligible risk compared to the considerable risk of COVID-19.</span></p><p><span>5</span><span>&nbsp;The following include 4000 IU within their tolerable intakes in official guidelines: NAM (US, Canada), SACN (UK), EFSA (Europe), Endocrine Society (international), Nordic countries, The Netherlands, Australia &amp; New Zealand, UAE, and the American Geriatrics Soc. (USA, elderly). No major agency specifies a lower tolerable intake limit. The US NAM said 4000 IU “is likely to pose no risk of adverse health effects to almost all individuals.” See also [</span><span><a href="https://pubmed.ncbi.nlm.nih.gov/32180081/">Giustina et al ‘20</a></span><span>].</span></p><p><span>The signatories below endorse this letter. Affiliations do not imply endorsement of the letter by the institutions themselves.</span></p><p><span>This letter takes no position on other public health measures besides vitamin D. Personal views of individual signatories on any other matter do not represent the group as a whole.</span></p><p><span>All signatories declare no conflicts of interest except as noted.</span></p><p><span>To emphasize: </span><span>The organizing signatories have no conflicts of interest in this area (financial or otherwise)</span><span>, nor have they done research in this area prior to 2020.</span></p><div><tbody><tr><td colspan="1" rowspan="1"><p><span>Signatories (185)</span></p></td><td colspan="1" rowspan="1"><p><span>recom- mended intake</span></p></td><td colspan="1" rowspan="1"><p><span>personal daily intake</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Karl Pfleger</span><span>, PhD AI &amp; Computer Science, Stanford. Former Google Data Scientist. Biotechnology Investor, AgingBiotech.info, San Francisco, CA, USA. (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>7000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gareth Davies</span><span>, PhD Medical Physics, Imperial College, London, UK. Codex World’s Top 50 Innovator 2019. Independent Researcher. Lead author of “</span><span><a href="https://www.medrxiv.org/content/10.1101/2020.05.01.20087965v3">Evidence Supports a Causal Role for Vitamin D Status in COVID-19 Outcomes</a></span><span>.” (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Bruce W Hollis</span><span>, PhD. Professor of Pediatrics, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barbara J Boucher</span><span>, MD, FRCP (London). </span><span>Honorary Professor (Medicine), Blizard Institute, Bart's &amp; The London School of Medicine and Dentistry, Queen Mary University of London, UK. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Ashley Grossman</span><span>, MD FRCP FMedSci. Emeritus Professor of Endocrinology, University of Oxford, UK. Professor of Neuroendocrinology, Barts and the London School of Medicine. 2020 Endocrine Society Laureate Award.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2200 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gerry Schwalfenberg</span><span>, MD, CCFP, FCFP. Assistant Clinical Professor in Family Medicine, University of Alberta, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Giovanna Muscogiuri</span><span>, MD PhD. Associate Editor, European Journal of Clinical Nutrition. </span><span>Department of Clinical Medicine and Surgery, Section of Endocrinology, University "Federico II" of Naples, Naples, Italy.</span><span>.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>1000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Michael F. Holick</span><span>, PhD MD. Professor Medicine, Physiology and Biophysics and Molecular Medicine, Director Vitamin D, Skin and Bone Research Laboratory, Boston University Medical Center, USA. (6000 IU) </span><span>Disclosure: Consultant Biogena and speaker's Bureau Abbott Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. John Umhau</span><span>, MD, MPH. CDR, USPHS (ret). </span><span>President, Academy of Medicine of Washington, DC, USA. Ex-NIH: c</span><span>o-author of the first peer-reviewed report linking vitamin D deficiency with acute respiratory infection.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. </span><span>Pawel</span><span>&nbsp;</span><span>Pludowski</span><span>, MD, dr hab. Associate Professor, Biochemistry, Radioimmunology and Experimental Medicine, Children’s Memorial Health Institute, Warsaw, Poland. Chair, European Vitamin D Association (EVIDAS) [non-profit].</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Cedric F. Garland</span><span>, DrPH. Professor Emeritus, Department of Family Medicine and Public Health, University of California, San Diego, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Jose M. Benlloch</span><span>, Professor, Director of the Institute for Instrumentation on Molecular Imaging, CSIC-UPV, Valencia, Spain.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>3000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Samantha Kimball</span><span>, PhD, MLT. Professor, St. Mary's University, Calgary, Alberta, Canada. Research Director, GrassrootsHealth Nutrient Research Institute [non-profit].</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. William B. Grant</span><span>, PhD Physics, U. of California, Berkeley. Director at Sunlight, Nutrition, and Health Research Center [non-profit], San Francisco, CA, USA. </span><span>Disclosure: Receives funding from Bio-Tech Pharmacal, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5300 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Carol L. Wagner,</span><span>&nbsp;MD. Professor, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Paul Marik</span><span>, MD, FCCP, FCCM. </span><span>Chief of Pulmonary and Critical Care Medicine and Professor of Medicine</span><span>, Eastern Virginia Medical School, Norfolk, VA, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Morry Silberstein</span><span>, MD. Associate Professor, Curtin University, Australia.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Vatsal Thakkar</span><span>, MD. Founder, Reimbursify, NY, USA. &nbsp;Former faculty, NYU and Vanderbilt. &nbsp;Op-Ed writer on Vitamin D and COVID-19.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Peter H Cobbold</span><span>, PhD. Emeritus Professor, Cell Biology, University of Liverpool, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Afrozul Haq</span><span>, PhD. Professor Dept of Food Technology, Jamia Hamdard University, New Delhi, India.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barry H. Thompson</span><span>, MD, FAAP, FACMG. Clinical Associate Professor (Pediatrics), Uniformed Services University of the Health Sciences, Bethesda, MD, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Reinhold Vieth</span><span>, PhD, FCACB. Professor, Departments of Nutritional Sciences and Laboratory Medicine &amp; Pathobiology, University of Toronto, Canada. Director (retired), Bone and Mineral Group Laboratory, Mt Sinai Hospital. </span><span>Disclosure: </span><span>Receives patent royalties from Ddrops (an infant vitamin D supplement).</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Linda Benskin</span><span>, PhD, RN, SRN(Ghana), CWCN, CWS, DAPWCA. Independent Researcher for Tropical Developing Countries and Ferris Mfg. Corp, Texas, USA. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Jim O’Neill</span><span>, CEO, SENS Research Foundation. Former principal associate deputy secretary of Health and Human Services, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Eric Feigl-Ding</span><span>, PhD. Epidemiologist &amp; Health Economist. Senior Fellow, Federation of American Scientists. USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Rt Hon David Davis MP</span><span>, Member of Parliament (Conservative Party). BSc, Joint Hons Molecular Science / Computer Science, Warwick University, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Rupa Huq MP,</span><span>&nbsp;Member of Parliament (Labour Party). PhD, Cultural Studies, University of East London, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Susan J Whiting</span><span>, PhD. Professor Emerita, University of Saskatchewan, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Richard Mazess</span><span>. PhD. Emeritus Professor, University of Wisconsin, Madison, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Helga Rhein</span><span>, MD (retired). </span><span>Sighthill…</span></p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitamindforall.org/letter.html">https://vitamindforall.org/letter.html</a></em></p>]]>
            </description>
            <link>https://vitamindforall.org/letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680282</guid>
            <pubDate>Fri, 08 Jan 2021 01:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding instruction cache misses (2019)]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25680125">thread link</a>) | @nkurz
<br/>
January 7, 2021 | https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/ | <a href="https://web.archive.org/web/*/https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div role="main"><div><article><p>Modern processors are quite complex, with many parts having the potential to become a bottleneck. It is relatively easy to reason about the performance of short pieces of code, especially if memory effects are kept to a minimum. Both static analysis tools like LLVM MCA and microbenchmarks can provide a lot of information in such cases. However, the behaviour of the whole program is not just the sum of those small parts. As the code becomes larger and more complex other effects start appearing. One of such potential problems are excessive instruction cache misses.</p><p>Every program has different properties, and those large-scale effects will affect it differently. However, if its job is to execute complex logic on a small amount of data, the instruction cache is likely to become a problem at some point. The actual impact may vary significantly from codebase to codebase, which is why I won’t show any numbers in this article. Let’s consider this just a collection of ideas, but it is not easy to tell how much any of them will help for a given application.</p><p>First, let’s have a quick look at the processor front end. Below is a simplified diagram of how it is arranged in Skylake, the numbers between units are the maxima per cycle.</p><p><img loading="lazy" width="630" height="860" src="https://paweldziepak.dev/static/icache-front-end.min.2e73578fff.svg" alt="CPU front end"></p><p>Each cycle the processor fetches up to 16 bytes from the instruction cache using information from the Branch Prediction Unit to predict the control flow. The pre-decode unit determines instruction lengths and puts up to five of them in the Instruction Queue. From the Instruction Queue, up to 5 instructions (with macro-fusion) are brought each cycle to the decoders. There is one complex decoder that can handle instructions that translate to up to 4 µops and 3 simple decoders that can handle only single-µop instructions. In total, all decoders are limited to producing no more than 5 µops each cycle. Instructions that require more than 4 µops go through Microcode Sequence ROM, which emits 4 µops per cycle, and while it is active, the decoders are disabled. There is also Decoded ICache (<abbr title="Decoded Stream Buffer">DSB</abbr>) which caches decoded µops. It can emit up to 6 µops each cycle. All µops, regardless of their source, end up in the Instruction Decode Queue (IDQ). The Loop Stream Detector (LSD) detects small loops and keeps them in the queue, so that no fetched, decodes or reads from the DSB are needed during the duration of the loop. IDQ is the last part of the front end, and the queued µops continue to the back end.</p><p>From the instruction cache point of view, the front end has two weaknesses. Firstly, instructions are processed in-order which can severely limit the processor ability to hide latencies of cache misses. HyperThreading can make sure that this part of the processor still does some useful work, but it is also the source of the second problem – all resources, including the L1 instruction cache and µop cache are shared between the hardware threads.</p><p>Modern processors provide various metrics that help monitor their behaviour. However, the task of extracting the relevant data requires a proper approach if it is to be done efficiently. Top-down analysis is invaluable with helping to understand microarchitectural phenomena in large codebases. The idea is to monitor program behaviour with the <abbr title="Performance Monitoring Unit">PMU</abbr> counters and identify the bottleneck starting with the major functional parts of the CPU and then digging deeper narrowing down on the exact source of the problem. It can be done in an automated way by tools like VTune or toplev.</p><pre><code>FE    Frontend_Bound:                                      39.48 +-  0.00 % Slots
BE    Backend_Bound:                                       16.19 +-  0.00 % Slots
    This category represents fraction of slots where no uops are
    being delivered due to a lack of required resources for
    accepting new uops in the Backend...
FE    Frontend_Bound.Frontend_Latency:                     24.92 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Bandwidth:                   13.45 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Latency.ICache_Misses:       14.45 +-  0.00 % Clocks &lt;==
    This metric represents fraction of cycles the CPU was
    stalled due to instruction cache misses...
    Sampling events:  frontend_retired.l2_miss:pp frontend_retired.l1i_miss:pp
FE    Frontend_Bound.Frontend_Latency.ITLB_Misses:          8.71 +-  0.00 % Clocks
    This metric represents fraction of cycles the CPU was
    stalled due to instruction TLB misses...
    Sampling events:  frontend_retired.stlb_miss:pp frontend_retired.itlb_miss:pp
FE    Frontend_Bound.Frontend_Latency.Branch_Resteers:      8.42 +-  0.00 % Clocks_Est
    This metric represents fraction of cycles the CPU was
    stalled due to Branch Resteers...
    Sampling events:  br_misp_retired.all_branches:u
FE    Frontend_Bound.Frontend_Bandwidth.MITE:              31.93 +-  0.00 % CoreClocks
    This metric represents Core fraction of cycles in which CPU
	was likely limited due to the MITE pipeline (Legacy Decode
    Pipeline)...
</code></pre><p>Above is an example of a toplev result. We can see that the instruction cache misses were the dominating bottleneck. Unsurprisingly instruction TLB misses also show up. On the front end bandwidth side of things, toplev points to the legacy decode pipeline. That makes perfect sense if the instructions are supplied from DSB or LSD, then there are no instruction fetches, and no cache misses.</p><p>Sometimes, the final summary may not provide sufficient information if there are changes in the code behaviour during the test. When that’s the case, a graph is likely to be a much more helpful way of presenting the results.</p><p><img loading="lazy" width="950" height="950" src="https://paweldziepak.dev/static/icache-toplev.min.2b465fdb6f.svg" alt="toplev"></p><p>Tools like toplev are great for initial identification of the problem, but once that’s done what we need is a right way for comparing different solutions. Ultimately, the most important metric is the actual performance of the program in a real-life workload. toplev still can be helpful as it shows the balance between different performance-limiting factors. What also can be useful is <code>perf stat</code> which can show the performance counter statistics. The event most relevant for us is <code>L1-icache-load-misses</code>, though there are more model-specific registers that may be of interest.</p><p>Now, that we know how to diagnose excessive instruction cache misses, let’s see what can be done to deal with this problem.</p><h2 id="avoiding-work">Avoiding work</h2><p>If the number of executed instructions is the problem, the most obvious solution is to try to reduce that number. Obviously, that’s much easier said than done, but there are some common patterns for dealing with this issue. One example would be prepared statements in databases. The general idea is that if a client knows it will send requests that have some commonality, it can tell the database engine early that the requests are going to match specific templates. This information allows the server to do as much work as possible during the preparation stage, thus reducing the amount of logic that needs to be executed for each individual request.</p><p>Extracting common patterns doesn’t have to be explicit. A server or any other kind of an application which actions depend on the user input could attempt to look for repeating patterns and cache some common parts. This is a very vague idea and most likely won’t be easily implementable in a lot of applications, but in some cases may be quite a natural solution. It also shows the main problem with the “just do less” approach – it is very application specific. On the plus, side, if this can be done, it is likely to help with the overall performance, not just the instruction cache misses.</p><p>Another potential problem is making sure that the preparation phase can really do something to help during the execution phase. If that means pre-computing some values, then it’s simple. However, if the only thing that preparation gives us is the knowledge which code paths are going to be exercised and which branches taken during the execution, it is going to be harder to take benefit from it. One option is to have some specialised code for the most common paths, C++ templates may come in handy here. If it is not easy to determine what may be the most common paths, then a just-in-time compiler may be used to generate code in the preparation stage.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><h2 id="batching-work">Batching work</h2><p>So far, we have been trying to reduce the number of executed instructions, by taking advantage of some earlier knowledge to avoiding repeating the same work. In other words, we have introduced two stages:</p><ul><li>preparation, which is performed rarely and, consequently, less performance critical</li><li>execution, which is done many times and is expected to dominate overall performance</li></ul><p>The way this can help with the instruction cache misses is that the execution stage, being smaller, is more likely to fit in the instruction cache. Whether this brings any measurable benefits depends highly on the type of the application and how much logic can be moved from execution to preparation stages.</p><p>We have already split our processing pipeline into preparation and execution stage. If the execution stage can fit in the instruction cache, we are done. However, often, that’s not the case. What we can do to improve the situation more is to split the execution into more stages. This time the goal is not to reuse work as it was with the preparation, but to group entities that need to have the same code executed for them. In other words, if the processing pipeline consists of steps A, B and C the idea is to separate them, add a queue in front of each of those stages, and then cycle through those stages each time handling multiple elements from the queue. Connections between the stages don’t have to be one-to-one, any directed graph is fine.</p><p><img loading="lazy" width="756" height="331" src="https://paweldziepak.dev/static/icache-seda.min.7259b25adc.svg" alt="SEDA diagram"></p><p>In the diagram above, there is one stage that feeds tasks to one of two stages. This could be, for example, a front-end of a database server. The first stage does some initial request processing and then, depending on whether it is a read or write, puts it in the appropriate queue. Each stage processes requests in batches, the first one warms up the instruction …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</a></em></p>]]>
            </description>
            <link>https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680125</guid>
            <pubDate>Fri, 08 Jan 2021 01:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CO2 already emitted will warm Earth beyond climate targets, study finds]]>
            </title>
            <description>
<![CDATA[
Score 336 | Comments 248 (<a href="https://news.ycombinator.com/item?id=25679618">thread link</a>) | @colinprince
<br/>
January 7, 2021 | https://www.cbc.ca/news/technology/climate-targets-1.5861537 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/climate-targets-1.5861537">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds. But it can be delayed for centuries if governments takes action.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4922800.1543350548!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/us-coal-s-decline.jpg"></p></div><figcaption>Smoke and steam rise from the smokestack of a coal-fired power plant near Ordos in northern China's Inner Mongolia Autonomous Region in 2015.  A new study estimates that 2.3 C of warming is inevitable, but can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.<!-- --> <!-- -->(Mark Schiefelbein/Associated Press)</figcaption></figure><p><span><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds.</p>  <p>But it's not game over because, while that amount of warming may be inevitable, it can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.</p>  <p>For decades, scientists have talked about so-called "committed warming" or the increase in future temperature based on past carbon dioxide emissions that stay in the atmosphere for well over a century. It's like the distance a speeding car travels after the brakes are applied.</p>  <p>But Monday's <a href="https://www.nature.com/articles/s41558-020-00955-x">study in the journal Nature Climate Change</a> calculates that a bit differently and now figures the carbon pollution already put in the air will push global temperatures to about 2.3 degrees Celsius (4.1 degrees Fahrenheit) of warming since pre-industrial times.</p>  <p>Previous estimates, including those accepted by international science panels, were about a degree Celsius (1.8 degrees Fahrenheit) less than that amount of committed warming.</p>  <p>International climate agreements set goals of limiting warming to 2 C&nbsp;(3.6 F) since pre-industrial times, with the more ambitious goal of limiting it to 1.5 C&nbsp;(2.7 F) added in Paris in 2015. The world has already warmed about 1.1 C&nbsp;(2 F).</p>  <p>"You've got some ... global warming inertia that's going to cause the climate system to keep warming, and that's essentially what we're calculating," said study co-author Andrew Dessler, a climate scientist at Texas A&amp;M University. "Think about the climate system like the Titanic. It's hard to turn the ship when you see the icebergs."</p>  <p>Dessler and colleagues at the Lawrence Livermore National Lab and Nanjing University in China calculated committed warming to take into account that the world has warmed at different rates in different places and that places that haven't warmed as fast are destined to catch up.</p>    <p>Places such as the Southern Ocean, surrounding Antarctica are a bit cooler, and that difference creates low-lying clouds that reflect more sun away from earth, keeping these places cooler. But this situation can't keep going indefinitely because physics dictates that cooler locations will warm up more and when they do, the clouds will dwindle and more heating will occur, Dessler said.</p>  <p>Previous studies were based on the cooler spots staying that way, but Dessler and colleagues say that's not likely.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/greenland-record-melt.jpg 300w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/greenland-record-melt.jpg 460w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/greenland-record-melt.jpg 620w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg 780w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/greenland-record-melt.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg"></p></div><figcaption>In this Aug. 16, 2019 file photo, icebergs float away as the sun rises near Kulusuk, Greenland. Greenland lost a record amount of ice that year. The world has already warmed 1.1 C since pre-industrial times.<!-- --> <!-- -->(Felipe Dana/The Associated Press)</figcaption></figure></span></p>  <h2>More research needed, outside experts say</h2>  <p>Outside experts said the work is based on compelling reasoning, but want more research to show that it's true. Breakthrough Institute climate scientist Zeke Hausfather said the new work fits better with climate models than observational data.</p>  <p>Just because the world is bound to get more warming than international goals, that doesn't mean all is lost in the fight against global warming, said Dessler, who cautioned against what he called "climate doomers."</p>  <p>If the world gets to net zero carbon emissions soon, 2 degrees of global warming could be delayed enough so that it won't happen for centuries, giving society time to adapt or even come up with technological fixes, he said.</p>  <p>"If we don't, we're going to blow through (climate goals) in a few decades," Dessler said. "It's really the rate of warming that makes climate change so terrible. If we got a few degrees over 100,000 years, that would not be that big a deal. We can deal with that. But a few degrees over 100 years is really bad."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/climate-targets-1.5861537</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679618</guid>
            <pubDate>Fri, 08 Jan 2021 00:23:20 GMT</pubDate>
        </item>
    </channel>
</rss>
