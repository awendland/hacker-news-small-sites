<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 27 Nov 2020 16:39:43 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 27 Nov 2020 16:39:43 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[We need a FrontPage that lets common folk retake the internet with creativity]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25218794">thread link</a>) | @pmlnr
<br/>
November 26, 2020 | https://invisibleup.com/articles/33/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/33/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/33/thumb.png" alt="FrontPage: The Good, The Bad, and The Ugly thumbnail">
	
	

	<p>PLEASE don't use FrontPage for modern web development! It's filled with security vulnerabilities and obsolete standards. The goal of this is not to convince you otherwise. The newest version came out almost two decades ago!</p>

<p>Microsoft FrontPage. The mere mention of that name is making most (if not all) of you seasoned web devs groan. "FrontPage was utter rubbish from dark ages of GeoCities" you say. "Everything it touched was ruined with horrific output and proprietary nonsense!" And yes, it was.</p>
<p>But... FrontPage as a concept. As a dream of what could have been, and a window into what <em>was</em>. Letting the typical home user at the time create websites, express creativity, and conquer the world by storm, all without being forced to learn HTML or CSS or JavaScript... In that regard, FrontPage couldn't be beat.</p>
<p>Let's talk about why Microsoft FrontPage was for a brief period of time the ultimate content creation tool of the Internet, and why it later fell from grace.</p>
<h2>History</h2>
<p>Before we can talk about goodness and ugliness, we need to talk about carphones and business meetings. Because this was 1994, when the Internet was still really new. At that point in time most internet chatter occured on Usenet groups (think something like Reddit) or BBS systems (think something like <a href="https://invisibleup.com/articles/5/">old AOL</a>; example pictured below). If you needed buisness stuff, like stocks or the such, you had to log onto the BBS of whoever had what you needed. This was kind of a pain.</p>
<p><img alt="A picture of a BBS (tilde.town) as of today" src="https://invisibleup.com/articles/33/BBS.png"></p>
<p>Enter Randy Forgaard and Charles H. Ferguson. Ferguson, renowned computer industry consultant, contacted MIT graduate Forgaard (over carphone, in case you were wondering) to discuss starting a new, internet-based company.</p>
<p>His idea was that many corporations such as the Dow Jones, Bloomberg, Apple, etc. were sinking millions into building their own, completely incompatible dial-in Internet services. Therefore, they should create a standardized, completely open server/client combo to replace all the independent efforts. This hopefully would reduce the cost of development for those corporations, and provide a market for growth by making buisnesses <em>want</em> to have an Interent presence.</p>
<p>The two decided to found their own company, Vermeer Technologies, Inc. A month later, still in the planning stages, they caught wind of the brand new World Wide Web out of CERN. It was decentralized, open, and even more robust than they were planning. It was just about perfect. The only issue was that it was rather a pain to make websites if you were just some lowly advertising manager or whoever. The web needed an authoring tool for websites.</p>
<p><img alt="FrontPage 1.0a, taken from WinWorldPC.com" src="https://invisibleup.com/articles/33/FP-1.0.png"></p>
<p>So, somehow, they managed to hire many professional coders for no salary whatsoever to work on FrontPage. (Early start-up culture, perhaps?) Evidently it worked, as FrontPage was released (only!) a week behind schedule on October of 1995. By then the World Wide Web was exploding, with a 20% increase in sites <em>per month</em>. FrontPage also managed to explode, receiving many awards and positive reviews. In fact, it was so good that Microsoft ended up buying them out. According to them, not only did it feel like a native Office application, it was perfect for their ongoing plan to become more internet centric.</p>
<p><img alt="FrontPage 97, taken from WinWorldPC.com" src="https://invisibleup.com/articles/33/FP-97.png"></p>
<p>FrontPage over the years got integrated into the Office suite and made a flagship product for Microsoft productivity products. By Office 2000, FrontPage had more Office integration than you should shake a stick at; nailing down the Office user interface and allowing imports and exports across the whole suite. There's... other stuff as well, but let's stay positive for now.</p>
<p>I'll be covering FrontPage 2002, as that's the version I own, and the one I have the most experience with.</p>
<h2>The Good</h2>
<p>The interface... is (in my opinion) one of the best interfaces for any program ever. No hyperbole. I think only the other Microsoft applications of the era like PowerPoint and Visio can top it. I can <em>see</em> why it won awards.</p>
<p><img alt="FrontPage's start screen with no webs open" src="https://invisibleup.com/articles/33/FP-Start.png"></p>
<p>Like any other Microsoft Office XP program, there's the sidebar on the right with common tasks. What you'll probably want to do is, of course, make a new site.</p>
<p>FrontPage's equivalent to "projects" are called "Webs". These Webs contain the files (all your HTML, CSS, images, etc.) and preferences (such as which web server to sync up with or what compatibility settings to use) for that website.</p>
<p><img alt="FrontPage's template selector" src="https://invisibleup.com/articles/33/FP-NewWeb.png"></p>
<p>Start by selecting a new "Empty Web". Up pops a bunch of templates, including the "Empty Web" template. A bit odd, but sure.</p>
<p><img alt="The &quot;Personal Homepage&quot; template in action" src="https://invisibleup.com/articles/33/FP-Template.png"></p>
<p>If you <em>were</em> to choose a template, it would give you a pre-populated fill-in-the-blanks site ready for your words and pictures. It takes some of the layout work and design originality out of it, but that <em>is</em> the purpose of a template after all. (Although, as a word of advice, <em>don't use these.</em> They're rather awfully designed from a web standards point of view. You can see it barely fitting in my window there. Imagine that on a smartphone.)</p>
<p><img src="https://invisibleup.com/articles/33/FP-BlankWeb.png" alt="FrontPage open to a new blank web. Folder list and Views bar are visible."></p>
<p>Anyways, once you open your blank web, you get... nothing! (That's what you asked for, isn't it?) No worries. Really, if you think about it, it would be rather silly to start making a page off the bat. You see, FrontPage takes a <em>project oriented</em> approach to things. While you easily <em>could</em> just sit down and start banging stuff out, that's really not the way FrontPage wants you to go.</p>
<p><img alt="FrontPage Navigation editor with some pages created and linked up." src="https://invisibleup.com/articles/33/FP-NavView.png"></p>
<p>Here's probably my favorite FrontPage feature: the Navigation editor. Here you create blank pages and link them together in a logical hierarchy. This closely resembles the process you'd usually take on paper when designing a website.</p>
<p><img alt="Navigation bar settings dialog" src="https://invisibleup.com/articles/33/FP-Navbar.png"></p>
<p>With this hierarchy, you can automatically create a navigation bar in all your pages that are properly linked. If you decide to make a new top-level page, for instance, every page on your site will be updated to feature that page. (To replicate that feature on this site, I had to use some pretty tricky template scripting with my custom Flask server. I'd vastly prefer something like this.)</p>
<p>This feature is also nice because it forces you to <em>think about your site</em>. You can't just sit down like it's Microsoft Word and bang out some pages. You need a coherent plan. Before you can even start, you need to sit down with your client/team/self and ask "What do you want on your website?" To most people it's obvious that you need a website. Everybody has a website. What's significantly less obvious is <em>what</em> needs to be on the website. And FrontPage's web editor allows you to play around with hierarchies and layouts before commiting to anything.</p>
<p><img alt="PowerPoint Slide Sorter mode&quot;" src="https://invisibleup.com/articles/33/PPT-SlideSorter.png"></p>
<p>One thing that's intersting is that Word, PowerPoint and Access all (vaguely) follow a similar model. Word has the Outline editor, PowerPoint has the Slide Sorter mode (pictured above, showing an interactive game I made when I was 11), and Access, being a typical database program, requires you to declare your tables before you can work on them.</p>
<p>What's even more interesting is that, with the exception of Access (which not many people used, mostly due to its cost and relative rarity), you were never <em>required</em> to have a plan before starting. Most people I've seen use Word just do straight typing, or perhaps work off another document with an outline. But the option was there! One could do their outline <em>in their document</em> and flesh out around that. Likewise with PowerPoint, as well.</p>
<p><img alt="Highlighted template include code" src="https://invisibleup.com/articles/33/FP-TemplateInclude.png"></p>
<p>Another common task in web design is defining a "template" page where you fill all your content into. For example, every page on this site you're reading on now has the same header and footer, and every article has the same sort of thumbnail image at the top. That was all scripted using template features.</p>
<p>FrontPage, being an Office product, supports templates. The implementation admittedly is <em>super</em> janky, but it's there. You can include pages within other pages just fine, it's just a little tricky to set up. (FYI, Word, Excel, and PowerPoint do templates too. It's one of their lesser-known features, IMHO.)</p>
<p><img alt="Report view window" src="https://invisibleup.com/articles/33/FP-Reports.png"></p>
<p>Another really neat feature: reports. Like a compiler in an IDE, FrontPage produces warnings, errors, and statistics for your site. At a glance I can view all broken links, orphaned pages, oversized images, etc. This is a <em>fantastic</em> feature, something that modern web dev software just <em>doesn't</em> have.</p>
<p><img alt="Hyperlinks view window" src="https://invisibleup.com/articles/33/FP-Links.png"></p>
<p>In the same vein as the Reports, you can see at a glance what links to what. It's a lot like the call chart in a software development IDE. I can see quickly every site linked from any page (shown here is <a href="https://invisibleup.com/articles/24/">the Sonic R color fix article</a>) and any subpages.</p>
<p><img alt="Tasks view, showing a task labeled &quot;Write FrontPage article&quot;" src="https://invisibleup.com/articles/33/FP-Tasks.png"></p>
<p>Last feature, although this isn't nearly as useful in the year 2020. In the tasks view, you can put up a list of tasks that needs to be accomplished. Already that seems rather nice for keeping track of what you need to do. It's a lot like GitHub or GitLab's issue tracker, in a sense.</p>
<p>However, if you connect to a server with FrontPage Web Extensions (I'll get to that...), you can share this task list with other people. You can (again, like an issue tracker) put up a task to be done by someone else and work on a task that somebody else put up. It's a <em>very</em> nice feature for web development, but nowadays this is normally handled by source control providers like GitHub or GitLab.</p>
<p><img alt="FrontPage editing the Sonic R color mod article" src="https://invisibleup.com/articles/33/FP-Editor.png"></p>
<p>And, of course, there's the webpage editor. This works almost exactly like Microsoft Word, with some web-flavored spice. You type words and they appear in the page. You make those words blue, they're blue. <em>That said</em>, when you edit elements like that, it inserts an HTML 3.2 style <code>&lt;FONT&gt;</code> tag instead of trying to match it to a CSS rule. There's ways around this, but you have to be very diligent in doing so. This is mostly just due to FrontPage being a product of its time, though.</p>
<p>FrontPage is a program about planning, executing, and reviewing. Take the Navigation editor. You plan out the content of your site. You sketch up the layout. Then you reflect on if your layout matches your requirements. Or the Reports. Create content, check reports. Or the Tasks. Plan out what you need to do, do that, and then check if the task is complete. That, right ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/33/">https://invisibleup.com/articles/33/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/33/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218794</guid>
            <pubDate>Thu, 26 Nov 2020 10:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[6 Essential Things I Wish I Knew When I Started Programming]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25218351">thread link</a>) | @nickbull
<br/>
November 26, 2020 | https://blog.nickbulljs.com/6-essential-things-i-wish-i-knew-when-i-started-programming | <a href="https://web.archive.org/web/*/https://blog.nickbulljs.com/6-essential-things-i-wish-i-knew-when-i-started-programming">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>I could probably achieve 300% more in 6 years as a programmer if I knew these things when I started.</p>
<h2 id="coding-is-not-about-the-coding">Coding Is Not About The Coding</h2>
<p>What do you think programming is about?</p>
<p>Writing code?</p>
<p>Writing good code?</p>
<p><strong>No.</strong></p>
<p>It's just a part of the truth.</p>
<p><strong>Programming is not about coding, programming is about solving problems with coding.</strong></p>
<p>End customers don‚Äôt care what technologies, languages, frameworks, or methodologies you use. They care only about one thing, whether your product solves their problem or not.</p>
<p>That‚Äôs why no one cares what technologies Google search is using under the hood. Until people can find relative information with it, they will use it.</p>
<p>It‚Äôs the number one thing I wish I knew when I started programming.</p>
<p>I would spend less time writing ‚Äúbest code‚Äù and more time solving customer‚Äôs problems best.</p>
<p><strong>Don‚Äôt write code just to write code, solve customer‚Äôs problems with the code.</strong></p>
<h2 id="communication-skills-more-important-than-coding-skills">Communication Skills More Important Than Coding Skills</h2>
<p>When I just started my career, lack of social skills was not my main problem. But when I moved higher, to the middle, senior, and leadership position, my weak soft skills became my Achilles heel.</p>
<p>When you work on a product with a group of different people (engineers, designers, managers), communication is the only thing that makes you a ‚Äúteam‚Äù and helps you effectively develop the product.</p>
<p>Lack of social skills does the opposite, it decreases the product development time and overall productivity.</p>
<p>Here is the real situation you might face:</p>
<p>The leadership team tells your product manager that they want to create a new product feature and put it in the next product release. It‚Äôs not urgent, they just want to release it as soon as possible (as always).</p>
<p>The product Manager calls you on Zoom, tells you what you need to build, and asks, <em>‚ÄúHow much time do you need to build it?‚Äù</em></p>
<p>You are doing a rough calculation and tell, <em>‚ÄúI need 20 hours.‚Äù</em></p>
<p>The Product Manager is not satisfied with your answer. He wants to release it as soon as possible and show the management that he can deliver results fast (this is a very common situation).</p>
<p>So he asks you, <em>‚ÄúCan you build it for 10 hours? We really need this feature in the next product release!‚Äù</em></p>
<p>And you know that you can if you cut the corners (no tests, messy code) but then you will need to refactor it, and it will take an additional 30 hours. Because other engineers will work with your messy code when you release it. And after refactoring, you will need to integrate their code with yours.</p>
<p>So here‚Äôs what will happen next. If you have bad social skills, you will not convince the Product Manager that you actually need 20 hours to build this feature. </p>
<p>Why?</p>
<p>Product Managers often have good social skills, from my experience. So if you can‚Äôt convince him that refactoring later is worse than spending 20 hours right now, he will easily argue with you and convince you that ‚Äúrefactoring later is okay.‚Äù And the whole team will lose additional 30 hours for this refactoring (I don't count the time to fix unpredictable bugs after).</p>
<p>But if you have good communication skills you will be able to convince him of the opposite.</p>
<p><strong>So improve your social skills as well as coding skills</strong> (send memes in the group chats on Slack or something).</p>
<p>And remember one simple truth:</p>
<p><strong>People work with people, not machines.</strong></p>
<h2 id="regular-breaks-help-to-program-better">Regular Breaks Help To Program Better</h2>
<p>For 4 years I always feel exhausted after work. Somehow I could productively work only for a couple of hours. After that, I didn't have much energy. Until I learned about the Pomodoro technique.</p>
<p>It‚Äôs quite simple. You work for 25 minutes and take a break for 5 minutes.</p>
<p>Your working routine becomes:</p>
<p>8:00-8:25 ‚Äì Work</p>
<p>8:25-8:30 ‚Äì Break</p>
<p>8:30-8:55 ‚Äì Work</p>
<p>8:55-9:00 ‚Äì Break</p>
<p>‚Ä¶</p>
<p>I tried it for a week and was surprised at how focused, energetic, and productive I became  (<a target="_blank" href="https://www.focusboosterapp.com/blog/the-science-behind-the-pomodoro-technique/">the science behind Pomodoro</a>)</p>
<p>Then I went further and implemented the <a target="_blank" href="https://twitter.com/nickbulljs/status/1303037682294173699">52+17 system</a> and my productivity levels spiked by 200%.</p>
<p><strong>So</strong> <strong>take regular breaks if you want to operate at your maximum capabilities.</strong></p>
<h2 id="10x-engineers-dont-exist">10X Engineers Don‚Äôt Exist</h2>
<p>At the beginning of my career, I thought that a great programmer is a person who knows tons of programming languages, frameworks, and methodologies.</p>
<p><strong>I was wrong.</strong></p>
<p>Such a mindset only gave birth to my impostor syndrome. I thought that I don't deserve my current position, my salary, that I am a ‚Äúfraud.‚Äù So I started to follow every popular developer on Twitter, read every technical news, and thousands of developer blogs just to convince myself that I deserve what I have and to feel more close to the title ‚Äúgreat developer.‚Äù</p>
<p><strong>This was not a healthy behavior.</strong></p>
<p>But it helped me to discover that a lot of people I followed (I thought were 10X engineers) actually didn‚Äôt know a lot of things. They may know how to do some complex things that require a lot of different deep knowledge in a couple of fields and at the same time don‚Äôt know some primitive things. Like to know how to design highly scalable database architectures but don‚Äôt know how vertical-align an element with CSS.</p>
<p>Big thanks to those developers, like Dan Abramov (creator of Redux) for <a target="_blank" href="https://overreacted.io/things-i-dont-know-as-of-2018/">this article</a>, they cured my imposter syndrome and showed me that it is okay not to know something.</p>
<h2 id="programming-is-not-hard-if-you-know-how-to-learn">Programming Is Not Hard If You Know How To Learn</h2>
<p>When I started to learn JavaScript, it was hard. <strong>Because I learned the wrong way.</strong></p>
<p>Read a lot of theory without the practice, no routine, no end goal. Chaos.</p>
<p>I thought it was normal to learn like this. Until I discovered <strong>deliberate practice.</strong></p>
<p>It‚Äôs a purposeful and systematic type of practice (learning).</p>
<p>The difference between normal practice and deliberate is that deliberate requires focused attention and is conducted with the specific goal of improving performance.</p>
<p>After I applied a deliberate practice, I began to notice how fast I'm progressing with learning JavaScript. My knowledge started to stick for a long time, not just for 5 minutes after tutorials. I created the end goal, why I am learning JavaScript, and understand what I need to learn, and what I don't.</p>
<p>üìå <em>Quick note: I‚Äôm creating a JavaScript course where I‚Äôm using deliberate practice to <strong>combine modern and practical JavaScript theory with a lot of real-world practice</strong> to teach you how to become a skilled JavaScript developer with knowledge of modern language features. <a target="_blank" href="https://javascriptcoursethatworks.com/">Join here.</a></em></p>
<p>So here is what you need to perform deliberate practice on your own:</p>
<ol>
<li><strong>Teacher:</strong> provides practice activities designed to help you improve performance.</li>
<li><strong>Perform at maximum effort:</strong> constantly being taken out of your comfort zone.</li>
<li><strong>Well defined and specific goals:</strong> not just ‚Äúoverall improvement.‚Äù</li>
<li><strong>To be in focus:</strong> give your full attention, no distractions.</li>
<li><strong>Do conscious actions:</strong> no autopilot.</li>
<li><strong>Instant response to feedback and modifying your strategy.</strong></li>
</ol>
<p>When you start learning a new language, technology, framework, whatever, stick to these rules to get big results as quickly as possible.</p>
<h2 id="there-is-no-best-programming-language">There is no ‚Äúbest programming language‚Äù</h2>
<p>There is no <strong>best "something"</strong> in our world. Only <strong>best in something</strong>.</p>
<p>Let‚Äôs take cars. How can we choose the best car in the world? By speed? By safety? By what criteria?</p>
<p>It‚Äôs impossible.</p>
<p>We can only choose the best car in a certain category. Like the safest car. Or the best offroad car.</p>
<p>And if we look deeper, every category solves some problems.</p>
<p>For example.</p>
<p><strong>Problem:</strong> We have children and we take them to school every day, we want our children to be safe on the way to school.</p>
<p><strong>Solution:</strong> Buy the safest car.</p>
<p><strong>Problem:</strong> We go camping every weekend, so we need some vehicle that can easily get us to places that are difficult to access.</p>
<p><strong>Solution:</strong> Buy the best off-road car.</p>
<p>The same is with programming languages. Some languages and tools are better at solving some problems than others.</p>
<p>If we want to build an interactive website, we choose JavaScript.</p>
<p>If we want to go with ML/AI, we choose Python.</p>
<p>Remember, <strong>there is no best programming language, there is the best programming language to ...</strong></p>
<p>So start with a problem first, then pick a language to solve it.</p>
<h2 id="in-the-end">In the end...</h2>
<p>If you like this article, share it with your friends and <a target="_blank" href="https://twitter.com/nickbulljs">follow me on Twitter</a>.</p>
<p>Also, every week I send out a "3‚Äì2‚Äì1" newsletter with 3 tech news, 2 articles, and 1 piece of advice for you.</p>
<p>üìå <a target="_blank" href="https://nickbulljs.com/">Subscribe to my 3‚Äì2‚Äì1 newsletter here</a> üìå</p>
</div></div>]]>
            </description>
            <link>https://blog.nickbulljs.com/6-essential-things-i-wish-i-knew-when-i-started-programming</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218351</guid>
            <pubDate>Thu, 26 Nov 2020 09:28:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf 2020: State of Retro Gaming in Emacs]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25218177">thread link</a>) | @sohkamyung
<br/>
November 26, 2020 | https://emacsconf.org/2020/schedule/27/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/schedule/27/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">





<p>Back to the <a href="https://emacsconf.org/2020/schedule/">schedule</a><br>
Previous: <a href="https://emacsconf.org/2020/schedule/26">Emacs as a Highschooler: How It Changed My Life</a><br>
Next: <a href="https://emacsconf.org/2020/schedule/28">Welcome To The Dungeon</a></p>

<p>Sunday, Nov 29 2020,  1:16 PM -  1:26 PM EST<br>
Sunday, Nov 29 2020, 10:16 AM - 10:26 AM PST<br>
Sunday, Nov 29 2020,  6:16 PM -  6:26 PM UTC<br>
Sunday, Nov 29 2020,  7:16 PM -  7:26 PM CET<br>
Monday, Nov 30 2020,  2:16 AM -  2:26 AM +08</p>



<p>Vasilij "wasamasa" Schneidermann</p>

<p>Many jokes have been made about the true nature of Emacs, such as it
being a fully-fledged operating system.  This talk will demonstrate
its suitability for playing retro games, then explore the inner
workings of a <a href="https://en.wikipedia.org/wiki/CHIP-8">CHIP-8</a> emulator capable of smooth video game emulation.</p>

<p>Back to the <a href="https://emacsconf.org/2020/schedule/">schedule</a><br>
Previous: <a href="https://emacsconf.org/2020/schedule/26">Emacs as a Highschooler: How It Changed My Life</a><br>
Next: <a href="https://emacsconf.org/2020/schedule/28">Welcome To The Dungeon</a></p>

<p>All times are approximate, and we might shuffle talks around as needed.
Please check <a href="https://emacsconf.org/2020">https://emacsconf.org/2020</a> a few days before the start of the
conference for instructions on how to watch and participate. See you then!</p>

</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/schedule/27/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218177</guid>
            <pubDate>Thu, 26 Nov 2020 08:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Move, iPad]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 114 (<a href="https://news.ycombinator.com/item?id=25218050">thread link</a>) | @rcarmo
<br/>
November 26, 2020 | https://beckyhansmeyer.com/2020/11/25/your-move-ipad/ | <a href="https://web.archive.org/web/*/https://beckyhansmeyer.com/2020/11/25/your-move-ipad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Hear that? It‚Äôs the sound of Mac fans. No, not your shiny new M1 Mac‚Äôs fans‚Äîchances are, you‚Äôll never hear those‚Äîbut rather, the sound of <em>excitement</em> rippling through the Mac community. This is something big. Really big. Now, I‚Äôm only 33, but someday when I go full fuddy-duddy I will speak of this: the great Intel/Apple Silicon transition. The beginning of a new era at Apple.</p>



<p>All that sounds dramatic, of course, but it‚Äôs interesting to trace all of the different paths that led us to this point. The A-Series chips, the introduction of Metal, rapid machine learning gains, the gradually degrading repairability scores as components became more integrated, the Secure Enclave, a new super fast emulation layer, new unified memory architecture, and 5nm process‚Ä¶ years and years of work have now come to fruition with the first Apple Silicon chips for Mac. And our minds are blown.</p>



<p>Suddenly, we‚Äôre handed a thin, entry-level fanless laptop that performs better than almost every other Mac computer out there, and a low-end MacBook Pro and Mac Mini that make current Mac Pro owners sweat and clutch their wheels. So many questions abound. What new hardware designs will these gains make possible? What on earth does Apple have in store for its high-end Macs? Will anyone else even be able to compete? It‚Äôs an exciting time to be a Mac lover, but, surprise: this post isn‚Äôt really about the Mac. It‚Äôs about the iPad.</p>



<p>There‚Äôs no question that Apple has struggled to craft a cohesive, compelling narrative for the iPad. For a long time, there seemed to be a distinct lack of product vision. Everyone likes to speculate over what role Steve Jobs ultimately intended the iPad to have in people‚Äôs lives, but not only is that pointless, it‚Äôs also irrelevant. We don‚Äôt need Steve to tell us what the iPad is good for. We know what it‚Äôs good for, and we can easily imagine what it <em>could</em> be good for, if only Apple would set it free.</p>



<p>Just as Apple left us with great expectations for its Pro Mac line-up, the latest iPad Air also raises the bar in new and interesting ways. The Air served as sort of an appetizer for the new M1 chips, while also receiving a generous trickle-down of features from the iPad Pro, including USB-C and support for the latest keyboard and Pencil accessories. There have been rumors of new mini-LED displays for the next-gen iPad Pros, but it‚Äôs going to take a lot more than new display tech to set the Pros apart.</p>



<p>Francisco Tolmasky (<a href="https://twitter.com/tolmasky/status/1330033394349125642?s=20">@tolmasky</a>) recently tweeted:</p>



<blockquote><p>‚ÄúA sad but inescapable conclusion from the impressive launch of the M1 is just how much Apple squandered the potential of the iPad. The iPad has had amazing performance for awhile, so why is the M1 a game changer? Because it‚Äôs finally in a machine we can actually <em>do things on</em>.‚Äù</p></blockquote>



<p>Francisco is right: Power and performance aren‚Äôt the bottleneck for iPad, and haven‚Äôt been for some time. So if raw power isn‚Äôt enough, and new display tech isn‚Äôt enough, where does the iPad go from here? Will it be abandoned once more, lagging behind the Mac in terms of innovation, or will Apple continue to debut its latest tech in this form factor? Is it headed toward functional parity with the Mac or will it always be hamstrung by Apple‚Äôs strict App Store policies and seemingly inconsistent investment in iPadOS?</p>



<p>It‚Äôs clear that Apple <em>wants</em> the iPad Pro to be a device that a wide variety of professionals can use to get work done. And since so many people use web apps for their work, the introduction of ‚Äúdesktop‚Äù Safari for iPad was an important step toward that goal. The Magic Keyboard and trackpad was another step.</p>



<p>Here are ten more steps I believe Apple could and should take to help nudge the iPad into this exciting next era of computing.</p>



<ol><li>Give the iPad Pro another port. Two USB 4.0 ports would be lovely.</li><li>Adopt a landscape-first mindset. Rotate the Apple logo on the back and move the iPad‚Äôs front-facing camera on the side beneath the Apple Pencil charger to better reflect how most people actually use their iPad Pros.</li><li>Introduce Gatekeeper and app notarization for iOS. The process of side-loading apps should <em>not</em> be as simple as downloading them from the App Store. Bury it in Settings, make it slightly convoluted, whatever: just have an officially-sanctioned way of doing it.</li><li>Ruthlessly purge the App Store Guidelines of anything that prevents the iPad from serving as a development machine. Every kind of development from web to games should be possible on an iPad. And speaking of games‚Äîemulators should be allowed, too.</li><li>Release a suite of professional first-party apps at premium prices. If someone can edit 4K videos in Final Cut on their M1 MacBook Air, they should be able to edit 4K videos in Final Cut on their iPad Pro. I refuse to believe that these pro apps can‚Äôt be re-imagined and optimized for a touch experience. If Apple leads the way in developing premium software for iPad, others will follow.</li><li>Make it possible to write, release, and install plug-ins (if appropriate) for the aforementioned first party apps.</li><li>Bring App Library to the iPad and allow widgets to be positioned anywhere on the Home Screen. This isn‚Äôt groundbreaking, it just annoys the heck out of me.</li><li>Release a new keyboard + trackpad case accessory that allows the iPad to be used in tablet mode without removing it from the case.</li><li>Introduce Time Machine backups for iPadOS.</li><li>5G, ofc.</li></ol>



<p>In the end, fostering a vibrant community of iPad app developers can only stand to benefit the Mac (and vice-versa).</p>



<p>It‚Äôs simple: people love their iPads. They love them so much they wish they could do even more with them. The new M1 Macs should give iPad fans reason to be excited; now that we‚Äôve seen hints of what future Macs can be, it‚Äôs time for the iPad to reassert itself‚Äîto remind us once again who it‚Äôs for, and what makes it special.</p>



<p>In other words: Your move, iPad.</p>
			</div></div>]]>
            </description>
            <link>https://beckyhansmeyer.com/2020/11/25/your-move-ipad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25218050</guid>
            <pubDate>Thu, 26 Nov 2020 08:28:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cracks in the Great Stagnation?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25216017">thread link</a>) | @edward
<br/>
November 25, 2020 | https://www.agglomerations.tech/cracks-in-the-great-stagnation/ | <a href="https://web.archive.org/web/*/https://www.agglomerations.tech/cracks-in-the-great-stagnation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 300w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 600w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 1000w,
                            https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://images.unsplash.com/photo-1602611061438-ca00df2a4319?ixlib=rb-1.2.1&amp;q=80&amp;fm=jpg&amp;crop=entropy&amp;cs=tinysrgb&amp;w=2000&amp;fit=max&amp;ixid=eyJhcHBfaWQiOjExNzczfQ" alt="Cracks in the Great Stagnation">
            </figure>

            <section>
                <div>
                    <p>For the last 60 years, we‚Äôve seen consistently low productivity growth rates in the US and across the Western world. Meanwhile, recent scientific discoveries seem to be <a href="https://www.theatlantic.com/science/archive/2018/11/diminishing-returns-science/575665/">less fundamental</a> to our understanding of the world than previous breakthroughs have been. While the growth of digital technology has been tremendous since the 1990s, it‚Äôs the only significant part of our world that seems to have been changing. To look up from our smartphones is to see a physical environment that looks basically the same as it did in 1970. Innovation has been constrained to the world of bits and left the world of atoms mostly untouched.</p><p>This might finally be changing. Last month, the economist Tyler Cowen <a href="https://www.bloomberg.com/opinion/articles/2020-10-05/how-much-worse-can-things-get-that-question-may-be-a-good-sign">speculated</a> that we may be seeing signs that this <a href="https://www.amazon.com/Great-Stagnation-Low-Hanging-Eventually-eSpecial-ebook/dp/B004H0M8QS">Great Stagnation</a> is ending. Since his article was published, we‚Äôve already seen almost a dozen announcements that have only driven home the point further. There seem to be cracks in the Great Stagnation and light is peeking through on the other end. </p><p><strong>Innovation in the physical world</strong><br>Most obviously, the recent announcement of the <a href="https://www.statnews.com/2020/11/09/covid-19-vaccine-from-pfizer-and-biontech-is-strongly-effective-early-data-from-large-trial-indicate/">successful development of several vaccines</a> to the novel coronavirus are a sign that America (with some help from Germany) is still capable of achieving Big Things when we are pushed to it. Despite consistent failings of the US regulatory state in <a href="https://slatestarcodex.com/2020/04/14/a-failure-but-not-of-prediction/">delaying the adoption</a> of face masks and in <a href="https://thedispatch.com/p/timeline-the-regulationsand-regulatorsthat">slowing the rollout</a> of mass testing, the US essentially bet the farm that our strong biotech clusters would be able to create a vaccine to a new disease in record time, and it looks like we‚Äôre going to be able to do it in under a year! </p><p>It‚Äôs worth highlighting just how speedy this development timeline is when compared to the vaccines for diseases like polio and measles. </p><figure><img src="https://www.agglomerations.tech/content/images/2020/11/Vaccination-innovation-chart.png" alt="" srcset="https://www.agglomerations.tech/content/images/size/w600/2020/11/Vaccination-innovation-chart.png 600w, https://www.agglomerations.tech/content/images/size/w1000/2020/11/Vaccination-innovation-chart.png 1000w, https://www.agglomerations.tech/content/images/size/w1600/2020/11/Vaccination-innovation-chart.png 1600w, https://www.agglomerations.tech/content/images/size/w2400/2020/11/Vaccination-innovation-chart.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>https://ourworldindata.org/vaccination</figcaption></figure><p>And not only did we develop a new vaccine, we developed a new *type* of vaccine. mRNA vaccines have long been speculated to work, but this is the <a href="https://www.bostonherald.com/2020/11/20/pfizer-and-moderna-vaccines-showing-potential-success-of-mrna-platform-a-first/">first instance</a> of a successful vaccine application in humans using this technique. </p><p>In transportation, the promise of driverless cars has long been a centerpiece for a tech-optimistic vision of safer roads, better-designed cities, and eliminating the drudgery of a morning commute through traffic. But the technical delays of the last few years (when compared to the most optimistic timelines) have become a rallying cry for the <a href="https://blog.piekniewski.info/2018/05/28/ai-winter-is-well-on-its-way/">tech-skeptic</a> as well. </p><p>It seems like they may finally be getting here. A few weeks ago, <a href="https://arstechnica.com/cars/2020/10/waymo-finally-launches-an-actual-public-driverless-taxi-service/">Waymo announced</a> that their long-running pilot program in Arizona is going to be open to the public <a href="https://twitter.com/jjricks_/status/1316318196375330816">without any safety driver</a> in the front seat. Days later, Elon Musk and Tesla rolled out a new self-driving beta program. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">These two guys used a drone to make a video of Tesla's new "full self-driving" software in action. The drone, the self-driving car, and the global video-steaming service were all been science fiction when I was born. Living in the future is neat. <a href="https://t.co/4QqGcjFXsc">https://t.co/4QqGcjFXsc</a></p>‚Äî Timothy B. Lee (@binarybits) <a href="https://twitter.com/binarybits/status/1321102111883579397?ref_src=twsrc%5Etfw">October 27, 2020</a></blockquote>

</figure><p>This is a remarkable engineering feat, especially on Waymo‚Äôs end. It shows the company can successfully lead product development in an industry that relies on more stringent safety-critical engineering instead of the release-and-iterate model that its parent company grew up with. Waymo is evidence that Silicon Valley can ‚Äúmove at a moderate pace and not break things‚Äù when it needs to.</p><p>Granted, it‚Äôs unclear how long until and at what pace deployment of AVs to the rest of the country and the world will happen. If the Waymo model looks to be successful, it will be a steady, resource-intensive process of region-by-region expansion as the cars learn to handle new operational design domains and are rigorously validated in each city before the keys are turned over to the AI. In other words, expansion could look more like a cell phone coverage map than a software update that is instantaneously available everywhere. </p><p>But still, this is a significant, tangible mile marker that the industry has passed. AVs are operating in the wild now. We get to talk about *when* we reach the driverless future, not *if*. </p><p>In addition to the almost ho-hum daily progress in solar, wind, and battery technology where prices have fallen <a href="https://www.greentechmedia.com/articles/read/solar-pv-has-become-cheaper-and-better-in-the-2010s-now-what">90</a>, <a href="https://www.forbes.com/sites/energyinnovation/2020/01/21/renewable-energy-prices-hit-record-lows-how-can-utilities-benefit-from-unstoppable-solar-and-wind/?sh=491f10ec2c84">70</a>, and <a href="https://about.bnef.com/blog/battery-pack-prices-fall-as-market-ramps-up-with-market-average-at-156-kwh-in-2019">87</a> percent over the last ten years, we‚Äôve also started to hear very promising reports about the development of more fundamental breakthroughs. The NYT reports that a compact nuclear fusion reactor is ‚Äú<a href="https://www.nytimes.com/2020/09/29/climate/nuclear-fusion-reactor.html?action=click&amp;module=News&amp;pgtype=Homepage">Very Likely to Work</a>‚Äù after a major theoretical advancement. There was also a fantastic David Robert‚Äôs <a href="https://www.vox.com/energy-and-environment/2020/10/21/21515461/renewable-energy-geothermal-egs-ags-supercritical">deep dive into geothermal energy</a> and the promise of advanced geothermal (whereby water pumped into the ground through a closed loop reaches a high enough temperature that it becomes ‚Äúsupercritical‚Äù and can carry 10x more energy per unit mass), in particular. Either technology, if perfected, would provide abundant, zero-carbon, baseload energy that is available anywhere around the world. </p><p>Cowen mentions briefly the huge market growth we‚Äôve seen in lab-grown meat and plant-based alternatives. A few weeks ago it was announced that Impossible Foods, one of the largest actors in the industry is <a href="https://venturebeat.com/2020/10/20/impossible-foods-will-double-rd-to-eliminate-animal-farming/">doubling their R&amp;D team</a> as they seek to take on plant-based milk, steak, and fish as well as improve the supply chains for plant proteins. In tandem, McDonald‚Äôs <a href="https://www.washingtonpost.com/food/2020/11/10/mcdonalds-mcplant-sandwich/">just announced</a> that in 2021 they are going to be testing out a new McPlant menu.</p><p><strong>Digital innovation continues apace</strong></p><p>Not to be left out, in the digital world we‚Äôve been seeing impressive progress as well. AI techniques like deepfakes which have been heralded as the <a href="https://www.sundayguardianlive.com/opinion/deepfakes-destroy-democracy">death knell for democracy</a> are now being <a href="https://arstechnica.com/gadgets/2020/11/nvidia-used-neural-networks-to-improve-video-calling-bandwidth-by-10x/">deployed by NVIDIA</a> to increase video fidelity while cutting bandwidth transmission for video calls by a factor of 10. In general, techniques to reduce bandwidth use are greatly underrated, and it‚Äôs going to be exciting to see the ways in which smarter compression can perhaps bring similar efficiency gains across the board. </p><p>And now factor in the steady rollout of 5G network technologies which promise to increase the raw bandwidth available to all mobile devices. With the combination of smarter compression and vastly increased bandwidth we could be looking at a baseline 50x increase in network capacity over the next decade. It‚Äôs hard to predict ahead of time what new applications will be enabled by all this new capacity, but in retrospect it could look like another example of <a href="https://diff.substack.com/p/how-bubbles-and-megaprojects-parallelize">parallel innovation</a> that both enables and is driven by the growth of VR/AR, driverless vehicles, and telehealth.*</p><p><em>*For those who are skeptical that increased capacity will generate new applications because a few cities have tried gigabit broadband<a href="https://www.wsj.com/graphics/faster-internet-not-worth-it/"> without much effect</a>, I would argue that both hardware and app developers are optimizing for the baseline user experience and we won‚Äôt see a ton of investment in new applications until we‚Äôve changed the baseline capacity that developers can expect a sizeable user base to have. </em></p><p>Equally as impressive, Apple‚Äôs new M1 chip that was launched on November 10th seems to have taken the world by storm. As John Gruber <a href="https://daringfireball.net/2020/11/the_m1_macs">summarizes</a>: ‚ÄúTo acknowledge how good they are‚Äâ‚Äî‚Äâand I am here to tell you they are astonishingly good‚Äâ‚Äî‚Äâyou must acknowledge that certain longstanding assumptions about how computers should be designed, about what makes a better computer better, about what good computers need, are wrong.‚Äù Just as interesting is <a href="https://medium.com/pcmag-access/what-is-the-apple-m1-chip-613935ea0903">how they did it</a>. By miniaturizing the whole system architecture and integrating it onto a single chip (no discrete RAM, graphics card, etc.) Apple has managed to pump out massive efficiency gains both in processing power and in battery life. (There‚Äôs perhaps a metaphor here for the <a href="https://www.wsj.com/articles/breaking-up-big-tech-is-hard-to-do-1532290123">value of integration</a> for large tech firms as well‚Ä¶)</p><figure><img src="https://lh5.googleusercontent.com/tXP4ZnW93TIsJ_dJe3NVmevfz5eMUnNC6CS40Dz_S0568BDiQKr8K8LqT5Ja-kLnXUKnS1UkDQf_6WYzBhfGa4c99lQDfqudhQaDF-XCYBEkxNoP3Vo3FlGtLl3sGFQcdtHBlGbv" alt=""><figcaption>https://techcrunch.com/2020/11/17/yeah-apples-m1-macbook-pro-is-powerful-but-its-the-battery-life-that-will-blow-you-away/</figcaption></figure><p>Finally, the virtual reality space has seen its most impressive entrant in years with the arrival of the Quest 2 from Facebook on October 13th. There is no VR headset that matches it on a performance/cost basis, and the relative simplicity and elegance of the system makes it an ideal entry point. The deliberately low entry barrier of $299 is meant to entice a large enough user base that it kickstarts the virtuous cycle of having a significant enough market for dedicated VR developers to make significant investments in new applications, which then drives new user growth. Facebook believes we finally have a minimum viable product for VR that means this kind of two-sided market is possible, and it is betting billions of dollars to make it happen. Early signs seem to show that it is working as intended with <a href="https://www.theverge.com/2020/10/30/21541535/oculus-quest-2-preorders-sales-developers-zuckerberg">pre-orders reportedly 5x</a> larger than the original Quest, popular applications like Beat Saber seeing record growth, and all this with the upcoming holiday rush and a massive advertising blitz to come. </p><p>Notably, all of these announcements/developments I‚Äôve outlined have occurred in just the last few months. This is by no means a comprehensive look at the exciting progress being made in many other fields. But the sheer scope and pace of tangible changes to our physical and digital words is something to be excited about.</p><p><strong>A few caveats </strong></p><p>Some of these innovations will boost productivity in the traditional ways that show up in economic growth statistics. We should strive for and celebrate those achievements. But some of these innovations won‚Äôt necessarily, instead they make human civilization more durable and sustainable in a variety of ways. In response, we should start to think of increased sustainability as a type of productivity. </p><p>A vaccine to the COVID pandemic is the most obvious example. While economic statistics won‚Äôt show a boost in productivity compared to the pre-COVID economy because of the vaccine, the ability to return to trend is itself incredibly valuable. In fact, measured labor productivity from the vaccine will likely fall as lower-wage ‚Ä¶</p></div></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.agglomerations.tech/cracks-in-the-great-stagnation/">https://www.agglomerations.tech/cracks-in-the-great-stagnation/</a></em></p>]]>
            </description>
            <link>https://www.agglomerations.tech/cracks-in-the-great-stagnation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25216017</guid>
            <pubDate>Thu, 26 Nov 2020 01:14:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Broken link]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25215398">thread link</a>) | @sandwall
<br/>
November 25, 2020 | https://www.bnnbloomberg.ca/danish-nuclear-startup-taps-billionaire-for-asian-reactor-1.1527485.html | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/danish-nuclear-startup-taps-billionaire-for-asian-reactor-1.1527485.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
                  
    
  
    
  
    
    
        

<section ng-controller="bm-scoreboard" ng-cloak="" ng-init="init()">
	<div ng-class="{ 'overflow' : ! showBoards }">
	<p><span ng-click="showBoards = ! showBoards"><span data-url="{{currentBoardDataUrl}}" ng-cloak="" ng-show="currentBoardShortName">{{ currentBoardShortName }}</span><span></span></span></p><ul ng-cloak="">
        					<li ng-click="boardClick('Markets Overview', 'Markets', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Markets</li> 
							<li ng-click="boardClick('Indices', 'Indices', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Indices</li> 
							<li ng-click="boardClick('Currencies', 'Currencies', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Currencies</li> 
							<li ng-click="boardClick('Energy', 'Energy', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Energy</li> 
							<li ng-click="boardClick('Metals', 'Metals', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Metals</li> 
			        </ul>
    </div>
	
	<div>
		
		<div ng-cloak="" ng-hide="!dataLoaded" data-sticky="false">
				<ul>
	                <li ng-if="groupArray.length > 1" ng-repeat-start="group in groupArray" data-test="{{$index}}"></li>
	                <li ng-repeat-end="" ng-repeat="data in group.data" ng-class="{'selected' : $first &amp;&amp; group.RICS[$index].showChart &amp;&amp; $parent.$first, 'linked' :  group.RICS[$index].link != null }">
	                	<!-- Linked Item -->
	                	<a ng-if="group.RICS[$index].link != null" ng-href="{{group.RICS[$index].link.href}}">
		                	<div>
					 			<p>{{data.symbol | reutersRICLabelFormat:group.RICS}}</p>
						 		<p>{{data.netChng  | number: 4 }}</p>
						 		<p>{{data.netChng  | number: 2 }}</p>
						 		<p><span>{{data | displayCurrencySymbol}}</span> {{data.price  | number: 4 }}</p>
						 		<p>{{data.price  | number: 2 }}</p>
						 	</div>	
					 		
	                	</a>
						<!-- Non Linked Item -->
	                	<div ng-if="group.RICS[$index].link == null">
							<div>
					 			<p>{{data.symbol | reutersRICLabelFormat:group.RICS}}</p>
						 		<p>{{data.netChng  | number: 4 }}</p>
						 		<p>{{data.netChng  | number: 2 }}</p>
						 		<p><span>{{data | displayCurrencySymbol}}</span> {{data.price  | number: 4 }}</p>
						 		<p>{{data.price  | number: 2 }}</p>
						 	</div>
					 								 		
	                	</div>
				 		
	                </li>
	            </ul>
		</div>			
	</div>
	
    <div>
    	    		<p><span><a href="https://www.bnnbloomberg.ca/markets">Markets</a></span></p><p>
			As of:  
			{{timeStamp.date}} <br>
			{{timeStamp.time}}
		</p>
    </div>	

	    <div>
        <div>
            <h3>Markets</h3>
			<div ng-class="{ 'overflow' : ! showBoards }" ng-cloak="">
				<p><span ng-click="showBoards = ! showBoards"><span ng-cloak="" ng-show="currentBoardShortName">{{ currentBoardShortName }}</span><span></span></span></p><ul>
		        							<li ng-click="boardClick('Markets Overview', 'Markets', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Markets</li> 
											<li ng-click="boardClick('Indices', 'Indices', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Indices</li> 
											<li ng-click="boardClick('Currencies', 'Currencies', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Currencies</li> 
											<li ng-click="boardClick('Energy', 'Energy', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Energy</li> 
											<li ng-click="boardClick('Metals', 'Metals', '//data.bnn.ca/dispenser/hydra/dapi/stockChart?s=%s')">Metals</li> 
							        </ul>
            </div> 
		</div>
        <div>
		 	<div> 
				<div ng-cloak="" data-sticky="false">
					<div ng-hide="!dataLoaded">
						<div>
							<ul>
								<li ng-repeat="group in groupArray" ng-class="$first ? 'active' : '' " ng-click="groupClick(group.name, $event)">
									
								</li>
							</ul>					
							<div ng-repeat="group in groupArray" data-group="{{group.name}}" ng-class="$first ? '' : 'hide' ">
							 	<div ng-repeat="data in group.data" ng-cloak="" ng-class="$first &amp;&amp; group.RICS[$index].showChart ? 'selected' : '' ">
							 		<a ng-if="group.RICS[$index].link != null" ng-href="{{group.RICS[$index].link.href}}">
								 		<div>
								 			<p>{{data.symbol | reutersRICLabelFormat:group.RICS}}</p>
									 		<p>{{data.netChng  | number: 4 }}</p>
									 		<p>{{data.netChng  | number: 2 }}</p>
									 		<p><span ng-if="group.RICS[$index].isCurrency">{{data | displayCurrencySymbol}}</span> {{data.price  | number: 4 }}</p>
									 		<p>{{data.price  | number: 2 }}</p>
									 	</div>	
								 		
								 	</a>
								 	<div ng-if="group.RICS[$index].link == null">
								 		<div>
								 			<p>{{data.symbol | reutersRICLabelFormat:group.RICS}}</p>
									 		<p>{{data.netChng  | number: 4 }}</p>
									 		<p>{{data.netChng  | number: 2 }}</p>
									 		<p><span ng-if="group.RICS[$index].isCurrency">{{data | displayCurrencySymbol}}</span> {{data.price  | number: 4 }}</p>
									 		<p>{{data.price  | number: 2 }}</p>
									 	</div>	
								 		
								 	</div>
							 	</div>				 							
							</div>
						</div>
					</div>
				</div>		
			</div> 	 	
        </div>
    </div>    
</section>


      
    
    
        

<div ng-cloak="" ng-controller="StockTicker" ng-init="init()">
			            <div>
				<div>					
				</div>
			</div>
		

	    <div id="tickerWrapper">
	    <ul>
	    	<li ng-repeat="stock in tickerData"><a href="https://www.bnnbloomberg.ca/stock/%7B%7B%20stock.symbol%20%7D%7D">
		    	<span>{{ stock.symbol }}</span>
	    		<span>{{ stock.price | currency }}</span>
	    		<span bm-market-icon-indicator="" bm-net-change="{{stock.netChng | number: 2}}">&nbsp;</span>
	    		<span>{{ stock | formatPrefix }}{{ stock.netChng | formatNetChange }}</span>
	    		</a>
	    	</li>
		</ul>
	</div>
    

</div>

      
  
              </div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/danish-nuclear-startup-taps-billionaire-for-asian-reactor-1.1527485.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25215398</guid>
            <pubDate>Wed, 25 Nov 2020 23:20:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Discord bans me for using their official client]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25214777">thread link</a>) | @jkcclemens
<br/>
November 25, 2020 | https://annaclemens.io/discord | <a href="https://web.archive.org/web/*/https://annaclemens.io/discord">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section>
      

      <p>
        Quick note: I don't really have a blog, but I wanted to publish this
        on my site, so this just has some quick styles applied.
      </p>

      <hr>

      <p>
	<strong>Resolution</strong>: My Discord account has been unbanned. After posting this page on Hacker News, the head of Discord's anti-abuse team saw it and looked into the issue. It turns out that my use of a third-party Discord client called Ripcord was the reason for my ban. At the time of the ban, I had been using this client for years, but I wasn't actively using it. I was actually using the official client, hence the older title of this page, but the third-party client was open on my laptop in the background. I leave this page here to chronicle how unacceptable Discord's response to this was.
      </p>

      <hr>

      <p>
        It's true: Discord banned me for using their own client. On 1
        November, I was scrolling through my old DMs. It was kind of messy, so
        I started to close some of them (which really just <em>hides</em>
        them). After closing maybe around seven of them, Discord booted me
        back to the login screen. I thought that was weird, but I grabbed my
        phone to scan the QR code to log in, but it didn't work. Annoyed, I
        manually typed in my login details only to find that my account has
        been disabled.
      </p>

      <h2>1 November</h2>

      <p>
        On the same day, 1 November, I opened a ticket (9765093) stating that
        I wasn't sure why my account was disabled and that I would like to
        know. They had sent me an email telling me that my account had been
        disabled, but the email only listed a vague list of reasons that could
        have caused the ban, and I didn't feel that I had done any of them.
      </p>

      <h2>3 November <small>2 days</small></h2>

      <p>
        On 3 November, two days later, Discord got back to me and let me know
        that I had received an email stating why my account was disabled
        (false) and that they had reviewed my ban and would not be reinstating
        my account.
      </p>

      <p>
        The same day, I responded to their email, stating that their
        explanation wasn't good enough and that I hadn't done anything
        wrong. I demanded they give me an actual reason and reinstate my
        account.
      </p>

      <h2>6 November <small>5 days</small></h2>

      <p>
        Three days go by with no response from Discord. On 6 November, I send
        another response to their email, reiterating my desires and asking
        that I at least be able to transfer power of my larger servers if they
        insist on being corrupt.
      </p>

      <h2>12 November <small>11 days</small></h2>

      <p>
        Another six days without a peep from Discord. 12 November: I send yet
        another response, reiterating what I had said in previous emails and
        asking to be put in contact with a GDPR officer to get the data I
        want.
      </p>

      <h2>14 November <small>13 days</small></h2>

      <p>
        After two more days, Discord <em>still</em> has <strong>not</strong> responded outside of
        the initial email I received. On 14 November, I file a new ticket
        (9984772) and mention my previous ticket number and restate that I
        would like a reason why my account was banned and to have my account
        reinstated, considering I hadn't actually done anything besides <em>use
        their official client</em>.
      </p>

      <h2>17 November <small>16 days</small></h2>

      <p>
        After three days, on 17 November, the new ticket gets a
        response. Discord gives me the same list of reasons (a list of bullet
        points that count as "spam and/or platform abuse") and assure me that
        they understand "you may not have malicious intent, [but] we have to
        protect Discord as a whole, and this behavio[u]r can hurt Discord and
        its users." They also go on to mention that as a "one-time gesture",
        they "went ahead" (past tense) and lifted the ban on my account.
      </p>

      <p>
        Hooray, I guess. I go to log in to Discord and it turns out that was a
        lie. My account is still disabled. I figure maybe it needs some time
        to propagate the change, but after hours and then days of trying, my
        account remains disabled. During these initial attempts on 17
        November, I sent a response to Discord, stating that I would like to
        know the real reason I was banned, since what I was doing while I was
        banned wasn't spam or platform abuse, it was closing old DMs manually
        with the official client, a supported use-case. I also made note that my
        account had not been unbanned.
      </p>

      <h2>18 November <small>17 days</small></h2>

      <p>
        On 18 November, my account is still banned despite Discord saying they
        would lift the ban, so I send a quick response asking when the ban
        will be lifted.
      </p>

      <h2>19 November <small>18 days</small></h2>

      <p>
        On 19 November, I ask again, noting that this is the third time I've
        replied to this ticket and still not received a response.
      </p>

      <h2>20 November <small>19 days</small></h2>

      <p>
        On 20 November, I open yet another new ticket (10088193), reference
        the old one, and ask why I haven't been unbanned, demanding that they
        honour their word and lift my ban.
      </p>

      <h2>25 November <small>24 days</small></h2>

      <p>
        On 25 November, <em>eight days</em> after I was told my account would be
        unbanned and <em>twenty-four days</em> after the ban in question, I still
        have not heard from Discord. I was (and am still) banned for doing
        nothing wrong. Discord did not deign to reply to my last ticket at
        all, but I'm filing another one today (25 Nov, 10166788). I will
        continue to update this log of communications as time goes on.
      </p>
    </section>
  

</div>]]>
            </description>
            <link>https://annaclemens.io/discord</link>
            <guid isPermaLink="false">hacker-news-small-sites-25214777</guid>
            <pubDate>Wed, 25 Nov 2020 22:01:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ten Commandments of Egoless Programming]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25213591">thread link</a>) | @kiyanwang
<br/>
November 25, 2020 | https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html?m=1 | <a href="https://web.archive.org/web/*/https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-1360687395129563554" itemprop="articleBody">
<p><span>We are nothing but the values we carry. All through my life thus far, I tried to influence people around me with the virtues I value. Thanks to some good reading habits I had inculcated, and the fortune of being in good community of peers and mentors alike, I managed to have read some real good books. This post is about the 10 commands of egoless programming in Weinberg's book. I shall explain the commandments based on my experience here.</span></p><p data-pm-slice="1 1 []"><span>So very many decades ago, Gerald M. Weinberg authored&nbsp;<a href="https://www.goodreads.com/book/show/2229333.Psychology_of_Computer_Programming"><u>The Psychology of Computer Programming</u></a>. In it, he listed <strong>The Ten Commandments of&nbsp;</strong><a href="https://en.wikipedia.org/wiki/Egoless_programming"><strong><u>Egoless Programming</u></strong></a>, which remains relevant even today for us as not just programmers but as team-members.</span></p><p><span>Weinberg is regarded as a pioneer in taking a people-centric approach to computing, and his work endures as a good guide to intelligence, skill, teamwork, and problem-solving power of a developer. When they appear to inspire and instruct, we find that they can apply to just about every business area, and even to life itself.</span></p><p><span>Here are the 10 important lessons developers, project managers, and stakeholders would do well to keep in mind during the project lifecycle.</span></p><ol><li><p><span><strong>Understand and accept that you will make mistakes.</strong><br>Mistakes are rarely fatal in our industry, so find them early, before they make it into production, learn from them, and move on.</span></p></li><li><p><span><strong>You are not your code.</strong><br>The point of a review is to find problems. Don't take it personally when one is found. Remember&nbsp;<a href="https://olxpeople.atlassian.net/wiki/spaces/OPETE/pages/940179552">my words</a>, ‚ÄúTo err is only human, repeating it is what makes you either evil or insane‚Äù.</span></p></li><li><p><span><strong>No matter how much "karate" you know, someone else will always know more.</strong><br>Seek and accept input from others. You can learn new techniques if you just ask. Always remember, it is never too late to learn.</span></p></li><li><p><span><strong>Don't rewrite code without consultation.</strong><br>It is always a good idea to pair-up and have conversations on the code that you are tempted to re-write because you think it is bad. Your risks are much lesser if the code is backed by Unit tests. The least you can do is get it code reviewed before pushing code to main-stream branch.</span></p></li><li><p><span><strong>Treat people who know less than you with respect and patience.</strong><br>Don‚Äôt be a bully. Seriously, just don‚Äôt be one. Grow up!</span></p></li><li><p><span><strong>The only constant in the world is change.</strong><br>Things change, sometime for better and sometimes for worse. There are some things in your control which you can leverage to change things for better. Be the change that you wish for good. Also be willing to accept change for the overall good of the team.</span></p></li><li><p><span><strong>The only true authority stems from knowledge, not from position.</strong><br>Don't wield a title like a badge of "rightness."&nbsp;<span>If you want to be loved and respected in an egoless environment, cultivate knowledge. It may or may not lead to authority, but sure leads to love and respect from others. </span></span></p></li><li><p><span><strong>Fight for what you believe, but gracefully accept defeat.</strong><br>Open culture is not being polite in the front and back-bitching in the back. Rise up, voice your concerns, be heard, and make your point of view by doing your homework, all with an intent to help and learn otherwise. You can‚Äôt accept defeat, if you carry the burden of your ego. </span></p></li><li><p><span><strong>Don't be "the guy in the room".</strong><br>There are so many beer buddies, movie mates, cigarette companions, and what not, who can come together or fight fiercely on any non-professional topics by respecting each other; but definitely not discuss and debate openly, work related matters for team‚Äôs betterment. Just don‚Äôt be that guy in the room.  </span></p></li><li><p><span><strong>Critique code instead of people ‚Äì be kind to the coder, not to the code.</strong><br>Pour your frustration on lifeless things instead of on emotional beings. Corollary, if someone were to show his frustrations on you instead of your work, be a little polite to him, discounting it as emotional down syndrome. I have been on both sides, and so will you sometime. Let us support one another and grow together.</span></p></li></ol><p><span>Just to re-iterate, these commandments are still incredibly relevant. Put it to deliberate practice and with time they will bring out a better developer and co-worker in you.</span></p><p><span>You can get this book from <a href="https://amzn.to/3lZvXr9" target="_blank">Amazon</a>.</span></p>

</div></div>]]>
            </description>
            <link>https://blog.codonomics.com/2020/11/ten-commandments-of-egoless-programming.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25213591</guid>
            <pubDate>Wed, 25 Nov 2020 19:59:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[This is how Google will collapse]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25213493">thread link</a>) | @partingshots
<br/>
November 25, 2020 | http://www.sfu.ca/olc/blog/engage/how-google-will-collapse | <a href="https://web.archive.org/web/*/http://www.sfu.ca/olc/blog/engage/how-google-will-collapse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>Previously published in&nbsp;<a href="https://hackernoon.com/how-google-collapsed-b6ffa82198ee">HACKERNOON</a>. Originally written by SFU Masters of Digital Media student Daniel Colin James.&nbsp;Re-published with permission of the writer.</em></p>
<p><em>Illustration Credit:&nbsp;</em><a href="https://mandelasmith.artstation.com/">Mandela Smith</a></p>
<hr>
<p>Google made almost all its money from ads. It was a booming business ‚Äî until it wasn‚Äôt. Here‚Äôs how things looked right before the most spectacular crash the technology industry had ever seen.</p>
<div>
<h3>The crumbling of Google‚Äôs cornerstone</h3>
<p>Search was Google‚Äôs only unambiguous win, as well as its&nbsp;<a href="http://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html" rel="noopener" target="_blank" data-href="http://www.cnbc.com/2017/01/26/googlealphabet-reports-fourth-quarter-2016-earnings-q4.html">primary source of revenue</a>, so when Amazon&nbsp;<a href="http://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/" rel="noopener" target="_blank" data-href="http://www.geekwire.com/2017/amazon-continues-grow-lead-google-starting-point-online-shoppers/">rapidly surpassed Google</a>&nbsp;as the top product search destination, Google‚Äôs foundations began to falter.&nbsp;As&nbsp;<a href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/" rel="noopener" target="_blank" data-href="https://techcrunch.com/2016/08/11/google-isnt-safe-from-yahoos-fate/">many noted</a>&nbsp;at the time, the online advertising industry experienced a major shift from search to discovery in the mid-2010s.</p>
<p>While Google protected its monopoly on the dying search advertising market, Facebook ‚Äî Google‚Äôs biggest competitor in the online advertising space ‚Äî got on the&nbsp;<a href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417" rel="noopener" target="_blank" data-href="https://www.emarketer.com/Article/Google-Facebook-Increase-Their-Grip-on-Digital-Ad-Market/1015417">right side of the trend</a>&nbsp;and dominated online advertising with its in-feed native display advertising.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.1.jpeg" width="533" height="239"></p>
<p><em><span>The people who turned to Amazon over Google? <a href="https://cdn.geekwire.com/wp-content/uploads/2017/01/Screen-Shot-2017-01-13-at-10.40.08-AM.png">The 18-29 led the way</a></span></em></p>
<p>In late 2015, Apple ‚Äî Google‚Äôs main competitor in the mobile space ‚Äî added a feature to their phones and tablets that allowed users to block ads.</p>
<p>Devices running iOS were responsible for an&nbsp;<a href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue" rel="noopener" target="_blank" data-href="http://appleinsider.com/articles/15/05/27/apples-ios-drives-75-of-googles-mobile-advertising-revenue">estimated 75%</a>&nbsp;of Google‚Äôs revenue from mobile search ads, so by making this move, Apple was simultaneously weighing in decisively on the great ad blocking debate of the 2010s and dealing a substantial blow to the&nbsp;<a href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/" rel="noopener" target="_blank" data-href="https://techcrunch.com/2016/07/24/apple-lays-the-groundwork-to-kill-online-advertising/">future of online advertising</a>.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.3.jpeg" width="533" height="196"></p>
<p><em><sub>The rising number of users blocking ads on mobile showed no signs of slowing down</sub></em></p>
</div>
<div>
<p>A year later, as the internet went mobile, so too did ad blocking. The number of people blocking ads on a mobile device grew&nbsp;<a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" rel="noopener" target="_blank" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">102% from 2015 to 2016</a>; by the end of 2016, an estimated 16% of smartphone users globally were&nbsp;<a href="https://pagefair.com/blog/2016/mobile-adblocking-report/" rel="noopener" target="_blank" data-href="https://pagefair.com/blog/2016/mobile-adblocking-report/">blocking ads</a>&nbsp;when browsing the internet on a mobile device. The number was&nbsp;<a href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333" rel="noopener" target="_blank" data-href="https://www.emarketer.com/Article/Why-More-than-Quarter-of-US-Internet-Users-Block-Ads/1014333">as high as 25%</a>&nbsp;for desktop and laptop users in the United States, a country that accounted for&nbsp;<a href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/" rel="noopener" target="_blank" data-href="https://www.statista.com/statistics/266250/regional-distribution-of-googles-revenue/">47% of Google‚Äôs revenue</a>.</p>
<p>The people most likely to block ads were also the most valuable demographic:&nbsp;<a href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546" rel="noopener" target="_blank" data-href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546"><em>millennials and high earners</em></a><em>.</em></p>
<p><em><img src="http://www.sfu.ca/olc/sites/default/files/1.4.png" width="533" height="300"><br></em></p>
</div>
<div>
<p><em><sub>Young users are a good indicator for the future of technology, and&nbsp;<a href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546" rel="noopener" target="_blank" data-href="http://marketingland.com/ad-blocker-usage-highest-among-key-advertiser-demos-millennials-and-high-earners-143546">they were heavy users of ad blocking&nbsp;software</a></sub></em></p>
<p><strong>Internet users had spoken, and they hated ads.</strong></p>
<p>In early 2017, Google announced its plans to build an ad blocker into its popular Google Chrome browser. Google‚Äôs ad blocker would only block ads that were deemed unacceptable by the&nbsp;<a href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads" rel="noopener" target="_blank" data-href="http://www.thedrum.com/news/2016/09/16/procter-gamble-unilever-google-facebook-and-more-form-coalition-better-ads">Coalition For Better Ads</a>, effectively allowing the company to use its dominant web browser to strengthen its already dominant advertising business.</p>
<p>Even after making this desperate and&nbsp;<a href="http://fortune.com/2017/04/20/google-ad-blocker/" rel="noopener" target="_blank" data-href="http://fortune.com/2017/04/20/google-ad-blocker/">legally questionable</a>&nbsp;move, it would quickly become clear to Google that even though ads were getting better, ad blocking numbers would&nbsp;<a href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/" rel="noopener" target="_blank" data-href="http://adage.com/article/digital/ad-blocking-increases-consumers-improving/305978/">continue to rise</a>. Google had given even more people a small taste of what an ad-free internet experience could look like.&nbsp;<strong>The company discovered that it wasn‚Äôt just annoying ads that people didn‚Äôt like; it was ads in general.</strong></p>
<p><strong><img src="http://www.sfu.ca/olc/sites/default/files/1.5.png" width="533" height="300"></strong></p>
<p><em><sub>The advertising industry trying to figure out why people hated ads so much</sub></em><strong><br></strong></p>
</div>
<p>A key platform where Google served ads was YouTube, which it bought in 2006 and quickly turned into one of its biggest entities. But even with a&nbsp;<a href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html" rel="noopener" target="_blank" data-href="http://www.huffingtonpost.com/2013/03/21/youtube-stats_n_2922543.html">sixth of the world</a>&nbsp;visiting this video-sharing behemoth every month, YouTube&nbsp;<a href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967" rel="noopener" target="_blank" data-href="https://www.wsj.com/articles/viewers-dont-add-up-to-profit-for-youtube-1424897967">never became profitable</a>. In an attempt to combat the effect of ad blockers, YouTube launched an ad-free subscription model in late 2015, but the subscription numbers were&nbsp;<a href="http://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music" rel="noopener" target="_blank" data-href="http://www.theverge.com/2016/11/2/13498470/youtube-red-subscribers-video-content-music">underwhelming</a>.</p>
<p>YouTube‚Äôs already insurmountable problems multiplied in early 2017 as advertisers&nbsp;<a href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube" rel="noopener" target="_blank" data-href="http://www.fiercepharma.com/marketing/google-scrambling-for-solutions-after-advertiser-departures-youtube">began to pull out amid ad placement controversies</a>, and huge revenue generators began to&nbsp;<a href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797" rel="noopener" target="_blank" data-href="http://www.ibtimes.com/pewdiepie-starts-weekly-twitch-show-uploads-youtube-over-party-video-2523797">leave the site</a>. Even those who weren‚Äôt blocking ads had trained themselves to ignore them entirely. Researchers dubbed this phenomenon ‚Äú<a href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/" rel="noopener" target="_blank" data-href="http://www.tobiipro.com/fields-of-use/marketing-consumer-research/advertising/">banner blindness</a>‚Äù. The average banner ad was clicked on by a dismal&nbsp;<a href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/" rel="noopener" target="_blank" data-href="https://www.thinkwithgoogle.com/intl/en-gb/planning-tool/display-benchmarks/">0.06% of viewers</a>, and of those clicks, roughly&nbsp;<a href="http://www.goldspotmedia.com/fat-finger-report/" rel="noopener" target="_blank" data-href="http://www.goldspotmedia.com/fat-finger-report/">50% were accidental</a>.</p>
<p>Research showed that&nbsp;<a href="http://www.bannersnack.com/blog/build-trust-display-ads/" rel="noopener" target="_blank" data-href="http://www.bannersnack.com/blog/build-trust-display-ads/">54% of users</a>&nbsp;reported a lack of trust as their reason for not clicking banner ads and 33% found them completely&nbsp;<a href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf" rel="noopener" target="_blank" data-href="http://downloads.pagefair.com/reports/adblocking_goes_mainstream_2014_report.pdf">intolerable</a>. These figures painted a pretty grim picture for the sustainability of online advertising, but especially for Google‚Äôs position within the industry.</p>
<p><em>Google‚Äôs mighty engine had started to sputter.</em></p>
<p><strong>A chance to pivot, and how Google missed&nbsp;it</strong></p>
<p>If losing a major portion of their audience and annoying the rest wasn‚Äôt bad enough, Google also failed to get ahead of one of the biggest shifts in technology‚Äôs history. They recognized the importance of artificial intelligence but their approach missed the mark. Since Google‚Äôs search pillar had become unstable, a lot was riding on the company‚Äôs strategy for artificial intelligence.</p>
<p><em>‚ÄúWe will move from mobile first to an AI first&nbsp;world.‚Äù</em></p>
<p>Google‚Äôs then-CEO Sundar Pichai&nbsp;<a href="https://blog.google/topics/inside-google/this-years-founders-letter/" rel="noopener" target="_blank" data-href="https://blog.google/topics/inside-google/this-years-founders-letter/">famously predicted</a>&nbsp;in 2016 that ‚Äú<em>the next big step will be for the very concept of the ‚Äòdevice‚Äô to fade away‚Äù&nbsp;</em>and that<em>&nbsp;‚Äúover time, the computer itself ‚Äî whatever its form factor ‚Äî will be an intelligent assistant helping you through your day. We will move from mobile first to an AI first world.‚Äù</em></p>
<p>Google‚Äôs ability to acknowledge the coming trend and still fail to land in front of it reminded many observers of its catastrophic failures in the booming industries of social media and instant messaging.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.6.jpeg" width="533" height="296"></p>
<p><em><sub>Sundar Pichai wondering how to monetize a virtual assistant</sub></em></p>
<p><strong>Google vs.&nbsp;Amazon</strong></p>
<p>Meanwhile, in 2014, Amazon released a product called Amazon Echo, a small speaker that could sit in your home and answer questions, perform tasks, and buy things online for you. The Echo was a&nbsp;<a href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1" rel="noopener" target="_blank" data-href="http://www.businessinsider.com/amazon-echo-success-could-spell-big-trouble-for-google-2017-1">smash success</a>. Google released its copycat product, Google Home, two years later, but it was already&nbsp;<a href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology" rel="noopener" target="_blank" data-href="https://www.theguardian.com/technology/2017/jan/22/home-battleground-amazon-google-voice-technology">too late to catch up</a>, and had no clear revenue strategy.</p>
<p>Alexa ‚Äî the assistant that lived inside the Echo ‚Äî on the other hand, was quickly integrated into several products and services, and its monetization model was clear, viable, and most importantly future-friendly. The Echo made it easy to order products through Amazon, and every time someone used an Echo to purchase something, Amazon made money.</p>
<p>Google extended the reach of their virtual assistant by building it into Android, but doing so still didn‚Äôt provide an answer for how the technology would generate enough revenue to sustain Google‚Äôs expanding repertoire of expensive innovations.</p>
<p>Google‚Äôs ads relied on screens, yet voice interaction subverted screens entirely. Google briefly tried playing audio ads with the Google Home, but consumers were&nbsp;<a href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/" rel="noopener" target="_blank" data-href="https://www.engadget.com/2017/03/17/google-home-ads-bad-precedent/">far from receptive</a>. Investors&nbsp;<a href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1" rel="noopener" target="_blank" data-href="http://www.businessinsider.com/google-ceo-sundar-pichai-responds-to-concerns-over-monetizing-voice-search-2017-1">started to voice their concerns in 2017</a>, but Sundar Pichai told them not to worry, leaving them to assume that Google would use their age-old strategy and analyze users‚Äô voice searches so that users could be shown more suitable ads on devices with screens.</p>
<p><img src="http://www.sfu.ca/olc/sites/default/files/1.7.jpeg" width="533" height="336"></p>
<p><em><sub>Alexa celebrating its victory over Google</sub></em></p>
<p>Headlines in early 2017&nbsp;<a href="https://www.wired.com/2017/01/ces-alexa-in-everything/" rel="noopener" target="_blank" data-href="https://www.wired.com/2017/01/ces-alexa-in-everything/">proclaimed</a>&nbsp;that ‚ÄúAlexa Just Conquered CES. The World is Next.‚Äù Amazon then made their technology&nbsp;<a href="http://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/" rel="noopener" target="_blank" data-href="http://www.zdnet.com/article/amazon-opens-echo-microphone-tech-to-third-party-alexa-devices/">available</a>&nbsp;to third party manufacturers, putting even more distance between the two companies. Amazon&nbsp;<a href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/" rel="noopener" target="_blank" data-href="http://www.investors.com/news/technology/amazon-confronts-microsoft-google-ibm-in-cloud-computing-wars/">had already beaten Google once before</a>, holding 54% of the cloud computing market (compared to Google‚Äôs 3%) in 2016, and they were just getting started. By early 2017, Amazon&nbsp;<a href="http://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html" rel="noopener" target="_blank" data-href="http://www.cnbc.com/2017/03/31/competing-with-amazon-is-crushing-retailers.html">had begun closing in</a>&nbsp;on&nbsp;<a href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail" rel="noopener" target="_blank" data-href="https://www.forbes.com/sites/groupthink/2017/02/03/amazon-go-is-the-future-plus-4-reasons-why-amazon-might-just-win-retail">the entire</a>&nbsp;<a href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4" rel="noopener" target="_blank" data-href="http://www.businessinsider.com/retailers-are-going-bankrupt-at-a-staggering-rate-2017-4">retail industry</a>.</p>
<p><strong>Ads weren‚Äôt&nbsp;forever</strong></p>
<p>At its peak, Google had a massive and loyal user-base across a staggering number of products, but advertising revenue was the glue that held everything together. As the numbers waned, Google‚Äôs core began to buckle under the weight of its vast empire.</p>
<p>Google was a driving force in the technology industry ever since its disruptive entry in 1998. But in a world where people despised ads, Google‚Äôs business model was not innovation-friendly, and they missed several opportunities to pivot, ultimately rendering their numerous grand and ambitious projects unsustainable. Innovation costs money, and Google‚Äôs main stream of revenue had started to dry up.</p>
<p>In a few short years, Google had gone from a fun, commonplace verb to a reminder of how quickly a giant can fall.</p>
<h2><img src="http://www.sfu.ca/~sfuolc/OLC/Website/Forall/About-Author-Top.png" width="517" height="16"></h2>
<p><em><img src="http://www.sfu.ca/olc/sites/default/files/1.2.jpg" width="90" height="90"></em><em>Daniel is a Master of Digital Media student, currently completing his internship as a product manager at a Vancouver-based blockchain startup called Covalent. Daniel likes writing code and writing words, and he‚Äôs not sure what‚Äôs next, but he‚Äôs excited about it. You can find out what he‚Äôs up to now by checking out&nbsp;</em><em><a href="https://www.linkedin.com/in/danielcolinjames/">his LinkedIn page</a></em><em>.</em></p>
<hr>
<h2><strong>Beyond the Article</strong></h2>
<ul>
<li>Check out how Daniel's article led him to get recommended by Google's VP of Design <a href="https://danielcolinjames.com/how-google-collapsed">here</a></li>
<li>See some of his other work on his <a href="https://danielcolinjames.com/">portfolio site</a></li>
</ul>
</div></div>]]>
            </description>
            <link>http://www.sfu.ca/olc/blog/engage/how-google-will-collapse</link>
            <guid isPermaLink="false">hacker-news-small-sites-25213493</guid>
            <pubDate>Wed, 25 Nov 2020 19:51:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Office 365 spies on employees for bosses]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25212742">thread link</a>) | @samizdis
<br/>
November 25, 2020 | https://pluralistic.net/2020/11/25/the-peoples-amazon/#clippys-revenge | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/11/25/the-peoples-amazon/#clippys-revenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1636">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
publishing, viacom, cbs, paramount, simon and schuster, big publishing, merger to monopoly, random house, random penguin, Bertelsmann, argentina, correo compras, state-owned amazon, big tech, shitty technology adoption curve, shock doctrine, microsoft, microsoft 365, attack surface, tech, attack surface lectures, annalee newitz, ken liu, science fiction, little brother,

Summary:
Tech in SF; Office 365 spies on employees for bosses; A state-owned Amazon; Random Penguin to buy Simon & Schuster

URL:
https://pluralistic.net/2020/11/25/the-peoples-amazon/

Title:
Pluralistic: 25 Nov 2020 dubious-quantitative-residue

Bullet:
üêÆ

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: ACAB For Cutie (https://twitter.com/RamaTheVoice), Naked Capitalism (https://www.nakedcapitalism.com/), Slashdot (https://slashdot.org/).

--><br>
<a href="https://pluralistic.net/2020/11/25/the-peoples-amazon/"><img src="https://i1.wp.com/craphound.com/images/25Nov2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/25Nov2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/25/the-peoples-amazon/#asl">Tech in SF</a>: Annalee Newitz and Ken Liu in the final Attack Surface Lecture.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/25/the-peoples-amazon/#clippys-revenge">Office 365 spies on employees for bosses</a>: It looks like you're creating a technological dystopia. Would you like some help with that?
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/25/the-peoples-amazon/#correo-compras">A state-owned Amazon</a>: Notes on Argentina's Correo Compras.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/25/the-peoples-amazon/#merger-to-monopoly">Random Penguin to buy Simon &amp; Schuster</a>: And then there were four.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/25/the-peoples-amazon/#retro">This day in history</a>: 2010, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/11/25/the-peoples-amazon/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="asl"></a><br>
<img src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/Doctorow-Attack-Surface-Tour-Graphics-Twitter.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Today on the Attack Surface Lectures (8 panels exploring themes from the third Little Brother book, hosted by Tor Books and 8 indie bookstores): Tech in SF with Annalee Newitz and Ken Liu, recorded on Oct 16 by Interabang.</p>
<p><a href="https://www.youtube.com/watch?v=_GecqbDNbTI">https://www.youtube.com/watch?v=_GecqbDNbTI</a></p>
<p>You can watch it without Youtube's surveillance courtesy of the Internet Archive:</p>
<p><a href="https://archive.org/details/asl-tech">https://archive.org/details/asl-tech</a></p>
<p>Or get the audio as an MP3:</p>
<p><a href="https://archive.org/download/asl-tech/Tech%20in%20SF%20with%20Annalee%20Newitz%20and%20Ken%20Liu.mp3">https://archive.org/download/asl-tech/Tech%20in%20SF%20with%20Annalee%20Newitz%20and%20Ken%20Liu.mp3</a></p>
<p>Earlier instalments in the series:</p>
<p>I. Politics and Protest (Eva Galperin and Ron Deibert, hosted by The Strand):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/">https://craphound.com/attacksurface/2020/11/16/the-attack-surface-lectures-politics-and-protest-fixed/</a></p>
<p>II. Cross-Media Sci-Fi (Amber Benson and John Rogers, hosted by the Brookline Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/">https://craphound.com/attacksurface/2020/11/17/the-attack-surface-lectures-cross-media-sci-fi/</a></p>
<p>III. Race, surveillance and tech (Meredith Whittaker and Malkia Devich-Cyril, hosted by The Booksmith):</p>
<p><a href="https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/">https://craphound.com/attacksurface/2020/11/18/the-attack-surface-lectures-intersectionality-race-surveillance-and-tech-and-its-history/</a></p>
<p>IV. Cyberpunk &amp; Post-Cyberpunk (Christopher Brown and Bruce Sterling, hosted by Anderson's Bookshop)</p>
<p><a href="https://craphound.com/attacksurface/2020/11/19/the-attack-surface-lectures-cyberpunk-and-post-cyberpunk/">https://craphound.com/attacksurface/2020/11/19/the-attack-surface-lectures-cyberpunk-and-post-cyberpunk/</a></p>
<p>V. Little Revolutions (Tochi Onyebuchi and Bethany C Morrow, hosted by Skylight Books)</p>
<p><a href="https://craphound.com/news/2020/11/20/the-attack-surface-lectures-little-revolutions/">https://craphound.com/news/2020/11/20/the-attack-surface-lectures-little-revolutions/</a></p>
<p>VI. Opsec and Personal Cybersecurity (Window Snyder and Runa Sandvik, hosted by Third Place Books)</p>
<p><a href="https://craphound.com/attacksurface/2020/11/23/the-attack-surface-lectures-opsec-and-personal-cyber-security/">https://craphound.com/attacksurface/2020/11/23/the-attack-surface-lectures-opsec-and-personal-cyber-security/</a></p>
<p>VII. Sci-Fi Genre (Sarah Gailey and Chuck Wendig, hosted by Fountain Books)</p>
<p><a href="https://craphound.com/attacksurface/2020/11/24/the-attack-surface-lectures-sci-fi-genre/">https://craphound.com/attacksurface/2020/11/24/the-attack-surface-lectures-sci-fi-genre/</a></p>
<p>VIII. Tech in SF (Annalee Newitz and Ken Liu, hosted by Interabang)</p>
<p><a href="https://craphound.com/attacksurface/2020/11/25/the-attack-surface-lectures-tech-in-sf/">https://craphound.com/attacksurface/2020/11/25/the-attack-surface-lectures-tech-in-sf/</a></p>
<p>Here's a master post with all the media:</p>
<p><a href="https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/">https://craphound.com/news/2020/11/16/attack-surface-lectures-master-post/</a></p>
<p>And you can also get this as it's posted on my podcast feed ‚Äì search for "Cory Doctorow podcast" in your podcatcher or use the RSS:</p>
<p><a href="https://feeds.feedburner.com/doctorow_podcast">https://feeds.feedburner.com/doctorow_podcast</a></p>
<hr>
<p><a name="clippys-revenge"></a><br>
<img src="https://i2.wp.com/craphound.com/images/EnlqLitXEAEdtaD.jpeg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/EnlqLitXEAEdtaD.jpeg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>The Shitty Tech Adoption Curve describes the process by which oppressive technology is normalized and distributed through all levels of society. The more privilege someone has, the harder it is to coerce them to use dehumanizing tech, so it starts with marginalized people.</p>
<p>Asylum seekers, prisoners and overseas sweatshop workers get the first version. Its roughest edges are sanded off against their tenderest places, and once it's been normalized a little, we inflict it on students, mental patients, and blue collar workers.</p>
<p>Lather, rinse, repeat: before long, everyone's been ropted in. If your meals were observed by a remote-monitored CCTV 20 years ago, it was because you were in a supermax prison. Today, it's because you bought a home video surveillance system from Google/Apple/Amazon.</p>
<p>The lockdown has been a powerful accellerant for shitty technology adoption curve: the combination of an atomized polity that can't have in-person solidarity conversations and overall precarity has kicked off a powerful shock doctrine for tech surveillance.</p>
<p>Pre-pandemic, work-from-home call-center workers (mostly poor Black women) lived under surveillance that transformed "work from home" to "live at work." The tech preserved the fiction that these misclassified employees were "independent contractors."</p>
<p><a href="https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise">https://pluralistic.net/2020/10/02/chickenized-by-arise/#arise</a></p>
<p>Within days of the lockdown, this technological oppression raced up the privilege gradient in the form of "invigilation" software like Proctorio, cruel surveillance tools inflicted on university students. The company is pursuing its critics in court.</p>
<p><a href="https://pluralistic.net/2020/10/17/proctorio-v-linkletter/#proctorio">https://pluralistic.net/2020/10/17/proctorio-v-linkletter/#proctorio</a></p>
<p>Now, every remote worker is in line to get the treatment previously reserved for misclassified employees and college kids. Microsoft has rolled out on-by-default workplace surveillance for Office 365.</p>
<p><a href="https://twitter.com/WolfieChristl/status/1331221942850949121">https://twitter.com/WolfieChristl/status/1331221942850949121</a></p>
<p>The tool tracks every click and interaction by employees and presents managers with leaderboards showing relative "productivity" of each employee, down to how many mentions they get in workplace emails.</p>
<p>As Wolfie Christie points out in his thread, the arbitrary metrics that Microsoft has chosen will have a hugely distorting effect on workplace behavior. Remember Goodhart's Law: "Any measure becomes a target, and then ceases to be a useful measure."</p>
<p><a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">https://en.wikipedia.org/wiki/Goodhart%27s_law</a></p>
<p>This is the quantitative fallacy on steroids: software can't measure qualitative factors like whether your work accomplished "soft goals" like "a better product" or "a conceptual breakthrough."</p>
<p>So they blithely vaporize these qualitative elements and do math on the dubious quantitative residue left behind. It's the data scientist's version of looking for your keys under the lamp-post: "We can't do math on it, so we won't consider it."</p>
<p>It's a far cry from the early days of Microsoft, when Bill Gates mocked IBM for paying programmers by how many lines of code they produced, calling it "the race to build the world's heaviest airplane."</p>
<p>I wonder if the programmers who built this feature are subjected to it themselves? And if not, I wonder when they will be.</p>
<p>I mean, they won't be in the EU. This shit is radioactively illegal under the GDPR. But Americans have <em>freedom</em>.</p>
<p>Now, you may be thinking, "I bet the managers who use this tool will regret it when <em>their</em> bosses start using it on <em>them</em>."</p>
<p>You're thinking too small. Microsoft has ambition: they're not subjecting <em>managers</em> to this, they're subjecting <em>companies</em> to it.</p>
<p>Microsoft incentivizes companies to turn on an industry-wide comparison "feature" that sends <em>all your employee data</em> to Microsoft and then gives you a chart telling you how your employees fare against their counterparts elsewhere.</p>
<p>You get a chart. Microsoft gets fine-grained data on your company's operations ‚Äì data it can sell, or mine, or you know, just lose control over and leak all over the internet. That's some unprecedented Shitty Tech Adoption Curve accelerationism right there.</p>
<p>Not since the day when Amazon convinced Borders Books (RIP) to use it for all digital ordering and fulfilment (giving Amazon 100% access to all Borders' customer data) has a tech company offered a shadier B2B deal.</p>
<p>Last year, Slate's Future Tense and ASU's Center for Science and the Imagination asked me to write some fiction illustrating the Shitty Technology Adoption Curve. The result it "Affordances," a story that grows dismally more relevant with each passing day.</p>
<p><a href="https://slate.com/technology/2019/10/affordances-cory-doctorow-sf-story-algorithmic-bias-facial-recognition.html">https://slate.com/technology/2019/10/affordances-cory-doctorow-sf-story-algorithmic-bias-facial-recognition.html</a></p>
<hr>
<p><a name="correo-compras"></a><br>
<img src="https://i2.wp.com/craphound.com/images/correocompras.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/correocompras.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>In most of the world, the lockdown has destroyed small businesses while increasing the profits of Big Tech intermediaries like Amazon, who control access to customers on one side, and access to merchants on the other.</p>
<p>The government of Argentina is trying to avert this fate. Their postal service is launching a "state-owned Amazon" called Correo Compras, which will offer low-cost ecommerce listings to businesses, and do fulfilment through  postal workers.</p>
<p><a href="https://www.correocompras.com.ar/">https://www.correocompras.com.ar/</a></p>
<p>Correo Compras competes directly with Mercadolibre, a latinamerican ecommerce titan with a well-deserved reputation for squeezing suppliers and workers ‚Äì its deliveries are made by precarious gig economy drivers.</p>
<p><a href="https://www.opendemocracy.net/en/oureconomy/what-would-state-owned-amazon-look-ask-argentina/">https://www.opendemocracy.net/en/oureconomy/what-would-state-owned-amazon-look-ask-argentina/</a></p>
<p>Correo Compras is making a bet: that by eliminating Mercadolibre's vast margin (45%!), it can pay workers a living wage, offer fair treatment to vendors, and still sell at competitive prices.</p>
<p>They're also rolling out digital payments (BNA+) provided by the Banco Nacion, competing with Mercadolibre's Mercadopagos, which has seen a surge in usage and profits (thanks to high fees) since the lockdown. BNA+ also builds in instalment payments.</p>
<p>In many ways, Argentina is well-situated to try the experiment: it has very high internet penetration, a thriving domestic tech industry, and high levels of technological literacy.</p>
<p>It also struggles with structural poverty, thanks in part to US vulture capitalists who absorb vast amounts of its GDP to service odious debts.</p>
<p>As Cecilia Rikap points out in her Open Democracy article on the venture, Correo Compras will give Argentine state planners access to important market information ‚Äì data that currently sits in private hands thanks to digital surveillance.</p>
<p>But while data can improve industrial policy, it can also serve state oppression. The debt that is currently crushing the country is partly the price-tag for the former military dictatorship's program of mass surveillance, torture, murder and terror.</p>
<p>Data collected for beneficial purposes can be weaponized. The Dutch government collected data on minorities so that they could provide settlement services to them. Nazi occupiers used this data to locate minorities and ship them to camps.</p>
<p><a href="https://medium.com/@hansdezwart/during-world-war-ii-we-did-have-something-to-hide-40689565c550">https://medium.com/@hansdezwart/during-world-war-ii-we-did-have-something-to-hide-40689565c550</a></p>
<p>This is not merely a historical fact. Australia's spy agencies were just caught tapping into data ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/11/25/the-peoples-amazon/#clippys-revenge">https://pluralistic.net/2020/11/25/the-peoples-amazon/#clippys-revenge</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/11/25/the-peoples-amazon/#clippys-revenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25212742</guid>
            <pubDate>Wed, 25 Nov 2020 18:47:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sit Straight Up: How Dieting Is Like Posture]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25211957">thread link</a>) | @pbw
<br/>
November 25, 2020 | https://www.kmeme.com/2020/11/sit-up-straight-dieting-is-like-posture.html | <a href="https://web.archive.org/web/*/https://www.kmeme.com/2020/11/sit-up-straight-dieting-is-like-posture.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-6117893139176476722" itemprop="description articleBody">
<p>After years of struggling to lose weight, I've lost 30 pounds this year. My number one takeaway has been realizing I need to be mindful of what I eat all day, from eyes open to going to bed.</p>

<p>For years I'd been giving up single things. No soda or juice. No desserts. No chips. No fries. Yet incredibly, whatever I did it didn't make a dent, at least not for long. Which seemed totally impossible.</p>

<p>I'd just cut out thousands of calories! And... nothing. Eventually, I realized it was like pushing down on a waterbed. I'd just end up eating the calories somewhere else. Automatically and without fail.</p>

<div><p><a href="https://lh3.googleusercontent.com/-U2RZSjyEQRU/X8B4u5G8aVI/AAAAAAAFHHQ/_OawWuIiGL0lKvmMWlJnnVeqdd-SUMzJACLcBGAsYHQ/image.png"><img data-original-height="381" data-original-width="750" height="326" src="https://lh3.googleusercontent.com/-U2RZSjyEQRU/X8B4u5G8aVI/AAAAAAAFHHQ/_OawWuIiGL0lKvmMWlJnnVeqdd-SUMzJACLcBGAsYHQ/w640-h326/image.png" width="640"></a></p><p>Maintaining good posture is easy: when you notice you are slumping, sit up straight. The hard part is noticing. What's going on at that moment when you start to slump? The exact moment when your head tilts down or your back starts to curve? Where is your mind right at that moment? How are you letting this happen? I mean what the hell, who is minding the store here?</p></div>

<p>I feel like that's exactly where my mind was when I was making a late-night snack, or grabbing another handful of chips, or digging into another piece of pizza. I was there for those moments in a way, but also not there.</p><p>Honestly, sometimes I felt like a spectator. I'd look at the snack I fixed myself and say, ‚ÄúBoy I should not be eating this,‚Äù then I‚Äôd sit down and eat it. Afterward, I'd say, ‚ÄúI should not have eaten that‚Äù. Can I talk to a manager, is there no one in charge here?</p>

<p>What finally worked was pushing the desire to lose weight down deeply into every fiber of my being, so in those moments I was present, the ‚ÄúI‚Äù that I wanted to be was present. Once present, the choice was actually easy. If I'm trying to lose weight, which I am, should I eat this handful of M&amp;M's? No, no I should not.</p>

<p>How to stay present? I did mindfulness meditation for several years, and I think mindfulness is what we are talking about. It's the opposite of mindlessness, and mindlessness is the enemy. What they don't advertise is there are ways to increase mindfulness without meditation. They are just... a little weird.</p>

<p>When you have an itch, even an intense one, just observe it for a while. See what happens. Often it will go away. If it's unbearable then scratch it, but not every time, and not right away.</p>

<p>If you are doing anything rushed, like writing or cleaning or typing your password in wrong, once in a while do it really slow. Like impossibly slow. The other day I was tearing a perforated piece of paper such that I waited for each single pop, then pulled it a bit more. One time I shaved so slowly that I was enjoying listening to the individual whiskers snap.</p>

<p>The goal is not just ‚Äúdo things slowly‚Äù. The goal is to catch yourself doing something on auto-pilot and intervene with some deliberate action. To be aware of what you were doing, then modify what you were doing mindfully. It's best to do this for different activities, sporadically. Sense that the auto-pilot has taken over, then do something to disrupt that automatic behavior.</p><p><a href="https://lh3.googleusercontent.com/-fievTLupx7M/X76Ld1UoftI/AAAAAAAFHG8/qIy8zP7hJ3IFRLtE0MkjzJQpY7YMIONlgCLcBGAsYHQ/image.png"><img data-original-height="282" data-original-width="425" height="424" src="https://lh3.googleusercontent.com/-fievTLupx7M/X76Ld1UoftI/AAAAAAAFHG8/qIy8zP7hJ3IFRLtE0MkjzJQpY7YMIONlgCLcBGAsYHQ/w640-h424/image.png" width="640"></a></p>

<p>Sometimes if I'm on a mostly empty road, but I'm following someone too closely, I'll slow WAY down, until they are far in front of me. I've learned that for me this ‚Äúfollowing behavior‚Äù is very automatic.</p>

<p>After there's a gap I resume my exact same speed, but now I'm a constant five seconds behind. It's less stressful and safer, and the only downside is I'll arrive a whopping five seconds after they will. Notice you are doing something, then modify what you are doing.</p>

<p>When I finally put it together there was no grit your teeth effort required, it was just being consistently mindful of my goal, and therefore mindful as to whether my behavior was aligned with my goal. It required a light touch, not a heavy lift. If ‚ÄúI‚Äù was there, I'd make the right decision. If I was on auto-pilot, I'd make the wrong decision. So my goal was no longer really to lose weight, it was simply to always be there.</p>

<p><b>Related Posts on kmeme</b></p>
<ul><li><a href="https://www.kmeme.com/2020/09/lose-weight-with-nightmare-fuel.html">The Hungry Ancestor Diet</a></li>
<li><a href="https://www.kmeme.com/2019/09/mindfulness-is-driving-without-texting.html">Mindfulness is driving without texting</a></li>
<li><a href="https://www.kmeme.com/2016/03/mindfull-reps.html">Mindul Reps</a></li>
<li><a href="https://www.kmeme.com/2016/07/waking-up.html">Waking Up</a></li>
</ul>

</div></div>]]>
            </description>
            <link>https://www.kmeme.com/2020/11/sit-up-straight-dieting-is-like-posture.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25211957</guid>
            <pubDate>Wed, 25 Nov 2020 17:49:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[They Tried to Cancel Me]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25210750">thread link</a>) | @Reedx
<br/>
November 25, 2020 | https://www.persuasion.community/p/they-tried-to-cancel-me | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/they-tried-to-cancel-me">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F35432742-bb0c-428b-84d4-b4900c042632_4896x3264.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F35432742-bb0c-428b-84d4-b4900c042632_4896x3264.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/35432742-bb0c-428b-84d4-b4900c042632_4896x3264.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:5110873,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Things began innocently enough. </p><p>My wife, Andrea, and I emerged from Covid-reclusion one evening last July and ventured into Saratoga Springs for a dining option outdoors, so that we could safely avoid the mask-down/food-in/mask-up protocol. We also planned to check out the ‚ÄúBack the Blue‚Äù rally in support of the police, held in nearby Congress Park. We had heard about the rally through a friend, and were intrigued by the organizer‚Äôs pledge that it would be ‚Äúa positive all-inclusive‚Äù and ‚Äúpeaceful event.‚Äù We stood at the far edge of the crowd for 20 minutes or so, witnessed a little back-and-forth between rally participants and Black Lives Matter counterprotesters. One of the counterprotesters took a photo of us with his phone, and cursed, which seemed strange at the time. Soon after, we retreated to the comfort of our dinner. </p><p>The following morning, as I was preparing for my daily run, I took a peek at my email, and found several messages from an unknown sender. The first explained that my wife and I had become the targets of a rapidly expanding social media campaign bent on destroying our reputations and costing us our jobs. The sender was alerting us out of a sense of compassion, and asked to remain anonymous as he feared being labeled a traitor. His emails contained screenshots of messages disseminated in this campaign, including a photo of us, a long list of spurious accusations, some contact information, and templates for drafting emails to my department chair, the dean of the faculty, the dean of students, and the president of Skidmore College, where I am a professor of art, teaching jewelry design and metalwork.&nbsp; </p><p>Over the next few days, college administrators received a flood of poison-pen emails, most from the same template, alleging that we ‚Äúwere seen protesting with Blue Lives Matter while Skidmore alumni and students were being tear-gassed.‚Äù In point of fact, there never was any tear gas, although riot police did use pepper-bullets later that evening‚Äîmany hours after we had returned home. The poison-pen emails added that I was known to be a racist and a sexist, and that I was guilty of ‚Äúconsistent mistreatment and disregard for non-cis white males‚Äù in my classes and advocated ‚Äúexclusionary, racist and fascist ideology.‚Äù They demanded my immediate termination, as well as that of my wife, unaware that she hadn‚Äôt even taught at Skidmore since 2018.&nbsp; </p><p>The president of the college issued a guarded statement, affirming the First Amendment rights of all community members, but made no mention of the malicious campaign against me. The administration replied to those who sent individual emails (several hundred, at a minimum), pledging the college‚Äôs commitment to investigate the complaints, while avoiding any suggestion that a smear campaign conflicted with the college‚Äôs values. True to their word, the administration did investigate my teaching, combing through several years of student evaluations, searching for evidence of racial or gender bias. They would find none. Despite receiving a few personal expressions of support from Skidmore officials, Andrea and I felt wholly abandoned by the college and extremely anxious about our future. It was clear that the college would not fire me, but it was equally clear that my reputation was taking a pounding, and that the program I had worked so hard to build over the past 31 years was in jeopardy.&nbsp; </p><p><strong>A little online research revealed to me</strong> just how common it was for faculty, even tenured faculty like myself, to simply resign rather than suffer the indignity of investigations, hearings and ‚Äúre-education.‚Äù But Andrea and I resolved to stay and fight. When the investigation had run its course (six weeks later), I was informed that there would be no sanctions against me. I felt nothing. No victory. Not even relief. Someone once stole my wallet in a pool hall in Terre Haute, and returned it empty. I felt much the same then.</p><p>What my detractors failed to achieve through the administrative inquest, they partly accomplished through a boycott. My once robust enrollments fell to distressingly low numbers during the first few days, with one of the classes bottoming out at zero. </p><p>Activists posted a handbill on the door of my studio classroom: ‚ÄúSTOP: By entering this class you are crossing a campus-wide picket line and breaking the boycott against Professor David Peterson. David Peterson is notorious for the blatant sexism he treats his female students with, his outwardly transphobic treatment of trans students, and his general disregard for all students who are not white cis men‚Ä¶This is not a safe environment for marginalized students. By continuing to take this course you are enabling bigotted [sic] behavior on this campus.‚Äù</p><p>Leaving nothing to chance, a small contingent of student activists picketed my studio on the first day of classes, confronting the few remaining students with the fliers that denounced me as sexist and transphobic (this last claim having replaced ‚Äúracist‚Äù for some reason). Peer pressure has always been a sharp tool of coercion, so I won‚Äôt fault those who opted out of my classes; I hope they wish to return in future. What I cannot guarantee is how much enthusiasm I will have when the future arrives. What was my passion is, for now at any rate, just an income source.&nbsp; </p><p>In contrast to the position of the administration, many faculty colleagues from across campus supported Andrea and me. Some offered advice, some encouragement, some were just mad as hell that our students would do such a thing and think it noble.&nbsp; Without their generosity and advice, Andrea and I might have withdrawn into bitterness and considered my resignation. </p><p><strong>Media scrutiny played an unexpected role</strong> in my case. A college paper, <em>The Skidmore News</em>, published an <a href="http://skidmorenews.com/new-blog/2020/8/31/opinion-the-petersons-amp-blue-lives-matter-students-reveal-a-pattern-of-racism-among-skidmore-faculty-and-staff">opinion piece</a> by an undergraduate, asserting (without a single example) that ‚Äúthere have been many claims of Mr. Peterson making students of color and queer students feel uncomfortable and unheard.‚Äù The article said that many white professors ridiculed students of color, and that members of the campus support staff made racist comments. ‚ÄúStudents of color and Black students especially feel threatened to have staff enter their spaces or to come face-to-face with individuals that empower beliefs that inherently go against their identities,‚Äù the article said.</p><p>Within hours of the article‚Äôs publication on Aug. 31, I began receiving emails, letters and phone calls of support from a surprising mixture of folks, including alumni, parents of students, local residents and a number of journalists. Conservative media outlets, which feast on reports of cancel culture at colleges, posted their own articles, from <em>Breitbart</em> to <em>The College Fix</em> to <em><a href="https://www.nationalreview.com/2020/09/skidmore-college-professor-david-peterson-defends-his-reputation-against-student-smear-campaign/">The National Review</a></em>. The two largest regional newspapers, <em><a href="https://www.timesunion.com/news/article/Churchill-At-Skidmore-curiosity-might-get-you-15553968.php">The Albany Times Union</a></em> and <em><a href="https://dailygazette.com/2020/09/26/skidmore-professor-passes-official-look-after-students-call-for-his-ouster/">The Schenectady Gazette</a></em>, also published articles, which helped replace the rumors with facts.</p><p>So, that college-newspaper article, which might have muddied my reputation further, instead provoked events that placed public opinion squarely behind me. Demands for my termination suddenly ended. Some have suggested that the events of the past year‚Äîthe pandemic, the civil unrest, and the looming presidential election‚Äîwere contributing factors in the students‚Äô rush to judgement. Others cite the decline in civility in politics. I can accept this to a point. But I see nothing abrupt about the decline of civil discourse and free speech on college campuses. </p><p>Forty years ago, speech may have been freer, but it certainly was not free. Most of my professors in the 1970s endorsed leftist agendas. Yet to assert an unpopular view then simply required debate-preparation and pluck. Today, it requires almost reckless courage and prudent financial planning. No longer do I believe I can challenge the prevailing doctrines on campus without facing an emotionally charged response. Tears are not uncommon. Profanity is almost guaranteed. Wrong-thinking is no longer simply unpopular. It is downright risky.&nbsp; </p><p><strong>Research confirms that left-leaning faculty</strong> outnumber right-leaning faculty by a wide margin (12 to 1 is the current consensus). The student population may be less lopsided, but only slightly. But what I wonder about are the political inclinations of non-teaching staff, such as technicians, secretaries and workers in campus facilities. Blue-collar staff are assumed to be more conservative, but this is speculation. You might think that these marginalized, voiceless, underpaid employees would be the focus of student and faculty sympathies, but you‚Äôd be wrong. </p><p>I have always felt a kinship with workers in the trades‚Äîelectricians, carpenters, plumbers, and so on. My upbringing was decidedly hands-on, and many of the smartest, most generous people I have known have been those who solved problems with tools. I may be ‚Äúan artist‚Äù to some, but when my father calls me ‚Äúa metalworker,‚Äù he is flattering me. </p><p>I have come to know quite a few staff members, and many reached out to me when my troubles began. I, in turn, asked their views on free speech and open expression, and the allegations leveled against support staff in the student paper. Their responses were almost uniform: They preferred to leave their politics at home, and focus on their jobs when at work. More than one expressed it like this: ‚ÄúI keep my mouth shut, my head down, and do my job.‚Äù </p><p>Several said that they felt it was a privilege to work at the college, that they almost always enjoyed their interactions with students and faculty, and hoped their contribution was valued. I pushed harder: ‚ÄúWhat about the <em>Skidmore News</em> article?‚Äù Yes, they agreed, that was unfortunate‚Äîbut not a fair characterization of their interactions with students: ‚ÄúThese are good kids. They‚Äôll learn when they get out in the workplace,‚Äù one said. If they were hurt by the remarks in the article, they kept it to themselves. They were, without exception, gracious and forgiving. In the search for institutional values, I would recommend these.&nbsp; </p><p>T‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.persuasion.community/p/they-tried-to-cancel-me">https://www.persuasion.community/p/they-tried-to-cancel-me</a></em></p>]]>
            </description>
            <link>https://www.persuasion.community/p/they-tried-to-cancel-me</link>
            <guid isPermaLink="false">hacker-news-small-sites-25210750</guid>
            <pubDate>Wed, 25 Nov 2020 16:13:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our OS caching library, intelligent cache]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25209897">thread link</a>) | @sklivvz1971
<br/>
November 25, 2020 | https://sklivvz.com/posts/announcing-intelligent-cache-our-caching-library | <a href="https://web.archive.org/web/*/https://sklivvz.com/posts/announcing-intelligent-cache-our-caching-library">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It is with great pleasure that we are announcing today our newest open source project <a href="https://github.com/intelligenthack/intelligentcache">intelligent cache</a>. We are very enthusiastic about this project because we think we constructed a very usable interface and ecosystem which you can rely on and extend extremely easily. Let me talk to you about it.</p>
<p><a href="https://github.com/intelligenthack/intelligentcache">Intelligent Cache</a> is currently a dotnet-core, netstandard and .net 4.6.1 library but it's easily extensible to almost any other language.</p>
<p><a href="https://github.com/intelligenthack/intelligentcache"><img src="https://imgur.com/y3ZLi1nm.png" alt="intelligent cache"></a></p>
<p><a href="https://github.com/intelligenthack/intelligentcache">Fork it here</a> -- <a href="https://www.nuget.org/packages/intelligenthack.intelligentcache/">Nuget Package here</a></p>
<h2>The Cache</h2>
<p>At the heart of the library, there is a pattern (actually a monad) that defines two important things:</p>
<ul>
<li>what a cache should look like (an interface)</li>
<li>how to combine caches so they work together (a composition class)</li>
</ul>
<p>The cache interface at the moment is very minimalistic, as we try to include only what we actually need in production and not to add features based on perceived, but not actual, needs.</p>
<pre><code>public interface ICache
{
    Task&lt;T&gt; GetSetAsync&lt;T&gt;(string key, Func&lt;CancellationToken, Task&lt;T&gt;&gt; calculateValue, TimeSpan duration, CancellationToken cancellationToken = default) where T: class;

    T GetSet&lt;T&gt;(string key, Func&lt;T&gt; calculateValue, TimeSpan duration) where T: class;

    Task InvalidateAsync(string key, CancellationToken cancellationToken = default);

    void Invalidate(string key);
}
</code></pre>
<p>There are both async and sync versions of the cache to support both future and current systems that might not have adopted async or that will adopt it in the future. The two main methods are <code>GetSet</code> and <code>Invalidate</code>. The first returns an object from the cache and fills the cache using the given lambda if the key specified is empty or null. The second method, <code>Invalidate</code>, clears the current key and it's useful in case we know that the current cache has become stale, typically in case of updates.</p>
<p>The composition function chains together different caches so they "fall through": if the requested key is not present in the first cache, it looks in the second before actually fetching a new value. This is useful to create distributed caches, but also to add other kinds of behaviors as we will see below. The composition class has this signature.</p>
<pre><code>public class CompositeCache : ICache
{
    public CompositeCache(ICache level1, ICache level2)
    {
            // ...
    }

    // ICache implementation ...
}
</code></pre>
<p>At the moment we have 3 implementations of the cache, a local cache based on <code>MemoryCache</code>, a distributed cache based on Redis, and a passthrough cache. On top of these three basic building blocks, we have two classes that should be used together to distribute invalidation messages in case you need to keep caches in sync over multiple servers. </p>
<p>Here is what the dataflow of a full-fledged 2 tier distributed library looks like:</p>
<p><img src="https://imgur.com/GZX7yPg.png" alt=""></p>
<p>This cache can be built with the following composition pattern.</p>
<pre><code>ISubscriber subscriber = GetRedisSubscriber();
var invalidationChannel = "cache-invalidations";
var cache = new CompositeCache(
    new RedisInvalidationReceiver(
        new MemoryCache(/* arguments */),
        subscriber,
        invalidationChannel
    ),
    new CompositeCache(
        new RedisCache(/* arguments */),
        new RedisInvalidationSender(subscriber, invalidationChannel)
    )
);
</code></pre>
<p>Of course, there's much more information including working examples and tests on the <a href="https://github.com/intelligenthack">intelligent cache repo</a>.</p>
<h2>Extending the cache</h2>
<p>The caching library is built to be trivial to extend with your own implementation. Let's say that you wanted to log to console all operations of a cache. This can be done very easily by extending ICache and composing:</p>
<pre><code>public class LogToConsoleBehavior: ICache
{
    public T GetSet&lt;T&gt;(string key, Func&lt;T&gt; calculateValue, TimeSpan duration) where T: class
    {
        Console.WriteLine("GetSet called");
        return calculateValue();
    }

    // other methods are implemented similarly

}

ICache cache = new Cache(); // this is the cache we want to extend with logging
var logToConsoleCache = new CompositeCache(new LogToConsoleBehavior(), cache);

// now logToConsoleCache is just like cache, except it logs to console
</code></pre>
<h2>Contributions</h2>
<p>We are looking for contributors, please look at <a href="https://github.com/intelligenthack/intelligentcache/issues">our open issues</a> if you are looking for something to do. If you find this project useful, please give us a star on GitHub and share the library.</p>
<p>The project has been developed through the sponsorship of <a href="https://intelligenthack.com/en">Intelligent Hack</a> and <a href="https://isolutions.it/">iSolutions</a>. Please give them a shout out if you can.</p>
<div>
<p><a href="https://www.isolutions.it/"><img src="https://imgur.com/sBx0iT2m.png" alt="" title=""></a></p><p>
<a href="https://intelligenthack.com/en"><img src="https://imgur.com/C0a0ewMm.png" alt="" title=""></a></p></div>
</div></div>]]>
            </description>
            <link>https://sklivvz.com/posts/announcing-intelligent-cache-our-caching-library</link>
            <guid isPermaLink="false">hacker-news-small-sites-25209897</guid>
            <pubDate>Wed, 25 Nov 2020 15:00:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What is Breach and Attack Simulation]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25209359">thread link</a>) | @dkccit
<br/>
November 25, 2020 | https://www.cloudcape.de/en/what-is-breach-and-attack-simulation/ | <a href="https://web.archive.org/web/*/https://www.cloudcape.de/en/what-is-breach-and-attack-simulation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="35cb009c" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			<p>In recent years, more and more providers of so-called Breach and Attack Simulation platforms have emerged in the market. In 2017, Gartner included Breach and Attack Simulation as a new category in the ‚ÄúHype Cycle for Threat-Facing Technologies‚Äù and it was even attested that Breach and Attack Simulation has the potential to become mainstream within the next 10 years. Some even speak of a technological revolution that will fundamentally change the way companies analyze their security status in the future.</p>
<p>In this blog article I would like to answer the following questions about Breach and Attack Simulation:</p>
<ul>
<li>What is behind this new technology?</li>
<li>What problems does BAS try to solve?</li>
<li>For which companies are BAS solutions particularly suitable?</li>
<li>Which solutions are on the market and how do they differ from each other?</li>
<li>How does Breach and Attack Simulation relate to classical <a href="https://www.cloudcape.de/en/penetration-testing/">penetration testing of enterprise networks</a>?</li>
</ul>
<p>So, here we go!</p>
<h2>What is Breach and Attack Simulation?</h2>
<p>Breach and Attack Simulation is a new way of testing IT security efforts that mimics real-world attack actions to determine if the company‚Äôs various security measures actually serve their purpose. There are three different types of BAS solutions:</p>
<p><strong>Agent-based BAS solutions:</strong></p>
<p>Agent-based solutions are the simplest form of BAS. Agents are deployed across the LAN and vulnerabilities are identified to determine which routes are open to a potential attacker to move around the network. An agent-based BAS solution is very similar to vulnerability scanning, but offers much more context.</p>
<p><strong>BAS solutions based on ‚Äúmalicious‚Äù traffic</strong></p>
<p>These BAS solutions generate intrusive traffic within the network between dedicated virtual machines that serve as targets for a wide range of attack scenarios. An overview is then created of which events have not been detected and blocked by the company‚Äôs own security controls. As with agent-based BAS solutions, you get information about how an attacker could move if he enters the network.</p>
<p><strong>Cloud-based BAS solutions</strong></p>
<p>BAS solutions that are cloud-based are the closest to a real attack. They simulate numerous attack scenarios from the outside via different entry points. (so-called multi-vector attacks) and thus also the network perimeter of the company. The cloud platforms are fed with the latest threats from a wide variety of sources and are therefore always very up-to-date. Being SaaS solutions, they can be implemented very quickly.</p>
<h2>What problems do BAS tools attempt to solve?</h2>
<p>BAS solutions give companies an answer to the question ‚ÄúDo our cybersecurity programs really work? Large companies invest heavily in security products, but still do not have the confidence that they can withstand increasingly sophisticated attacks. For financial and practical reasons it is also not possible to test entire enterprise production environments permanently and manually for security vulnerabilities. Breach and Attack Simulation fills exactly this gap and allows companies to get more out of their existing security solutions by enabling continuous testing of the enterprise network at low risk.</p>
<h2>For which companies are BAS solutions suitable?</h2>
<p>If you have a look around the BAS market, you will find that many offers are tailored to large enterprise customers with high security requirements, such as financial institutions and insurance companies. It is not surprising that Breach and Attack Simulation is especially interesting for this kind of companies. They typically have numerous security products in use, a dynamic IT landscape and a high level of IT maturity. In addition, there are high demands on IT security and high compliance pressure. High-end solutions like Breach and Attack Simulation are predestined for this environment.</p>
<p>However, there is also the possibility for smaller companies to use BAS technology. Some solution providers have made their BAS tools multi-tenant ready so that smaller companies can also benefit from them via partner companies.</p>
<p>Which products are on the market and how do they differ from each other? In the still very young BAS market, a number of companies and start-ups, mainly from Israel and the USA, are thriving. In the following I would like to introduce some selected solution providers:</p>
<p><strong>SafeBreach (Israel/USA)</strong></p>
<p>SafeBreach was founded in 2014 in Tel Aviv and is therefore one of the ‚Äúolder‚Äù players on the market. SafeBreach describes their product as a Continuous Security Validating Platform, which takes over the role of a virtual ethical hacker. The platform consists of two components: the cloud management console and on-premise virtual machines called ‚ÄúBreach Simulators‚Äù, which play so-called ‚ÄúWar Games‚Äù among each other. SafeBreach‚Äôs solution is in fact based on ‚Äúmalicious‚Äù traffic that flows between the Breach Simulators themselves and the cloud.</p>
<p>SafeBreach is the pioneer in the BAS industry and now has an extensive ‚ÄúHacker‚Äôs Playbook‚Äù with thousands of attack methods, which is constantly updated by the SafeBreach Lab.</p>
<p><strong>Cymulate (Israel)</strong></p>
<p>Cymulate was also founded in Israel in 2016. In 2018, Cymulate was named a ‚ÄúCool Vendor‚Äù by Gartner and is probably the platform in the BAS market that gets the biggest hype. Among its successes, Cymulate has raised considerable amounts of funds from well-known venture capitalists. Cymulate advertises with particularly easy deployment and operation. Only a single agent is required in the network itself. The platform offers numerous attack vectors (e-mail gateway, web gateway, web application firewall, lateral movement, data loss prevention and endpoint security control) and can therefore simulate an Advanced Persistent Threat (APT). Great are the integrations to other security products, such as <strong><a href="https://www.cloudcape.de/en/vulnerability-management-as-a-service-en/">vulnerability management</a></strong>, SIEM and EDR solutions. Cymulate is very pricy. Currently, the <strong><a href="https://aws.amazon.com/marketplace/pp/B0882VSXXY?ref_=srh_res_product_title">7-Vector bundle costs 7000 USD per month via the AWS Marketplace</a></strong>. However, there is also a light version with fewer attack vectors available. On Youtube, you can get a good impression of the platform:</p>
<p><iframe title="Cymulate Immediate Threats Intelligence Module - Training" width="1200" height="675" src="https://www.youtube.com/embed/TzEdImSxNc0?start=29&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<p><strong>XM Cyber (Israel)</strong></p>
<p>XM Cyber is in my opinion another notable player in the BAS market. Since its foundation in 2016 by top leaders of the Israeli cyber intelligence community, the company has gained some attention and is currently expanding globally. The HaXM platform is relatively easy to roll out. A lightweight software agent must be installed on all critical assets, and the platform itself is delivered as Software-as-a-Service. For very security-conscious companies, the solution can also be set up on-premise. The simulations are performed in three steps:</p>
<ul>
<li>First, all critical assets are selected</li>
<li>Secondly, attacks are simulated and all attack vectors to critical assets are revealed (this is done very clearly in the platform‚Äôs ‚ÄúBattle Ground‚Äù dialogue box)</li>
<li>Lastly, detailed remediation reports and security evaluations can be exported</li>
</ul>
<p>This 3-minute demo of XM Cyber gives a very good impression of the platform and shows the impressive user interface.</p>
<p><iframe title="XM Cyber Breach and Attack Simulation Demo Video" width="1200" height="675" src="https://www.youtube.com/embed/inDj1MFxzvg?start=73&amp;feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>

<h2>How does Breach and Attack Simulation relate to manual penetration testing?</h2>
<p>The interesting question remains whether Breach and Attack Simulation can replace traditional penetration testing of networks in the future. Currently, the market adoption of Breach and Attack Simulation is not very widespread. As a penetration tester, I believe that you will not have to fear for your job any time soon. In addition, compliance requirements still demand the conducting of classic penetration tests. Last but not least, Breach and Attack Simulation is also a question of your budget ‚Äì many small and medium-sized companies are already struggling to invest in a small penetration test, so it is quite doubtful if these companies will invest in an expensive BAS solution.</p>
<p>Some BAS tools on the market only offer attack scenarios that do not include exploits and should therefore be supplemented with manual pentesting in case of doubt. It should not be forgotten that a simulation remains a simulation and collected data is analyzed externally to determine what would happen in reality. This increases the probability of false positives and false negatives.</p>
<p>Despite the obstacles that BAS solution providers still have to overcome, I am very confident that Breach and Attack Simulation will, as it matures, greatly reduce the need for traditional network pentesting. With good BAS solutions, it is possible to ‚Äúexecute‚Äù exploits that cannot cause any damage. A conscientious pentester would not even address such exploits with typical pentesting tools, because there is always the danger of damaging the customer environment. In addition, Breach and Attack Simulation provides consistent results regardless of a person‚Äôs abilities, continuously and not just as a snapshot. I am very confident that soon there will be pentest-as-a-service offerings powered by Breach and Attack Simulation that will be available to organizations of all sizes.</p>
<h2>Conclusion</h2>
<p>It is worth keeping an eye on the developments on the BAS market. In the future, the importance of BAS solutions will most likely increase significantly. In my opinion, Breach and Attack Simulation has the potential to become a viable alternative to classical Network Penetration Testing with increasing technological maturity and decreasing costs.</p>
		</div>
				</div></div>]]>
            </description>
            <link>https://www.cloudcape.de/en/what-is-breach-and-attack-simulation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25209359</guid>
            <pubDate>Wed, 25 Nov 2020 14:09:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Libgen Storage Decentralization on IPFS]]>
            </title>
            <description>
<![CDATA[
Score 269 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25209246">thread link</a>) | @jerheinze
<br/>
November 25, 2020 | https://freeread.org/ipfs/ | <a href="https://web.archive.org/web/*/https://freeread.org/ipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
        
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                  
                
                
                
<p>IPFS is here. IPFS is a de-centralized file and webhosting protocol founded on ideals of freedom and openness. The Library Genesis collection is live on IPFS as of today, accessible via <a href="http://libgen.rs/">libgen.rs</a> and <a href="https://libgen.fun/">libgen.fun</a>. IPFS is like BitTorrent but has a single global swarm, and it's accessible on the web. You can learn about the IPFS project from <a href="https://ipfs.io/">IPFS.io</a> or <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">Wikipedia</a>.</p>
<p>IPFS is the next technical revolution in peer-to-peer networking, allowing people like you to share books with readers who request them. IPFS is the next best weapon in the fight against domain take-downs and internet censorship.</p>
<p>We can now each become a founding shelf for a free, global library. Let's start.</p>
<h2 id="get-started">Get started</h2>
<p>IPFS is simple. <em>Hosts</em> (you) <em>Pin</em> files (books) using <em>Content Identifiers</em> (CID Hashes) to share them on the IPFS network. CID Hashes can represent individual files or an entire folder. Pinning saves the files to your local computer so you can share them, and others can Pin them from you.</p>
<p>Each CID Hash for Library Genesis represents 1,000 books, or about 5 gigabytes of local file storage. 100 pins = 100,000 books! Who ever told you that you couldn't start your own library?</p>
<h2 id="copyright-warning">Copyright warning</h2>
<p>Before you begin, make sure you understand <a href="https://www.nolo.com/legal-encyclopedia/what-to-do-if-your-named-bit-torrent-lawsuit.html">the legal implications of hosting and sharing copyrighted material.</a></p>
<h2 id="installing-ipfs">Installing IPFS</h2>
<p>Are you a power-user or run a server? Jump to the section on <a href="#docker-for-servers">getting started with Docker.</a></p>
<p>If you're not, just install the <a href="https://ipfs.io/#install">IPFS Desktop client</a>. Make sure to read the <a href="#system-requirements">desktop system requirements.</a></p>
<h2 id="desktop-client">Desktop client</h2>
<h3 id="system-requirements">System requirements</h3>
<p>Note that IPFS Desktop client is an alpha-stage software still in development. The command line version of the software for servers/home servers is more mature.</p>
<ul>
<li>Requires internet serice provider with unlimited bandwidth. Do not install IPFS if you have a monthly bandwidth or data cap.</li>
<li>Recommended at least 16GB RAM and Intel i5 or equivalent processor</li>
<li>Recommended at least 100 mbps, gigabit connection preferred</li>
<li>Recommended <a href="#port-forwarding">port forwarding</a></li>
</ul>
<h3 id="get-started_1">Get started</h3>
<h4 id="pin-your-first-cid-hash">Pin your first CID Hash</h4>
<p>Click Files &gt; Import &gt; From IPFS</p>
<p>Then copy and paste in your first CID Hash containing 1,000 books (about 6GB). Once it's complete, jump to the <a href="#cid-hash-index">CID Hash index</a>.</p>
<pre><code>
bafykbzaceaeofefgje22l7rhgtcgs22m32f4ysw5nqa3ty5zawfovqam7pj2c

</code></pre>

<p><img alt="Screenshot" src="https://freeread.org/img/ipfs.2.png"></p>
<h2 id="docker-for-servers">Docker for servers</h2>
<p>Previously downloaded the Library Genesis torrents for the Library Genesis Seeding Project? Follow these steps then jump to <a href="#torrents">torrents</a>.</p>
<h3 id="system-requirements_1">System requirements</h3>
<ul>
<li>Docker (<a href="https://docs.docker.com/get-docker/">docker.com/get-docker</a>)</li>
<li>Requires internet serice provider with unlimited bandwidth. Do not install IPFS if you have a monthly bandwidth or data cap.</li>
<li>Requires between 10GB or more of hard-drive space. For more information refer to the <a href="https://cryptpad.fr/sheet/#/2/sheet/view/I5UinPRnv2LNZlMQcNODieaoo7W9L1KDbJMX36OKvdE/">CID Hash index with file sizes.</a></li>
<li>Recommended at least 16GB RAM and Intel i5 or equivalent processor</li>
<li>Recommended at least 100 mbps, gigabit connection preferred</li>
<li>Recommended <a href="#port-forwarding">port forwarding</a></li>
</ul>
<h3 id="get-started_2">Get started</h3>
<h4 id="create-your-docker-container">Create your docker container</h4>
<p>You can more documentation for the Go-based IPFS Docker container at <a href="https://hub.docker.com/r/ipfs/go-ipfs/">Docker Hub.</a>.</p>
<p>/export will store your downloaded files, while the books from pinned CID Hashes will be located in /ipfs/data/blocks.</p>
<pre><code>docker run -d \
--name go-ipfs \
-v $HOME/ipfs/export:/export \
-v $HOME/ipfs/data:/data/ipfs \
-p 4001:4001 \
-p 127.0.0.1:8080:8080 \
-p 127.0.0.1:5001:5001 \
ipfs/go-ipfs:latest 
</code></pre>

<pre><code>docker start go-ipfs
</code></pre>

<h4 id="pin-your-first-cid-hash_1">Pin your first CID Hash</h4>
<p>This 'docker exec' command runs your 'go-ipfs' container with container command 'ipfs pin add'. This CID Hash contains 1,000 books, to add it run:</p>
<pre><code>docker exec go-ipfs ipfs pin add bafykbzaceaeofefgje22l7rhgtcgs22m32f4ysw5nqa3ty5zawfovqam7pj2c --progress
</code></pre>

<p>Once it's complete, jump to the <a href="#cid-hash-index">CID Hash index</a>.</p>
<p>You can also access the WebUI and add or manage pins from there. Port 5001 is the API port of the IPFS docker container and contains the same UI as IPFS desktop. You can access the webui in your browser at <a href="http://127.0.0.1:5001/webui">http://127.0.0.1:5001/webui</a>.</p>
<h4 id="cid-hash-index">CID Hash index</h4>
<p>Once you've pinned your first 1,000 you can add the next 100,000 books of the Library Genesis Scitech collection here:</p>


<h4 id="port-forwarding">Port forwarding</h4>
<p>The IPFS swarm peer port is 4001. Opening it up will help you connect, but it is optional if you can't do so. To learn how to port forward port 4001 search your <a href="https://www.google.com/search?q=ac1750+port+forwarding"><em>router model + port forward.</em></a></p>
<h2 id="torrents">Torrents</h2>
<p>Many volunteers have helped seed the torrents with the <a href="https://www.reddit.com/r/DataHoarder/comments/ed9byj/library_genesis_project_update_25_million_books/">Library Genesis Seeding Project</a>.</p>
<p>If you already downloaded the torrents you can add torrent folders to IPFS using <code>ipfs add</code></p>
<p>Start go-ipfs normally with <code>docker start go-ipfs</code></p>
<p>Configure go-ipfs to allow you link folders to the Filestore:</p>
<pre><code>docker exec go-ipfs ipfs config --json Experimental.FilestoreEnabled true
</code></pre>

<p>Restart with <code>docker stop go-ipfs &amp;&amp; docker start go-ipfs</code></p>
<p>Add the folders from where you saved them, starting with folder 1000:</p>
<pre><code>docker exec go-ipfs ipfs add $home/books/1000/ -r -w --nocopy --hash=blake2b-256 &gt;&gt;  $home/books/ipfs-add.log
</code></pre>

<p>Watch the log and check out the network activity:</p>
<pre><code>docker exec go-ipfs tail -f $home/books/ipfs-add.log
docker exec go-ipfs ipfs stats bw --poll=true --interval=1s
</code></pre>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        

      
    </div></div>]]>
            </description>
            <link>https://freeread.org/ipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25209246</guid>
            <pubDate>Wed, 25 Nov 2020 13:58:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Janki Method ‚Äì Using SRS to Improve Programming (2011)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25207890">thread link</a>) | @semicolonandson
<br/>
November 25, 2020 | https://www.jackkinsella.ie/articles/janki-method | <a href="https://web.archive.org/web/*/https://www.jackkinsella.ie/articles/janki-method">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <p><strong>EDIT: Update To JANKI Method</strong><br>
For many years after I wrote this post I have continued to use flashcards to learn and have made a number of refinements to my recommendations. I summarised these points in <a href="http://www.jackkinsella.ie/articles/janki-method-refined">Janki Method Refined</a>, part 2 of a separate article, <a href="https://drive.google.com/file/d/1JCHkqVoX598Ob_111khrGoJ5cpeh_ahU/view?usp=sharing">Guide to Autodidactism</a>, and, in 2020, within a series of YouTube videos:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/kshXDo8psj8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<p><b>This video contains my most up-to-date opinions on using SRS to improve programming. Start here.</b></p>

<p>This is a guide to becoming a productive programmer quickly. In his book <em>Outliers</em>, Malcolm Gladwell told the world it takes 10,000 hours to master something. Practice three hours a day, and you will shine in ten short years. Millions of readers felt inspired since they too could become the next Bill Gates, if only they put in the hours. As the days turned to months we discovered that 10,000 hours was a lot longer than we anticipated. Limitless potential transformed into fantasy about what might have been.</p>

<p><strong>Janki Method</strong> is an attempt to shorten the time needed to learn programming. It grew out of my impatient dream to build an automated web business that would free me financially, geographically and temporally. I didn√¢‚Ç¨‚Ñ¢t want to wait 10,000 hours. I suspect you don√¢‚Ç¨‚Ñ¢t either.</p>

<p><img src="https://confessions-production.s3.amazonaws.com/uploads/photo/file/7/anki.jpg" alt="Anki"></p>

<p>Well-intentioned learners don√¢‚Ç¨‚Ñ¢t always learn quickly, despite their smarts and enthusiasm. For most, eventual ability is determined by the volume of time expended. Malcolm√¢‚Ç¨‚Ñ¢s 10k sounds about right.</p>

<p>You√¢‚Ç¨‚Ñ¢ve read that learning by doing is better than passive reading; that expressing ideas in writing forces understanding; that knowledge needs constant revision to stay fresh; that creativity comes from linking disparate ideas; and that your past mistakes are your best teachers. How many of these ideas do you apply to your learning efforts?</p>

<p><strong>Janki Method</strong> is built on the suspicion that Malcolm√¢‚Ç¨‚Ñ¢s 10k to mastery can be hastened if you take a focused approach to learning. The core of Janki Method is the use of a spaced repetition flashcard system, <a href="http://ankisrs.net/">Anki</a>, programmed by the brilliant Damien Elmes.</p>

<p>By following my approach, I believe that any intelligent and disciplined reader can achieve proficiency* in a given field of programming (e.g. web applications, iPhone applications) in less than 12 months.</p>

<p>I call this the <strong>Janki Challenge</strong>, and I invite you to take part.</p>



<h2 id="problem-1-we-forget-too-quickly">Problem 1: We Forget Too Quickly</h2>

<p>Have you ever spent a week studying for an exam, only to forget 90% of what you learned within 2 months and everything else within a year?</p>

<p>Forgetting impedes learning knowledge-intensive skills such as programming. You need to remember various languages, solutions, libraries and gotchas if you want to build large applications. Because technical material can be so abstract and dry, you forget particularly quickly.</p>

<p><em>The first rule of <strong>Janki</strong> boosts your memory:</em><br>
<strong>√¢‚Ç¨≈ìEvery time you learn something new create a question and answer flashcard and add this card to Anki.√¢‚Ç¨ÔøΩ</strong></p>

<p>Anki is a Spaced Repetition System. Most algorithms make computers efficient; Anki makes you efficient. Using the minimal number of repetitions necessary for permanent retention, Anki drills flashcards into your long-term memory.</p>

<p>Begin by creating a deck of flashcards called, say, computer science. A deck contains many cards, and each card consists of a question and an answer. You tag these cards with the categories that best describe their contents. For example, one card might be tagged with √¢‚Ç¨ÀúRails√¢‚Ç¨‚Ñ¢, and another with √¢‚Ç¨ÀúSQL√¢‚Ç¨‚Ñ¢. Each card can have numerous tags, something useful given how technologies frequently overlap.</p>

<p>Over time you will build up a repository of knowledge on programming, cleanly categorized, easily searchable and regularly backed up in the cloud. Keeping a repository like this is useful, but it doesn√¢‚Ç¨‚Ñ¢t do anything to help you keep the knowledge inside your head. The key to this is doing your Ankis.</p>

<p>Every morning Anki calculates which cards you risk forgetting, and then prompts you to review these cards. Doing your Ankis only takes a few minutes per day, since you only need to review a fraction of your deck on any given day.</p>

<p><img src="https://confessions-production.s3.amazonaws.com/uploads/photo/file/9/daily-reviews.png" alt="daily-reviews"></p>

<p>For every card you review, Anki shows you the question side with the answer side initially blocked out. Your job is to answer the question in your head, and then reveal the answer and check whether you got it right. After you answer, four buttons appear at the bottom of the screen: √¢‚Ç¨≈ìagain√¢‚Ç¨ÔøΩ, √¢‚Ç¨≈ìgood√¢‚Ç¨ÔøΩ, √¢‚Ç¨≈ìeasy√¢‚Ç¨ÔøΩ and √¢‚Ç¨≈ìvery easy√¢‚Ç¨ÔøΩ. Assess how easily you could recall that card and then press the appropriate button. Based on which button you press, Anki determines when next to show you that card, so answering honestly is crucial if you want the algorithm to work.</p>

<p><img src="https://confessions-production.s3.amazonaws.com/uploads/photo/file/13/question1.png" alt="question1"></p>

<p>Do this every day and you will not forget.</p>

<h2 id="problem-2-we-give-up-too-soon">Problem 2: We Give Up Too Soon</h2>

<p>Most people fail to learn programming for the same reason they don√¢‚Ç¨‚Ñ¢t get good at playing guitar: they give up too soon. Although they practice hard for the first few weeks, they soon lose motivation, and give up before they get results.</p>

<p>Trying to learn using a rhythm of intense activity over short periods of time followed by long pauses is problematic. Your mind needs time to absorb what it learns, so learning skills cannot be condensed into a weekend. By accepting this reality and using a learning approach that emphasizes incremental daily effort, you will be less likely to burn out and more likely to succeed.</p>

<p><em>The second rule of <strong>Janki</strong> encourages a commitment to daily learning:</em><br>
<strong>√¢‚Ç¨≈ìYou must use Anki every single day - including weekends and holidays - and commit to doing so indefinitely.√¢‚Ç¨ÔøΩ</strong></p>

<p>Doing your Ankis must hold the same force of habit as brushing your teeth, and you should feel naughty if you ever miss your Ankis.</p>

<p>Rule 2 isn√¢‚Ç¨‚Ñ¢t as demanding as it might at first seem. After a few months of practice you will be able do your Ankis in 5-8 minutes. Finding that time shouldn√¢‚Ç¨‚Ñ¢t be a problem either, since Anki is available on smart-phone, meaning you can review while you walk to work, sit in the bus or have a spare minute at the office. Anki even synchronizes the state of your decks across all your devices, so changes to your desktop deck will be reflected across all of your devices.</p>

<h2 id="problem-3-we-learn-out-of-context">Problem 3: We Learn Out Of Context</h2>

<p>Learning out of context is wasteful. Reading a textbook from cover to cover may be interesting, but if those concepts are not relevant to the technical problems you currently face, then you will lack the mental context needed to assimilate that knowledge effectively. Incomplete understanding and wasted effort ensues.</p>

<p><em>The third rule of <strong>Janki</strong> keeps you focused on what is important in the moment:</em><br>
<strong>√¢‚Ç¨≈ìLearn in context. Pick a project, and learn only what you need to get it done.√¢‚Ç¨ÔøΩ</strong></p>

<h4 id="when-i-was-writing-this-blog-post-i-didnt-know-how-to-add-images-in-the-textile-language">When I was writing this blog post I didn√¢‚Ç¨‚Ñ¢t know how to add images in the Textile language.</h4>

<h5 id="step-1-i-googled-it">Step 1: I Googled it.</h5>
<p><img src="https://confessions-production.s3.amazonaws.com/uploads/photo/file/6/new-card1.png" alt="new-card1"></p>

<h5 id="step-2-i-tried-the-code-out-by-adding-an-image-to-the-post">Step 2: I tried the code out by adding an image to the post.</h5>
<p><img src="https://confessions-production.s3.amazonaws.com/uploads/photo/file/10/new-card2.png" alt="new-card2"></p>

<h5 id="step-3-after-checking-that-it-worked-i-added-my-new-technique-to-my-anki-deck">Step 3: After checking that it worked, I added my new technique to my Anki Deck.</h5>
<p><img src="https://confessions-production.s3.amazonaws.com/uploads/photo/file/11/new-card3.png" alt="new-card3"></p>

<h2 id="problem-4-we-think-we-can-learn-without-doing">Problem 4: We Think We Can Learn Without Doing</h2>

<blockquote>
  <p><em>√¢‚Ç¨≈ìI learned about sex the hard way √¢‚Ç¨‚Äú from a book.√¢‚Ç¨ÔøΩ <strong>Eddie Izzard</strong></em></p>
</blockquote>

<p>Like sex, programming is better and more enjoyably mastered through practice. Learning without practice insulates you from reality.</p>

<p>When you read about programming without trying out the code, you form an internal representation that is incomplete, poorly understood, and difficult to apply practically.</p>

<p>You will fail to notice critical details. Many things may seem trivial when you first read about them in a textbook. Maybe it√¢‚Ç¨‚Ñ¢s the placing of quotations around a parameter to a function, or rules about where whitespace is allowed. These overlooked points can often be critical in practice, and anything less than complete understanding will cripple your productivity. It is only by trying code out that you will notice the nuances of these rules, and really understanding the language, techniques, and commands in question.</p>

<p><em>The fourth rule of <strong>Janki</strong> grounds knowledge in reality:</em><br>
<strong>√¢‚Ç¨≈ìOnly add a card to your deck after having tried to use the item of knowledge therein.√¢‚Ç¨ÔøΩ</strong></p>

<p>Say you are working on an application powered by an SQL database. To build it you will need to refer to literature on database design and SQL (a query language for selecting records from database tables). As you work on the application you will be exposed to new concepts. Try out each new nugget of knowledge before adding it to your Anki deck. If, for example, you read about how to delete a row in a database table, then you should try deleting an actual row in your database before creating the Anki card detailing that SQL query.</p>

<h2 id="problem-5-we-make-more-mistakes-than-we-need-to">Problem 5: We Make More Mistakes Than We Need To</h2>

<p>Our past mistakes serve as excellent memory aids. This is a major reason why we learn by doing. That said, not all past mistakes are equally effective at teaching us lessons; there is a correlation between the emotional impact of an error and the length of time that lesson will remain in memory.</p>

<p>Say you make a big mistake. You accidentally push incomplete code to a live server, taking your app down for 12 hours. You panic to fix it, and as the customer complaints flood in, you feel stupid and embarrassed. This emotional punishment serves as a strong reminder of your error, and you will be more careful when pushing code to a server in future.</p>

<p>Errors with emotional impact are, thankfully, rare, and you are unlikely to need <strong>Janki Method</strong> to learn from these. But what about the rest of the mistakes we make, where the emotional element is diminished or even absent? We may need to make these mistakes many times before eventually learning our lesson.</p>

<p>Mistake repetition is the number of times you need to commit a particular mistake over a lifetime before learning a permanent lesson. Because mistakes are costly, embarrassing and potentially career threatening, it is sensible to minimize their occurrence. Bosses, customers and co-workers understand a first time mistake, and all but the most unreasonable will forgive you. They will not, however, ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.jackkinsella.ie/articles/janki-method">https://www.jackkinsella.ie/articles/janki-method</a></em></p>]]>
            </description>
            <link>https://www.jackkinsella.ie/articles/janki-method</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207890</guid>
            <pubDate>Wed, 25 Nov 2020 10:51:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[View of Andromeda over Patagonia]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25207824">thread link</a>) | @jayass
<br/>
November 25, 2020 | https://misspellede.com/us/andromeda-over-patagonia/ | <a href="https://web.archive.org/web/*/https://misspellede.com/us/andromeda-over-patagonia/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div> 
                            <p><img loading="lazy" src="https://apod.nasa.gov/apod/image/2011/M31Horizon_Ferrarino_1080.jpg" alt="Andromeda over Patagonia cover image"></p>
            <p><a href="https://misspellede.com/us/cosmos/">cosmos</a></p><p>Gerardo Ferrarino ‚Ä¢ 2020-11-25</p><p>How far can you see?  The Andromeda Galaxy at 2.5 million light years away is the most distant object easily seen with your unaided eye.  Most other apparent denizens of the night sky -- stars, clusters, and nebulae -- typically range from a few hundred to a few thousand light-years away and lie well within our own Milky Way Galaxy.  Given its distance, light from Andromeda is likely also the oldest light that you can see.  Also known as M31, the Andromeda Galaxy dominates the center of the featured zoomed image, taken from the dunes of Bah√≠a Creek, Patagonia, in southern Argentina.  The image is a combination of 45 background images with one foreground image -- all taken with the same camera and from the same location within 90 minutes.  M110, a satellite galaxy of Andromenda is visible just below and to the left of M31's core. As cool as it may be to see this neighboring galaxy to our Milky Way with your own eyes, long duration camera exposures can pick up many faint and breathtaking details.  Recent data indicates that our Milky Way Galaxy will collide and combine with the similarly-sized Andromeda galaxy in a few billion years.</p>

        </div>
    </article></div>]]>
            </description>
            <link>https://misspellede.com/us/andromeda-over-patagonia/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207824</guid>
            <pubDate>Wed, 25 Nov 2020 10:43:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I wrote a script in 4 hours that will save my hospital $40k every year]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25207590">thread link</a>) | @joshcase
<br/>
November 25, 2020 | https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year | <a href="https://web.archive.org/web/*/https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <div>
                    <div>
        
        <h2>An example of JavaScript automation at work in medicine</h2>

        
            <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/notepad-pathology-js.png"></p><p>
    	I'm not sure if you've ever tried to write an app in Notepad - but I <b>really</b> don't recommend it. Although, when inspiration strikes, you've got to make do with the tools you've got in front of you.
    </p>

    <p>
    	You can view the the <b>pathology.js</b> script repository in its entirety on <a href="https://github.com/joshcase/pathology.js/blob/master/pathology.js">GitHub</a>.
    </p>

    <p>
    	If you're often frustrated with the volume of <i>"copy and paste"</i> or simple data entry required to complete a task at your workplace or elsewhere, you're probably looking at a problem that could be solved with <b>automation</b>.
    </p>

    <p>
    	<b>Automation</b> refers to using computer programs to handle tedious or repetitive tasks, freeing up humans for more meaningful work.
    </p>

    <p>
    	I recently found myself in such a situation when I joined a general surgery unit at a hospital in Australia. The unit employs 4-6 junior doctors to start work up to 60 minutes before everyone else does, purely to manually update a list of patients under their care, along with their current management plans and pathology results.
    </p>

    <p>
    	 The idea is that all the clinical information is collated into a portable, easy-to-read format for the senior decision makers to digest. This document is affectionately known as <b>The List√¢‚Äû¬¢</b>. Here's a de-identified example of what I mean:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/list.png"></p><p>
    	Once the information is organised in this way, it provides a convenient overview of the unit and the patients under our care. The problem is that creating <b>The List√¢‚Äû¬¢</b> is a tedious and time-consuming task that virtually all of the junior doctors I know dread. On a weekend, there might be <b>40 patients</b> on <b>The List√¢‚Äû¬¢</b>, all of whom need their blood tests from the last 24 hours manually entered into the correct table - all before you start work! Ouch.
    </p>

    <p>
    	Above all, it makes the job less enjoyable, and is probably a contributor to clinician burnout, as most of the clinicians I know signed up to see and treat patients rather than to fill out spreadsheets.
    </p>

    <p>
    	Unfortunately, most hospitals in Australia and indeed the world hold their information in independent silos that aren't integrated. As a result there's a huge administrative overhead associated with checking multiple sources of information and centralising it.
    </p>

    <p>
    	In this case specifically, there are typically 5 junior doctors each weekday spending anywhere from 15 minutes to 1 hour preparing <b>The List√¢‚Äû¬¢</b>. Opening our patient information system, copying patient details, cross-checking that with our pathology system, copying across the new information - <i>ad nauseam</i>.
    </p>

    <p>
    	For simplicity's sake, let's say there's 5 doctors spending 30 minutes every week day doing this, as well as 1 doctor spending 1.5 hours each day of the weekend.
    </p>

    <p>
    	Assuming we're paying the doctors at overtime rates ($50 per hour), we can cost the labour used for this task annually as follows:
    </p>

    <p>
        Annual Cost ($AUD) = 50 * (5 * 5 * 0.5 + 2 * 1.5) * 52
    </p>

    <p>
    	Which gives us a grand total of <b>$40,300</b> annually. That's a truckload of public cash!
    </p>

    <p>
    	But given this task is highly repetitive and data-entry focused, could we try and automate it?
    </p>

    <p>
    	<i>Yes. Yes we can.</i>
    </p>

    <p>
    	Being the lazy, bratty and entitled millenial I am, after working this job for less than one week, I knew there had to be a better way.
    </p>

    <p>
    	I initially hoped to open a dialogue with the hospital IT department to allow me to deploy a Python application to handle this task for us, but I quickly realised that this route would likely take 6 months of emailing alone before they'd even consider letting me start experimenting with the problem at hand.
    </p>

    <p>
    	Furthermore, maintaining a Python environment on any of the computers where I wanted the script to run would be an absolute headache. So Python seems to be a no-go.
    </p>

    <p>
    	It wasn't until I realised (mid shift, I might add) that I didn't need executable rights to solve this problem at all.
    </p>

    <p>
    	I immediately took my lunch break and fired up <b>*Notepad*</b> of all apps to start throwing together the solution. Desperate times call for desperate measures.
    </p>

    <p>
    	The hospital I'm referring to uses a program called the <b>The Viewer</b> in an attempt to centralise all the information from the different silos I mentioned above. The Viewer is a browser-based web application that asynchronously loads information about a given patient and their admission through hospital.
    </p>

    <p>
    	<i>Because I take patient privacy really seriously and because I'm quite paranoid about accidentally leaking patient data, I've decided not to include a screenshot of The Viewer.</i>
    </p>

    <p>
    	When you open a patient on The Viewer, it first opens a blank web page, and then subsequently sends additional web requests to each of the information silos to get information about the patient - what their recent blood tests have been, what their recent scans have shown, when their outpatient appointments are <i>et cetera</i>. It then populates this initially blank web page with the information it received from the web requests to each of the respective silos.
    </p>

    <p>
    	Any time you open a webpage, depending on which browser you're running, you can right click on the page, click <b>Inspect</b> to open a special menu, and then look for some variation of the <b>Network</b> tab. This essentially allows you to view all the web traffic that is coming to and from the page you've got open.
    </p>

    <p>
    	Here's an example of the Network tab for <i>joshcase.dev</i>:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/network-tab.png"></p><p>
    	It's fairly messy to the untrained eye, but you can certainly see a few familiar things: requests to load images like <i>josh-case.png</i> (the portrait for the website footer), to load <i>main.css</i> (the file that has all the webpage structure/decoration information in it) as well as files like <i>list.png</i> that constitute the other pictures in the article.
    </p>

    <p>
    	By refreshing the web page a few times and by poking around, I eventually realised The Viewer was leveraging a script called <b>GetCompletedContent</b> to load the information from each of the information silos.
    </p>

    <p>
    	What's more, when you click on a specific web request in the Network tab, you can see which parameters were sent with the request, essentially allowing you to understand what sort of structure the server is expecting:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/network-parameters.png"></p><p>
    	Again, this image isn't from The Viewer, it's also from a <i>joshcase.dev</i> request relating to MailChimp, but you can still see the Query String Parameters that represent the type of data the corresponding server is expecting.
    </p>

    <p>
    	Working this out enabled me to reverse-engineer The Viewer pathology API to poll the hospital servers for specific patient information using JavaScript. I could leverage the knowledge of the <b>GetCompletedContent</b> request and the structure it uses to request pathology information, to automatically pull the information for a given patient.
    </p>

    <p>
    	All I had to do was send a similar request to <b>The Viewer</b> servers in the way <b>GetCompletedContent</b> did:
    </p>

    <p><img src="https://joshcase.dev/img/articles/script-in-4-hours/pathology-request.png"></p><p>
    	And the beauty of using JavaScript to attack this problem is that it will run on any hospital machine at any time - as every modern browser will interpret and run JavaScript.
    </p>

    <p>
    	If you're new around here and don't believe me, right click on this webpage (anywhere) and click <b>Inspect</b>. Look for and click on the <b>Console</b> tab. Copy the following code, and paste it into the console text box:
    </p>

    <p>
        alert("JavaScript will run anywhere.");
    </p>

    <p>
    	And then hit enter. Awesome, right?!
    </p>

    <p>
    	Once I'd written the script to emulate the <b>GetCompletedContent</b> request for the blood test silo, there were a few other implementation details to iron out, (such as parsing the response information and compiling it nicely into a readable table) but the lion's share of the detective work had been done.
    </p>

    <p>
    	A job that once took 5 people 45 minutes to complete now takes 1 person 10 minutes.
    </p>

    <p>
    	That's poised to save the hospital $400,000 over the next 10 years!
    </p>

    <p>
    	 Isn't technology awesome?
    </p>

    <p>
    	If you like stories about technology and medicine, be sure to follow me on <a href="https://twitter.com/_JoshCase">Twitter</a>.
    </p>


        <p>________________</p>        
        

    </div>
            </div>

        </div></div>]]>
            </description>
            <link>https://joshcase.dev/articles/i-wrote-a-script-in-4-hours-that-will-save-my-hospital-40k-every-year</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207590</guid>
            <pubDate>Wed, 25 Nov 2020 10:01:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asking a Tech Recruiter]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25207447">thread link</a>) | @lawik
<br/>
November 25, 2020 | https://underjord.io/asking-a-tech-recruiter.html | <a href="https://web.archive.org/web/*/https://underjord.io/asking-a-tech-recruiter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-25</small>
        <p>Since I left my comfy job as the tech lead for a SaaS product and went into running my own business I took a closer look at my relationship with recruiters. While working I mostly found the attention of recruiters slightly reassuring but often annoying. I think that annoyance is fairly common, usually built up from countless LinkedIn drive-by attempts from unreading keyword-hunting recruiters. I thought that now, out on my own, maybe this legion of recruiters can be my sales department. And they have been, to an extent.</p>
<p>During my first few days as a free agent I did reach out to one recruiter in particular. This was the one that had been closest to dislodging me from my previous position and I had a feeling he was a sharp one. I had also thrown my cousin at him and he had helped him land his first real ops gig. When I got in touch this recruiter quite swiftly landed me my first client. In parallel I started to accept more recruiter connections and had a lot more conversations with assorted recruitment agencies. It has netted a fair bit of work. But I dare say the hit-rate is mostly low.</p>
<p>The recruiters that I‚Äôve found to give the best results also give recurring results. They are the people that follow up, consider your needs, balance them with client needs and make things happen. It is my feeling that there remains a large cultural gap between the majority of recruiters and developers. I‚Äôve been thinking about how to usefully bridge that. I don‚Äôt particularly need it right now but I want to help junior developers find their way into work and more experienced developers find their way to what they actually want. I think recruiters could help there. But I think we‚Äôre still quite far off from that.</p>
<p>I reached out  about this to my network on LinkedIn (where the recruiters live). I got a response from Emy Wennerberg Kristoffersson who was willing to take a chance and reach some new developers. Emy works mostly in Sweden around Gothenburg and Helsingborg, so while she might not work in your particular area I think the information and exchange is widely applicable. We figured a good first step is to tackle some of the common skepticisms that developers tend to have around recruiters and recruitment. I hope this will be helpful. The post is not sponsored, I asked her to answer a bunch of uncomfortable and nuanced questions which I think she does gracefully. Let‚Äôs get into it.</p>
<p><strong>For some background, can you introduce yourself and tell us a little bit about your professional experience?</strong></p>
<p>Emy: My name is Emy Wennerberg Kristoffersson. I was born and raised in Helsingborg (south of Sweden), but moved to Gothenburg back in 2016. I am passionate about tech, human beings and business development. I settled on tech-recruitment because it gives me the opportunity to combine all of these areas. For the last three years, I have been working in the recruitment industry. I work for Bonsai Consulting, a Gothenburg-based company that specializes in tech recruitment.</p>
<p>I have always had a huge tech-interest. Though, this wasn‚Äôt something that I seized back in my younger years, at least not to a greater extent (apart from when loved ones encountered technical problems and I wanted to impress ‚Äì hah!). My father has always been in the IT sector so I‚Äôm quite sure that his tech skills have influenced me. I am a people-person at heart, so I eventually decided to study Human Resources in Gothenburg. In time, I got in touch with Bonsai Consulting whereupon I started to work as a researcher, and my main task was to build a network of candidates who were open to new opportunities. After a couple of months, I leveled up to a position as a recruiter and got a bigger responsibility within the company. Back then we worked broadly in recruitment and recruited to many different industries, but due to my tech-interest, the positions that related to IT and tech always ended up on my desk. One and a half years ago, we decided to work exclusively with tech recruitment due to the enormous demand within the industry.</p>
<p>One of the most interesting things in my profession is the potential for improvement in the recruitment industry. Today, I am aware that there is a lot of frustration against the recruitment profession and I do think that this is a misconception. Many jobseekers consider recruiters as an annoying part of the job search. Generally speaking, we have a pretty bad reputation (let‚Äôs talk more about this later). But the thing is, in fact, that we are an asset in a candidate‚Äôs job search and in a company‚Äôs recruiting process. My vision is to get fewer people out there to see us as an annoying piece of the puzzle, and instead see the value of taking our help as a job coach.</p>
<p><strong>Finding and hiring experienced developers has been a challenging proposition for a while due simply to enormous demand, how does this affect your job?</strong></p>
<p>Emy: The first thing that comes to my mind, is the challenge of getting the companies to understand the market and the developers‚Äô situation. It is a bitter pill to swallow for many recruiters and companies, but today many developers have at least 4-5 opportunities available for him or her. Unfortunately, not all companies understand how coveted many developers are, and therefore they don‚Äôt understand the necessity of offering a great deal to potential employees. Not just the salary has been rising during the last years, other requirements have changed considerably as well. Today, many developers expect to be able to work remotely, having flexibility in their working day, good opportunities to develop within the company and to be able to develop their own skills (and so on‚Ä¶). Outstanding developers know their value on the market, and if a company‚Äôs position doesn‚Äôt sound interesting or profitable, they will go on to their next available opportunity. Many companies lack the understanding of how many offers a developer can have on their table and are therefore unable (or even unwilling) to match their needs. This is a tough nut to crack.</p>
<p>Another thing that comes top of mind is the art of standing out as a recruiter. Due to the enormous demand, many developers are likely to get contacted by a countless number of recruiters every day. The old-fashioned way of sending an email to a developer saying ‚ÄúHi, here‚Äôs a job I‚Äôd like you to consider‚Äù doesn‚Äôt work today. Why? Because that developer has probably received multiple requests from other recruiters already, and my message is likely to disappear somewhere in all that noise. Over the years that I have worked as a recruiter, I have come to understand the importance of understanding the developers needs and desires before sending them multiple job descriptions, preferably even before I contact him or her. It is my duty, as a recruiter, to do my research before I expect a developer to take his or her time to talk with me. For example, If I check their Github I may find out that this developer prefers back-end development in C#/.Net, then I know that it won‚Äôt be necessary for me to contact him or her in order to talk about a front-end position where your main focus is in React and Typescript. If I don‚Äôt do my research, I‚Äôm likely to waste the person‚Äôs time. If I don‚Äôt find anything on Github or similar, then I think it is pure decency of me to first of all ask if they are interested in having a conversation with me and if they are, I can‚Äôt just throw a job description in their face without first understanding what this person is interested in.</p>
<p><strong>Has everything changed with the pandemic? Is development work hard to find now?</strong></p>
<p>Emy: A lot has changed with the pandemic. From my experience, I think that the biggest challenge for recruiters right now is that developers in general are unwilling to take on a new job, even though they might know that their current position isn‚Äôt exactly what they want. I think it‚Äôs a result of the uncertainty with the pandemic, that no one knows how it will develop and what will happen next. Since the pandemic seriously shook the market during spring and summer, many developers are worried that it will put them in a situation where they‚Äôve left a permanent employment and the safety that it entails, to be the ‚Äúlast man/woman in, first out‚Äù.</p>
<p>In the beginning of the pandemic the market was disastrous, from March until September it was clear that even the IT-industry (despite the great demand) suffered from the pandemic. Many start-ups had to end their businesses and bigger companies were prohibited from hiring, many were even forced to dismiss employees in order to survive. Since August until today it has eased, and more companies dare to hire today. With that said though, companies take precautions when hiring and the processes might include more steps than normally in order to be really sure that it‚Äôs a good fit for the position.</p>
<p>I‚Äôd say that there are many opportunities on the market by now, but of course we are far from ‚Äúnormal‚Äù. Unfortunately, many companies demand more senior developers today, in order to fill the positions that they dismissed during spring. So, for junior developers it may still be a challenge to find their first or next position. Many companies can hire junior developers as a short-term consultant-assignment, so it is advantageous to be open to these opportunities as a junior developer.</p>
<p><strong>Is the poor reputation of the recruitment profession in tech among developers deserved or overstated?</strong></p>
<p>Emy: Sadly, I do think that it is deserved. I think that many recruiters have the wrong approach when recruiting for developer-positions. I have talked to many, many, many developers about this, and my understanding of the situation is that developers experience that recruiters don‚Äôt understand them nor their industry. And above all, many developers think that recruiters are a bit ignorant and uninterested in understanding it.</p>
<p>Recruiters and developers communicate differently, which is natural due to very different professions. ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://underjord.io/asking-a-tech-recruiter.html">https://underjord.io/asking-a-tech-recruiter.html</a></em></p>]]>
            </description>
            <link>https://underjord.io/asking-a-tech-recruiter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207447</guid>
            <pubDate>Wed, 25 Nov 2020 09:36:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25207055">thread link</a>) | @dijit
<br/>
November 25, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a ‚Äúliving document‚Äù that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody‚Äôs going to ditch the Web and switch to Gemini or Gopher today
(that‚Äôll take, like, a month at the longest). Until that happens, here‚Äôs a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts‚Äìlocal or remote‚Äìbesides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It‚Äôs a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most ‚Äúdark mode‚Äù
browser addons. More on this below.</li>
<li>A good score on Mozilla‚Äôs <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I‚Äôd like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen‚Äôs DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn‚Äôt evil! It isn‚Äôt
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn‚Äôt dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user‚Äôs system.</p>
<p>A personal example: I set my preferred fonts in my computer‚Äôs fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don‚Äôt change their fonts‚Ä¶</h3>
<p>The ‚Äúusers don‚Äôt know better and need us to make decisions for them‚Äù mindset isn‚Äôt
without merits; however, in my opinion, it‚Äôs overused. Using system fonts doesn‚Äôt
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn‚Äôt
about making software easier for non-technical users; it‚Äôs about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can‚Äôt users globally override stylesheets instead?</h3>
<p>It‚Äôs not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn‚Äôt have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there‚Äôs
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn‚Äôt
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article‚Äôs advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn‚Äôt that allow a website to fingerprint with fonts?</h3>
<p>I don‚Äôt know much about fingerprinting, except that you can‚Äôt do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don‚Äôt
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don‚Äôt need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user‚Äôs system, the user‚Äôs canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox‚Äôs <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of ‚Äúdead zones‚Äù with
abysmal download speeds, and my home‚Äôs Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don‚Äôt finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn‚Äôt expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn‚Äôt this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don‚Äôt decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don‚Äôt have reason to trust that
linked content doesn‚Äôt practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn‚Äôt
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can‚Äôt users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn‚Äôt essential, you shouldn‚Äôt include it inline.</li>
<li>Yes, users could disable images. That‚Äôs <em>their</em> choice. If your page uses lazy
loading, you‚Äôve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren‚Äôt black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here‚Äôs
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I‚Äôve found that it‚Äôs the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25207055</guid>
            <pubDate>Wed, 25 Nov 2020 08:24:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Graphical Output from Our Custom RISC-V Operating System in Rust]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25206221">thread link</a>) | @azhenley
<br/>
November 24, 2020 | https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>An operating system is used to make our job easier when using graphics. In our instance, in addition to everything else. In this post, we will be writing a GPU (graphics processing unit) driver using the VirtIO specification. In here, we will allow user applications to have a portion of the screen as RAM‚Äìwith what is commonly known as a <em>framebuffer</em>.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#overview">Overview</a></li><li><a href="#pixels">Pixels and Resolution</a></li><li><a href="#virtio">The GPU VirtIO Device</a></li><li><a href="#init">Initialization</a></li><li><a href="#invalid">Invalidation and Transfer</a></li><li><a href="#response">Device Responses</a></li><li><a href="#user">User Space</a></li><li><a href="#api">Simple Graphics API</a></li><li><a href="#conclusion">Conclusions and Further Reading</a></li></ol>



<hr>



<h2 id="overview">Overview</h2>



<p>We command the virtual GPU (virtio-gpu) by sending certain commands to the host (the device). The guest (the OS driver) has an allocation of RAM that becomes the framebuffer. The driver then tells the device, ‚Äúhey, here‚Äôs the RAM that we‚Äôre going to use to store pixel information.‚Äù</p>



<p>The RAM is contiguous in our OS, but according to the specification, this isn‚Äôt strictly required. We will give the driver a rectangle. Everything that falls within that rectangle will be copied to the host. We don‚Äôt want to keep copying the entire buffer over and over again.</p>



<p>We will be using the virtio protocol that we used for the block driver here, so I won‚Äôt rehash the general virtio protocol. However, the device-specific structures are a bit different, so we‚Äôll cover that part more in depth.</p>



<hr>



<h2 id="pixels">Pixels and Resolution</h2>



<p>A framebuffer must be large enough to store \(\text{width}\times\text{height}\times\text{pixel size}\) number of bytes. There are \(\text{width}\times\text{height}\) number of pixels. Each pixel has a 1-byte red, green, blue, and alpha channels. So, each pixel is exactly 4 bytes with the configuration we‚Äôre going to specify.</p>



<p>The framebuffer for our junior GPU driver is going to support a fixed resolution of \(640\times 480\). If you‚Äôre a child of the 90s, you saw this resolution a lot. In fact, my first computer, a Laser Pal 386, had a 16-color monitor with a resolution of 640 pixels wide with 480 pixels tall.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png" alt="" width="458" height="281" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13.png 611w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-13-300x184.png 300w" sizes="(max-width: 458px) 100vw, 458px"></a></figure></div>



<p>There are red, green, and blue pixels so close together that by varying the intensity of these three channels, we can change the color. The closer we get to our monitors, the easier a pixel is to see.</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png" alt="" width="285" height="288" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14.png 380w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-14-297x300.png 297w" sizes="(max-width: 285px) 100vw, 285px"></a><figcaption>Pixels on a Viewsonic VX2770SMH-LED monitor.</figcaption></figure></div>



<p>You can see these little squares. If you squint enough, you can see that they aren‚Äôt pure white. Instead, you can see bits of red, blue, and green. That‚Äôs because each one of these little squares is subdivided into three colors: yep, red, green, and blue! To make white, these pixels are turned up to 11 (get the joke?). To make black, we turn off all three channels of that pixel.</p>



<p>The resolution refers to how many of these squares are on our monitor. This is a 1920√ó1080 monitor. That means that there are 1920 of these squares going left to right, and there are 1080 of these squares from top to bottom. All in all, we have \(1920\times 1080=2,073,600\) number of pixels. Each one of these pixels is expressed using 4 bytes in the framebuffer, meaning we need \(2,073,600\times 4=8,294,400\) bytes in RAM to store the pixel information.</p>



<p>You can see why I limited our resolution to 640√ó480, which only requires \(640\times 480\times 4=1,228,800\) bytes‚Äìa bit over a megabyte.</p>



<hr>



<h2 id="virtio">The GPU VirtIO Device</h2>



<p>The GPU device requires us to read a more up-to-date VirtIO specification. I‚Äôll be reading from version 1.1, which you can get a copy here: <a href="https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html">https://docs.oasis-open.org/virtio/virtio/v1.1/virtio-v1.1.html</a>. Specifically, chapter 5.7 ‚ÄúGPU Device‚Äù. This is an <em>unaccelerated</em> 2D device, meaning that we must use the CPU to actually form the framebuffer, then we transfer our CPU formulated memory location to the host GPU, which is then responsible for drawing it to the screen.</p>



<p>The device uses a request/response system, where we the driver make a command to request something from the host (the GPU).  We add a bit of extra memory into our request so that the host can formulate its response. When the GPU interrupts us, we can take a look at this response memory location to see what the GPU told us. This is much like the <em>status</em> field on the block driver, where the block device tells us the status of our last request.</p>



<p>Each request starts with a <em>Command Header</em>, which in Rust looks as follows:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(C)]
struct CtrlHeader {
	ctrl_type: CtrlType,
	flags: u32,
	fence_id: u64,
	ctx_id: u32,
	padding: u32
}</pre>



<p>The header is common for all requests and all responses. We can differentiate by the CtrlType enumeration, which is:</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum CtrlType {
	/* 2d commands */
	CmdGetDisplayInfo = 0x0100,
	CmdResourceCreate2d,
	CmdResourceUref,
	CmdSetScanout,
	CmdResourceFlush,
	CmdTransferToHost2d,
	CmdResourceAttachBacking,
	CmdResourceDetachBacking,
	CmdGetCapsetInfo,
	CmdGetCapset,
	CmdGetEdid,
	/* cursor commands */
	CmdUpdateCursor = 0x0300,
	CmdMoveCursor,
	/* success responses */
	RespOkNoData = 0x1100,
	RespOkDisplayInfo,
	RespOkCapsetInfo,
	RespOkCapset,
	RespOkEdid,
	/* error responses */
	RespErrUnspec = 0x1200,
	RespErrOutOfMemory,
	RespErrInvalidScanoutId,
	RespErrInvalidResourceId,
	RespErrInvalidContextId,
	RespErrInvalidParameter,
}</pre>



<p>I took this directly from the specification, but Rust-ified the names to avoid getting yelled at by the linter.</p>



<h3>Pixel Formats</h3>



<p>Recall that the framebuffer is just a bunch of bytes in memory. We need to put a structure behind the framebuffer so the host (the GPU) knows how to interpret your sequence of bytes. There are several formats, but all-in-all, they just re-arrange the red, green, blue, and alpha channels. All are exactly 4 bytes, which makes the <em>stride</em> the same. The stride is the spacing from one pixel to another‚Äì4 bytes.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#[repr(u32)]
enum Formats {
	B8G8R8A8Unorm = 1,
	B8G8R8X8Unorm = 2,
	A8R8G8B8Unorm = 3,
	X8R8G8B8Unorm = 4,
	R8G8B8A8Unorm = 67,
	X8B8G8R8Unorm = 68,
	A8B8G8R8Unorm = 121,
	R8G8B8X8Unorm = 134,
}</pre>



<p>The type, <em>unorm</em>, is an 8-bit (1-byte) unsigned value from 0 through 255, where 0 represents no intensity and 255 represents full intensity, and a number in between is a linear-interpolation between no and full intensity. Since there are three color (and one alpha), that gives us \(256\times 256\times 256=16,776,216\) different colors or levels of colors.</p>



<p>For this tutorial, I selected <code>R8G8B8A8Unorm = 67</code>, which has red first, green second, blue third, and alpha fourth. This is a common ordering, so I‚Äôll select it to make it easy to follow along.</p>



<p>Our selected format makes the pixel structure look as follows:</p>



<div><figure><a href="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21.png"><img loading="lazy" src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png" alt="" width="512" height="307" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1024x614.png 1024w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-300x180.png 300w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-768x461.png 768w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-1536x921.png 1536w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-21-2048x1228.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></a></figure></div>



<p>Recall that each individual component R, G, B, and A are each one byte a piece, so each Pixel referred to by (x, y) is 4 bytes. This is why our memory pointer is a Pixel structure instead of a byte.</p>



<hr>



<h2 id="init">Initialization</h2>



<p>Just like all other virtio devices, we set up the virtqueues first and then we work on device-specific initialization. In my code, I just directly copied-and-pasted from the block driver into the gpu driver. The only thing I added to the Device structure was the framebuffer and dimensions of the framebuffer.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">pub struct Device {
	queue:        *mut Queue,
	dev:          *mut u32,
	idx:          u16,
	ack_used_idx: u16,
	framebuffer:  *mut Pixel,
	width:        u32,
	height:       u32,
}</pre>



<p>The specification tells us to do the following in order to initialize the device and get things ready to draw. I Rust-ified some of the content to match our enumerations.</p>



<h4>Create a framebuffer and configure scanout</h4>



<ol><li>Create a host resource using <code>CmdResourceCreate2d</code>.</li><li>Allocate a framebuffer from guest ram, and attach it as backing storage to the resource just created, using <code>CmdResourceAttachBacking</code>.</li><li>Use <code>CmdSetScanout</code> to link the framebuffer to a display scanout.</li></ol>



<h3>A Request Structure</h3>



<p>Recall that our request and response come packaged together. We will put them in separate descriptors, but whenever we get a response back from the device, it is going to be easier if we free just once to free both the request and response. So, in Rust, I created the Request structure to support doing this.</p>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">struct Request&lt;RqT, RpT&gt; {
	request: RqT,
	response: RpT,
}
impl&lt;RqT, RpT&gt; Request&lt;RqT, RpT&gt; {
	pub fn new(request: RqT) -&gt; *mut Self {
		let sz = size_of::&lt;RqT&gt;() + size_of::&lt;RpT&gt;();
		let ptr = kmalloc(sz) as *mut Self;
		unsafe {
			(*ptr).request = request;
		}
		ptr
	}
}</pre>



<h4>Step 1: Create host resource</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request::new(ResourceCreate2d {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceCreate2d,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	format: Formats::R8G8B8A8Unorm,
	width: dev.width,
	height: dev.height,
});
let desc_c2d = Descriptor {
	addr: unsafe { &amp;(*rq).request as *const ResourceCreate2d as u64 },
	len: size_of::&lt;ResourceCreate2d&gt;() as u32,
	flags: VIRTIO_DESC_F_NEXT,
	next: (dev.idx + 1) % VIRTIO_RING_SIZE as u16,
};
let desc_c2d_resp = Descriptor {
	addr: unsafe { &amp;(*rq).response as *const CtrlHeader as u64 },
	len: size_of::&lt;CtrlHeader&gt;() as u32,
	flags: VIRTIO_DESC_F_WRITE,
	next: 0,
};
unsafe {
	let head = dev.idx;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).desc[dev.idx as usize] = desc_c2d_resp;
	dev.idx = (dev.idx + 1) % VIRTIO_RING_SIZE as u16;
	(*dev.queue).avail.ring[(*dev.queue).avail.idx as usize % VIRTIO_RING_SIZE] = head;
	(*dev.queue).avail.idx = (*dev.queue).avail.idx.wrapping_add(1);
}</pre>



<p>All we‚Äôre really telling the GPU here is our resolution and the format of the framebuffer. When we create this, the host gets to configure itself, such as allocating an identical buffer to make transfers from our OS.</p>



<h4>Step 2: Attach framebuffer backing.</h4>



<pre data-enlighter-language="rust" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">let rq = Request3::new(AttachBacking {
	hdr: CtrlHeader {
		ctrl_type: CtrlType::CmdResourceAttachBacking,
		flags: 0,
		fence_id: 0,
		ctx_id: 0,
		padding: 0,
	},
	resource_id: 1,
	nr_entries: 1,
},
MemEntry {
	addr: dev.framebuffer as u64,
	length: dev.width * dev.height * size_of::&lt;Pixel&gt;() as u32,
	‚Ä¶</pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/">https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/11/11/risc-v-os-using-rust-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25206221</guid>
            <pubDate>Wed, 25 Nov 2020 05:14:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remember when you could reboot your computer without rebooting your phone first?]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 56 (<a href="https://news.ycombinator.com/item?id=25205031">thread link</a>) | @mdoms
<br/>
November 24, 2020 | https://annoying.technology/posts/7b574a72da90e5cd/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/7b574a72da90e5cd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/31a8603310fa498ae382fe6140ad8db20c277711/6bc2e/media/neustartdoeswell.png"></p><p>Remember when you could reboot your computer without rebooting your phone first?</p><p>I‚Äôm not even kidding: I needed to reboot my Mac because I was unable to navigate character by character using the arrow keys when composing new iMessages in Big Sur, but Finder refused to quit during the reboot with the above error message. It was still syncing my iPhone. (Remember when we thought the iTunes rewrite would be a good thing? <a href="https://twitter.com/manu_faktur/status/1260099839511212032">Good Times</a>!) I tried quite a few things on both devices, but was unable to cancel said sync in any other way than to reboot the phone.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/7b574a72da90e5cd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25205031</guid>
            <pubDate>Wed, 25 Nov 2020 01:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Build a Production Grade Workflow with SQL Modelling]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25203365">thread link</a>) | @oedmarap
<br/>
November 24, 2020 | https://shopify.engineering/build-production-grade-workflow-sql-modelling | <a href="https://web.archive.org/web/*/https://shopify.engineering/build-production-grade-workflow-sql-modelling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><strong>By Michelle Ark and Chris Wu</strong></p>
<p>In January of 2014, Shopify built a data pipeline platform for the data science team called Starscream. Back then, we were a smaller team and needed a tool that could deal with everything from ad hoc explorations to machine learning models. We chose to build with PySpark to get the power of a generalized distributed computer platform, the backing of the industry standard, and the ability to tap into the Python talent market.&nbsp;</p>
<p>Fast forward six years and our data needs have changed. Starscream now runs 76,000 jobs and writes 300 terabytes a day! As we grew, some types of work went away, but others (like simple reports) became so commonplace we do them every day. While our Python tool based on PySpark was computationally powerful, it wasn‚Äôt optimized for these commonplace tasks. If a product manager needed a simple rollup for a new feature by country, pulling it, and modeling it wasn‚Äôt a fast task.</p>
<p>We‚Äôll show you how we moved to a SQL modelling workflow by leveraging <a href="https://www.getdbt.com/" target="_blank" title="Analytics engineering is the data transformation work that happens between loading data into your warehouse and analyzing it. dbt allows anyone comfortable with SQL to own that workflow." rel="nofollow noopener noreferrer">dbt</a> (data build tool) and created tooling for testing and documentation on top of it. All together, these features provide Shopify‚Äôs data scientists with a robust, production-ready workflow to quickly build straightforward pipelines.</p>

<p>When we interviewed our users to understand their workflow on Starscream, there were two issues we discovered: <em>development time</em> and <em>thinking</em>.</p>
<p><em>Development time</em> encompasses the time data scientists use to prototype the data model they‚Äôd like to build, run it, see the outcome,and iterate. The PySpark platform isn‚Äôt ideal for running straightforward reporting tasks, often forcing data scientists to write boilerplate and it yields long runtimes. This led to long iteration cycles when trying to build models on unfamiliar data.</p>
<p>The second issue, <em>thinking</em>, is more subtle and deals with the way the programming language forces you to look at the data. Many of our data scientists prefer SQL to python because its structure forces consistency in business metrics. When interviewing users, we found a majority would write out a query in SQL then translate it to Python when prototyping. Unfortunately, query translation is time consuming and doesn‚Äôt add value to the pipeline.</p>
<p>To understand how widespread these problems were, we audited the jobs run and surveyed our data science team for the use cases. We found that 70% or so of the PySpark jobs on Starscream were full batch queries that didn‚Äôt require generalized computing. We viewed this as an opportunity to make a kickass optimization for a painful workflow.&nbsp;</p>

<p>Our goal was to create a SQL pipeline for reporting that enables data scientists to create simple reporting data faster, while still being production ready. After exploring a few alternatives, we felt that the dbt library came closest to our needs. Their tagline ‚Äúdeploy analytics code faster with software engineering practices‚Äù was <em>exactly</em> what we were looking for in a workflow. We opted to pair it with Google BigQuery as our data store and dubbed the system and its tools, Seamster.</p>
<p>We knew that any off-the-shelf system wouldn‚Äôt be one size fits all. In moving to dbt, we had to implement our own:</p>
<ul>
<li>source and model structure to modularize data model development</li>
<li>unit testing to increase the types of testable errors</li>
<li>continuous integration (CI) pipelines to provide safety and consistency guarantees.</li>
</ul>
<h2>Source Independence and Safety</h2>
<p>With dozens of data scientists making data models in a shared repository, a great user experience would</p>
<ul>
<li>maximize focus on work&nbsp;</li>
<li>minimize the impact of model changes by other data scientists.</li>
</ul>
<p>By default, dbt declares raw sources in a central <code>sources.yml</code>. This quickly became a very large file as it included the schema for each source, in addition to the source name. It creates a huge bottleneck for teams editing the same file across multiple PRs.&nbsp;</p>

<p>To mitigate the bottleneck, we leveraged the flexibility of dbt and created a top-level ‚Äòsources‚Äô directory to represent each raw source with its own source-formatted yaml file. This way, data scientists can parse only the source documentation that‚Äôs relevant for them and contribute to the <code>sources.yml</code> file without stepping on each other‚Äôs toes.</p>

<p><em>Base models are one-to-one interfaces to raw sources.</em></p>
<p>We also created a Base layer of models using the <a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" rel="nofollow noopener noreferrer">‚Äò</a><a href="https://discourse.getdbt.com/t/how-we-structure-our-dbt-projects/355" target="_blank" title="How we structure our dbt projects" rel="nofollow noopener noreferrer">staging‚Äô concept from dbt</a> to implement their best practice of <a href="https://docs.getdbt.com/docs/guides/best-practices/#limit-references-to-raw-data" target="_blank" title="Limit references to raw data - dbt" rel="nofollow noopener noreferrer">limiting references to raw data</a>. Our Base models serve as a one-to-one interface to raw sources. They don‚Äôt change the grain of the raw source, but do apply renaming, recasting, or any other cleaning operation that relates to the source data collection system.&nbsp;</p>
<p>The Base layer serves to protect users from breaking changes in raw sources. Raw external sources are by definition out of the control of Seamster and can introduce breaking changes for any number of reasons at any point in time. If and when this happens, you only need to apply the fix to the Base model representing the raw source, as opposed to every individual downstream model that depends on the raw source.&nbsp;</p>
<h2>Model Ownership for Teams</h2>
<p>We knew that the tooling improvements of Seamster would be only one part of a greater data platform at Shopify. We wanted to make sure we‚Äôre providing mechanisms to support good dimensional modelling practices and support data discovery.</p>
<p>In dbt, a model is simply a .sql file. We‚Äôve extended this definition in Seamster to define a model as a directory consisting of four files:&nbsp;</p>
<ul>
<li><code>model_name.sql</code></li>
<li><code>schema.yml</code></li>
<li><code>README.md</code></li>
<li><code>test_model_name.py</code></li>
</ul>
<p>You can further organize models into directories that indicate a data science team at Shopify like ‚Äòfinance‚Äô or ‚Äòmarketing‚Äô.&nbsp;</p>
<p>To support a clean data warehouse we‚Äôve also organized data models into these rough layers that differentiate between:</p>
<ul>
<li>
<strong>base</strong>: data models that are one-to-one with raw data, but cleaned, recast and renamed</li>
<li>
<strong>application-ready</strong>: data that isn‚Äôt dimensionally modelled but still transformed and clean for consumption by another tool (for example,&nbsp; training data for a machine learning algorithm)</li>
<li>
<strong>presentation</strong>: shareable and reliable data models that follow dimensional modelling best practices and can be used by data scientists across different domains.</li>
</ul>
<p>With these two changes, a data consumer can quickly understand the data quality they can expect from a model and find the owner in case there is an issue. We also pass this metadata upstream to <a href="https://shopify.engineering/solving-data-discovery-challenges-shopify" target="_blank" title="How We‚Äôre Solving Data Discovery Challenges at Shopify" rel="nofollow noopener noreferrer">other tools</a> to help with the data discovery workflow.</p>
<h2>More Tests</h2>
<p>dbt has native support for ‚Äòschema tests‚Äô, which are encoded in a model‚Äôs schema.yml file. These tests run against production data to validate data invariants, such as the presence of null values or the uniqueness of a particular key. This feature in dbt serves its purpose well, but we also want to enable data scientists to write unit tests for models that run against fixed input data (as opposed to production data).</p>
<p>Testing on fixed inputs allows the user to test edge cases that may not be in production yet. In larger organizations, there can and will be frequent updates and many collaborators for a single model. Unit tests give users confidence that the changes they‚Äôre making won‚Äôt break existing behaviour or introduce regressions.&nbsp;</p>
<p>Seamster provides a Python-based unit testing framework. Data scientists write their unit tests in the <code>test_model_name.py</code> file in the model directory. The framework enables constructing ‚Äòmock‚Äô input models from fixed data. The central object in this framework is a ‚Äòmock‚Äô data model, which has an underlying representation of a Pandas dataframe. You can pass fixed data to the mock constructor as either a csv-style string, Pandas dataframe, or a list of dictionaries to specify input data.&nbsp;</p>
<p><img alt="Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967" src="https://cdn.shopify.com/s/files/1/0779/4361/files/input-expected-mock-models.jpg?v=1605811967"><br><em>Input and expected MockModels are built from static data. The actual MockModel is built from input MockModels by BigQuery. Actual and expected MockModels can assert equality or any Great Expectations expectation.</em></p>
<p>A constructor creates a test query where a common table expression (CTE) represents each input mock data model, and any references to production models (identified using dbt‚Äôs ‚Äòref‚Äô macro) are replaced by references to the corresponding CTE. Once you execute a query, you can compare the output to an expected result. In addition to an equality assertion, we extended our framework to support all expectations from the open-source <a href="https://github.com/great-expectations/great_expectations" target="_blank" title="Great Expectations - Always know what to expect from your data." rel="nofollow noopener noreferrer">Great Expectations</a> library to provide more granular assertions and error messaging.&nbsp;</p>
<p>The main downside to this framework is that it requires a roundtrip to the query engine to construct the test data model given a set of inputs. Even though the query itself is lightweight and processes only a handful of rows, these roundtrips to the engine add up. It becomes costly to run an entire test suite on each local or CI run. To solve this, we introduced tooling both in development and CI to run the minimal set of tests that could potentially break given the change. This was straightforward to implement with accuracy because of dbt‚Äôs lineage tracking support; we simply had to find all downstream models (direct and indirect) for each changed model and run their tests.&nbsp;</p>
<h2>Schema and Directed Acyclic Graph Validation on the Cheap</h2>
<p>Our objective in Seamster‚Äôs CI is to give data scientists peace of mind that their changes won‚Äôt introduce production errors the next time the warehouse is built. They shouldn‚Äôt have to wonder whether removing a column will cause downstream dependencies to break, or whether they made a small typo in their SQL model definition.</p>
<p>To achieve this accurately, we would need to build and tear down the entire warehouse on every commit. This isn‚Äôt feasible from both a time and cost perspective. Instead, on every commit we materialize every model as a view in a temporary BigQuery dataset which is created at the start of the validation process and removed as soon as the validation finishes. If we can‚Äôt build a view because its upstream model doesn‚Äôt provide a certain column, or if the SQL is invalid for any reason, BigQuery fails to build the view and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/build-production-grade-workflow-sql-modelling">https://shopify.engineering/build-production-grade-workflow-sql-modelling</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/build-production-grade-workflow-sql-modelling</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203365</guid>
            <pubDate>Tue, 24 Nov 2020 21:52:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US internet speeds 91% faster in 2020 according to user speed tests]]>
            </title>
            <description>
<![CDATA[
Score 202 | Comments 254 (<a href="https://news.ycombinator.com/item?id=25203256">thread link</a>) | @mootothemax
<br/>
November 24, 2020 | https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis | <a href="https://web.archive.org/web/*/https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><ul><li>US broadband speeds <strong>increased 91%</strong> from 2019-2020, <strong>nearly doubling</strong> YoY, as measured by annual speed test medians</li><li>US average broadband speeds overtook western EU countries like the UK, France, and Germany for the first time in 5 years</li><li>Broadband speeds in the EU overall rose 57% from 2019‚Äì2020, 34% lower than the 91% performance increase in the US</li></ul><p>American internet users have had a very good 2020: according to research performed by FairInternetReport, median US internet speeds in 2020 doubled to 33.16mbps, up from 17.34mbps in 2019. Covering the five years of 2016, 2017, 2018, 2019, and 2020, this is the largest speed increase seen in the US, with speeds staying essentially the same in 2016 and 2017 (8.91mbps and 9.08mbps respectively), and 2018 recording a median speed of 12.83mbps.</p><p>The US stills lags behind many European and developed nations worldwide, and its major cities also often lag behind their European equivalents. That said, there is cause for celebration in Dallas, Seattle and Austin, after our analysis has shown that these cities are performing extremely well relative to most European capital cities.</p></div></div></div>]]>
            </description>
            <link>https://fairinternetreport.com/research/usa-vs-europe-internet-speed-analysis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25203256</guid>
            <pubDate>Tue, 24 Nov 2020 21:38:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Emacs Speed Up 1000%]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25202942">thread link</a>) | @tartoran
<br/>
November 24, 2020 | https://blog.binchen.org/posts/emacs-speed-up-1000.html | <a href="https://web.archive.org/web/*/https://blog.binchen.org/posts/emacs-speed-up-1000.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
<p>
I'm still <b>NOT</b> satisfied with my Emacs performance after applying below tricks:
</p>

<ul>
<li>autoload packages</li>
<li>idle-load packages</li>
<li>compiling *.el to  *.elc</li>
</ul>
<p>
After some research, I found I could make my Emacs 1000% fast <b>in 1 minute</b>.
</p>

<p>
Please note I'm talking about the <b>general performance</b> not just startup time.
</p>

<p>
The solution is really simple.
</p>

<p>
Since I'm a Linux guy and my computer got enough (24G) memory. I can place my setup into <a href="http://en.wikipedia.org/wiki/Tmpfs">memory</a>.
</p>

<p>
<b>Step 1</b>, insert below line into /etc/fstab and restart computer:
</p>

<div>

<pre><code>tmpfs       /tmp        tmpfs       nodev,nosuid,size=8G    0   0
</code></pre>

</div>

<p>
<b>Step 2</b>, run the script "emacs2ram":
</p>

<div>

<pre><code>#!/bin/sh

if [ -z "$1" ];then
    echo "Usage:"
    echo "  emacs2ram start"
    echo "  emacs2ram restore"
    exit 1
fi

if [ "$1" == "start" ];then
    backup=emacs.d-backup
    link=.emacs.d
    volatile=/tmp/.emacs.d-$USER

    IFS=
    set -efu

    cd ~/

    if [ ! -r $volatile ]; then
        mkdir -m0700 $volatile
    fi

    # link -&gt; volatie does not exist
    if [ "$(readlink $link)" != "$volatile" ]; then
        # backup project at first
        mv $link $backup
        # create the link
        ln -s $volatile $link
    fi

    if [ -e $link/.unpacked ]; then
        echo "Sync .emacs.d from memory to backup ..."
        rsync -avq --delete --exclude .unpacked ./$link/ ./$backup/
        echo "DONE!"
    else
        echo "Sync .emacs.d from disk to memory ..."
        rsync -avq ./$backup/ ./$link/
        touch $link/.unpacked
        echo "DONE!"
    fi
else
    echo "Moving .emacs.d back to disk ..."
    backup=$2-backup
    link=$2
    volatile=/tmp/$2-$USER
    cd ~/projs
    rm $link &amp;&amp; mv $backup $link &amp;&amp; rm -rf $volatile
    echo "DONE!"
fi
</code></pre>

</div>

<p>
That's all! Please enjoy Emacs as usual.
</p>

<p>
The original script is from ArchLinux Wiki. I learned this technique eight years ago. I'm just wondering why I need eight years to apply it?
</p>

<p>
BTW, I've also moved <b>all my projects into memory</b>, using similar scripts.
</p>

<p>
<b>UPDATE 1:</b>
I also publicize my project-managing script at <a href="https://gist.github.com/redguardtoo/596b1a9fd3eac1cedd13#file-proj2ram">gist</a>. It's almost same as emacs2ram. 
</p>

<p>
<b>UPDATE 2:</b>
Now I use <a href="https://hoytech.com/vmtouch/">vmtouch</a> which is easier to use and more light weight. Run <code>vmtouch -vt ~/.emacs.d</code> to place the directory into memory.
</p>

<p>
Unfortunately, <code>vmtouch</code> doesn't support Windows. You can convert my bash script to DOS batch script. Basically the script copies the directory into ram disk and create a link to the directory in memory. You can use <a href="https://sourceforge.net/projects/imdisk-toolkit/">ImDisk Toolkit</a> to create ram disk.</p>
</div>
        </div></div>]]>
            </description>
            <link>https://blog.binchen.org/posts/emacs-speed-up-1000.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202942</guid>
            <pubDate>Tue, 24 Nov 2020 20:58:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: Black Magic Fuckery]]>
            </title>
            <description>
<![CDATA[
Score 981 | Comments 1039 (<a href="https://news.ycombinator.com/item?id=25202147">thread link</a>) | @singhkays
<br/>
November 24, 2020 | https://www.singhkays.com/blog/apple-silicon-m1-black-magic/ | <a href="https://web.archive.org/web/*/https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<blockquote>
<p>Black. Magic. Fuckery.</p>
</blockquote>
<p>These are the words used by the user <a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvn0oy/">holdagold on reddit</a> to describe their experience with the new Apple Silicon M1 Macbook Air. Rarely does a product leave people effusing to the extent Apple Silicon M1 has done this week. At best, you get the people who really care about a system‚Äôs internals very excited like we saw with Zen 3‚Äôs launch recently. For everyday users who just want to browse the web, stream some Netflix, maybe edit some documents, computers have been ‚Äúperfectly fine‚Äù for the last decade. We‚Äôve seen incremental year over year improvements with slightly more performance, slightly more battery life, marginally faster SSD, somewhat thinner design, etc. But something genuinely new, something revolutionary, something once in a generation has been missing. I believe the Apple M1 represents something we can truly call ‚Äúrevolutionary‚Äù.</p>
<p>Before we proceed, it‚Äôs essential to set the context that I‚Äôve only used two Apple devices in my entire life - <em>a personal 2013 MacBook Air and a 2019 MacBook Pro that I got through work</em>. Everything else has been either a custom-built PC, Windows laptop, or an Android/Windows Mobile smartphone. Even for a ‚ÄúPC/Android Guy‚Äù, I have to admit what I saw this week is something special. I believe it‚Äôll go down as a significant milestone in computing history on par with some industry-defining chips like Intel‚Äôs 8086, 386, 486, Pentium, Conroe or AMD‚Äôs K8, Zen, etc. I hope for the return of Moore‚Äôs law and awakening of the x86 manufacturers from their slumber as this will be the ‚Äú<em>slowest</em>‚Äù CPU Apple will ever make. <em>As Henry Clay once said</em>,</p>
<blockquote>
<p>Of all human powers operating on the affairs of mankind, none is greater than that of competition.</p>
</blockquote>
<p>This blog is then my observation of the excitement around this significant launch and captures some of the user and reviewer commentary.</p>

<p>Apple launched its own M1 SoC that integrates an 8-core CPU, 8-core GPU, 16-core Neural Engine, Media encode and decode engines, RAM - all on a single-chip. By including the RAM on the SoC, Apple is marketing this as a Unified Memory Architecture (UMA), central to the performance improvements M1 brings.</p>
<figure>
<img sizes="(min-width: 35em) 1200px, 100vw" srcset="
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_480x0_resize_q75_box.jpg 480w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg 800w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1200x0_resize_q75_box.jpg 1200w,
                
                       https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_1500x0_resize_q75_box.jpg 1500w,
                " src="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/media/apple-silicon-M1-product-card-summary_hu0c2aa631255d48edd87f1b690f013f66_224784_800x0_resize_q75_box.jpg" alt="Apple Silicon M1 summary capabilities">
</figure>
<p>The first products and price points the M1 will be going into are:</p>
<ol>
<li>Mac Mini - $699</li>
<li>MacBook Air 13" - $999</li>
<li>MacBook Pro 13" - $1299</li>
</ol>
<p>Apple promises its new chip is much more energy-efficient than its Intel counterparts, so the battery life promises have gone up across the board:</p>
<ol>
<li>On the MacBook Air - up to 18 hours of video on a single charge (<em>up from 12 hours on this year‚Äôs Intel-powered MacBook Air</em>) and offers up to 15 hours of wireless web browsing per charge (<em>up from 11 hours previously</em>)</li>
<li>On the MacBook Pro - up to 17 hours of wireless web browsing (<em>up from 10 hours with this year‚Äôs Intel-powered MacBook Pro</em>), and 20 hours of video playback (<em>up from 10 hours before</em>).</li>
</ol>
<p>To showcase that energy efficiency, Apple is shipping the Macbook Air without any fan! It will be passively cooled like all iPhones and iPads.</p>


<p>Surprisingly no! Apple included Rosetta 2 ahead-of-time binary translation technology that translates code designed to run on Intel/x86 CPUs for the Apple Silicon CPUs. The performance is much better than expected and ranges between 70-80% of native code, which is surprising compared to Microsoft‚Äôs struggles in emulating x86 Windows apps on ARM CPUs. Apple‚Äôs answer might lie in something called TSO, aka. total store ordering as explained by <a href="https://www.reddit.com/r/hardware/comments/i0mido/apple_silicon_has_a_runtime_toggle_for_tso_to/">u/Veedrac and and u/ShaidarHaran2 on reddit</a>:</p>
<blockquote>
<p>TSO, aka. total store ordering, is a type of memory ordering, and affects how cores see the operations performed in other cores. Total store ordering is a strong guarantee provided by x86, that very roughtly means that all stores from other processors are ordered the same way for every processor, and in a reasonably consistent order, with exceptions for local memory.</p>
<p>In contrast, Arm architectures favour weaker memory models, that allows a lot of reordering of loads and stores. This has the advantage that in general there is less overhead where these guarantees are not needed, but it means that when ordering is required for correctness, you need to explicitly run instructions to ensure it. Emulating x86 would require this on practically every store instruction, which would slow emulation down a lot. That‚Äôs what the hardware toggle is for.</p>
<blockquote>
<p>In other words, Apple has, of course, been playing the very long game. TSO is quite a large benefit to emulating x86, hence why Rosetta 2 appears to put out a very decent 70% of native chip performance, that and install time translation for everything but JIT features. That‚Äôs on a chip not even meant to be a mac chip, so with further expanded caches, a wider, faster engine, perhaps applying the little cores to emulation which they‚Äôre not currently, and so on, x86_64 performance should be very very decent. I‚Äôm going to dare upset some folks and say perhaps even be faster in emulation than most contemporary x86 chips of the time, if you only lose 20% of native performance when it‚Äôs all said and done, it doesn‚Äôt take much working backwards to figure where they‚Äôd need to be, and Gurman said they were aiming for over 50% faster than Intel.</p>
</blockquote>
</blockquote>

<p>There have been numerous professional reviews and YouTube videos enumerating how Apple‚Äôs new products are better than their previous Intel counterparts. In the end, though, it comes down to how these products fit into the core workflows of the consumer who‚Äôs spending their money on them. There have been plenty of real-world experiences that I‚Äôve seen in my filter bubble, mostly Reddit and Twitter. I will share some of these throughout this blog.</p>
<h2 id="the-speed">The Speed</h2>
<blockquote><p lang="en" dir="ltr">I pray that Intel, AMD, and Qualcomm is letting the M1 give them ideas, take them in new directions. Because this level of sorcery is too damn powerful to be held by a single company. Especially a monopolizing conglomerate like Apple. But fucking kudos to those chip wizards üëè</p>‚Äî DHH (@dhh) <a href="https://twitter.com/dhh/status/1330903542463422469?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>
<blockquote><div lang="en" dir="ltr"><p>Purchased a new MacBook Air w/ Apple's M1 chip. </p><p>Holy crap. </p><p>Everything is WICKED fast.</p><p>Windows and prompts pop up instantly. Slowdown NEVER happens ‚Äî even w/ numerous apps going. </p><p>Evernote, always a resources hog for me, is now a non-issue.</p><p>Huge props, Apple. üëç</p></div>‚Äî JP Mangalindan (@JPManga) <a href="https://twitter.com/JPManga/status/1329265657796390914?ref_src=twsrc%5Etfw">November 19, 2020</a></blockquote>
<blockquote><p lang="en" dir="ltr">Have had my M1 MacBook for about a week now... and have been blown away by the performance. Battery just last and lasts, and either the fan never runs or is inaudible. Everything seems faster, even the stuff not yet compiled for Apple Silicon.</p>‚Äî Blake Scholl üõ´ (@bscholl) <a href="https://twitter.com/bscholl/status/1331084298451963904?ref_src=twsrc%5Etfw">November 24, 2020</a></blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/the_macbook_air_is_once_again_the_benchmark_by/gczfgs9">u/MagneticGray on reddit</a>:</p>
<blockquote>
<p>Definitely don‚Äôt get near one! I have the 12.9‚Äù iPad Pro, new Max iPhone, older 13‚ÄùMBP, and a beastly gaming PC. Our IT guy got the new MacBook Pro today and after playing with it for 10 minutes I was already rearranging my finances in my head.</p>
<p>People keep saying this but it‚Äôs eerily fast and silent, like alien technology. I exported a 5 minute clip in unoptimized Premiere Pro and I swear it did it faster than my PC with a 2070 ever has. The MBP wasn‚Äôt even warm to the touch afterwards either.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gctzgic/">u/leach4_pikes on reddit</a>:</p>
<blockquote>
<p>&gt; It‚Äôs honestly the best purchase I‚Äôve made in the last 10 years.</p>
<p>This is exactly how I feel. Feels like I‚Äôm holding a magical device that shouldn‚Äôt exist. Haven‚Äôt felt that in a long long time</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxu58m/apple_m1_arm_performance_with_a_2020_mac_mini/gd082ng/">u/lawrencejuliano and u/havaloc on reddit</a>:</p>
<blockquote>
<p>I have a 2018 15‚Äù MacBook Pro which is used almost exclusively in clamshell mode these days and attached to an ultrawide monitor. I use it mainly for photoshop and Lightroom for my photography work, and it‚Äôs been painful to say the least. It‚Äôs quick for all of two minutes until the fan kicks in with the thermal throttling, at which point the machine chugs to a crawl. I‚Äôve been wanting to get a desktop in replacement, eyeing the previous gen Mac Minis but unable to make the move due to the lack of discrete GPU and an inability to push my monitor‚Äôs resolution.</p>
<p>In comes the M1 Mac Mini - I ordered right away and received it Tuesday, and my god has it been a breath of fresh air. First impressions were insanely positive, even hooked to my 5120x1440 display it was lightning fast. But yesterday I put it through the paces with edits from a recent shoot, and it was beyond stellar. More photoshop tabs open than ever before, Lightroom CC and classic open together, nothing could slow it down.</p>
<p>To say I‚Äôm impressed with this first gen is a massive understatement, this is shaping up to be one of the most enjoyable devices I‚Äôve ever owned. First computer that hasn‚Äôt had some feeling of compromise in a long time.</p>
</blockquote>

<h2 id="buyers-remorse-is-real">Buyers remorse is real</h2>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gcyyfjl">u/afelzz and u/WizardSleeveLoverr on reddit</a>:</p>
<blockquote>
<p>I feel so fucking stupid for ordering a Macbook Air in April this year.</p>
<blockquote>
<p>Same. I‚Äôm mad at myself. I ordered a MacBook Pro around the same time and of course this comes out. Trade in value is a joke too.</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gd0n94p">u/2shizhtzu4u on reddit</a>:</p>
<blockquote>
<p>I was stupid to by [sic] the early 2020 model. Sent it back today in exchange for this one. The performance on the M1 is far more than what I expected</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jxqyio/_/gczjpa8">u/kelev on reddit</a>:</p>
<blockquote>
<p>As someone who got an entry level 2020 MBP in June‚Ä¶ fuck.</p>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/_/gcu471l">u/hijusthappytobehere, u/CanadianMapleBacon and u/takesthebiscuit on reddit</a>:</p>
<blockquote>
<p><em>cries in 2020 MBP</em></p>
<blockquote>
<p>2020 MacBook Air purchased in August :(:(:(</p>
</blockquote>
<blockquote>
<p>Ha my dad is 5 months into his MBP gutted</p>
</blockquote>
</blockquote>
<p><a href="https://www.reddit.com/r/apple/comments/jx360c/for_context_m1_macbook_air/gcvvtju/">u/mraheem on reddit</a>:</p>
<blockquote>
<p>Sucks cause i just bought a MacBook 3 years ago. And that battery is super super appealing.</p>
</blockquote>
<h2 id="battery-life-is-insane">Battery life is insane!</h2>
<blockquote><div lang="en" dir="ltr"><p>I haven‚Äôt plugged in this M1 Mac in almost 2 days. It‚Äôs only half dead. lol. What is this sorcery? üîã </p><p>Apple Silicon Macs are the future, man. Competing laptops are gonna have a hard time catching up. <a href="https://t.co/FmX5uVKkFd">pic.twitter.com/FmX5uVKkFd</a></p></div>‚Äî Computer Clan (üìåÔ£øM1) (@thecomputerclan) <a href="https://twitter.com/thecomputerclan/status/1329611818847891460?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote>

<blockquote><div lang="en" dir="ltr"><p>The battery life on the new MacBook Pro with M1 chip is INSANE</p><p>I've been doing work on this for several hours, and it's still at 87% ü§Øü§Øü§Ø</p><p>I guess it was a good thing I got my 3 week old laptop stolen? Lol<a href="https://twitter.com/hashtag/AppleM1?src=hash&amp;ref_src=twsrc%5Etfw">#AppleM1</a> <a href="https://t.co/fENYDS235O">pic.twitter.com/fENYDS235O</a></p></div>‚Äî William Lex Ham ‚úäüèΩüß¢ #TheyCantBurnUsAll (@WillLexHam) <a href="https://twitter.com/WillLexHam/status/1329906722845188097?ref_src=twsrc%5Etfw">November 20, 2020</a></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</a></em></p>]]>
            </description>
            <link>https://www.singhkays.com/blog/apple-silicon-m1-black-magic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202147</guid>
            <pubDate>Tue, 24 Nov 2020 19:36:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Grinch Bots Will Steal the Best Deals This Holiday Season]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25202140">thread link</a>) | @mch82
<br/>
November 24, 2020 | https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals | <a href="https://web.archive.org/web/*/https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Grinch bots, also known as scalper bots, have won deals at super-human speeds that consumers can't match in previous holiday seasons. However, due to the development of bots in the sneaker industry and COVID-19, the 2020 holiday season will see software bots complete a record number of online transactions.</p>
<p>In 2018, members of Congress drafted <a rel="nofollow noopener" target="_blank" title="a bill" href="https://tonko.house.gov/uploadedfiles/grinch_bots_fact_sheet.pdf">a bill</a> to outlaw grinch bots, stating that "Allowing grinch bots to rig prices and squeeze consumers during the holiday season hurts American families, small business owners, product makers and entrepreneurs. We will not allow this market manipulation to go unchecked."</p>
<p>This holiday season, grinch bots will purchase over $100 million of sneakers. In addition, this fast-growing software trend will impact clothing, collectibles, computers, electronics, gaming, and any attractive deal where demand outweighs supply. As a result, consumers will either miss out on the hottest holiday gifts, or be forced to purchase them from reseller platforms like eBay at steep markups.</p>
<p>Below, we outline what grinch bots are, how they work, and share details on the industries that are expected to be hardest hit.</p>
<p><strong>Table of Contents</strong></p>
<ul>
<li><a href="#what-are-grinch-bots">What Are Grinch Bots?</a></li>
<li><a href="#how-do-grinch-bots-work">How Do Grinch Bots Work?</a></li>
<li><a href="#grinch-bots-over-500-million">Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</a></li>
<li><a href="#grinch-bots-in-other-industries">Grinch Bots Are Increasingly Popular In Other Industries</a></li>
<li><a href="#grinch-bots-cost-10000-dollars">The Leading Grinch Bots Are Now Being Sold for Almost $10,000</a></li>
<li><a href="#what-holiday-deals-will-grinch-bots-target-2020">What Holiday Merchandise Will Grinch Bots Target in 2020?</a></li>
</ul>

<h2>What Are Grinch Bots?</h2>
<p>Grinch bots, otherwise known as scalper bots, are software programs built to rapidly purchase scarce goods from websites before humans have the chance to do so. In other words, they automate the checkout process on eCommerce websites. Some grinch bots are programmed and owned by individual hackers. Others, like those mentioned below, are built and sold to consumers known as 'botters.'</p>
<p>The typical features found in grinch bots are: </p><div>
<div>
<ul>
<li>Retailer website compatibility</li>
<li>Captcha solvers</li>
<li>Automated checkout</li>
<li>Restock checking</li>
<li>Proxy integrations</li>
<li>Mobile applications</li>
<li>Customer support</li>
</ul>
</div>
</div>
<p>Botters use technologies in addition to the bots to scalp merchandise. The two most common are proxies and servers. Proxies, offered by companies like <a rel="nofollow noopener" target="_blank" title="Oculus" href="https://oculusproxies.com/index">Oculus</a> and <a rel="nofollow noopener" target="_blank" title="Surge" href="https://www.surgeproxies.com/">Surge</a>, are entered into the bots so that each checkout can use a unique IP address. Servers, managed by companies like <a rel="nofollow noopener" target="_blank" title="Amazon Web Services" href="https://aws.amazon.com/">Amazon Web Services</a> or <a rel="nofollow noopener" target="_blank" title="10xServers" href="https://10xservers.com/">10xServers</a>, are used to increase bot speed. Botters host virtual servers in the same locations as the websites they are botting to reduce the physical distance that the data needs to travel.</p>
<h2>How Do Grinch Bots Work?</h2>
<p>When botters purchase their bot, they program it with their personal information ‚Äì shipping &amp; billing addresses, credit card info, usernames &amp; passwords. The botters' proxies are also added to the bot.</p>
<p>In anticipation of a sale, botters enter the specific merchandise they hope to purchase from a given retailer. As you can see below, these are stored as tasks in the software.</p>
<div>
<p><img alt="Cybersole task screenshot" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/prismbot-tasks 2x">
</p>
</div>
<p>Once the sale goes live on the target retailer website, the bot begins the checkout process. Botters can manually complete any necessary actions that the retailer requires during checkout, such as completing a CAPTCHA.</p>
<h2>Grinch Bots Will Purchase Over $100 Million of Sneakers During the 2020 Holidays</h2>
<p>Grinch bots will purchase over $100 million of sneakers during the 2020 holidays. This is consistent with the current size of the U.S. sneaker resale market, which is <a rel="nofollow noopener" target="_blank" title="estimated at $2 billion" href="https://finance.yahoo.com/news/global-sneaker-resale-market-could-reach-30-billion-by-2030-cowen-191003371.html">estimated at $2 billion</a>.</p>
<p>To calculate this figure, we completed a bottoms-up analysis using publicly available data shared by the bots. Many, but not all of the bots, share their transaction volume for each successful sale on Twitter. Cybersole's <a rel="nofollow noopener" target="_blank" title="Twitter account" href="https://twitter.com/Cybersole">Twitter account</a> is a good example, where you can find several posts a month celebrating the purchase of thousands of pairs of shoes.</p>
<p>The estimated 2020 holiday sales of the seven bots below is $70 million. This does not include sales from several other leading bots that do not publicly share their transaction volumes.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Est. Monthly Transactions</th><th colspan="" rowspan="">Est. Monthly Sales</th><th colspan="" rowspan="">Est. Holiday Sales</th><th colspan="" rowspan="">Annual Run Rate</th></tr></thead><tbody><tr><td colspan="" rowspan="">Kodai</td><td colspan="" rowspan="">50,000</td><td colspan="" rowspan="">$10 million</td><td colspan="" rowspan="">$24 million</td><td colspan="" rowspan="">$120 million</td></tr><tr><td colspan="" rowspan="">Cybersole</td><td colspan="" rowspan="">45,000</td><td colspan="" rowspan="">$9 million</td><td colspan="" rowspan="">$22 million</td><td colspan="" rowspan="">$108 million</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">25,000</td><td colspan="" rowspan="">$5 million</td><td colspan="" rowspan="">$12 million</td><td colspan="" rowspan="">$60 million</td></tr><tr><td colspan="" rowspan="">Project Destroyer</td><td colspan="" rowspan="">15,000</td><td colspan="" rowspan="">$3 million</td><td colspan="" rowspan="">$7.2 million</td><td colspan="" rowspan="">$36 million</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan="">AIO Bot</td><td colspan="" rowspan="">5,000</td><td colspan="" rowspan="">$1 million</td><td colspan="" rowspan="">$2.4 million</td><td colspan="" rowspan="">$12 million</td></tr><tr><td colspan="" rowspan=""><strong>Total</strong></td><td colspan="" rowspan=""><strong>145,000</strong></td><td colspan="" rowspan=""><strong>$29 million</strong></td><td colspan="" rowspan=""><strong>$70 million</strong></td><td colspan="" rowspan=""><strong>$348 million</strong></td></tr></tbody></table>
</div>
</div>

</div>
<h2>Grinch Bots Are Increasingly Popular In Other Industries</h2>
<p>While bots have the deepest penetration in footwear, they are becoming increasingly popular in several other industries. There are several recent high-profile reports of bots outdueling humans to secure valuable in-demand merchandise, for example: </p><div>
<div>
<ul>
<li>In November, resellers used bots to purchase the majority of PlayStation 5s from top online retailers like GAME, John Lewis and Tesco (<a rel="nofollow noopener" target="_blank" title="source" href="https://metro.co.uk/2020/11/20/ps5-retail-websites-crashed-due-to-scalper-bots-13627423/#:~:text=It's%20believed%20that%20scalpers%20were,each%20other%20for%20late%20deliveries.">source</a>)</li>
<li>In September, resellers used bots to purchase the majority of Nvidia's RTX3080 video card (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.extremetech.com/gaming/315210-resellers-used-bots-to-dominate-the-rtx-3080-launch">source</a>)</li>
<li>In April, resellers used bots to exacerbate shortages of the Nintendo Switch (<a rel="nofollow noopener" target="_blank" title="source" href="https://www.ign.com/articles/nintendo-switch-shortages-exacerbated-by-resellers-using-auto-buying-bots">source</a>)</li>
</ul>
</div>
</div>
<p>One of the largest online forums for botters is Reddit, and more specifically the community <a rel="nofollow noopener" target="_blank" title="r/shoebots" href="https://www.reddit.com/r/shoebots/">r/shoebots</a>. While this community started out focused on shoes, many recent threads are about CPUs, electronics, sports cards, and video games. As you can see below, the community has grown exponentially as botting has grown in popularity. It started 2020 at 9,630 members and has 22,400 members as of November 21, 2020.</p>
<div>
<p><img alt="r/shoebots reddit user growth over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/rshoebots-user-growth 2x">
</p>
</div>
<p>The sneaker market and COVID-19 are two of the largest catalysts of grinch bot adoption. COVID-19 impacted the market in two ways ‚Äì&nbsp;it increased unemployment, and shifted retail spend online. These forces led to more individuals looking for a new source of income online.</p>
<p>Bots have also begun advertising their ability to operate on websites outside of the footwear industry. On November 12, Prism <a rel="nofollow noopener" target="_blank" title="announced" href="https://twitter.com/PrismAIO/status/1326920747625885698">announced</a> that its bot works on Walmart.com. In fact, there are several bots that work on both <a rel="nofollow noopener" target="_blank" title="Target and Walmart's websites" href="https://www.reddit.com/r/shoebots/comments/jyrwnb/best_walmart_and_target_bot_for_mac/">Target and Walmart's websites</a>. Cybersole's website advertises the ability to use its bot on over 270 websites.</p>
<h2>The Leading Grinch Bots Are Now Being Sold for Almost $10,000</h2>
<p>The market for grinch bots has become increasingly competitive as more software products have entered the market. However, finding and purchasing a copy of the best bots is difficult ‚Äì&nbsp;bot creators typically limit the number of instances they sell in an effort to prevent their bots from becoming too popular, and obsolete.</p>
<p>As a result, many of the top bots must be purchased through resale themselves. The bot resale website BotBroker.io has sold over 31,000 bots. The pricing data below was recorded from its website in November 2020.</p>
<div>
<div>
<div>
<table><thead><tr><th colspan="" rowspan="">Bot</th><th colspan="" rowspan="">Last Sale Price</th><th colspan="" rowspan="">Bot Creation Date</th></tr></thead><tbody><tr><td colspan="" rowspan="">Wrath</td><td colspan="" rowspan="">$8,299</td><td colspan="" rowspan="">February, 2018</td></tr><tr><td colspan="" rowspan="">CyberAIO</td><td colspan="" rowspan="">$5,600</td><td colspan="" rowspan="">April, 2016</td></tr><tr><td colspan="" rowspan="">Prism</td><td colspan="" rowspan="">$3,998</td><td colspan="" rowspan="">October, 2018</td></tr><tr><td colspan="" rowspan="">SwftAIO</td><td colspan="" rowspan="">$3,750</td><td colspan="" rowspan="">January, 2019</td></tr><tr><td colspan="" rowspan="">Polaris</td><td colspan="" rowspan="">$3,300</td><td colspan="" rowspan="">November, 2019</td></tr><tr><td colspan="" rowspan="">Balko</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">August, 2018</td></tr><tr><td colspan="" rowspan="">MekAIO</td><td colspan="" rowspan="">$2,400</td><td colspan="" rowspan="">October, 2020</td></tr><tr><td colspan="" rowspan="">Nebula</td><td colspan="" rowspan="">$2,399</td><td colspan="" rowspan="">March, 2018</td></tr><tr><td colspan="" rowspan="">TohruAIO</td><td colspan="" rowspan="">$2,065</td><td colspan="" rowspan="">October, 2019
</td></tr></tbody></table>
</div>
</div>

</div>
<p>Wrath is currently the most expensive bot on BotBroker.io. As you can see below, its price has been steadily increasing the past year.</p>
<div>
<p><img alt="Wrath bot price over time" src="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time" srcset="https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_1.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 1x, https://res.cloudinary.com/softwarepundit/image/upload/c_limit,dpr_2.0,f_auto,h_1600,q_auto,w_1600/v1/software/wrath-price-over-time 2x">
</p>
</div>
<h2>What Holiday Merchandise Will Grinch Bots Target in 2020?</h2>
<p>The development of bots in the sneaker industry and COVID-19 mean that the holiday season of 2020 will see a record level of grinch bot transactions. The merchandise categories that will see the greatest bot transaction volume will be: </p><div>
<div>
<ul>
<li>Clothing</li>
<li>Collectibles</li>
<li>Computers</li>
<li>Electronics</li>
<li>Gaming</li>
<li>Sneakers</li>
<li>Toys</li>
</ul>
</div>
</div>
<p>In addition, resellers will almost certainly target flash sales of any high-demand item. Botters have formed 'cook groups' on Discord, where they share the latest information about promising upcoming 'drops' and sales. These groups provide botters an additional advantage over the average consumer.</p>
<p>Unfortunately for these consumers, it's likely that they will be forced to pay a significant premium to purchase the hottest items of the 2020 holiday season. It's hard to compete with the botters and their bots.</p>
</div></div>]]>
            </description>
            <link>https://www.softwarepundit.com/industry-research/grinch-bots-steal-holiday-deals</link>
            <guid isPermaLink="false">hacker-news-small-sites-25202140</guid>
            <pubDate>Tue, 24 Nov 2020 19:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Email a Dumpster Fire]]>
            </title>
            <description>
<![CDATA[
Score 1019 | Comments 319 (<a href="https://news.ycombinator.com/item?id=25201798">thread link</a>) | @bschne
<br/>
November 24, 2020 | https://hey.science/dumpster-fire/ | <a href="https://web.archive.org/web/*/https://hey.science/dumpster-fire/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>What's this experiment all about?</p>
    <p>Well, 2020's been a rough year. An absolute dumpster fire of a year for a lot of people.</p>
    <p>That's when it came to us. Can email be a conduit for catharsis? If you could type out an email, press send, and see it being consumed in an actual dumpster fire, would it help reclaim a little bit of what we've lost?</p>
    <p>Let's find out.</p>
    <p>P.S. We'll only use your email address to notify you about your burn. That's it, the end.</p>
    <p>P.P.S. We're offsetting by 3x every bit of CO2 this creates via <a href="https://www.cooleffect.org/content/project/native-alaskans-saving-lands" target="_blank" rel="noopener nofollow">Cool Effect</a>.</p>
  </div></div>]]>
            </description>
            <link>https://hey.science/dumpster-fire/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201798</guid>
            <pubDate>Tue, 24 Nov 2020 19:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Rainbow Tables Work]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25201513">thread link</a>) | @susam
<br/>
November 24, 2020 | http://kestas.kuliukas.com/RainbowTables/ | <a href="https://web.archive.org/web/*/http://kestas.kuliukas.com/RainbowTables/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><h6><a href="http://kestas.kuliukas.com/">kestas.kuliukas.com</a></h6>
<h3>How Rainbow Tables work</h3>
<p>I found the creator of Rainbow Table's paper, aimed at cryptanalysts,
was pretty inaccessible considering the simplicity and elegance of
Rainbow Tables, so this is an overview of it for a layman.</p>

<hr>

<p>Hash functions map plaintext to hashes so that you can't tell a
plaintext from its hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/1.png"></center>

<p>If you want to find a given plaintext for a certain hash there are two
simple methods:<br>
- Hash each plaintext one by one, until you find the hash.<br>
- Hash each plaintext one by one, but store each generated hash in a
sorted table so that you can easily look the hash up later without
generating the hashes again</p>

<p>Going one by one takes a very long time, and storing each hash takes an
amount of memory which simply doesn't exist (for all but the smallest of
plaintext sets). Rainbow tables are a compromise between pre-computation
and low memory usage.</p>

<p>The key to understanding rainbow tables is understanding the
(unhelpfully named) reduction function.<br>
A hash function maps plaintexts to hashes, the reduction function maps
hashes to plaintexts.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/2.png"></center>


<p>It's important to note that it does the reverse of a hash function
(mapping hashes to plaintexts), but it is /not/ an inverse hash
function. The whole purpose of hash functions is that inverse hash
functions can't be made. If you take the hash of a plaintext, and take
the reduction of the hash, it will not give you the original plaintext;
but some other plaintext.</p>

<p>If the set of plaintexts is [0123456789]{6} (we want a rainbow table of
all numeric passwords of length 6), and the hashing function is MD5(), a
hash of a plaintext might be MD5("493823") -&gt;
"222f00dc4b7f9131c89cff641d1a8c50".<br>
In this case the reduction function R() might be as simple as taking the
first six numbers from the hash; R("222f00dc4b7f9131c89cff641d1a8c50")
-&gt; "222004".<br>
We now have generated another plaintext from the hash of the previous
plaintext, this is the purpose of the reduction function.</p>


<p>Hashes are one-way functions, and so are reduction functions. The chains
which make up rainbow tables are chains of one way hash and reduction
functions starting at a certain plaintext, and ending at a certain hash.
A chain in a rainbow table starts with an arbitrary plaintext, hashes
it, reduces the hash to another plaintext, hashes the new plaintext, and
so on. The table only stores the starting plaintext, and the final hash
you choose to end with, and so a chain "containing" millions of hashes
can be represented with only a single starting plaintext, and a single
finishing hash.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/3.png"></center>


<p>After generating many chains the table might look something like:<br>
iaisudhiu -&gt; 4259cc34599c530b1e4a8f225d665802<br>
oxcvioix -&gt; c744b1716cbf8d4dd0ff4ce31a177151<br>
9da8dasf -&gt; 3cd696a8571a843cda453a229d741843<br>
[...]<br>
sodifo8sf -&gt; 7ad7d6fa6bb4fd28ab98b3dd33261e8f</p>

<hr>

<p>The chains are now ready to be used. We have a certain hash with an
unknown plaintext, and we want to check to see whether it is inside any
of the generated chains.</p>

<p>The algorithm is:<br>
</p><ul><li>Look for the hash in the list of final hashes, if it is there break
out of the loop.</li>
<li>If it isn't there reduce the hash into another plaintext, and hash the
new plaintext.</li>
<li>Goto the start.</li>
<li>If the hash matches one of the final hashes, the chain for which the
hash matches the final hash contains the original hash.</li></ul>
You can now get that chain's starting plaintext, and start hashing and
reducing it, until you come to the known hash along with its secret
plaintext.

<p>In this way you check through the hashes in the chains, which aren't
actually stored anywhere on disk, by iterating column by column through
the table of chains, backwards from the last column in the chain, to the
starting plaintext.</p>

<hr>
<p>If you wanted to check whether the hash exists in the last column of any 
of the chains you reduce and hash the given hash once, then check the 
generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a1.png"></center>

<p>You can check the second last column by reducing and hashing twice, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a2.png"></center>

<p>And the third is checked by reducing and hashing three times, 
then check the generated hash against the chain end hashes.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a3.png"></center>

<p>Supposing
a chain ending matches the generated hash the matching chain end might
contain the hash. The starting plaintext which was stored with the ending 
hash can be reduced and hashed until the correct plaintext is found within 
the chain.
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/a4.png"></center>

<hr>

<p>Collisions are the only problem with Rainbow Tables. Ironically
collisions are seen as a bad thing for hashing algorithms, but in the
case of Rainbow Tables a hashing algorithm which generates collisions
fairly regularly will be more secure.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/5.png"></center><br>
A given hash may be generated by multiple plaintexts (this is called a
collision), which is a big problem for chains because it causes chains
which start different to converge into one. Also you get loops, which
are caused when a hash is reduced to a plaintext that was hashed at a
previous point in the chain.<br>
<center><img src="http://kestas.kuliukas.com/RainbowTables/6.png"></center>


<p>Because of these collision problems there is no guarantee that there
will be a hash of a plaintext that will reduce to some other given
plaintext.<br>
If you have a simple list of hashes and corresponding plaintexts for
every plaintext in a set you will know that if you have not found the
hash in the generated hashes the plaintext that generated the hash is
not in the set.<br>
If you have a table of chains where the reduction function reduces
hashes into the set of plaintexts you could have trillions of chains
generated but you still may not have generated every plaintext in the
set you want to check. You can only say how probable it is that a table
of chains contains a certain plaintext, and this can approach 1 but will
probably never reach 1.<br>
If you have a rainbow table with 10 chains of length 100 you have hashed
1000 plaintexts, but even if there are only 100 plaintexts in the set of
desired plaintexts the 1000 hashes you have in the chains may not
contain all the desired hashes.</p>

<hr>

<p>The way collisions are handled is what sets Rainbow Tables apart from
its predecessor which was developed in 1980.</p>

<p>The predecessor solved the problem of certain plaintexts never being
reduced to by using many small tables. Each small table uses a different
reduction function. This doesn't solve the problem completely, but it
does help.<br>
To solve chain merges and loops each chain ended at a "distinct point";
a hash which was unique in some way, eg hashes where the first 4
characters are 0. The chains keep on going until it reaches a distinct
point. If two chains end up at the same distinct point then there has
been a collision somewhere in the chain, and one of the chains is
discarded. If a chain is generated for an unusually long time without
reaching a distinct point a loop is suspected (where a chain of hashes
ends up reducing and hashing to a previous hash in the chain).
The problem with this is that if there is a collision there is
potentially a whole branch which has to be cut off and won't make it
into the chains, and a loop will cause all the hashes which came before
the loop in the chain to be discarded.<br>
</p><center><img src="http://kestas.kuliukas.com/RainbowTables/7.png"></center><br>
Also all the time spend generating that chain will be wasted, and by
ending only at distinct points you have chains of variable length. This
means that you may have to keep checking for a hash within especially
long chains long after the other chains have ended.

<hr>

<p>Rainbow tables differ in that they don't use multiple tables with
different reduction functions, they only use one table. However in
Rainbow Tables a different reduction function is used for each column.
This way different tables with different reduction functions aren't
needed, because different reduction functions are used within the same
table. It is still unlikely that all plaintexts in the desired set will
be hashed, but the chances are higher for a given number of chains.
Chain merges are much, much rarer, because collisions have to occur on
the same column. For a chain of length l the chance of a collision
causing a merge is reduced to 1/l. Loops are also solved, because if a
hash in a chain is the same as a previous hash it won't reduce to the
same plaintext.</p>

<p>The reason they're called Rainbow Tables is because each column uses a
different reduction function. If each reduction function was a different
color, and you have starting plaintexts at the top and final hashes at
the bottom, it would look like a rainbow (a very vertically long and
thin one).<br>
By using Rainbow Tables the only problem that remains is that you can
never be certain that the chains contain all the desired hashes, to get
higher success rates from a given Rainbow Table you have to generate
more and more chains, and get diminishing returns.</p>


<hr>

<p>I hope by explaining the Rainbow Table I haven't made them any less 
wonderful ...</p>

<hr>

<a name="improving"></a>
<h4>An easy way to improve on the "rainbowcrack" Rainbow Tables implementation</h4>
<p>This section probably goes a bit beyond where a layman would be comfortable, 
but if you're interested in the practical applications of the above theory or have some 
interest in cryptography read on..</p>

<p>The rainbowcrack application is how most people come to learn 
about Rainbow Tables, because it is the application which puts the 
theory above into code. It has been very successful, with many websites 
dedicated to generating rainbowcrack hash tables and letting users search them.</p>

<p>However there is a pretty clear way this application could be improved, 
very easily, in the sense that the generated tables would take up a lot less
disk space, but be equally as effective for breaking hashes:</p>

<p>Remember above that when you want to generate a certain chain 
you start from an arbitrary hash. This just means it doesn't matter where 
you choose to start from. The rainbowcrack application starts from a randomly 
generated 64-bit number. This number is then used to generate a chain which 
ultimately ends with a 128-bit hash, which is reduced to another 64-bit number.</p>

<p>Why use a randomly generated number as the starting point? A ‚Ä¶</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://kestas.kuliukas.com/RainbowTables/">http://kestas.kuliukas.com/RainbowTables/</a></em></p>]]>
            </description>
            <link>http://kestas.kuliukas.com/RainbowTables/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201513</guid>
            <pubDate>Tue, 24 Nov 2020 18:43:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What does it mean to ‚Äúreconcile to cash‚Äù?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25201471">thread link</a>) | @qin
<br/>
November 24, 2020 | https://www.moderntreasury.com/journal/what-is-automatic-reconciliation | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/what-is-automatic-reconciliation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Businesses that manage payments at scale face the complex challenge of reliably monitoring cash. Most of us have experienced the time delays inherent to ACH, wires, and checks. These delays make it difficult to tie a payment you‚Äôve made or expect to receive to the actual transaction that posts to your bank account. This process is called reconciliation and it is essential for a business to understand how completed and in-progress transactions add up to the cash balance in its bank account.&nbsp;<br></p><p>Most finance teams try to solve the reconciliation problem with spreadsheets, email and manual examination of bank statements ‚Äî processes that are inefficient and error-prone. At Modern Treasury, we‚Äôve built a better solution that helps finance teams save time and minimize errors. We call it Automatic Reconciliation.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury automatically matches your payments and returns to transactions as they are made available by your bank. Reconciled transactions are reflected in the previous day and intra-day balances available through the API and dashboard, allowing you to reliably monitor cash across all your business bank accounts.&nbsp;</p><p>‚Äç<br></p><h4>How Does Reconciliation Help With Monitoring Cash?<br></h4><p>Let‚Äôs say you run a marketplace for artisanal coffee that lets coffee aficionados buy coffee from artisanal coffee roasters anywhere in the country. You collect payments from the buyer, deduct your platform fee and pay the seller. You also need to handle other types of transactions, like refunds and bonus payments to your top performing sellers. Business is going well so you‚Äôre processing thousands of orders a week.&nbsp;<br></p><p>To reliably monitor cash, you need to be able to match every single payment you‚Äôve made or received to the corresponding transaction in your bank statement. At scale, this quickly gets very complicated for three reasons.&nbsp;</p><p>‚Äç</p><h4>1. Banks Don‚Äôt Move Money as Fast as Your Business <br></h4><p>The time it takes for your transaction to settle depends on which payment method you use. Here‚Äôs a list of business payment methods used in the US and their typical settlement times. Because of these settlement timeframes, the rate at which you move money is slower than your business activities.&nbsp;<br></p><figure id="w-node-260693cab140-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc098771bac937c487c98a_AutomaticReconciliationTable.png" loading="lazy" alt=""></p></figure><p><br>Let‚Äôs say you pay coffee sellers on a daily basis. If you initiate a number of ACH credits on Monday, they are likely to settle by Tuesday. But by the time they settle, you have already initiated a new batch of payments on Tuesday that will settle on Wednesday.&nbsp;<br></p><p>Without reconciliation, it‚Äôs hard to keep track of the cash available in your bank account, what transactions are processing versus complete, and when different sets of transactions are likely to settle.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p><h4>2. Banks Process Transactions in Batches</h4><p>Let‚Äôs say you need to pay 10 coffee roasters $1000 each at the end of the week. You initiate 10 ACH credit transactions, each for $1000 on Friday before the day‚Äôs cut-off. These transactions will likely post to your bank statement Monday evening or Tuesday morning next week.&nbsp;<br></p><p>When you ask your bank to make a payment, it‚Äôs placed into a queue that‚Äôs sent to the network for processing after a certain cut-off time for the day. Any transactions submitted after the cut-off time are queued up to be processed the next business day. Different banks have different <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">cut-off times</a> for processing transactions.<br></p><p>The next day, instead of seeing 10 separate transactions next week, you‚Äôll see one transaction for $10,000 on your statement. Because ACH transactions take place in batches, your bank directly debits your account for the total amount even though it represents 10 separate payments. Reconciliation helps you tie each payment to the appropriate transaction on your bank statement.&nbsp;</p><h4>3. Monitoring Incoming Payments and Returns is Difficult</h4><p>Let‚Äôs say you‚Äôre also expecting 100 payments of $20 each from your buyers. You need to know when they hit your bank account to predict cash accurately. You also need to tie each payment to an order. Similar to when you make bulk payments, your bank may record all or some of those payments as a single transaction on your statement.&nbsp;<br></p><p><a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">Payment returns</a> also complicate monitoring cash flow. For example, ACH credits will fail due to incorrect account or routing numbers and ACH debits will fail if the counterparty doesn‚Äôt have sufficient funds in their account. In both scenarios, your bank will post a return transaction to your bank statement that needs to be reconciled with the original payment.</p><h4>Automatic Reconciliation<br></h4><p>Until now, many companies have relied on manual reconciliation processes that typically involve exporting transactions from the bank portal to a spreadsheet and manually matching them with payments. In addition to being time consuming, the need to email multiple spreadsheets back and forth makes collaboration painful.&nbsp;<br></p><p>With Automatic Reconciliation, Modern Treasury instantly reconciles every single payment with transactions in your bank statement. We <a href="https://www.moderntreasury.com/journal/tentative-reconciliation" target="_blank">tentatively reconcile</a> the transaction when it‚Äôs pending and complete the process when it posts. Because ACH processes transactions in batches, a large number of transactions on your bank statement are likely to represent multiple distinct payments. If the transaction aggregates multiple Payment Orders, we automatically create matching <a href="https://docs.moderntreasury.com/reference#transaction-line-item-object" target="_blank">Transaction Line Items</a>.&nbsp;<br></p><p>When you see a Payment Order marked as completed, you can click into it in the web application to see the matching transaction.&nbsp;<br>‚Äç<br></p><figure id="w-node-bb5fd7410dc0-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08ea82af2f7050239826_Payment%20Orders%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Expected Payments feature allows you to monitor your bank account for payments you do not initiate. When the transaction is made available by your bank, it is automatically reconciled with the Expected Payment. You can choose to be notified by <a href="https://docs.moderntreasury.com/reference#expected-payments">webhook</a> or email about its status.&nbsp;&nbsp;&nbsp;<br></p><figure id="w-node-6bf8f8776d0d-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc08fdea9cc07dcb14b23c_Expected%20Payments%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>The Returns feature automatically matches returned payments to transactions and the original Payment Order, making identifying, correcting and redrafting returns a breeze.&nbsp;<br></p><figure id="w-node-2fa9dd183a06-b8df1e0f"><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/5fbc0910f4c807451c4b685e_Returns%20-%20640%20px.gif" loading="lazy" alt=""></p></figure><p><br>All the data you see in the app is also available through the API, allowing you to further automate and streamline reconciliation by integrating Modern Treasury directly into your business systems or platform.&nbsp;<br></p><p>We also have direct integrations with QuickBooks and NetSuite through our <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">Continuous Accounting</a> product. It syncs Modern Treasury directly with your general ledger, allowing you to tag payments with accounting categories. When you‚Äôre closing out the books, all you need to do is click a few buttons in the web app to transfer payments that have been Automatically Reconciled to your accounting software.<br></p><p>Finally, because we connect to <a href="https://docs.moderntreasury.com/docs/banks" target="_blank">multiple banks</a>, you can use Modern Treasury to reconcile transactions and monitor cash across all your business bank accounts.&nbsp;</p><h4>Get Started With Automatic Reconciliation</h4><p><a href="https://www.moderntreasury.com/product-demo" target="_blank">Get in touch</a> if you‚Äôre interested in exploring Automatic Reconciliation for your business. We‚Äôd love to discuss your use case in detail.</p></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/what-is-automatic-reconciliation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201471</guid>
            <pubDate>Tue, 24 Nov 2020 18:39:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Expensive Security Fails in Healthcare Apps]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25201335">thread link</a>) | @_Tata_
<br/>
November 24, 2020 | https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019 | <a href="https://web.archive.org/web/*/https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><a href="https://www.ego-cms.com/tags/healthcare"><p>Healthcare</p></a><h2>Most Expensive Healthcare App Security Fails in 2018‚Äì2019</h2><p>MyFitnessPal, PumpUp, and Strava all were unable to avoid data breaches. Find out why and what you can learn from these cases to make your app more secure.
</p></div></div><article><div target="_blank"><p>In 2018, the average cost for a corporate data breach reached almost <a href="https://igniteoutsourcing.com/healthcare/healthcare-security-breaches/">$4 million</a>.&nbsp;</p><p>Let‚Äôs take a look at a few of these attacks to learn what went wrong and secure your business from such risks.</p><h2>1 MyFitnessPal</h2><p>MyFitnessPal is a typical fitness application. It allows users to log cardio and strength exercises, connects with more than 50 devices and other apps, tracks steps, counts calories, and so on. Released in 2009, MyFitnessPal quickly gained popularity ‚Äî it was chosen as the number one health and fitness app four years in a row. But everything changed in February 2018.</p><figure id="w-node-9fe8c2a22398-7a0a8b78"><p><iframe allowfullscreen="true" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/KRcvSWvR0kc"></iframe></p></figure><p>The MyFitnessPal data breach was probably one of the most publicized in the healthcare industry. Hackers accessed the personal data of almost <strong>150 million users</strong>, stealing their names, hashed passwords, IP addresses, and email addresses. Fortunately, the criminals couldn‚Äôt get to users‚Äô credit card and social security numbers, as this data was collected and stored separately.&nbsp;<br></p><p><a href="https://www.underarmour.com/en-us?&amp;cid=PS%7Cgoogle%7CTrademark%7CUA%7CIP%7CExact%7Cunder%20armour%7CSRnf0L2T&amp;gclid=CjwKCAjw1_PqBRBIEiwA71rmtbPVRSTc31VHHLODl9D2ZnA-9HiTBv4xxSkBkyeWl8Z7kAJldUZ_QhoCaG8QAvD_BwE">Under Armour</a>, the company which acquired MyFitnessPal in 2015, became aware of the data breach at the end of March 2018. Four days later, users started to receive notifications and emails requiring them to change their passwords and offering recommendations on how to safeguard their accounts. In February 2019, the stolen personal details appeared on the dark web.&nbsp;<br></p><p>Other apps owned by Under Armour were not affected, but the company still <strong>lost 4.6% of its market</strong> <strong>value</strong> because of the data breach. However, the company and the app survived. MyFitnessPal still has a lot of users and pretty high ratings in the app stores (4.5 on Google Play).</p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>MyFitnessPal should have been equipped with <strong>two-factor authentication</strong>. For a mobile application, we would recommend using biometric authentication or at least push notifications.&nbsp;</li></ul><ul role="list"><li>Reliable <strong>encryption</strong> is a must for companies that are serious about privacy and security.</li><li>For the majority of passwords, Under Armour used the <a href="https://content.myfitnesspal.com/security-information/FAQ.html">Bcrypt</a> hashing function. This is a reliable mechanism. But for the remaining passwords, the company used the <strong>rather weak </strong><a href="https://content.myfitnesspal.com/security-information/FAQ.html"><strong>SHA-1</strong></a>. Using Bcrypt for all passwords could have reduced the scope of the breach.</li></ul><ul role="list"><li>Collecting and <strong>storing</strong> the most important <strong>data separately</strong> is a great practice ‚Äî it kept credit card data safe. Otherwise, Under Armour could have faced a much more serious loss in market value.</li></ul><ul role="list"><li>If a breach happens, it‚Äôs essential to <strong>notify users as fast as possible</strong> ‚Äî keeping silent will simply destroy your company‚Äôs reputation. Under Armour did well here.</li></ul><h2>2 PumpUp</h2><p><a href="https://www.pumpup.com/#home">PumpUp</a> positions itself as the world‚Äôs most positive fitness community. It offers users numerous workouts and programs, an opportunity to learn more about fitness and get support from other members, and other features. After the app was released in 2012, it became rather popular.<br></p><p>The PumpUp data breach took place in May 2018, when personal data of more than <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/"><strong>6 million users</strong></a><strong> </strong>stopped being private. Data compromised included information on users‚Äô locations, email addresses, gender, and dates of birth, full-resolution profile photos, workout data, health information (for instance, weight and height), device data, and private messages. In certain cases, even credit card data was exposed.&nbsp;<br></p><p>The incident happened because the core backend server hosted on the Amazon Cloud was left without a password for an indefinite amount of time. Anyone could see the private content of the app‚Äôs users.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7cdf1127270466b858d20_5d78d2e9cd001218b4a025f0_eb187d1d-170d-44e4-8ab7-2aa08946fd06.png" loading="lazy" alt=""></p></figure><p>The exposed server wasn‚Äôt even found by the company ‚Äî it was discovered by security researcher Oliver Hough who then contacted <a href="https://www.zdnet.com/article/fitness-app-pumpup-leaked-health-data-private-messages/">ZDNet</a>, a business technology news website, to investigate the case. ZDNet spent a week trying to get in touch with PumpUp, but there was no reply. However, in the end, the server was secured.<br></p><p>Since there were no comments from PumpUp after the breach, we can‚Äôt tell exactly how much money they lost. But their reputation was definitely affected.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>To avoid this problem, PumpUp had at least to protect their data with a password. Ideally, this would have been combined with <strong>two-factor authentication</strong> to keep users‚Äô data safe.&nbsp;</li></ul><ul role="list"><li>It seems that the company didn‚Äôt run any security tests ‚Äî <strong>regular security scanning</strong> would have helped them notice the problem much earlier. EGO recommends performing such tests on a regular basis.</li><li>Another mistake PumpUp made was ignoring<strong> communications</strong> from ZDNet and ignoring the incident. If a breach happens, a company should stay in touch to show users that it cares.</li></ul><h2>Strava</h2><p><a href="https://www.strava.com/mobile">Strava</a> is a fitness app for tracking running, cycling, swimming, and other activities. It allows users to map and record their routes, analyze their activities, participate in challenges, etc. The app was released in 2009, and since then it has been installed more than 10 million times on Android OS alone (according to <a href="https://play.google.com/store/apps/details?id=com.strava&amp;hl=en">Google Play</a>; no data on iOS downloads is available).<br></p><p>The story of the Strava failure began in November 2017, when the company released a global heat map showing running routes for all users who opted to make their data publicly available. To create the map, Strava used GPS data from smartphones and fitness tracking devices on <strong>1 billion</strong> activities. This data was collected from 2015 to 2017. Over <strong>27 million</strong> users tracked their routes during this time, and due to confusing privacy settings, some of them didn‚Äôt even know that they were sharing sensitive data.&nbsp;<br></p><p>This map was the brainchild of Strava. But in January 2018, Nathan Ruser, an Australian student, noticed that by analyzing the map, it was possible to determine the whereabouts of military bases and other sensitive locations.</p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c54a7adc793c1f5f41b3_5d78d3ce1f37d12d04642dcc_Artboard.png" loading="lazy" alt=""></p></figure><p>Strava and its map got a lot of criticism. In response, the company didn‚Äôt delete the map, but rather changed it significantly.&nbsp;<br></p><p>First of all, the data isn‚Äôt available to everyone anymore ‚Äî to zoom in and see street-level detail, users now have to log in with their Strava account.&nbsp;<br></p><p>Second, the map is now updated monthly, which means that if a user changes their privacy settings and doesn‚Äôt want to provide data for the heat map anymore, their data won‚Äôt be included in the next month‚Äôs map.&nbsp;<br></p><p>Third, all roads and paths with little activity aren‚Äôt shown on the map until they‚Äôre used by different users (not only runners, for example) for different activities.<br></p><p>To develop the heat map, Strava had to collect, analyze, and put together loads of data, which took money and a lot of time. Then the company had to update the map significantly, which meant unexpected additional expenses.&nbsp;<br></p><h4><strong>What to learn from this case:</strong></h4><ul role="list"><li>In the case of Strava, there were no hackers or other criminals ‚Äî the company gave out important information on its own. There was not even some kind of social engineering, as no fraud was involved. Strava simply didn‚Äôt pay enough attention to the potential outcome, and that was their main mistake ‚Äî they didn‚Äôt anticipate the consequences. Explaining the importance of security and privacy to the entire team and <strong>training staff</strong> on a regular basis probably couldn‚Äôt have prevented this incident fully. But if the Strava staff would have thought about possible implications, they would have noticed that something was wrong during the map development phase.&nbsp;</li><li><strong>Privacy settings</strong> should not be confusing. Users must be able to set everything up easily and quickly. If privacy settings had been clearer, most users would have been able to prevent their private data from being published.</li></ul><h2>The Bottom Line</h2><p>To protect your healthcare app from security mistakes and failures, you have to pay attention not only to encryption and multi-factor authentication. As you can see from the Strava case, it‚Äôs also crucial to plan updates and new releases very carefully.&nbsp;<br></p><p>Follow these simple rules: run security tests and staff trainings on a regular basis, secure your app with multi-factor authentication and encryption, keep privacy settings simple, and analyze all potential outcomes.&nbsp;<br></p><p>And, obviously, if something does go wrong, stay in touch with your users. </p><figure><p><img src="https://uploads-ssl.webflow.com/5c755d7d6fa90e6b6027e74c/5fb7c533a29d5b2035e7ec00_5f6cbf011fddb44501d8d28d_5d3042f66324e92dec2018cb_Business%20Insights.png" loading="lazy" alt=""></p></figure><p>‚Äç<br></p></div></article><section><div><div><p>LIKE THIS ARTICLE? Help us SPREAD THE WORD.</p></div></div></section></div>]]>
            </description>
            <link>https://www.ego-cms.com/post/most-expensive-healthcare-app-security-fails-in-2018-2019</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201335</guid>
            <pubDate>Tue, 24 Nov 2020 18:26:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error codes are far slower than exceptions]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25201269">thread link</a>) | @vips7L
<br/>
November 24, 2020 | https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/ | <a href="https://web.archive.org/web/*/https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
TL;DR On modern 64-bit PC architectures, C++ exceptions only add unreachable code with destructor calls into functions and their effect on performance is below 1%, but such low values are difficult to measure. Handling rare errors with return values requires additional branching that slows down the program in realistic scenarios by about 5% and are also less convenient. If an exception is actually thrown, stack unwinding costs about 2 ¬µs per stack frame.
</p>

<p>C is considered to be the fastest programming language. C++ has features that only make C more convenient without an effect on performance and features that do impact performance. They help a lot to improve code quality, so they are often used anyway. Runtime polymorphism is virtually ubiquitous, exceptions less so.</p>



<p>A completely valid reason not to use exceptions is when the executable‚Äôs size is or is expected to be tightly constrained by the platform‚Äôs limitations. A questionable reason not to use them is performance, as it‚Äôs unlikely for completely new functionality to work without compromises. Also, using exceptions in wrong cases can completely ruin performance because handling a thrown exception is known to be very expensive.</p>



<p>But how significant is the performance impact? On most modern 64-bit platforms, exceptions are implemented in a way that minimises their cost as long as they are not thrown. There are no checks for exceptions being thrown in the generated functions, the execution switches to special functions and special data when handling an exception. However, not using exceptions is not free either. Rare errors have to be handled somehow. One possibility is to have the program simply abort, leaving any broken state on the disk, leading to very annoying user experience (done for example in Unreal Engine and Unity Engine, where incorrect API usage in code causes the editor to crash and keep crashing until the incorrect binaries are manually erased). Another alternative are error codes, when functions report they failed and the calling code is supposed to react appropriately, which is less convenient for the programmer and requires the program an additional check after returning from functions, however, it‚Äôs often done for performance reasons.</p>



<p>But actually, how do these approaches affect performance? I have tested this on realistic examples that simulate use cases typical for video games.</p>



<h2>Reminder ‚Äì where not to use exceptions?</h2>



<p>An exception, as its name suggests, is supposed to deal with <em>exceptional</em> cases. An exception is a case when a rule doesn‚Äôt apply. In software, that means something isn‚Äôt going as intended. Not a part of a use case. A failure. Invalid user input, connection failure, corrupted data, invalid packet, failure to initialise a device, missing file, programmer errors‚Ä¶</p>



<p>In many of these cases, the program shouldn‚Äôt just abort. Invalid user input stopping the program is super annoying because it causes all unsaved data to be lost and forcing the user to wait until the program restarts. Connection failure is a very recoverable problem, usually solvable by simply reconnecting. Invalid packet causing a program to crash is an open door to sabotage, as anyone can send invalid packets to cause the program to crash. And that is what can be solved by exceptions. Throwing them is slow, but the code does not need to be optimised to what isn‚Äôt its use case.</p>



<p>Examples of incorrect use of exceptions is when they‚Äôre thrown when everything works as it should. Breaking from a double loop, handling the end of a container, checking if a number can be deserialised in order to use a default value otherwise‚Ä¶</p>



<p>Modern 64 bit architectures use a model called <em>zero-cost exceptions</em> that optimises error handling with exceptions strongly in favour of the happy path when no exception is thrown at the cost of very bad performance of exceptions when they are actually thrown.</p>



<p>In other words, it should be possible to run the program in a debugger with the stop on exception function enabled.</p>



<p>Although not all error handling can be efficiently handled with exceptions, error codes can handle all of it. The question is, should they?</p>



<h2>Test 1 ‚Äì XML parsing</h2>



<p>For the purpose of this test, I have written an XML parser. I chose to write a parser because it can fail at many locations and does not depend on I/O. It‚Äôs definitely not standard-compliant or guaranteed to fail on every possible invalid input, but it can parse a usual XML configuration file and should end with an error in most cases where the file is syntactically incorrect. The code is quite low level and should be relatively fast (about 150 MiB/s), but I did not optimise it and used STL containers to make it convenient to use (as opposed to in-situ parsing). I wrote it with a lot of <code>#ifdef</code> checks to switch between exceptions, error codes and abort on error just with compiler arguments and thus ensure that the only differences between the variants would be what is necessary for different error handling.</p>



<p>I benchmarked it with <a href="https://gist.github.com/Dugy/5fee1b49777054d01f12e22ce9f986e5">an XML file that imitates the configuration of a video game</a>. Its size is 32 kiB and is loaded into memory before the benchmarks start. The parsing was repeated 10000 times and the duration was averaged, then repeated 10 times to test that its imprecision was below 1%.</p>



<p>The code was compiled with GCC 9, on Ubuntu 20.04, with an Intel i7-9750H processor with maximum single threaded frequency 4.5 GHz. I ran all experiments that I wanted to compare at a similar time, without doing anything in between, in order to equalise the influence of other programs occupying cache. Anyway, there were still outliers that took noticeably more than average. I removed these.</p>



<p>The version that aborted on error was as fast as the version with exceptions. The version with error codes was 5% slower.</p>



<p>For some reasons, if failures were handled by a special function that printed the error and exited the program, it was for some reasons slightly (about 1%) slower than the version with exceptions. I had to use a macro to make it comparable to the speed of code using exceptions. This behaviour was repeated in the other tests.</p>



<h2>Test 2 ‚Äì filling classes with the parsed XML</h2>



<p>For this test, I‚Äôve written several classes meant to represent the structures in the XML file and code for filling the data with the parsed XML structure. This part was about 10 times faster, probably because there was much less dynamic allocation.</p>



<p>The error margins of the code with exceptions and the code with no proper error handling overlapped, but the times were 0.6% higher for exceptions. In the case of error codes, the program was 4% slower. I achieved a similar slowdown by forgetting to use move semantics.</p>



<h2>Test 3 ‚Äì Updating with data from a binary stream</h2>



<p>This test imitates the usage of an asynchronous API for reading data from a TCP socket (such as Boost Asio or Unix Sockets). These APIs are used in a way that always a certain number of bytes is read from the stream, have to be processed and then more data is read. For faster processing and reduced bandwidth, the data are in binary form. Because network data in video games are streamed continuously, waiting for the end is not feasible.</p>



<p>The communication is represented by three message types that identify different possible updates. Because the messages have different lengths, it‚Äôs not possible to exactly determine whether all of the message‚Äôs length is available, so the function that identifies the message and calls appropriate parsing code will fail often even if everything is running correctly ‚Äì so exceptions cannot be used to handle this type of failure. Other failures, like unidentifiable message types, wrong identification of objects or large sudden changes of values (either cheating or data corruption) are still handled by exceptions (in the case where they are used).</p>



<p>The data were read from memory in order to prevent networking from influencing the tests. The data were generated by <a href="https://gist.github.com/Dugy/d3d851ab4826cc3121fc00b79cb5124d">this script</a>.</p>



<p>The result of the test was similar to previous tests ‚Äì the code using exceptions for error handling was 0.8% slower than the code that aborted on error, which was within the margin of error, while the code using error codes to handle errors was 6% slower.</p>



<h2>The results</h2>



<p>The times taken by the benchmarks are summarised in the following table, scaled so that the time needed by the version that aborts when an error happens is 100%.</p>



<figure><table><thead><tr><th>Test</th><th>Abort</th><th>Exception</th><th>Error code</th></tr></thead><tbody><tr><td>Parsing</td><td>100%</td><td>100%</td><td>106.2%</td></tr><tr><td>Filling</td><td>100%</td><td>100.6%</td><td>104.2%</td></tr><tr><td>Updating</td><td>100%</td><td>100.8%</td><td>106.2%</td></tr></tbody></table></figure>



<p>The imprecision was around 1%, so the version using exceptions might not really be slightly slower and the difference might be the result of chance or some invisible compiler decisions, like inlining. The time needed by the version using error codes was consistently higher.</p>



<p>The entire source code is <a href="https://gist.github.com/Dugy/2532c810bb232b8ff1603cfa679bdf28">here</a>.</p>



<h2>Error handling and clean code</h2>



<p>When an exception is not handled in a block, the execution exits the block automatically until it finds a piece of code that can catch it. Any other type of handling does not support this and requires writing additional logic to handle the failure, although in almost all cases the appropriate reaction is to abort the operation the program is performing (the test with reading from a stream is an example where this does not apply). This can significantly lengthen the code even if the reaction to any failure in a function being called is to return the error code to the caller‚Äôs caller.</p>



<p>This is a line from the initialisation sector of a constructor in test 2:</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">	animation(*source.getChild("animation")),</pre>



<p>It forwards the child XML tag called <code>animation</code> of its argument to the constructor of a member class called&nbsp;<code>animation</code>. The constructor may fail due to incorrect content of the XML tag, or <code>getChild</code> function can fail because the entire tag is missing. This aborts the creation of the structure, or some other process in the program that‚Äôs in the <code>catch</code> block.</p>



<p>If the errors ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/">https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</a></em></p>]]>
            </description>
            <link>https://lordsoftech.com/programming/error-codes-are-far-slower-than-exceptions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201269</guid>
            <pubDate>Tue, 24 Nov 2020 18:20:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[P¬≤ quantile estimator ‚Äì estimating the median without storing values]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25201093">thread link</a>) | @ciprian_craciun
<br/>
November 24, 2020 | https://aakinshin.net/posts/p2-quantile-estimator/ | <a href="https://web.archive.org/web/*/https://aakinshin.net/posts/p2-quantile-estimator/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span><time datetime="2020-11-24">November 24, 2020</time>
&nbsp;&nbsp;
<i></i>&nbsp;
<a href="https://aakinshin.net/tags/statistics/">Statistics</a>
<a href="https://aakinshin.net/tags/quantiles/">Quantiles</a>
<a href="https://aakinshin.net/tags/performance-telemetry/">Performance Telemetry</a></span></p><p>Imagine that you are implementing performance telemetry in your application.
There is an operation that is executed millions of times, and you want to get its ‚Äúaverage‚Äù duration.
It‚Äôs not a good idea to use the arithmetic mean because the obtained value can be easily spoiled by outliers.
It‚Äôs much better to use the median which is one of the most robust ways to describe the average.</p><p>The straightforward median estimation approach requires storing all the values.
In our case, it‚Äôs a bad idea to keep all the values because it will significantly increase the memory footprint.
Such telemetry is harmful because it may become a new bottleneck instead of monitoring the actual performance.</p><p>Another way to get the median value is to use a sequential quantile estimator
(also known as an online quantile estimator or a streaming quantile estimator).
This is an algorithm that allows calculating the median value (or any other quantile value)
using a fixed amount of memory.
Of course, it provides only an approximation of the real median value,
but it‚Äôs usually enough for typical telemetry use cases.</p><p>In this post, I will show one of the simplest sequential quantile estimators that is called the P¬≤ quantile estimator
(or the Piecewise-Parabolic quantile estimator).</p><h3 id="the-p-quantile-estimator">The P¬≤ quantile estimator</h3><p>This algorithm was initially suggested in <a href="#Jain1985">[Jain1985]</a>.
Below you can find a short overview of this approach,
notes about typos in the original paper,
numerical simulation,
and a C# implementation.</p><h4 id="the-main-idea">The main idea</h4><p>Let‚Äôs say we have a stream of observations <span>\(\{ x_0, x_1, x_2, x_3, x_4, \ldots \}\)</span>
and we want to estimate p-quantile.
The suggested approach introduces five markers that correspond to the estimations of</p><ul><li><span>\(q_0\)</span>: The minimum</li><li><span>\(q_1\)</span>: The (p/2)-quantile</li><li><span>\(q_2\)</span>: The p-quantile</li><li><span>\(q_3\)</span>: The ((1+p)/2)-quantile</li><li><span>\(q_4\)</span>: The maximum</li></ul><p>The <span>\(q_i\)</span> values are known as the marker heights.</p><p>Also, we have to maintain the marker positions <span>\(\{ n_0, n_1, n_2, n_3, n_4 \}\)</span>.
These integer values describe actual marker indexes across obtained observations at the moment.</p><p>Next, we have to define the marker desired positions <span>\(\{ n'_0, n'_1, n'_2, n'_3, n'_4 \}\)</span>.
For the first <span>\(n\)</span> observations, these real values are defined as follows:</p><ul><li><span>\(n'_0 = 0\)</span></li><li><span>\(n'_1 = (n - 1) p / 2\)</span></li><li><span>\(n'_2 = (n - 1) p\)</span></li><li><span>\(n'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(n'_4 = (n - 1)\)</span></li></ul><p>In order to speed up the algorithm, we can precalculate increments of the desired positions which
should be added to the current values after each new observation:</p><ul><li><span>\(dn'_0 = 0\)</span></li><li><span>\(dn'_1 = p / 2\)</span></li><li><span>\(dn'_2 = (n - 1) p\)</span></li><li><span>\(dn'_3 = (n - 1) (1 + p) / 2\)</span></li><li><span>\(dn'_4 = (n - 1)\)</span></li></ul><p>Note that in the original paper, the authors use one-based indexing.
I decided to adapt it to the zero-based indexing which is more convenient from the implementation point of view.</p><h4 id="initialization">Initialization</h4><p>Once we collected the first five elements, we should perform initialization logic:</p><p><span>\[\left\{
\begin{array}{llll}
q_0 = x_{(0)}, &amp; n_0 = 0, &amp; n'_0 = 0,      &amp; dn'_0 = 0,\\
q_1 = x_{(1)}, &amp; n_1 = 1, &amp; n'_1 = 2p,     &amp; dn'_1 = p/2,\\
q_2 = x_{(2)}, &amp; n_2 = 2, &amp; n'_2 = 4p,     &amp; dn'_2 = p,\\
q_3 = x_{(3)}, &amp; n_3 = 3, &amp; n'_3 = 2 + 2p, &amp; dn'_3 = (1+p)/2,\\
q_4 = x_{(4)}, &amp; n_4 = 4, &amp; n'_4 = 4,      &amp; dn'_4 = 1.
\end{array}
\right.
\]</span></p><h4 id="marker-invalidation">Marker invalidation</h4><p>For each <span>\(x_j\)</span> for <span>\(j \geq 5\)</span>, we should invalidate our markers.</p><p>Firstly, we should adjust extreme marker heights
(if <span>\(x_j &lt; q_0\)</span>, we should update <span>\(q_0\)</span>; if <span>\(x_j &gt; q_4\)</span>, we should update <span>\(q_4\)</span>) and
find <span>\(k\)</span> such that <span>\(q_k \leq x_j &lt; q_{k+1}\)</span>
(or <span>\(q_k \leq x_j \leq q_{k+1}\)</span> for <span>\(k=3\)</span>):</p><table><thead><tr><th>Condition</th><th><span>\(q_i\)</span> update</th><th>k</th></tr></thead><tbody><tr><td><span>\(\phantom{q_0 \leq~} x_j &lt; q_0\)</span></td><td><span>\(q_0 = x_j\)</span></td><td>0</td></tr><tr><td><span>\(q_0 \leq x_j &lt; q_1\)</span></td><td></td><td>0</td></tr><tr><td><span>\(q_1 \leq x_j &lt; q_2\)</span></td><td></td><td>1</td></tr><tr><td><span>\(q_2 \leq x_j &lt; q_3\)</span></td><td></td><td>2</td></tr><tr><td><span>\(q_3 \leq x_j &lt; q_4\)</span></td><td></td><td>3</td></tr><tr><td><span>\(q_4 \leq x_j\)</span></td><td><span>\(q_4 = x_j\)</span></td><td>3</td></tr></tbody></table><p>Secondly, we should update the marker positions and the marker desired positions:</p><p><span>\[\begin{array}{lcl}
n_i = n_i + 1 &amp; \textrm{for} &amp; i = k + 1, \ldots, 4; \\
n'_i = n'_i + dn'_i &amp; \textrm{for} &amp; i = 0, \ldots, 4. \\
\end{array}
\]</span></p><p>Finally, we should adjust non-extreme marker heights (<span>\(q_i\)</span>) and positions (<span>\(n_i\)</span>) for <span>\(i \in \{ 1, 2, 3\} \)</span>
in the following way:</p><div><pre><code data-lang="cs"><span>for</span> <span>(</span><span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
<span>{</span>
    <span>d</span> <span>=</span> <span>nÍûå</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span>
    <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span>  <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span>  <span>1</span> <span>||</span>
        <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
    <span>{</span>
        <span>d</span> <span>=</span> <span>sign</span><span>(</span><span>d</span><span>)</span>
        <span>qÍûå</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>if</span> <span>(!(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qÍûå</span> <span>&amp;&amp;</span> <span>qÍûå</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]))</span>
            <span>qÍûå</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>d</span><span>)</span>
        <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qÍûå</span>
        <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>d</span>
    <span>}</span>
<span>}</span>
</code></pre></div><p>The core equation of the algorithm is a piecewise-parabolic prediction (P¬≤) formula
that adjusts marker heights for each observation:</p><p><span>\[q'_i = q_i + \dfrac{d}{n_{i+1}-n_{i-1}} \cdot
\Bigg(
(n_i-n_{i-1}+d)\dfrac{q_{i+1}-q_i}{n_{i+1}-n_i} +
(n_{i+1}-n_i-d)\dfrac{q_i-q_{i-1}}{n_i-n_{i-1}}
\Bigg).
\]</span></p><p>Once we calculated <span>\(q'_i\)</span>, we should check that <span>\(q_{i-1} &lt; q'_i &lt; q_{i+1}\)</span>.
If this condition is false, we should ignore the parabolic prediction and use the linear prediction instead:</p><p><span>\[q'_i = q_i + d \dfrac{q_{i+d}-q_i}{n_{i+d}-n_{i}}.
\]</span></p><h4 id="the-result">The result</h4><p>Once you need the requested quantile estimation value, we should just take the value of <span>\(q_2\)</span>.</p><h4 id="typos-in-the-original-paper">Typos in the original paper</h4><p>A find a few typos in the original paper which may confuse readers who want to implement the algorithm from scratch:</p><ul><li>Page 1079, Box 1, B2:
<code>$i = k, \ldots, 5$</code>
should be replaced by
<code>$i = k + 1, \ldots, 5$</code></li><li>Page 1079, Box 1, B3:
<code>$\textbf{THEN}\; q_i \leftarrow q_i$</code>
should be replaced by
<code>$\textbf{THEN}\; q_i \leftarrow q'_i$</code></li></ul><h3 id="numerical-simulation">Numerical simulation</h3><p>It‚Äôs time to check how it works.
I decided to visualize sequential values of the following quantiles estimator:</p><ul><li><strong>The P¬≤ quantile estimator</strong><br>A sequential estimator that is described above.</li><li><strong>The Type 7 quantile estimator</strong><br>It‚Äôs the most popular quantile estimator which is used by default in
R, Julia, NumPy, Excel (<code>PERCENTILE</code>, <code>PERCENTILE.INC</code>), Python (<code>inclusive</code> method).
We call it ‚ÄúType 7‚Äù according to notation from <a href="#Hyndman1996">[Hyndman1996]</a>,
where Rob J. Hyndman and Yanan Fan described nine quantile algorithms which are used in statistical computer packages.</li><li><strong>The Harrell-Davis quantile estimator</strong><br>It‚Äôs my favorite option in real life for non-sequential cases because
it‚Äôs more robust than classic quantile estimators based on linear interpolation,
and it provides more reliable estimations on small samples.
This quantile estimator is described in <a href="#Harrell1982">[Harrell1982]</a>.</li><li><strong>Actual</strong><br>The true median value which is taken from the underlying distribution.</li></ul><p>Below, you can find several plots for the following distributions:</p><ul><li><strong>Normal distribution</strong> <span>\(\mathcal{N}(0, 1)\)</span></li><li><strong>Gumbel distribution</strong> for <span>\(\mu = 0, \beta = 1\)</span></li><li><strong>Beta distribution</strong> <span>\(\textrm{Beta}(10, 2)\)</span></li><li><strong>Uniform distribution</strong> <span>\(\mathcal{U}(0, 1)\)</span></li><li><strong>Bimodal distribution</strong> (mixture of <span>\(\mathcal{N}(10, 1)\)</span> and <span>\(\mathcal{N}(20, 1)\)</span>)</li></ul><p>Here are the results:</p><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" target="_blank" alt="normal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/normal-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" target="_blank" alt="gumbel"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/gumbel-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" target="_blank" alt="beta"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/beta-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" target="_blank" alt="uniform"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/uniform-light.svg"></picture></a></div></div><br><div><div><a href="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" target="_blank" alt="bimodal"><picture>
<source theme="dark" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-dark.svg" media="(prefers-color-scheme: dark)"><source theme="light" srcset="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg" media="(prefers-color-scheme: light), (prefers-color-scheme: no-preference)"><img width="800" src="https://aakinshin.net/posts/p2-quantile-estimator/img/bimodal-light.svg"></picture></a></div></div><p>As you can see, The P¬≤ quantile estimator produces reasonable median estimates.
I also checked how it works on a considerable number of real data sets and
I‚Äôm pretty satisfied with the results.
You can also find a discussion about accuracy and the equation for the mean squared error in the original paper.</p><h3 id="reference-implementation">Reference implementation</h3><p>Below you can find a C# implementation of the discussed algorithm.
Also, you can use it via
the latest nightly version (0.3.0-nightly.64+) of <a href="https://github.com/AndreyAkinshin/perfolizer">perfolizer</a>.</p><div><pre><code data-lang="cs"><span>public</span> <span>class</span> <span>P2QuantileEstimator</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>double</span> <span>p</span><span>;</span>
    <span>private</span> <span>readonly</span> <span>int</span><span>[]</span> <span>n</span> <span>=</span> <span>new</span> <span>int</span><span>[</span><span>5</span><span>];</span> <span>// marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>ns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// desired marker positions
</span><span></span>    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>dns</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span>
    <span>private</span> <span>readonly</span> <span>double</span><span>[]</span> <span>q</span> <span>=</span> <span>new</span> <span>double</span><span>[</span><span>5</span><span>];</span> <span>// marker heights
</span><span></span>    <span>private</span> <span>int</span> <span>count</span><span>;</span>

    <span>public</span> <span>P2QuantileEstimator</span><span>(</span><span>double</span> <span>p</span><span>)</span>
    <span>{</span>
        <span>p</span> <span>=</span> <span>probability</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>void</span> <span>AddValue</span><span>(</span><span>double</span> <span>x</span><span>)</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>q</span><span>[</span><span>count</span><span>++]</span> <span>=</span> <span>x</span><span>;</span>
            <span>if</span> <span>(</span><span>count</span> <span>==</span> <span>5</span><span>)</span>
            <span>{</span>
                <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>);</span>

                <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
                    <span>n</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>i</span><span>;</span>

                <span>ns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>ns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>4</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>2</span> <span>+</span> <span>2</span> <span>*</span> <span>p</span><span>;</span>
                <span>ns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>4</span><span>;</span>

                <span>dns</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>0</span><span>;</span>
                <span>dns</span><span>[</span><span>1</span><span>]</span> <span>=</span> <span>p</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>2</span><span>]</span> <span>=</span> <span>p</span><span>;</span>
                <span>dns</span><span>[</span><span>3</span><span>]</span> <span>=</span> <span>(</span><span>1</span> <span>+</span> <span>p</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
                <span>dns</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>1</span><span>;</span>
            <span>}</span>

            <span>return</span><span>;</span>
        <span>}</span>

        <span>int</span> <span>k</span><span>;</span>
        <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>0</span><span>])</span>
        <span>{</span>
            <span>q</span><span>[</span><span>0</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>}</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>1</span><span>])</span>
            <span>k</span> <span>=</span> <span>0</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>2</span><span>])</span>
            <span>k</span> <span>=</span> <span>1</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>3</span><span>])</span>
            <span>k</span> <span>=</span> <span>2</span><span>;</span>
        <span>else</span> <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>q</span><span>[</span><span>4</span><span>])</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>else</span>
        <span>{</span>
            <span>q</span><span>[</span><span>4</span><span>]</span> <span>=</span> <span>x</span><span>;</span>
            <span>k</span> <span>=</span> <span>3</span><span>;</span>
        <span>}</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>k</span> <span>+</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>n</span><span>[</span><span>i</span><span>]++;</span>
        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>5</span><span>;</span> <span>i</span><span>++)</span>
            <span>ns</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dns</span><span>[</span><span>i</span><span>];</span>

        <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>3</span><span>;</span> <span>i</span><span>++)</span>
        <span>{</span>
            <span>double</span> <span>d</span> <span>=</span> <span>ns</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>];</span>
            <span>if</span> <span>(</span><span>d</span> <span>&gt;=</span> <span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&gt;</span> <span>1</span> <span>||</span> <span>d</span> <span>&lt;=</span> <span>-</span><span>1</span> <span>&amp;&amp;</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>&lt;</span> <span>-</span><span>1</span><span>)</span>
            <span>{</span>
                <span>int</span> <span>dInt</span> <span>=</span> <span>Math</span><span>.</span><span>Sign</span><span>(</span><span>d</span><span>);</span>
                <span>double</span> <span>qs</span> <span>=</span> <span>Parabolic</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>if</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>&lt;</span> <span>qs</span> <span>&amp;&amp;</span> <span>qs</span> <span>&lt;</span> <span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>])</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>qs</span><span>;</span>
                <span>else</span>
                    <span>q</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>Linear</span><span>(</span><span>i</span><span>,</span> <span>dInt</span><span>);</span>
                <span>n</span><span>[</span><span>i</span><span>]</span> <span>+=</span> <span>dInt</span><span>;</span>
            <span>}</span>
        <span>}</span>

        <span>count</span><span>++;</span>
    <span>}</span>
    
    <span>private</span> <span>double</span> <span>Parabolic</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>double</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>*</span> <span>(</span>
            <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>]</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>])</span> <span>+</span>
            <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>1</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span> <span>-</span> <span>1</span><span>])</span>
        <span>);</span>
    <span>}</span>

    <span>private</span> <span>double</span> <span>Linear</span><span>(</span><span>int</span> <span>i</span><span>,</span> <span>int</span> <span>d</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>q</span><span>[</span><span>i</span><span>]</span> <span>+</span> <span>d</span> <span>*</span> <span>(</span><span>q</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>q</span><span>[</span><span>i</span><span>])</span> <span>/</span> <span>(</span><span>n</span><span>[</span><span>i</span> <span>+</span> <span>d</span><span>]</span> <span>-</span> <span>n</span><span>[</span><span>i</span><span>]);</span>
    <span>}</span>

    <span>public</span> <span>double</span> <span>GetQuantile</span><span>()</span>
    <span>{</span>
        <span>if</span> <span>(</span><span>count</span> <span>&lt;=</span> <span>5</span><span>)</span>
        <span>{</span>
            <span>Array</span><span>.</span><span>Sort</span><span>(</span><span>q</span><span>,</span> <span>0</span><span>,</span> <span>count</span><span>);</span>
            <span>int</span> <span>index</span> <span>=</span> <span>(</span><span>int</span><span>)</span> <span>Math</span><span>.</span><span>Round</span><span>((</span><span>count</span> <span>-</span> <span>1</span><span>)</span> <span>*</span> <span>p</span><span>);</span>
            <span>return</span> <span>q</span><span>[</span><span>index</span><span>];</span>
        <span>}</span>

        <span>return</span> <span>q</span><span>[</span><span>2</span><span>];</span>
    <span>}</span>
<span>}</span>
</code></pre></div><h3 id="conclusion">Conclusion</h3><p>The P¬≤ quantile estimator allows estimating quantile values on a stream of numbers without storing individual ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aakinshin.net/posts/p2-quantile-estimator/">https://aakinshin.net/posts/p2-quantile-estimator/</a></em></p>]]>
            </description>
            <link>https://aakinshin.net/posts/p2-quantile-estimator/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25201093</guid>
            <pubDate>Tue, 24 Nov 2020 18:06:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How do people find bugs?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25200893">thread link</a>) | @bitwizzle
<br/>
November 24, 2020 | https://cryptologie.net/article/511/how-do-people-find-bugs/ | <a href="https://web.archive.org/web/*/https://cryptologie.net/article/511/how-do-people-find-bugs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<p>You might wonder how people find bugs. Low-hanging fruit bugs can be found via code review, static analysis, dynamic analysis (like fuzzing), and other techniques. But what about deep logic bugs. Those you can‚Äôt find easily. Perhaps the protocol implemented is quite complicated, or correctness is hard to define, and edge-cases hard to detect. One thing I‚Äôve noticed is that re-visiting protocols are an excellent way to find logic bugs.</p>
<p>Ian Miers once said something like that: "you need time, expertise, and meaningful engagement‚Äù. I like that sentence, although one can point out that these traits are closely linked--you can‚Äôt have meaningful engagement without time and expertise--it does show that finding bugs take "effort".</p>
<p>OK. Meaningful engagement can lead to meaningful bugs, and meaningful bugs can be found at different levels.
So you're here, seating in your undies in the dark, with a beer on your side and some uber eats lying on the floor.
Your computer is staring back at you, blinking at a frequency you can't notice, and waiting for you to find a bug in this protocol.
What do you do?
Perhaps the protocol doesn't have a proof, and this leads you to wonder if you can write one for it...</p>
<p>It worked for Ariel Gabizon, who in 2018 <a href="https://electriccoin.co/blog/zcash-counterfeiting-vulnerability-successfully-remediated/">found a subtle error</a> in a <a href="https://eprint.iacr.org/2013/879">2013 zk-SNARK paper</a> used by the Zcash cryptocurrency he was working on.
He found it by trying to write a proof for the paper he was reading, realizing that the authors had winged it.
While protocols back in the days could afford to wing it, these days people are more difficult--they demand proofs.
The bug Ariel found could have allowed anyone to forge an unlimited amount of money undetected.
It was silently fixed months later in an upgrade to the network.</p>
<blockquote>
<p>Ariel Gabizon, a cryptographer employed by the Zcash Company at the time of discovery, uncovered a soundness vulnerability. The key generation procedure of [BCTV14], in step 3, produces various elements that are the result of evaluating polynomials related to the statement being proven. Some of these elements are unused by the prover and were included by mistake; but their presence allows a cheating prover to circumvent a consistency check, and thereby transform the proof of one statement into a valid-looking proof of a different statement. This breaks the soundness of the proving system.</p>
</blockquote>
<p>What if the protocol already had a proof though?
Well that doesn't mean much, people enjoy writing unintelligible proofs, and people make errors in proofs all the time.
So the second idea is that reading and trying to understand a proof might lead to a bug in the proof.
Here's some meaningful engagement for you.</p>
<p>In 2001, Shoup revisited some proofs and <a href="https://eprint.iacr.org/2000/060.pdf">found some darning gaps in the proofs for RSA-OAEP</a>, leading to a newer scheme OAEP+ which was never adopted in practice.
Because back then, as I said, we really didn't care about proofs.</p>
<blockquote>
<p>[BR94] contains a valid proof that OAEP satisfies a certain technical property which they call ‚Äúplaintext awareness.‚Äù Let us call this property PA1. However, it is claimed without proof that PA1 implies security against chosen ciphertext attack and non-malleability. Moreover, it is not even clear if the authors mean adaptive chosen ciphertext attack (as in [RS91]) or indifferent (a.k.a. lunchtime) chosen ciphertext attack (as in [NY90]).</p>
</blockquote>
<p>Later in 2018, a series of discoveries on the proofs for the OCB2 block cipher quickly led to <a href="https://eprint.iacr.org/2019/311">practical attacks breaking the cipher</a>.</p>
<blockquote>
<p>We have presented practical forgery and decryption attacks against OCB2, a high-profile ISO-standard authenticated encryption scheme. This was possible due to the discrepancy between the proof of OCB2 and the actual construction, in particular the interpretation of OCB2 as a mode of a TBC which combines XEX and XE.</p>
</blockquote>
<blockquote>
<p>We comment that, due to errors in proofs, ‚Äòprovably-secure schemes‚Äô sometimes still can be broken, or schemes remain secure but nevertheless the proofs need to be fixed. Even if we limit our focus to AE, we have many examples for this, such as NSA‚Äôs Dual CTR [37,11], EAX-prime [28], GCM [22], and some of the CAESAR submissions [30,10,40]. We believe our work emphasizes the need for quality of security proofs, and their active verification.</p>
</blockquote>
<p>Now, reading and verifying a proof is always a good idea, but it‚Äôs slow, it‚Äôs not flexible (if you change the protocol, good job changing the proof), and it‚Äôs limited (you might want to prove different things re-using parts of the proofs, which is not straight forward).
Today, we are starting to bridge the gap between pen and paper proofs and computer science: it is called formal verification.
And indeed, formal verification is booming, with a number of papers in the recent years finding issues here and there just by describing protocols in a formal language and verifying that they withstand different types of attacks.</p>
<p><a href="https://eprint.iacr.org/2019/526">Prime, Order Please! Revisiting Small Subgroup and Invalid Curve Attacks on Protocols using Diffie-Hellman</a>:</p>
<blockquote>
<p>We implement our improved models in the Tamarin prover. We find a new attack on the Secure Scuttlebutt Gossip protocol, independently discover a recent attack on Tendermint‚Äôs secure handshake, and evaluate the effectiveness of the proposed mitigations for recent Bluetooth attacks.</p>
</blockquote>
<p><a href="https://eprint.iacr.org/2019/779">Seems Legit: Automated Analysis of Subtle Attacks on Protocols that Use Signatures</a>:</p>
<blockquote>
<p>We implement our models in the Tamarin Prover, yielding the first way to perform these analyses automatically, and validate them on several case studies. In the process, we find new attacks on DRKey and SOAP‚Äôs WS-Security, both protocols which were previously proven secure in traditional symbolic models.</p>
</blockquote>
<p><img alt="tamarin" src="https://cryptologie.net/upload/tamarin-obseq-lemma-attack.jpg"></p>
<p>But even this kind of techniques has limitation! (OMG David when will you stop?)</p>
<p>In 2017 <a href="https://blog.cryptographyengineering.com/2017/10/16/falling-through-the-kracks/">Matthew Green wrote</a>: </p>
<blockquote>
<p>I don‚Äôt want to spend much time talking about KRACK itself, because the vulnerability is pretty straightforward. Instead, I want to talk about&nbsp;why&nbsp;this vulnerability continues to exist so many years after WPA was standardized. And separately, to answer a question: how did this attack slip through, despite the fact that the 802.11i handshake was&nbsp;formally proven secure?</p>
</blockquote>
<p>He later writes:</p>
<blockquote>
<p>The critical problem is that while people looked closely at the two components ‚Äî handshake and encryption protocol ‚Äî&nbsp;in isolation, apparently nobody looked closely at the two components as they were connected together. I‚Äôm pretty sure there‚Äôs an entire&nbsp;geek meme&nbsp;about this.</p>
</blockquote>
<p>pointing to the "2 unit tests. 0 integration tests." joke.</p>
<p><img alt="meme" src="https://cryptologie.net/upload/ezgif-3-a0aa048a0c79.gif"></p>
<p>He then recognizes that it‚Äôs a hard problem:</p>
<blockquote>
<p>Of course, the reason nobody looked closely at this stuff is that doing so is just&nbsp;plain&nbsp;hard. Protocols have an exponential number of possible cases to analyze, and we‚Äôre just about at the limit of the complexity of protocols that human beings can truly reason about, or that peer-reviewers can verify. The more pieces you add to the mix, the worse this problem gets.
In the end we all know that the answer is for humans to stop doing this work. We need machine-assisted verification of protocols, preferably tied to the&nbsp;actual source code that implements them. This would ensure that the protocol actually does what it says, and that implementers don‚Äôt further screw it up, thus invalidating the security proof.</p>
</blockquote>
<p>Well, Matthew, we do have formally generated code! <a href="https://hacl-star.github.io/">HACL*</a> and <a href="http://adam.chlipala.net/papers/FiatCryptoSP19/FiatCryptoSP19.pdf">fiat-crypto</a> are two examples.
Anybody has heard of that failing? I‚Äôd be interested‚Ä¶</p>
<p>In any case, what‚Äôs left for us? A lot! Formally generated code is hard, and generally covers small parts of your protocol (e.g. field arithmetic for elliptic curves).
So what else can we do?
Implementing the protocol, if it hasn‚Äôt been implemented before, is a no-brainer.
In 2016, Taylor Hornby an engineer at Zcash <a href="https://electriccoin.co/blog/fixing-zcash-vulns/">wrote about a bug he found</a> while implementing the zerocash paper into the Zcash cryptocurrency:</p>
<blockquote>
<p>In this blog post, we report on the security issues we‚Äôve found in the Zcash protocol while preparing to deploy it as an open, permissionless financial system.
Had we launched Zcash without finding and fixing the InternalH Collision vulnerability, it could have been exploited to counterfeit currency. Someone with enough computing power to find 128-bit hash collisions would have been able to double-spend money to themselves, creating Zcash out of thin air.</p>
</blockquote>
<p>Perhaps re-implementing the protocol in a different language might work as well?</p>
<p><img alt="" src="https://cryptologie.net/upload/Screen_Shot_2020-11-23_at_10.16_.18_PM_.png"></p>
<p>One last thing, most of the code out there is not formally verified.
So of course, reviewing code works, but you need time, expertise, money, etc.
So instead, what about testing?
This is what <a href="https://github.com/google/wycheproof">Wycheproof</a> does by implementing a number of test vectors that are known to cause issues:</p>
<blockquote>
<p>These observations have prompted us to develop Project Wycheproof, a collection of unit tests that detect known weaknesses or check for expected behaviors of some cryptographic algorithm. Project Wycheproof provides tests for most cryptographic algorithms, including RSA, elliptic curve crypto and authenticated encryption. Our cryptographers have systematically surveyed the literature and implemented most known attacks. We have over 80 test cases which have uncovered more than&nbsp;40 bugs. For example, we found that we could recover the private key of widely-used DSA and ECDHC implementations.</p>
</blockquote>
<p>In all of that, I didn't even talk about the benefits of writing a specification... that's for another day.</p>
</article><p>Well done! You've reached the end of my post. Now you can <a href="">leave a comment</a> or read something else.</p></div>]]>
            </description>
            <link>https://cryptologie.net/article/511/how-do-people-find-bugs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200893</guid>
            <pubDate>Tue, 24 Nov 2020 17:49:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby on Rails: Still the Best Web App Framework for Most Teams]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25200799">thread link</a>) | @sairamkunala
<br/>
November 24, 2020 | https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html | <a href="https://web.archive.org/web/*/https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>Earlier this year, I was in the position to choose the framework for the startup at which I‚Äôm now the CTO. I
could‚Äôve chosen anything. I went with Rails.  And you should, too. It still is the best framework for getting up
and running <em>and</em> for continued iteration and development.</p>

<!-- more -->

<p>Writing a web app requires many moving pieces.  If you use something like Spring, Node, Express, or any other basic
library, you have a <em>lot</em> of decisions to make:</p>

<ul>
  <li>How are URLs routed to code?</li>
  <li>How are headers, params, and request bodies parsed?</li>
  <li>Where does the code live to manage this?</li>
  <li>How are responses created?</li>
  <li>How do we generate dynamic HTML?</li>
  <li>How do we mitigate against common security vulnerabilities such as cross-site scripting?</li>
</ul>

<p>Of course, web apps almost always have a database, which leads to more decisions:</p>

<ul>
  <li>How will we access the database?</li>
  <li>How is the database schema managed?</li>
  <li>What conventions will we use for table and column names?</li>
</ul>

<p>Then, there are concerns around the development environment:</p>

<ul>
  <li>How do we write tests?</li>
  <li>How can we execute a test using a web browser?</li>
  <li>How do we manage the data needed for our tests?</li>
  <li>How do we manage data needed to run the app locally?</li>
</ul>

<p>Finally, there are concerns around deployment and production:</p>

<ul>
  <li>How do I get JavaScript packaged for the browser?</li>
  <li>How do I manage CSS?</li>
  <li>How do I create cacheable bundles for CDNs?</li>
</ul>

<h2 id="the-cost-of-making-so-many-decisions">The Cost of Making So Many Decisions</h2>

<p>These decisions are only the beginning.  I‚Äôve worked on web apps that used libraries only‚Äîno frameworks‚Äîand all of
these decisions plus more had to be made. Many had to be made before the team could start working.  But as time
went by and the team‚Äôs composition changed, managing these decisions was a constant tax.</p>

<p>‚Ä¶managing these decisions was a constant tax</p>

<p>Because <em>we</em> made these decisions and <em>we</em> configured our libraries to work in a particular way, it was not
uncommon for developers to want to know why we did it that way, and could we change it?  Many of these decisions
amount to conventions not enforceable with code, so a good chunk of our code reviews required making sure everyone
followed the conventions.</p>

<p>And then we would update our libraries to find out they were suddenly incompatible.  Because we‚Äôd hand-selected
libraries to solve each problem, we had no way to guarantee they all worked together other than making sure our app
still worked.  It was hard to see the value in the series of decisions that led to this architecture.</p>

<h2 id="stop-making-so-many-decisions">Stop Making So Many Decisions</h2>

<p>With Rails, you don‚Äôt have to make <em>any</em> of the decisions above. None.  Once you type <code>rails new</code> all of those
decisions are made.  True, there are more decisions you will have to make, but Rails will have eliminated a huge number of ultimately pointless decisions.</p>

<p>Rails will have eliminated a huge number of ultimately pointless decisions</p>

<p>It simply doesn‚Äôt matter how JavaScript is packaged, what your database naming conventions are, or how HTTP requests are routed to code. You need answers and conventions for all of that, yes, but the actual conventions don‚Äôt matter.</p>

<p>What you also need are the conventions to be enforced or managed in code, not documentation. That way, everyone is
incentivized to focus on the problems specific to their domain instead of the plumbing of their app.</p>



<p>This has been the value proposition for Rails since its inception over 15 year ago.  In that time, Rails and its
ecosystem have matured, improved, and continued moving forward.  The value Rails brings is still needed, and it is
<em>still</em> the best framework for most teams.</p>

<p>Engineers without Rails experience may continue to believe the fantasy that Rails does not scale or that it can‚Äôt
be used for ‚Äúserious‚Äù problems.  Those of us <em>with</em> Rails experience know this isn‚Äôt true.  But what we also worry
about is that Rails apps can become unmaintainable.</p>

<h2 id="rails-helps-maintainability">Rails Helps Maintainability</h2>

<p>Hopefully, it‚Äôs obvious that no framework or set of libraries can ensure maintainability.  I would argue that Rails
gives you a better chance.  Rails‚Äîand its ecosystem‚Äîtend to evolve together, so you can rely on the stability of
your core tools over many years.</p>

<p>Rails basis in conventions also means that there are generally fewer parts of an app to get crufty as time goes by.
But, it‚Äôs still up to the team to establish conventions and ways of working to capitalize on that.  As it would be
on any team.</p>

<p>So what happens when the team stops making pointless decisions, worrying about library compatibility, and spending
code-review time on conventions?  They start thinking about the problems they need to solve. That‚Äôs why Rails is
the best web framework for most teams.</p>

  </section></div>]]>
            </description>
            <link>https://naildrivin5.com/blog/2020/11/23/rails-is-the-best-choice-for-most-teams.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200799</guid>
            <pubDate>Tue, 24 Nov 2020 17:40:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No surprises here ‚Äì On the absence of information in today‚Äôs media]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 99 (<a href="https://news.ycombinator.com/item?id=25200732">thread link</a>) | @s3v
<br/>
November 24, 2020 | https://www.turningchaos.com/essays/no-surprises-here | <a href="https://web.archive.org/web/*/https://www.turningchaos.com/essays/no-surprises-here">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-4a3121594376e73eb592"><div><h2>The absence of information in today‚Äôs press</h2><p>"<em>Nobody goes to a newspaper for news.</em>" ‚ÄîMartin Gurri</p><p>We're told we live in the information age. Statements like this often quote the mind-boggling amount of data produced on the internet using exotic-sounding words like zettabytes per day as proof. To function in this sea of data, we're supposed to find signals in the noise and read from credible sources of news and other information. With news media taking political stances, it's not that easy.</p><p>My assertion, paradoxically, is that polarization has greatly diminished the <em>quantity of information</em> being produced and consumed via today's press despite the sea of content they produce. The result is a loss of the press's effectiveness in their two functions within a healthy democracy, as a check on government and promoter of informed debate.</p><h2>Information</h2><p>It's important to define terms. What is information?</p><p>In the <a href="https://en.wikipedia.org/wiki/Information_theory">information theory</a> definition, the quantity of information in a message is related to the amount of <em>surprise</em> it contains. This idea of surprise is key so I'm going to spend some time on it.</p><p>Let's imagine you're receiving messages about some set of data and you're trying to determine its distribution. Each message contains one data point. Early on, as you receive messages, the information provided by each piece of data is high because you know very little about the data itself. With each new piece of information, you start to construct a representation of the overall data set like the one shown in the image below.</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606176449103_6575"><div><p>After some number of points, you realize the data is a normal distribution or bell-curve and you can make some determination about its structure. In this case, the mean or average value as well as its width (or standard deviation). Let's say the average value is 0 and the standard deviation is 1. This means that 68% of the values will be between -1 and 1, 95% will be between -2 and 2, and &gt;99% will be between -3 and 3.</p><p>Great! Let's say the next set of messages that you get are 0, 0.1, and 1. Those numbers are completely within the expected range we calculated earlier. There's nothing particularly surprising about them, and as a result, <strong>there is almost no information</strong> contained within them.</p><p>What if you get a message of 10? Now there's a problem. There's almost no chance that the distribution we described above should include a value of 10. Getting 10 is very surprising. So surprising that it may mean the model we had for this data is entirely wrong. That's a lot of information contained in one message of 10, way more than the other messages we got earlier.</p><p>Why does 10 have so much information? It's because it's surprising. It causes us to challenge the model we had built. It could be that the message was a mistake, a fluke. But it could also be that the conclusions we held were wrong. <strong>The more high-information messages like this we get, the more we should start to challenge the beliefs we previously held.</strong> Now let's get back to media.</p><h2>News media</h2><p>In today's polarized media, each side of the media discourse has established its perspective, and the content they publish conforms to this perspective. When you go to a news outlet with a particular leaning, you may not know exactly what stories they'll be writing about, but you do know what <em>kind</em> of stories will be covered and from what perspective. Your knowledge about that outlet's outlook was built up over time as you encountered what they publish.</p><p>When one outlet consistently publishes pieces that align with their perspective, the information content provided by each article starts to diminish. When the theme of each article aligns within the expected distribution, there's no surprise and thus no information.</p><p>It's important to take a moment to distinguish surprise from shock. As you may be familiar, it's common for media to publish stories that have a shock value as they compete with other organizations for your attention. What I'm discussing in this essay isn't the shock value or the particular event that the news media is writing about, it's the perspective of the news organization and the degree of surprise that they published it. For example, you might be shocked at the behavior of one political party's behavior, but are you surprised by it, and more importantly, are you surprised that a news organization that takes the opposite position is publishing a story about it? Shock and surprise can be related, but there's a distinction here between headlines that are attention-grabbing and whether the content fits the mold of the news organization's narrative.</p><h2>Implications</h2><p>The danger of this is two-fold. First, if you only read from one source or a set of sources with similar outlooks, the media source's perspective can start to become yours. You end up with a world-view that aligns with the publisher's view. Since that source never prints anything which disputes that view, your perspective on the world becomes insulated and unchallenged. It's like the example above where we thought we knew the distribution was a bell-curve until we got a few message outliers. Those outliers demanded we reconsider our earlier conclusions. Except this time, <strong>the outliers exist but we never receive them</strong>. We go about our days oblivious to information that would challenge our world-view because it doesn't get published anywhere we look.</p><p>"<em>A free press is one of the pillars of democracy</em>." - Nelson Mandela</p><p>The second danger involves the media's role as a check on government. The branches of government exist to prevent the abuse of power by one another. <strong>The press exists to prevent the abuse of information by the government.</strong> It should question and investigate claims by the government to inform voters and further civic discourse.</p><p>However, this function requires the press to be viewed as impartial, truth-seeking, and without advancing an opinion except where explicitly noted (i.e. the opinion section). If the average voter comes to distrust the press, this function is lost. Articles that would normally inform the voter, providing surprise and evidence that would counter a particular world-view, instead go unread or dismissed. Voters either write off the press entirely or read solely from outlets with views that align with their own further solidifying their own beliefs. In either case, we end up with tribes of perspectives unwilling to seek a compromise that can allow the country to proceed collectively.</p><p>I'm not claiming that all reporters are like this. There are excellent reporters that seek truth regardless of politics. Unfortunately, this independent perspective is increasingly difficult to find. Well-reasoned, objective reporting doesn't generate the same attention as partisan emotion.</p><p>Instead, our press needs to promote information and surprise without bias. By only publishing from one narrative, they insulate the public (and themselves!) from information that could lead to honest debate and discovery. Likewise, our opinions should be formed from a careful examination of arguments and evidence on each side of the issue, <strong>reading from only one perspective is akin to not reading at all.</strong></p></div></div></div>]]>
            </description>
            <link>https://www.turningchaos.com/essays/no-surprises-here</link>
            <guid isPermaLink="false">hacker-news-small-sites-25200732</guid>
            <pubDate>Tue, 24 Nov 2020 17:35:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Quicklang.net ‚Äì A Simple Programming Language That Runs in the Browser]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25199865">thread link</a>) | @chkas
<br/>
November 24, 2020 | https://quicklang.net/ide/ | <a href="https://web.archive.org/web/*/https://quicklang.net/ide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://quicklang.net/ide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199865</guid>
            <pubDate>Tue, 24 Nov 2020 16:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My EOY Reflection Checklist]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25199785">thread link</a>) | @opsgal
<br/>
November 24, 2020 | https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong | <a href="https://web.archive.org/web/*/https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em><strong>The End-of-Year Checklist</strong><span>&nbsp;</span></em><em><span></span></em></p>
<p><span>I like starting the year with an empty to-do list and a fresh perspective. As an obsessive list maker, this process naturally starts with another list. Some of the questions can be treated as action items, but many require deeper reflection (perfect for the quiet week at the end of the year). I hope that you find it useful as you close out 2020!</span></p>

<h5><strong>As a Company</strong></h5>
<ul>
<li><span>What actions most moved the company forward and how can we double down on them? What should we have spent less time doing?&nbsp;</span></li>
<ul>
<li><span>Using the </span><a href="https://www.forbes.com/sites/kevinkruse/2016/03/07/80-20-rule/?sh=15a5959d3814"><span>Pareto Principle</span></a><span>, the return on certain actions will significantly outweigh others.</span></li>
</ul>
<li><span>Did our actions reflect our values? Did we call out times that employees personified our values? Do we need to add or subtract values?</span></li>
<li><span>Which relationships are most important to our success (e.g. customers, investors, partners) and what can we be doing to provide them with more value?</span></li>
</ul>

<h5><strong>As a Manager</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Do we have the </span><a href="https://www.jimcollins.com/concepts/first-who-then-what.html"><span>right people on the bus</span></a><span>?</span></li>
<li><span>Are the right people owning the right things or are there better ways that we can be distributing the work?</span><br><span></span><span></span></li>
</ul>

<p><span>I keep a Trello board to manage this; <a data-cke-saved-href="https://trello.com/b/v6lu8Xpc" href="https://trello.com/b/v6lu8Xpc" target="_blank" rel="noopener">steal my template here</a>.</span></p>
<p><img src="https://cdn.buttercms.com/j9hSXZluRBG3S2HjajIu" alt="trello chart" width="683" height="158"></p>
<ul>
<li><span>How were my 1:1s? Did my reports walk away feeling that I had removed blockers, clarified vagueness, and given clear instructions?</span></li>
<li><span>Do my reports know their metrics for success?</span></li>
<li><span>How connected is the team overall?</span><strong></strong><span></span></li>
</ul>
<h5><strong>Meetings</strong><span>&nbsp;</span></h5>
<ul>
<li><span>Is every meeting on my calendar still relevant and useful?</span></li>
<li><span>Have I invited the right people to each one?</span></li>
<li><span>Are the major meetings for the upcoming year already scheduled? Mine are:</span>
<ul>
<li><span>Off-sites</span></li>
<li><span>Customers business reviews</span></li>
<li><span>Employee reviews</span></li>
<li><span>Team town halls</span></li>
<li><span>Quarterly kickoffs</span></li>
<li><span>Annual trainings</span></li>
</ul>
</li>
<li><span>Do I like the cadence and timing of my recurring meetings?</span>
<ul>
<li><span>Can I schedule any back-to-back to minimize distractions?</span></li>
<li><span>Are meetings optimized to my energy peaks?</span>
<ul>
<li><span>I‚Äôm fresh and driven in the mornings and do my best work then. Mentally challenging meetings are best during this window.</span></li>
<li><span>My mind is more relaxed and able to freely brainstorm in the afternoons; I shift most meetings to this time.</span>&nbsp;</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5><strong>Tools</strong></h5>
<ul>
<li><span><span>Are we using the right tools (software, banking, equipment, etc.) to accomplish our goals? Can we eliminate any?</span></span></li>
</ul>
<figure><img src="https://cdn.buttercms.com/exgcpuvKRdmBDDBzKUvF" alt="saas-list" width="772" height="101">
<figcaption>
<p><span>This number balloons quickly, so I keep a spreadsheet of all our tools to track which are still in use and who has access.</span></p>
</figcaption>
</figure>
<ul>
<li><span>Do the right people have access to each tool? Has admin access been given to the logical person?</span></li>
<li><span>Do we have the right tier of service for our size?</span></li>
<li><span>Are there more effective tools available that could reduce or combine the efforts of others?&nbsp;</span></li>
</ul>
<h5><strong>Finance</strong></h5>
<ul>
<li><span>Are our finances generally in order? This can include:</span></li>
<ul>
<li><span>Outstanding invoices</span></li>
<li><span>Unpaid bills</span></li>
<li><span>Sales commissions</span></li>
<li><span>Expense reconciliation</span></li>
<li><span>Credit card charges</span></li>
</ul>
<li><span>Are there areas that we could cut costs next year?</span></li>
<li><span>Is billing set to preferred person and method? (I like to see every charge come through and to optimize points based on spend.)</span></li>
</ul>

<h5><strong>Operations</strong></h5>
<ul>
<li><span>Where can we automate tasks?</span></li>
<li><span>Are the company files clean and organized? What about mine?</span></li>
<ul>
<li><span>If a company file no longer seems relevant, I dump it into an archive folder rather than delete anything.</span></li>
<li><span>I run an inbox-zero on my file downloads and desktop, forcing myself to put any important files somewhere safe in case something happens to my computer.</span></li>
</ul>
<li><span>Are our templated documents up to date?</span></li>
<ul>
<li><span>Check company address, point of contact, and legalese on contracts, mNDAs, etc.</span></li>
</ul>
<li><span>How are our processes? Which ones are sloppy, overly prescriptive, or begging to be eliminated entirely?</span></li>
</ul>

<h5><strong>Performance</strong></h5>
<ul>
<li><span>How did I perform against my job description?</span></li>
<ul>
<li><span>I keep my job description as a living document to capture what I take on and hand off over time. When I doubt where my time is being spent, I discuss this document with my boss and adjust accordingly.</span></li>
</ul>
<li><span>How were my 1:1s with my boss? Did I come to the meeting with thoughtful questions and specific to-dos?&nbsp;</span></li>
<li><span>Did I listen to and incorporate feedback effectively?</span></li>
<li><span>Did I step up when I needed to? Did I delegate my areas of weakness?</span></li>
</ul>
<h5><strong>Role</strong></h5>
<ul>
<li><span>How do I want my job description to change in the next year based on what the company needs and on my own strengths and weaknesses?</span></li>
<li><span>Which relationships within the company are most important to my efficacy? Can I do anything to improve upon those relationships?</span></li>
<li><span>Which tasks I should be taking on or offloading?</span></li>
</ul>
<h5><strong>Time</strong></h5>
<ul>
<li><span>Am I spending time on </span><a href="https://www.nfx.com/post/time-management-for-founders/"><span>the most valuable things</span></a><span> and letting the unimportant things fall through the cracks?</span></li>
<li><span>What have I been putting off?&nbsp;</span>
<ul>
<li><span>Can I eliminate it or delegate it?</span></li>
<li><span>Can I give it more clarity?</span></li>
</ul>
</li>
<ul>
<li><span>I tend to dread tasks that either feel pointless or excessively vague, so I ask:&nbsp;&nbsp;</span></li>
</ul>
<li><span>What can I stop doing altogether?</span></li>
</ul>
<h5><strong>Personal</strong></h5>
<ul>
<li><span>Do I like my personal systems for keeping track of to-dos?</span></li>
<li><span>Do I know what I bring to the table when I join a meeting?</span></li>
<li><span>Am I maintaining a network of people I can turn to for advice?</span></li>
<li><span>Am I making time outside of work for activities that keep me healthy and happy?</span></li>
</ul>
</div></div>]]>
            </description>
            <link>https://boringstartupstuff.com/newsletter/nov-24th-2020-finish-the-year-strong</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199785</guid>
            <pubDate>Tue, 24 Nov 2020 16:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ham Radio Needs to Embrace the Hacker Community Now More Than Ever]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25199686">thread link</a>) | @parsecs
<br/>
November 24, 2020 | https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/ | <a href="https://web.archive.org/web/*/https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane">
  <div>
    
    <h2 id="an-open-letter-to-all-ham-radio-operators">An Open Letter To All Ham Radio Operators</h2>
<p>‚ÄúHam Radio is dying!‚Äù A phrase all to often uttered that it‚Äôs become clich√©, but it‚Äôs partly true. You can‚Äôt deny a considerable section of the ham radio operators in the world are in the latter part of their lives.They won‚Äôt be around forever so naturally new people must assume their place. The good news is amateur radio licenses are on the rise. The bad news is the people induced to ham radio these days aren‚Äôt interested in pushing the limits of RF technology. To be blunt I‚Äôm talking about preppers and those solely interested in emergency communications. Neither of which have any desire to explore ham radio beyond a disaster fetish in which they use their $25 BaoFeng HT to save the world. So what can ham radio operators do? Easy, reach out to the hacker community! First, allow me define the word hacker since there are nefarious connotations of the word‚Äôs meaning. When I use the word hacker, I‚Äôm talking about the type of individual who wants to comprehend how a given technology works and who explores all the possibilities that technology has to offer. These are the people who grew up dismantling electronics just to appreciate how they work, the people who stayed up late into the night teaching themselves to code, and these are the people ham radio needs to propel it further into the future. To attract and retain hackers within the ham community there are a few things that we need to do.</p>
<h3 id="1-stop-primarly-promoting-emergency-communications">1. Stop Primarly Promoting Emergency Communications</h3>
<p>Every day I see on the <a href="https://www.reddit.com/r/amateurradio/">r/amateurradio</a> subreddit a number of people who solely promote ham radio‚Äôs role in emergency communications. Does it have a place within the hobby and community? Certainly, however, there is little interest from the hacker community in relaying messages about the state of the weather during a thunderstorm. Ham radio offers so much morel. You do it a disservice when you either dismiss the other areas of the hobby as secondary to emergency communications or fail to mention them at all. For crying out loud, we launch our own communications satellites and utilize them every day. Satellite communications, the blending of RF and VoIP to communicate around the world, software defined radio represent the things we need to promote to the hacker community. To effectively communicate, identify your audience.</p>
<h3 id="2-start-promoting-software-defined-radio">2. Start Promoting Software Defined Radio</h3>
<figure>
    <img src="https://www.kj7nzl.net/img/radios/hackrf-one-sdr-001.webp" alt="Will SDRs like the HackRF One be the future of ham radio?"> <figcaption>
            <p>Will SDRs like the HackRF One be the future of ham radio?</p>
        </figcaption>
</figure>

<p>There is a lot of interesting work that‚Äôs currently being done within the hacker community with RF. Most of this work is currently centered around WiFi, LoRa, IoT networks. It not difficult to imagine someone who has an interest in these communication technologies wouldn‚Äôt be open to software defined radio. They just need to be presented with easy to understand examples and a little encouragement to become licensed. Kelly Albrink‚Äôs 2020 DerpCon talk <em>Ham Hacks: Breaking into the World of Software Defined Radio</em> does just that.</p>

<p>
  <iframe src="https://www.youtube.com/embed/LIcE0frWtLo" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>Software Defined Radio is here and we as hams need to explore all the potential the technology has to offer. Currently full SDR transceivers are available from Flex Radio, and the major ham radio manufactures are beginning to produce hybrid SDR transceivers. With SDRs such as the BladeRF 2.0, LimeSDR and the HackRF One the entry point into software defined radio is relatively low. These lowcost SDRs make excellent platforms for experimentation within the VHF/UHF bands. The <a href="https://www.youtube.com/c/TechMindsOfficial">YouTube channel Tech Minds</a> has some excellent videos of what these little radios can do.</p>

<p>
  <iframe src="https://www.youtube.com/embed/qx_orXHiQk8" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="3-provide-communities-that-foster-technical-discussion-and-exploration">3. Provide Communities That Foster Technical Discussion and Exploration</h3>
<p>It‚Äôs been my experience that local radio club are more focused on emergency communications rather than the more technical aspects of ham radio (Seriously, why so much obsession with emergency communications?). Most of the anecdotal evidence I‚Äôve collected has suggested this is a common occurrence around the United States. This type of focus doesn‚Äôt foster an environment of learning and exploration. Why would the hacker community want to participate, in discussions about who‚Äôs going provide communications ‚Äúsupport‚Äù on the corner of Elm and Main St. during the annual Forth of July parade? You need to create the type of environment where the discussion is focused on RF technology. If you can‚Äôt do that locally in person or over the air, then it‚Äôs time to turn to the digital voice modes. That‚Äôs right, DStar, DMR, and System Fusion provide an opportunity to essentially create local communities of common interest. Access to these communities are as easy as connecting to one‚Äôs hotspot; I guess you could present the argument that some repeaters are connected to these digital networks and blah blah blah. Hotspots! That‚Äôs what the cool kids are doing these days. As an aside, <a href="https://www.kj7nzl.net/blog/building-my-own-lonestar-electronics-mmdvm-hotspot/">check out my new hotspot</a>.</p>
<h4 id="introducing-the-radio-hackers-ysf-reflector">Introducing the Radio Hackers YSF Reflector</h4>
<p>In my efforts to better understand the System Fusion and WiresX Network and how they relate to each other, I created a YSF Reflector called Radio Hackers. As you may have guessed this is the beginning stages of the hacker community, I‚Äôm fostering among ham radio operators. This is by nowhere complete and I welcome you to assist me in any way that you can. The most significant thing you can do is inform others and join in on the discussion on the reflector.</p>
<ul>
<li>ID: 33360</li>
<li>Name: Radio Hackers</li>
<li>Dashboard: <a href="http://hackers.ysf.kj7nzl.net/">http://hackers.ysf.kj7nzl.net</a></li>
<li>Bridged Networks: TBD</li>
</ul>
<p>If anyone knows more about bridging networks together with XLX please reach out to me. I‚Äôd love to speak with you more. My contact information is provided on the <a href="https://www.kj7nzl.net/">home page</a> of this site.</p>

  </div>
</section></div>]]>
            </description>
            <link>https://www.kj7nzl.net/blog/ham-radio-needs-to-embrace-the-hacker-community-now-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199686</guid>
            <pubDate>Tue, 24 Nov 2020 16:09:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aurora 7 Prototype ‚Äì 7 Screen Laptop]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 184 (<a href="https://news.ycombinator.com/item?id=25199499">thread link</a>) | @882542F3884314B
<br/>
November 24, 2020 | https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/ | <a href="https://web.archive.org/web/*/https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="Actual_Page_Container">

<!-- REVOLUTION SLIDER -->

<!-- /REVOLUTION SLIDER --><!-- -->

<section>
<div>





<h2>Prototype Objective Summary:</h2>

<p>Very simple :) - Design and build a proper mobile Security Operations Center.</p>

<p>I always knew this would be an ambitious undertaking. Power considerations, structural rigidity, actual portability and the ability to be easily and quickly compactible were priorities. For a further break down of the objectives please read on.</p>



<h2>Prototype Objective Breakdown and Achievement percentage:</h2>

<p>This is a breakdown of the objectives. It also shows how much of the objective in percentage was achieved with the Aurora 7 Prototype.</p>

<div>


<div><p><label><span>100%</span> 6 Cores or more at 5GHZ capability </label></p>
</div>

<div><p><label><span>100%</span> Fully integrated Multi Touch Screen in Palm rest </label></p>
</div>

<div><p><label><span>100%</span> 4 x 17.3 UHD/4K Screens </label></p>
</div>

<div><p><label><span>70%</span> Ability to easily replace parts </label></p>
</div>

<div><p><label><span>70%</span> Ability to swap wiring and parts with easily attainable parts </label></p>
</div>

<div><p><label><span>90%</span> Rechargeable battery system fully self contained </label></p>
</div>

<div><p><label><span>70%</span> Easily Replaceable batteries </label></p>
</div>



<div><p><label><span>100%</span> NVIDIA GTX 10 Series Graphics </label></p>
</div>

<div><p><label><span>100%</span> Separate Programmable System Monitor LCD </label></p>
</div>

<div><p><label><span>100%</span> User/Arduino accessible Embedded Microcontroller. </label></p>
</div>





<div><p><label><span>100%</span> Ability to fold down compactly to facilitate travel </label></p>
</div>

<div><p><label><span>100%</span> Full NO-NONSENSE 104 Key tactile backlit Keyboard. </label></p>
</div>

<div><p><label><span>80%</span> Overall Structural Rigidity </label></p>
</div>



<div><p><label><span>100%</span> Everything folds or swivels out of the primary chassis (NO appendages) </label></p>
</div>



<div><p><label><span>100%</span> Out of band always visible battery gauge </label></p>
</div>



<div><p><label><span>100%</span> More than 16TB SSD Storage potential </label></p>
</div>
</div>

</div>
</section>

</div></div>]]>
            </description>
            <link>https://expanscape.com/the-aurora-7-prototype/the-story-of-the-aurora-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199499</guid>
            <pubDate>Tue, 24 Nov 2020 15:50:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Don't Work With Startups (Or FAANGs)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25199374">thread link</a>) | @elliotbnvl
<br/>
November 24, 2020 | https://devcareer.elliotbonneville.com/no-startups-or-faangs | <a href="https://web.archive.org/web/*/https://devcareer.elliotbonneville.com/no-startups-or-faangs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-no-startups-or-faangs"><p><span><span>This chapter is not a hard and fast set of rules you should always abide by, but is some reasoning and facts that I‚Äôve found to be true about picking a company to work for, while optimizing for a high rate, freedom, and flexibility.</span></span></p><p><span><span>The tl;dr version is that you shouldn‚Äôt work with startups, because they are high pressure and don‚Äôt pay well, and you shouldn‚Äôt work with household names (Facebook, Amazon, Google, Netflix, and their ilk) because they don‚Äôt provide as much flexibility.</span></span></p><p><span><span>Instead, you should target a sweet spot right in the middle, working with companies who have enough money to pay you well, but aren‚Äôt large enough and well-run enough that they can afford to be extremely exclusive and demanding of their employees.</span></span></p><p><span><span>As a side effect of their size, these companies often have pressing technical issues that are growing pains which haven‚Äôt been resolved yet that you can be of real value in solving. Working with them leads to doing high-value, satisfying work that pays well and affords you freedoms you wouldn‚Äôt otherwise find.</span></span></p><p><span><span>We‚Äôll clear up some common misunderstandings and establish our reasoning by tackling this topic from first principles, as per usual.
</span></span></p><p><span><span><em>This post is an early release chapter of </em></span><span><em><a href="https://devcareer.elliotbonneville.com/">a book I'm writing in public</a></em></span><span><em>, working title of </em></span><span>Refactor Your Career</span><span><em>. If you're interested in following along for more prerelease chapters and other info, you can sign up for the newsletter below:</em></span></span></p><h2 id="block-b97dcd7b406e467b87a25fbcb87546ba"><span id="b97dcd7b406e467b87a25fbcb87546ba"></span><span><span>Don‚Äôt work with startups</span></span></h2><p><span><span>The definition of a startup is ‚Äúa company prioritizing fast growth over everything else.‚Äù</span></span></p><p><span><span>Given the current economic incentive structure of the venture capital model, startups often take outside investment to grow more quickly.</span></span></p><p><span><span>As a result, startups typically optimize to get as much done with as little money and in as little time as possible, because they are not cash-flow positive and have limited financial runway.</span></span></p><p><span><span>Therefore, they are incentivized to find extremely high return-on-investment employees who will work long hours for little money. To find these employees, they will use a number of strategies:</span></span></p><ul><li id="block-53700a214aaf4831be4625f6876e0ed7"><span><span>Offer equity instead of cash compensation</span></span></li><li id="block-2b21919a7bb64e3e962a21fd7d352e42"><span><span>Offer ‚Äúfun‚Äù benefits (beer, ping pong table, catered lunches, free movie tickets, etc.)</span></span></li><li id="block-bb36db0b8db44966b9505bbb5ec4ea1a"><span><span>Target young, talented, and hardworking engineers who are new to the industry and don‚Äôt have connections</span></span></li></ul><p><span><span>An extremely high return-on-investment employee is always getting the short end of the stick. The money has to come from somewhere, and in this case the money is coming from the employees‚Äô pockets.</span></span></p><p><span><span>As an aside, your employer wins when they get the most bang for their buck, but the more bang they get for their buck, the less bang you get in return for the most valuable resource you possess -- your time.</span></span></p><p><span><span>At its core, hourly billing is a profoundly adversarial relationship, and you need to understand the rules by which it operates in order to not be taken advantage of. If you don‚Äôt know the rules of the game, you will lose. If you know the rules of the game and don‚Äôt play to them, you will lose. If you want to win, you must play intelligently, intentionally, and aggressively.</span></span></p><p><span><span>Hourly billing is just the beginning. As you grow in skill and ‚Äúcareer capital‚Äù (c.f. </span><span><a href="https://www.amazon.com/Good-They-Cant-Ignore-You-ebook/dp/B0076DDBJ6" target="_blank" rel="noopener noreferrer"><em>So Good They Can‚Äôt Ignore You</em></a></span><span>, Cal Newport), you‚Äôll want to explore ways to move away from hourly billing to a better way of billing, i.e. separating time worked from results delivered. Big benefits to you and your clients all the way around. Jonathan Stark writes eloquently on the issues with hourly billing </span><span><a href="https://jonathanstark.com/the-moral-dilemma-of-hourly-billing" target="_blank" rel="noopener noreferrer">here</a></span><span>.</span></span></p><p><span><span>Let‚Äôs take a deeper look at the strategies startups use to find employees, and why that means working for one is usually a bad strategy.</span></span></p><h3 id="block-5b675128f52f4bc7ae0ffadf51c842d9"><span id="5b675128f52f4bc7ae0ffadf51c842d9"></span><span><span>Taking equity is becoming a micro venture capitalist</span></span></h3><p><span><span>Venture capitalism is a bet on the future. Even the best venture capitalists lose money on most of their investments. They only turn a profit because they invest at scale and need just a couple of big wins per batch of investments in order to make up for that extremely high percentage of losses. They also study investing all day, every day, and are surrounded by people all doing the exact same thing.</span></span></p><p><span><span>Second, time is fungible. If you want, you can trade time for money directly (that‚Äôs what hourly billing is, after all). Therefore, an investment of time is an investment of your personal funds.</span></span></p><p><span><span>As a result, if you take equity compensation instead of cash when working at a startup, you are investing your money directly into that startup.</span></span></p><p><span><span>Given all of the above and bearing in mind that venture capitalism is a high risk bet that only works at scale for people who exclusively study how to invest, the odds that you are going to make a return on your investment with the limited amount of resources that you have to invest is vanishingly low.</span></span></p><p><span><span>Don‚Äôt try to play venture capitalist with the most valuable thing you have -- your time.</span></span></p><p><span><span><a href="https://www.jwz.org/about.html" target="_blank" rel="noopener noreferrer">Jamie Zawinski</a></span><span> (OG programmer, one of the founders of Netscape and Mozilla.org, the guy who probably wrote your screensaver, and now a dance club proprietor [yes, really]) has this to say about working for startups:</span></span></p><blockquote id="block-bf5cc1f488d24661902d79343aefc830"><span><span>Follow the... money. When a VC tells you what's good for you, check your wallet, then count your fingers.

He's telling you the story of, "If you bust your ass and don't sleep, you'll get rich" because the only way that people in his line of work get richer is if young, poorly-socialized, naive geniuses believe that story! Without those coat-tails to ride, VCs might have to work for a living. Once that kid burns out, they'll just slot a new one in.</span></span></blockquote><p><span><span>You can read the full post from 2011 </span><span><a href="https://www.jwz.org/blog/2011/11/watch-a-vc-use-my-name-to-sell-a-con/" target="_blank" rel="noopener noreferrer">here</a></span><span> and I highly encourage you to do so. It‚Äôs a zinger.</span></span></p><h3 id="block-ffa7baffd6a6461a9f9db8658d9237c6"><span id="ffa7baffd6a6461a9f9db8658d9237c6"></span><span><span>Empirically, equity is not as valuable as it seems</span></span></h3><p><span><span>Backing up the logic above, loose empirical analysis shows that if you look at total startup compensation as income combined with equity </span><span><em>adjusted for likelihood of realizing that equity‚Äôs value</em></span><span>, statistically you end up making less money in the end.</span></span></p><p><span><span>Patrick McKenzie, a well-known entrepreneur and prolific writer, and currently working at Stripe to ‚Äúincrease the GDP of the internet,‚Äù has this to say on the topic of valuing equity grants:</span></span></p><blockquote id="block-f861c0e363034719a6aa4cf4032f0005"><span><span>Roll d100. (Not the right kind of geek? Sorry. rand(100) then.)

0~70: Your equity grant is worth nothing.

71~94: Your equity grant is worth a lump sum of money which makes you about as much money as you gave up working for the startup, instead of working for a megacorp at a higher salary with better benefits.

95~99: Your equity grant is a lifechanging amount of money. You won‚Äôt feel rich ‚Äî you‚Äôre not the richest person you know, because many of the people you spent the last several years with are now richer than you by definition ‚Äî but your family will never again give you grief for not having gone into $FAVORED_FIELD like a proper $YOUR_INGROUP.

100: You worked at the next Google, and are rich beyond the dreams of avarice. Congratulations.

Perceptive readers will note that 100 does not actually show up on a d100 or rand(100).</span></span></blockquote><p><span><span>Dan Luu, another well-known developer and blogger, has this to say on the subject:</span></span></p><blockquote id="block-841b5199ddf14a02af23c89b2adf0131"><span><span>For a more serious take that gives approximately the same results, 80000 hours finds that the average value of a YC founder after 5-9 years is $18M. That sounds great! But there are a few things to keep in mind here. First, YC companies are unusually successful compared to the average startup. Second, in their analysis, 80000 hours notes that 80% of the money belongs to 0.5% of companies. Another 22% are worth enough that founder equity beats working for a big company, but that leaves 77.5% where that's not true.

If you're an employee and not a founder, the numbers look a lot worse. If you're a very early employee you'd be quite lucky to get 1/10th as much equity as a founder. If we guess that 30% of YC startups fail before hiring their first employee, that puts the mean equity offering at $1.8M / .7 = $2.6M. That's low enough that for 5-9 years of work, you really need to be in the 0.5% for the payoff to be substantially better than working at a big company unless the startup is paying a very generous salary.</span></span></blockquote><p><span><span>You can read the rest of Patrick‚Äôs post </span><span><a href="https://www.kalzumeus.com/2011/10/28/dont-call-yourself-a-programmer/" target="_blank" rel="noopener noreferrer">here</a></span><span>, and the rest of Dan‚Äôs post </span><span><a href="https://danluu.com/startup-tradeoffs/" target="_blank" rel="noopener noreferrer">here</a></span><span>. I highly recommend that you do so; they are erudite writers with a lot of insight into the industry.</span></span></p><h3 id="block-886c6f74b682471f90e8c002e01f09c9"><span id="886c6f74b682471f90e8c002e01f09c9"></span><span><span>Startup benefits are the cheese in the mousetrap</span></span></h3><p><span><span>While it might seem rather cynical, the benefits at a startup are just the cheese in the mousetrap. If you calculate the actual cash value of the benefits that many startups offer, you‚Äôll find that they‚Äôre laughably low. Free beer, access to the company ping pong table (that never gets used), free movie tickets and a two hundred dollar per month business learning stipend actually work out to a relatively low amount of cold, </span><span><del>hard</del></span><span> mildly wrinkled Franklins.</span></span></p><p><span><span>Even things that are seemingly inherent to the unpurchasable, intangible benefits of startup culture like an open desk plan, brilliant and intense coworkers, and technically cutting-edge work can all be had elsewhere for a fraction of the time-cost of working at a startup if you‚Äôre willing to think outside the box.</span></span></p><p><span><span>Given that remaining within this particular box is so expensive, I highly encourage you not to do so without full understanding of what you‚Äôre doing.</span></span></p><p><span><span>If you can make $80/hr at a startup and $130/hr at a regular company, you are paying the startup $50/hr for the privilege of working there. For $50/hr, you can figure out a way to get most of the same benefits and come out way, way ahead.</span></span></p><p><span><span>Do what makes you happy, but do it with your eyes open. Also, if you really want to work at a startup, you might be better served by starting one.</span></span></p><h2 id="block-aebdc986fc9a4a39917e802441860771"><span id="aebdc986fc9a4a39917e802441860771"></span><span><span>Don‚Äôt work with household names</span></span></h2><p><span><span>There‚Äôs a word that gets tossed around a lot in the communities where developers that talk about their careers hang out (Hacker News, Reddit, et. al.) -- FAANG. It‚Äôs an acronym that refers to Facebook, Apple, Amazon, Netflix, and Google.</span></span></p><p><span><span>People talk about these companies (which pretty much are all out in Silicon Valley or in Seattle) so much that an acronym evolved as a catchall to refer to them. When I say ‚Äúhousehold name,‚Äù these are the companies ‚Ä¶</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://devcareer.elliotbonneville.com/no-startups-or-faangs">https://devcareer.elliotbonneville.com/no-startups-or-faangs</a></em></p>]]>
            </description>
            <link>https://devcareer.elliotbonneville.com/no-startups-or-faangs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199374</guid>
            <pubDate>Tue, 24 Nov 2020 15:35:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Disc as Dongle]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25199286">thread link</a>) | @mortenjorck
<br/>
November 24, 2020 | https://interuserface.net/2020/11/the-disc-as-dongle/ | <a href="https://web.archive.org/web/*/https://interuserface.net/2020/11/the-disc-as-dongle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
          <!-- <style>
        body.single {
          background-color: #;
        }
      </style> -->
      <h3>November 23, 2020</h3>
      
      <p>One possible future of digital distribution is already here ‚Äì in the guise of an existing format.</p>
      
<p><span>The industrial design</span> of the just-released Playstation 5 may be <a href="http://interuserface.net/2020/06/the-regressive-design-of-the-playstation-5/" data-type="post" data-id="633">regressive</a>, but it looks to the future in one critical way: Judging by the ungainly grafting-on of its disc drive, its original conception as a digital-only console is unmistakable.</p>



<p>For many, digital-only is a conflicting proposition. It curtails long-established freedoms of lending and resale, yet most would agree that it is also inevitably the future. But it doesn‚Äôt have to be the former. There is a solution ‚Äì and it already exists.</p>



<p>The physical discs included with the retail versions of console games have served an increasingly marginal utility over the past console generation. Ever-larger day-one patches weigh in in the gigabytes. Triple-A games already require tens of gigabytes of data to be copied from the disc to the hard drive in order to manage load times, and the Playstation 5‚Äôs reliance on a super-fast SSD architecture only formalizes this. </p>



<hr>



<p><span>This leaves the disc</span> with precious little to actually do ‚Äì it‚Äôs too slow to be played from, its data is often outdated by the time it‚Äôs installed, and as broadband speeds continue to inch upward, the read speed of even a modern Blu-ray drive is already slower than some fiber connections. Yet despite all this, the lowly disc still has one ace in the hole.</p>



<p>Even stripped of its value as a storage mechanism for game data, the disc serves a critical purpose: It is the physical manifestation of a license, an unencumbered and freely transferable token with which ownership of a game is immutably entangled. Future games could well ship with an essentially empty disc, relying on the network for everything else, yet the advantage of the disc-anchored license would remain undisputed. The disc allows one to, as memorably demonstrated in Sony‚Äôs 2013 response to Microsoft‚Äôs aborted digital-only Xbox play, simply <a href="https://www.polygon.com/2013/6/10/4417490/playstations-one-step-tutorial-on-sharing-used-games">hand that license to someone else.</a></p>



<hr>



<p><span>All this then invites the question:</span> Why does it have to be a <em>disc?</em> Why does a console need a noisy, mechanically complex, and expensive optical drive just to read a license? Professional software has long used USB peripherals, or dongles as they are semi-affectionately known, as the physical manifestation of licenses. The disc has become a dongle, so why not just use a dongle?</p>



<p>A few kilobytes and an encryption scheme are all that‚Äôs required to tie licenses to a physical device today. A tiny, inexpensive USB device could serve as the retail form factor for future games, ushering in an all-download future that retains nearly all the benefits of physical legacy formats. It could perhaps even, via firmware update, add ‚Äúphysical media‚Äù support to both the digital-only Playstation 5 and Xbox Series S.</p>
      <!-- <p class="metadata">
        Clayton Miller&ensp;&bull;&ensp;      </p> -->
      </article></div>]]>
            </description>
            <link>https://interuserface.net/2020/11/the-disc-as-dongle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25199286</guid>
            <pubDate>Tue, 24 Nov 2020 15:27:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Homemade recycling rig turns plastic waste into new products]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198780">thread link</a>) | @lysp
<br/>
November 24, 2020 | https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/ | <a href="https://web.archive.org/web/*/https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-26604">
<h3>Homemade recycling rig turns plastic waste into new products</h3>
<p> ‚Äî <span>November 24th, 2020</span>
</p>
<div>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-300x225.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-385x289.jpg 385w, https://blog.arduino.cc/wp-content/uploads/2020/11/F3ZCZAFKHJ4PNG6-768x576.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>While that plastic cup, bag, dish, or other item may have served its purpose, more than likely it could be formed into something new. With this in mind, the SOTOP-Recycling team of Manuel Maeder, Benjamin Krause, and Nadina Maeder developed <a href="https://www.instructables.com/Automated-Injection-Molding-Machine-for-Plastic-Re/">an automated injection molding machine</a> that can be built at home and is small enough to allow you to run your own recycling operation!</p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder.png 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-300x218.png 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/Plastic-Shredder-768x558.png 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>The ‚ÄúSmart Injector‚Äù receives shredded pieces of plastic in a small hopper, then transports them down an extrusion pipe where heat is applied. This material is clamped together via a pair of stepper motors, with screws and timing belts implemented to apply sufficient pressure. Everything is controlled by an <a href="https://store.arduino.cc/mega-2560-r3">Arduino Mega</a>. </p>
<figure><p><img src="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg" alt="" srcset="https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD.jpg 1024w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-300x200.jpg 300w, https://blog.arduino.cc/wp-content/uploads/2020/11/FEFM6F6KHKK52GD-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"></p></figure>
<p>As shown in the video, the plastic waste is converted into phone covers in just minutes, though other things could also be made depending on the form tooling used.</p>
<figure><p>
<iframe title="Injection molding machine for recycling plastic" width="500" height="281" src="https://www.youtube.com/embed/Eq9IbetsLB4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<section>


<p>
<small>

You can follow any responses to this entry through the <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/feed/">RSS 2.0</a> feed.
You can <a href="#respond">leave a response</a>, or <a href="https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/trackback/" rel="trackback">trackback</a> from your own site.
</small>
</p>
</section>
</div>
</div></div>]]>
            </description>
            <link>https://blog.arduino.cc/2020/11/24/homemade-recycling-rig-turns-plastic-waste-into-new-products/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198780</guid>
            <pubDate>Tue, 24 Nov 2020 14:39:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making 8500 plants available to you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25198771">thread link</a>) | @roboben
<br/>
November 24, 2020 | https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html | <a href="https://web.archive.org/web/*/https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://permapeople.org/blog/assets/making-8500-plants-available-on-permapeople.jpg" alt="8500 plants available on Permapeople"></p>

<p><strong>tl;dr We made ~8500 plants available to you by importing the Plant For a Future dataset. You can use it now to create lists, guilds and help improving that data.</strong></p>

<p>The first thing I did when I started Permapeople was to look at other plant databases and platforms with a similar focus. If you ever were in the situation to try to get some information about specific plants, especially attributes which are important for a Permaculture style of gardening, there is a high chance you found <a href="https://pfaf.org/">Plants for a Future</a> (PFAF). It is a database started by Addy and Ken Fern, later turned into a not for profit organization operated by a handful of trustees. In recent years, they refocused their work on plants‚Äô role in fighting climate change through carbon sequestration. If you don‚Äôt know them, you should definitely check them out.</p>

<p>I put a lot of consideration into importing the PFAF database into Permapeople, but decided against it in the beginning. The more I talked to people and our first users, I figured that using existing datasets saves contributors a lot of time and provides an immediate value. Most people I talked to are beginners or people running larger gardening operations, and I wanted to create something that could help them immediately in their projects. I think the PFAF database is one of the best resources available, but I found some problems with it, limiting its usefulness.</p>

<h2 id="data-quality">Data Quality</h2>

<p>While the PFAF dataset is probably the biggest by numbers and completeness, it has a few problems: Many things are outdated, incorrect, ambiguous, or incoherent. Some might think that plant data and its field, <em><a href="https://en.wikipedia.org/wiki/Botany">botany</a></em> is a static field. Actually, it is really the opposite: New discoveries, nomenclature changes, and fresh scientific research comes in weekly. Keeping track of this with a tiny circle of paid workers is a tough job to do. Even if you could contribute a fix, there is no way of doing that. Crowdsourcing this problem by letting anyone change the data could be very helpful. This is one of the main reasons I started Permapeople: I wanted to have one place to find up-to-date, correct, peer-reviewed information on the plants I want to grow. If I miss some info or find something incorrect, I can easily edit it and help everyone who needs this information after me. Think Wikipedia, but specifically for plants.</p>

<h2 id="no-clear-roadmap">No clear roadmap</h2>

<p>What makes working with PFAF data more challenging is that there is no information on if and when data gets corrected, updated, or added to PFAF. We do not know if and when new features will be added and if the organization will shift its focus to other projects in the future.</p>

<h2 id="unstructured-data">Unstructured Data</h2>

<p>While this is related to the data quality, the PFAF data is not structured and rather a full-text description of the plant. This makes it hard to find or sort through specific info because many attributes are not filterable and searchable. For example, while PFAF has great information on <em>companion planting</em>, it‚Äôs impossible to search based on these connections. You are left with searching through many plant profiles, reading long paragraphs, and scanning for the required information.</p>

<h2 id="missing-features">Missing features</h2>

<p>Having a database is great, but information seekers and contributors need some functionality to work with it. PFAF doesn‚Äôt provide any of that, and this is why we already added some of these missing features to Permapeople.</p>

<h3 id="see-the-editing-history-and-sources">See the editing history and sources</h3>

<p>A huge factor of why Wikipedia is so trustworthy is that every change is public and can be easily reviewed by anyone. This lets a user easily gauge any meta-information about a plant: Is this info credible or just a myth created by the hive-mind of the internet? Do many people agree with that info? Are there sources proving the correctness of the information? If yes, how many? Or how are people working within a similar climate to you faring with that plant?</p>

<h3 id="create-plant-connections-and-guilds">Create plant connections and guilds</h3>

<p>Companion planting and the more advanced <a href="http://www.neverendingfood.org/b-what-is-permaculture/permaculture-guilds/">concept of guilds</a> are a huge part of the success of Permaculture. At Permapeople, you can create explicit plant connections (may they be beneficial or adversary) and organize plants into guilds. This info can be fed back to the database and give users even better information: If two plants are used in many user-generated guilds, there is a high chance that these plants go well together.</p>

<p>Much of this functionality is in a very early stage, and we need your help and feedback to improve these features and the data itself. I hope this post helped you understand why I imported the PFAF dataset into Permapeople and how we plan to improve on the hard work PFAF and its contributors have already accomplished. In the best case, we can contribute our changes back to PFAF.</p>

<p>If you are interested, I suggest you try to <a href="https://permapeople.org/search">search for some plants</a> and <a href="https://permapeople.org/users/sign_up">sign up</a> to create your first list or guild.</p>

<p>Happy growing üå±‚úåÔ∏è,</p>

<p>Ben</p>

<p>PS: If you work for PFAF (or know someone who does), please reach out to us at hello at permapeople org - we‚Äôd love to talk about the future!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://permapeople.org/blog/2020/11/23/making-8500-plants-available.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198771</guid>
            <pubDate>Tue, 24 Nov 2020 14:38:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25198597">thread link</a>) | @mooreds
<br/>
November 24, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I‚Äôve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you‚Äôll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn‚Äôt mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don‚Äôt need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone‚Äôs lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you‚Äôve ever had a great comment explain a confusing bit of code, you‚Äôll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn‚Äôt apply, remove it. If there‚Äôs cut and paste documentation which doesn‚Äôt apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn‚Äôt tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as ‚Äúcan I instantiate this object‚Äù or ‚Äúhow does this function react when I pass it two null values‚Äù, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don‚Äôt get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It‚Äôs easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I‚Äôll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don‚Äôt refactor what you don‚Äôt understand. Don‚Äôt drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don‚Äôt do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It‚Äôs sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn‚Äôt spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn‚Äôt benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don‚Äôt do so, eventually dependencies will end of life and you‚Äôll be forced to update. That‚Äôll be even less pleasant. </p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn‚Äôt everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198597</guid>
            <pubDate>Tue, 24 Nov 2020 14:16:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digitizing Old 8mm Tapes]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198435">thread link</a>) | @todsacerdoti
<br/>
November 24, 2020 | https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ | <a href="https://web.archive.org/web/*/https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-660">
	<!-- .entry-header -->

	<div>
		
		<p>It‚Äôs astounding to think back and consider how much technological progress has occurred in just the past 15 years. Most folks today carry a smartphone in their pocket everywhere they go, and a great many of those smartphones have powerful cameras built in capable of recording multiple hours in high definition. Pair this ability with low-cost video editing software‚Äî<a href="https://www.blackmagicdesign.com/products/davinciresolve/" rel="noopener noreferrer" target="_blank">some of which comes at no cost at all</a>‚Äîand far more people today have the tools to practice shooting, editing, compositing, and rendering professional-looking videos on a modest budget.</p>
<p>My personal experience with photography began around age 7 shooting on <a href="https://en.wikipedia.org/wiki/110_film" rel="noopener noreferrer" target="_blank">110 film</a> using a small ‚Äúspy‚Äù camera I got as a gift. My dad‚Äôs <a href="https://www.sony.com/electronics/support/product/ccd-v5" rel="noopener noreferrer" target="_blank">Sony CCD-V5</a> was bulky, heavy, and probably expensive when he bought it around 1987, so he was reluctant to let me or my sister operate it under his supervision, let alone borrow it to make our own films by ourselves. As a consequence, my sister and I kept ourselves entertained by making audio recordings on much cheaper audio cassette hardware and tapes‚Äîwe produced an episodic ‚Äúradio show‚Äù starring our stuffed animals long before the podcast was invented. Though my sister and I took good care of our audio equipment, Dad stuck to his guns when it came to who got to use the camcorder, but he would sometimes indulge us when we had a full production planned, scripted, and rehearsed. <a href="https://en.wikipedia.org/wiki/8_mm_video_format#Video8" rel="noopener noreferrer" target="_blank">Video8</a> tapes were expensive, too, and for the most part Dad reserved their use for important events like concerts, school graduations, birthdays, and family holidays.</p>
<figure id="attachment_706" aria-describedby="caption-attachment-706"><img data-attachment-id="706" data-permalink="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/ccd-v5/" data-orig-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" data-orig-size="528,390" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ccd-v5" data-image-description="" data-medium-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=300%2C222&amp;ssl=1" data-large-file="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?fit=528%2C390&amp;ssl=1" loading="lazy" src="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=528%2C390&amp;ssl=1" alt="Sony CCD-V5 camcorder" width="528" height="390" srcset="https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?w=528&amp;ssl=1 528w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=300%2C222&amp;ssl=1 300w, https://i2.wp.com/blitter.net/assets/uploads/2020/10/ccd-v5.png?resize=210%2C155&amp;ssl=1 210w" sizes="(max-width: 528px) 100vw, 528px" data-recalc-dims="1"><figcaption id="caption-attachment-706">I remember it being a lot bigger.</figcaption></figure>
<p>I went off to college and spent a <em>lot</em> of time lurking the <a href="https://originaltrilogy.com/" rel="noopener noreferrer" target="_blank">originaltrilogy.com forums</a>. It was here that not only did I learn a lot about the making and technical background of the Star Wars films (a topic I could blog about ad nauseum), but I also picked up a lot about video editing, codecs, post-production techniques, and preservation. OT.com was and still is home to a community of video hobbyists and professionals, most of whom share a common love for the <a href="https://starwarsviscomp.wordpress.com/" rel="noopener noreferrer" target="_blank">unreleased ‚Äúoriginal unaltered‚Äù versions</a> of the Star Wars trilogy. As such, many tips were/are shared as to how to produce the best ‚Äúfan preservations‚Äù of Star Wars and other classic films given the materials available, sacrificing the least amount of quality.</p>
<p>I bought my dad a <a href="https://www.sony.com/electronics/support/product/hdr-cx100" rel="noopener noreferrer" target="_blank">Sony HDR-CX100</a> camcorder some years ago to supplement his by that time affinity for digital still cameras‚Äîhe took it to Vienna and Salzburg soon after and has since transitioned to shooting digital video mostly on his iPhone. But the 8mm tapes chronicling my family‚Äôs milestones over the first 25 years of my life continued to sit, undisturbed, in my folks‚Äô cool, dry basement. My dad has recordings on them going as far back as 1988 that I‚Äôve found so far. These recordings are over 30 years old, so the tapes must be at least that age. </p>
<p>8mm video tape <a href="https://fstoppers.com/diy/unlocking-memories-8mm-tapes-324466" rel="noopener noreferrer" target="_blank">does not last forever</a>, but making analog copies of video tape incurs generational loss each time a copy is dubbed. On the other hand, a digital file can be copied as many times as one wants without any quality loss. All I need is the right capture hardware, appropriate capture software, enough digital storage, and a way to play back the source tapes, and I can preserve one lossless digital capture of each tape indefinitely. The last 8mm camcorder my dad bought‚Äîa <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a>‚Äîstill has clean, working heads and can route playback of our existing library of tapes through its S-video and stereo RCA outputs. This provides me with the best possible quality given how they were originally shot.</p>
<hr>
<p>Generally with modern analog-to-digital preservation, you want to losslessly capture the raw source at a reasonably high sample rate with as little processing done to the source material as possible, from the moment it hits the playback heads to the instant it‚Äôs written to disk. Any cleanup can be done in post-production software; in fact, as digital restoration technology improves, it is ideal to have a raw, lossless original available to revisit with improved techniques. For this project, I am using my dad‚Äôs aforementioned <a href="https://www.sony.com/electronics/support/product/ccd-tr917" rel="noopener noreferrer" target="_blank">Sony CCD-TR917</a> camcorder attached directly to the S-video and stereo audio inputs of a <a href="https://web.archive.org/web/20150128124027/https://www.blackmagicdesign.com/products/intensity/models" rel="noopener noreferrer" target="_blank">Blackmagic Intensity Pro</a> PCIe card. The capturing PC is running Debian Linux and is plugged into the same circuit as the camcorder to avoid possible ground loop noise.</p>
<p>Since my Debian box is headless, I‚Äôm not interested in bringing up a full X installation just to grab some videos. Therefore I use the open source, command-line based <a href="https://github.com/lu-zero/bmdtools" rel="noopener noreferrer" target="_blank">bmdtools</a> suite‚Äîspecifically bmdcapture‚Äîto do the raw captures from my Intensity Pro card. I do have to pull down the <a href="https://www.blackmagicdesign.com/developer/product/capture-and-playback" rel="noopener noreferrer" target="_blank">DeckLink SDK</a> in order to build bmdcapture, which does have some minor X-related dependencies, but I have to pull down the DeckLink software anyway for Linux drivers. I invoke the following from a shell before starting playback on the camcorder:</p>
<p><code>$ ./bmdcapture -C 0 -m 0 -M 4 -A 1 -V 6 -d 0 -n 230000 -f &lt;output&gt;.nut</code></p>
<p>The options passed to bmdcapture configure the capture as follows:</p>
<ul>
<li><code>-C 0</code>: Use the one Intensity Pro card I have installed (ID 0)</li>
<li><code>-m 0</code>: Capture using mode 0; that is, 525i59.94 NTSC, or 720√ó486 pixels at 29.97 FPS</li>
<li><code>-M 4</code>: Set a queue size of up to 4GB. Without this, bmdcapture can run out of memory before the entire tape is captured to disk.</li>
<li><code>-A 1</code>: Use the ‚ÄúAnalog (RCA or XLR)‚Äù audio input. In my case, stereo RCA.</li>
<li><code>-V 6</code>: Use the ‚ÄúS-Video‚Äù video input. The S-video input on the Intensity Pro is provided as <a href="https://web.archive.org/web/20150122212738im_/https://images.blackmagicdesign.com/media/products/intensity/models/connections-intensitypro.png" rel="noopener noreferrer" target="_blank">an RCA pair</a> for chroma (‚ÄúB-Y In‚Äù) and luma/sync (‚ÄúY In‚Äù); <a href="https://www.amazon.com/dp/B07K768YD1/" rel="noopener noreferrer" target="_blank">an adapter cable</a> is necessary to convert to the standard miniDIN-4 connector.</li>
<li><code>-d 0</code>: Fill in dropped frames with a black frame. The Sony CCD-TR917 has a built-in <a href="https://en.wikipedia.org/wiki/Time_base_correction" rel="noopener noreferrer" target="_blank">TBC</a> (which I leave enabled since I don‚Äôt own a separate TBC), but owing to the age of the tapes, there is an occasional frame drop.</li>
<li><code>-n 230000</code>: Capture 230000 frames. At 29.97 FPS, that‚Äôs almost 7675 seconds, which is a little over two hours. Should be enough even for full tapes.</li>
<li><code>-f &lt;output&gt;.nut</code>: Write to <code>&lt;output&gt;.nut</code> in the <a href="https://wiki.multimedia.cx/index.php/NUT" rel="noopener noreferrer" target="_blank">NUT container format</a> by default, substituting the tape‚Äôs label for <code>&lt;output&gt;</code>. The <a href="https://github.com/lu-zero/bmdtools/blob/master/README.md" rel="noopener noreferrer" target="_blank">README.md provided with bmdtools</a> suggests sticking with the default, and since FFmpeg has no trouble converting from NUT and I‚Äôve had no trouble capturing to that format, I leave the output file format alone.</li>
</ul>
<p>Once I have my lossless capture, I compress the .nut file using bzip2, getting the file size down to up to a quarter of the original size depending on how much of the tape is filled. I then create parity data on the .bz2 archive <a href="https://en.wikipedia.org/wiki/Parchive" rel="noopener noreferrer" target="_blank">using the par2 utility</a>, and put my compressed capture and parity files somewhere safe for long-term archival storage. üôÇ</p>
<p>My Windows-based Intel NUC is where I do most of my video post-production work. It lacks a PCIe slot, so I can‚Äôt capture there, but that‚Äôs fine because at this point my workflow is purely digital and I only have to worry about moving files around. My tools of choice here are AviSynth 2.6 and VirtualDub 1.10.4, but since AviSynth/VirtualDub are designed to work with AVI containers, I first convert my capture from the NUT container to the AVI container using FFmpeg:</p>
<p><code>$ ffmpeg.exe -i &lt;output&gt;.nut -vcodec copy -acodec copy &lt;output&gt;.avi</code></p>
<p>The options passed to FFmpeg are order-dependent and direct it to do the following:</p>
<ul>
<li><code>-i &lt;output&gt;.nut</code>: Use <code>&lt;output&gt;.nut</code> as the input file. FFmpeg is smart and will auto-detect its file format when opened.</li>
<li><code>-vcodec copy</code>: Copy the video stream from the input file‚Äôs container to the output file‚Äôs container; do not re-encode.</li>
<li><code>-acodec copy</code>: Likewise for the audio stream, copy from the input file‚Äôs container to the output file; do not re-encode.</li>
<li><code>&lt;output&gt;.avi</code>: Write to <code>&lt;output&gt;.avi</code>, again substituting my tape‚Äôs label for <code>&lt;output&gt;</code> in both the input and output filenames.</li>
</ul>
<div id=""><div>
<h2>A note about video containers vs. video formats</h2>
<p>Pop quiz! Given a file with the .mov extension, do you know for sure whether it will play in your media player?</p>
<p>Files ending with .mov, .avi, .mkv, and even the .nut format mentioned above are ‚Äúcontainer‚Äù files. When you save a digital video as a QuickTime .mov file, the .mov file is just a wrapper around your media, which must be encoded using one or more ‚Äúcodecs.‚Äù Codecs are small programs that can en<strong>co</strong>de and/or <strong>dec</strong>ode audio or video. These codecs must be specified at the same time as when you save your movie. QuickTime files can wrap among a great many codecs: Motion JPEG, MPEG, H.264, and Cinepak just to name a few. They‚Äôre a bit like Zip files, except that instead of files inside you have audio and/or video tracks, and there‚Äôs no compression other than what‚Äôs already done by the tracks‚Äô codecs. Though Apple provides support in QuickTime for a number of modern codecs, older formats have been dropped over time and so any particular .mov file may or may not play‚Ä¶ even using Apple‚Äôs own QuickTime software! Asking for a ‚ÄúQuickTime movie‚Äù is terribly vague‚Äîa QuickTime .mov file may not play properly on a given piece of hardware if support for a containing <em>codec</em> is missing.</p>
<p>AVI, MKV, and MP4 are containers, too‚ÄîMP4 is in fact based on Apple‚Äôs own QuickTime format. But these are still just <em>containers</em>, and a movie file is nothing without some media inside that can be decoded. Put another way, when I buy a book I‚Äôm often offered the option of PDF, hardcover, or paperback form. But if the words contained therein are in Klingon, I still won‚Äôt be able to read it. When asked to provide a movie in QuickTime or AVI ‚Äúformat,‚Äù get the specifics‚Äîwhat codecs should be inside?</p></div></div>
<p>Now that I have an AVI source file, I can open it in VirtualDub. Owing to its namesake, VirtualDub‚Äôs interface is reminiscent of a dual cassette deck ready to ‚Äúdub‚Äù from one container to another. It isn‚Äôt as user-friendly as, say, Premiere or Resolve when it comes to editing and compositing, but what it lacks in usability it gains in flexibility. In particular, VirtualDub is designed to run a designated range of source video through one or more ‚Äúfilters,‚Äù encoding to one of several output codecs available at ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/">https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</a></em></p>]]>
            </description>
            <link>https://blitter.net/blog/2020/11/24/digitizing-old-8mm-tapes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198435</guid>
            <pubDate>Tue, 24 Nov 2020 13:59:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam and Static Types with Louis Pilfold]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25198388">thread link</a>) | @crowdhailer
<br/>
November 24, 2020 | https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/ | <a href="https://web.archive.org/web/*/https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="fl-main-content" itemprop="mainContentOfPage" role="main">

		
<div>
	<div>

		
		<div>
			<article id="fl-post-6124" itemscope="" itemtype="https://schema.org/BlogPosting">

	
	<header role="banner">
		
		<meta itemscope="" itemprop="mainEntityOfPage" itemtype="https://schema.org/WebPage" itemid="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="datePublished" content="2020-11-24"><meta itemprop="dateModified" content="2020-11-24"><div itemprop="publisher" itemscope="" itemtype="https://schema.org/Organization"><meta itemprop="name" content="Thinking Elixir"></div>	</header><!-- .fl-post-header -->

	
	
	<div itemprop="text">
		<p>
We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!
</p>

<p>
  Show Notes online ‚Äì <a href="https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold">https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold</a><br>
  
</p>
<p><strong>Elixir Community News</strong></p>

<ul>
<li><a href="http://devonestes.com/announcing_muzak" target="_blank" rel="noopener noreferrer">http://devonestes.com/announcing_muzak</a> ‚Äì Devon Estes‚Äô Muzak mutation testing library</li>
<li><a href="https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html" target="_blank" rel="noopener noreferrer">https://blog.appsignal.com/2020/11/17/announcing-appsignal-for-elixir-integration-2-0.html</a> ‚Äì AppSignal released 2.0 of their reporting tool</li>
<li><a href="https://github.com/phoenixframework/phoenix_live_view/pull/1223" target="_blank" rel="noopener noreferrer">https://github.com/phoenixframework/phoenix_live_view/pull/1223</a> ‚Äì Phoenix LiveView file upload fix for components</li>
<li><a href="https://github.com/rrrene/credo" target="_blank" rel="noopener noreferrer">https://github.com/rrrene/credo</a> ‚Äì Happy 5th birthday Credo!</li>
<li><a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/" target="_blank" rel="noopener noreferrer">https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/</a> ‚Äì New Elixir case-study looks at the collaborative wiki product Slab</li>
<li><a href="https://github.com/teamon/tesla/releases/tag/v1.4.0" target="_blank" rel="noopener noreferrer">https://github.com/teamon/tesla/releases/tag/v1.4.0</a> ‚Äì Tesla v1.4.0 released ‚Äì an Elixir HTTP client</li>
<li><a href="https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119" target="_blank" rel="noopener noreferrer">https://elixirforum.com/t/introducing-elixirls-the-elixir-language-server/5857/119</a> ‚Äì ElixirLS version 0.6.2 released.</li>
<li><a href="https://dashbit.co/blog/you-may-not-need-redis-with-elixir" target="_blank" rel="noopener noreferrer">https://dashbit.co/blog/you-may-not-need-redis-with-elixir</a> ‚Äì Jose Valim wrote a blog post addressing the idea of people saying ‚Äúyou don‚Äôt need Redis when you use Elixir‚Äù.</li>
<li><a href="https://baremessages.org/" target="_blank" rel="noopener noreferrer">https://baremessages.org/</a> ‚Äì A new ‚Äúbinary serialization library‚Äù called ‚Äúbare‚Äù. Aims to make Erlang data structures serialize easier in <em>other</em> languages</li>
<li><a href="https://sr.ht/~hauleth/BARE-Erlang/" target="_blank" rel="noopener noreferrer">https://sr.ht/~hauleth/BARE-Erlang/</a></li>
</ul>
<p>Do you know some Elixir news we don‚Äôt? Tell us at <a href="https://twitter.com/ThinkingElixir">@ThinkingElixir</a></p>
<p><strong>Discussion Resources</strong></p>

<ul>
<li><a href="https://github.com/gleam-lang/gleam" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam</a></li>
<li><a href="https://gleam.run/" target="_blank" rel="noopener noreferrer">https://gleam.run/</a></li>
<li><a href="https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/" target="_blank" rel="noopener noreferrer">https://gleam.run/news/gleam-v0.12-and-gleam-otp-v0.1-released/</a></li>
<li><a href="https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/" target="_blank" rel="noopener noreferrer">https://thinkingelixir.com/podcast-episodes/016-gleam-games-and-types-with-quinn-wilton/</a></li>
<li><a href="https://github.com/gleam-lang/gleam/graphs/contributors" target="_blank" rel="noopener noreferrer">https://github.com/gleam-lang/gleam/graphs/contributors</a></li>
<li><a href="https://www.embark-studios.com/" target="_blank" rel="noopener noreferrer">https://www.embark-studios.com/</a></li>
<li><a href="https://racket-lang.org/" target="_blank" rel="noopener noreferrer">https://racket-lang.org/</a></li>
<li><a href="https://akka.io/" target="_blank" rel="noopener noreferrer">https://akka.io/</a></li>
<li><a href="https://developers.google.com/protocol-buffers/" target="_blank" rel="noopener noreferrer">https://developers.google.com/protocol-buffers/</a></li>
<li><a href="https://github.com/lalrpop/lalrpop" target="_blank" rel="noopener noreferrer">https://github.com/lalrpop/lalrpop</a></li>
<li><a href="http://www.elixir.london/2016/louis-pilfold" target="_blank" rel="noopener noreferrer">http://www.elixir.london/2016/louis-pilfold</a></li>
<li><a href="https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0" target="_blank" rel="noopener noreferrer">https://www.youtube.com/watch?v=IONWi9hayEA&amp;index=13&amp;list=PLWbHc_FXPo2ivlIjzcaHS9N_Swe_0hWj0</a></li>
<li><a href="https://gleam.run/community/" target="_blank" rel="noopener noreferrer">https://gleam.run/community/</a> ‚Äì Join the Gleam Discord server</li>
<li><a href="https://twitter.com/louispilfold" target="_blank" rel="noopener noreferrer">https://twitter.com/louispilfold</a> ‚Äì on Twitter</li>
<li><a href="https://github.com/lpil/" target="_blank" rel="noopener noreferrer">https://github.com/lpil/</a> ‚Äì on Github</li>
<li><a href="https://lpil.uk/" target="_blank" rel="noopener noreferrer">https://lpil.uk</a> ‚Äì Blog</li>
</ul>
<p><strong>Find us online</strong></p>
<ul>
<li>Message the show ‚Äì <a href="https://twitter.com/ThinkingElixir" target="_blank" rel="noopener noreferrer">@ThinkingElixir</a></li>
<li>Mark Ericksen ‚Äì <a href="https://twitter.com/brainlid" target="_blank" rel="noopener noreferrer">@brainlid</a></li>
<li>David Bernheisel ‚Äì <a href="https://twitter.com/bernheisel" target="_blank" rel="noopener noreferrer">@bernheisel</a></li>
<li>Cade Ward ‚Äì <a href="https://github.com/cadebward" target="_blank" rel="noopener noreferrer">Github</a></li>
</ul>
<div itemscope="" itemtype="http://schema.org/AudioObject"><meta itemprop="name" content="#023 Gleam and Static Types with Louis Pilfold"><meta itemprop="uploadDate" content="2020-11-24T04:15:45-07:00"><meta itemprop="encodingFormat" content="audio/mpeg"><meta itemprop="duration" content="PT48M57S"><meta itemprop="description" content="We talk with Louis Pilfold about how he created Gleam, a static typed language that runs on the BEAM. Louis explains some of the challenges with bringing static types to the BEAM and shares ideas on what can possibly be done about it. We learn how Gleam got started, how it works, and how Elixir and Erlang can interop with it. We cover the recently released Gleam OTP work, talk about Type Driven Development and much more!



Show Notes online - https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold"><meta itemprop="contentUrl" content="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3"><meta itemprop="contentSize" content="67.4"><div id="powerpress_player_8498"><!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
<p><audio id="audio-6124-1" preload="none" controls="controls"><source type="audio/mpeg" src="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3?_=1"><a href="https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3">https://media.blubrry.com/thinkingelixir/p/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3</a></audio></p></div></div><p>Podcast: <a href="https://media.blubrry.com/thinkingelixir/s/thinkingelixir-podcast.s3.amazonaws.com/023-gleam-louis-pilfold.mp3" title="Download" rel="nofollow" download="023-gleam-louis-pilfold.mp3">Download</a></p>	</div><!-- .fl-post-content -->

	
	<div></div>		
</article>


<!-- .fl-post -->
		</div>

		
	</div>
</div>


	</div></div>]]>
            </description>
            <link>https://thinkingelixir.com/podcast-episodes/023-gleam-and-static-types-with-louis-pilfold/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198388</guid>
            <pubDate>Tue, 24 Nov 2020 13:52:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Htmx 1.0.0 Release]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25198287">thread link</a>) | @crbelaus
<br/>
November 24, 2020 | https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/ | <a href="https://web.archive.org/web/*/https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>htmx 1.0.0 Release</h2>
<p>I'm happy to announce the <a href="https://unpkg.com/browse/htmx.org@1.0.0/">1.0.0 release</a> of htmx.</p>
<p>htmx is now mature enough that I can recommend it as a general replacement for intercooler.js
projects.  I <strong>don't</strong> think there is a strong reason to port an existing intercooler project to
htmx.  I have several large intercooler apps and will not be moving them over any time soon. I can, however, recommend using htmx over intercooler for new projects.</p>
<p>htmx is a different sort of javascript library.  It is an HTML &amp; hypertext-oriented reply to the current dominance of javascript-based SPA libraries.  It is a response to Tom MacWright's question:
<a href="https://macwright.com/2020/10/28/if-not-spas.html">"If not SPAs, What?"</a>.</p>
<p>As the <a href="https://htmx.org/">homepage says</a>:</p>
<ul>
<li>Why should only <code>&lt;a&gt;</code> and <code>&lt;form&gt;</code> be able to make HTTP requests?</li>
<li>Why should only <code>click</code> &amp; <code>submit</code> events trigger them?</li>
<li>Why should only GET &amp; POST be available?</li>
<li>Why should you only be able to replace the entire screen?</li>
</ul>
<p>HTML-oriented web development was abandoned not because hypertext was a bad idea, but rather because HTML didn't have sufficient expressive power.  htmx aims to fix that &amp; allows you to implement <a href="https://htmx.org/examples/">many common modern web UI patterns</a> using the original hypertext model of the web.</p>
<h3>History &amp; Thanks</h3>
<p>htmx began life as <a href="https://intercoolerjs.org/">intercooler.js</a> back in <a href="https://github.com/bigskysoftware/intercooler-js/commit/62d3dbdb5c056ee866aba3575e148de649fc3efe">2013</a>.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/commit/e38dea64dd1065003a0e833d7b469d24e6bc2919">april</a> of this year I began work on a jQuery-indepenent &amp; improved version of intercoolerjs, renamed
to htmx.  I chose to rename the library because, in working on intercooler, I had come to appreciate that intercooler &amp; htmx were completing HTML as a hypertext rather than just some funky, idiosyncratic javascript libraries.</p>
<p>In <a href="https://github.com/bigskysoftware/htmx/releases/tag/v0.0.1">May</a> htmx reached 0.0.1.  Soon thereafter I had the good fortune of being contacted by <a href="https://twitter.com/ben_pylo">Ben Croker</a>
who was interested in htmx as a base for his new reactive library, <a href="https://putyourlightson.com/plugins/sprig">Sprig</a>.  Ben was willing to be an early adopter of htmx and pushed the library along
much faster than it would have gone otherwise.</p>
<p>I have been very lucky to the have help and feedback from many contributors in <a href="https://github.com/bigskysoftware/htmx/graphs/contributors">Github</a> and on <a href="https://htmx.org/discord">Discord</a>.  I'd like to thank, in particular, <a href="https://github.com/benpate">Ben Pate</a>, <a href="https://github.com/rschroll">Robert Schroll</a> &amp; <a href="https://github.com/jreviews">Alejandro Schmeichler</a> for contributing code as well as new ideas and discussions.</p>
<p>I would like to thank <a href="https://devmode.fm/">Devmode.fm</a> for having me on to <a href="https://devmode.fm/episodes/dynamic-html-with-htmx">talk about htmx</a> and for cleaning up all my "uhhs" and "umms".</p>
<p>Finally, I would like to thank <a href="https://github.com/jsampson">Justin Sampson</a>, who took a lot of time to explain REST &amp; HATEOAS to me and how intercooler (and now htmx) fit into that model for web development.</p>
<h3>Changes</h3>
<ul>
<li>I bumped the version number :)</li>
</ul>
<p>Enjoy!</p>

</div></div>]]>
            </description>
            <link>https://htmx.org/posts/2020-11-24-htmx-1.0.0-is-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198287</guid>
            <pubDate>Tue, 24 Nov 2020 13:38:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use Reddit to get your first users]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 146 (<a href="https://news.ycombinator.com/item?id=25198280">thread link</a>) | @xavier_
<br/>
November 24, 2020 | https://blog.spreadtheworld.net/posts/get-first-users-reddit/ | <a href="https://web.archive.org/web/*/https://blog.spreadtheworld.net/posts/get-first-users-reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As an indie hacker, we all struggle to validate our ideas, get our first users, and get some traffic. I played a lot with <a href="https://www.reddit.com/user/xAvi_r">Reddit</a> for the last few months, and I can tell you: it‚Äôs a gold mine!</p><p>Reddit is super powerful:&nbsp;there are millions of users on the platform, each subreddit is very segmented by niche, and it‚Äôs free to use!</p><p>We sometimes see it as an intimidating platform, but it‚Äôs not that hard.</p><p>Here is how I&nbsp;use it:</p><h2 id="validate-your-idea">Validate your idea</h2><p>The first step of your indie hacker journey is to validate your idea. You don‚Äôt want to spend weeks building something nobody wants. But it can be hard to find your potential customers to validate your product idea.</p><p>With Reddit, you can do it easily. There are subreddits dedicated to Ideas‚Äô feedback. You can post your idea there and you will get some responses within 24hrs. The feedback can be pretty generic as the people in these subs are mostly entrepreneurs and not your potential customer.</p><p>To validate my product idea I prefer to post directly on the sub I&nbsp;want to target. Let‚Äôs say you create a tool for developers then I‚Äôd post to /r/webdev. You don‚Äôt need to have a working MVP, just make some screenshot (or a video) and ask for feedback. Or, even better show them a landing page with a pre-order button or an email form and wait for their reactions.</p><p><em>(For the idea validation step, don‚Äôt be afraid to post on a big subreddit with hundreds of thousands of users, the more people see your idea the stronger your validation will be)</em></p><p>Within 24hrs you‚Äôll know if that idea is worth pushing! If you get positive feedback - or even pre-orders - you can build your MVP. If you‚Äôre ignored or trashed, then find another way or get another idea!</p><h2 id="get-your-first-users">Get your first users</h2><p>Once your MVP is ready you need a bunch of beta testers to give you some feedback.
Reddit can also help you with that.</p><p>But this time I‚Äôd go with a small subreddit, and a super targeted one. Let‚Äôs say you created a no-code tool for startups, I‚Äôll try to get my early adopters from /r/nocode (3.7k members) instead of posting on /r/startups (517k members) for instance. It‚Äôs a small subreddit, very niche. Then, once you have the first feedback you can iterate on it and post on some bigger subs.</p><p>The idea of ‚Äúincremental launches‚Äù is to start small, build an audience, get some feedback, and grow step by step. Once the super-targeted subreddit loves your product you can start to post on big subreddit and get some traction.</p><p><em>PS: Small subreddit are super powerful if you choose them wisely. I got more than <a href="https://twitter.com/AngeZanetti/status/1325847913466048516">400 visits</a> in 48hrs from my last post on /r/nocode!</em></p><h2 id="get-some-traffic">Get some traffic</h2><p>Last step of the process: your MVP is ready, you need some traffic. And you want a lot of it!</p><p>The strategy here is to create some content around your product and share it with big subreddits. The secret is to provide as much value as you can. Share your secrets, how you grow your product, share your analytics, how much money you make, what did you learn during your journey, etc‚Ä¶ It needs to be valuable and targeted to an audience.</p><p>Post your content to the biggest subreddits like /r/Entrepreneur, /r/Programming, or /r/Marketing and add a link to your product/blog at the end (Check the rules of the sub first, but most of them are ok with it)</p><p>If your content is well-targeted and brings some serious value you can get thousands of visitors in a day! And it‚Äôs totally repeatable. As long as you can provide value you‚Äôll get some free traffic!</p><p>Do you want to launch on Reddit? DM me on Twitter, I‚Äôll be happy to help ‚Üí <a href="https://twitter.com/angezanetti">Twitter</a></p></div></div>]]>
            </description>
            <link>https://blog.spreadtheworld.net/posts/get-first-users-reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25198280</guid>
            <pubDate>Tue, 24 Nov 2020 13:36:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An opinionated list of best practices for textual websites]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197950">thread link</a>) | @kkoncevicius
<br/>
November 24, 2020 | https://seirdy.one/2020/11/23/website-best-practices.html | <a href="https://web.archive.org/web/*/https://seirdy.one/2020/11/23/website-best-practices.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	<p><em>The following applies to minimal websites that focus primarily on text. It does not
apply to websites that have a lot of non-textual content. It also does not apply to
websites that focus more on generating revenue or pleasing investors than being good
websites.</em></p>
<p>This is a ‚Äúliving document‚Äù that I add to as I receive feedback. See the
<a href="https://git.sr.ht/~seirdy/seirdy.one/log/master/content/posts/website-best-practices.md">changelog</a>.</p>
<p>I realize not everybody‚Äôs going to ditch the Web and switch to Gemini or Gopher today
(that‚Äôll take, like, a month at the longest). Until that happens, here‚Äôs a
non-exhaustive, highly-opinionated list of best practices for websites that focus
primarily on text:</p>
<ul>
<li>Final page weight under 50kb without images, and under 200kb with images.</li>
<li>Works in Lynx, w3m, links (both graphics and text mode), Netsurf, and Dillo</li>
<li>Works with popular article-extractors (e.g.&nbsp;Readability) and HTML-to-Markdown
converters. This is a good way to verify that your site uses simple HTML and works
with most non-browser article readers (e.g.&nbsp;ebook converters, PDF exports).</li>
<li>No scripts or interactivity (preferably enforced at the CSP level)</li>
<li>No cookies</li>
<li>No animations</li>
<li>No fonts‚Äìlocal or remote‚Äìbesides <code>sans-serif</code> and <code>monospace</code>. More on this
below.</li>
<li>No referrers</li>
<li>No requests after the page finishes loading</li>
<li>No 3rd-party resources (preferably enforced at the CSP level)</li>
<li>No lazy loading (more on this below)</li>
<li>No custom colors OR explicitly set the both foreground and background colors. More
on this below.</li>
<li>A maximum line length for readability</li>
<li>Server configured to support compression (gzip, optionally zstd as well). It‚Äôs a
free speed boost.</li>
<li>Supports dark mode via a CSS media feature and/or works with most ‚Äúdark mode‚Äù
browser addons. More on this below.</li>
<li>A good score on Mozilla‚Äôs <a href="https://observatory.mozilla.org/">HTTP Observatory</a></li>
<li>Optimized images.</li>
<li>Maybe HTTP/2. There are some cases in which HTTP/2 can make things slower. Run some
tests to find out.</li>
</ul>
<p>I‚Äôd like to re-iterate yet another time that this only applies to websites that
primarily focus on text. If graphics, interactivity, etc. are an important part of
your website, less (possibly none) of this article applies.</p>
<p>Earlier revisions of this post generated some responses I thought I should address
below. Special thanks to the IRC and <a href="https://lobste.rs/s/akcw1m">Lobsters</a> users who
gave good feedback!</p>
<h2 id="about-fonts">About fonts</h2>
<p>If you <em>really</em> want, you could use <code>serif</code> instead of <code>sans-serif</code>, but serif fonts
tend to look worse on low-res monitors. Not every screen‚Äôs DPI has three digits.</p>
<p>To ship custom fonts is to assert that branding is more important than user choice.
That might very well be a reasonable thing to do; branding isn‚Äôt evil! It isn‚Äôt
<em>usually</em> the case for textual websites, though. Beyond basic layout and optionally
supporting dark mode, authors generally shouldn‚Äôt dictate the presentation of their
websites; that is the job of the user agent. Most websites are not important enough
to look completely different from the rest of the user‚Äôs system.</p>
<p>A personal example: I set my preferred fonts in my computer‚Äôs fontconfig settings.
Now every website that uses <code>sans-serif</code> will have my preferred font. Sites with
<code>sans-serif</code> blend into the users' systems instead of sticking out.</p>
<h3 id="but-most-users-dont-change-their-fonts">But most users don‚Äôt change their fonts‚Ä¶</h3>
<p>The ‚Äúusers don‚Äôt know better and need us to make decisions for them‚Äù mindset isn‚Äôt
without merits; however, in my opinion, it‚Äôs overused. Using system fonts doesn‚Äôt
make your website harder to use, but it does make it smaller and stick out less to
the subset of users who care enough about fonts to change them. This argument isn‚Äôt
about making software easier for non-technical users; it‚Äôs about branding by
asserting a personal preference.</p>
<h3 id="cant-users-globally-override-stylesheets-instead">Can‚Äôt users globally override stylesheets instead?</h3>
<p>It‚Äôs not a good idea to require users to automatically override website stylesheets.
Doing so would break websites that use fonts such as Font Awesome to display vector
icons. We shouldn‚Äôt have these users constantly battle with websites the same way
that many adblocking/script-blocking users (myself included) already do when there‚Äôs
a better option.</p>
<p>That being said, many users <em>do</em> actually override stylesheets. We shouldn‚Äôt
<em>require</em> them to do so, but we should keep our pages from breaking in case they do.
Pages following this article‚Äôs advice will probably work perfectly well in these
cases without any extra effort.</p>
<h3 id="but-wouldnt-that-allow-a-website-to-fingerprint-with-fonts">But wouldn‚Äôt that allow a website to fingerprint with fonts?</h3>
<p>I don‚Äôt know much about fingerprinting, except that you can‚Äôt do font enumeration
without JavaScript. Since text-based websites that follow these best-practices don‚Äôt
send requests after the page loads and have no scripts, fingerprinting via font
enumeration is a non-issue on those sites.</p>
<p>Other websites can still fingerprint via font enumeration using JavaScript. They
don‚Äôt need to stop at seeing what sans-serif maps to; they can see all the available
fonts on a user‚Äôs system, the user‚Äôs canvas fingerprint, window dimensions, etc. Some
of these can be mitigated with Firefox‚Äôs <code>privacy.resistFingerprinting</code> setting, but
that setting also understandably overrides user font preferences.</p>
<p>Ultimately, surveillance self-defense on the web is an arms race full of trade-offs.
If you want both privacy and customizability, the web is not the place to look; try
Gemini or Gopher instead.</p>
<h2 id="about-lazy-loading">About lazy loading</h2>
<p>For users on slow connections, lazy loading is often frustrating. I think I can speak
for some of these users: mobile data near my home has a number of ‚Äúdead zones‚Äù with
abysmal download speeds, and my home‚Äôs Wi-Fi repeater setup occasionally results in
packet loss rates above 60% (!!).</p>
<p>Users on poor connections have better things to do than idly wait for pages to load.
They might open multiple links in background tabs to wait for them all to load at
once, or switch to another window/app and come back when loading finishes. They might
also open links while on a good connection before switching to a poor connection; I
know that I often open 10-20 links on Wi-Fi before going out for a walk in a
mobile-data dead-zone.</p>
<p>Unfortunately, pages with lazy loading don‚Äôt finish loading off-screen images in the
background. To load this content ahead of time, users need to switch to the loading
page and slowly scroll to the bottom to ensure that all the important content appears
on-screen and starts loading. Website owners shouldn‚Äôt expect users to have to jump
through these ridiculous hoops.</p>
<h3 id="wouldnt-this-be-solved-by-combining-lazy-loading-with-pre-loadingpre-fetching">Wouldn‚Äôt this be solved by combining lazy loading with pre-loading/pre-fetching?</h3>
<p>A large number of users with poor connections also have capped data, and would prefer
that pages don‚Äôt decide to predictively load content ahead-of-time for them. Some go
so far as to disable this behavior to avoid data overages. Savvy privacy-conscious
users also generally disable pre-loading because they don‚Äôt have reason to trust that
linked content doesn‚Äôt practice dark patterns like tracking without consent.</p>
<p>Users who click a link <em>choose</em> to load a full page. Loading pages that a user hasn‚Äôt
clicked on is making a choice for that user.</p>
<h3 id="cant-users-on-poor-connections-disable-images">Can‚Äôt users on poor connections disable images?</h3>
<p>I have two responses:</p>
<ol>
<li>If an image isn‚Äôt essential, you shouldn‚Äôt include it inline.</li>
<li>Yes, users could disable images. That‚Äôs <em>their</em> choice. If your page uses lazy
loading, you‚Äôve effectively (and probably unintentionally) made that choice for a
large number of users.</li>
</ol>
<h2 id="about-custom-colors">About custom colors</h2>
<p>Some users' browsers set default page colors that aren‚Äôt black-on-white. For
instance, Linux users who enable GTK style overrides might default to having white
text on a dark background. Websites that explicitly set foreground colors but leave
the default background color (or vice-versa) end up being difficult to read. Here‚Äôs
an example:</p>
<picture>
<source srcset="https://seirdy.one/misc/website_colors.webp" type="image/webp">
<img src="https://seirdy.one/misc/website_colors.png" alt="This page with a grey background, a header with unreadable black/grey text, and unreadable white-on-white code snippets">
</picture>
<p>If you do explicitly set colors, please also include a dark theme using a media
query: <code>@media (prefers-color-scheme: dark)</code>. For more info, read the relevant docs
<a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@media/prefers-color-scheme">on
MDN</a></p>
<h2 id="image-optimization">Image optimization</h2>
<p>Some image optimization tools I use:</p>
<ul>
<li><a href="http://pngquant.org/">pngquant</a> (lossy)</li>
<li><a href="https://github.com/shssoichiro/oxipng">Oxipng</a> (lossless)</li>
<li><a href="https://github.com/tjko/jpegoptim">jpegoptim</a> (lossless or lossy)</li>
<li><a href="https://developers.google.com/speed/webp/docs/cwebp">cwebp</a> (lossless or lossy)</li>
</ul>
<p>I put together a <a href="https://git.sr.ht/~seirdy/dotfiles/tree/3b722a843f3945a1bdf98672e09786f0213ec6f6/Executables/shell-scripts/bin/optimize-image">quick
script</a>
to losslessly optimize images using these programs in my dotfile repo.</p>
<p>You also might want to use the HTML <code>&lt;picture&gt;</code> element, using JPEG/PNG as a fallback
for more efficient formats such as WebP or AVIF. More info in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/picture">MDN
docs</a></p>
<p>Most of my images will probably be screenshots that start as PNGs. My typical flow:</p>
<ol>
<li>Lossy compression with <code>pngquant</code></li>
<li>Losslessly optimize the result with <code>oxipng</code> and its Zopfli backend (slow)</li>
<li>Also create a lossless WebP from the lossy PNG, using <code>cwebp</code></li>
<li>Include the resulting WebP in the page, with a fallback to the PNG using a <code>&lt;picture&gt;</code> element.</li>
</ol>
<p>It might seem odd to create a lossless WebP from a lossy PNG, but I‚Äôve found that it‚Äôs the best way to get the smallest possible image at the minimum acceptable quality for screenshots with solid backgrounds.</p>
<h2 id="other-places-to-check-out">Other places to check out</h2>
<p>The <a href="https://250kb.club/">250kb club</a> gathers websites at or under 250kb, and also
rewards websites that have a high ratio of content size to total size.</p>
<p>Also see <a href="https://motherfuckingwebsite.com/">Motherfucking Website</a>. Motherfucking
Website inspired several unofficial sequels that tried to gently improve upon it. My
favorite is <a href="https://bestmotherfucking.website/">Best Motherfucking Website</a>.</p>
</article></div>]]>
            </description>
            <link>https://seirdy.one/2020/11/23/website-best-practices.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197950</guid>
            <pubDate>Tue, 24 Nov 2020 12:46:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Elon of the 70s]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197941">thread link</a>) | @revolucien
<br/>
November 24, 2020 | https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s | <a href="https://web.archive.org/web/*/https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-nc-base="header" data-controller="AncillaryLayout">
      

      

      <div>

        

        <div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5f18775b30d9fd6c1ed21e6a" data-item-id="5f18775b30d9fd6c1ed21e6a">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1595439165510" id="item-5f18775b30d9fd6c1ed21e6a"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1595439201816_6409"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg" data-image-dimensions="2400x1600" data-image-focal-point="0.5,0.5" alt="Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG  (Source:    OTRAG   )" data-load="false" data-image-id="5f18789af192c5616c553b96" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1595439277525-N1KY1FTDNW9EB1P2KT6U/ke17ZwdGBToddI8pDm48kKtijf5x5S0rIV7X_qDH3dB7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaZbTVdO5VSPAOxIcVIbmIFLIFeVDbQiz7iBIgNCzklBDD2o6CESiqIlH5ssNFrtmA/Lutz_Kayser.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Meet Lutz Kayser, the pioneering rocket engineer and founder of OTRAG<em> (Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a><em>)</em></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-1f175e5db5ee82782e37"><div><p>It‚Äôs 1977 and you‚Äôre standing on a rocky plateau overlooking the dense jungle of Zaire in what is now modern-day Congo. You and a group of maverick engineers work for OTRAG, a West German rocket startup that is sponsored by Zaire‚Äôs dictator, Mobutu Sese Seko. After many months of toil in the African bushland, you‚Äôre ready to launch the world‚Äôs first privately developed rocket booster‚Äì‚Äìa 9-meter (30 ft) tall juggernaut which, from a distance, looks like a bundle of aluminum pencils with a nose cone. The countdown proceeds smoothly. Then finally, there‚Äôs liftoff: The rocket leaves the launch pad with a deafening roar and climbs to an altitude of 12 km (7.5 miles) before plummeting back to Earth. The plateau erupts in jubilation.</p><p>Wait, what? This unlikely scene from the jungle might sound crazy to you. A private rocket company from West Germany that is attempting to make it into space in the late seventies? That‚Äôs more than three decades before Elon Musk‚Äôs <a href="https://en.wikipedia.org/wiki/SpaceX" target="_blank">SpaceX</a> successfully launched its first rocket, the <a href="https://www.youtube.com/watch?v=dLQ2tZEH6G0" target="_blank">Falcon 1</a>, into orbit. But this incredible and long-forgotten tale is entirely true and forms the plot of the documentary<em> </em><a href="https://vimeo.com/300738920" target="_blank"><em>Fly Rocket Fly</em></a><em>, </em>which premiered at the Munich Film Festival in 2018. The film is now available to stream on <a href="https://www.amazon.com/Fly-Rocket-Lutz-Keyser/dp/B082H4WJJG" target="_blank">Amazon Prime</a> and <a href="https://vimeo.com/ondemand/flyrocketfly" target="_blank">Vimeo</a>.</p><p>The rise and fall of OTRAG is one of the strangest, and most remarkable, startup tales I‚Äôve encountered to date. It‚Äôs an almost surreal story of entrepreneurial adventure and ambition that bears an astonishing resemblance to Werner Herzog‚Äôs<em> </em><a href="https://en.wikipedia.org/wiki/Fitzcarraldo" target="_blank"><em>Fitzcarraldo</em></a><em>. </em>In Herzog‚Äôs 1982 movie, Klaus Kinski plays an obsessive dreamer who manually drags his massive steamship over a steep hill in the Amazon jungle. Unfortunately for Fitzcarraldo, this astonishing engineering feat doesn‚Äôt translate into his mission‚Äôs overall success (Herzog later went so far as to call it a ‚Äú<a href="https://www.nytimes.com/2009/08/02/books/review/Harris-t.html" target="_blank">conquest of the useless</a>‚Äù). The same could be said about OTRAG. Despite a number of successful test launches, OTRAG was a spectacular failure. The company burned through massive amounts of funding and eventually ran afoul of Cold War politics. Its demise is a case study in what happens to startups when their timing is wrong, their technology speculative, and their market unwilling to embrace disruptive innovation.</p><h3><strong>The Emperor of OTRAG</strong></h3><p>All startups are a reflection of their founders. The man behind the rocket-building adventure in the jungle was Lutz Kayser, a German aerospace engineer who was something of a 20th-century Elon Musk. Kayser began pursuing his dream of a low-cost rocket launcher in the 1960s. As a student of rocket pioneer <a href="https://en.wikipedia.org/wiki/Eugen_S%C3%A4nger" target="_blank">Eugen S√§nger</a>, he experimented with new propulsion systems using industrially available components and low-cost fuels. The initial work with S√§nger carried over into Kayser‚Äôs first startup, Technology Research Ltd., which he founded in 1970. The company received several million Deutschmark in research grants and was hired by the West German government to explore a low-cost alternative to the ailing <a href="https://en.wikipedia.org/wiki/Europa_(rocket)" target="_blank">Europa II</a> rocket program.&nbsp;</p><p>It was during this time that Kayser developed his vision for a low-cost, modular rocket system that could transport satellites into orbit<em>.</em> The idea was as simple as it was revolutionary: it involved the parallel clustering of many standard fuel tank and engine modules <em>(B√ºndelrakete)</em>. The smallest flight-worthy rocket module consisted of four clustered tank units and four identical engines. Bigger, more powerful boosters could be constructed by bundling together larger quantities of these tank-and-engine modules. The largest configuration on paper had as many as 600 individual engines! And there was another idiosyncrasy to the design: instead of being stacked <em>atop</em> one another, the stages would be nested <em>inside</em> one another and shed like layers of an onion as they burned out. This arrangement didn‚Äôt make for a particularly handsome vehicle and the rocket‚Äôs design was frequently compared to a<em> </em>bundle of asparagus. But aesthetics weren‚Äôt the point; ‚Äúlow cost, not high tech‚Äù was the North Star.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_13600"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png" data-image-dimensions="1988x966" data-image-focal-point="0.5,0.5" alt="Lutz Kayser with a prototype of his ‚Äúcluster rocket‚Äù (left), next to a design sketch by Klaus B√ºrgle (right).  Source:    OTRAG" data-load="false" data-image-id="5fba982f2b4bfe31fd69b8dc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064185347-VN7XY7VCBE5NGAOK3N04/ke17ZwdGBToddI8pDm48kJmhqGN-mSClKRKwJ41evzEUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dt65uYDq5wjmpAbzmJV4EKyPzCeG_9Y6bPguKi4sPluTCjLISwBs8eEdxAxTptZAUg/1.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Lutz Kayser with a prototype of his ‚Äúcluster rocket‚Äù (left), next to a design sketch by Klaus B√ºrgle (right). <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_15492"><div><p>The key to holding down the rocket‚Äôs cost lay in three simple design principles, some of which have been rediscovered by the current crop of ‚Äú<a href="https://en.wikipedia.org/wiki/Private_spaceflight#NewSpace_terminology" target="_blank">NewSpace</a>‚Äù companies. The first principle was rooted in the modular platform architecture itself. Building a whole family of launch vehicles around the same tank-and-engine modules simplified the vehicle configuration and saved millions in development costs. It also meant lots of tanks and engines in production, generating both economies of scale and lower prices. SpaceX applies the same design philosophy today: its main rocket, the <a href="https://en.wikipedia.org/wiki/Falcon_9" target="_blank">Falcon 9</a>, employs nine identical engines (plus another one to power the second stage), while the <a href="https://en.wikipedia.org/wiki/Falcon_Heavy" target="_blank">Falcon Heavy</a> uses 27 units of the same engine. This creates a virtuous cycle whereby the operating model helps drive the business model: being the cheapest launch provider in the market translates into a greater number of launch contracts, which in turn drives higher volumes and scale efficiencies. Once this flywheel is in motion, it becomes easier to run the business as it continues to operate.</p><p>The second design principle was to use mass produced, commercially available components instead of expensive ‚Äúspace grade‚Äù equipment from government contractors. The tank units, for example, were made of long pipeline tubes that were manufactured by the German steelmaker Krupp. Amusingly, a Volkswagen windshield-wiper motor was used to open and close the valves that controlled the propellant flow to the engines. Complex and trouble-prone components, like <a href="https://en.wikipedia.org/wiki/Turbopump" target="_blank">turbopumps</a> or <a href="https://en.wikipedia.org/wiki/Gimbaled_thrust" target="_blank">gimbals</a>, were avoided altogether. Instead, the fuel tanks were partially filled with compressed air that forced the propellant into the engines, and the rocket was steered by throttling back individual engines on the side where less thrust was desired. SpaceX would later use components from existing supply chains as well: The Falcon 1 used readily available car wash valves with modified seals to feed propellant into the engine, while the first <a href="https://en.wikipedia.org/wiki/SpaceX_Dragon" target="_blank">Dragon</a> spacecraft utilized a modified bathroom stall latch for securing the cargo lockers.</p><p>The third design principle was a simplified rocket engine that could run on extremely low-cost fuels. The<em> </em>basic job of rocket fuel is to burn steadily and intensely when combined with an oxidizer. Once the fuel and oxidizer are fed through an injector into the combustion chamber, they produce a hot gas that shoots out of the bell-shaped exhaust nozzle at the bottom. This creates the necessary thrust to launch the rocket upwards. The most common rocket propellant in use today is a mix of ultra-refined kerosene (RP-1) and liquid oxygen (LOX). SpaceX, <a href="https://en.wikipedia.org/wiki/Rocket_Lab" target="_blank">Rocket Lab</a>, and many other launch providers work with this fuel mix. Kayser, in contrast, opted for a much cheaper propellant combination: regular diesel oil as fuel and nitric acid as oxidizer. Though providing less thrust per pound than RP-1/LOX and being extremely toxic, this combination cost only 5% as much and was readily available.&nbsp;</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606063350099_27594"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png" data-image-dimensions="1986x962" data-image-focal-point="0.5,0.5" alt="Kayser in the control center at the German Aerospace Center in Lampoldshausen.  Source:    OTRAG" data-load="false" data-image-id="5fba9899317ba5146213cb17" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5f11f960974e102b616d905f/1606064291685-VEMSFLQL8VPXVMHIP4SE/ke17ZwdGBToddI8pDm48kFhaRfXD0sHRzS4HFtXwQmMUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYy7Mythp_T-mtop-vrsUOmeInPi9iDjx9w8K4ZfjXt2dnuqrDbxeiwpNrWn4d5W-MeZh_NIeMKNsMLkG5wAFm5KCjLISwBs8eEdxAxTptZAUg/2.png">
          </p>
        
          
        

        
          
          <figcaption>
            <p>Kayser in the control center at the German Aerospace Center in Lampoldshausen. <em>Source: </em><a href="http://otrag.com/" target="_blank"><em>OTRAG</em></a></p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606063350099_29089"><div><p>Much of the early work on this novel rocket concept was done at a test stand rented from the German Aerospace Center in <a href="https://www.dlr.de/content/en/articles/sites/lampholdshausen/about-lampoldhausen.html" target="_blank">Lampoldshausen</a>, north of Stuttgart. Over a period of four years, Kayser‚Äôs team went through hundreds of test firings to perfect the diesel oil/nitric acid cocktail. The biggest challenge around getting the engine to work was the ‚Äú<a href="https://en.wikipedia.org/wiki/Hypergolic_propellant" target="_blank">hypergolic</a>‚Äù nature of the fuel mix: diesel oil and nitric acid ignite immediately upon contact and are subject to <a href="https://en.wikipedia.org/wiki/Combustion_instability" target="_blank">unstable burning</a>. Just getting the engine started was difficult: if ignition happened too late, a pool of almost-ready to burn propellant had already accumulated in the combustion chamber, triggering an explosion that would demolish the engine and its immediate surroundings. The group eventually achieved a breakthrough by inventing a radial fuel injection system that provided the right vapor mixture of fuel and oxidizer.</p><p>Then came an unexpected setback. By 1974, the West German government had lost interest in the project and decided to concentrate its rocket research efforts on a new, pan-European launch vehicle, the <a href="https://en.wikipedia.org/wiki/Ariane_1" target="_blank">Ariane 1</a>. Technology Research Ltd.‚Äôs fiscal tap<em> </em>was shut off. Kayser was undeterred. He began looking for private funding to bring his rocket to market but it was difficult. Venture capital as we know it today didn‚Äôt exist in 1974. Venerable firms like <a href="https://www.kleinerperkins.com/our-history/" target="_blank">Kleiner Perkins</a> and <a href="https://www.sequoiacap.com/article/remembering-don-valentine/" target="_blank">Sequoia</a>, both founded in 1972, were still in their infancy and unavailable to a little-known entrepreneur from West Germany. Kayser‚Äôs only option was a highly unorthodox crowdfunding strategy: he decided to raise money from wealthy individuals who wrote off their investment through tax deductions <em>(Abschreibungsgesellschaft). </em>Few investors believed that Kayser‚Äôs company would actually succeed, but that ‚Ä¶</p></div></div></div></div></div></article></section></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s">https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</a></em></p>]]>
            </description>
            <link>https://www.muellerfreitag.com/essays/the-german-elon-of-the-70s</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197941</guid>
            <pubDate>Tue, 24 Nov 2020 12:45:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posting JSON with an HTML Form (2016)]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25197155">thread link</a>) | @graderjs
<br/>
November 24, 2020 | https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html | <a href="https://web.archive.org/web/*/https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A coworker and I were looking at an application today that, like so many other
modern web applications, offers a RESTful API with JSON being used for
serialization of requests/responses.  She noted that the application didn‚Äôt
include any sort of CSRF token and didn‚Äôt seem to use any of the headers
(X-Requested-With, Referer, Origin, etc.) as a ‚Äúpoor man‚Äôs CSRF token‚Äù, but
since it was posting JSON, was it really vulnerable to CSRF?  <strong>Yes, yes,
definitely yes!</strong></p>

<p>Interestingly, this is reminiscent of many of the confusions between server and
browser that are described in Michal Zalewski‚Äôs <a href="https://amzn.to/2QyTUaH">The Tangled
Web</a>.</p>

<p>The idea that the use of a particular encoding is a security boundary is, at
worst, a completely wrong notion of security, and at best, a stopgap until W3C,
browser vendors, or a clever attacker gets hold of your API.  Let‚Äôs examine JSON
encoding as a protection against CSRF and demonstrate a mini-PoC.</p>

<h3 id="the-application">The Application</h3>

<p>We have a basic application written in Go.  Authentication checking is elided
for post size, but this is <em>not</em> just an unauthenticated endpoint.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre></td><td><pre><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"encoding/json"</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>type</span> <span>Secrets</span> <span>struct</span> <span>{</span>
	<span>Secret</span> <span>int</span>
<span>}</span>

<span>var</span> <span>storage</span> <span>Secrets</span>

<span>func</span> <span>handler</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>if</span> <span>r</span><span>.</span><span>Method</span> <span>==</span> <span>"POST"</span> <span>{</span>
		<span>json</span><span>.</span><span>NewDecoder</span><span>(</span><span>r</span><span>.</span><span>Body</span><span>)</span><span>.</span><span>Decode</span><span>(</span><span>&amp;</span><span>storage</span><span>)</span>
	<span>}</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"The secret is %d"</span><span>,</span> <span>storage</span><span>.</span><span>Secret</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>handler</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>As you can see, it basically serves a secret number that can be updated via
HTTP POST of a JSON object.  If we attempt a URL-encoded or multipart POST, the
JSON decoding fails miserably and the secret remains unchanged.  We must POST
JSON in order to get the secret value changed.</p>

<h3 id="exploring-options">Exploring Options</h3>

<p>So let‚Äôs explore our options here.  The site can locally use AJAX via the
XMLHTTPRequest API, but due to the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">Same-Origin
Policy</a>,
an attacker‚Äôs site cannot use this.  For most CSRF, the way to get around this
is plain HTML forms, since form submission is not subject to the Same-Origin
Policy.  The W3C had a <a href="https://www.w3.org/TR/html-json-forms/">draft specification for JSON
forms</a>, but that has been abandoned
since late 2015, and isn‚Äôt supported in any browsers.  There are probably some
techniques that can make use of Flash or other browser plugins (aren‚Äôt there
always?) but it can even be done with basic forms, it just takes a little work.</p>

<h3 id="json-in-forms">JSON in Forms</h3>

<p>Normally, if we try to POST JSON as, say, a form value, it ends up being URL encoded,
not to mention including the field name.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>&lt;form</span> <span>method=</span><span>'POST'</span><span>&gt;</span>
  <span>&lt;input</span> <span>name=</span><span>'json'</span> <span>value=</span><span>'{"foo": "bar"}'</span><span>&gt;</span>
  <span>&lt;input</span> <span>type=</span><span>'submit'</span><span>&gt;</span>
<span>&lt;/form&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Results in a POST body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>json=%7B%22foo%22%3A+%22bar%22%7D
</pre></td></tr></tbody></table></code></pre></div></div>

<p>Good luck decoding that as JSON!</p>

<p>Doing it as the form field name doesn‚Äôt get any better.</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>%7B%22foo%22%3A+%22bar%22%7D=value
</pre></td></tr></tbody></table></code></pre></div></div>

<p>It turns out you can set the enctype of your form to <code>text/plain</code> and avoid the
URL encoding on the form data.  At this point, you‚Äôll get something like:</p>



<p>Unfortunately, we still have to contend with the form field name and the
separator (<code>=</code>).  This is a simple matter of splitting our payload across both
the field name and value, and sticking the equals sign in an unused field.  (Or
you can use it as part of your payload if you need one.)</p>

<h3 id="putting-it-all-together">Putting it All Together</h3>

<div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>&lt;body</span> <span>onload=</span><span>'document.forms[0].submit()'</span><span>&gt;</span>
  <span>&lt;form</span> <span>method=</span><span>'POST'</span> <span>enctype=</span><span>'text/plain'</span><span>&gt;</span>
    <span>&lt;input</span> <span>name=</span><span>'{"secret": 1337, "trash": "'</span> <span>value=</span><span>'"}'</span><span>&gt;</span>
  <span>&lt;/form&gt;</span>
<span>&lt;/body&gt;</span>
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This results in a request body of:</p>

<div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>{"secret": 1337, "trash": "="}
</pre></td></tr></tbody></table></code></pre></div></div>

<p>This parses just fine and updates our secret!</p>

  </div><p>This post contains affiliate links.  If you click on
a link, I may earn a small commission at no cost to you.</p></div>]]>
            </description>
            <link>https://systemoverlord.com/2016/08/24/posting-json-with-an-html-form.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197155</guid>
            <pubDate>Tue, 24 Nov 2020 10:26:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Curl Web Infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25197053">thread link</a>) | @virde
<br/>
November 24, 2020 | https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>The purpose of the <a href="https://curl.se/">curl web site</a> is to inform the world about what curl and libcurl are and provide as much information as possible about the project, the products and everything related to that.</p>



<p>The web site has existed in some form for as long as the project has, but it has of course developed and changed over time.</p>



<h2>Independent</h2>



<p>The curl project is completely independent and stands free from influence from any parent or umbrella organization or company. It is not even a legal entity,  just a bunch of random people  cooperating over the Internet. And a bunch of <a href="https://curl.se/sponsors.html">awesome sponsors</a> to help us.</p>



<p>This means that we have no one that provides the infrastructure or marketing for us. We need to provide, run and care for our own servers and anything else we think we should offer our users.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="187" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 187px) 100vw, 187px"></a></figure></div>



<p>I still do a lot of the work in curl and the curl web site and I work full time on curl, for <a href="https://www.wolfssl.com/">wolfSSL</a>. This might of course ‚Äútaint‚Äù my opinions and views on matters, but doesn‚Äôt imply ownership or control. I‚Äôm sure we‚Äôre all colored by where we work and where we are in our lives right now.</p>



<h2>Contents</h2>



<p>Most of the web site is static content: generated HTML pages. They are served super-fast and very lightweight by any web server software.</p>



<p>The web site source exists in the <a href="https://github.com/curl/curl-www/">curl-www</a> repository (hosted on GitHub) and the web site syncs itself with the latest repository changes several times per hour. The parts of the site that aren‚Äôt static are mostly consisting of smaller scripts that run either on demand at the time of a request or on an interval in a cronjob in the background. That is part of the reason why pushing an update to the web site‚Äôs repository can take a little while until it shows up on the live site.</p>



<p>There‚Äôs a deliberate effort at not duplicating information so a lot of the web pages you can find on the web site are files that are converted and ‚ÄúHTMLified‚Äù from the source code git repository.</p>



<h2>‚ÄúDesign‚Äù</h2>



<p>Some people say the curl web site is ‚Äúretro‚Äù, others that it is plain ugly. My main focus with the site is to provide and offer all the info, and have it be accurate and accessible. The look and the design of the web site is a constant battle, as nobody who‚Äôs involved in editing or polishing the web site is really interested in or particularly good at design, looks or UX. I personally have done most of the editing of it, including CSS etc and I can tell you that I‚Äôm not good at it and I don‚Äôt enjoy it. I do it because I feel I have to.</p>



<p>I get occasional offers to ‚Äúredesign‚Äù the web site, but the general problem is that those offers almost always involve rebuilding the entire thing using some current web framework, not just fixing the looks, layout or hierarchy. By replacing everything like that we‚Äôd get a lot of problems to get the existing information in there ‚Äì and again, the information is more important than the looks.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png" alt="" width="379" height="145" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-1200x459.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-200x76.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-450x172.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/04/good_curl_logo-768x294.png 768w" sizes="(max-width: 379px) 100vw, 379px"></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2016/05/27/a-new-curl-logo/" data-type="post" data-id="8817">curl logo</a> is designed by a proper designer however (Adrian Burcea).</p>



<p>If you want to help out designing and improving the web site, you‚Äôd be most welcome!</p>



<h2>Who</h2>



<p>I‚Äôve already touched on it: the web site is mostly available in git so ‚Äúanyone‚Äù can submit issues and pull-requests to improve it, and we are around twenty persons who have push rights that can then make a change on the live site. In reality of course we are not that many who work on the site any ordinary month, or even year.  During the last twelve month period, 10 persons authored commits in the web repository and I did 90% of those.</p>



<h2>How</h2>



<p>Technically, we build the site with traditional makefiles and we generate the web contents mostly by preprocessing files using a C-like preprocessor called <a href="https://daniel.haxx.se/projects/fcpp/">fcpp</a>. This is an old and rather crude setup that we‚Äôve used for over twenty years but it‚Äôs functional and it allows us to have a mostly static web site that is also fairly easy to build locally so that we can work out and check improvements before we push them to the git repository and then out to the world.</p>



<p>The web site is of course only available over HTTPS.</p>



<h2>Hosting</h2>



<div><figure><a href="https://www.haxx.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png" alt="" width="288" height="97" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010.png 1046w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-200x68.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-450x152.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-768x260.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2018/01/Haxx_logo_2010-1038x354.png 1038w" sizes="(max-width: 288px) 100vw, 288px"></a></figure></div>



<p>The <a href="https://daniel.haxx.se/blog/2020/10/23/a-server-transition/" data-type="post" data-id="14836">curl web site is hosted</a> on an origin VPS server in Sweden. The machine is maintained by primarily by me and is paid for by <a href="https://www.haxx.se/">Haxx</a>. The exact hosting is not terribly important because users don‚Äôt really interact with our server directly‚Ä¶ (Also, as they‚Äôre not sponsors we‚Äôre just ordinary customers so I won‚Äôt mention their name here.)</p>



<h2>CDN</h2>



<p>A few years ago we experienced repeated server outages simply because our own infrastructure did not handle the load very well, and in particular not the traffic spikes that could occur when I would post a blog post that would suddenly reach a wide audience.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-1200x630.png" alt="" width="242" height="127" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo.png 1200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-200x105.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-450x236.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2017/04/fastly-logo-768x403.png 768w" sizes="(max-width: 242px) 100vw, 242px"></figure></div>



<p>Enter <a href="https://www.fastly.com/">Fastly</a>. Now, when you go to <a href="https://curl.se/">curl.se</a> (or <a href="https://daniel.haxx.se/">daniel.haxx.se</a>) you don‚Äôt actually reach the origin server we admin, you will instead  reach one of Fastly‚Äôs servers that are distributed across the world. They then fetch the web contents from our origin, cache it on their edge servers and send it to you when you browse the site. This way, your client speaks to a server that is likely (much) closer to you than the origin server is and you‚Äôll get the content faster and experience a ‚Äúsnappier‚Äù web site. And our server only gets a tiny fraction of the load.</p>



<p>Technically, this is achieved by the name <strong>curl.se</strong> resolving to a number of IP addresses that are <a href="https://en.wikipedia.org/wiki/Anycast">anycasted</a>. Right now, that‚Äôs 4 IPv4 addresses and 4 IPv6 addresses.</p>



<p>The fact that the CDN servers cache content ‚Äúa while‚Äù is another explanation to why updated contents take a little while to ‚Äútake effect‚Äù for all visitors.</p>



<h2>DNS</h2>



<p>When we just recently switched the site over to <a href="https://daniel.haxx.se/blog/2020/11/04/the-journey-to-a-curl-domain/" data-type="post" data-id="14930">curl.se</a>, we also adjusted how we handle DNS.</p>



<div><figure><a href="https://www.kirei.se/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/kirei.png" alt="" width="265" height="117"></a></figure></div>



<p>I run our own main DNS server where I control and admin the zone and the contents of it.  We then have four secondary servers to help us really up our reliability. Out of those four secondaries, three are sponsored by <a href="https://www.kirei.se/">Kirei</a> and are anycasted. They should be both fast and reliable for most of the world.</p>



<p>With the help of fabulous friends like Fastly and Kirei, we hope that the curl web site and services shall remain stable and available.</p>



<p>DNS enthusiasts have remarked that we don‚Äôt do DNSSEC or registry-lock on the curl.se domain. I think we have reason to consider and possibly remedy that going forward.</p>



<h2>Traffic</h2>



<p>The curl web site is just the home of our little open source project. Most users out there in the world who run and use curl or libcurl will not download it from us. Most curl users get their software installation from their Linux distribution or operating system provider. The git repository and all issues and pull-requests are done on GitHub.</p>



<p>Relevant here is that we have no logging and we run no ads or any analytics. We do this for maximum user privacy and partly because of laziness, since handling logging from the CDN system is work. Therefore, I only have aggregated statistics.</p>



<p>In this autumn of 2020, over a normal 30 day period, the web site serves almost 11 TB of data to 360 million HTTP requests. The traffic volume is up from 3.5 TB the same time last year. 11 terabytes per 30 days equals about 4 megabytes per second on average.</p>



<p>Without logs we cannot know what people are downloading ‚Äì but we can guess! We know that the <a href="https://curl.haxx.se/docs/caextract.html">CA cert bundle</a> is popular and we also know that in today‚Äôs world of containers and CI systems, a lot of things out there will download the same packages repeatedly. Otherwise the web site is mostly consisting of text and very small images.</p>



<p>One interesting specific pattern on the server load that‚Äôs been going on for months: every morning at 05:30 UTC, the site gets over 50,000 requests within that single minute, during which 10 gigabytes of data is downloaded. The clients are distributed world wide as I see the same pattern on access points all over. The minute before and the minute after, the average traffic rate remains at 200MB/minute. It makes for a fun graph:</p>



<figure><img loading="lazy" width="1525" height="471" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/11/Screenshot_2020-11-24-Fastly-Stats-curl.png" alt=""><figcaption>An eight hour zoomed in window of bytes transferred from the web site. UTC times.</figcaption></figure>



<p>Our servers suffer somewhat from being the target of weird clients like <a href="https://daniel.haxx.se/blog/2020/04/09/a-qqgamehall-storm/" data-type="post" data-id="13880">qqgamehall</a> that continuously ‚Äúhammer‚Äù the site with requests at a high frequency many months after we started always returning error to them. An effect they have is that they make the admin dashboard to constantly show a very high error rate.</p>



<h2>Software</h2>



<p>The origin server runs Debian Linux and Apache httpd. It has a reverse proxy based on nginx. The DNS server is bind. The entire web site is built with free and open source. Primarily: fcpp, make, roffit, perl, curl, hypermail and enscript.</p>



<p>If you curl the curl site, you can see in response headers that <a href="https://www.fastly.com/blog/benefits-using-varnish">Fastly uses Varnish</a>.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/11/24/the-curl-web-infrastructure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197053</guid>
            <pubDate>Tue, 24 Nov 2020 10:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enterprise UX Design: Make me think]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25197041">thread link</a>) | @Dmytro_Trotsko
<br/>
November 24, 2020 | https://adamfard.com/blog/enterprise-ux | <a href="https://web.archive.org/web/*/https://adamfard.com/blog/enterprise-ux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="article-content"><p>‚ÄúDon‚Äôt make me think‚Äù is a renowned mantra in the world of design, coined by Steve Krug. It has served as a guiding principle in the world of design and UX for twenty&nbsp;years. It teaches us how to create great experiences in a straightforward and accessible manner.&nbsp;</p><p>In today‚Äôs article, we‚Äôd like to look into enterprise design and its peculiarities. It‚Äôs essential to underline that the very nature of enterprise UX slightly differs from consumer UX. As a result, some of Krug‚Äôs principles must be adjusted when designing enterprise software.&nbsp;</p><p>This article is by no means a refutation of the design principle. Please treat it as a mere asterisk with a fine print at the bottom.</p><h2><strong>Learning curves aren‚Äôt inherently bad</strong></h2><p>According to Krug, products that make people think also make people unhappy. <a href="https://uxdesign.cc/the-learning-curve-design-problem-4d4dc2965098">Products with steep learning curves</a> very rarely succeed in the modern business ecosystem. Customers will pretty much always choose the path of least resistance. This isn‚Äôt necessarily true of enterprise products.</p><p>Enterprise users are power users ‚Äî and it‚Äôs imperative that we take this into account when designing products for them. They interact with niche software on a daily basis and quite possibly for many years. They know their way around the logic of the products they use.&nbsp;</p><p>Creating an interface that demands some learning results in a steeper learning curve isn‚Äôt inherently wrong. It allows users to work more efficiently once they‚Äôve invested a certain amount of time into training and learning.&nbsp;</p><figure><img src="https://www.datocms-assets.com/16499/1606137908-figma-shortcuts-cheatsheet-1014x487.jpg?w=900&amp;auto=compress"><figcaption><a href="https://www.figmacrush.com/figma-shortcuts-cheatsheet/">Source</a></figcaption></figure><p>Take, for instance, products like Figma, Sketch, Adobe Pro, or any other professional software ‚Äî most of them have a wide array of shortcuts. Features such as shortcuts may take a while to master, but they‚Äôll ensure a significant boost in productivity once learned.&nbsp;</p><h2>Simplify cautiously&nbsp;</h2><p>We‚Äôre very well aware of the importance of keeping interfaces simple and obvious. However, it‚Äôs essential to keep in mind the complexity of the tasks typically performed in enterprise software. The pursuit for a clean UI could rid users of the vital context necessary to get work done.&nbsp;</p><p>Plus, it can be argued that by making the interface too simple, we risk generating friction rather than eliminating it. Let‚Äôs envision an interface of a product that displays a wide array of charts and data, like a trading platform.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606138044-image2.png?w=900&amp;auto=compress"></p><p>A professional that regularly interacts with visual data needs immediate access to it at all times. Having to perform extra actions to access vital features is both frustrating and unproductive. And here lies one of the most significant differences between consumer UX and enterprise UX (eUX).&nbsp;</p><p>Consumer UX is really passionate about sleek UIs, while enterprise software must ensure that users are able to do their work comfortably. Therefore, simplified, minimalistic interfaces aren‚Äôt really what eUX designers are after.&nbsp;</p><h2>Wizards are cool, but‚Ä¶</h2><p><a href="https://adamfard.com/blog/ux-onboarding">Onboarding your users</a> is a vital step aimed at ensuring optimal user experience. However, while Wizards and guided tours are an excellent solution for casual users, it‚Äôs not necessarily the case for power users.&nbsp;</p><p>In both consumer and enterprise UX, designers must aim to develop products that require <a href="https://adamfard.com/blog/stickiness">as little hand-holding as possible</a>. However, simplistic product tours can be‚Ä¶ well, simplistic. They often fail to uncover the entire functionality of a product, which is especially relevant for experienced users.&nbsp;</p><p>After running a series of tests, we found out that enterprise users tend to prefer to leave the app or platform for instructions. While this does seem somewhat disruptive to the experience of a product ‚Äî it is understandable.&nbsp;</p><p><img src="https://www.datocms-assets.com/16499/1606210515-initiative-alladded1-1.png?w=900&amp;auto=compress"></p><p>Off-page instructions can provide more in-depth explanations rather than the ones that are placed on the screen. Compare, for instance, a tool-tip and an article dedicated to a particular function.&nbsp;</p><h2>Plan for non-linear flows&nbsp;</h2><p>When it comes to designing eUX UIs, designers face a truly arduous task of creating complex, non-linear flows. These flows often involve a variety of roles, profile types, responsibilities, kinds of security, and much more. Our goal is to create a consistent and recognizable experience throughout all of these variables.&nbsp;</p><p>The complicated part, however, is not to force users into flows and scenarios. Experts and professional users need that freedom to make decisions and use the platform as they see fit.</p><p>Think of a person that is deeply versed in Microsoft Excel. They‚Äôve been using this software for nearly a decade, and they know it like the back of their hand. More importantly, they have their style of working and solving problems. Limiting such users via linear and rigid flows could defeat the purpose of boosting their productivity.&nbsp;</p><h2>Don‚Äôt fix it if it‚Äôs not broken</h2><p>Innovation is a crucial element of UX design. We strive to continuously seek new and creative solutions to old problems. Often, we can even choose to be bold and put forth experimental solutions.&nbsp;</p><p>However, when it comes to eUX, we have to be somewhat more conservative and experiment with caution. Enterprise software isn‚Äôt quite receptive to design solutions that go against the grain.&nbsp;</p><p>Since the central purpose of such software is to deliver quality work in short amounts of time, ‚Äúreinventing the wheel‚Äù isn‚Äôt always a great idea.&nbsp;</p><p>When designing for enterprise, keeping an eye on your competition is even more relevant than in consumer software.&nbsp;</p><p>Let‚Äôs go back to Excel once more ‚Äî imagine <a href="https://adamfard.com/blog/website-redesign">you‚Äôre trying to reinvent</a> a complex, spreadsheet-based product. You‚Äôre looking to change the ways it represents data, or certain actions are performed. While this does sound like a laudable task, the critical question is ‚Äî why?&nbsp;</p><p>In eUX, the real value of a product is in its unique selling point that is translated via a design that looks familiar and intuitive.&nbsp;</p><p>That is not to say that the light of innovation never shines on enterprise products, but user expectations often trim the lengths we can go.&nbsp;</p><h2>In conclusion</h2><p>In order to reward you, our beloved reader, for making it till the end, we‚Äôve designed a picture that summarizes the arguments in this article. We hope it will come in handy.</p><p><img src="https://www.datocms-assets.com/16499/1606138895-enterprise-ux-summary.png?w=900&amp;auto=compress"></p><p>While the principles of ‚Äúdon‚Äôt make me think‚Äù will most likely outlive us, it‚Äôs crucial to outline the situations where they can be somewhat amended.&nbsp;</p><p>Enterprise user experience is a slightly more conservative field in terms of design, yet these limitations push us to become even more creative. By operating within these constraints, we have the power to make the future of work exciting and even more promising.&nbsp;</p><p>Meta: In this article, we explore the peculiarities of enterprise user experience design (eUX) through the lens of the ‚ÄúDon‚Äôt make me think‚Äù principle.&nbsp;</p></article></div>]]>
            </description>
            <link>https://adamfard.com/blog/enterprise-ux</link>
            <guid isPermaLink="false">hacker-news-small-sites-25197041</guid>
            <pubDate>Tue, 24 Nov 2020 10:07:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing iPhone OS 1.0 with iOS 14 using tree maps]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25196720">thread link</a>) | @yankcrime
<br/>
November 24, 2020 | https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/ | <a href="https://web.archive.org/web/*/https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>If you followed the recent Apple events, you probably saw a picture of the A14 and M1 dies‚Ä¶ that got me thinking about what you would see if you could pass iOS under X-Rays‚Ä¶</p>
<p>In my previous article about the <a href="https://blog.timac.org/2020/1019-evolution-of-the-programming-languages-from-iphone-os-to-ios-14/">evolution of the programming languages from iPhone OS 1.0 to iOS 14</a>, I analyzed iOS based on the number of binaries and their programming languages. As I pointed out in this past post, the size of the binaries were not taken in account. In this new article, I look at iPhone OS 1.0 and iOS 14 from a size perspective using tree maps.</p>

<p>To produce the images in this article, I extracted the root filesystem (including the dyld shared cache) of each major iOS release:</p>
<table>
<thead>
<tr>
<th>Version</th>
<th>Device</th>
</tr>
</thead>
<tbody>
<tr>
<td>iOS&nbsp;14.0 (18A373)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;13.1 (17A844)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;12.0 (16A366)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;11.1 (15B93)</td>
<td>iPhone X</td>
</tr>
<tr>
<td>iOS&nbsp;10.1 (14B72)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;9.0 (13A344)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;8.0 (12A365)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;7.0.1 (11A470a)</td>
<td>iPhone 5s</td>
</tr>
<tr>
<td>iOS&nbsp;6.0 (10A403)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;5.0 (9A334)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iOS&nbsp;4.0 (8A293)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;3.0 (7A341)</td>
<td>iPhone 3GS</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;2.0 (5A347)</td>
<td>iPhone 2G</td>
</tr>
<tr>
<td>iPhone&nbsp;OS&nbsp;1.0 (1A543a)</td>
<td>iPhone 2G</td>
</tr>
</tbody>
</table>
<p>I then created a tree map. You might be familiar with tree maps as they are often used to visualize a file hierarchy to give you a graphical overview of the structure. One key characteristic is that each file is shown as a rectangle with an area proportional to the file's size. The tree maps displayed in this article have been created using the awesome <a href="http://grandperspectiv.sourceforge.net/">GrandPerspective</a> and annotated with <a href="https://www.pixelmator.com/">Pixelmator</a>.</p>

<p>Let's look at what you would see if you could scan iPhone OS 1.0 using X-Rays:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1.png" alt=""></p>
<p>The diagram below highlights some of the major functional blocks:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_structures.png" alt=""></p>
<p>We can already notice that:</p>
<ul>
<li>The structure is quite simple and has similarities to macOS</li>
<li>Frameworks are taking more than a third of the size</li>
<li>Fonts are taking more than 25% of the whole operating system</li>
</ul>
<p>We can go one level deeper and identify all the components:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS1_details.png" alt=""></p>
<p>From the list of components, we can clearly determine all the main features of iPhone OS 1.0:</p>
<ul>
<li>Phone</li>
<li>SMS</li>
<li>Weather</li>
<li>Clock</li>
<li>Mail</li>
<li>Safari + Web</li>
<li>Calendar</li>
<li>Maps</li>
<li>Wallpaper</li>
<li>Ringtones</li>
<li>Office support</li>
<li>Audio player</li>
<li>Video player</li>
<li>‚Ä¶</li>
</ul>
<p>A couple of components worth mentioning:</p>
<ul>
<li>The UIKit framework is taking more than 13 % of the total size</li>
<li>The wallpapers and ringtones count for 6 %</li>
<li>ICU (International Components for Unicode) takes more than 5 %</li>
<li>SpringBoard is roughly 2 %</li>
</ul>

<p>On popular demand, I added this section to provide more info about the fonts.
The huge <code>Fonts</code> block is composed of 2 parts:</p>
<ul>
<li>the fonts representing 2/3 of the size</li>
<li>some caches (visible at the top of the area and representing a third of the size)</li>
</ul>
<p>For the font lovers, here is the complete list of fonts in iPhone OS 1.0:</p>
<pre><code>AmericanTypewriter.ttf
AmericanTypewriterBold.ttf
AmericanTypewriterCondensed.ttf
AmericanTypewriterCondensedBold.ttf
AmericanTypewriterCondensedLight.ttf
AmericanTypewriterLight.ttf
Arial.ttf
ArialBold.ttf
ArialBoldItalic.ttf
ArialItalic.ttf
ArialRoundedMTBold.ttf
arialuni.ttf
CourierBoldOblique.ttf
CourierNew.ttf
CourierNewBold.ttf
CourierNewBoldItalic.ttf
CourierNewItalic.ttf
CourierOblique.ttf
DB_LCD_Temp-Black.ttf
Georgia.ttf
GeorgiaBold.ttf
GeorgiaBoldItalic.ttf
GeorgiaItalic.ttf
Helvetica.ttf
HelveticaBold.ttf
HelveticaBoldOblique.ttf
HelveticaOblique.ttf
LockClock.ttf
MarkerFeltThin.ttf
MarkerFeltWide.ttf
PhonepadTwo.ttf
TimesNewRoman.ttf
TimesNewRomanBold.ttf
TimesNewRomanBoldItalic.ttf
TimesNewRomanItalic.ttf
TrebuchetMS.ttf
TrebuchetMSBold.ttf
TrebuchetMSBoldItalic.ttf
TrebuchetMSItalic.ttf
Verdana.ttf
VerdanaBold.ttf
VerdanaBoldItalic.ttf
VerdanaItalic.ttf
Zapfino.ttf
</code></pre>
<p>The cache contains info for all these fonts and includes the 2 extra files:</p>
<ul>
<li>HelveLTMM.ps</li>
<li>TimesLTMM.ps</li>
</ul>

<p>I won't give details about each iOS release but you can inspect the tree maps from iPhone OS 2.0 to iOS 13.1:</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>iPhone OS 2.0</td>
<td>iPhone OS 3.0</td>
<td>iOS 4.0</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS2_small.png" alt="" title="iPhone OS 2.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS3_small.png" alt="" title="iPhone OS 3.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS4_small.png" alt="" title="iOS 4.0"></a></td>
</tr>
<tr>
<td>iOS 5.0</td>
<td>iOS 6.0</td>
<td>iOS 7.0.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS5_small.png" alt="" title="iOS 5.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS6_small.png" alt="" title="iOS 6.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS7_small.png" alt="" title="iOS 7.0.1"></a></td>
</tr>
<tr>
<td>iOS 8.0</td>
<td>iOS 9.0</td>
<td>iOS 10.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS8_small.png" alt="" title="iOS 8.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS9_small.png" alt="" title="iOS 9.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS10_small.png" alt="" title="iOS 10.1"></a></td>
</tr>
<tr>
<td>iOS 11.1</td>
<td>iOS 12.0</td>
<td>iOS 13.1</td>
</tr>
<tr>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS11_small.png" alt="" title="iOS 11.1"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS12_small.png" alt="" title="iOS 12.0"></a></td>
<td><a href="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13.png"><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS13_small.png" alt="" title="iOS 13.1"></a></td>
</tr>
</tbody>
</table>
<p>Note that the number of building blocks increased with each new iOS release and the components are becoming smaller.</p>

<p>We are now in 2020 and iOS 14 is available. Without a surprise, iOS 14 is way more complex than iPhone OS 1.0:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14.png" alt=""></p>
<p>Here is the diagram highlighting the functional blocks in iOS 14:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_structures.png" alt=""></p>
<p>We can note that the main structure is still fairly similar to the original iPhone OS 1.0 version: the fonts, frameworks, applications, library, /usr, ‚Ä¶ are still there.</p>
<p>There are however a couple of big differences:</p>
<ul>
<li>iOS 14 contains a lot of <code>Preinstalled Assets</code> and <code>Linguistic Data</code>. As far as I can tell, these components are used for on-device machine learning: language detector, voices, tokenizers, vocalizers, ‚Ä¶</li>
<li>The dyld shared cache, a caching mechanism introduced in iPhone OS 3.1, causes the Frameworks and Private Frameworks to be split in several areas. The dyld shared cache has been marked with the red box in the diagram.</li>
<li>Health is clearly an important feature of iOS 14.</li>
</ul>
<p>There are so many components in iOS 14 that it is way more complex to identify all of them. I gave it a try nonetheless:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/iOS14_details.png" alt=""></p>
<p>Although it is now difficult to list all the features, there are some clear trends:</p>
<ul>
<li>iOS 14 is packed with on-device machine learning technologies: Face Detection, Deep Convolutional Networks, Vision frameworks, Text Recognition, Neural Network, ‚Ä¶</li>
<li>A lot of components are related to the camera and photos: Effects, Memories, video processing, photo library, ‚Ä¶</li>
<li>Siri and voices are clearly visible.</li>
<li>As we already mentioned, Health is an important feature.</li>
<li>We can identify a couple of features added over the years: HomeKit, Watch, CarPlay, Spotlight, Emoji ü§ü, News, iWork, Wallet, Shortcuts, ARKit, ‚Ä¶</li>
</ul>
<p>More statistics:</p>
<ul>
<li>Fonts are now counting for less than 6 % of the size</li>
<li>Linguistic Data represent almost 8 % of the size</li>
<li>Although the ICU size was multiplied by more than 3 since iPhone OS 1.0, it now represents approximatively 0.5% of the total</li>
</ul>

<p>For readability the previous tree maps in this article were all displayed using the same size. If we present iPhone OS 1.0 next to iOS 14 with a proportional area, you would see that the whole iPhone OS 1.0 is basically taking the size of the iOS 14 wallpapers:</p>
<p><img src="https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/images_article/Compare-iOS1-iOS14.png" alt=""></p>

<p>When iPhone OS 1.0 was released in 2007, it redefined the smartphone with a limited set of core features. Nowadays iOS 14 contains an incredible amount of components. By looking at them based on their size, we can determine the most important features. We thus distinctly see Apple's AI push into on-device machine learning with technologies like object detection in images and video, language analysis, sound classification and text recognition.</p>

<p><strong>Update 24.11.2020:</strong></p>
<ul>
<li>Added fonts in the iPhone OS 1.0 tree map</li>
<li>Added fonts in the iOS 14 tree map</li>
<li>Add section with fonts info for iPhone OS 1.0</li>
</ul>
</div></div>]]>
            </description>
            <link>https://blog.timac.org/2020/1122-comparing-iphone-os-with-ios-14-using-tree-maps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196720</guid>
            <pubDate>Tue, 24 Nov 2020 09:18:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is carbon capture a viable solution?]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 339 (<a href="https://news.ycombinator.com/item?id=25196633">thread link</a>) | @scottbucks
<br/>
November 24, 2020 | https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.5.0"><div dir="ltr"><div><h3 id="viewer-foo"><span><strong><span>Is this technology a viable solution to beating the climate crisis or <!-- -->can it cause more harm than good?</span></strong></span></h3><p id="viewer-efp47"><span>With the climate crisis continuously getting worse, businesses and governments need to find solutions to reduce the amount of carbon going into the atmosphere. To beat the crisis, the world can't simply rely on renewable energy, governments will need to include carbon capture, usage and storage (CCUS) into the mix if they want to <span>hit their climate targets.</span></span></p><p id="viewer-4uch7"><span>According to the International Energy Agency (IEA), CCUS could <a href="https://www.iea.org/reports/transforming-industry-through-ccus" target="_blank" rel="noopener"><u>reduce carbon emissions by almost a fifth</u></a>, but can this technology deliver on its promises or is it too good to be true?</span></p><h3 id="viewer-5vpth"><span>What is <!-- -->Carbon capture, usage and storage?</span></h3><p id="viewer-pi2c"><span>Carbon capture, usage and storage (CCUS) refers to <!-- -->a chain of different technologies aimed at capturing waste <!-- -->carbon dioxide<!-- --> (<!-- -->CO2<!-- -->), usually from large <!-- -->point sources of pollution like power plants, <!-- -->transporting it to a storage site, and depositing it where it will not enter the atmosphere. Some could be used to help grow greenhouse plants, make plastics, or even carbonate fizzy drinks. The first step is to fit factory chimneys with solvent filters, which trap carbon emissions before they escape, then the gas can be piped to locations to be used or stored. For the moment, t<span>here are about 30 CCUS projects operating around the world, which is nowhere near enough to clean up all of our emissions. </span></span></p><h3 id="viewer-fds85"><span><span>Why is CCUS needed?</span></span></h3><p id="viewer-7vj3h"><span><span>Nowadays, </span>Industrial production <span>accounts for one-quarter of CO</span>2Ôªø<span> emissions from energy and industrial processes. With the demand for cement, steel and chemicals remaining strong to support a growing and increasingly urbanised global population, the future production of these materials will have to be more efficient and emit much less CO</span>2<span> if governments want to meet their climate goals.</span></span></p><p id="viewer-8ofv8"><span><span>In the </span><a href="https://www.iea.org/reports/material-efficiency-in-clean-energy-transitions" target="_blank" rel="noopener"><u>IEA's "Clean Technology Scenario"</u></a>, <span>more than 28 GtCO</span>2<span>Ôªø could be captured from industrial facilities between now and 2060.</span></span></p><p id="viewer-5eiqn"><span><span>Carbon capture, usage and storage also offers several other potential benefits:</span></span></p><ul><li id="viewer-63jb1"><p><span>The ability to generate additional power thanks to </span><span>geologically stored CO</span>2 which<span> could be used to extract geothermal heat from the same locations in which it‚Äôs injected, producing renewable geothermal energy.</span></p></li><li id="viewer-bcq59"><p><span>CO2 can technically be turned into fuel, although it is rather difficult to achieve.</span></p></li><li id="viewer-dru7v"><p><span>Captured CO</span>2<span> could also be used to strengthen concrete, leading to increased infrastructure durability.</span></p></li></ul><div id="viewer-den6h"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_1000%2Ch_853%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_220f0481ef95495b80fcd23b618197f0~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-e8ds9"><span><span><strong>Suggested Articles:</strong></span></span></h3><ul><li id="viewer-apsbb"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-8crgb"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-4jk2p"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è </strong></p></li></ul><h3 id="viewer-9j318"><span>What's the catch?</span></h3><p id="viewer-89c60"><span>CCUS has always been controversial, m<!-- -->ost people are either heavily in favour of CCUS technology or heavily against. There are several reasons why this technology might not be the best solution.</span></p><p id="viewer-3g635"><span>Environmentalists<!-- --> tend to see CCUS as a distraction from the need to convert to <!-- -->renewable energy as quickly as possible<!-- -->. Some argue that investing in carbon capture wasting money that could be put to better use, like perfecting <!-- -->solar energy<!-- -->, <!-- -->building insulation<!-- -->, <!-- -->wind turbines or even <!-- -->tidal power. </span></p><p id="viewer-bts9g"><span>Another drawback of carbon capture, usage and storage, is the considerable amount of extra power it requires, which would increase the cost of electricity. Talking of cost, CCUS technology is said to be very expensive, however, new methods for capturing and extracting CO2 are constantly being developed, always with the aim to become cheaper.</span></p><h3 id="viewer-3q94h"><span>Where is CCUS in place?</span></h3><p id="viewer-2ukm3"><span>There are currently almost 30 carbon capture, usage and storage projects in place around the world namely in the <span>US, Canada, Norway, China and the UK.</span></span></p><p id="viewer-4rv4i"><span><span>Here are some of the biggest projects:</span></span></p><ul><li id="viewer-65sfn"><p><span>The Century natural gas processing facility in West Texas, US. The capturing plant began operations in November 2010 and is now the world‚Äôs single biggest CCS plant.</span></p></li><li id="viewer-3iluh"><p>The Boundary Dam Carbon Capture and Storage (CCS) project located in Saskatchewan, Canada. Owned by SaskPower, the <span>Boundary Dam coal-fired plant located in Estevan, Saskatchewan began operations in 2014.</span></p></li><li id="viewer-3uhge"><p><span>The Shute Creek gas processing plant, located in Wyoming, US. The CCS facility, built near LaBarge, Lincoln County, is owned by ExxonMobil and captures approximately 365 million cubic feet per day of CO</span>2<span>, which is equivalent to removing more than 1.5 million cars off the road.</span></p></li></ul><div id="viewer-eol67"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Photo of fumes, CO2 from an industrial plant."><p><img data-pin-url="https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis" data-pin-media="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_1000%2Ch_851%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_e6bddda6d2d54b038510cf9aec5bc37a~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg" alt="Photo of fumes, CO2 from an industrial plant."></p></div></div></div></div><h3 id="viewer-4dtjt"><span><span>The bottom line</span></span></h3><p id="viewer-1abo"><span><span>Despite the controversy, it seems that </span>carbon capture, usage and storage technology will become an important part of tackling the climate crisis. I think that if future projects aren't too expensive, it could definitely be a solution to this ever-growing problem, so long as it isn't to the expense of investing in renewable energy and other methods of reducing our CO2 emissions.</span></p><h3 id="viewer-6af0g"><span><span><strong>More from The Detechtor:</strong></span></span></h3><ul><li id="viewer-8a6vc"><p><strong>üöÑ </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a></p></li><li id="viewer-63fca"><p><strong>‚åöÔ∏è </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a></p></li><li id="viewer-anbaq"><p><strong>üì± </strong><a href="https://www.thedetechtor.com/post/smartphones-the-true-cost-of-upgrades" target="_blank" rel="noopener"><strong><u>Smartphones: The True Cost of Upgrades</u></strong></a><strong> ‚ôªÔ∏è</strong></p></li></ul><h3 id="viewer-4ja8h"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-6j517"><p>üì© Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-91ucr"><p>üéô <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><u>The Detechtor Podcast</u></a> is now available on all podcast players!                                                      <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><u>Apple Podcasts</u></a> | <a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><u>Spotify</u></a> | <a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><u>Google Podcasts</u></a> | <a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><u>Stitcher</u></a> | <a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><u>Tunein</u></a></p></li><li id="viewer-3sf88"><p>üì≤ Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><u>Instagram</u></a> | <a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><u>Youtube</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/carbon-capture-usage-and-storage-the-solution-to-the-climate-crisis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196633</guid>
            <pubDate>Tue, 24 Nov 2020 09:04:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[5th UberEats cyclist killed in Sydney in 3 months: Analysis and photos]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25196375">thread link</a>) | @jakecopp
<br/>
November 24, 2020 | https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/ | <a href="https://web.archive.org/web/*/https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Last updated: November 24th, 2020. Please leave comments on <a href="https://news.ycombinator.com/item?id=25196375">Hacker News</a> (&gt;6 comments).</p>

<p><strong>Content warning</strong>: Description of a death, and photos of the cleaned site of death.</p>
<p>After <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">four cyclists were killed by car drivers in Sydney in the last 2 months</a>, a <a href="https://www.abc.net.au/news/2020-11-24/uber-eats-vows-to-improve-safety-cyclist-killed-in-inner-sydney/12913840">37-year-old man from Malaysia</a> was killed at ~6:40pm last night - on my street, 200 metres from my front door, at an intersection I cycle through 2-4 times a day. I would have gone through that intersection within 15 minutes of that time if I didn‚Äôt skip a class. If you know me, I‚Äôm usually quite outspoken about the dangers cyclists face, but this was absolutely brutal to hear.</p>
<p>They cleaned up the body, but didn‚Äôt completely clean up the UberEats meal the man was delivering. The man likely died while earning less than minimum wage - A survey conducted by the Transport Workers‚Äô Union in September <a href="https://www.theguardian.com/business/2020/nov/23/death-of-sydney-uber-eats-rider-the-fourth-food-delivery-fatality-in-two-months">found</a> that food deliverers earned an average of just $10.42 an hour after costs. 73% said they were worried about being ‚Äúseriously hurt or killed‚Äù at work.</p>
<p><em>Content warning: Image of scattered food on road, blue glove likely from police investigation.</em></p>
</div><div>
<p>An <a href="https://www.reddit.com/r/sydney/comments/jzewgi/fifth_food_delivery_rider_dies_following_truck/gdbm0s4/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">eyewitness account on Reddit</a>:</p>
<blockquote>
<p>‚Ä¶I was driving along Cleveland st, and only had a glimpse of what happened: for those of you arguing about PPE - I think there was a helmet - and a crushed head and body, and a twisted bicycle, and, yes, one of those grey food delivery bags all in the middle of Chalmers st. I am crying tonight, because that was someone‚Äôs child, friend ‚Ä¶ a person - who is no more‚Ä¶ .</p>
</blockquote>
<p><em>Content warning: Image of fragment of the helmet of the cyclist in the road gutter.</em></p>
</div><div>
<h2 id="contributing-causes">Contributing causes</h2>
<p>This is a tragedy in itself, but there are also a number of contributing causes at play here:</p>
<ul>
<li><p>In NSW, cycling on a footpath <a href="https://bicyclensw.org.au/who-can-ride-on-a-footpath-in-nsw/">is illegal and carries a fine of $114</a> for those above 15 years of age. Footpath cycling is <a href="https://www.bykbikes.com.au/blogs/bike-riding-tips/riding-bikes-on-the-footpath-the-laws-for-kids-and-adults-in-australia">legal in</a> Queensland, Tasmania, the ACT, the Northern Territory and South Australia.</p>
<ul>
<li>In the UK in 2017, there is a cyclist/pedestrian collision every <a href="https://www.cyclingweekly.com/news/rise-pedestrians-hit-cyclists-not-cause-leap-conclusions-396047">~9.9 million kilometres walked by a pedestrian</a>, or 531 in total. Of these 531 collisions 3 people were killed.</li>
</ul></li>
<li><p>Gig economy workers have little training and often no insurance. California recently proposed a law to force Uber and other platforms to treat their workers like employees. It narrowly failed to pass after <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/Uber,%20Lyft,%20and%20DoorDash%20poured%20over%20$200%20million%20into">Uber, Lyft and Doordash spent &gt; US$200m</a> campaigning against the law.</p></li>
<li><p>Dedicated infrastructure for cyclists is rare in Sydney. Not only are separated bicycle lanes hard to come by, a state government <a href="https://concreteplayground.com/sydney/design-style/sustainability/state-goverment-moves-to-rip-up-college-street-cycleway">actively removed</a> a cycleway in 2015 (which <a href="https://www.dailytelegraph.com.au/newslocal/central-sydney/college-st-syclists-four-times-as-likely-to-be-involved-in-a-crash-since-cycleway-removed/news-story/98ebe30e5c649407e45fd1aa7f023049">increased accidents by 400%</a>) <a href="https://www.bicyclenetwork.com.au/newsroom/2019/03/12/planned-removal-of-alexandra-canal-cycleway/">and in 2019</a>. Walking and cycling infrastructure typically receives <a href="https://theconversation.com/cycling-and-walking-can-help-drive-australias-recovery-but-not-with-less-than-2-of-transport-budgets-142176">0.1-2% of transport budgets</a>. Clover Moore is pushing hard on adding new dedicated cycle infrastructure in the City of Sydney - <a href="https://www.cityofsydney.nsw.gov.au/building-new-infrastructure/creating-pop-up-cycleways-in-sydney">Six pop-up cycleways</a> have been added, which may remain if their is popular support.</p></li>
<li><p>Australian car drivers have a <a href="https://www.abc.net.au/triplej/programs/hack/mythbusting-the-reasons-why-people-hate-cyclists/8689058">unique hatred of cyclists</a>. Cyclists <a href="https://www.smh.com.au/lifestyle/youre-a-cyclist-so-its-your-fault-20140205-321np.html">attract a level of vitriol</a>, if not outright malice, reserved for few subjects in the laid back Aussie‚Äôs mind. Even Tour de France winner Cadel Evans, a self described ‚Äúcar guy‚Äù who has a number of classic and sports cars, said <a href="https://www.smh.com.au/entertainment/books/even-tour-de-france-winner-cadel-evans-finds-cycling-in-sydney-too-intimidating-20161118-gss316.html">he doesn‚Äôt cycle in Sydney</a> due to the culture. Cyclists want to be on the road even less than car drivers want them there, but as stated earlier it is illegal to cycle on the footpath.</p></li>
</ul>
<p><em>Content warning: Image of the street where event took place, recognisable to those who live in Sydney.</em></p>
</div><div>
<h2 id="reasons-for-change">Reasons for change</h2>
<h3 id="public-safety">Public safety</h3>
<p>Car crashes are one of the <a href="https://www.seattletimes.com/life/lifestyle/the-most-dangerous-activity-driving/">leading causes of death in western countries</a>, and air pollution due to cars killed <a href="https://www.smh.com.au/politics/federal/road-death-toll-should-include-victims-of-vehicle-emissions-report-20190628-p522a8.html">two times</a> as many people as <a href="https://roadsafety.transport.nsw.gov.au/statistics/index.html">crashes do</a> in NSW each year - and they didn‚Äôt even have a choice. <a href="http://publications.jrc.ec.europa.eu/repository/bitstream/JRC89231/jrc89231-online%20final%20version%202.pdf">Half of PM10 particle emissions come from tire wear, suspended road dust and brake wear</a>- electric cars (even with regen braking) won‚Äôt fix this. In the US, drivers of cars <a href="http://vpc.org/regulating-the-gun-industry/gun-deaths-compared-to-motor-vehicle-deaths/">kill more people</a> than guns each year.</p>
<p>NSW has a program called <a href="https://towardszero.nsw.gov.au/">Towards Zero</a>, with the aim of reducing road fatalities to zero. One of the few cities to achieve this goal is Oslo, which <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the <em>city centre</em> <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches, increasing business.</p>
<p><em>Content warning: Image of food on the tarmac, and diffracted reflection from fluid likely used to clean the road.</em></p>
</div><div>
<h3 id="cars-are-heavily-subsidised-in-australia">Cars are heavily subsidised in Australia</h3>
<p>By the most generous measure, drivers only contribute <a href="https://www.ptua.org.au/myths/petroltax/">two-thirds of the cost of the road system</a> through rego and petrol taxes. The damage to a road is proportional to the <em>fourth power</em> of axle weight. Many cyclists also own a car and already pay rego. Contrary to popular belief, cyclists are likely subsidising car users.</p>
<h3 id="investing-in-cycle-infrastructurereducing-car-usage-makes-economic-sense">Investing in cycle infrastructure/reducing car usage makes economic sense</h3>
<p>In one study, for each dollar of investment in cycle focused infrastructure, the best practice policy returns 24 dollars in health, congestion, and air and noise pollution related benefits (<a href="https://ec.europa.eu/environment/integration/research/newsalert/pdf/378na1_en.pdf">Macmillan, A., Connor, J., Witten, K., et al.&nbsp;(2014). The Societal Costs and Benefits of Commuter Bicycling: Simulating the Effects of Specific Policies Using System Dynamics Modeling</a>)</p>
<p>A paper submitted to Infrastructure Australia estimated the value of commuter cycling in Australian capital cities as worth approximately <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">$0.76 per kilometre travelled</a>, equating to $2,667 for each regular commuter. Another paper <a href="https://www.infrastructureaustralia.gov.au/sites/default/files/2019-06/Cycling_Infrastructure_Background_Paper_16Mar09_WEB.pdf">estimated</a> that converting drivers to cycling in Sydney &amp; Brisbane is worth $0.74 per kilometre, $1,920 per person annually in inner Sydney.</p>
<p>Banning cars on a street in Rome led to <a href="https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/www.theguardian.com/cities/2015/mar/13/pedestrianisation-rome-italy-car-parking-ban">30% increase</a> in retail spending in that street.</p>
<p>There are <a href="https://cityobservatory.org/ten-things-more-inequitable-that-road-pricing/">a lot of things</a> in our current system more inequitable than road pricing in urban areas.</p>
<h3 id="a-lot-of-other-cities-are-reducing-car-usage">A lot of other cities are reducing car usage</h3>
<p>I know this argumentum ad populum, but hey.</p>
<p>The following cities have a <a href="https://en.wikipedia.org/wiki/Congestion_pricing">congestion tax</a> in their urban core:</p>
<ul>
<li><a href="https://theconversation.com/london-congestion-charge-what-worked-what-didnt-what-next-92478">London</a></li>
<li><a href="https://en.wikipedia.org/wiki/Congestion_pricing_in_New_York_City">New York</a> (soon)</li>
<li>Stockholm</li>
<li>Singapore</li>
<li>Milan</li>
<li>Gothenburg</li>
</ul>
<p>Other efforts to reduce car usage:</p>
<ul>
<li><p>Oslo (population 673k) <a href="https://twitter.com/andershartmann/status/1212465415743512576">reduced pedestrian and cyclist deaths in 2019 to 0</a> by making the city centre <a href="https://www.fastcompany.com/90294948/what-happened-when-oslo-decided-to-make-its-downtown-basically-car-free">effectively car free</a>, replacing more than 700 parking spots with bike lanes, plants, parks and benches. Amsterdam, New York, and San Francisco are <a href="https://www.citylab.com/perspective/2019/12/car-free-streets-plans-sf-market-street-new-york-europe-us/603391/">banning cars from their major streets</a>.</p></li>
<li><p>Madrid banned cars from its city centre during the 2018 Christmas period, <a href="https://copenhagenize.eu/news-archive/2019/3/14/the-benefits-of-car-free-streets">increasing retail profit by 9.5%</a>, and they are planning to ban cars from <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">500 acres of the city centre this year</a>.</p></li>
<li><p>In <a href="https://www.businessinsider.com.au/cities-going-car-free-ban-2018-12?r=US&amp;IR=T">Paris</a>, the first Sunday of every month is free of cars.</p></li>
</ul>
<p><em>Content warning: Image of food in the gutter of the road.</em></p>
</div><div>







<div><p>Disagree with my argument? Have I missed something or is there a mistake? I'd love to hear, please
contact me at <a href="https://jakecoppinger.blog/cdn-cgi/l/email-protection#b1dbd0dad4f1dbd0dad4d2dec1c1d8dfd6d4c39fd2dedc"><span data-cfemail="2b414a404e6b414a404e48445b5b42454c4e5905484446">[email&nbsp;protected]</span></a>. I'm open changing my views if presented with new evidence.
</p></div></div></div>]]>
            </description>
            <link>https://jakecoppinger.blog/articles/the-last-delivery-of-an-ubereats-cyclist-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25196375</guid>
            <pubDate>Tue, 24 Nov 2020 08:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That‚Äôs not why I did it]]>
            </title>
            <description>
<![CDATA[
Score 202 | Comments 69 (<a href="https://news.ycombinator.com/item?id=25195659">thread link</a>) | @MaysonL
<br/>
November 23, 2020 | https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/ | <a href="https://web.archive.org/web/*/https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
<div id="content">

	
		<div id="post-11347">
			

			<p>It has been a very long time since I‚Äôve dealt with a major loom screw up.&nbsp; A really long time.&nbsp; Like I don‚Äôt remember the last time?&nbsp; And it isn‚Äôt because I‚Äôm so very good at this whole weaving thing, but it sort of is.&nbsp; I‚Äôve been weaving since the mid 70‚Äôs.&nbsp; If there is a mistake, or screw up, I can assure you I made it or did it at some point in my career.&nbsp; One of the glorious things about being a weaver is the pure tenacity that controls what we do and how we approach a situation.&nbsp;&nbsp;</p>
<p>Of course by now, you are all familiar with my daughter and her major accomplishments as a weaver.&nbsp; She works for me now, and is responsible for converting all of my garment patterns into <a href="https://www.weaversew.com/shop/sewing-patterns.html">digital downloads</a>.&nbsp; She is also responsible for filming, producing and editing all of my videos for my YouTube channel, <a href="https://www.youtube.com/channel/UCmz2mYvnteUP11-LvK8-eNg"><em>The Weaver Sews</em></a> and writing all of the Closed Captioning.&nbsp; (Yes, I caught that there were a couple of misspellings in previous episodes‚Ä¶)&nbsp; I couldn‚Äôt have moved into this next portion of my professional life without her, but that‚Äôs not why I did it‚Ä¶</p>
<p>My daughter, Brianna, yes she has a real name, not the one she uses on Facebook, was asked back last winter if she would give a lecture to her old weaving guild in MA, near where she went to school.&nbsp; The lecture, on differential sett, was scheduled for April of this year.&nbsp; And of course we all know what happened in the northeast by April.&nbsp; The world was cancelled.</p>
<p>Since my daughter is a soon to be 28 year old millennial, she does her best work under deadline pressure.&nbsp; (Truth be told, so do I‚Ä¶)&nbsp; The guild called her last week and asked if she would be willing to give the lecture remotely.&nbsp; Hahahahah!&nbsp; Of course she said yes, which is what I would have done at that age.&nbsp; I use to have a sign on&nbsp; my studio door that said, ‚ÄúSay yes, then worry‚Ä¶‚Äù</p>
<p>So my daughter had to build an entire lecture that only existed as an outline, and weave all the samples in less than two weeks (the lecture is next week), plus edit and create new content for me, plus work in the evenings on her schooling, (yes, she is still in school to get her vet tech license).&nbsp; But that‚Äôs not why I did it‚Ä¶.</p>
<p>One of the samples Brianna decided to weave, was exploring what happens when you use differential sett with really slippery rayon, warp and weft, and then slippery rayon warp and a dragging kind of weft like Shetland wool.&nbsp; The sample with the slippery rayon warp, though challenging, was completely successful.&nbsp; She then wound a warp with the Shetland wool, and the idea was she would tie into the rayon warp and repeat the experiment with a rayon weft and a wool weft, producing an additional two samples.&nbsp;&nbsp;</p>
<p>At one point, she said to me, as I was weaving on another of the looms in the studio, ‚ÄúThis is ridiculous, tying in a new warp, I could have started fresh, sleying and rethreading in half the time‚Ä¶‚Äù&nbsp; and I couldn‚Äôt disagree with her.&nbsp; I‚Äôve never found tying in a new warp to be a time saver.</p>
<p>I went off to do something else and came back and she had only tied in about 2/3rds of the warp, and she moved onto a different loom to do other samples of different weave structures.&nbsp; She told me that she was fed up and didn‚Äôt have the time to waste tying in 600 ends on a table loom.&nbsp; But that‚Äôs not why I did it‚Ä¶</p>
<p>I went off to other projects of my own, like writing the script for Friday‚Äôs <a href="https://www.youtube.com/channel/UCmz2mYvnteUP11-LvK8-eNg"><em>The Weaver Sews</em></a> Youtube installment.&nbsp; I came back and decided to finish tying in the rest of the warp, which would have been 200 ends.&nbsp; It wasn‚Äôt a big deal, and I can do stuff like that in my sleep.&nbsp; I was surprised when she directed me to make a square knot, I had always tied in new warps with an overhand knot, but I learned long ago that I didn‚Äôt argue with my late husband, and I don‚Äôt argue with his daughter.&nbsp; Even though I have almost a half century of experience‚Ä¶</p>
<p>I finished the task and then turned the job of beaming the 1&nbsp; 1/2 yard warp of sticky Shetland wool, onto the warp beam, over to my daughter.&nbsp; I think I went off to bed‚Ä¶</p>
<p>I came back the next day to find the warp abandoned.&nbsp; It was a complete disaster.&nbsp; I don‚Äôt think even at my worst I‚Äôve ever had a mess like that.&nbsp; Partly I take some responsibility because my daughter has worked along side of me since she first learned to throw a shuttle.&nbsp; She never had the opportunity to fall flat on her face, like most weavers, including me, have had to do.&nbsp; I‚Äôve always been there to guide her, when she chooses to listen to me.&nbsp; But that‚Äôs not why I did it‚Ä¶</p>
<p>Largely what happened, is that when she put tensioning bars in the back of the warp, and tried to beam the new sticky Shetland warp into the old slick rayon warp, the square knots didn‚Äôt hold, they slipped right out.&nbsp; And for some reason, the Shetland wool ends, that slipped out of the knots, ended up in the front of the beater, probably about 200 of the 600 ends.&nbsp; I think this wins an award for the most messed up warp I‚Äôve ever seen.&nbsp; That‚Äôs partly why I did it‚Ä¶</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster1.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster2.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>I felt really sorry for my daughter, she was trying so hard to see this lecture into fruition‚Ä¶&nbsp; But that‚Äôs not why I did it‚Ä¶</p>
<p>I felt partly responsible because I knew that when you tie in a warp, you always use overhand knots.&nbsp; There are a lot of things I know, but I don‚Äôt know why I know them.&nbsp; And because my daughter requested square knots, I obliged.&nbsp; But that‚Äôs not why I did it‚Ä¶</p>
<p>I laid awake all Thursday night haunted by the mess on one of the looms in the garage right underneath of me.&nbsp; I kept thinking, if that were me, I wouldn‚Äôt have gone to bed without fixing it.&nbsp; But that‚Äôs me, even though I knew I had a video to shoot in the morning. I didn‚Äôt sleep the whole night.&nbsp; My daughter just moved to a different loom, and started on a different group of samples she had been planning.</p>
<p>In fact my daughter was so upset by what happened that she couldn‚Äôt even look at the loom. She couldn‚Äôt even walk over to that area of the studio.&nbsp; &nbsp;She is not use to having major loom screw ups‚Ä¶&nbsp; I‚Äôve largely protected her from that‚Ä¶&nbsp; But that‚Äôs not why I did it‚Ä¶</p>
<p>We stopped everything to shoot the new video Friday morning, and I had some computer/business stuff to attend to, but Friday afternoon, I sat at the loom and thought, it has been a very long time since I‚Äôve bailed a loom out of a major temper tantrum, and you know what?&nbsp; I really wanted to just dive in there and fix it.&nbsp; That‚Äôs why I wanted to do it.</p>
<p>A couple of years ago, I had my new to me dog chew up a skein of yarn that was being wound into pirns for the weft yarn for a project I was working on.&nbsp; I got distracted by the doorbell, and when I returned I found&nbsp; the skein stretched around my loom, and all the way down the stairs, and the skein chewed beyond help.&nbsp; I can‚Äôt believe the number of weaver‚Äôs who offered to have me send them the skein and promised to untangle every last yard.&nbsp; There is something about fixing a monumental disaster that is really appealing for a weaver.&nbsp;&nbsp;</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-169x300.jpg" alt="" width="169" height="300" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-169x300.jpg 169w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster-84x150.jpg 84w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/NoroDisaster.jpg 345w" sizes="(max-width: 169px) 100vw, 169px"></a></p>
<p>I sort of think that it has to do with creating calm in chaos.&nbsp; There is so little in the world that we have any control over.&nbsp; But what happens at our looms, that thing, we have control over.&nbsp; And if what happens on our looms becomes total chaos, then patience, tenacity, and time will make it work.&nbsp; That‚Äôs why I did it.&nbsp;&nbsp;</p>
<p>So I started Friday afternoon, after the shoot, and I began to reassess the 600 ends and how to best resolve the mess.&nbsp; Cutting the whole thing off and starting over was an option, but it would mean wasting a perfectly good 1 1/2 yard Shetland warp, that I paid good money for‚Ä¶</p>
<p>I decided that the best way out, was to carefully pull the warps that ended up in front of the reed, since they were only 1 1/2 yards, and resleying them where required (because this was a differential sett warp, there were dents where there were as many as five ends) and then carefully tying them back into the slippery rayon warps that went through the heddles, one by one.&nbsp; I probably spent 10 hours.&nbsp; This was really really challenging.</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster3.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>I did it because there is something intensely satisfying about bringing order to chaos.&nbsp; There is something intense about saving a project.&nbsp; I had my doubts that this was even weaveable, 5 ends of Shetland in a 12 dent reed on a table loom didn‚Äôt see realistic, but that wasn‚Äôt for me to judge.&nbsp; I grabbed my 5X glasses, a magnifying OTT lite, and a sley hook and started in.&nbsp; 10 hours later I was triumphant.&nbsp;&nbsp;</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster4.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>As I suspected, the warp was unweaveable at that dentage, Brianna had to pull some of the densest parts of the warp, but after much bitching and kvetching, she managed to get the sample she needed, but that‚Äôs not why I did it‚Ä¶</p>
<p><a href="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5.jpg"><img loading="lazy" src="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-300x225.jpg" alt="" width="300" height="225" srcset="https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-300x225.jpg 300w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5-150x113.jpg 150w, https://weaversew.com/wordblog/wp-content/uploads/2020/11/Disaster5.jpg 614w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>For all of you out there who have ever had to deal with the warp from hell, remember that there is something healing in finally controlling that which would not be controlled, something triumphant about making something from total chaos.&nbsp; And that‚Äôs&nbsp; why I did it.&nbsp; It has been a long time since I‚Äôve had to bail out a major loom screw up, and I loved every minute of it.&nbsp; It wasn‚Äôt my screw up, but I felt like a warrior on a mission and I was ultimately successful.&nbsp; Mission accomplished.&nbsp; It was sort of poignant that in the middle of the last inch and a half, that the election finals were called.&nbsp; No matter who you supported, the wait is over.&nbsp; And there is a sort of relief there, and now we as a nation can move forward to what I hope is a common goal.&nbsp; My ten hours of determination over a warp from hell was finally over.&nbsp; And I won.</p>
<p>Brianna did manage to beam and weave the new samples.&nbsp; She did as I suspected have to cull some of the warps in the densest part of the reed.&nbsp; But she learned that on her own.&nbsp; And she also learned that when tying in a new warp, you should use overhand knots.&nbsp; But kids learn by falling flat on their faces and picking themselves up and reevaluating the experience.&nbsp; I never had anyone to tell me otherwise, so I learned the hard way, by trial and error, but that weaver‚Äôs tenacity kept me moving forward.&nbsp;&nbsp;</p>

<p>To say that I‚Äôm so proud of the body of samples she ‚Ä¶</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/">https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/</a></em></p>]]>
            </description>
            <link>https://weaversew.com/wordblog/2020/11/07/thats-not-why-i-did-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195659</guid>
            <pubDate>Tue, 24 Nov 2020 05:43:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Love Ed on CP/M]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25195420">thread link</a>) | @todsacerdoti
<br/>
November 23, 2020 | https://techtinkering.com/articles/i-love-ed-on-cpm/ | <a href="https://web.archive.org/web/*/https://techtinkering.com/articles/i-love-ed-on-cpm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>I love ED on CP/M.  It's often derided but I think it's just misunderstood and with a little practise its true value can shine through.  It's elegant, easy to learn and only has about 25 commands but these can be combined.  Once you get used to it most editing tasks are pretty quick.  If I'm editing text that is made up of separate lines, ideally not more than the width of the terminal, I find it excellent.  It does have a line limit of 128 characters so for continuous prose I will switch to something like Wordstar, but for editing source code and config files on CP/M, it's my first choice.</p>
<p>ED came as standard with CP/M and is only 7k for CP/M 2.2 and 10k for CP/M Plus.  One advantage of ED is that it will work both with teleprinters and video terminals without having to be configured for each device.  It is also good at manipulating large files even when the system is short of memory.</p>
<p><img src="https://techtinkering.com/img/articles/cpm_ed_copy_paste.png" title="Copying and Pasting with ED"></p><p>Like many early editors, ED is a modal editor which you start in command mode and while in this mode you can view existing text, move between lines and points in the line.  It allows you to do standard operations such as copy and paste, inserting text from other files, searching for and replacing text, etc.  When we want to enter input mode, we can use the 'I' command.  This is much like VI, except that you can only enter text in the non-command mode but not edit it.  To exit data input mode and return to command mode you use ^Z (CTRL-Z).  These commands can be combined together and one of the most powerful facilities that ED has is the 'M' Macro command to repeat sequences of commands.</p>
<p>Upon executing ED it creates a temporary output file and as you write out from ED it goes to this temporary file.  When editing a file we append text from it into the memory buffer and save to the temporary output file as we go or at the end.</p>
<p>ED keeps track of a number of values such as where it is in the source file,  the line number in the memory buffer and the character pointer (CP) on the line.  These are altered as you move around the file and memory buffer.</p>
<p>I'm not going to give a fuller explanation of how to use ED here because the CP/M 2.2 Operating Manual has a good section on the <a href="http://www.gaby.de/cpm/manuals/archive/cpm22htm/ch2.htm">CP/M Editor</a>.  I do, however, want to show it being used properly in the video below.  Further down in this article I have highlighted some useful command sequences.</p>
<h2>An Example Macro</h2>
<p>ED has a macro facility which allows you to repeat a sequence of commands as many times as you like.  This makes it a good example of the power of ED and the following is a typical macro which searches through the memory buffer and displays any occurrences of the text 'CPM', pauses in case you want to stop the macro and then replaces it with 'CP/M'.</p>
<pre><code>MFCPM^Z0TT6Z-3CSCPM^ZCP/M^Z
</code></pre>
<p>The 'M' command will run the sequences of commands that follows it until an error is raised, such as end of file.  If we wanted to we could prepend 'M' with a number to indicate the number of times we want it to run.  I'll break down each command in the sequence below:</p>
<table>
  <tbody><tr><td><code>M</code></td><td>Run the following command sequence until an error</td></tr>
  <tr><td><code>FCPM^Z</code></td><td>Find 'CPM' and leave Character Pointer (CP) after it</td></tr>
  <tr><td><code>0T</code></td><td>Display the line up to CP</td></tr>
  <tr><td><code>T</code></td><td>Display the rest of the line from CP to end </td></tr>
  <tr><td><code>6Z</code></td><td>Pause</td></tr>
  <tr><td><code>-3C</code></td><td>Move CP back 3 characters</td></tr>
  <tr><td><code>SCPM^ZCP/M^</code></td><td>Substitute 'CPM' for 'CP/M'</td></tr>
</tbody></table>
<p><code>^Z</code> in the above is CTRL-Z and indicates the end of an argument for a command.</p>
<p>The above macro could also be written:</p>
<pre><code>MFCPM^Z0TT6Z-3DICP/M^Z
</code></pre>
<p>In which case:</p>
<table>
  <tbody><tr><td><code>-3D</code></td><td>Delete the 3 previous characters</td></tr>
  <tr><td><code>ICPM^Z</code></td><td>Insert the text 'CP/M'</td></tr>
</tbody></table>
<h2>Video</h2>
<p>The video below shows ED being used properly and some of the things that make it great, including searching and replacing text, copying and pasting, macros and handling files bigger than the available memory.</p>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/7pqaj050X7g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Common Command Sequences</h2>
<p>Below are some useful command command sequences which may be overlooked when reading the manual for ED.</p>
<div><table>
  <tbody><tr><th>Sequence</th><th>Explanation</th></tr>
  <tr><td>#A</td><td>Load whole file into buffer</td></tr>
  <tr><td>0A</td><td>Load enough of the file to fill half the buffer.  This is great for large files</td></tr>
  <tr><td>#W0A</td><td>Save entire buffer and load more of the source file, enough to fill half of the buffer.  Useful to move through large files.</td></tr>
  <tr><td>0W</td><td>Write half of the buffer to the new file.  Useful to make room of the buffer is full.</td></tr>
  <tr><td>-B</td><td>Move to end of the last line in the buffer</td></tr>
  <tr><td>0L</td><td>Move CP to beginning of line</td></tr>
  <tr><td>L-2C</td><td>Move to end of line before the &lt;cr&gt;&lt;lf&gt; sequence</td></tr>
  <tr><td>0P</td><td>Display page from CP without moving CP</td></tr>
  <tr><td>0LT</td><td>Move CP to beginning of line and display line (Should this be +/-n ??)</td></tr>
  <tr><td>0T</td><td>Type line up to but not including CP</td></tr>
  <tr><td>0TT</td><td>Type whole line without moving CP</td></tr>
  <tr><td>0T&lt;cr&gt;T</td><td>Type whole line without moving CP.  Display up to CP on first list and from CP on next line.  This is useful to see where CP is on line.</td></tr>
  <tr><td>B#T</td><td>Display the whole buffer</td></tr>
  <tr><td>KI</td><td>Replace a line</td></tr>
  <tr><td>0K</td><td>Delete up to CP on current line</td></tr>
  <tr><td>S^L^Z</td><td>Join current line with next</td></tr>
  <tr><td>I^L^Z</td><td>To split a line at CP</td></tr>
  <tr><td>0V</td><td>Print free/total memory buffer stats</td></tr>
  <tr><td>0X</td><td>Empties the temporary default exchange file: X$$$$$$$.LIB, used by the <em>X</em> command</td></tr>
</tbody></table></div>
<p>In the table above the following holds true:</p>
<dl>
  <dt>#</dt><dd>Represents the highest value for n</dd>
  <dt>^L</dt><dd>CTRL-L - Stands for carriage return sequence &lt;cr&gt;&lt;lf&gt;</dd>
  <dt>^Z</dt><dd>CTRL-Z - Indicates the end of a command's argument</dd>
  <dt>&lt;cr&gt;</dt><dd>Carriage Return - Actually pressing the <em>Return</em> key</dd>
</dl>
<br>
<h2>Do You Like ED Too?</h2>
<p>I know that I'm in the minority, but I'm sure there must be other people who also like ED.  I'd love to hear if I'm not alone in this.  You can leave comments via the links below or via the YouTube video above.</p>
      </div></div>]]>
            </description>
            <link>https://techtinkering.com/articles/i-love-ed-on-cpm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25195420</guid>
            <pubDate>Tue, 24 Nov 2020 04:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A fully public domain, highly portable first person shooter running on 32kb RAM]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25193953">thread link</a>) | @ClawsOnPaws
<br/>
November 23, 2020 | https://drummyfish.gitlab.io/anarch/ | <a href="https://web.archive.org/web/*/https://drummyfish.gitlab.io/anarch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <a href="https://drummyfish.gitlab.io/anarch"><img src="https://drummyfish.gitlab.io/anarch/media/logo_big.png" alt="logo"></a>

    <span><i>suckless, anticapitalist, public domain game for everyone</i></span>

    

    <span><a href="https://drummyfish.itch.io/anarch">itch.io</a></span>

    <dl>
      <dt> <a href="https://forum.freegamedev.net/viewtopic.php?f=22&amp;t=14771#p95387">Easily the most plain and boring FPS I've ever played.</a> </dt> <dd> Onpon4, libre game developer </dd>
      <dt> <a href="https://talk.pokitto.com/t/anarch-doom-clone-fps/2008/70">Technically the most impressive game on Pokito yet.</a> </dt> <dd> Jonne, the creator of Pokitto </dd>
      <dt> <a href="https://archive.li/tFWrL#84%">Kill yourself.</a> </dt> <dd> Anonymous on 4chan </dd>
    </dl>

    <span>THIS IS SPECIAL</span>

    <ul>
      <li>needs only <b>200 KB</b>, <b>32 KB RAM</b>, <b>40 MHz CPU</b>!</li>
      <li><b>suckless</b>, pure C, <b>no dependencies</b>, no FPU, GPU or file I/O needed</li>
      <li>10 levels, 6 weapons, 7 enemy types, 3 ammo types</li>
      <li>varying floor/ceiling oldschool SW ray casting engine with mouse support</li>
      <li><b>100% public domain</b> CC0 free software and culture</li>
      <li>100% original work, no third party assets</li>
      <li>well documented, hackable, <b>extremely portable</b></li>
      <li>completely <b>gratis</b>, without ads, DRM or similar bullshit</li>
    </ul>

    <p>
      This isn't a 90s style retro shooter, this <b>is</b> a 90s shooter.
    </p>

    <p>
      This game runs everywhere and adheres to great <a href="https://suckless.org/">simplicity</a>.
      It is much more efficient and portable than Doom and has completely
      <b>no dependencies</b>. Not even floating point is used, in case your
      computer doesn't have the HW unit. The game can fit into <b>200 KB</b>
      (including assets!) and can run with just <b>32 KB RAM</b>. No build system,
      library, internet connection or package manager is inherently required for
      compilation as the whole game is written in pure C language.
    </p>

    <p>
      This is an experiment and art that categorically rejects capitalist
      technology.
    </p>
 
   <img src="https://drummyfish.gitlab.io/anarch/media/3screens.png" alt="screenshots">

    <span>MORE THAN A GAME</span>

    <p>
      This is not a mere entertainment or toy meant for killing time or pursuing
      low goals such as making profit or something to put on portfolio, this is
      much more. Anarch is completely <b>gratis and free as in freedom</b> and
      besides entertainment can also be used for education, research, hacking, media
      creation, as a benchmark, as a test, as an environment, as an engine, as
      a basis for something greater. You are not limited by anything, there are
      no conditions to agree to. Nothing is hidden, everything is allowed, no
      burdens are imposed. The best motivation for creating anything is only
      the <b>pure love of creation for its own sake</b>, unburdened by any other
      goal than creating something truly useful. 
    </p>

    <img src="https://upload.wikimedia.org/wikipedia/commons/8/83/Anarch_Devices.jpg" alt="screenshots">

    <span>NO ONE OWNS THIS</span>

    <p>
      Not even I, the creator, own any part of this game.
      I&nbsp;have purposefully created everything myself from scratch,
      including the engine, graphics, sounds, music, even the font and palette,
      so that I could eventually give up all my rights and
      dedicate this game fully and <b>completely to the public domain</b>,
      to you, my dear fellow human being. No one should be allowed to own
      information and art.
    </p>

    <p>
      I've done my best to ensure this is 100% free as in freedom software and
      culture, well understandable and documented. This isn't made for any
      profit. This is made out of <b>love</b>, for you and for the greater good.
    </p>

    <h2>Download</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_LQ_linux64_sdl_elf_1-0?inline=false">GNU/Linux SDL LQ</a></li>
      <li><a href="https://drummyfish.gitlab.io/anarch/bin/web/anarch.html">play in browser</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_pokitto_1-0.pop?inline=false">Pokitto</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_gbmeta_1-0.zip?inline=false">GB Meta</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/raw/master/bin/Anarch_winshitxp_sdl_1-0.zip?inline=false">M$ Win$hit XP SDL</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/archive/master/anarch-master.zip">source code</a></li>
      <li><a href="https://gitlab.com/drummyfish/anarch/-/tree/master/bin">more downloads</a></li>
    </ul>

    <h2>Explore</h2>

    <ul>
      <li><a href="https://gitlab.com/drummyfish/sucklessfps">source code</a></li>
      <li><a href="https://www.tastyfish.cz/">author's website</a></li>
      <li><a href="https://libregamewiki.org/Anarch">libre game wiki</a></li>
      <li><a href="">OGA assets</a></li>
    </ul>

    <h2><a href="https://gitlab.com/drummyfish/anarch#faq">FAQ in readme</a></h2>

    

  

</div>]]>
            </description>
            <link>https://drummyfish.gitlab.io/anarch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25193953</guid>
            <pubDate>Tue, 24 Nov 2020 00:56:26 GMT</pubDate>
        </item>
    </channel>
</rss>
