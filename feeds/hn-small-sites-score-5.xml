<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 04 Dec 2020 16:43:45 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 04 Dec 2020 16:43:45 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Sockets in Your Shell]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25287144">thread link</a>) | @signa11
<br/>
December 3, 2020 | https://who23.github.io/2020/12/03/sockets-in-your-shell.html | <a href="https://web.archive.org/web/*/https://who23.github.io/2020/12/03/sockets-in-your-shell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Something I learned recently and I thought was <em>amazing</em> - you can create sockets straight from your shell! Well, assuming you use bash or zsh - from some surface level digging, I couldnâ€™t find anything for fish.</p>

<p>Hereâ€™s how it works:</p>

<h2 id="bash">bash</h2>
<p>Bash supports tcp and udp connections out of the box, and does so with an imaginary device in <code>/dev</code>. Enter</p>
<div><div><pre><code><span>$ </span><span>echo</span> <span>"text!"</span> <span>&gt;</span> /dev/<span>$PROTO</span>/<span>$HOST</span>/<span>$PORT</span>
</code></pre></div></div>
<p>And youâ€™ll create a connection to <code>HOST:PORT</code>. <code>$PROTO</code> can be <code>tcp</code> or <code>udp</code>. If the connection canâ€™t be made, writing to/reading the file will fail.</p>

<p>Along with being easy to access from the terminal, itâ€™s <em>very</em> handy for scripts, especially if you donâ€™t have <code>nc</code>/<code>telnet</code>. For example, if a local build of a web app runs on port 8000, you can check if itâ€™s running with:<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>

<div><div><pre><code><span>#!/bin/bash</span>
<span>if </span><span>exec </span>3&gt;/dev/tcp/localhost/4000 <span>;</span> <span>then
	</span><span>echo</span> <span>"server up!"</span>
<span>else
	</span><span>echo</span> <span>"server down."</span>
<span>fi</span>
</code></pre></div></div>
<p>And then use that information somewhere else.</p>

<p>If youâ€™re unfamiliar, <code>exec</code> without any arguments is used to redirect file descriptors and files. By associating fd 3 with <code>/dev/tcp/localhost/4000</code>, it attempts to create a file there and thus a connection. We use <code>&gt;</code> to open the socket for writing, although we donâ€™t need to write anything in this case.</p>

<p>By using <code>&lt;&gt;</code> we can open a file for reading and writing, and use it to create a super simple curl:</p>
<div><div><pre><code><span>#!/bin/bash</span>
<span>exec </span>3&lt;<span>&gt;</span>/dev/tcp/<span>"</span><span>$1</span><span>"</span>/80
<span>echo</span> <span>-e</span> <span>"GET / HTTP/1.1</span><span>\n</span><span>"</span> <span>&gt;</span>&amp;3
<span>cat</span> &lt;&amp;3
</code></pre></div></div>
<div><div><pre><code>$ ./simplecurl www.google.com
HTTP/1.1 200 OK
Date: Thu, 03 Dec 2020 00:57:30 GMT
Expires: -1
....
&lt;google website&gt;
</code></pre></div></div>

<p>Iâ€™m sure you can see the power of being able to open sockets with bash alone. Go play around with it!</p>

<h2 id="zsh">zsh</h2>
<p>zsh has an external module you can load in order to use itâ€™s socket capabilities. It doesnâ€™t support udp like bash, but itâ€™s more powerful in a few ways!</p>

<p>To load the module, put the following in your <code>.zshrc</code> or run it in your shell:</p>


<p>We now have access to the zsh networking builtin - <code>ztcp</code>!</p>

<p><code>ztcp</code> allows creating connections, like bash, but also allows listening for connections.</p>

<p>Straight from the zsh docs, we can create a connection between two machines with <code>ztcp</code>:</p>

<div><div><pre><code><span># host machine:</span>
ztcp <span>-l</span> 7128
<span>lfd</span><span>=</span><span>$REPLY</span>
ztcp <span>-a</span> <span>$lfd</span>
<span>talkfd</span><span>=</span><span>$REPLY</span>

<span># client machine</span>
ztcp HOST 7128
<span>talkfd</span><span>=</span><span>$REPLY</span>
</code></pre></div></div>

<p>The <code>$REPLY</code> variable here is a file descriptor returned by the last <code>ztcp</code> command, referring to the socket/connection it just created.</p>

<p>So, <code>talkfd</code> on both machines is a file descriptor for talking to the other:</p>
<div><div><pre><code><span># host machine</span>
<span>echo</span> <span>-e</span> <span>"hello!"</span> <span>&gt;</span>&amp;<span>$talkfd</span>

<span># client machine</span>
<span>read</span> <span>-r</span> line &lt;&amp;<span>$talkfd</span><span>;</span> print <span>-r</span> - <span>$line</span>
<span>&gt;</span> hello!
</code></pre></div></div>

<p>Again, thereâ€™s a lot more you can do, especially with the ability to listen for connections.</p>

<p>Hope this was as interesting to you as it was to me!</p>

<hr>


</div></div>]]>
            </description>
            <link>https://who23.github.io/2020/12/03/sockets-in-your-shell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25287144</guid>
            <pubDate>Thu, 03 Dec 2020 09:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Daniel Stenberg: Twitter lockout, again]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25286809">thread link</a>) | @sohkamyung
<br/>
December 3, 2020 | https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong>Status: 00:27 in the morning of December 4 my account was restored again.</strong> No words or explanations on how it happened.</p>



<p>This morning (December 3rd, 2020) I woke up to find myself logged out from my Twitter account on the devices where I was previously logged in. Due to “suspicious activity” on my account. I don’t know the exact time this happened. I checked my phone at around 07:30 and then it has obviously already happened. So at time time over night.</p>



<p>Trying to log back in, I get prompted saying I need to update my password first. Trying that, it wants to send a confirmation email to an email address that isn’t mine! Someone has managed to modify the email address associated with my account.</p>



<p>It has only been two weeks since someone <a href="https://daniel.haxx.se/blog/2020/11/16/i-lost-my-twitter-account/" data-type="post" data-id="15196">hijacked my account</a> the last time and abused it for scams. When I got the account back, I made very sure I both set a good, long, password and activated 2FA on my account. 2FA with auth-app, not SMS.</p>



<p>The last time I wasn’t really sure about how good my account security was. This time I know I did it by the book. And yet this is what happened.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2020/12/Screenshot_2020-12-03-Losenordsaterstallning.png" alt="" width="467" height="328"><figcaption>Excuse the Swedish version, but it wasn’t my choice. Still, it shows the option to send the email confirmation to an email address that isn’t mine and I didn’t set it there.</figcaption></figure></div>



<h2>Communication</h2>



<p>I was in touch with someone at Twitter security and provided lots of details of my systems , software, IP address etc while they researched their end about what happened. I was totally transparent and gave them all info I had that could shed some light.</p>



<p>Nobody from Twitter has said anything or brought any explanation, blame or excuse as to how this happened or why.</p>



<h2>Was I breached?</h2>



<p>Many people have proposed that the attacker must have come through my local machine to pull this off. If someone did, it has been a very polished job as there is no trace at all of that left anywhere on my machine. Also, to reset my password I would imagine the attacker would need to somehow hijack my twitter session, need the 2FA or trigger a password reset and intercept the email. I don’t receive emails on my machine so the attacker would then have had to (also?) manage to get into my email machine and removed that email – and not too many others because I receive a lot of email and I’ve kept on receiving a lot of email during this period.</p>



<p>I’m not ruling it out. I’m just thinking it seems unlikely.</p>



<p>If the attacker would’ve breached my phone and installed something nefarious on that, it would not have removed any reset emails and it seems like a pretty touch challenge to hijack a “live” session from the Twitter client or get the 2FA code from the authenticator app. Not unthinkable either, just unlikely.</p>



<h2>Most likely?</h2>



<p>As I have no insights into the other end I cannot really say which way I think is the most likely that the perpetrator used for this attack, but I will maintain that I have no traces of a local attack or breach and I know of no malicious browser add-ons or twitter apps on my devices.</p>



<h2>Details</h2>



<p>Firefox version 83.0 on Debian Linux with Tweetdeck in a tab – a long-lived session started over a week ago (ie no recent 2FA codes used), </p>



<p>Browser extensions: Cisco Webex, Facebook container, multi-account containers, HTTPS Everywhere, test pilot and ublock origin.</p>



<p>I only use one “authorized app” with Twitter and that’s Tweetdeck.</p>



<p>On the Android phone, I run an updated Android with an auto-updated Twitter client. That session also started over a week ago. I used <em>Google Authenticator</em> for 2fa.</p>



<p>While this hijack took place I was asleep at home (I don’t know the exact time of it), on my WiFi, so all my most relevant machines would’ve been seen as originating from the same “NATed” IP address. This info was also relayed to Twitter security.</p>



<h2>Restored</h2>



<p>The actual restoration happens like this (and it was the exact same the last time): I just suddenly receive an email on how to reset my password for my account.</p>



<p>The email is a standard one without any specifics for this case. Just a template press the big button and it takes you to the Twitter site where I can set a new password for my account. There is nothing in the mail that indicates a human was involved in sending it. There is no text explaining what happened. Oh, right, the mail also include a bunch of standard security advice like “use a strong password”, “don’t share your password with others” and “activate two factor” etc as if I hadn’t done all that already…</p>



<p>It would be prudent of Twitter to explain how this happened, at least roughly and without revealing sensitive details. If it was my fault somehow, or if I just made it easier because of something in my end, I would really like to know so that I can do better in the future. But no.</p>



<h2>What was done to it?</h2>



<p>No tweets were sent. The name and profile picture remained intact. I’ve not seen any DMs sent or received from while the account was “kidnapped”. Given this, it seems possible that the attacker actually only managed to change the associated account email address.</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2020/12/03/twitter-lockout-again/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25286809</guid>
            <pubDate>Thu, 03 Dec 2020 08:27:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In-Database Machine Learning [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25285983">thread link</a>) | @redwrasse
<br/>
December 2, 2020 | https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf | <a href="https://web.archive.org/web/*/https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://btw.informatik.uni-rostock.de/download/tagungsband/B6-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25285983</guid>
            <pubDate>Thu, 03 Dec 2020 06:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the US Banning Crypto Wallets?]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25283610">thread link</a>) | @mkmccarty3
<br/>
December 2, 2020 | https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets | <a href="https://web.archive.org/web/*/https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          

          <main>
            
              <section data-content-field="main-content">
                <article id="post-5fc557916457125654ede725" data-item-id="5fc557916457125654ede725">

    
      
    

    <div data-layout-label="Post Body" data-type="item" data-updated-on="1606768551080" id="item-5fc557916457125654ede725"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_4996"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png" data-image-dimensions="834x466" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baa31d106d256baa5ca2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859427069-IMZ962U40BK6V610BXZ0/ke17ZwdGBToddI8pDm48kDdYOT--AF0GQA05lGhHN6xZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZamWLI2zvYWH8K3-s_4yszcp2ryTI0HqTOaaUohrI8PIuTIZPllpt4oUHZVwVNvJYrOOWDDZGBPAJ1bGYAesFpI/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-98c39078cd9c52d11cda"><div><p>Just as Bitcoin was guiding cryptocurrency markets skyward with a renewed push for an all-time high valuation, prices came crashing down without warning.</p><p>Wait — <em>was there a warning</em>?</p><p><a href="https://twitter.com/brian_armstrong/status/1331744884856741888">In a tweet</a> with what some deemed suspicious timing, Coinbase CEO Brian Armstrong let loose an alarming rumor. The United States Treasury, with Secretary Mnuchin at the helm, is poised to ban the use of anonymous non-custodial crypto wallets before the year's end.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_22941"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          <a href="https://twitter.com/brian_armstrong/status/1331745659989360640">
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859896793-32N3SDYCIGJL7FQQWI1O/ke17ZwdGBToddI8pDm48kIzQK2Xbu_9Rwy3schbNl8FZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxMPwOXQ5XHVczUuSM__CeJaRVde0ElwrtrQUL7fUx9Y2HxA7PMOPrJo8qnOuHHIME/brian+armstrong+tweet.PNG" data-image-dimensions="589x256" data-image-focal-point="0.5,0.5" alt="brian armstrong tweet.PNG" data-load="false" data-image-id="5fc6bc78e2dcb1274dd6fb85" data-type="image">
          </p>
        
          </a>
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_23230"><div><p>What is a non-custodial crypto wallet, you ask? Simple — any crypto wallet that is self-hosted (i.e., you own and hold the private keys) fits the description.</p><p>So, if you currently use a cold storage wallet like a Ledger Nano S or a software wallet such as MetaMask, you may soon find yourself running afoul of new regulations.</p><p>While this all seems pretty bad for Bitcoin when you consider the sheer amount of people using non-custodial crypto wallet storage, there are a couple silver linings worth considering.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_25472"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860003015-D7PWZRUGRXLDVSEUVKEA/ke17ZwdGBToddI8pDm48kJtHoCldZmbUzRsNK-HRabIUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcAg44e5RqXWm62Rp9AfQjNZ02d_YH6EpEcM1aSuHuNzPAFiIg8-3tQXzSNASsJ8HT/wallet+guide.PNG" data-image-dimensions="1306x735" data-image-focal-point="0.5,0.5" alt="wallet guide.PNG"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>In this article, we will discuss how experts choose their cryptocurrency wallets and what types of wallets exist. </p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_25761"><div><p>At the core of the rumored regulations is what appears to be a bank-centric push to force all current and future cryptocurrency users toward intermediary platforms.</p><p>What this means for you is, if the rumors are true, you will need to share KYC information (identification data) with exchanges you use before withdrawing or depositing from your self-hosted wallet. This push will make it so your currently anonymous crypto wallet will be inextricably linked to your real-world identity.</p><p>OK — so there go crypto wallets, right? You might as well delete your Exodus wallet, shut down the MetaMask, and turn everything over to the bankers lying in wait.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_7734"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6baf2ad3e6411922cd0a2" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859506519-3BVCS0NCZUUZV5KXWT0L/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_8023"><div><p><strong>Wrong.</strong> Try as they might, there is simply <strong>no way</strong> to enforce data collection on the use of non-custodial wallets. Such regulations appear more symbolic than anything else — they might scare newbies looking to enter the market discreetly, but anyone who understands how cryptocurrency storage works, especially when using hardware wallets, knows there are options outside of centralized exchanges.</p><p>Consider the scenario where the US Treasury makes good on their threat to enforce data collection on crypto wallets. Now, Coinbase requires you to KYC your wallet before allowing you to withdraw freshly purchased BTC. What are your options?</p><p>For one thing, you can use a decentralized exchange to trade crypto. Uniswap has already surpassed Coinbase in terms of trading volume — if crypto wallets regulations come into play, expect Uniswap to get much more action.</p><p>Moreover, with the push toward DeFi in the cryptocurrency industry, along with endless options for swapping liquidity, the likelihood that centralized exchanges stay relevant gets slimmer every day.</p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_15299"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png" data-image-dimensions="512x512" data-image-focal-point="0.5,0.5" alt="" data-load="false" data-image-id="5fc6bbd593ad1a48120388ca" data-type="image" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606859733286-8P6U1ZQGNXDVXLFNJIXT/ke17ZwdGBToddI8pDm48kGfiFqkITS6axXxhYYUCnlRZw-zPPgdn4jUwVcJE1ZvWQUxwkmyExglNqGp0IvTJZUJFbgE-7XRK3dMEBRBhUpxQ1ibo-zdhORxWnJtmNCajDe36aQmu-4Z4SFOss0oowgxUaachD66r8Ra2gwuBSqM/image-asset.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1606858594054_15588"><div><p>Satoshi Nakamoto never envisioned cryptocurrency as a way for governments to collect private data. That's why blockchains are built to enable censorship-free financial access.</p><p>As CoinDesk noted <a href="https://www.coindesk.com/crypto-wallet-regulations-industry-pros">in a recent analysis of the situation</a>, there exists a revealing difference in the language used to refer to crypto wallets by regulators and crypto investors.</p><p>Regulators call crypto wallets <em>unhosted wallets,</em> whereas investors refer to them as <em>self-hosted wallets</em>. The difference here is all about privacy — crypto users believe in financial independence, freedom from oversight, and digital asset autonomy.</p><p>On the other hand, an unhosted wallet points to the view that such wallets lack hosting — a situation that should be remedied by regulation and the cooperation of centralized institutions.</p><p>This seemingly small difference in language does indeed point to a large divide in exactly how each side views the purpose of storing crypto assets.</p><p>As Armstrong noted in his original Twitter thread, the crypto industry has been preparing for this eventuality for at least a few months. In fact, they've known long enough to form a lobby, and have responded to the rumors by sending the US Treasury a plea to leave crypto alone.</p><p>The regulation is expected to come into effect before the year's end, mostly owing to the US election results and the impending changing of the guard. As such, the rush is on for Mnuchin to push through regulations before time is up.</p><p>Does data-collection on self-hosted crypto wallets amount to the US government declaring a ban on cryptocurrency wallets we know them?</p><p><strong>Not really</strong>.</p><p>Moreover, can the government enforce these regulations and push people onto the centralized platforms decentralized blockchains were built to avoid?</p><p>The answer there is clearer: <strong>certainly not.</strong></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1606858594054_28135"><div>








  

    

      <figure data-scrolled="" data-test="image-block-v2-outer-wrapper">

        <div>
          
            <div data-animation-role="image" data-description="">
            
            <p><img data-src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png" data-image-dimensions="1442x669" data-image-focal-point="0.5,0.5" alt="beginners guide to bitcoin cover.png" src="https://images.squarespace-cdn.com/content/v1/5bdc8c06697a98bb346792b9/1606860181795-31T33KPC9K7FBN89JRZ0/ke17ZwdGBToddI8pDm48kC4WVkWChCLParlq_1Nh_lsUqsxRUqqbr1mOJYKfIPR7LoDQ9mXPOjoJoqy81S2I8N_N4V1vUb5AoIIIbLZhVYxCRW4BPu10St3TBAUQYVKcIrrjBD1NZmr3Lj4Iz0Q2EGYi8eyZhZ8ZZtbo9mp2mza1ovWzepp4UuvSM2A0Sojq/beginners+guide+to+bitcoin+cover.png"></p>
          
            </div>
          

        </div>

        
          
          <figcaption data-width-ratio="">
            <div>

              
                <div></div>
              

              
                <div><p>Each of these strategies is simple to implement, even for novice investors, but that doesn’t mean these strategies aren’t used by professions.</p></div>
              

              
                <div><div></div></div>
              

            </div>
          </figcaption>
        

      </figure>

    

  


</div></div></div></div></div>

    

    

    <section id="comments-5fc557916457125654ede725">
      
  


    </section>

  </article>





  <nav>

    
      <a href="https://blog.shrimpy.io/blog/coinbase-vs-uniswap">
        <svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="21.5,1.3 2.6,23.4 21.5,45.7 "></polyline>
          </g>
        </svg><!--
        --><div>
          <p>Previous</p>
          <h4>Coinbase vs. Uniswap — Which Exchange Is Better?</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-12-02">December 2, 2020</time></p><!--

            Tags

            --><p><span>coinbase, uniswap, review, general, notlatest</span></p><!--

            Comments

            --></div>
        </div>
      </a>
    

    
      <a href="https://blog.shrimpy.io/blog/machine-learning-for-crypto-portfolio-management-case-study-week-30">
        <div>
          <p>Next</p>
          <h4>Machine Learning for Crypto Portfolio Management Case Study: Week 30</h4>
          <div>
            <!--

            Categories

            --><p><span>Investor</span></p><!--

            Author

            --><p><span>Michael McCarty</span></p><!--

            Date

            --><p><time datetime="2020-11-30">November 30, 2020</time></p><!--

            Tags

            --><p><span>data, notlatest, topsection</span>
          </p></div>
        </div><!--
        --><svg viewBox="0 0 23 48">
          <g>
            <polyline fill="none" stroke-miterlimit="10" points="1.5,45.7 20.4,23.5 1.5,1.3 "></polyline>
          </g>
        </svg>
      </a>
    

  </nav>
              </section>
            
          </main>

        </div></div>]]>
            </description>
            <link>https://blog.shrimpy.io/blog/is-the-us-government-banning-crypto-wallets</link>
            <guid isPermaLink="false">hacker-news-small-sites-25283610</guid>
            <pubDate>Thu, 03 Dec 2020 00:13:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spaced Repetition in the Classroom]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25283013">thread link</a>) | @jlmao
<br/>
December 2, 2020 | https://www.podsie.org/blog/spaced-practice-in-the-classroom/ | <a href="https://web.archive.org/web/*/https://www.podsie.org/blog/spaced-practice-in-the-classroom/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>When my students bombed their first semester exam, it shocked me. It was my second year of teaching eighth grade math, and unlike the previous year, my students had actually done well on the exit tickets and tests up to that point. However, my students seemed to have forgotten everything.</p><p>The next semester, I made a concerted effort to carve out time for review, but it was tedious, and I never knew which specific topics to review, and how often to review each topic.</p><p>Years later when I was no longer a teacher, I found out that there was actually a science behind the best way to review, and that there was also <a href="https://www.gwern.net/Spaced-repetition" target="_blank" rel="noopener noreferrer">a large body of research to back it up</a>.</p><h5>Ebbinghaus and the Forgetting Curve</h5><p>This body of research goes as far back as the 1880s, when a German psychologist named Hermann Ebbinghaus mapped out memory and how we forget over time.</p><p><img src="https://www.researchgate.net/profile/Bo_Ae_Chun/publication/324816198/figure/fig1/AS:620205050982405@1524879815703/Ebbinghaus-forgetting-curve-and-review-cycle.png" alt="Forgetting Curve"></p><p>In his model of memory, Ebbignhaus stated that when content is first learned, without review, memory of that content deteriorates quickly. However, with each subsequent review and retrieval of that information, the memory becomes more durable, and over time, less and less review is required to keep retention fresh.</p><p>When I first learned about this, I felt an "Aha!" moment as Ebbinghaus broke down exactly why my students struggled when I was teaching.</p><p>For me, because planning out new lessons was already such a tough process, I never had enough time to adequately review throughout the school year. Instead, every year in March, I dedicated an entire month to review all of the content before the state exam. In fact, several lower-performing districts encouraged students and teachers to have â€œreview weeksâ€� to cram review before state assessments. We would power through countless hours of material that students had already "learned", but it never stuck as well as I would have liked.</p><p>Ebbinghaus proposed something that I had always intuitively known, but failed to put into practice in my own classroom: spreading out review over time is much more effective than cramming it all into one session.</p><h5>More Research</h5><p>Since Ebbinghuas, several researchers have fleshed out this idea of the forgetting curve and spaced review.</p><p>To start, <a href="https://www.podsie.org/blog/spaced-practice-in-the-classroom/(https://pcl.sitehost.iu.edu/rgoldsto/courses/dunloskyimprovinglearning.pdf)" target="_blank" rel="noopener noreferrer">John Dunlosky, a professor of psychological sciences at Kent State University, and others broke down 10 different learning techniques</a>, including common practices like re-reading and highlighting, and found that spaced review was one of the most effective ways to learn and retain knowledge and skills.</p><p>Meanwhile, <a href="https://pcl.sitehost.iu.edu/rgoldsto/courses/dunloskyimprovinglearning.pdf" target="_blank" rel="noopener noreferrer">Sean Kang, a cognitive psychologist at the University of Melbourne, highlighted spaced review as a highly effective learning technique</a> that does not require more time and drastic changes to the classroom.</p><p>Specifically, he states:</p><blockquote><p>Incorporating spaced practice into education can be a cost-effective approachâ€” learning becomes more durable in the same amount of time (relative to massed practice), and this can lead to future savings because less time needs to be spent on relearning content that has been forgotten, leaving more time for other productive learning activities (e.g., higher order analysis, application of knowledge). <strong>In short, spaced practice enhances the efficacy and efficiency of learning, and it holds great promise as an educational tool.</strong></p></blockquote><p>In a different paper, <a href="https://scottbarrykaufman.com/wp-content/uploads/2014/01/Lindsey-et-al.-2014.pdf" target="_blank" rel="noopener noreferrer">Robert Lindsey, another research scientist and now the founder of Imagen Technologies, and others also assessed the efficacy of a computer program that personalized review for each student over time</a>. In this study, personalized spaced review improved retention by 16.5%!</p><p>The more research I read, the more I was perplexed â€”perplexed as to why I hadn't learned about this research-backed learning technique while I was teaching. I had sat through countless hours of professional development and undergone a long certification process, but I had never once heard about how to maximize learning in my classroom through spaced review.</p><p>Clearly, there was a gap between research and practical application, and I wanted to see if there was a way to fill that gap.</p><h5>Spacing in the Classroom</h5><p>So how would spaced review work in the classroom?</p><p>After I learned about spaced review, I shared it with my best friend, Chris, who is currently a science teacher in Texas. He also dug into the research and was excited to try it out in his classroom the next school year. He did a deep dive into all of the learning tools available to help him facilitate spaced review in the classroom. Most tools he came across seemed better suited for individual learners, and were not well-suited for the classroom.</p><p>Long story short, Chris and I decided to build out Podsie, a platform that fully automates spaced review in a personalized way for each student. With Podsie, Chris creates an exit ticket of around 5-8 questions that assesses the content that students learned that day. When students complete a question, the question goes into that student's personal deck.</p><p>Each student's personal deck is powered by a spacing algorithm that determines when the student should review a question again. Then, Chris gives his students 10 minutes in the beginning of class to complete every question that is due on their personal decks, ensuring that each student reviews exactly what they should be reviewing on that day.</p><p>With this approach, Chris no longer has to do the traditional cram session before state assessments. This year, even with distance learning, the spaced review has been so effective for him that he's decided to completely cut out that month of review that he also traditionally did. Like the quote from Sean Kang above predicted, spacing out review saved Chris a significant amount of time because "less time needs to be spent on relearning content that has been forgotten."</p><h5>Last Thoughts</h5><p>In Sean Kang's paper on spacing, he reflects:</p><blockquote><p>Despite over a century of research findings demonstrating the spacing effect, however, it does not have widespread application in the classroom. <strong>The spacing effect is â€œa case study in the failure to apply the results of psychological researchâ€� (Dempster, 1988, p. 627).</strong></p></blockquote><p>Podsie hopes to be that bridge between psychological research and the classroom.</p><p>We know this year has been extraordinarily challenging for everyone in the education system, and we hope that by providing an effective and efficient tool, each student and teacher's life can be made a little easier.</p><p><strong><em>If you're interested in using Podsie in your classroom to help with your students' retention of content, you can <a href="https://www.podsie.org/#sign-up">sign up here!</a></em></strong></p></div></div></div>]]>
            </description>
            <link>https://www.podsie.org/blog/spaced-practice-in-the-classroom/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25283013</guid>
            <pubDate>Wed, 02 Dec 2020 23:08:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using GitHub Issues as a Hugo Front End with GitHub Actions and Netlify]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25281958">thread link</a>) | @todsacerdoti
<br/>
December 2, 2020 | https://shazow.net/posts/github-issues-as-a-hugo-frontend/ | <a href="https://web.archive.org/web/*/https://shazow.net/posts/github-issues-as-a-hugo-frontend/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I got into the habit of dumping quick blog post ideas into issues on my blog’s repo. It’s a convenient place to iterate on them and share with friends for feedback before actually publishing on my blog post.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100761218-a6cb2280-33c0-11eb-92df-1b52d91cc16e.png" alt="image"></p><p>The drafts keep accumulating, how do I trick myself into publishing more? Perhaps by reducing the effort required for the next step? Let’s do it!</p><h2 id="architecture">Architecture</h2><p>My blog is statically generated using <a href="https://github.com/gohugoio/hugo">Hugo</a>, the <a href="https://github.com/shazow/shazow.net">code is hosted on Github</a>, then when a pull request comes in it is built, previewed, and published on merge by <a href="https://netlify.com/">Netlify</a>.</p><p>The blog post drafts are posted as Github issues, so there is a clear gap: How do we convert issues into pull requests for Netlify? Enter Github Actions!</p><h2 id="github-action-issue-to-pull-request">Github Action: Issue to Pull Request</h2><p>My <a href="https://github.com/shazow/shazow.net/blob/master/.github/workflows/publish.yml">full workflow lives here</a> if we want to jump ahead, but let’s break down the broad strokes.</p><p>I decided to trigger the publishing process once an issue is labelled with ‘publish’, so let’s start with that:</p><div><pre><code data-lang="yaml"><span>name</span><span>:</span><span> </span>Publish<span> </span>post<span> </span>from<span> </span>issue<span>
</span><span>
</span><span></span><span>on</span><span>:</span><span>
</span><span>  </span><span>issues</span><span>:</span><span>
</span><span>    </span><span>types</span><span>:</span><span> </span><span>[</span><span>'labeled'</span><span>]</span><span>
</span><span>
</span><span></span><span>jobs</span><span>:</span><span>
</span><span>  </span><span>build</span><span>:</span><span>
</span><span>    </span><span>if</span><span>:</span><span> </span>${{<span> </span>github.event.label.name<span> </span>==<span> </span><span>'publish'</span><span> </span>}}<span>
</span><span>    </span><span>runs-on</span><span>:</span><span> </span>ubuntu-latest<span>
</span><span>    </span><span>steps</span><span>:</span><span>
</span><span>      </span>...<span>
</span></code></pre></div><p>Next up we want to specify the steps, first thing is to check out the repository into the action’s environment:</p><p>Once the source code is available, we want to generate the blog post from the issue metadata. Here is a very basic version of this, though I ended up doing more tweaking in the end:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Generate<span> </span>Post<span>
</span><span>        </span><span>env</span><span>:</span><span>
</span><span>          </span><span>POST_TITLE</span><span>:</span><span> </span>${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>          </span><span>POST_BODY</span><span>:</span><span> </span>${{<span> </span>github.event.issue.body<span> </span>}}<span>
</span><span>        </span><span>run</span><span>:</span><span> </span><span>|
</span><span>          cat &gt; "content/posts/${POST_TITLE}.md" &lt;&lt; EOF</span><span>
</span><span>          </span>${POST_BODY}<span>
</span><span>          </span>EOF<span>
</span></code></pre></div><p>This shoves the body of the issue, which is already markdown, into a markdown file named based on the title of the issue. This is a good place to add frontmatter, or slugify the title, or whatever else your blog setup requires.</p><p>Running the payload through environment variables helps with not needing to escape various characters like `.</p><p>And finally, we make the pull request using Peter Evan’s create-pull-request action which makes this super easy:</p><p>This is the minimum of what we need, but we can specify all kinds of additional options here: like auto-deleting the branch, setting a custom title, body, and whatever else. Here’s an example of what I’m doing:</p><div><pre><code data-lang="yaml"><span>      </span>- <span>name</span><span>:</span><span> </span>Create<span> </span>Pull<span> </span>Request<span>
</span><span>        </span><span>uses</span><span>:</span><span> </span>peter-evans/<a href="https://shazow.net/cdn-cgi/l/email-protection" data-cfemail="3b58495e5a4f5e164b4e575716495e4a4e5e484f7b4d08">[email&nbsp;protected]</a><span>
</span><span>        </span><span>with</span><span>:</span><span>
</span><span>          </span><span>delete-branch</span><span>:</span><span> </span><span>true</span><span>
</span><span>          </span><span>title</span><span>:</span><span> </span><span>"publish: ${{ github.event.issue.title}}"</span><span>
</span><span>          </span><span>body</span><span>:</span><span> </span><span>|
</span><span>            Automagically sprouted for publishing.</span><span>
</span><span>            </span><span>Merging will publish to</span><span>:</span><span> </span>https<span>:</span>//shazow.net/posts/${{<span> </span>github.event.issue.title<span> </span>}}<span>
</span><span>            </span>Closes<span> </span><span>#${{ github.event.issue.number }}</span><span>
</span><span>          </span><span>reviewers</span><span>:</span><span> </span>${{<span> </span>github.repository_owner<span> </span>}}<span>
</span><span>          </span><span>commit-message</span><span>:</span><span> </span><span>"post: ${{ github.event.issue.title }}"</span><span>
</span></code></pre></div><h2 id="result">Result</h2><p>When my blog post draft is ready, I add the tag and the Github action takes it away, creating a pull request:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763017-a764b880-33c2-11eb-860f-5bab932ac558.png" alt="image"></p><p>The pull request automatically pings me as a reviewer, and includes a “Closes #X” line which will close the draft issue once the PR is merged. Very convenient!</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763219-ded36500-33c2-11eb-8387-ff28b6561875.png" alt="image"></p><p>Once the pull request is ready, Netlify takes it away, builds everything and generates a handy preview:</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100763300-fa3e7000-33c2-11eb-9172-206f58556ddd.png" alt="image"></p><p>I can make sure everything looks right, and even apply edits directly inside the pull request. This is another great step to send a long blog post for feedback, using all of the wonderful Pull Request Review features!</p><p>When all is said and done, merging the pull request triggers Netlify to publish my changes to my domain, and merging closes the original issue, and I’m done!</p><h2 id="bonus">Bonus</h2><p>Drag n’ drop images work in Github Issues, so it’s super easy to write a quick post with a bunch of screenshots or what have you.</p><p>It’s important to me that I’m not too tightly coupled to third-party services, so the pull request and code merge flow makes sure that all of the published state continues to live inside of my Git repository.</p><p>I can still make blog posts the way I used to: Pull the latest repo, write some markdown, and push to publish.</p><p>I added a little <a href="https://github.com/shazow/shazow.net/blob/master/frontmatterify">frontmatterify script</a> to process the incoming markdown and convert the remote Github Issue uploaded images into local images that are included in the pull request. The script also generates frontmatter that I use for Hugo. It’s a bit clunky but works for now.</p><p>Alright, let’s do this.</p><p><img src="https://shazow.net/posts/github-issues-as-a-hugo-frontend/100764184-11ca2880-33c4-11eb-8c84-e992765ace49.png" alt="image"></p></div></div>]]>
            </description>
            <link>https://shazow.net/posts/github-issues-as-a-hugo-frontend/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25281958</guid>
            <pubDate>Wed, 02 Dec 2020 21:35:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Topology to Classify Labelled Graphs]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25279820">thread link</a>) | @Topolomancer
<br/>
December 2, 2020 | https://bastian.rieck.me/blog/posts/2020/topology_graphs/ | <a href="https://web.archive.org/web/*/https://bastian.rieck.me/blog/posts/2020/topology_graphs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I have written at lengths about certain aspects of topological data
analysis, but I have neglected to discuss one of its main applications,
i.e. the classification of graphs. In this post, I will therefore take
you on a quick tour of our ICML paper <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">A Persistent Weisfeiler–Lehman Procedure for Graph Classification</a>.</p>
<p>Let us assume that we are given a graph with node label information. The
graph could, for instance, be a molecule, whose nodes are atoms such as
carbon or oxygen, and whose edges indicate chemical bonds. The goal
could now be to classify a given molecule into a set of classes, such as
‘toxic’, ‘carcinogen’, etc. How can we achieve such a classification?
One of the simplest techniques dates back to the 1960s and involves
calculating an <em>iterative fingerprint</em> of the graph! This procedure was
suggested by <a href="https://en.wikipedia.org/wiki/Boris_Weisfeiler">Boris Weisfeiler</a>
and Andrei Lehman&nbsp;(sometimes also transliterated as ‘Leman’) in
their seminal article <a href="https://www.iti.zcu.cz/wl2018/pdf/wl_paper_translation.pdf">The reduction of a graph to canonical form and the
algebra which appears therein</a>.</p>
<p>At its core, the algorithm is an iteration scheme that works like this:</p>
<ol>
<li>For a node $v$, collect its label and the labels of adjacent nodes in
a multiset.</li>
<li>Assign this multiset a new label by hashing it—with the proviso
that the hashing function is <a href="https://en.wikipedia.org/wiki/Perfect_hash_function"><em>perfect</em></a>, i.e.
it maps distinct labels to distinct values with no collisions.</li>
<li>Replace all node labels by their multiset hashes.</li>
</ol>
<p>Intuitively, each step of the algorithm accumulates more information
from nodes that are further removed from the current node. The hashed
multiset label is thus an expression of the neighbourhood around
a node—and after a sufficiently large number of iterations, the
hashed labels will not change any more.</p>
<p>For example, suppose you are dealing with this simple graph&nbsp;(to
prevent confusion of node labels and node IDs, I used <em>colours</em> to
indicate node labels in this example):</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_graph.svg" alt="Weisfeiler--Lehman example graph" height="128"> 
</figure>

</div>
<p>Tabulating the neighbourhood of each node then results in the following
table:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_1.svg" alt="Weisfeiler--Lehman multiset example (before hashing)" height="128"> 
</figure>

</div>
<p>Now for the hashing step. In this example, <em>perfect hashing</em> means
choosing a set of colours that is distinct for every distinct
combination of neighbourhood labels and vertex labels:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_table_2.svg" alt="Weisfeiler--Lehman multiset example (after hashing)" height="128"> 
</figure>

</div>
<p>Notice how nodes A, B, and G are hashed to the same colour—because
in the first iteration of the algorithm, they cannot be distinguished.
How can we use the information about the hashed labels in a subsequent
comparison task? The answer is lies in <em>counting</em> them in a histogram
vector, which is indexed by the unique labels—this is where our
requirement of the perfect hashing function is helpful. For the
previously-shown graph, it looks like this:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/weisfeiler_lehman_feature_vector.svg" alt="Weisfeiler--Lehman subtree feature vector" height="128"> 
</figure>

</div>
<p>The <em>fingerprint</em> of this graph, according to the first iteration of the
Weisfeiler–Lehman scheme is therefore $(3, 1, 2, 1)$. Further iterations
just make the feature vector longer&nbsp;(technically, the initial
labels already give rise to a feature vector of counts). This procedure
can now be repeated for higher-order iterations and the resulting
feature vectors can be compared across graphs by evaluating, for
example, their dot product. More formalisations of this idea have
resulted in the very successful <a href="https://www.jmlr.org/papers/volume12/shervashidze11a/shervashidze11a.pdf">Weisfeiler–Lehman Graph
Kernels</a>
publication. This method arguably constitutes the basis for graph neural
networks—in fact, these networks can be seen as a parametrised
version of the Weisfeiler–Lehman iteration scheme. But I digress—if
you are interested in these aspects, please read <a href="https://towardsdatascience.com/beyond-weisfeiler-lehman-approximate-isomorphisms-and-metric-embeddings-f7b816b75751">Michael Bronstein’s
article on going beyond graph
isomorphism</a>
for more details.</p>
<p>Now, despite its great practical utility, this feature vector is lacking
some <em>structural</em> information about the graph. It does not know whether
a certain label contributes much to the topological structure of
a graph—such as a ring of carbon atoms would in molecule—or not. To
this end, we introduced a notion of topological relevance for each node
label! Briefly put, we first developed a distance metric that would
permit us turn any <em>labelled</em> graph into a <em>weighted</em> graph. We then
calculate a persistence barcode, a topological descriptor of the graph.
This descriptor assesses the relevance of a topological feature created
by some node label. We use the topological relevance of each feature as
an additional <em>weight</em> for the previously-shown feature vector. In
essence, labels that contribute a large amount of topological structure
in a graph are assigned a higher weight than labels that only contribute
a meagre amount!</p>
<p>Here is a graphical depiction of our process:</p>
<div>
<figure>
    <img src="https://bastian.rieck.me/images/p_wl_pipeline.svg" alt="Persistent Weisfeiler--Lehman pipeline" height="128"> 
</figure>

</div>
<p>If you want to brush up your understanding of the barcode calculation,
head on over to <a href="https://christian.bock.ml/">Christian’s website</a>; he has
an <a href="https://christian.bock.ml/posts/persistent_homology">excellent article on persistent
homology</a>.</p>
<p>The neat thing about our approach is that we can easily integrate
information about <em>cycles</em> into the feature vector—this is
a functionality that the original Weisfeiler–Lehman Graph Kernels
Framework lacks. Moreover, these cycles turn out to be crucial in
improving classification performance—we get an increase of more than
3% in classification accuracy by considering them in some data sets!</p>
<p>If this has whet your appetite, I invite you to <a href="http://proceedings.mlr.press/v97/rieck19a/rieck19a.pdf">read our
paper</a> or <a href="https://github.com/BorgwardtLab/P-WL">take
a look at the code</a>. If you want
to learn more about graph classification using graph kernels, take
a look at our <a href="https://arxiv.org/abs/2011.03854">recent survey on graph kernels</a>,
which will hopefully be officially announced in time for NeurIPS 2020.
In the best tradition of Fermat, I would very much like to cover the
content of the survey here, but this blog is too small to contain all of
it—maybe for a subsequent post?</p>
<p>Until next time!</p>

      </div></div>]]>
            </description>
            <link>https://bastian.rieck.me/blog/posts/2020/topology_graphs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279820</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A founder’s guide to understanding users]]>
            </title>
            <description>
<![CDATA[
Score 184 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25279814">thread link</a>) | @mgadams3
<br/>
December 2, 2020 | https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44 | <a href="https://web.archive.org/web/*/https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2 id="9bcd">Four steps to ensure your customer discovery &amp; development efforts result in great products that solve real customer problems</h2><div><div><div><p><a href="https://medium.com/@mgadams?source=post_page-----c68feaecac44--------------------------------" rel="noopener"><img alt="Mike Adams" src="https://miro.medium.com/fit/c/96/96/1*Myw6S5WzM6_5PfbkyNAwUQ.jpeg" width="48" height="48"></a></p></div></div></div></div></div><div><div><p id="4ad5">When building any technology product, one of the most common pieces of advice is “talk to your users.”</p><p id="cec4">But the default way most of us talk to customers and prospects is unscientific and fraught with confirmation bias, putting us in danger of being lied to and wasting months building something nobody wants.</p><p id="ee5b">I learned this truth the hard way over the past decade founding multiple companies — but it wasn’t until I was working on my <a href="http://grain.co/utm_source=medium" rel="noopener">third startup</a> that I came to understand a better way to actually understand users.</p><p id="a218">When I first started building start-ups a decade ago, I never anticipated how applicable Yoda’s wisdom about the value of failure would be as a founder.</p><p id="3a5b">When I first started out, we had an idea, turned it into a UI, and hired developers to make it real. After nearly a year and tens of thousands of dollars — we launched it.</p><p id="d4d8">Ghost town. Crickets. Nobody wanted what we’d built.</p><p id="998b">I determined that the missing piece of the puzzle was my <a rel="noopener" href="https://mgadams.com/want-to-learn-to-code-start-with-excel-4f5902fb1b2f?source=collection_home---6------0-----------------------">lack of technical ability</a>, so I enrolled as one of the first dozen students at a now-famous<a href="https://www.hackreactor.com/" rel="noopener"> coding bootcamp</a> and actually got a job as a software engineer at a <a href="http://opentable.com/" rel="noopener">real company</a>.</p><p id="3b53">So surely when I started my <a href="https://twitter.com/missionu?lang=en" rel="noopener">next start-up</a>, this time things would be different. This time we talked to dozens of potential users and industry experts before we built anything. This time it worked. Sort of.</p><p id="d494">Our mission was compelling as we launched to <a href="https://www.inc.com/magazine/201806/leigh-buchanan/missionu-career-training-school.html" rel="noopener">fanfare</a> and raised <a href="https://techcrunch.com/2017/09/14/missionu-raises-8-5m-to-build-an-alternative-one-year-education-program/" rel="noopener">$11.5M</a> within 10 months of founding the company. However, after just two years we were acqui-hired, our investors got their money back, and the product was immediately <a href="https://www.insidehighered.com/digital-learning/article/2018/05/23/missionu-self-styled-alternative-higher-education-closes-after" rel="noopener">shut down</a>.</p><p id="6863">I was gutted, still am TBH.</p><p id="0f28">But with hindsight, I could look back to my original research notes and see I had ignored several fatal warnings. I had listened to what they said — exactly as they said it, but I did not realize until much later that I failed to actually understand what they meant.</p><p id="9305">So if I wanted to avoid failing a third time, I needed to figure out what I was missing about how to <em>really</em> understand users.</p><p id="9c98">Marty Cagan, Silicon Valley Product Group founder and former PM at early eBay, says there are “<a href="https://svpg.com/the-inconvenient-truth-about-product/" rel="noopener">two inconvenient truths about product</a>.”</p><p id="b881">Truth #1: <strong>At least half of our ideas are just not going to work</strong>:</p><p id="ed0c">Truth #2: <strong>Even the good ideas take several iterations to become viable.</strong></p><p id="3d8c">My experience has also been that there’s simply no escaping these inconvenient truths — I only wish I would have learned about them sooner.</p><p id="30d3">It doesn’t matter how smart or experienced we may be, statistically speaking, most of our ideas are simply not going to work. And the successful ones take time and hard work to turn into a real product that gets widely adopted by a market.</p><p id="de93">Your ideas are not nearly as important as your process — and the best process starts with understanding what the customers you wish to serve <em>already</em> do to solve their problems today and even more importantly, understanding why.</p><p id="9883">Yet, even as a 3rd time founder, I fell into the trap of ignoring the two inconvenient truths <em>again.</em></p><p id="87c7">Confirmation bias is a hell of a drug.</p><p id="f8b7">When we started <a href="http://grain.co/?utm_source=medium" rel="noopener">grain.co</a> two years ago, we began with a specific product solution in mind, built prototypes, and got feedback from users. They told us they’d love to use it but after months turning prototypes into a product, few actually did.</p><p id="a400">So we started over from scratch, but this time with a different approach:</p><ol><li id="2be7">Focus on a very specific user type with a very specific job to be done.</li><li id="bb56">Interview dozens of them only to understand how and why they solve their problem today.</li></ol><p id="0128">Our goal was not to validate whether the merit of a specific solution but to observe existing customer behaviors and desires as a means of generating new ideas for potential product solutions.</p><p id="3dec">This is what is known as <strong>generative research</strong>.</p><p id="4699">As you listen to your target market describe what they do today to solve their problems, you can better understand potential customers’ existing incentives, behaviors, and desires in anticipation for how they’d react to a new solution.</p><p id="331b"><a href="https://twitter.com/robfitz" rel="noopener">Rob Fitzpatrick</a> has famously coined this generative research phase “ <a href="http://momtestbook.com/" rel="noopener">The Mom Test</a>,” which is a set of simple rules to ask good questions so that even your Mom can’t lie to you in her answers to protect your ego.</p><p id="7e65">Generative research questions are focused on understanding existing behavior. For example, here are some questions from an interview guide we used at <a href="http://grain.co/" rel="noopener">Grain</a> to understand how our prospective users already document and share information from live meetings:</p><ul><li id="fcb3">What’s your current process to document and share information from a video meeting?</li><li id="fa1f">How important is it that the information you document and share is accurate?</li><li id="6568">What measures do you currently take to ensure accuracy of captured information?</li><li id="33f9">What can happen if your documentation is inaccurate?</li><li id="32f3">How often are you in conversations where you don’t need to document or share anything?</li><li id="cda6">Which types of conversations are the most important for you to document and share?</li></ul><p id="9e72">Be sure to avoid hypothetical questions about what people <em>might</em> do. Don’t try to validate your future product with questions that begin with “would you use this” or “what do you think about the possibility of” — that’s what we call leading the witness, and it will inevitably bias your data and waste your time building the wrong thing. At this stage, you simply need to observe what users are <em>already doing,</em> not what they might theoretically do.</p><figure><div></div></figure><p id="69d3">I recently connected with <a href="https://twitter.com/robfitz" rel="noopener">Rob</a> where he shared an updated model of 3 ways where users will lie to you if you’re not careful:</p><ol><li id="afa0">Asking the wrong questions</li><li id="6697">Remembering the wrong thing</li><li id="6a57">Making the wrong decision “justified” by what you think you heard</li></ol><p id="ecb1">Rob and most other researchers suggest asking for permission from their interviewees to record these interviews and take time-annotated notes that will help them to accurately remember and codify behavioral patterns that could eventually help to define <a href="https://www.uxmatters.com/mt/archives/2019/02/the-pitfalls-of-personas-and-advantages-of-jobs-to-be-done.php" rel="noopener">“jobs to be done”</a> that product, engineering, and design teams can build for with confidence.</p><p id="556d">After gaining insights about the problems your target market faces in generative research, you may be confident enough to test out a specific product solution to see if these users would actually value it.</p><p id="4717">This is the concept behind <strong>evaluative testing</strong>.</p><p id="f326">At this early stage, you want to put an <em>ultra-lightweight implementation </em>of a product solution in front of your target users to see how they react. While the closer to reality your prototype is the better, it doesn’t need to be a fully functional product yet: designs on paper, prototypes, mock-ups-anything like that will work.</p><p id="b1b0">Your goal at this stage is to get clear qualitative signals that users:</p><ol><li id="9f21">understand the proposed product solution</li><li id="fcda">express unmistakable excitement about the prospect of the product as a superior solution to the status quo</li></ol><p id="2033">Unfortunately, all too many product teams speed through this testing or skip it all together and simply march ahead to engineering and delivery. Depending on the complexity of the market and the problem you’re trying to solve, this stage could take months or, in some cases, years.</p><p id="d10d">That might sound discouraging and time-consuming, but I know this for certain: the success of your product will be <strong><em>directly proportiona</em>l</strong> to the quality of work done in this initial customer discovery phase. It’s worth doing it, and it’s certainly worth doing it well.</p><p id="0fd4">Even if your team creates something that people want, if customers can’t figure out how to use it, the product is dead in the water. This is why product teams conduct usability testing throughout the build process.</p><p id="ee09">The traditional approach to usability interviews is to set up a test environment, where we watch as a user navigates the product. An interviewer encourages a user to explain what they see, think, and observe. The interviewer also offers prompts for what the user might consider next if they get stuck using the product. Usability issues in the product become self-evident in most of these cases.</p><p id="8825">My friend <a href="https://medium.com/u/b2d49a9606e3?source=post_page-----c68feaecac44--------------------------------" target="_blank" rel="noopener">Behzod Sirjani</a>, has created a framework for conducting usability testing interviews where he recommends asking the participant about their:</p><ol><li id="084d">Expectation (about what will happen)</li><li id="4d83">Reaction (to what happens)</li><li id="64e1">Reflection (on the difference between 1 and 2)</li></ol><figure><div></div></figure><p id="ec98">A less scientific and more agile approach to identifying lower-hanging usability issues is concierge onboarding. In concierge onboarding, someone from your team guides — via video call is best — new users through setting up the product and answers the questions in real-time. Concierge onboarding helps the team member understand the steps users are asked to take and the ways those steps directly lead to value.</p><figure><div></div></figure><p id="2293">In a recent Zoom call with Behzod, he told me how at Slack it was essential to turn usability interviews into video highlights of moments of user struggle to help his team form a shared understanding of the problem and gain alignment around solutions that will actually work.</p><p id="5379">The best product teams never stop this work of generative and evaluative testing for new features. Even as their initial research and testing turns into a real product, they know the importance of creating a customer discovery and product delivery engine that never stops learning and growing.</p><p id="b7d9">It’s much more common for product teams to continually learn and discover from their existing users than it is for them to gather insights from completely unbiased non-users. But a balance between the two groups — existing and new — is ideal. New users can give you a better understanding of your initial product experience, and existing “power users” can offer you insights that come from living with a product for weeks or months.</p><p id="1af9">Great product teams develop long-standing relationships of trust with their most active users. You’ll often see the people on these teams setting up recurring feedback sessions to gain insight and listen to users’ concerns and ideas. The point of these interviews is to find out what’s delightful and what’s frustrating, what’s there and working well, and …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44">https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</a></em></p>]]>
            </description>
            <link>https://mgadams.com/the-founders-guide-to-actually-understanding-users-c68feaecac44</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279814</guid>
            <pubDate>Wed, 02 Dec 2020 18:46:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop slacking, start rocking: Why we built Rock for a distributed workforce]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25279417">thread link</a>) | @kenzofong
<br/>
December 2, 2020 | http://rock.so/stopslacking | <a href="https://web.archive.org/web/*/http://rock.so/stopslacking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <!-- split row one -->
      <div>
        <div>

          <!-- Row one -->
          <div>
            
            <div>
              <p>
                  <br><b>tl;dr</b> <i>Remote work is here to stay and the productivity tools that currently exist are not built for a more distributed workforce. With Rock, we're bringing together both synchronous and asynchronous ways of collaborating, so working with a distributed team becomes easier. <span><a href="#"><i></i> See how Rock works.</a></span></i>
                </p>
            </div>
            
          </div>

          <!-- Row one -->
          <div>
            
            <div>
              <div>
                <p>
                  <br>
                  <b>We are now in more meetings and work longer hours than ever before.</b> With <a href="https://time.com/collection/great-reset/5900753/rethinking-work-covid-19/">62% of people working from home</a> because of the pandemic -- the number of meetings has gone up 12.9%, the volume of emails has increased and workdays have grown 48 ½ minutes longer.
                </p>
                <p>
                  All of these distractions take up 40% of someone’s productive time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row two -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-1.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row three -->
          <div>
            
            <div>
              <div>
                <p>
                  There are different reasons why this has happened, but one of the main reasons is that the way we work hasn't really changed. When companies started shifting their workforce to a remote model, they took the tools they were already using (e.g. Slack, Zoom) and sent their employees home.
                </p>
                <p>
                  These tools are now being used in the same way they were used in the office, where most of the interaction happened in real-time.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row four -->
          <div>
            
            <div>
              <div>
                <h3>We're moving towards a more distributed way of working.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row five -->
          <div>
            
            <div>
              <div>
                <p>
                  A quick chat is now another Zoom meeting in a long succession of meetings and a tap on the shoulder is yet another Slack message that pulls you away from what you were doing.
                  This firehose of messages and meetings is not sustainable as it leads to <a href="https://www.cnbc.com/2020/07/28/remote-work-burnout-is-growing-as-coronavirus-pandemic-stretches-on.html">anxiety</a>, <a href="https://www.fastcompany.com/90554935/the-red-flag-signs-you-may-be-burning-out-while-working-from-home">burnout</a> and <a href="https://www.forbes.com/sites/bryanrobinson/2020/09/06/how-remote-workers-can-recognize-burnout-and-6-actions-to-take/?sh=64da6cf14326">pressure</a> to always be connected.
                </p>
                <p>
                  With a <a href="https://www.spglobal.com/marketintelligence/en/news-insights/latest-news-headlines/covid-19-driving-lasting-change-for-business-practices-it-spending-8211-451-survey-60716654">majority of companies</a> stating that remote work is here to stay, <a href="https://socketsite.com/archives/2020/10/nearly-12-million-square-feet-of-vacant-office-space-in-s-f.html">office footprints</a> being reduced dramatically and tech companies like Twitter telling their staff that they can <a href="https://www.washingtonpost.com/technology/2020/10/01/twitter-work-from-home/?arc404=true">work from home forever</a> some of these changes will become the new normal. Most people agree that whatever happens, companies will be way more distributed than they were before the pandemic.
                  One thing is for sure -- the communication &amp; collaboration tools that exist today just don't cut it.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row six -->
          <div>
            
            <div>
              <div>
                <h3>We need tools for a distributed workforce.</h3>
                
              </div>
            </div>
            
          </div>

          <!-- Row seven -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-2.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eight -->
          <div>
            
            <div>
              <div>
                <p>
                  <b>This is where <a href="http://rock.so/">Rock</a> comes in</b>. <a href="https://www.linkedin.com/in/liming/">Ming</a> and I started building Rock about a year ago to make it easier to shift towards a <a href="http://rock.so/about">more asynchronous way of working</a>. This way of working gives you <b>more control</b> over your workday, makes you <b>more productive</b> while <b>reserving face-to-face meetings</b> for the most important things. It's also ideally suited to a workforce that is more distributed.
                </p>
                <p>
                  With the right tools and mindset, working with your team becomes more like a <b>relay race</b>. Everybody knows what's going on, you can pick things up when you're ready, and work happens in a state of flow.
                </p>
              </div>
            </div>
            
          </div>

          

          <div>
            
            <div>
              <div>
                <p>
                  Rock combines real-time messaging and video calls with more asynchronous ways of communicating like <a href="http://rock.so/tasks">tasks</a>, <a href="http://rock.so/notes">notes</a>, and <a href="http://rock.so/files">files</a> and makes this available in <a href="http://rock.so/product">one space</a>. Because we combine these different types of communication, we make it easy for you to pick and choose the best way to interact with your team. We also work with Google Drive (and will work with Zoom and others soon) so it's easier to tap into your existing workflows.
                </p>
                <p>
                  When you <a href="http://rock.so/better-than-slack">compare Rock to Slack</a> you can easily see why we think Rock just works better for how work happens today.
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row nine -->
          <div>
            
            <div>
              <p>
                <h3>Rock empowers anyone to work from anywhere</h3>
              </p>
            </div>
            
          </div>

          <!-- Row ten -->
          <div>
            
            <div>
              <div>
                <p><img src="http://rock.so/assets/images/blog/stopslacking/images-slacking-3.svg" alt="slider image">
                </p>
              </div>
            </div>
            
          </div>

          <!-- Row eleven -->
          <div>
            
            <div>
              <div>
                <p>
                  It's our mission to <b>build tools to empower anyone to work from anywhere</b>. When this happens - companies are more diverse, job opportunities are not limited by location and we all meet less, while doing more.
                </p>
                <p>
                  We have a lot more to say and lots more to build. If you want to join us on this journey to bring some much needed balance to the way we work, check out the video below or try out <a href="https://web.rock.so/?utm_source=website&amp;utm_medium=blog&amp;utm_campaign=hello">Rock</a> today.
                </p>
              </div>
            </div>
            
          </div>

          

          

          <section>
            <div>
              
          <!-- box card section -->
          <div>
            <div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/async.svg" alt="async"></p><h4>Product <br> details</h4>
                  <p>
                    Key features and more details about Rock.
                    <a href="http://rock.so/product">Read more</a>
                  </p>
                </div>

              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/recruiting/cross-org.svg" alt="async"></p><h4>How Rock <br> Works</h4>
                  <p>
                    Videos and walkthroughs to get you ready to Rock.
                    <a href="http://rock.so/how-rock-works">Read more</a>
                  </p>
                </div>
              </div>
              <div>
                <div>
                  <p><img src="http://rock.so/assets/images/blog/zoom.svg" alt="async"></p><h4>Stop slacking, <br> start rocking.</h4>
                  <p>
                    Why Rock is better than Slack
                    <a href="http://rock.so/better-than-slack">Read more</a>
                  </p>
                </div>
              </div>
            </div>
          </div>
          <!-- box card section end -->


        </div>
      </section></div>

      
    </div></section></div>]]>
            </description>
            <link>http://rock.so/stopslacking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279417</guid>
            <pubDate>Wed, 02 Dec 2020 18:16:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An interactive simulation to explore the effect of luck in success]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25279213">thread link</a>) | @rameerez
<br/>
December 2, 2020 | https://rameerez.com/success-hard-work-vs-luck/ | <a href="https://web.archive.org/web/*/https://rameerez.com/success-hard-work-vs-luck/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

    



    <nav>
  

  <a href="https://rameerez.com/">
    <img src="https://rameerez.com/wp-content/themes/rameerez-yuuta/assets/images/rameerez-startup-studio-logo-border-white.svg" height="30">
  </a>

  

  
</nav>

    

    <section id="step-">
      
      
    </section>


    <section id="step-">
      <div>
        <div>
          <div>
            <div>
              <p>Entrepreneurs, athletes, artists, politicians, astronauts... there's one thing they all have in common: <b>success</b>. Most will say this is just the product of skill, hard work and dedication: <b>but is it really?</b></p>
              <p><a href="#step-" type="button" onclick="">Let's find out</a>
            </p></div>
          </div>
        </div>
      </div>
    </section>

    <section id="step-">
      <div>
        <div>
          <div>
            <div>
              
              <div id="random-self-explanation">
                <p>Let's take one random person as an example. <b>This will be you</b>.</p>
                <p>You will be represented by a random <b>🏋️ hard work score</b> (skill) and a random <b>🍀 luck score</b>. Your <b>🏆 total success</b> will be calculated as <span id="effort-impact"></span>% hard work and <span>0</span>% luck.</p>
              </div>
              <p><a type="button" id="toggle-random-self-btn" onclick="generateRandomSelf(); toggleRandomSelf();">Generate your random self</a>
            </p></div>
          </div>
        </div>
        
      </div>
    </section>


    <section id="step-">
      <div>
        <div>
          <p>But you're not alone in the world, aren't you? These are <b><span>0</span> more random people</b>, representing the rest of the population – the people you have to compete with. They have been randomly generated, just like you.</p>
        </div>

        

        

        
      </div>
    </section>

    <section id="step-">
      <div>
        <div>
          <div>
            <p>Okay, your peers seem pretty random, but... is there any pattern we can see? What if we sort all people by <b>🏆 total success</b> and look just at the top 10 performers?</p>
            <p><a href="#step-" type="button" onclick="sortAndUpdateSubjects()">Sort and reveal the top 10 people</a>
          </p></div>
        </div>
      </div>
    </section>

    <section id="step-">
      <div>
        <div>
          <div>
            <h2>The top 10 performers</h2>
            <p>These are the top 10 performers. Do you see <b>the pattern</b> among them? <a onclick="updateTopMetrics(); revealPattern(); ">Reveal the pattern</a></p>
          </div>
        </div>

        

        

        

        
      </div>
    </section>

    <section id="step-">
      <div>
        <div>
          <div>
            <div>
              <p>Top candidates have a <b>📈 very consistent good deal of luck</b>, even though luck only accounts for <span>0</span>% of the overall success.</p>
              <p>🙅‍♂️ <b>No one reaches the top by luck alone</b>: working hard is just a pre-requisite. Luck just stacks on top of hard work.</p>
              <p>Is this fair? What if we removed luck?</p>
              <p><a href="#step-" type="button" onclick="onRemoveLuck()">Discover what happens if we remove luck</a>
            </p></div>
          </div>
        </div>
      </div>
    </section>

    <section id="step-">
      <div>

        <div>

          <div>
            <h2>The top 10 performers <br>if luck was not considered</h2>
            <p>Imagine a world where luck was not even a concept and success was entirely determined by hard work alone. These would be the top 10 performers if luck was not considered.</p>
          </div>
        </div>

        <div>

          <div>
            <h3>Original top 10</h3>
            <ol>
                              <li>
                                    🥇&nbsp;
                  <span id="subject-sorted-2-0-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-0-id">0</span>)</span>
                </li>
                              <li>
                                    🥈&nbsp;
                  <span id="subject-sorted-2-1-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-1-id">0</span>)</span>
                </li>
                              <li>
                                    🥉&nbsp;
                  <span id="subject-sorted-2-2-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-2-id">0</span>)</span>
                </li>
                              <li>
                                    4.&nbsp;
                  <span id="subject-sorted-2-3-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-3-id">0</span>)</span>
                </li>
                              <li>
                                    5.&nbsp;
                  <span id="subject-sorted-2-4-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-4-id">0</span>)</span>
                </li>
                              <li>
                                    6.&nbsp;
                  <span id="subject-sorted-2-5-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-5-id">0</span>)</span>
                </li>
                              <li>
                                    7.&nbsp;
                  <span id="subject-sorted-2-6-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-6-id">0</span>)</span>
                </li>
                              <li>
                                    8.&nbsp;
                  <span id="subject-sorted-2-7-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-7-id">0</span>)</span>
                </li>
                              <li>
                                    9.&nbsp;
                  <span id="subject-sorted-2-8-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-8-id">0</span>)</span>
                </li>
                              <li>
                                    10.&nbsp;
                  <span id="subject-sorted-2-9-name"></span>
                  <span>(<span></span>#<span id="subject-sorted-2-9-id">0</span>)</span>
                </li>
                          </ol>
          </div>

          <div>
            <h3>Top 10 "no luck"</h3>
            <ol>
                              <li>
                                    🥇&nbsp;
                  <span id="subject-noluck-0-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-0-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    🥈&nbsp;
                  <span id="subject-noluck-1-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-1-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    🥉&nbsp;
                  <span id="subject-noluck-2-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-2-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    4.&nbsp;
                  <span id="subject-noluck-3-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-3-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    5.&nbsp;
                  <span id="subject-noluck-4-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-4-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    6.&nbsp;
                  <span id="subject-noluck-5-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-5-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    7.&nbsp;
                  <span id="subject-noluck-6-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-6-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    8.&nbsp;
                  <span id="subject-noluck-7-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-7-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    9.&nbsp;
                  <span id="subject-noluck-8-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-8-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                              <li>
                                    10.&nbsp;
                  <span id="subject-noluck-9-name"></span>
                  <span>(<span></span>#<span id="subject-noluck-9-id">0</span>)</span>
                </li>
                <!-- <div class="col-6 col-md my-0 my-md-5 tiny-subject-box">
                </div> -->
                          </ol>
          </div>

        </div>

        <div>
          <div>
            <p><span id="number-of-same-subjects">0</span> out of 10 of them are different people – <b>only <span id="number-of-different-subjects">0</span> remain the same</b> when we take luck out of the equation.</p>

            <p>For reference, these were original the top 10 performers:</p>
          </div>
        </div>

        

        
      </div>
    </section>


    <!-- <section id="step-" class="vertical-center">
      <div class="container">
        <div class="row">
          <div class="col-12 col-md-6 offset-md-3">
            <div class="text-center">
              <p>Or is it? Turns out as the number of people in the simulation increases, luck only becomes more and more important...</p>
              <p>Todo graph</p>
              <a href="#step-" type="button" class="btn-next btn btn-primary" onclick="">Is there anything we can do?</a>
            </div>
          </div>
        </div>
      </div>
    </section> -->

    <section id="step-">
      <div>
        <div>
          <div>
            <div>
              <p>While there's not much we can do to compensate this effect, this experiment allows to draw two key conclusions:</p>

              <ol>
                <li>You need to <b>🏋️ work at 100%</b> of your abilities to even stand a chance.</li>
                <li>You need to <b>🍀 maximize your luck</b> by maximizing the opportunities you're exposed to, if you want to get to the top.</li>
              </ol>

              <p>Another interesting observation is that successful people are probably not even aware of their own survivorship bias: they just feel it's all been hard work.</p>

              <p><a href="#step-" type="button" onclick="">How would you compare to others?</a>

            </p></div>
          </div>
        </div>
      </div>
    </section>

    <section id="step-">
      <div>
        <div>

          <div>
            <h2>You would have scored <span>0</span>/<span>0</span></h2>
            <p>You would have been more successful than <span>0</span>% of all people</p></div>
          </div>

          

          <div>

            <p>You only can maximize success in your life by maximizing opportunities, and do that by getting out there and making your voice heard.</p>

            <p>So go ahead and <b>share this thought experiment</b> – and make other people think, too.</p>
            
            
          </div>

          <div>

            <p><b>Check out the other products I make ✨</b></p>

            

            <p><b>Did you like this? Support my work 🎉</b></p>

            

            <!-- <input type="email" placeholder="newsletter" /> -->
          </div>

          

          

        </div>
      
    </section>

    <section id="step-">
      <div>
        <div>
          <div>
            <div>
              <p>This experiment is somewhat simplistic. There are a wide variety of factors we've simplified into "luck": health, family, country, environment...</p>

              <p>So, does luck really account for only 5% of total success – or is it really more? Play yourself with the numbers – or move on to the next step.</p>

              <p>

              <a href="#step-2">Re-play with a <span>0</span>% luck</a>
              <a href="#step-" type="button" onclick="">How would you compare to others?</a>
            </p></div>
          </div>
        </div>
      </div>
    </section>


    

    
    
    
    
    
    
    

  
</div>]]>
            </description>
            <link>https://rameerez.com/success-hard-work-vs-luck/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279213</guid>
            <pubDate>Wed, 02 Dec 2020 18:02:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Search speed metrics for any site on the web]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25279207">thread link</a>) | @Ask11
<br/>
December 2, 2020 | https://treo.sh/sitespeed | <a href="https://web.archive.org/web/*/https://treo.sh/sitespeed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Chrome UX Report dashboard</h2><p><img src="https://treo.sh/assets/files/_origin.494b8b5.png" alt="Chrome UX Report Logo"></p><p>Treo Site Speed is a fast and powerful<!-- --> <a href="https://developers.google.com/web/tools/chrome-user-experience-report/">Chrome UX Report (CrUX)</a> <!-- -->dashboard. It shows detailed historical data across form factors, connections, and locations.<br>Enter your website domain and see page experience metrics. Change filters and dive into details. Compare with your competitors. Make your website faster. Receive monthly updates.</p><div><div><div><div><h3>Core Web Vitals</h3><p>Access important page experience metrics without setup and tracking. Improving Core Web Vitals helps to improve your site's UX and<!-- --> <a href="https://developers.google.com/search/blog/2020/11/timing-for-page-experience">SEO</a>.</p><picture><source srcset="https://treo.sh/assets/files/web-vitals-1x.f7901b2.webp, https://treo.sh/assets/files/web-vitals-2x.0189378.webp 2x" type="image/webp"><img srcset="https://treo.sh/assets/files/web-vitals-1x.aceee56.jpeg, https://treo.sh/assets/files/web-vitals-2x.df26382.jpeg 2x" src="https://treo.sh/assets/files/web-vitals-2x.df26382.jpeg" alt="Monthly change of Core Web Vitals" width="510" height="294" loading="lazy"></picture></div></div><div><div><h3>Devices and Connections</h3><p>Filter metrics by a form factor or a connection type. And see how they change over time and on the map.</p><picture><source srcset="https://treo.sh/assets/files/connections-1x.7ff4f2e.webp, https://treo.sh/assets/files/connections-2x.792e62b.webp 2x" type="image/webp"><img srcset="https://treo.sh/assets/files/connections-1x.2e6b07d.jpeg, https://treo.sh/assets/files/connections-2x.b8542ac.jpeg 2x" src="https://treo.sh/assets/files/connections-2x.b8542ac.jpeg" alt="Treo Site Speed Connections Chart" width="510" height="385" loading="lazy"></picture></div></div></div><div><div><div><h3>Geography</h3><p>Filter metrics by country and make sure your web pages are always fast for all users. A fast website is an accessible website.</p><picture><source srcset="https://treo.sh/assets/files/geography-1x.6fcb0c7.webp, https://treo.sh/assets/files/geography-2x.f698aeb.webp 2x" type="image/webp"><img srcset="https://treo.sh/assets/files/geography-1x.edf263e.jpeg, https://treo.sh/assets/files/geography-2x.9d30cc2.jpeg 2x" src="https://treo.sh/assets/files/geography-2x.9d30cc2.jpeg" alt="Geographic distribution of Core Web Vitals" width="510" height="291" loading="lazy"></picture></div></div><div><div><h3>Monthly updates</h3><p>Receive an email with the latest site speed metrics for your website. A new dataset is published every second Thursday of every month.<!-- --> <a href="https://developers.google.com/web/tools/chrome-user-experience-report/bigquery/changelog">Learn more about CrUX updates <span>→</span></a></p></div></div><div><div><h3>Immediate access to terabytes of data</h3><p>Treo Site Speed uses the raw BigQuery data and caches it on many levels. To get one report, you would need to scan <strong>12 terabytes</strong>, which would cost <strong>$60</strong>. If you are interested in getting the same power (and much more) for your business – <br><a href="mailto:info@treo.sh?Subject=Treo%20CrUX%20API%20Access">contact us to get a quote (only for the Enterprise plan).</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://treo.sh/sitespeed</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279207</guid>
            <pubDate>Wed, 02 Dec 2020 18:02:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PTM – Page Table Manipulation from Usermode]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25279155">thread link</a>) | @DyslexicAtheist
<br/>
December 2, 2020 | https://back.engineering/01/12/2020/ | <a href="https://web.archive.org/web/*/https://back.engineering/01/12/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>

<div>

<hr>
<p>PDF Version (Best Version) can be downloaded here: <a href="https://githacks.org/_xeroxz/PTM/-/blob/master/PTM.pdf">PDF Download</a>.<br>
You can download the source from the open source repo here: <a href="https://githacks.org/_xeroxz/PTM">VDM Repo</a>.</p>

<hr>
<p>PTM is a Windows 10 C++ library that allows a programmer to manipulate all memory, physical, and virtual from user-mode. The project inherits an interface from VDM allowing the use of a physical memory read-write primitive to fuel this project. VDM is used solely to configure the page tables in such a way that PTM can manage them from user-mode. Once the page tables are configured for PTM VDM is no longer required. However, VDM can inherit an instance of PTM as a means to read and write physical memory. Both VDM and PTM work extremely well together and independently from each other.</p>

<hr>
<p>Page table manipulation is an extremely powerful primitive. One that allows groundbreaking projects to be created such as patching the kernel only in specific process-contexts, or mapping of a source process address space into a target process address space. PTM is a user-mode library that allows a programmer to manipulate page tables from user-mode on 64-bit Windows 10 systems. PTM does this by using VDM; a project designed to abuse vulnerable drivers exposing a physical memory read-write primitive (RWP) to elevate to arbitrary kernel execution. VDM is used to configure the page tables in such a way that they can be managed from user-mode without the need for VDM’s vulnerable driver being loaded into the kernel after initialization. PTM can then be used to get and set all levels of page table entries, translation linear virtual addresses from user-mode, map physical memory into virtual memory, and even create new page tables. PTM can also be used as a means to directly read and write physical memory, thus it can be used with VDM to leverage arbitrary kernel execution without the need of VDM’s vulnerable driver being loaded into the kernel.</p>

<hr>
<p>Paging is the concept of breaking memory into fixed-sized chunks called pages. Pages can be moved in and out of physical memory allowing for memory that is not accessed frequently to be moved to disk. In order for this to work, the CPU cannot directly interface with physical memory instead the CPU interfaces with virtual memory. Virtual addresses are translated to physical addresses using a set of tables called page tables. On a 64-bit system with the CPU in long mode, there are four layers of page tables: PML4(s), PDPT(s), PD(s), and lastly PT(s). All page tables are the same size (1000h bytes) unless configured otherwise. Each page table entry is eight bytes in size. This means that each table contains 512 entries (8 * 512 = 1000h). The last twelve bits of every virtual address is called the page offset and is an offset into a physical page. The page offset of a virtual address can be bigger than 12 bits depending on the paging structure configuration for a given virtual address. The length of the page offset field can be either 12 bits (physical page is 4kB), 21 bits (2MB physical page), or 30 bits (1GB page).</p>
<p><img src="https://imgur.com/IqB4B22.png"></p><p>In order to translate linear virtual addresses to linear physical addresses, the page tables must be traversed. As depicted in figure one, each virtual address space has its own PML4, the physical address of this table is stored in CR3.</p>

<hr>
<p>On Windows, the thread scheduler utilizes KPROCESS.DirectoryTableBase when scheduling threads. The KPROCESS structure is a substructure of the EPROCESS structure and contains DirectoryTableBase at offset 28h. A programmer using VDM can obtain the linear physical address of the PML4 of a process easily by DKOM’ing a desired process KPROCESS structure.</p>
<pre><code>kd&gt; dt !_KPROCESS ffffc38759d9e080
nt!_KPROCESS
   +0x000 Header           : _DISPATCHER_HEADER
   +0x018 ProfileListHead  : _LIST_ENTRY 
   +0x028 DirectoryTableBase : 0x00000001`15684000
   +0x030 ThreadListHead   : _LIST_ENTRY 
   +0x040 ProcessLock      : 0
   +0x044 ProcessTimerDelay : 0
   +0x048 DeepFreezeStartTime : 0
</code></pre><p>Once the physical address of the desired processes PML4 has been obtained the trick is interfacing with the paging structures. Although VDM allows reading and writing of physical memory, be aware that MmMapIoSpace cannot be used to map the paging structures into virtual memory. Drivers that use MmCopyMemory and ZwMapViewOfSection to interface with physical memory can however be used to directly manipulate the page tables. To properly support VDM which PTM inherits as a codebase, the project does not rely on the physical read and write primitive exposed from the driver. Instead PTM allocates its own set of page tables and inserts a PML4E into the current processes PML4 pointing at such tables. This allows a programmer to map physical memory at will into the current virtual memory address space, all from user-mode. In other words, once the tables are allocated and configured, there is no need for VDM anymore since the paging tables can be controlled entirely from user-mode.</p>

<hr>
<p>The translation look-aside buffer is a hardware-based cache that assists in translating linear virtual addresses to linear physical addresses. The TLB caches virtual to physical address translations, as well as other information like page access rights and cache type information. Although extremely important for efficiency, the TLB has made PTM an interesting challenge. For example, when physical memory is mapped into a virtual address space, page table entries will be inserted, or changed. This insertion or alteration of an existing page table entry may be of a cached entry in the TLB. This means that the effects applied to the page table entry will not be seen until the TLB entry for the given virtual page has been invalidated, along with the changes written to main memory. To counteract this, the CPU has an instruction that allows a programmer to invalidate a page table entry in the TLB’s cache. This instruction is called INVLPG and is a privileged instruction. It’s not something PTM can use since the library is designed to operate entirely from user-mode. Directly invalidating TLB is not the only way to invalidate entries. If a page fault occurs, the TLB invalidates entries for the given address that caused the fault (the address in CR2). This is an effective method for invalidating desired virtual addresses from user-mode but is extremely slow. Context switches do not inherently cause the TLB to flush, rather the PCID is changed to another PCID. This allows the TLB to retain entries from multiple address spaces and improve performance. However, yielding execution can invalidate TLB entries because the scheduler will reschedule the logical processor to execute somewhere else for some time, possibly filling the TLB with other entries and removing the ones that were previously cached.</p>
<h3 id="tlb_outrun"><a href="#tlb_outrun">TLB - Outrun</a></h3>
<hr>
<p>Although the TLB is an effective hardware-based cache, it cannot cache linear virtual addresses that have not been accessed before, this simple fact means a programmer can create a new linear virtual address every single time they would want to map a new physical page into virtual memory. This, however, is not a solid solution that works soundly on all modern CPUs. With the industry pushing forward with virtualization technology, the expansion of the TLB continues. Thus solely generating a new linear virtual address every time you would want to interface with a physical page is not a sound solution and is already unstable on most modern AMD chips. Instead combining this technique with other techniques is ideal.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>map_page(<span>void</span><span>*</span> addr) <span>-&gt;</span> <span>void</span><span>*</span>
{
	<span>++</span>pte_index;
	<span>if</span> (pte_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pde_index;
		pte_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pde_index <span>&gt;</span> <span>511</span>)
	{
		<span>++</span>pdpte_index;
		pde_index <span>=</span> <span>0</span>;
	}

	<span>if</span> (pdpte_index <span>&gt;</span> <span>511</span>)
		pdpte_index <span>=</span> <span>0</span>;

	<span>// insert paging table entries down here…
</span><span></span>	<span>//... (refer to PTM repo to see that code)...
</span><span></span>	<span>// returns the newly generated virtual address...
</span><span></span>	<span>return</span> <span>get_virtual_address</span>();
}
</code></pre></div><p>The code above generates a new linear virtual address that has not been accessed before. This linear virtual address points to the requests physical page in memory. This allows the programmer to circumvent the TLB by accessing new linear virtual addresses instead of trying to invalidate TLB entry of an existed and already cached page. This however has limitations since the code only provides 512^3 different possible virtual pages.</p>
<h3 id="tlb_benefit_of_the_doubt"><a href="#tlb_benefit_of_the_doubt">TLB - Benefit of The Doubt</a></h3>
<hr>
<p>Although outrunning the TLB is the fastest solution for mapping physical memory into virtual memory without needing to invalidate any TLB entries, it is not the most stable on modern hardware. Instead, a mixture of generating a new virtual address and an SEH try/except loop is preferred. By giving the new virtual address the benefit of the doubt that it has not been cached yet, an attempt to access the newly created page is performed. If the access is successful, the new linear virtual address is returned to the caller of ptm::ptm_ctx::map_page. However, if the access causes a page fault, the TLB invalidates the entries associated with this newly created linear virtual address. The except block then attempts to access the new page in a loop whilst yielding execution at each failure to access the new virtual address. This technique provides the most performant solution to dealing with the TLB from user-mode. This method guarantees that the linear virtual address generated is accessible before returning it to the caller.</p>
<div><pre><code data-lang="cpp"><span>auto</span> ptm_ctx<span>::</span>get_virtual_address() <span>const</span> <span>-&gt;</span> <span>void</span><span>*</span>
{
    <span>//...
</span><span></span>    
    <span>// start off by making sure that 
</span><span></span>	<span>// the address is accessible...
</span><span></span>	<span>__try</span>
	{
		<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value <span>=</span> <span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new_addr.value;
		<span>return</span> new_addr.value;
	}

	<span>// if its not accessible then the
</span><span></span>	<span>// TLB just invalidated its entry...
</span><span></span>	<span>__except</span> (EXCEPTION_EXECUTE_HANDLER)
	{
		<span>// loop until this new address is accessible…
</span><span></span>		<span>// do not return until this new virtual
</span><span></span>		<span>// address is accessible....
</span><span></span>		<span>while</span> (true)
		{
			<span>// try again to access the page again 
</span><span></span>			<span>// and it should return...
</span><span></span>			<span>__try</span>
			{
				<span>*</span>(std<span>::</span><span>uint8_t</span><span>*</span>)new…</code></pre></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://back.engineering/01/12/2020/">https://back.engineering/01/12/2020/</a></em></p>]]>
            </description>
            <link>https://back.engineering/01/12/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25279155</guid>
            <pubDate>Wed, 02 Dec 2020 17:56:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Poetry Link, a website for writing poetry collaboratively]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25278793">thread link</a>) | @jhedwards
<br/>
December 2, 2020 | https://www.poetry-link.com/about | <a href="https://web.archive.org/web/*/https://www.poetry-link.com/about">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
    	<p>Poetry link is a poetry website with a simple twist: every line of every poem can be used to either start
      or finish a new poem. When a line is used in this way, the original poem will be decorated with an arrow that
    links to the new poem. The new poem, likewise, will have an arrow on the borrowed line linking back to the source poem.</p>
      <p>Poetry on this website doesn't have to be ground-breaking or original. Anything you write here could be used
    as inspiration for someone else, and you are free to find a line you like and write something new with it.</p>
      <p>Please direct questions, comments or issues to poetry.link.website@google.com</p>
      <p>Please review the <a href="https://www.poetry-link.com/terms">terms of use</a> before posting.</p>
    </div>
  </div></div>]]>
            </description>
            <link>https://www.poetry-link.com/about</link>
            <guid isPermaLink="false">hacker-news-small-sites-25278793</guid>
            <pubDate>Wed, 02 Dec 2020 17:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vector 0.11 Release: K8s, ARC, and metrics collection]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25278771">thread link</a>) | @zhs
<br/>
December 2, 2020 | https://vector.dev/releases/0.11.0/ | <a href="https://web.archive.org/web/*/https://vector.dev/releases/0.11.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><li><div><p><a href="https://github.com/timberio/vector/pull/3099" target="_blank" title="View pull request..."><i></i> 3099</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Cleanup `list` command</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3190" target="_blank" title="View pull request..."><i></i> 3190</a></p></div><h4><span title="Filter to 'buffers' changes only">buffers</span><span title="Filter to 'sinks' changes only">sinks</span>Upgrade all VecBuffer sinks to allow setting `max_bytes`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3236" target="_blank" title="View pull request..."><i></i> 3236</a></p></div><h4><span title="Filter to 'socket source' changes only">socket source</span>Add max_length to UDP</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3151" target="_blank" title="View pull request..."><i></i> 3151</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'stdin source' changes only">stdin source</span>Instrument "stdin" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3241" target="_blank" title="View pull request..."><i></i> 3241</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Add received and invalid line events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3278" target="_blank" title="View pull request..."><i></i> 3278</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Provide error context on parse error</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3187" target="_blank" title="View pull request..."><i></i> 3187</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'kafka source' changes only">kafka source</span>Instrument "kafka" source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3300" target="_blank" title="View pull request..."><i></i> 3300</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3317" target="_blank" title="View pull request..."><i></i> 3317</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'prometheus source' changes only">prometheus source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3315" target="_blank" title="View pull request..."><i></i> 3315</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'syslog source' changes only">syslog source</span>Update instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3264" target="_blank" title="View pull request..."><i></i> 3264</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'http source' changes only">http source</span>Add internal events for `http` source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3351" target="_blank" title="View pull request..."><i></i> 3351</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Make sourcetype templatable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3254" target="_blank" title="View pull request..."><i></i> 3254</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'statsd source' changes only">statsd source</span>Add events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3345" target="_blank" title="View pull request..."><i></i> 3345</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'docker source' changes only">docker source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3312" target="_blank" title="View pull request..."><i></i> 3312</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'splunk_hec source' changes only">splunk_hec source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/2913" target="_blank" title="View pull request..."><i></i> 2913</a></p></div><h4><span title="Filter to 'data_dog_metrics sink' changes only">data_dog_metrics sink</span>Add DataDog's `distribution` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3327" target="_blank" title="View pull request..."><i></i> 3327</a></p></div><h4><span title="Filter to 'splunk_hec sink' changes only">splunk_hec sink</span>Add configuration for source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3337" target="_blank" title="View pull request..."><i></i> 3337</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Allow configuration of type field (#3300)</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3328" target="_blank" title="View pull request..."><i></i> 3328</a></p></div><h4><span title="Filter to 'humio_logs sink' changes only">humio_logs sink</span>Add source configuration to Humio sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3356" target="_blank" title="View pull request..."><i></i> 3356</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logplex source' changes only">logplex source</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3417" target="_blank" title="View pull request..."><i></i> 3417</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Add more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3421" target="_blank" title="View pull request..."><i></i> 3421</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'ansi_stripper transform' changes only">ansi_stripper transform</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3419" target="_blank" title="View pull request..."><i></i> 3419</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3418" target="_blank" title="View pull request..."><i></i> 3418</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3439" target="_blank" title="View pull request..."><i></i> 3439</a></p></div><h4><span title="Filter to 'aws_s3 sink' changes only">aws_s3 sink</span>Add additional canned ACLs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3434" target="_blank" title="View pull request..."><i></i> 3434</a></p></div><h4><span title="Filter to 'codecs' changes only">codecs</span><span title="Filter to 'console sink' changes only">console sink</span>Add "text" encoding for metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3436" target="_blank" title="View pull request..."><i></i> 3436</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'file source' changes only">file source</span>Even more instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3286" target="_blank" title="View pull request..."><i></i> 3286</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Rewrite parser, improve error handlings </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3476" target="_blank" title="View pull request..."><i></i> 3476</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'startup' changes only">startup</span><span title="Filter to 'shutdown' changes only">shutdown</span>Add events for starting, stopping, and reloading</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3502" target="_blank" title="View pull request..."><i></i> 3502</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add Heartbeat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3373" target="_blank" title="View pull request..."><i></i> 3373</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span><span title="Filter to 'compression' changes only">compression</span>Add support for gzip compression</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3475" target="_blank" title="View pull request..."><i></i> 3475</a></p></div><h4><span title="Filter to 'file sink' changes only">file sink</span>Sync all data before finishing</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3521" target="_blank" title="View pull request..."><i></i> 3521</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3486" target="_blank" title="View pull request..."><i></i> 3486</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket source' changes only">socket source</span>Add and unify events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3523" target="_blank" title="View pull request..."><i></i> 3523</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'regex_parser transform' changes only">regex_parser transform</span>Enhance instrumentation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3553" target="_blank" title="View pull request..."><i></i> 3553</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'grok_parser transform' changes only">grok_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3598" target="_blank" title="View pull request..."><i></i> 3598</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add the ability to store pod labels flat</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3602" target="_blank" title="View pull request..."><i></i> 3602</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Store pod labels flat by default, remove the switch</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3586" target="_blank" title="View pull request..."><i></i> 3586</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Add `file` label</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3582" target="_blank" title="View pull request..."><i></i> 3582</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add more `main` events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3593" target="_blank" title="View pull request..."><i></i> 3593</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3490" target="_blank" title="View pull request..."><i></i> 3490</a></p></div><h4><span title="Filter to 'wasm transform' changes only">wasm transform</span>Implement some UX improvements for WASM</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3610" target="_blank" title="View pull request..."><i></i> 3610</a></p></div><h4><span title="Filter to 'kuberentes platform' changes only">kuberentes platform</span>Adds new Helm template variable for podsLabels.</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3607" target="_blank" title="View pull request..."><i></i> 3607</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Multiline support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3577" target="_blank" title="View pull request..."><i></i> 3577</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tag_cardinality_limit transform' changes only">tag_cardinality_limit transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3554" target="_blank" title="View pull request..."><i></i> 3554</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'coercer transform' changes only">coercer transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3655" target="_blank" title="View pull request..."><i></i> 3655</a></p></div><h4><span title="Filter to 'http sink' changes only">http sink</span>Increase rate_limit_num to its maximum</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3690" target="_blank" title="View pull request..."><i></i> 3690</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span>Add a new options to control the auto concurrency limiter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3720" target="_blank" title="View pull request..."><i></i> 3720</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Fix TcpEventSent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3730" target="_blank" title="View pull request..."><i></i> 3730</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'swimlanes transform' changes only">swimlanes transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3699" target="_blank" title="View pull request..."><i></i> 3699</a></p></div><h4><span title="Filter to 'socket sink' changes only">socket sink</span>Add IPv6 supports</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3726" target="_blank" title="View pull request..."><i></i> 3726</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3782" target="_blank" title="View pull request..."><i></i> 3782</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'journald source' changes only">journald source</span>Enhance checkpoint errors with file name</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3812" target="_blank" title="View pull request..."><i></i> 3812</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'reduce transform' changes only">reduce transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3809" target="_blank" title="View pull request..."><i></i> 3809</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'dedupe transform' changes only">dedupe transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3807" target="_blank" title="View pull request..."><i></i> 3807</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'tokenizer transform' changes only">tokenizer transform</span>add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3846" target="_blank" title="View pull request..."><i></i> 3846</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Support `summary` statistic</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3725" target="_blank" title="View pull request..."><i></i> 3725</a></p></div><h4><span title="Filter to 'datadog_metrics sink' changes only">datadog_metrics sink</span>Support datadog `distribution` metric </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3850" target="_blank" title="View pull request..."><i></i> 3850</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Regularize internal event messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3824" target="_blank" title="View pull request..."><i></i> 3824</a></p></div><h4><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'security' changes only">security</span>Enable tls by default  for `papertrail` and `datadog_logs` sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3861" target="_blank" title="View pull request..."><i></i> 3861</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Improve retry error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3989" target="_blank" title="View pull request..."><i></i> 3989</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Accept more timestamp patterns in `to_timestamp`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4018" target="_blank" title="View pull request..."><i></i> 4018</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Include container_name in kubernetes_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3833" target="_blank" title="View pull request..."><i></i> 3833</a></p></div><h4><span title="Filter to 'gcp_stackdriver sink' changes only">gcp_stackdriver sink</span>Insert timestamp into stackdriver message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3778" target="_blank" title="View pull request..."><i></i> 3778</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>GraphQL client</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4075" target="_blank" title="View pull request..."><i></i> 4075</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_timestamp` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4090" target="_blank" title="View pull request..."><i></i> 4090</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `contains` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4092" target="_blank" title="View pull request..."><i></i> 4092</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `slice` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4093" target="_blank" title="View pull request..."><i></i> 4093</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `tokenize` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4020" target="_blank" title="View pull request..."><i></i> 4020</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add container_image and pod_node_name annotations</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4034" target="_blank" title="View pull request..."><i></i> 4034</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'socket sink' changes only">socket sink</span>Emit warning on incomplete UDP sent</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4170" target="_blank" title="View pull request..."><i></i> 4170</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `strip_ansi_escape_codes` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4188" target="_blank" title="View pull request..."><i></i> 4188</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha2` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4198" target="_blank" title="View pull request..."><i></i> 4198</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `sha3` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4215" target="_blank" title="View pull request..."><i></i> 4215</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'json_parser transform' changes only">json_parser transform</span>add field's value in warn message when failing to parse</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4236" target="_blank" title="View pull request..."><i></i> 4236</a></p></div><h4><span title="Filter to 'docker platform' changes only">docker platform</span>Added distroless-libc and distroless-static docker container bases</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4186" target="_blank" title="View pull request..."><i></i> 4186</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `parse_duration` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4032" target="_blank" title="View pull request..."><i></i> 4032</a></p></div><h4><span title="Filter to 'prometheus sink' changes only">prometheus sink</span>Add support for `summary` metric</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4049" target="_blank" title="View pull request..."><i></i> 4049</a></p></div><h4><span title="Filter to 'auth' changes only">auth</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'aws service' changes only">aws service</span>Add EKS Web Identity Support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4191" target="_blank" title="View pull request..."><i></i> 4191</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Initial GraphQL topology</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4288" target="_blank" title="View pull request..."><i></i> 4288</a></p></div><h4><span title="Filter to 'console sink' changes only">console sink</span>Improve error handling</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4220" target="_blank" title="View pull request..."><i></i> 4220</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>add `format_number` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4383" target="_blank" title="View pull request..."><i></i> 4383</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Bidirectional source/transform/sink GraphQL types</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4429" target="_blank" title="View pull request..."><i></i> 4429</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Improve error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4412" target="_blank" title="View pull request..."><i></i> 4412</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span><span title="Filter to 'sinks' changes only">sinks</span>Option to specify `quantiles`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4037" target="_blank" title="View pull request..."><i></i> 4037</a></p></div><h4><span title="Filter to 'security' changes only">security</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>add TLS settings to influxdb_logs and influxdb_metrics sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4068" target="_blank" title="View pull request..."><i></i> 4068</a></p></div><h4><span title="Filter to 'influxdb_metrics sink' changes only">influxdb_metrics sink</span>Add a tags configuration options to add user-defined tags</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4544" target="_blank" title="View pull request..."><i></i> 4544</a></p></div><h4><span title="Filter to 'debian platform' changes only">debian platform</span>Add vector user to adm in debian packaging</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/3557" target="_blank" title="View pull request..."><i></i> 3557</a></p></div><h4><span title="Filter to 'statsd sink' changes only">statsd sink</span>Support all socket types in statsd sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/3032" target="_blank" title="View pull request..."><i></i> 3032</a></p></div><h4><span title="Filter to 'sinks' changes only">sinks</span><span title="Filter to 'networking' changes only">networking</span><span title="Filter to 'compression' changes only">compression</span>Add compression level</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4182" target="_blank" title="View pull request..."><i></i> 4182</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Allow using custom selectors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4406" target="_blank" title="View pull request..."><i></i> 4406</a></p></div><h4><span title="Filter to 'aws service' changes only">aws service</span><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span><span title="Filter to 'auth' changes only">auth</span>Support assume_role with EKS web identity</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4580" target="_blank" title="View pull request..."><i></i> 4580</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>Rename "identifier_fields" to "group_by"</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4579" target="_blank" title="View pull request..."><i></i> 4579</a></p></div><h4><span title="Filter to 'reduce transform' changes only">reduce transform</span>"concat_newline" strategy merges using newline</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4586" target="_blank" title="View pull request..."><i></i> 4586</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Advanced container filtering</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4428" target="_blank" title="View pull request..."><i></i> 4428</a></p></div><h4><span title="Filter to 'remap transform' changes only">remap transform</span>Add `parse_url` function</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4164" target="_blank" title="View pull request..."><i></i> 4164</a></p></div><h4><span title="Filter to 'datadog_logs sink' changes only">datadog_logs sink</span><span title="Filter to 'networking' changes only">networking</span>Support datadog logs new HTTPS transport</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4385" target="_blank" title="View pull request..."><i></i> 4385</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span><span title="Filter to 'auth' changes only">auth</span>Basic auth support</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4174" target="_blank" title="View pull request..."><i></i> 4174</a></p></div><h4><span title="Filter to 'datadog service' changes only">datadog service</span>Added region configuration parameter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4408" target="_blank" title="View pull request..."><i></i> 4408</a></p></div><h4><span title="Filter to 'windows platform' changes only">windows platform</span>Correctly handle service restart</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4557" target="_blank" title="View pull request..."><i></i> 4557</a></p></div><h4><span title="Filter to 'statsd source' changes only">statsd source</span>Add support for all socket types</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4647" target="_blank" title="View pull request..."><i></i> 4647</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'internal_metrics source' changes only">internal_metrics source</span>Updated internal metrics names to match standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4481" target="_blank" title="View pull request..."><i></i> 4481</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span><span title="Filter to 'logfmt_parser transform' changes only">logfmt_parser transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4701" target="_blank" title="View pull request..."><i></i> 4701</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span><span title="Filter to 'metrics' changes only">metrics</span>Add `namespace` to `Metric` </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4734" target="_blank" title="View pull request..."><i></i> 4734</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Force daemonset to redeploy when configmap is updated</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4581" target="_blank" title="View pull request..."><i></i> 4581</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Topology added/removed GraphQL subscriptions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4652" target="_blank" title="View pull request..."><i></i> 4652</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API host metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4733" target="_blank" title="View pull request..."><i></i> 4733</a></p></div><h4><span title="Filter to 'logplex source' changes only">logplex source</span>annotate logs with query parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4751" target="_blank" title="View pull request..."><i></i> 4751</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Expose the performance related parameters</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4735" target="_blank" title="View pull request..."><i></i> 4735</a></p></div><h4><span title="Filter to 'reload' changes only">reload</span>Resolve port conflict in sinks</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4835" target="_blank" title="View pull request..."><i></i> 4835</a></p></div><h4><span title="Filter to 'kubernetes platform' changes only">kubernetes platform</span>Add the ability to set conatiner ports at vector-agent Helm chart</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4480" target="_blank" title="View pull request..."><i></i> 4480</a></p></div><h4><span title="Filter to 'aws_ec2_metadata transform' changes only">aws_ec2_metadata transform</span>Add internal events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4819" target="_blank" title="View pull request..."><i></i> 4819</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Adds optional file output to generator</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4831" target="_blank" title="View pull request..."><i></i> 4831</a></p></div><h4><span title="Filter to 'log_to_metric transform' changes only">log_to_metric transform</span>Add `namespace` option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4859" target="_blank" title="View pull request..."><i></i> 4859</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>display full error chain</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4884" target="_blank" title="View pull request..."><i></i> 4884</a></p></div><h4><span title="Filter to 'logdna sink' changes only">logdna sink</span>Support template syntax in hostname and tags field</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4881" target="_blank" title="View pull request..."><i></i> 4881</a></p></div><h4><span title="Filter to 'prometheus source' changes only">prometheus source</span>Add TLS and authentication options</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4873" target="_blank" title="View pull request..."><i></i> 4873</a></p></div><h4><span title="Filter to 'gcp_pubsub sink' changes only">gcp_pubsub sink</span>Add configurable endpoint</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4928" target="_blank" title="View pull request..."><i></i> 4928</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Kind/type for `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4836" target="_blank" title="View pull request..."><i></i> 4836</a></p></div><h4><span title="Filter to 'journald source' changes only">journald source</span>Restart journalctl on errors, save checkpoint on shutdown</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4998" target="_blank" title="View pull request..."><i></i> 4998</a></p></div><h4><span title="Filter to 'sources' changes only">sources</span>make scrape interval configurable</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4945" target="_blank" title="View pull request..."><i></i> 4945</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Humanized formatting for `vector top` metrics</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4958" target="_blank" title="View pull request..."><i></i> 4958</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Batch events processed total</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5002" target="_blank" title="View pull request..."><i></i> 5002</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Added batch subscriptions for component bytes and errors</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5004" target="_blank" title="View pull request..."><i></i> 5004</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API batch support + tests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5018" target="_blank" title="View pull request..."><i></i> 5018</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>API version + hostname queries</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4887" target="_blank" title="View pull request..."><i></i> 4887</a></p></div><h4><span title="Filter to 'kubernetes_logs source' changes only">kubernetes_logs source</span>Add PodIPs into Pod Metadata events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4999" target="_blank" title="View pull request..."><i></i> 4999</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>More debug info on more HTTP requests</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5026" target="_blank" title="View pull request..."><i></i> 5026</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>add internal option to ignore missing files</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5034" target="_blank" title="View pull request..."><i></i> 5034</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Edited a few vector top error messages</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4902" target="_blank" title="View pull request..."><i></i> 4902</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>compile-time program result type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5008" target="_blank" title="View pull request..."><i></i> 5008</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>support enum variants for function arguments</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5015" target="_blank" title="View pull request..."><i></i> 5015</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>use path arguments for `del` and `only_field` functions</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5039" target="_blank" title="View pull request..."><i></i> 5039</a></p></div><h4><span title="Filter to 'docker source' changes only">docker source</span>Renamed docker source to docker_logs</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5053" target="_blank" title="View pull request..."><i></i> 5053</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>expressions no longer return an option</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5074" target="_blank" title="View pull request..."><i></i> 5074</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Rename `version` -&gt; `versionString` in GraphQL schema</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5056" target="_blank" title="View pull request..."><i></i> 5056</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>undefined path or variable return null</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5016" target="_blank" title="View pull request..."><i></i> 5016</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add I/O (throughput) columns to `vector top`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5146" target="_blank" title="View pull request..."><i></i> 5146</a></p></div><h4><span title="Filter to 'file source' changes only">file source</span>Expire checkpoints</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5153" target="_blank" title="View pull request..."><i></i> 5153</a></p></div><h4><span title="Filter to 'kafka source' changes only">kafka source</span>Include kafka metadata as optional keys</h4></li><li><div><p><a title="View upgrade guide..." href="https://vector.dev/highlights/2020-11-26-0-11-upgrade-guide/"><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4918" target="_blank" title="View pull request..."><i></i> 4918</a></p></div><h4><span title="Filter to 'sampler transform' changes only">sampler transform</span>Add rating by `index`</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5095" target="_blank" title="View pull request..."><i></i> 5095</a></p></div><h4><span title="Filter to 'elasticsearch sink' changes only">elasticsearch sink</span>Support basic-auth credentials in endpoint configuation</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5171" target="_blank" title="View pull request..."><i></i> 5171</a></p></div><h4><span title="Filter to 'api' changes only">api</span> Allow querying transform outputs on transform components</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4615" target="_blank" title="View pull request..."><i></i> 4615</a></p></div><h4><span title="Filter to 'metrics' changes only">metrics</span>Expose internal metrics cardinality as a internal metric counter</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5218" target="_blank" title="View pull request..."><i></i> 5218</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add test for component links</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5204" target="_blank" title="View pull request..."><i></i> 5204</a></p></div><h4><span title="Filter to 'loki sink' changes only">loki sink</span>Allow tenant_id to be templatable on loki sink</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5059" target="_blank" title="View pull request..."><i></i> 5059</a></p></div><h4><span title="Filter to 'remap' changes only">remap</span>improve arithmetic type checking</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4699" target="_blank" title="View pull request..."><i></i> 4699</a></p></div><h4><span title="Filter to 'mongodb_metrics source' changes only">mongodb_metrics source</span>Renamed mongo metrics to new naming standards</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4681" target="_blank" title="View pull request..."><i></i> 4681</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Add `ConnectionOpen` gauge</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4806" target="_blank" title="View pull request..."><i></i> 4806</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sinks</h4></li><li><div><p><a title="View upgrade guide..."><i></i> breaking</a><a href="https://github.com/timberio/vector/pull/4833" target="_blank" title="View pull request..."><i></i> 4833</a></p></div><h4><span title="Filter to 'data model' changes only">data model</span>Use `namespace` field in metric sources</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4996" target="_blank" title="View pull request..."><i></i> 4996</a></p></div><h4><span title="Filter to 'shutdown' changes only">shutdown</span>Extend `Resource` to sources </h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5048" target="_blank" title="View pull request..."><i></i> 5048</a></p></div><h4><span title="Filter to 'cli' changes only">cli</span>Beautify reports of conflicting `Resource` usage</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5098" target="_blank" title="View pull request..."><i></i> 5098</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>add _total suffix to events</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/4922" target="_blank" title="View pull request..."><i></i> 4922</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Emit `FileOpen` in `file` sink and source</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5183" target="_blank" title="View pull request..."><i></i> 5183</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Incorrect Log Level Message</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5005" target="_blank" title="View pull request..."><i></i> 5005</a></p></div><h4><span title="Filter to 'config' changes only">config</span>Allow JSON and YAML config formats in addition to TOML</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5296" target="_blank" title="View pull request..."><i></i> 5296</a></p></div><h4><span title="Filter to 'observability' changes only">observability</span>Enable TLS subscription connections in vector top</h4></li><li><div><p><a href="https://github.com/timberio/vector/pull/5021" target="_blank" title="View pull request..."><i></i> 5021</a></p></div><h4><span title="Filter to 'pulsar sink' changes only">pulsar sink</span>introduce encoding schema and pulsar avro schema</h4></li></div></div>]]>
            </description>
            <link>https://vector.dev/releases/0.11.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25278771</guid>
            <pubDate>Wed, 02 Dec 2020 17:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Materialize Raises a $32M Series B]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25277511">thread link</a>) | @austinbirch
<br/>
December 2, 2020 | https://materialize.com/materialize-series-b/ | <a href="https://web.archive.org/web/*/https://materialize.com/materialize-series-b/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today we <a href="https://www.prnewswire.com/news-releases/materialize-raises-40-million-to-simplify-streaming-data-with-sql-and-speed-up-real-time-analytics-301180777.html">announced</a> that we raised a $32M Series B round of funding led by Kleiner Perkins. This follows a $8.5m Series A last year led by Lightspeed Venture Partners, bringing our total funding to-date to a little over $40 million. With our Series B, <a href="https://www.kleinerperkins.com/people/bucky-moore/" target="_blank" rel="noopener noreferrer">Bucky Moore</a> joins <a href="https://lsvp.com/?team=ravi-mhatre/" target="_blank" rel="noopener noreferrer">Ravi Mhatre</a> on our board of directors.</p>
<p>At Materialize, we believe that at every business it will soon be essential for all information to be always up-to-date. Whether it’s delivering personalized experiences, accurately identifying fraud, building predictive AI, or discovering new business opportunities, the ability to run complex queries on multiple streams of data and keep their answers up to date is critical to making better decisions about the changing world around us.</p>
<p>While the past decade has seen a groundswell in the adoption of streaming platforms, they are still too difficult to use. Current systems require users to make tradeoffs between dumbing down their queries, waiting for hours-long batch ETL pipelines to finish, or building and orchestrating sprawling microservices. We believe users should not have to make these tradeoffs.</p>
<p>Materialize’s mission is to make queries against streaming data simple. We support industry standard SQL: write queries with multi-way joins, correlated subqueries, and complex aggregations, and we’ll keep the answers always up to date for you. In a world where “real-time” has become an empty buzzword, Materialize provides answers that are up to date within milliseconds. All of this comes in <a href="https://materialize.com/docs/install/" target="_blank" rel="noopener noreferrer">a single binary</a> that is easy to install, easy to use, and easy to deploy. With Materialize, users can get interactive and always-up-to-date answers about their changing data using only their existing SQL skills.</p>
<p>While Materialize is a young company, it is built on top of the award winning Timely Dataflow project, spanning almost a decade of cutting-edge research on stream processing led by my co-founder Frank McSherry. Starting from this solid foundation, $40 million dollars of capital gives us the resources to build the no-compromise streaming database that lets every developer build streaming applications.</p>
<p>With this new round of funding, we are well equipped to deliver on <a href="https://materialize.com/blog-roadmap/" target="_blank" rel="noopener noreferrer">an ambitious roadmap</a>, including a fully-managed cloud service with tiered storage and replication. We’re also excited to continue work on broadening the suite of SQL tools that we support, as well as investing in a SQL optimizer, performance and benchmarking work, and in making Materialize more resilient and battle-tested. If you’re interested in working on any of these challenges, Materialize <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">is hiring</a> across the board.</p>
<p>And finally, while it is exciting to build Materialize, it has been even more exciting to see how Materialize is being used to build applications that previously would have required months of development, using just a few simple SQL queries. If you’re as excited about Materialize as we are, we’d love for you to get involved. <a href="https://materialize.com/quickstart/" target="_blank" rel="noopener noreferrer">Download</a> and try Materialize, try <a href="https://materialize.com/docs/katacoda/?intro-wikipedia" target="_blank" rel="noopener noreferrer">a demo</a> in your browser, <a href="https://join.slack.com/t/materializecommunity/shared_invite/zt-jjwe1t45-klG9k7V7xibdtqA6bcFpyQ" target="_blank" rel="noopener noreferrer">join the community</a> and say hello, or <a href="http://materialize.com/careers" target="_blank" rel="noopener noreferrer">apply</a> to join our growing team today!</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/materialize-series-b/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277511</guid>
            <pubDate>Wed, 02 Dec 2020 15:55:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rga: Ripgrep, but also search in PDFs, E-Books, Office documents, zip, tar.gz]]>
            </title>
            <description>
<![CDATA[
Score 627 | Comments 128 (<a href="https://news.ycombinator.com/item?id=25277280">thread link</a>) | @angrygoat
<br/>
December 2, 2020 | https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/ | <a href="https://web.archive.org/web/*/https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><small><time datetime="2019-06-16T00:00:00.000Z">Jun 16, 2019</time> • <a href="https://github.com/phiresky/blog/commits/master/posts/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg.md">Last Update <time datetime="2019-06-16T00:00:00.000Z">Oct 21, 2019</time></a></small></p><p><a href="https://github.com/phiresky/ripgrep-all">rga</a> is a line-oriented search tool that allows you to look for a regex in a multitude of file types. rga wraps the awesome <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> and enables it to search in pdf, docx, sqlite, jpg, zip, tar.*, movie subtitles (mkv, mp4), etc.</p><p><a href="https://github.com/phiresky/ripgrep-all"><img src="https://img.shields.io/badge/repo-github.com%2Fphiresky%2Fripgrep--all-informational.svg" title=""></a>
<a href="https://crates.io/crates/ripgrep-all"><img src="https://img.shields.io/crates/v/ripgrep-all.svg" title=""></a>
<a href="https://www.reddit.com/r/rustjerk/top/?sort=top&amp;t=all"><img src="https://img.shields.io/badge/concurrency-fearless-success.svg" title=""></a></p><h2 id="examples">Examples</h2><h3 id="pdfs">PDFs</h3><p>Say you have a large folder of papers or lecture slides, and you can’t remember which one of them mentioned <code>GRU</code>s. With rga, you can just run this:</p><div><pre>~$ rga "GRU" slides/
<span>slides/2016/winter1516_lecture14.pdf</span>
Page 34:   <span></span><span>GRU</span>                            LSTM
Page 35:   <span></span><span>GRU</span>                            CONV
Page 38:     - Try out <span></span><span>GRU</span>-RCN! (imo best model)

<span>slides/2018/cs231n_2018_ds08.pdf</span>
Page  3: ●   CNNs, GANs, RNNs, LSTMs, <span></span><span>GRU</span>
Page 35: ● 1) temporal pooling 2) RNN (e.g. LSTM, <span></span><span>GRU</span>)

<span>slides/2019/cs231n_2019_lecture10.pdf</span>
Page 103:   <span></span><span>GRU</span> [Learning phrase representations using rnn
Page 105:    - Common to use LSTM or <span></span><span>GRU</span>

</pre></div><p>and it will recursively find a string in pdfs, including if some of them are zipped up.</p><p>You can do mostly the same thing with <a href="https://pdfgrep.org/"><code>pdfgrep -r</code></a>, but you will miss content in other file types and it will be much slower:</p><div><p>Searching in 65 pdfs with 93 slides each</p><div><div><svg width="600" height="200" viewBox="0 0 600 200" version="1.1"><defs><clipPath id="recharts2-clip"><rect x="105" y="5" height="160" width="490"></rect></clipPath></defs><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="165" x2="595" y2="165"></line><g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="105" y1="171" x2="105" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="105" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="105" dy="0.71em">0</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="227.5" y1="171" x2="227.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="227.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="227.5" dy="0.71em">5</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="350" y1="171" x2="350" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="350" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="350" dy="0.71em">10</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="472.5" y1="171" x2="472.5" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="472.5" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="472.5" dy="0.71em">15</tspan></text></g><g><line type="number" orientation="bottom" width="490" height="30" x="105" y="165" stroke="#666" fill="none" x1="595" y1="171" x2="595" y2="165"></line><text type="number" orientation="bottom" width="490" height="30" x="595" y="173" stroke="none" fill="#666" text-anchor="middle"><tspan x="595" dy="0.71em">20</tspan></text></g></g></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="105" y1="5" x2="105" y2="165"></line><g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="31.666666666666668" x2="105" y2="31.666666666666668"></line><text type="category" width="100" orientation="left" height="160" x="97" y="31.666666666666668" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">pdfgrep</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="85" x2="105" y2="85"></line><text type="category" width="100" orientation="left" height="160" x="97" y="85" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (first run)</tspan></text></g><g><line type="category" width="100" orientation="left" height="160" x="5" y="5" stroke="#666" fill="none" x1="99" y1="138.33333333333334" x2="105" y2="138.33333333333334"></line><text type="category" width="100" orientation="left" height="160" x="97" y="138.33333333333334" stroke="none" fill="#666" text-anchor="end"><tspan x="97" dy="0.355em">rga (subsequent runs)</tspan></text></g></g></g><g><g><g><path name="pdfgrep" fill="#8884d8" width="469.41999999999996" height="42" x="105" y="10.333333333333334" radius="0" d="M 105,10.333333333333334 h 469.41999999999996 v 42 h -469.41999999999996 Z"></path></g><g><path name="rga (first run)" fill="#8884d8" width="72.27500000000003" height="42" x="105" y="63.66666666666667" radius="0" d="M 105,63.66666666666667 h 72.27500000000003 v 42 h -72.27500000000003 Z"></path></g><g><path name="rga (subsequent runs)" fill="#8884d8" width="2.2539999999999907" height="42" x="105" y="117" radius="0" d="M 105,117 h 2.2539999999999907 v 42 h -2.2539999999999907 Z"></path></g></g></g></svg><div><ul><li><svg width="14" height="14" style="display:inline-block;vertical-align:middle;margin-right:4px" viewBox="0 0 32 32" version="1.1"><path stroke="none" fill="#8884d8" d="M0,4h32v24h-32z"></path></svg><span>run time (seconds, lower is better)</span></li></ul></div></div></div></div><p>On the first run rga is mostly faster because of multithreading, but on subsequent runs (with the same files but any regex query) rga will cache the text extraction, so it becomes almost as fast as searching in plain text files. All runs were done with a warm FS cache.</p><h3 id="other-files">Other files</h3><p>rga will recursively descend into archives and match text in every file type it knows.</p><p>Here is an example directory with different file types:</p><pre><code>demo
├── greeting.mkv
├── hello.odt
├── hello.sqlite3
└── somearchive.zip
    ├── dir
    │&nbsp;&nbsp; ├── greeting.docx
    │&nbsp;&nbsp; └── inner.tar.gz
    │&nbsp;&nbsp;     └── greeting.pdf
    └── greeting.epub</code></pre><p>(see the actual directory <a href="https://github.com/phiresky/ripgrep-all/tree/master/exampledir/demo">here</a>)</p><div><pre>~$ rga "hello" demo/

<span>demo/greeting.mkv</span>
metadata: chapters.chapter.0.tags.title="Chapter 1: <span></span><span>Hello</span>"
00:08.398 --&gt; 00:11.758: <span></span><span>Hello</span> from a movie!

<span>demo/hello.odt</span>
<span></span><span>Hello</span> from an OpenDocument file!

<span>demo/hello.sqlite3</span>
tbl: greeting='<span></span><span>hello</span>', from='sqlite database!'

<span>demo/somearchive.zip</span>
dir/greeting.docx: <span></span><span>Hello</span> from a MS Office document!
dir/inner.tar.gz: greeting.pdf: Page 1: <span></span><span>Hello</span> from a PDF!
greeting.epub: <span></span><span>Hello</span> from an E-Book!
</pre></div><p>It can even search jpg / png images and scanned pdfs using OCR, though this is disabled by default since it is not useful that often and pretty slow.</p><div><pre>~$ # find screenshot of crates.io
~$ rga crates ~/screenshots --rga-adapters=+pdfpages,tesseract
<span>screenshots/2019-06-14-19-01-10.png</span>
<span></span><span>crates</span>.io I Browse All <span></span><span>Crates</span>  Docs v
Documentation Repository Dependent <span></span><span>crates</span>

~$ # there it is!
</pre></div><h2 id="setup">Setup</h2><p>Linux, Windows and OSX binaries are available in GitHub releases. See <a href="https://github.com/phiresky/ripgrep-all#installation">the readme</a> for more information.</p><p>For Arch Linux, I have packaged <code>rga</code> in the AUR: <a href="https://aur.archlinux.org/packages/ripgrep-all/"><code>yay -S ripgrep-all</code></a></p><h2 id="technical-details">Technical details</h2><p>The code and a few more details are here: <a href="https://github.com/phiresky/ripgrep-all">https://github.com/phiresky/ripgrep-all</a></p><p><code>rga</code> simply runs ripgrep (<code>rg</code>) with some options set, especially <code>--pre=rga-preproc</code> and <code>--pre-glob</code>.</p><p><code>rga-preproc [fname]</code> will match an <span>"<!-- -->adapter<!-- -->"</span> to the given file based on either it’s filename or it’s mime type (if <code>--rga-accurate</code> is given). You can see all adapters currently included in <a href="https://github.com/phiresky/ripgrep-all/tree/master/src/adapters">src/adapters</a>.</p><p>Some rga adapters run external binaries to do the actual work (such as pandoc or ffmpeg), usually by writing to stdin and reading from stdout. Others use a Rust library or bindings to achieve the same effect (like sqlite or zip).</p><p>To read archives, the <code>zip</code> and <code>tar</code> libraries are used, which work fully in a streaming fashion - this means that the RAM usage is low and no data is ever actually extracted to disk!</p><p>Most adapters read the files from a <a href="https://doc.rust-lang.org/std/io/trait.Read.html">Read</a>, so they work completely on streamed data (that can come from anywhere including within nested archives).</p><p>During the extraction, rga-preproc will compress the data with ZSTD to a memory cache while simultaneously writing it uncompressed to stdout. After completion, if the memory cache is smaller than 2MByte, it is written to a <a href="https://docs.rs/rkv/0.9.6/rkv/">rkv</a> cache. The cache is keyed by (adapter, filename, mtime), so if a file changes it’s content is extracted again.</p><h2 id="future-work">Future Work</h2><ul><li>I wanted to add a photograph adapter (based on object classification / detection) for fun, so you can grep for <span>"<!-- -->mountain<!-- -->"</span> and it will show pictures of mountains, like in Google Photos. It worked with <a href="https://pjreddie.com/darknet/yolo/">YOLO</a>, but something more useful and state-of-the art <a href="https://github.com/aimagelab/show-control-and-tell">like this</a> proved very hard to integrate.</li><li>7z adapter (couldn’t find a nice to use Rust library with streaming)</li><li>Allow per-adapter configuration options (probably via env (RGA_ADAPTERXYZ_CONF=json))</li><li>Maybe use a different disk kv-store as a cache instead of rkv, because I had some <a href="https://github.com/phiresky/ripgrep-all/blob/05835c1c42bc3575023a81e5494c5530078730fc/src/preproc_cache.rs#L30">weird problems</a> with that. SQLite is great. All other Rust alternatives I could find don’t allow writing from multiple processes.</li><li>Tests!</li><li>There’s some more (mostly technical) todos in the code I don’t know how to fix. Help wanted.</li><li>Other <a href="https://github.com/phiresky/ripgrep-all/issues">open issues</a></li></ul><ul><li><a href="https://pdfgrep.org/">pdfgrep</a></li><li><a href="https://gist.github.com/phiresky/5025490526ba70663ab3b8af6c40a8db">this gist</a> has my proof of concept version of a caching extractor to use ripgrep as a replacement for pdfgrep.</li><li><a href="https://gist.github.com/ColonolBuendia/314826e37ec35c616d70506c38dc65aa">this gist</a> is a more extensive preprocessing script by <a href="https://github.com/ColonolBuendia">@ColonolBuendia</a></li><li><a href="https://github.com/wofr06/lesspipe">lesspipe</a> is a tool to make <code>less</code> work with many different file types. Different usecase, but similar in what it does.</li></ul></div></div>]]>
            </description>
            <link>https://phiresky.github.io/blog/2019/rga--ripgrep-for-zip-targz-docx-odt-epub-jpg/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277280</guid>
            <pubDate>Wed, 02 Dec 2020 15:38:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Life of PII for Apache Kafka]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25277100">thread link</a>) | @Natasha_Fll
<br/>
December 2, 2020 | https://lenses.io/blog/2020/12/life-of-pii-data-masking-and-compliance-for-apache-kafka/ | <a href="https://web.archive.org/web/*/https://lenses.io/blog/2020/12/life-of-pii-data-masking-and-compliance-for-apache-kafka/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Several years ago when I was working on a big data project, I saw something a data engineer shouldn’t see. Curious to understand the level of detail in a new credit score dataset we’d received in our data lake, I queried it. I was surprised at how easily and suddenly my screen was flooded with the mortgage history, overdraft limits and year-end financial statements of my colleagues, and I felt deeply uneasy. 
</p><p>If I stumbled upon this data, how easy would it be for a malicious user to sell PII (personally identifiable information) data across the dark web? The kind of breach that has since lost trading licenses and slapped several organizations with fines for millions of dollars.</p><p>More recently, contracting at a large global financial services firm, my team encountered constant challenges getting our data projects signed off and into production. The biggest was meeting the maze of data compliance controls. 
</p><p>Asking for special dispensation was getting more difficult in a world of Dodd-Frank, MIFID II and post-financial crash. 
</p><p>Fast forward a few years, the level of regulation has increased, as has the need for engineering teams to continuously access real-time data.
</p><p>We knew that helping organizations meet data compliance for Apache Kafka should be one of our priorities. This would be with the following in mind:
</p><ul><li><p> <b>Responsiveness to real-time needs: </b>The likes of Apache Kafka are powerful Open Source streaming technologies, but we need rules in place to make them useful for business outcomes.</p></li><li><p> <b>
Design for a world of DevOps and DataOps:</b> This means introducing controls in a world of agile data management and data engineering.</p></li><li><p> <b>Flexibility to apply constant regulation updates</b> and change access controls to cover multiple regulatory frameworks, including SEC,<a target="_blank" href="https://lenses.io/blog/2020/04/how-you-can-keep-your-real-time-data-operations-on-the-right-side-of-gdpr-apache-kafka/"> GDPR</a>, CCPA, HIPAA etc.
</p></li><li><p> <b>Identifying (and mitigating) data risk:</b> Not all data carries the same impact and level of confidentiality. </p></li><li><p> <b>Passing audits without manual processes:</b> Helping speed up the reporting time of audits.</p></li></ul><p>For us this has been implemented as a Data Policy framework. 
</p><p>The framework is designed to cover data compliance and information security best practices for real-time data. 
</p><p>And although we often talk about protecting PII data, the Data Policies framework helps address data compliance more broadly.  For example, we give visibility over sales transactions whilst masking the order value from internal employees to meet insider trading compliance. 
</p><p>Here we outline the framework and the journey you can take to increase your compliance. </p><h2>Discovery of PII residing in Kafka</h2><p>As your Kafka adoption across teams and projects expands, it’s easy for data sources to proliferate. And to find yourself non-compliant at any moment.&nbsp;&nbsp;</p><p>Keeping track of information flowing through Apache Kafka will be especially important when it comes to conducting audits.&nbsp;&nbsp;</p><p>But Apache Kafka as a black box doesn’t make this easy.</p><p>This usually means weeks if not months of manual reporting and interviewing teams when it comes to a compliance audit.&nbsp;</p><p>This is the first problem we're addressing with our<a href="https://help.lenses.io/using-lenses/data/data-policies/"> Data Policies</a>.</p><p>We do this by intelligently keeping track of metadata across your Kafka Streams, no matter the serialization (CSV, <a target="_blank" href="https://lenses.io/videos/custom-serde-classes-google-protobuf-for-apache-kafka/">Protobuf </a>and custom proprietary formats).&nbsp;</p><p>It’s the same technology that powers our <a target="_blank" href="https://lenses.io/blog/2020/07/Why-new-Streaming-SQL-opens-up-data-platform/">SQL engine</a> to query data on the wire as well as our <a target="_blank" href="https://lenses.io/blog/2020/07/data-dump-real-time-data-catalog-apache-kafka/">data catalog</a>.&nbsp;</p><p>And it's presented as a data experience UI. Having a variety of ways to interface with data policies makes it easier to zoom in or out of topics and applications to see how they are interrelated, whether in a list or in a Topology as shown here:</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/4ZsimkLEYFBGwb0hyLIl42/e02f5ddd45be08a4bddc0b1c3fadb865/Data-Policies-Illustrations_04.png" alt="Data-Policies-Kafka"></p><p>Understanding how data is related allows us to define interesting fields that represent datasets. More on this later.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/MBUcR5AREioRWHA5pJKgl/cdddbeedf7492b1ce0e10424345b3dbc/data-policies-3.png" alt="data-policies-3"></p><p>This detection covers the datasets themselves (Kafka Topics or Elasticsearch Indexes) as well as the applications (this can be anything from your custom external producer/consumer applications and microservices, <a target="_blank" href="https://lenses.io/connect/">Kafka Connect connectors</a> or Lenses Streaming SQL applications).&nbsp;</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/4wamiKZYyHtyao58emzBA3/d29b392a067bf35e5254e1fd69a4fc0a/data_policies_kafka.png" alt="data policies kafka"></p><h2>Categorizing PII</h2><p>With your streaming data discovered, the next step is to classify the data.&nbsp;</p><p>We used the National Institute of Standards and Technology (NIST) and their <a target="_blank" href="https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-122.pdf">guidelines for protecting PII</a> to help.</p><p>This Ontology can be tuned to the specific business domain or data domain such as ‘crypto-assets’, a regulatory framework such as ‘MiCA’ and a confidentiality level.</p><h3>An example of Data Protection Ontology</h3><p><u>Name</u> : <i>Full Name, Maiden Name, Mother’s name, Alias</i></p><p><u>Personal Identification Information</u> :<i> SSN, Passport number, Driver’s license Number, TaxPayer identification number, Patient Identification Number, Financial Account, Credit Card Number, Login name / Username</i></p><p><u>Address Information</u> : <i>Street Address, Email Address, Zip Code, City, Country</i></p><p><u>Asset Information</u> : <i>IP Address, MAC Address</i></p><p><u>Telephone Number</u> : <i>Mobile, Business and Personal number</i></p><p><u>Personally owned property</u> : <i>Vehicle registration Number</i></p><p><u>Personal linkable Information</u> :<b> </b><i>Data of birth, age, place of birth, religion, race, weight, height, activities, geographical indicators, employment information, medical info, educational info, financial info</i></p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/3IG62VjzyLiRiO7Cgd1noF/9e3454ffd16519fa82178741bd3ebd91/data_policies_2__1_.png" alt="data protection ontology"></p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/7KlbbKO1ms1L1ZLraynI80/cf46bc21bc2bb6e3f962ac69a4b1c8b8/data_protection_ontology1.png" alt="data protection ontology1"></p><p>Of course, not all data have the same confidentiality impact level. Fields that can be used to fully identify a person (i.e. Passport or Social Security Number) have to be treated with additional care, whereas information like Country or Postcode can only partially reveal the identity of a subject.</p><p>Here we’ve highlighted data at different impact levels. Social Security Number is very high, whereas postcode is comparatively low.&nbsp;</p><p><code>SSN&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;high</code></p><p><code>Financial&nbsp;Account&nbsp;number&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;high</code></p><p><code>Biometric&nbsp;Records&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;high</code></p><p><code>Medical&nbsp;Information&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;high</code></p><p><code>Passport&nbsp;Number&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;high</code></p><p><code>Phone&nbsp;number&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;medium</code></p><p><code>Postcode&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;low</code></p><p><code>Religion&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;-&nbsp;low</code></p><p>The combination of the Data Policy impact level with the detected streams and applications helps risk managers and compliance officers ensure they apply the appropriate safeguards based on the confidentiality impact level.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/2S6rCLEvDuyjOfXDQeUrep/191a6e45b9779abe4dbb0756cad29161/data_policies_1__1_.png" alt="data policies ontology impact levels (1)"></p><h2>Data Masking &amp; PII confidentiality</h2><p>With data discovered and classified, the final step is to redact or anonymize data, so that users can access it whilst meeting compliance.</p><p>For many, this can be one of the biggest compliance challenges you will encounter whilst working with Kafka.&nbsp;</p><p>For Lenses, this is achieved through redaction rules associated with each Policy. </p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/1H7EA7ZDhImZ1K1cLzljR6/792b2c2f602504941683831c9787f061/data_redaction_policy_kafka.png" alt="data redaction policy kafka"></p><p>When data is accessed by a user that matches a Policy, we can automatically anonymize data.&nbsp;&nbsp;</p><p>Here are some examples of redaction policies and how they may mask fields within streaming data.&nbsp;</p><p>Policy&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sample Data &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; Sample Output</p><p>Initials Only &nbsp; &nbsp; &nbsp; &nbsp; Jon Smith&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; J S</p><p>First-3 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (212) 509-6995&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; (212) xxx-xxxx</p><p>Last-4&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 4111 4050 6070 8090 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xxxx xxxx xxxx 8090</p><p>Redaction &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 123 &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; xxx</p><p>Email Mask&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; myEmail@org.com &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; <a target="_blank" href="mailto:mxxxxx@org.com">mxxxxx@org.com</a></p><p>The masking is applied on-the-fly as opposed to redacting the data at rest or on the wire. This is a means of giving users access to data to meet any number of different compliance controls, whilst avoiding having to re-architect an application.</p><p><img src="https://images.ctfassets.net/tnuaj0t7r912/7G4vuR8IiuQSOi1482KsCV/4b8424332d34f7dd3b65df73fc77c0d6/data_masking__1_.png" alt="Lenses.io - Data masking for Apache Kafka"></p><p><b>Good data policies, rather than adding friction, actually open up data to those who can understand it and apply it.&nbsp;</b></p><p>As you can see from the rules in the examples above, data governance is not technology specific. It is not implemented - it is applied. 
</p><p>In fact, features like these are helping data engineers at heavily regulated firms:
</p><ul><li><p> <!-- -->Move their data projects from pilot to production
</p></li><li><p> <!-- -->Reduce their <a target="_blank" href="https://lenses.io/customers/viseca/">time-to-market by 10x
</a></p></li><li><p> <!-- -->Create policies that are easy to remember, and easy to apply
</p></li><li><p> <!-- -->Move forward with a technology-agnostic governance framework
</p></li></ul><p>We hope they do the same for yours.
</p><p>Curious to see how it works? You can watch this short example of meeting data compliance for streaming data including data masking:</p><p><iframe src="https://player.vimeo.com/video/443057175" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe></p><p>You can also see Data Policies in action in an all-in-one Kafka and Lenses environment as a Docker container or Cloud instance.&nbsp;Start <a target="_blank" href="https://lenses.io/start/">here</a></p></div></div>]]>
            </description>
            <link>https://lenses.io/blog/2020/12/life-of-pii-data-masking-and-compliance-for-apache-kafka/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277100</guid>
            <pubDate>Wed, 02 Dec 2020 15:21:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Against Netflix]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25277041">thread link</a>) | @leopold_a
<br/>
December 2, 2020 | https://www.forourposterity.com/against-netflix/ | <a href="https://web.archive.org/web/*/https://www.forourposterity.com/against-netflix/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


            <section>
                <div>
                    <p>It has become fashionable to lambast big tech corporations and social media sites, the Facebooks and Twitters and Googles, blaming them for a litany of social ills. Seemingly escaping this ire has been the—in my view—most pernicious by far: Netflix.</p><p>Simply put, Netflix (and its imitators) produce too many TV shows that are too good—and too easy to binge. Consequently, too many great minds spend their time watching TV rather than thinking and inventing and creating.</p><h2 id="the-greatness-we-lose">The Greatness We Lose</h2><p>Consider the writer Matthew Yglesias. He just wrote an excellent <a href="https://www.amazon.com/One-Billion-Americans-Thinking-Bigger/dp/0593190211/">book</a>, which partially inspired my <a href="https://www.forourposterity.com/canada-and-mexico-should-join-the-union/">last post</a>. Recently, Yglesias <a href="https://web.archive.org/web/20200912220900/https://twitter.com/mattyglesias/status/1304904789055156225">tweeted</a>:</p><blockquote>Someone asked … “how’d you get this book written without taking time off work?” and the dumb boring answer was basically “didn’t watch much TV for six months.”</blockquote><p>He adds,</p><blockquote>I am perfectly aware that the difference between times when I’m most productive &amp; creative and times when I’m not is how much of the week I waste on watching television, yet tonight I’m almost certainly going to finish season two of Hannibal.</blockquote><p>Yglesias, turn off the TV! Write more books instead! Heck, write more tweets, if you prefer!</p><p>Just think of all the original ideas Yglesias could be contributing if he continued to abstain from watching TV. Of them we are being robbed. That is an epic <a href="https://applieddivinitystudies.com/murder-of-wilbur/">tragedy</a>.</p><h2 id="why-modern-tv-is-different">Why Modern TV Is Different</h2><p>I don’t mean to pick on Yglesias. In fact, I don’t blame him. Modern shows are just too good. As a result, it’s become accepted—even the norm—among elite, educated classes to watch inordinate amounts of TV.</p><p>Modern shows are different from classic TV in two key ways. First, they are much more engrossing. Netflix shows are just on a different level in terms of quality than what TV once offered. Second, they are bingeable. Instead of tuning in for an hour each week, Netflix encourages viewers to enter the dark hole of watching episode after episode after episode. This becomes a vicious cycle. Viewers binge late into the night, lose sleep, and then don’t feel energetic enough to do much in their free time the next day besides…watching more Netflix.</p><p>Movies were always pretty engrossing. But the boundless quantity of content on Netflix—as well as their deliberate addictiveness—puts it on a different level.</p><p>To be sure, the broad America public has always watched <a href="https://www.theatlantic.com/technology/archive/2018/05/when-did-tv-watching-peak/561464/">extraordinary amounts</a> of television, in particular retirees. For them, the improved quality of modern shows is surely an upgrade. But I do think Netflix has distinctly changed the culture around TV among the young and educated.</p><p>As an undergraduate at Columbia, it was extremely common for students to spend much of their free time engorging themselves on Netflix. Many were caught in that maelstrom of bingeing, losing sleep, and then bingeing more. What was most shocking was this practice’s sheer acceptability. Watching dozens of hours of Netflix a week wasn’t something out of the ordinary, something people were embarrassed by. Rather, Netflix bingeing was a core part of the culture, something people would make countless memes about and base their identities on. Amazingly, people’s chief complaint was often that they had exhausted all of Netflix’s content (how do you even do that?!).</p><p>Yglesias got his start blogging in college. Would the next Yglesias be able to do the same? Or would his free time and energy instead be sucked up by the latest, ever-more addictive Netflix show? What a loss for civilization that would be.</p><h2 id="for-a-new-temperance-movement">For a New Temperance Movement</h2><p>Again, I don’t blame the students. I am victim to the same human follies. But I do blame the culture we have created. We don’t tell our bright young minds that it’s alright to waste away your days drinking or abusing drugs. Sure, some end up doing so regardless, but the cultural tabu keeps those impulses in check. Why do we tell them it’s alright to waste away your days watching Netflix?</p><p>Indeed, there has been considerable pushback against video games, which for some are a similar time suck. While many still struggle, this cultural pushback has kept video games in check. At least among the educated classes, Netflix and its imitators have become the far greater time suck.</p><p>For those who can enjoy TV in moderation—great. Modern shows are often meaningful art worth appreciating. The problem with modern TV is that for many, it is closer to alcoholism than a one-off drink. One you watch that first episode—take that first drink—it often doesn’t stay at one episode—as it doesn’t stay at one drink.</p><p>Perhaps it is time for a modern TV-temperance movement. It would be worth encouraging moderation in TV consumption in general. But given that many TV habits resemble alcoholism, it may be appropriate to take a more radical approach: advocating TV-abstinence. Although complete avoidance of TV may be difficult at first, once it becomes a habit, I think most wouldn’t miss much. But they would enjoy an abundance of reclaimed time and energy. And the rest of us would enjoy the wonderful works they create with that newfound time and energy.</p><h2 id="brains-in-vats">Brains in Vats</h2><p>The culture we establish around Netflix matters not just for the present, but for what comes next. As entertainment technology relentlessly advances, are we destined to become brains in vats, nominally pumped full of artificial bliss but doomed to lives of passivity and complacency?</p><p>Look, if that’s what the Europeans want to do, they should go for it. But part of what makes America special is a certain harshness—first embodied in the Puritans and their quest to settle America’s unforgiving wilderness. Great achievements, new ideas, ingenious inventions emerge from a culture that prizes travail and perseverance, not one that prioritizes comfort and ephemeral satisfaction.</p><p>A blithe acceptance of Netflix has insidiously infiltrated our culture. We should push back. Let’s look to the stars, not the next episode.</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to For Our Posterity</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>
              <h2><span id="cove-count"></span> Comments</h2>

    <p>Sign in or become a For Our Posterity member to join the conversation.<br>
    Just enter your email below to get a log in link.</p>
    

  


  


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.forourposterity.com/against-netflix/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25277041</guid>
            <pubDate>Wed, 02 Dec 2020 15:15:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Escape the Modern Rat Race]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 87 (<a href="https://news.ycombinator.com/item?id=25276844">thread link</a>) | @durmonski
<br/>
December 2, 2020 | https://durmonski.com/psychology/escape-the-modern-rat-race/ | <a href="https://web.archive.org/web/*/https://durmonski.com/psychology/escape-the-modern-rat-race/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
																					<div>
																										<p><span>Last updated:</span><time datetime="2020-11-30T06:06:37+00:00">30/11/2020</time></p>
<p><em>The worst thing about our modern culture is the growing ignorance towards what’s really valuable in the world. From an early age, we join a long-distance rat race where the competition is measured not by who we are, but by what we own. Therefore, the desire for material possessions and attention from our peers become our chief goals. Survival, it seems to us, is based on how well we portray our qualities to the outside world – even if we don’t necessarily possess them.</em></p>



<p>Living a normal life according to our society, even if we don’t always admit it, is tightly connected to the acquisition of funds. One of the most talked-about traits promoted by institutions regardless of our location is the value of money. Of course, this is not directly mentioned by the media outlets or by our neighbors, it’s beautifully camouflaged by what money can buy.</p>



<p>As soon as we understand that all breathing humans worship money and stuff, the sooner we start to desire <a href="https://durmonski.com/psychology/why-we-hate-cheap-things/" target="_blank" aria-label="luxury items (opens in a new tab)" rel="noreferrer noopener">luxury items</a>. Not so much because they are useful, but because these fancy goods make us look like we are more.</p>



<p>And so it happens, that directly after we come into being, these values and principles get embedded in our brains and later influence our decisions. We want better and more beautiful things. But most of all, we want others to <em>see</em> that we actually own these marvelous objects.</p>



<p>This game of competitive signaling has become unbearable only recently. When the number of available choices vastly increased and the way we communicate with others (compare ourselves with them) significantly improved.</p>



<p>In this post, we’ll look at why we’re stuck in this competitive rat race. Why the desire to acquire new things is never tamed and what we can do about it. </p>



<p>By bringing awareness to the problems, I want to liberate more people from the destructive components of this never-ending race to the bottom.</p>







<h2>What is Rat Race Life?</h2>



<p>A modern rat race categorizes as an endless pursuit – often quite exhausting – where you earn small rewards by conspicuous behavior reinforced by acquiring more financial gains or possessions – or both. However, these gains never feel satisfactory enough. As new things constantly appear on the horizon – new products and new competitors who are also part of the race – the only way we can stay ahead of the curve is by constantly investing resources in this rivalry.</p>



<p>In a way, participating in this vain competition is required. After all, our survival is tightly related to the tools, the resources we personally own, plus the relationship we form with others. That’s why we stay devoted to the race – because deep inside, our genes are focused on survival and replication.</p>



<p>That’s the general concept of the modern rat race. Or in the words of Tyler Durden, the protagonist in the masterpiece Fight Club, “We buy things we don’t need with money we don’t have to impress people we don’t like.” But to really grasp the reasons we commit to a life of struggle over resources, we need to go a step deeper.</p>



<p>Let’s unpack the modern rat race ideology further…</p>







<h2>Why and How The Rat Race Was Formed?</h2>



<p>The first reference of the expression rat race was used in the 1930s during aviation training. As stated by Popular Science magazine in 1941, ‘A rat race is … a simple game of “follow the leader.'”<span id="easy-footnote-1-12306"></span><span><a href="#easy-footnote-bottom-1-12306" title="&amp;#8220;<a aria-label=&quot;Rat-race (opens in a new tab)&quot; rel=&quot;noreferrer noopener nofollow&quot; href=&quot;https://www.etymonline.com/search?q=rat+race&quot; target=&quot;_blank&quot; class=&quot;ek-link&quot;>Rat-race</a>&amp;#8220;. Online Etymology Dictionary."><sup>1</sup></a></span> Or in other words, the expression meant that the trainee fighter pilot had to copy all the actions performed by the senior pilot. </p>



<p>A decade later, the term changed its original meaning.</p>



<p>Nowadays, the expression is more closely related to how we live our lives day by day. We don’t simply “follow the leaders”, we compete with them. We want to be like them. To have what they have and to eventually beat them in the game of resources.</p>



<p>This fierce rivalry for wealth is inspired and fueled by three main motivators:</p>







<h3>1. The Genes Want to Survive</h3>



<p>We, our actions, are highly influenced by the desires of the microorganisms that form our bodies – our genes. According to Richard Dawkins, the author of <a aria-label="The Selfish Gene (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/the-selfish-gene/" target="_blank">The Selfish Gene</a>, “the main goal of the body is to propagate copies of the genes which ride inside it.” To achieve this feat, the body is required to strictly follow two commands: survive and replicate.</p>



<p>There is nothing more important for the genes. We live to live another day and to copy ourselves.</p>







<h3>2. Universal Recognition of Money</h3>



<p>Different religions exist in different countries but we are all loyal to one and only lord – the money lord. Or as Yuval Noah Harari writes in his bestseller, <a aria-label="Sapiens (opens in a new tab)" rel="noreferrer noopener" href="https://durmonski.com/book-summaries/sapiens-a-brief-history-of-humankind/" target="_blank">Sapiens</a>, “Money is the most universal and most efficient system of mutual trust ever devised.”</p>



<p>During the years of our existence, we form a love-hate relationship with money. On the one hand, we hate it when we see people who are willing to do whatever it takes to earn more and to gain more power. We have movies, literature, songs, and words that mock the aggressive pursuit of more cash.</p>



<p>On the other hand, however, we adequately recognize the need for this resource. Since money is the currency that can literally save our lives from misery and decay, we have no other choice but to obey some sort of rules to gain more of this finite resource. Even so, while it surely exists, our desire to get more money is usually not directly expressed. Throughout our lives, we learn to successfully decoy our desire for wealth. That’s actually why money is a taboo subject.</p>







<h3>3. Technological Advancements</h3>



<p>High-tech gizmos and the internet greatly exceeded our expectations. These two innovations enabled us to connected like no other species.</p>



<p>At first, we used the Wi-Fi connection to send emails and to communicate better. Now, we use it to showcase our self-worth and to advertise our qualities to the whole world. All of this, done with the underlying desire to feel more desirable by others.</p>







<hr>



<p>The three above-mentioned notes can be portrayed in the following way:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg" alt="the-modern-rat-race" srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/the-modern-rat-race-1024x512.jpg"><figcaption>The cravings for money, survival, being appreciated by others is something we don’t verbally express. We show it by the stuff we obtain and the things we say/do.</figcaption></figure>







<p>Our inner eagerness to survive forces us to obtain money. And cash, supports our existence. But for most, the comfort of holding large chunks of capital in the bank is not enough. We also want to be seen as wealthy.</p>



<p>After all, just owning money is not enough to increase your chances of survival – meeting new friends that will help you along the way and also potential mates. That’s why, we’re also eager to parade with what we have.&nbsp;&nbsp;</p>



<p>Just as the peacock spreads its feathers to show its impeccable genes, we, through our actions and the things we acquire, show the world our features hoping that they’ll pick us. This our way of saying to others, “Look at me, my qualities and traits are so good that I can afford to spend $50,000 on a car. You should want to hang around with me.”</p>



<p>Our possessions are an advertisement, a way of showing off. They reinforce the image we desire to portray. And by going around and talking about ourselves, we want to signal to others – in a non-verbal way in most of the cases – why we are a worthy choice.</p>



<p>This is also called competitive signaling.</p>







<h2>What is Competitive Signaling?</h2>



<p>The way you spend your money can say a lot about how you want to position yourself in modern competition. </p>



<p>If you think carefully about everything before you buy it, and you’re not interested in high-end goods, your income is either average or you’re careless of what others think of you. In contrast, if you focus primarily on obtaining premium goods, you’re probably either rich or you want to be perceived as rich.<span id="easy-footnote-2-12306"></span><span><a href="#easy-footnote-bottom-2-12306" title="The last two are completely different things."><sup>2</sup></a></span></p>



<p>Thorstein Veblen, an American economist and sociologist, argued that the demand for luxury goods is driven largely by a single social motive: “flaunting one’s wealth.”</p>



<p>For example, Nissan is a car. It’s an average, not-flashy, automobile that will help you go from point A to point B, faster. Porsche, on the other hand, is an art museum on wheels. It can also get you from point A to point B, but while driving around town in this beast on wheels you radiate a completely different vibe. You present yourself as a modern, high-paid individual with taste and ambition. Figuratively speaking, the amount of cash that each of them has in the bank – the person owning a Nissan and the person owning a Porsche – can be exactly the same. On the outside though, they appear quite different.&nbsp;&nbsp;</p>



<p>The more interesting thing to consider, if say the individuals in the above example really do have the same amount of cash stashed, is how they approach buying domestic goods – a set of dishes, blankets, or say cleaning products. Since these goods are not to be seen by others, they both, even the person owning a sports car, will most probably end up getting the same cheap things.<span id="easy-footnote-3-12306"></span><span><a href="#easy-footnote-bottom-3-12306" title="This, of course, says a lot more things about their personality. For example, you can have an average income and still get a flashy car. But then, the things that are not visible by others will probably be average to compensate. Conversely, if you&amp;#8217;re <em>really</em> rich, you&amp;#8217;ll probably buy luxury domestic goods, too."><sup>3</sup></a></span></p>



<p>With this, we can conclude that the available products on the market are a mix of personal value and signaling value.</p>



<p>The car you have is simultaneously a way to move faster in the city and also a representation of your hierarchy in the world. Each product on the market, nowadays, comes with these qualities.</p>



<p>And if we can put this in a graph, it will look something like this:</p>



<figure><img width="1024" height="512" src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg" alt="luxury-goods-vs-useful-goods" srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201024%20512'%3E%3C/svg%3E" data-lazy-srcset="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg 1024w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-300x150.jpg 300w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-770x385.jpg 770w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1536x768.jpg 1536w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-566x283.jpg 566w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1151x575.jpg 1151w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1481x740.jpg 1481w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-274x137.jpg 274w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-751x376.jpg 751w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1381x691.jpg 1381w, https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods.jpg 2000w" data-lazy-src="https://durmonski.com/wp-content/uploads/2020/11/luxury-goods-vs-useful-goods-1024x512.jpg"><figcaption>Above the line the products don’t get more useful, they do something else. Luxury goods help you display, publicly, your wealth. The “scientific term” for this is conspicuous consumption.<span id="easy-footnote-4-12306"></span><span><a href="#easy-footnote-bottom-4-12306" title="<a aria-label=&quot;Conspicuous consumption (opens in a new tab)&quot; href=&quot;https://en.wikipedia.org/wiki/Conspicuous_consumption&quot; target=&quot;_blank&quot; rel=&quot;noreferrer noopener nofollow&quot; class=&quot;ek-link&quot;>Conspicuous consumption</a>, Thorstein Veblen"><sup>4</sup></a></span></figcaption></figure>







<p>At some point, certain products become a beacon of your self-worth. If you want to signal to others that you have more money, which internally means that you want to show that you’re smarter, slimmer, better than others in a way, you’ll eventually lean towards goods that are considered a luxury.</p>



<p>The extra you’re paying for a Porche, for example, has more to do with the message you want to convey to others, not with the usefulness of the product itself.<span id="easy-footnote-5-12306"></span><span><a href="#easy-footnote-bottom-5-12306" title="We all know that Porche is certainly a great vehicle. But there are still cheaper alternatives that will do the same job in terms of helping you move from point A to point B."><sup>5</sup></a></span></p>



<p>You might be …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://durmonski.com/psychology/escape-the-modern-rat-race/">https://durmonski.com/psychology/escape-the-modern-rat-race/</a></em></p>]]>
            </description>
            <link>https://durmonski.com/psychology/escape-the-modern-rat-race/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276844</guid>
            <pubDate>Wed, 02 Dec 2020 14:55:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Many Customers Does a Successful Side Hustle Need? Just 99]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25276662">thread link</a>) | @i-dont-remember
<br/>
December 2, 2020 | https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/ | <a href="https://web.archive.org/web/*/https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-pane"><div><p>The founding stories of big tech companies get people pumped on the idea of starting their own thing, from <a href="https://en.wikipedia.org/wiki/Software_as_a_service" title="https://en.wikipedia.org/wiki/Software_as_a_service">SaaS</a> products to <a href="https://trends.vc/trends-0036-paid-newsletters/" title="https://trends.vc/trends-0036-paid-newsletters/">paid newsletters</a> . The concept sounds awesome. Build something, it picks up speed, and swiftly grows into a multi-million dollar company. It’s a crazy success story, you’re set for life! Silicon Valley has no shortage of examples to be gawked at: AirBnb, Amazon, Dropbox, Facebook, Google, Netflix, etc which all exploded in the last 15 years.</p><p>Once you start trying to create it, though, odds are your idea is not a runaway success. There are ideas where the problem is so important, so valuable, so sticky to businesses that you can give them the worst pile of garbage in the world and they will fork over bajillions of dollars. If you are in that camp and pulling in cash is as easy as drinking water, stop reading, this isn’t for you.</p><p>Getting users is really freakin’ hard. Getting customers who will pay you to use your idea is even harder. When you’re struggling to acquire new users, it’s frustrating to look at the big tech companies and realize they have millions, if not billions of users. How are you ever supposed to convince that many people your idea is awesome, but you’re struggling to get just 10.</p><p>Divorce yourself from the notion you need to match those giant tech companies. How many customers does it actually take to support one person? Is it a million? 100,000? 10,000? Try 99.</p><p>I’ll back it up with the math in a second, but for now, think about how awesome this is. 99 is an achievable number. You know more than 99 people on a first-name basis. You’ve waited in lines longer than 99 people! But, I’m just some guy on the internet saying this. Heck, for all you know I’m not actually a person, this is just a <a href="https://www.theverge.com/2020/8/16/21371049/gpt3-hacker-news-ai-blog" title="https://www.theverge.com/2020/8/16/21371049/gpt3-hacker-news-ai-blog">pile of words GPT-3 thinks sound nice together</a>. So let’s break it down and see how you only need 99 people’s support to make a drastic change to your life.</p><h2 id="assumptions--definitions">Assumptions &amp; Definitions</h2><p>Assumptions first. I’ll be calculating this for one person, but it should scale up if you have a team. When it comes to making money, I see several inflection points of Monthly Recurring Revenue (MRR).</p><ol><li>$1</li><li><strong>Beer Money (BM) MRR</strong> - $100</li><li><strong>Rent MRR</strong> - $1,000</li><li><strong>College Grad (CG) MRR</strong> - $5,000</li><li><strong>Magical (MA) MRR</strong> - $10,000</li></ol><p>Stage 1, you’ve made your first dollar. Somebody out there thinks your idea doesn’t suck. Celebrate this, it’s a big achievement! One caveat for your dollar, it does <strong>NOT</strong> count if it came from your mom.</p><p>At <strong>Beer Money MRR</strong>, you are making $100 every month. You have cracked the 3 digit barrier, and can buy a lot of beer/wine/cheese/whatever without feeling too guilty about your budget.</p><p><strong>Rent MRR</strong> is where things get good, this is $1,000 a month. In some places this isn’t enough to live on by itself, but it is life-changing money no matter where you are. It likely covers all or a good chunk of your rent, hence the name. If you are poo-pooing me for saying $1k MRR is a big deal, you should get your head out of your ass and look at the rest of the world outside your bubble.</p><p><strong>College Grad MRR</strong> is $5k a month. This is $60k a year, which is near the average for a college graduate in the U.S. and more importantly, the math is easy when it divides nice. No calculators needed to read this article!</p><p><strong>Magical MRR</strong> is the last stop for this train. This is $10k a month, which is a <strong>TON</strong> of money. You’ll have taxes and expenses and junk, but to have people paying you $120k a year to use your idea must feel fantastic. I call it magical because $10k gets thrown around a lot in indie hacker articles &amp; community as a magic number to reach.</p><h2 id="show-me-the-money">Show Me the Money!</h2><p>Ok we have some definitions locked in, now we’ll go through 2 product examples: <strong>Product A</strong> at $10 and <strong>Product B</strong> at $50, again keeping the math easy. This could be a <a href="https://en.wikipedia.org/wiki/Software_as_a_service" title="https://en.wikipedia.org/wiki/Software_as_a_service">SaaS</a> charging monthly, an eBook, a course, paid newsletter, whatever. We’re looking per month, so the specifics of what is pulling in the dough don’t matter for this article. I took a couple liberties to knock off 1 sale here and there to keep it to 2 or 3 digits, because seeing those inflection points is what inspires me personally. Only 2 digits of people? I can do that.</p><p><strong>Product A, $10:</strong></p><p><strong>BM =</strong> 10 people</p><p><strong>Rent =</strong> 99 people is all it takes</p><p><strong>CG =</strong> 500 people</p><p><strong>MA =</strong> 999 people a month need to feel like your idea is worth it</p><hr><p><strong>Product B, $50:</strong></p><p><strong>BM =</strong> 2 people</p><p><strong>Rent =</strong> 20 people is all it takes</p><p><strong>CG =</strong> 99 people</p><p><strong>MA =</strong> 200 people a month need to feel like your idea is worth it</p><p>You can reach a life changing amount of money from your side hustle, and you need to convince less than 1,000 people that what you do/create/build is worth it. It’s often thrown around that you need <a href="https://kk.org/thetechnium/1000-true-fans/" title="https://kk.org/thetechnium/1000-true-fans/">1,000 true fans</a>, or as the math would suggest, just 99. Out of <a href="https://www.worldometers.info/world-population/" title="https://www.worldometers.info/world-population/">7.8 billion</a> humans, you only need 99 in your corner to break the threshold to <strong>Rent MRR</strong>. It’s still a large group of people, don’t get me wrong. I would be terrified to give a speech to that crowd, but it’s small enough you can comprehend it. To make it even easier, let’s do some visualizations and connect these numbers to concrete concepts in our lives. Recognizing a connection with something you already know helps it feel achievable.</p><h3 id="20-people">20 People</h3><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>At some point in your life, you’ve been in a class greater than 20 people.</p><p>Your extended family gatherings are close to this many people.</p><p>You’ve likely been forced to give a presentation to <em>at least</em> this many listeners.</p><h3 id="99-people">99 People</h3><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>You’ve waited in lines longer than 99 people.</p><p>This is a small lecture hall, mostly full.</p><p>You could reasonably have a short conversation with 99 different people over the course of a day.</p><h3 id="200-people">200 People</h3><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️ - 🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️🙅‍♂️</p><p>A couple hundred people could fit in a crowded bar or a conference presentation.</p><p>You can know the names and faces of 200 people with very little effort.</p><p>The majority of you have <a href="https://brandongaille.com/17-great-facebook-friend-statistics/" title="https://brandongaille.com/17-great-facebook-friend-statistics/">more than 200 friends on Facebook</a>.</p><p>If you’ve ever worked in a customer facing job, you’ve probably talked to more than 200 people in one shift!</p><h3 id="500-people">500+ People</h3><p><a href="https://blog.lime.link/visualizing-crowd-sizes/" title="https://blog.lime.link/visualizing-crowd-sizes/">This article</a> gives a great rundown of audience sizes from 50 to 100k people, and it’ll have to cover for the 500+ user visualizations. I won’t make you look at another 1499 emoji people. Okay, just one more. This is you making something awesome for all these people 👩‍💻 .</p><h2 id="the-real-world">The Real World</h2><p>The real world can be brutal when theories come into contact with it. It’s easy for me to sit here and talk about how you only need 99 customers to change your world, but you want to see something to back it up and show it still rings true out in the wild. Luckily, there are a lot of companies that share their stats as a part of being <a href="https://trends.vc/trends-0015-open-startups/" title="https://trends.vc/trends-0015-open-startups/">Open Startups</a>, many listed at <a href="https://openstartup.dev/" title="https://openstartup.dev/">https://openstartup.dev/</a> and <a href="https://baremetrics.com/open-startups" title="https://baremetrics.com/open-startups">https://baremetrics.com/open-startups</a>. You can also find great interviews on <a href="http://starterstory.com/" title="http://starterstory.com">starterstory.com</a>, where they go in-depth on how people started their businesses and their current revenue. Diving into a few data points from Nov 2020:</p><p>$1.3k : 124 users - <strong>Grip</strong> <a href="https://grip.baremetrics.com/" title="https://grip.baremetrics.com/"><em>https://grip.baremetrics.com/</em></a></p><p>$5.3k : 49 users - **Friendly **<a href="https://friendly.baremetrics.com/" title="https://friendly.baremetrics.com/"><em>https://friendly.baremetrics.com/</em></a></p><p>$7.0k : 144 users - <strong>Bannerbear</strong> <a href="https://www.bannerbear.com/open/" title="https://www.bannerbear.com/open/"><em>https://www.bannerbear.com/open/</em></a></p><p>$7.6k : 513 users - <strong>Simple Analytics</strong> <a href="https://simpleanalytics.com/open" title="https://simpleanalytics.com/open"><em>https://simpleanalytics.com/open</em></a></p><p>$9.0k : 479 users - <strong>Software Ideas</strong> (Paid reports/newsletter) <a href="https://softwareideas.baremetrics.com/" title="https://softwareideas.baremetrics.com/"><em>https://softwareideas.baremetrics.com/</em></a></p><p>$11k : 728 users - <strong>Hypefury</strong> <a href="https://hypefury.baremetrics.com/" title="https://hypefury.baremetrics.com/"><em>https://hypefury.baremetrics.com/</em></a></p><p>. . . . and then a crazy one</p><p>$<strong>133k</strong> : 871 users - **Baremetrics **<a href="https://demo.baremetrics.com/" title="https://demo.baremetrics.com/"><em>https://demo.baremetrics.com/</em></a></p><p>These companies are in all sorts of industries, they all have less than 1,000 users, and yet are making at minimum <strong>Rent MRR.</strong> While most of the Open Startups I listed are SaaS products built by developers, don’t be discouraged if you are non-technical or not interested in building software. There are examples out there of people growing non-technical products like ebooks, courses, newsletters, and more to sustain their livelihood if you take the time to look. Starter Story, mentioned above, is a collection of interviews &amp; ideas built up to <a href="https://www.starterstory.com/open" title="https://www.starterstory.com/open">$18k MRR in ~2 years</a>. Twitter and <a href="https://www.indiehackers.com/" title="https://www.indiehackers.com/">Indie Hackers</a> are great sources if you need even more inspiration.</p><h2 id="find-99-people-that-love-you">Find 99 people that love you</h2><p>If you haven’t gathered yet, the takeaway from all this is you don’t need to gun for crazy scale like the Facebooks of the world. You can aim to just support yourself. Find your true fans, as Kevin Kelley calls them in his essay <a href="https://kk.org/thetechnium/1000-true-fans/" title="https://kk.org/thetechnium/1000-true-fans/">1000 true fans</a>, and create for them.</p><p>This is not to trivialize the work needed to get to $100 MRR , or 10 users that love your product. It’s hard to get users. But making your vision more achievable helps keep the fire burning. It feels different pulling in the 1st of 99 people than the 1st of 100,000. So go forth and make something, you have the power and the global reach of the internet at your disposal. Go find 99 people that love your idea enough to pay you for it, and …</p></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/">https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/</a></em></p>]]>
            </description>
            <link>https://kevinquinn.fun/blog/how-many-customers-does-a-successful-side-hustle-need-just-99/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276662</guid>
            <pubDate>Wed, 02 Dec 2020 14:35:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Cybersecurity Escape Room]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25276033">thread link</a>) | @atum47
<br/>
December 2, 2020 | https://eloeffler.gitlab.io/eloeffler/proto-vcser/ | <a href="https://web.archive.org/web/*/https://eloeffler.gitlab.io/eloeffler/proto-vcser/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="indexgreeter">
    
<p>    Marwin Mueller, age 65, owns Spass GmbH. An SME in Luzern which has an annual turnover of close to 1.000.000 CHF and an annual profit of 200.000 CHF.  </p>
<p>    Spass GmbH has been operating in the hospitality industry for the last 30 years and is managing renouned hotels and villas in the Luzern Lake area.  </p>
<p>    Anne Kingston, age 29, is Marwins assistant and accountant. She has joined a year back and during her interactions, she mentioned to Marwin that she is a single mom of a six year old boy named Ryan.  </p>
<p>    Anne is a pleasant and helping personality. She likes plants and playing video games.  </p>
<p>    Marwin is very proud of his business achievements and sometimes acts as an arrogant boss. He is a bit insensitive to kids, due to his experiences. In general, he gets along with Anne and they form a great team at Spass. In the past year, Anne took over most of the office tasks at Spass. She is technology savvy and Marwin likes this quality of Anne's over his other staff.  </p>
<p>    Marwin and Anne worked on important digital initiatives at Spass like listing its properties on booking portals, creating their own website, launching social media accounts and enabling online banking at UBC Bank in Luzern.  </p>
<p>    This gave Marwin an edge over his competitors and Spass has seen a 30% increase in revenues and profits this year.  </p>
<p>    Today, Marwin remembers that two weeks back, Anne came to him and wanted a 1 week vacation to spend time with her son Ryan on occasion of his birthday.  </p>
<p>    Once again, Marwin and Anne had arguments on Anne's vacations in peak season and Marwin blamed Ryan for this.  At the end, Marwin reluctantly agreed to the holidays.</p>
<p>Since then, Anne did not turn up for work. She is not reachable on her mobile and her house is locked.</p>
<p>Marwin has just found that his bank account is debited with 2.000 CHF every day since Anne left.</p>
<p>Marwin has no idea what is happening and he is worried. Therefor, as trusted friends, he has requested that you come here and help him.</p>
<p>Marwin believes it is not a good idea to report the incident immediately to the police or bank as it can damage his reputation.</p>
<p>Now it's Friday. It's 7pm and the UBC Bank is already closed for the weekend.</p>
<p>You need to analyze the gaps Anne might have in her Cybersecurity awareness and secure the Online Banking to stop the money transfers.</p>
<p>Also, try to find out where Anne might be.</p>
<p>All the very best.
  </p></div></div>]]>
            </description>
            <link>https://eloeffler.gitlab.io/eloeffler/proto-vcser/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25276033</guid>
            <pubDate>Wed, 02 Dec 2020 13:15:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[National parks of New Zealand in 3D]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25275588">thread link</a>) | @pheelicks
<br/>
December 2, 2020 | https://felixpalmer.github.io/new-zealand-3d/ | <a href="https://web.archive.org/web/*/https://felixpalmer.github.io/new-zealand-3d/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://felixpalmer.github.io/new-zealand-3d/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275588</guid>
            <pubDate>Wed, 02 Dec 2020 12:01:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK approves Pfizer vaccine for rollout next week]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25275329">thread link</a>) | @williamsharris
<br/>
December 2, 2020 | https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week | <a href="https://web.archive.org/web/*/https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>LONDON –</strong> Britain today became the first Western country to approve a Covid-19 vaccine for general use as it announced a rollout of Pfizer-BioNTech's drug from next week.&nbsp;</p>

<p>"The government has today accepted the recommendation from the independent Medicines and Healthcare products Regulatory Agency (MHRA) to approve Pfizer-BioNTech's Covid-19 vaccine for use," the Health Department said in a statement.</p>

<p>"The vaccine will be made available across the UK from next week," the statement said. Priority groups will include care home residents, health and care staff, the elderly and the clinically extremely vulnerable.</p>

<p>After months of "rigorous" clinical trials and thorough analysis of the data, the MHRA "concluded that the vaccine has met its strict standards of safety, quality and effectiveness", the statement added.</p>

<p>"To aid the success of the vaccination programme, it is vital everyone continues to play their part and abide by the necessary restrictions in their area so we can further suppress the virus and allow the NHS (National Health Service) to do its work without being overwhelmed."</p>

<p>Pfizer chairman Albert Bourla said it was a "historic moment in the fight against Covid-19".&nbsp;</p>

<p>"This authorisation is a goal we have been working toward since we first declared that science will win, and we applaud the MHRA for their ability to conduct a careful assessment and take timely action to help protect the people of the UK," he said.</p>

<p>Pfizer and BioNTech added that they expected further regulatory decisions from other countries "in the coming days and weeks".</p>

<p>The announcement came as England exited a month-long coronavirus lockdown, but most of the country remained under restrictions as a new regional system for cutting infection rates kicked in.</p>

<p>The four-week lockdown, which began last month, was imposed to stop surging rates of infection, ease pressure on health services, and to allow families to gather for Christmas.</p>

<p>Prime Minister Boris Johnson, a Covid survivor, succeeded in winning a vote on the measures in parliament late yesterday, despite significant opposition within his own Conservative ranks.</p>

<p>"All we need to do now is to hold our nerve until these vaccines are indeed in our grasp and indeed being injected into our arms," he told lawmakers before the vote.</p>

<p>Until then "we cannot afford to relax, especially during the cold months of winter", he warned. – AFP, December 2, 2020</p>

                
                

                <div>
                    <div>
                        <h2>Get news, from every side. Subscribe to our newsletter!</h2>
                        


                    </div>
                </div>
            </div></div>]]>
            </description>
            <link>https://www.thevibes.com/articles/world/8174/uk-approves-pfizer-vaccine-for-rollout-next-week</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275329</guid>
            <pubDate>Wed, 02 Dec 2020 11:06:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Senate Passes Cybersecurity Improvement Act on to the President for Signature]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25275067">thread link</a>) | @Prototype_
<br/>
December 2, 2020 | https://mender.io/blog/a-landmark-day-for-device-security-us-senate-passes-cybersecurity-improvement-act-on-to-the-president-for-signature | <a href="https://web.archive.org/web/*/https://mender.io/blog/a-landmark-day-for-device-security-us-senate-passes-cybersecurity-improvement-act-on-to-the-president-for-signature">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <div>

              
    <div>
      
            
      <p>Our mission to secure the world’s connected devices got a timely boost when the US Senate passed the <a href="https://www.congress.gov/116/bills/hr1668/BILLS-116hr1668eh.pdf" target="_blank">Internet of Things (“IoT”) Cybersecurity Improvement Act (H.R. 1668)</a> into law. This is the brainchild of Congresswoman Robin Kelly from Illinois.
The legislation provides for the establishment of a minimum set of cybersecurity standards for government purchased, internet connected devices.</p>
<p>The National Institute of Standards and Technology (NIST) has been directed through the legislation to provide standards and guidelines for the  federal government agencies to comply with in order to better  manage the security of their IOT devices. These standards and guidelines are designed to provide a high level of continuity and more progress on the work already done by these agencies to address considerations around vulnerability detection, identity management, patching and the configuration of their IOT devices. </p>
<p><em>Don’t comply, Fed won’t buy</em></p>
<p>There is also a procurement dimension to the legislation and the law will require federal purchasers to apply restrictions on the purchase of devices from vendors who do not meet the NIST standards and guidelines. There are waivers in certain instances such as national security or research purposes, but the general rule will apply greater discipline to the treatment of security in product design and sale. This is obviously going to have a very big impact on manufacturers in the private sector who will need to meet these requirements to sell into federal government departments. There is likely to be an overspill effect into broader industrial and consumer electronics markets as the government starts to stand up and take IoT device security at all levels very seriously.</p>
<p><em>Get out of the kitchen if you can’t take the heat</em></p>
<p>It’s timely that in a <a href="https://mender.io/blog/good-news-the-u-s-house-passes-the-iot-cybersecurity-bill" target="_blank">recent blog post</a> our CEO Thomas Ryd noted that with these new IOT cybersecurity regulations being introduced, vendors who have not placed security at the center of their product development strategies will have to take a serious look at what they are doing, if they want to stay relevant and competitive in the market. </p>
<p>The <strong>Triangle of Trust</strong> is the strategic framework that guides product strategy and development at Northern.tech and Mender. We educate our customers to put this principle at the centre of their connected device management strategy. </p>
<p>Only <strong> authorised people</strong> can deploy <strong>authorised software</strong> to <strong>authorised devices</strong>. </p>
<p>Which leads to</p>
<p>Only the <strong> right people</strong> deploying the <strong>right software</strong> to the <strong>right devices</strong>.</p>
<p><em>Security in action in our IOT</em></p>
<p>We have developed the security features and strategic partnerships to translate this principle into operational reality for our customers. This puts us at the forefront of the market. For example, we work with NXP to support hardware encryption on their iMx gateway processors. This means that a device is highly secure from tampering with and malicious take over attempts. We also support Mutual TLS handshakes and PKP certificates and align to enterprise security standards and policies. We also consider less complex gateway devices and support elliptic curve cryptography for resource-efficient security and protection. </p>
<p>We thank Congresswoman Kelly for progressing and enacting this important legislation with fellow legislators in the US Senate. We believe that we are a provider that has prepared for this day, and have anticipated the requirements knowing that it was in the best interests of the customers we serve to make sure their devices avoid malicious attacks. </p>
<p>You can read the full details on this landmark legislation from <a href="https://www.natlawreview.com/article/breaking-news-internet-things-cybersecurity-legislation-clears-congress-heads-to" target="_blank">here</a>.</p>


      

              

        
          </div>


    
 
    

          </div>
        </div></div>]]>
            </description>
            <link>https://mender.io/blog/a-landmark-day-for-device-security-us-senate-passes-cybersecurity-improvement-act-on-to-the-president-for-signature</link>
            <guid isPermaLink="false">hacker-news-small-sites-25275067</guid>
            <pubDate>Wed, 02 Dec 2020 10:15:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux kernel heap quarantine versus use-after-free exploits]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25274928">thread link</a>) | @kmwyard
<br/>
December 2, 2020 | https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html | <a href="https://web.archive.org/web/*/https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>It's 2020. Quarantines are everywhere – and here I'm writing about one, too.
But this quarantine is of a different kind.</p>

<p>In this article I'll describe the <strong>Linux Kernel Heap Quarantine</strong> that I developed
for mitigating kernel use-after-free exploitation. I will also summarize
the discussion about the prototype of this security feature on the Linux Kernel
Mailing List (LKML).</p>



<p>Use-after-free (UAF) vulnerabilities in the Linux kernel are very popular for
exploitation. There are many exploit examples, some of them include:</p>
<ul>
  <li><a href="https://seclists.org/oss-sec/2016/q4/607">CVE-2016-8655</a></li>
  <li><a href="https://www.openwall.com/lists/oss-security/2017/02/26/2">CVE-2017-6074</a></li>
  <li><a href="https://a13xp0p0v.github.io/2017/03/24/CVE-2017-2636.html">CVE-2017-2636</a></li>
  <li><a href="https://ssd-disclosure.com/ssd-advisory-linux-kernel-af_packet-use-after-free/">CVE-2017-15649</a></li>
  <li><a href="https://a13xp0p0v.github.io/2020/02/15/CVE-2019-18683.html">CVE-2019-18683</a></li>
</ul>

<p>UAF exploits usually involve <strong>heap spraying</strong>.
Generally speaking, this technique aims to put attacker-controlled bytes at a defined memory
location on the heap. Heap spraying for exploiting UAF in the
Linux kernel relies on the fact that when <code>kmalloc()</code> is called, the slab
allocator returns the address of memory that was recently freed:</p>

<center><a href="https://a13xp0p0v.github.io/img/no_quarantine.png"><img src="https://a13xp0p0v.github.io/img/no_quarantine.png" width="60%"></a></center>


<p>So allocating a kernel object with the same size and attacker-controlled
contents allows overwriting the vulnerable freed object:</p>

<center><a href="https://a13xp0p0v.github.io/img/uaf.png"><img src="https://a13xp0p0v.github.io/img/uaf.png" width="70%"></a></center>


<p>Note: Heap spraying for out-of-bounds exploitation is a separate technique.</p>



<p>In July 2020, I got an idea of how to break this heap spraying technique for UAF
exploitation. In August I found some time to try it out. I extracted the slab
freelist quarantine from <a href="https://www.kernel.org/doc/html/latest/dev-tools/kasan.html">KASAN</a> functionality and called it <code>SLAB_QUARANTINE</code>.</p>

<p>If this feature is enabled, freed allocations are stored in the quarantine
queue, where they wait to be actually freed. So there should be no way for them
to be instantly reallocated and overwritten by UAF exploits.
In other words, with <code>SLAB_QUARANTINE</code>, the kernel allocator behaves like so:</p>

<center><a href="https://a13xp0p0v.github.io/img/with_quarantine.png"><img src="https://a13xp0p0v.github.io/img/with_quarantine.png" width="60%"></a></center>


<p>On August 13, <a href="https://www.openwall.com/lists/kernel-hardening/2020/08/13/7">I sent</a> the first early PoC to LKML and started deeper research of
its security properties.</p>



<p>For researching the security properties of the kernel heap quarantine, I developed
two <code>lkdtm</code> tests (<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/7">code is available here</a>).</p>

<p>The first test is called <code>lkdtm_HEAP_SPRAY</code>. It allocates and frees an object
from a separate <code>kmem_cache</code> and then allocates 400,000 similar objects.
In other words, this test attempts an original heap spraying technique for UAF
exploitation:</p>

<div><div><pre><code><span>#define SPRAY_LENGTH 400000
</span>    <span>...</span>
    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>...</span>
    <span>pr_info</span><span>(</span><span>"Original heap spraying: allocate %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>if</span> <span>(</span><span>spray_addrs</span><span>[</span><span>i</span><span>]</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"FAIL: attempt %lu: freed object is reallocated</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>
    
    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span>
        <span>pr_info</span><span>(</span><span>"OK: original heap spraying hasn't succeeded</span><span>\n</span><span>"</span><span>);</span>
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is disabled, the freed object is instantly
reallocated and overwritten:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000002b5b3ad4 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: FAIL: attempt 0: freed object is reallocated
</code></pre></div></div>

<p>If <code>CONFIG_SLAB_QUARANTINE</code> is enabled, 400,000 new allocations don't overwrite
the freed object:</p>

<div><div><pre><code>  # echo HEAP_SPRAY &gt; /sys/kernel/debug/provoke-crash/DIRECT
   lkdtm: Performing direct entry HEAP_SPRAY
   lkdtm: Allocated and freed spray_cache object 000000009909e777 of size 333
   lkdtm: Original heap spraying: allocate 400000 objects of size 333...
   lkdtm: OK: original heap spraying hasn't succeeded
</code></pre></div></div>

<p>That happens because pushing an object through the quarantine requires <strong>both
allocating and freeing memory</strong>. Objects are released from the quarantine as
new memory is allocated, but only when the quarantine size is over the limit.
And the quarantine size grows when more memory is freed up.</p>

<p>That's why I created the second test, called <code>lkdtm_PUSH_THROUGH_QUARANTINE</code>.
It allocates and frees an object from a separate <code>kmem_cache</code> and then performs
<code>kmem_cache_alloc()+kmem_cache_free()</code> for that cache 400,000 times.</p>

<div><div><pre><code>    <span>addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
    <span>...</span>
    <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>addr</span><span>);</span>
    <span>pr_info</span><span>(</span><span>"Allocated and freed spray_cache object %p of size %d</span><span>\n</span><span>"</span><span>,</span>
                    <span>addr</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>

    <span>pr_info</span><span>(</span><span>"Push through quarantine: allocate and free %d objects of size %d...</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>,</span> <span>SPRAY_ITEM_SIZE</span><span>);</span>
    <span>for</span> <span>(</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>SPRAY_LENGTH</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>push_addr</span> <span>=</span> <span>kmem_cache_alloc</span><span>(</span><span>spray_cache</span><span>,</span> <span>GFP_KERNEL</span><span>);</span>
        <span>...</span>
        <span>kmem_cache_free</span><span>(</span><span>spray_cache</span><span>,</span> <span>push_addr</span><span>);</span>

        <span>if</span> <span>(</span><span>push_addr</span> <span>==</span> <span>addr</span><span>)</span> <span>{</span>
            <span>pr_info</span><span>(</span><span>"Target object is reallocated at attempt %lu</span><span>\n</span><span>"</span><span>,</span> <span>i</span><span>);</span>
            <span>break</span><span>;</span>
        <span>}</span>
    <span>}</span>

    <span>if</span> <span>(</span><span>i</span> <span>==</span> <span>SPRAY_LENGTH</span><span>)</span> <span>{</span>
        <span>pr_info</span><span>(</span><span>"Target object is NOT reallocated in %d attempts</span><span>\n</span><span>"</span><span>,</span>
                    <span>SPRAY_LENGTH</span><span>);</span>
    <span>}</span>
</code></pre></div></div>

<p>This test effectively pushes the object through the heap quarantine and
reallocates it after it returns back to the allocator freelist:</p>

<div><div><pre><code>  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000008fdb15c3 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182994
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000004e223cbe of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 186830
  # echo PUSH_THROUGH_QUARANTINE &gt; /sys/kernel/debug/provoke-crash/
   lkdtm: Performing direct entry PUSH_THROUGH_QUARANTINE
   lkdtm: Allocated and freed spray_cache object 000000007663a058 of size 333
   lkdtm: Push through quarantine: allocate and free 400000 objects of size 333...
   lkdtm: Target object is reallocated at attempt 182010
</code></pre></div></div>

<p>As you can see, the number of the allocations needed for overwriting
the vulnerable object is almost the same. That would be good for stable
UAF exploitation and should not be allowed.
That's why I developed <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6"><strong>quarantine randomization</strong></a>. This randomization
required very small hackish changes to the heap quarantine mechanism.</p>

<p>The heap quarantine stores objects in batches. On startup, all
quarantine batches are filled by objects. When the quarantine shrinks,
I randomly choose and free half of objects from a randomly chosen batch.
The randomized quarantine then releases the freed object at an unpredictable moment:</p>

<div><div><pre><code>   lkdtm: Target object is reallocated at attempt 107884
   lkdtm: Target object is reallocated at attempt 265641
   lkdtm: Target object is reallocated at attempt 100030
   lkdtm: Target object is NOT reallocated in 400000 attempts
   lkdtm: Target object is reallocated at attempt 204731
   lkdtm: Target object is reallocated at attempt 359333
   lkdtm: Target object is reallocated at attempt 289349
   lkdtm: Target object is reallocated at attempt 119893
   lkdtm: Target object is reallocated at attempt 225202
   lkdtm: Target object is reallocated at attempt 87343
</code></pre></div></div>

<p>However, this randomization alone would not stop the attacker:
the quarantine stores the attacker's data (the payload) in the sprayed objects!
This means the reallocated and overwritten vulnerable object contains the payload
until the next reallocation (very bad!).</p>

<p>This makes it important to <strong>erase heap objects before placing them in the heap quarantine</strong>.
Moreover, filling them with zeros gives a chance to detect UAF
accesses to non-zero data for as long as an object stays in the quarantine (nice!).
That functionality already exists in the kernel, it's called <code>init_on_free</code>.
<a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/5">I integrated it</a> with <code>CONFIG_SLAB_QUARANTINE</code> as well.</p>

<p>During that work I found a bug: in <code>CONFIG_SLAB</code>, <code>init_on_free</code> happens too
late. Heap objects go to the KASAN quarantine while still "dirty." I provided the fix
in a <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/4">separate patch</a>.</p>

<p>For a deeper understanding of the heap quarantine's inner workings, I provided an <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/8">additional
patch</a>, which contains verbose debugging (not for merge).
It's very helpful, see the output example:</p>

<div><div><pre><code>   quarantine: PUT 508992 to tail batch 123, whole sz 65118872, batch sz 508854
   quarantine: whole sz exceed max by 494552, REDUCE head batch 0 by 415392, leave 396304
   quarantine: data level in batches:
     0 - 77%
     1 - 108%
     2 - 83%
     3 - 21%
   ...
     125 - 75%
     126 - 12%
     127 - 108%
   quarantine: whole sz exceed max by 79160, REDUCE head batch 12 by 14160, leave 17608
   quarantine: whole sz exceed max by 65000, REDUCE head batch 75 by 218328, leave 195232
   quarantine: PUT 508992 to tail batch 124, whole sz 64979984, batch sz 508854
   ...
</code></pre></div></div>

<p>The heap quarantine <code>PUT</code> operation you see in this output happens during kernel memory freeing.
The heap quarantine <code>REDUCE</code> operation happens during kernel memory allocation, if the quarantine
size limit is exceeded. The kernel objects released from the heap quarantine return to the allocator
freelist – they are actually freed.
In this output, you can also see that on <code>REDUCE</code>, the quarantine releases some part of
a randomly chosen object batch (see the <a href="https://www.openwall.com/lists/kernel-hardening/2020/09/29/6">randomization patch</a> for more details).</p>



<p>I made <a href="https://www.openwall.com/lists/kernel-hardening/2020/10/01/7">brief performance tests</a> of the quarantine PoC on real hardware and in virtual machines:</p>
<ol>
  <li>
    <p>Network throughput test using <code>iperf</code> <br>
server: <code>iperf -s -f K</code> <br>
client: <code>iperf -c 127.0.0.1 -t 60 -f K</code></p>
  </li>
  <li>
    <p>Scheduler stress test <br>
<code>hackbench -s 4000 -l 500 -g 15 -f 25 -P</code></p>
  </li>
  <li>
    <p>Building the defconfig kernel <br>
<code>time make -j2</code></p>
  </li>
</ol>

<p>I compared vanilla Linux kernel in three modes:</p>
<ul>
  <li><code>init_on_free=off</code></li>
  <li><code>init_on_free=on</code> (upstreamed feature)</li>
  <li><code>CONFIG_SLAB_QUARANTINE=y</code> (which enables <code>i…</code></li></ul></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html">https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</a></em></p>]]>
            </description>
            <link>https://a13xp0p0v.github.io/2020/11/30/slab-quarantine.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274928</guid>
            <pubDate>Wed, 02 Dec 2020 09:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hackers can take full control of online compilers through a RCE exploit (2018)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25274699">thread link</a>) | @crecker
<br/>
December 2, 2020 | https://serhack.me/articles/hackers-full-control-of-online-compilers-through-a-common-exploit/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/hackers-full-control-of-online-compilers-through-a-common-exploit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://serhack.me/images/compilers/1.png" alt="Compilers security report"></p><p>Online compilers are a handy tool to save time and resources for coders, and are freely available for a variety of programming languages. They are useful for learning a new language and developing simple programs, such as the ubiquitous <a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program">“Hello World”</a> exercise. I often use online compilers when I am out, so that I don’t have to worry about locating and downloading all of the resources myself.</p><p>Since these online tools are essentially remote compilers with a web interface, I realized that I might be able to take remote control of the machines through command injection. My research identified a common weakness in many compilers: inadequate sanitization of user-submitted code prior to execution. My analysis revealed that this lack of input filtration enables exploits that an hacker can use to take control of the machine or deliberately cause it to crash.</p><p>A clever attacker can exploit built-in C functions and POSIX libraries to gain control over the computer hosting the online compiler. Commands like <a href="https://linux.die.net/man/3/execl">execl()</a>, <a href="https://linux.die.net/man/3/system">system()</a>, and <a href="https://linux.die.net/man/3/getenv">GetEnv()</a> can be used to probe the target machine operating system and run any command on its built-in shell.</p><p>I wanted to write this article to remind how sandboxed environment are important when shipping an application such as this!</p><h2 id="vulnerability-description">Vulnerability description</h2><p>In this section, I will introduce the reader to the vulnerability explaining both theory and practice processes.</p><h3 id="gaining-access">Gaining access</h3><p>In several of the C/C++ compilers that I analyzed, the GetEnv(), system(), functions allow an attacker to study and execute any command on the remote machine. The GetEnv() function allows a hacker to learn information about the machine that is otherwise concealed from the web interface, such as the username and OS version.</p><p>Once this information is revealed, the attacker can begin testing various exploits to achieve privilege escalation and gain access to a root shell. For example, the system() command can be used to execute malicious code and access sensitive data such as logs, website files, etc.</p><p>Since the exploit I discovered involves inserting hostile commands to gain control of an unwitting machine, this attack vector is classified as a <a href="https://en.wikipedia.org/wiki/Code_injection">code injection</a> vulnerability.</p><h3 id="maintaining-control">Maintaining control</h3><p>If hacker tries to run the online compiler every time they want to send a new command, the attack would leave an obvious trace, and the resource use might draw attention to the suspicious activity. These obstacles can be conveniently sidestepped by using the execl() function, which allows the user to specify any arbitrary program to replace the current process. An attacker can gain access to the machine’s built-in shell by invoking the execl() function to replace the current process with <code>/bin/sh</code>, with catastrophic implications.</p><p>Many compilers allow input from the browser, in which case the hacker can craft a program to relay input commands to the shell of the compromised machine. Once the hacker uses <code>execl()</code> to open a shell via browser, they can simply operate the remote machine using <code>system()</code> to inject various instructions. This avoids the need to run the compiler each time the attacker wishes to explore or exploit the compromised machine.</p><h3 id="implications">Implications</h3><p>A hacker that obtains shell access in this way gains access to files and services typically protected from outside users. The attacker now has many options at their disposal for exploiting the machine and/or wreaking havoc; how they proceed will depend on their tools and motives.</p><p>If the attacker wishes to crash the target machine, they can achieve this by (mis)using the fork() function, which creates <a href="https://serhack.me/articles/introduction-to-monerov-and-its-inherent-risks/"><del>a new cryptocurrency</del></a> clone of the current process. A fork() function placed within a while (true) loop will execute indefinitely, repeatedly cloning the process to greedily consumed precious RAM memory. This rapid uncontrolled use of resources will overwhelm the machine, causing a self-DOS (denial of service attack).</p><p>Instead of maliciously crashing a machine, an attacker may wish to monetize their illicit access. This can be accomplished by injecting a cryptocurrency miner, which will generate funds for the attacker at the expense of the victim’s computational resources and electric bill. My analysis showed that this maneuver allows useful exploitation of online compilers that successfully stymied other attacks by sandboxing the environment or adopting more advanced techniques to limit file access.</p><h3 id="theory">Theory</h3><p>This section documents the commands used to gain and maintain access to the online compiler. These functions require the unistd.h and stdlib.h libraries.</p><h4 id="execl">execl()</h4><h5 id="declaration">Declaration</h5><div><pre><code data-lang="c"><span>int</span> <span>execl</span>(<span>const</span> <span>char</span> <span>*</span>pathname, <span>const</span> <span>char</span> <span>*</span>arg, ...);</code></pre></div><p>Parameters:</p><ul><li><p><strong>pathname</strong> - char*, the name of the program</p></li><li><p><strong>arg</strong> - char*, arguments passed to the program, specified by _pathname_</p></li></ul><h6 id="description">Description</h6><p>The execl() function replaces the current process with a new process. This is the command exploited to maintain control over the remote machine without having to repeatedly use the online compiler. Reference the underlying <em>execve()</em> function for more details.</p><h4 id="system">system()</h4><h6 id="declaration-1">Declaration</h6><div><pre><code data-lang="c"><span>int</span> <span>system</span>(<span>const</span> <span>char</span><span>*</span> command);</code></pre></div><p>Parameters:</p><ul><li><strong>command</strong> - char* command name</li></ul><h6 id="description-1">Description</h6><p>The C system function passes the command name, specified by command, to the host’s built-in shell (/bin/sh for UNIX-based systems) which executes it. This function is based on execl(), so system() will be called by executing:</p><div><pre><code data-lang="c">execl(, <span>"sh"</span>, <span>"-c"</span>, command, (<span>char</span> <span>*</span>)<span>0</span>);</code></pre></div><p>This function returns the output of the command after it has been executed. If the shell encounters an error while executing the command, it will return the numeric value -1.</p><h4 id="getenv">GetEnv()</h4><h6 id="declaration-2">Declaration</h6><div><pre><code data-lang="c"><span>char</span> <span>*</span>getenv(<span>const</span> <span>char</span> <span>*</span>name)</code></pre></div><p>Parameters:</p><ul><li><strong>name</strong> - const char* variable name.</li></ul><h6 id="description-2">Description</h6><p>Retrieves a string containing the value of the environment variable whose name is specified as an argument ( <em>name</em> ). The function returns the contents of the requested environment variable as a string. If the requested variable is not part of the list of environments, the function returns a null pointer.</p><h3 id="proof-of-concepts">Proof of Concepts</h3><div><pre><code data-lang="C"><span>#include</span> <span>"stdio.h"</span><span>
</span><span>#include</span> <span>"unistd.h"</span><span>
</span><span></span>
<span>int</span> <span>main</span>(){
	 execl(<span>"/bin/sh"</span>,NULL,NULL); <span>// Open the shell 
</span><span></span>	 <span>return</span> <span>0</span>;
}</code></pre></div><div><pre><code data-lang="C"><span>#include</span> <span>"stdio.h"</span><span>
</span><span>#include</span> <span>"stdlib.h"</span><span>
</span><span></span>
<span>int</span> <span>main</span>(){
	system(<span>"whoami"</span>); <span>// Find username 
</span><span></span>	system(<span>"cd / &amp;&amp; ls"</span>); <span>// Lists all files and directories on /
</span><span></span>	<span>return</span> <span>0</span>;
}</code></pre></div><h3 id="solutions-sandboxed-environment">Solutions: sandboxed environment</h3><p>Thankfully, most of the risks highlighted above can be mitigated relatively easily. Access to protected files and services can be prevented by creating a secure sandbox for the application. This minimizes the potential for collateral damage and inappropriate data access, but will not prevent some attacks such as cryptocurrency miner injection. In order to avoid these “mining” attacks, the sandbox should have limited resources and it should be able to reboot itself every 10 minutes.</p><p>To eliminate the underlying weakness, the libraries could be recompiled without the particular exploitable functions. An attacker cannot gain a foothold if the execl() and system() are removed or disabled by recompiling libraries.</p><p>In addition to this, tools such as <a href="https://docker.com/">Docker</a> might be used to create a sandboxed environment. A sandbox is a mechanism to run applications in a limited space. It usually provides a restricted and controlled set of resources to the program that needs to be tested, such as a restricted area of memory or a set of limited system calls; normally, network access, the ability to inspect the host system or read from input devices, are disabled or highly restricted.</p><p>At the time of my search, I found at least two compilers with a non-sandboxed environment. I contacted the managers and they resolved in less than a week. For others I verified that they were actually under a sandboxed environment. Injected scripts were immediately identified and the “malicious” user was banned.</p><p>Do you have any suggestions for my articles? Please reach me at <a href="https://twitter.com/@serhack_">Twitter</a> or <a href="mailto:hi@serhack.me">send me an e-mail</a>.</p><h3 id="screenshot">Screenshot</h3><p><img src="https://serhack.me/images/compilers/2.png"></p><p><img src="https://serhack.me/images/compilers/3.png" alt="Shell opened">
<img src="https://serhack.me/images/compilers/4.png" alt="PoC code"></p></div></div>]]>
            </description>
            <link>https://serhack.me/articles/hackers-full-control-of-online-compilers-through-a-common-exploit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274699</guid>
            <pubDate>Wed, 02 Dec 2020 09:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Security: Getting Started with Dependabot]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25274169">thread link</a>) | @henrikwm
<br/>
December 1, 2020 | https://security.christmas/2020/2 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Integrating security as a part of application development is desirable, but it's often forgotten or dismissed in practice. Dependabot is a Github feature that will help you keep all your dependencies invulnerable and up-to-date, and you can enable it in just a few clicks!</p>
</section><article><section><p>I've often been told that integrating security as a role and shared responsibility in application development is important. Yet, in my experience, security is frequently given a low priority by developers. Progress is primarily estimated by looking at an application's new features, and security measures are considered invasive and complicating to our day-to-day-work. Luckily, there are tools that requires little effort to increase our focus on security, such as Github's Dependabot  </p>
<h2>What is Dependabot?</h2>
<p>Simply put, Dependabot is a tool designated to keep dependencies secure and up-to-date. How it works can be summarized in the following three steps:</p>
<ol>
<li>Dependabot scans your dependency files for outdated or insecure dependencies.</li>
<li>Dependabot creates pull requests for dependencies that need an update.</li>
<li>You review, test and merge Dependabot’s changes.</li>
</ol>
<p>Following Github's acquisition of Dependabot in May 2019, the feature was added natively to Github. With only a few clicks, Dependabot can easily be enabled from the Github dashboard, and help you keep your application’s dependencies up-to-date.</p>
<h2>Getting started</h2>
<p>Enough background information, let us talk about how to get started. Github's security settings can be configured for an <a href="https://docs.github.com/en/free-pro-team@latest/github/setting-up-and-managing-organizations-and-teams/managing-security-and-analysis-settings-for-your-organization">entire organization</a>, applying to all of the organization’s repositories, or it can be configured <a href="https://docs.github.com/en/free-pro-team@latest/github/administering-a-repository/managing-security-and-analysis-settings-for-your-repository">per repository</a>. Which is the better option depends on your context. If you are the owner of your organization and it is desirable to enable the security features across all of its repositories, obviously it would be less time consuming to configure this on the organization level, rather than for each repository individually. However, if you are a part of a large organization with lots of teams and projects, enabling Dependabot on the repository level might be the only option.</p>
<p>In this example, we will enable Dependabot on a single repository. In your repository, there should be a button titled “Security”. Note that the security option is only visible to administrators, hence it will not be visible if you don't have the admin role in the repository. </p>
<p><img src="https://i.ibb.co/kScW0pN/screenshot-2020-11-21-at-18-06-01-1.png" alt="To enable Dependabot, click on the &quot;Security&quot; button."></p>
<p>In the security overview, there is a row titled “Dependabot alerts”. If not already activated, there should be a button to “Enable Dependabot alerts”. Click it. You should now have three options that you can enable:</p>
<ul>
<li>Dependency graph</li>
<li>Dependabot alerts</li>
<li>Dependabot security updates</li>
</ul>
<h3>Dependency graph</h3>
<p>The dependency graph is a summary of the manifest and lock files stored in a repository. Enabling this feature is a prerequisite for the other options, as Dependabot requires access to the dependency graph in order to create alerts and updates.</p>
<h3>Dependabot alerts</h3>
<p>The alerts allows Dependabot to notify you when it finds a weakness. This is probably the key feature that you are here for. When activated, the number of unresolved alerts is highlighted in the "Security" button that we previously clicked. On the security tab, the alerts highlighting currently outdated dependencies are listed. By clicking on an alert, you will find more details on it, such as a description of the vulnerability and in what version of the dependency it was patched.</p>
<p><img src="https://i.ibb.co/VMrM5Kh/screenshot-2020-11-16-at-19-59-16.png" alt="Security: Dependabot alerts" title="Unresolved Dependabot alerts are listed in the repository."></p>
<h3>Dependabot security updates</h3>
<p>By enabling the third option, the security updates, whenever a vulnerable dependency is discovered, Dependabot will try to fix it. If it is possible to upgrade the vulnerable dependency without disrupting the dependency graph of the repository, Dependabot will generate a pull request bringing the dependency up-to-date. The pull request is given a compatibility score indicating whether the update could cause breaking changes. The number is based on the percentage of tests in public repositories that passed when performing the same update.</p>
<p><img src="https://i.ibb.co/2vr3GBb/dependabot-pull-request.png" alt="Example pull request generated by Dependabot" title="A pull request generated by Dependabot"></p>
<p>Unfortunately, in my experience working with Dependabot, more often than not, it is unable to generate pull requests. This is often because the source of the vulnerability is an indirect or transitive dependency. The Dependabot documentation states that <em>“(...) security updates are triggered only for dependencies that are specified in a manifest or lock file. Dependabot is unable to update an indirect or transitive dependency that is not explicitly defined.”.</em> This means that even though Dependabot is able to perform some automatic updates, you should expect to perform most of the updates yourself - for now.</p>
<p>Even though Dependabot is unable to perform automated dependency updates most of the time, I would recommend enabling the feature. Occasionally it <em>will</em> be able to create the pull request for you, and you'll have saved yourself a couple of minutes that you can spend on something else.</p>
<p><img src="https://i.ibb.co/xXLhGLr/dependabot-pr-error.png" alt="Error message: Dependabot cannot update to the required version" title="More often than not, Dependabot is unable to generate a pull request"></p>
<p>If you already have established an effective process to update your project's dependencies, Dependabot might not be able to help you. Otherwise, you should definitely give it a try. It's free, it takes minimal effort to set up and - no matter how you use it - it's a better option than not monitoring your dependencies in any way.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274169</guid>
            <pubDate>Wed, 02 Dec 2020 07:59:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reggie Fowler owes lawyers $600k]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25274167">thread link</a>) | @amycastor
<br/>
December 1, 2020 | https://amycastor.com/2020/12/02/man-linked-to-missing-bitfinex-tether-funds-owes-lawyers-600000/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2020/12/02/man-linked-to-missing-bitfinex-tether-funds-owes-lawyers-600000/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4872">
			<!-- .entry-header -->
		<div>
		
<p>Reggie Fowler, the former NFL minority owner linked to missing Tether and Bitfinex funds, owes his defense team more than $600,000, according to a new<a href="https://amyhcastor.files.wordpress.com/2020/12/106df130-d8cc-418e-bbc0-8e46715e7b0a.pdf"> court filing</a> on Tuesday.&nbsp;</p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg"><img loading="lazy" data-attachment-id="4875" data-permalink="https://amycastor.com/reginald-fowler/" data-orig-file="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg" data-orig-size="1644,2048" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="reginald-fowler" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=241" data-large-file="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=822" src="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=822" alt="" width="313" height="390" srcset="https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=313 313w, https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=626 626w, https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=120 120w, https://amyhcastor.files.wordpress.com/2020/12/reginald-fowler.jpeg?w=241 241w" sizes="(max-width: 313px) 100vw, 313px"></a></figure></div>



<p>Fowler’s lawyers <a href="https://amycastor.com/2020/11/12/reginald-fowlers-lawyers-want-to-quit-did-he-neglect-to-pay-them/">want to drop out of the case</a> due to nonpayment, but they need to get permission from the court first.&nbsp;</p>



<p><a href="https://amycastor.com/2020/11/24/reggie-fowler-hoodwinks-his-own-defense-team/">Last we left off</a>, U.S. District Judge Andrew Carter ordered attorneys at law firm Hogan Lovells—also representing defense lawyer Scott Rosenblum at Rosenblum Schwartz &amp; Fry—to file three versions of a sealed letter dated Nov. 18.</p>



<p>The public version—redacting what should not be revealed to the government or the public—discloses more details on the lawyers’ frustrations with a client who perpetually strings them along.&nbsp;</p>



<p>Hogan Lovells attorneys James McGovern and Michael Hefter initially asked for a $25,000 retainer in late 2018 when they first met with their client. Fowler only ever paid the retainer, and two years later, he now owes them $600,000.</p>



<p>His defense team believed all the stories he told them that he was swimming in money, so they weren’t too concerned—at first.</p>



<p>“From the very inception of this matter, we have been led to believe that Mr. Fowler is a high net worth individual with substantial assets, which would allow him to pay his legal bills with little hardship,” the lawyers said in their letter to the judge. </p>



<p>Hogan Lovells started working with Fowler on October 18, 2018. They had their first meeting with him on Nov. 8, 2018, around the time Fowler was initially contacted by the FBI. </p>



<p>“When we agreed to represent Mr. Fowler, it was our understanding that he had been targeted by cryptocurrency businessmen seeking to take advantage of Mr. Fowler’s personal balance sheet as a means of transacting cryptocurrency transactions without drawing the attention of bank compliance officers or regulators,” they said. </p>



<p>Fowler was later arrested in Chandler, Arizona, on<a href="https://www.justice.gov/usao-sdny/pr/arizona-man-and-israeli-woman-charged-connection-providing-shadow-banking-services"> </a>April 30, 2019. (<a href="https://www.justice.gov/usao-sdny/pr/arizona-man-and-israeli-woman-charged-connection-providing-shadow-banking-services">DoJ press release and indictment</a>.)</p>



<p>After his release in May <a href="https://amycastor.com/2019/05/11/reginald-fowler-man-at-center-of-cryptocurrency-scheme-out-on-5-million-bail/">on $5 million bail</a>, Fowler hired Scott Rosenblum to join the defense team. Rosenblum asked for a $275,000 retainer and an additional $85,000 per week retainer, if the case went to trial.&nbsp;Rosenblum received a partial retainer of $100,000, which Hogan Lovells notes that Fowler paid “while he had several unpaid, overdue invoices for legal services issued by Hogan Lovells.”&nbsp;</p>



<p>Additionally, Fowler paid another lawyer (unnamed) in Portugal in full for her services. He also paid international law firm Reed Smith LLP for&nbsp;services rendered in 2018.</p>



<p>“The fact that other attorneys had received payments from Mr. Fowler for their services led us reasonably to believe that Mr. Fowler’s representations to us that he would pay our bills was truthful,” the lawyers said.</p>



<p>In the second half of 2019, the lawyers were diligent about contacting Fowler for money. Each time they reached out, he told them payment was imminent and that “transactions or business deals that would fund the payment of our fees were in process”—but he never paid him.&nbsp;</p>



<p>In February, following a plea bargain that went awry and a superseding indictment, the defense team realized the case would likely go to trial, requiring a substantial amount of work, and still no check from their client. </p>



<p>Fowler has ample funds, they said, including “$10 million in real estate that is unencumbered and could have been liquidated or monetized at any point during the past two years.” His refusal to pay, the lawyers added, has “led to a breakdown in the attorney-client relationship.”</p>



<p>The government has till Dec. 8 to respond and replies are due Dec. 11.</p>



<p><em>If you like my work, please consider supporting my writing by subscribing to my&nbsp;<a href="https://www.patreon.com/amycastor">Patreon account</a>&nbsp;for as little as $5 a month.</em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://amycastor.com/2020/12/02/man-linked-to-missing-bitfinex-tether-funds-owes-lawyers-600000/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274167</guid>
            <pubDate>Wed, 02 Dec 2020 07:59:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enigma: Archaeologists find legendary Nazi cipher machine in the Baltic Sea]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25274023">thread link</a>) | @jhoechtl
<br/>
December 1, 2020 | https://www.de24.news/en/2020/12/enigma-archaeologists-find-legendary-nazi-cipher-machine-in-the-baltic-sea.html | <a href="https://web.archive.org/web/*/https://www.de24.news/en/2020/12/enigma-archaeologists-find-legendary-nazi-cipher-machine-in-the-baltic-sea.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><a href="https://i1.wp.com/cdn.prod.www.spiegel.de/images/6020fe30-75d6-43d7-95e1-f6aea75091d4_w1280_r1.77_fpx39_fpy40.jpg?ssl=1" data-caption=""><img fifu-featured="1" width="696" height="" src="https://i1.wp.com/cdn.prod.www.spiegel.de/images/6020fe30-75d6-43d7-95e1-f6aea75091d4_w1280_r1.77_fpx39_fpy40.jpg?w=696&amp;resize=696%2C&amp;ssl=1" alt="" title=""></a></p>
 

<p>
As an archaeologist, Florian Huber is in the truest sense of the word with all waters. He searched for ancient Mayan antiquities in the flooded caves of the Yucatán, and dived to the bottom of fjords and deep alpine lakes. Again and again, however, the Kiel underwater researcher was drawn to the bottom of the Baltic Sea, where he tracked down wrecks or examined flora and fauna together with biologists.
</p>
<p>
It was here, of all places, that the well-traveled researcher made his most exciting discovery. Huber was actually working with two colleagues in the Geltinger Bucht, not far from Flensburg, in the service of environmental protection. The divers looked for ghost nets, abandoned fishing nets that become deadly traps for marine animals at the bottom.
</p>
<p>
From on board the “Mola Mola”, a nearly eight-meter-long motor catamaran, the researchers systematically scanned the sea floor with sonar. If the system detects a disused network or another object on the ground, the tracking device receives conspicuous sound pulses. The divers then slip into their suits, strap on their compressed air cylinders and drop backwards from the ship’s railing into the cold water to check.
</p>
 <p>
<a href="https://www.spiegel.de/wissenschaft/mensch/enigma-archaeologen-finden-legendaere-nazi-chiffriermaschine-in-der-ostsee-a-6058cbd5-6daf-49bb-937f-eb79b9423d56" target="_blank" rel="nofollow noopener noreferrer">Source link </a><br>
<a href="https://www.spiegel.de/wissenschaft/mensch/enigma-archaeologen-finden-legendaere-nazi-chiffriermaschine-in-der-ostsee-a-6058cbd5-6daf-49bb-937f-eb79b9423d56" target="_blank" rel="nofollow noopener noreferrer">https://www.spiegel.de/wissenschaft/mensch/enigma-archaeologen-finden-legendaere-nazi-chiffriermaschine-in-der-ostsee-a-6058cbd5-6daf-49bb-937f-eb79b9423d56</a></p>
 </div></div>]]>
            </description>
            <link>https://www.de24.news/en/2020/12/enigma-archaeologists-find-legendary-nazi-cipher-machine-in-the-baltic-sea.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25274023</guid>
            <pubDate>Wed, 02 Dec 2020 07:27:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use AirDrop on a Raspberry Pi 3]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25272550">thread link</a>) | @OMGCable
<br/>
December 1, 2020 | https://owlink.org/2019/05/16/howto-use-airdrop-on-raspberry-pi-3.html | <a href="https://web.archive.org/web/*/https://owlink.org/2019/05/16/howto-use-airdrop-on-raspberry-pi-3.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In this article, we are going to get AirDrop running on a Raspberry Pi 3 (not B+, unfortunately) running Rasbian Stretch.
While AirDrop itself implements a HTTP-based protocol (see <a href="https://owlink.org/code/">OpenDrop</a>), it uses a dedicated Wi-Fi based link layer called Apple Wireless Direct Link (AWDL). In order to use AirDrop, we’ll enable AWDL capabilities on the Raspberry Pi using <a href="https://owlink.org/code/">OWL</a>, our open AWDL implementation. OWL is implemented as user space program and requires a Wi-Fi card with working monitor mode and frame injection.</p>

<h2 id="enable-monitor-mode-with-frame-injection">Enable monitor mode with frame injection</h2>

<p>Since the BCM43430A1 Wi-Fi chip in the RPi3 does not support monitor mode out-of-the-box, we’ll use <a href="https://nexmon.org/">Nexmon</a> to patch the firmware.
The following steps are adapted from the project’s <a href="https://github.com/seemoo-lab/nexmon/blob/master/README.md">README</a>.</p>

<p>First, we need to install some dependencies.</p>

<div><div><pre><code><span>sudo </span>apt update <span>&amp;&amp;</span> apt upgrade
<span>sudo </span>apt <span>install </span>raspberrypi-kernel-headers git <span>\</span>
                 libgmp3-dev gawk qpdf bison flex make
<span>sudo </span>apt remove wpasupplicant
</code></pre></div></div>

<p>Then, we prepare Nexmon…</p>

<div><div><pre><code>git clone https://github.com/seemoo-lab/nexmon.git
<span>cd </span>nexmon
<span>touch </span>DISABLE_STATISTICS
</code></pre></div></div>

<p>… and compile required libraries and tools.</p>

<div><div><pre><code><span>sudo </span>su
<span>if</span> <span>[[</span> <span>!</span> <span>-f</span> /usr/lib/arm-linux-gnueabihf/libisl.so.10 <span>]]</span><span>;</span> <span>then</span> <span>\</span>
   <span>cd </span>buildtools/isl-0.10/ <span>&amp;&amp;</span> ./configure <span>&amp;&amp;</span> make <span>&amp;&amp;</span> make <span>install</span> <span>&amp;&amp;</span> <span>\</span>
   <span>ln</span> <span>-s</span> /usr/local/lib/libisl.so <span>\</span>
         /usr/lib/arm-linux-gnueabihf/libisl.so.10 <span>&amp;&amp;</span> <span>\</span>
   <span>cd</span> ../../ <span>;</span> <span>fi
</span><span>source </span>setup_env.sh
make
<span>cd </span>utilities/nexutil/ <span>&amp;&amp;</span> make <span>&amp;&amp;</span> make <span>install</span> <span>&amp;&amp;</span> <span>cd</span> ../../
</code></pre></div></div>

<p>We are now ready to build and install the monitor mode firmware patch.</p>

<div><div><pre><code><span>cd </span>patches/bcm43430a1/7_45_41_46/nexmon/
make
make backup-firmware
make install-firmware
</code></pre></div></div>

<blockquote>
  <p>Note that the above step is only necessary for Wi-Fi chips/drivers where monitor mode and frame injection support is missing. Other chips using the ath9k driver such as the Atheros AR9280 work out-of-the-box. Since Nexmon does not offer frame injection for the BCM43455C0 chip yet, you currently cannot use OWL on a 3B+ model.</p>
</blockquote>

<h2 id="install-owl">Install OWL</h2>

<p>Next, we are installing <a href="https://github.com/seemoo-lab/owl">OWL</a>, our AWDL implementation. First, we need some libraries (libpcap, libev, and libnl).</p>

<div><div><pre><code><span>sudo </span>apt <span>install </span>libpcap-dev libev-dev libnl-3-dev <span>\</span>
                 libnl-genl-3-dev libnl-route-3-dev
</code></pre></div></div>

<p>Then, it should be as easy as:</p>

<div><div><pre><code>git clone https://github.com/seemoo-lab/owl.git
<span>cd </span>owl
git submodule update <span>--init</span>
<span>mkdir </span>build
<span>cd </span>build
cmake ..
make
<span>sudo </span>make <span>install</span>
</code></pre></div></div>

<h2 id="install-opendrop">Install OpenDrop</h2>

<p>In the last step, we’ll install our AirDrop-compatible <a href="https://github.com/seemoo-lab/opendrop">OpenDrop</a> client and server.
Again, we need some dependencies:</p>

<div><div><pre><code><span>sudo </span>apt <span>install </span>python3 python3-pip libjpeg-dev libopenjp2-7-dev
</code></pre></div></div>

<p>Then, we can clone and install the software.</p>

<div><div><pre><code>git clone https://github.com/seemoo-lab/opendrop.git
<span>sudo </span>pip3 <span>install</span> ./opendrop
</code></pre></div></div>

<div>
	<p><a href="https://owlink.org/assets/raspi-airdrop.png">
		<img title="Sending a file to a Raspberry Pi 3 via AirDrop" alt="Sending a file to a Raspberry Pi 3 via AirDrop" src="https://owlink.org/assets/raspi-airdrop.png">
	</a></p><p>Sending a file to a Raspberry Pi 3 via AirDrop</p>
</div>

<h2 id="receive-files-via-airdrop">Receive files via AirDrop</h2>

<p>Now that all tools are installed, we can start a test run and use the Raspberry Pi to receive files via AirDrop.</p>

<p>Since we use Nexmon to enable monitor mode, we need to manually enable monitor mode and set the correct Wi-Fi channel (the RPi3 only supports the 2.4 GHz band, so we’ll use channel 6).</p>

<div><div><pre><code><span>sudo </span>iw phy <span>`</span>iw dev wlan0 info | gawk <span>'/wiphy/ {printf "phy" $2}'</span><span>`</span> interface add mon0 <span>type </span>monitor
<span>sudo </span>ifconfig mon0 up
<span>sudo </span>nexutil <span>-k6</span>
</code></pre></div></div>

<p>Next, we start <code>owl</code> to enable frame reception via AWDL (option <code>-N</code> tells <code>owl</code> that the interface is already in monitor mode, you can add <code>-v</code> to increase the logging output).</p>



<p>In a second shell, we can start the <code>opendrop</code> receiver.</p>



<p>Now, when opening the sharing pane on an iOS device, a new receiver appears after a short delay and we can send files!</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://owlink.org/2019/05/16/howto-use-airdrop-on-raspberry-pi-3.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272550</guid>
            <pubDate>Wed, 02 Dec 2020 02:16:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front: The $1.3B Startup Slackifying Email]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 129 (<a href="https://news.ycombinator.com/item?id=25272533">thread link</a>) | @bdr
<br/>
December 1, 2020 | https://sacra.com/research/front-inside-the-startup-slackifying-email/? | <a href="https://web.archive.org/web/*/https://sacra.com/research/front-inside-the-startup-slackifying-email/?">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="appMain">
      <article>
        <header>
          
          
          <div>
            <p><img src="https://images.prismic.io/sacra/869b3341-1d4e-4cdd-abfc-731301d0af9d_CleanShot+2020-09-04+at+16.02.20%402x.png?auto=compress,format&amp;rect=48,0,1148,1148&amp;w=48&amp;h=48"></p><address>
              Jan-Erik Asplund
            </address>
            <p><time pubdate="" datetime="12-01-2020">Published Dec 01st, 2020</time>
          </p></div>
        </header>
        <section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="email-is-just-a-wedge">Email is just a wedge</h2><p>Slack's meteoric growth won the headlines, generated case studies, and drew the admiration of venture capitalists and Wall Street investors alike.</p><p>But there's another company that—albeit growing more slowly—may have a much higher ceiling than the intra-team chat app.</p><p>Front is like Slack for your email, except instead of creating another distracting, noisy, always-on tool, Front allows users to spin up ephemeral chats within email threads themselves. </p><p>Instead of forwarding an email to a colleague or going into Slack to ask them a question that relates to a customer question or request, you can tag them into the thread and have a quick chat right in the context that's most useful.</p><p>At first, this sounds like a localized version of Slack—a niche tool. And Front was, at first, popular mostly with support teams and other teams that deal with a high volume of customer inquiries. But over time, Front has grown from being a product for a specific kind of workflow to being a tool that people use across organizations.</p><p>The fact is that most companies are still stuck in time from twenty years ago when it comes to managing how they triage, assign, and respond to all those emails. That's a big pain point, because as it turns out, a lot of the critical work that companies do takes place over email. </p><p>What Front has realized is that owning the orchestration and collaboration around email puts them in a position to “back into” $66B worth of vertical markets—CRM, project management, knowledge management, conversational marketing, and others.</p><p>To show the size of that opportunity and demonstrate the progress that Front has made towards its goal in this report, we aggregated all the public data out there on Front, then extrapolating and interpolating to fill in the gaps using backchannels to confirm our numbers.&nbsp;</p><p>We learned that Front, like Slack, has consumer-grade engagement, elite compounding revenue from their land and expand strategy, and increasingly broad adoption inside teams.</p><p>By focusing on external vs. internal communication, however, Front may also have a TAM that is several times as large as Slack's.</p><h2 id="front-s-roadmap-to--2b--4b--20b">Front's roadmap to $2B/$4B/$20B</h2><ul><li><strong>Our financial model values Front at $1.3B, with a price per share around $11.</strong> At their Series C in January, they were valued at $920M, or about $7.70~ per share.</li><li><strong>Front is currently trading on the secondary market between $7.25 and $9.00 per share.</strong> 5-year IRR for each scenario in our model ranges from 3% to 22% in the bear case, 22% to 46% in the base case, and 84% to 118% in the bull case.</li><li><strong>Front is like Slack for email</strong>. It is a multiplayer tool that lets teams better communicate—via chatting with other team members within the context of a personal or shared inbox—and coordinate—via tagging, rules, and 3rd-party integrations—how they respond to email.</li><li><strong>Front's 72% DAU/MAU ratio is on par with elite, consumer-grade apps</strong>. WhatsApp was at 70% pre-Facebook acquisition. Combined with its 148 minutes of average active daily usage (compare to Slack at 90 minutes) Front effectively has the engagement of a high-grade consumer app.</li><li><strong>Front's 137% net dollar retention demonstrates they are landing and expanding with an extremely efficient bottom-up model.</strong> Compare to 143% for Slack at IPO and 140% for Zoom at IPO.</li><li><strong>Zendesk and Intercom pose a threat because they have much deeper access to customer data. </strong>Intercom embeds itself in their customers' websites, giving them direct insight into the behavior of their customers, while Zendesk serves as a centralized hub for all things sales, support, and/or knowledge management for hundreds of thousands of companies.</li><li><strong>However, Front's high engagement platform makes them attractive to third-party developers. </strong>The more activity Front can promote on its platform, and the larger the variety of integrations their customers are using, the more adoption they'll have inside organizations and the wider their moat—based on the cost of switching away to another email product—will become.</li><li><strong>Expanding across organization opens up the opportunity to "back into" $66B worth of adjacent vertical markets </strong>. While today Front is focused on facilitating third-party integrations to tools like Hubspot, Marketo, and Salesforce, building their own versions of these products would allow them to (at minimum, and per product) 2-3x their average revenue per user—today, Zendesk's Enterprise plan costs $199 a seat, while Front's most expensive plan is just $79 per seat.</li><li><strong>Building their own vertical solutions also puts Front on a converging course with Salesforce ($226B), Microsoft ($1.63T), and Google ($1.19T).</strong> Front's endgame is essentially to recreate the Google or Office 365 suite. But Microsoft was able to overtake Slack's active user count within just two years—a company that had similar ambitions. The threat Microsoft/Google pose and their ability to freely push copycat products to a user base of millions could make it extremely challenging for Front to move upmarket and reach enterprise scale.</li><li><strong>Front's product also makes them an attractive acquisition target. </strong>Rather than attempt to build their own team email product, Microsoft and/or Google could buy Front. That said, Salesforce is the company most likely to acquire Front—both because they don't have any email tool of their own yet and because there's no risk of cannibalization or customer confusion as there would be with a Microsoft/Google acquisition.</li><li><strong>Ultimately, Front’s consumer-grade engagement and ability to achieve org-wide adoption position them well to compete on their own in the cloud productivity space</strong>. Most deep workflow products serve specific functional units (Intercom, Zendesk, Salesforce) while products that serve whole teams (Outlook, Gmail) have only superficial access to customer data. Front, on the other hand, is a workflow product and an org-wide tool all in one: a combination that could make them a formidable competitor even to the 800 lb. gorillas of B2B SaaS.
</li></ul><h2 id="valuation--front-is-worth--1-3b">Valuation: Front is worth $1.3B</h2><p>Today, based on our model, we estimate Front is worth about $1.3B, with a fair share price of $9.5 to $11.</p><p>That’s up 40% from Front’s Series C, which valued the company at about $7.7 per share or $920M post-money. At the time, Front was at $26M ARR growing 5% CMGR6 for a 35x multiple.&nbsp;</p><p>Today, we project Front is at about $38M ARR or $3.1M MRR, growing 3% CMGR6.&nbsp;</p><img src="https://images.prismic.io/sacra/731caebc-6ce9-4c26-8451-56f39d4618df_image13.png?auto=compress,format"><p><em>Applying the 35x multiple from Front’s last round to their current $38M revenue run rate gives us a valuation of $1.3B and an implicit per share price of $11. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Slack, for reference, was growing at 12% CMGR6 at the same ARR. According to our model, Front hasn’t grown at more than 10% CMGR6 since the summer of 2017, with growth hanging steady around 5% CMGR between April 2019 and early 2020, then declining slightly with the onset of COVID-19 in March.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/898c9394-e3df-4252-9a04-11f7995f0454_image33.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front today is at about $3.1M MRR, growing at 3% CMGR6. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s relatively slow and steady growth has been buoyed by impressive net dollar retention, though: 150% by their Series B and 137% by their Series C.&nbsp;</p><p>A large percentage of Front’s revenue comes from expansion versus bringing on new customers—based on our model, Front could grow at 2.66% monthly without any further investment in new customer acquisition.</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/6b8fe508-6373-4fae-a20b-49e5ea3c01e6_image6.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front’s -2.66% net monthly MRR churn creates a floor on growth. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s organic growth will be helped along by secular growth in the cloud-based productivity market.&nbsp;</p><p>Long-term, the total addressable market for cloud-based productivity tools is large and mostly unpenetrated, suggesting strong industry-wide growth for the next 10 to 15 years. Gartner estimates 1 billion knowledge workers worldwide. A 20% paid conversion rate with $100 - $300 contract value per year per user suggests $20 – 60 billion TAM.&nbsp;</p><p>Looking towards the future, Front’s bear, base, and bull cases hinge largely on whether the company’s growth will re-accelerate or whether it will continue to decline, and if so, how quickly it will do so:</p><ul><li>Our 5-year bull case has Front growing at 70% CAGR and reaching a $19B valuation ($600M ARR at a 30x multiple).</li><li>Our base case has them slowing to a steady 30% growth rate and being valued at a more modest $3.8B ($139M ARR on a 25x multiple).&nbsp;</li><li>In our bear case, Front’s growth slows even further, with the company reaching a …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/front-inside-the-startup-slackifying-email/?">https://sacra.com/research/front-inside-the-startup-slackifying-email/?</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/front-inside-the-startup-slackifying-email/?</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272533</guid>
            <pubDate>Wed, 02 Dec 2020 02:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[NN-SVG: Generate publication-ready NN-architecture schematics]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25272360">thread link</a>) | @tzm
<br/>
December 1, 2020 | https://alexlenail.me/NN-SVG/AlexNet.html | <a href="https://web.archive.org/web/*/https://alexlenail.me/NN-SVG/AlexNet.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
                <div>
                    
                    <div id="collapsable">
                        <div id="AlexNet" role="tabpanel">


                            <h4>Style:</h4>
                            <div id="rendererType">
                                <p><label for="rendererType">Renderer</label></p><p><label>
                                         webGL
                                    </label>
                                </p>
                                <p><label>
                                         SVG
                                    </label>
                                </p>
                                <p><small>The SVG renderer is required to download SVG, however the WebGL renderer is required to show tensor dimensions.</small>
                            </p></div>

                            
                            <p>
                                <label for="color1">Color 1</label>
                            </p>
                            <p>
                                <label for="color2">Color 2</label>
                            </p>
                            <p>
                                <label for="color3">Color 3</label>
                            </p>
                            <p><label for="rectOpacity">Tensor Opacity</label>
                                
                            </p>
                            <div>
                            <p><label for="strideOpacity">Filter Opacity</label>
                                
                            </p>
<!--                             <div>
                                <label for="borderWidth">Border Width</label>
                                <input type="range" id="borderWidth" name="" min="0.01" max="3" step="0.01" value="1" style="position: relative; top: 3px;">
                            </div> -->
                            <p><label for="betweenLayers">Spacing Between Layers</label>
                                
                            </p>

                            <hr>
                            <p>
                                <label for="logDepth">Log Feature-Map Depth Scaling</label>
                            </p>
                            <p><label for="depthScale">Depth Size Scaling</label>
                                
                                <span id="depthSpan">10</span>
                            </p>
                            <p>
                                <label for="logWidth">Log Feature-Map Width Scaling</label>
                            </p>
                            <p><label for="widthScale">Width Size Scaling</label>
                                
                                <span id="widthSpan">10</span>
                            </p>
                            <p>
                                <label for="logConvSize">Log Convolutional Filter Size Scaling</label>
                            </p>
                            <p><label for="convScale">Convolutional Filter Scaling</label>
                                
                                <span id="convSpan">1</span>
                            </p>

                            <hr>
                            <p>
                                <label for="showDims">Show Tensor Dimensions</label>
                            </p>
                            <p>
                                <label for="showConvDims">Show Conv Dimensions</label>
                            </p>

                            <hr>
                            <h4>Architecture:</h4>
                            <div id="architecture">
                                <p>Height | Width | Depth | filter Height | filter Width</p>
                                
                                
                                
                                
                                
                                
                                
                            </div>

                            <hr>
                            

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexlenail.me/NN-SVG/AlexNet.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272360</guid>
            <pubDate>Wed, 02 Dec 2020 01:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer Science Degree – Is it worthy it? Should You Get it?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 45 (<a href="https://news.ycombinator.com/item?id=25272222">thread link</a>) | @amiamigo
<br/>
December 1, 2020 | https://monalidor.com/computer-science-degree-is-it-worthy-it/ | <a href="https://web.archive.org/web/*/https://monalidor.com/computer-science-degree-is-it-worthy-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <p>This is my own journey on getting a CS degree and why I think you should or shouldn't major in Computer Science.</p><p>If you google right now, what are the best majors to study in college, it's a guarantee that Computer Science (CS) will be on almost every list. There are so many statistics about how much <a href="https://insights.dice.com/2019/06/12/computer-science-graduates-earnings/">CS graduates make</a>. At some big companies the likes of FAANG (Facebook, Amazon, Apple, Netflix, Google), fresh CS graduates can easily command six figures salaries, including benefits and cool perks. The total compensation in these companies is hardly less than six figures ($100,000)!</p><p>Computer Science is considered one of the top majors as far as ROI (Return on Investment) is concerned. Just year one out of school and into the workforce a CS grad will be making higher compared to grads from other majors. Even when someone isn't lucky enough to land one of the positions in big tech companies (FAANG), still they can easily make 55k fresh from school. <em>It should also be noted that the writer of this article is based in the US, so the figures here might not be so representative of other regions in the world.</em></p><p>So looking at the job prospects and earning potential, you can see why there is such a flux of students wanting to do CS in college.</p><p>And here is the question, should you major in Computer Science? </p><p>This post is about my journey on deciding to major in CS and why I would advise someone to major or not to major in CS. </p><p>...</p><p>December 2014, I got the news that I will be going to a small college in the Midwest of the United States for my college education. I was 23 by the time and at that point in my life, I had made some big life mistakes already (like quitting high school to become a professional athlete). As you might have guessed that didn't end well. 2 years and a half taught me a lot about life, dreams, aspirations. and most importantly it taught me about family...that will be a blog post for some other time. But there I was reading the email that in about 8 months I would be in school again for my bachelor's. Before quitting high school, I used to say to myself... "if I go to college I would study Psychology and Philosophy"...because the two fields really dug my intellectual curiosity. But when people asked me what would I do with Psychology or Philosophy...I didn't know what to tell them...I only knew I wanted to learn more about the two fields. I wasn't interested in a professional career in any of the two fields...just wanted to study them. Did that ever happen to you?</p><p>So I didn't want to make the same mistakes I did during high school years...I intentionally made a choice of choosing a major field of study that will be lucrative and pretty much guarantee me success. There I was googling the best majors to study in college.</p><p>Here is a short snippet of that research:</p><figure><img src="https://monalidor.com/content/images/2020/11/Majors-That-Pay-Back.png" alt="Majors That Pay You Back" srcset="https://monalidor.com/content/images/size/w600/2020/11/Majors-That-Pay-Back.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Majors-That-Pay-Back.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Majors-That-Pay-Back.png 1600w, https://monalidor.com/content/images/2020/11/Majors-That-Pay-Back.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Majors That Pay You Back</figcaption></figure><figure><img src="https://monalidor.com/content/images/2020/11/Major-vs-Salary.png" alt="Major vs Salary Potential" srcset="https://monalidor.com/content/images/size/w600/2020/11/Major-vs-Salary.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Major-vs-Salary.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Major-vs-Salary.png 1600w, https://monalidor.com/content/images/2020/11/Major-vs-Salary.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Major vs Salary Potential</figcaption></figure><p>Armored with that research plus a lot of other information I got from friends who were already studying CS and those who graduated with good jobs, I narrowed to Computer Science.</p><p>...</p><p>Fall 2015, my first year in college:</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Fall-2015-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2015-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2015-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2015-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2015-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Spring-2016-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2016-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2016-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2016-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2016-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Fall 2015 (Left) &amp; Spring 2016(Right) CS Classes</figcaption></figure><p>Sophomore year, Fall 2016</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Fall-2016-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2016-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2016-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2016-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2016-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Spring-2017-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2017-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2017-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2017-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2017-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Fall 2016 (Left) &amp; Spring 2017 (Right) CS Classes</figcaption></figure><p>By the end of Spring semester 2017, I had completed<strong> 22 credits of the 46 credits</strong> required by the CS program at my school.</p><p>In the fall of 2017, I didn't return back to campus...I had an opportunity to study abroad in London where for the whole semester I didn't take any Computer Science class. The school offered just general classes like Art History, Psychology, Religion, etc. In short, the study abroad program was a mixture of travel experience and study.</p><p>...</p><p>Junior Year, 2018</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Spring-2018-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2018-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2018-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2018-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2018-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Fall-2018-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2018-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2018-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2018-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2018-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Spring 2018 (Left) &amp; Fall 2018 (Right) CS Classes</figcaption></figure><p>Senior Year, 2019</p><figure><div><div><p><img src="https://monalidor.com/content/images/2020/11/Spring-2019-CS-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Spring-2019-CS-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Spring-2019-CS-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Spring-2019-CS-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Spring-2019-CS-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p><p><img src="https://monalidor.com/content/images/2020/11/Fall-2019-Classes.png" width="2000" height="1200" alt="" srcset="https://monalidor.com/content/images/size/w600/2020/11/Fall-2019-Classes.png 600w, https://monalidor.com/content/images/size/w1000/2020/11/Fall-2019-Classes.png 1000w, https://monalidor.com/content/images/size/w1600/2020/11/Fall-2019-Classes.png 1600w, https://monalidor.com/content/images/2020/11/Fall-2019-Classes.png 2000w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Spring 2019 (Left) &amp; Fall 2019 (Right) CS Classes</figcaption></figure><p>That was the order in which I took most of my CS classes, I dropped a few classes during my time and had to take them in the semesters that followed. But for easy of following through I just listed in the order of the first time I took them. In addition, I took one elective from another school which was <strong>CS 428</strong> <strong>Network Programming, </strong>and also I took <strong>EN 300C,</strong> an <strong>Advanced Writing</strong> class from another department in my school which substituted for my <strong>Technical Writing</strong> class in my CS major. And one more <strong>Math class</strong> was required to satisfy the requirements for the CS major.</p><p>So in a nutshell, that was my major. 4.5 or 5 years later, <strong>46 CS credits</strong> bagged and I graduated with a bachelor's in Computer Science.</p><p>The reason I listed all those classes above is to give you kinda a full picture of what a CS degree is about. When you just hear the words 'Computer Science', you might not really know what it's about...So the subjects above will at least shade some light. However, if you really wanna dive deep, I would suggest not just to look at the subjects offered in the program BUT make sure you read the syllabus too if you're able to get one. Syllabi will list topic by topic and week by week of exactly what the specific CS subjects will cover, there will be no surprises!</p><p>...</p><p>Now comes the meat of my blog post...Should you major in Computer Science?</p><p>Taking the money component out - we already know that a CS major can result in higher earning potential overall. What other reasons are there for you to major in see? Are you even interested in the field itself?</p><p>Most people when they hear about the Tech fields or Silicon Valley or working at Google or Microsoft, they mostly think about Computers and they might think about Computer Science as a way to get there, though they might not really know much about the Computer Science field itself.</p><p>I don't blame them, I was in the same situation...Initially I thought Computer Science will be learning about how to create these beautiful websites that I see on the Internet. Or maybe by studying Computer Science I will be able to make the next Facebook, Instagram and so forth. That was what initially clouded my mind.</p><p>Some of you might be surprised to know that a career in tech especially the one involving Computer Science or Programming for that matter...might not necessarily constitute you making products from scratch. There will be a lot of trying to understand, fix and maintain past code base. It might not be as alluring as some of the TV shows might make you believe. The technologies you work with might not be the ones of your interest. For example, I have never liked C# as a programming language or .NET frameworks as a web dev platform but there I was at my first job...using Windows, Visual Studio and .NET framework. You can imagine how excited I was.</p><p>...</p><p>As someone who has traveled this journey though not for so long, I can't emphasize enough on the importance of knowing exactly what you're getting yourself into. After all, college is a big investment both in terms of money and time, so pick both your majors and career carefully. One way of getting a good feel for what you're getting yourself into, either it's Computer Science or any other field is to make sure you get some internships while in college. Get an internship in something you're either majoring in or considering a career in. That will give you real-world experience of what your profession will look like once you graduate. It will give you time to think about the work culture, the work hours, the pressure, the work itself, etc. ...I had a friend in college who after doing an internship for about 4 months or so...he found out a career in Computer Science or programming wasn't for him. And he went ahead and changed his major from Computer Science to Economics, on the way he secured a minor in Computer Science.</p><figure><img src="https://monalidor.com/content/images/2020/12/Monalidor---Do-you-like-your-job.png" alt="Do you like your job?" srcset="https://monalidor.com/content/images/size/w600/2020/12/Monalidor---Do-you-like-your-job.png 600w, https://monalidor.com/content/images/size/w1000/2020/12/Monalidor---Do-you-like-your-job.png 1000w, https://monalidor.com/content/images/size/w1600/2020/12/Monalidor---Do-you-like-your-job.png 1600w, https://monalidor.com/content/images/2020/12/Monalidor---Do-you-like-your-job.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Do you like your job?</figcaption></figure><p>One of the things that will make you like your job is by first enjoying studying the field that you're in. Do you enjoy the field you're majoring in?</p><p>Look at the classes I listed above, do they interest you in any way? If they do then congrats! A CS program might be a good fit. But don't just end there like I said in the beginning...I would like you to go and check the syllabus for all those classes and see what you will study week in and week out. </p><p>Let me tell you something... as someone who was more interested in web development...I didn't enjoy most if not all of my CS classes. Had I used that time to learn more about web design and development...learning specific languages used for the job I would have benefited more and enjoyed my time in college. Here web development technologies like JavaScript, PHP and their frameworks together with WordPress, SASS, the JAM stack, etc.</p><p>So what am I trying to say here..? If the reason you decided to get into a CS program is because you love to design and develop websites...then you might be in the wrong place...a CS class in Computational modeling will be pretty much a bore to you. You would appreciate that time instead if you were learning first hand the tools and languages you will be working with in the real world.</p><p>Walk this process backward...ask yourself...who do you want to become...a web developer? a software engineer? a UI/UX engineer? a database administrator..? a network engineer? Then once you know whom you want to become...look for resources that will allow you to do that...these might involve a major in college, maybe a minor, books, online courses, tools used in the industry, etc.</p><p> If you pick a major, don't be blinded by a bracket name like a 'Computer Science'. Understand exactly what that entails...go and look at the syllabus of each course you will take in that major. Don't just assume a CS major will grant you those mobile or web development skills etc. The job market can be very specific...They might look for a Java developer, a PHP developer, a Python developer, an iOS developer etc. While knowledge of one language might help you easily pick up another one...it's a good thing if you can focus on what you're interested in early on. </p><p>...Being a mobile developer is different from being a web …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://monalidor.com/computer-science-degree-is-it-worthy-it/">https://monalidor.com/computer-science-degree-is-it-worthy-it/</a></em></p>]]>
            </description>
            <link>https://monalidor.com/computer-science-degree-is-it-worthy-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25272222</guid>
            <pubDate>Wed, 02 Dec 2020 01:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Networking Tools Every Developer Needs to Know]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25271029">thread link</a>) | @pngmangi
<br/>
December 1, 2020 | https://martinheinz.dev/blog/38 | <a href="https://web.archive.org/web/*/https://martinheinz.dev/blog/38">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://martinheinz.dev/blog/38</link>
            <guid isPermaLink="false">hacker-news-small-sites-25271029</guid>
            <pubDate>Tue, 01 Dec 2020 22:41:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Manuscripts.io]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25270775">thread link</a>) | @cw
<br/>
December 1, 2020 | https://www.manuscripts.io/about/ | <a href="https://web.archive.org/web/*/https://www.manuscripts.io/about/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><header></header><div><div><p>A simple authoring tool for complex documents.</p></div></div><p><img src="https://www.manuscripts.io/about/static/WindowChrome2x-2b58e9e9c86429ab8d2fac5352d89155.png" width="1024" alt=""></p><p><svg width="64" height="70" viewBox="0 0 64 70"><g fill="none" fill-rule="evenodd"><path d="M33.5 5.02a3 3 0 00-3 0L6.787 18.712a3 3 0 00-1.5 2.598v27.382a3 3 0 001.5 2.598L30.5 64.979a3 3 0 003 0l23.713-13.69a3 3 0 001.5-2.598V21.309a3 3 0 00-1.5-2.598L33.5 5.021z" stroke="#5E6F7E" stroke-width="2"></path><path fill="#5E6F7E" d="M29.842 38.738L23.34 40l4.344-5-4.344-5 6.502 1.262L32 25l2.158 6.262L40.66 30l-4.344 5 4.344 5-6.502-1.262L32 45z"></path></g></svg><h2>Research is collaborative and dynamic.</h2></p><p>Word processors are not. Manuscripts is a collaborative authoring tool built specifically to support scientific content and reproducibility, from the moment a project begins.</p><div><p><img src="https://www.manuscripts.io/about/static/BlueBoxScreenshots-6e19c8d8e118427a65f17e8258450083.png" width="585" alt=""></p><div><h2>Plan and organise writing</h2><p>Save time planning and formatting your work by utilizing one of over 1,300 built-in journal submission templates. Or, upload an existing file, start a blank document, or reformat one manuscript into another template automatically. Manuscripts structured documents support scientific work from the start.</p></div></div><div><p><img src="https://www.manuscripts.io/about/static/GreenBoxScreenshots-8b320e138e54a666993aa50479909f68.png" width="585" alt=""></p><div><h2>Collaborate in real time</h2><p>Invite and collaborate with coauthors live within Manuscripts. No more reconciling multiple versions - work alongside each other, leave comments, or work offline and sync your changes later.</p></div></div><div><p><img src="https://www.manuscripts.io/about/static/OrangeBoxScreenshots-c3270d909e222e3b077a2e432d972a24.png" width="585" alt=""></p><div><h2>Execute and verify</h2><p>Include mathematical equations, code, and data and execute figures live with a behind-the-scenes Jupyter computational notebook integration. Make your work reproducible from the very beginning by including all the elements of your research in Manuscripts.</p></div></div><div><svg width="65" height="70" viewBox="0 0 65 70"><g fill="none" fill-rule="evenodd"><path d="M33.492 5.008a3 3 0 00-2.984 0L6.795 18.602a3 3 0 00-1.508 2.603v27.14a3 3 0 001.508 2.602l23.713 13.594a3 3 0 002.984 0l23.713-13.594a3 3 0 001.508-2.603v-27.14a3 3 0 00-1.508-2.602L33.492 5.008z" stroke="#FFF" stroke-width="2"></path><path d="M25.995 35.037a.95.95 0 00-1.38.03l-.906.975a1.052 1.052 0 00.027 1.442l5.558 5.582L42.198 29.94a1.015 1.015 0 00-.002-1.423l-.94-.943a.995.995 0 00-1.414.005L29.21 38.267l-3.215-3.23z" fill="#FFF"></path></g></svg><h2>All the research features you need in one app</h2><p>Write better research with Manuscripts.</p><div><div width="1,0.5"><div><ul><li>Format citations and bibliography automatically.</li><li>Cross-referencing.</li><li>Footnotes and endnotes.</li><li>Multi-panel figures and tables.</li><li>Equations and inline math with LaTeX support.</li><li>Syntax-highlighted code snippets.</li><li>Menu and keyboard shortcuts for most actions.</li></ul></div></div><div width="1,0.5"><div><ul><li>Share document using links (read-write and read-only).</li><li>Invite and manage roles of collaborators.</li><li>Collaboratively format author lists with contributions and affiliations.</li></ul></div></div><div width="1,0.5"><div><ul><li>Manage styles associated with paragraph types, figures, tables, equations.</li><li>Use templates that bundle together a set of styles and content requirements.</li></ul></div></div><div width="1,0.5"><div><ul><li>Import Markdown, Word, and LaTeX.</li><li>Export Markdown, Word, LaTeX, and PDF.</li><li>Directly submit your manuscripts to hundreds of journals in one click.</li><li>Support for JATSXML and HTML-first publishing workflows.</li></ul></div></div><div width="1,0.5"><div><ul><li>Annotate paragraphs, figures, tables, equations, code listings and citations.</li><li>Include quotes in annotation comments.</li><li>Mention keywords with #hashtags in annotation comments.</li><li>Mention contributors with @mentions in annotation comments.</li></ul></div></div><div width="1,0.5"><div><ul><li>Search for and add citations easily from CrossRef, PubMed, Datacite.</li><li>View and share references in a library across documents and projects.</li><li>Format citations and references in over 8,000 styles.</li></ul></div></div><div width="1,0.5"><div><ul><li>Outline: navigate, manipulate document structure using an outline view of it.</li><li>Smart gutter: shortcut actions for fast access to key editor features.</li></ul></div></div></div></div><p><svg width="69" height="70" viewBox="0 0 69 70"><g stroke="#5E6F7E" stroke-width="2" fill="none" fill-rule="evenodd"><path d="M36.492 5.008a3 3 0 00-2.984 0L9.795 18.602a3 3 0 00-1.508 2.603v27.14a3 3 0 001.508 2.602l23.713 13.594a3 3 0 002.984 0l23.713-13.594a3 3 0 001.508-2.603v-27.14a3 3 0 00-1.508-2.602L36.492 5.008z"></path><path stroke-linecap="round" stroke-linejoin="round" d="M24.89 27.44L18 34.823l6.89 7.383M44.578 27.44l6.89 7.383-6.89 7.383m-14.765 5.906l9.843-27.563"></path></g></svg><h2>Free and open</h2></p><p>Research is increasingly free and open to build on – research tools should be, too.</p><p>Manuscripts is modular: it is a product made of a series of separable components that can also be used to extend or create other systems.</p><div><svg width="187" height="39" viewBox="0 0 187 39"><defs><linearGradient x1="3.726%" y1="50%" x2="77.22%" y2="50%" id="svg-connectlogomonochrome-a"><stop stop-color="#D7F3FF" offset="0%"></stop><stop stop-color="#FFF" offset="100%"></stop></linearGradient></defs><g fill="none"><path d="M52.979 29.434c-1.712.022-3.4-.38-4.897-1.168a8.6 8.6 0 01-3.39-3.229 8.973 8.973 0 01-1.226-4.638c0-1.742.411-3.318 1.225-4.689a8.499 8.499 0 013.391-3.211 10.359 10.359 0 014.897-1.15 9.982 9.982 0 014.125.836 7.432 7.432 0 013.022 2.45l.083.116-1.556 1.077-.091-.12a6.108 6.108 0 00-2.405-1.916 7.75 7.75 0 00-3.178-.64 7.956 7.956 0 00-3.806.903 6.643 6.643 0 00-2.635 2.549 7.448 7.448 0 00-.956 3.795 7.448 7.448 0 00.956 3.795 6.63 6.63 0 002.635 2.544 7.947 7.947 0 003.806.905 7.775 7.775 0 003.178-.64 6.121 6.121 0 002.405-1.933l.09-.119 1.557 1.076-.083.117a7.424 7.424 0 01-3.022 2.45 9.981 9.981 0 01-4.125.84zm19.091 0a9.354 9.354 0 01-4.636-1.168 8.477 8.477 0 01-3.252-3.23 9.256 9.256 0 01-1.181-4.642 9.26 9.26 0 011.181-4.656 8.485 8.485 0 013.252-3.23 9.838 9.838 0 019.272 0 8.485 8.485 0 013.251 3.23 9.248 9.248 0 011.182 4.656 9.244 9.244 0 01-1.182 4.656 8.477 8.477 0 01-3.251 3.23 9.354 9.354 0 01-4.636 1.154zm0-16.29a7.087 7.087 0 00-3.6.92 6.694 6.694 0 00-2.508 2.564 7.605 7.605 0 00-.92 3.76 7.595 7.595 0 00.92 3.757 6.688 6.688 0 002.509 2.565 7.5 7.5 0 007.198 0 6.688 6.688 0 002.508-2.565 7.588 7.588 0 00.921-3.758 7.589 7.589 0 00-.921-3.759 6.694 6.694 0 00-2.508-2.564 7.087 7.087 0 00-3.6-.92zm27.94 16.291V19.1c0-1.936-.512-3.427-1.523-4.432-1.01-1.004-2.45-1.51-4.275-1.51-2.107 0-3.788.61-4.996 1.815-1.208 1.204-1.823 2.856-1.823 4.9v9.56h-2.067V11.478h1.99v3.395a7.052 7.052 0 012.603-2.456c1.275-.71 2.799-1.068 4.532-1.068 2.332 0 4.204.663 5.567 1.97 1.363 1.309 2.052 3.21 2.052 5.654v10.463h-2.06zm23.721 0V19.1c0-1.936-.513-3.427-1.53-4.432-1.019-1.004-2.45-1.51-4.274-1.51-2.107 0-3.788.61-4.996 1.815-1.208 1.204-1.817 2.856-1.817 4.9v9.56h-2.067V11.478h1.99v3.395a7.042 7.042 0 012.603-2.456c1.274-.71 2.799-1.068 4.532-1.068 2.332 0 4.204.663 5.565 1.97 1.362 1.309 2.054 3.21 2.054 5.654v10.463h-2.06zm16.013-.001c-1.877 0-3.573-.39-5.04-1.167a8.751 8.751 0 01-3.473-3.21c-.83-1.36-1.253-2.93-1.253-4.67a9.237 9.237 0 011.18-4.65 8.47 8.47 0 013.262-3.228 9.93 9.93 0 019.288-.017 8.43 8.43 0 013.228 3.201 9.149 9.149 0 011.179 4.635l-.047.615h-16.021a6.82 6.82 0 001.078 3.42 6.81 6.81 0 002.743 2.413 8.767 8.767 0 003.912.856 8.894 8.894 0 003.316-.61 6.41 6.41 0 002.529-1.786l.116-.135 1.243 1.332-.085.096a8.131 8.131 0 01-3.107 2.155 10.798 10.798 0 01-4.048.75zm6.302-10.091a6.594 6.594 0 00-1.04-3.135c-1.25-1.952-3.516-3.128-5.94-3.084a7.382 7.382 0 00-3.462.804 6.373 6.373 0 00-2.46 2.261 7.064 7.064 0 00-1.055 3.154h13.957zm14.378 10.091a10.23 10.23 0 01-4.894-1.168 8.598 8.598 0 01-3.39-3.229 8.976 8.976 0 01-1.232-4.653c0-1.741.411-3.318 1.232-4.688a8.496 8.496 0 013.39-3.211 10.353 10.353 0 014.894-1.136 9.973 9.973 0 014.123.837 7.44 7.44 0 013.021 2.449l.083.117-1.556 1.077-.09-.12a6.106 6.106 0 00-2.404-1.916 7.744 7.744 0 00-3.177-.641 7.95 7.95 0 00-3.804.903 6.641 6.641 0 00-2.634 2.549 7.45 7.45 0 00-.955 3.795 7.45 7.45 0 00.955 3.795 6.629 6.629 0 002.634 2.544 7.941 7.941 0 003.804.905 7.769 7.769 0 003.177-.641 6.122 6.122 0 002.403-1.918l.091-.118 1.556 1.076-.083.116a7.432 7.432 0 01-3.021 2.451 9.97 9.97 0 01-4.123.825zm18.59.001c-1.64 0-2.922-.448-3.823-1.333-.901-.884-1.354-2.123-1.354-3.69V12.86h-3.395v-1.774h3.395V7.174h2.077v3.912h5.871v1.774h-5.871v11.381c0 1.124.276 1.983.825 2.557.55.575 1.37.863 2.452.863 1.11 0 2.039-.323 2.768-.957l.138-.122.903 1.46-.09.081a4.667 4.667 0 01-1.737.978 7.016 7.016 0 01-2.16.334z" fill="#FFF"></path><path d="M28.572 12.972a3.428 3.428 0 000-6.855h-.938v-2.69A3.43 3.43 0 0024.208 0H9.938a3.432 3.432 0 00-3.427 3.428v2.688H3.44A3.43 3.43 0 00.017 9.54L0 22.446a3.426 3.426 0 003.428 3.43h22.654a.93.93 0 01.929.927v1.77a.929.929 0 01-.929.927H9.938a.929.929 0 01-.928-.928v-1.436h-2.5v1.436A3.432 3.432 0 009.939 32h16.144a3.432 3.432 0 003.428-3.428v-1.767a3.433 3.433 0 00-3.428-3.428H9.015V9.873H6.511v13.511H3.428a.927.927 0 01-.93-.929L2.515 9.55a.93.93 0 01.928-.927H23.88V6.116H9.01V3.428a.93.93 0 01.928-.93h14.27a.93.93 0 01.927.93v6.115a3.433 3.433 0 003.437 3.43z" fill="url(#svg-connectlogomonochrome-a)" transform="translate(3 3)"></path></g></svg><h2>One account for all your research</h2><p>Manuscripts is part of Connect. By signing up for Manuscripts, you get access to all of Atypon's apps for discovering, organising, writing, and publishing research.</p><div><div width="1"><div width="1,0.5"><div><p>A simple writing tool for complex documents. Built for collaboration and scholarship.<!-- --> </p></div></div><p>To be connected soon</p></div></div></div><p><svg width="60" height="70" viewBox="0 0 60 70"><g fill="#5E6F7E"><path d="M36.857 29h-1.714c-.629 0-1.143.675-1.143 1.5s.514 1.5 1.143 1.5h1.714c.629 0 1.143-.675 1.143-1.5s-.514-1.5-1.143-1.5zm-7.015 0h-8.684C20.52 29 20 29.675 20 30.5s.521 1.5 1.158 1.5h8.684C30.48 32 31 31.325 31 30.5s-.521-1.5-1.158-1.5zm18.021-7H21.137c-.625 0-1.137.675-1.137 1.5s.512 1.5 1.137 1.5h26.726c.625 0 1.137-.675 1.137-1.5s-.512-1.5-1.137-1.5z"></path><path d="M53.423 11H15.5c-3.067 0-5.577 2.506-5.577 5.568v12.25H4.346A3.353 3.353 0 001 32.16v17.818a3.353 3.353 0 003.346 3.341h5.577v5.568c0 .446.279.836.67 1.003.167.055.278.111.445.111.28 0 .558-.111.725-.278l6.916-6.125.056-.056c.167-.167.39-.223.725-.223h7.25a3.353 3.353 0 003.346-3.34v-7.796h1.004c.836 0 1.617.278 2.23.89l10.43 9.634c.222.167.501.278.78.278.167 0 .279-.056.446-.111a1.1 1.1 0 00.67-1.003v-9.688h7.807c3.067 0 5.577-2.506 5.577-5.568V16.568C59 13.506 56.49 11 53.423 11zM27.825 49.977c0 .613-.502 1.114-1.115 1.114h-7.25c-.893 0-1.673.278-2.287.835l-5.02 4.455v-4.176c0-.613-.501-1.114-1.115-1.114H4.346a1.118 1.118 0 01-1.115-1.114V32.16c0-.612.502-1.114 1.115-1.114h5.577v5.569c0 3.062 2.51 5.568 5.577 5.568h12.325v7.795zm28.944-13.363a3.353 3.353 0 01-3.346 3.34h-7.808v-3.34c0-.613-.502-1.114-1.115-1.114s-1.115.501-1.115 1.114v12.695l-8.533-7.907c-1.004-.946-2.342-1.447-3.792-1.447H15.5a3.353 3.353 0 01-3.346-3.341V16.568a3.353 3.353 0 013.346-3.34h37.923a3.353 3.353 0 013.346 3.34v20.046z"></path></g></svg><h2>Have a question?</h2></p><p>Contact us via <a href="mailto:support@manuscripts.io">support@manuscripts.io</a>.</p><main></main><p>2019 © Atypon Systems, LLC, All rights reserved | <a href="https://www.atypon.com/privacy-policy/">Privacy policy</a></p></div></div></div></div>]]>
            </description>
            <link>https://www.manuscripts.io/about/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25270775</guid>
            <pubDate>Tue, 01 Dec 2020 22:17:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front: The $1.3B Startup Slackifying Email]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25270424">thread link</a>) | @smalter
<br/>
December 1, 2020 | https://sacra.com/research/front-inside-the-startup-slackifying-email/ | <a href="https://web.archive.org/web/*/https://sacra.com/research/front-inside-the-startup-slackifying-email/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="appMain">
      <article>
        <header>
          
          
          <div>
            <p><img src="https://images.prismic.io/sacra/869b3341-1d4e-4cdd-abfc-731301d0af9d_CleanShot+2020-09-04+at+16.02.20%402x.png?auto=compress,format&amp;rect=48,0,1148,1148&amp;w=48&amp;h=48"></p><address>
              Jan-Erik Asplund
            </address>
            <p><time pubdate="" datetime="12-01-2020">Published Dec 01st, 2020</time>
          </p></div>
        </header>
        <section>
           <p><em>This report contains forward-looking statements regarding the companies reviewed as part of this report that are based on beliefs and assumptions and on information currently available to us during the preparation of this report. In some cases, you can identify forward-looking statements by the following words: “will,” “expect,” “would,” “intend,” “believe,” or other comparable terminology. Forward-looking statements in this document include, but are not limited to, statements about future financial performance, business plans, market opportunities and beliefs and company objectives for future operations. These statements involve risks, uncertainties, assumptions and other factors that may cause actual results or performance to be materially different. We cannot assure you that any forward-looking statements contained in this report will prove to be accurate. These forward-looking statements speak only as of the date hereof. We disclaim any obligation to update these forward-looking statements.</em></p><h2 id="email-is-just-a-wedge">Email is just a wedge</h2><p>Slack's meteoric growth won the headlines, generated case studies, and drew the admiration of venture capitalists and Wall Street investors alike.</p><p>But there's another company that—albeit growing more slowly—may have a much higher ceiling than the intra-team chat app.</p><p>Front is like Slack for your email, except instead of creating another distracting, noisy, always-on tool, Front allows users to spin up ephemeral chats within email threads themselves. </p><p>Instead of forwarding an email to a colleague or going into Slack to ask them a question that relates to a customer question or request, you can tag them into the thread and have a quick chat right in the context that's most useful.</p><p>At first, this sounds like a localized version of Slack—a niche tool. And Front was, at first, popular mostly with support teams and other teams that deal with a high volume of customer inquiries. But over time, Front has grown from being a product for a specific kind of workflow to being a tool that people use across organizations.</p><p>The fact is that most companies are still stuck in time from twenty years ago when it comes to managing how they triage, assign, and respond to all those emails. That's a big pain point, because as it turns out, a lot of the critical work that companies do takes place over email. </p><p>What Front has realized is that owning the orchestration and collaboration around email puts them in a position to “back into” $66B worth of vertical markets—CRM, project management, knowledge management, conversational marketing, and others.</p><p>To show the size of that opportunity and demonstrate the progress that Front has made towards its goal in this report, we aggregated all the public data out there on Front, then extrapolating and interpolating to fill in the gaps using backchannels to confirm our numbers.&nbsp;</p><p>We learned that Front, like Slack, has consumer-grade engagement, elite compounding revenue from their land and expand strategy, and increasingly broad adoption inside teams.</p><p>By focusing on external vs. internal communication, however, Front may also have a TAM that is several times as large as Slack's.</p><h2 id="front-s-roadmap-to--2b--4b--20b">Front's roadmap to $2B/$4B/$20B</h2><ul><li><strong>Our financial model values Front at $1.3B, with a price per share around $11.</strong> At their Series C in January, they were valued at $920M, or about $7.70~ per share.</li><li><strong>Front is currently trading on the secondary market between $7.25 and $9.00 per share.</strong> 5-year IRR for each scenario in our model ranges from 3% to 22% in the bear case, 22% to 46% in the base case, and 84% to 118% in the bull case.</li><li><strong>Front is like Slack for email</strong>. It is a multiplayer tool that lets teams better communicate—via chatting with other team members within the context of a personal or shared inbox—and coordinate—via tagging, rules, and 3rd-party integrations—how they respond to email.</li><li><strong>Front's 72% DAU/MAU ratio is on par with elite, consumer-grade apps</strong>. WhatsApp was at 70% pre-Facebook acquisition. Combined with its 148 minutes of average active daily usage (compare to Slack at 90 minutes) Front effectively has the engagement of a high-grade consumer app.</li><li><strong>Front's 137% net dollar retention demonstrates they are landing and expanding with an extremely efficient bottom-up model.</strong> Compare to 143% for Slack at IPO and 140% for Zoom at IPO.</li><li><strong>Zendesk and Intercom pose a threat because they have much deeper access to customer data. </strong>Intercom embeds itself in their customers' websites, giving them direct insight into the behavior of their customers, while Zendesk serves as a centralized hub for all things sales, support, and/or knowledge management for hundreds of thousands of companies.</li><li><strong>However, Front's high engagement platform makes them attractive to third-party developers. </strong>The more activity Front can promote on its platform, and the larger the variety of integrations their customers are using, the more adoption they'll have inside organizations and the wider their moat—based on the cost of switching away to another email product—will become.</li><li><strong>Expanding across organization opens up the opportunity to "back into" $66B worth of adjacent vertical markets </strong>. While today Front is focused on facilitating third-party integrations to tools like Hubspot, Marketo, and Salesforce, building their own versions of these products would allow them to (at minimum, and per product) 2-3x their average revenue per user—today, Zendesk's Enterprise plan costs $199 a seat, while Front's most expensive plan is just $79 per seat.</li><li><strong>Building their own vertical solutions also puts Front on a converging course with Salesforce ($226B), Microsoft ($1.63T), and Google ($1.19T).</strong> Front's endgame is essentially to recreate the Google or Office 365 suite. But Microsoft was able to overtake Slack's active user count within just two years—a company that had similar ambitions. The threat Microsoft/Google pose and their ability to freely push copycat products to a user base of millions could make it extremely challenging for Front to move upmarket and reach enterprise scale.</li><li><strong>Front's product also makes them an attractive acquisition target. </strong>Rather than attempt to build their own team email product, Microsoft and/or Google could buy Front. That said, Salesforce is the company most likely to acquire Front—both because they don't have any email tool of their own yet and because there's no risk of cannibalization or customer confusion as there would be with a Microsoft/Google acquisition.</li><li><strong>Ultimately, Front’s consumer-grade engagement and ability to achieve org-wide adoption position them well to compete on their own in the cloud productivity space</strong>. Most deep workflow products serve specific functional units (Intercom, Zendesk, Salesforce) while products that serve whole teams (Outlook, Gmail) have only superficial access to customer data. Front, on the other hand, is a workflow product and an org-wide tool all in one: a combination that could make them a formidable competitor even to the 800 lb. gorillas of B2B SaaS.
</li></ul><h2 id="valuation--front-is-worth--1-3b">Valuation: Front is worth $1.3B</h2><p>Today, based on our model, we estimate Front is worth about $1.3B, with a fair share price of $9.5 to $11.</p><p>That’s up 40% from Front’s Series C, which valued the company at about $7.7 per share or $920M post-money. At the time, Front was at $26M ARR growing 5% CMGR6 for a 35x multiple.&nbsp;</p><p>Today, we project Front is at about $38M ARR or $3.1M MRR, growing 3% CMGR6.&nbsp;</p><img src="https://images.prismic.io/sacra/731caebc-6ce9-4c26-8451-56f39d4618df_image13.png?auto=compress,format"><p><em>Applying the 35x multiple from Front’s last round to their current $38M revenue run rate gives us a valuation of $1.3B and an implicit per share price of $11. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Slack, for reference, was growing at 12% CMGR6 at the same ARR. According to our model, Front hasn’t grown at more than 10% CMGR6 since the summer of 2017, with growth hanging steady around 5% CMGR between April 2019 and early 2020, then declining slightly with the onset of COVID-19 in March.&nbsp;</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/898c9394-e3df-4252-9a04-11f7995f0454_image33.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front today is at about $3.1M MRR, growing at 3% CMGR6. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s relatively slow and steady growth has been buoyed by impressive net dollar retention, though: 150% by their Series B and 137% by their Series C.&nbsp;</p><p>A large percentage of Front’s revenue comes from expansion versus bringing on new customers—based on our model, Front could grow at 2.66% monthly without any further investment in new customer acquisition.</p>
        <div>
            <p><img src="https://images.prismic.io/sacra/6b8fe508-6373-4fae-a20b-49e5ea3c01e6_image6.png?auto=compress,format"></p><div>
                <div>
                    <p>Get the full report on Front, with historical financials, appendix, and valuation framework.</p>
                    <p><a href="https://sacra.com/research/front-initiating-coverage-research-report/access" target="_blank" rel="noreferrer" content="never">Buy</a>
                </p></div>
            </div>
        </div>
    <p><em>Front’s -2.66% net monthly MRR churn creates a floor on growth. <a href="https://sacra.com/research/front-initiating-coverage-research-report/access" rel="noopener noreferrer" target="_blank">Click here</a> to get the full data set.</em></p><p>Front’s organic growth will be helped along by secular growth in the cloud-based productivity market.&nbsp;</p><p>Long-term, the total addressable market for cloud-based productivity tools is large and mostly unpenetrated, suggesting strong industry-wide growth for the next 10 to 15 years. Gartner estimates 1 billion knowledge workers worldwide. A 20% paid conversion rate with $100 - $300 contract value per year per user suggests $20 – 60 billion TAM.&nbsp;</p><p>Looking towards the future, Front’s bear, base, and bull cases hinge largely on whether the company’s growth will re-accelerate or whether it will continue to decline, and if so, how quickly it will do so:</p><ul><li>Our 5-year bull case has Front growing at 70% CAGR and reaching a $19B valuation ($600M ARR at a 30x multiple).</li><li>Our base case has them slowing to a steady 30% growth rate and being valued at a more modest $3.8B ($139M ARR on a 25x multiple).&nbsp;</li><li>In our bear case, Front’s growth slows even further, with the company reaching a …</li></ul></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sacra.com/research/front-inside-the-startup-slackifying-email/">https://sacra.com/research/front-inside-the-startup-slackifying-email/</a></em></p>]]>
            </description>
            <link>https://sacra.com/research/front-inside-the-startup-slackifying-email/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25270424</guid>
            <pubDate>Tue, 01 Dec 2020 21:49:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Five Things We Need to Know About Technological Change – By Neil Postman, 1998]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25268936">thread link</a>) | @samim
<br/>
December 1, 2020 | https://samim.io/p/2019-12-16-five-things-we-need-to-know-about-technological-change/ | <a href="https://web.archive.org/web/*/https://samim.io/p/2019-12-16-five-things-we-need-to-know-about-technological-change/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p><b>"<a href="https://samim.io/dl/Five_Things_We_Need_to_Know_About_Technological_Change_by_Neil_Postman.pdf">Five Things We Need to Know About Technological Change</a>"</b> - by <a href="https://en.wikipedia.org/wiki/Neil_Postman">Neil Postman </a>(1998) <br></p><ul><li><b>Idea 1: </b>Culture always pays a price for technology.</li><li><b>Idea 2:</b> There are always winners and losers in technological change.<br></li><li><b>Idea 3:</b> Every  technology  has  a  philosophy: “The medium is the message.”</li><li><b>Idea 4:</b> Technological change is not additive; it is ecological.</li><li><b>Idea 5:</b> Media tend to become  mythic. </li></ul><blockquote><p><b>"Conclusion:</b> And  so,  these  are  my  five  ideas  about  technological  change. <b> First</b>,  that  we  always  pay  a  price  for technology;  the  greater  the  technology,  the  greater  the  price. <b> Second</b>,  that  there  are  always  winners  and losers, and that the winners always try to persuade the losers that they are really winners. <b>Third</b>, that there is  embedded  in  every  great  technology  an  epistemological,  political  or  social  prejudice.  Sometimes  that bias  is  greatly  to  our  advantage.  Sometimes  it  is  not.  The  printing  press  annihilated  the  oral  tradition; telegraphy  annihilated  space;  television  has  humiliated  the  word;  the  computer,  perhaps,  will  degrade community life.  And so on. <b>Fourth</b>, technological change  is not additive;  it is ecological,  which  means, it changes everything and is, therefore, too important to be left entirely in the hands of Bill Gates. And <b>fifth</b>, technology tends to become  mythic; that is, perceived as  part of the  natural  order of things, and therefore tends to control more of our lives than is good for us.&nbsp;</p><p>I will close  with this thought. <b>In the past,  we experienced technological change  in  the  manner  of  sleep-walkers</b>.  <b>Our  unspoken  slogan  has  been “technology  über  alles,” and  we have been willing to shape our lives to fit the requirements of technology, not the requirements of culture. This is a form of stupidity, especially in an age of vast technological change. We need to proceed with our eyes wide open so that we many use technology rather than be used by it."</b></p></blockquote><p><b>Presentation: <a href="https://prezi.com/p/egoxlf6-bln8/neil-postmans-five-ideas-to-technological-change/">Neil Postman's Five Ideas to Technological Change</a></b></p><p><b>"The Surrender of Culture to Technology" - talk by Neil Postman </b></p><div>
	<figure>
		<div>
			<p><iframe src="https://www.youtube.com/embed/hlrv7DIHllE?rel=0" allowfullscreen="" allow="encrypted-media; accelerometer; gyroscope; picture-in-picture"></iframe></p>
		</div>
	</figure>
	
</div><p><a href="https://samim.io/tag/Technology">#Technology</a> <a href="https://samim.io/tag/Media">#Media</a> <a href="https://samim.io/tag/Politics">#Politics</a> <a href="https://samim.io/tag/Philosophy">#Philosophy</a>  </p>
      </div></div>]]>
            </description>
            <link>https://samim.io/p/2019-12-16-five-things-we-need-to-know-about-technological-change/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25268936</guid>
            <pubDate>Tue, 01 Dec 2020 19:39:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Get started with Kubernetes the Release way]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25268645">thread link</a>) | @erik_landerholm
<br/>
December 1, 2020 | https://releaseapp.io/blog/awesome-release-docker-compose-examples-working-in-release-and-kubernetes | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/awesome-release-docker-compose-examples-working-in-release-and-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><h2 id="i-needwantlove-examples">I Need/Want/Love Examples</h2><p>I know that when I try out a new product, if it’s hard to see what it does quickly I usually move on. This is a shame because I’m sure there are products out there that I could have benefited from but it was just too difficult to get something up and running.</p><p>Release is the easiest way to create environments from any code change, Pull Request or the click of a button. We deploy your environments in a Kubernetes cluster that’s completely managed for you. <em>But in order to see how Release can change how you build software, you have to get your application running in Release.</em> Most of the time this is pretty straightforward, but there is definitely a setup curve to get over before you can see our product in full form. </p><p>The best technical products I’ve used always have a TON of great examples.  Stripe is definitely the king of this idea… we were just recently integrating their checkout feature into Release and <a href="https://github.com/stripe-samples" target="_blank" rel="noreferrer">their examples repo</a> is a model for how this can be done. It made our integration with Stripe so much easier than digging through docs to figure this all out.</p><p>I think examples are highly under-done, especially with highly technical products. I’m pretty sure I know why (especially after this project): it’s hard to spend the time and energy building out examples when you have features to build. But at Release, examples are a first class citizen and we believe will make getting up and running with Release easier.</p><h2 id="awesome-compose-is-awesome">awesome-compose is awesome</h2><p>As we started building and testing Release, we came across this fantastic repository, <a href="https://github.com/docker/awesome-compose" target="_blank" rel="noreferrer">https://github.com/docker/awesome-compose</a>, that has community created applications known to work with docker-compose. </p><p>Since Release can easily use a docker-compose file to create blueprints for environments, this was a perfect way for us to test out Release and make sure all the various ways docker-compose files are used are supported in the platform. Enter awesome-release</p><h2 id="awesome-release-is-awesome">awesome-release is awesome++</h2><p>We put together an <em>awesome</em> organization in Github with a ton of repositories that just work in Release that are derived from awesome-compose.</p><p><a href="https://github.com/awesome-release" title="Awesome examples running in Release" target="_blank" rel="noreferrer">https://github.com/awesome-release</a> is chock full of amazing projects that just work. The great part about all of these projects is that they show the range of how making simple applications to complex applications can be run and environments created within Release.</p><p>So if you’re getting started and need a project that will just work out of the box, I highly recommend forking or copying any of these repos and use it to create an app in Release. Every repository in <em>awesome-release</em> just works.</p><p>We’ve made modifications to some of the awesome-compose repos that needed slight tweaks. In each README we’ve described what we did to make the project work. Most of these things are minor adjustments that enable the project to run in a hosted Kubernetes environment vs being run locally via docker-compose.</p><p><a href="https://releaseapp.io/" target="_blank" rel="noreferrer">Click here to signup for Release and give it a shot!</a></p><p>Please let us know if there is an example you’d like to see and we’ll put it together for you. Just send us an email at <a href="mailto:support@releaseapp.io" target="_blank" rel="noreferrer">support@releaseapp.io</a> and we’ll add it to the list.</p><p><strong>Have fun and happy Releasing!</strong></p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/awesome-release-docker-compose-examples-working-in-release-and-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25268645</guid>
            <pubDate>Tue, 01 Dec 2020 19:11:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to buy gifts that people actually want]]>
            </title>
            <description>
<![CDATA[
Score 334 | Comments 269 (<a href="https://news.ycombinator.com/item?id=25267847">thread link</a>) | @willpatrick
<br/>
December 1, 2020 | https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want | <a href="https://web.archive.org/web/*/https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><h2>I Love It! (I Hate It.)</h2><p>There's a sound of rustling paper. You crack the wrap at the seam. You look inside, unveiling the item within. It's...</p><p>Crap. It’s crap. It’s a crap present that you don’t want.</p><p>You lift your head and, with a beaming grin, you <em>somehow</em> manage to let out a torrent of thanks and praise for what you have just received. This is wonderful! It's just what I wanted! How did you know? I love it! I'll treasure it forever!</p><p>Within a day, it's stuffed in a drawer. Within a week, it's forgotten. Within a month, it's on eBay or off to the charity shop. Worse, it just ends up in a landfill somewhere.</p><p>If you had to guess, how many times would you say this has happened to you when you've received gifts at Christmas or on birthdays?</p><p>Here comes the even worse part: now think about how many times this might have happened with gifts<em> that you have given to others.</em></p><p><strong>Think you've got a perfect record?</strong> Think again, because you really, honestly, probably don't.</p><h2>A Lot of Gifts Aren't Actually That Good</h2><p>In 1993 - to cries of 'Grinch!' - economist Joel Waldfogel published a now-infamous paper (among certain economist circles, anyway) titled '<a href="https://graphics8.nytimes.com/images/blogs/freakonomics/pdf/WaldfogelDeadweightLossXmas.pdf">The Deadweight Loss of Christmas</a>'.</p><p>In it, Waldfogel argues that huge sums of money are wasted every year on gifts that nobody really wants. More accurately, he reported that many gift recipients valued their gifts at a dollar amount much lower than was actually paid for the item.</p><p>For example, if I bought you a gift for $100 and you thought that it was actually worth about $70 it would mean that, somewhere along the line, <em>you’ve destroyed $30</em>. Pop! It's gone. You might as well have just taken your cash and burnt it.</p><p>Waldfogel found that anywhere between 10% and 33% of all Christmas gifts cause this kind of loss every year. This is stunning, especially when we extrapolate out to the entire population.</p><p>He concludes by saying that many people could do worse than simply giving cash as a gift because it would carry more value than the actual gifts they might otherwise have bought.</p><p>Unless you are absolutely convinced that you are god's gift to... well, gift-giving, then you're probably seeing the same loss of value with your own gifts. Or, to put it another way, <strong>a lot of your gifts probably suck whether you realise it or not</strong>.</p><p>You won't see this, though, because nobody is going to turn around and tell you that your gifts were 'only 70% good'. If anything, the reactions that we get with a good gift and a bad gift are remarkably similar. Nobody wants to make you feel like a bastard at Christmas, even if you did hand out some absolute clangers.</p><p>But is it so bad, really, losing a few dollars every year? In short, yes. And then some. But not just because of the money you're wasting.</p><h2>Good Gift Giving Is Incredibly Important</h2><p>Outside of bland analysis by economists that ordinary people haven’t heard of, gift-giving helps us maintain and preserve social ties at all of life’s most important occasions; birthdays, Christmas, Valentine's day, anniversaries, graduations... you name it.</p><p>In between these occasions there is usually some kind of imbalance between the gifts that we have given to one another. That is, you might knock it out of the park one year and I might give you something that’s nowhere near as good. Next time, I'm going to want to do much better. This imbalance leads, in part, to the continuation of the tradition.</p><p>Giving good gifts help to form and strengthen social bonds. It helps us show people how much we care, how much we love them. It helps us say sorry. It helps us convey meaning. It helps us have fun and take delight in generosity. A life without giving and receiving gifts would be a dull life indeed.</p><p>On the other hand, giving bad gifts can degrade the quality of those same bonds. <strong>At best, it can be annoying to be given a bad gift. At worst, it can drive people apart.</strong> If Waldfogel's research is correct, an awful lot of us are unwittingly dropping the ball every year, without really realising it.</p><p>Luckily, it's not just economists giving their miserable analysis of the situation; a handful of psychologists have waded in and they're here to tell you that you're just <em>thinking</em> <em>about it all wrong</em>.</p><h2>Why Our Gifts Don't Work</h2><p>There's a surprising amount of research literature out there that all points in a similar direction as to why gifts don't work and what we can do about it. To find a way through this gift-giving minefield, I've gone through some of the most widely-cited papers to get to the bottom of it all. (Citations can be found at the end of this article.)</p><h3>Gift-Givers and Gift-Receivers Think Differently</h3><p>Gifts don't always hit the spot because the psychology of <em>giving</em> gifts is totally different to the psychology of <em>getting</em> gifts. Although it all happens during the same event, we unwittingly think about these two things in totally different ways.</p><p>When people <em>give</em> gifts, they typically want to nail one or more of these four different things:</p><ul role="list"><li>Surprise (the wow factor)</li><li>Desirability (the clout factor)</li><li>Materiality (the price tag)</li><li>Social responsibility (that is, looking virtuous)</li></ul><p>Gift <em>receivers</em>, though? <strong>Their priorities are completely different</strong>. They want:</p><ul role="list"><li>Usefulness (can I do something with it?)</li><li>Versatility (can I do a variety of things with it?)</li><li>Quality (is it well made/going to last?)</li><li>Stuff they've asked for (did I actually say I want this?)</li></ul><p>Given the difference between these two lists, is it any wonder that some gifts simply don't hit the mark?</p><h3>We Focus too Much on The Moment of Exchange</h3><p>When we give gifts we are mostly thinking about 'the moment' in which we hand it over, seeing the reaction of our recipients. We narcissistically want the chorus of 'oohs' and 'aahs' that come with nailing a really good gift that somebody loves. Whether or not those reactions last any longer than the moment of exchange, though, is not something that gift givers really care about.</p><p>Research shows that we make greater errors with gift giving when those gifts are being opened in public - perhaps at a party - than when we give them in private - such as wedding presents.</p><p>This is because<strong> we end up optimising for the maximum showboat potential of the gifts we give</strong> because it feels good to do so well in public. Once the event is over, though, we basically forget about it all. Onto the next thing.</p><p>Not so for the gift recipient. After the party is over and everyone's gone home... they've still got the gift. It matters much more to them what comes <em>after</em> the moment of exchange.</p><p>This means that it's better to buy a gift that has greater long term appeal than just the momentary 'wow' factor, even if it doesn't feel as good to us in the moment.</p><h3>We Like to Be Given Experiences... But We Don't Like to Gift Them</h3><p>Research shows that an 'experience' gift - like a night out at the theatre or a wine tasting course - is often preferred instead of the usual variety of material gifts that get doled out every year.&nbsp;</p><p>The only problem is that gift-givers don't really like to give experiences as gifts because the moment of exchange is relatively dull. This is usually because there's some stand-in that gets handed over - a voucher or a certificate - and the response is likely to be bland at best.</p><p>The <em>real</em> excitement comes much later when they cash that voucher in. But, of course, the gift-giver can’t actually be there to see that happen. No good.</p><h3>We Care too Much About the Price</h3><p>Gift-givers tend to believe that the more generous or pricey a gift is, the better it must be. This rarely works. For recipients, the absolute quality of the gift matters much more. This is equally true for something that the giver thinks is really thoughtful, too.</p><p>This happens when we put an enormous amount of thought and money into a gift for a friend or relative, <strong>only to find that they have no interest in it.&nbsp;</strong></p><p>A good example of this might be picking up on someone's love for music and then buying them a beautiful acoustic guitar. There's little guarantee that they have any interest in playing an instrument at all, no matter how expensive it is or how much thought you put into it.</p><p>If they're not regularly playing that thing a year later, you’ve probably goofed.</p><h3>We're Too Distant</h3><p>If you're genuinely quite distant from the gift recipient, it's almost impossible to get a good gift for them that they will genuinely want. This means one of two things:</p><ol role="list"><li>You probably shouldn't bother, or</li><li>You can give them cash (or a cash equivalent)</li></ol><p>Whether or not you <em>should</em> give them cash is another question. If they're your grandchildren this is absolutely fine. If they're your grandparents, perhaps not.</p><p>In the latter instance, a good 'consumable' like a decent bottle of wine or a box of chocolates will do. But don't worry about it much more than that.</p><h3>Be Careful With Charity Gifts</h3><p>Sadly, recipients are less grateful about virtuous charitable gifts than we would hope for. While they're good for the cause, they don't score well against the ways in which we normally value gifts. They make the gift giver look good and they feel good in the moment, but they are not valued as much. </p><p>Of course, if someone tells you that they would value a charitable gift then go for it. But don't assume that anybody will actually like it as a gift unless you have discussed it in advance.</p><h2>How to Buy Gifts People Actually Want</h2><p>All hope is not lost. You <em>shall</em> buy gifts that people will actually want! Here's how.</p><h3>Be Realistic About Your Relationship With The Recipient</h3><p>In Waldfogel's 1993 study, there's a chart of gift effectiveness that more or less screams at aunts, uncles and grandparents to simply not bother with material gifts and to give cash instead:</p><figure id="w-node-9f5a4418121f-c39ae183"><p><img src="https://uploads-ssl.webflow.com/5e8b192239b9b4843e9ae18f/5fbfe9af234e056f30021f18_GTfsGCvFwKV3s1qidXi6Ls7EIYGoOQBVRr8o_3XvvwZ6IHt4QwNvAaje0p8Il8hWv-Yz1jcRU9A98nTmQMijJOrXU6E6gZC5FSi4_f_WOLuJY2XXZtR2CCIEYZsyAMvYo1P60Hr3.jpeg" alt=""></p></figure><p>Are you soulmates, together as a couple for many years? You obviously stand a much higher chance of getting the recipient something they will actually want.</p><p>If you’re anyone else, you will have a harder time and should maybe not worry so much about making sure your gift is as ‘thoughtful’ as possible and just focus on making their gift useful or buying them an experience.</p><h3>...Ask Them What They Want</h3><p>It seems obvious, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want">https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want</a></em></p>]]>
            </description>
            <link>https://www.willpatrick.co.uk/articles/how-to-buy-gifts-that-people-actually-want</link>
            <guid isPermaLink="false">hacker-news-small-sites-25267847</guid>
            <pubDate>Tue, 01 Dec 2020 18:06:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-Hosting Still Pays]]>
            </title>
            <description>
<![CDATA[
Score 376 | Comments 328 (<a href="https://news.ycombinator.com/item?id=25267651">thread link</a>) | @emperor_
<br/>
December 1, 2020 | https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image.jpg" data-caption="Colo V AWS 2020 Cover Image"><img width="696" height="392" src="https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-696x392.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image-747x420.jpg 747w, https://www.servethehome.com/wp-content/uploads/2020/11/Colo-v-AWS-2020-Cover-Image.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Colo V AWS 2020 Cover Image" title="Colo V AWS 2020 Cover Image"></a><figcaption>Colo V AWS 2020 Cover Image</figcaption></figure></div>
            <!-- content --><p>Years ago, we had a big decision to make. In 2013, STH had grown to a size that would seem immeasurably small by the traffic we do today. Still, at that point, we made the decision that it made fiscal sense to leave Amazon AWS for colocation. We chronicled the reasoning in <a href="https://www.servethehome.com/falling-sky-sth-leaving-cloud-amazon-aws/">Falling From the Sky Why STH is Leaving the Cloud</a> and then the cost breakdown in&nbsp;<a href="https://www.servethehome.com/falling-sky-part-3-evaluating-amazon-ec2-vps-dedicated-colocation-options/">Falling From the Sky Part 3 – Evaluating Amazon EC2, VPS, Dedicated and Colocation Options</a>. Since 2013, we have been doing some irregular updates that largely correspond to planned upgrades of our infrastructure. Since we are taking a look at a few upgrades again, it is time to go through the exercise again.<span id="more-48850"></span></p>

<p>If you want to hear this instead of just reading, we have a YouTube video with some commentary here:</p>
<p><iframe title="Our Colocation Hosting versus AWS Costs Compared 2020 Edition" width="696" height="392" src="https://www.youtube.com/embed/RqetN_i0BnE?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Of course, we can go into a bit more detail below, but some prefer to listen rather than read so we have that option.</p>

<p>In 2018, we looked again at whether it was time to move back to the cloud. In our cost analysis, this is what we found using 1-year estimates:</p>
<figure id="attachment_26722" aria-describedby="caption-attachment-26722"><a href="https://www.servethehome.com/falling-from-the-sky-part-4-leaving-the-cloud-5-years-later/sth-2018-web-hosting-budget-v-aws/" rel="attachment wp-att-26722"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS.jpg" alt="STH 2018 Web Hosting Budget V AWS" width="536" height="156" srcset="https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS.jpg 536w, https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS-400x116.jpg 400w, https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS-533x156.jpg 533w, https://www.servethehome.com/wp-content/uploads/2018/03/STH-2018-Web-Hosting-Budget-v-AWS-534x156.jpg 534w" sizes="(max-width: 536px) 100vw, 536px"></a><figcaption id="caption-attachment-26722">STH 2018 Web Hosting Budget V AWS</figcaption></figure>
<p>Just to give some sense of how that March 2018 estimate has gone in the 32 months since we looked at this, we ended up using:</p>
<ul>
<li>Way more bandwidth. STH has grown a ton since 2018. We also focus more on reviews which tend to use more photos. Even with lazy loading images, our bandwidth usage is significantly higher. This did not incur an incremental cost based on how we buy bandwidth. See: <a href="https://www.servethehome.com/buyers-guide-hosting-bandwidth-data-transfer-billing/">Buyer’s Guide to Hosting: Bandwidth, Data Transfer and Billing</a></li>
<li>Several of our VMs doubled memory requirements and we added slightly more storage. We overprovisioned so this was absorbed with still enough leftover.</li>
<li>We replaced a <a href="https://www.servethehome.com/9-step-calm-and-easy-proxmox-ve-boot-drive-failure-recovery/">SSD</a>, upgraded a firewall, and added another <a href="https://www.servethehome.com/explaining-the-automatic-transfer-switching-ats-pdu/">ATS PDU</a>. We have not done long-term infrastructure upgrades.</li>
<li>We ended up using an upgraded node that we had available, as a “hot spare”. We tend to “self-warranty” hardware, and so we had an extra system/ chassis there.</li>
<li>We are going to say we used four hours of labor. This includes drive time to the primary data center. Since it is far away (18-20 minute drive), we actually did not go there for several quarters. So over 32 months, we had budgeted $640 for remote hands. We effectively either paid $160/ hr or paid less than that even rounding up to four hours.</li>
</ul>
<p>Overall, it looks like we probably over-estimated self-hosting costs again, and underestimated AWS costs with respect to how much we would spend there, even after service discounts.</p>
<h2>The Late 2020 AWS v. Colocation Update</h2>
<p>We wanted to answer the question of what the picture would look like for hosting STH now. A few quick words before we get there on assumptions.</p>
<p>First off, we completely could change the way we run the site. That is a given. Frankly, running in VMs whether on the cloud or in self-hosting is convenient. Indeed, we run containers in VMs as well. We could also overhaul the entire software stack again, but frankly, we want to spend more time creating content then doing that work. Something that we learned was that we had less reliability by increasing complexity than by keeping things as simple as possible.</p>
<p>Second, we are modeling current data transfer, and a minimal set of VMs. We actually have a lot more running, including some services that we run for some of the labs. One could argue that since they are lab services they are part of bringing you STH, but they are not focused on the web hosting aspect so we are going to remove them. Also, we have other VMs that are likely only online because we wanted to try something and had capacity. We may or may not elect to run the VMs if there was the AWS incremental cost. We could model these as on-demand or spot instances, but instead, we are just removing them entirely.</p>
<p>Third, we completely understand spot pricing. We are modeling a basic set instead of adding extras. At some point, we need databases, nginx servers, and so forth.</p>
<p>Fourth, we are going to add a mix of AMD EPYC and Intel Xeon instances roughly about what we use for our hosting. We are heavily weighting the larger instances toward the EPYC instances since that helps bring down the costs and for our workloads, there is no appreciable difference. We could go Arm, but that requires some small lift and shift work.</p>
<p>Finally, we do use some AWS services. Those services we would use regardless so we are excluding them from the analysis. We are also not modeling services such as Mailchimp which handles our weekly newsletter, Teespring that handles our online merch shop, YouTube which hosts our videos, and so forth.</p>
<h3>AWS Cost 1-Year Reserved No Upfront</h3>
<p>Here is the calculator for the absolute base setup for our hosting using 1-year reserved upfront instances:</p>
<figure id="attachment_48851" aria-describedby="caption-attachment-48851"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-calculator-1-year-reserved-no-upfront/" rel="attachment wp-att-48851"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront.jpg" alt="2020 AWS Calculator 1 Year Reserved No Upfront" width="1114" height="222" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront.jpg 1114w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-400x80.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-800x159.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-696x139.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Reserved-No-Upfront-1068x213.jpg 1068w" sizes="(max-width: 1114px) 100vw, 1114px"></a><figcaption id="caption-attachment-48851">2020 AWS Calculator 1 Year Reserved No Upfront</figcaption></figure>
<p>As you can see, our hosting costs are just under $4,300 per month.</p>
<h3>AWS Cost 1-Year Reserved Partial Upfront</h3>
<p>Swapping to 1-year reserved partial up-front on the instances helps bring pricing down a bit albeit with a $19,512 up-front cost.</p>
<figure id="attachment_48853" aria-describedby="caption-attachment-48853"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-calculator-1-year-partial-upfront/" rel="attachment wp-att-48853"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront.jpg" alt="2020 AWS Calculator 1 Year Partial Upfront" width="1112" height="242" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront.jpg 1112w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-400x87.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-800x174.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-696x151.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-1-Year-Partial-Upfront-1068x232.jpg 1068w" sizes="(max-width: 1112px) 100vw, 1112px"></a><figcaption id="caption-attachment-48853">2020 AWS Calculator 1 Year Partial Upfront</figcaption></figure>
<p>When we factor in the up-front we get a $4,137.63 monthly cost along with a $49,651.56 total annual cost for the year. We are not discounting here using future values/ present values. There is a big issue with this. Typically, we tend to see our servers run for years. To model that, we tend to use 3-year reserved partial upfront.</p>
<h3>AWS Cost 3-Year Reserved Partial Upfront</h3>
<p>Using the 3-year reserved partial upfront on the instances gives us a much lower operating cost with a larger up-front payment.</p>
<figure id="attachment_48852" aria-describedby="caption-attachment-48852"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-calculator-3-year-partial-upfront/" rel="attachment wp-att-48852"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront.jpg" alt="2020 AWS Calculator 3 Year Partial Upfront" width="1117" height="247" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront.jpg 1117w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-400x88.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-800x177.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-696x154.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-Calculator-3-Year-Partial-Upfront-1068x236.jpg 1068w" sizes="(max-width: 1117px) 100vw, 1117px"></a><figcaption id="caption-attachment-48852">2020 AWS Calculator 3 Year Partial Upfront</figcaption></figure>
<p>First off, the $39,020 is more than we have spent in the last three years on hosting hardware. We do not purchase machines with long warranties or high markups, so if you are buying the average Dell/ HPE/ Lenovo server and think that sounds like a single server, you are trading higher upfront costs for service contracts. Given what we have seen on hardware/ remote hands, it is not a model we are pursuing. On the operating side, we get down to $1,968.51 per month which is great.</p>
<h2>STH 2020 Hosting Budget</h2>
<p>Next year, we will likely do two small changes. First, we will upgrade database nodes and instead of using Optane SSDs, we will move to Cascade Lake and Optane PMem DIMMs into the database servers and upgrade a few older nodes to AMD EPYC 7002 “Rome” systems. We are testing the Ampere Altra 80-core server right now, and we are at the point where we might consider using Arm in the hosting cluster this year. We are going to increase our hardware budget to $10,000 this year. Although we did not use most of our hardware budget in 2019 nor 2020, we expect to in 2021.</p>
<p>Making up our monthly cost, we increased a bit for inflation. We used a $895/ mo budget in 2018. Our costs are effectively flat, but we are going to assume a bit more labor to install servers/ upgrade the hardware.</p>
<figure id="attachment_48855" aria-describedby="caption-attachment-48855"><a href="https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/2020-aws-v-self-hosting/" rel="attachment wp-att-48855"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-v-Self-Hosting.jpg" alt="2020 AWS V Self Hosting" width="685" height="197" srcset="https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-v-Self-Hosting.jpg 685w, https://www.servethehome.com/wp-content/uploads/2020/11/2020-AWS-v-Self-Hosting-400x115.jpg 400w" sizes="(max-width: 685px) 100vw, 685px"></a><figcaption id="caption-attachment-48855">2020 AWS V Self Hosting</figcaption></figure>
<p>We are budgeting $22,000 per year or around $1833.33 per month. This is about the same as we would need for EC2’s 3-year partial upfront reserved instance, albeit without the up-front costs.</p>
<p>The one item that skews this substantially, is that we are not replacing every node every year. We are now in a very different place than we were when we started this journey. We have existing infrastructure that is frankly fine from a performance and node count standpoint even though we have relatively under-invested over the past 32 months. We had budgeted around $1687/ month for the last two months and spent under $1000. Still, at some point, we like to replace equipment before it fails.</p>
<h2>Final Words</h2>
<p>There is clearly a lot going into this. We now have just under 8 years since this 10U colocation spot in Las Vegas was our first setup:</p>
<figure id="attachment_8644" aria-describedby="caption-attachment-8644"><a href="https://www.servethehome.com/colocation-architecture-servethehome-2013/sth-colo-10u-rear-picture-annotated-small/" rel="attachment wp-att-8644"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small.png" alt="STH Colo 10U Rear Picture - Annotated small" width="600" height="394" srcset="https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small.png 600w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-300x197.png 300w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-16x11.png 16w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-32x21.png 32w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-28x18.png 28w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-56x37.png 56w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-64x42.png 64w, https://www.servethehome.com/wp-content/uploads/2013/02/STH-Colo-10U-Rear-Picture-Annotated-small-184x120.png 184w" sizes="(max-width: 600px) 100vw, 600px"></a><figcaption id="caption-attachment-8644">STH Colo 10U Rear Picture – Annotated small</figcaption></figure>
<p>What is not reflected in our discussion is all of the lessons learned along the way. Also, as hardware has gotten faster, and memory prices have decreased, the cost of self-hosting has gone down significantly for our applications. We are also taking advantage of falling bandwidth prices. While AWS is absolutely the right choice for many applications, and indeed we use them, for our web hosting it is not what we want for a simple and inexpensive setup. This may not be the perfect analysis, but it is a little bit of how we now look at hosting at STH.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/falling-from-the-sky-2020-self-hosting-still-pays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25267651</guid>
            <pubDate>Tue, 01 Dec 2020 17:50:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Update on PromQL Compatibility Across Vendors]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25267601">thread link</a>) | @jrv
<br/>
December 1, 2020 | https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors | <a href="https://web.archive.org/web/*/https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Prometheus's query language <a href="https://prometheus.io/docs/prometheus/latest/getting_started/">PromQL</a> is one of the cornerstones of the Prometheus ecosystem. Back in our August blog post, <a href="https://promlabs.com/blog/2020/08/06/comparing-promql-correctness-across-vendors">Comparing PromQL Correctness Across Vendors</a>, we looked at several external projects and monitoring vendors that claimed to offer PromQL-compatible APIs. Using an <a href="https://github.com/promlabs/promql-compliance-tester">open-source compliance checker tool</a>, we evaluated each implementation by running a set of test queries against both the native Prometheus server and the vendor implementation. As a result, we found multiple bugs in the tested projects, and mapped out in detail how each deviated from the upstream implementation.</p>
<p>Meanwhile, more vendors have entered the PromQL space, while existing projects have worked on improving their PromQL support as a result of our last blog post. Today, we are presenting an updated set of PromQL test results both for existing projects and a couple of new ones. We tested each of these implementations against the latest Prometheus version, <a href="https://github.com/prometheus/prometheus/releases/tag/v2.23.0">v2.23.0</a>.</p>
<h3 id="before-we-start-a-note-on-interpreting-test-scores"><a href="#before-we-start-a-note-on-interpreting-test-scores" aria-label="before we start a note on interpreting test scores permalink"></a>Before we start: a note on interpreting test scores</h3>
<p>When looking at individual test results, please note that the numeric scores alone paint a limited picture. They don't necessarily tell you how impactful implementation errors are, nor how many distinct behavioral differences there are. Since PromQL expressions naturally compose and build on top of each other, it is infeasible to isolate all possible query errors into fully independent test cases. Many of the test queries will contain the same constructs as other queries, in a nested way. For example: If an implementation selects data incorrectly, then this breaks not only a simple data selection test query, but also all other test query cases that try to run a function, operator, or other transformation based on selected data. The test cases also include a lot of variations of the same type of query, but with different ranges, quantile values, or other parameters. So if e.g. a function is broken in a general way, it may cause multiple test case variants to fail at the same time.</p>
<p>Another matter of more subtle interpretation are vendor extensions and extreme edge-case behavior. For example, a vendor may choose to not raise an error when executing a function with a parameter value that is illegal in native PromQL, but legal and sensical in the extended language. Or a vendor may return a different value for an unusual edge-case behavior, such as running <code>histogram_quantile()</code> with a quantile value larger than <code>1</code>.</p>
<p>We still provide the numeric test scores as a quick way to map out the vendor landscape and to motivate the ecosystem towards achieving a 100% score. But if you need to understand behavioral differences in more depth, please <a href="https://promlabs.com/promql-compliance-tests">take a look at the full test results</a> and read on for the details.</p>
<h3 id="criteria-for-including-a-vendor-in-tests"><a href="#criteria-for-including-a-vendor-in-tests" aria-label="criteria for including a vendor in tests permalink"></a>Criteria for including a vendor in tests</h3>
<p>We are always on the lookout for new PromQL implementations to include in these tests. To include a project or vendor, we look for two criteria:</p>
<ul>
<li>Someone is either advertising full or partial PromQL compatibility of their system, and/or otherwise positioning their solution as a drop-in replacement for an existing PromQL implementation.</li>
<li>For practical purposes, we need to be able to ingest test data into the system and query it back via a PromQL-style HTTP API. Otherwise, we can't run any tests.</li>
</ul>
<p>Unfortunately, some vendors failed the second criterium for now, so we couldn't include them:</p>
<ul>
<li><a href="https://sysdig.com/">Sysdig</a> <a href="https://docs.sysdig.com/en/using-promql.html">advertises PromQL support</a>, but has no <code>remote_write</code> protocol support to ingest arbitrary test data. According to contacts at Sysdig, <code>remote_write</code> may be supported at some point in the future, but we couldn't get a recent update on its availability timeline.</li>
<li><a href="https://www.vmware.com/de/company/acquisitions/wavefront.html">Wavefront</a> <a href="https://docs.wavefront.com/wavefront_prometheus.html">advertises partial PromQL support</a>, but they lack an HTTP endpoint against which to run test queries. Their PromQL support is only available within their own user interface so far, which makes it difficult to test against. However, judging by the various compatibility caveats listed in their documentation, we do not expect that they would reach a high test score if we could test them.</li>
</ul>
<p>We hope to be able to test even more vendors in the future.</p>
<p><strong>UPDATE:</strong> After publishing, we received questions about PromQL support in two more vendors:</p>
<ul>
<li><a href="https://www.influxdata.com/products/influxdb/">InfluxDB</a> once <a href="https://github.com/influxdata/promql">started implementing PromQL support</a> (coincidentally with the help of the author of this blog post), but as far as we are aware, this effort has been paused and PromQL support in InfluxDB is neither currently available nor is it being advertised.</li>
<li><a href="https://www.elastic.co/">Elastic</a> recently <a href="https://www.elastic.co/blog/elastic-metrics-7-7-0-released">advertised PromQL support in Elastic Metrics</a>. However, the announced feature is only about Elastic Metrics being able to run queries against an <em>existing</em> external PromQL endpoint (such as Prometheus) to then ingest the query result as metrics into Elasticsearch. There is no way to run PromQL on the resulting data stored in Elasticsearch itself.</li>
</ul>
<h3 id="minor-updates-to-the-test-query-set"><a href="#minor-updates-to-the-test-query-set" aria-label="minor updates to the test query set permalink"></a>Minor updates to the test query set</h3>
<p>Since the last testing round in August, we made minor changes to the test query set:</p>
<ul>
<li>For queries that looked at the absolute values of counter metrics (e.g. with no <code>rate()</code> or similar counter-related function applied), we changed the selected metrics to be gauges instead. This helps keep test cases somewhat more independent for a vendor like New Relic, which does not support storing or retrieving absolute values for counters.</li>
<li>We added a query selecting an intermittently present series to test whether <a href="https://prometheus.io/docs/prometheus/latest/querying/basics/#staleness">staleness handling</a> works.</li>
</ul>
<h3 id="lets-get-started-updated-comparisons"><a href="#lets-get-started-updated-comparisons" aria-label="lets get started updated comparisons permalink"></a>Let's get started: Updated comparisons</h3>
<p>In this round of tests, we tested the following projects and vendors, in alphabetical order:</p>
<ul>
<li><a href="https://chronosphere.io/">Chronosphere</a> - A hosted monitoring and observability platform.</li>
<li><a href="https://cortexmetrics.io/">Cortex</a> - An open-source, horizontally scalable reimplementation of Prometheus.</li>
<li><a href="https://grafana.com/products/cloud/">Grafana Cloud</a> - A hosted monitoring and observability service.</li>
<li><a href="https://m3db.io/">M3</a> - An open-source metrics engine and time series database.</li>
<li><a href="https://www.metricfire.com/">MetricFire</a> - A hosted monitoing and observability service.</li>
<li><a href="https://newrelic.com/">New Relic</a> - A hosted monitoring and observability service.</li>
<li><a href="https://thanos.io/">Thanos</a> - An open-source project to provide query aggregation for long-term storage and HA on top of Prometheus.</li>
<li><a href="https://github.com/timescale/promscale">Promscale</a> (<a href="https://www.timescale.com/">TimescaleDB</a>) - An open-source project to store Prometheus data in TimescaleDB.</li>
<li><a href="https://victoriametrics.com/">VictoriaMetrics</a> - An open-source time-series database and monitoring system.</li>
</ul>
<p>Let's look at the test results for each of these systems:</p>
<h4 id="chronosphere"><a href="#chronosphere" aria-label="chronosphere permalink"></a>Chronosphere</h4>
<p>Chronosphere does not have a self-service account creation system yet, but they helpfully provided us with a test account with <code>remote_write</code> and PromQL HTTP API support. Chronosphere is built on top of M3 (tested below), so we expected similar test results for the two. After an initial test run against an outdated test environment using an older M3 version, Chronosphere updated our test account and we achieved a test score of <strong>100%</strong> against it.</p>
<h4 id="cortex"><a href="#cortex" aria-label="cortex permalink"></a>Cortex</h4>
<p>Last time we tested Cortex we encountered two minor issues: floating-point input timestamps were <a href="https://github.com/cortexproject/cortex/issues/2932">not rounded in the same way</a> as in Prometheus, and the system did not <a href="https://github.com/cortexproject/cortex/issues/416">support executing queries without a metric name</a>. The first issue has been resolved entirely, while the second one is being addressed by a new storage mode in Cortex - the new <a href="https://cortexmetrics.io/docs/blocks-storage/">blocks storage mode</a> vs. the older <a href="https://cortexmetrics.io/docs/chunks-storage/">chunks storage mode</a>.</p>
<p>Let's look at <a href="https://github.com/cortexproject/cortex/releases/tag/v1.5.0">version 1.5.0 of Cortex</a> and see what scores each of these modes received:</p>
<h6 id="cortex-with-chunks-storage"><a href="#cortex-with-chunks-storage" aria-label="cortex with chunks storage permalink"></a>Cortex with chunks storage</h6>
<p>When testing Cortex with the old chunks storage, we can now remove the query tweak to align input timestamps, since that bug has been fixed. Other than that, we still get the same test score of <strong>99.62%</strong> due to the chunks mode not supporting queries without metric names.</p>
<h6 id="cortex-with-blocks-storage"><a href="#cortex-with-blocks-storage" aria-label="cortex with blocks storage permalink"></a>Cortex with blocks storage</h6>
<p>Cortex with blocks storage mode now also does not require any query tweaks anymore and passes with a score of <strong>100%</strong>.</p>
<h4 id="grafana-cloud"><a href="#grafana-cloud" aria-label="grafana cloud permalink"></a>Grafana Cloud</h4>
<p>Grafana Cloud is a new test candidate that <a href="https://grafana.com/docs/grafana-cloud/metrics/prometheus/">advertises full hosted Prometheus functionality</a>. Under the hood, Grafana Cloud uses Cortex to offer this service. According to representatives from Grafana Labs, they are in the process of phasing out the last (shared) chunks-based Cortex cluster, while all new Cortex clusters are already using blocks as their storage mode.</p>
<p>To be able to cache PromQL queries, Grafana Cloud aligns incoming query start and end timestamps to the query resolution step width (10 seconds in our case). This is currently not configurable on the Grafana Cloud side, so we had to apply a cross-cutting query tweak to align input timestamps to our reference Prometheus server in the same way, to get comparable results.</p>
<p>With this in mind, we tested a Grafana Cloud account via <code>remote_write</code> and their Prometheus-style HTTP query API on both the remaining legacy cluster and a new dedicated blocks-storage cluster, and we got the same <strong>99.62%</strong> and <strong>100%</strong> test scores as for Cortex itself. Since the chunks-mode cluster is being retired this month, we count that as an overall <strong>100%</strong> score for Grafana Cloud.</p>
<h4 id="m3"><a href="#m3" aria-label="m3 permalink"></a>M3</h4>
<p>M3 is also a new candidate in this group that states, "M3 can be used as Prometheus Remote Storage and has 100% PromQL compatibility", <a href="https://m3db.io/">on its homepage</a>. Its documentation also mentions <a href="https://m3db.github.io/m3/integrations/prometheus/">Prometheus and PromQL integrations</a> that include <code>remote_write</code> support and a PromQL HTTP API endpoint. Using these with M3 version v1.0.0, we ran our test suite and received a test score of <strong>100%</strong>.</p>
<p><strong>Note:</strong> For PromQL to work 100% the same as in Prometheus, we had to ensure that our test query was only hitting raw, non-aggregated data in M3 (vs. data that has been downsampled into a lower resolution). We did this by not configuring any aggregation in our test M3 database.</p>
<h4 id="metricfire"><a href="#metricfire" aria-label="metricfire permalink"></a>MetricFire</h4>
<p>MetricFire, a hosted service by the people behind <a href="https://www.hostedgraphite.com/">hostedgraphite.com</a>, is still pretty new in the Prometheus space. While MetricFire documents how to write data into the system using the <code>remote_write</code> protocol, there is no officially supported way to run external PromQL queries against the collected data using an HTTP API yet. However, MetricFire representatives kindly explained a way to do this. We won't detail it here, but we expect that there will be a documented public HTTP API soon. In our talks with MetricFire we learned that they also use Cortex to back their service, and we also …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors">https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors</a></em></p>]]>
            </description>
            <link>https://promlabs.com/blog/2020/11/26/an-update-on-promql-compatibility-across-vendors</link>
            <guid isPermaLink="false">hacker-news-small-sites-25267601</guid>
            <pubDate>Tue, 01 Dec 2020 17:46:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[REBASE'20 talk: Lies we tell ourselves about developer infrastructure]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25267166">thread link</a>) | @programLyrique
<br/>
December 1, 2020 | http://rebase-conf.org/2020/#lies-we-tell-ourselves-about-developer-infrastructure | <a href="https://web.archive.org/web/*/http://rebase-conf.org/2020/#lies-we-tell-ourselves-about-developer-infrastructure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="about">
  <div>
    <!-- <h2 class="about__heading">About</h2> -->
    <div>
      <!-- TODO can we make the rebase text "ff-market-web",cursive; or something like that? -->
      <p>
        <strong>Rebase</strong> is a new conference for and by practitioners who want to engage academics about tomorrow's technologies while fondly recalling the achievements of yesterday.
      </p>
      
      <p>
        This year, <strong>Rebase</strong> was planned to occur twice, once in Berlin
        with the <a href="https://2020.ecoop.org/">ECOOP</a> conference and
        once in Chicago with the <a href="https://2020.splashcon.org/">SPLASH</a> conference.
        Due to outside forces, there will be a single virtual event.
      </p>
      
      <p>
        <strong>Rebase</strong> will use the Clowdr platform for interaction,
        registration allows attendees to ask questions and meet with each other
        and with speaker. Registration also give access to all of the
        <a href="https://2020.splashcon.org/">SPLASH</a> co-located events.
      </p>
      
      <p>
        <strong>Rebase is free. All talks were streamed live and are now available on <br> <a href="https://www.youtube.com/playlist?list=PLyrlk8Xaylp6aNlOgiyE4W30X7DpXx74m"><i></i>&nbsp;YouTube</a>.</strong>
        
      </p>
    </div>
  </div>
</section></div>]]>
            </description>
            <link>http://rebase-conf.org/2020/#lies-we-tell-ourselves-about-developer-infrastructure</link>
            <guid isPermaLink="false">hacker-news-small-sites-25267166</guid>
            <pubDate>Tue, 01 Dec 2020 17:13:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Computer Graphics from Scratch (2017)]]>
            </title>
            <description>
<![CDATA[
Score 286 | Comments 43 (<a href="https://news.ycombinator.com/item?id=25266812">thread link</a>) | @fanf2
<br/>
December 1, 2020 | https://www.gabrielgambetta.com/computer-graphics-from-scratch/ | <a href="https://web.archive.org/web/*/https://www.gabrielgambetta.com/computer-graphics-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<header>

</header>
<p>
No Starch Press is publishing a book based on this website in early 2021. Stay tuned!
</p>
<p><strong>TL;DR:</strong> This book will <em>not</em> teach you how to use OpenGL or DirectX; instead, it can teach you how OpenGL and DirectX <em>work</em>. In practice you won’t write a software renderer for production use, but understanding how and why a renderer works will let you use OpenGL and DirectX more effectively.</p>
<p>Computer Graphics is a fascinating topic - how do you make <em>Toy Story</em> out of algorithms and some geometric data? Interestingly enough, it’s a mysterious topic not only for the average cinema fan, but also for world-class engineers who just haven’t been exposed to it.</p>
<p>Computer Graphics is also a frighteningly broad topic. From 3D rendering to photographic image filters, from fonts to particle systems, there’s a multitude of disciplines that can be categorized under CG. This work focuses exclusively on 3D rendering.</p>
<p><strong>Computer Graphics from scratch</strong> is my humble attempt to demystify that slice of Computer Graphics in an accessible way. It can be easily understood by high-school students, while covering the same topics of an university course. It is, in fact, based on my years of teaching the subject at my university.</p>
<p>There’s little pre-requisite knowledge, nor hardware or software dependencies. The only primitive used in the book is a method that lets us set the color of a pixel - hence <strong>“from scratch”</strong>. The algorithms are conceptually simple, and the math is straightforward. There is some high-school level trigonometry. There’s some basic Linear Algebra as well, but I’m including an appendix that can be consulted as necessary.</p>
<p>This work is divided in two main parts, <strong>Raytracing</strong> and <strong>Rasterization</strong>, which focus on the two main ways to make pretty pictures out of data. The <strong>Common concepts</strong> chapter introduces some basic knowledge necessary to understand these two parts.</p>
<p>The focus of this work is not on performance, but on clear conceptual exposition. The sample code is, well, <em>sample code</em>, written in the most <em>clear</em> way possible, which may not be the most <em>efficient</em> way to implement the algorithms. Where there are different ways to do something, I’ve chosen the easiest to understand.</p>
<p>The “end result” of this work is two complete, fully functional renderers: a raytracer and a rasterizer. Although they follow very different approaches, they produce similar results when used to render a simple scene:</p>
<figure>
<img src="https://www.gabrielgambetta.com/computer-graphics-from-scratch/images/comparison-1.png">
</figure>
<p>While their sets of features have considerable overlap, they aren’t identical, so this book covers their specific strengths:</p>
<figure>
<img src="https://www.gabrielgambetta.com/computer-graphics-from-scratch/images/comparison-2.png">
</figure>
<p>The book provides sample code throughout the text, as somewhat informal pseudocode; it also provides fully working implementations written in JavaScript that can run directly on your browser, rendering to a <code>canvas</code> element.</p>
<h2 id="why-read-this">Why read this?</h2>
<p>This work should give you all the knowledge necessary to write software renderers. Although in the age of GPUs few people have good reasons to write a pure software renderer, the experience of writing one is valuable for the following reasons:</p>
<ol type="1">
<li><p><strong>Shaders</strong>. The first GPUs had their algorithms hardcoded in hardware, but in modern ones you’re expected to write your own shaders. In other words, you’re still implementing big chunks of rendering software, except it now runs on the GPU.</p></li>
<li><p><strong>Understanding</strong>. Whether you’re using a fixed pipeline or writing your own shaders, <em>understanding</em> what’s going on behind the scenes lets you use the fixed pipeline better and write better shaders.</p></li>
<li><p><strong>Fun</strong>. Few areas of Computer Science have the kind of immediately visible results offered by Computer Graphics. The sense of accomplishment you get when your SQL query runs just right is <em>nothing</em> compared to what you feel the first time you get ray traced reflections right. I taught Computer Graphics at my university for 5 years. I often wondered why I enjoyed teaching the same thing semester after semester for so long; in the end, what made it worth it was seeing the faces of my students light up and use their first renders as desktop backgrounds.</p></li>
</ol>
<h2 id="work-in-progress">Work in progress</h2>
<p>This is a work in progress. Here’s a non-exhaustive to do list:</p>
<ul>
<li>Texture filtering</li>
<li>Normal mapping</li>
<li>Textures in the raytracer</li>
<li>Shadows in the rasterizer (stencil and shadow maps)</li>
<li>Reflection in the rasterizer</li>
<li>Expand the CSG and Refraction sections into chapters</li>
<li>Linear algebra appendix</li>
<li>Make demos interactive</li>
<li>Clean up demo code</li>
</ul>
<p>Feel free to contribute or to correct mistakes - all the text, diagrams and demos are in <a href="https://github.com/ggambetta/computer-graphics-from-scratch">Github</a>. PRs welcome!</p>

<p>I’m a senior software engineer at Google. In the past I’ve worked at <a href="http://improbable.io/">Improbable</a>, who have a good shot at building the Matrix, for real (or at the very least revolutionizing multiplayer game development), and at <a href="http://mysterystudio.com/">Mystery Studio</a>, a game development company I founded and ran for about a decade, and which released almost 20 games you probably never heard of.</p>
<p>I taught Computer Graphics for five years at university, where it was a semester-long third-year subject. I am grateful to all of my students, who served as unwitting guinea pigs for the materials that inspired this book.</p>
<p>I have other interests besides Computer Graphics, engineering-related and otherwise. See <a href="http://gabrielgambetta.com/">my website</a>, for more details and contact information.</p>


<p><span>Found an error?</span> Everything is in <a href="https://github.com/ggambetta/computer-graphics-from-scratch">Github</a>.
</p>


<hr>
</div></div>]]>
            </description>
            <link>https://www.gabrielgambetta.com/computer-graphics-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25266812</guid>
            <pubDate>Tue, 01 Dec 2020 16:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS to FreeBSD migration a.k.a. why I left macOS]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 346 (<a href="https://news.ycombinator.com/item?id=25266435">thread link</a>) | @rodrigo975
<br/>
December 1, 2020 | https://antranigv.am/weblog_en/posts/macos_to_freebsd/ | <a href="https://web.archive.org/web/*/https://antranigv.am/weblog_en/posts/macos_to_freebsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>I think the title tells a lot about the story I’m going to tell you.</p>
<p>This is not a technical documentation for how I migrated from macOS to FreeBSD. This is a high-level for <em>why</em> I migrated from macOS to FreeBSD.</p>
<p>Not so long ago, I was using macOS as my daily driver. The main reason why I got a macbook was the underlying BSD Unix and the nice graphics it provides. Also, I have an iPhone. But they were also the same reasons for why I <strong>left</strong> macOS.</p>
<p>I did not want to write this post right after the migration, I wanted to take my time, use FreeBSD daily, see if I will ever miss macOS.</p>
<p>Here’s a tweet of mine from 8 months ago</p>
<blockquote><div lang="en" dir="ltr"><p>Every 4 months I look at my systems (servers, laptops, desktops, embedded) to see if there's anything suspicious, if anything got hacked, etc.</p><p>man, I did not realize that macOS is that complicated. Why is there a "studentd" running? I don't even use Classrooms :/</p></div>— Antranig Vartanian (@antranigv) <a href="https://twitter.com/antranigv/status/1234753346600394752?ref_src=twsrc%5Etfw">March 3, 2020</a></blockquote>


<p>Let’s look at it this way. macOS is becoming less Unix-y every year, <code>date(1)</code> is outdated, there are 100+ Unix processes running by the time the system is booted, most of them are useless for the general user, it has no native package manager (at least MacPorts/homebrew/pkgsrc is out there) and for a power user, there is no proper documentation. Have you ever checked the FreeBSD handbook? Everything is right there!</p>
<p>Okay, the nice graphics part. Have you seen the latest and greatest Big Sur? It feels like eye-candy, it’s not made for power users at all, everything seems to be a distraction now, even the icons. I’m no UI guru, but bringing iOS to the desktop is not for everyone.</p>
<p>So I decided to move to FreeBSD. This is where many people will tell me “Okay but not everything works outside the box”, true! but which OS works outside the box these days anyway? Windows is still a nightmare, setting up macOS took me 3 days the last time, Linux takes way more if you’re building it from scratch. Setting up FreeBSD took me 3 days, however this meant that I will NOT need to change it again for a very, very, VERY long time.</p>
<p>Every time Apple pushed an updated, my <code>pf.conf</code> and <code>automount</code> configs got broken on macOS. They either got deleted or they moved somewhere. Well, the last 2 times it just got deleted.</p>
<p>On FreeBSD, I upgraded from <code>12.1-RELEASE</code> to <code>12.2-RELEASE</code> and nothing broke, and in case there were any changes, FreeBSD just asked me what to do about them.</p>
<p>Let’s come back for a second. Unix is outdated and Apple does not care about it, fancy graphics are too fancy now. Doing forensics is almost impossible. And the hardware is, well, not the best out there (have you ever disassembled a MacBook Pro? it’s takes 2 hours to change a battery while I can reassemble my Dell Latitudes and ThinkPads in 30 minutes).</p>
<p>So there was no reason to stay here anymore. I had to migrate. The question is: where?</p>
<p>Linux has systemd, not my favorite thing out there, Windows is privacy nightmare. That left me with 2 major options: Linuxes without systemd (Gentoo, in my case) or BSDs.</p>
<p>Since I run FreeBSD servers anyway, I just migrated to FreeBSD.</p>
<p>Here’s a short review about running FreeBSD on ThinkPad T480s.</p>
<ul>
<li>WiFi: works. not the fastest, but fast enough.</li>
<li>Graphics: works.</li>
<li>Touchpad: works with multiple fingers AND very configurable via <code>sysctl</code>.</li>
<li>BT does discovery and pairs, I still have to try it with non-Apple headphones.</li>
<li>COVID-19 era: Zoom, Google Hangouts, Jitsi and all other WebRTC-based video conferencing software works via web as well.</li>
<li>Thanks to <a href="https://forums.freebsd.org/threads/linuxulator-how-to-run-google-chrome-linux-binary-on-freebsd.77559/">Linuxulator</a>, I can watch Netflix as well: <a href="https://twitter.com/antranigv/status/1327422687107555329">here’s a screenshot</a>.</li>
</ul>
<p>Most importantly, it’s Free and Open Source.</p>
<p>It’s been 1 month and 1 day since I last touched my MacBook Pro, so, what do I miss?</p>
<ul>
<li>Better BT support</li>
<li>Faster WiFi</li>
</ul>
<p>That’s it, that’s all missing on a FreeBSD laptop these days. WiFi can do 48Mbps according to <code>ifconfig</code> but I usually get 10-20Mbps. BT pairs with my Apple AirPods but I wish it worked till the end.</p>
<p>Having a nice workstation/laptop is not an easy thing, using macOS means living by Apple rules, Windows is the same for Microsoft. The BSDs gave me the power to be as free as possible :)</p>
<p>During the next weeks I’ll try to blog about the actual setup.</p>
<p>P.S. dear Apple employee, in case you’re reading this, please tell your management to update their BSD Unix layer. Some of us still care, some of us are not just Docker people, some of us are not just “modern” web developers. Thanks in advance.</p>
<p>That’s all folks! :)</p>

      </div></div>]]>
            </description>
            <link>https://antranigv.am/weblog_en/posts/macos_to_freebsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25266435</guid>
            <pubDate>Tue, 01 Dec 2020 16:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to scope software projects when everything is something you’ve never done]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25266352">thread link</a>) | @KaiserSanchez
<br/>
December 1, 2020 | https://www.7pace.com/blog/how-to-scope-software-projects | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/how-to-scope-software-projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>When 7pace <a href="https://www.7pace.com/blog/7pace-for-github-announcement">decided to build a time tracking solution for the GitHub universe</a>, our developers thought it should be a somewhat straightforward project. Take the Timetracker we already built for Azure DevOps, and make it work for Github users. No sweat, right?</p>



<p>If you’re a developer, you probably already see where this is going.</p>



<p>Of course it wasn’t that simple.</p>



<p>“The team [working on the GitHub extension] came from that original team,” said 7pace product manager Sascha Zierfuss. “So although we know exactly what we’re doing, we understand how customers are using it and all that — the new product is in a different realm. So a lot of the assumptions and the knowledge that we had no longer applies.”</p>



<p>In other words, features that were simple to build for the <a href="https://www.7pace.com/blog/azure-devops-best-practices">Azure DevOps Timetracker</a> were a lot more complicated to build for the GitHub Timetracker. And that meant, as the team was making time and effort estimates for different parts of the work, they were off —&nbsp;sometimes <em>way</em> off.</p>



<p>“Now we take a bit more time to dive a bit more deeply and think about it a bit more before coming up with an answer as to how complex or how easy or difficult something is,” Zierfuss explained. “We take a bit more time upfront. But that has made our sprints a lot more successful and helped with the planning as well. If there’s something we think we can achieve in, say, a few months, we’re now better able to assess whether we need some help to reach that goal, if we have to cut a few things, and so on.”</p>



<p>As the developers who are nodding along already know, the 7pace team didn’t have a unique problem. Most, if not all, software teams struggle at some point with scoping work, especially when they’re working on something they’ve never done before. But how can your team accurately scope work when <em>every</em> project is something new?</p>



<p>We don’t have a perfect answer —&nbsp;whoever figures out how to solve this challenge will be a hero to the developer community. But we think some of the lessons our team learned about this can help other developers. We think there’s a secret weapon for scoping that many teams haven’t even considered.</p>



<h2>Step 1: Keep Calm and Code On</h2>



<p>The first thing to keep in mind is that this isn’t a world-ending problem. Yes, we should all be striving to get better at scoping work. But it’s a challenge that literally every software team faces. Don’t believe us? Well, <a href="https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/delivering-large-scale-it-projects-on-time-on-budget-and-on-value#">one recent study</a> found that two out of every three enterprise software projects have cost and effort overruns.</p>



<figure><img loading="lazy" width="1024" height="668" src="http://www.7pace.com/wp-content/uploads/2020/11/66-with-frame-1024x668.png" alt="66% of enterprise software products have cost and effort overruns" srcset="https://www.7pace.com/wp-content/uploads/2020/11/66-with-frame-1024x668.png 1024w, https://www.7pace.com/wp-content/uploads/2020/11/66-with-frame-300x196.png 300w, https://www.7pace.com/wp-content/uploads/2020/11/66-with-frame-768x501.png 768w, https://www.7pace.com/wp-content/uploads/2020/11/66-with-frame-1536x1003.png 1536w, https://www.7pace.com/wp-content/uploads/2020/11/66-with-frame.png 1590w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>When it comes to scoping work, a little perspective can often be helpful. Keep in mind that estimates are a part of every step of the development process. We’re not giving you permission to give up on trying to be better at scoping, but we are saying: Don’t panic. Keep the work moving forward, even if it turns out your scoping is all wrong. And in the meantime, use these tips to get better at scoping your work.</p>



<h2>Project Scoping Best Practices</h2>



<p>When trying to scope a project, there are some best practices that can help all teams.</p>



<h3>Remember that Building Software Is an Evolving Process</h3>



<p>They call building software a “process of discovery” for a reason. As you move through any given project, you can <a href="https://www.7pace.com/blog/learning-is-work">expect it to evolve and change</a>. Requirements aren’t set in stone at the outset of a project, and as you progress through building the software, you may well find that you need to change the requirements along the way to better fit the spirit of what you’re trying to build.</p>



<p>This means that an important best practice is to stay in constant communication — with your team and with your client or organization. Keep every up-to-date on when and how project requirements are changing. This may mean making adjustments to your estimated scope as you go. But over time, your team should get better at making more accurate estimates.</p>



<h3>Mind Parkinson’s Law</h3>



<p>Parkinson’s Law says that work will expand to <a href="https://www.7pace.com/blog/healthier-work-systems">fill the time allotted for it</a>. That means that by giving yourself and your team deadlines based on your project scope, it’s just as important not to <em>overestimate</em> time and effort as it is not to <em>underestimate</em> them.</p>



<p>We get it. It’s easy to avoid missing deadlines by giving your team padded deadlines to allow for those unforeseen delays that every software team encounters. But this can just as easily result in taking much longer to deliver on a project than you actually need to, and thus getting in the habit of overestimating your scope.</p>



<p>Combat this by keeping sprints short. This means you get constant feedback on progress and new directions for the next sprint, which will help improve the quality of your time and effort estimates.</p>



<h3>Don’t Try to Transfer Estimates</h3>



<p>When scoping work, a very important thing to keep in mind is that time and effort estimates are not transferable between different members of your team. Developers vary wildly in their experience, expertise, work styles, and so many other factors that can affect how long it takes them to do a job.&nbsp;</p>



<p>You’ll make better estimates about scope if you do so with everyone’s personal experience and skill level in mind —&nbsp;and even better if every dev on the team is invited to help scope their own work.</p>



<h3>Beware of Context Switching</h3>



<p>Part of the work that developers do is juggling multiple projects, clients, and responsibilities. It’s not often that a developer or a team will be solely dedicated to one project at all times.</p>



<p>While this keeps the job fun and interesting, it comes with a major downside: Frequent switching between tasks and projects can severely interrupt your team’s flow, which can slow down the work and lead to inaccurate scoping.&nbsp;</p>



<p>This is another area where doing short sprints can help. That way, your team has predetermined blocks of time for different tasks and projects, and can mentally prepare as needed.</p>



<h2>How to Scope a Project, Step by Step</h2>



<p>Most of these best practices require having <em>some</em> grasp of the time and effort it will take your team to complete a project. But what if you truly don’t know, because the project is something totally new to your team?</p>



<p>Use this framework for collecting information and turning it into a project scope that’s as accurate as possible, even when you’re navigating new territory.</p>



<figure><img loading="lazy" width="1024" height="646" src="http://www.7pace.com/wp-content/uploads/2020/11/how-to-scope-a-software-dev-project-1024x646.png" alt="How to Scope a Software Development Project" srcset="https://www.7pace.com/wp-content/uploads/2020/11/how-to-scope-a-software-dev-project-1024x646.png 1024w, https://www.7pace.com/wp-content/uploads/2020/11/how-to-scope-a-software-dev-project-300x189.png 300w, https://www.7pace.com/wp-content/uploads/2020/11/how-to-scope-a-software-dev-project-768x484.png 768w, https://www.7pace.com/wp-content/uploads/2020/11/how-to-scope-a-software-dev-project-1536x969.png 1536w, https://www.7pace.com/wp-content/uploads/2020/11/how-to-scope-a-software-dev-project.png 1754w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3>Step 1: Collect All Crucial Information</h3>



<p>Before even beginning to estimate a project’s scope, you need to collect every piece of information about the project that might be relevant to the scope. This includes:</p>



<ul><li>Project deliverables</li><li>All available resources, including team members, money, and work capacity</li><li>Inclusions and exclusions</li><li>Project constraints</li></ul>



<p>Gather as much detail about each of these as you can, as well as any other project information that might be relevant to the scope.</p>



<h3>Step 2: Build a Project Schedule</h3>



<p>Using all the relevant project information, you can start to sketch a rough schedule for completing the project. In your schedule, start with major tasks and milestones, and once those are laid out, try to break them down further into minor tasks and milestones. For especially long or complex projects, it might help to break up the work into phases, first.</p>



<h3>Step 3: Tailor the Scope to Fit Your Team</h3>



<p>Every team has <a href="https://www.7pace.com/blog/autonomy-software-teams">different work styles and methodologies</a>. Now’s the time to take your rough project schedule, and adapt it as needed to fit how your team works. This may mean breaking the first phase or milestone into your first sprints. It may mean assigning certain milestones to certain stakeholders to oversee. This will be different for every team.</p>



<h3>Step 4: Compile Your Scope and Review</h3>



<p>Now that you’ve gathered so much project information and turned it into a project scope, it’s time to review it —&nbsp;with other stakeholders, if necessary —&nbsp;and make any adjustments as needed. This is also the time to put the scope in writing and make sure it’s agreed upon by all the major stakeholders in the project. That way, you can refer back to your scope agreement throughout the duration of the work, and treat it as a guide for making changes or decisions. This can also help avoid scope creep, or any changes that will require time or money you don’t have.</p>



<p>The scope agreement may not be perfect, but having it in place can help negotiations go smoother if your estimates do turn out to be wrong, and you need to make scope adjustments as the project moves forward.</p>



<h2>For More Accurate Scoping, You Need Historical Data</h2>



<p>One great way for teams to find a starting point for scoping work (even on projects they’ve never tackled before) is by looking at historical data.</p>



<p>We know that time tracking isn’t the most popular thing among software teams (because <a href="https://www.7pace.com/blog/timekeeping-is-not-toxix">so many managers use it as a way to micromanage their developers’ time</a>). But we think time tracking can be so much more than that. We think it can be a powerful, if often overlooked, tool that software teams can use to make themselves better.</p>



<p><a href="https://www.7pace.com/timetracker">7pace Timetracker</a> is built by developers, for developers. It’s meant to be a timetracker that runs fully in the background so you don’t even notice it’s there. But all the while, it’s collecting data about the time you and your team spend working, and compiling that data so you can use it to identify your <a href="https://www.7pace.com/blog/software-development-pace-calculation">pace</a>, <a href="https://www.7pace.com/blog/what-causes-software-bugs">hurdles</a>, and successes — as an individual dev or as a team. The best part? You can use that data to help scope work —&nbsp;even when it’s work you’ve never done before.</p>



<p>We’re not saying this is a silver bullet. Accurately estimating work scopes, particularly on new types of projects, will probably always be a challenge for developers. But by using the right tools, teams can continue to improve their scoping skills.</p>



<p>Ready to see how 7pace Timetracker can help your team improve its scoping? <a href="http://7pace.com/">Learn more</a>.</p>
						</div></div>]]>
            </description>
            <link>https://www.7pace.com/blog/how-to-scope-software-projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-25266352</guid>
            <pubDate>Tue, 01 Dec 2020 16:05:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All talks from REBASE'20 now available]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25265902">thread link</a>) | @janvite6
<br/>
December 1, 2020 | http://rebase-conf.org/2020 | <a href="https://web.archive.org/web/*/http://rebase-conf.org/2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="about">
  <div>
    <!-- <h2 class="about__heading">About</h2> -->
    <div>
      <!-- TODO can we make the rebase text "ff-market-web",cursive; or something like that? -->
      <p>
        <strong>Rebase</strong> is a new conference for and by practitioners who want to engage academics about tomorrow's technologies while fondly recalling the achievements of yesterday.
      </p>
      
      <p>
        This year, <strong>Rebase</strong> was planned to occur twice, once in Berlin
        with the <a href="https://2020.ecoop.org/">ECOOP</a> conference and
        once in Chicago with the <a href="https://2020.splashcon.org/">SPLASH</a> conference.
        Due to outside forces, there will be a single virtual event.
      </p>
      
      <p>
        <strong>Rebase</strong> will use the Clowdr platform for interaction,
        registration allows attendees to ask questions and meet with each other
        and with speaker. Registration also give access to all of the
        <a href="https://2020.splashcon.org/">SPLASH</a> co-located events.
      </p>
      
      <p>
        <strong>Rebase is free. All talks were streamed live and are now available on <br> <a href="https://www.youtube.com/playlist?list=PLyrlk8Xaylp6aNlOgiyE4W30X7DpXx74m"><i></i>&nbsp;YouTube</a>.</strong>
        
      </p>
    </div>
  </div>
</section></div>]]>
            </description>
            <link>http://rebase-conf.org/2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25265902</guid>
            <pubDate>Tue, 01 Dec 2020 15:21:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 PCR test protocol is being challenged by 22 scientists]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25265876">thread link</a>) | @mhkool
<br/>
December 1, 2020 | https://cormandrostenreview.com/report/ | <a href="https://web.archive.org/web/*/https://cormandrostenreview.com/report/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1">
<small>
    <a href="https://cormandrostenreview.com/2020/11/27/">November 27, 2020</a></small>
    
<blockquote><p><strong>This extensive review report has been officially submitted to Eurosurveillance editorial board on 27th November 2020 via their submission-portal, enclosed to this review report is a <a href="https://cormandrostenreview.com/retraction-request-letter-to-eurosurveillance-editorial-board/" data-type="URL" data-id="https://cormandrostenreview.com/retraction-request-letter-to-eurosurveillance-editorial-board/">retraction request letter</a>, signed by all the main &amp; co-authors. First and last listed names are the first and second main authors. All names in between are co-authors.</strong></p></blockquote>



<h2><strong>External peer review of the RTPCR test to detect SARS-CoV-2 reveals 10 major scientific flaws at the molecular and methodological level: consequences for false positive results.</strong></h2>



<h4>Pieter Borger<sup>(1)</sup>, Bobby Rajesh Malhotra<sup>(2)</sup> , Michael Yeadon<sup>(3)</sup> , Clare Craig<sup>(4)</sup>, Kevin McKernan<sup>(5)</sup> , Klaus Steger<sup>(6)</sup> , Paul McSheehy<sup>(7)</sup> , Lidiya Angelova<sup>(8)</sup>, Fabio Franchi<sup>(9)</sup>, Thomas Binder<sup>(10)</sup>, Henrik Ullrich<sup>(11)</sup> , Makoto Ohashi<sup>(12)</sup>, Stefano Scoglio<sup>(13)</sup>, Marjolein Doesburg-van Kleffens<sup>(14)</sup>, Dorothea Gilbert<sup>(15)</sup>, Rainer Klement<sup>(16)</sup>, Ruth Schruefer<sup>(17)</sup>, Berber W. Pieksma<sup>(18)</sup>, Jan Bonte<sup>(19)</sup>, Bruno H. Dalle Carbonare<sup>(20)</sup>, Kevin P. Corbett<sup>(21)</sup>, Ulrike Kämmerer<sup>(22)</sup></h4>







<h2><strong>ABSTRACT</strong></h2>



<p>In the publication entitled “Detection of 2019 novel coronavirus (2019-nCoV) by real-time RT-PCR” (Eurosurveillance 25(8) 2020) the authors present a diagnostic workflow and RT-qPCR protocol for detection and diagnostics of 2019-nCoV (now known as SARS-CoV-2), which they claim to be validated, as well as being a robust diagnostic methodology for use in public-health laboratory settings.&nbsp;</p>



<p>In light of all the consequences resulting from this very publication for societies worldwide, a group of independent researchers performed a point-by-point review of the aforesaid publication in which 1) all components of the presented test design were cross checked, 2) the RT-qPCR protocol-recommendations were assessed w.r.t. good laboratory practice, and 3) parameters examined against relevant scientific literature covering the field.&nbsp;</p>



<div><p>The published RT-qPCR protocol for detection and diagnostics of 2019-nCoV and the manuscript suffer from numerous technical and scientific errors, including insufficient primer design, a problematic and insufficient RT-qPCR protocol, and the absence of an accurate test validation. Neither the presented test nor the manuscript itself fulfils the requirements for an acceptable scientific publication. Further, serious conflicts of interest of the authors are not mentioned. Finally, the very short timescale between submission and acceptance of the publication (24 hours) signifies that a systematic peer review process was either not performed here, or of problematic poor quality.&nbsp;&nbsp;We provide compelling evidence of several scientific inadequacies, errors and flaws. </p><p>Considering the scientific and methodological blemishes presented here, we are confident that the editorial board of Eurosurveillance has no other choice but to retract the publication.</p></div>







<h2><strong>CONCISE REVIEW REPORT</strong></h2>



<div><p>This paper will show numerous serious flaws in the Corman-Drosten paper, the significance of which has led to worldwide misdiagnosis of infections attributed to SARS-CoV-2 and associated with the disease COVID-19. We are confronted with stringent lockdowns which have destroyed many people’s lives and livelihoods, limited access to education and these imposed restrictions by governments around the world are a direct attack on people’s basic rights and their personal freedoms, resulting in collateral damage for entire economies on a global scale.</p><p><strong>There are ten fatal problems with the Corman-Drosten paper which we will outline and explain in greater detail in the following sections.</strong></p></div>



<p>The first and major issue is that the novel Coronavirus SARS-CoV-2 (in the publication named 2019-nCoV and in February 2020 named SARS-CoV-2 by an international consortium of virus experts) is based on in silico (theoretical) sequences, supplied by a laboratory in China [1], because at the time neither control material of infectious (“live”) or inactivated SARS-CoV-2 nor isolated genomic RNA of the virus was available to the authors. To date no validation has been performed by the authorship based on isolated SARS-CoV-2 viruses or full length RNA thereof. According to Corman et al.:</p>



<blockquote><p><strong><em>“We aimed to develop and deploy robust diagnostic methodology for use in public health laboratory settings without having virus material available.”</em> [1]</strong></p></blockquote>



<p>The focus here should be placed upon the two stated aims: a) <em>development</em> and b) <em>deployment of a diagnostic test for use in public health laboratory settings</em>. These aims are not achievable without having any actual virus material available (e.g. for determining the infectious viral load). In any case, only a protocol with maximal accuracy can be the mandatory and primary goal in any scenario-outcome of this magnitude. Critical viral load determination is mandatory information, and it is in Christian Drosten’s group responsibility to perform these experiments and provide the crucial data.</p>



<div><p>Nevertheless these in silico sequences were used to develop a RT-PCR test methodology to identify the aforesaid virus. This model was based on the assumption that the novel virus is very similar to SARS-CoV from 2003 as both are beta-coronaviruses.</p><p>The PCR test was therefore designed using the genomic sequence of SARS-CoV as a control material for the Sarbeco component; we know this from our personal email-communication with [2] one of the co-authors of the Corman-Drosten paper. This method to model SARS-CoV-2 was described in the Corman-Drosten paper as follows:</p></div>



<blockquote><p><em>“<strong>the establishment and validation of a diagnostic workflow for 2019-nCoV</strong> <strong>screening and specific confirmation, designed in absence of available virus isolates or original patient specimens. Design and validation were enabled by the close genetic relatedness to the 2003 SARS-CoV, and aided by the use of synthetic nucleic acid technology.”</strong></em></p></blockquote>



<p>The Reverse Transcription-Polymerase Chain Reaction (RT-PCR) is an important biomolecular technology to rapidly detect rare RNA fragments, which are known in advance. In the first step, RNA molecules present in the sample are reverse transcribed to yield cDNA. The cDNA is then amplified in the polymerase chain reaction using a specific primer pair and a thermostable DNA polymerase enzyme. The technology is highly sensitive and its detection limit is theoretically 1 molecule of cDNA. The specificity of the PCR is highly influenced by biomolecular design errors.</p>



<h3><strong>What is important when designing an RT-PCR Test and the quantitative RT-qPCR test described in the Corman-Drosten publication?</strong></h3>



<h5><strong>1. The primers and probes:</strong></h5>



<p>a) the concentration of primers and probes must be of optimal range <br>(100-200 nM)<br>b) must be specific to the target-gene you want to amplify<br>c) must have an optimal percentage of GC content relative to the total nitrogenous bases (minimum 40%, maximum 60%)<br>d) for virus diagnostics at least 3 primer pairs must detect 3 viral genes (preferably as far apart as possible in the viral genome)</p>



<h5><strong>2. The temperature at which all reactions take place:</strong></h5>



<p>a) DNA melting temperature (&gt;92°)<br>b) DNA amplification temperature (TaqPol specific)<br>c) Tm; the annealing temperature (the temperature at which the primers and probes reach the target binding/detachment, not to exceed 2 ̊C per primer pair). Tm heavily depends on GC content of the primers</p>



<h5><strong>3. The number of amplification cycles (less than 35; preferably 25-30 cycles);</strong></h5>



<p>In case of virus detection, &gt;35 cycles only detects signals which do not correlate with infectious virus as determined by isolation in cell culture [reviewed in 2]; if someone is tested by PCR as positive when a threshold of 35 cycles or higher is used (as is the case in most laboratories in Europe &amp; the US), the probability that said person is actually infected is less than 3%, the probability that said result is a false positive is 97% [reviewed in 3]</p>



<h5><strong>4. Molecular biological validations; amplified PCR products must be validated either by running the products in a gel with a DNA ruler, or by direct DNA sequencing</strong></h5>



<h5><strong>5. Positive and negative controls should be specified to confirm/refute specific virus detection</strong></h5>



<h5><strong>6. There should be a Standard Operational Procedure (SOP) available</strong></h5>



<p>SOP unequivocally specifies the above parameters, so that all laboratories are able to set up the exact same test conditions. To have a validated universal SOP is essential, because it enables the comparison of data within and between countries.</p>



<h3><strong>MINOR CONCERNS WITH THE CORMAN-DROSTEN PAPER</strong></h3>



<p>1. In Table 1 of the Corman-Drosten paper, different abbreviations are stated – “nM” is specified, “nm” isn’t. Further in regards to correct nomenclature, nm means “nanometer” therefore nm should read nM here.</p>



<p>2. It is the general consensus to write genetic sequences always in the 5’-3’ direction, including the reverse primers. It is highly unusual to do alignment with reverse complementary writing of the primer sequence as the authors did in figure 2 of the Corman-Drosten paper. Here, in addition, a wobble base is marked as “y” without description of the bases the Y stands for.</p>



<p>3. Two misleading pitfalls in the Corman-Drosten paper are that their Table 1 does not include Tm-values (annealing-temperature values), neither does it show GC-values (number of G and C in the sequences as %-value of total bases).</p>



<h3><strong>MAJOR CONCERNS WITH THE CORMAN-DROSTEN PAPER</strong></h3>



<h4>A) BACKGROUND</h4>



<div><p>The authors introduce the background for their scientific work as: “The ongoing outbreak of the recently emerged novel coronavirus (2019-nCoV) poses a challenge for public health laboratories as virus isolates are unavailable while there is growing evidence that the outbreak is more widespread than initially thought, and international spread through travelers does already occur”.</p><p>According to BBC News [4] and Google Statistics [5] there were 6 deaths world-wide on January 21st 2020 – the day when the manuscript was submitted. Why did the authors assume a challenge for public health laboratories while there was no substantial …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cormandrostenreview.com/report/">https://cormandrostenreview.com/report/</a></em></p>]]>
            </description>
            <link>https://cormandrostenreview.com/report/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25265876</guid>
            <pubDate>Tue, 01 Dec 2020 15:17:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does NTS work and why is it important]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25264031">thread link</a>) | @JoachimS
<br/>
December 1, 2020 | https://www.netnod.se/time-and-frequency/white-paper-how-does-nts-work-and-why-is-it-important | <a href="https://web.archive.org/web/*/https://www.netnod.se/time-and-frequency/white-paper-how-does-nts-work-and-why-is-it-important">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>This white paper gives an overview of NTS and a detailed description of the authentication process that ensures you receive time information from a trusted source. This includes the step-by-step details of the key establishment and time stamping process. We also provide a summary of the elements that enable NTS to scale and to secure NTP against a range of attack vectors.</p><div><h2>This is a preview of Netnod's NTS white paper. To read&nbsp;the full white paper, see link below.
</h2><p>Introduction
</p><p>Many of the important security tools that keep us safe online depend on accurate time. But until recently there was no way to ensure that the time you received over the Internet was correct. There was simply no way to tell if you were being fed time from a malicious or trusted source.</p>
<p>This is largely because the current standard for receiving time over the Internet, the Network Time Protocol (NTP), was created in 1985. In those more innocent times, the need to secure NTP, the type of security needed, and how to provide it were less understood.</p>
<p>Over the last 35 years, a range of security flaws and some high-profile attacks have shown that NTP needed significantly improved security. The new Network Time Security (NTS) standard has been designed to fix that.</p>
<p><span><strong>NTP security issues&nbsp;</strong></span></p>
<p>Unsecured NTP is vulnerable to Man-in-the-Middle (MITM) attacks where a malicious actor sits between you and the NTP server, listens in on the conversation, forges&nbsp; messages and lies to you about time. As a lot of processes are dependent on accurate time, the consequences here can be very serious and can include:</p>
<ul><li>Incorrect timestamps on logs and transactions which can support fraudulent activities or help disguise other criminal action&nbsp;</li>
<li>Authentication problems, attacks and issues with authentication security measures&nbsp;</li>
<li>Issues with cryptographic signatures and establishing encrypted sessions such as Transport Layer Security (TLS)&nbsp;</li>
<li>DNS Security (DNSSEC) failing to work if the client doesn’t have accurate time</li>
</ul><p><span><strong>Previous attempts at NTP security&nbsp;</strong></span></p>
<p>There have been some previous attempts to add security to NTP. Commonly referred to as NTP-AUTH, these attempts did not provide all necessary aspects of security (confidentiality, authentication and integrity including protection against replay attacks).&nbsp;</p>
<p>Moreover, the underlying security mechanism for NTP-AUTH (MD5 or SHA-1) could be considered weak at best. NTP-AUTH is based on secret keys but the key agreement is not standardized. This means that any NTP service provider wanting to use NTP-AUTH has to find their own way to exchange keys with the client out-of-band.&nbsp;</p>
<p>This often requires a potential client to send a letter or fax to get the secret key. The need for a server to store uniquesecret keys for all clients creates scalability problems: as the number of users grows, the storage requirements and especially the ability to rapidly look up a given key makes the service hard to scale.</p>
<p>Given all these issues, it has long been apparent that a new security mechanism for NTP is needed; one based on modern security mechanisms that could also allow the service to scale to potentially millions of clients.</p>
<h2><strong>The NTS standard</strong></h2>
<p>NTS has been developed within the Internet Engineering Task Force (IETF). In March 2015, the first Internet-Draft of the NTS standard was published. Over the next five years, the draft went through 28 further iterations until the Internet Draft ‘Network Time Security for the Network Time Protocol’ was published as a Proposed Standard (RFC8915) in September 2020.&nbsp;</p>
<p>NTS uses modern cryptography to add an important layer of security to NTP. It prevents spoofing and MITM attacks by using authenticated packets. Amplification attacks are prevented by ensuring that request and response packets are always the same size.</p>
<p>NTS is really two protocols: a key establishment protocol, and NTP with some new Extension Fields. The reason for using two protocols is separation of concerns:</p>
<p>1. The seldom used key establishment on top of standard Transport Layer Security (TLS), and</p>
<p>2. The (already existing) low latency UDP-based time synchronisation path.</p>
<p>This means that the existing NTP functionality is the same as before, but the time data can now be authenticated.&nbsp;</p>
<h2><strong>The NTS authentication process</strong></h2>
<p>The authentication process consists of a key establishment and a timestamp request. The key exchange server typically runs on an ordinary computer, but the slim NTS-enabled NTP server is UDP-based and stateless. It can be served from anycast addresses and can be implemented at the hardware level. The NTP server’s state about each client is kept in the cookie provided by the client itself with each request. As there can potentially be hundreds of millions of clients, this is crucial for the smooth operation of a large-scale NTS service.</p>
<p>Since the cryptographic operations in the NTS path are symmetric it is both easier to implement them in hardware and to make them use constant time. This increases the accuracy of the time synchronisation and keeps the slower key exchange outside of the time synchronisation path.&nbsp;</p>
<p>NTS uses Authenticated Encryption using the Advanced Encryption Standard (AES), more specifically what is known as Synthetic Initialization Vector (RFC 5297). This is a block cipher mode of operation providing nonce-based,&nbsp;misuse-resistant authenticated encryption. Using AES-SIV enables the encryption processes described below to add integrity and origin authentication. The consequences for this at a hardware level will be discussed in an upcoming&nbsp;white paper.</p>
<p><span><strong>The key establishment</strong></span></p>
<p>The key establishment process works as follows: first, a client initiates a key establishment using the NTS-KE protocol embedded in TLS (see figure 1.)</p>
<p><img alt="NTS wp figure 1" data-entity-type="file" data-entity-uuid="b47760fa-6300-4ae3-bd73-39fd7e16a80d" data-full-width="0" src="https://www.netnod.se/sites/default/files/inline-images/NTS_wp_01.jpg"></p>
<p><em>Figure 1: Key establishment. Note: the numbers shown correspond to the text below.</em></p>

<p><strong>To read the full white paper,<a href="https://www.netnod.se/sites/default/files/2020-11/Netnod%20NTS%20Whitepaper.pdf" target="_blank"> click here</a>&nbsp;</strong></p>
</div></div>]]>
            </description>
            <link>https://www.netnod.se/time-and-frequency/white-paper-how-does-nts-work-and-why-is-it-important</link>
            <guid isPermaLink="false">hacker-news-small-sites-25264031</guid>
            <pubDate>Tue, 01 Dec 2020 10:27:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bekk.christmas – 264 articles about tech, design, strategy and innovation]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25263682">thread link</a>) | @selbekk
<br/>
December 1, 2020 | https://blogg.bekk.no/wishing-you-all-a-very-bekk-christmas-8505a0a332e2 | <a href="https://web.archive.org/web/*/https://blogg.bekk.no/wishing-you-all-a-very-bekk-christmas-8505a0a332e2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p id="d520">Bekk is a Norwegian consultancy that merges the disciplines of technology, user experience, design, product innovation and strategy, and helps Norwegian businesses improve their products and services.</p><p id="4d8f">But mostly, we’re people that are really passionate about what we do. We see that every day on our company Slack, where we ask questions about challenging topics, and get tons of replies in a matter of minutes. We see that every time one of our colleagues is a featured speaker at international conferences. We see that every time we host a meetup, or a workshop, or meet students both online and on site.</p><p id="b7de">We love sharing what we know, because it helps us grow. That’s why we’re continuing our great tradition of sharing some of the stuff we know every December.</p><p id="e0e1">This year, we’ve created 11 advent calendar sites, each with its own particular topic, and each with 24 different entries. 10 of them contain 24 articles each, and one contains a set of 24 podcast episodes. The articles will be short, to the point and will try to inspire you to learn something new every day this December.</p><p id="b8c3">We’re incredibly proud to share the following calendars with you this year:</p><h2 id="785a">elm.christmas</h2><p id="f171">Bekk ❤️ Elm. We’ve been using it for years at <a rel="noopener" href="https://blogg.bekk.no/using-elm-at-vy-e028b11179eb">some of our biggest clients</a>, we have helped organize <a href="https://2020.osloelmdays.no/" rel="noopener">one of the world’s greatest Elm conferences</a>, and even help <a href="https://elm-lang.org/news/elm-and-bekk" rel="noopener">sponsor the development of Elm itself</a>. This year, we’re sharing 24 interesting things you might not know about Elm!</p><h2 id="9bd3">javascript.christmas</h2><p id="cecd">JavaScript is a huge part of most of what we do today. Whether it’s through Node, Vue or React, it’s one of the most versatile languages out there. This year — which marks the third year of our JavaScript calendar — we’re diving into a bunch of topics that will help you understand this wonderful language even better.</p><h2 id="77b9">functional.christmas</h2><p id="929e">The functional programming paradigm has been with us for decades, but has definitely seem an up-turn in interest the last couple of years. This calendar aim to teach you how to up your functional programming game in a matter of 24 days.</p><h2 id="4c60">kotlin.christmas</h2><p id="893a">Kotlin has become incredibly popular the last couple of years, and is one of our favorite languages to implement advanced backends in. It’s a great language to learn, and to introduce bit-by-bit on legacy Java codebases. This year, we’re excited to share yet another 24 tips and tricks on how you can up <em>your</em> Kotlin game.</p><h2 id="4c7e">innovation.christmas</h2><p id="5607">Product development and innovation are two of the coolest things we do at Bekk. That’s why we’re sharing 24 different conversations with entrepreneurs, innovators, specialists and strategists, each pertaining to a particular topic. Note that these podcast episodes are available in Norwegian only.</p><h2 id="4be8">react.christmas</h2><p id="f73a">For the fourth year in a row, this calendar keeps teaching you new React tips, tricks and techniques in a small bite-sized way. We share our experiences with different tools, and help you understand how to use the world’s most popular frontend framework.</p><h2 id="e4af">security.christmas</h2><p id="2241">Creating secure solutions is one of the hardest challenges we’ve tasked to do. That’s why we have a dedicated group within Bekk to teach ourselves — and others — how to do it right. We’re excited to share 24 new articles about how you can do the same.</p><h2 id="34ad">strategy.christmas</h2><p id="3077">Developing modern strategies for a modern marketplace is incredibly important. Some of our best product and business strategists have sat down to share some of their best insights on how you can change your business for the better — from within.</p><h2 id="94eb">talks.christmas</h2><p id="0202">We do a lot of talks, presentations and workshops, both for ourselves, our customers, and at external meetups and conferences. It’s not as easy at it looks — but with the right training, we believe anyone can do it. This year, we’re sharing 24 articles, listicles, tipsicles (is that a thing?) and experience reports from some of the most seasoned speakers in the business.</p><h2 id="5fd1">thecloud.christmas</h2><p id="ec69">We were kidding about doing on-prem.christmas this year, but the cloud just makes everything so easy (and hard!) that we decided to go with the latter. This year’s cloud calendar will teach you more than you wish you knew about Kubernetes, Azure, AWS and GCP.</p><h2 id="423e">ux.christmas</h2><p id="3692">Last, but definitely not least, we’re continuing last year’s success of sharing the thoughts and knowledge of some of the best user experience designers we know. Look forward to learning a ton about UX, design and our experiences with our clients</p></div></div></section></div>]]>
            </description>
            <link>https://blogg.bekk.no/wishing-you-all-a-very-bekk-christmas-8505a0a332e2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25263682</guid>
            <pubDate>Tue, 01 Dec 2020 09:05:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Busybox-based Linux distro from scratch]]>
            </title>
            <description>
<![CDATA[
Score 179 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25263398">thread link</a>) | @pfrog
<br/>
December 1, 2020 | https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/ | <a href="https://web.archive.org/web/*/https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1624">
	<!-- .entry-header -->

	<div>
		<p><img width="257" height="303" src="https://re-ws.pl/wp-content/uploads/2020/11/logo.gif" alt="linux logo" loading="lazy"></p><figure id="attachment_1648" aria-describedby="caption-attachment-1648"><a href="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib.jpg"><img loading="lazy" src="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-263x300.jpg" alt="Canon SD MMC card 16 MiB" width="263" height="300" srcset="https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-263x300.jpg 263w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-899x1024.jpg 899w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-768x875.jpg 768w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib-1348x1536.jpg 1348w, https://re-ws.pl/wp-content/uploads/2020/11/mmc16mib.jpg 1443w" sizes="(max-width: 263px) 100vw, 263px"></a><figcaption id="caption-attachment-1648">16 MiB SD/MMC card. Made in Japan in 2005</figcaption></figure>
<p>Today, I would like to show something different, than usual reverse-engineering, that appears on my blog usually. I needed to prepare a Linux distro for myself to be able to run it on my PC. But not the ordinary operating system that we download from webpage, then use fancy graphical installer to select, what we want and where. My goals were very specific. First was to have it custom-compiled. With that in mind there aren’t many choices left (maybe Gentoo?). Second was to not cross 16 MiB boundary. Why exactly that? That’s simple. I have old (15 years old to be precise) SD/MMC card made for Canon of exactly that size. Quick check showed me that this is possible. I tried buildroot and it failed to fulfill second requirement and I decided not to continue, despite the obvious optimizations on kernel modules, I could do. It’s simply too complex for such a simple task. If not buildroot, then let’s go and see how to do such thing from scratch!</p>

<p>Basically the plan is to have custom Linux distro compiled from scratch. It may sound like something incredibly complex and hard to do. But it’s not. There are just few problems one must learn on how to overcome. The most problematic constraint in my case is, obviously, 16 MiB limit. To not exceed it, I have to use busybox as my userspace. This by the way simplifies distro development significantly. Busybox works the way, that, if linked statically, requires only one, single binary to be able to work correctly. So, to sum up, on software side, we need Linux and busybox. You may wonder, how do I want to boot that system, then? Well. I said I need Linux 🙂 Maybe some people know, some does not, that Linux is itself a boot loader of some kind. At least, when using UEFI and this is what I want to use, it can be loaded directly by UEFI firmware. But that’s another thing to note – I will describe a way to prepare a distro for UEFI – it won’t be as simple as that, for legacy BIOS.</p>
<p>The whole plan will look as follows:</p>
<ol>
<li>Get compiler</li>
<li>Compile Linux kernel</li>
<li>Compile busybox (statically and stripped!)</li>
<li>Prepare initramfs with whole userspace</li>
<li>Format drive as EFI System Partition</li>
<li>Combine kernel and initramfs into single binary</li>
<li>Optionally sign the binary, in case we want Secure Boot to be enabled</li>
<li>Add entry to embedded UEFI boot manager</li>
</ol>
<p>In the meantime, I am going to show few ways to debug the system, in case of any problems.<span id="more-1624"></span></p>

<p>This is maybe not so obvious, but you need new compiler. Most likely, you could use the one that your distro provides, aliased as simply gcc. But this way, you will by the way use glibc as your standard library. For a lightweight system, glibc does not fit well, as this is most heavyweight libc, we have available. Therefore, I will use uClibc. And for that, we need a compiler. Or, to be precise, a toolchain. A toolchain, consisting of kernel headers, uClibc and gcc. Here, I could show, how to build such thing from scratch. But it’s not a tutorial about building a toolchain. This requires knowledge that can fill another tutorial. Instead, I will use the toolchain prepared by my latest project – <a href="https://github.com/v3l0c1r4pt0r/cc-factory" target="_blank" rel="noopener noreferrer">cc-factory</a>. For those, who did not read <a href="https://re-ws.pl/2020/10/meet-cc-factory-a-factory-for-cross-compilers/">my previous post</a>, it is toolchain factory running in Docker container, that provides a recipe for a toolchain that just works. If you tried compiling a toolchain from scratch in the past, then you know that this can fail, even if you use crosstool-ng. With cc-factory, it works as long as Docker can start a service and has Docker Hub working. But enough of that. In cc-factory, I am experimenting with releasing binary distributions of my toolchain. And <a href="https://github.com/v3l0c1r4pt0r/cc-factory/releases/tag/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1">newest one</a> is special-made for this job. You can simply download it to you disk with:</p>
<pre>wget <span>'</span><span>https://github.com/v3l0c1r4pt0r/cc-factory/releases/download/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1/x86_64-gcc10.2.0-linux5.9.13-uclibc1.0.36-1.tar.gz</span><span>'</span>
</pre>
<p>After that, you have to install it to your <code>/opt</code> directory with:</p>
<pre>tar <span>-xvf</span> x86_64-gcc10.<span>2</span>.0-linux5.<span>9</span>.13-uclibc1.<span>0</span>.36-1.tar.gz <span>-C</span> /
</pre>
<p>If you prefer another installation path, then head onto cc-factory project to see, how to build one from source. Then, you can choose whatever path, you like for this SDK.</p>
<p>Next step is to export SDK’s bin directory to you PATH for convenience:</p>
<pre><span>export</span> <span>PATH</span>=<span>"</span><span>$PATH</span><span>:/opt/x86_64-linux-uclibc/bin</span><span>"</span>
</pre>
<p>Now, it’s nice to check, if toolchain works. Let’s write one-liner C hello world program to your temp directory, compile and run:</p>
<pre><span>echo</span><span> -e </span><span>'</span><span>#include &lt;stdio.h&gt;\nint main() {printf("Hello, World!\\n");}</span><span>'</span> <span>&gt;</span>/tmp/main.c
x86_64-linux-uclibc-gcc <span>-static</span> <span>-o</span> /tmp/main /tmp/main.c
/tmp/main
</pre>
<p>And you should see the familiar text on your screen. You are ready to go!</p>

<p>That is, in my opinion, the easiest part. First, we have to download kernel image, that we want to use. For that purpose, we need to go to <a href="https://www.kernel.org/" target="_blank" rel="noopener noreferrer">Kernel Archives</a> and download latest stable tarball. Optionally, we can download PGP signature and verify its correctness. But this is outside the scope of this tutorial. Another option to get kernel is to clone its stable repo with:</p>
<pre>git clone git://git.kernel.org/pub/scm/linux/kernel/git/stable/linux.git
</pre>
<p>This is the path, I chose, because I don’t like leaving multiple copies of kernel sources on my hard drive, so I prefer to have one, central clone of repo and use for any project, I need it to.</p>
<p>In case of tarball, it now has to be unpacked with usual:</p>
<pre>tar <span>-xvf</span> linux-*.tar.gz
</pre>
<p>Then, in case of tarball, you got directory with name dependent on you kernel version, in case of git repo, it is simply linux. So we can cd into it, in any of the above cases:</p>
<pre><span>cd</span> linux*
</pre>
<p>In theory at this point, we could set the compiler, we prepared to be run by kernel buildsystem. But this is optional, as we target <code>x86_64</code> platform, that we run our host on, so default compiler should be as good as uClibc variant. I case, you want to use custom one, you have to export the following:</p>
<pre><span>export</span> <span>CROSS_COMPILE</span>=x86_64-linux-uclibc-
</pre>
<p>Now, we have to configure our kernel.</p>
<p>First step is to choose defconfig. Possible values can be listed in case of x86 with:</p>
<pre><span>ls</span> arch/x86/configs/
</pre>
<p>At the time of writing this returned the following options:</p>
<pre>i386_defconfig tiny.config x86_64_defconfig xen.config
</pre>
<p>As you can see, there are only a few. So, we do:</p>
<pre>make x86_64_defconfig
</pre>
<p>At this point, we are ready to compile. In case, you want to do some modifications, you could do:</p>
<pre>make menuconfig
</pre>
<p>And select (or deselect) some options there. If you think, you are ready, you can type:</p>
<pre>make <span>-j</span>
</pre>
<p>And wait couple of minutes (up to half an hour), depending on speed of your PC. Afterwards, you should see that <code>bzImage</code> has been made and is available at <code>arch/x86/boot/bzImage</code>. We can copy it somewhere in order to not accidentally start its recompilation:</p>
<pre>cp arch/x86/boot/bzImage ../
</pre>
<h2>Testing on hardware</h2>
<p>At this point, it is possible to run the kernel on our system. If you don’t have Secure Boot enabled, then you can try to copy the kernel to you EFI System Partition (wherever it is, I will call this path <code>ESP</code> from now on). But first create new directory for your distro:</p>
<pre><span>mkdir</span> <span>-p</span> ESP/EFI/linux
cp arch/x86/boot/bzImage ESP/EFI/linux/linuxx64.efi
</pre>
<p>I am changing the name in the meantime, as I heard that some systems does not like binaries without <code>.efi</code> extension. Now, we can try to boot.There is more than one way to do it. The one that works always is to utilize EFI firmware directly. But this one differs significantly between manufacturers, so if you prefer that one, please refer to his support pages. The other is to use one of existing tools. For sure KeyTool, that manages Secure Boot keys, is able to start any executable from ESP by browsing the filesystem. But the way I would like to show is, by using so called EFI shell. Why? Because EFI shell allows us to experiment with kernel parameters, by simply typing them, as we would start new user program. And, in fact, from EFI perspective, we simply start a new program.</p>
<p>There are many shells in the wild. I tried EDK2, that is available on Arch as <code>edk2-shell</code> package. It is then available at <code>/usr/share/edk2-shell/x64/Shell.efi</code> You can simply copy it to <code>ESP</code>, just like with kernel, then you have to add it to your EFI boot manager, or use boot manager that is able to autodetect it. You can find a bunch of resources on how to do it, even from inside Linux. But, please do not add the kernel, you copied in such way, to boot manager, as we will play with it a bit, later. Now, in EFI shell, you will be presented with a list of partitions, that the shell has detected. This might be not so obvious at first, but, somehow, you have to identify the one, that is you EFI partition. You should see a similar numbering to the one you see in Linux console, when you list with e.g. <code>lsblk</code>. You can try guessing it by typing its name, in similar way as in Windows, e.g.:</p>
<pre>FS0:
</pre>
<p>to switch to <code>FS0</code> partition. Then you can simply type ls to list its content. Once, you found the right one, it’s worth to remember it, as you might need it couple of times. How many, depends on how many problems, you would have.</p>
<p>Then go to the directory, where you copied your kernel:</p>
<pre><span>cd</span> EFI\linux
</pre>
<p>And ls to make sure, it is there. Now, we are ready to call it:</p>
<pre>linuxx64.efi
</pre>
<p>Yes. It’s as simple as that. But this will fail. We did not provide any root filesystem for our kernel, so it will gonna panic. But don’t worry, as long as reason of the panic is like that:</p>
<pre>not syncing: VFS: Unable to mount root fs on unknown-block(0,0)
</pre>
<p>then it was expected. In case of any other error, act accordingly, as this may be hardware dependent. So, probably, something has to be reconfigured in menuconfig.</p>
<h2>Testing in qemu</h2>
<p>It’s quite a nice option to be able to test your work on real hardware. However, in my opinion, it is much easier to do it in virtualized environment, that you can quickly reset at any time and where you would have latest binaries for testing, all the time, without wasting time for flashing them somewhere. Therefore I recommend to prepare qemu as such environment.</p>
<p>For that, you will need …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/">https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/</a></em></p>]]>
            </description>
            <link>https://re-ws.pl/2020/11/busybox-based-linux-distro-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25263398</guid>
            <pubDate>Tue, 01 Dec 2020 08:10:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Is Functional Programming?]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25263365">thread link</a>) | @bendiksolheim
<br/>
December 1, 2020 | https://functional.christmas/2020/1 | <a href="https://web.archive.org/web/*/https://functional.christmas/2020/1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><section><p>Welcome to another year of the functional programming advent calendar! Every day until December 24th you will get an article, video or other functional programming related content that hopefully will make the waiting feel a bit shorter! 😄</p>
</section><article><section><p>As previous years the articles will span a large range of topics and complexity. If you are looking for something beginner friendly, or more advanced topics, there should be something for everyone these next 23 days.</p>
<p>Let’s start this advent of with a look at the basics: what is functional programming (FP)? This question has been answered many times before, in many different ways. <a href="https://functional.christmas/2019/1">We took our own stab at it last year</a>. Even though there are no single definition for FP and many different ways to approach it, there are some things that are shared throughout the related communities.</p>

<p>Today I want to use the words and pictures of Russ Olsen and highlight his talk from GOTO 2018. Russ is a great communicator and I love the down to earth and practical perspective he brings in this talk. He explains functional programming in an understandable way and shows why people prefer FP. I hope you enjoy! </p>
<p>Link: <a href="https://youtu.be/0if71HOyVjY">https://youtu.be/0if71HOyVjY</a></p>
<p> <iframe src="https://www.youtube-nocookie.com/embed/0if71HOyVjY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe> </p>
<p>What is your favorite FP intro talk?</p></section></article></div></article></div>]]>
            </description>
            <link>https://functional.christmas/2020/1</link>
            <guid isPermaLink="false">hacker-news-small-sites-25263365</guid>
            <pubDate>Tue, 01 Dec 2020 08:03:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Tiny mobile-friendly interactive fiction game]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25262631">thread link</a>) | @memalign
<br/>
November 30, 2020 | https://memalign.github.io/m/dungeon/index.html | <a href="https://web.archive.org/web/*/https://memalign.github.io/m/dungeon/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://memalign.github.io/m/dungeon/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25262631</guid>
            <pubDate>Tue, 01 Dec 2020 05:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QEMU Advent Calendar 2020]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25262608">thread link</a>) | @todsacerdoti
<br/>
November 30, 2020 | https://www.qemu-advent-calendar.org/2020/ | <a href="https://web.archive.org/web/*/https://www.qemu-advent-calendar.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    


    <div id="myCarousel">
      <div>
        <div>
          <div>
            <div>
              <p><img src="https://www.qemu-advent-calendar.org/2020/images/qemu-winter.png" alt="QEMU"></p>
              <h2>Brightening your days in the winter holiday season.</h2>
              <p>
               This advent calendar is brought to you by the
               <a href="https://www.qemu.org/">QEMU community</a>.
              </p>
            </div>
          </div>
        </div>
      </div>
    </div><!-- /.carousel -->

    <div id="day-1">
     <p>
	<img id="img-day01" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 1" onclick="opendoor('day01', 'Day 1 - Tweetable bootsector game');">
     </p>
     <h2 id="title-day01">Day 1</h2>
     <div id="desc-day01">
      <p>
        This bootloader game can be generated from text that fits in a tweet.
      </p>
      <p>
       Size of download is 893 bytes.
      </p>
      
     </div>
     <p>
       <a href="https://www.qemu-advent-calendar.org/2020/download/day01.tar.gz" role="button">Download</a>
     </p>
    </div>

    <div id="day-2">
     <p>
       <img id="img-day02" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 2" onclick="opendoor('day02', 'Day 2 - QEMU 5.2.0-rc4');">
     </p>
     <h2 id="title-day02">Day 2</h2>
     <div id="desc-day02">
      <p>
       No disk image today, but a new release candidate for QEMU: Version 5.2.0-rc4 has just been published yesterday – please download the package and give it a try! 
      </p>
      <p>
       Size of download is 102 MB
      </p>
      
     </div>
     <p>
       <a href="https://download.qemu.org/qemu-5.2.0-rc4.tar.xz" role="button">Download</a>
     </p>
    </div>

    <div id="day-3">
     <p>
       <img id="img-day03" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 3" onclick="opendoor('day03', 'Day 3 - GW-BASIC');">
     </p>
     <h2 id="title-day03">Day 3</h2>
     <div id="desc-day03">
      <p>
	GW-BASIC is a dialect of the BASIC programming language and it came with MS-DOS. It was open-sourced on May 21st 2020 under the MIT License. The famous BASIC game DONKEY.BAS is included as a demo.
      </p>
      <p>
       Size of download is 10.2 MB
      </p>
      
     </div>
     <p>
       <a href="https://www.qemu-advent-calendar.org/2020/download/gw-basic.tar.xz" role="button">Download</a>
     </p>
    </div>

    <div id="day-4">
     <p>
       <img id="img-day04" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 4" onclick="opendoor('day04', 'Day 4 - bootRogue');">
     </p>
     <h2 id="title-day04">Day 4</h2>
     <div id="desc-day04">
      <p>
	bootRogue, a roguelike game that fits in a boot sector (511 bytes) by Oscar Toledo G.
      </p>
      <p>
       Size of download is 1936 Bytes
      </p>
      
     </div>
     <p>
       <a href="https://www.qemu-advent-calendar.org/2020/download/day04.tar.gz" role="button">Download</a>
     </p>
    </div>

    <div id="day-5">
     <p>
       <img id="img-day05" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 5" onclick="zonk('day05');">
     </p>
     <h2 id="title-day05">Day 5</h2>
     <p>
       Image will be available on December 5th.
      </p>
     
    </div>

    <div id="day-6">
     <p>
       <img id="img-day06" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 6" onclick="zonk('day06');">
     </p>
     <h2 id="title-day06">Day 6</h2>
     <p>
       Image will be available on December 6th.
      </p>
     
    </div>

    <div id="day-7">
     <p>
       <img id="img-day07" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 7" onclick="zonk('day07');">
     </p>
     <h2 id="title-day07">Day 7</h2>
     <p>
       Image will be available on December 7th.
      </p>
     
    </div>

    <div id="day-8">
     <p>
       <img id="img-day08" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 8" onclick="zonk('day08');">
     </p>
     <h2 id="title-day08">Day 8</h2>
     <p>
       Image will be available on December 8th.
      </p>
     
    </div>

    <div id="day-9">
     <p>
       <img id="img-day09" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 9" onclick="zonk('day09');">
     </p>
     <h2 id="title-day09">Day 9</h2>
     <p>
       Image will be available on December 9th.
      </p>
     
    </div>


    <div id="day-10">
     <p>
       <img id="img-day10" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 10" onclick="zonk('day10');">
     </p>
     <h2 id="title-day10">Day 10</h2>
     <p>
       Image will be available on December 10th.
      </p>
     
    </div>

    <div id="day-11">
     <p>
       <img id="img-day11" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 11" onclick="zonk('day11');">
     </p>
     <h2 id="title-day11">Day 11</h2>
     <p>
       Image will be available on December 11th.
      </p>
     
    </div>

    <div id="day-12">
     <p>
       <img id="img-day12" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 12" onclick="zonk('day12');">
     </p>
     <h2 id="title-day12">Day 12</h2>
     <p>
       Image will be available on December 12th.
      </p>
     
    </div>

    <div id="day-12">
     <p>
       <img id="img-day14" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 13" onclick="zonk('day13');">
     </p>
     <h2 id="title-day13">Day 13</h2>
     <p>
       Image will be available on December 13th.
      </p>
     
    </div>

    <div id="day-14">
     <p>
       <img id="img-day14" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 14" onclick="zonk('day14');">
     </p>
     <h2 id="title-day14">Day 14</h2>
     <p>
       Image will be available on December 14th.
      </p>
     
    </div>

    <div id="day-15">
     <p>
       <img id="img-day15" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 15" onclick="zonk('day15');">
     </p>
     <h2 id="title-day15">Day 15</h2>
     <p>
       Image will be available on December 15th.
      </p>
     
    </div>

    <div id="day-16">
     <p>
       <img id="img-day16" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 16" onclick="zonk('day16');">
     </p>
     <h2 id="title-day16">Day 16</h2>
     <p>
       Image will be available on December 16th.
      </p>
     
    </div>

    <div id="day-17">
     <p>
       <img id="img-day17" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 17" onclick="zonk('day17');">
     </p>
     <h2 id="title-day17">Day 17</h2>
     <p>
       Image will be available on December 17th.
      </p>
     
    </div>

    <div id="day-18">
     <p>
       <img id="img-day18" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 18" onclick="zonk('day18');">
     </p>
     <h2 id="title-day18">Day 18</h2>
     <p>
       Image will be available on December 18th.
      </p>
     
    </div>

    <div id="day-19">
     <p>
       <img id="img-day19" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 19" onclick="zonk('day19');">
     </p>
     <h2 id="title-day19">Day 19</h2>
     <p>
       Image will be available on December 19th.
      </p>
     
    </div>

    <div id="day-20">
     <p>
       <img id="img-day20" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 20" onclick="zonk('day20');">
     </p>
     <h2 id="title-day20">Day 20</h2>
     <p>
       Image will be available on December 20th.
      </p>
     
    </div>

    <div id="day-21">
     <p>
       <img id="img-day21" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 21" onclick="zonk('day21');">
     </p>
     <h2 id="title-day21">Day 21</h2>
     <p>
       Image will be available on December 21th.
      </p>
     
    </div>

    <div id="day-22">
     <p>
       <img id="img-day22" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 22" onclick="zonk('day22');">
     </p>
     <h2 id="title-day22">Day 22</h2>
     <p>
       Image will be available on December 22th.
      </p>
     
    </div>

    <div id="day-23">
     <p>
       <img id="img-day23" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 23" onclick="zonk('day23');">
     </p>
     <h2 id="title-day23">Day 23</h2>
     <p>
       Image will be available on December 23th.
      </p>
     
    </div>

    <div id="day-24">
     <p>
       <img id="img-day24" src="https://www.qemu-advent-calendar.org/2020/images/closed-door.png" alt="Day 24" onclick="zonk('day24');">
     </p>
     <h2 id="title-day24">Day 24</h2>
     <p>
       Image will be available on December 24th.
      </p>
     
    </div>

    <hr>

    <div>

      <div id="about">
        <h2>About</h2>
        <p>
          The QEMU Advent Calendar 2020 features a QEMU disk image each day of
          December until the 24th. Each day a new package becomes available
          for download.
        </p>
        <p>
          Every download contains a little 'run' shell script that starts the
          QEMU emulator with the recommended parameters for the disk image.
          Disk images are either contained directly in the download or are
          downloaded by the 'run' script (you need to have installed 'curl' or
          'wget' in that case).
        </p>
        <p>
          The disk images contain interesting operating systems and software
          that run under the QEMU emulator. Some of them are well-known or
          not-so-well-known operating systems, old and new, others are custom
          demos and neat algorithms.
        </p>
        <p>
          The 'run' scripts (and disk images if included in the download)
          were created by volunteers from the QEMU community to showcase cool
          software that QEMU can run.
        </p>
      </div>

      

      <hr>

      

    </div><!-- /.container -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    
    
  

</div>]]>
            </description>
            <link>https://www.qemu-advent-calendar.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25262608</guid>
            <pubDate>Tue, 01 Dec 2020 05:23:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why do I care the open web is dying?]]>
            </title>
            <description>
<![CDATA[
Score 385 | Comments 337 (<a href="https://news.ycombinator.com/item?id=25261132">thread link</a>) | @archajain
<br/>
November 30, 2020 | https://insightbrowser.com/blog/open-web-dying-why-care | <a href="https://web.archive.org/web/*/https://insightbrowser.com/blog/open-web-dying-why-care">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><div><div><p><em>Part 1: How your user experience changes for the worse as the open web gives way to walled gardens</em></p><p>I hang out in two circles. Open web enthusiasts that are lamenting its demise, and regular users who are happy with their fast snappy apps and couldn't care less. </p><p>These groups have a hard time talking because the "open web" too often comes across as an idealistic abstract notion and most end users just don't tangibly feel the bad consequences. In fact, they're often happier with the snappy, vertically integrated experience of closed app ecosystems. </p><p>My goal here is to make it more palpable how everyday apps, searches and tools get worse when we let big centralized companies take over the web, and explore some paths for reversing it.</p><h2>What is the open web?</h2><p>Most definitions of the "open web" I've seen are either too technical to be accessible or too abstract to be usable and getting gridlocked in this debate often means watching from the sidelines while actual user welfare slowly diminishes.</p><p>Three characteristics that proponents of the open web will agree to in roughly descending order are:</p><ul><li><strong>Ease of publishing</strong>: anyone can publish to it freely or at least very cheaply, and is on the same footing with a globally accessible URL</li><li><strong>Ease of consuming</strong>: Net neutrality — ISP's dont cut deals with corporations to make some websites load faster or cheaper than others.</li><li><strong>Ease of remixing</strong>. You can see the source code. Content licenses and tools are permissive for derived works.</li></ul><h2>Detour: A framework to break down how people use the web</h2><p>I want to focus on the user experience point of view. To do this, I'm going to introduce a framework that divides up all our internet usage into two categories.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/xscGdbWOOPkGjdER.png" alt="Frame 1.png"></p><h3><strong>Unfamiliar problems</strong></h3><p>You have an unfamiliar problem and to solve it you either need to learn something new, or purchase goods or services to solve it</p><ul><li>e.g. taking out a mortgage, a health problem in the family, where to go to college, what skill to acquire next.</li><li>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services.</li><li>These user journeys start with search engines — Google predominantly and **a lot of the time solving them is spent on web pages**.</li><li>When people are looking to solve unfamiliar problems, **revenue is typically higher-margin**, because users can't price the products and services as well.</li><li>These ultimately transition to being familiar problems.</li></ul><h3><strong>Familiar problems</strong></h3><ul><li>e.g. being entertained, keeping the dog food in stock,</li><li>These are best solved with apps like Email, Netflix, Twitter, DTC subscription boxes, etc.</li><li>Solving these needs has a very well defined user interaction journey. You open the app you're familiar with and follow its standard flow.</li><li>Revenue from people solving familiar problems is typically lower-margin and there's more competing products.
</li></ul><h3>How we're spending our time on familiar vs. unfamiliar problems</h3><p>Using time spent in apps vs mobile web on mobile is a way to proxy how we divide up our time.<strong> We spend most of our time on familiar problems but have a constant trickle of unfamiliar problems</strong>.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/cPuXkKFELALeIAkI.png" alt="Untitled (1).png"></p><h2>Unfamiliar problems are better solved with the open web</h2><p>Think about the last time you did some research, e.g. choosing a phone plan. You asked your friends, compared on forums, looked at the official sites, scribbled some notes and made a decision. Even if this journey was quick, you likely traversed a dozen services and products to do this.</p><p>Unfamiliar problems have less constraints, require creativity to solve, and thus are better suited to open solutions. Some other things that work for the open web here</p><ul><li>comparing alternatives is easier.</li><li>changing modalities (e.g. from reading to video) is easier.</li></ul><h2>Familiar problems stand to benefit more from tight vertical integration</h2><p>Take Spotify for example. It solves the very familiar problem of listening to music. Spotify just works better as an app because</p><ul><li>Controlling the user experience end to end makes for smoother flows.</li><li>Having all the user data kept with Spotify allows for better recommendation algorithms.</li><li>Spotify can easily hand off between devices.</li><li>It can run in the background</li></ul><p>Sure, the web can do a bunch of these things, but they're simply not first-class considerations in the open-read-close workflow that the browser was designed for.</p><h2>But the open web can be better for familiar problems too, especially for breaking monopolies</h2><p>Let's look at Amazon. Initially you start buying there because of their "always low prices" and the convenience of 2 day shipping. Over the years you keep shopping there, until you've forgotten that </p><ol><li>free 2 day shipping is now near universal</li><li>amazon isn't often the cheapest place</li></ol><p>On the Amazon app, you see the story around the product that best serves Amazon, not the buyer. Meanwhile, over on Insight you can use the web version and do all these things the app can't.</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/ZEblynrLvBsutnlQ.png" alt="Screen Shot 2020-11-17 at 5.42.21 PM.png"></p><p>... and not just that

</p><p><img src="https://landen.imgix.net/blog_uSsTzKptQlxlvUvQ/assets/JVZoTRazmYPZXBQQ.png" alt="Screen Shot 2020-11-17 at 5.59.22 PM.png"></p><h2><strong>How solving unfamiliar problems gets harder too</strong></h2><p>Unfamiliar problems are solved in large part with acquiring new knowledge, not just products or services. The incentives to freely create knowledge that solves unfamiliar problems is lost as the web closes down.</p><ul><li>Google increasingly takes a larger percent of ad revenue as they <a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/">start extracting answers from pages and showing them on their search result pages.</a><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a></li><li><a href="https://sparktoro.com/blog/less-than-half-of-google-searches-now-result-in-a-click/"></a>Publishers have to either a) paywall their content (e.g. NYTimes) or b) subtly sell products (everyone standing a Wirecutter alternative), or c) ask for donations in order to survive.</li><li>Only a few big name publishers survive. Google and Facebook start sending them more of the traffic that's left, and since domain rank plays a big part in Google's ranking, those that survived assimilate more power and rank better.</li><li>and search engines seem more littered with SEO junk and less actually useful information year over year.</li></ul><h2>In conclusion, and where we fit in.</h2><p>And that's how your user experience slowly degrades, and that's why we stand to suffer as users if we give up the ability to remix software that the web brought us and closed apps are now taking away. </p><p>Our goal with Insight is to give the web (in particular on mobile) a fighting chance by exhibiting how it can be more powerful than a closed ecosystem and give more control to the end-user. We do this by showcasing the web's infinite extensibility and customizability for common use cases like <a href="http://insightbrowser.com/collections/search">search</a>, <a href="https://insightbrowser.com/collections/shopping">shopping</a>, <a href="https://insightbrowser.com/collections/reading">reading</a> and <a href="https://insightbrowser.com/collections/cooking">cooking</a>.</p><p>Insight's advanced features will soon only be available to Pro subscription users but for a limited time we're opening up <strong>lifetime free beta access if you download it via TestFlight below.</strong></p><h3>Coming up in part 2</h3><ul><li>What parts of the open web probably should die off?</li><li>A pragmatic path for what's left of the open web to thrive again.</li></ul><p>We'd love to hear from you, feel free to tweet at or DM us at @<a href="https://twitter.com/insightbrowser">insightbrowser</a>, and my personal Twitter is <a href="https://twitter.com/abhinavsharma">@abhinavsharma</a>.</p></div></div></div></div>]]>
            </description>
            <link>https://insightbrowser.com/blog/open-web-dying-why-care</link>
            <guid isPermaLink="false">hacker-news-small-sites-25261132</guid>
            <pubDate>Tue, 01 Dec 2020 01:16:22 GMT</pubDate>
        </item>
    </channel>
</rss>
