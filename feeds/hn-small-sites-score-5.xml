<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 26 Aug 2020 20:21:59 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 26 Aug 2020 20:21:59 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Code-first GraphQL server by Prisma]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24269944">thread link</a>) | @oczek
<br/>
August 25, 2020 | https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/ | <a href="https://web.archive.org/web/*/https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>GraphQL schema is a set of rules describing the functionality available to the client, including specification of operations (queries and mutations) that can be executed to execute against your data graph. When building a GraphQL service, there is a choice that needs to be made whether you want to follow the code-first or schema-first path: </p>
<ul>
<li>Schema-first - which prioritizes process of designing the schema which puts schema as your source of truth and forces your code to follow the definitions stored in your schema,</li>
<li>Code-first (resolver-first) - is an approach where the GraphQL schema is implemented programmatically.</li>
</ul>
<p>In either case, we will end up with a fully functional GraphQL service, but this choice will influence your project in terms of the amount of work you will need to put to introduce some features (but it’s a topic that deserves to be covered in a separate post).</p>
<h2>Code-first framework for GraphQL Server development</h2>
<p>The rapid growth of GraphQL’s popularity generated the natural need for different tools, both schema-first and code-first oriented, facilitating GraphQL working experience. One of the tools representing the code-first approach is <a href="https://nexus.js.org/">GraphQL Nexus framerwork</a>.</p>
<p>GraphQL Nexus is a GraphQL framework for building your GraphQL Server, where the schema is defined and implemented programmatically. GraphQL Nexus relies on a Node.js and TypeScript thanks to which it can provide features such as:</p>
<ul>
<li><strong>Type-Safety</strong> -  type-definitions are being generated as you proceed with the development process &amp; inferred in your code, providing you with auto-completion and error catching,</li>
<li><strong>Compatibility with GraphQL Ecosystem</strong> - GraphQL Nexus relies heavily on graphql-js and works well with its existing types when constructing the schema which makes the auto-generated schema compatible with most popular tools like Apollo Server etc.,</li>
<li><strong>Data-Agnostic</strong> - GraphQL Nexus is a declarative syntax layered on the top of the graphql-js library which basically means that you can achieve with it all that you can do with graphql-js or apollo-tools.</li>
</ul>
<p>Having figured out all the types you need for your schema all you need to do is simply use <code>makeSchema</code> function to create the schema instance that would be used as the foundation for your GraphQL server.</p>
<div data-language="tsx"><pre><code><span>const</span> schema <span>=</span> <span>makeSchema</span><span>(</span><span>{</span>
  
  types<span>:</span> <span>[</span>User<span>,</span> Query<span>,</span> Mutation<span>]</span><span>,</span>

  
  outputs<span>:</span> <span>{</span>
    typegen<span>:</span> __dirname <span>+</span> <span>'/generated/typings.ts'</span><span>,</span>
    schema<span>:</span> __dirname <span>+</span> <span>'/generated/schema.graphql'</span><span>,</span>
  <span>}</span><span>,</span>

  
  nonNullDefaults<span>:</span> <span>{</span>
    input<span>:</span> <span>true</span><span>,</span>
    output<span>:</span> <span>true</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span>

</code></pre></div>
<h2>Getting started</h2>
<p>As previously mentioned GraphQL Nexus relies heavily on <code>graphql-js</code> and it’s also required for the installation:</p>
<div data-language="text"><pre><code>npm install nexus
npm install graphql # required as a peer dependency</code></pre></div>
<p>The best way to begin with GraphQL Nexus is of course the <a href="https://nexus.js.org/docs/getting-started">official documentation</a>. After familiarizing with it the next step could be playing around with their <a href="https://github.com/prisma/nexus/tree/develop/examples">official examples</a> and the <a href="https://nexus.js.org/playground">online Playground</a>. Have fun!</p></div><p>The GraphQL Editor is a supportive tool for both advanced GraphQL users as well as those taking their first steps with GraphQL APIs. Our all-in-one development environment for GraphQL will help you build, manage &amp; deploy your GraphQL API much faster thanks to dozens of built-in micro features. Its graphical interface will also fix communication within your product team. Visualization is the key!</p></div>]]>
            </description>
            <link>https://blog.graphqleditor.com/graphql-nexus-codefirst-graphql-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269944</guid>
            <pubDate>Tue, 25 Aug 2020 10:46:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Hierarchy First Approach to Note Taking]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24265824">thread link</a>) | @kevinslin
<br/>
August 24, 2020 | https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html | <a href="https://web.archive.org/web/*/https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text"> <figure> <img src="https://www.kevinslin.com/assets/images/tree.jpeg" alt="tree"> </figure> <p>Ten years ago I wrote a note.</p> <p>That led to <strong>another</strong>, and then <strong>another</strong>, and soon enough, I had a <strong>few thousand</strong> of them and an increasingly unhappy dropbox client that refused to sync it all.</p> <p>The reason for all these notes is because of technology.</p> <p>I worked at AWS and tried to keep on top of <strong>cloud stuff</strong>. I programmed in three different languages and kept notes to help me context switch between different <strong>programming languages</strong>. I also did full-stack development on the side and that, well, it required referencing <strong><a href="https://www.reddit.com/r/webdev/comments/747hfu/does_everybody_find_the_modern_fullstack_learning/">everything</a></strong>.</p> <p>My primary use for notes is as a <a href="https://en.wikipedia.org/wiki/Cache_(computing)">cache</a>. Think <a href="https://redis.io/">Redis</a>, but for humans.</p> <p>If I spent <strong>more than 5 minutes</strong> figuring something out, those are five minutes I <strong>never</strong> want to spend again figuring out the <strong>same problem</strong>.</p> <p>But this is difficult to do in practice.</p> <p>Sometimes you run into a thing that only pops up on some specific version of a cli command on an outdated bash shell on a specific Linux distro. How do you document this sort of thing when you might encounter a dozen of them a day?</p> <p>My solution is something I call <strong>hierarchal note taking</strong>. It’s a system I’ve developed over the past ten years that has allowed me to amass a corpus of +10k notes.</p> <p>This system has some awesome properties that I haven’t been able to replicate with anything else:</p> <ul> <li>it lets me <strong>find any specific note within seconds</strong> even with thousands of existing notes</li> <li>it helps me build a <strong>comprehensive mental model</strong> around a domain through the act of organizing my notes</li> <li>it <strong>can be used on any note-taking tool that supports markdown notes</strong></li> <li>it’s compatible with existing note-taking methodologies like <a href="https://fortelabs.co/blog/para/">PARA</a></li> </ul> <p>The rest of this post will describe the journey I took to arrive at hierarchal note-taking and the problems that they help me solve.</p> <h2 id="the-problem-with-clis"> <a href="#the-problem-with-clis" aria-labelledby="the-problem-with-clis"></a> The Problem with CLIs </h2> <p>I spend a lot of time in the command line in Unix-like systems. If you do as well, you might be familiar with the following comic.</p> <p><img src="https://www.kevinslin.com/assets/images/2020-06-09-15-11-27.png" alt="tar bomb"></p> <blockquote> <p>Comic from <a href="https://xkcd.com/">XKCD</a></p> </blockquote> <p>I’ve probably used <code>tar</code> a few thousand times in my life but still can’t tell you what the arguments mean (it’s mostly muscle memory at this point). Unix tools do one thing and one thing well, and on most days, that one thing is making you reach for a <a href="https://en.wikipedia.org/wiki/Man_page">man page</a>.</p> <p>This is because every command has many dozen options, many of which are invoked with obscure single character letters in a specific order for specific inputs (I’m looking at you <code>rsync</code>).</p> <p>Growing tired of reading man pages and stack overflow threads, I wanted a way to capture and reference commands that I’ve run in the past. And so I started taking notes.</p> <p>I created a folder called <code>notes</code>. I created a note called <code>tar.md</code>.</p>  <p>Note that my <code>tar.md</code> note doesn’t have every option or use case involving <code>tar</code>. Instead, it’s only the options that I find most useful and use cases that I’ve had to do. This tends to be my approach to note-taking - I like to capture the bare minimum information I need so that the future me can get value out of the note.</p> <p>What started as a single markdown file quickly spawned a few hundred more. It was exhilarating - instead of turning to google every time I ran into a dusty corner of Linux, I could just reference my notes. 95% of the time, there would be a nicely summarized note waiting for me :)</p> <h2 id="the-problem-with-languages"> <a href="#the-problem-with-languages" aria-labelledby="the-problem-with-languages"></a> The Problem with Languages </h2> <p>While the above approach worked for cli commands, things got more complicated as I needed notes on additional domains. Most commonly with my work, it was programming languages.</p> <p>Take <a href="https://www.python.org/">python</a> as an example. Python is both a <strong>programming language</strong> as well as a <strong>cli command</strong>. Without changing the name of one of the notes or introducing folders, there would be no way to create notes on both.</p> <p>But I didn’t want folders. Folders were messy and besides, weren’t supported in <a href="http://notational.net/">notational velocity</a>, my primary note-taking tool at the time. So instead of folders, I decided to create a hierarchy using the <code>.</code> symbol as my delimiter.</p> <p>Now I could represent the language and the cli as two different <code>.</code> delimited hierarchies.</p> <div><div><pre><code>cli.python.md
lang.python.md
</code></pre></div></div> <p>Though on the surface, this seems like a simple change and not all that different from a traditional folder hierarchy, I found that it equal to the difference between using a <a href="https://en.wikipedia.org/wiki/Commodore_64">commodore 64</a> and the latest (non-<a href="https://www.theverge.com/2020/5/4/21246223/macbook-keyboard-butterfly-magic-pro-apple-design">butterfly keyboard</a>) Macbook.</p> <p>For starters, files now had the ability to both contain data and have children. They could act as both files and folders.</p> <p>And whereas folders were traditionally used to <strong>organize</strong> information, there was no straightforward way to use a folder hierarchy to quickly <strong>find</strong> information. Having the hierarchy in the filename made it easy to <strong>find</strong> information using the <strong>hierarchy</strong>.</p> <p><img src="https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/lookup-cli.gif" alt="cli lookup"></p> <h2 id="finding-the-truth"> <a href="#finding-the-truth" aria-labelledby="finding-the-truth"></a> Finding the Truth </h2> <p>There’s the joke in computer science that there are only 3 meaningful quantities in the field: 0, 1 or infinite. If you can create a thing more than once, there is nothing in theory that should stop you from creating an infinite amount of said thing.</p> <p>Once I realized I had a system of making two-level hierarchies, I realized I didn’t need to stop there. This soon led to deeper hierarchies like the one below.</p> <div><div><pre><code>.
└── lang
    └── python
        ├── data
        │   ├── boolean
        │   ├── array
        │   ├── string
        │   └── flow
        ├── flow
        │   ├── for
        │   ├── while
        │   └── if
        └── operator
            ├── comment
            ├── compare
            ├── scope
            ├── inspect
            ├── format
            ├── iterate
            └── destructure
</code></pre></div></div> <p>The above hierarchy was stored as simple plain text files inside my <code>notes</code> folder.</p> <div><div><pre><code>lang.python.data.boolean.md
lang.python.data.array.md
lang.python.data.string.md
lang.python.flow.md
lang.python.flow.for.md
lang.python.flow.while.md
lang.python.flow.if.md
lang.python.operator.md
lang.python.operator.comment.md
lang.python.operator.compare.md
lang.python.operator.scope.md
lang.python.operator.inspect.md
lang.python.operator.format.md
lang.python.operator.iterate.md
lang.python.operator.destructure.md
</code></pre></div></div> <p>With this hierarchy, I could quickly reference anything I needed from a programming language.</p> <p><img src="https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/blog.python.lookup.gif" alt="python data structure lookup"></p> <blockquote> <p>Looking up different data structures in python</p> </blockquote> <p>Once I built out my hierarchy on <code>python</code>, I found that I could also apply it to any other language. This made context switching between languages much easier.</p> <p>As an example, I can never remember what counts as <code>truthy</code> in dynamic languages. But now I don’t have to.</p> <p><img src="https://foundation-prod-assetspublic53c57cce-8cpvgjldwysl.s3-us-west-2.amazonaws.com/assets/images/blog.lookup.bool.gif" alt="finding the truth"></p> <blockquote> <p>Finding the truth</p> </blockquote> <p>The cool thing about this approach is that the implementation details of any particular language became less important as I build out my hierarchies. Instead of thinking in terms of “how well do I understand <strong>python</strong>”, I think in terms of how well I understand <strong>programming languages</strong>.</p> <h2 id="externalizing-mental-models"> <a href="#externalizing-mental-models" aria-labelledby="externalizing-mental-models"></a> Externalizing Mental Models </h2> <p>As I started building hierarchies across more and more domains, I found that it became useful to document what they were. I called these <em>externalized hierarchies</em> <strong>schemas</strong>. They were a table of contents for a particular hierarchy. I started adding a special <code>schema</code> file directly underneath the root of each hierarchy.</p> <div><div><pre><code>lang.schema.md
cli.schema.md
aws.schema.md
...
</code></pre></div></div> <p>Inside each <code>schema</code> note, I would have something like the following</p> <div><div><pre><code>- lang (namespace) # indicates that there are any number of languages underneath here
    - data: data structures
    - flow: control flow
    - oo: object-oriented programming
    - ...
</code></pre></div></div> <p>I would use schemas as a common source of truth when building out a hierarchy and use them to make sure that each hierarchy was internally consistent. As I began to use this system day by day, I realized that I had stumbled upon a radically more effective way of learning.</p> <h2 id="hierarchal-notes"> <a href="#hierarchal-notes" aria-labelledby="hierarchal-notes"></a> Hierarchal Notes </h2> <p>By associating every note I took to a hierarchy, I found that looking up information no longer felt like an <strong>tax on my time</strong>, but instead, a <strong>path to self augmentation</strong>.</p> <p>Whereas before I would look up a thing only to forget it a few weeks later, I could now quickly incorporate it into my notes and <strong>know with certainty</strong> that I will be able to <strong>reference this again</strong> at a later date.</p> <p>Better yet, when I found something that didn’t fit any of my existing hierarchies, I could use it as a chance to update my schemas on said hierarchies. This would slowly expand my conceptual understanding of the entire domain.</p> <p>A concrete example: earlier this year, I ended up making use of the <a href="https://en.wikipedia.org/wiki/Null_coalescing_operator">null coalescing operator</a> in javascript. This is a convenient way of assigning values when dealing with <code>null</code></p> <p>In the following example, <code>a</code> will be assigned the value of <code>b</code> if the value of <code>b</code> is not <code>null</code> or <code>undefined</code>, otherwise, it will be assigned 3.</p>  <p>After learning about it, I added it to my language schema under <code>operators</code>.</p> <div><div><pre><code>- lang (namespace)
    - {specific language}
        - operator (alias: op)
            - add
            - subtract
            - ...
            - null # null coalescing operator
</code></pre></div></div> <p>Not only did this expand my vocabulary of language operators, but it also let me note down how the equivalent functionality can be expressed in languages that did not natively support it.</p> <div><div><pre><code><span>other</span> <span>=</span> <span>s</span> <span>or</span> <span>"some default value"</span>
</code></pre></div></div> <blockquote> <p>Python example of “null coalescing”</p> </blockquote> <p>What is nice about this approach is that I have completely divorced the concept of “null coalescing” with the implementation detail of any particular language. The next time I’m using python and want to do <code>null coalescing</code>, I can simply look up <code>python.op.null</code> and be reminded of the implementation.</p> <p>There are dozens of <strong>main stream</strong> programming languages. There are hundreds of additional domain-specific languages. In a prior life, there would have been no way for me to <strong>know</strong> even a tiny fraction of them. But a hierarchal first approach to note-taking changes the game - instead of having to know the details of <strong>every</strong> language, I can collapse it all down to my <strong>one language schema</strong>. This schema can capture the points of interest of <strong>every language</strong> and in this way, I can claim to <strong>know</strong> something of all programming languages.</p> <h2 id="the-present-day"> <a href="#the-present-day" aria-labelledby="the-present-day"></a> The Present Day </h2> <p>Today, my knowledge base encompasses over a dozen different hierarchies that span 10K+ notes. I’ve expanded my use cases of note-taking beyond caching to also …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html">https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html</a></em></p>]]>
            </description>
            <link>https://www.kevinslin.com/notes/3dd58f62-fee5-4f93-b9f1-b0f0f59a9b64.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24265824</guid>
            <pubDate>Mon, 24 Aug 2020 21:38:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust-Style Futures in C]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24264841">thread link</a>) | @axelf4
<br/>
August 24, 2020 | https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html | <a href="https://web.archive.org/web/*/https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>All networking applications essentially boil down to stringing together
multiple asynchronous calls in the <em>right</em> way.
Traditionally for programs written in C this would be done through
registering callbacks where the callee either handles the event itself
or dispatches through a state machine.
In such implementations however reasoning about memory safety
can be treacherous, with it sometimes requiring full-program knowledge.
Futures, or promises, as they are also referred to,
ease in that regard by allowing asynchronous programs
to be written in direct style, keeping the control flow linear.</p>

<p>All things considered, I do think that futures can be a good fit
for C programming under the right circumstances.
I also hope this article can serve to help one understand Rust futures,
by being a separate reference that only touches the fundamentals.</p>

<p>The Rust futures story is especially interesting because it is
fundamentally different from the usual workings of futures
in functional languages or, say, JavaScript.
Whereas other implementations are <em>push</em>-based -
meaning you give a function to be pushed to with
the resolved result of the future -
Rust futures are <em>poll</em>-based.
Let us see how this looks in C with the simplification
that we limit ourselves to a single task,
i.e. one top-level future running on one thread.
This is common in embedded programming, and still <em>fairly</em> manageable
without the security guarantees given by Rust.
<a href="https://libuv.org/">libuv</a> is used for the event loop.
No heap allocations will be required - it is all downhill from here
(Get it? Because the stack grows down.) -
other than those imposed by the libuv interface.</p>

<p>The main <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>std::future::Future</code></a> trait
translated into C as a virtual method table becomes</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>{</span> <span>POLL_PENDING</span><span>,</span> <span>POLL_READY</span> <span>};</span>

<span>struct</span> <span>Future</span> <span>{</span>
	<span>enum</span> <span>Poll</span> <span>(</span><span>*</span><span>poll</span><span>)(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>);</span>

	<span>// For now let's skip this method</span>
	<span>// void (*drop)(struct Future *self, struct Context *ctx);</span>
<span>};</span>
</code></pre></div></div>
<p>As an example, let us consider the simplest case:
A future that immediately resolves with the number <code>4</code>,</p>
<div><div><pre><code><span>enum</span> <span>Poll</span> <span>simpleFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>SimpleFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>SimpleFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>self</span><span>-&gt;</span><span>result</span> <span>=</span> <span>4</span><span>;</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>SimpleFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>int</span> <span>result</span><span>;</span>
<span>}</span> <span>simpleFuture</span> <span>=</span> <span>{</span> <span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>simpleFuturePoll</span><span>,</span> <span>}</span> <span>};</span>

<span>// ... and in the event loop</span>
<span>simpleFuture</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>simpleFuture</span><span>,</span> <span>ctx</span><span>);</span> <span>// =&gt; POLL_READY</span>
<span>// Here we can now use the result</span>
<span>simpleFuture</span><span>.</span><span>result</span> <span>// =&gt; 4</span>
</code></pre></div></div>
<p>To <em>attempt</em> to resolve the future, we poll it;
it returns <code>POLL_READY</code> and as such we are done.
And for futures that instead return <code>POLL_PENDING</code> when polled,
we just make sure to poll them again later -
futures are lazy and do not make progress unless actively told to do so.
No one knows better than the future itself when it should
be polled again - <em>awoken</em> -
so the context given to all futures allows them to awake their own task.
With many parallel tasks the additional complexity would make itself apparent here,
but in our case something like</p>
<div><div><pre><code><span>struct</span> <span>Context</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>*</span><span>mainFuture</span><span>;</span>
	<span>uv_loop_t</span> <span>loop</span><span>;</span>
<span>};</span>

<span>void</span> <span>wakeTask</span><span>(</span><span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>if</span> <span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>-&gt;</span><span>poll</span><span>(</span><span>ctx</span><span>-&gt;</span><span>mainFuture</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_READY</span><span>)</span> <span>{</span>
		<span>exit</span><span>(</span><span>EXIT_SUCCESS</span><span>);</span> <span>// Finished!</span>
	<span>}</span>
<span>}</span>
</code></pre></div></div>
<p>will suffice.
Polling the future once at startup will then kick off the machinery.</p>

<p>For a libuv timer future, we would want to write something like</p>
<div><div><pre><code><span>enum</span> <span>TimerStatus</span> <span>{</span> <span>TIMER_NOT_STARTED</span><span>,</span> <span>TIMER_WAITING</span><span>,</span> <span>TIMER_FINISHED</span> <span>};</span>

<span>struct</span> <span>TimerFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>enum</span> <span>TimerStatus</span> <span>status</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>uint64_t</span> <span>timeout</span><span>;</span>
		<span>uv_timer_t</span> <span>*</span><span>handle</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>static</span> <span>void</span> <span>uvCloseFree</span><span>(</span><span>uv_handle_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>free</span><span>(</span><span>handle</span><span>);</span>
<span>}</span>

<span>static</span> <span>void</span> <span>timerCb</span><span>(</span><span>uv_timer_t</span> <span>*</span><span>handle</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>data</span><span>;</span>
	<span>struct</span> <span>Context</span> <span>*</span><span>ctx</span> <span>=</span> <span>handle</span><span>-&gt;</span><span>loop</span><span>.</span><span>data</span><span>;</span>
	<span>uv_close</span><span>((</span><span>uv_handle_t</span> <span>*</span><span>)</span> <span>handle</span><span>,</span> <span>uvCloseFree</span><span>);</span>
	<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_FINISHED</span><span>;</span>
	<span>wakeTask</span><span>(</span><span>ctx</span><span>);</span>
<span>}</span>

<span>static</span> <span>enum</span> <span>Poll</span> <span>timerFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TimerFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TimerFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>status</span><span>)</span> <span>{</span>
		<span>case</span> <span>TIMER_NOT_STARTED</span><span>:</span>
			<span>uint64_t</span> <span>timeout</span> <span>=</span> <span>state</span><span>-&gt;</span><span>timeout</span><span>;</span>
			<span>state</span><span>-&gt;</span><span>handle</span> <span>=</span> <span>malloc</span><span>(</span><span>sizeof</span> <span>*</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>uv_timer_init</span><span>(</span><span>ctx</span><span>.</span><span>loop</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>handle</span><span>-&gt;</span><span>data</span> <span>=</span> <span>state</span><span>;</span>
			<span>uv_timer_start</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>handle</span><span>,</span> <span>timerCb</span><span>,</span> <span>timeout</span><span>,</span> <span>/* no repeat */</span> <span>0</span><span>);</span>
			<span>state</span><span>-&gt;</span><span>status</span> <span>=</span> <span>TIMER_WAITING</span><span>;</span>
			<span>/* fallthrough */</span>
		<span>case</span> <span>TIMER_WAITING</span><span>:</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
		<span>case</span> <span>TIMER_FINISHED</span><span>:</span>
			<span>return</span> <span>POLL_READY</span><span>;</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>

<span>struct</span> <span>TimerFuture</span> <span>timerFutureNew</span><span>(</span><span>uint64_t</span> <span>timeout</span><span>)</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TimerFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>timerFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>status</span> <span>=</span> <span>TIMER_NOT_STARTED</span><span>,</span>
		<span>.</span><span>timeout</span> <span>=</span> <span>timeout</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>
<p>The timer handle is made to hold a reference to the future in
its user data field,
so that the callback knows which future to toggle the status on.
However this requires the future object to be pinned in memory,
moving it would make the reference dangling.
Rust deals with this unsafety using the <a href="https://doc.rust-lang.org/std/pin/index.html">Pin construct</a>,
that wraps a pointer type, <code>P</code>,
and only permits operations that cannot move the pointee
(for cases where it may not always be safe to do so, i.e. <code>P: !Unpin</code>)
and ensures its memory remains valid until it gets dropped,
or helps make manually vetted code <em>nonleaky</em>.
In C there is no such thing;
the closest you will get is with a red paragraph buried in the documentation.
This means treading with care,
allocating storage for the main future once and never copying it, and
only referring to futures with pointers to their static place in memory.</p>

<p>Note that it is possible to get by with just one global <code>uv_timer_t</code>
by recognizing that whenever the main future is awoken either:
(I) A timer, necessarily the one with smallest timeout, fired;
or (II) All timers need be dropped and reset, since the futures form a tree,
as we will see.</p>

<h2 id="after-you">After you</h2>

<p>Running multiple futures sequentially is just a matter of
constructing a new future that polls each future to completion,
one after the other.
The poll method of the outer future will have to return <code>POLL_PENDING</code>
after each intermediate step,
before continuing where it left off - like a coroutine.
Rust turns each future into a state machine,
and doing the same in C means playing the part of the Rust compiler.
An adaptation of <a href="https://en.wikipedia.org/wiki/Duff%27s_device">Duff’s device</a>,
as <a href="https://www.chiark.greenend.org.uk/~sgtatham/coroutines.html">described by Simon Tatham</a>,
can help cut down on the boilerplate.
The idea is that with a <code>switch</code> statement enveloping the whole function-body,
you can yield by creating a unique label using the <code>__LINE__</code> macro
where execution will begin upon reentry,
setting the switch-expression as such, and returning.
The following macros do just that</p>
<div><div><pre><code><span>typedef</span> <span>unsigned</span> <span>Coroutine</span><span>;</span>

<span>#define COR_START(s) switch (*(s)) { case 0:;
#define COR_YIELD(s, r) do {*(s) = __LINE__; return (r); case __LINE__:;} while(0)
#define COR_END }
</span></code></pre></div></div>
<p>where <code>s</code> is a pointer to the coroutine state.
Great care has to be taken because when returning all locals are invalidated -
if only there was a language that could statically check for such mistakes.
Awaiting then becomes</p>
<div><div><pre><code><span>#define AWAIT(s, ctx, fut) while ((fut)-&gt;poll((fut), (ctx)) == POLL_PENDING) \
	COR_YIELD((s), POLL_PENDING)
</span></code></pre></div></div>
<p>that is, yielding until the given future is resolved.</p>

<p>To illustrate, here is a future that prints four times to standard output,
first thrice at one second intervals, and then again after two more seconds:</p>
<div><div><pre><code><span>struct</span> <span>TestFuture</span> <span>{</span>
	<span>struct</span> <span>Future</span> <span>future</span><span>;</span>
	<span>Coroutine</span> <span>c</span><span>;</span>
	<span>union</span> <span>{</span>
		<span>struct</span> <span>{</span>
			<span>int</span> <span>i</span><span>;</span>
			<span>struct</span> <span>TimerFuture</span> <span>timerA</span><span>;</span>
		<span>};</span>
		<span>struct</span> <span>TimerFuture</span> <span>timerB</span><span>;</span>
	<span>};</span>
<span>};</span>

<span>struct</span> <span>TestFuture</span> <span>testFutureNew</span><span>()</span> <span>{</span>
	<span>return</span> <span>(</span><span>struct</span> <span>TestFuture</span><span>)</span> <span>{</span>
		<span>.</span><span>future</span> <span>=</span> <span>{</span> <span>.</span><span>poll</span> <span>=</span> <span>testFuturePoll</span><span>,</span> <span>},</span>
		<span>.</span><span>c</span> <span>=</span> <span>0</span><span>,</span>
	<span>};</span>
<span>}</span>
</code></pre></div></div>

<div><table>
<thead><tr><th>With macros</th><th>Desugared</th></tr></thead>
<tbody><tr>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>COR_START</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span>

	<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
		<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
		<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>);</span>
		<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
	<span>}</span>

	<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
	<span>AWAIT</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>c</span><span>,</span> <span>ctx</span><span>,</span> <span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>);</span>
	<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>

	<span>COR_END</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
<td>
        <div><div><pre><code><span>enum</span> <span>Poll</span> <span>testFuturePoll</span><span>(</span><span>struct</span> <span>Future</span> <span>*</span><span>self</span><span>,</span> <span>struct</span> <span>Context</span> <span>*</span><span>ctx</span><span>)</span> <span>{</span>
	<span>struct</span> <span>TestFuture</span> <span>*</span><span>state</span> <span>=</span> <span>(</span><span>struct</span> <span>TestFuture</span> <span>*</span><span>)</span> <span>self</span><span>;</span>
	<span>switch</span> <span>(</span><span>state</span><span>-&gt;</span><span>c</span><span>)</span> <span>{</span>
		<span>case</span> <span>0</span><span>:</span> <span>;</span>
		<span>for</span> <span>(</span><span>state</span><span>-&gt;</span><span>i</span> <span>=</span> <span>0</span><span>;</span> <span>state</span><span>-&gt;</span><span>i</span> <span>&lt;</span> <span>3</span><span>;</span> <span>++</span><span>state</span><span>-&gt;</span><span>i</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>timerA</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>1000</span><span>);</span>
			<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerA</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
				<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>1</span><span>;</span>
				<span>return</span> <span>POLL_PENDING</span><span>;</span>
				<span>case</span> <span>1</span><span>:</span> <span>;</span>
			<span>}</span>
			<span>printf</span><span>(</span><span>"One second has passed!"</span><span>);</span>
		<span>}</span>

		<span>state</span><span>-&gt;</span><span>timerB</span> <span>=</span> <span>timerFutureNew</span><span>(</span><span>2000</span><span>);</span>
		<span>while</span> <span>(</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>.</span><span>poll</span><span>(</span><span>&amp;</span><span>state</span><span>-&gt;</span><span>timerB</span><span>.</span><span>future</span><span>,</span> <span>ctx</span><span>)</span> <span>==</span> <span>POLL_PENDING</span><span>)</span> <span>{</span>
			<span>state</span><span>-&gt;</span><span>c</span> <span>=</span> <span>2</span><span>;</span>
			<span>return</span> <span>POLL_PENDING</span><span>;</span>
			<span>case</span> <span>2</span><span>:</span> <span>;</span>
		<span>}</span>
		<span>printf</span><span>(</span><span>"Another two seconds have passed!"</span><span>);</span>
	<span>}</span>
	<span>return</span> <span>POLL_READY</span><span>;</span>
<span>}</span>
</code></pre></div>        </div>
      </td>
</tr>
</tbody></table></div>
<p>Note that the local <code>i</code> had to be spilled to the future struct
in order to persist across yield points,
and that unions are used to show what variables are active at each step,
and squeeze out that last driblet of performance even in the face of
uncompromising undefined behaviour threats from all directions.</p>

<h2 id="off-to-the-races">Off to the races</h2>

<p>In a similar vein, multiple futures can be made to run in parallel
using a future combinator whose poll method polls all of its children
and either waits for all to complete - <em>joins</em> them,
or selects the first to become ready.
The latter is a tad more difficult, so let us focus on that.
The reason is that after the first future has resolved,
the rest may still be running, their memory possibly referenced elsewhere.
This is where the <code>drop()</code> method that we have skimmed over comes in.
Dropping a pinned object should relax the constraint
that its memory remains valid.
The drop implementation of <code>TimerFuture</code> above could for example
call <code>uv_timer_stop()</code> so the callback never fires
or overwrite the dangling reference to the future with <code>NULL</code>.
For other types, since their drop implementations are …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html">https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</a></em></p>]]>
            </description>
            <link>https://axelf4.github.io/2020/08/24/rust-style-futures-in-c.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264841</guid>
            <pubDate>Mon, 24 Aug 2020 20:01:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jensen Huang’s vision for data center dominance may destroy the Arm ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24264288">thread link</a>) | @kasabali
<br/>
August 24, 2020 | https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="552" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="680b3ce0" data-element_type="section">
						<div>
							<div>
					<div data-id="c620d2" data-element_type="column">
			<div>
							<div>
						<div data-id="6eb11d27" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>As the weeks pass by, the rumors keep spinning, the likelihood of an Nvidia Arm acquisition increases. On first glance, the two businesses look completely incompatible. A highly vertically integrated graphics and AI company with very high margins buying a low margin IP licensor doesn’t make sense. Nvidia can already build any product they wish as an Arm licensee. Purchasing the whole cow doesn’t yield additional milk or synergies from the current business model. Furthermore, given Nvidia’s reputation as a partner, it would likely even cause customers to start looking for contingencies and accelerate RISC-V adoption. Jensen Huang, in his quest for data center dominance, may destroy the Arm ecosystem for everyone else.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/1.jpg?resize=1140%2C606&amp;ssl=1" alt="1" width="1140" height="606" data-recalc-dims="1"></p><p>The rational for purchasing Arm seems ridiculous to many, but Jensen’s vision is for the datacenter being a computer and Nvidia being the one to build it. They need to be to be completely vertically integrated and control every aspect of this computer. Currently they have the accelerator market on lock-down with their impressive hardware and vast software moat of CUDA/various SDKs which was built by thousands of Nvidia engineers over the last decade. With the acquisition of Mellanox, they bring the “Data Processing Unit (DPU)” of the data center in house as well. They have also continued to expand their vertically integrated software stack to networking with acquisitions of SwiftStack and Cumulus Networks.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/2.jpg?resize=1140%2C575&amp;ssl=1" alt="2" width="1140" height="575" data-recalc-dims="1"></p><p>The datacenter is a 3 legged stool, and the remaining missing piece is a CPU. AMD, Intel, and various hyperscalers are also working to build out their own 3-legged stool. The largest threat to Nvidia is Intel/AMD finally having competent GPUs and software stacks to accompany them. With the US Department of Energy dumping money into SYCL and many in the industry congregating around it, the software front is accelerating rapidly. Furthermore, various hyperscalers are rapidly building out their own CPUs with Arm Neoverse IP to hook in with their accelerators such as the Google TPU and Amazon Inferentia for AI workloads. Lastly, these hyperscalers also already have their own custom network stacks. Nvidia is currently in very strong position, but it is very precarious as their moats may all be eroded simultaneously.</p><p>In any business, in order to maintain a high margin over a long period of time, one must create barriers of entry so high, that no one can break in and disrupt. Even though Intel has stopped executing for essentially 5 years, they are still raking in the dough with &gt;55% gross margins. Jensen Huang’s vision, if fully realized, would see Nvidia building a nearly impenetrable moat that commands high margins and locks customers in. This may sound nefarious, but Nvidia’s solution will be plug and play. The vast majority of companies do not have the resources required to build out the entire software stack to match specialized hardware. Nvidia would offer the best solution, which would eventually become an expensive deal imprisoning you in the Devil’s ecosystem.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/3.png?resize=1140%2C587&amp;ssl=1" alt="3" width="1140" height="587" data-recalc-dims="1"></p><p>This is where acquiring Arm rather than licensing her technology comes into play. Nvidia needs to build the moat, and the only way to do this is to effectively hijack the entire open Arm ecosystem. Developing your own CPU ISA is far too large of an investment and there would be no adoption. Even the opening up of Power and MIPS have failed to stop their slow declines to irrelevancy. RISC-V is also still in its infancy and will take many years to move into any verticals besides embedded.</p><p>Jensen can only realize the of the vision of data center dominance by becoming the only company with the trifecta of CPU, GPU, and DPU. Nvidia can only achieve this by acquiring Arm at an unreasonable price. An independent Arm is simply not worth the $35B-$50B which SoftBank wants. Even a $20B valuation would be high valuation for Arm.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/4.jpg?resize=1140%2C641&amp;ssl=1" alt="4" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia can justify this price if they are willing to flip the semiconductor IP world on its head. The ultimate path to ROI means upending the current Arm business model. Given Nvidia’s over $300B valuation, the deal wouldn’t have to be very dilutive to current shareholders. They would start by purchasing the business in a cash/stock deal and obtaining regulatory approval. Regulatory approval initially seems like a large hurdle, but we believe it will not be. The UK will gladly approve if Nvidia makes commitments for large investments. China would be willing to look the other way if the current Arm China JV drama is swept under the rug. The EU would likely need concessions, but because Nvidia does not compete in most of Arm’s verticals, it shouldn’t be too difficult to obtain approval here either. The US regulators would be foaming at the thought of US control of Arm.</p><p>The next step would involve assuring the clients that the businesses would operate separately. Jensen has already begun telegraphing this according to the <a href="https://www.ft.com/content/b4649576-9541-4857-b3a4-5b4ccb847642">Financial Times</a>.</p><blockquote><p>As the company extends its reach to supply a complete data centre computing platform, it would sell parts of the technology as separate “layers”, Mr Huang said. Other companies would also be able to license its intellectual property for use in their own chips, rather than needing to buy silicon from Nvidia, he added.</p></blockquote><p>As part of the integration of the two companies, Nvidia would cut or sell the Arm Mali GPU and Ethos NPU business. These would be redundant and can be supplemented with Nvidia’s own expertise. This would be quite the shock as Nvidia’s previous attempts to license their GPU architecture have completely failed. If Nvidia is successful in the renewed licensing efforts, we could live in a world where their CUDA architecture with accompanying software stack (read lock-in) is proliferated across phones, embedded, and the upcoming augmented reality segment. There would be some attrition as companies like Samsung have turned to licensing AMD’s RDNA graphics. In general, it would also accelerate the move out of the Arm ecosystem to RISC-V, but this will be a painful and slow move for most.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/5.png?resize=1024%2C395&amp;ssl=1" alt="5" width="1024" height="395" data-recalc-dims="1"></p><p>The key for Nvidia here is creating captive, dependant customers by rocking the boat, but not too violently. If the NvidiArm solution is convenient and cheap, most of the ecosystem will not attempt to rush out. Nvidia likely does not increase prices for a while in order to give their licensees an illusion of a happy status quo. Eventually, these price increases will come. The attrition will be the worst in the embedded market where RISC-V is mostly already here and players like <a href="https://twitter.com/dylan522p/status/1295500585123188737?s=20">Alibaba</a> and Si-Five have the IP nearly ready to go.</p><p>The mobile SOC market is captive to Arm roadmaps for years to come, and this is one of the sectors Nvidia can start aggressively extracting ROI. Apple has a perpetual license and so they won’t be affected, but Qualcomm, Samsung, and Mediatek would start to sweat bullets as their licensing costs soar and they have no alternatives without their own custom core teams which have been disbanded. Mediatek specifically is highly dependent on not only ARM CPUs, but also GPUs and interconnects for many of their SOCs.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/6.png?resize=1140%2C641&amp;ssl=1" alt="6" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia’s largest avenue for ROI comes the data center. x86 is long overdue for some disruption. Even with AMD innovating rapidly, the world wants more options. Arm server development is being done by multiple hyperscalers and independent fabless vendors. Arm is going to break the x86 monopoly with a combination of licensed Neoverse designs and in-house designs from the likes of Nuvia or Marvell. Once the x86 duopoly is broken, Nvidia can also raise prices rapidly here. &nbsp;The hyperscalers in-house Arm Neoverse designs will still have better TCO than any merchant silicon, but the savings will begin to wane.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/7.png?resize=1140%2C641&amp;ssl=1" alt="7" width="1140" height="641" data-recalc-dims="1"></p><p>Another adjacent market where Nvidia can begin to pressure their competition is automotive. While Intel’s Mobileye currently uses MIPS and is transitioning to x86, Tesla and Qualcomm use Arm Cores. If licensing fees ratchet up here significantly, Nvidia can begin to extract margin out of their competitors’ sales. Ultimately, the CPU isn’t a competitive advantage in automotive, but just the cheapest and most convenient option.</p><p>As the Arm ecosystem matures, it will stop being the cheapest option, but only remain the convenient one. Embedded markets have already seen the light of RISC-V and the adoption can only accelerate from here. Other markets have been hooked to the drug of cheap, licensed, Arm IP. With aggressive Nvidia ownership, the junkies will have no choice but to pay up and give in to demands for the short run. They will search for alternative supplies, but this move will take a long time.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/8.jpg?resize=1140%2C642&amp;ssl=1" alt="8" width="1140" height="642" data-recalc-dims="1"></p><p>Nvidia’s endgame isn’t more revenue from licensing costs. Their endgame is a fully vertically integrated data center provider. They will want to make and control every part of the three legged stool. This means they slowly destroy the idea of Neoverse. Whether through making that IP extremely costly, or having their own in house designs be a generation ahead, Nvidia will build a moat around Arm server CPUs. Over time, Jensen Huang will muscle out other Arm vendors supplementing them with Nvidia’s in-house designs. The open Arm ecosystem will be hijacked, and be replaced with a closed off ecosystem rivaling or exceeding that of Intel and AMD.</p><p><span>If Nvidia can quickly seize the worlds most important IP, the most commonly used CPU ISA and designs, they will control the destiny of mobile and data center. This is Jensen Huang’s “Trojan Horse” for a Machiavellian takeover of the future of computing.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264288</guid>
            <pubDate>Mon, 24 Aug 2020 19:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Test Case Generator for a Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24263117">thread link</a>) | @azhenley
<br/>
August 24, 2020 | http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html | <a href="https://web.archive.org/web/*/http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Maxime Chevalier-Boisvert requested resources for learning about fuzzing
programming language implementations on Twitter:</p>

<blockquote>
  <p>I’d like to learn about fuzzing, specifically fuzzing programming language
implementations. Do you have reading materials you would recommend, blog
posts, papers, books or even recorded talks?</p>
</blockquote>

<p><cite><a href="https://twitter.com/Love2Code">@Love2Code</a> · <a href="https://twitter.com/Love2Code/status/1290363848885776385">August 3,
2020</a></cite></p>

<p>Maxime received many replies linking to informative papers, blog posts, and
lectures. <a href="https://twitter.com/johnregehr/status/1290368969199636480">John Regehr suggested writing a simple generative fuzzer for the
programming
language.</a></p>

<p>A generative fuzzer combines a test case generator with the system under test
(e.g. your compiler), generating new test cases and feeding them into the
system:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>generative_fuzzer</span><span>()</span> <span>{</span>
    <span>loop</span> <span>{</span>
        <span>// Use the test case generator to create a new</span>
        <span>// input.</span>
        <span>let</span> <span>input</span> <span>=</span> <span>generate_test_case</span><span>();</span>

        <span>// Feed that input into the system under test.</span>
        <span>let</span> <span>result</span> <span>=</span> <span>run_system_under_test</span><span>(</span><span>input</span><span>);</span>

        <span>// Finally, if the system under test crashed,</span>
        <span>// failed an assertion, etc... then report</span>
        <span>// that!</span>
        <span>if</span> <span>result</span><span>.is_interesting</span><span>()</span> <span>{</span>
            <span>report</span><span>(</span><span>input</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>I realized that many people might not know what it takes to write their own
generative fuzzer, so this blog post shows one aspect of it: implementing a test
case generator.</p>

<p>Our test case generator will generate <a href="https://webassembly.org/">WebAssembly</a> programs. While
WebAssembly has its own quirks — it’s a binary format and is generally a
compilation target rather than a source language — it is a small and
simple language. The techniques we use when generating WebAssembly should
transfer to generating the programming language of your choice.</p>

<p>If you want to skip the exposition and jump head first into the code, <a href="https://github.com/fitzgen/wasm-smith">here is
the repository for our final test case generator</a>.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#what-is-a-test-case-generator">What is a Test Case Generator?</a></li>
  <li><a href="#getting-set-up">Getting Set Up</a></li>
  <li><a href="#translating-grammars-into-generators">Translating Grammars into Generators</a></li>
  <li><a href="#generating-the-type-section">Generating the Type Section</a></li>
  <li><a href="#generating-the-import-section">Generating the Import Section</a></li>
  <li><a href="#generating-the-code-section">Generating the Code Section</a></li>
  <li><a href="#using-the-test-case-generator">Using the Test Case Generator</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="what-is-a-test-case-generator">What is a Test Case Generator?</h2>

<p>Test case generators generate test cases. These test cases are always within the
test domain: no cycles are wasted on invalid inputs, such as source text that
fails to parse. Compare this to <a href="https://www.fuzzingbook.org/beta/html/MutationFuzzer.html">mutation-based fuzzing</a>, where existing seed
inputs are mutated to produce new inputs. In general, nothing guarantees that
the new, mutated input is still within the test domain: the mutation may have
introduced a syntax error. This property, that generated inputs are always
within the test domain, is generative fuzzing’s main advantage and the test case
generator’s main responsibility.</p>

<p>A test case generator should, additionally, support every feature of its target
programming language. You won’t discover a bug in your compiler’s handling of
<code>switch</code> statements if the test case generator doesn’t support generating
<code>switch</code> statements. Pushing this idea even further, the test case generator
should <em>uniformly sample</em> from the test domain. If the test case generator can
technically generate <code>switch</code> statements but the probability of doing so is
nearly zero, then you likely still won’t find that bug. However, uniformly
sampling from the infinite set of all programs that can be written in a
particular programming language is
<a href="https://blog.regehr.org/archives/1700">nontrivial</a> and an area of
<a href="https://arxiv.org/pdf/0807.0992v1.pdf">active</a>
<a href="https://havrikov.github.io/publications/ase19-preprint.pdf">research</a>.</p>

<p>A test case generator should, finally, be fast. The faster we can generate test
cases, the faster we will discover bugs. If the generator is too slow, we can
blow our time budget, failing to find those bugs at all.</p>

<h2 id="getting-set-up">Getting Set Up</h2>

<p>First, we create a new crate with <code>cargo</code>. We’ll name this crate <code>wasm-smith</code>,
giving a little nod to <a href="https://embed.cs.utah.edu/csmith/">Csmith</a>, the popular C program generator.</p>

<figure><pre><code data-lang="shell"><span>$ </span>cargo new <span>--lib</span> wasm-smith</code></pre></figure>

<p>Second, we add <a href="https://github.com/rust-fuzz/arbitrary">the <code>arbitrary</code> crate</a> as a dependency:</p>

<figure><pre><code data-lang="toml"><span># wasm-smith/Cargo.toml</span>

<span>[dependencies]</span>
<span>arbitrary</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.4.6"</span><span>,</span> <span>features</span> <span>=</span> <span>["derive"]</span> <span>}</span></code></pre></figure>

<p>The <code>arbitrary</code> crate helps us generate structured data from arbitrary bytes. It
is typically used in combination with <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> to translate the raw bytes
given to use by libFuzzer into something that the system you’re testing can
process. For example, a color conversion library might use <code>arbitrary</code> to turn
the raw fuzzer-provided bytes into <code>Rgb</code> or <code>Hsl</code> color types. We will use it in
a similar way for this project, translating raw bytes given to us by libFuzzer
into semantically valid WebAssembly modules.</p>

<p>The <code>arbitrary</code> crate’s main export is <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/trait.Arbitrary.html">the <code>Arbitrary</code> trait</a>:</p>

<figure><pre><code data-lang="rust"><span>pub</span> <span>trait</span> <span>Arbitrary</span><span>:</span> <span>Sized</span> <span>+</span> <span>'static</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>;</span>

    <span>// Provided methods hidden...</span>
<span>}</span></code></pre></figure>

<p>It takes an <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/struct.Unstructured.html"><code>Unstructured</code></a>, which is a helpful wrapper around a byte slice, and
returns an instance of the type for which it is implemented.</p>

<p>For our <code>wasm-smith</code> crate, we define a <code>Module</code> type that represents our
pseudo-random WebAssembly modules, and then we implement the <code>Arbitrary</code> trait
for it:</p>

<figure><pre><code data-lang="rust"><span>use</span> <span>arbitrary</span><span>::{</span><span>Arbitrary</span><span>,</span> <span>Result</span><span>,</span> <span>Unstructured</span><span>};</span>

<span>/// A pseudo-random WebAssembly module.</span>
<span>pub</span> <span>struct</span> <span>Module</span> <span>{</span>
    <span>// ...</span>
<span>}</span>

<span>impl</span> <span>Arbitrary</span> <span>for</span> <span>Module</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>todo!</span><span>()</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Before we fill in that <code>todo!()</code> lets take a moment to settle on a design for
what the implementation will look like.</p>

<h2 id="translating-grammars-into-generators">Translating Grammars into Generators</h2>

<p>Writing a generator is remarkably similar to hand-writing a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent
parser</a>, so if you’ve done that before, then you should feel right at home. For
example, given this grammar production (borrowed and lightly edited from <a href="https://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangling">the
C++ name mangling</a> grammar):</p>

<pre><code>&lt;class-enum-type&gt; ::= Ts &lt;name&gt;
                    | Tu &lt;name&gt;
                    | Te &lt;name&gt;
</code></pre>

<p>A recursive descent parser will, almost mechanically, translate the production
into something like this:</p>

<figure><pre><code data-lang="rust"><span>impl</span> <span>Parse</span> <span>for</span> <span>ClassEnumType</span> <span>{</span>
    <span>fn</span> <span>parse</span><span>(</span><span>p</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Parser</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Ts"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Ts"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Ts</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Tu &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Tu"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Tu"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Tu</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Te &lt;name&gt;</span>
        <span>p</span><span>.consume</span><span>(</span><span>"Te"</span><span>)</span><span>?</span><span>;</span>
        <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
        <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Te</span><span>(</span><span>name</span><span>))</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Our generator will do something similar, except instead of peeking at the input
string to decide which right-hand side of the production to parse, we will make
a pseudo-random choice to generate one of those potential right hand sides.</p>

<p>We could use a random number generator directly to make these choices, but this
has two problems:</p>

<ol>
  <li>
    <p>We give up determinism unless we are careful to control the RNG’s seed and
reuse the same RNG everywhere, threading it through all of our functions as a
parameter. Determinism is extremely important for reproducing test failures!
It’s definitely possible to do these things, but can occasionally be a little
annoying.</p>
  </li>
  <li>
    <p>More importantly, using an RNG precludes a mature fuzzing engine, like
libFuzzer, from guiding our test case generation based on code coverage and
other insights.</p>
  </li>
</ol>

<p>Instead, we use a raw input byte slice given to us by libFuzzer or AFL as a
sequence of predetermined choices.<sup id="back-dont-require-libfuzzer"><a href="#foot-dont-require-libfuzzer">0</a></sup> This <a href="https://arxiv.org/pdf/1812.00078v1.pdf">lets the fuzzer guide our
test case generation</a>, and <a href="https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf">gives us test case reduction “for
free”</a> since we can ask the fuzzer to reduce the raw input
sequence, rather than write a domain-specific test case reducer. This comes as a
relief because writing a reducer that understands WebAssembly is easily as much
effort as writing the generator itself.</p>

<p>Here is the same C++ mangling example from above, but translated from a parser
into a generator, using <code>Unstructured</code>:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_class_enum_type</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>output</span><span>:</span> <span>&amp;</span><span>mut</span> <span>String</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
    <span>match</span> <span>u</span><span>.int_in_range</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>(</span><span>0</span><span>..=</span><span>2</span><span>)</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>0</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Ts"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Tu &lt;name&gt;</span>
        <span>1</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Tu"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Te &lt;name&gt;</span>
        <span>2</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Te"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>_</span> <span>=&gt;</span> <span>unreachable!</span><span>(),</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Once again, this is mostly mechanical.</p>

<p>This pattern will generate <em>syntactically</em> correct test cases that can be parsed
successfully but which likely contain a plethora of type errors, calls to
undefined functions, etc. We’ve set out to generate <em>semantically</em> correct test
cases that pass type checking and will exercise more than just the language
implementation’s frontend.</p>

<p>Our final pattern maintains some extra information about the program we’ve
generated thus far, so that we can consult that information when generating new
forms. This extra information might include which names are in scope, the types
of each variable, etc. We consult that information while dynamically building up
thunks for every valid option we could generate. Once we have enumerated every
option, we ask the <code>Unstructured</code> to choose one of them, and finally we call the
chosen thunk to generate the form.</p>

<p>Here is an example of using this pattern for generating integer expressions,
where an integer expression is either a constant integer, an arithmetic
operation, a use of an integer variable, or a call of a function that returns an
integer:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_int_expr</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>scope</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
    <span>// We will dynamically build up all of the valid</span>
    <span>// options of what we can generate.</span>
    <span>let</span> <span>mut</span> <span>options</span><span>:</span> <span>Vec</span><span>&lt;</span><span>fn</span> <span>(</span>
        <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
        <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
    <span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;&gt;</span> <span>=</span> <span>vec!</span><span>[];</span>

    <span>// It is always valid to generate a constant.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>_</span><span>|</span> <span>{</span>
        <span>Ok</span><span>(</span><span>Expr</span><span>::</span><span>Constant</span><span>(</span><span>u</span><span>.arbitrary</span><span>::</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>()</span><span>?</span><span>))</span>
    <span>});</span>

    <span>// It is always valid to generate an addition.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>scope</span><span>|</span> <span>{</span>
        <span>let</span> <span>lhs</span> <span>=</span> <span>arbitrary_int_expr</span><span>(</span><span>u</span><span>,</span> …</code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</a></em></p>]]>
            </description>
            <link>http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263117</guid>
            <pubDate>Mon, 24 Aug 2020 17:36:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talking Resilience with Roy Bahat of Bloomberg Beta]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24263090">thread link</a>) | @RoboCornell88
<br/>
August 24, 2020 | https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta | <a href="https://web.archive.org/web/*/https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><p>Our <strong>12 Questions</strong> series takes you into the minds of influential leaders to discuss today’s hot topics. Read their fresh views on leadership, managing through change, and the ins and outs of modern work. Think of it as your office hours with some of the most innovative people in business.</p><p>We continue this series on resilience with <a href="https://www.linkedin.com/in/roybahat/" rel="noopener" target="_self">Roy Bahat</a>. Roy is the head of Bloomberg Beta, a venture fund backed by Bloomberg L.P. that invests in companies that make business work better. Roy has been an entrepreneur (started a venture-backed video game console), a public company executive (at News Corporation), a board member for companies and nonprofits, and in government (in his hometown of New York). When he’s not teaching media at U.C. Berkeley’s Haas School of Business or investing in the future of work, he’s also not sharing advice on <a href="https://twitter.com/roybahat" rel="noopener" target="_self">Twitter</a>.</p><hr><p><strong>Thanks for joining us for 12 Questions, Roy. Can you describe your career in twelve words or less</strong></p><p>A determined random walk that only became clear in retrospect.<br></p><p><strong>That's very meta. Do you want to expand on that mental image?</strong></p><p>Sure. I was always jealous of the people who knew what they wanted to do. I had to work in a bunch of settings to figure out where my home was: from nonprofit, academia, and government to professional services, startups, and big corporations. And I think my "home" is in supporting people who are building new organizations. At the moment, that's venture-backed startups.<br></p><p><strong>Let's dive into a topic that is top of mind for most people, given the state of the world right now. What does resilience mean to you?</strong></p><p>I think we often treat resilience as an innate characteristic of people. But I believe that it's a skill that we use to recover from hardship through repeated attempts and self-management to keep ourselves going.<br></p><p><strong>So, how has your thinking about resilience changed in 2020?</strong></p><p>I've come to a realization this year that in the startup world, we love the myth of the heroic individual—and resilience is a part of that myth. It's something I've thought about a lot, but the current situation has confirmed it for me. While I believe in an individual creators' power, we often take the focus off the system that enables them to be resilient. And it takes the focus off the differences that make one person's resilience easier to practice than another.</p><p>There are many psychological reasons why that happens, including the fact that all successful people had to overcome some hardship. But that doesn't make their hardship equivalent to somebody else's. So in the aftermath of the protest surrounding George Floyd's murder and the changed circumstances with the pandemic, it reminded me that resilience is something that stems from having the opportunity to show you can be resilient.</p><p><strong>Resilience as a proxy for opportunity. Curious: when was the last time you checked-in with yourself?</strong></p><p>This morning. I try to have a scientist's attitude about it, which is to say hypotheses that you falsify.</p><p>If you're confident you're going in the right direction regardless of what the evidence says, you're probably not paying attention to the world. So I ask myself a lot, "how do I know if I'd be wrong?" And one of the places <a href="https://www.linkedin.com/in/roybahat/detail/recent-activity/posts/" rel="noopener" target="_self">I've written about that is on LinkedIn</a>. I try to write an <a href="https://also.roybahat.com/your-career-is-a-mess-a8a58acd18fa" rel="noopener" target="_self">honest accounting</a> of what I was thinking and what was right or wrong about different choices. Unless I can learn from them, I don't know where I'm going.</p><p><strong>Is there a time when you wish you were more resilient?</strong></p><p>It might just be because of this present moment, but I think I'm one of these people who tries to think of myself as a good person and do the right thing. And so I can be fragile when critiqued around bias, whether that's sexism or racism because it doesn't align with how I think about what I try to do. And so, I wish that I could've been more resilient in not dismissing that the first few times it came up in my life and try to learn from it.</p><p><strong>Related, what's one big mistake you made, and how did you bounce back from that?</strong></p><p>I should have proposed to my wife years before I did.</p><p>I used to think relationships should all be easy. I was mistaken. Any relationship worth having is one you should take seriously and keep working on it. I wrote a <a href="https://also.roybahat.com/what-our-kids-see-7dc650be8a90" rel="noopener" target="_self">blog post</a> a few years ago now about my son asking me to get off my phone. It stung. But my relationship with my son matters more to me than my ego, and when something I do hurts him, I want to pay attention and grow from it.<br></p><p><strong>In your view, how can people be more resilient in their work-life?</strong></p><p>We should think of resilience as a skill or a muscle. You see something you want to achieve and the obstacle to it and then get resourceful. I think the mistake is being in a situation where you weren't resilient, which leads to some inherent judgment about you as a person versus "you know I didn't hit that basket, I've got to try again."<br></p><p><strong>How does being vulnerable help in building a resilient team?</strong></p><p>The more I see the humanity in the people with whom I am working, the better I can work with them. I know where they're coming from, and I have empathy for them because of that. Somewhat connected to the hero myth—being resilient and being cold is not the same thing.</p><p><strong>Who is the most resilient person that you know, and why?</strong></p><p>Honestly, there are probably many I don't realize are resilient because they keep their struggles private. <a href="https://adeolonoh.com/page/2/" rel="noopener" target="_self">Ade Olonoh</a> wrote a recent <a href="https://www.formstack.com/blog/2020/why-we-should-talk-about-race-ade-olonoh/" rel="noopener" target="_self">piece about race issues</a> and how he struggled to talk about it. I've known the guy for years, and I didn't realize this was something he was going through. So, that makes me think about all the other people who are there who have a sort of silent resilience.</p><p>In terms of people I know, I'd say my wife. She had a much more difficult upbringing that I did economically, and the fact that she's the amazing person that she is, I think, is a sign of resilience. And my mom. My dad passed away when I was 12, and my mom persevered. My brother and I were never worried about things falling apart because she handled it. But again, are they the most resilient people I know? Maybe not. They're the people I know the most about their resilience.</p><p><strong>If you could give people one piece of advice about what's going on in the world right now, what would it be?</strong></p><p>Well, first, I have to say that I'm allergic to the idea of giving advice.</p><p>Someone once told me that all advice is autobiographical. Whether it's one person trying to get you to justify what they do to feel better about themselves or, worse, they're trying to live vicariously through you as an experiment for themselves. Either way, it's not in your interest. I do this <a href="https://twitter.com/search?q=%23thisisnotadvice&amp;src=typed_query&amp;f=live" rel="noopener" target="_self">daily series of tips about work on Twitter</a>, where I go deeper into this concept.</p><p>From my experience, I would say to look at what's happening in the world as a project. And not like a side project. You have to put it front and center for yourself and amp up your experimentation on what's working for you. If that means limiting the amount of news you consume to a few hours a day or eating healthier, taking a long bath, calling someone you love every day, fighting for social justice, etc. Treat yourself as the subject of your experiments. I made a list of 14 things that might work to help myself get through this time, and I think I had to do 12 of the 14 before I felt much better. And now I'm in a much clearer place, but it's still a work in progress.<br></p><p><strong>What are some books or resources you'd recommend on resilience, or that help with getting through tough times?</strong></p><p>Read more fiction. I think we tend to read these abstract advice books about grit and related topics, but for me, what keeps me going are the stories I experience in my own life and the stories I read. Of course, you should listen to the Brene Brown TED talk on vulnerability and shame—it's really good. But I would read stories written by authors who had to go through tough times to get to where they are.</p><p>The new one I've started is <a href="https://www.wsj.com/articles/nk-jemisin-city-became-book-coronavirus-11597764521" rel="noopener" target="_self">N. K. Jeminsin</a>, because I've never read any of her stuff before, and I've gotten a lot out of <a href="https://en.wikipedia.org/wiki/John_Irving" rel="noopener" target="_self">John Irving's books</a>—A Prayer for Owen Meany is one of my favorite novels. The sustenance for progress is examples, and we get those examples from a specific technology: stories.</p><p><a href="https://twitter.com/roybahat?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor" rel="noopener" target="_self"><img src="https://cdn.sanity.io/images/e422uarq/production/96577fbf0ed9b0619149cc5f5d8dc663554a299d-2316x2316.jpg?fm=jpg&amp;w=330&amp;dpr=2&amp;q=40" alt="Roy Bahat and family"></a></p><hr></div></div></section></div>]]>
            </description>
            <link>https://www.range.co/blog/talking-resilience-with-roy-bahat-of-bloomberg-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263090</guid>
            <pubDate>Mon, 24 Aug 2020 17:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24262336">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262336</guid>
            <pubDate>Mon, 24 Aug 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I helped fix Canadaʼs Covid Alert app]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24262236">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app | <a href="https://web.archive.org/web/*/https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="https://pm.gc.ca/en/news/news-releases/2020/07/31/new-mobile-app-help-notify-canadians-potential-covid-19-exposure-now">On July 31st</a>, Canada's <a href="https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covid-alert.html">COVID Alert</a> app was made available for general use, though it does not have support for actually <em>reporting</em> a diagnosis in most provinces, yet.</p>
<p>In Quebec, we can run the tracing part of the app, and if diagnosis codes become available here, the app can retroactively report contact. It uses the tracing mechanism that <a href="https://covid19.apple.com/contacttracing">Google and Apple created together</a>, and in my opinion—at least for now—Canadians should be running this thing to help us all deal with COVID-19. I won't run it forever, but for now, it seems to me that the benefits outweigh the "government can track me" fear (it's not actually tracking you; it doesn't even know who you are), and it's enabled on my phone.</p>
<p>But, before I decided to take this position and offer up my own movement data, I wanted to be sure the app is doing what it says it's doing—at least to the extent of my abilities to be duly diligent. (Note: it's not purely <em>movement</em> data that's shared—at least without more context—but it's actual physical interactions with other people whose phones are available within the radio range of Bluetooth LE.)</p>
<p>Before installing the app on my real daily-carry phone, I decided to put it on an old phone I still have, and to do some analysis on the most basic level of communication: who is it contacting?</p>
<p>In 2015, I gave a <a href="https://prezi.com/iqwzy66rn3uo/inspect-https-with-your-own-man-in-the-middle-non-attacks/">talk</a> at <a href="https://confoo.ca/en">ConFoo</a> entitled "<em>Inspect HTTP(S) with Your Own Man-in-the-Middle Non-Attacks</em>", and this is exactly what I wanted to do here. The tooling has improved in the past 5 years, and firing up <em>mitmproxy</em>, even without ever having used it on this relatively new laptop, was a one-liner, thanks to <a href="https://nixos.org/learn.html">Nix</a>:</p>
<pre><span>nix-shell -p mitmproxy --run mitmproxy</span>
</pre>

<p>This gave me a terminal-based UI and proxy server that I pointed my old phone at (via the Wifi Network settings, under HTTP proxy, pointed to my laptop's local IP address). I needed to have mitmproxy create a Certificate Authority that it could use to generate and sign "trusted" certificates, and then have my phone trust that authority, by visiting <code>http://mitm.it/</code> in mobile Safari, and doing the certificate acceptance dance (this is even more complicated on the latest versions of iOS). Worth noting also, is that certain endpoints such as the Apple App Store appear to use <a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">Certificate Pinning</a>, so you'll want to do things like install the COVID Alert app from the App Store before turning on the proxy.</p>
<p>Once I was all set up to intercept my own traffic, I visited some <code>https://</code> URLs and saw the request flows in mitmproxy.</p>
<p>I fired up the COVID Alert app again, and noticed something strange… something disturbing:</p>
<p><img src="https://files.scoat.es/covid-tracker-traffic.png" title="COVID Alert app traffic in mitmproxy" alt="shows that the app is accessing clients.google.com"></p>
<p>In addition to the expected traffic to <code>canada.ca</code> (I noticed it's using <code>.alpha.canada.ca</code>, but I suspect that's due to the often-reported unbearably-long bureaucratic hassle in getting a <code>.canada.ca</code> TLS certificate, but that's another story), my phone, when running COVID Alert, was contacting Google.</p>
<pre><span>HEAD https://clients4.google.com/generate_204</span>
</pre>

<p>A little web searching helped me discover that this is a commonly-used endpoint that helps developers determine if the device is behind a "captive portal" (an interaction that requires log-in or payment, or at least acceptance of terms before granting wider access to the Web). I decided that this was <em>probably</em> unintended by the developers of COVID Alert, but it still bothered me that an app, designed for <em>tracking interactions between people['s devices]</em>, that the <em>government</em> wants us to run is telling Google that I'm running it, and disclosing my IP address in doing so:</p>
<p><img src="https://files.scoat.es/covid-alert-google.png" title="A request to clients.google.com, from the COVID Alert app" alt="shows that the User Agent header identifies the app as " covid="" alert="" version=""></p>
<p>(Note that the app clearly identifies itself in the <code>User-Agent</code> header.) </p>
<p>A bit more quick research turned up a <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/pipeda-compliance-help/pipeda-interpretation-bulletins/interpretations_02/#fn50-rf">statement by Canada's Privacy Commissioner</a>:</p>
<blockquote><p>An Internet Protocol (IP) address can be considered personal information if it can be associated with an identifiable individual. For example, in one complaint finding, we determined that some of the IP addresses that an internet service provider (ISP) was collecting were personal information because the ISP had the ability to link the IP addresses to its customers through their subscriber IDs.</p></blockquote>

<p>It's not too difficult to imagine that Google <em>probably</em> has enough data on Canadians for this to be a real problem.</p>
<p>I discovered that this app is maintained by the <a href="https://digital.canada.ca/">Canadian Digital Service</a>, and that the <a href="https://github.com/cds-snc/covid-alert-app">source code is on GitHub</a>, but that the <a href="https://github.com/cds-snc/covid-alert-app/search?q=clients3.google.com&amp;unscoped_q=clients3.google.com&amp;type=Code">code itself didn't directly contain any references to <code>clients3.google.com</code></a>.</p>
<p>It's a <a href="https://reactnative.dev/">React Native</a> app, and I figured that the call out to Google must be in one of the <a href="https://github.com/cds-snc/covid-alert-app/blob/master/package.json">dependencies</a>, which—considering the norm with JavaScript apps—are pleasantly restrained mostly to React itself. I had no idea which of these libraries was calling out to Google.</p>
<p>Now, I could have run this app on the iOS Simulator (which did I end up doing to test my patches, below), but I thought "let's see what my <em>actual</em> phone is doing." I threw caution to the wind, and I ran <a href="https://checkra.in/">checkra1n</a> on my <em>old</em> phone, which gave me ssh access, which in turn allowed me to copy the app's application bundle to my laptop, where I could do a little more analysis (note the app is bundled as <em>CovidShield</em> because it was previously <a href="https://www.covidshield.app/">developed by volunteers at Shopify</a> and was then renamed by CDS (or so I gather, anyway)).</p>
<pre><span>~/De/C/iphone/CovidShield.app ▶ grep -r 'clients3.google.com' *</span>
<span>main.jsbundle:__d(function(g,r,i,a,m,e,d){Object.defineProperty(e,"__esModule",{value:!0}),</span>
<span>e.default=void 0;var t={reachabilityUrl:'https://clients3.google.com/generate_204',</span>
<span>reachabilityTest:function(t){return Promise.resolve(204===t.status)},reachabilityShortTimeout:5e3,</span>
<span>reachabilityLongTimeout:6e4,reachabilityRequestTimeout:15e3};e.default=t},708,[]);</span>
</pre>

<p>(Line breaks added for legibility.) Note <code>reachabilityUrl:'https://clients3.google.com/generate_204</code>. Found it! A bit more searching led me to a package called <code>react-native-netinfo</code> (which was directly in the above-linked <code>package.json</code>), and its <a href="https://github.com/react-native-community/react-native-netinfo/blob/4e3e9813fbae89013bbeee6470b005b6d923e022/src/internal/defaultConfiguration.ts#L2">default configuration</a> that sets the <code>reachabilityUrl</code> to Google.</p>
<p>Now that I knew where it was happening, I could fix it.</p>
<p>To make this work the same way, we needed a reliable <code>204</code> endpoint that the app could hit, and to keep with the expectation that this app should not "leak" data outside of <code>canada.ca</code>, I ended up <a href="https://github.com/cds-snc/covid-alert-server/pull/241">submitting a patch</a> for the <a href="https://github.com/cds-snc/covid-alert-server">server side code</a> that the app calls. (It turns out that this was not necessary after all, but I'm still glad I added this to my report.)</p>
<p>I also <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">patched</a>, and tested the app code itself via the iOS Simulator.</p>
<p>I then submitted a write-up of what was going wrong and why it's bad, to the main app repository, as <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">cds-snc/covid-alert-app issue 1003</a>, and felt pretty good about my COVID Civic Duty of the day.</p>
<p>The fine folks at the Canadian Digital Service seemed to recognize the problem and agree that it was something that needed to be addressed. A few very professional back-and-forths later (I'll be honest: I barely knew anything about the CDS and I expected some runaround from a government agency like this, and I was pleasantly surprised), we landed on a solution that simply didn't call the reachability URL at all, and they <a href="https://github.com/cds-snc/covid-alert-app/releases">released a version of the app</a> that fixed my issue!</p>
<p><img src="https://files.scoat.es/covid-alert-release.jpg" title="COVID Alert release notes showing my fix" alt=""></p>
<p>With the new version loaded, I once again checked the traffic and can confirm that the new version of the app does not reach out to anywhere but <code>.canada.ca</code>.</p>
<p><img src="https://files.scoat.es/covid-alert-no-google.png" alt="A mitmproxy flow showing traffic to canada.ca and not google.com"></p>
</div>
    </div></div>]]>
            </description>
            <link>https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262236</guid>
            <pubDate>Mon, 24 Aug 2020 16:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is max MySQL transactions per second = max fsyncs per second?]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24262057">thread link</a>) | @Sirupsen
<br/>
August 24, 2020 | https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/ | <a href="https://web.archive.org/web/*/https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="article-content">
    

    <p>Napkin friends, from near and far, it’s time for another napkin problem!</p>
<p>Since the beginning of this newsletter I’ve posed problems for you to try to
answer. Then in the next month’s edition, you hear my answer. Talking with a few
of you, it seems many of you read these as posts regardless of their
problem-answer format.</p>
<p>That’s why I’ve decided to experiment with a simpler format: posts where I both
present a problem and solution in one go. This one will be long, since it’ll
include an answer to last month’s.</p>
<p>Hope you enjoy this format! As always, you are encouraged to reach out with
feedback.</p>
<h2 id="problem-10-is-mysqls-maximum-transactions-per-second-equivalent-to-fsyncs-per-second">Problem 10: Is MySQL’s maximum transactions per second equivalent to fsyncs per second?</h2>
<p>How many transactions (‘writes’) per second is MySQL capable of?</p>
<p>A naive model of how a write (a SQL insert/update/delete) to an ACID-compliant
database like MySQL works might be the following (this applies equally to
Postgres, or any other relational/ACID-compliant databases, but we’ll
proceed to work with MySQL as it’s the one I know best):</p>
<ol>
<li>Client sends query to MySQL over an existing connection: <code>INSERT INTO products (name, price) VALUES ('Sneaker', 100)</code></li>
<li>MySQL inserts the new record to the write-ahead-log (WAL) and calls
<code>fsync(2)</code> to tell the operating system to tell the filesystem to tell the
disk to make <em>sure</em> that this data is <em>for sure</em>, pinky-swear committed to
the disk. This step, being the most complex, is depicted below.</li>
<li>MySQL inserts the record into an in-memory page in the backing storage engine
(InnoDB) so the record will be visible to subsequent queries. Why commit to
the storage engine <em>and</em> the WAL? The storage engine is optimized for serving
query results the data, and the WAL for writing it in a safe manner – we
can’t serve a <code>SELECT</code> efficiently from the WAL!</li>
<li>MySQL returns <code>OK</code> to the client.</li>
<li>MySQL eventually calls <code>fsync(2)</code> to ensure InnoDB commits the page to disk.</li>
</ol>
<p><img src="https://user-images.githubusercontent.com/97400/87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png" alt="Napkin_10"></p>
<p>In the event of power-loss at any of these points, the behaviour can be defined
without nasty surprises, upholding our dear ACID-compliance.</p>
<p>Splendid! Now that we’ve constructed a naive model of how a relational database
might handle writes safely, we can consider the latency of inserting a new
record into the database. When we consult <a href="https://github.com/sirupsen/napkin-math">the reference napkin numbers</a>, we
see that the <code>fsync(2)</code> in step (2) is by <em>far</em> the slowest operation in the
blocking chain at 1 ms.</p>
<p>For example, the network handling at step (1) takes roughly ~10 μs (TCP Echo
Server is what we can classify as ‘the TCP overhead’). The <code>write(2)</code> itself
prior to the <code>fsync(2)</code> is also negligible at ~10 μs, since this system call
essentially just writes to an in-memory buffer (the ‘page cache’) in the kernel.
This doesn’t guarantee the actual bits are committed on disk, which means an
unexpected loss of power would erase the data, dropping our ACID-compliance on
the floor. Calling <code>fsync(2)</code> guarantees us the bits are persisted on the disk,
which will survive an unexpected system shutdown.  Downside is that it’s 100x
slower.</p>
<p>With that, we should be able to form a simple hypothesis on the maximum
throughput of MySQL:</p>
<blockquote>
<p>The maximum theoretical throughput of MySQL is equivalent to the maximum
number of <code>fsync(2)</code> per second.</p>
</blockquote>
<p>We know that <code>fsync(2)</code> takes 1 ms from earlier, which means we would naively
expect that MySQL would be able to perform in the neighbourhood of: <code>1s / 1ms/fsync = 1000 fsyncs/s = 1000 transactions/s</code> .</p>
<p>Excellent. We followed the first three of the napkin math steps: (1) Model the
system, (2) Identify the relevant latencies, (3) Do the napkin math, (4) Verify
the napkin calculations against reality.</p>
<p>On to (4: Verifying)! We’ll write a simple benchmark in Rust that writes to
MySQL with 16 threads, doing 1,000 insertions each:</p>
<div><pre><code data-lang="rust"><span>for</span><span> </span>i<span> </span><span>in</span><span> </span><span>0</span>..<span>16</span><span> </span>{<span>
</span><span>    </span>handles.push(thread::spawn({<span>
</span><span>        </span><span>let</span><span> </span>pool<span> </span><span>=</span><span> </span>pool.clone();<span>
</span><span>        </span><span>move</span><span> </span><span>||</span><span> </span>{<span>
</span><span>            </span><span>let</span><span> </span><span>mut</span><span> </span>conn<span> </span><span>=</span><span> </span>pool.get_conn().unwrap();<span>
</span><span>            </span><span>// TODO: we should ideally be popping these off a queue in case of a stall
</span><span></span><span>            </span><span>// in a thread, but this is likely good enough.
</span><span></span><span>            </span><span>for</span><span> </span>_<span> </span><span>in</span><span> </span><span>0</span>..<span>1000</span><span> </span>{<span>
</span><span>                </span>conn.exec_drop(<span>
</span><span>                    </span><span>r"INSERT INTO products (shop_id, title) VALUES (:shop_id, :title)"</span>,<span>
</span><span>                    </span>params<span>!</span><span> </span>{<span> </span><span>"shop_id"</span><span> </span><span>=&gt;</span><span> </span><span>123</span>,<span> </span><span>"title"</span><span> </span><span>=&gt;</span><span> </span><span>"aerodynamic chair"</span><span> </span>},<span>
</span><span>                </span>)<span>
</span><span>                </span>.unwrap();<span>
</span><span>            </span>}<span>
</span><span>        </span>}<span>
</span><span>    </span>}));<span>
</span><span>
</span><span>    </span><span>for</span><span> </span>handle<span> </span><span>in</span><span> </span>handles<span> </span>{<span>
</span><span>      </span>handle.join().unwrap();<span>
</span><span>    </span>}<span>
</span><span>    </span><span>// 3 seconds, 16,000 insertions
</span><span></span>}<span>
</span></code></pre></div><p>This takes ~3 seconds to perform 16,000 insertions, or ~5,300 insertions per
second. This is <strong>5x</strong> more than the 1,000 <code>fsync</code> per second our napkin math
told us would be the theoretical maximum transactional throughput!</p>
<p>Typically with napkin math we aim for being within an order of magnitude, which
we are. But, when I do napkin math it usually establishes a lower-bound for the
system, i.e. from first-principles, how fast <em>could</em> this system perform in
ideal circumstances?</p>
<p>Rarely is the system 5x faster than napkin math. When we identify a
significant-ish gap between the real-life performance and the expected
performance, I call it the “first-principle gap.” This is where curiosity sets
in. It typically means there’s (1) an opportunity to improve the system, or (2)
a flaw in our model of the system. In this case, only (2) makes sense, because
the system is faster than we predicted.</p>
<p>What’s wrong with our model of how the system works? Why aren’t fsyncs per
second equal to transactions per second?</p>
<p>First I examined the benchmark… is something wrong? Nope <code>SELECT COUNT(*) FROM products</code> says 16,000. Is the MySQL I’m using configured to not <code>fsync</code> on every
write? Nope, it’s at the <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit">safe default</a>.</p>
<p>Then I sat down and thought about it. Perhaps MySQL is <em>not</em> doing an <code>fsync</code>
for every <em>single</em> write? If it’s processing 5,300 insertions per second,
perhaps it’s batching multiple writes together as part of writing to the WAL,
step (2) above? Since each transaction is so short, MySQL would benefit from
waiting a few microseconds to see if other transactions want to ride along
before calling the expensive <code>fsync(2)</code>.</p>
<p>We can test this hypothesis by writing a simple <code>bpftrace</code> script to observe the
number of <code>fsync(1)</code> for the ~16,000 insertions:</p>
<div><pre><code data-lang="d"><span>tracepoint:</span>syscalls<span>:</span>sys_enter_fsync<span>,</span>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fdatasync
<span>/</span>comm <span>==</span> <span>"mysqld"</span><span>/</span>
<span>{</span>
        <span>@fsyncs</span> <span>=</span> count<span>();</span>
<span>}</span>
</code></pre></div><p>Running this during the ~3 seconds it takes to insert the 16,000 records we get
~8,000 <code>fsync</code> calls:</p>
<div><pre><code data-lang="bash">$ sudo bpftrace fsync_count.d
Attaching <span>2</span> probes...
^C

@fsyncs: <span>8037</span>
</code></pre></div><p>This is a peculiar number. If MySQL was batching fsyncs, we’d expect something
far lower. This number means that we’re on average doing ~2,500 <code>fsync</code> per
second, at a latency of ~0.4ms. This is twice as fast as the <code>fsync</code> latency we
expect, the 1ms mentioned earlier. For sanity, I ran the script to benchmark
<code>fsync</code> outside MySQL again, no, <a href="https://github.com/sirupsen/napkin-math/blob/fe780331c6f0c6f225a70c8a37c21e0740f7c73c/src/main.rs#L491">still 1ms</a>. <a href="https://gist.github.com/sirupsen/9fd5fe9466e82df073ed8a13ed1f661f#file-napkin-bash">Looked at the
distribution</a>, and it was consistently ~1ms.</p>
<p>So there’s two things we can draw from this: (1) We’re able to <code>fsync</code> more than
twice as fast as we expect, (2) Our hypothesis was correct that MySQL is more
clever than doing one <code>fsync</code> per transaction, however, since <code>fsync</code> also was
faster than expected, this didn’t explain everything.</p>
<p>If you remember from above, while committing the transaction could theoretically
be a single <code>fsync</code>, other features of MySQL might also call <code>fsync</code>. Perhaps
they’re adding noise?</p>
<p>We need to group <code>fsync</code> by file descriptor to get a better idea of how MySQL
uses <code>fsync</code>. However, the raw file descriptor number doesn’t tell us much. We
can use <code>readlink</code> and the <code>proc</code> file-system to obtain the file name the file
descriptor points to. Let’s write a <a href="https://github.com/iovisor/bpftrace"><code>bpftrace</code> script</a> to see what’s being
<code>fsync</code>'ed:</p>
<div><pre><code data-lang="d"><span>tracepoint:</span>syscalls<span>:</span>sys_enter_fsync<span>,</span>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fdatasync
<span>/</span>comm <span>==</span> str<span>(</span>$1<span>)/</span>
<span>{</span>
        <span>@fsyncs</span><span>[</span>args<span>-&gt;</span>fd<span>]</span> <span>=</span> count<span>();</span>
        <span>if</span> <span>(</span><span>@fd_to_filename</span><span>[</span>args<span>-&gt;</span>fd<span>])</span> <span>{</span>
        <span>}</span> <span>else</span> <span>{</span>
                <span>@fd_to_filename</span><span>[</span>args<span>-&gt;</span>fd<span>]</span> <span>=</span> <span>1</span><span>;</span>
                system<span>(</span><span>"echo -n 'fd %d -&gt; ' &amp;1&gt;&amp;2 | readlink /proc/%d/fd/%d"</span><span>,</span> args<span>-&gt;</span>fd<span>,</span> pid<span>,</span> args<span>-&gt;</span>fd<span>);</span>
        <span>}</span>
<span>}</span>

END <span>{</span>
        clear<span>(</span><span>@fd_to_filename</span><span>);</span>
<span>}</span>
</code></pre></div><p>Running this while inserting the 16,000 transactions into MySQL gives us:</p>
<div><pre><code data-lang="bash">personal@napkin:~$ sudo bpftrace --unsafe fsync_count_by_fd.d mysqld
Attaching <span>5</span> probes...
fd <span>5</span> -&gt; /var/lib/mysql/ib_logfile0 <span># redo log, or write-ahead-log</span>
fd <span>9</span> -&gt; /var/lib/mysql/ibdata1 <span># shared mysql tablespace</span>
fd <span>11</span> -&gt; /var/lib/mysql/#ib_16384_0.dblwr <span># innodb doublewrite-buffer</span>
fd <span>13</span> -&gt; /var/lib/mysql/undo_001 <span># undo log, to rollback transactions</span>
fd <span>15</span> -&gt; /var/lib/mysql/undo_002 <span># undo log, to rollback transactions</span>
fd <span>27</span> -&gt; /var/lib/mysql/mysql.ibd <span># tablespace</span> 
fd <span>34</span> -&gt; /var/lib/mysql/napkin/products.ibd <span># innodb storage for our products table</span>
fd <span>99</span> -&gt; /var/lib/mysql/binlog.000019 <span># binlog for replication</span>
^C

@fsyncs<span>[</span>9<span>]</span>: <span>2</span>
@fsyncs<span>[</span>12<span>]</span>: <span>2</span>
@fsyncs<span>[</span>27<span>]</span>: <span>12</span>
@fsyncs<span>[</span>34<span>]</span>: <span>47</span>
@fsyncs<span>[</span>13<span>]</span>: <span>86</span>
@fsyncs<span>[</span>15<span>]</span>: <span>93</span>
@fsyncs<span>[</span>11<span>]</span>: <span>103</span>
@fsyncs<span>[</span>99<span>]</span>: <span>2962</span>
@fsyncs<span>[</span>5<span>]</span>: <span>4887</span>
</code></pre></div><p>What we can observe here is that the majority of the writes are to the “redo
log”, what we call the “write-ahead-log” (WAL). There’s a few <code>fsync</code> calls to
commit the InnoDB table-space, not nearly as often, as we can always recover
this from the WAL in case we crash between them. Reads work just fine prior to
the <code>fsync</code>, as the queries can simply be served out of memory from InnoDB.</p>
<p>The only surprising thing here is the substantial volume of writes to the
binlog, which we haven’t mentioned before. You can think of the binlog as the
“replication stream.” It’s a stream of events such as <code>row a changed from x to y</code>, <code>row b was deleted</code>, and <code>table u added column c</code>. The primary replica
streams this to the read-replicas, which use it to update their own data.</p>
<p>When you think about it, the <code>binlog</code> and the WAL need to be kept exactly in
sync. We can’t have something committed on the primary replica, but not
committed to the replicas. If they’re not in sync, this could cause loss of data
due to drift in the read-replicas. The primary could commit a change to the WAL,
lose power, recover, and never write it to the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/">https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/</a></em></p>]]>
            </description>
            <link>https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262057</guid>
            <pubDate>Mon, 24 Aug 2020 16:12:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 2: Shannon's story]]>
            </title>
            <description>
<![CDATA[
Score 384 | Comments 271 (<a href="https://news.ycombinator.com/item?id=24261948">thread link</a>) | @usefulcat
<br/>
August 24, 2020 | https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-clbfl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_900,h_450,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-7adfi">How much Vitamin D should I take? This is still the looming question, and it’s time to address it. </h3><p id="viewer-9k73p">First, though, imagine that someone in a public forum online asked me, “How much metoprolol (a common blood pressure medication) should I take?” It would be clear that I could not give a real answer. I could give a heavily qualified blanket statement that covered indications and common starting doses, and then recommended speaking with a doctor regarding a personalized dosage. I wouldn’t give a specific dose. But no one would expect me to.  Metoprolol is a medication, and medications are usually prescribed by a physician.</p><p id="viewer-7tpp4">We think of vitamins and supplements differently. A few readers have made comments like this: “I understand that the evidence for Vitamin D in healthy adults doesn’t really show a benefit, but I take Vitamin D because it probably won’t hurt me, and it might help.” This is a common sentiment regarding supplements, but not a statement that most people would make about metoprolol, or any prescribed medication.  Medications are generally understood to be substances taken in response to a specific disease or condition, and we hope that research has shown that they work. Supplements are given a pass; we take them if they might help, even though they may not be needed. </p><p id="viewer-2fbtq"><strong>But Vitamin D should be thought of as a medication</strong>, despite being sold over-the-counter in the supplements aisle. </p><p id="viewer-5549c">To illustrate this, let me introduce Shannon. </p><p id="viewer-518ch">In the fall of 2018, Shannon R. was the special education director for a large Arizona school district. Normally energetic and expressive, the otherwise healthy 38-year-old began having an odd and disturbing symptom: difficulty speaking. Her husband and two boys would ask her questions, and though understanding the question, she was unable to formulate the words to respond. </p><p id="viewer-e7f4v">Milder problems had started over the summer, when she felt more tired than usual. As the months passed, new symptoms appeared: palpitations, insomnia, anxiety, along with cognitive deficits – “like my brain wouldn’t function,” she recalled. Her heart rate, normally in the 60s, now often stayed in the 90s, even while in bed. She barely slept at night and lost nearly 50 pounds. By mid-semester, she was often unable to work. At around 1 AM one October morning, she was taken to the emergency room for a racing heart. When there, she had difficulty responding to the doctors’ and nurses’ questions. After a full workup, the doctors had no explanation, so they resorted to what doctors often reach for when confronted with mystery ailments: psychiatric illness. </p><p id="viewer-fu7id">Shannon would be hospitalized several times for “catatonia,” a general symptom describing difficulty with speaking or moving that is caused by certain psychiatric conditions like depression and schizophrenia. Though she had never exhibited mental illness before, doctors assumed that Shannon had developed a severe psychiatric disorder. </p><p id="viewer-4pb27">Shannon’s husband, as well as her new psychiatrist, doubted this diagnosis, and sought second and third opinions. By the time she contacted me four months later, they had consulted multiple specialists at three different hospitals around the state, but still did not have an explanation for her physical and mental decline. There was something that all of the doctors had noticed, though. Her blood calcium levels were often mildly to moderately elevated above normal, up to 11.1 mg/dl (normal for her age would be up to 10.2 mg/dl). The cause of this was unclear, but her doctors did not believe that this incidental finding was relevant to her current issues, and did not pursue it. <strong>Shannon was not taking calcium supplements at all throughout this time, but her levels were still high.</strong> When she emailed me in February 2019, she was desperate for answers and thought the calcium levels might be a clue. </p><p id="viewer-1miap">My specialty is parathyroid disease, which is the most common cause of high calcium. Based on her parathyroid hormone tests, it did not appear that Shannon had parathyroid disease. But she had high calcium levels, and the rise in those levels correlated with the onset of her symptoms. High calcium levels might initially appear to be a good thing, since we need calcium for our bones. But they are not. High blood calcium levels usually indicate a serious illness.</p><div id="viewer-ep36c"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_900,h_434,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-5d4om"><em>Calcium is known for its role in bone health, but its role in the brain and nervous system is just as important. Calcium levels need to be within a small range; anything too high or too low can cause problems.  Image by </em><a href="https://www.bigstockphoto.com/search/?contributor=madrock24" target="_blank" rel="noopener">madrock24</a> on <a href="http://bigstockphoto.com/" target="_blank" rel="noopener"><u>bigstockphoto.com</u></a></p><p id="viewer-115r5">Most patients with high calcium develop fatigue and body aches, and just generally feel bad. They may develop insomnia and palpitations, a feeling like the heart is racing. Some have more severe neurologic symptoms like muscle weakness and problems with balance, and some have psychiatric symptoms like depression and anxiety. Untreated high calcium can also lead to kidney stones, kidney failure, cardiac arrhythmias, headaches, and gastrointestinal problems. Shannon had some of the classic symptoms, as well as what appeared to be more severe “psychiatric” symptoms. I suspected they were all related to her calcium levels. </p><p id="viewer-bac7q">But why was her calcium high? The parathyroid glands exist to regulate calcium, and they do a very good job at it, keeping blood calcium within a tight range. Usually, a problem with calcium indicates a problem with the parathyroids. But over the last few years I have had more patients coming to me with high calcium related to something else: Vitamin D. </p><p id="viewer-6d1js"><strong>Vitamin D is a steroid hormone</strong>, in the same category as sex hormones like estrogen and testosterone, and glucocorticoids like the stress hormone cortisol. Steroid hormones are all made from cholesterol, and looking at their molecular structures, you can see the similarities. </p><div id="viewer-6s0p9"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_1586,h_972,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-3upia">Like the other steroid hormones, Vitamin D acts on multiple organs and only tiny amounts of the molecule are required to have substantial effects. Anyone who has gone through puberty understands the impressive physiologic changes brought about by relatively small shifts in hormone levels. Not surprisingly, most steroid hormones are considered medications that require a physician's order. Vitamin D is an exception. In the U.S., high dose Vitamin D can be purchased by anyone, without a prescription, in most drugstores and grocery stores. It is called a dietary supplement, which sounds safer than a medication, but this is misleading. Due to its role in calcium absorption, high dose Vitamin D can cause serious problems. </p><p id="viewer-21t00">Eventually we worked out what happened with Shannon: In 2013 she was diagnosed with mild osteopenia, a thinning of the bones that can be a precursor to osteoporosis. Her Vitamin D was low at the time, so her physician started her on over-the-counter Vitamin D supplementation at 5000 international units (IUs) daily. Five years later, she was still on this dose, and her blood Vitamin D level had risen to 79 ng/ml. This level is within what many labs call the normal range, between 30 and 100 ng/ml, but levels above 70 are almost always a result of high dose supplementation, and I have seen toxicity with levels between 70 and 100 ng/ml. (A better “normal range” based on what I have seen would probably be between 30 and 60.) Vitamin D builds up over time, so the longer someone is on a high dose, the more likely she is to develop toxicity. Shannon’s calcium levels began rising in the fall of 2018, when her severe symptoms developed. </p><p id="viewer-c0tav">Ironically, Shannon started to recover because she became too sick to worry about taking her vitamins, and stopped taking Vitamin D in October. It often takes many months for high Vitamin D levels to drop, and it took six months for Shannon’s level to fall into the 50s. As it fell, her calcium level gradually started to normalize, and her symptoms slowly resolved. By May, she was starting to feel like herself again. </p><p id="viewer-208hf">I spoke with Shannon recently. All of the symptoms that characterized her frightening and rapid decline in health had resolved completely. Listening to this animated woman, it was difficult to imagine her unable to talk. The only lingering effects appeared to be a wariness of physicians and distrust of vitamins, both understandable. Shannon agrees that Vitamin D should be treated like a medication. “It’s a hormone!” she exclaimed. “If I had to take ‘Hormone D’, I would have questioned my doctor about why I needed it.” Shannon is now committed to educating others about Vitamin D. </p><p id="viewer-16oc8">Of course, there is a selection bias in who comes to me. There are people out there doing just fine on 5000 units of Vitamin D daily. I only see the ones who develop high calcium levels. But I see enough of them to know that this is not an exceptionally rare occurrence. I have been to lectures in which physicians have claimed that Vitamin D toxicity almost never occurs. In my experience, this is false. I have seen many cases of Vitamin D toxicity in people who were taking the recommended dose from an over-the-counter bottle.</p><p id="viewer-8pgar">Unfortunately, none of those patients were warned about the potential for Vitamin D to cause high calcium. They all believed that they were taking a supplement to improve health and that there was very little risk. Supplements don’t require prescriptions, and most do not have the warning labels that accompany medications. For Vitamin D, a steroid hormone, that may need to change. </p><p id="viewer-4ie1g"><strong>So, how much Vitamin D should you take? </strong></p><p id="viewer-9iecb">Vitamin D should be approached like a medication that is used to treat low calcium levels and low levels of the hormone called Vitamin D. The dose depends on your calcium and current Vitamin D levels, and needs to be adjusted appropriately in response to those levels. For my patients, I can and do give very specific recommendations on Vitamin D doses. In future posts, I can go through how I decide that. I will not give any recommendation without first knowing Vitamin D and calcium levels. </p><p id="viewer-ecd8g"><strong>Edited to add: This post should not be taken as a …</strong></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261948</guid>
            <pubDate>Mon, 24 Aug 2020 16:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Mechanist's Guide to the Coronavirus Genome]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261853">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome | <a href="https://web.archive.org/web/*/https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to my Coronavirus Genome Walkthrough.</p>

<p>(Hoping someone comes out with that Vaccine Speedrun soon. This boss battle is really shaping up to be an intense one and we’ll need all the artifacts we can get.)</p>

<p>Here, I aim to provide a <em>mechanistic explanation</em> of the SARS-CoV-2 genome’s syntax and semantics. Let’s investigate what the SARS-CoV-2 viral genome actually does as if reading through code like a compiler, from nucleotides to amino acids all the way to proteins. From the four base pairs all the way up to the completed protein-coated virus, what is a virus like this is actually made of on the concrete, physical level?</p>

<h3 id="understanding-a-full-system">Understanding a Full System</h3>

<p>The underlying purpose of this essay is less about the coronavirus <em>per se</em> and more about how having a small—but functionally complete—piece of viral RNA to analyze gives me a unique opportunity to try to understand a complete self-replicating machine from scratch. This is not a feat that I would have the fortitude to manually replicate with the full human genome, for example—but the coronavirus genome, like the <a href="http://openworm.org/">nematode genome</a>, is small enough that we stand a chance at building a complete understanding. The task is perhaps akin to <a href="https://distill.pub/2018/building-blocks/">interpretability</a>, but for biological systems instead of artificial neural networks.</p>

<p>As a consequence, this essay is not intended to produce epidemiological conclusions; there are plenty of other sources for that! This essay is about fully understanding a biological system at the chemical and physical level.</p>

<h3 id="play-curiosity-and-mechanical-understanding">Play, Curiosity, and Mechanical Understanding</h3>

<p>Throughout this essay, I follow my curiosity in the style of <a href="https://en.wikipedia.org/wiki/Serious_play">serious play</a>: if I <a href="https://www.readthesequences.com/Noticing-Confusion-Sequence">notice I’m confused</a> about something, I look into it and explore it until I’m satisfied that I now understand, and that my understanding is <em>a <a href="https://plato.stanford.edu/entries/science-mechanisms/#ConMec">mechanical</a> understanding</em>. Things are made of stuff! It turns out that we can understand that stuff!</p>

<p>I may skip over some details that were not confusing to me during my own research, but your journey need not be the same as mine. If you’re confused about something while reading this essay, I encourage you to go and look it up! <a href="http://agentyduck.blogspot.com/2015/06/the-art-of-noticing.html">Notice</a> when your curiosity arises; that’s the meditation. It’s always possible to discover the <a href="http://samoburja.com/how-to-find-the-frontier-of-knowledge/">frontier of your own knowledge</a> and to expand it.</p>

<p>This all, at least, has been my intention as I set out to create this piece! As Ken Liu said of his philosophy while translating The Three-Body Problem, “I may not have succeeded, but these were the standards I had in mind as I set about my task.”</p>

<p>Part 1, here, covers just the genome and its translation to proteins. I hope to also write a Part 2 which would cover the structure and function of those proteins, their protein-protein interactions, and the full viral life cycle.</p>

<!--Finally, as you may already be able to tell, this essay also serves as a philosophical manifesto-by-example of how to think concretely about problems in biology. Along the way, I give some of my thoughts about the role of thermodynamics in molecular biology, legibility in complex systems, pedagogy, and the future of computational modeling.-->

<p>Let’s get started.</p>



<p>As a reminder, SARS-CoV-2 is a <em>positive-sense single-stranded RNA virus</em>.</p>



<p>What does this mean we can expect?</p>

<ol>
  <li><em>Single-stranded</em>: Its genome is a single strand of <a href="https://en.wikipedia.org/wiki/RNA">RNA</a> (ssRNA).</li>
  <li><em>Positive-sense</em>: That single strand of RNA can be immediately translated into protein by the ribosomes of the cell it infects.</li>
</ol>

<p>From this we can also infer that one of the proteins the virus encodes for must be <em>RNA-dependent RNA polymerase</em> (RdRP), a protein which synthesizes new RNA given an RNA template. That’s right: RNA → RNA. However, according to the <a href="https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology">central dogma of molecular biology</a>, isn’t RNA → RNA an unconscionable heresy? Correspondingly, RdRP is not naturally found in cells! All known positive-sense ssRNA viruses therefore <em>must encode</em> RdRP in order to successfully commit this heresy.</p>



<p>…Wait a minute, the phrase “positive-sense ssRNA virus” implies the existence of <em>negative-sense</em> viruses. If those don’t encode their proteins directly, how can they possibly work?</p>

<h2 id="positive-sense-and-negative-sense">Positive sense and negative sense</h2>

<p>Negative-sense ssRNA viruses also exist! Influenza, Ebola, and measles are examples.</p>



<p>The inner contents of <em>negative-sense</em> ssRNA viruses consist not of an RNA genome but of a <em>ribonucleoprotein</em>, which incorporates both an RNA genome as well as a cohort of viral proteins capable of replicating RNA. Unlike positive-sense ssRNA viruses, negative-sense ssRNA viruses must travel with a working copy of their RNA-replicating proteins. This ribonucleoprotein has enzymatic activity!</p>

<h2 id="rdrp-as-drug-target">RdRP as drug target</h2>

<p>Since RdRP has (as far as I know) no legitimate purpose in human cells and is not naturally coded by them, might it offer a potential target for novel antiviral drugs?</p>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">Velkov et al. 2014</a> explores RdRP as a drug target for antivirals against the <a href="https://en.wikipedia.org/wiki/Henipavirus">Hendra virus</a>, a negative-sense ssRNA virus, though I am unable to find the full text.</p>

<!-- <div class="unfurl-embed-info-media-default gallery-item-selectable"><img class="unfurl-embed-card-feature-image" src="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image.png"><div class="unfurl-embed-card-title unfurl-embed-card-title-default notranslate"><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">The RNA-dependent-RNA Polymerase, an Emerging Antiviral Drug Target for the Hendra Virus - PubMed</a></div><div class="unfurl-embed-card-description unfurl-embed-card-description-default notranslate"><div style="overflow: hidden; text-overflow: ellipsis; -webkit-box-orient: vertical; display: -webkit-box; -webkit-line-clamp: 2;">Australia is facing a major national medical challenge with the emergence of the Hendra virus (HeV) as a medically and economically important pathogen of humans and animals. Clinical symptoms of human HeV infection can include fever, hypotension, dizziness, encephalitis, respiratory haemorrhage and …</div></div><div class="unfurl-embed-card-url notranslate">pubmed.ncbi.nlm.nih.gov</div></div> -->

<blockquote>
  <p>This review examines the current knowledge based on the multi-domain architecture of the Hendra RdRP and highlights which essential domain functions represent tangible targets for drug development against this deadly disease.</p>
</blockquote>

<p>There must be some reason that developing antivirals against this protein is technically (or socially) complicated, or I’d have expected us to do it by now – there are a lot of RNA viruses that this drug target could theoretically hit. Flagging this discrepancy for further research.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">1</a></sup></p>



<p>Back to SARS-CoV-2! First, let’s get us a genome. Obviously this virus has seen some mutations as it’s spread around, as you can explore at <a href="https://nextstrain.org/ncov/global">NextStrain</a>, so we’ve technically got choices as to which one to analyze. For this thread I’ll just stick to analyzing <em>one</em> version of the genome: Wuhan-Hu-1.</p>

<p>As a reminder, each <code>A</code>, <code>G</code>, <code>C</code>, and <code>T</code> in a genome is one of the four <a href="https://en.wikipedia.org/wiki/Nucleotide">nucleotides</a>: <a href="https://en.wikipedia.org/wiki/Adenine">adenine</a>, <a href="https://en.wikipedia.org/wiki/Guanine">guanine</a>, <a href="https://en.wikipedia.org/wiki/Cytosine">cytosine</a>, and <a href="https://en.wikipedia.org/wiki/Thymine">thymine</a>. There are actually <a href="https://www.scripps.edu/romesberg/publications.html">plenty of ways to engineer</a> different <a href="https://pubmed.ncbi.nlm.nih.gov/22850726/">unnatural base pair systems</a> by adding <a href="https://science.sciencemag.org/content/363/6429/884">artificial nucleotides</a>, and these can even be integrated into <a href="https://www.pnas.org/content/98/9/4922">transcription</a> and <a href="https://www.nature.com/articles/nature24659">translation</a>, but <a href="https://carlbrannen.wordpress.com/2007/06/13/why-does-dna-only-use-4-nucleotides/">for</a> <a href="https://dreamerbiologist.wordpress.com/2013/02/16/why-did-nature-settle-on-just-four-nucleotides/">whatever</a> <a href="https://www.pnas.org/content/114/32/E6476">reason</a>, these four <a href="https://www.nature.com/articles/s41467-018-07389-2">and not others</a> are <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3331698/">what life ultimately ended up with</a>.</p>

<p><img src="https://csvoss.com/images/nucleotides.png"></p>
<p><small>The four nucleotides in DNA.</small></p>

<p>The genome of Wuhan-Hu-1 is available from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>. Since SARS-CoV-2 is an RNA virus, each <code>T</code> in this string technically represents a <code>U</code>, for <a href="https://en.wikipedia.org/wiki/Uracil">uracil</a>, RNA’s information-equivalent of thymine. The genome sequence is therefore:</p>

<div><div><pre><code>1     AUUAAAGGUU UAUACCUUCC CAGGUAACAA ACCAACCAAC UUUCGAUCUC UUGUAGAUCU
61    GUUCUCUAAA CGAACUUUAA AAUCUGUGUG GCUGUCACUC GGCUGCAUGC UUAGUGCACU
121   CACGCAGUAU AAUUAAUAAC UAAUUACUGU CGUUGACAGG ACACGAGUAA CUCGUCUAUC

...

29761 ACAGUGAACA AUGCUAGGGA GAGCUGCCUA UAUGGAAGAG CCCUAAUGUG UAAAAUUAAU
29821 UUUAGUAGUG CUAUCCCCAU GUGAUUUUAA UAGCUUCUUA GGAGAAUGAC AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>

<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>That’s 29,903 nucleotides. Since there are only four possible nucleotides, we can estimate the information compression value of each nucleotide at approximately 2 bits; the virus’s genome therefore requires only 7.5 kilobytes to store. That’s roughly as much data, byte for byte, as there are characters in this essay up to this point!</p>

<!-- <img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/110/2016/05/02212445/Figure_03_05_03.png"> -->

<p>Lay out those 29,903 nucleobases along a ribose-phosphate backbone, reading them left to right <a href="https://en.wikipedia.org/wiki/Directionality_(molecular_biology)">from the 5’ end to the 3’ end</a>, and bam – if that single molecule* were teleported into a cell, that’s 100% chemically sufficient** to infect a person with the plague du jour.</p>

<p>*plus the 5’ cap, discussed below</p>

<p>**modulo viral load effects??</p>

<p><img src="https://csvoss.com/images/polynucleotide.png"></p>
<p><small>How to interpret the Wuhan-Hu-1 genome as a complete molecule.</small></p>

<h2 id="poly-a-tail">Poly-A tail</h2>

<p>First question, and perhaps the most obvious one to the naked eye – what’s with all the <code>AAAAA</code> at the end of the viral genome?</p>

<div><div><pre><code>29821 ...                                                ... AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>
<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>It’s… yelling at us? Is it… suffering? Should we <a href="https://reducing-suffering.org/is-there-suffering-in-fundamental-physics/">help</a>?</p>

<p>Simple: It’s a <a href="https://bioinformatics.stackexchange.com/questions/11227/why-does-the-sars-cov2-coronavirus-genome-end-in-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa">3’ poly-A tail</a>! This <a href="https://en.wikipedia.org/wiki/Polyadenylation">long tail of adenosine monomers</a> is extremely common in both our own cells and in RNA viruses.</p>

<p>Our own messenger RNA (mRNA) has a poly-A tail when it’s freshly produced in the nucleus so as to slow its degradation by the cell, allowing it to last long enough to be transcribed into protein. Naturally, if you’re a positive-strand RNA virus, you’re also going to want to last long enough to be transcribed into protein – so, you need the same feature, yourself.</p>

<p>Genome 0.11% explained. So far so good!</p>

<h2 id="5-cap">5’ cap</h2>

<p>While we’re discussing chemical features of mRNA, note that the viral genome presumably must also have a <a href="https://en.wikipedia.org/wiki/Five-prime_cap">5’ cap</a> – an extra <a href="https://en.wikipedia.org/wiki/7-Methylguanosine">7-methylguanosine</a> at the 5’ end of its RNA strand – just like mRNAs do.</p>

<p><img src="https://csvoss.com/images/5primecap.png"></p>
<p><small>A 5' cap, consisting of a 7-methylguanosine as well as methylation of the first two ribose sugars.</small></p>

<p>The cap is not directly shown in the viral genome sequence or mentioned in NCBI GenBank, but it is referenced in multiple papers discussing coronaviral genomes:</p>

<blockquote>
  <p>Since 2003, the outbreak of severe acute respiratory syndrome coronavirus has drawn increased attention and stimulated numerous studies on the molecular virology of coronaviruses. Here, we review the current understanding of the mechanisms adopted by coronaviruses to produce the 5′-cap structure and methylation modification of viral genomic RNAs.</p>
</blockquote>



<blockquote>
  <p>Coronaviruses possess a cap structure at the 5′ ends of viral genomic RNA and subgenomic RNAs, which is generated through consecutive methylations by virally encoded guanine-N7-methyltransferase (N7-MTase) and 2′-O-methyltransferase (2′-O-MTase). The coronaviral N7-MTase is unique for its physical linkage with an exoribonuclease (ExoN) harbored in nonstructural protein 14 (nsp14) of coronaviruses.</p>
</blockquote>



<blockquote>
  <p>Here, we have reconstituted complete SARS-CoV mRNA cap methylation <em>in vitro</em>.</p>
</blockquote>



<p>Like the poly-A tail, the 5’ cap helps the genome to be recognized and translated by ribosomes rather than destroyed by the cell’s immune response.</p>

<p>How does the virus even ensure that it receives a 5’ cap and a poly-A tail, not to mention its outer coat? Hopefully these questions will be resolved by our review of its genes… let’s move on to look at those!</p>



<p>Per the “Features” section of the genome, again from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>, here are the identifiable genes in this genome, in order:</p>

<ol>
  <li><code>Orf1ab</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269089">orf1ab polyprotein</a>)</li>
  <li><code>S</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269090">surface glycoprotein</a>)</li>
  <li><code>Orf3…</code></li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</a></em></p>]]>
            </description>
            <link>https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261853</guid>
            <pubDate>Mon, 24 Aug 2020 15:55:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being OK with not being extraordinary]]>
            </title>
            <description>
<![CDATA[
Score 709 | Comments 333 (<a href="https://news.ycombinator.com/item?id=24261826">thread link</a>) | @tmatthe
<br/>
August 24, 2020 | https://www.tiffanymatthe.com/not-extraordinary | <a href="https://web.archive.org/web/*/https://www.tiffanymatthe.com/not-extraordinary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>23.08.2020</time> — <a href="https://www.tiffanymatthe.com/tags/mindset">Mindset</a> — <span>2<!-- --> min read</span></p><section><img src="https://www.tiffanymatthe.com/static/c239dad4f9476bf8d02961e957aa71cf/a6c62/rock-climbing.jpg"><p>The internet always highlights the first place winners, the billionaires, the award-winning artists, the best-selling authors, the largest philanthropists, the extraordinary. Their stories are ones of success, of inspiration. They show us what is possible, and push us to achieve more.</p><p>But I don't feel inspired when I see extraordinary. I feel disappointed, jealous. My constant exposure to these amazing stories of success has normalized the extraordinary. I started comparing myself to these "normal" extraordinary people, and wondered why I was not them. This disappointment would incite me to take action, but after a few days of hard work, I would just quit. Quitting was easier; it helped me avoid thinking about the extraordinary and the negative dark clouds that I had shrouded it with.</p><p>This mentality was self-defeating. No one starts off as extraordinary, so that meant I quit a lot in the past. Over time, I came to realize two things:</p><ol><li>extraordinary as I perceived it was one-dimensional and unrealistic,</li><li>to improve, extraordinary could not be my end goal.</li></ol><p><strong>We need to redefine extraordinary.</strong> Extraordinary is often defined by the internet as a permanent trait someone has. They seemed to have been born with it, and extraordinary permeates their every pore. </p><p>But real extraordinary is nothing like this. Yes, it's exciting, but it also comes with sacrifices, limitations, and constraints. And it's not permanent. Extraordinary can disappear over time, just like you can achieve it over time.</p><p>Extraordinary also comes in many forms, and its value does not have to be measured in terms of money. You can be a tech giant who built their entire empire from scratch, just as you can be an amazing organizer who rallies entire communities together for a single cause. You can be a top-notch violinist player, or a inspiring storyteller. Extraordinary can be anything. Sometimes, when you realize what extraordinary really entails, you might not even want it. That's okay.</p><p><strong>Extraordinary should not be the end goal.</strong> I like to envision the extraordinary space in society as a small ledge at the top of a cliff. It gives you a beautiful view and a sense of accomplishment, but is also tight and oppressing. The sheer physical constraints means that not everyone will reach it. But that shouldn't stop you from putting a hand on the cliff and lifting yourself towards that ledge.</p><p>Why? Because the ledge is not the only thing that exists. There is a vast amount of space under it, other ledges, crooks, and crannies, that most people forget about. That space is just as valuable.</p><p>For example, someone starting out on Youtube might be disappointed that they don't have millions of subscribers. They don't think they have what it takes, so they quit. But most people don't only look at the channels with millions of subscribers. Smaller ones are as valuable for viewers, and the creators can get just as much value out of creating their original content and connecting with like-minded people.</p><p>So instead of searching for an extraordinary that is distorted and unrealistic, search to climb up to some space beneath the top ledge. You will be less disappointed and jealous, and you will still maintain some velocity in the right direction. Climbing to a higher vantage point can also unlock new forms of extraordinary that you might have never noticed before.</p><p>By consistently climbing and reassessing which direction to take, you might just reach your own extraordinary as a bonus.</p></section></div></div>]]>
            </description>
            <link>https://www.tiffanymatthe.com/not-extraordinary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261826</guid>
            <pubDate>Mon, 24 Aug 2020 15:53:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remains of 17th century bishop support Neolithic emergence of tuberculosis]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24261768">thread link</a>) | @benbreen
<br/>
August 24, 2020 | https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis | <a href="https://web.archive.org/web/*/https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>Bishop Peder Winstrup of Lund, Sweden passed away in the winter of 1679 at the age of 74 and was interred in a crypt at Lund Cathedral. Three centuries later, his astonishingly well-preserved remains provide insights to the origins of tuberculosis.</p>
  

  

  <p>In a recent study published in <em>Genome Biology</em>, researchers from the Max Planck Institute for the Science of Human History, Lund University and the Swedish Natural Historical Museum present analysis of the highest quality ancient Mycobacterium tuberculosis genome to date, suggesting the pathogen is much younger than previously believed.</p>
  
  
<figure data-description="Portrait of Bishop Peder Jensen Winstrup" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Portrait of Bishop Peder Jensen Winstrup
        </p>
        <p>
           © Orf3us / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)
        </p>
    </figcaption>
</figure>


<p>When Anthropologist Caroline Arcini and her colleagues at the Swedish Natural Historical Museum discovered small calcifications in the extremely well preserved lungs of Bishop Peder Winstrup, they knew more investigation was needed. “We suspected these were remnants of a past lung infection,” says Arcini, “and tuberculosis was at the top of our list of candidates. DNA analysis was the best way to prove it.”</p>
<p>Up to one quarter of the world’s population is suspected to have been exposed to bacteria of the <i>Mycobacterium tuberculosis</i> complex, which cause tuberculosis (TB). Bishop Winstrup would have been one of many to fall ill during the onset of the so-called “White Plague” TB pandemic that ravaged post-medieval Europe. Today, TB is among the most prevalent diseases, accounting for the highest worldwide mortality from a bacterial infection.</p>
<p>The global distribution of TB has led to the prevailing assumption that the pathogen evolved early in human history and reached its global distribution via the hallmark Out of Africa human migrations tens of thousands of years ago, but recent work on ancient TB genomes has stirred up controversy over when this host-pathogen relationship began. In 2014, a team led by scientists from the University of Tübingen and Arizona State University reconstructed three ancient TB genomes from pre-contact South America – not only were the ancient strains unexpectedly related to those circulating in present-day seals, but comparison against a large number of human strains suggested that TB emerged within the last 6000 years. Understandably, skepticism surrounded this new estimate since it was based entirely on ancient genomes that are not representative of the TB strains associated with humans today.</p>
<p>“Discovery of the Bishop’s lung calcification gave us the opportunity to revisit the question of tuberculosis emergence with data from an ancient European,” comments Kirsten Bos, group leader for Molecular Paleopathology at the Max Planck Institute for the Science of Human History (MPI-SHH), who co-led the study. “If we could reconstruct a TB genome from Bishop Winstrup, where we know his date of death to the day, it would give a secure and independent calibration for our estimates of how old TB, as we know it, actually is.”</p>
<p><b>The highest quality ancient TB genome to date&nbsp; </b></p>
<p>In a new study published this week in Genome Biology, Susanna Sabin of MPI-SHH and colleagues reconstruct a tuberculosis genome from the calcified nodule discovered in Bishop Winstrup's remains.</p>
<p>“The genome is of incredible quality – preservation on this scale is extremely rare in ancient DNA,” comments Bos.</p>

<figure data-description="Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB
        </p>
        <p>
           © NIAID
        </p>
    </figcaption>
</figure>


<p>Together with a handful of tuberculosis genomes from other work, the researchers revisit the question of the age of the Mycobacterium tuberculosis complex, with the year of the Bishop’s death as a fine-tuned calibration point. Using multiple molecular dating models, all angles indeed point to a relatively young age of the <i>Mycobacterium tuberculosis</i> complex.</p>
<p>“A more recent emergence of the tuberculosis pathogen complex is now supported by genetic evidence from multiple geographic regions and time periods,” comments Sabin, first author of the study. “It’s the strongest evidence available to date for this emergence having been a Neolithic phenomenon.”</p>
<p>This most recent shift in the narrative for when bacteria in the <i>Mycobacterium tuberculosis </i>complex became highly infectious to humans raises further questions about the context of its emergence, as it appears to have coincided with the rise of pastoralism and sedentary lifestyles.</p>
<p>“The Neolithic transition seems to have played an important role for the emergence of a number of human pathogens,” comments Denise Kühnert, group leader for disease transmission research at MPI-SHH who co-led the investigation.&nbsp;</p>
<p>“For TB in particular, stronger evidence could only come from an older genome, though these deeper time periods are unlikely to yield preservation on the scale of what we’ve seen for Bishop Winstrup,” adds Bos.</p>
<p>“Moving forward,” Sabin further comments, “the hope is we will find adequately preserved DNA from time periods close to the emergence of the complex, or perhaps from its ancestor.”</p>
  
</div></div>]]>
            </description>
            <link>https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261768</guid>
            <pubDate>Mon, 24 Aug 2020 15:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meaningful Slack Alerts for Software Development Teams]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261545">thread link</a>) | @necco908
<br/>
August 24, 2020 | https://linearb.io/blog/slack-alerts-for-software-development-teams/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/slack-alerts-for-software-development-teams/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="4117" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="dae3957" data-element_type="section">
						<div>
				<div>
				<div data-id="ed4d5ab" data-element_type="column">
			<div>
					<div>
				<div data-id="cdf097d" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Slack alerts are necessary for dev team success. Which ones should your team be using?

</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="95b19bf" data-element_type="section">
						<div>
				<div>
				<div data-id="0417682" data-element_type="column">
			<div>
					<div>
				<div data-id="96a0db0" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/1-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="e7499ee" data-element_type="section">
						<div>
				<div>
				<div data-id="87a8310" data-element_type="column">
			<div>
					<div>
				<div data-id="e96f0b1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>As an engineering team lead at a software company it’s my responsibility to fence distractions and make sure my developers are focused on the goals of the sprint. Too much noise from the business or tools can cause interruptions in our workflows and defocus the team from our priorities. Slack alerts are one of those distractions that can become too noisy very quickly. Whether it’s Jira, Github, Docker or LinearB, I am constantly analyzing which Slack alerts are actually useful to my team. Here is what I’ve learned.&nbsp; </span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="4ceae4f" data-element_type="section">
						<div>
				<div>
				<div data-id="bcb252a" data-element_type="column">
			<div>
					<div>
				<div data-id="fdeb9a1" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>The most common Slack alerts for software developers are continuous integration and continuous deployment alerts. Automation servers like Jenkins and CircleCI provide in-chat deployment process alerts letting dev teams know the outcome of their build, test, and deployment workflows. The success of deployment alerts at the team level has made this feature a minimum requirement for any CI/CD tool trying to make it in today’s world. Is it possible to replicate the success of deployment alerts, in the development process phase? </span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3a742ca" data-element_type="section">
						<div>
				<div>
				<div data-id="8a3670b" data-element_type="column">
			<div>
					<div>
				<div data-id="14a4d34" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/4-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="0f4d469" data-element_type="section">
						<div>
				<div>
				<div data-id="f536820" data-element_type="column">
			<div>
					<div>
				<div data-id="d6a7845" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Three Levels of Software Alerts 
</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="07f9b63" data-element_type="section">
						<div>
				<div>
				<div data-id="e862224" data-element_type="column">
			<div>
					<div>
				<div data-id="02dd0bd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>At LinearB we categorize automated software alerts into three distinct levels. </span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="658c831" data-element_type="section">
						<div>
				<div>
				<div data-id="816641c" data-element_type="column">
			<div>
					<div>
				<div data-id="e994fc1" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/2-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="77f04b2" data-element_type="section">
						<div>
				<div>
				<div data-id="10c4b2f" data-element_type="column">
			<div>
					<div>
				<div data-id="43fd444" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span><strong>Critical</strong> – Production outage alerts. Companies use tools like PagerDuty to notify their dev leads when there is a production outage or service degradation.&nbsp;</span></p><p><span><strong>High</strong> – Workflow breakages alerts. These are your deployment alerts sent to you from your CI/CD tools, letting your teams know the success or failure of your deployment.&nbsp;</span></p><p><span><strong>Medium</strong> – Task Progress alerts. These are team alerts based on Jira subtask progress or Git operations that are often turned off due to the sheer amount of noise they produce.&nbsp;</span></p><p><span>We can also visualize these levels in the form of Production – Deployment – Development</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="26c09ee" data-element_type="section">
						<div>
				<div>
				<div data-id="d86b397" data-element_type="column">
			<div>
					<div>
				<div data-id="099593e" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/3-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="8170dd9" data-element_type="section">
						<div>
				<div>
				<div data-id="e79e454" data-element_type="column">
			<div>
					<div>
				<div data-id="5d57e27" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>I believe most people agree that production and deployment level alerts are important to the success of engineering teams. But for many companies, the jury is still out on the importance and effectiveness of development process level alerts. </span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="7da54f8" data-element_type="section">
						<div>
				<div>
				<div data-id="f5370fa" data-element_type="column">
			<div>
					<div>
				<div data-id="875f361" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>The Sound of a Thousand Branches</h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="46e90e6" data-element_type="section">
						<div>
				<div>
				<div data-id="bbcc6af" data-element_type="column">
			<div>
					<div>
				<div data-id="33bf639" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Production and deployment level alerts are very binary in nature. Production is running or it’s broken. The test passed or failed. The merge was complete or not.&nbsp;</span></p><p><span>As we go deeper into the development level, binary type alerts are not as effective due to volume and necessity. How many Jira stories get progressed throughout the week? How many pull requests are issued? For many teams, the volume would be enormous, they would cover up actually useful alerts, and team members generally don’t need to know when a pull request is issued.&nbsp;</span></p></div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="65c4bfb" data-element_type="section">
						<div>
				<div>
				<div data-id="93aef09" data-element_type="column">
			<div>
					<div>
				
				<div data-id="1ebb5ec" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><h3>We analyze signals in Git &amp; Jira and alert you to risky &amp; blocked work</h3></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
				<div data-id="a5b244a" data-element_type="column">
			<div>
					<div>
				<div data-id="a1b8ff2" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="766" src="https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-1024x981.png" alt="" srcset="https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-1024x981.png 1024w, https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-300x287.png 300w, https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM-768x735.png 768w, https://linearb.io/wp-content/uploads/2000/08/Screen-Shot-2020-08-20-at-2.02.46-PM.png 1038w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="818e8cc" data-element_type="section">
						<div>
				<div>
				<div data-id="3f1e0dc" data-element_type="column">
			<div>
					<div>
				
				<div data-id="518dcdd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Noise is an efficiency killer. Any team who’s turned on out of the box slack alerts without any filters will tell you how unproductive it is to have hundreds of notifications flooding your Slack channel.&nbsp;&nbsp;</span></p><p><span>To cut through all the noise, dev teams carefully manicure which alerts are coming through so only the most important information is being reported. Build start, test status, and merge success should all sound familiar. If you’re just starting out, deployment alerts like these are a good place to begin.&nbsp;</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="74fbbdf" data-element_type="section">
						<div>
				<div>
				<div data-id="955735a" data-element_type="column">
			<div>
					<div>
				<div data-id="42714d4" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>Development Process Level Slack Alerts </h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="79091f5" data-element_type="section">
						<div>
				<div>
				<div data-id="c8993be" data-element_type="column">
			<div>
					<div>
				<div data-id="2eb7733" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>How do you decipher which 10 development process level alerts are important when there are 500 per week? How do you find a needle in a haystack? Parameters.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="0009dfc" data-element_type="section">
						<div>
				<div>
				<div data-id="1447407" data-element_type="column">
			<div>
					<div>
				<div data-id="4ae904b" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts.png.webp 1386w" sizes="(max-width: 1386px) 100vw, 1386px">
<img width="1386" height="660" src="https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts.png 1386w, https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/08/5-Blog-SlackAlerts-768x366.png 768w" sizes="(max-width: 1386px) 100vw, 1386px">
</picture>
											</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="ed0ff01" data-element_type="section">
						<div>
				<div>
				<div data-id="14ba0ee" data-element_type="column">
			<div>
					<div>
				<div data-id="bd6e628" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>What does the needle look like, should be your first question. What exactly are we looking for within these hundreds of development level alerts? At LinearB we developed parameters that allowed us to identify risk and stuck work.</span></p><p>Identifying stuck and at-risk work during development places these alerts somewhere between high and critical on the importance scale. Stuck work can easily mean other dependent branches being delayed or deployed out of order, resulting in a workflow issues. Work-at-risk slack alerts provide early identification of code that has the potential to cause a production breakage.&nbsp;</p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="23119d1" data-element_type="section">
						<div>
				<div>
				<div data-id="f0372cd" data-element_type="column">
			<div>
					<div>
				<div data-id="05951da" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><strong>Risk</strong></p><p><span>Identifying risk at the development process level can be incredibly useful. Whether it’s a massive PR merge or a PR issued with a high amount of refactor, notifying the team to keep an eye out when high risk actions take place is helpful. </span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9979a28" data-element_type="section">
						<div>
				<div>
				<div data-id="18e13bc" data-element_type="column">
			<div>
					<div>
				<div data-id="2894215" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Top Slack Alerts for Development Teams to identify work at risk include:</span></p>
<ul>
<li><span>Substantial PR merged without review</span></li>
<li><span>Substantial branch with high rework or refactor rate </span></li>
</ul></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="12c4ae4" data-element_type="section">
						<div>
				<div>
				<div data-id="ac2f5d2" data-element_type="column">
			<div>
					<div>
				
				<div data-id="605aa9b" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM.png.webp 1222w" sizes="(max-width: 1222px) 100vw, 1222px">
<img width="1222" height="354" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM.png 1222w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM-300x87.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM-1024x297.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.53.45-PM-768x222.png 768w" sizes="(max-width: 1222px) 100vw, 1222px">
</picture>
											<figcaption>LinearB Slack Alert, Pull Request merged without review</figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="8cebaf9" data-element_type="section">
						<div>
				<div>
				<div data-id="9f85135" data-element_type="column">
			<div>
					<div>
				<div data-id="5f1d3a9" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM.png.webp 1264w" sizes="(max-width: 1264px) 100vw, 1264px">
<img width="1264" height="338" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM.png 1264w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM-300x80.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM-1024x274.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.54.29-PM-768x205.png 768w" sizes="(max-width: 1264px) 100vw, 1264px">
</picture>
											<figcaption>LinearB Work-at-risk  Slack Alert</figcaption>
										</figure>
					</div>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="fb858d6" data-element_type="section">
						<div>
				<div>
				<div data-id="a1ed9f5" data-element_type="column">
			<div>
					<div>
				<div data-id="7abae44" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>These preemptive notifications allow engineers to open a discussion about the work before it’s a problem. Earlier discovery almost always saves time during the iteration. Automated Slack alerts for these high risk actions also improve the way your teams work. By calling out high risk actions like Pull Request merged without review, it brings focus to detrimental behavior. Once it’s identified, it can be improved upon.&nbsp;</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="bf826ec" data-element_type="section">
						<div>
				<div>
				<div data-id="c314480" data-element_type="column">
			<div>
					<div>
				<div data-id="4b9f666" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span><strong>Stuck Work</strong>&nbsp;</span></p><p><span>Notifying the team about work that has stagnated in your pipeline increases team efficiency and helps give a voice to shy or distributed developers. </span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="243c555" data-element_type="section">
						<div>
				<div>
				<div data-id="6ddeb40" data-element_type="column">
			<div>
					<div>
				<div data-id="e1deb15" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Top Development-level Slack alerts for stuck work include:&nbsp;</span></p>
<ul>
<li><span>PR is waiting for review (Review Request Pending)</span></li>
<li><span>High interaction review&nbsp;</span></li>
<li><span>Review Not Merged (Long Review Detected)</span></li>
</ul></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="b3a64a7" data-element_type="section">
						<div>
				<div>
				<div data-id="e6e8696" data-element_type="column">
			<div>
					<div>
				<div data-id="3f44d4d" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM.png.webp 1136w" sizes="(max-width: 1136px) 100vw, 1136px">
<img width="1136" height="336" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM.png 1136w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM-300x89.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM-1024x303.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-1.01.55-PM-768x227.png 768w" sizes="(max-width: 1136px) 100vw, 1136px">
</picture>
											<figcaption>LinearB Slack Alert, Review request hanging</figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="0603a68" data-element_type="section">
						<div>
				<div>
				<div data-id="20c8ce8" data-element_type="column">
			<div>
					<div>
				<div data-id="e498bd8" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM.png.webp 1216w" sizes="(max-width: 1216px) 100vw, 1216px">
<img width="1216" height="354" src="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM.png 1216w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM-300x87.png 300w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM-1024x298.png 1024w, https://linearb.io/wp-content/uploads/2020/08/Screen-Shot-2020-08-20-at-12.55.17-PM-768x224.png 768w" sizes="(max-width: 1216px) 100vw, 1216px">
</picture>
											<figcaption>LinearB Slack Alert, Long Review</figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="727da78" data-element_type="section">
						<div>
				<div>
				<div data-id="e6d063b" data-element_type="column">
			<div>
					<div>
				<div data-id="aa7bf47" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p><span>Back when we were working in an office, if someone issued a PR and no one picked it up for review within the week, they would have to bring it up during synchronous communication periods like stand-up, lunch, or interrupting someone’s work. Now that everyone is distributed, it can be even more challenging to identify stuck work in our development process, or know when I’m not interrupting anyone. Slack alerts are an easy asynchronous way to communicate when something needs attention without someone having to personally reach out, or wait until the next stand up — which could be 20 hours away.&nbsp;</span></p>

<p><span>The other major pros to asynchronous stuck work slack alerts are using them to balance teamwork and drive discussions. Asking someone to drop what they are doing to follow-up on your request is bad form. An alert however can be read when someone is taking a break and picked up by whoever has time.&nbsp;</span></p>

<p><span>These alerts also provide an opportunity to have a focused Slack or Zoom discussion that may not have been otherwise had. Giving developers the chance to provide context around the alert is an easy way to make sure your devs are being heard, as well as learn how you can best support your teammates.&nbsp;</span></p></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="198b3aa" data-element_type="section">
						<div>
				<div>
				<div data-id="2f194b3" data-element_type="column">
			<div>
					<div>
				<div data-id="4100a0e" data-element_type="widget" data-widget_type="heading.default">
				<p>
			<h2>The Future of Software Development Slack Alerts </h2>		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="59e22c6" data-element_type="section">
						<div>
				<div>
				<div data-id="1d4cc60" data-element_type="column">
			<div>
					<div>
				<div data-id="89512b9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>At LinearB, we’ve worked hard to provide development teams with all of the Slack alerts I mentioned above. Our risk and stuck work alerts have changed the way my team works and I hope they will help yours as well. With that in mind, we are focused on the continued development of even smarter alerts…and …</span></p></div></div></div></div></div></div></div></section></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/slack-alerts-for-software-development-teams/">https://linearb.io/blog/slack-alerts-for-software-development-teams/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/slack-alerts-for-software-development-teams/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261545</guid>
            <pubDate>Mon, 24 Aug 2020 15:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making money building Shopify micro-SaaS apps]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24261192">thread link</a>) | @gk1
<br/>
August 24, 2020 | https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Starting your first business can be a daunting task. There’s so many variables involved - which ones to solve for, which ones to figure out?</p><p>Typically as software engineers and product people, building the product and writing code is not where we falter. </p><p>Where we get stuck is with existential questions like:</p><ul role="list"><li>Does anybody want this app?</li><li>How will I get users?</li></ul><p>And from my little experience in entrepreneurship, I find these questions to be more important than actually designing and building the app. Trust me when I say this.</p><p>Since I’ve been answering questions on email and Twitter DMs around these topics already, writing a guide came as the natural next step.</p><h3>Who this guide is for</h3><ul role="list"><li>You are starting your first micro-SaaS business</li><li>You want to earn extra outside your job, or you want to eventually replace your job income with a business</li><li>You can design apps with a baseline level of UX, and you can write code. Or, you have a business partner who can do these</li><li>You have 10+ hours to allocate every week (initially, more is better) and are in it for the long haul (say 3-6 months before you start seeing significant income from the business)</li><li>You want to serve customer’s needs</li></ul><h3>Who this guide is NOT for</h3><ul role="list"><li>You want to become a millionaire quickly</li><li>You are in it for the short term gain but you don’t see building businesses as your long-term path</li><li>You don’t know the A of design or coding, and neither have a business partner who does</li><li>You don’t have the patience to struggle for 3-6 months when the results might be 0, before things suddenly start to work in your favour</li></ul><p>If this guide is for you, read on. I’ve laid out the index of topics covered in the post. </p><p>Depending on the stage of your journey, feel free to skip to the sections that are most relevant to you.<br></p><h3><strong>Topics covered in this post</strong></h3><ol role="list"><li>Make money building Shopify apps</li><li>Discover problems, niches, and Shopify app ideas</li><li>Standing out from competition</li><li>Shopify App Store optimisation basics</li><li>Find your #1 keyword</li><li>How to build a Shopify app</li><li>Getting customers to review your Shopify app (by delivering great customer support)</li><li>Getting the first customers for your Shopify app</li><li>Finding early users and beta testers for your Shopify app outside the App Store</li><li>Getting listed under the right categories &amp; collections, and getting featured on the Shopify App Store</li><li>The right pricing model for your Shopify app</li><li>Optimising for trials</li><li>Long term game plan in the Shopify App Store</li></ol><p>‍<br></p><h2><strong>Make money building Shopify apps</strong></h2><p>Shopify isn’t the only choice when it comes to picking an apps marketplace. There’s </p><ul role="list"><li><a href="https://slack.com/apps" target="_blank">Slack</a></li><li><a href="https://marketplace.atlassian.com/" target="_blank">Atlassian</a></li><li><a href="https://appexchange.salesforce.com/" target="_blank">Salesforce</a></li><li><a href="https://gsuite.google.com/marketplace" target="_blank">GSuite Marketplace</a></li><li><a href="https://chrome.google.com/webstore/category/extensions" target="_blank">Chrome Web Store</a></li><li><a href="https://play.google.com/store/apps" target="_blank">Google Play Store</a></li><li><a href="https://www.apple.com/in/ios/app-store/" target="_blank">Apple iOS App Store</a></li><li><a href="https://apps.apple.com/us/genre/mac/id39?mt=12" target="_blank">Mac App Store</a></li></ul><p>All these marketplaces are valid options for you to start. I would lean on a marketplace where there’s a combination of 2 factors</p><ol role="list"><li><strong>Familiarity with problems</strong> - You know what the core product is about, you understand or can empathise with its users maybe from using the tool at your previous workplace, you have an idea on the different kind of problems that exist in the ecosystem and don’t find it too boring to solve them</li><li><strong>Skillset to execute</strong> - If you don’t know how to build Android, iOS, or Mac apps, perhaps steer clear of it. Your goal is not to take on a hard challenge, it’s to take on a challenge where you have some advantage from skill and insight. The goal is to win.<br></li></ol><h3>Why you should pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Huge distribution:</strong> Marketing is often a big reason for a business’s failure, the App Store takes care of it. Shopify has 1mn+ merchants and tons of new signups every month who go to the app store browsing for solutions. <br>Shopify promotes apps within its product and has made it an integral part of its user journey. A new app is able to gain traction fairly easily in the app marketplace, which makes it friendly to newcomers. <br>Marketing is often a big reason for a business’s failure, the App Store takes care of it.</li><li><strong>Tons of app opportunities:</strong> E-commerce store owners have 101+ problems to be taken care of, and you can address any one and do a great job at it to build a sustainable business. It’s not hard (relative standards) to gain 200 paying customers paying you $10/mo to earn $2000/mo ($1600 after Shopify’s 20%)</li><li><strong>Ease of development:</strong> Shopify’s documentation and APIs are first-class, they get out of the way allowing you to build fast. Additionally, Shopify’s <a href="https://polaris.shopify.com/" target="_blank">Polaris UI framework</a> makes building app interfaces a piece of cake. It’s based on React and comes with a Sketch/Figma file to help you design and prototype solutions fast.</li><li><strong>Billing taken care of:</strong> Heads up, Shopify takes a 20% commission on all earnings. So if your app’s monthly subscription fees is $10, you get $8. In return, Shopify takes care of billing end to end.<br>You can charge monthly, annually, charge per activity, provide app credit, and issue refunds with very little effort. You don’t need to worry about failed payments, Shopify takes care of it. You don’t even need to generate an invoice, app bills are included in the merchant’s monthly Shopify invoice.</li><li><strong>Familiarity with ecommerce:</strong> If you’re someone who can jump into an industry and learn all about it, great. If not, you would want some familiarity with how an ecommerce store works, what are the typical problems faced by a merchant.<br>You can do this by creating a Shopify store and trying to sell your own products. Or you could have conversations with 10 different store owners and absorb from their experience. You could also find someone who works at an e-commerce agency for valuable insights. It’s not that hard.<br></li></ul><h3>Why you shouldn’t pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Copycat galore:</strong> You’re likely to copy an existing app and make a slight improvement in terms of product, pricing, or both. Guess what, the next smart person with the same idea can do the same to you. If you’re dependent on getting all or majority of your customers from the app store, be ready for stiff competition from copycats. <br>This doesn’t mean you cannot grow your app to $1k or $10k MRR. SaaS is not a winner take all market. It just means that it gets harder to grow as you grow. If this is something you are not mentally prepared for, steer clear. <br>There’s ways you can grow out of this by taking a long term strategy, either by taking a brand-centric approach (brand is not your name, but the experience that customers remember you by for which they’ll choose you over a copycat). <br>Or you can go upmarket and target large volume and Plus merchants, where ticket sizes are $200/mo or higher and switching does not happen often. </li><li><strong>Low-end, high-maintenance customers:</strong> Majority of Shopify merchants are people who don’t want to pay beyond $10-$15/mo and yet they expect world-class customer service. Some will ask for phone support or to jump on a video call. <br>You can tackle this by solving problems where the ticket sizes are higher, in the range of $50-$100/mo, but also expect it to be significantly harder to rank and fight existing competitors in such problem spaces. Example - <a href="https://apps.shopify.com/search?q=page+builder" target="_blank">page builders</a>, <a href="https://apps.shopify.com/search?q=product+reviews" target="_blank">product review</a> apps. <br>You can mitigate this by going in with the mindset that you’ll be serving $15/mo customers, so your app better be self-serve ready, have a dead simple UX and sufficient documentation or walkthrough videos. You can also aim to be the cost-leader of a segment, example - <a href="https://apps.shopify.com/judgeme" target="_blank">Judge.me</a> </li></ul><p>‍<br></p><h2><strong>Discover problems, niches, and Shopify app ideas</strong></h2><p>I’ve previously written about <a href="https://www.preetamnath.com/blog/shopify-micro-saas-growth" target="_blank">uncovering opportunities on Shopify</a> and I also shared all my research in my big <a href="https://docs.google.com/spreadsheets/d/1Hnpcl1VAlPC9MuFvvsl2UsU0yu1iM6aKR-iK30VtbwA/edit?usp=sharing" target="_blank">Shopify app ideas spreadsheet</a>. Let me reiterate on the advice shared there in a more structured manner that will hopefully better answer questions like:</p><ul role="list"><li>“How do you find niches in the app store in the first place?”</li><li>“How to find a problem worth solving within shopify? (worth solving=stressful enough for merchants &amp; competition not too tough)”<br></li></ul><p>There have been people who have asked me what kind of problems to solve, or what are the underserved niches. The thing is - if there's an obviously underserved niche and people have taken the time to research about it, they are probably busy solving it. If it's being posted in any blog post, know that it's no longer an underserved or hidden niche, because clearly anyone could find it.</p><p>Ultimately, only you can find an idea that you find worthy enough to pursue, whose various pros and cons are justified in your mind. And therefore, I can only provide a directional framework towards evaluating ideas. I can't list out ideas.</p><p>The best use of a directional framework is to</p><ol start="" role="list"><li><strong>First</strong> - cast a wide net, get to know what's out there</li><li><strong>Second</strong> - narrow down your search based on parameters you have decided</li></ol><p>This first section of the article will help you with casting a wide net. </p><p>As you go further along the article, I've shared ideas and techniques which you can use to narrow down your search.<br></p><h3>1- Browse the entire App Store</h3><p>I recommend this as the starting point for anyone new to the Shopify ecosystem. Start by browsing all the categories &amp; sub-categories of apps on the app store. You can do the same on <a href="https://sasi.unionworks.co.uk/categories" target="_blank">SASI</a>. </p><p>The purpose of browsing this way is to familiarise yourself with the different types of problems faced by merchants and being solved by apps. Ideally, you want to note down some interesting apps that you come across during your browsing adventure to investigate later on.</p><figure id="w-node-892fc283544a-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f1c114edd643e073591f8cc_browse%20categories%20shopify%20app%20store.png" alt=""></p></figure><h3>2- Go through every letter in search autocomplete</h3><p>Okay, this is a step I took when&nbsp;I was browsing the app store. I would type in "aa", "ab", "ac"... ... ... "zz" on the search bar, note the autocomplete terms and check the results of ones I found to be interesting.</p><p>Turns out, Shopify has since updated their algorithm. Autocomplete suggestions only show up after you type 3 letters now. So you can't recreate what I did with autocomplete and go through every letter. It's not feasible anymore.</p><p>Not to worry, it's still useful.</p><h4>Plug in keywords of shortlisted apps into the search bar</h4><p>From step 1, all the apps (hopefully at least a dozen) that you shortlisted for being interesting, extract the keywords used in the app's title or description. </p><p>Now, enter those keywords in search to find whether they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261192</guid>
            <pubDate>Mon, 24 Aug 2020 14:47:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hong Kong man reinfected with different strain of Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24260152">thread link</a>) | @platz
<br/>
August 24, 2020 | https://news.rthk.hk/rthk/en/component/k2/1545589-20200824.htm | <a href="https://web.archive.org/web/*/https://news.rthk.hk/rthk/en/component/k2/1545589-20200824.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
			Researchers at the University of Hong Kong on Monday said they have proved that a Hong Kong man was infected with Covid-19 for a second time â€“ the worldâ€™s first such documented case. </p><p>

The 33-year-old IT worker was cleared of Covid-19 and discharged from a hospital in April. He tested positive for the virus again after returning from Spain earlier this month. </p><p>

Health officials at first were unsure if the man was a "persistent carrier" of the virus from his previous infection. </p><p>

But the HKU research team said genetic sequencing showed the virus strains contracted by him in April and August were â€œclearly differentâ€�. The study has been accepted by the Clinical Infectious Diseases journal, the researchers said. </p><p>

â€œMany believe that recovered Covid-19 patients have immunity against re-infection because most developed a serum neutralising antibody response. However, there is evidence that some patients have waning antibody level after a few months," the researchers said.  </p><p>

â€œOur findings suggest that the SARS-CoV-2 may persist in the global human population as is the case for other common cold-associated human coronaviruses, even if patients have acquired immunity via natural infection,â€� they said. </p><p>

They said, therefore, patients who recovered after getting Covid-19 should also wear masks and maintain social distancing.</p><p>

"Since the immunity can be short-lasting after natural infection, vaccination should also be considered for those with one episode of infection," they said.		</p></div></div>]]>
            </description>
            <link>https://news.rthk.hk/rthk/en/component/k2/1545589-20200824.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260152</guid>
            <pubDate>Mon, 24 Aug 2020 12:57:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UMASH: A fast and universal enough hash function]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24260020">thread link</a>) | @pkhuong
<br/>
August 24, 2020 | https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/ | <a href="https://web.archive.org/web/*/https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We accidentally a whole hash function… but we had a good reason!
Our
<a href="https://github.com/backtrace-labs/umash">MIT-licensed UMASH hash function</a>
is a decently fast non-cryptographic hash function that guarantees
a worst-case bound on the probability of collision
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">between any two inputs generated independently of the UMASH parameters</a>.</p><p>On the
<a href="https://en.wikichip.org/wiki/intel/xeon_platinum/8175m">2.5 GHz Intel 8175M</a>
servers that power <a href="https://backtrace.io/">Backtrace</a>’s hosted
offering, UMASH computes a 64-bit hash for short cached inputs of up
to 64 bytes in 9-22 ns, and for longer ones at up to 22 GB/s, while
guaranteeing that two distinct inputs of at most \(l\) bytes collide
with probability less than \(\lceil l / 2048 \rceil \cdot 2^{-56}\).
If that’s not good enough, we can also reuse most of the parameters to
compute two independent UMASH values. The resulting 128-bit
<a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint function</a>
offers a short-input latency of 9-26 ns, a peak throughput of 11.2
GB/s, and a collision probability of \(\lceil l / 2048 \rceil^2 \cdot
2^{-112}\) (better than \(2^{-70}\) for input size up to 7.5 GB).
These collision bounds hold for all inputs constructed without any
feedback about the randomly chosen UMASH parameters.</p><p>The latency on short cached inputs (9-22 ns for 64 bits, 9-26 ns for
128) is somewhat worse than the state of the art for non-cryptographic
hashes—
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> achieves
8-15 ns and <a href="http://fastcompression.blogspot.com/2019/03/presenting-xxh3.html">xxh3</a>
8-12 ns—but still in the same ballpark. It also
compares well with latency-optimised hash functions like
<a href="https://en.wikipedia.org/wiki/Fowler%E2%80%93Noll%E2%80%93Vo_hash_function#FNV-1a_hash">FNV-1a</a>
(5-86 ns) and
<a href="https://en.wikipedia.org/wiki/MurmurHash#MurmurHash2">MurmurHash64A</a>
(7-23 ns).</p><p>Similarly, UMASH’s peak throughput (22 GB/s) does not match
the current best hash throughput (37 GB/s with
<a href="https://github.com/Cyan4973/xxHash">xxh3</a>
and <a href="https://github.com/gamozolabs/falkhash">falkhash</a>, apparently
10% higher with <a href="https://github.com/cmuratori/meow_hash">Meow hash</a>),
but does comes within a factor of two; it’s actually higher than that of
some performance-optimised hashes, like
<a href="https://github.com/wangyi-fudan/wyhash">wyhash</a> (16 GB/s) and
<a href="https://github.com/google/farmhash">farmhash32</a>
(19 GB/s). In fact, even the 128-bit fingerprint (11.2 GB/s) is
comparable to respectable options like
<a href="https://github.com/aappleby/smhasher/blob/master/src/MurmurHash2.cpp#L89">MurmurHash64A</a>
(5.8 GB/s) and
<a href="https://burtleburtle.net/bob/hash/spooky.html">SpookyHash</a> (11.6 GB/s).</p><p>What sets UMASH apart from these other non-cryptographic hash
functions is its proof of a collision probability bound. In the
absence of an adversary that adaptively constructs pathological inputs
as it infers more information about the randomly chosen parameters, we
know that two distinct inputs of \(l\) or fewer bytes will have the
same 64-bit hash with probability at most \(\lceil l / 2048 \rceil
\cdot 2^{-56},\) where the expectation is taken over the random
“key” parameters.</p><p>Only one non-cryptographic hash function in
<a href="https://github.com/rurban/smhasher">Reini Urban’s fork of SMHasher</a>
provides this sort of bound: <a href="https://github.com/lemire/clhash">CLHash</a>
<a href="https://arxiv.org/abs/1503.03465">guarantees a collision probability \(\approx 2^{-63}\)</a>
in the same
<a href="https://en.wikipedia.org/wiki/Universal_hashing#Mathematical_guarantees">universal hashing</a>
model as UMASH. While CLHash’s peak throughput (22 GB/s) is
equal to UMASH’s, its latency on short inputs is worse (23-25 ns
instead of 9-22ns). We will also see that its stronger collision
bound remains too weak for many practical applications. In order to
compute a <a href="https://en.wikipedia.org/wiki/Fingerprint_(computing)">fingerprint</a>
with CLHash, one would have to combine multiple hashes, exactly like
we did for the 128-bit UMASH fingerprint.</p><p>Actual cryptographic hash functions provide stronger bounds in a much
more pessimistic model; however they’re also markedly slower than
non-cryptographic hashes. <a href="https://github.com/BLAKE3-team/BLAKE3">BLAKE3</a>
needs at least 66 ns to hash short inputs, and achieves a peak throughput
of 5.5 GB/s. Even the <a href="https://github.com/rust-lang/rust/issues/29754">reduced-round SipHash-1-3</a>
hashes short inputs in 18-40 ns and longer ones at a peak throughput
of 2.8 GB/s. That’s the price of their pessimistically adversarial
security model. Depending on the application, it can make sense to
consider a more restricted adversary that must prepare its dirty deed
before the hash function’s parameters are generated at random, and
still ask for provable bounds on the probability of collisions.
That’s the niche we’re targeting with UMASH.</p><p>Clearly, the industry is comfortable with no bound at all.
However, even in the absence of
<a href="https://www.131002.net/siphash/#at">seed-independent collisions</a>,
timing side-channels in a data structure implementation could
theoretically leak information about colliding inputs, and iterating
over a hash table’s entries to print its contents can divulge even more
bits. A sufficiently motivated adversary could use something like
that to learn more about the key and deploy an algorithmic denial of
service attack. For example, the linear structure of UMASH (and of
other polynomial hashes like CLHash) makes it easy to combine known
collisions to create exponentially more colliding inputs. There is no
universal answer; UMASH is simply another point in the solution space.</p><p>If reasonable performance coupled with an actual bound on collision
probability <em>for data that does not adaptively break the hash</em> sounds
useful to you,
<a href="https://github.com/backtrace-labs/umash">take a look at UMASH on GitHub</a>!</p><p>The <a href="#but-why">next section</a> will explain why we found it useful to
design another hash function. The rest of the post
<a href="#umash-high-level">sketches how UMASH works</a> and
<a href="#implementation-tricks">how it balances short-input latency and strength</a>,
before <a href="#usage">describing a few interesting usage patterns.</a></p><p><small>The latency and throughput results above were all measured on
the same unloaded 2.5 GHz Xeon 8175M. While we did not disable
frequency scaling (#cloud), the clock rate seemed stable at 3.1
GHz during our run.</small></p><h2 id="a-idbut-whyahow-did-we-even-get-here"><a id="but-why"></a>How did we even get here?</h2><p>Engineering is the discipline of satisficisation: crisply defined
problems with perfect solutions rarely exist in reality, so we must
resign ourselves to satisfying approximate constraint sets “well
enough.” However, there are times when all options are not only
imperfect, but downright sucky. That’s when one has to put on a
different hat, and question the problem itself: are our constraints
irremediably at odds, or are we looking at an under-explored
solution space?</p><p>In the former case, we simply have to want something else. In the
latter, it might make sense to spend time to really understand the
current set of options and hand-roll a specialised approach.</p><p>That’s the choice we faced when we started caching intermediate
results in
<a href="https://help.backtrace.io/en/articles/2428859-web-console-overview">Backtrace’s database</a>
and found a dearth of acceptable hash functions. Our in-memory
columnar database is a core component of the backend, and, like most
analytics databases, it tends to process streams of similar queries.
However, a naïve query cache would be ineffective: our more heavily
loaded servers handle a constant write load of more than 100 events
per second with dozens of indexed attributes (populated column values)
each. Moreover, queries invariably select a large number of data
points with a time windowing predicate that excludes old data… and
the endpoints of these time windows advance with each wall-clock
second. The queries evolve over time, and must usually consider newly
ingested data points.</p><p><a href="https://www.gsd.inesc-id.pt/~rodrigo/slider_middleware14.pdf">Bhatotia et al’s Slider</a>
show how we can specialise the idea of
<a href="http://adapton.org/">self-adjusting or incremental computation</a>
for repeated MapReduce-style queries over a sliding window.
The key idea is to split the data set at stable boundaries (e.g., on
date change boundaries rather than 24 hours from the beginning of the
current time window) in order to expose memoisation opportunities, and
to do so recursively to repair around point mutations to older data.</p><p>Caching fully aggregated partial results works well for static
queries, like scheduled reports… but the first step towards creating
a great report is interactive data exploration, and that’s an activity
we strive to support well, even when drilling down tens of millions of
rich data points. That’s why we want to also cache intermediate
results, in order to improve response times when tweaking a saved
report, or when crafting ad hoc queries to better understand how and
when an application fails.</p><p>We must go back to a
<a href="http://www.umut-acar.org/self-adjusting-computation">more general incremental computation strategy</a>:
rather than only splitting up inputs, we want to stably partition the
data dependency graph of each query, in order to identify shared
subcomponents whose results can be reused. This finer grained
strategy surfaces opportunities to “resynchronise” computations, to
recognize when different expressions end up generating a subset of
identical results, enabling reuse in later steps. For example, when
someone updates a query by adding a selection predicate that only
rejects a small fraction of the data, we can expect to reuse some of
the post-selection work executed for earlier incarnations of the
query, if we remember to key on the selected data points rather than
the predicates.</p><p>The complication here is that these intermediate results tend to be
large. Useful analytical queries start small (a reasonable query
coupled with cache/transaction invalidation metadata to stand in for
the full data set), grow larger as we select data points, arrange them
in groups, and materialise their attributes, and shrink again at the
end, as we summarise data and throw out less interesting groups.</p><p>When caching the latter shrinking steps, where resynchronised reuse
opportunities abound and can save a lot of CPU time, we often
find that storing a fully materialised representation of the cache key
would take up more space than the cached result.</p><p>A classic approach in this situation is to fingerprint cache keys with
a cryptographic hash function like
<a href="https://en.wikipedia.org/wiki/BLAKE_(hash_function)">BLAKE</a>
or <a href="https://en.wikipedia.org/wiki/SHA-3">SHA-3</a>, and store a
compact (128 or 256 bits) fingerprint instead of the cache key: the
probability of a collision is then so low that we might as well assume
any false positive will have been caused by a bug in the code or a
hardware failure. For example,
<a href="https://users.ece.cmu.edu/~omutlu/pub/memory-errors-at-facebook_dsn15.pdf#page=3">a study of memory errors at Facebook</a>
found that uncorrectable memory errors affect 0.03% of servers each
month. Assuming a generous clock rate of 5 GHz, this means each
clock cycle may be afflicted by such a memory error with probability
\(\approx 2.2\cdot 10^{-20} &gt; 2^{-66}.\) If we can guarantee that
distinct inputs collide with probability significantly less than
\(2^{-66}\), e.g., \(&lt; 2^{-70},\) any collision is far
more likely to have been caused by a bug in our code or by
hardware failure than by the fingerprinting algorithm itself.</p><p>Using cryptographic hashes is certainly safe enough, but requires a lot of
CPU time, and, more importantly, worsens latency on smaller keys (for
which caching may not be that …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/">https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</a></em></p>]]>
            </description>
            <link>https://engineering.backtrace.io/2020-08-24-umash-fast-enough-almost-universal-fingerprinting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24260020</guid>
            <pubDate>Mon, 24 Aug 2020 12:39:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Year of Nushell]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24259914">thread link</a>) | @rainworld
<br/>
August 24, 2020 | https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html | <a href="https://web.archive.org/web/*/https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <section>
      

      <p>Hard to imagine that it’s already been a year since Nu first went public. At the time, it was largely a demo of what could be possible, but still needed quite a bit of work to make it ready for everyday use. A year later and we’ve learned a lot, and made a few mistakes along the way. In this post, we look back over the year and see how we did and where we might be going in the future.</p>



<p>When Nu first started, it started with a simple idea: the output of <code>ls</code>, <code>ps</code>, and <code>sysinfo</code> should all output the same thing. Taking a page from PowerShell, we explored outputting structured data and quickly settled on a table design that would support the output of each of the three commands, with the added ability of streaming the output as it became available.</p>

<p>Around this idea, we then built a set of “filters”, like the <code>where</code> clause, borrowed from SQL, and a growing set of data types we would support natively.  Soon, we were able to write more complex statements like <code>ls | where size &gt; 10kb</code>. This became the crux of the idea - commands that output values from a core set of data types into a stream, composed together with the traditional UNIX pipe (<code>|</code>), so that you could build up a complex set of commands that work over the data as it streams through.</p>



<h2 id="contributors">Contributors</h2>

<p>Before we got started talking about Nushell today, we wanted to give a <em>big</em> “thank you!” to everyone who has contributed to Nu to get us to this point. Nu is what it is because of your help.</p>

<p>1ntEgr8, AaronC81, AdminXVII, aeosynth, aeshirey, aidanharris, almindor, Aloso, Amanita-muscaria, amousa11, andrasio, Andrew-Webb, arashout, arnaldo2792, avandesa, avranju, bailey-layzer, BatmanAoD, bndbsh, Bocom, boisgera, Borimino, BradyBromley, BurNiinTRee, Byron, candostdagdeviren, casidiablo, charlespierce, chhetripradeep, cjpearce, coolshaurya, cristicismas, DangerFunPants, daschl, daveremy, davidrobertmason, Delapouite, dependabot[bot], Detegr, devnought, Dimagog, djc, drmason13, DrSensor, elichai, eltonlaw, EmNudge, eoinkelly, equal-l2, est31, fdncred, filalex77, Flare576, gilesv, gorogoroumaru, GuillaumeGomez, hdhoang, he4d, hilias, HiranmayaGundu, hirschenberger, homburg, iamcodemaker, incrop, ineol, Jacobious52, jankoprowski, JCavallo, jdvr, jerodsanto, JesterOrNot, johnae, johnterickson, jonathandturner, JonnyWalker81, jonstodle, JosephTLyons, jzaefferer, k-brk, Kelli314, klnusbaum, kloun, kornelski, kubouch, kvrhdn, landaire, lesichkovm, LhKipp, lightclient, lincis, lord, luccasmmg, marcelocg, matsuu, mattclarke, mattyhall, max-sixty, mfarberbrodsky, mhmdanas, mike-morr, miller-time, mistydemeo, mlbright, mlh758, morrme, nalshihabi, naufraghi, nespera, neuronull, nickgerace, nmandery, notryanb, oknozor, orf, orientnab, oskarskog, oylenshpeegul, pag4k, Paradiesstaub, philip-peterson, piotrek-szczygiel, pizzafox, pka, pmeredit, pontaoski, Porges, pulpdrew, q-b, quebin31, rabisg0, ramonsnir, rimathia, ritobanrc, rnxpyke, romanlevin, routrohan, rrichardson, rtlechow, rutrum, ryuichi1208, Samboy218, samhedin, sandorex, sdfnz, sebastian-xyz, shaaraddalvi, shiena, siedentop, Sosthene-Guedon, Southclaws, svartalf, taiki-e, Tauheed-Elahee, tchak, thegedge, tim77, Tiwalun, twe4ked, twitu, u5surf, UltraWelfare, uma0317, utam0k, vsoch, vthriller, waldyrious, warrenseine, wycats, yaahc, yahsinhuangtw, yanganto, ymgyt, zombie110year</p>



<p>Nushell is an interactive programming language for working with your files, your system, and your data as a shell, a notebook, and more.</p>

<h2 id="nu-is-more-than-a-shell">Nu is more than a shell</h2>

<p>It’s easy to think of Nushell as just a shell. It’s even got ‘shell’ in the name. It’s the first and probably main way you’ll interact with it. So why say it’s “more than a shell”?</p>

<p>In truth, Nushell is actually two things at once: Nu and Nushell. Nu is an interactive language for processing streams of structured data, data that you’re probably getting from files, your system, a web address, etc.</p>

<p>So what’s Nushell?</p>

<p>Nushell is taking the Nu language and putting it into a shell, and building around it a set of shell features to make it feel comfortable to use as a login shell. Completions, pretty error messages, and the like.</p>

<p>When we say that “Nu is more than a shell”, does that imply that Nu can be used in other places, too? Absolutely. We’ve got two more hosts that let you run Nu, a <a href="https://github.com/nushell/nu_jupyter">jupyter-based</a> host that lets you run Nu in jupyter notebooks, and a <a href="https://github.com/nushell/demo">WebAssembly-based</a> host that we use to create the <a href="https://www.nushell.sh/demo/">Nu playground</a></p>

<p>The idea of Nu runs deeper than just the shell, to being a language that’s relatively easy to learn, yet powerful enough to do real work with your system, to process large amounts of data, to interactively let you iterate quickly on an idea, to invite exploration by building up a pipeline one piece at a time. There’s really no shortage of ambition for where we hope to go.</p>



<p>Nu’s original design has proven surprisingly robust thus far. Some of its core ideas are continuing to pay dividends a year later. Let’s look at the designs that still feel right.</p>

<h2 id="pipelines-are-infinite">Pipelines are infinite</h2>

<p>When we first started writing Nu, we took a few shortcuts that had us processing all the data in a pipeline at once. Very quickly, we realize this wasn’t going to work. External commands (think <code>cat /dev/random</code>) can output an infinite stream of data, and the system needs to be able to handle it. Understanding this, we transitioned to a different model: data flows between command as infinite streams of structured data. As the data is processed, we avoid collecting the data whenever possible to allow this streaming to happen.</p>

<p>Because the streams can be infinite, even the printing out of tables is done a batch at a time.</p>

<h2 id="separating-viewing-data-from-the-data-itself">Separating viewing data from the data itself</h2>

<p>Coming from other shells, the idea of running <code>echo</code> or <code>ls</code> goes hand-in-hand with printing something to the terminal. It’s difficult to see that there two steps going on behind the scenes: creating the information and then displaying it to the screen.</p>

<p>In Nu, these two steps are distinct. The <code>echo</code> command gets data ready to output into stream, but doesn’t do any work to print it to the screen. Likewise, <code>ls</code> gets ready to output a stream of file and directory entries, but doesn’t actually display this information.</p>

<p>That’s because both <code>echo</code> and <code>ls</code> are lazy commands. They’ll only do the work if the data is pulled from the stream. As a result, the step of viewing the data is separate from the step of creating it.</p>

<p>Behind the scenes, Nu converts a standalone <code>ls</code> to be the pipeline <code>ls | autoview</code>. The work of viewing comes from <code>autoview</code> and it handles working with the data and calling the proper viewer. In this way, we’re able to keep things as structured data for as long as possible, and only convert it to be displayed as the final step before being shown to the user. (note: the wasm-based demo and jupyter do a similar step, but instead of adding <code>autoview</code>, they add <code>to html</code>)</p>

<h2 id="rich-data-types">Rich data types</h2>

<p>In a similar way to working with structured data, rather than only plain text, Nu takes a different approach to data types as well. Nu takes the traditional set of basic types, like strings and numbers, and extends them into a richer set of basic data primitives.</p>

<p>Numbers are represented internally as big numbers and big decimals, rather than integers and floating point machine-based representations. This gives us more flexibility to do math more accurately, and generally removes the worry of whether the number you want to work with will fit in the integer or float size you have available.</p>

<p>We carry this further, by also representing values common in modern computer usage: URLs, file paths, file sizes, durations, and dates are all examples of built-in data types. By building them in, Nu can have better syntax and type checking with their use.</p>

<p>For example, in Nu it’s possible to write <code>= 1min + 1sec</code> to create a duration that is one minute one second long.  You can also use the file sizes, like being able to filter a directory list by the size of the file <code>ls | where size &gt; 10kb</code>.</p>

<p>Nu also can help if you try to mix types that shouldn’t. For example, if you had written: <code>= 1min + 1kb</code> it seems you didn’t mean to add time and file sizes together, and Nu gives you an error if you do:</p>

<div><div><pre><code>error: Coercion error
  ┌─ shell:1:3
  │
1 │ = 1min + 1kb
  │   ^^^^   --- filesize(in bytes)
  │   │       
  │   duration
</code></pre></div></div>

<p><em>note: we’ll be making this error better in the future</em></p>

<p>Data in Nu also isn’t just the value, but it’s also a set of metadata that comes with the value. For example, if you load data from a file using the <code>open</code> command, we track the place that it’s loaded along with the data that’s loaded. We can see this metadata using the <code>tags</code> command:</p>

<div><div><pre><code>open package.json | tags
───┬─────────────────┬──────────────────────────────────────────────────────────────────────────────
 # │      span       │                                    anchor                                    
───┼─────────────────┼──────────────────────────────────────────────────────────────────────────────
 0 │ [row end start] │ /home/jonathan/Source/servo/tests/wpt/web-platform-tests/webrtc/tools/packag 
   │                 │ e.json                                                                       
───┴─────────────────┴──────────────────────────────────────────────────────────────────────────────
</code></pre></div></div>

<p>This extra information allows us to know how to view the contents, and even save you time when you use the <code>save</code> command, as it will use the original location by default.</p>

<h2 id="keeping-it-fun">Keeping it fun</h2>

<p>Something we attached to early on was the idea that Nu should be fun. It should be fun to work on, it should be fun to contribute to, and it should be fun to use.</p>

<p>Nu is really about play. You play with your data, you play with the structures that make up your files and filesystem, you play with what web services give back to you. Everything about Nu is made to invite you to explore how things work and how data is put together. As you play, you learn more about Nu works and how to better use it. We firmly believe …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</a></em></p>]]>
            </description>
            <link>https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259914</guid>
            <pubDate>Mon, 24 Aug 2020 12:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why People Become Internet Trolls]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24259728">thread link</a>) | @Gedxx
<br/>
August 24, 2020 | https://dradambell.com/why-people-become-internet-trolls/ | <a href="https://web.archive.org/web/*/https://dradambell.com/why-people-become-internet-trolls/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="1c056633" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div>
<p><span>When I was 10 years old and first introduced to the miracle of the World Wide Web, chat rooms were by far my favorite thing. Talking to random people from all over the world about anything you want — what more could a bored kid ask for?</span></p>

<p><span>I’d spend hours in these chat rooms, asking my new friends how old they were, what they had for breakfast, and how much pocket money their parents gave them. I shared this experience with a friend who didn’t own a computer and had never used the internet.</span></p>

<p><span>He asked if he could have a go. “Sure!” I said, excited for him to experience the wonder of the internet. Without hesitation, he began typing the worst insults and swear words he could think of. Horrified I had awoken a dark and malevolent force, and fearing he had forever ruined my friendship with strawberry88, I shut down my computer and didn’t invite him to play on the internet again.</span></p>

<p><span>To this day, I remain baffled by this behavior. When faced with the endless possibility of the internet, my childhood friend’s first impulse was to verbally abuse strangers. This innocent 10-year-old had become a troll.</span></p>

<h4 id="02ff"><span>Wretched impulses</span></h4>

<p><span>John Oliver once described the internet as a “dark carnival of humanity’s most wretched impulses.” Was it these wretched impulses that had consumed my childhood friend?</span></p>

<p><span>The act of trolling is best described from where its name&nbsp;<a href="https://www.etymonline.com/word/troll" target="_blank" rel="noreferrer noopener">may have come from</a>&nbsp;— the form of fishing where a lure is dangled off a moving boat.</span></p>

<figure><span><img src="https://miro.medium.com/max/3200/0*f3HYZpvSGgrg1vHC" alt=""></span></figure>

<p><span>The troll casts his bait (the offensive comment) into the water of the internet. An unsuspecting fish (the targeted user) sees the bait and feels compelled to go for it (the defensive comment). Soon they are hooked and reeled in without mercy. But unlike trolling for fish, which delivers a clear and edible reward, the troll’s reward isn’t entirely clear.</span></p>

<p><span>Trolling is a hard concept to define because there are various methods of trolling and differing degrees of depravity. Some are abhorrent, like “suicide baiting,” where trolls encourage vulnerable users to kill themselves, or “RIP trolls” who vandalize Facebook memorial sites of the recently deceased. But others, like “griefers” who play online games in a manner that purposely disrupts other players, are more of a nuisance.</span></p>

<p><span>Who are these trolls, and what drives them?</span></p>

<h4 id="4d5f"><span>The dark tetrad</span></h4>

<p><span>Psychologists have found&nbsp;<a href="https://www.sciencedirect.com/science/article/abs/pii/S0191886914000324" target="_blank" rel="noreferrer noopener">a link between trollish behavior</a>&nbsp;and a set of personality traits called “the dark tetrad.”</span></p>

<figure><span><img src="https://miro.medium.com/max/2974/0*sAMy6kU4hSsBKYQy" alt=""></span></figure>

<p><span>The dark tetrad comprises:</span></p>

<ul>
<li><span>Sadism — deriving pleasure from another’s pain</span></li>
<li><span>Psychopathy — impairment of empathy and remorse</span></li>
<li><span>Machiavellianism — manipulative and emotionally “cold” behavior</span></li>
<li><span>Narcissism — self-involvement and a need for admiration</span></li>
</ul>

<p><span><a href="https://www.academia.edu/41115419/Loneliness_moderates_the_relationship_between_Dark_Tetrad_personality_traits_and_internet_trolling" target="_blank" rel="noreferrer noopener">In a recent study</a>, trolls were positively correlated with three of the four dark tetrad traits, with narcissism being the odd one out. They found trolls were manipulative, lacked empathy, and enjoyed hurting others. Men exhibited these traits more commonly than women and were more likely to troll. Loneliness was also a significant predictor of trolling when in the presence of Machiavellianism or psychopathy.</span></p>

<p><span>Most studies on trolls use internet surveys to collect data, which is questionable: Can we really trust trolls to complete surveys accurately? This method may also not account for those who don’t consider their behavior to be trollish or those unaware of their trollish behavior.</span></p>

<p><span>In the book&nbsp;<a href="https://www.hardiegrant.com/au/publishing/bookfinder/book/troll-hunting-by-ginger-gorman/9781743794357" target="_blank" rel="noreferrer noopener"><em>Troll Hunting</em></a>, journalist Ginger Gorman spends years building relationships with the worst trolls she can find in an attempt to understand what drives them. To her surprise, trolls were not uneducated lost souls who lacked social skills and lived in their mother’s basement. These trolls had partners, children, and full-time jobs. They showed leadership skills as commanders of&nbsp;<a href="https://www.theguardian.com/books/2019/jan/28/it-was-like-being-skinned-alive-ginger-gorman-goes-hunting-for-trolls" target="_blank" rel="noreferrer noopener">large trolling syndicates</a>. They were socially intelligent and able to pinpoint users’ weaknesses with vicious precision. But what was driving them?</span></p>

<p><span>Many saw trolling as a hobby — something that entertained or amused. Some were ideologically driven, attacking anybody opposing their belief system. But both types of troll tended to engage users that threatened their beliefs or sense of self.</span></p>

<p><span>Some of the trolls exhibited dark tetrad traits. In these trolls, she saw a common pattern — excessive internet use with little to no parental supervision between the ages of 11 and 16. But some trolls didn’t fit the dark tetrad personality type. These trolls were pleasant, friendly, and compassionate when she engaged them directly. How could these trolls behave so antisocially online yet appear to function as typical members of society offline?</span></p>

<h4 id="7160"><span>Empathy deficit</span></h4>

<p><span>The human brain was primarily designed for face-to-face interaction. It hasn’t had time to adapt to communication over the internet.</span></p>

<p><span>Nonverbal communication — facial expressions, gestures, and voice qualities — provides the precise social context of an interaction. While the claim that 93% of communication being nonverbal is&nbsp;<a href="https://cornerstone.lib.mnsu.edu/cgi/viewcontent.cgi?article=1000&amp;context=ctamj" target="_blank" rel="noreferrer noopener">inaccurate</a>, it is a crucial part of how we communicate. Words alone can only go so far. Even if we used the full&nbsp;<a href="https://englishlive.ef.com/blog/language-lab/many-words-english-language/" target="_blank" rel="noreferrer noopener">170,000 words</a>&nbsp;currently in use in the English language, we still couldn’t convey what an expressive face or a suggestive voice could.</span></p>

<p><span>Most internet discussions only allow words. Well, words and emojis and GIFs and stickers and all the other substitutes created to replace nonverbal cues.</span></p>

<p><span>If you say something mean to my face and make me cry, you will probably start to feel uncomfortable. Unless you’re especially mean or psychopathic, my distress will trigger an empathic response and lead you to have mercy. If you tweet something mean and make me cry, no amount of emojis can convey what the sight of a grown man weeping can. If there is no social cue to elicit an empathic response, you might continue your tirade of meanness.</span></p>

<p><span>The absence of nonverbal feedback leads to an “empathy deficit,” and this is what sociopaths suffer from.</span></p>

<h4 id="53a2"><span>Toxic disinhibition</span></h4>

<p><span>When you combine an empathy deficit with the anonymity of online interactions, you get “<a href="https://en.wikipedia.org/wiki/Online_disinhibition_effect" target="_blank" rel="noreferrer noopener">toxic disinhibition</a>,” which is more than just the phenomenon of being rude to bar staff after that fifth shot of tequila.</span></p>

<p><span>Anonymity can lead to “<a href="https://en.wikipedia.org/wiki/Deindividuation" target="_blank" rel="noreferrer noopener">deindividuation</a>” — a temporary loss of one’s identity leading to behavior incongruent with one’s character. It explains why groups of civilized people can engage in riots. It also explains trolling. If a lack of nonverbal cues is what makes us detached from the other person’s suffering, deindividuation is what makes us detached from the awareness of our misconduct.</span></p>

<p><span>True anonymity offers protection from real-world social repercussions, and this has profound effects on human behavior. The image-based bulletin board 4chan, where registration isn’t possible and users remain anonymous, has been&nbsp;<a href="https://theconversation.com/4chan-raids-how-one-dark-corner-of-the-internet-is-spreading-its-shadows-68394" target="_blank" rel="noreferrer noopener">infamous as a troll incubator</a>&nbsp;for this reason. When there are no real-world consequences to your actions, it liberates you from a lifetime of societally inhibited behaviors. Society discourages antisocial behavior and encourages prosocial behavior, so it is antisocial behavior that seeks liberation.</span></p>

<p><span>We are a delicate balance between prosocial humans and antisocial primates. When society cannot enforce prosocial human behavior, the antisocial primate may come back into power. And thus the troll is created.</span></p>

<h4 id="f597"><span>Troll begets troll</span></h4>

<p><span>Researchers at Stanford and Cornell universities performed a large-scale data analysis on&nbsp;<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5791909/" target="_blank" rel="noreferrer noopener">over 16 million comments</a>&nbsp;from December 2012 to August 2013 on CNN.com and found 1 in 4 posts flagged as abusive were from users with no prior record of trollish behavior. This suggests trolling isn’t always a full-time occupation and that one may indulge sporadically.</span></p>

<p><span>The researchers could predict the likelihood of trolling based on the nature of other comments in the discussion and the user’s mood. If earlier comments were negative, the propensity to troll was greater. Like a bad mood, trolling is contagious. All it takes is another user’s trollish comment and a bad mood to create an environment in which our inner troll can blossom.</span></p>

<h4 id="b294"><span>The inner troll</span></h4>

<p><span>It is easier to view trolls as bad apples than see them as something inside all of us, waiting for the right environment to let loose. But when we condemn trolls as inherently malicious individuals, we limit our understanding of what may drive these behaviors.</span></p>

<p><span>While RIP trolls or suicide baiters are likely to be dark tetrad personality types who use the internet as an outlet to indulge their darkest impulses, lesser trolls may be part-time participants who will engage with the right combination of a bad day and a noxious environment. We have only begun to scratch the surface in our understanding of trolls, but the evidence we have suggests we may all be vulnerable.</span></p>

<p><span>Is anyone exempt from toxic disinhibition? Few respond to a tweet that offends them with “Excuse me, I really don’t want to be rude, but if I may could I please respectfully disagree with your opinion for these reasons …” While an offhand remark may appear harmless, the less empathic our online interactions collectively become, the greater risk we all stand of becoming trolls. The gentle ripples of impolite tweets may become crashing toxic waves of disinhibited hatred.</span></p>

<p><span>Trolling isn’t black and white, it is somewhere in the grey between prosocial human and antisocial primate. Ultimately, our propensity for antisocial behavior in the physical world is likely to predict similar online behavior.</span></p>

<h4 id="9272"><span>How can we manage our inner trolls?</span></h4>

<p><span>The more accountable we are for our behavior, the less potential we have of becoming trolls. Employing&nbsp;<a href="https://scholarspace.manoa.hawaii.edu/bitstream/10125/41373/1/paper0224.pdf" target="_blank" rel="noreferrer noopener">less anonymity may help</a>, but this raises privacy concerns for many. Anonymity can also be a good thing. Benign disinhibition — the friendly sibling of toxic disinhibition — is where users freely discuss their deepest insecurities and concerns with other users. This can be very therapeutic and shouldn’t be discouraged. But by using anonymity only where it is necessary, we reduce the likelihood of toxic disinhibition.</span></p>

<p><span>Empathy doesn’t come …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dradambell.com/why-people-become-internet-trolls/">https://dradambell.com/why-people-become-internet-trolls/</a></em></p>]]>
            </description>
            <link>https://dradambell.com/why-people-become-internet-trolls/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259728</guid>
            <pubDate>Mon, 24 Aug 2020 11:50:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Generators, Meet XPath]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24259688">thread link</a>) | @fanf2
<br/>
August 24, 2020 | https://jack.wrenn.fyi/blog/xpath-for-2020/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/xpath-for-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
<article>
    <header>
      
      <span>2020-08-22&nbsp;</span>
    </header>

    <p>Using Generators to Modernize a Geriatric Javascript API for <code>$CURRENT_YEAR</code></p>
<span id="continue-reading"></span>
<hr>
<p>How do you find-and-replace text on an HTML page?</p>
<pre><code><span>&lt;div&gt;</span><span>Hello, </span><span>&lt;span&gt;</span><span>human</span><span>&lt;/span&gt;</span><span>!</span><span>&lt;/div&gt;
</span></code></pre>
<p>If the text is neatly neatly isolated inside an HTML element, it's easy; this will do:</p>
<pre><code><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"span"</span><span>)</span><span>.textContent </span><span>= </span><span>"evolved ape"</span><span>;
</span></code></pre>
<p><strong>But here's a puzzle</strong>: how do you you change text that <em>isn't</em> neatly isolated in an HTML element?</p>
<p>You <em>could</em> use <code>innerHTML</code>:</p>
<pre><code><span>let </span><span>elt </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>;
</span><span>elt</span><span>.innerHTML </span><span>= </span><span>elt</span><span>.innerHTML.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>...but this will hose any event listeners registered on <code>elt</code>'s children.</p>
<p>You <em>could</em> grapple onto the nearest selectable element:</p>
<pre><code><span>let </span><span>node </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>.childNodes[</span><span>0</span><span>];
</span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>Yuck; this sort of child-node indexing feels <em>really</em> brittle.</p>
<p><strong>Why can't we just <em>directly</em> select the text nodes containing <code>Hello</code>?</strong></p>
<h2 id="xpath">XPath</h2>
<p><strong>We can!</strong> Enter: <a href="https://en.wikipedia.org/wiki/XPath">XPath</a>, the <em>excessively</em> powerful language for querying XML documents. It's usable in web-browsers with the, uh, <em>descriptively</em>-named method <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/evaluate"><code>document.evaluate</code></a>.</p>
<p>It's a <em>bit</em> of a production to use:</p>
<pre><code><span>let </span><span>xpath </span><span>= </span><span>"//text()[contains(., 'Hello')]"</span><span>; </span><span>// find text nodes containing 'Hello'
</span><span>let </span><span>context </span><span>= </span><span>document</span><span>.body; </span><span>// look in the body element
</span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>; </span><span>// some sorta xml voodoo
</span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE; </span><span>// DEFINITELY MAKE SURE YOU USE THIS

</span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

</span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>) {
  </span><span>let </span><span>node </span><span>= </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
}
</span></code></pre>
<p>Yes, you really need to write <em>all</em> of that. The <code>result_type</code> argument is technically optional, but omit it at your own peril: without it, you must instead stream results via <code>iterateNext</code>, and this will crash with an exception if you dare <em>modify</em> the queried elements!</p>
<p>It's no wonder <code>document.evaluate</code> is seldom used. <strong>Can we improve on it?</strong></p>
<h2 id="iterizing-xpath-queries">Iterizing XPath Queries</h2>
<p>Yes, with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators"><strong>generators</strong></a>! We can exploit the implicit iterability of generators to modernize this unwieldy API:</p>
<pre><code><span>Document</span><span>.</span><span>prototype</span><span>.xpath </span><span>= </span><span>Element</span><span>.</span><span>prototype</span><span>.</span><span>xpath </span><span>=
  </span><span>function* </span><span>xpath</span><span>(</span><span>xpath</span><span>) {
    </span><span>let </span><span>context </span><span>= </span><span>this </span><span>instanceof </span><span>Document </span><span>? </span><span>document</span><span>.documentElement </span><span>: </span><span>this</span><span>;
    </span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>;
    </span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE;
    </span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

    </span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>)
      </span><span>yield </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  };
</span></code></pre>
<p>And because the result of this function is iterable, we can use it with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax">spread syntax</a>:</p>
<pre><code><span>[</span><span>...</span><span>document</span><span>.</span><span>xpath</span><span>(</span><span>"//text()[contains(., 'Hello')]"</span><span>)</span><span>].
  </span><span>forEach</span><span>(</span><span>node </span><span>=&gt; </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>))</span><span>;
</span></code></pre>
</article>

        </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/xpath-for-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259688</guid>
            <pubDate>Mon, 24 Aug 2020 11:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golden Age]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24259618">thread link</a>) | @_squared_
<br/>
August 24, 2020 | https://gaby.dev/posts/golden-age | <a href="https://web.archive.org/web/*/https://gaby.dev/posts/golden-age">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			
			<h4>Published Sun Aug 23 2020</h4>
			<hr>
			<blockquote>
<p>He settled the black terry sweat-band across his forehead, careful not to disturb the flat Sendai dermatrodes.<br>He closed his eyes.<br>A gray disk, the color of Chiba sky.<br>Disk beginning to rotate, faster, becoming a sphere of paler gray. Expanding –<br>And flowed, flowered for him, fluid neon origami trick, the unfolding of his distanceless home, his country, transparent 3D chessboard extending to infinity. Inner eye opening to the stepped scarlet pyramid of the Eastern Seaboard Fission Authority burning beyond the green cubes of the Mitsubishi Bank of America, and high and very far away he saw the spiral arms of military systems, forever beyond his reach.<br>And somewhere he was laughing, in a white-painted loft, distant fingers caressing the deck, tears of release streaking his face.</p>
<p>– William Gibson, <em>Neuromancer</em> (edited)</p>
</blockquote>
<p>I believe when times are tough we should take a moment to take a breath and marvel at the world around us. A flower blossoming towards the sky, a rose-tinted cloud at dawn, a painter's thoughtful stroke on a canvas.<br>And while I cultivate many passions, I often marvel at technology - because oh my, there is so much to marvel at!</p>
<p>It would be an understatement to say that a lot has happened since humankind cobbled together a bunch of silicium and electrocuted it into <em>thinking</em>, of all things. And while we have not quite reached Gibson's vision of cyberspace, I'd argue that we are, more likely than not, in a tech "golden age".</p>
<p>This might come as a surprise to you. After all, we're starting to see <a href="https://www.nature.com/news/the-chips-are-down-for-moore-s-law-1.19338">the end of Moore's law</a>, a <a href="https://en.wikipedia.org/wiki/Big_Tech">few tech giants</a> have leveraged consumers' laziness to build an advertising market bubble that rules the world's economy, and a rising superpower's "<a href="https://en.wikipedia.org/wiki/Cyberspace_Administration_of_China">Cyberspace Administration</a>" managed to deny 1.8 billion people <a href="https://en.wikipedia.org/wiki/Great_Firewall">free, uncensored access to information</a>.</p>
<p>And still, especially for hackers, makers, post-dotcom entrepreneurs and other digital-age freaks, now more than ever is the time to get excited.</p>
<p>The COVID-19 pandemic has catapulted what was left of the old world into digitalization. Millions of apes wired to one another waited long months in their home for their screens to blink and tell them "lockdown's over". No 1984 science-fiction writer could have imagined such an alien scenario, nor its consequences.</p>
<p>As hordes of white-collar workers download videoconferencing software, unknowingly settling down in cyberspace for an ever-expanding portion of their lives, the curious among them will start to notice this is a land of opportunities.</p>
<p>Here, most resources can be leased dirt cheap and in unimaginable quantities - data storage, bandwidth, computing power. A common form of business are <a href="https://en.wikipedia.org/wiki/Software_as_a_service">SaaS</a> products, leased access to computer programs that, if made correctly, can accommodate a virtually unlimited number of tenants, effectively printing cash.</p>
<p>While we haven't figured out <a href="https://en.wikipedia.org/wiki/Brain%E2%80%93computer_interface">dermatrodes</a> yet, you can dive in on a wide range of devices, and soon from pretty much anywhere on <a href="https://en.wikipedia.org/wiki/Starlink">this planet</a>, and perhaps <a href="https://en.wikipedia.org/wiki/Interplanetary_Internet">the next one</a>, too. Oh, you're also joining a growing population of <a href="https://internetworldstats.com/stats.htm">4.8 billion</a> humans - other inhabitants include <a href="https://en.wikipedia.org/wiki/Internet_of_things">connected IoT devices</a>, <a href="https://en.wikipedia.org/wiki/Web_crawler">crawlers</a> and other cyber automatons, and the occasional <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">neural network</a>, which might have a <a href="https://liamp.substack.com/p/my-gpt-3-blog-got-26-thousand-visitors">blog</a> - in fact, you can't really <em>know</em> for sure that this very piece you're reading hasn't been written by one.</p>
<p>So go ahead, explore, learn, build something. Whatever it is you're thinking of, you can probably learn about, build, ship, and scale it on the Internet. Your paychecks live there too, as will your food orders, entertainment, relationships...</p>
<p>Meatspace is becoming more irrelevant each and every day.<br>Now is your time to punch deck and get yourself a place in cyberspace.</p>
<p>Welcome to the Golden Age.</p>

		</article></div>]]>
            </description>
            <link>https://gaby.dev/posts/golden-age</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259618</guid>
            <pubDate>Mon, 24 Aug 2020 11:29:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of Venmo (2014)]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24259509">thread link</a>) | @saadalem
<br/>
August 24, 2020 | https://kortina.nyc/essays/origins-of-venmo/ | <a href="https://web.archive.org/web/*/https://kortina.nyc/essays/origins-of-venmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I often speak about the origins of Venmo in person and finally wrote down the story here to share with our latest intern class that started this week. (You can also watch an excellent video of Iqram speaking about even more of the history of Venmo <a href="https://www.youtube.com/watch?v=aX7JCCCmLJw">here</a>. It’s a good place to pickup the story where this post leaves off.)</p>

<p>My friend Iqram and I started Venmo to solve a very simple problem for ourselves and for our friends: we noticed that we were still using cash and checks to pay each other back and thought this was silly. Everyone should be using PayPal to pay each other back, but no one we knew was. We thought something must be not quite right about the PayPal experience for casual use, and we decided to design something that felt “right,” something that felt consistent with all of the other mobile tools we used to interact with our friends, like SMS, Gmail, Facebook, etc. This is the story of how we got to Venmo.</p>

<h2 id="penn">Penn</h2>

<p>Iqram and I met as randomly paired freshman year roommates at the University of Pennsylvania in 2001. We’ve been great friends ever since.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iqram-kortina-college.png">
<figcaption>Oldest pic I could find of me and Iqram.</figcaption>
</figure>

<p>Iqram studied computer science at Penn. I started in computer science, but found that much of the learning I was doing happened while I was doing homework exercises, and I was getting no additional value out of the University. I couldn’t justify tuition costs when I was only learning by spending time doing programming exercises, and I developed a hypothesis that I would maximize the value of tuition costs by studying the least practical subjects possible, the things I would not get to do after graduation / outside of University, like reading and discussing great books with a group of incredibly smart students and professors (this backfired, btw–liberal arts is very practical stuff!). I eschewed big lectures and things like On Campus Recruiting, and tried to spend as much time possible in seminars and writing workshops. I ended up with majors in Philosophy and Creative Writing and minors in Computer Science and Logic.</p>

<p>I remained interested in building things during this time, however, and always took the opportunity to build websites for various clubs I was in or for friends with bands, etc.</p>

<p>During our senior year, Iqram and I built our first real project together, a college classifieds site called My Campus Post. It was our first taste of all night coding sessions to get a product to market, and we learned a bunch about grassroots marketing and retention challenges that arise from products with seasonal usage.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/mycampuspost.png">
<figcaption>My Campus Post marketing paraphernalia.</figcaption>
</figure>

<p>I loved spending all of my time reading philosophy, working on fun side projects, and actively ignoring practical things like interviewing for jobs, but I clearly remember the day when my Mom was in town for graduation and she asked, “What are you doing after you graduate?” I was sitting on the floor of my dorm room, and I remember being very scared about the question, thinking, “I have no idea what I want to do with my life,” but also feeling OK about the short term, eventually answering, “I don’t have to move out of my dorm until 2 weeks after graduation. I’ll figure something out.”</p>

<h2 id="post-grad-door-to-door-sales">Post Grad Door to Door Sales</h2>

<p>Iqram ended up finding a cheap sublet in West Philly, and we spent the summer building websites for restaurants, salons, bars, etc. We went door to door selling, “Hey, you need a website. We’ll build it for $500…. $100? OK, deal.” We learned a lot as we tried to abstract the sites we were building into something modular, and we got a lot of experience pitching and hearing “no.” One “no” that I still regret more than most of the others I have subsequently heard (for much bigger deals) was for this amazing Pakistani restaurant, Kabobeesh, that served a chicken kabob sandwich on fresh naan bread for $3.50: we tried to sell them a site for 100 chicken rolls, but failed to close them.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/kabobeesh.png">
<figcaption>Kabobeesh: I recommend the chicken rolls and chicken karahi.</figcaption>
</figure>

<p>Once, we were chatting at a bar about how we might pad our sporadic income with some part time jobs. We noticed the bar was hiring, got two applications, and started filling them out. We spent a few minutes getting through all the basic background stuff, education, personal info, and got to the references section. We didn’t really have past employers to list at the time, so I put Iqram as a reference, and he put me. We were still rooming together at the time, so we had the same street address. We did not get a call back.</p>

<h2 id="swooge-and-philafunk">Swooge and Philafunk</h2>

<p>During this period, we were always also working on startup-y things, like a realtime website analytics tool called Swooge (which now reminds me of Chartbeat + Google Analytics) and a web based music selling platform, Philafunk (it was like iTunes + MySpace).</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/philafunk.jpg">
<figcaption>Philafunk site and flyer.</figcaption>
</figure>

<p>After working on a few of these, we realized we had a lot to learn about building a successful startup, so we decided to go find one and work there. Many of these projects we worked on were still in my opinion great ideas and solid evidence that execution matters much more than the idea.</p>

<h2 id="iminlikewithyou">iminlikewithyou</h2>

<p>So we found this NYC company, iminlikewithyou.com, that was just getting started out of Y Combinator, and we joined as 2 of the first 3 employees, all engineers starting together the day we moved to NYC. We had a talented team, built a really innovative, immersive web experience, and learned a bunch about doing startups for real. Eventually, the company pivoted from the original flirting-site idea into a casual games company (OMGPOP), and we both left because we weren’t interested in building games.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iminlikewithyou.png">
<figcaption>iminlikewithyou site.</figcaption>
</figure>

<h2 id="ticketleap-and-bitly">Ticketleap and Bit.ly</h2>

<p>Iqram worked at Ticketleap as the VP of Engineering for a few years, and I bounced around and ended up spending a bunch of time working at Betaworks, on Bit.ly.</p>

<p>We both learned a lot during this period, but I looked forward to the time when we would work on a new project together, with more knowledge and experience this time. Over the years, I often brought up this idea, but the timing was never quite right.</p>

<h2 id="exploring-new-product-ideas">Exploring New Product Ideas</h2>

<p>In early 2009, Iqram chatted me mentioning that he was feeling ready to move on from Ticketleap, and I remember thinking, “Great let’s do this.” We began getting together on weekends (he was in Philly and I was in NYC) to hack on different ideas.</p>

<h2 id="yogorino">Yogorino</h2>

<p>We had a friend in Philadelphia who was opening a yogurt shop, and while helping her get up and running technically, we realized how horrible traditional point of sales software was. We prototyped a web based point of sales software that would turn any laptop into a cash register with a $50 USB magtek swiper. As we thought about it more, it seemed like this would present a really challenging distribution problem (we remembered our days of door to door restaurant sales…). Plus, although this was designed to solve a problem for one of our friends, it wasn’t software that we would be using ourselves daily.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/cardswiper.png">
<figcaption>Web POS prototype.</figcaption>
</figure>

<h2 id="back-to-music">Back to Music</h2>

<p>Another idea we explored came to us at a local jazz show: we thought, “It would be awesome to be able to download this show by sending a text message to this band right now, and then have an mp3 show up in our email.” This was getting closer to the Venmo concept we ultimately arrived at, and the detailed wireframes we constructed for this definitely informed a lot of the original Venmo service.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/rootsbuy.png">
<figcaption>Wireframe for selling music downloads via SMS.</figcaption>
</figure>

<p>This concept even bore the Venmo name. Lots of people ask about the origin of the name. The brainstorming process was one of many we tried and was not important as the requirements. We were exploring the Latin root vendere “sell” and mo for mobile, but purely as a means to get to a name that (1) was short, 5-6 letters, (2) could be a verb, (3) didn’t have a unintuitive spelling, and (4) was cheap. Venmo was available on GoDaddy and met the important criteria, so we grabbed it.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/visionslide.png">
<figcaption>A slide from our deck for an SMS music service.</figcaption>
</figure>

<h2 id="discovering-venmo">Discovering Venmo</h2>

<p>One of the weekends we were getting together to work on this idea, Iqram was visiting me in NYC and left his wallet in Philly. I covered him for the whole weekend, and he ended up writing me a check to pay me back. It was annoying for him to have to find a checkbook to do this, and annoying for me to have to go to the bank if I wanted to cash it (I never did). We thought, “Why are we still doing this? We do everything else with our phones. We should definitely be using PayPal to pay each other back. But we don’t, and none of our friends do.”</p>

<p>So we decided, let’s just try to solve this problem, and build a way to pay each other back that feels consistent with all of the other experiences we have in apps we use with our friends.</p>

<p>We got pretty excited about this idea, and thought, “Surely someone else must be doing this.” We found a laptop and started googling, and soon came across Obopay: a way to send money to anyone directly from your cell phone. They had recently raised $70M from Nokia, and we thought, “Uh-oh.” But then we poked around the website and the product and found that there was no feel and it seemed a little clunky and not like something anyone we knew would ever use.</p>

<h2 id="evolution-of-the-note">Evolution of the Note</h2>

<p>We got a prototype working pretty quickly. It worked over SMS, and was dead simple. To send iqram $20, text “iqram 20” to our number (a hacked Google Voice account, because the alternative, Textmarks, required that you prefix every text message with a keyword–this was back in the days before Twilio…). The recipient saw “kortina paid you $20.”</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/gvhack.png">
<figcaption>Google Voice SMS hack.</figcaption>
</figure>

<p>Right after we got this working we decided we needed to have a note with each payment so we could keep track of what all of these random amounts were for: “iqram 20 for thai lunch at Nooch.”</p>

<p>The interface was SMS, so we immediately thought, of course it would only be natural for the person on the other end to see the message, so we updated …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kortina.nyc/essays/origins-of-venmo/">https://kortina.nyc/essays/origins-of-venmo/</a></em></p>]]>
            </description>
            <link>https://kortina.nyc/essays/origins-of-venmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259509</guid>
            <pubDate>Mon, 24 Aug 2020 11:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BPF Portability and CO-Re (Compile Once Run Everywhere)]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24259499">thread link</a>) | @nyellin
<br/>
August 24, 2020 | https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html | <a href="https://web.archive.org/web/*/https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>What does portability mean in BPF context? What are the challenges of writing portable BPF programs that developers need to deal with? This post will describe BPF portability problem and how BPF CO-RE (Compile Once – Run Everywhere) is helping to address this problem.</p>
<!--truncate-->

<h2>BPF: state of the art</h2>
<p>Since the inception of (e)BPF, it’s been a constant priority for the BPF community to simplify BPF application development as much as possible, make it as straightforward and familiar of an experience as it would be for a user-space application. And with the steady progress around BPF programmability, writing BPF programs has never been easier.</p>
<p>Despite these usability improvements, though, one aspect of BPF application development has been neglected (mostly for technical reasons): portability. What does "BPF portability" mean, though? We define <strong>BPF portability</strong> as the ability to write a BPF program that will successfully compile and pass kernel verification, and will work <strong>correctly</strong> across <em>different kernel versions</em> without the need to recompile it for each particular kernel.</p>
<p>This note describes the BPF portability problem and our solution to it: BPF CO-RE (Compile Once – Run Everywhere). First, we’ll look at the BPF portability problem itself, describing why it is a problem and why it’s important to solve it. Then, we will outline high-level components of our solution, BPF CO-RE, and will give a glimpse into the pieces of the puzzle that needed to be put together to make it happen. We’ll conclude with a tutorial of sorts, describing the user-visible API of the BPF CO-RE approach and demonstrating its application with examples.</p>
<h2>The problem of BPF portability</h2>
<p>A BPF program is a piece of user-provided code which is injected straight into a kernel. Once loaded and verified, BPF programs execute in kernel context. These programs operate inside kernel memory space with access to all the internal kernel state available to it. This is extremely powerful and is one of the reasons why BPF technology is successfully used in so many varied applications. However, this powerful capability also creates the BPF portability pains we have today: BPF programs do not control memory layout of a surrounding kernel environment. They have to work with what they get from independently developed, compiled, and deployed kernels.</p>
<p>Additionally, kernel types and data structures are in constant flux. Different kernel versions will have struct fields shuffled around inside a struct, or even moved into a new inner struct. Fields can be renamed or removed, their types changed, either into some trivially-compatible ones or completely different ones. Structs and other types can get renamed, or they can be conditionally compiled out (depending on kernel configuration), or just plain removed between kernel versions.</p>
<p>In other words, things change all the time between kernel releases and yet BPF application developers are expected to cope with this problem somehow. How is it even possible to do anything useful with BPF today considering this ever-changing kernel environment? There are a few reasons for this.</p>
<p>First, not all BPF programs need to look into internal kernel data structures. One example is <code>opensnoop</code> tool, which relies on kprobes/tracepoints to track which processes open which files, and just needs to capture a few syscall arguments to work. As syscall parameters offer a stable ABI, these don’t change between kernel versions and as such portability is not a concern to begin with. Unfortunately, applications like this are quite rare. These types of applications are also typically quite limited in what they can do.</p>
<p>So, additionally, BPF machinery inside kernel provides a limited set of "stable interfaces" that BPF programs can rely on to be stable between kernels. In reality, underlying structures and mechanisms do change, but these BPF-provided stable interfaces abstract such details from user programs.</p>
<p>As one example, for networking applications it is usually enough to look at a limited set of <code>sk_buff</code>'s attributes (and packet data, of course) to be extremely useful and versatile. To that end, BPF verifier provides a stable <strong><code>__sk_buff</code></strong> "view" (notice underscores in front), which shields BPF programs from changing <code>struct sk_buff</code> layout. All the <code>__sk_buff</code> field accesses are transparently rewritten into an actual <code>sk_buff</code> accesses (sometimes quite elaborate ones – doing a bunch of internal pointer chasing before finally fetching requested field). Similar mechanisms are available to a bunch of different BPF program types. They are done as program type-specific BPF contexts understood by BPF verifier. So, if you are developing a BPF program with such context, consider yourself lucky, you can blissfully live in a nice illusion of stability.</p>
<p>But as soon as you need to get a glimpse at any raw internal kernel data (e.g., very commonly a <code>struct task_struct</code> which represents a process/thread and contains a treasure trove of process information), you are on your own. It is commonly the case for tracing, monitoring, and profiling applications, which are a huge class of extremely useful BPF programs.</p>
<p>In such cases, how do you make sure you are not reading garbage data when some kernel added an extra field before the field you thought is, say, at offset 16 from the start of <code>struct task_struct</code>? Suddenly, for that kernel, you'll need to read data from, e.g., offset 24. And the problems don't end there: what if a field got renamed, as was the case with <code>thread_struct</code>'s <code>fs</code> field (useful for accessing thread-local storage), which got renamed to <code>fsbase</code> between 4.6 and 4.7 kernels. Or what if you have to run on two different configurations of a kernel, one of which disabled some specific feature and completely compiled out parts of the struct (a common case for additional accounting fields, which are optional, but extremely useful if present)? All this means that you can no longer compile your BPF program locally using kernel headers of your dev server and distribute it in compiled form to other systems, while expecting it to work and produce correct results. This is because kernel headers for different kernel versions will specify a different memory layout of data your program relies on.</p>
<p>So far, people have been dealing with this problem by relying on <a href="https://github.com/iovisor/bcc/">BCC</a> (BPF Compiler Collection). With BCC, you embed your BPF program C source code into your user-space program (control application) <em>as a plain string</em>. When control application is eventually deployed and executed on target host, BCC invokes its embedded Clang/LLVM, pulls in local kernel headers (which you have to make sure are installed on the system from correct <code>kernel-devel</code> package), and performs compilation on the fly. This will make sure that memory layout that BPF program expects is exactly the same as in the target host's running kernel. If you have to deal with some optional and potentially compiled-out stuff in kernel, you'll just do <code>#ifdef</code>/<code>#else</code> guarding in your source code to accommodate such hazards as renamed fields, different semantics of values, or any optional stuff not available on current configuration. Embedded Clang will happily remove irrelevant parts of your code and will tailor BPF program code to specific kernel.</p>
<p>This sounds great, doesn't it? Not quite so, unfortunately. While this workflow works, it's not without major drawbacks.</p>
<ul>
<li><p>Clang/LLVM combo is a big library, resulting in big fat binaries that need to be distributed with your application.</p></li>
<li><p>Clang/LLVM combo is resource-heavy, so when you are compiling BPF code at start up, you'll use a significant amount of resources, potentially tipping over a carefully balanced production workfload. And vice versa, on a busy host, compiling a small BPF program might take minutes in some cases.</p></li>
<li><p>You are making a big bet that the target system will have kernel headers present, which most of the time is not a problem, but sometimes can cause a lot of headaches. This is also an especially annoying requirement for kernel developers, because they often have to build and deploy custom one-off kernels as part of their development process. And without a custom-built kernel header package, no BCC-based application will work on such kernels, stripping developers of a useful set of tools for debugging and monitoring.</p></li>
<li><p>BPF program testing and development iteration is quite painful as well, as you are going to get even most trivial compilation errors only in runtime, once you recompile and restart your user-space control application. This certainly increases friction and is not helping to iterate fast.</p></li>
</ul>
<p>Overall, while BCC is a great tool, especially for quick prototyping, experimentation, and small tools, it certainly has lots of disadvantages when used for widely deployed production BPF applications.</p>
<p>We are stepping up the game of BPF portability with BPF CO-RE and believe this is a future of BPF program development, especially for complex real-world BPF applications.</p>
<h2>High-level BPF CO-RE mechanics</h2>
<p>BPF CO-RE brings together necessary pieces of functionality and data at all levels of the software stack: kernel, user-space BPF loader library (libbpf), and compiler (Clang) – to make it possible and easy to write BPF programs in a portable manner, handling discrepancies between different kernels within the same pre-compiled BPF program. BPF CO-RE requires a careful integration and cooperation of the following components:</p>
<ul>
<li><p>BTF type information, which allows to capture crucial pieces of information about kernel and BPF program types and code, enabling all the other parts of BPF CO-RE puzzle;</p></li>
<li><p>compiler (Clang) provides means for BPF program C code to express the intent and record relocation information;</p></li>
<li><p>BPF loader (<a href="https://github.com/libbpf/libbpf">libbpf</a>) ties BTFs from kernel and BPF program together to adjust compiled BPF code to specific kernel on target hosts;</p></li>
<li><p>kernel, while staying completely BPF CO-RE-agnostic, provides advanced BPF features to enable some of the more advanced scenarios.</p></li>
</ul>
<p>Working in ensemble, these components …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</a></em></p>]]>
            </description>
            <link>https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259499</guid>
            <pubDate>Mon, 24 Aug 2020 11:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My startup/idea validation process]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24259246">thread link</a>) | @NeilRamp
<br/>
August 24, 2020 | https://neilcocker.com/2020/08/22/my-startup-validation-process/ | <a href="https://web.archive.org/web/*/https://neilcocker.com/2020/08/22/my-startup-validation-process/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article id="post-2340">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>I’m very interested in how startups validate their ideas. I’m finding that actually a staggering amount of them barely do. Or just do it very badly.</p>



<p>There’s no one right way to validate a startup idea. And, even if you do it perfectly, it doesn’t guarantee success. But it does hugely reduce the risk of failure.</p>



<p>What I outline below is the method I’ve been using for a while. It’s <strong>not comprehensive</strong>, and each of the steps can be done in a much more detailed way. But it’s <strong>quick</strong>, captures good data, and gives you a very strong footing to start your journey.</p>



<p>TL;DR</p>



<ul><li>Define your customer – 1 hour</li><li>Read a book – 3 hours</li><li>Write your hypothesis – 1 hour</li><li>Create and distribute a survey – 4 hours</li><li>Speak to people (properly!) – 10+ hours</li></ul>



<figure><img data-attachment-id="2355" data-permalink="https://neilcocker.com/william-iven-gcsnospexfs-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg" data-orig-size="4193,2785" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="william-iven-gcsnospexfs-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=580" src="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/william-iven-gcsnospexfs-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@firmbee?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">William Iven</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>Here’s a quick breakdown of each one of these. </p>



<p>1 – Define your potential market, and your potential customer. You may already have a typical customer in mind, but try to drill down into something specific. It’s not enough to just say “This is for entrepreneurs”. Or “It’s for single mums”. You need to define them more clearly by their behaviours, as well as their primary characteristics. Try something like “Time-rich, cash-poor,&nbsp; freelancers who need extra sources of income”. Or “High net worth individuals who take more than ten flights for business a year”. </p>



<p>2 (Optional, but VERY strongly recommended) – Read <a href="http://momtestbook.com/">The Mom Test</a>. I think it’s the most important business book I’ve ever read, and it fundamentally changed how I talk to (potential) customers. It stopped me being obsessed with my product, and fall in love with the problem. I should get commission for how often I recommend it! If you have already read it, and are confident that you don’t need to refresh your memory, then move on to stage 3.</p>



<p>The Mom Test is a book that helps you speak to your customers in a way in which they can’t lie to you, subconsciously or otherwise. By talking about their life, and the problems they face around your area of interest, INSTEAD of your solution, you get an unfiltered, unbiased set of feedback about what they REALLY want to have solved. And not just feedback to the idea you have presented to them, which is probably a very different thing. This is a VERY important thing to understand, especially as “no market need” is the most often cited reason for startups failing.</p>



<p>Don’t let your ego get in the way of having a successful business. <strong>Your solution isn’t more important than their problem.</strong></p>



<p>If you don’t want to spend 3 hours reading the book, spend an hour<a href="https://www.youtube.com/watch?v=FG1Fa-t4AEQ&amp;t=0s"> watching the author talk about it</a>. If you don’t want to spend an hour watching that, spend three minutes watching<a href="https://www.youtube.com/watch?v=Hla1jzhan78"> this video</a>, or reading<a href="https://medium.com/@nataliekorotaeva/how-to-talk-with-your-users-3-takeaways-from-the-mom-test-by-rob-fitzpatrick-bbeb4a93ba07"> this blogpost</a>. Ideally you’ll do all of the above, just so you fully embrace the idea.</p>



<figure><img data-attachment-id="2359" data-permalink="https://neilcocker.com/nesa-by-makers-igur1ix0mqm-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg" data-orig-size="6720,4480" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="nesa-by-makers-igur1ix0mqm-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=580" src="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/nesa-by-makers-igur1ix0mqm-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@nesabymakers?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">NESA by Makers</a> on <a href="https://unsplash.com/s/photos/startup?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>3 – Write your hypothesis. I won’t write too much here, as there are lots of great blogposts out there that do a great job of explaining good ways of nailing this. In short, you’re looking to find a hypothesis that you can test with your customer conversations. There are several different templates for this, but this is a simple one to start with. </p>



<p><em>I believe [target market] will [engage in this behaviour / use this solution] for [this reason].</em></p>



<p>You can refine this as you go along, and as you speak to customers. After all, there’s a very good chance that your research will show you that your hypothesis is wrong – and therefore you’ve just saved yourself thousands of Pounds, Dollars, or Euros, and 2 years of your life. Yay!</p>



<p>If your hypothesis is proven wrong, you can come up with a new one, and start again. </p>



<p>4 – Design a survey that is easy to distribute, and easy to fill in (multiple choice here). The idea is to capture some rough data, but mainly it’s the top of a funnel for getting people on the phone to the real interviews. </p>



<p>Here’s <a href="https://docs.google.com/forms/d/e/1FAIpQLSdSwINF3uDxeD2fx0Y5sWaX9esyrG39HzCzeXSPMcwMRo5wnw/viewform?usp=sf_link">an example of a real, live survey</a> that I’m currently using to capture data from potential customers. Feel free to steal the format, and also <strong>feel free to fill it in if you’re an early stage founder, too</strong>.</p>



<p>I’ve used Google Forms in this example, but I also heartily recommend the services of <a href="https://doopoll.co/">Doopoll</a>.</p>



<p>Make it mainly multi-choice, to make it a low barrier to people filling t in, but if you feel like you want to devote one question to free-entry, then go ahead. It can sometimes be a simple “Is there anything else you would like to tell us?” thing at the end.</p>



<p>Distribute via the usual channels, and call in favours from people who can help you reach your target market.</p>



<p>Hint – <strong>Twitter is a search engine for human beings</strong>. Want to find people interested in, for example, medtech? There’s a ton of hashtags these people will use, and that info may also be in their bio. It wouldn’t take too long to tweet a few hundred of them with a polite message, asking them to give you 2 mins of their time to fill in the survey, as they’re interested in your area of research.</p>



<p>Bonus – it’s an email list for you to approach to be your beta users once you have an MVP up and running. But, be respectful. These people gave you their time for free, so don’t just add them to a never-ending drip campaign.</p>



<figure><img data-attachment-id="2357" data-permalink="https://neilcocker.com/daria-nepriakhina-zocdwpuirua-unsplash/" data-orig-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg" data-orig-size="4032,2688" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="daria-nepriakhina-zocdwpuirua-unsplash" data-image-description="" data-medium-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300" data-large-file="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=580" src="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024" alt="" srcset="https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=1024 1024w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=2048 2048w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=150 150w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=300 300w, https://neilcocker.files.wordpress.com/2020/08/daria-nepriakhina-zocdwpuirua-unsplash.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Photo by <a href="https://unsplash.com/@epicantus?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Daria Nepriakhina</a> on <a href="https://unsplash.com/s/photos/research?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a></figcaption></figure>



<p>4 – Speak to the ones you have chosen. Read The Mom Test *before* you speak to them. It’ll allow you to ask questions that get to the root of the real problems they face in this area, and not just answer questions that are limited to the scope of your proposed product. In an ideal world, they’ll end the session not having a clue what your product is. It’s all about them, NOT your product.</p>



<p>I’d strongly recommend speaking to at least 25 people. Preferably more like 50. If you have chosen a well-enough defined target (and not just something vague like “car owners” or “entrepreneurs”), and you listen carefully, clear trends will start to emerge. And these may well be problems that you can solve!</p>



<p>Hint – I strongly recommend Calendly (or similar) to provide a 15 or 20-min link to your interviewees, allowing them to book the relevant slot in your calendar. This will give them confidence that you intend to honour your 15 min promise. It also keeps you concise in your questioning, and get to the point. If they’re happy to keep talking, that’s great. But don’t abuse their goodwill.</p>



<p>Finally – Fall in love with the problem, not your product. The market, in a true economic sense, doesn’t care about your product. It only cares about you being able to solve a problem. Don’t succumb to Ugly Baby Syndrome, where you have come up with an idea that you LOVE, and you’re deaf to any market signals that tell you that it’s no good.</p>



<p>I know that I’ve made this mistake in the past. To be enthusiastic, and in love with your idea is a very normal thing. And it’s particularly typical of entrepreneurs, as we’re all out trying to change the world. But we’ve been mis-sold the concept that the moment of genius, and the idea itself, is sacrosanct. But successful entrepreneurship is about a disciplined process. And validation is an absolutely vital part of it.</p>



<p>I once had the “product-first instead of problem-first” way of doing things described to me as “<strong>designing a key (product) and running around trying to find a lock (problem) that it will open</strong>“. Surely it’s much better to find a lock, study it, understand it, then design a key to open it. </p>



<p>If you’ve done all the steps above, you now understand the lock MUCH better. Go make a key to open it.</p>



<p>Update – I’ve had a few people ask for my input on their ideas. If you’d like a free mentoring session, you can <a href="https://neilcocker.com/toughquestions/">book in here</a>.</p>
			
			
			
		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
	<!-- .pagination-single -->

	
		<!-- .comments-wrapper -->

		
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://neilcocker.com/2020/08/22/my-startup-validation-process/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259246</guid>
            <pubDate>Mon, 24 Aug 2020 10:30:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pieter Levels Makes $600k a Year from Nomad List and Remote OK]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24259201">thread link</a>) | @Pete-Codes
<br/>
August 24, 2020 | https://www.nocsdegree.com/pieter-levels-learn-coding/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/pieter-levels-learn-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p><a href="https://twitter.com/levelsio">Pieter Levels </a>makes about $600,000 a year. He taught himself to code and has an unconventional philosophy. This is not an interview but an analysis piece. Pieter defied the critics and built Nomad List and Remote OK into successful businesses without cutting edge tools like React or other modern frameworks. I send articles like this twice a week - <a href="https://nocsdegree.carrd.co/">join 2,000 developers that get the newsletter</a>.</p><h2 id="who-is-pieter-levels">Who is Pieter Levels</h2><p>Pieter is a self-taught developer from The Netherlands. He has an MBA but no coding qualifications. As we will see in today's article he has a rough and ready approach to coding but it pays off handsomely. </p><p>His <a href="https://www.nomadlist.com/">Nomad List</a> directory and community for digital nomads draws in over $300k a year and that's despite a recent fall in revenue due to people not travelling during the Corona virus crisis. </p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.30.06.png" alt=""></figure><p>His Remote Ok job board for remote workers made <a href="https://remoteok.io/open">$300,000 over the last 12 months</a></p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.23.51.png" alt="Revenue chart for Remote OK job board"></figure><p>So that's a total of $600,00 from the last 12 months! Not bad for a self-taught developer! Pieter is active on Twitter and has a very stong following there. </p><p>As he works for himself he is able to travel extensively and live where he choses. Although, rather than the common misconception of digital nomads being constantly on the move, Pieter recommends spending a few months in each place. This way you avoid travel burnout. </p><h2 id="how-did-pieter-levels-learn-to-code">How did Pieter Levels learn to code?</h2><p>Not a lot is known about his very earlies forays into coding apart from the fact that as a teenager he played around programming. His first attempt at a web business was an analytics service for Youtube which would let you see how all your videos/channels were performing in one place. Unfortunately, he worked on it for a year without making any money from it. </p><p>From that point Pieter adopted his now familar approach to coding and business - build websites quickly and monetize from the beginning. He only adds more features if there is money coming in and the idea is validated by the market.</p><p>Pieter takes the "search on Google" approach to Google. So when he wanted to connect a database to a website or make a button do something on his website he would just search the terms on Google and find solutions in places like Stackoverflow. Pieter is a strong critic of the approach of doing courses as he believes people learn best by doing and building. </p><p>One analogy would be different approaches to learning Spanish. One person might study a course, learn the correct grammar and then go to Spain. Whereas Pieter would go to Spain, ask for the words he needs to use and go from there. </p><p>When asked in the past why he didn't use modern frameworks like React he made the point that as he was a solo founder he couldn't afford to spend time re-building his websites as this would mean his project would stall. </p><!--kg-card-begin: markdown--><p><a href="https://gum.co/GGofo"><img src="https://www.nocsdegree.com/content/images/2020/08/monetize.png" alt="monetize"></a></p>
<!--kg-card-end: markdown--><h2 id="what-technologies-does-pieter-levels-use">What technologies does Pieter Levels use?</h2><p>Pieter is famous (or infamous) for having a rather eccentric choice of stack by modern standards. It's essentially the easiest, least glamorous tools you could imagine. But that's ok because Pieter makes $600k a year! </p><p>Here is his stack:</p><ul><li>HTML (hand coded so no template to make life easier)</li><li>CSS (He has used pre-processors like LESS and SASS in the past)</li><li>Javascript (No frameworks - this is sometimes referred to jokingly as Vanilla Javascript. There is no such thing as Vanilla JS though. It's just plain-old Javascript without a framework such as React, Vue or Angular) </li><li>jQuery (An unfashionable choice nowadays but it does the job)</li><li>PHP (He doesn't use any frameworks like Laravel)</li><li>SQLite - Pieter says it's super quick and swears by it. SQLite is a database written in a single file so Pieter doesn't need to set up a server for it. &nbsp;</li><li>his sites are hosted on a single VPS running Ubuntu with NGINX.</li></ul><p>Here are some modern options Pieter doesn't use </p><ul><li>React - he jokes a lot about how he never wants to learn it due to it's (perceived) complexity. </li><li>Node - for a time he considered using it but he's never used it in production</li><li>Angular/ Vue - he doesn't use any Javascript frameworks </li><li>SQL/ Postgres - he doesn't use any of the conventional databases </li></ul><h2 id="get-a-job-without-a-cs-degree-">Get a job without a CS degree 👇</h2><!--kg-card-begin: markdown--><p><a href="http://nocsok.com/"><img src="https://www.nocsdegree.com/content/images/2020/08/Screenshot-2020-08-07-at-17.35.28-2.png" alt="No-CS-OK-screenshot-1"></a></p>
<!--kg-card-end: markdown--><h2 id="what-results-has-pieter-had-with-this-approach-to-coding">What results has Pieter had with this approach to coding?</h2><p>Despite the technical critics, Pieter has been consistently making six figures since 2014. He currently makes approximately $600,000 a year which is far more than most developers. He has been able to live in countries with a low cost of living so he will likely be able to have financial independence and not need to work relatively soon. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">📈 Record sales yesterday of $2,342.04 on <a href="https://t.co/S9Qv34rpbP">https://t.co/S9Qv34rpbP</a> for no apparent reason (maybe companies are spending their EOY HR budgets?). Normal sales is like $299 or 1 post per day. <a href="https://t.co/8HukglDuiv">pic.twitter.com/8HukglDuiv</a></p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938699122445451265?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr"><a href="https://t.co/rORz8xdCQp">https://t.co/rORz8xdCQp</a> is a single PHP file called "index.php" generating $2,342.04 in a day. No frameworks. No libraries. 💖</p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938707166508154880?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><h2 id="what-is-pieter-levels-working-on-now">What is Pieter Levels working on now?</h2><p>He just released a new project, <a href="https://remoteworkers.dev/">Remote Workers</a>, where people can post their resumé. He "built in public" - that is to say he gave daily updates of his code on Twitter. This is also a great way for developers to build an audience! You can check out what people are saying about Remote Workers on <a href="https://www.producthunt.com/posts/remote-workers">Product Hunt</a>. </p><h2 id="conclusion">Conclusion</h2><p>Pieter is like a bare knuckle boxer so don't compare him to a Judo practioner going to the Olympics. One is going to win no matter what and one is going to follow the rules they have trained under and have finer technique. Neither is better or worse. It depends on the situation. </p><p>Pieter's approach would not be good if you were trying to get a job in a lot of companies. But Pieter isn't looking for a job and the proof for him is in his bank balance. So Pieter's scrappy technique is better suited if you are attracted to coding for entrepreneurship and being a solo founder who doesn't have to share their code with others to work on. He doesn't use Github to save his code, for instance and this is an industry standard that most employers expect. If you want to be an indie hacker/entrepreneur though then Pieter is a fine act to follow. </p><h3 id="if-you-enjoyed-this-article-please-send-it-to-a-friend">If you enjoyed this article please send it to a friend </h3><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="and-you-should-totally-sign-up-for-the-newsletter">And you should totally <a href="https://nocsdegree.carrd.co/">sign up for the newsletter</a> </h3>
                    </div>
                </section></div>]]>
            </description>
            <link>https://www.nocsdegree.com/pieter-levels-learn-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259201</guid>
            <pubDate>Mon, 24 Aug 2020 10:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built a collaborative flashcard tool]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24259037">thread link</a>) | @mvind
<br/>
August 24, 2020 | https://memordo.com/launch/hn | <a href="https://web.archive.org/web/*/https://memordo.com/launch/hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>All your flashcards are stored safely in the cloud. Create and review
                    flashcards instantly on any platform. </p><p>
                    <span>
                        <span><i></i></span> Study using Spaced Repetition
                        <br>
                        <span><i></i></span> Cram for Special Occasions
                        <br>
                        <span><i></i></span> 100% Custom Review Schedules
                        <br>
                        <span><i></i></span> Get Data Analytics and
                        Statitics on your Studying <br>
                    </span></p></div></div>]]>
            </description>
            <link>https://memordo.com/launch/hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259037</guid>
            <pubDate>Mon, 24 Aug 2020 09:52:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of webpage speed, or throwing away React]]>
            </title>
            <description>
<![CDATA[
Score 343 | Comments 286 (<a href="https://news.ycombinator.com/item?id=24258855">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
  <p>Back in 2011, I happened to get a job writing <a href="https://backbonejs.org/">Backbone.js</a> app. If you never did that, don’t. I was complaining about difficulties with composition left and right to whoever would listen. As I started digging into alternatives for the front-end, I discovered <a href="https://en.wikipedia.org/wiki/Functional_reactive_programming">FRP</a> and <a href="https://www.flapjax-lang.org/">Flapjax</a>, and <a href="https://clojurescript.org/">ClojureScript</a>. The last one got me hooked on <a href="https://clojure.org/">Clojure</a>. I even did a <a href="https://fwdays.com/event/js-frameworks-day-2013/review/Functional-Reactive-Programming-&amp;-ClojureScript">successful talk</a> on FRP and ClojureScript (and precursor to <a href="https://hoplon.io/">Hoplon</a>, called hlisp).</p>
<h2 id="react">React</h2>
<p>Then in May 2013 React was released. I championed it on my new job and discovered during Clojure-themed hackaton (<a href="https://solovyov.net/blog/2013/clojurecup/">Clojure Cup 2013</a>) that CLJS and React are a great match. What’s so good about React though? To me, the main selling point is that it composes well.</p>
<p>When you use predecessors like jQuery or Backbone or Angular or whatever after just a year of development your code is a mess of event listeners and triggers. Don’t get me started on unobtrusive JS, code locality is non-existent with jQuery. Which handler is bound where and what it does? It’s too hard to discover to be a good base for a good codebase!</p>
<p>Then I started working at <a href="https://kasta.ua/">Kasta</a>, where web frontend was exactly that jQuery-ish mess. Nobody ever wanted to touch checkout, since you could spend hours, if not days, making the smallest change. Then QA would find more invalid states than you can dream of. And then users would report more bugs to our call center. It was just as awful as you can imagine.</p>
<p>So after some experiments, tests, and checks, I decided that we’re going React + ClojureScript way with server-side rendering done in Clojure.</p>
<h2 id="demise">Demise</h2>
<p>And for a while, things were looking good. We had this <a href="https://solovyov.net/blog/2017/server-side-rendering/">architecture</a> where our components are executed as Clojure on the backend, so no Node.js on the server, hurray! And developer UX is through the roof with the excellent live reload (thanks CLJS), ability to connect from your editor to browser REPL, and experiment there. It is just great!</p>
<p>To make a long story short, our frontend grew bigger and bigger. Incremental compilation started to become slower — it now routinely takes more than a second or two. And while there were few attempts on keeping the whole app performant, ultimately we failed. It’s a death by a thousand cuts. The application became too big and its boot time became too long. Server side rendering helps partially, but then hydration freezes the browser. On the older hardware or Androids it became unacceptable!</p>
<p>One of the main reasonings back in 2016 was that we take a hit on startup time, but in turn, get no page loads and have a rich web application with a lot of interactions. And for a while that worked! But startup time became longer and longer, leading to a shameful rating of 5/100 from Google’s PageSpeed (okay, it was sometimes up to ~25/100, whatever).</p>
<p>More than that, while doing what is described below, we’ve discovered that React also leads to some questionable practices. Like hovers in JS (rather than in CSS), drop-down menus in JS, not rendering hidden (under a hover) text (Google won’t be happy), weird complex logic (since it’s possible!), etc. You can have a React app without those problems, but apparently, you have to have better self-control than we had (nobody’s perfect!).</p>
<p>Also since then, the vast majority of our users switched to mobile apps. This made the web app the main entry point for new users. This means its main goal is rendering fast for a newcomer, because old-timers, which want more functionality, are on mobile app now. And <a href="https://web.dev/tti/">TTI</a> (time to interactive) is so much more important here.</p>
<h2 id="time-for-a-change">Time For A Change</h2>
<p>So given that circumstances have changed, what do we do? I read articles “how I survive on vanilla JS” since before React appeared and they usually don’t make sense — it’s either a pink-glassed rant about how great it is, disregarding all the problems (separation of concerns, cohesion, composability, code locality) or a project by one (or few) persons, who just keep everything in their head.</p>
<p>Somewhere back in February I stumbled upon <a href="https://intercoolerjs.org/">Intercooler.js</a>. I’m not sure if I ever saw it before — maybe I did but skimmed over — it does not matter. This time it captured my attention.</p>
<p>The idea is that all HTML is rendered on the server. And client updates parts of HTML, controlled by element’s attributes. Basically like HTML+XHR on steroids. You can’t do anything you want, but that’s partially the point: some limits are good so you won’t do crazy stuff. And you need some support from the server, so you can render partial results — just an optimization, but quite an important one.</p>
<p>There is an alternative library — <a href="https://unpoly.com/">Unpoly</a>. It has more features around layout and styling but has a little bit less thought out XHR stuff (hard to do a POST request with parameters without having a form, for example). And the library size is much bigger. And it’s written in CoffeeScript with lots of classes, <a href="https://solovyov.net/blog/2020/inheritance/">ugh</a>.</p>
<p>So I made a proof-of-concept implementation of our catalogue page in Intercooler and it worked! Except there was a dependency on jQuery and some other irritating stuff… As I was struggling to make a batch request for HTML fragments I understood one thing: when I wrote down a roadmap for catalogue the last point was “small intercooler-like thing for analytics”.</p>
<p>So why wait?</p>
<h2 id="twinspark">TwinSpark</h2>
<p>I liked Intercooler’s coherent approach to working around AJAX, so I decided to name the library after some automotive stuff as well, and TwinSpark seems like an appropriate name. So what’s the deal?</p>
<p><a href="https://github.com/kasta-ua/twinspark-js">TwinSpark</a> is a framework for declarative HTML enhancement: you put additional attributes on your element and TwinSpark does something with them. Like makes an AJAX call and replaces target with a response, or adds a class, or… well, see <a href="https://kasta-ua.github.io/twinspark-js/">examples</a>, shall you?</p>
<p>There are some differences with Intercooler, of course, because why would it exist? The most noticeable one is that there is no dependency on jQuery. It supports only modern browsers (not IE or Opera Mini) but drops that 88kb monster.</p>
<p>It also has:</p>
<ul>
<li>no inheritance — can’t stress that enough!</li>
<li>clear extension points for your directives</li>
<li>support for batching requests to a server</li>
<li>tighter attribute name convention (my own opinion, but <code>ic-get</code> and <code>ic-post</code> irritate me: do not make me change keys!)</li>
<li>much smaller payload (thanks to no jQuery!)</li>
<li>should be faster (thanks to no jQuery again)</li>
</ul>
<p>Honestly speaking, the main reasons are <a href="https://kasta-ua.github.io/twinspark-js/#batch">batching</a> and <a href="https://solovyov.net/blog/2020/inheritance/">no inheritance</a>. Inheritance is particularly painful here. In Intercooler, if you declared <code>ic-target</code> on the body, all tags inside will think it’s their target too. So you include a component somewhere in HTML tree and an attribute higher on tree changes this component behavior. I mean this is a freaking dynamic scope, I want none of that! :)</p>
<p>Funnily enough, after about a month of dabbling with TwinSpark, Intercooler’s author announced that he’s doing a jQuery-less modern version: <a href="https://htmx.org/">htmx</a>. :) It has really good extensions points, so maybe it’s possible to add batching… but inheritance is still there. :-(</p>
<h2 id="why-is-that-a-good-idea">Why is that a good idea</h2>
<p>We need to look at it from two sides: if it’s good for developers and if it’s good for users. React was great at former and terrible at later.</p>
<p>TwinSpark approach is much better in most cases for the user: less JavaScript, less jitter, more common HTML-like behavior. In the worst case, we would serve you 2.5MB of minified (non-gzipped) JS and 700KB of HTML (half of it were initial data for React) for catalogue. JS bundle is not that big because of embedded images or css or some other obscure stuff, it’s big because it’s the whole app, with a lot of views and logic.</p>
<p>Now it’s 40KB of minified non-gzipped JS (TwinSpark, analytics, some behavior, IntersectionObserver polyfill) and 350KB of HTML. Two orders of magnitude difference and even HTML is smaller! This is just like Christmas in childhood!</p>
<p>On the developer side, I think React is better still, but code locality is great, composability is much better (since you are forced in a limited world of working in a simplistic model) than with jQuery. Plus there are a lot of ways to improve it.</p>
<p>The good news is that the development process did not change that much! We’re still writing components that query necessary data from site-wide memory store (and make a call to API when needed), but they are executed only on the server. We effectively piggy-backend on our previous architecture, and this gives us the perfect ability to render “partial” HTML - since components do not wait for some “controller” to give them all necessary data. This is what allowed us to have both React and non-React versions to co-exist and make an A/B test without writing the markup twice.</p>
<h2 id="results">Results</h2>
<p>It took us four months since the first experiments to release. Not exactly the amount of time I imagined when we started (“should take two to three weeks at most!"), heh, but we were not exclusively doing that. It still took a lot of time and energy to remove React-isms from the code and wrangle our app to be a server-side citizen. It still could use some polishing, but we decided to release it despite that just to cut it short. And A/B test showed that we were right — especially for Android phones.</p>
<p>Google gives our catalogue 75/100 now instead of 5/100. Hurray, I guess? :)</p>

  </section></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258855</guid>
            <pubDate>Mon, 24 Aug 2020 09:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The GemRB project celebrates 20 year anniversary with a new release]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24258780">thread link</a>) | @Lightkey
<br/>
August 24, 2020 | https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html | <a href="https://web.archive.org/web/*/https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        </header>
      

      <section itemprop="text">
        
        <p>The GemRB team announces the availability of GemRB 0.8.7, a new minor release to kick off
a week of celebrations of the project’s founding anniversary. 20 years ago, on the 21st of
August, the project initiator Daniele Colantoni registered it on SourceForge to try to make
it a team effort. Many things have happened since, the path was convoluted and bumpy, but
GemRB has continued to grow throughout the years.</p>

<p>GemRB is a portable free/libre open-source implementation of Bioware’s Infinity Engine, which
powered classic CRPGs like Baldur’s Gate, Icewind Dale and Planescape: Torment. The goal of
the project is to make these games available on a wide range of platforms forever, fix or avoid
old bugs, add new features and provide a superb platform for mod (and eventually game) development.</p>

<p>It was started 20 years ago by a student fresh out of town, Daniele Colantoni:
<em>“I missed playing D&amp;D with my friends so much /…/ I wanted to create my game to play
via internet. So I started my personal reverse engineering process on the base files
from Baldur’s Gate.”</em></p>

<p>Predictably it turned out to be much more complicated and time consuming than first
imagined, but the effort continued. From its Windows-only 32-bit beginnings GemRB was
made to run on all common and many niche platforms (from AmigaOS to IRIX and Symbian;
x86 to PPC, ARM, MIPS and WebAssembly). This was largely made possible through use
of open source libraries that are themselves very portable (SDL, OpenAL, libpython, zlib).
Without an open development model and supporting infrastructure, the project would have
never succeeded.</p>

<figure>
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2-kuldahar-gem.jpg" title="IWD2 remains to be fully understood">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2-kuldahar-gem.jpg" alt="IWD2 GemRB battle screenshot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/10pp6.jpg" title="Larger player parties is one of the most popular features">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/10pp6.jpg" alt="10pp6.jpg">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/iwd2stylecombat2.jpg" title="IWD2-style combat output">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/iwd2stylecombat2.jpg" alt="IWD2-style combat output">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/goi.jpg" title="Glory of Istar game shot">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/goi.jpg" alt="Glory of Istar game shot">
      </a>
    
  
    
      <a href="https://gemrb.org/assets/img/screenshots/sorcerer_monk.jpg" title="Sorcerer/monk multiclass">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/sorcerer_monk.jpg" alt="Sorcerer/monk multiclass">
      </a>
    
  
    
      <a href="https://lynxlynx.info/bugs/mushroom.madness.jpg" title="Sometimes things go hilariously wrong ...">
          <img src="https://gemrb.org/assets/img/screenshots/thumb/fonts.png" alt="Sometimes things just go wrong ...">
      </a>
    
  
  
    <figcaption>Various screenshots.
</figcaption>
  
</figure>

<p>The engine can be used to play the full Baldur’s Gate saga, the first Icewind Dale and
Planescape: Torment. The latter requires more reverse engineering and polishing, but
one can finish the game already. Icewind Dale 2 is a different matter — while it
appears more polished than Torment, only the first two chapters of the game are
playable.</p>

<p>As GemRB marks its 20th anniversary, Jaka Kranjc, the current maintainer, is optimistic about
the project’s future. <em>“Our work is not finished, but this sort of thing is like an
ultramarathon — for most of the run the goal is not within reach. Companies come and go, but
FLOSS persists!”</em></p>

<p>The <a href="https://gemrb.org/2020/08/24/gemrb-0-8-7-released.html">new release</a>
brings over 500 changes manifested as bugfixes, smaller features, cleanups
and an improved setup experience. More than that, it introduces a new <a href="https://gemrb.org/2020/07/16/new-pathfinder-smarter-movement.html">smarter
pathfinder</a> with
bumping support and other movement related improvements. At the same time work continued
on the drawing and GUI handling rewrite — stay tuned for a deeper dive later this week.
With this anniversary release out of the way, finishing that rewrite is again the team’s
main priority.</p>

<p>Overall it’s clear that after all this time the GemRB effort is still active, slowly building
missing pieces of the Infinity Engine mosaic, revitalising older code, extending features and
working throughout the project to keep the effort vibrant for years to come. The team is
looking for <a href="https://github.com/gemrb/gemrb/blob/master/CONTRIBUTING.md">new contributors</a>,
especially programmers with OpenGL experience, who could help them finish a drawing backend
refactoring — for better performance and to remain available on a wide berth of platforms.</p>

<p>A pearl to you!</p>

<p><em>PS: check our news section in the following days for a daily retrospective with past maintainers and a look into the project’s future.</em></p>

<hr>
<p>Project links:</p>
<ul>
  <li>Web site: <a href="https://gemrb.org/">https://gemrb.org</a></li>
  <li>Downloads: <a href="https://gemrb.org/Install">https://gemrb.org/Install</a></li>
  <li>News: <a href="https://gemrb.org/News">https://gemrb.org/News</a> (RSS available)</li>
  <li>Screenshots: <a href="https://gemrb.org/Media">https://gemrb.org/Media</a></li>
</ul>

<p>If you want to be notified of further releases, subscribe to
<a href="https://sourceforge.net/projects/gemrb/lists/gemrb-release">gemrb-release</a> (low volume).</p>

<p>If you <em>need</em> to get in touch via email, write to &lt;registracije+gemrb20@lynxlynx.info&gt;.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://gemrb.org/2020/08/24/the-gemrb-project-celebrates-20-year-anniversary-with-a-new-release.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258780</guid>
            <pubDate>Mon, 24 Aug 2020 09:11:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing Teams Through Interfaces]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24258519">thread link</a>) | @jstanier
<br/>
August 24, 2020 | https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/ | <a href="https://web.archive.org/web/*/https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="primary" role="main">
		
<article id="post-1410">

			<!-- end .entry-header -->

		<div>
		
		<div>
			
<p><em>This article is part of a </em><a href="https://www.theengineeringmanager.com/managing-managers/"><em>series on managing managers</em></a><em>.</em></p>



<p>Making the switch to managing managers, and hence managing many teams, can be taxing on the brain. If you’ve not done it before, then you may look at others in more senior roles, potentially running organizations of hundreds of people, and wonder to yourself how they ever find any clock time or mental time for getting anything done.</p>



<p>If you’re used to running one team, that’s a reasonable thought to have. After all, running a team is a tough job. It involves balancing your time between managing others and making your own contributions, working with people outside of your team, deeply understanding the personalities and desires of your staff, and, of course, let’s not forget the most important thing: shipping software.</p>



<p>When viewed through this lens, the thought of having multiple teams may seem quite overwhelming. How are you meant to carry everything in your head that you did before, but at many times the scale? Well, the answer is that you <em>shouldn’t have to</em>. That’s exactly why you have managers reporting to you, which allows you to work at a higher level of abstraction.</p>



<p>Working at this higher level of abstraction allows you to focus your efforts on what’s important; whether that importance manifests in the <a href="https://www.theengineeringmanager.com/managing-managers/vp-director-what/">operational running of work streams or strategic planning for the future</a>. It allows you to step back and to focus your energy where it pays the greatest dividends: the outputs of tens, if not hundreds, of people.</p>



<p>Since those that read this website typically have a background in writing software, I’ll lean on a software engineering analogy in order to explain how you use your managers to work at this higher level of abstraction. We’re going to be looking at the interface between yourself and your managers by looking at, erm, <strong>interfaces</strong>. How handy.</p>



<h2>Interfaces</h2>



<p>The programming language that I have the most experience in is Java, so I’m going to lean on it for this particular analogy. An interface in Java, like in other languages, is a type that allows you to define abstract methods that other classes must have if they implement that interface.&nbsp;</p>



<p>So, for example, you may define an interface for a CurseGenerator:</p>



<pre><code>interface CurseGenerator {
  public String curse();
}</code></pre>



<p>Of which we could then implement a British version:</p>



<pre><code>public class BritishCurseGenerator implements CurseGenerator {
  public String curse() {
    return “Oh, bloody hell!”;
  }
}</code></pre>



<p>An interface allows extensibility in software systems because a particular piece of code can work with any class that implements a given interface, since the interface’s methods are checked to be present in the implementing class at compilation time.&nbsp;</p>



<p>Most importantly,&nbsp;the code that works with an interface <em>does not need to know the details of the implementation</em>.<em> </em>The implementing class can do whatever it wants as long as it abides by the contract of the method signatures. The interface <em>delegates </em>the implementation to the implementing class. </p>



<p>Do you see where this is going? I’m sure you do. Back to the management analogy:</p>



<ul><li><strong>As a manager of managers, you define what the interface that represents each of your teams looks like.</strong> For example, you may define particular measurements that are important, such as KPIs like application uptime, daily active users, and so on. You may also require that your managers hold weekly one to ones with each of their staff, write a report on progress to the rest of the company every two weeks, or to fix critical priority bugs in one business day.</li><li><strong>Each of your managers has the flexibility of deciding exactly how those teams are run, as long as they follow the interface contract.</strong> So the way in which they decide to tackle improving the uptime percentage or the number of daily active users is entirely up to them. Which member staff works on which part of the codebase is down to them and the team. How and when they schedule their one-to-ones and the content that they discuss is for them to decide. But fundamentally, they should be done to abide by the contract of the interface.</li></ul>



<p>Clear interfaces allow you to not have to worry about the exact implementation details of how each of your managers run their teams, but they allow you to make it clear <em>exactly what you expect of each of them in doing so, and therefore how you define success</em>. OK, I’ll stop the programming analogy now.</p>



<h2>Defining the interface</h2>



<p>So you start by defining that interface with each of your managers. There’s a neat exercise for your first one-to-one meetings (although you can do it at any time) called <a href="https://www.theengineeringmanager.com/management-101/contracting/">Contracting, that I’ve written about before</a>. You can expand on that Contracting exercise by having you both think about the answers to the following questions, which make up the interface:</p>



<ul><li><strong>What success looks like for the team.</strong> What measurements are being used to prove that the team is being successful? Is it working towards an outcome, or some KPI, or shipping particular projects on time? Does it also take into account the happiness, productiveness and psychological security of their staff? How will this information be gathered and made accessible to you?</li><li><strong>Which processes will be used to run the team.</strong> In order to be successful, how are they going to compose themselves? Will they use scrum, kanban, just get on with it, or something else? How do they intend to ship to production regularly? How will they prioritize and execute on their work? Each team of yours may operate differently depending on the skills and seniority of the people on each.</li><li><strong>How the manager interfaces with each of their own staff.</strong> They’ll need to think about the different personalities, skills and career development trajectories for each of their staff and consider what that means for how each of them can operate with autonomy, mastery and purpose. What is an acceptable cadence for one-to-ones? Do they prefer synchronous or asynchronous communication?&nbsp;</li><li><strong>How will you know if something is going wrong? </strong>Code throws errors or performs slowly, bringing problems to your attention. How will issues with the team be made visible so you can work on them together?</li><li><strong>Whether you’d occasionally like to inspect the implementation yourself.</strong> Although defining an interface is meant to hide the complexity from you, occasionally it’s interesting to look under the hood and see what’s going on there. You might have some suggestions to make it better, or you may even learn something new. You can arrange a cadence for skip-level meetings, occasionally pop-up in their group meetings to listen, and get feedback from the individuals and the team as a whole.</li></ul>



<p>With a little work up front on the interface, you can make it absolutely clear at what level of involvement you both feel comfortable with having in your relationship. This allows you to abstract away from issues you don’t need to know about as a manager of managers, and gives your direct report the freedom to run the team how they want, as long as the fundamentals that you expect are being implemented. And that’s great, because you can build a great coaching relationship from that foundation, rather than being at risk of micromanaging or firing and forgetting.</p>



<h2>Debugging problems</h2>



<p>Occasionally things will go wrong, as they do in code. You may need to get the debugger out to see what’s going on. But that’s OK, since you’ve already discussed the interface between you, your direct report, and their team. That interface gives you a number of methods to attach your debugger to.</p>



<p>Perhaps if the team’s cadence is slowing down, you can dig deeper into the processes that are being used to run the team. How often are they shipping? If that’s not very often, why is that? How does code get written, reviewed and deployed? You can keep <a href="https://www.theengineeringmanager.com/growth/first-principles-and-asking-why/">asking why</a> in order to get to the bottom of quirks that might be bugs. And then you can fix them together.</p>



<p>Sometimes it’s interesting to attach the debugger out of pure curiosity. You can do this in your one-to-ones with your direct report. Focus on one area of your interface and go deep into the implementation by asking questions. You’ll always find something worth discussing, and often there’s some neat performance optimizations to try out.</p>



<h2>Beginning with the end in mind</h2>



<p>So why have interfaces?&nbsp;</p>



<p>The ideal end state is that you have clear expectations and boundaries between yourself and the managers that are reporting into you. When you’ve made it clear which high-level functions that each of your managers should be performing, you can delegate the implementation to them so they can do so in whichever way they feel is best for them and their team.</p>



<p>This allows you to move away from details that you don’t need to spend your time focussing on, enabling you to work at a higher level of abstraction. If you were programming, this abstraction would allow you to concentrate on making the system surrounding the interface more efficient, extensible, performant and elegant. That’s exactly what you’ll be wanting to do with the organization, structure and strategic direction of teams as well.</p>



<p><a href="http://eepurl.com/cSMExr">You can sign up to my mailing list to hear when new posts are published.</a></p>
					</div><!-- end .entry-content -->

			</div><!-- end .entry-wrap -->

</article><!-- end .post-1410 -->
	<!-- #comments .comments-area -->
	</div></div>]]>
            </description>
            <link>https://www.theengineeringmanager.com/managing-managers/managing-through-interfaces/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258519</guid>
            <pubDate>Mon, 24 Aug 2020 08:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apparatus with Magnets]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24258396">thread link</a>) | @jiriro
<br/>
August 24, 2020 | https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e | <a href="https://web.archive.org/web/*/https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258396</guid>
            <pubDate>Mon, 24 Aug 2020 07:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM 5160]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24258010">thread link</a>) | @hwdegroot
<br/>
August 23, 2020 | https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/ | <a href="https://web.archive.org/web/*/https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <div>
            <blockquote>
<p>640 Kilobytes!!!!1!!1 I shit you not. That is like 10 times the size of Donald Trump’s brain.</p>
</blockquote>
<p>Recently I was trying to get my son enthousiastic for programming. He is currently 7 years old and getting interested in all kinds of electronics,
so I thought that getting acquainted with programming would not hurt him. And I like to think of myself as a parent that stimulates his kids, so I used that
as an excuse to look into older computers, because <em>nostalgics</em>.</p>
<p><a href="#show-me-the-pics">Show me them footage</a></p>
<p>My kids grew up with LED monitors and TV’s and never really saw a real cathode tube, except on the episodes of <a href="https://en.wikipedia.org/wiki/Pat_%26_Mat">Pat &amp; Mat</a>.
I still remember the soft fading sound of of the tv turning off and the graphics vanishing into this thin line.</p>



<figure id="6fe72747c83aa07dbdebd9927f00a3d7">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/mesmerizing-shutdown.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Mesmerizing shutdown. The terminal vanishes into a line.

        </small>
    </figcaption>
    
    </p>
</figure>


<p>Besides that, I am a fan of clicky keyboards. I have a <a href="https://www.daskeyboard.com/daskeyboard-4C-ultimate/">DasKeyboard 4C ultimate</a> tenkeyless with Cherry Blue switches and a <a href="https://www.daskeyboard.com/daskeyboard-4C-tenkeyless-professional/">4C Profressional</a> with brown switches. Sitting at home during the
corona period, made me google old skool stuff a lot.</p>
<p>So first I laid my eyes on a <a href="https://clickykeyboards.com/product/ibm-model-m2-1395300-made-by-ibm-06-30-1993/">IBM Model M2</a> and got this pretty cheap on
the dutch eBay. Getting this to work on my modern laptop was not rocket science, but not straight forward either. I warned my collegues
that the quiet days at the office were over. But this also opened up a window into vintage computers and computing. What if I could get a vintage computer, I thought. How awesome would that be?</p>
<p>How cool would it be to program a vintage computer with my collegues, or my kids. With all the speed we get nowadays, who still thinks about the limits of computing power. This will be totally different if you have just a fraction of the memory and chip available.</p>
<h2 id="ibm-5160">IBM 5160</h2>
<p>I am from 1983. So I was looking for a computer from that year. IBM was <em>the company</em> in those days for personal computing and when it came to makeing PC’s (I am NOT an apple fan). So I found that IBM produced the <a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer_XT"><strong>IBM PC XT</strong></a> in that year. I also found out that you could still get them online for a reasonable price.
Luckliy I was able to lay my hands on one, in a pretty good state. It came with an <a href="https://clickykeyboards.com/product-category/1986-1989-ibm-model-m-silver-label/">IBM Model M</a> keyboard with the silver label (the PC is from 1986). The sound of that is even better than than the <code>Model M2</code>.</p>


<figure id="c1eacc927bc26694d18237b77c9b6c5e">
    <p><audio controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/audio/IBM-model-m-oh-that-clicky-sound.mp3" type="audio/mpeg">
            Your browser does not support the audio tag.
        </audio>
    </p>
    
    <figcaption>
        <small>
            
Need I say more...

        </small>
    </figcaption>
    
</figure>


<p>After introducing my kids to th <code>DIR</code> command (it was the only one I was pretty sure about it would work), they wanted to type “words” on the old computer (first success).</p>
<h2 id="exiting-vim-is-hard">Exiting Vim is hard?</h2>
<p>So, I know the <code>DIR</code> command. But now what. Let’s see what commands are available.</p>
<ul>
<li>No tab completion. <code>TAB</code> just places the cursor somewhere down the line</li>
<li>No <code>HISTORY</code>. You can repeat the last command by pressing the right-arrow.</li>
</ul>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>This is incorrect. You say that you have IBM PC DOS 5. If so, this includes the DOSKEY command. This will give you a command-line history with editing. Just type <code>dos\doskey</code> to load it.</p>
</blockquote>
<p>For a starters, on <code>IBM DOS</code> (version 5.0) there is no <code>$PATH</code>. The executables are located in <code>C:\DOS</code> (or <code>c:\dos</code>, because <code>DOS</code> don’t care about casing). the most executables are located. After a day or two I figured this out, so I finally managed to open my first <code>BASIC</code> program. All fine, until I wanted to quit the program. It’s not that easy as <a href="https://stackoverflow.com/questions/11828270/how-do-i-exit-the-vim-editor">exiting <code>Vim</code></a>. It took me quite some time googling, until I finally found this <a href="https://stackoverflow.com/questions/44253055/how-can-i-exit-microsoft-gw-basic-ibm-basica-or-other-similar-old-dialects-of">lifesaver</a>.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>There certainly should be! DOS has 2 configuration files, which live in the root directory of the boot drive (A: or C:). They are called [1] CONFIG.SYS and [2] AUTOEXEC.BAT. In the 2nd, there should be a line:
<code>PATH=C:\DOS; C:\</code></p>
</blockquote>








<figure id="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen_hu03af1e9e4264eec2575cd1ba06f1e20e_255454_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Entering BASIC is peanuts

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><span id="close-1fadd62c83243e573af5941d4eb32c02">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic_hu7173749eb1353b22f37803cfee1222d6_251610_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Stuck in BASIC

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><span id="close-0e171f24d2705fcfc1f3dddef5ea66e3">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic.jpg" width="4032" height="3024"></p>
    </div>
</div>





<figure id="34bf581ec5de30d29fb4a52465d157a0">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/trying-stuff-in-qbasic.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    
    
    <figcaption>
        <small>
            
Trying to exit QBASIC. Epic fail

        </small>
    </figcaption>
    
    </p>
</figure>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>That is <em>not</em> <code>QBASIC</code>; <code>QBASIC</code> has a GUI. You were in either <code>BASICA</code> or <code>GWBASIC</code>. The command to quit is <code>syst em</code>, if I remember correctly after 30 years.</p>
</blockquote>
<p>So, now I can start a few commands, but getting all available commands is not that straight forward. There is a lot in the <code>DOS</code> directory, but there is no scrolling, and the monitor only is 25 lines.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>Yes there is [scrolling]. Type <code>dir /p</code> for page-by-page. <code>dir /w</code> gives a wide listing. You can combine these: <code>dir /w /p</code>. You can also do <code>dir | more</code></p>
</blockquote>
<blockquote>
<p>[the monitor is only 25 lines] This depends on the graphics card. If you have an MDA card, no, 25 lines is all. Try <code>mode con: lines=43</code> or <code>mode con: lines=50</code>. This will only work on a VGA-compatible card, though, and you will need ANSI.SYS installed, I think.</p>
</blockquote>
<p>So figuring out the available commands is using a lot of <code>DIR *.EXE</code>'s and <code>DIR *.COM</code>'s.</p>
<p>First class fun.</p>
<h2 id="show-me-the-pics">Show me the pics</h2>
<p>Not so long ago I was explaining my collegue (who is using a screensaver), <a href="https://en.wikipedia.org/wiki/Screensaver">where a screensaver got its name from</a>. Back in the days, when we were all running the <a href="https://www.youtube.com/watch?v=Uzx9ArZ7MUU">pipes</a> so the screen would not <span>fuck up</span>
.</p>
<p>But now, sit back and relax…</p>



<figure id="f3b027a374567777bfd8178001360334">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/insane-refresh-rate-oldskool-monitor.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Check this insane refresh rate of the cathode tube. The color of the terminal is magnificent! 😍

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="4cdf95e55b8fbd6e1c5e3ea1f0bd43bf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/more-refresh-rate.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
And more refresh rate. The mesmerizing fading away of the fonts into the background. Beautiful, just beautiful

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="6f82255ebe285b0963065fc046514bcf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 The startup is amazing as well. The sound of the fan, and the nostalgic beep.

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="43c3937b62bdb5325a2b1a8a57bc530d">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos-again.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 One more time. I could loop this forever.

        </small>
    </figcaption>
    
    </p>
</figure>










<figure id="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch_hu3a6de3285dc77b6df0e675474f4c7576_447189_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
un DOS tres. The fluorescence is soooo pretty.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><span id="close-01da5907dc0ec7a58dc42ca82d974286">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file_hu5af41f7c240e39ab901ff694320d0a39_288464_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
wppreview, I totally miss the point of this program. But, hey, it's there.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><span id="close-69f512f8bcce7a3b38b62b31e321231a">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file.jpg" width="4032" height="3024"></p>
    </div>
</div>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It [wppreview] is not part of DOS. Sounds like a WordPerfect preview program for use with mailmerge.</p>
</blockquote>
<h2 id="what-next">What next?</h2>
<p>So far I had to explain to my son what a <code>file(name)</code> and a <code>command</code> is (when they were typing “words” the IBM kept returning</p>
<p>So the experience is already educational :)</p>
<p>To be honest, I do not have a clear idea what I am going to do with it next. I will be playing with it for a while like an 8 year old with his trains.
After the <a href="https://twitter.com/hashtag/stayathome"><code>#stayathome</code></a> is over, hopefully I can take it to the office, so we can start doing real cool things with it.</p>
<p>I will definitely have to up my <a href="https://www.qb64.org/wiki/GOTO"><code>GOTO</code></a> skills :)</p>
<p>I will start using my Model M2 for work (sorry collegues), for sure. I will have to remap my function key in <a href="https://i3wm.org/"><code>i3</code></a>, because I am currently using the
windows key for this. But the Model M2 does not have one. But I will overcome.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It is easy to remap CapsLock to be a “Windows” (Super) key. This is how I use my IBM Model M in Linux. I suggest <code>xmodmap</code>.</p>
</blockquote>
<p>Besides that, I found this great archive with <a href="ihttps://archive.org/search.php?query=dos%20ibm">manuals</a> and <a href="http://www.retroarchive.org/dos/disks/">bootdisks</a> and even <a href="https://winworldpc.com/download/40c2a543-4218-c39a-11c3-a4e284a2c3a5">PC DOS 5.02</a>. Currently I am trying to get a VM up running PC DOS 5.0 (yes, that is possible in <a href="https://www.youtube.com/watch?v=xfjUkJMe_kw">virtualbox</a>)</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>If you are willing to change the DOS version, I suggest DR DOS 3.41. The reason is this: MS/PC DOS 5, 6 &amp; later are designed for 386 memory management. This is impossible on an 8088 chip, and as a result, you will have very little free memory. Many DOS programs won’t work.</p>
</blockquote>
<blockquote>
<p>DR-DOS is a better 3rd party clone of DOS, by the company that wrote the original OS (CP/M) that MS-DOS was ripped-off from. The first version is 3.41 (before that it had different names) and it is far more memory-efficient. <a href="https://winworldpc.com/product/dr-dos/3x">https://winworldpc.com/product/dr-dos/3x</a></p>
</blockquote>
<blockquote>
<p>But if you want to stay with an IBM original DOS, then IBM developed PC DOS all the way to version 7.1, which supports EIDE hard disks over 8GB, FAT32 and some other nice features. It is a free download.</p>
</blockquote>
<blockquote>
<p>I have described how to get it here: <a href="https://liam-on-linux.livejournal.com/59703.html">https://liam-on-linux.livejournal.com/59703.html</a></p>
</blockquote>
<blockquote>
<p>PC DOS 7 is a bit strange; IBM removed Microsoft’s GUI editor and replaced it with an OS/2-derived one called E, which has a weird UI. IBM also removed GWBASIC and replaced it with the Rexx scripting language.</p>
</blockquote>
<blockquote>
<p>Personally, I combine bits of PC-DOS 7.1 with Microsoft’s editor, Microsoft’s diagnostics, Scandisk disk-repair tool and some other bits, but that is more than I can cover in a comment!</p>
</blockquote>
<blockquote>
<p>There is a lot you can do to upgrade a 5160 if you wish. Here is a crazy example: <a href="https://sites.google.com/site/misterzeropage/">https://sites.google.com/site/misterzeropage/</a></p>
</blockquote>
<blockquote>
<p>I would not go that far, but a VGA card, VGA CRT, a serial mouse and an XTIDE card with a CF card in it, and it would be a lot easier to use…</p>
</blockquote>
<p>The downside, my Cherry MX blue switches feel like second class now.</p>
<h2 id="update">UPDATE</h2>
<p>When I was installing my VM with <code>PC DOS</code>, at the end of the installation I was aske if I wanted to start in <code>shell</code> mode. It turns out there is a command <code>DOSSHELL</code> (needs to be executed fron <code>C:\DOS</code>) which gives you a very fancy
gui.</p>








<figure id="8a76cf6b5c012a99a1bf166c516671c4">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/dosshell_hu8b1374a2b83ba8d4970af29e66446ddf_361223_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
😱 It …</small></figcaption></div></figure></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</a></em></p>]]>
            </description>
            <link>https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258010</guid>
            <pubDate>Mon, 24 Aug 2020 06:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GCD and the magic of subtraction]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24257871">thread link</a>) | @plumsempy
<br/>
August 23, 2020 | https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/ | <a href="https://web.archive.org/web/*/https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1295">

	

	
			<figure>
				<img width="1229" height="727" src="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1229" alt="" loading="lazy" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png 1229w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1024 1024w" sizes="(max-width: 1229px) 100vw, 1229px" data-attachment-id="1315" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-4/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png" data-orig-size="1229,727" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 4" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>The greatest common divisor is something I learned in school but it was one of those “so what?” subjects. But recently I revisited it and it is very interesting.</p>



<p><strong>Why is gcd cool?</strong></p>



<p>Every number, can be expressed as the product of prime numbers. This product for every number is unique; sort of like saying, every number has a fingerprint. This is called the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">fundamental theorem of arithmetic</a>. 36 is <code>4x9</code>, and 45 is <code>5x9</code>. This means that some numbers will have common parts with each other.</p>



<p>These common parts can divide both numbers, and thus they are common divisors. In the example above, 36 is <code>4x9</code> or <code>2x2x3x3</code>, while 45 is <code>5x3x3</code>; 3 is a common divisor of both, so is <code>3x3</code>, which is 9; but 9 is the greatest divisor of both 36 and 45.</p>



<p>One question I had when I was younger, was why we are talking about the “greatest” and not the smallest common divisor. We could, but soon, this gets boring: there is 1, the smallest common divisor of every number, then there are some common divisors in between 1 and the gcd. But what the gcd does so uniquely, is that it takes two numbers and gives us <em>all</em> the common parts of two numbers. </p>



<figure><img data-attachment-id="1328" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-1-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png" data-orig-size="1150,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 1" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png 1150w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>common and uncommon parts of 36(4×9) and 45(5×9). The gcd of 36 and 45 is 9.</figcaption></figure>



<p>This is cool! The uncommon parts are relatively prime! — meaning, they have nothing in common but the number 1. </p>



<p>So to find the gcd, then, we need to find all the common parts of the two numbers when written in terms of their prime factors. </p>



<p><code>36=3x3x2x2</code> and <code>45=3x3x5</code>, thus the gcd of 36 and 45 is <code>3x3</code>, which is 9. So 36 is 9(4) and 45 is 9(5). It is very interesting to look at numbers as multiples of gcds. Moreover, notice that these multipliers, 4 and 5 in the example above, are relatively prime. </p>



<p><strong>The magic of subtraction</strong></p>



<p>Subtracting two relatively prime numbers, will produce another number that, while not necessarily prime itself, will be relatively prime to both the previous numbers. As an example, <code>13-7=6</code>. 6 is not prime, but it is relatively prime to both 7 and 13. If we subtract 6 from 13 we will get 7 again which is not very interesting. But if we subtract 6 from 7, the smaller one, since 6 and 7 are relatively prime we should get another number that is relatively prime to them both; <code>7-6=1</code>, which is relatively prime to every other number, if keep doing this:</p>


<pre title="">13 -  7 = 6
7  -  6 = 1
6  -  1 = 5
5  -  1 = 4
4  -  1 = 3
3  -  1 = 2
2  -  1 = 1
1  -  1 = 0

(1, 0)
</pre>


<p>The final two numbers are 0 and 1. So whenever we start with two relatively prime numbers and do this on them, it will always end with 0 and 1. This is pretty strange and magical. I am still perplexed by it, but the way I convinced myself, is to think about it bottom up: if we start with the number 1, and try to build our way to any other number by addition, there are finite number of ways. So when we start subtracting, what we are doing is walking that path backwards towards 1. </p>



<figure><img data-attachment-id="1319" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png" data-orig-size="1226,634" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 3" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>There is a limited set of paths from any two numbers back to 1 by successive subtractions.</figcaption></figure>



<p>Now why do these two numbers need to be relatively prime? because if they are not relatively prime, that means that they have some parts in common, like 36 and 45 above, remember? they are 9(4) and 9(5). If we do the subtracting trick on them:</p>


<pre title="">9(5) - 9(4) = 9(1)
9(4) - 9(1) = 9(3)
9(3) - 9(1) = 9(2)
9(2) - 9(1) = 9(1)
9(1) - 9(1) = 9(0)

(9(1), 0)
</pre>


<p>So you see, the common part survives the subtractions, while the uncommon parts converge to 1. But 9 is <em>all</em> the common parts of 36 and 45, in other words the gcd of 36 and 45! </p>



<p>Can we keep subtracting any two numbers until we reach (X, 0) and then proclaim X is the greatest common divisor? yes, we can, and it is called the <em><a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclidean Algorithm</a></em>.</p>



<p>Here is a silly experiment, what if we subtract the partially common parts? for 36 and 45, what if we wrote them as 3(12) and 3(15)?</p>


<pre title="">3(15) -  3(12) = 3(3)
3(12) -  3(3)  = 3(9)
3(9)  -  3(3)  = 3(6)
3(6)  -  3(3)  = 3(3)
3(3)  -  3(3)  = 3(0)

(3(3), 0)
</pre>


<p>This is really funny. The algorithm basically told us that the gcd of 12 and 15 is 3. Now if we choose to multiply the other 3 that we have factored out before we started our subtraction, it will yield the same result: the gcd of 36 and 45 is 9.</p>



<p><strong>What just happened?</strong></p>



<p>We started by finding the gcd of two numbers, then subtracting the uncommon, relatively prime parts to realize we always reach 1, so if we always subtract any two numbers from each other repeatedly, since the gcd is a common factor of both, it will remain constant until the end, when the uncommon parts have reduced down to 1 and 0; and then what we are left with is the gcd. </p>



<p>Here is a recursive implementation of it in Python:</p>


<pre title="">def gcd(a,b):
    if a == 0: return b
    if b == 0: return a

    return gcd(abs(a-b), min(a,b))
</pre>


<p>If someone has a better explanation of why subtracting relatively prime numbers repeatedly will always result in one, please leave a comment or reach out and help me understand better.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257871</guid>
            <pubDate>Mon, 24 Aug 2020 05:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introducing Tcl 8.7 Part 11: The ZIP virtual file system]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24257855">thread link</a>) | @systems
<br/>
August 23, 2020 | https://www.magicsplat.com/blog/tcl87-zipfs/ | <a href="https://web.archive.org/web/*/https://www.magicsplat.com/blog/tcl87-zipfs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <header>
                        
                        <p>
                            Published <time datetime="2020-08-23+0000">2020-08-23</time>
                        </p>
                    </header>
                    <p>
                        This is the eleventh in a series of <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">posts</a> about new features in the upcoming version 8.7 of Tcl. It is the first of a pair of posts describing core support for treating ZIP archives as virtual file systems within Tcl. This post focuses on base operations dealing with existing ZIP archives. The next describes the creation of ZIP archives and their use for building <em>zipkits</em> and single file executables.
                    </p><!-- more -->
                    <blockquote>
                        <p>
                            To take Tcl 8.7 for a spin, you can download the <a href="https://sourceforge.net/projects/tcl/files/Tcl/8.7a3/">source</a> distribution. Binary distributions for Windows are available from <a href="https://sourceforge.net/projects/magicsplat/files/barebones-tcl/">magicsplat</a> and <a href="http://www.bawt.tcl3d.org/download.html#tclbi">BAWT</a>.
                        </p>
                    </blockquote>
                    <p>
                        With Tcl 8.6, access to files in ZIP archives was already possible. Tcl itself offered the ability to compress and decompress data with the <code>zlib</code> command. The <code>zipfile</code> module in <code>tcllib</code> then made use of these to permit access to files within an archive.
                    </p>
                    <p>
                        Tcl 8.7 goes beyond these capabilities by treating ZIP archives as mountable <em>virtual file systems</em> (VFS). This makes access to the files within the archive much simpler through the standard Tcl channel commands <code>open</code>, <code>gets</code> etc.
                    </p>
                    <h2>
                        Mounting ZIP archives
                    </h2>
                    <p>
                        The first step to accessing ZIP archives is to mount them as a Tcl VFS. This is done with the <code>zipfs mount</code> command.
                    </p>
                    <pre><code>% zipfs mount mnt demo.zip</code></pre>
                    <p>
                        This results in the archive <code>demo.zip</code> being mounted as a VFS under the path <code>zipfs:/mnt</code>.
                    </p>
                    <p>
                        The root of all ZIP file systems is given by the <code>zipfs root</code> command.
                    </p>
                    <pre><code>% zipfs root
zipfs:/</code></pre>
                    <p>
                        This root is platform-specific, <code>zipfs:/</code> on Windows and <code>//zipfs:/</code> on Unix(y) systems.
                    </p>
                    <p>
                        Naturally, you can mount multiple archives or even the same archive multiple times. The mount points of course have to be different but one can be nested inside another. For example,
                    </p>
                    <pre><code>% zipfs mount mnt2 demo.zip
% zipfs mount mnt/nested demo2.zip</code></pre>
                    <p>
                        Invoking <code>zipfs mount</code> without any arguments will return the currently mounted ZIP archives as a flat list of mount points and the archive file path.
                    </p>
                    <pre><code>% zipfs mount
zipfs:/mnt demo.zip zipfs:/mnt/nested demo2.zip zipfs:/mnt2 demo.zip</code></pre>
                    <p>
                        ZIP archives may be protected with a password. In that case the password must be supplied as the last argument to the command.
                    </p>
                    <p>
                        When no longer needed the each VFS should be unmounted with <code>zipfs unmount</code>.
                    </p>
                    <pre><code>% zipfs unmount mnt2
% zipfs unmount mnt/nested
% zipfs mount
zipfs:/mnt demo.zip</code></pre>
                    <h2>
                        Introspecting archives
                    </h2>
                    <p>
                        Once mounted, the archives can be introspected.
                    </p>
                    <p>
                        The <code>zipfs list</code> command returns a list of the files in the ZIP file system. Optionally, regular expression or glob wildcard patterns may be specified to filter the returned paths.
                    </p>
                    <pre><code>% zipfs list
zipfs:/mnt/demo zipfs:/mnt zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/subdir zipfs:/mnt/demo/demo.txt
% zipfs list *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -glob *.txt
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt
% zipfs list -regexp {\.txt$}
zipfs:/mnt/demo/subdir/file.txt zipfs:/mnt/demo/demo.txt</code></pre>
                    <p>
                        Notice there is no mount point specified above. The command lists all files and directories under the ZIP VFS root. To restrict to a specific archive, specify it as a pattern.
                    </p>
                    <p>
                        A similar command returns a list of all file paths under a specific directory.
                    </p>
                    <pre><code>% zipfs find zipfs:/mnt/demo/subdir
zipfs:/mnt/demo/subdir/file.txt</code></pre>
                    <p>
                        <strong>TIP:</strong> The <code>zipfs find</code> command will work with any file system, not just ZIP VFS'es.
                    </p>
                    <p>
                        Since the ZIP archive is mounted as a Tcl VFS, standard Tcl commands for retrieving generic file information can be used. For example,
                    </p>
                    <pre><code>% file size zipfs:/mnt/demo/demo.txt
12
% clock format [file atime zipfs:/mnt/demo/demo.txt]
Sun Aug 23 12:33:24 IST 2020</code></pre>
                    <p>
                        The <code>zipfs info</code> command returns additional information that is specific to the ZIP archive format.
                    </p>
                    <pre><code>% zipfs info zipfs:/mnt/demo/demo.txt
demo.zip 12 14 50</code></pre>
                    <p>
                        The returned list contains the name of the ZIP archive (as originally passed), the original file size, the compressed file size and the offset of the file's compressed data within the ZIP archive. (As an aside, note in our example that the "compressed" size is greater than the actual size as often happens for small files.)
                    </p>
                    
                    <p>
                        Data transfer from compressed files in the archive is achieved through the standard Tcl channel I/O commands.
                    </p>
                    <pre><code>% set chan [open zipfs:/mnt/demo/demo.txt]
zipfs_32_1
% gets $chan
Demo file 
% close $chan</code></pre>
                    <p>
                        You can also open the file for writing. However, the ZIP VFS does not support the append mode.
                    </p>
                    <h2>
                        Coming up
                    </h2>
                    <p>
                        Having described the basics of access to ZIP archives, in the next post I will illustrate the use of the new features for creating ZIP archives, zipkits and single-file executables.
                    </p>
                    <h2>
                        References
                    </h2>
                    <ol>
                        <li>
                            <p>
                                <a href="https://core.tcl-lang.org/tips/doc/trunk/tip/430.md">TIP 430: Add basic ZIP archive support to Tcl</a>
                            </p>
                        </li>
                        <li>
                            <p>
                                <a href="http://www.tcl-lang.org/man/tcl8.7/TclCmd/zipfs.htm">zipfs man page</a>
                            </p>
                        </li>
                    </ol>
                    <nav>
                        Tagged:
                        <ul>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl/">Tcl</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tcl-8-7/">Tcl 8.7</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/tutorial/">tutorial</a>
                            </li>
                            <li>
                                <a href="https://www.magicsplat.com/blog/tags/zip/">zip</a>
                            </li>
                        </ul>
                    </nav><!-- tags -->
                </section></div>]]>
            </description>
            <link>https://www.magicsplat.com/blog/tcl87-zipfs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257855</guid>
            <pubDate>Mon, 24 Aug 2020 05:54:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principal Component Analysis]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24257468">thread link</a>) | @keyboardman
<br/>
August 23, 2020 | https://leimao.github.io/article/Principal-Component-Analysis/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Principal-Component-Analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Principal components analysis (PCA) is one of a family of techniques for taking high-dimensional data, and using the dependencies between the variables to represent it in a more tractable, lower-dimensional form, without losing too much information. It has been widely used for data compression and de-noising. However, its entire mathematical process is sometimes ambiguous to the user.</p>



<p>In this article, I would like to discuss the entire process of PCA mathematically, including PCA projection and reconstruction, with most of the derivations and proofs provided. At the end of the article, I implemented PCA projection and reconstruction from scratch. After reading this article, there should be no more black box in PCA anymore.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="orthogonal-matrix">Orthogonal Matrix</h4>

<p>In linear algebra, an orthogonal matrix is a real square matrix whose columns and rows are orthogonal unit vectors (orthonormal vectors).</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\top}A = AA^{\top} = I
\end{align}\]

</p><p>By <a href="https://en.wikipedia.org/wiki/Invertible_matrix">the definition of invertible matrix</a>, this means matrix $A$ is invertible and $A^{-1} = A^{\top}$.</p>



<p>We could also view this from the perspective of determinant.</p>



<p>Because $A$ and $A^{\top}$ are square matrices and using <a href="https://en.wikipedia.org/wiki/Determinant#Properties_of_the_determinant">the properties of determinant</a></p><p>

\[\begin{align}
\det(I) &amp;= \det(A^{\top}A) \\
&amp;= \det(AA^{\top}) \\
&amp;= \det(A) \det(A^{\top}) \\
&amp;= \det(A) \det(A) \\
&amp;= \det(A)^2 \\
&amp;= \det(A^{\top})^2 \\
&amp;= 1 \\
\end{align}\]

</p><p>Since $\det(A) \neq 0$, matrix $A$ is invertible. We multiply $A^{-1}$ on both side of the orthogonal matrix definition.</p><p>

\[\begin{align}
A^{\top}A A^{-1} &amp;= I A^{-1}\\
A^{\top} I &amp;= A^{-1} \\
A^{\top} &amp;= A^{-1} \\
\end{align}\]

</p><p>We have also derived the conclusion that $A^{-1} = A^{\top}$.</p>



<p>Similarly, a complex square matrix $A$ is unitary if its transpose conjugate $A^{\dagger}$ is also its inverse.</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\dagger}A = AA^{\dagger} = I
\end{align}\]

</p><h4 id="symmetric-matrix">Symmetric Matrix</h4>

<p>Real symmetric matrix has the following useful properties:</p>



<p>If $A$ is a real symmetric matrix, all of its eigenvalues are real numbers.</p>



<p>Because of <a href="https://en.wikipedia.org/wiki/Complex_conjugate#Generalizations">the conjugate properties</a> and $\overline{A} = A$ since $A$ is a real value matrix,</p><p>

\[\begin{align}
\overline{Av} &amp;= \overline{\lambda v} \\
&amp;= \overline{A} \overline{v} \\
&amp;= A \overline{v} \\
&amp;= \overline{\lambda} \overline{v} \\
\end{align}\]

</p><p>We got $A \overline{v} = \overline{\lambda} \overline{v}$.</p>



<p>Let $\lambda \in \mathbb{C}$ be an eigenvalue of the symmetric matrix $A$. $Av = \lambda v$ and $v \neq 0$. We multiply $v^{\dagger}$ ($v^{\dagger} = \overline{v}^{\top}$) to the both sides, and because of $A^{\top} = A$ and the property we have just derived $A \overline{v} = \overline{\lambda} \overline{v}$,</p><p>

\[\begin{align}
v^{\dagger} A v &amp;= \lambda v^{\dagger} v \\
&amp;= v^{\dagger} A^{\top} v \\
&amp;= \overline{v}^{\top} A^{\top} v \\
&amp;= (A\overline{v})^{\top} v \\
&amp;= (\overline{\lambda} \overline{v})^{\top} v \\
&amp;= \overline{\lambda}^{\top} \overline{v}^{\top} v \\
&amp;= \overline{\lambda} v^{\dagger} v \\
\end{align}\]

</p><p>We have $\lambda v^{\dagger} v = \overline{\lambda} v^{\dagger} v$, thus $\lambda$ is real.</p>



<p>This concludes the proof.</p>

<h4 id="positive-semi-definite-matrix">Positive Semi-Definite Matrix</h4>

<p>The $n \times n$ symmetric matrix $A$ is defined to be positive semi-definite, if $x^{\dagger} A x \geq 0$ for $x \in \mathbb{C}^n$.</p>



<p>The positive semi-definite matrix has the following important property:</p>



<p>The eigenvalues of positive semi-definite matrix are non-negative.</p>



<p>Because $x^{\dagger} A x \geq$ for $x \in \mathbb{C}^n$, suppose $x$ is an eigenvector of $A$ and $Ax = \lambda x$ where $x \neq 0$,</p><p>

\[\begin{align}
x^{\dagger} A x &amp;= x^{\dagger} \lambda x \\
&amp;= \lambda x^{\dagger} x \\
&amp;\geq 0 \\
\end{align}\]

</p><p>Because $x^{\dagger} x$ must be real number and $x^{\dagger} x &gt; 0$, we have $\lambda \geq 0$.</p>



<p>This concludes the proof.</p>

<h4 id="covariance-matrix">Covariance Matrix</h4>

<p>The covariance matrix has the following important property:</p>



<p>Covariance matrix is positive semi-definite. This means that the eigenvalues of covariance matrix is non-negative.</p>



<p>The proof of that covariance must be positive semi-definite could be found in my previous post on <a href="https://leimao.github.io/blog/Multivariate-Gaussian-Covariance-Matrix/">Multivariate Gaussian and Covariance Matrix</a>.</p>

<h4 id="singular-values">Singular Values</h4>

<p>The singular values, $\sigma_1$, $\sigma_2$, $\cdots$, $\sigma_r$, of an $m \times n$ matrix $A$ are the square roots, $\sigma_i = \sqrt{\lambda_i}$, of non-negative eigenvalues of the associated Gram matrix $K = A^{\dagger}A$. The corresponding eigenvectors of $K$ are known as singular vectors of $A$.</p>



<p>Note that the associated Gram matrix $K = A^{\dagger}A$ is real and symmetric, so the eigenvalues of $K$ are all real.</p>



<p>$K = A^{\dagger}A$ is also positive semi-definite.</p>



<p>For any vector $x$</p><p>

\[x^{\dagger} (A^{\dagger} A) x = (Ax)^{\dagger} Ax\]

</p><p>Because $Ax$ is also a vector,</p><p>

\[\begin{align}
x^{\dagger} (A^{\dagger} A) x \geq 0
\end{align}\]

</p><p>Therefore, all the eigenvalues of $K = A^{\dagger}A$ are non-negative and they all have a corresponded singular value of $A$.</p>

<h4 id="singular-value-decomposition">Singular Value Decomposition</h4>

<p>In linear algebra, the singular value decomposition (SVD) is a factorization of a real or complex matrix that generalizes the eigendecomposition of a square normal matrix to any $ m\times n$ matrix via an extension of the polar decomposition.</p>



<p>Specifically, the singular value decomposition of an $m \times n$ real or complex matrix $M$ is a factorization of the form $U \Sigma V^{\dagger}$, where $U$ is an $m \times m$ real or complex unitary matrix, $\Sigma$ is a $m \times n$ rectangular diagonal matrix with non-negative real numbers on the diagonal, and $V$ is an $n \times n$ real or complex unitary matrix.</p>



<p>The diagonal entries $\sigma_{i}=\Sigma_{ii}$ of $\Sigma$ are known as the singular values of $M$. The number of non-zero singular values is equal to the rank of $M$.</p>



<p>In particular, for any matrix $A \in \mathbb{C}$,</p><p>

\[A_{m \times n} = U_{m\times m} \Sigma_{m \times n} V_{n \times n}^{\dagger}\]

</p><p>We will skip the proof for why every matrix has SVD and the algorithm for SVD.</p>

<h4 id="singular-value-decomposition-for-norm-matrix">Singular Value Decomposition for Norm Matrix</h4>

<p>For any matrix $A \in \mathbb{C}$, $A^{\dagger} A$ could be expressed as</p><p>

\[\begin{align}
A^{\dagger} A &amp;= (U \Sigma V^{\dagger})^{\dagger} U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} U^{\dagger}  U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} I \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} \Sigma V^{\dagger}
\end{align}\]

</p><p>We multiply $V$ at both side of the equation.</p><p>

\[\begin{align}
A^{\dagger} A V &amp;= V \Sigma^{\dagger} \Sigma V^{\dagger} V \\
&amp;=  V \Sigma^{\dagger} \Sigma I \\
&amp;=  V \Sigma^{\dagger} \Sigma \\
&amp;= \Sigma^{\dagger} \Sigma V \\
\end{align}\]

</p><p>Note that $\Sigma^{\dagger} \Sigma$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma^{\dagger} \Sigma$, including the zeros, are the eigenvalues of $A^{\dagger} A$. All the columns of $V$ are the corresponding eigenvectors of $A^{\dagger} A$.</p>



<p>Similarly, $A A^{\dagger}$ could be expressed as</p><p>

\[\begin{align}
A A^{\dagger} U &amp;= \Sigma \Sigma^{\dagger} U \\
\end{align}\]

</p><p>Note that $\Sigma \Sigma^{\dagger}$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma \Sigma^{\dagger}$, including the zeros, are the eigenvalues of $A A^{\dagger}$. All the columns of $U$ are the corresponding eigenvectors of $A A^{\dagger}$.</p>

<h3 id="mathematics-of-principal-components-analysis">Mathematics of Principal Components Analysis</h3>

<p>We start with $p$-dimensional vectors, and want to summarize them by projecting down into a $q$-dimensional subspace, where $q \leq p$. Our summary will be the projection of the original vectors on to $q$ directions, the principal axes, which span the subspace.</p>

<h4 id="minimizing-projection-residuals">Minimizing Projection Residuals</h4>

<p>Given a dataset $X \in \mathbb{R}^{n \times p}$ whose row is the centered data vectors $x_i \in \mathbb{R}^p$ for $0 \leq i \leq n-1$ ($\sum_{i=0}^{n-1} x_{i} = 0$), if we have a unit vector $w \in \mathbb{R}^p$ ($|w| = 1$) and we project the all the data vectors to this unit vector $w$.</p>



<p>The length of projection for data vector $x_i$ on $w$, by definition, is</p><p>

\[\begin{align}
|x_i| \cos \theta &amp;= \frac{\langle x_i, w \rangle}{|w|} \\
&amp;= \langle x_i, w \rangle \\
\end{align}\]

</p><p>where $\langle x_i, w \rangle$ is the inner product of $x_i$ and $w$.</p>



<p>The projection vector for data vector $x_i$ on $w$ is $\langle x_i, w \rangle w$.</p>



<p>The residual, which is the distance from data vector $x_i$ to $w$, is the length of vector $x_i - \langle x_i, w \rangle w$.</p>



<p>Let’s check what the residual square $| x_i - \langle x_i, w \rangle w | ^2$ is.</p><p>

\[\begin{align}
| x_i - \langle x_i, w \rangle w |^2 &amp;= \langle x_i - \langle x_i, w \rangle w, x_i - \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, \langle x_i, w \rangle w \rangle - \langle \langle x_i, w \rangle w, x_i \rangle + \langle \langle x_i, w \rangle w, \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, w \rangle \langle x_i, w \rangle - \langle x_i, w \rangle \langle w, x_i \rangle + \langle x_i, w \rangle ^2 \langle w,  w \rangle \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 |w| ^2 \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 \\
&amp;= \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \\
\end{align}\]

</p><p>The optimization goal of projection is to minimize mean squared error $\text{MSE}(w)$, which is the mean of the residual sum of squares.</p><p>

\[\begin{align}
\text{MSE}(w) &amp;= \frac{1}{n} \sum_{i=0}^{n-1} | x_i - \langle x_i, w \rangle w |^2 \\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \big( \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \big)\\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \langle x_i, x_i \rangle - \frac{1}{n} \sum_{i=0}^{n-1}  \langle x_i, w \rangle ^2\\
\end{align}\]

</p><p>Remember the relationship between variance and expected value, $\mathbb{V}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2$, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Principal-Component-Analysis/">https://leimao.github.io/article/Principal-Component-Analysis/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Principal-Component-Analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257468</guid>
            <pubDate>Mon, 24 Aug 2020 04:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an SSDP Directory in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24256984">thread link</a>) | @luu
<br/>
August 23, 2020 | https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir | <a href="https://web.archive.org/web/*/https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a href="https://netscape-browser.en.softonic.com/" target="_blank">
        <img src="https://quinnwilton.com/images/netscape_now.gif">
      </a>
    </header>
<a href="https://quinnwilton.com/blog"><img src="https://quinnwilton.com/images/back.png"></a>

<section>
  
  <h2>2020-02-26</h2>

<p>I used to spend all of my free time programming random toy projects. Over time, likely after spending a few years in industry, I started to spend so much time thinking about how to write maintainable code that I think I started to lose out on what makes programming fun: exploring new ideas and learning how to do things I’ve never done before. I’d like to rediscover that joy, and to do that, I need to stop being so much of a perfectionist.</p>
<p>I think that in an office setting, deadlines force me to move on and call things done, but in my personal life, lack of that kind of pressure means that I can spend literally forever architecting and rearchitecting the same piece of code until it’s perfect (it never is).</p>
<p>To fix this, I’m going to try blogging! If I can make myself excited to share my code with other people, imperfect and unfinished as it is, then maybe I can start to unlearn the paralysis that’s been plaguing me for the past few years.</p>
<p>To start, I just want to walk through a small program I wrote a few months ago. I wanted to learn how <a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol">SSDP</a> works, so I implemented an SSDP Directory! For those of you who aren’t aware, SSDP is a fairly simple protocol from the 90s that’s used to facilitate the discovery of network services. Nowadays, it’s also used by everything from smart TVs to Hue lights.</p>
<p>My implementation can be found <a href="https://github.com/QuinnWilton/ssdp_directory">here</a>, and the (very readable!) RFC is <a href="https://tools.ietf.org/html/draft-cai-ssdp-v1-03">here</a>.</p>
<p>If I run the application, it discovers all of the devices on my network:</p>
<pre><code>iex(1)&gt; SSDPDirectory.list_services
%{
  "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice" =&gt; %SSDPDirectory.Service{
    location: "http://192.168.0.150:60000/upnp/dev/b236f169-9c9d-db64-ffff-ffffcff91970/desc",
    type: "upnp:rootdevice",
    usn: "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice"
  },
  ...
}</code></pre>
<p>The key to SSDP is what’s called <a href="https://en.wikipedia.org/wiki/Multicast">multicast addressing</a>. Essentially, services broadcast their presence to a specially designated multicast address, and then anyone else on the network is able to listen for those presence notifications in order to track the appearance and disappearance of new services.</p>
<p>Fortunately, Elixir, my language of choice, makes subscribing to these notifications <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/multicast_channel.ex">easy</a>!</p>
<pre><code>defmodule SSDPDirectory.MulticastChannel do
  use GenServer

  alias __MODULE__

  alias SSDPDirectory.{
    Discovery,
    Presence
  }

  @multicast_group {239, 255, 255, 250}
  @multicast_port 1900

  def start_link(opts \\ []) do
    GenServer.start_link(__MODULE__, :ok, opts)
  end

  @spec broadcast(GenServer.name(), iodata) :: :ok
  def broadcast(channel \\ MulticastChannel, packet) do
    GenServer.cast(channel, {:broadcast, packet})
  end

  @spec init(:ok) :: {:ok, %{socket: port}}
  def init(:ok) do
    udp_options = [
      :binary,
      active: true,
      add_membership: {@multicast_group, {0, 0, 0, 0}},
      multicast_if: {0, 0, 0, 0},
      multicast_loop: false,
      reuseaddr: true
    ]

    {:ok, socket} = :gen_udp.open(@multicast_port, udp_options)

    {:ok, %{socket: socket}}
  end

  def handle_cast({:broadcast, packet}, state) do
    :ok = :gen_udp.send(state.socket, @multicast_group, @multicast_port, packet)

    {:noreply, state}
  end

  def handle_info({:udp, _socket, _ip, _port, data}, state) do
    Task.Supervisor.start_child(SSDPDirectory.DecodingSupervisor, fn -&gt;
      with {:ok, packet, rest} &lt;- :erlang.decode_packet(:http_bin, data, []),
           {:ok, handler} &lt;- packet_handler(packet),
           {:ok, decoded} &lt;- handler.decode(rest) do
        :ok = handler.handle(decoded)
      end
    end)

    {:noreply, state}
  end

  defp packet_handler({:http_request, "NOTIFY", _target, _version}),
    do: {:ok, Presence}

  defp packet_handler({:http_response, _version, 200, "OK"}),
    do: {:ok, Discovery.Response}

  defp packet_handler(_packet), do: :error
end</code></pre>
<p>Most of the magic happens in the <code>init/1</code> function. By opening a UDP socket and joining it to the protocol’s multicast group, our process is now able to receive packets that are broadcast to that group. That receiving logic is located in the <code>handle_info/2</code> function within the same file.</p>
<p>When receiving a packet, we spawn another process that is responsible for handling that packet. This process runs under a <code>Task.Supervisor</code> in order to isolate crashes of that process from the <code>MulticastChannel</code>. Also interesting, is that we’re able to decode the incoming packets using <a href="http://erlang.org/doc/man/erlang.html#decode_packet-3">:erlang.decode_packet/3</a>. This is a builtin function that allows us to decode a variety of packet formats, piece-by-piece. In this case, we’re using it to parse the packet as an HTTP packet. This is the same way that Elixir’s <a href="https://github.com/elixir-mint/mint/blob/master/lib/mint/http1/response.ex#L7">Mint</a> decodes HTTP responses too!</p>
<p>Based on the type of packet decoded, <code>packet_handler/1</code> then delegates the handling of that packet to another module. Either we’ve received an HTTP NOTIFY request, and we’re dealing with a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence.ex">presence notification</a>, or we’ve received a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/discovery/response.ex">response to a discovery request</a>.</p>
<p>Let’s take a look at the presence case. In case you’re curious, here’s an example presence notification:</p>
<pre><code>NOTIFY * HTTP/1.1
Host: 239.255.255.250:reservedSSDPport
NT: blenderassociation:blender
NTS: ssdp:alive
USN: someunique:idscheme3
AL: &lt;blender:ixl&gt;&lt;http://foo/bar&gt;
Cache-Control: max-age = 7393</code></pre>
<p>And here’s where we handle it:</p>
<pre><code>defmodule SSDPDirectory.Presence do
  require Logger

  alias __MODULE__
  alias SSDPDirectory.HTTP

  @type command :: Presence.Alive.t() | Presence.ByeBye.t()

  @spec decode(binary) ::
          :error
          | {:ok, command}
  def decode(data) do
    case HTTP.decode_headers(data, []) do
      {:ok, headers, _rest} -&gt;
        process_headers(headers)

      :error -&gt;
        _ = Logger.debug(fn -&gt; "Failed to decode NOTIFY request: " &lt;&gt; inspect(data) end)

        :error
    end
  end

  @spec handle(command) :: :ok
  def handle(%Presence.Alive{} = command) do
    Presence.Alive.handle(command)
  end

  def handle(%Presence.ByeBye{} = command) do
    Presence.ByeBye.handle(command)
  end

  defp process_headers(headers) do
    do_process_headers(headers, %{})
  end

  defp do_process_headers([], args) do
    case args do
      %{command: "ssdp:alive", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.Alive{
           usn: usn,
           type: type,
           location: Map.get(args, :location)
         }}

      %{command: "ssdp:byebye", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.ByeBye{
           usn: usn,
           type: type
         }}

      _ -&gt;
        :error
    end
  end

  defp do_process_headers([{"nts", command} | rest], args) do
    args = Map.put(args, :command, command)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"nt", type} | rest], args) do
    args = Map.put(args, :type, type)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"usn", usn} | rest], args) do
    args = Map.put(args, :usn, usn)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"al", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"location", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([_ | rest], args) do
    do_process_headers(rest, args)
  end
end</code></pre>
<p>It looks like there’s a lot going on here, but it’s actually pretty simple. Starting in <code>decode/1</code>, we continue decoding the packet from <code>MulticastChannel</code>. This time it’s the headers we’re interested in, so we decode those, and then process them in order to determine what kind of command we’re dealing with.</p>
<p>The processing step simply involves recursing over the list of headers, and accumulating the relevant ones in a map . Once we’ve done that, we just construct the corresponding command!</p>
<p>Lastly, the command handler delegates to a third module based on the type of command being processed. For example, in the case of an <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence/alive.ex">ssdp:alive</a> command:</p>
<pre><code>defmodule SSDPDirectory.Presence.Alive do
  require Logger

  alias __MODULE__

  alias SSDPDirectory.{
    Cache,
    Service
  }

  @enforce_keys [:usn, :type]
  defstruct [:location] ++ @enforce_keys

  @type t :: %Alive{}

  @spec handle(Alive.t()) :: :ok
  def handle(%Alive{} = command) do
    _ = Logger.debug(fn -&gt; "Handling ssdp:alive request: " &lt;&gt; inspect(command) end)

    service = %Service{
      usn: command.usn,
      type: command.type,
      location: command.location
    }

    :ok = Cache.insert(service)
  end
end</code></pre>
<p>Here we just construct a service using the parameters in the command, and then store it in our <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/cache.ex">cache</a>:</p>
<pre><code>defmodule SSDPDirectory.Cache do
  use GenServer

  require Logger

  alias __MODULE__
  alias SSDPDirectory.Service

  def start_link(opts \\ []) do
    GenServer.start_link(Cache, :ok, opts)
  end

  def contents(cache \\ Cache) do
    :ets.tab2list(cache)
    |&gt; Enum.into(%{})
  end

  def insert(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:insert, service})
  end

  def delete(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:delete, service})
  end

  def flush(cache \\ Cache) do
    GenServer.call(cache, :flush)
  end

  def init(:ok) do
    table = :ets.new(Cache, [:named_table, read_concurrency: true])

    {:ok, %{table: table}}
  end

  def handle_call({:insert, %Service{usn: usn} = service}, _from, data) when not is_nil(usn) do
    :ets.insert(data.table, {usn, service})

    _ = Logger.debug(fn -&gt; "Cached service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call({:delete, %Service{usn: usn}}, _from, data) when not is_nil(usn) do
    :ets.delete(data.table, usn)

    _ = Logger.debug(fn -&gt; "Evicted service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call(:flush, _from, data) do
    :ets.delete_all_objects(data.table)

    _ = Logger.debug(fn -&gt; …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</a></em></p>]]>
            </description>
            <link>https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-24256984</guid>
            <pubDate>Mon, 24 Aug 2020 02:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How an unemployed 29 year old created the biotech industry]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24255736">thread link</a>) | @unignorant
<br/>
August 23, 2020 | https://www.baybridgebio.com/blog/lessons-from-genentech.html | <a href="https://web.archive.org/web/*/https://www.baybridgebio.com/blog/lessons-from-genentech.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              <div>
                
                
                <p>by Richard Murphey</p>
                <p>
                <img src="https://www.baybridgebio.com/Images/tom_perkins_on_bob_swanson.png"></p><p>There is no shortage of online content about how to start a tech company, but there is comparatively little on how to start a biotech startup.  I recently came across an amazing set of interviews with the founders of Genentech that is the one of the best resources I've seen on biotech entrepreneurship.</p>
                <p>In this post, I'll highlight 16 key quotes from early Genentech leaders and comment on how they can be applied to biotech startups today.</p>
                <p>The interviews that these quotes came from were originally conducted as source material for Sally Smith Hughes' book <a href="https://www.amazon.com/dp/B00629MDKI/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">Genentech: The Beginnings of Biotech</a>.  This book is a must-read for anyone looking to learn about the industry (it's a quick and engaging read as well -- I finished it in a day).  The interview transcripts are worth reading in their entirety (especially the <a href="https://oac.cdlib.org/view?docId=kt9c6006s1&amp;query=&amp;brand=oac4">Bob Swanson</a> and <a href="https://oac.cdlib.org/view?docId=kt467nb7wh&amp;query=&amp;brand=oac4">Dave Goeddel</a> interviews) and are available for free online through <a href="http://bancroft.berkeley.edu/ROHO/projects/biosci/oh_list.html">Berkeley's Bancroft Library Oral History Center</a><sup>1</sup>.</p>
                <br>
                <h3>Early Genentech at a glance</h3>
                
                <p>To set the stage, here is a chart with major value inflection points during the early days of the company.  At this time, Bob Swanson, the founding CEO, was in his late 20s / early 30s, and most of Genentech's scientists, led by Dave Goeddel, were also in their 20s and 30s.  Bob's co-founder, UCSF professor Herb Boyer, was more experienced, but he took a fairly hands-off approach to the science.  Prior to starting Genentech, Bob had been laid off by venture fund Kleiner Perkins.</p>
                <p><img src="https://www.baybridgebio.com/Images/genentech_vc_valuation.png"></p><p>Genentech was created to use emerging genetic engineering technology to create new medicines.  When the company was founded, genetic engineering was a new and relatively unknown field.  The leading scientists in the area thought it would be years or decades before genetic engineering was advanced enough to create medicines.  Big pharma companies were universally dismissive of the technology.</p>
                <p>The venture capital and startup industry was also in its infancy.  There was no such thing as a biotech startup, and there hadn't been a new pharma company created in decades.  Kleiner Perkins, one of the first venture capital funds, had just started (Bob was an early employee of the fund).  Apple was founded on April 1, 1976, less than a week before Genentech was founded.</p>
                <p>(As a side note, Apple and Genentech have always been somewhat linked.  Steve Jobs and Bob Swanson were the original young tech entrepreneurs.  When Genentech went public in 1980, it was the biggest tech IPO ever -- until Apple went public months later.  Art Levinson, who took over as Apple's chairman after Steve Jobs passed away and was on Google's board from 2004-2009, was an early employee at Genentech and was Genentech's CEO in the 1990s and 2000s).</p>
                <br>
                <h4>Overview of early Genentech's strategy</h4>
                
                <p>Genentech's strategy was to first prove that the technology could work -- that bacteria or yeast could be engineered to make human proteins -- and then to use genetic engineering to make products.  They proved the concept by getting bacteria to produce somatostatin, a small hormone.  Somatostatin wasn't useful as a medicine, but it was a relatively simple molecule to make with their tech and thus a good proof-of-concept.</p>
                <p>Genentech's first major product was recombinant insulin.  At the time, insulin was obtained by killing pigs or cows and extracting it from their tissues.  This was an expensive and potentially less safe approach than producing human insulin from bacteria or yeast.  Cloning insulin put Genentech on the scientific and financial map and kickstarted the biotech industry.</p>
                <p>With that context in hand, here's how Genentech approached building a biotech startup:</p>
                <br>
                <h3>Create value by eliminating risk</h3>
                <br>
                <div>
                    <p>Bill Hambrecht…has said the only common characteristic he has noticed in the successful entrepreneurs he's invested in has been that they're all basically conservative…they're willing to go for it, but everyone is looking at how you minimize the risks as you're doing so.</p>
                    <p>- Bob Swanson</p>
                </div>
                <p>In most industries, companies create value by growing revenue or profits.  In biotherapeutics, companies cannot sell products until FDA approves them, which can take years.  But pre-revenue drugs can still be immensely valuable.  In development-stage drug companies, value is created by eliminating technical risk.</p>
                <p>Like many other entrepreneurs, Bob had a unique attitude toward risk: part risk-averse, part risk-seeking.  In the <a href="https://www.perell.com/podcast/josh">words of Josh Wolfe</a>, co-founder of Lux Capital, "entrepreneurs aren't risk takers.  They're risk killers".</p>
                <br>
                <h3>Build a "staircase of value"</h3>
                <br>
                <div>
                    <p>I tried to organize things so that once you had success and created value in the company, then you raised the next round of money for the next success that would create greater value…. So it's sort of building a staircase…to the point where your cash flow is positive from product sales.</p>
                    <p>- Bob Swanson</p>
                </div>
                <p>Bob's goal from the beginning was to build a fully integrated pharma company -- one that developed and sold its own products.  He broke this goal into small units of value creation, and raised a new round of capital to fund each unit.</p>
                <br>
                <h3>"Make something people want"</h3>
                <br>
                <div>
                    <p>This is the essence of a company. The better you understand customers' needs…the more value the product has that they're willing to buy. Then you make more money, and the more money you make, the more it says, "I'm doing things right. I'm a healthy company.”</p>
                    <p>- Bob Swanson</p>
                </div>
                <p>Bob understood that the success of the company depended on its ability to create value for customers.  In the words of Paul Graham, co-founder of Y Combinator, <a href="http://www.paulgraham.com/good.html">"make something people want"</a>.</p>
                <p>This holds true in biotech today.  Understanding a patient's condition, the available treatment options, and unmet clinical needs is the starting point for developing a drug.</p>
                <br>
                <h3>Science first</h3>
                <br>
                <div>
                    <p>One of the reasons companies succeed or fail is which projects get cut and which ones don’t…. It's a judgement call, and that's where you need the very top scientists and medical doctors and everybody to make that call--when to stop it, when is enough, and when to go the next round.</p>
                    <p>- Bob Swanson</p>
                </div>
                <p>Genentech focused on recruiting the best scientists and creating a culture that prized science above all else.  Genentech needed the best scientists because it was working in a competitive, cutting edge field, but also knew that the company needed to be rigorous and scientific in its business decision making.</p>
                <br>
                <h3>Scientists first</h3>
                <br>
                <div>
                    <p><i>Bob Swanson</i>: Boyer's idea was…"Let's give [the young scientists] the credit." He didn't put his name on the insulin paper. And that, for a postdoc, is pretty attractive, rather than having your boss trying for the credit all the time and to keep you as the worker….</p>
                    <p>So the advantages were freedom from seeking out grants, a chance to be owners of the company.</p>
                    <p><i>Sally Smith Hughes</i>: Could you in addition to the equity offer them higher salaries than they were making in academia?</p>
                    <p><i>Bob</i>: Oh, yes. Postdocs continue to be very poorly paid. So yes, we could offer them good salaries.</p>
                </div>
                <p>To recruit the best scientists, Genentech combined the best attributes of academia and industry.  Genentech gave scientists the opportunity to work on important scientific problems, a large degree of freedom, and encouraged them to publish their results.  At the same time, Genentech gave credit based on merit, not seniority, paid scientists much more than they would make in academia, and issued stock grants that could provide life-changing financial gains if the company succeeded.</p>
                <br>
                <h3>Work on ambitious problems</h3>
                <br>
                <div>
                    <p>We don't work on any projects we can't get someone excited about…I think the key to any organization is hiring outstanding people, and helping them get excited about what they're doing.</p>
                    <p>- Bob Swanson</p>
                </div>
                <p>Genentech's ambition was key to recruiting and motivating the best scientists.  As <a href="http://blog.samaltman.com/how-to-be-successful">Sam Altman</a> says, "It’s easier to do a hard startup than an easy startup. People want to be part of something exciting and feel that their work matters."</p>
                <br>
                <h3>Products before platform</h3>
                <br>
                <div>
                    <p>We were very focused on products, and that made a big difference. I know Cetus at the time was more into developing the technology. I said, "Well, let's make a product, and we'll develop the technology we need to make the product, and let the product drive the science, rather than the other way around." Actually, we wound up doing better science because of that, and also we got a product.</p>
                    <p>- Bob Swanson</p>
                </div>
                <p>Genentech was developing arguably the most powerful tech platform in the history of pharma, but it didn't focus on building a platform.  Genentech focused first on products, and built their platform to support product development efforts.  This ended up being a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.baybridgebio.com/blog/lessons-from-genentech.html">https://www.baybridgebio.com/blog/lessons-from-genentech.html</a></em></p>]]>
            </description>
            <link>https://www.baybridgebio.com/blog/lessons-from-genentech.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24255736</guid>
            <pubDate>Sun, 23 Aug 2020 22:12:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Clean Start for the Web]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 86 (<a href="https://news.ycombinator.com/item?id=24255541">thread link</a>) | @tannhaeuser
<br/>
August 23, 2020 | https://macwright.com/2020/08/22/clean-starts-for-the-web.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/08/22/clean-starts-for-the-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The web is in need of some reinvention right now.</p><p>The web’s evolution over the last decade has mirrored the American economy. All of the essential indicators are going “up and to the right,” a steady stream of fundamental advances reassure use that there “is progress,” but the actual experience and effects for individuals stagnates or regresses.</p><p>The crisis affects platforms, creators, and consumers alike.</p><p><em>I’m going to try and dissect and diagnose this situation, a bit. You can skip forward if you just want to read my casual, unprofessional pitch for a reboot of the web. The idea is that we could choose a new lightweight markdown format to replace HTML &amp; CSS, split the web into documents and applications, and find performance, accessibility, and fun again.</em></p><details><summary>This post uses the pedantic definition of "the web"</summary>I've discussed attempts to reinvent the "Internet" a few times. Things like dat, IPFS, and arweave are all projects to reinvent an Internet, or a transport and data-sharing layer. The web is what lies on top of that, the HTML, CSS, URLs, JavaScript, browsing experience.</details><h3 id="the-platform-collapse">The platform collapse</h3><p>The platform side is what changed last week, when <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla laid off 250 employees</a> and indicated that it would affect Firefox development. Firefox wasn’t the #2 browser - that’s Safari, mainly because of the captive audience of iPhone and iPad users. But it was the most popular browser that people <em>chose</em> to use.</p><p><img alt="Chart of browser market share, with Chrome becoming the monopoly" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-chart-of-browser-market-share-with-chrome-becoming-the-monopoly.png"></p><p><em>Chart from <a href="https://gs.statcounter.com/browser-market-share#monthly-200901-202007">statcounter</a></em></p><p>The real winner is not just Chrome, but Chrome’s engine. One codebase, <a href="https://en.wikipedia.org/wiki/KHTML">KHTML</a>, split into <a href="https://en.wikipedia.org/wiki/WebKit">WebKit</a> (Safari), and <a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)">Blink</a> (Chrome, Microsoft Edge, Opera, etc.)</p><p>This a textbook monoculture. In one sense, it’s a victory for collaboration because nobody’s ‘wasting time’ on competing implementations and web developers can expect the same features and bugs across different browsers. But in a deeper way, it threatens one of the basic principles of how the web has evolved.</p><h3 id="specs--implementations">Specs &amp; implementations</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.webp" type="image/webp"><img alt="Decline" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.jpg"></picture></p><p>The web has evolved through a combination of <em>specifications</em> and <em>implementations</em>. Organizations like the <a href="https://whatwg.org/">WHATWG</a>, <a href="https://www.w3.org/">W3C</a>, and <a href="https://www.ietf.org/">IETF</a> have been collaboration spaces for independent developers, corporations, and academics to discuss potential new features of the web. Then, browsers would test those ideas out in a variety of implementations.</p><p>This was an interesting structural piece: it reassured us all that it was <em>possible</em> to follow along, and that a multi-participant web was one of our goals. It was frustrating to pull up <a href="https://caniuse.com/">caniuse</a> and see blank spots, but the idea was that different browsers may take the lead in some areas, but everyone catches up eventually. Chrome was not always the first to jump on features, or the first to optimize.</p><p>It’s slower to collaborate than to work alone, but it was beneficial in some ways that we’ve lost now. Chrome has been moving extremely fast, adding new specifications and ideas at a startling rate, and it’s becoming one of the hardest pieces of software to replicate.</p><p>Mike Healy I think <a href="https://twitter.com/mike_hasarms/status/1296575224599556097">said it best</a>:</p><blockquote><p>Do you think the web has almost ‘priced itself out of the market’ in terms of complexity if only 1-2 organisations are capable of building rendering engines for it?</p></blockquote><p>Not only is it nearly impossible to build a new browser from scratch, once you have one the ongoing cost of keeping up with standards requires a full team of experts. Read Drew DeVault’s <a href="https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html">Web browsers need to stop</a> for that point, and keep reading all of Drew’s stuff.</p><details><summary>What about Flow?</summary>Yep, there’s a <a href="https://www.ekioh.com/flow-browser/">browser called Flow</a>, which may exist and may support a full range of web standards. If it does exist, I’ll be very excited about it, but it has been teased for almost a year now without any concrete evidence, so it could equally be vaporware.</details><h3 id="the-problem-for-creators">The problem for creators</h3><p>The web has gotten much harder to develop for.</p><p>The web has had about 25 years to grow, few opportunities to shrink, and is now surrounded by an extremely short-sighted culture that is an outgrowth of economic and career short-termism. There are lots of <a href="https://frankchimero.com/blog/2018/everything-easy/">ways to do anything</a>, and some of the most popular ways of building applications on the web are - in my opinion - <a href="https://macwright.com/2020/05/10/spa-fatigue.html">usually ghoulish overkill</a>.</p><p>The best way for folks to enter <em>web development</em> in 2020 is to choose a niche, like <a href="https://vuejs.org/">Vue.js</a> or <a href="https://reactjs.org/">React</a>, and hope that there’s a CSS and accessibility expert on their team.</p><p>For folks who just want to create a web page, who don’t want to enter an industry, there’s a baffling array of techniques, but all the simplest, probably-best ones are stigmatized. It’s easier to stumble into building your resume in React with GraphQL than it is to type some HTML in Notepad.</p><h3 id="the-problem-for-consumers">The problem for consumers</h3><p>We hope that all this innovation is <em>for the user</em>, but often it isn’t. Modern websites seem to be as large, slow, and buggy as they’ve ever been. Our computers are <a href="https://macwright.com/2019/11/15/something-is-wrong-with-computers.html">barely getting faster</a> and our internet connection speeds are stagnating (don’t even <em>try</em> to mention 5G). Webpage <a href="https://www.pingdom.com/blog/webpages-are-getting-larger-every-year-and-heres-why-it-matters/">size growth</a> is outpacing it all.</p><p>The end result is that I no longer expect pages to be fast, even with <a href="https://github.com/gorhill/uBlock">uBlock</a> installed in Firefox and a good local <a href="https://sonic.net/">fiber internet provider</a>.</p><p>I don’t want to lay all of the blame at <em>those web developers</em>, though. Here’s a story from an old job that I find kind of funny. We were collecting some data from user interactions to answer simple questions like “do people click to upload or do they drag &amp; drop?” So we enabled <a href="https://segment.com/">Segment</a>, a tool that lets you add data-collection pipelines by including a single script. The problem, though, is that Segment offered a big page of on/off switches with hundreds of data providers &amp; ad-tech companies on it. And, sure, enough, some folks closer to the business side started <em>clicking all those buttons</em>.</p><p>See, the problem with ads and data tracking is that <em>you can</em>, and who is going to say no? (In that instance, I said no, and added a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a> that would block new advertiser access at the page level.)</p><h2 id="recreating-simplicity">Recreating simplicity</h2><blockquote><p>You cannot get a simple system by adding simplicity to a complex system. - <a href="http://erlang.org/pipermail/erlang-questions/2012-March/065087.html">Richard O’Keefe</a></p></blockquote><p>Where do we go from here? Some of the smartest folks out there have been <a href="https://twitter.com/_developit/status/1296628134406692865">advocating for a major version revision</a> of the web.</p><p><em>I am in no way qualified to speculate on a whole new web from scratch, but the <a href="https://www.nytimes.com/2020/08/21/us/california-wildfires.html">air quality</a> is scary so I’m skipping my run and it’s Saturday morning so here we are.</em></p><p>How do we make the web fun, participatory, and good?</p><p>My first thought is that there are two webs:</p><h3 id="the-document-web">The document web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.webp" type="image/webp"><img alt="Illustration of web pages" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.jpg"></picture></p><p>There is the “document web”, like blogs, news, Wikipedia, Twitter, Facebook. This is basically the original vision of the web, as far as I can understand it (I was 2). Basically CSS, which we now think of as a way for designers to add brand identity and tweak pixel-perfect details, was instead mostly a way of making plain documents readable and letting the <em>readers</em> of those documents customize how they looked. This attribute actually <a href="https://twitter.com/autiomaa/status/1296755641164468224">survived for a while in Chrome, in the form of user stylesheets</a>, and <a href="https://davidwalsh.name/firefox-user-stylesheet">still works in Firefox</a>. Though it’s going to be a rough ride in the current web which has basically thrown away <a href="https://en.wikipedia.org/wiki/Semantic_HTML">semantic HTML</a> as an idea.</p><h3 id="the-application-web">The “application” web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.webp" type="image/webp"><img alt="Illustration of machines" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.jpg"></picture></p><p>Then there’s the “application web”. This started as <em>server</em> applications, built with things like <a href="https://www.djangoproject.com/">Django</a> and <a href="https://rubyonrails.org/">Ruby on Rails</a> and before them a variety of technologies that will live forever in corporations, like <a href="https://en.wikipedia.org/wiki/Jakarta_Servlet">Java Servlets</a>.</p><p><a href="https://backbonejs.org/">Backbone.js</a> demonstrated that a lot of these applications could be moved into the browser, and then <a href="https://reactjs.org/">React</a> and its many SPA-style competitors established a new order for the web – highly-interactive, quite complex, client-side applications.</p><h3 id="the-war-between-the-parts-of-the-web">The war between the parts of the web</h3><p>I posit that this dual-nature is part of what gives the web its magic. But it’s also a destructive force.</p><p>The magic is that a simple blog can be creative expression, can be beautifully interactive. This one isn’t, but I’m just saying - <a href="https://www.typewolf.com/site-of-the-day">it’s possible</a>.</p><p>The problem is that the “document web” is often plagued by application characteristics - it’s the JavaScript and animations and complexity that makes your average newspaper website an unmitigated disaster. Where document websites adopt application patterns they often accidentally sacrifice <a href="https://www.a11yproject.com/">accessibility</a>, performance, and <a href="https://en.wikipedia.org/wiki/Web_scraping">machine readability</a>.</p><p>And the “application web” is plagued by the document characteristics - interactive applications are going to great lengths to avoid most of the essential characteristics of HTML &amp; CSS and just use them as raw materials - avoiding writing any HTML directly at all, avoiding <a href="https://mxstbr.com/thoughts/css-in-js">writing any CSS directly at all</a>, avoiding <a href="https://www.react-spring.io/">default animation features</a>, replacing <a href="https://reactrouter.com/">page-based navigation with something that looks like it but works completely differently</a>. The application web uses <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, not HTML, and would like that in the browser itself, or <a href="https://svelte.dev/">Svelte</a>, instead of JavaScript, and would like that too.</p><p>When I read blog posts from ‘traditional web developers’ who are mad that HTML &amp; CSS aren’t enough anymore and that everything is complicated –&nbsp;I think this is largely that the application stack for building websites has replaced the document stack in a lot of places. Where we would use Jekyll or server-side rendering, we now use React or Vue.js. There are advantages to that, but for a lot of minimally-interactive websites, it’s throwing away decades worth of knowledge in exchange for certain performance perks that might not even matter.</p><p>The appeal of social networks is partly because they let us create <em>documents</em> without thinking about web technology, and they provide guarantees around performance, accessibility, and polish that otherwise would take up our time. You don’t have to think about whether your last Facebook post will load quickly on your friend’s phone or whether your Instagram post will be correctly cropped and resized in the timeline - those things are taken care of.</p><p>To some extent, this doesn’t <em>need</em> to be something that only social networks provide, though: standards like <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> and services like <a href="https://www.instapaper.com/">Instapaper</a> show that pleasing formatting and distribution can be done at the <em>platform level</em> and be provided on top of existing vanilla websites.</p><details><summary>These are not absolutes.</summary>Yeah, I can hear it now: but these categories are not …</details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/08/22/clean-starts-for-the-web.html">https://macwright.com/2020/08/22/clean-starts-for-the-web.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/08/22/clean-starts-for-the-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24255541</guid>
            <pubDate>Sun, 23 Aug 2020 21:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loot boxes in online games and their effect on consumers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24254712">thread link</a>) | @infodocket
<br/>
August 23, 2020 | https://www.europarl.europa.eu/RegData/etudes/ATAG/2020/652732/IPOL_ATA(2020)652732_EN.pdf | <a href="https://web.archive.org/web/*/https://www.europarl.europa.eu/RegData/etudes/ATAG/2020/652732/IPOL_ATA(2020)652732_EN.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.europarl.europa.eu/RegData/etudes/ATAG/2020/652732/IPOL_ATA(2020)652732_EN.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24254712</guid>
            <pubDate>Sun, 23 Aug 2020 19:47:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bare Metal Rust Generics]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24254048">thread link</a>) | @cube00
<br/>
August 23, 2020 | https://www.ecorax.net/as-above-so-below-1/ | <a href="https://web.archive.org/web/*/https://www.ecorax.net/as-above-so-below-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I've had the pleasure to work with very experienced firmware developers; the
kind of people who know the size of their <a href="https://en.wikipedia.org/wiki/Red_zone_(computing)">red
zones</a> and routinely
transform coffee into linker scripts and pointer dereferences. In other words,
the <a href="http://www.catb.org/%7Eesr/jargon/html/story-of-mel.html">Mels</a> and <a href="https://www.usenix.org/system/files/1311_05-08_mickens.pdf">Zeus
Hammers</a> of the
world.</p>
<p>When it comes to the tools of our trade, many of them are curious and
experimental. Some of them—very much myself included—explore far enough to leave
pragmatism behind and veer into idealism, stubbornly forcing beautiful round
pegs into industrial square holes. Hey, maybe they're square for a reason, but
it doesn't hurt to try.</p>
<p>The majority of them aren't like that. Your average battle-tested firmware
developer has accrued a healthy distrust of the abstract, probably born of
watching shiny platonic constructs crash and burn with painfully <em>real</em> and
<em>concrete</em> error traces. It is sobering, having to chase a hardfault on a tiny
MCU across enough vtables and templated code to make Herb Sutter puke angle
brackets. No wonder modern approaches are met with some resistance unless the
LOADs and the STOREs are in clear view.</p>
<p>I felt this way too when someone suggested to me, back in 2014, that an
up-and-coming language called <a href="https://www.rust-lang.org/">Rust</a> showed promise
in the embedded field. <em>Surely not</em>, I thought, <em>too high level.</em> Even though I
had been playing with it already, my profoundly ingrained bit-twiddling
instincts told me not to trust a language that supported functional programming,
or one that dared to have an <em>opinion</em> on how I managed my memory. Bah! That's
how you get philosophers to run out of forks, and your forks to turn into
SIGSEGVs.</p>
<p>I was wrong.</p>
<p>Through the past five years of experimentation, I've gone from intrigued, to
optimistic, to <em>convinced</em> that Rust is an ideal language to build industrial
grade, bulletproof bare metal software. Beyond that, I've come to realize that
even the highest level constructs that the base language offers are applicable
to firmware development, very much unlike other languages that span a wide range
of paradigms (I'm looking at you, C++). There are a few reasons I felt this way:</p>
<ul>
<li>Rust's safety guarantees and general strictness bring the debug time down
significantly, so there's less need to spend time developing mental maps of
how high level constructs correspond to hardware primitives.</li>
<li>The type system is <em>great</em> at enforcing local reasoning and preventing leaky
abstractions. Building decoupled systems with no runtime cost is easy.</li>
<li>The compiler error messages are worthy of an AI assistant with <em>concerning</em>
mind-reading abilities.</li>
</ul>
<p>Lately, I've had the chance to work on a Rust
<a href="https://www.st.com/en/microcontrollers-microprocessors/stm32f412.html">STM32F412</a>
project in a professional setting, with one of the goals being to foster a Rust
knowledge pool at my company. The project, <code>Loadstone</code>, is a 32kb secure
bootloader targeting bare metal devices for the medical industry.</p>
<p>While it would've been easier—and much less of a headache to my colleagues—to
stick to a subset of Rust more familiar to C developers, with your <code>for</code>s, your
<code>*mut u8</code>s and your <code>unsafe</code>s, I instead decided not to pull any punches and
make liberal use of generics, iterator adapters, typestate programming and other
stuff that would've made 2010's cuervo cry blood and hug the closest copy of
Kernighan and Ritchie.</p>
<p>The pressures of a real collaborative project have taught me a lot, and many
assumptions have been refined thanks to the criticism of several skilled
outsiders who, as outsiders often do, had a privileged view on things I took for
granted.</p>
<p>A topic that came up frequently in code review is
<a href="https://thume.ca/2019/07/14/a-tour-of-metaprogramming-models-for-generics/">generics</a>.
Perhaps still recovering from a SFINAE nightmare, some colleagues were
unsure about the use of generics to group behaviour that we'd normally write
separate implementations for. The concerns tended to fall in one of three
categories:</p>
<ul>
<li>Runtime performance.</li>
<li>Binary size bloat.</li>
<li>Habitability and readability.</li>
</ul>
<p>The first is easy to dispel, as it often comes from unfamiliarity with static
dispatch. No vtables or heap allocations in anything we're doing, promise! The
second concern is valid but I've found it to be negligible in practice; I have
plans for another blog post giving some concrete benchmarks.</p>
<p>The last concern is the most subjective and thus the hardest to argue, so I
decided to focus on it in this blog series. I'll go over the design process of
two similar flash memory drivers, and hopefully show how generic programming can
make the job easier and the result more habitable, even in the barren, heapless,
rugged world of bare metal firmware.</p>
<blockquote>
<p>Compile times are another common—and very valid—argument against liberal use
of generics. However, it is not a big problem for low footprint embedded
projects like this one.</p>
</blockquote>

<p><a href="https://en.wikipedia.org/wiki/Flash_memory">Flash memory</a> is electronic
non-volatile storage. It's ubiquitous in consumer electronics; any time you
switch a small device off and it <em>remembers something</em>—whether it's settings,
songs, documents, even its own program—chances are you have flash memory to
thank. We'll be looking at two different <em>NOR</em> flash chips, since the first demo
port of <code>Loadstone</code> requires us to operate both:</p>
<ul>
<li>The embedded
<a href="https://www.st.com/en/microcontrollers-microprocessors/stm32f412.html">STM32F412</a>
1MB MCU flash.</li>
<li>The external 128MB <a href="https://www.micron.com/-/media/client/global/documents/products/data-sheet/nor-flash/serial-nor/n25q/n25q_128mb_1_8v_65nm.pdf">Micron
N25Q128</a>
flash chip present in the <a href="https://www.st.com/en/evaluation-tools/32f412gdiscovery.html">STM32F412ZGT6 Discovery
Kit</a></li>
</ul>
<p>You probably knew what flash memory is used for already, but what non-firmware
developers may not know is that flash memory is <em>quirky</em>. You cannot simply
write a byte to a NOR flash address, sir, that would be rude. While a blob of
flash memory will happily turn a <code>1</code> into a <code>0</code>, the opposite operation will
fail silently.</p>
<p>You can think of every <code>1</code> bit (NOR flash's <em>erased</em> state) as a lit candle you
can blow out. However, in this metaphor you don't get a lighter
to light them back up; you get a flamethrower. Without getting into the hardware
principles involved, the design of NOR flash memory requires that you erase
(i.e. set to <code>1</code>) memory <em>in bulk</em>, in chunks often orders of magnitude bigger
than the minimum addressable memory. On most chips you even have a three way
mismatch: your read, write and erase sizes aren't equal. Ugh.</p>
<p>As you can imagine, this makes writing flash drivers a bit of a pain,
particularly because even the smallest write operations turn into <em>read/write
cycles</em>. Writing a single byte requires reading the minimum erasable block
surrounding the targeted address (which may itself require multiple reads),
potentially erasing the entire block, then writing back the original data merged
with the desired byte.</p>
<p>As you can also imagine, nobody but the person writing this driver <em>wants to
care about this</em>. Even in the minimalistic world of bare metal software,
productive collaboration depends on developers filing away these sharp edges,
presenting interfaces that uniformize or hide any aspects of hardware irrelevant
to the bigger design. As such, a first stab at a flash memory interface should
simply offer a way to read and write ranges of memory.</p>
<p>Let's look at some code:</p>
<pre><code><span>pub trait </span><span>ReadWrite {
   </span><span>type </span><span>Error;
   </span><span>type </span><span>Address;
   </span><span>fn </span><span>read</span><span>(</span><span>&amp;</span><span>mut </span><span>self</span><span>, </span><span>address</span><span>: </span><span>Self::</span><span>Address, </span><span>bytes</span><span>: </span><span>&amp;</span><span>mut</span><span> [</span><span>u8</span><span>]) -&gt; </span><span>Result</span><span>&lt;(), </span><span>Self::</span><span>Error&gt;;
   </span><span>fn </span><span>write</span><span>(</span><span>&amp;</span><span>mut </span><span>self</span><span>, </span><span>address</span><span>: </span><span>Self::</span><span>Address, </span><span>bytes</span><span>: </span><span>&amp;</span><span>[</span><span>u8</span><span>]) -&gt; </span><span>Result</span><span>&lt;(), </span><span>Self::</span><span>Error&gt;;
   </span><span>fn </span><span>range</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; (</span><span>Self::</span><span>Address, </span><span>Self::</span><span>Address);
   </span><span>fn </span><span>erase</span><span>(</span><span>&amp;</span><span>mut </span><span>self</span><span>) -&gt; </span><span>Result</span><span>&lt;(), </span><span>Self::</span><span>Error&gt;;
}
</span></code></pre>
<p>The above is what I converged on as a generic interface to a flash
driver. If you're unfamiliar with Rust generics, the above isn't a type, or a
parent class to inherit from. It's more like a Haskell typeclass; a set of
requirements for a concrete type to implement, described in this case in the
form of associated types (<code>Error</code> and <code>Address</code>) and method signatures (<code>read</code>,
<code>write</code>, <code>range</code> and <code>erase</code>).</p>
<p>Even at this early step, some tradeoffs have to be made. The keen,
hardfault-traumatized reader will notice that this interface doesn't lend itself
well to timing sensitive problems. All methods are blocking, and abstracting the
read/write cycle away will naturally lead to non-deterministic write times; a
write may take very little if it only requires toggling bits off, or it might
take very long if it straddles two big sectors requiring erase operations. The
<code>bytes</code> output parameter in <code>read</code> might also strike you as not too rusty, where
returning a <code>Vec&lt;u8&gt;</code> is often idiomatic. Unfortunately we have no heap to work
with, so if you want to take your bytes home you'll have to bring your own bag.</p>
<p>Indeed, it's hard to write the universal interface. This one made sense for the
problems we're solving, but make sure to keep in mind the requirements of your
project!</p>
<h3 id="why-not-simply-write-a-concrete-type">Why not simply write a concrete type?<a href="#why-not-simply-write-a-concrete-type" aria-label="Anchor link for: why-not-simply-write-a-concrete-type">🔗</a></h3>
<p>Ah, the word "simply" is tricky. Datasheet in hand, it may have been easier to
write. It might even save us a few bytes down the line. But altogether I think
the benefits of starting here are well worth the drawbacks:</p>
<ul>
<li>Makes it easy to write test doubles and leverage static dispatch for unit
testing. This kind of approach is what I miss the most when writing C, where
I'm forced to resort to link time substitution or to do things with the
preprocessor too vile to even mention here.</li>
<li>Decouples your design from the get go and makes collaboration easy. Another
developer can immediately start working against this interface, and it's
abstract enough to give you confidence it won't need to be changed as more
knowledge of the hardware emerges.</li>
<li>Going abstract first forces you to think long and hard about what behaviour is
common to each implementation and what behaviour isn't, which helps to <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">not
repeat yourself</a>.</li>
</ul>
<p>But the biggest reason, and one where C++ and Rust diverge, is the fact that
<em>you can reason about this interface locally</em>. This stems from a non-obvious
difference between the C++ template system and Rust traits. Where C++ templates
type check at the point of instantiation, Rust traits type check at the point of
definition.</p>
<p>What does this mean? It means that the inscrutable, seven-feet-deep-in-a-library
C++ template errors are impossible in Rust, because the compiler doesn't need to
go beyond the interface to prove it is used correctly.</p>
<p>A similar interface using C++ …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ecorax.net/as-above-so-below-1/">https://www.ecorax.net/as-above-so-below-1/</a></em></p>]]>
            </description>
            <link>https://www.ecorax.net/as-above-so-below-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24254048</guid>
            <pubDate>Sun, 23 Aug 2020 18:26:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 fatality rate “worst miscalculation in the history of humanity”]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24253636">thread link</a>) | @mrfusion
<br/>
August 23, 2020 | https://muchadoaboutcorona.ca/worst-miscalculation/ | <a href="https://web.archive.org/web/*/https://muchadoaboutcorona.ca/worst-miscalculation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
		<!-- #masthead .site-header -->

	<div id="main">

		<div id="primary">
			<div id="content" role="main">

			
				

				
<article id="post-1262">
	<!-- .entry-header -->

	<div>
		
		
<div><figure><img loading="lazy" src="https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/Ron-Brown-PhD-.jpg" alt="Ron Brown Phd" width="167" height="171" srcset="https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/Ron-Brown-PhD-.jpg 333w, https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/Ron-Brown-PhD--292x300.jpg 292w" sizes="(max-width: 167px) 100vw, 167px"><figcaption><sup>Ronald B. Brown PhD</sup></figcaption></figure></div>



<p>This month, Dr. Ronald B. Brown had a daring paper published in <a rel="noreferrer noopener" href="https://www.cambridge.org/core/journals/disaster-medicine-and-public-health-preparedness/article/public-health-lessons-learned-from-biases-in-coronavirus-mortality-overestimation/7ACD87D8FD2237285EB667BB28DCC6E9#" target="_blank">Disaster Medicine and Public Health Preparedness</a>, conservatively entitled <em>Public health lessons learned from biases in coronavirus mortality overestimation</em>. </p>



<p>“The subject of this article is disruptive, to say the least, although it is not as obvious from the title,” Dr. Brown told me in an email. “The manuscript cites the smoking-gun, documented&nbsp;evidence showing that the public’s overreaction to the coronavirus pandemic was based on the worst miscalculation in the history&nbsp;of humanity,&nbsp;in my opinion. My manuscript underwent an intensive&nbsp;peer-review process. You are the first media guy who has responded to my invitation.”</p>



<p>It’s sadly no surprise the media has not kept Dr. Brown’s phone ringing with interview requests. The abstract, in itself, contains a firecracker where he says: </p>



<p>“Results of this critical appraisal reveal information bias and selection bias in coronavirus mortality overestimation, most likely caused by misclassifying an influenza infection fatality rate (IFR) as a case fatality rate (CFR).”</p>



<p>Is that not what we’ve seen? The number of people they said would be buried in mass COVID-19 graves better reflects how many people simply ended up with a cough and fever.</p>



<p>Dr. Brown added that CDC and WHO documents show that the case fatality rate for influenza was similar to the coronavirus, implying that the lockdowns were pointless. His paper questions why the 2017-2018 influenza season in the United States did not “receive the same intensive media coverage as COVID-19.”</p>



<p>He points out that “the accuracy of coronavirus tests rushed into production during the pandemic were unknown.” And he explores how the  media began focusing on an increase in coronavirus cases while ignoring the decrease in  death rates.</p>



<p>Much of the article looks at how lockdowns and anti-social distancing probably had little or no effect on reducing COVID-19 deaths. He says that “the public’s belief that mitigation measures were responsible for reducing coronavirus mortality may be a post hoc fallacy if lower mortality was actually due to the overestimation of coronavirus deaths.”</p>



<p>Speaking on the damage done by the counter-measures, Brown writes: “The ethics of implementing fear-based public health campaigns needs to be reevaluated for the potential harm these strategies can cause.”</p>



<p>His report includes this mind-map on how we were all mind-warped:</p>



<div><figure><img loading="lazy" width="447" height="447" src="https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/image.png" alt="" srcset="https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/image.png 447w, https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/image-300x300.png 300w, https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/image-150x150.png 150w" sizes="(max-width: 447px) 100vw, 447px"></figure></div>



<p>You can read Brown’s full paper at <a rel="noreferrer noopener" href="https://www.cambridge.org/core/services/aop-cambridge-core/content/view/7ACD87D8FD2237285EB667BB28DCC6E9/S1935789320002980a.pdf/public_health_lessons_learned_from_biases_in_coronavirus_mortality_overestimation.pdf" target="_blank">Cambridge University Press</a>. It succinctly dismisses the notion that the <a href="https://muchadoaboutcorona.ca/resist-the-corona-craze/" data-type="post" data-id="405">corona craze</a> has anything to do with welfare of the people. As Albert Camus warned: “The welfare of the people in particular has always been the alibi of tyrants, and it provides the further advantage of giving the servants of tyranny a good conscience.”</p>
 	



</div><!-- .entry-content -->

	
</article><!-- #post-1262 -->
	
<p><span>				
<hr>
<p><a href="https://muchadoaboutcorona.ca/face-mask-flyer/" rel="prev">previous</a> | 
<a href="https://muchadoaboutcorona.ca/subscribe">subscribe</a> | 
<a href="https://muchadoaboutcorona.ca/sanity-and-her-son/" rel="next">next</a></p>

<p colspan="3">
<img src="https://muchadoaboutcorona.ca/wp-content/uploads/2020/08/john-manley-outside-aug-2020-e1598311423971.jpeg" width="100" alt="John C. A. Manley">
	
	
	
	
	<strong>John C. A. Manley</strong>&nbsp;has spent over a  decade ghostwriting for medical doctors, as well as naturopaths, chiropractors  and Ayurvedic physicians. He publishes the&nbsp;<a href="https://muchadoaboutcorona.ca/subscribe">COVID-19(84) Red Pill Posts</a>&nbsp;–  an email-based newsletter dedicated to preventing the governments of the world  from using an exaggerated pandemic as an excuse to violate our freedom, health,  privacy, livelihood and humanity. He is also writing a novel,&nbsp;<a href="https://muchadoaboutcorona.ca/covid-27">COVID-27: A Dystopian Love Story</a>. You can visit his website at:&nbsp;<a href="https://muchadoaboutcorona.ca/">MuchAdoAboutCorona.ca</a>
	
	
	
	</p></span>
			
			</p></div><!-- #content .site-content -->
		</div><!-- #primary .content-area -->


<!-- #masthead .site-header -->

	</div><!-- #main .site-main -->


	<!-- #colophon .site-footer -->
</div></div>]]>
            </description>
            <link>https://muchadoaboutcorona.ca/worst-miscalculation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24253636</guid>
            <pubDate>Sun, 23 Aug 2020 17:37:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding vulnerable Twitter accounts with expired domains]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24252524">thread link</a>) | @zainamro
<br/>
August 23, 2020 | https://zainamro.com/hacks/finding-vulnerable-twitter-accounts | <a href="https://web.archive.org/web/*/https://zainamro.com/hacks/finding-vulnerable-twitter-accounts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <p><a href="https://zainamro.com/hacks">← hacks</a></p>
    <h3>Finding vulnerable Twitter accounts with expired domains</h3>
    <p>August 23, 2020</p>
    <p>Recently, I discovered a simple yet suprisingly effective attack vector against Twitter accounts (and which likely applies to other platforms as well). This attack vector makes it easy to find and hack vulnerable accounts with login emails that are using expired domains. If a user creates a Twitter account with an email on their own domain, then forgets to renew their domain at some point, that account can be hijacked by registering the domain, forwarding all emails to your email, then submitting a password reset on that account. By itself, this is hardly an attack vector since finding such vulnerable accounts is the more important part, and we already know that owning someone's email is essentially a "game over" situation. This attack becomes more dangerous when you can combine it with an efficient method to find these vulnerable accounts quickly and at scale. As it turns out, this is trivial on Twitter for several reasons attributable to their platform design.</p>
    <p>If you're familiar with Twitter, you know that users are given the option to add a public website url. With a simple script and proxy, an attacker can quickly iterate over millions of accounts and check if the domain in that url is not registered; this usually indicates some likelihood that the Twitter account was created with an email address on a now-expired domain. To verify this, they can submit a password reset which will show them a censored version of the account email address for confirmation; however, even though it's censored, it still provides enough information to check if the email domain matches the expired domain listed on their account profile. If it does, the attacker now knows this is an account that can be hacked. Once this entire process is automated, it makes finding these accounts very easy. This method of account hijacking is very likely being used right now by malicious hackers, and I believe it accounts for a large portion of stolen accounts/handles on the platform.</p>
    <img src="https://zainamro.com/assets/img/twitter-emails.png">
    <p>This attack can potentially be executed on other platforms besides Twitter, assuming one can find a similar discovery method. In Twitter's case, they could make it harder to discover these accounts by not showing any email confirmation upon requesting a password reset. This would make the process more costly for attackers who would no longer be able to verify whether an account can be hacked prior to registering the domain. Or perhaps, Twitter should monitor and unlist domains that are no longer registered and notify users when this happens so that they're aware. As for most users, in addition to turning on 2FA, it's important to be very cautious when using an email on your own domain to create accounts; it makes it much easier to lose access if you forget to renew or can't under certain extreme circumstances like incarceration or death.</p>
    <p><a href="https://news.ycombinator.com/item?id=24252524">Comments</a></p>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    
    
  

</div>]]>
            </description>
            <link>https://zainamro.com/hacks/finding-vulnerable-twitter-accounts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24252524</guid>
            <pubDate>Sun, 23 Aug 2020 15:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a simple Python to C compiler: hello, fibonacci]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24252233">thread link</a>) | @pcr910303
<br/>
August 23, 2020 | https://notes.eatonphil.com/writing-a-simple-python-compiler.html | <a href="https://web.archive.org/web/*/https://notes.eatonphil.com/writing-a-simple-python-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>In this post we'll write a Python to C compiler in Python. This is
especially easy to do since Python has a <a href="https://docs.python.org/3/library/ast.html">builtin parser
library</a> and because a
number of <a href="https://docs.python.org/3/c-api/">CPython internals are exposed for extension
writers</a>.</p>
<p>By the end of this post, in a few hundred lines of Python, we'll be able to
compile and run the following program:</p>
<pre><code>$ cat tests/recursive_fib.py
def fib(n):
    if n == 0 or n == 1:
        return n

    return fib(n - 1) + fib(n - 2)


def main():
    print(fib(40))
$ python3 pyc tests/recursive_fib.py
$ ./bin/a.out
102334155
</code></pre>
<p>This post implements an extremely small subset of Python and
<strong>completely gives up on even trying to manage memory</strong> because I
cannot fathom manual reference counting. Maybe some day I'll find a
way to swap in an easy GC like Boehm.</p>
<p><a href="https://github.com/eatonphil/pyc">Source code for this project is available on Github.</a></p>
<h3 id="dependencies">Dependencies</h3><p>We'll need Python3, GCC, libpython3, and clang-format.</p>
<p>On Fedora-based systems:</p>
<pre><code>$ sudo dnf install gcc python3-devel clang-format python3
</code></pre>
<p>And on Debian-based systems:</p>
<pre><code>$ sudo apt install gcc python3-dev clang-format python3
</code></pre>
<p>
  This program will likely work as well on Windows, Mac, FreeBSD,
  etc. but I haven't gone through the trouble of testing this (or
  providing custom compiler directives). Pull requests welcome!
</p><h3 id="a-hand-written-first-pass">A hand-written first-pass</h3><p>Before we get into the compiler, let's write the fibonacci program by
hand in C using libpython.</p>
<p>As described in the <a href="https://docs.python.org/3/extending/embedding.html#very-high-level-embedding">Python embedding
guide</a>
we'll need to include libpython and initialize it in
our <code>main.c</code>:</p>
<pre><code>#define PY_SSIZE_T_CLEAN
#include &lt;Python.h&gt;

int main(int argc, char *argv[]) {
  Py_Initialize();

  return 0;
}
</code></pre>
<p>To compile against libpython, we'll use
<a href="https://helpmanual.io/man1/python3-config/">python3-config</a> installed
as part of <code>python3-devel</code> to tell us what should be linked
at each step during compilation.</p>
<pre><code>$ gcc -c -o main.o $(python3-config --cflags) main.c
$ gcc $(python3-config --ldflags) main.o
$ ./a.out; echo $?
0
</code></pre>
<p>Cool! Now as we think about translating the fibonacci implementation,
we want to keep everything as Python objects for as long as
possible. This means passing and receiving
<a href="https://docs.python.org/3/c-api/object.html">PyObject*</a> to and from
all functions, and converting all C integers to
<a href="https://docs.python.org/3/c-api/long.html">PyLong*</a>, a "subtype" of
<code>PyObject*</code>. You can imagine that everything in Python is
an <code>object</code> until you operate on it.</p>
<p>
  For more information on objects in Python, check out
  the <a href="https://docs.python.org/3/reference/datamodel.html">Data
  model</a> page in Python docs.
</p><p>To map a C integer to a <code>PyLong*</code> we use
<a href="https://docs.python.org/3/c-api/long.html#c.PyLong_FromLong">PyLong_FromLong</a>. To
map in reverse, we use
<a href="https://docs.python.org/3/c-api/long.html#c.PyLong_AsLong">PyLong_AsLong</a>.</p>
<p>To compare two <code>PyObject*</code>s we can use
<a href="https://docs.python.org/3/c-api/object.html#c.PyObject_RichCompareBool">PyObject_RichCompareBool</a>
which will handle the comparison regardless of the type of the two
parameters. Without this helper we'd have to write complex checks to
make sure that the two sides are the same and if they are, unwrap them
into their underlying C value and compare the C value.</p>
<p>We can use
<a href="https://docs.python.org/3/c-api/number.html#c.PyNumber_Add">PyNumber_Add</a>
and
<a href="https://docs.python.org/3/c-api/number.html#c.PyNumber_Subtract">PyNumber_Subtract</a>
for basic arithmetic, and there are many similar helpers available to
us for operations down the line.</p>
<p>Now we can write a translation:</p>
<pre><code>#define PY_SSIZE_T_CLEAN
#include &lt;Python.h&gt;

PyObject* fib(PyObject* n) {
  PyObject* zero = PyLong_FromLong(0);
  PyObject* one = PyLong_FromLong(1);
  if (PyObject_RichCompareBool(n, zero, Py_EQ) || PyObject_RichCompareBool(n, one, Py_EQ)) {
    return n;
  }

  PyObject* left = fib(PyNumber_Subtract(n, one));

  PyObject* two = PyLong_FromLong(2);
  PyObject* right = fib(PyNumber_Subtract(n, two));

  return PyNumber_Add(left, right);
}

int main(int argc, char *argv[]) {
  Py_Initialize();

  PyObject* res = fib(PyLong_FromLong(7)); // Should be 13

  return PyLong_AsLong(res);
}
</code></pre>
<p>Compile and run it:</p>
<pre><code>$ gcc -c -o main.o $(python3-config --cflags) main.c
$ gcc $(python3-config --ldflags) main.o
$ ./a.out; echo $?
13
</code></pre>
<p>That's great! But we cheated in one place. We assumed that the input
to the <code>fib</code> function was an integer, and we propagated
that assumption everywhere we wrote <code>PyNumber_*</code>
operations. When we write the compiler, we'll need to check that both
arguments are an integer before we call a numeric helper, otherwise we
may need to call a string concatenation helper or something else
entirely.</p>
<h3 id="compiler-architecture">Compiler Architecture</h3><p>We'll break the code into four major parts:</p>
<ol>
<li><code>libpyc.c</code>: helper functions for generated code</li>
<li><code>pyc/context.py</code>: utilities for scope and writing code in memory</li>
<li><code>pyc/codegen.py</code>: for generating C code from a Python AST</li>
<li><code>pyc/__main__.py</code>: the entrypoint</li>
</ol>
<p>
  When I'm writing a new compiler using an existing parser I almost
  always start with the entrypoint and code generator so I can explore
  the AST. However, it's easiest to explain the code if we start with
  the utilities first.
</p><p>We'll also want an empty <code>pyc/__init__.py</code>.</p>
<h3 id="libpyc.c">libpyc.c</h3><p>This C file will contain three helper functions for safely adding,
subtracting, and printing. It will be concatenated to the top of the
generated C file. We'll only support integers for now but this
structure sets us up for supporting more types later on.</p>
<p>We'll use
<a href="https://docs.python.org/3/c-api/long.html#c.PyLong_Check">PyLong_Check</a>
before calling number-specific methods.</p>
<pre><code>#define PY_SSIZE_T_CLEAN
#include &lt;Python.h&gt;

inline PyObject* PYC_Add(PyObject* l, PyObject* r) {
  // TODO: allow __add__ override

  // Includes ints and bools
  if (PyLong_Check(l) &amp;&amp; PyLong_Check(r)) {
    return PyNumber_Add(l, r);
  }

  // TODO: handle str, etc.

  // TODO: throw exception
  return NULL;
}

inline PyObject* PYC_Sub(PyObject* l, PyObject* r) {
  // TODO: allow __add__ override

  // Includes ints and bools
  if (PyLong_Check(l) &amp;&amp; PyLong_Check(r)) {
    return PyNumber_Subtract(l, r);
  }

  // TODO: handle str, etc.

  // TODO: throw exception
  return NULL;
}

inline PyObject* PYC_Print(PyObject* o) {
  PyObject_Print(o, stdout, Py_PRINT_RAW);
  printf("\n");
  return Py_None;
}
</code></pre>
<p>That's it! We could generate these as strings in Python but it gets
hairy to do so. By using a dedicated C file, we can take advantage of
syntax highlighting since this file is only C code. And since we've
marked all functions as <code>inline</code>, there's no runtime cost
to using not embedding these as strings in Python.</p>
<h3 id="pyc/context.py">pyc/context.py</h3><p>This file will contain a <code>Context</code> class for managing
identifiers in scope and for proxying to a <code>Writer</code> class
that contains helpers for writing lines of C code.</p>
<p>We'll have two instances of the <code>Writer</code> class in
<code>Context</code> so that we can write to a body (or
current/primary) region and an initialization region.</p>
<p>The initialization region is necessary in case there are any variables
declared at the top-level. We can't initialize these variables in C
outside of a function since every <code>PyObject*</code> must be
created after calling <code>Py_Initialize</code>. This section will be
written into our C <code>main</code> function before we enter a
compiled Python <code>main</code> function.</p>
<pre><code>import copy


class Writer():
    content = ""

    def write(self, exp: str, indent: int = 0):
        self.content += ("  " * indent) + exp

    def writeln(self, stmt: str, indent: int = 0):
        self.write(stmt + "\n", indent)

    def write_statement(self, stmt: str, indent: int = 0):
        self.writeln(stmt + ";", indent)


class Context():
    initializations = Writer()
    body = Writer()
    indentation = 0

    scope = 0
    ret = None
    namings = {}
    counter = -1

    def __getattr__(self, name: str) -&gt; object:
        # Helpers to avoid passing in self.indentation every time
        outputs = [initializations", "body"]
        for output in outputs:
            if name.startswith(output):
                return lambda s, i=None: getattr(getattr(self, output), name[len(output)+1:])(s, i if i is not None else self.indentation)

        return object.__getattr__(self, name)

    def get_local(self, source_name: str) -&gt; dict:
        return self.namings[source_name]

    def register_global(self, name: str, loc: str):
        self.namings[name] = {
            "name": loc,
            "scope": 0,
        }

    def register_local(self, local: str = "tmp") -&gt; str:
        self.counter += 1
        self.namings[local] = {
            "name": f"{local}_{self.counter}",
            # naming dictionary is copied, so we need to capture scope
            # at declaration
            "scope": self.scope,
        }
        return self.namings[local]["name"]

    def copy(self):
        new = copy.copy(self)
        # For some reason copy.deepcopy doesn't do this
        new.namings = dict(new.namings)
        return new

    def at_toplevel(self):
        return self.scope == 0
</code></pre>
<p>This is all pretty boring boilerplate. Let's move on.</p>
<h3 id="pyc/<strong>main</strong>.py">pyc/<strong>main</strong>.py</h3><p>The entrypoint is responsible for reading source code, parsing it,
calling the code generator, writing the source code to a C file, and
compiling it.</p>
<p>First, we read and parse the source code:</p>
<pre><code>import ast
import os
import subprocess
import shutil
import sys

from context import Context
from codegen import generate

BUILTINS = {
    "print": "PYC_Print",
}


def main():
    target = sys.argv[1]
    with open(target) as f:
        source = f.read()
    tree = ast.parse(source, target)
</code></pre>
<p>Then we write <code>libpyc.c</code> into the body, register builtins,
and run code generation:</p>
<pre><code>
...

def main()
    ...

    ctx = Context()
    with open("libpyc.c") as f:
        ctx.body_write(f.read() + "\n")

    for builtin, fn in BUILTINS.items():
        ctx.register_global(builtin, fn)

    generate(ctx, tree)
</code></pre>
<p>Next, we create a clean output directory and write
<code>main.c</code> with the generated code and a <code>main</code>
function to initialization Python and any global variables:</p>
<pre><code>...

def main():
   ...

    # Create and move to working directory
    outdir = "bin"
    shutil.rmtree(outdir, ignore_errors=True)
    os.mkdir(outdir)
    os.chdir(outdir)

    with open("main.c", "w") as f:
        f.write(ctx.body.content)

        main = ctx.namings.get("main")["name"]
        f.write(f"""int main(int argc, char *argv[]) {{
  Py_Initialize();

  // Initialize globals, if any.
{ctx.initializations.content}
  PyObject* r = {main}();
  return PyLong_AsLong(r);
}}""")
</code></pre>
<p>Finally, we run <code>clang-format</code> and <code>gcc</code> against
the generated C code:</p>
<pre><code>...

def main():
    ...

    subprocess.run(["clang-format", "-i", "main.c"])

    cflags_raw = …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notes.eatonphil.com/writing-a-simple-python-compiler.html">https://notes.eatonphil.com/writing-a-simple-python-compiler.html</a></em></p>]]>
            </description>
            <link>https://notes.eatonphil.com/writing-a-simple-python-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24252233</guid>
            <pubDate>Sun, 23 Aug 2020 14:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft .NET SDK is violating the GDPR, object now]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24251579">thread link</a>) | @dgl
<br/>
August 23, 2020 | https://dgl.cx/2020/08/dotnet-sdk-gdpr | <a href="https://web.archive.org/web/*/https://dgl.cx/2020/08/dotnet-sdk-gdpr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><b>Skip to the end if you just want a template for a "Right to object"
letter.</b></p>

<p>The .NET Core software development kit (SDK) is a set of command line tools
that allow development against Microsoft's .NET. When the command line tool is
run it sends some telemetry back to Microsoft.</p>

<p>This telemetry is <a href="https://aka.ms/dotnet-cli-telemetry">documented</a>, however the way it is implemented appears
against the <a href="https://gdpr-info.eu/">GDPR</a> in multiple ways.</p>

<h3>Collection by default</h3>

<p>Running <code>dotnet help</code> on a clean install, will print a message about telemetry,
but will send the details on that run.</p>

<p><a href="https://dgl.cx/2020/08/dotnet-help.png"><img src="https://dgl.cx/2020/08/dotnet-help.png"></a></p>

<p>Therefore the GDPR requriements under <a href="https://gdpr-info.eu/recitals/no-42/">"Burden of proof and requirements for
consent"</a> cannot be met -- even if we
give Microsoft the benefit of doubt and consider a command line application
somewhat special, it does not give us a chance to opt-out, yet alone opt-in.</p>

<p><a href="https://dgl.cx/2020/08/dotnet-installer.png"><img src="https://dgl.cx/2020/08/dotnet-installer.png"></a></p>

<p>During the installation process, there is a link to Microsoft's <a href="https://privacy.microsoft.com/en-gb/privacystatement">Privacy
statement</a>, however this
does not mention the environment variable needed to opt-out, so there is no way
to opt out before the first piece of data is sent.</p>

<h3>Collecting personal data</h3>

<p>The linked information page, as well as the text printed  in the CLI both say "The data is
anonymous.", it clearly isn't. They collect MAC addresses and the current
working directory, which are sent to their servers hashed.</p>

<p>A key thing to understand: <b>Hashing without a salt does not make the data
anonymous or even pseudonymous.</b></p>

<p>See for example <a href="https://medium.com/@alexewerlof/gdpr-pseudonymization-techniques-62f7b3b46a56">GDPR pseudonymisation
techniques</a>.
Given this, it is a clear violation as <a href="https://gdpr-info.eu/art-6-gdpr/">Article
6</a> requires specific purposes for processing,
but the data was claimed to be anonymous, which it isn't.</p>

<p>A common place to run "dotnet help" might be a home directory, which can often
include a username, e.g. <code>/home/dgl</code>. So while it's hashed it is easily
possible to find the hash that relates to a particular user:</p>

<pre><code>$ pwd
/home/dgl
$ echo -n $PWD | sha256sum
67acfe0ddd44867e1e5da5ddaf25a5b90e928f523cecf614e201c683b7533cf6  -
</code>
</pre>

<p>This matches the relevant part of the JSON sent:</p>

<pre><code>  "Current Path Hash": "67acfe0ddd44867e1e5da5ddaf25a5b90e928f523cecf614e201c683b7533cf6",
</code></pre>

<p>There are some discussions about the collection of MAC addresses in
<a href="https://github.com/dotnet/sdk/issues/6145">issue #6145</a> but no
particular reply from Microsoft; people suspect it's a GDPR violation. Note
that under the GDPR there are time limits for replying, so that's another
potential GDPR issue.</p>

<p>The <a href="https://dgl.cx/2020/08/ms-report.txt">report</a> I sent to Microsoft detailed how a
MAC address is likely not even 48-bits of search space, as we know what ones
are assigned, so brute-forcing is quite possible, particularly when combined
with the fact the search space can be reduced by filtering on the path
hash.</p>

<p>One principle of the GDPR is you need to explain why you're collecting
information, Microsoft do in a round about way, rather than on the link
printed by the command (<a href="https://aka.ms/dotnet-cli-telemetry">https://aka.ms/dotnet-cli-telemetry</a>) which explains what they are collecting, the "why" is hidden on a <a href="https://devblogs.microsoft.com/dotnet/what-weve-learned-from-net-core-sdk-telemetry/">blog post</a>.</p><p>

It says:
</p><blockquote>
Hashed MAC address â€” Determine a cryptographically (SHA256) anonymous and unique ID for a machine. Useful to determine the aggregate number of machines that use .NET Core. This data will not be shared in the public data releases.
<p>

Hashed current working directory â€” Determine build machines from dev machines using the heuristic of a large number of working directories. This distinction helps explain large #s of builds from a machine.
</p></blockquote>


<p>This shows a clear intention to join the data, for some purposes. The "Hashed
MAC address" is obviously understood to be somewhat sensitive as it mentions
they won't share it. Interestingly the same is not said for the current working
directory, which is also sensitive.</p>

<h3>Privacy policy</h3>

<p>As mentioned Microsoft has a <a href="https://privacy.microsoft.com/en-gb/privacystatement">general privacy policy</a>.</p>

<p>This could allow some collection, however:</p>

<blockquote>
You have choices when it comes to the technology you use and the data you
share. When we ask you to provide personal data, you can decline.
</blockquote>

<p>This behaviour would be GDPR compliant, but the key point is due to the first
collection behaviour of e.g. running <code>dotnet help</code> there is no chance to
decline. So the behaviour of the dotnet tool is inconsistent with their own
privacy policy.</p>

<h3>How to respond?</h3>

<p>I sent a report to Microsoft's security team, because arguably incorrect use of
a cryptographic hashing function (SHA256 of the items, without a salt) is a
"Security Design Flaw" which qualifies under the <a href="https://www.microsoft.com/en-us/msrc/bounty-dot-net-core">dotnet 
bug bounty</a>. This was
obviously fishing a bit, and Microsoft denied me. More surpsingly they don't
seem to consider this a problem at all, their final reply was:</p>

<blockquote>
We have updates scheduled for the first run experience and related documentation to make it more accurate. Personal data is handled consistently with GDPR requirements.
</blockquote>

<p>You'll notice that they don't talk about any actual collection changes. Also
interestingly if the data is anonymous as they claim, what "Personal data" are
they referring to in this reply?</p>

<h4>What's the route the GDPR gives us here?</h4>

<p>This is an interesting one, partly <a href="https://gdpr-info.eu/art-11-gdpr/">Article 11 Processing which does not
  require identification</a> could apply, in that they can exclude themselves
from right of access, etc. With the exception of "Right to object".</p>

<p>There are two routes, either we give enough information for Microsoft to be
happy we identify ourselves (and use the right to erasure), or we use the right
to object, which while it doesn't require Microsoft to delete the data
entirely does require them to limit their use of it.</p>

<p>So I can object to any processing of my data, and as I've proved we can use
the MAC address to find my machine in their data. I believe given this has gone
on for several years that even if they make the data collection GDPR compliant,
there is a huge historical collection of data that may need clearing as it has
been collected unlawfully.</p>

<p>In my original <a href="https://dgl.cx/2020/08/ms-report.txt">report</a> to Microsoft I made some recommendations:</p>

<pre><code>
Recommendations:
<ul><li>Remove the telemetry, it avoids any potential GDPR issues;</li>
<li>Delete the historical data (I am not a lawyer, but I suspect this has GDPR
implications);
</li></ul></code></pre>

<p>It appears they do not intend to follow these so I suggest that any user of
.NET Core SDK in the European Union takes matters into their own hands and use
their right to object:</p>

<div>
<p>
[Your full address]
[The date]</p>

<p>To Data Controller, Microsoft Corporation</p>

<p>I am exercising my right to object under the General Data Protection
Regulation (Article 21).</p>

<p>It has come to my attention that Microsoft .NET Core SDK collects telemetry,
and the opt-out process for this data is flawed.</p>

<p>In particular setting the <code>DOTNET_CLI_TELEMETRY_OPTOUT</code> variable
is only suggested the first time the tool is run, so some data may have been
collected against my will.</p>

<p>In light of Microsoft not deleting this telemetry data for everyone (per the
report of David Leadbeater on 3 August 2020). I wish that my telemetry data is
restricted from further processing, as I have set the opt-out environment
variable, but I cannot be sure that some data has not reached Microsoft
already.</p>

<p>The MAC addresses of my machine(s) is/are:</p>

<p>XX:XX:XX:XX:XX:XX</p>

<p>I believe this is enough to identify my records, as they are stored as a
SHA256 hash of this MAC address.</p>

<p>Please send a full response within one calendar month confirming if you will
comply with my request. If you cannot respond within that timescale, please
tell me when you will be able to respond.</p>

<p>If there is anything you would like to discuss, please contact me.</p>

<p>Thank you,
</p></div>

<p>Obviously the somewhat strange thing about this is you reveal your MAC
address to Microsoft in the process, but I'm fairly sure the data protection
around GDPR requests is something that is well scrutinized.</p>

<p>If you do want to send this to Microsoft go to
<a href="https://www.microsoft.com/en-GB/concern/privacy">https://www.microsoft.com/en-GB/concern/privacy</a> and select "I want to contact
Microsoftâ€™s Data Protection Officer".</p>

<p>It's strange this is still an issue as this was previously discussed over
two years ago (see this <a href="https://news.ycombinator.com/item?id=17177241">Hacker News
thread</a>). Let's use our right to object!</p>

</div></div>]]>
            </description>
            <link>https://dgl.cx/2020/08/dotnet-sdk-gdpr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251579</guid>
            <pubDate>Sun, 23 Aug 2020 12:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Persisting as a solo founder]]>
            </title>
            <description>
<![CDATA[
Score 671 | Comments 244 (<a href="https://news.ycombinator.com/item?id=24251403">thread link</a>) | @vishnumohandas
<br/>
August 23, 2020 | https://vishnu.tech/posts/persistence/ | <a href="https://web.archive.org/web/*/https://vishnu.tech/posts/persistence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://sa.vishnu.tech/noscript.gif" alt="">




    



  



    
    <p><time itemprop="datePublished">August 19, 2020</time>
    </p>
    

<p>I quit my job in January 2020 to build a privacy friendly photo organizer.</p>

<p>As a 30 year old whose friends are either getting married or planning
off-springs, what I had underestimated was the difficulty involved in finding a co-founder and how that would compound the difficulty involved in
finding an investor.</p>

<p>Once I accepted the loneliness and the lack of a financial cushion I had to figure out a way to keep building without burning myself out.</p>

<p>It took me a while, but I have found a rhythm that works, and with it, a steady
source of endorphins. Here are some changes that helped me to keep things
moving.</p>

<h2 id="being-patient">Being patient</h2>

<p>Life is no longer as comfortable as it used to be and things are not always
going the way I want them to. Preseverance has been key and indirectly patience
too. Naval’s <a href="https://twitter.com/naval/status/1261481752448524289" target="_blank">take on
meditation</a> (60 minutes x
60 days), was an eye opener. I’ve stuck with it since, and I now have an easier
time identifying negative thought patterns and sitting out situations that would
otherwise overwhelm me.</p>

<p>On some level, spending the last few months locked indoors with my parents, who
are not the most rational people in the world has also helped. But I wouldn’t
recommend it.</p>

<h2 id="reducing-procrastination">Reducing procrastination</h2>

<p>Over time I’ve realized that action precedes motivation and procrastination precedes guilt.</p>

<p>Breaking down tasks into chunks that seem trivial to accomplish has helped reduce the friction in getting started on unexciting grunt work.</p>

<p>Then there are tasks which I loathe from my core, like writing out applications
to VCs explaining why what I’m doing will matter. To those I attach reinforcing
personal reasons, like, “I need the $50k to hire that college junior who I love
working with, and that will give me spare bandwidth to focus on traction channels”.</p>

<h2 id="thinking-clearer">Thinking clearer</h2>

<p>It is sub-optimal to not have a coworker to bounce ideas off and rant about problems to. A lot of times it’s these conversations that help you gain clarity.</p>

<p>It’s a luxury I do not have so every time I feel stuck, I type/scribble my thoughts out, and then question everything that was written, and then document my realizations.</p>

<p>Task tracking has also helped in clearing the path. I write down unstructured
thoughts into a diary, and once I’ve clarity, I promote them to a Notion board
(that’s divided into <em>Thinking</em>, <em>Building</em>, <em>Reading</em>, <em>Writing</em> and
<em>Adulting</em>) and every Monday within an Excel sheet I track what was done, and
what is left to be done.</p>

<h2 id="reducing-distractions">Reducing distractions</h2>

<p>I’ve reduced my information consumption to free up brain cycles. I’ve disabled all notifications on my phone barring a few contacts, and I’ve more or less stopped browsing on it. As an added bonus, this has reduced the negativity with which I perceived the world.</p>

<p>To minimize the overhead of context switches, I split tasks into a tree of checkpoints. Before taking a break I note down the next simplest checkpoint so that when I get back to work there’s little friction to resume.</p>

<p>To help me zone out I keep <a href="https://www.youtube.com/watch?v=5qap5aO4i9A" target="_blank">lofi
beats</a> or
<a href="http://github.audio/" target="_blank">github.audio</a> playing in the background. Listening to the
latter gives me a strange sense of motivation and makes me feel less alone.</p>

<h2 id="staying-grounded">Staying grounded</h2>

<p>I’m lucky to have some friends who call/text every other week. I look at them as my accountability partners and I talk to them about what I’m doing on a high level. While not all of them genuinely care, some do, and these conversations force me to reflect on how well I’m doing what I’m doing.</p>

<p>While Silicon Valley wisdom suggests that if I’m not sleeping I should be
working, failing because of a burn out would be stupid. An advantage of not
having a VC onboard so far has been the freedom to dictate my pace. So I spend
days thinking, reading, fiddling with my violin or just doing nothing when I
feel like writing code is not what I want to do.</p>

<hr>

<p>It’s been 7 months of building alone, and while this is not how I pictured things to be on my last day at work, this is the happiest I have ever been. There’s a long way to go, and the grind seems inviting.</p>

<p>This list is by no means exhaustive, for I’m still learning. If you’ve
anything to share, please join <a href="https://news.ycombinator.com/item?id=24251403" target="_blank">the discussion on HackerNews</a>.</p>

<hr>

<p>If you are curious about what I’ve been building, check out
<a href="https://ente.io/" target="_blank">ente.io</a>.</p>

    <br>
    


</div>]]>
            </description>
            <link>https://vishnu.tech/posts/persistence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251403</guid>
            <pubDate>Sun, 23 Aug 2020 12:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automate third-party tools without API or writing a single line of code]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24251082">thread link</a>) | @kinderjaje
<br/>
August 23, 2020 | https://community.vanila.io/automatio/general/automate-third-party-tools-without-api-or-writing-a-single-line-of-code~90f13832-1d14-4961-8bd7-a72fa98011de | <a href="https://web.archive.org/web/*/https://community.vanila.io/automatio/general/automate-third-party-tools-without-api-or-writing-a-single-line-of-code~90f13832-1d14-4961-8bd7-a72fa98011de">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Less than 1% of web have API. This means if the website or web app doesn't provide API, you will need to build a bot and automate it. If you are not programmer, it means you will need to hire someone to do it, which takes a lot of time and money. Even if you are a web developer, still it gonna take you days or weeks, depending on complexity. But!</p><h3>Meet Automatio</h3><p>This is how you can automate third-party tools without API or writing a single line of code. In this case, I am automating a website/tool for checking domain authority (DA) of the given URL.</p><p>Automatio will be able to deal with the complex scenario of inputting data (URL) into the input field, then solving Google re-captcha, clicking on the submit button, and then extracting the data we need.</p><p>🤖 Built with <a href="https://automatio.co/" target="_blank">Automatio</a> - No Code Web Automation Tool</p><p>🎥 Video URL: <a href="https://youtu.be/3KMDeQo8In8" target="_blank" rel="noopener nofollower">https://youtu.be/3KMDeQo8In8</a></p><p><iframe title="iframe-https://www.youtube.com/embed/3KMDeQo8In8" width="100%" height="200" allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/3KMDeQo8In8"></iframe></p></div></div></div>]]>
            </description>
            <link>https://community.vanila.io/automatio/general/automate-third-party-tools-without-api-or-writing-a-single-line-of-code~90f13832-1d14-4961-8bd7-a72fa98011de</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251082</guid>
            <pubDate>Sun, 23 Aug 2020 11:05:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remembering what you Read: Zettelkasten vs. P.A.R.A]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24251068">thread link</a>) | @stanulilic
<br/>
August 23, 2020 | https://www.zainrizvi.io/blog/remembering-what-you-read-zettelkasten-vs-para/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/remembering-what-you-read-zettelkasten-vs-para/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>I love reading. But retaining what I read tends to be a challenge. I usually walk away from a book feeling good but with only a faint idea of what was in there. Heck, if I spend a couple hours online I’ll barely remember what articles I read! And it’s not just me, studies show that <a href="https://learningsolutionsmag.com/articles/1379/brain-science-the-forgetting-curvethe-dirty-secret-of-corporate-training">you only retain a tiny percentage of what you read</a>.</p><p>I hated the idea of wasting all that time I spent reading, so a year ago I started looking into ways to retain what I learned.</p><p>My first attempt led me to Farnam Street’s tips on <a href="https://fs.blog/2014/05/remembering-what-you-read/">remembering what you read</a>. Their concept of writing your notes on the book itself was liberating (it’s okay to WRITE in my book?!?). Actively writing down notes helped me get more insights out of the text, but those thoughts would then be trapped in the analogue world, locked away until I happened to peruse the book some time in the future.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-1--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/07/2020-05-08-Remember-20what-20you-20read-20-1--1-.png 600w, https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-1--1-.png 769w" sizes="(min-width: 720px) 720px"></figure><p>FS also suggested writing down the book’s core ideas from memory right after you finish the book, but this is a process that requires discipline (unless you like testing yourself?) and things requiring discipline have a distressing tendency to not happen.</p><p>Those tips were exciting, but I couldn’t stick with it. I needed something different.</p><p>Next I came across the <a href="https://writingcooperative.com/zettelkasten-how-one-german-scholar-was-so-freakishly-productive-997e4e0ca125">Zettelkasten note taking method</a>. Its core idea is to create atomic notes, where each note is about exactly one topic (not more than a few paragraphs tops) and nothing more. Then you file the away in your system by linking that note to other notes which seem most relevant to it. All the notes are written in your own words, so you’re really writing down your own thoughts here.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-2--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/07/2020-05-08-Remember-20what-20you-20read-20-2--1-.png 600w, https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-2--1-.png 616w"></figure><p>The key here is that the linking process <strong><strong>groups relevant notes together</strong></strong>. Now when you’re interested in browsing your notes on a given topic, you’ll easily find them. You get to see how your ideas relate to each other as well as discover interesting ways they may play off against or even contradict one another.</p><p>But this technique is time intensive. You have to:</p><ul><li>Save the initial note, paraphrasing what you learned</li><li>Search for relevant notes to link it to</li><li>Potentially update your table of contents to find that note more easily later on</li></ul><p>If you take a lot of notes, the stream of incoming notes can quickly leave you overwhelmed. This technique requires time and dedication.</p><p>I couldn’t stick with it.</p><p>Finally I discovered Building a Second Brain and it’s <a href="https://fortelabs.co/blog/para/">P.A.R.A</a> technique. It offers an easier option for busy people.</p><p>With P.A.R.A. you organize all your notes by purpose, not by category. Let’s say you’re trying to build an app. You’ll have a folder called ‘app’ for all notes about it. Now if you study databases in order to build it, you’ll file any notes you take inside the ‘app’ folder, not in a separate ‘databases’ folder.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png 1000w, https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png 1500w" sizes="(min-width: 720px) 720px"></figure><p>What does this do? By creating purpose-based folders and putting all notes related to that <em>purpose</em> inside it, we’ve created a new way to group relevant notes together. All your notes related to that purpose are available front and center when you open the folder. This lets you avoid the time consuming process of sorting, organizing, and linking your notes in order to make them useful. Just drop the note in the right folder and BAM, that’s it.</p><p>How do you reference old notes? When you start working on a new project (like a writing assignment) you search the relevant folders and pull out notes that seem relevant to your task. All those notes will go into the new project’s folder. You’re effectively discovering related notes on the fly. You’ve avoided the work of double linking and cross referencing your notes. This solution gets you 80% of the way there with 20% of the effort. Just in Time linking.</p><p>When you finish a project, you file away the notes from that project in which ever folder you think they’ll be most useful in, and then archive the project folder. Now you’ve reset the notes to be discoverable the next time you need them.</p><p>And it’s not just good for retention. I’m finding that this purpose-based organization is helping me work much more productively on all my projects!</p><p>Even the step of summarizing what you read is optimized for efficiency. It’s called <a href="https://fortelabs.co/blog/progressive-summarization-a-practical-technique-for-designing-discoverable-notes/">Progressive Summarization</a></p><p>With progressive summarization you don’t bother summarizing what you’re learning, at least not at first. Instead you take the passages you found most interesting and copy them into your notes. If you ever reread those notes in the future then you can start highlighting the phrases that really spoke to you and if you reread them again, only then will you do the work to summarize the ideas in your own words.</p><p>It’s not that summarizing your notes from the beginning is bad, but if you procrastinate on it while still expecting yourself to do it then you’re setting yourself up for failure. Progressive summarization offers you a way to delay summarization while still retaining value.</p><p>Note what’s happened here: Instead of forcing myself to be disciplined about organizing my notes, P.A.R.A. + Progressive Summarization takes advantage of the times when I’m <strong><strong>already excited to work on them</strong></strong>. Each time I touch the notes, I have to take a small amount of effort which is proportionate to my level of interest in the task. <strong><strong>We’ve replaced forced discipline with leveraged excitement.</strong></strong></p><p>There is one other critical aspect of PARA that’s required to keep the system from being overwhelming. Successful followers of the Zettelkasten method seem to follow this instinctively, but <a href="https://zettelkasten.de/posts/collectors-fallacy/">it’s rarely mentioned</a>:</p><p>You’re highly encouraged to <strong><strong>limit</strong></strong> the kind of things you save in your second brain to the following:</p><ul><li>Things related to projects you’re <em>actively</em> working on. Don’t store trivia</li><li>Store things that surprise you: Don’t store stuff you already know</li><li>A 12 select problems that you love to think about</li></ul><p>Tiago recommends thinking about <a href="https://fortelabs.co/blog/how-to-use-evernote-for-your-creative-workflow/">the 12 problems you care most about</a> and <em>only</em> store things related to those problems in your notebook (so skip the articles about ancient mummies…unless you’re an archaeologist).</p><p>By limiting which topics you put in your second brain you free up more cognitive space to notice what you do store. By storing less you’ll remember more 🤯</p><p>Not making your second brain cognitively overwhelming is an under-emphasized part of the PARA system. There shouldn’t be anything in your project’s section unless you are actively working on it. Even the other sections are also meant to be pruned on a regular basis so that they only represent your primary interests. A good rule of thumb: if any folder gains more notes than you can easily skim (~50-100 notes), it might be time to split that folder into two or maybe even delete some notes.</p><p>This is by no means a complete comparison of Zettlekasten and P.A.R.A. (that would be a much longer essay) but it captures the major points.</p><p>Zettelkasten has its benefits: If you want to be able to casually browse through your notes, looking for ideas to spark your imagination, Zettelkasten will most likely have superior results since the ideas are already summarized right there for you. Zettelkasten makes it easy to compose essays and put together speeches, but that’s because you’ve already done the hard work of writing down your thoughts ahead of time.</p><p>It’s requirement to link all notes ahead of time is a HUGE barrier to entry, so Zettlekasten may be best suited to people with a strong research oriented disposition who’re already used to similar practices. The fact that there’s no good software available to help with this makes the process even harder. (Check out <a href="https://notes.andymatuschak.org/zUw5PuD8op9oq8kHvni6sug6eRTNtR9Wqma">Andy Matuschak’s notes</a> for a gorgeous Zettlekasten example)</p><p>P.A.R.A. is great for those who don’t have the time (or willpower) to force themselves to write down notes they may never use. Instead it’s Just-in-Time philosophy saves many hours and lets you be more productive. Tiago has designed P.A.R.A. to work with most productivity apps, but the process is optimized for his app of choice: Evernote.</p><p>All in all, I’m finding P.A.R.A. pretty useful so far. It has yet to pass the ultimate test of any knowledge management system: Will I still be using it three months from now? (ask me after July). I’m already noticing productivity boosts by using the PARA method to store notes for all my projects, so prospects are looking good 😁</p>
				</div><!-- .post-content -->
				<!-- .post-footer -->
				<!-- .comments-area -->


		</article></div>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/remembering-what-you-read-zettelkasten-vs-para/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251068</guid>
            <pubDate>Sun, 23 Aug 2020 11:03:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020: An Isolation Odyssey]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24250068">thread link</a>) | @unhammer
<br/>
August 22, 2020 | http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/ | <a href="https://web.archive.org/web/*/http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>2020: an isolation odyssey</em> is a reenactment of the iconic finale of <em>2001: A Space Odyssey</em> (Stanley Kubrick, 1968). Restaged in the context of home quarantine, the journey through time adapts to the mundane dramas of self-isolation–poking fun at the navel-gazing saga of life alone and indoors.</p>

<p>This project began in late March and was completed in late May, spanning the height of the pandemic in New York City. Staged in a one bedroom Brooklyn apartment, <em>2020</em> presents an obvious similarity to the domestic setting of <em>2001</em>. The stacked videos and synced movements also reveal parallels in emotion. The narrowness of daily life in a single space, transitioning from confusion to acceptance, a distorted sense of time, and ‘returning’ after a transformational event–all experiences analogous to quarantine. </p>

<p>The adapted version delineates the passing of time through wardrobe rather than age, identifying each phase of the character’s journey with a product of self care or PPE. Tools of private entertainment or self betterment are also used as props, questioning our confidence in products and productivity as anchors during times of uncertainty. Multitasking while #wfh, conjuring guilt or longing with unused exercise equipment, your entire being reduced to a measure of time–these scenes all illustrate the absurd comedy of trying to maintain control during this unprecedented and unpredictable time.<br>
</p></div></div>]]>
            </description>
            <link>http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250068</guid>
            <pubDate>Sun, 23 Aug 2020 06:37:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Problem-Solving Techniques That Work for All Types of Challenges (2017)]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24249449">thread link</a>) | @wyclif
<br/>
August 22, 2020 | https://www.spencergreenberg.com/2017/06/1514/ | <a href="https://web.archive.org/web/*/https://www.spencergreenberg.com/2017/06/1514/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>A lot of people don’t realize that there are general purpose problem solving techniques that cut across domains. They can help you deal with thorny challenges in work, your personal life, startups, or even if you’re trying to prove a new theorem in math.</p>



<p>Below are the 26 general purpose problem solving techniques that I like best, along with a one-word name I picked for each, and hypothetical examples to illustrate what sort of strategy I’m referring to.</p>



<p>Consider opening up this list whenever you’re stuck solving a challenging problem. It’s likely that one or more of these techniques can help!</p>



<h4>General Purpose Techniques for Solving Challenging Problems of All Kinds</h4>



<p>1. <strong>Clarifying</strong> – try to define the problem you are facing as precisely as you can, maybe by writing down a detailed description of exactly what the problem is and what constraints exist for a solution, or by describing it in detail to another person, which may lead to you realizing the problem is not quite what you had thought, or that it has a more obvious solution than you thought.</p>



<p>Life Example: <em>“I thought that I needed to find a new job, but when I thought really carefully about what I don’t like about my current job, I realized that I could likely fix those things by talking to my boss or even, potentially, just by thinking about them differently.”</em></p>



<p>Startup Example: <em>“we thought we had a problem with users not wanting to sign up for the product, but when we carefully investigated what the problem really was, we discovered it was actually more of a problem of users wanting the product but then growing frustrated because of bad interface design.”</em></p>



<p>2. <strong>Subdividing</strong> – break the problem down into smaller problems in such a way that if you solve each of the small problems, you will have solved the entire problem.</p>



<p>Startup Example:<em> “My goal is to get company Z to become a partner with my company, and that seems hard, so let me break that goal into the steps of (a) listing the ways that company Z would benefit from becoming a partner with us, (b) finding an employee at company Z who would be responsive to hearing about these benefits, and (c) tracking down someone who can introduce me to that employee.”</em></p>



<p>Math Example:<em> “I want to prove that a certain property applies to all functions of a specific type, so I start by (a) showing that every function of that type can be written as a sum of a more specific type of function, then I show that (b) the property applies to each function of the more specific type, and finally I show that (c) if the property applies to each function in a set of functions then it applies to arbitrary sums of those functions as well.”</em></p>



<p>3. <strong>Simplifying </strong>– think of the simplest variation of the problem that you expect you can solve that shares important features in common with your problem, and see if solving this simpler problem gives you ideas for how to solve the more difficult version.</p>



<p>Startup Example: <em>“I don’t know how to hire a CTO, but I do know how to hire a software engineer because I’ve done it many times, and good CTOs will often themselves be good software engineers, so how can I tweak my software engineer hiring to make it appropriate for hiring a CTO?”</em></p>



<p>Math Example: <em>“I don’t know how to calculate this integral as it is, but if I remove one of the free parameters, I actually do know how to calculate it, and maybe doing that calculation will give me insight into the solution of the more complex integral.”</em></p>



<p>4. <strong>Crowd-sourcing</strong> – use suggestions from multiple people to gain insight into how to solve the problem, for instance by posting on Facebook or Twitter requesting people’s help, or by posting to a Q&amp;A site like Quora, or by sending emails to 10 people you know explaining the problem and requesting assistance.</p>



<p>Business Example: <em>“Do you have experience outsourcing manufacturing to China? If so, I’d appreciate hearing your thoughts about how to approach choosing a vendor.”</em></p>



<p>Health Example: <em>“I have trouble getting myself to stick to doing exercise daily. If you also used to have trouble getting yourself to exercise but don’t anymore, I’d love to know what worked to make it easier for you.”</em></p>



<p>5. <strong>Splintering</strong> – if the problem you are trying to solve has special cases that a solution to the general problem would also apply to, consider just one or two of these special cases as examples and solve the problem just for those cases first. Then see if a solution to one of those special cases helps you solve the problem in general.</p>



<p>Startup Example: <em>“I want to figure out how to improve employee retention in general, let me examine how I could have improved retention in the case of the last three people that quit.”</em></p>



<p>Startup Example: <em>“I want to figure out how to convince a large number of people to become customers, let me first figure out how to convince just Bill and John to become customers since they seem like the sort of customer I want to attract, and see what general lessons I learn from doing that.”</em></p>



<p>6. <strong>Reading</strong> – read the books or textbooks that seems most related to the topic, and see whether they provide a solution to the problem, or teach you enough related information that you can now solve it yourself. </p>



<p>Economics Example: <em>“Economists probably have already figured out reasonable ways to estimate demand elasticity, let’s see what an econometrics textbook says rather than trying to invent a technique from scratch.”</em></p>



<p>Mental Health Example: <em>“I’ve been feeling depressed for a long time, maybe I should read some well-liked books about depression, such as ‘Feeling Good.'”</em></p>



<p>7. <strong>Searching </strong>– think of a similar problem that you think practitioners, bloggers or academics might have already solved and search online (e.g., via google, Q&amp;A sites, or google scholar academic paper search) to see if anyone has done a write-up about how they solved it.</p>



<p>Advertising Example: <em>“I’m having trouble figuring out the right advertising keywords to bid on for my specific product, I bet someone has a blog post describing how to approach choosing keywords for other related products.”</em></p>



<p>Machine Learning Example:<em> “I can’t get this neural network to train properly in my specific case, I wonder if someone has written a tutorial about how to apply neural networks to related problems.”</em></p>



<p>8. <strong>Unconstraining</strong> – list all the constraints of the problem, then temporarily ignore one or more of the constraints that make the problem especially hard, and try to solve it without those constraints. If you can, then see if you can modify that unconstrained solution until it becomes a solution for the fully constrained problem.</p>



<p>Startup Example: <em>“I need to hire someone who can do work at the intersection of machine learning and cryptography, let me drop the constraint of having cryptography experience and recruit machine learning people, then pick from among them a person that seems both generally capable and well positioned to learn the necessary cryptography.”</em></p>



<p>Computer Science Example: <em>“I need to implement a certain algorithm, and it needs to be efficient, but that seems very difficult, so let me first figure out how to implement an inefficient version of the algorithm (i.e., drop the efficiency constraint), then at the end I will try to figure out how to optimize that algorithm for efficiency.”</em></p>



<p>9. <strong>Distracting</strong> – fill your mind with everything you know about the problem, including facts, constraints, challenges, considerations, etc. and then stop thinking about the problem, and go and do a relaxing activity that requires little focus, such as walking, swimming, cooking, napping or taking a bath to see if new ideas or potential solutions pop into your mind unexpectedly as your subconscious continues to work on the problem without your attention.</p>



<p>Example: <em>“For three days, I’ve been trying to solve this problem at work, but the solution only came to me when I was strolling in the woods and not even thinking about it.”</em></p>



<p>Example from mathematician Henri Poincaré: <em>“The incidents of the travel made me forget my mathematical work. Having reached Coutances, we entered an omnibus to go someplace or other. At the moment when I put my foot on the step, the idea came to me, without anything in my former thoughts seeming to have paved the way for it, that the transformations I had used to define the Fuchsian functions were identical with those of non-Euclidean geometry.”</em></p>



<p>10. <strong>Reexamining</strong> – write down all the assumptions you’ve been making about the problem or about what a solution should look like (yes – make an actual list). Then start challenging them one by one to see if they are actually needed or whether some may be unnecessary or mistaken.</p>



<p>Psychology Example: <em>“We were assuming in our lab experiments that when people get angry they have some underlying reason behind it, but there may be some anger that is better modeled as a chemical fluctuation that is only loosely related to what happens in the lab, such as when people are quick to anger because they are hungry.”</em></p>



<p>Math Example: <em>“I need to construct a function that has this strange property, and so far I’ve assumed that the function must be smooth, but if it doesn’t actually need to be then perhaps I can construct just such a function out of simple linear pieces that are glued together.”</em></p>



<p>11.<strong> Reframing</strong> – try to see the problem differently. For instance, by flipping the default, analyzing the inverse of the problem instead, thinking about how you would achieve the opposite of what you want, or shifting to an opposing perspective.</p>



<p>Startup Example: <em>“If we were building this company over again completely from scratch, what would we do differently in the design of our product, and can we pivot the product in that direction right now?”</em></p>



<p>Life Example: <em>“Should move to New York to take a job that pays $20,000 more per year? Well, if I already lived in New York, the decision to stay there rather than taking a $20,000 pay cut to move here would be an easy one. …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spencergreenberg.com/2017/06/1514/">https://www.spencergreenberg.com/2017/06/1514/</a></em></p>]]>
            </description>
            <link>https://www.spencergreenberg.com/2017/06/1514/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24249449</guid>
            <pubDate>Sun, 23 Aug 2020 04:10:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Tools for Clearer Communication]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24248902">thread link</a>) | @AlexDReeve
<br/>
August 22, 2020 | https://reeve.blog/blog/five-tools-for-clearer-communication/ | <a href="https://web.archive.org/web/*/https://reeve.blog/blog/five-tools-for-clearer-communication/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p>We live in a noisy world.</p>



<p>To cut through this noise and create clarity for those around us, we all need to communicate effectively every day. Our work doesn’t speak for itself; we need to collaborate, inspire, and build relationships. To do this, we need to be able to communicate clearly.</p>



<p>As a shy child and introverted adult, externalizing my perspective never came naturally to me. It still doesn’t. In high school, I had the dubious honor of being cast in the only non-speaking role in drama class. Despite this, today, I spend the majority of my day, every day, communicating with people. In some ways, my day job&nbsp;<em>is</em>&nbsp;communication.</p>



<p>Communication is a learned skill. I’m certainly no Obama, but over time, I’ve collected a set of tools that have helped me communicate more effectively.</p>



<h3>Contents</h3>



<ol><li><a href="#rule-of-three">Rule of Three</a></li><li><a href="#answer-explain-example">Answer, Explain, Example</a></li><li><a href="#structure-say-summarize">Structure, Say, Summarize</a></li><li><a href="#feelings-last">Feelings Last Longer Than Words</a></li><li><a href="#pause-context">Pause and Give Context</a></li><li><a href="#so-what">“So What” Is Your One Key Takeaway</a></li></ol>



<h3 id="rule-of-three">Rule of Three</h3>



<p>Three is a magic number in communication. From stories, like The Three Musketeers, Three Blind Mice, and Three Little Pigs, to colloquialisms like “blood, sweat, and tears,” <em>three</em> is everywhere. There’s even a Latin phrase, omne trium perfectum, or <em>everything that comes in threes is perfect</em>.</p>



<p>Why is this? Humans beings seek both patterns and simplicity. We’re pattern-recognition machines, always looking for signals among the noise. Simultaneously, we have limited working memory. We can’t remember a list of fifteen things or even a list of five. But we can remember three, which is the minimum number of objects needed to make a pattern. Three is concise, persuasive, and memorable.</p>



<p>When you say, “there are three reasons we should do this,” people pay attention. They know that three is easy to digest and remember. And you, the speaker, are forced to structure your argument succinctly and compellingly. When you put seven bullet-points in a document or slide, people’s eyes glaze over. When you put a concise list of three, they digest it. Within reason, in verbal or written communication, distill what you have to say down to three.</p>



<h3 id="answer-explain-example">Answer, Explain, Example</h3>



<p>I heard this from a former LinkedIn executive. The premise is simple but powerful. When answering a question, give the answer, then elaborate, then provide an example. That’s it.</p>



<p>By answering the question immediately, you’re getting to the point and giving the person who asked a concise answer. Then you’re supporting it with your rationale. Finally, you’re backing it up with a real example.</p>



<h3 id="structure-say-summarize">Structure, Say, Summarize</h3>



<p>“Structure, Say, Summarize” is a tool I use when communicating something nuanced. The basis is this: First, structure how you’re going to make the statement. Second, make the statement. Third, summarize your position and the “<a href="#so-what">so what</a>.”</p>



<ul><li>Structure: It’s a risk, but there are three reasons we should do this.</li><li>Say: The first reason is X, the second is Y, the third reason is Z.</li><li>Summarize: I know nothing is guaranteed. But, given these reasons, we’re missing an opportunity to grow by not doing this.</li></ul>



<p>This structure is akin to a Dale Carnegie quote: “Tell the audience what you’re going to say, say it; then tell them what you’ve said.”</p>



<p>Verbal communication is messy, and it’s difficult for people to follow spoken paragraphs. Even when you don’t have a tidy list of three, starting with “there are a few reasons,” making stating a few points, then summarizing your view is a powerful way to communicate more clearly.</p>



<p>But don’t use this all the time, or you’ll seem like a robot.</p>



<h3 id="feelings-last">Feelings Last Longer Than Words</h3>



<p>People will often forget what you said, but they’ll never forget how you made them feel. You might have made a logically sound argument, but if the recipient didn’t feel enthused, inspired, or understood, it probably won’t stick.</p>



<p>Feelings are why the world’s most iconic brands are so effective. We don’t remember every detail, every line of copy, or every number. But they make us feel a certain way, and feelings are sticky.</p>



<p>If you want to inspire action or lead a team, logic is important, but so is ensuring people are inspired when they walk away from an interaction. People won’t remember everything you said, but they’ll remember how you made them feel.</p>



<h3 id="pause-context">Pause and Give Context</h3>



<p>Never assume that everyone has the same context that you do. There’s a magical and straightforward sequence of words for this: “Let me give some context to make sure we’re on the same page.”</p>



<p>In any given conversation, everyone has a perspective formulated from a different set of inputs. The more closely aligned you can get these inputs, the more effective your communication will be. Shared context helps avoid “talking past each other” situations.</p>



<p>One of the tenets of effective communication is <em>over-communication</em>. Most people associate this with being annoying or spam. In my experience, that isn’t true. Over-communication is about never assuming that people have the same context that you do.</p>



<h3 id="so-what">“So What” Is Your One Key Takeaway</h3>



<p>For every piece of communication that you create, find the “so what.” Whether a presentation, document, or slide,&nbsp;if someone asked, “so what?”, what would you say? </p>



<p>Whatever the answer to that question is, make sure it comes across clearly. The answer to “so what?” usually involves articulates the implication for the audience.</p>



<p>An easily applicable tip here is to title your slides or headers with the “so what” for that particular slide or section. Hone in on the most important takeaway and the implication for the audience — why should they care?</p>

			</div></article></main></div></div></div>]]>
            </description>
            <link>https://reeve.blog/blog/five-tools-for-clearer-communication/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24248902</guid>
            <pubDate>Sun, 23 Aug 2020 01:53:49 GMT</pubDate>
        </item>
    </channel>
</rss>
