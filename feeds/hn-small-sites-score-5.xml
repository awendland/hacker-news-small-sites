<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 17 Oct 2020 08:29:14 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 17 Oct 2020 08:29:14 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[LDM: My Favorite ARM Instruction]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24785357">thread link</a>) | @one_and_only
<br/>
October 14, 2020 | https://keleshev.com/ldm-my-favorite-arm-instruction/ | <a href="https://web.archive.org/web/*/https://keleshev.com/ldm-my-favorite-arm-instruction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  


  

<center>Vladimir Keleshev • 2020-10-13</center>


<p>LDM—or <em>load multiple</em>—is my favorite assembly instruction of the ARM instruction set. Here’s why.</p>
<p>First, let’s discuss what LDM does. An example:</p>
<pre><code>ldm r4, {r0, r1, r2, r3}</code></pre>
<p>Here, it takes a <em>base register</em> (in this case, <code>r4</code>) and a <em>register set</em> (in this case, <code>{r0, r1, r2, r3}</code>). It loads consecutive words from the address in the base register into the registers in the set. In this example, the effect could be described using the following C-like pseudo-code:</p>
<pre><code>r0 = r4[0];
r1 = r4[1];
r2 = r4[2];
r3 = r4[3];</code></pre>
<p>That’s quite a few assignments for a single instruction! And that’s why it’s called <em>load multiple</em>.</p>
<p>The set notation also allows for ranges. We can rewrite the previous example as follows:</p>
<pre><code>ldm r4, {r0-r3}</code></pre>
<p>Any and all of the 16 ARM registers are allowed in the set. So, the following is legal:</p>
<pre><code>ldm r0, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15}</code></pre>
<p>The register set is encoded as a 16-bit mask in a 32-bit instruction. Here’s a simplified encoding of the original example:</p>
<figure>
<img src="https://keleshev.com/ldm-my-favorite-arm-instruction/ldm-encoding-arm.svg" alt=""><figcaption>Simplified encoding of the LDM instruction</figcaption>
</figure>
<p>Such instruction is a perfect fit for a <a href="https://en.wikipedia.org/wiki/Load%E2%80%93store_architecture">load-store architecture</a> like ARM, where the primary workflow is:</p>
<ul>
<li>load many values from memory into registers,</li>
<li>perform operations exclusively on registers,</li>
<li>store results back from registers into memory.</li>
</ul>
<p>The opposite of LDM is STM—<em>store multiple</em>.</p>
<!---Since both of them operate on *sets* of registers (which are implemented as bit masks), you can't directly select the order in which the values are loaded or stored.
The set `{r0, r1, r2}` is the same as `{r2, r1, r0}`.
That's why-->
<h2 id="block-copy">Block copy</h2>
<p>With these two, you can copy large blocks of memory fast. You can copy eight words (or 32 bytes!) of memory in just two instructions:</p>
<pre><code>ldm r0, {r4-r11}
stm r1, {r4-r11}</code></pre>
<p>LDM and STM also have auto-increment variants (denoted with “!”) where the base register is incremented by the number of words loaded/stored so that you can do the copying in a fast loop:</p>
<pre><code>ldm r0!, {r4-r11}
stm r1!, {r4-r11}</code></pre>
<h2 id="implementing-stacks">Implementing stacks</h2>
<p>ARM’s POP instruction is simply an alias for LDM with a stack pointer (and auto-increment). The following two are exactly the same:</p>
<pre><code>ldm sp!, {r0-r3}
pop {r0-r3}</code></pre>
<p>And the PUSH instruction is an alias for an STM variant (STMDB).</p>
<p>You can push and pop large quantities to and from the stack in one go. And if you replace SP by another register you can implement efficient stacks in other regions of memory. For example, you can implement a <a href="https://en.wikipedia.org/wiki/Shadow_stack">shadow stack</a> in the heap.</p>
<h2 id="saving-registers">Saving registers</h2>
<p>Are you hesitating to use the call-preserved registers because you need to save them, and you might as well use a stack slot anyway? Not any more, because you can save all call-preserved registers you want to use in one go:</p>
<pre><code>push {r4-r11}</code></pre>
<h2 id="prologue-and-epilogue">Prologue and epilogue</h2>
<p>On ARM, the first four arguments, the return address (LR) and the frame pointer (FP) are all passed in registers. That’s why it’s especially important to have efficient prologues and epilogues. Fortunately, you can save FP and LR in one go, using a fairly standard ARM prologue:</p>
<pre><code>push {fp, lr}</code></pre>
<p>And then restore both and return (for the epilogue):</p>
<pre><code>pop {fp, lr}
bx lr</code></pre>
<p>Even better, you can restore both and return in one go!</p>
<pre><code>pop {fp, pc}</code></pre>
<p>This works by popping the return address value (LR) into the program counter register (PC), so you don’t need an explicit return!</p>
<p>This is good enough in itself, but you can—<em>at the same time</em>—spill some arguments onto the stack (for example, if their address is taken):</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>Or, you can save FP and LR and—<em>at the same time</em>—allocate some space on the stack:</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>In this case, we push <code>r0-r3</code> not for their value but to advance the stack pointer by four words.</p>
<h2 id="arm64">ARM64</h2>
<p>I suspect it was a difficult trade-off, but when it was time to design the 64-bit version of the ARM instruction set, the decision was made to double the number of registers to 32. I remember reading a paper saying that this change improves the performance by about 6% across the board. With 32 registers it is no longer possible to encode a bitmask of all registers into a 32-bit long instruction. So, instead, ARM64 has LDP and STP: load pair and store pair, which are the spiritual successors of LDM and STM.</p>
<hr>
<p>This blog post started out originally as a <a href="https://twitter.com/keleshev/status/1285654345988673536">Twitter thread</a>. <a href="https://keleshev.com/" title="Home">■</a></p>
<hr>
<p><em>Did you like this blog post? If so, check out my new book:</em> Compiling to Assembly from Scratch. <em>It teaches you enough assembly programming and compiler fundamentals to implement a compiler for a small programming language. </em></p>


      
  <p><a href="https://keleshev.com/compiling-to-assembly-from-scratch">
       <img alt="Compiling to Assembly from Scratch, the book by Vladimir Keleshev" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300">
      </a>
  </p>
  <hr>


</div>]]>
            </description>
            <link>https://keleshev.com/ldm-my-favorite-arm-instruction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24785357</guid>
            <pubDate>Thu, 15 Oct 2020 06:04:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eric Yuan's Visa Application Was Rejected 8 Times]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24783979">thread link</a>) | @shsachdev
<br/>
October 14, 2020 | https://www.careerfair.io/reviews/eric-yuan-effect | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/eric-yuan-effect">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
I’ve been reading about Eric Yuan, founder of Zoom.
</p>
<p>
Yuan migrated to the USA from China in the 80s. He had heard Bill Gates speak about the internet and he wanted to be a part of the digital revolution. 
</p>
<p>
So he applied for his visa. He was rejected. He applied again. Rejected again.
</p>
<p>
9 tries. It took Eric Yuan 9 tries to finally get his visa for the USA.
</p>
<p>
Once in the USA, he started working at the video conferencing software company WebEx. 
</p>
<p>
He worked there for a decade and rose up the ranks to become the VP of Engineering. 
</p>
<p>
Under Yuan’s leadership, WebEx grew to more than 750 engineers and had an annual revenue of around $1B (and was later acquired by Cisco). Safe to say the company was doing well. 
</p>
<p>
But there was a problem. 
</p>
<p>
The video conferencing software <em>sucked</em>. 
</p>
<p>
Yuan would meet with customers and they would be unhappy. They’d complain about video and audio lag. Connectivity issues. All sorts of stuff. 
</p>
<p>
In Yuan’s own words:
</p>

<blockquote>
  Before I left Cisco I spent a lot of time talking to WebEx customers and every time I talked to them I felt very embarrassed because I did not see a single happy customer, and I tried to understand why that was.
    <span>Eric Yuan</span>
</blockquote>

<p>
So in 2011, Yuan left. He decided to start his own company with the mission of building the best video conferencing software in the world. 
</p>
<p>
After he left, 40 of the 800 engineers he worked with immediately joined him at Zoom. 
</p>
<p>
And according to <a href="https://twitter.com/dscheinm/status/1300544031458553859">this tweet</a>, almost all of the others sent in resumes to work with him. He had something like 1000 job inquiries within a week of announcing his leaving.
</p>
<p>
Talk about engineering loyalty. 
</p>
<p>
Today Zoom is valued at more than $40 billion. The pandemic may have accelerated the company’s growth but make no mistake: this was an overnight success 9 years in the making. 
</p>
<h2>Takeaway</h2>
<p>
I think the part that stands out the most to me is that Yuan actually had the courage to leave Cisco and go on to start Zoom. 
</p>
<p>
There is often great inertia that prevents us from leaving jobs we’re unhappy with. 
</p>
<p>
In Yuan’s case, he had by all measures a very successful career ever since he immigrated to the US. Most people in his shoes wouldn’t even bother resigning from a comfortable VP of Engineering position. 
</p>
<p>
So he could have settled and just resigned himself to the fact that maybe video conferencing software was supposed to be like this. After all, there was very little competition in the market. 
</p>
<p>
But he didn’t. He chose discomfort and hundreds of other engineers believed in him. 
</p>
<p>
Keep moving forward and don’t settle. You might be surprised at how many people follow you. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/eric-yuan-effect</link>
            <guid isPermaLink="false">hacker-news-small-sites-24783979</guid>
            <pubDate>Thu, 15 Oct 2020 01:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Fascinating Influence of Cyclone (2019)]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24782047">thread link</a>) | @lemming
<br/>
October 14, 2020 | http://pling.jondgoodwin.com/post/cyclone/ | <a href="https://web.archive.org/web/*/http://pling.jondgoodwin.com/post/cyclone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

<p>In 2001, Trevor Jim (AT&amp;T Research) and Greg Morrisett (Cornell) launched
a joint project to develop a safe dialect of the C programming language,
an outgrowth of earlier work on
<a href="https://www.cs.cornell.edu/talc/">Typed Assembly Language</a>.
After five years of hard work and some published
<a href="https://cyclone.thelanguage.org/wiki/Papers/">papers</a>,
the team (including Dan Grossman, Michael Hicks, Nik Swamy, and
<a href="https://cyclone.thelanguage.org/wiki/People/">others</a>)
released <a href="https://cyclone.thelanguage.org/">Cyclone 1.0</a>.
And then the developers moved on to other things.</p>

<p>Few have heard of Cyclone and almost no one has used it.
And yet, when you throw the right rock into a receptive pond,
waves of influence ripple outwards.
Cyclone was a large, well-fashioned stone; the ripples of its zeitgeist,
as well as the notable innovations it distilled and pioneered,
continue to spread in fascinating ways.</p>

<p>Before telling this story, here is my warning:
Innovation and influence is a complicated social process.
Nothing new happens in a vacuum.
Thousands of people throw interesting rocks into the pond every year,
influenced by rocks tossed earlier.
No single post can do justice to all these chaotic ripples.</p>

<p>To keep this story coherent and digestible, I focus on certain themes:
progress in the evolution of
static safety and the application of linearity to memory management and concurrence,
as manifested in a few chosen mainstream (“imperative”) programming languages.
This means tons of relevant and important detail about influential academic languages
and research will receive insufficient attention.
Don’t let my editorial shortcomings mislead you into a simplistic understanding of cause and effect.
Instead, be curious, explore the historical record,
and appreciate the contributions of so many pioneers.</p>

<h2 id="cyclone">Cyclone</h2>

<p>At the end of the 20th century, systems software was usually built
using C (or pre-“modern” C++).
Because their semantics closely mirror the way CPUs are used,
these languages produce lean, high-performance systems.
The price one pays for this efficiency is the risk of safety bugs,
such as buffer overflows,
making our critical systems vulnerable to malicious actors.</p>

<p>The goal of the Cyclone team was
to build a C-compatible language that was at least as fast and lean,
but much, much safer. Their notion of safety was radical for its time:
unsafe programs should be hard to write, impossible to compile,
and panic when safety violations are encountered at runtime.</p>

<p>Vulnerabilities targeted for extinction included: buffer overflow,
null pointer de-referencing, use-after-free, dangling pointers, double free,
format string attacks, uninitialized variable use, unsafe casts,
indefinite returns, cross-scope gotos, and undiscriminated unions.</p>

<p>The primary weapon of choice for improving safety (and versatility)
came from strengthening C’s notoriously
weak type systems through the skillful application of
prior art from ML, Haskell, and published research, particularly:</p>

<ul>
<li><p><strong>Algebraic data types</strong>. Although C supports product types
with <code>struct</code>, use of <code>union</code> for sum types can be unsafe. Instead,
Cyclone introduces fixed-size <a href="https://cyclone.thelanguage.org/wiki/Tagged%20Unions/">tagged unions</a>,
variable-sized <a href="https://cyclone.thelanguage.org/wiki/Datatypes/">datatypes</a>,
and <a href="https://cyclone.thelanguage.org/wiki/Pattern%20Matching/">pattern matching</a>.
Cyclone also supports tuples, enabling functions to return multiple values.</p></li>

<li><p><strong>Quantified types</strong>. Cyclone supports
<a href="https://cyclone.thelanguage.org/wiki/Cyclone%20for%20C%20Programmers/#PolymorphicFunctions">parametric polymorphism</a>
(generics) on functions and types.
Despite being constrained to word-sized types and unable to monomorphize,
this feature is sufficient for supporting type-generic boxed collections.
Cyclone also supports abstract,
<a href="https://cyclone.thelanguage.org/wiki/Existential%20types/">existential types</a>,
with similar limitations.
Similar to traits, these allow use of method-like functions across
differently-implemented concrete types.</p></li>

<li><p><strong>Region-based memory management</strong>.
Cyclone was heavily inspired by
<a href="https://en.wikipedia.org/wiki/Region-based_memory_management#Region_inference">Tofte and Talpin</a>’s
seminal work on regional inference in the mid-1990s. As implemented in
<a href="https://www.researchgate.net/publication/220606837_A_Retrospective_on_Region-Based_Memory_Management">ML Kit</a>
(with Birkedal and others),
whole program inference made it possible to replace the use of
garbage-collected (GC) memory with faster, scope-nested memory regions (arenas).
Related work by Aiken applied arenas and ref-counted memory management to C.
The Cyclone team improved on these techniques,
replacing cross-functional inference with explicit
<a href="https://cyclone.thelanguage.org/wiki/Memory%20Management%20Via%20Regions/">region</a> annotations.
Importantly, they enriched this scheme to
support an unheard-of variety of safe, automatic memory management strategies:
arena regions (including first-class arenas), reference-counted,
tracing GC (via Boehm), and something they call the
<em>unique</em> region.</p></li>

<li><p><strong>Linear/affine types</strong>. Cyclone’s
<a href="https://cyclone.thelanguage.org/wiki/Pointers%20with%20Restricted%20Aliasing/#UniquePointers"><em>unique</em> region</a>
is a useful application of the
<a href="https://en.wikipedia.org/wiki/Linear_logic">linear logic</a>
work from the late 1980s by Girard, refined later by Wadler and then Walker.
By guaranteeing that allocated memory will only ever have
one owner (reference), we get safe, deterministic memory management
without run-time GC bookkeeping costs. Reference-counted memory management
is also more efficient when built using linear logic.
That said, linear logic (and regions) adds complexity to a language in terms
of move semantics and quantified types, challenges the Cyclone team
had to work through.</p></li>
</ul>

<p><a href="https://cyclone.thelanguage.org/wiki/Cyclone%20for%20C%20Programmers/#Pointers">Pointers</a>
required the most work to make them safe:</p>

<ul>
<li><p><strong>Null pointers</strong>.
Cyclone addressed Tony Hoare’s so-called “billion dollar mistake” by offering a choice.
You may define pointers as non-nullable (e.g., <code>int @x</code>) and use them freely and safely.
Or, if you do need a nullable pointer, the compiler will not let you de-reference it
until you demonstrate first that it is not null.</p></li>

<li><p><strong>Fat and bounded pointers</strong>.
To protect against buffer overflows, Cyclone offers “fat” pointers (<code>char ?</code>),
which bake in accurate bounds data next to the pointer.
Pointer arithmetic is allowed, but any attempt to
access elements outside the bounds triggers a runtime error.
Bounded pointers offer similar capability in a somewhat different way.</p></li>

<li><p><strong>Memory-safe pointers</strong>.
To ensure pointers can only access valid, live data,
a pointer type can be annotated with the region its object acquired memory from.
This annotation ensures that the object
is freed only when the last usable pointer to that object expires.
Using data flow analysis, pointers to stack allocated data are also kept safe.</p></li>

<li><p><strong>Polymorphic pointers</strong>.
With so many type annotations on pointers, type safety could
force us to duplicate code (or use generics) for every possible
pointer variation being passed to functions.
Cyclone overcame this usability challenge by supporting
<a href="https://cyclone.thelanguage.org/wiki/Pointer%20Subtyping/">polymorphic pointer types</a>,
which accommodate a wide variety of pointer types safely.</p></li>
</ul>

<p>More could be said about Cyclone’s safety extensions
(e.g., <a href="https://cyclone.thelanguage.org/wiki/Cyclone%20for%20C%20Programmers/#Exceptions">exception handling</a> and
<a href="https://cyclone.thelanguage.org/wiki/Definite%20Assignment/">definite assignment</a>),
but I think you get the point.
The Cyclone team was diligent and thorough about hunting down
and mitigating safety vulnerabilities.
They even worked through a static type strategy for
making <a href="https://homes.cs.washington.edu/~djg/papers/cycthreads.pdf">multi-threading safe</a>,
using thread locks and thread-local data.</p>

<p>Remarkably, all these safety and versatility improvements were designed to preserve
as much backward compatibility with C as possible.
For understandable reasons, they wanted to make the path to safety
as painless as possible for existing C programmers.
Their papers show helpful examples where C code was ported to Cyclone,
showing benchmark results that illustrate that safety need not
incur a steep performance penalty.</p>

<h2 id="c-ownership-and-aliasing">C++, Ownership and Aliasing</h2>

<p>Before going forward in time, I want to contrast Cyclone’s
safe memory management journey with that of C++.
C++’s memory management rests on two key features available before 1990:
templates (more versatile and complex than typical generics) and
Resource Acquisition Is Initialization (RAII).
Using RAII, a program can acquire and use some resource local to a block,
and expect the compiler to automatically
destroy that resource at the end of that block.
However, RAII does not work with objects dynamically allocated using <code>new</code>.</p>

<p>To address the potential for leaks due to forgotten <code>delete</code>s,
the 1997 standard introduced <code>auto_ptr</code>, the first “smart” pointer.
This template-defined feature acts like a pointer, while still
empowering RAII to ensure automatic deletion of the owned object.
Even better, <code>auto_ptr</code> was linear-like<sup>1</sup>:
Only one variable owned the pointed-at resource.
Assignment would transfer ownership.</p>

<p>However, <code>auto_ptr</code> had a fatal design flaw, limiting its usefulness.
In 2002, inspired by Andrew Koenig from Bell Labs, Howard Hinnant authored
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2002/n1377.htm#move_ptr%20Example">“A proposal to add move semantics to C++”</a>.
A key motivation was performance:
copying a pointer non-destructively is far cheaper than any sort of deep copy.
The standards process resulted with <code>unique_ptr</code> replacing <code>auto_ptr</code>
in 2005’s technical report (TR1) and ultimately C++11.
The same standard also introduced <code>shared_ptr</code>, a ref-counted smart pointer,
based on practices dating back to the late 1990s.</p>

<p>Thus, by 2006, divergent influences had resulted in both Cyclone and C++
supporting the same two forms of automatic memory management:
single owner (linear) and reference counted.
That said, Cyclone’s region-based memory management was more
versatile (as it also supported arenas and tracing GC) and far safer.</p>

<p>When it came to rigorous memory safety, the Cyclone team had a deeper well of academic research
and prior practice to leverage.
Besides the influences I mentioned earlier, they drew on
alias types (Smith and Walker, 2000, as implemented in Typed Assembly Language),
Objective C’s use of reference counting,
as well as the influential <a href="https://cacm.acm.org/magazines/2019/2/234356-separation-logic/fulltext">separation logic</a>
(Reynolds, O’Hearn, Pym, 2000-2002).
As Greg Morrisett says: “Cyclone’s contribution was to find a common framework to put a bunch of different things in.”</p>

<p>The handling of “borrowed” references illustrates the safety gap
between Cyclone and C++.
Using <code>get()</code> on a C++ smart pointers returns a aliased pointer.
Since C++ does no tracking to ensure pointer aliases are always safe to use,
it is problematically easy to use a pointer after the object it points to has been freed.</p>

<p>Cyclone also has a way to create a polymorphic pointer borrowed from any region-based pointer.
In contrast to C++, Cyclone carefully tracks the scope lifetime of every
borrowed pointer, often implicitly. Sophisticated compile-time analysis of
region lifetimes (including …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://pling.jondgoodwin.com/post/cyclone/">http://pling.jondgoodwin.com/post/cyclone/</a></em></p>]]>
            </description>
            <link>http://pling.jondgoodwin.com/post/cyclone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24782047</guid>
            <pubDate>Wed, 14 Oct 2020 21:49:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why software engineering processes and tools don’t work for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24781490">thread link</a>) | @ChefboyOG
<br/>
October 14, 2020 | https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/ | <a href="https://web.archive.org/web/*/https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    <div>
			
<p>“AI is the new electricity.” At least, that’s what <a href="https://www.coursera.org/instructor/andrewng">Andrew Ng</a> suggested at this year’s <a href="https://remars.amazon.com/">Amazon re:MARS</a> conference. In his <a href="https://www.youtube.com/watch?v=j2nGxw8sKYU">keynote address</a>, Ng discussed the rapid growth of artificial intelligence (AI) — its steady march into industry after industry; the unrelenting presence of AI breakthroughs, technologies, or fears in the headlines each day; the tremendous amount of investment, both from established enterprises seeking to modernize (see: <a href="https://www.engadget.com/2019/11/19/sony-ai/">Sony</a>, a couple of weeks ago) as well as from venture investors parachuting into the market riding a wave of AI-focused founders.&nbsp;</p>



<p>“AI is the next big transformation,” Ng insists, and we’re watching the transformation unfold.</p>



<p>While AI may be the new electricity (and as a Data Scientist at <a href="http://comet.ml/">Comet</a>, I don’t need much convincing), significant challenges remain for the field to realize this potential.<strong> In this blog post, I’m going to talk about why data scientists and teams can’t rely on the tools and processes that software engineering teams have been using for the last 20 years for machine learning</strong> <strong>(ML).&nbsp;</strong></p>



<p>The reliance on the tools and processes of software engineering makes sense – data science and software engineering are both disciplines whose principal tool is<em> code</em>. Yet <em>what is being done</em> in data science teams is radically different from what is being done in software engineering teams. An inspection of the core differences between the two disciplines is a helpful exercise in clarifying how we should think about structuring our tools and processes for doing AI.&nbsp;</p>



<p>At Comet, we believe the adoption of tools and processes designed specifically for AI will help practitioners unlock and enable the type of revolutionary transformation Ng is speaking about.</p>



<h2>Different Disciplines, Different Processes</h2>



<p>Software engineering is a discipline whose aim is, considered broadly, the design and implementation of programs that a computer can execute to perform a defined function. Assuming the input to a software program is within the expected (or constrained) range of inputs, its behavior is knowable. In a <a href="https://leon.bottou.org/talks/2challenges">talk</a> at ICML in 2015, Leon Bottou formulated this well: in software engineering an algorithm or program can be proven <em>correct</em>, in the sense that given particular assumptions about the input, certain properties will be true when the algorithm or program terminates.</p>
<figure id="attachment_2550" aria-describedby="caption-attachment-2550"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" alt="ml vs software eng" width="500" height="422" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x863.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w"><figcaption id="caption-attachment-2550">Source: Futurice</figcaption></figure>
<p>

The provable correctness of software programs has shaped the tools and processes we have built for doing software engineering. Consider one corollary characteristic of software programming that follows from provable correctness: if a program is provably correct for some input values, then the program contains sub-programs that are also provably correct for those input values. This is why engineering processes like <a href="https://en.wikipedia.org/wiki/Scaled_agile_framework">Agile</a> are, broadly speaking, successful and productive for software teams. Breaking apart these projects into sub-tasks works. Most <a href="https://en.wikipedia.org/wiki/Waterfall_model">waterfall</a> and <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)">scrum</a> implementations also include sub-tasking as well.</p>


<figure>
<figure id="attachment_2552" aria-describedby="caption-attachment-2552"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" alt="" width="700" height="376" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x550.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w"><figcaption id="caption-attachment-2552">Software Engineering vs. Machine Learning Lifecycle</figcaption></figure>
</figure>

<p>We see a lot of data science teams using workflow processes that are identical or broadly similar to these software methodologies. Unfortunately, they don’t work very well. The reason? The provable correctness of software engineering does not extend to AI and machine learning. In (supervised) machine learning, the only guarantee we have about a model we’ve built is that if the training set is an <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">iid</a> (independent and identically distributed) sample from some distribution, then performance on another iid sample from the same distribution will be <em>close</em> to the performance on the training set. Because uncertainty is an intrinsic property of machine learning, sub-tasking can lead to unforeseeable downstream effects.&nbsp;</p>

<h2><strong>Why is uncertainty intrinsic to machine learning?</strong>&nbsp;</h2>

<p>Part of the answer lies in the fact that the problems that are both (a) interesting to us and (b) amenable to machine learning solutions (self-driving cars, object recognition, labeling images, and generative language models, to name a few) do not have a clear reproducible mathematical or programmatic specification. In place of specifications, machine learning systems feed in lots of data in order to detect patterns and generate predictions. Put another way, the <em>purpose of machine learning is to create a statistical proxy that can serve as a specification for one of these tasks</em>. We hope our collected data is a representative subsample of the real-world distribution, but in practice we cannot know exactly how well this condition is met. Finally, the algorithms and model architectures we use are complex, sufficiently complex that we cannot always break them apart into sub-models to understand precisely what is happening.&nbsp;</p>

<p>From this description, obstacles to the <em>knowability</em> of machine learning systems should be somewhat obvious. Inherent to the types of problems amenable to machine learning is a lack of a clear mathematical specification. The statistical proxy we use in the absence of a specification is accumulating lots of environmental data we <em>hope</em> is iid and representative. And the models we use to extract patterns from this collected data are sufficiently complex that we cannot reliably break them apart and understand precisely how they work. My colleague at Comet, Dhruv Nair, has written a three-part series on uncertainty in machine learning (here’s a link to <a href="https://www.comet.ml/blog/?p=662">Part I</a>) if you’d like to dig deeper into this topic.&nbsp;</p>

<p>Consider, then, the implications for something like the Agile methodology used on a machine learning project. We cannot possibly hope to break machine learning tasks into <em>sub-tasks</em>, tackled as part of some larger sprint and then pieced together like legos into a whole product, platform, or feature, because we cannot reliably predict how the sub-models, or the model itself, will function.&nbsp;</p>

<figure>
<figure id="attachment_2553" aria-describedby="caption-attachment-2553"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" alt="" width="700" height="504" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x738.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w"><figcaption id="caption-attachment-2553">Source: Youtube</figcaption></figure>
<figcaption></figcaption>
</figure>

<p>Ng discussed this topic at re:MARS as well. He revealed how his team adopted a workflow system designed specifically for ML: <strong>1 day sprints</strong>, structured as follows:</p>

<ol>
<li>Build models and write code each day</li>
<li>Set up training and run experiments overnight</li>
<li>Analyze results in the morning and…</li>
<li>Repeat</li>
</ol>

<p>Ng’s 1 day sprints methodology reflects something crucial to understanding and designing teams that practice machine learning: it is an inherently <strong>experimental science</strong>. Because the systems being built lack a clear specification, because data collection is an imperfect science, and because machine learning models are incredibly complex, <em>experimentation is necessary</em>. Rather than structuring team processes around a multi-week sprint, it is usually more fruitful to test out many different architectures, feature engineering choices, and optimization methods rapidly until a rough image of what is working and what isn’t starts to emerge. 1 day sprints allow teams to move quickly, test many hypotheses in a short amount of time, and begin building intuition and knowledge around a modeling task.&nbsp;</p>

<h2><strong>Tools for ML: Experiment Management&nbsp;</strong></h2>

<p>Let’s say you adopt Andrew Ng’s 1 day sprints methodology or something similar (<em>and you should</em>). You’re setting new hyperparameters, tweaking your feature selections, and running experiments each night. What tool are you using to keep track of these decisions for each model training? How are you comparing experiments to see how different configurations are working? How are you sharing experiments with co-workers? Can your manager or co-worker reliably reproduce an experiment you ran yesterday?</p>

<p>In addition to processes, the tools you use to do machine learning matter as well. At Comet, our mission is to help companies extract business value from machine learning by providing a tool that does this for you. Most of the data science teams we speak to are stuck using a combination of git, emails, and (believe it or not) spreadsheets to record all of the artifacts around each experiment.&nbsp;</p>
<figure id="attachment_1994" aria-describedby="caption-attachment-1994"><img src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" alt="" width="700" height="314" srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x459.png" data-src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" data-srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w"><figcaption id="caption-attachment-1994">Comet: Hyperparameter space visualization for 20+ experiments.</figcaption></figure>
<p>

Consider a modeling task where you’re keeping track of 20 hyperparameters, 10 metrics, dozens of architectures and feature engineering techniques, all while iterating quickly and running dozens of models a day. It can become incredibly tedious to manually track all of these artifacts. Building a good ML model can oftentimes resemble tuning a radio with 50 knobs. If you don’t keep track of all of the configurations you’ve tried, the combinatorial complexity of finding the signal in your modeling space can become cumbersome.</p>
<figure id="attachment_2554" aria-describedby="caption-attachment-2554"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" alt="comet exp UI" width="700" height="372" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x544.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w"><figcaption id="caption-attachment-2554">Comet: Single experiment live metric tracking and dashboard</figcaption></figure>
<p><span>We’ve built Comet based on these needs (and what we wanted when we were working on data science and machine learning ourselves, at Google, IBM, and as part of research groups at Columbia University and Yale University). Every time you train a model, there should be </span><em>something</em><span> to capture all of the artifacts of your experiment and save them in some central ledger where you can look up, compare, and filter through all of your (or your team’s) work. Comet was built to provide this function to practitioners of machine learning.&nbsp;</span></p>

<p>Measuring workflow efficiency is a <a href="https://gravityflow.io/articles/measure-workflow-automations-roi/">notoriously difficult</a> thing to do, but on average our users report&nbsp;<em>20-30% time savings by using Comet</em> (note: Comet is free for individuals and researchers – <a href="https://www.comet.ml/pricing?opensignup=true&amp;utm_source=Software%20Eng%20vs%20ML&amp;utm_medium=Blog&amp;utm_campaign=Software%20Eng%20vs%20ML%20Blog%20Post">you can sign-up here</a>). This doesn’t take into account unique insights and knowledge that arise from having access to a visual understanding of your hyperparameter space, real-time metric tracking, team-wide collaboration and experiment comparison. Access to this knowledge enables time savings as well as, and perhaps more importantly, the ability to <em>build better models</em>.</p>

<h2><strong>Looking Ahead</strong></h2>

<p>It is tempting to ignore questions about ML tools and processes altogether. In a field responsible for self-driving cars, voice assistants, facial recognition, and many more groundbreaking technologies, one may be forgiven for leaping into the fray of building these tools themselves and not considering how best to build them.&nbsp;</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</a></em></p>]]>
            </description>
            <link>https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781490</guid>
            <pubDate>Wed, 14 Oct 2020 20:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient Evenly Distributed Sampling of Time Series Records in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24781057">thread link</a>) | @mooreds
<br/>
October 14, 2020 | https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/ | <a href="https://web.archive.org/web/*/https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6304">
	
	
	<div>
		
<h2>The Problem</h2>



<p>I have been working on an application that, at it’s heart, stores a large amount of data that is organized primarily through the use of a foreign key and a timestamp field. The table’s own primary key is UUID based, combining the foreign key with a UUID for the individual record itself, and it has a single primary data field that utilizes a JSONB type since it can receive arbitrary data. The table sees frequent, regular inserts, and periodic deletions, with old data being thinned out over time, but for each foreign key, there may be tens of thousands of records distributed amongst hundreds of thousands, or millions of other records for other foreign keys.</p>



<figure><table><thead><tr><th>Column</th><th data-align="center">Type</th></tr></thead><tbody><tr><td>id</td><td data-align="center">uuid</td></tr><tr><td>server_id</td><td data-align="center">uuid</td></tr><tr><td>data</td><td data-align="center">jsonb</td></tr><tr><td>created_at</td><td data-align="center">timestamp(6) without time zone</td></tr></tbody></table><figcaption>Basic Table Schema</figcaption></figure>



<p>This was all very simple, but when the time came to start writing the code that generates data graphs from this table, I encountered a puzzle.</p>



<p>How does one ensure that the API doesn’t return too much data? Too many data points just means sending more data than the user probably needs, and it results in the graphing tool having to work with more data than it wants for quick, responsive performance, as well.</p>



<p>And how does one, efficiently, find that data without running a query take takes a burdensome amount of time? In our case, the data is being returned to a React based front end by an API, and snappy application performance hinges on snappy API performance.</p>



<h2>THe first solution</h2>



<p>Early in the history of the application, I arrived at a solution. If I had a maximum cap on the number of data points to query, such as 500, I could query the total count of records which matched my query, and then a little integer division would give me an interval to use when querying.</p>



<p>Counting the data points is simple. It looks something like this:</p>


<pre title="">sql = &lt;&lt;-ESQL
SELECT
  COUNT(*)
FROM
  telemetries
WHERE
  server_id = $1
  AND created_at BETWEEN $2 AND $3
  AND data ? 'load_avg'
ESQL

count = 0_64
DBH.using_connection do |conn|
  count = conn.query_one(sql, uuid, start_date, end_date, as: {Int64})
end
</pre>


<p>Once the count of records is determined, an interval can be calculated which will be used to query the sample of records.</p>



<p>i.e. if there are 5000 data points, and I want to sample 500 of them, then I need to query every 10th record. It looks something like this to find that interval:</p>


<pre title="">row_modulo = count // limit
row_modulo = 1 if row_modulo == 0
</pre>


<p>Once one has an interval, there is a technique that can be used with Postgresql to select records on that interval. The <code><a rel="noreferrer noopener" href="https://www.postgresql.org/docs/12/functions-window.html" target="_blank">row_number()</a></code> is a <a rel="noreferrer noopener" href="https://www.postgresql.org/docs/12/tutorial-window.html" target="_blank">window function</a> that assigns a sequential number to each row in a result set. Once each record has a monotonically increasing sequential number assigned to it, that number can be used in a <code>WHERE</code> clause.</p>


<pre title="">SELECT
  stuff,
  ROW_NUMBER()
    OVER (ORDER BY created_at ASC)
    AS row
FROM
  mytable
WHERE
  row % 10 = 0
</pre>


<p>This example would <code>select</code>, for every 10th record from <code>mytable</code>, the <code>stuff</code> field. </p>



<p>In the context of full, working code, assembling that query looked like this:</p>


<pre title="">sql = &lt;&lt;-ESQL
SELECT
  t.*
FROM (
  SELECT
    data,
    created_at,
    row_number()
      OVER (ORDER BY created_at ASC)
      AS row
  FROM
    telemetries
  WHERE
    server_id = $1
    AND created_at BETWEEN $2 AND $3
    AND data ? 'load_avg'
) 
AS t
WHERE
  t.row %#{row_modulo} = 0
ESQL
</pre>


<p>This worked! It’s a viable general technique when you want to select every nth record from some result set, and you want to make the database do the work instead of your application. It’s also almost always faster and less resource intensive to do data management like this inside the database than it is to pull all of the data into your application and make it responsible for sorting through the data and pruning unneeded rows.</p>



<h2>A Wrinkle: Counting Isn’t Cheap!</h2>



<p>There are a couple of performance problems with this approach that become apparent when the table starts significantly growing.</p>



<p>First, pulling a <code>count</code> is not cheap. MySQL maintains a global record count for tables as part of it’s MyISAM data format. PostgreSQL, however, uses something called a multi-version concurrency control strategy with its tables, which essentially means that different views of a database may see different sets of rows. Thus there is no one single, simple count of records for it to fall back on. Thus, when you count records in a table in PostgreSQL, the database is required to actually walk through the data and count all of the visible records.</p>



<p>This is a relatively intense, and thus slow process.</p>



<p>If you simply want an estimate of the number of total rows in a  table, there is a way to get that very cheaply:</p>


<pre title="">SELECT
  reltuples::bigint
    AS estimated_count
FROM
  pg_class
WHERE
  relname = 'mytable'
</pre>


<div><p>This doesn’t work when you want to count only a subset of records, though, and this value is only an estimate. It is the estimate that the query planner uses, so it should generally always be within about 10% of the real value, but it is unlikely to ever match exactly unless the table size changes only rarely.</p><p>There are other counting strategies, but they all have tradeoffs or inherent inaccuracies, so for this use case, there is no getting around paying that up-front time and resource cost just to get a count of records to use when calculating the query interval that is needed.</p></div>



<p>The second expensive part of this technique is the use of <code>row_number()</code> in combination with a modulo (%) in the <code>WHERE</code> clause. This means that the database must traverse every possible record when running the query in order to figure out which ones satisfy the <code>WHERE</code> clause. So if there are 150000 records, but one only wants 500 of them, all 150000 will still be scanned.</p>



<p>These factors combine to make this approach brutally, unusably slow for queries that are intended to be ran ad hoc, and quickly, as part of an API driving a UI.</p>


<pre title="">                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Subquery Scan on t  (cost=105.19..2583.85 rows=1 width=387) (actual time=418.318..26002.490 rows=545 loops=1)
   Filter: ((t."row" % '49'::bigint) = 0)
   Rows Removed by Filter: 26198
   -&gt;  WindowAgg  (cost=105.19..2582.55 rows=87 width=387) (actual time=210.259..25995.686 rows=26743 loops=1)
         -&gt;  Bitmap Heap Scan on telemetries  (cost=105.19..2581.46 rows=87 width=379) (actual time=210.248..25959.166 rows=26743 loops=1)
               Recheck Cond: (data ? 'load_avg'::text)
               Filter: (server_id = 'a0dcc312-0623-af60-4dc0-238301cc9bf8'::uuid)
               Rows Removed by Filter: 178886
               Heap Blocks: exact=39489
               -&gt;  Bitmap Index Scan on telemetries_data_idx  (cost=0.00..105.17 rows=689 width=0) (actual time=101.188..101.188 rows=205629 loops=1)
                     Index Cond: (data ? 'load_avg'::text)
 Planning Time: 1.860 ms
 Execution Time: 26006.389 ms

</pre>


<p>This is a real example of a query on a real database using the prior technique, and this example had the advantage that the index that it uses (a <code>BTREE</code> index across the data field, since in production we are limiting results to fields that have one specific type of data) was already warm and cached in the database’s working set when I ran this example, so this result was a best case for this technique, on this database. If that index were not available, or were not used, it would have been even slower given that this index filter rejected almost 180,000 rows. That’s too slow to be triggered directly via an API request, as the user will be waiting a half-minute for data to even begin to show up in their browser.</p>



<h2>There has to be a better way</h2>



<p>It turns out that Postgresql offers a high performance option to sample a random set of data in a table. There is a <code><a href="https://www.postgresql.org/docs/9.6/sql-select.html#SQL-FROM" target="_blank" rel="noreferrer noopener">TABLESAMPLE</a></code> clause that can be placed in the <code>FROM</code> section of a query that will sample a subset of a table.</p>


<pre title="">SELECT
  data
FROM
  mytable
  TABLESAMPLE SYSTEM(5)
</pre>


<p>This would return a roughly random set of about 5% of <code>mytable</code>‘s rows. If one wants a specific number of rows, there is an extension that can provide that, <code><a rel="noreferrer noopener" href="https://www.postgresql.org/docs/9.6/tsm-system-rows.html" target="_blank">tsm_system_rows</a></code>.</p>


<pre title="">SELECT
  data
FROM
  mytable
  TABLESAMPLE SYSTEM_ROWS(500)
</pre>


<p>This would return a random-ish set of 500 rows from the table. A <code>WHERE</code> clause can be used in a query that uses <code>TABLESAMPLE</code> in order to select only the rows of interest, but the <code>TABLESAMPLE</code> is applied before the <code>WHERE</code> clause, which makes this method unsuitable for my use case. As an example:</p>


<pre title="">SELECT
  data,
  created_at
FROM
  telemetries
  TABLESAMPLE SYSTEM_ROWS(500)
WHERE
  server_id = $1
</pre>


<p>This would first select 500 random rows from the entire data set, and would then try to find records from that set which matched the <code>WHERE</code> clause. This would probably result in the query only returning a very small, and fairly unpredictable number of rows of data that is actually wanted. Also, because the records are random, there is no guarantee that they are evenly distributed through the data set. This might be fine if the data is being queried for statistical reasons, but it isn’t ideal when pulling data for graphs.</p>



<p>So while TABLESAMPLE can be a very fast way to select a random set of records over an entire table, it doesn’t work when we want a set of rows that is evenly distributed through the data set, but is only for a segment of the table’s total data, and for which we want to have some predictable control over the number of rows selected.</p>



<h2>Other Meanderings</h2>



<p>There are other solutions available when the problem to be solved is the random selection of table rows, but none of them are particularly useful for the selection of N or close-to N evenly distributed data points, and there is limited inspiration that can be found from them.</p>



<p>A…</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/">https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/</a></em></p>]]>
            </description>
            <link>https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781057</guid>
            <pubDate>Wed, 14 Oct 2020 20:17:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beginner's Guide to Digital Privacy]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24780861">thread link</a>) | @sciencenut
<br/>
October 14, 2020 | https://rsapkf.xyz/blog/beginners-guide-to-digital-privacy | <a href="https://web.archive.org/web/*/https://rsapkf.xyz/blog/beginners-guide-to-digital-privacy">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The following are basic instructions for beginners on maintaining privacy on the Internet. I use most of these services myself and highly recommend using these. Most of these are open-source projects. Please contribute to the maintainers via donations/code if you find them useful.</p><div>
<li>
<p>Understand why maintaining privacy is important. Start here:</p>
<ul>
<li><a href="https://privacytools.io/">privacytools.io</a></li>
<li><a href="https://old.reddit.com/r/privacy/wiki">r/privacy wiki</a></li>
<li><a href="https://en.wikipedia.org/wiki/Permanent_Record_(autobiography)">Permanent Record- Edward Snowden</a></li>
</ul>
</li>
<li>
<p>Always look for well known open source alternatives to services that you use:</p>
<ul>
<li><a href="https://alternativeto.net/">AlternativeTo.net</a></li>
<li><a href="https://ethical.net/">ethical.net</a></li>
<li><a href="https://restoreprivacy.com/">Restore Privacy</a></li>
</ul>
</li>
<li>
<p>Start by using reliable open source web browsers:</p>
<ul>
<li><a href="https://www.mozilla.org/en-US/firefox/">Firefox</a></li>
<li><a href="https://github.com/Eloston/ungoogled-chromium">Ungoogled Chromium</a></li>
<li><a href="https://torproject.org/">Tor</a></li>
</ul>
</li>
<li>
<p>Install privacy addons:</p>
<ul>
<li><a href="https://github.com/EFForg/privacybadger/">Privacy Badger</a></li>
<li><a href="https://github.com/gorhill/uBlock/">uBlock Origin</a></li>
<li><a href="https://decentraleyes.org/">Decentraleyes</a></li>
<li><a href="https://addons.mozilla.org/en-US/firefox/addon/multi-account-containers/">Firefox Multi-Account Containers</a></li>
<li><a href="https://gitlab.com/KevinRoebert/ClearUrls">ClearURLs</a>, etc.</li>
</ul>
</li>
<li>
<p>Use a search engine that doesn't log your search queries:</p>
<ul>
<li><a href="https://duckduckgo.com/">DuckDuckGo</a></li>
<li><a href="https://searx.me/">searx.me</a></li>
</ul>
</li>
<li>Disable Tracking, Fingerprinting, Cryptominers and Telemetry from browser preferences. Clear cookies frequently, disable location access to sites and cover your webcam unless necessary.</li>
<li>
<p>Quit using Google, Microsoft, Apple, Facebook products for personal/sensitive use cases.</p>
<p>These companies are great for security of your data, they hire top engineers from around the world but are worse for your privacy, esp. if they rely on advertisement for their revenue. If you have to use Google, go to your account settings and turn off all the <a href="https://myactivity.google.com/activitycontrols">activity controls</a> and <a href="https://adssettings.google.com/">ads personalization</a>. Go through similar settings on your dashboard for other accounts- Apple, Microsoft, etc.</p>
</li>
<li>
<p><strong>Always</strong> choose "Sign up with Email" while signing up on websites.</p>
<p>I cannot stress this enough. Please <strong>do not</strong> ever, unless mandatory, choose "Sign up with Google/Microsoft/Twitter/Facebook/Apple/Amazon, etc".</p>
<p>If you are required to continue with social signup, take care of what scopes and information you are permitting the service to use. Platforms usually provide a way to manage this info from your account settings:</p>
<ul>
<li><a href="https://www.facebook.com/settings?tab=applications">Facebook Apps and Websites</a></li>
<li><a href="https://myaccount.google.com/permissions">Apps with access to your Google account</a></li>
</ul>
</li>
<li>Create separate email accounts/aliases for signups, newsletters, communication, banking, music, etc.</li>
<li>
<p>Research beforehand if the service you're signing up for allows for an (easy) way to delete your account. You might regret later when you find out you can't delete your account. Some websites have tricky account deletion procedure:</p>
<ul>
<li>Amazon, Adobe (require contacting support)</li>
<li>TED (no delete account option in account settings)</li>
<li>Shopify (you must have a premium subsciption to close your store/account even if wish to close your store after your trial is over)</li>
</ul>
</li>
<li>
<p>Make use of <a href="https://protonmail.com/support/knowledge-base/addresses-and-aliases/">Email Aliases</a> or Email forwarding services:</p>
<ul>
<li><a href="https://github.com/anonaddy/anonaddy">AnonAddy</a></li>
<li><a href="https://github.com/simple-login/app">SimpleLogin</a></li>
</ul>
</li>
<li>
<p>Use disposable email addresses for temporary signups:</p>
<ul>
<li><a href="https://temp-mail.org/">Temp Mail</a></li>
<li><a href="https://10minutemail.com/">10 Minute Mail</a></li>
</ul>
</li>
<li>
<p>Use alternative frontends for platforms like Twitter, YouTube and Instagram:</p>
<ul>
<li><a href="https://invidio.us/">Invidio.us</a></li>
<li><a href="https://nitter.net/">Nitter.net</a></li>
<li><a href="https://bibliogram.net/">Bibliogram</a></li>
</ul>
</li>
<li>
<p>Don't like/comment on anything on Facebook, YouTube and social platforms. Use E2E-encrypted bookmark service like <a href="https://www.mozilla.com/en-US/firefox/sync/">Firefox Sync</a>.</p>
<p>Platforms these days track everything from what your see, what you click on, share or comment on, and even how long you looked at a particular item on your feed. Reduce your digital footprint as much as you can. Export your personal data from Facebook, Google from your account settings and work on deleting all of it.</p>
<ul>
<li><a href="https://facebook.com/dyi">Download your Facebook Information</a></li>
<li><a href="https://takeout.google.com/">Google Takeout</a></li>
</ul>
</li>
<li>
<p>Use decentralized services if you need:</p>
<ul>
<li><a href="https://mastodon.social/">Mastodon</a></li>
<li><a href="https://pixelfed.org/">PixelFed</a></li>
<li><a href="https://diasporafoundation.org/">Diaspora</a></li>
<li><a href="https://fediverse.party/">Fediverse</a></li>
</ul>
</li>
<li>
<p>Use E2E-encrypted messaging applications for communication:</p>
<ul>
<li><a href="https://signal.org/">Signal</a></li>
<li><a href="https://wire.com/">Wire</a></li>
</ul>
</li>
<li>
<p>Use E2E-encrypted email services:</p>
<ul>
<li><a href="https://tutanota.com/">Tutanota</a></li>
<li><a href="https://protonmail.com/">Protonmail</a></li>
</ul>
</li>
<li>
<p>Use E2E-encrypted note-taking apps:</p>
<ul>
<li><a href="https://standardnotes.org/">Standard Notes</a></li>
<li><a href="https://joplin.org/">Joplin</a></li>
</ul>
</li>
<li>
<p>Use E2E-encrypted cloud storage solutions:</p>
<ul>
<li><a href="https://pcloud.com/">pCloud Cypto</a></li>
<li><a href="https://sync.com/">Sync.com</a></li>
</ul>
</li>
<li>
<p>Encrypt your files before uploading them to Dropbox, Google Drive or Microsoft OneDrive:</p>
<ul>
<li><a href="https://veracrypt.fr/">VeraCrypt</a></li>
<li><a href="https://cryptomator.org/">Cryptomator</a></li>
</ul>
</li>
<li>
<p>Use a reliable VPN:</p>
<ul>
<li><a href="https://protonvpn.com/">ProtonVPN</a></li>
<li><a href="https://mullvad.net/">Mullvad VPN</a></li>
</ul>
</li>
<li>
<p>*Use a better DNS resolver:</p>
<ul>
<li><a href="https://1.1.1.1/">Cloudflare WARP</a></li>
</ul>
</li>
<li>
<p>*Use Linux/BSD. Any distro is fine:</p>
<ul>
<li>Made for privacy: <a href="https://tails.boum.org/">Tails</a>, <a href="https://www.whonix.org/">Whonix</a>, <a href="https://trisquel.info/">Trisquel</a>...</li>
<li>Debian based: <a href="https://www.debian.org/">Debian</a>, <a href="https://www.ubuntu.com/">Ubuntu</a>...</li>
<li>Arch based: <a href="https://www.archlinux.org/">Arch</a>, <a href="https://arcolinux.info/">ArcoLinux</a>, <a href="https://manjaro.org/">Manjaro</a>,...</li>
<li>BSDs: <a href="https://github.com/openbsd/src">OpenBSD</a>, <a href="https://www.netbsd.org/">NetBSD</a>, <a href="https://github.com/freebsd/freebsd/">FreeBSD</a>...</li>
</ul>
</li>
<li>
<p>*Switch your OS on your smartphone:</p>
<ul>
<li><a href="https://lineageos.org/">LineageOS</a></li>
<li><a href="https://ubuntu-touch.io/">Ubuntu Touch</a></li>
<li><a href="https://grapheneos.org/">GrapheneOS</a></li>
<li><a href="https://postmarketos.org/">postmarketOS</a></li>
</ul>
</li>
<li>*Self-host software on your own server by renting a VPS.</li>
</div><p>This is just a list of the most popular and reliable options for getting started on digital privacy. There are comprehensive guides, articles, books and websites for more advanced tips:</p><p>Make sure to research every option thoroughly to determine what works best for you. Let me know if you found a mistake or want to add another service to this list.</p></div>]]>
            </description>
            <link>https://rsapkf.xyz/blog/beginners-guide-to-digital-privacy</link>
            <guid isPermaLink="false">hacker-news-small-sites-24780861</guid>
            <pubDate>Wed, 14 Oct 2020 20:00:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualize Starlink's current coverage with active TLEs]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24780065">thread link</a>) | @blach
<br/>
October 14, 2020 | http://orbitalindex.com/feature/starlink-coverage/ | <a href="https://web.archive.org/web/*/http://orbitalindex.com/feature/starlink-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="_main" role="main" data-color="#4fb1ba" data-theme-color="black" data-image="/assets/img/sidebar-bg.jpg" data-overlay=""><article class="page" role="article"><header></header>   <div id="starlink-coverage"> <canvas id="globe"></canvas><div><p>Degrees From Horizon For Connectivity <span onclick="display_help()">?</span> <span onclick="hide_help()">✕</span></p><p>25°</p><div><p>Degrees From Horizon is the amount you have to tilt your head to look at the satellite when standing in a flat field.</p><p>We believe the initial constellation will have connectivity if the satellite is 25° above the receiver's horizon, and that this requirement will later be eased to 40° to increase performance as satellite density increases. Note: This angle defines the maximum height above the horizon in all directions that can be occluded by any terrain, trees, or other structures.</p></div></div></div>  </article></div></div>]]>
            </description>
            <link>http://orbitalindex.com/feature/starlink-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24780065</guid>
            <pubDate>Wed, 14 Oct 2020 18:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cotter – Add Passwordless Login Without Any Code]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24779695">thread link</a>) | @mmarcelline
<br/>
October 14, 2020 | https://blog.cotter.app/integrate-cotter-magic-link-to-webflow-in-less-than-15-minutes/ | <a href="https://web.archive.org/web/*/https://blog.cotter.app/integrate-cotter-magic-link-to-webflow-in-less-than-15-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<div>
<figure><iframe width="480" height="270" src="https://www.youtube.com/embed/oDUnHj_6Tc4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>Webflow + Cotter’s Magic Link Tutorial</figcaption></figure><p>In this tutorial we're going to guide you on how to authenticate your users using magic links on Webflow.</p><h2 id="part-1-cotter-setup">Part 1: Cotter Setup</h2><p>Go to <a href="https://dev.cotter.app/">https://dev.cotter.app</a> to create an account. Once you have created an account make sure to create a new project and grab the API Key ID. We will be using your API Key ID later in part 2.</p><h2 id="part-2-webflow-setup">Part 2: Webflow Setup</h2><p>For this tutorial we have created 2 pages: Login Page and Protected Page. The login page will display the embedded Cotter login form for your users to type in their email while the protected page will display protected content that only a logged in user can view.</p><h3 id="login-page-setup-where-the-login-form-will-show-up-">Login Page Setup (where the login form will show up)</h3><p>On the login page page we need to include a <strong>section element to load Cotter's login form; moreover, we need to set that section id "cotter-form-container".</strong> This enables Cotter's JS SDK to load the login form to the section element that we just added.</p><p>After finishing the page, setup we can start with adding custom code to the Login Page. Copy paste the code below to the custom code tab on the Login Page settings.</p><figure><img src="https://blog.cotter.app/content/images/2020/09/Screen-Shot-2020-09-06-at-7.47.23-PM.png"><figcaption>Page Settings</figcaption></figure><figure><img src="https://blog.cotter.app/content/images/2020/09/Screen-Shot-2020-09-06-at-7.49.28-PM.png"><figcaption>Scroll down to "Custom Code" section</figcaption></figure><ol><li>Get Cotter JS SDK</li></ol><p>Add the code below to the head of the Login Page.</p><pre><code>&lt;!--Get Cotter JS SDK--&gt;
&lt;script
    src="https://unpkg.com/<a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="4f2c203b3b2a3d0f7f617c617e79">[email&nbsp;protected]</a>/dist/cotter.min.js"
    type="text/javascript"
&gt;&lt;/script&gt;</code></pre><p>2. Initialize Cotter</p><p>Add the code below to the body of the Login Page.</p><pre><code>&lt;!-- 2. Initialize Cotter --&gt;
&lt;script&gt;
  var cotter = new Cotter("&lt;YOUR_API_KEY_ID&gt;"); // 👈 Specify your API KEY ID here
  cotter
  	// Choose what method of login do you want
    // Sign In with Magic Link
    .signInWithLink()
    // Send Magic Link via email
    .showEmailForm()
    
    .then(payload =&gt; {
	  // save OAuth token
      localStorage.setItem("user_session", JSON.stringify(payload));
      
      // redirect to the protected page
      window.location.href = "/protected";
    })
    .catch(err =&gt; {
      // handle error
    });
&lt;/script&gt;</code></pre><p>Make sure that you have pasted your <u>API Key ID</u> on the code block above.</p><h3 id="protected-page-setup-and-any-other-page-you-want-to-protect-">Protected Page Setup (and any other page you want to protect)</h3><p>Now let's move on to the protected page, <strong>we need to include a header (h2) element and set that header id "welcome-text-heading" in order to load the user's email address and a button element with button id "signout-button" to enable sign out functionality for the user.</strong></p><p>Moreover, we'll be adding custom code to both the head and the body. We'll be adding custom code to the header to check if a user is logged in and to fetch the user's OAuth token. The custom code in the body will be used to parse the user data and display his/her email on the page.</p><ol><li>Add the code below to the head of the Protected Page</li></ol><pre><code>&lt;script&gt;
// 1. We check if a user has already logged in
var cotterOAuthToken = localStorage.getItem("user_session");

// 2. If user is not logged in then we redirect to the login page
if (!cotterOAuthToken || cotterOAuthToken.length &lt;= 0) window.location.href = "/";

// 3. If user is logged in then we fetch the user data
let url = "https://cotterapp.herokuapp.com/login"
fetch(url, {
    method: 'POST',
    cache: 'no-cache',
    headers: {
      'Content-Type': 'application/json'
    },
    body: cotterOAuthToken
  })
  .then(resp =&gt; resp.json())
  .then(data =&gt; {
  	if(!data.success) { window.location.href = "/" }
  });
&lt;/script&gt;</code></pre><p>2. &nbsp;Add the code below to the body of the Protected Page</p><pre><code>&lt;script&gt;
// 1. Fetch the user data
let token = JSON.parse(cotterOAuthToken);
// 2. Display user email
document.getElementById("welcome-text-heading").innerHTML = `Welcome ${token.email},`;
// 3. Display sign out button
document.getElementById("signout-button").addEventListener("click", () =&gt; {
	window.localStorage.removeItem("user_session"); // Log user out
    window.location.href = "/";                     // Redirect to home				      
});
&lt;/script&gt;</code></pre><h2 id="part-3-publish-and-test">Part 3: Publish and Test</h2><p>We've arrived at the last part of this tutorial and all that you need to do is to click publish and test Cotter's magic link authentication for your Webflow website!</p><hr><h2 id="webflow-use-cases"><strong>Webflow Use Cases</strong></h2><ul><li><a href="https://blog.cotter.app/how-to-start-a-members-only-blog-with-webflow/">Members-only Blog</a></li><li><a href="https://blog.cotter.app/how-to-restrict-your-webflow-website-to-allowed-emails-only/">Restrict Site Login to "Allowed" Emails Only</a></li><li><a href="https://blog.cotter.app/rsvp-only-event-on-webflow/">RSVP-only Event</a></li><li><a href="https://blog.cotter.app/zapier-cotter-webflow/">Zapier + Webflow + Cotter: Send Logged-in User Data to Webflow CMS</a></li><li><a href="https://blog.cotter.app/webflow-forms-include-logged-in-users-email-on-form-submissions/">Include Logged-in User Email on Form Submissions</a></li></ul><hr><h3 id="questions-feedback">Questions &amp; Feedback</h3><p>Come and talk to the founders of Cotter and other developers who are using Cotter on <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Cotter's Slack Channel</a>.</p><h3 id="ready-to-use-cotter">Ready to use Cotter?</h3><p>If you enjoyed this tutorial and want to integrate Cotter into your website or app, you can <a href="https://dev.cotter.app/">create a free account</a> and <a href="https://docs.cotter.app/">check out our documentation</a>.</p><p>If you need help, ping us on our <a href="https://join.slack.com/t/askcotter/shared_invite/zt-dxzf311g-5Mp3~odZNB2DwYaxIJ1dJA">Slack channel</a> or email us at <a href="https://blog.cotter.app/cdn-cgi/l/email-protection" data-cfemail="e591808488a5868a91918097cb849595cb">[email&nbsp;protected]</a></p>
</div>
</section></div>]]>
            </description>
            <link>https://blog.cotter.app/integrate-cotter-magic-link-to-webflow-in-less-than-15-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24779695</guid>
            <pubDate>Wed, 14 Oct 2020 18:13:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24779624">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they’re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let’s start with an example. We have an app, and we want to export some data in a JSON format. Here’s what a function for that could look like:</p><pre><code><span>function</span><span> </span><span>exportFile</span><span>() { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>); </span><span>// '{"data": {...</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>); </span><span>// https://foo.com/export.json</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we’re done. </p><p>Okay, we’ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>isCSV</span><span>) { </span>
<span>  </span><span>...</span>
<span>  </span><span>let</span><span> </span><span>fileURL</span>
<span>  </span><span>if</span><span> (</span><span>isCSV</span><span>) { </span>
<span>    </span><span>const</span><span> </span><span>csvStr</span><span> </span><span>=</span><span> </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>csvStr</span><span>);</span>
<span>  } </span><span>else</span><span> { </span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>);</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>);</span>
<span>  }</span>
<span>  </span><span>...</span></code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2 id="the-key-advantage-is-that-our-logic-is-centralized">The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can’t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2 id="the-key-disadvantage-is-thatour-logic-is-centralized">The key <em>disadvantage</em> is that…our logic is centralized.</h2><p>This will work, but let’s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <strong><code>exportFile</code></strong> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn’t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They’d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> — now you have invariant conditions on your hands). By being so specific, you’ve chosen to make your function less abstract — this of course means that it is less powerful.  <strong><code>exportFile</code></strong> <strong>has become hard to extend</strong></p><h2 id="for-better-or-worse-configuration-gives-the-caller-the-least-amount-of-power">For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code><span>...</span>
<span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>...</span><span> </span><span>// *This can be different! Somehow we need to get a fileURL* </span>
<span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>...</span></code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>exportableDataToFileURL</span><span>) { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>exportableDataToFileURL</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Now, for JSON, we can write </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>and for CSV we can write: </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>Oky doke, this is cool. </p><h2 id="the-key-advantage-is-that-you-give-the-caller-more-power">The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won’t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We’ve given the caller much more power</p><h2 id="the-key-disadvantage-is-that-it-can-be-either-too-powerful-or-not-powerful-enough">The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We’ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format — instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it’s possible that there are numerous new usages of <code>exportFile</code>, which we’ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2 id="inversion-lies-in-the-middle-of-the-power-spectrum">Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it’s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code><span>function</span><span> </span><span>exportJSONFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveJSONFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span>
<!-- -->
<!-- -->
<span>function</span><span> </span><span>exportCSVFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveCSVFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span></code></pre><h2 id="the-key-advantage-is-that-the-user-gets-the-most-power">The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We’ve provided a lot of power for the user.</p><h2 id="the-key-disadvantage-is-that-you-are-the-most-vulnerable-to-mistakes">The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn’t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There’s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it’s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you’re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> — if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2 id="composition-is-at-the-end-of-the-spectrum">Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It’s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you’re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24779624</guid>
            <pubDate>Wed, 14 Oct 2020 18:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mixed Integer Programming for optimal risk mitigation strategy]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24779444">thread link</a>) | @JacobiX
<br/>
October 14, 2020 | https://www.vneuron.com/compliance/mixed-integer-programming-for-optimal-risk-mitigation-strategy/?w3tc_note=flush_all | <a href="https://web.archive.org/web/*/https://www.vneuron.com/compliance/mixed-integer-programming-for-optimal-risk-mitigation-strategy/?w3tc_note=flush_all">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="tm-row-5f8aab7091ccd"><div id="tm-column-5f8aab7092014"><div><div><div><p><strong>The Society for Risk Analysis (SRA) defines risk as to the possibility of an unfortunate occurrence, and quantitatively it can be defined as the combination of probability and magnitude/severity of consequences. From this basic definition, we can formalize the risk:</strong></p></div><div><p>Risk = Probability × Consequence</p></div><div><p><strong>Another variation that decomposes the probability into two components</strong> Threat <strong>and</strong> Vulnerability:</p></div><div><p>Risk = Threat × Vulnerability × Consequence</p></div><div><p><strong>The</strong> Threat <strong>is the probability of an event occurring and the</strong> Vulnerability <strong>is uncertainty about and severity of the consequences, given the occurrence of a risk source.</strong></p></div><div><p>A toy example of risks in a fictional organization :</p></div><div id="table-liste"><div><table><tbody><tr><th>Risk</th><th>Probability</th><th>Severity</th><th>Probability × Consequence</th></tr><tr><td>Cyberattacks</td><td>0.6</td><td>900</td><td>540</td></tr><tr><td>Talent Retention</td><td>0.7</td><td>800</td><td>560</td></tr><tr><td>IT Implementation</td><td>0.1</td><td>350</td><td>35</td></tr><tr><td>Cyber Fraud</td><td>0.3</td><td>600</td><td>180</td></tr><tr><td>Organizational Change</td><td>0.6</td><td>400</td><td>240</td></tr><tr><td>Compliance Risk</td><td>0.2</td><td>200</td><td>40</td></tr></tbody></table></div></div><div><p>Suppose for the sake of example, that we have identified the measures that may mitigate all the risks identified above.</p></div><div id="table-liste"><div><table><tbody><tr><th>Risk</th><th>Risk value before mitigation</th><th>Risk value after mitigation</th><th>Cost of mitigation measure</th></tr><tr><td>Cyberattacks</td><td>540</td><td>120</td><td>90</td></tr><tr><td>Talent Retention</td><td>560</td><td>400</td><td>80</td></tr><tr><td>IT Implementation</td><td>35</td><td>31</td><td>30</td></tr><tr><td>Cyber Fraud</td><td>180</td><td>45</td><td>45</td></tr><tr><td>Organizational Change</td><td>40</td><td>36</td><td>4</td></tr><tr><td>Compliance Risk</td><td>240</td><td>30</td><td>50</td></tr></tbody></table></div></div><div><p>Each mitigation measure has a cost, if we have a certain budget of x$ what is the optimal way to allocate which risk to mitigate?</p></div><div><p>Implementing a prescriptive model of decision making?</p></div><div><p>If we have an unlimited budget we could afford to mitigate all of the above risks by implementing the mitigation measures. But in the case of a limited budget, a decision should be made about which risk to mitigate.</p></div><div id="table-liste"><div><table><tbody><tr><th>Risk value before mitigation</th><th>Risk value after mitigation</th><th>Reduced risk (ri)</th><th>Cost</th><th>Decision</th></tr><tr><td>540</td><td>120</td><td>420</td><td>90</td><td>d1</td></tr><tr><td>560</td><td>400</td><td>160</td><td>80</td><td>d2</td></tr><tr><td>35</td><td>31</td><td>4</td><td>30</td><td>d3</td></tr><tr><td>180</td><td>45</td><td>135</td><td>45</td><td>d4</td></tr><tr><td>40</td><td>36</td><td>4</td><td>4</td><td>d5</td></tr><tr><td>240</td><td>30</td><td>210</td><td>50</td><td>d6</td></tr></tbody></table></div></div><div><figure><p><img width="388" height="299" src="https://www.vneuron.com/wp-content/uploads/2020/10/7.jpg" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/10/7.jpg 388w, https://www.vneuron.com/wp-content/uploads/2020/10/7-300x231.jpg 300w" sizes="(max-width: 388px) 100vw, 388px"></p></figure></div><div><div><p>The unknown variables in the above-stated problem are discrete variables, they are integer and restricted to 0 and 1. This is a discrete optimization problem, and since there is no quadratic term it is a linear problem.</p><p>This particular resource allocation problem where the decision-makers have to choose from a set of items under a fixed budget is called the knapsack problem. It has been studied extensively from as early as 1897. And because one can choose only an item to be included or not it is usually called the 0–1 knapsack problem. Many algorithms and heuristics exist for solving this type of problem, we choose to use a MIP approach<br> because it is very flexible when we want to add other constraints and logical considerations.</p><p>It should be noted that this problem is NP-complete, thus there is no known algorithm both correct and fast (polynomial-time) that can solve every case of the knapsack problem.</p></div></div><div><p>Suppose that a mitigation measure is a dependant on another. For instance, suppose that the implementation of a particular measure d1 cannot be done until the realization of another measure d5. One can include this consideration in the previous model by adding a new constraint.</p></div><div><figure><p><img width="105" height="38" src="https://www.vneuron.com/wp-content/uploads/2020/10/5-1.jpg" alt="" loading="lazy"></p></figure></div><div><p>In this case, if we have d1 = 1 then d5 &gt;= 1.</p></div><div><p>Modeling incompatible decisions</p></div><div><p>One can further enrich the model by adding more logical considerations, suppose that two mitigation plans are incompatible, they can’t be implemented at the same time. Let’s say d1 and d4 are conflicting mitigation measures, we can choose either d1 or d4:</p></div><div><figure><p><img width="165" height="39" src="https://www.vneuron.com/wp-content/uploads/2020/10/2-4.jpg" alt="" loading="lazy"></p></figure></div><div><p>We can consider also three or more conflicting decisions, if d1, d2, and d4 are incompatible and we can choose only one of them, we can simply add the following constraint:</p></div><div><figure><p><img width="237" height="39" src="https://www.vneuron.com/wp-content/uploads/2020/10/3-1.jpg" alt="" loading="lazy"></p></figure></div><div><p>We can keep adding constraints in order to model complex interaction between the decision, etc. If we have incompatible constraints, it may be possible that there is no solution to the optimization problem.</p></div><div><p>Mixed Integer Programming with branch-and-Cut</p></div><div><div><p>Integer programming is a subset of discreet optimization, that seeks to optimize an objective function subject to constraints. The LP format is a human-friendly modeling format. In practice, though other formats are more adequate for large-scale problems.</p><p>The basic constructs are really simple and can be translated directly from the mathematical formulation of the problem. The first section specifies the objective function to optimize and whether it’s a maximization or minimization problem. The second section specifies the constraints, an LP file may contain an arbitrary number of them. Finally, the last section specifies the type of the variable.</p><p>Once that the problem was formulated in LP format we can simply feed the file to a MIP optimizer and voilà we have an optimal solution. One such an optimizer is CBC: standing for Coin-or branch and cut, CBC is an open-source mixed-integer linear programming solver written in C++.</p><p>For a budget of <strong>150</strong></p></div></div><div><p>Maximize<br> \ The objective function<br> obj&nbsp; :&nbsp; 420&nbsp; d1 +&nbsp; 160&nbsp; d2&nbsp; +&nbsp; 4&nbsp; d3&nbsp; +&nbsp; 135&nbsp; d4&nbsp; +&nbsp; 4&nbsp; d5&nbsp; +&nbsp; 210&nbsp; d6<br> Subject To<br> c0&nbsp; :&nbsp; 90&nbsp; d1&nbsp; +&nbsp; 80&nbsp; d2&nbsp; +&nbsp; 30&nbsp; d3&nbsp; +&nbsp; 45&nbsp; d4&nbsp; +&nbsp; 4&nbsp; d5&nbsp; +&nbsp; 50&nbsp; d6&nbsp; &lt;=&nbsp; 150<br> Binary<br> d1&nbsp; d2&nbsp; d3&nbsp; d4&nbsp; d5&nbsp; d6<br> End</p></div><div><p>CBC provides a stand-alone executable that can be called directly from the command line to optimize the problem.</p></div><div><figure><p><img width="427" height="36" src="https://www.vneuron.com/wp-content/uploads/2020/10/4.jpg" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/10/4.jpg 427w, https://www.vneuron.com/wp-content/uploads/2020/10/4-300x25.jpg 300w" sizes="(max-width: 427px) 100vw, 427px"></p></figure></div><div><p>After waiting for some milliseconds the problem was solved.</p></div><div><figure><p><img width="502" height="152" src="https://www.vneuron.com/wp-content/uploads/2020/10/Screenshot_20201011_013017.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/10/Screenshot_20201011_013017.png 502w, https://www.vneuron.com/wp-content/uploads/2020/10/Screenshot_20201011_013017-300x91.png 300w" sizes="(max-width: 502px) 100vw, 502px"></p></figure></div><div><figure><p><img width="407" height="130" src="https://www.vneuron.com/wp-content/uploads/2020/10/Screenshot_20201011_013049.png" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/10/Screenshot_20201011_013049.png 407w, https://www.vneuron.com/wp-content/uploads/2020/10/Screenshot_20201011_013049-300x96.png 300w" sizes="(max-width: 407px) 100vw, 407px"></p></figure></div><div><p>The optimal strategy consists of mitigating <strong>risks 1, 5, and 6</strong>. This strategy gives a value of<strong> 634</strong> for the objective function.</p></div><div><p>Incorporating more logical constraints (dependencies &amp; conflicting decisions)</p></div><div><div><ol><li>Budget = 150</li><li>d1 cannot be done until the realization of d5.</li><li>d6 and d5 can not be done at the same time.</li></ol></div></div><div><p>Maximize*<br> \ The objective function<br> obj&nbsp; :&nbsp; 420&nbsp; d1&nbsp; +&nbsp; 160&nbsp; d2&nbsp; +&nbsp; 4&nbsp; d3&nbsp; +&nbsp; 135&nbsp; d4&nbsp; +&nbsp; 4&nbsp; d5&nbsp; +&nbsp; 210 d6<br> Subject To<br> c0&nbsp; :&nbsp; 90 d1&nbsp; +&nbsp; 80&nbsp; d2&nbsp; +&nbsp; 30&nbsp; d3&nbsp; +&nbsp; 45&nbsp; d4&nbsp; +&nbsp; 4&nbsp; d5&nbsp; +&nbsp; 50&nbsp; d6&nbsp; &lt;=&nbsp; 150&nbsp; c1&nbsp; :&nbsp; d5&nbsp; –&nbsp; d1&nbsp; &gt;=&nbsp; 0<br> c2&nbsp; :&nbsp; d6&nbsp; +&nbsp; d5&nbsp; &lt;=&nbsp; 1<br> Binary<br> d1&nbsp; d2&nbsp; d3&nbsp; d4&nbsp; d5&nbsp; d6<br> End</p></div><div id="table-liste"><div><table><tbody><tr><th>Optimal – objective value</th><th>Decisions</th></tr><tr><td>559</td><td>d1, d4, and d5</td></tr></tbody></table></div></div><div><figure><p><img width="640" height="454" src="https://www.vneuron.com/wp-content/uploads/2020/10/6-1024x727.jpg" alt="" loading="lazy" srcset="https://www.vneuron.com/wp-content/uploads/2020/10/6-1024x727.jpg 1024w, https://www.vneuron.com/wp-content/uploads/2020/10/6-300x213.jpg 300w, https://www.vneuron.com/wp-content/uploads/2020/10/6-768x545.jpg 768w, https://www.vneuron.com/wp-content/uploads/2020/10/6.jpg 1280w" sizes="(max-width: 640px) 100vw, 640px"></p></figure></div><div><div><p>Now that the novice merchant had learned the secrets of Mixed-Integer Programming, he went to apply his newly gained knowledge to optimize which goods to import based on its cost and expected price. He decided to allocate a budget of 1000$ and then he found the optimal solution. An old merchant, seeing what the novice was doing, gave him 1$.</p><p>The novice merchant said: “Why you gave me 1$ ?”. The old merchant said: “Redo your calculation with your new budget”. The novice merchant<br> was enlightened.</p></div></div><div><p>Due to the discreet nature of MIP problems, a small variation in the allocated budget can cause a huge difference in the solution.</p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.vneuron.com/compliance/mixed-integer-programming-for-optimal-risk-mitigation-strategy/?w3tc_note=flush_all</link>
            <guid isPermaLink="false">hacker-news-small-sites-24779444</guid>
            <pubDate>Wed, 14 Oct 2020 17:51:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Read-Only Mode for Better Rails Downtime]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24778920">thread link</a>) | @christoomey
<br/>
October 14, 2020 | https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/ | <a href="https://web.archive.org/web/*/https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <p>Recently I was looking to upgrade the Postgres version on an application I’ve
been working on. This would require a small amount of downtime, likely about 10
minutes.</p>

<p>The default solution I’d reach for in these cases would be to go into Heroku’s
maintenance mode, which serves an HTML maintenance page with a <code>503 Service
Unavailable</code> status code. This works but makes the application entirely
unusable during the upgrade, and I was hoping to find a better solution. In this
particular case, I also wanted to be able to provide JSON responses as the
application mainly provides an API for a mobile app.</p>

<p>After <a href="https://www.bikeshed.fm/262">exploring a handful of half-baked options</a>, I settled on using a
read-only connection to the database to still allow reads but prevent any
writes from occurring. While using the read-only connection, the Postgres adapter
will raise an error any time we attempt to change data in the database, but we
can easily rescue this specific error and convert it to a user-facing notice. I
felt a bit odd using exceptions as the core of this workflow, but in the end, it
worked out really well, so I wanted to share the specifics.</p>

<p>It’s worth noting that this solution is particularly well suited to this
specific application, which only provides an API and has very read-heavy usage,
but I imagine it could be extended to work with other styles of app as well.</p>

<h2 id="configuring-rails-to-use-the-read-only-connection">Configuring Rails to Use the Read-Only Connection</h2>

<p>If present, Rails will use the connection string in a <code>DATABASE_URL</code> env var to
connect to the database. Following the <a href="https://guides.rubyonrails.org/configuring.html#connection-preference">Connection Preference</a> notes in the
Rails guides, I realized that I could make this <code>DATABASE_URL</code> usage explicit
and allow for a temporary override. To do this, I added an explicit <code>url</code>
property for the production environment with desired connection preference:</p>

<div><pre><code><span># config/database.yml</span>

<span>production</span><span>:</span>
  <span>&lt;&lt;</span><span>:</span> <span>*default</span>
  <span>url</span><span>:</span> <span>&lt;%= ENV["DATABASE_URL_READ_ONLY"] || ENV["DATABASE_URL"] %&gt;</span>
</code></pre></div>
<p>With this in place, I can enable the read-only mode simply by setting the
<code>DATABASE_URL_READ_ONLY</code> env var:</p>

<div><pre><code>heroku config:set <span>\</span>
  <span>DATABASE_URL_READ_ONLY</span><span>=</span><span>'postgres://read_only_user:abc123...'</span> <span>\</span>
  <span>--remote</span> production
</code></pre></div>
<p>Likewise, to disable the read-only mode, I can use:</p>

<div><pre><code>heroku config:unset DATABASE_URL_READ_ONLY <span>--remote</span> production
</code></pre></div>
<p><em>Note</em>: I was able to use <a href="https://devcenter.heroku.com/articles/heroku-postgresql-credentials#managing-permissions">Heroku’s Postgres Credentials</a> interface to create
the read-only user, but if you’re not working with Heroku you should be able to
use <a href="https://dba.stackexchange.com/a/160817">these instructions</a> to create your read-only user.</p>

<h2 id="error-handling">Error Handling</h2>

<p>With other approaches I considered I found that I had to close off multiple
different potential ways to issue writes to the database, but the read-only
connection worked well to cut everything off in one change. That said, it
was only half the solution, as I certainly didn’t want the errors making it to
users.</p>

<p>Thankfully it was relatively straightforward to provide a centralized <code>rescue</code>
that would allow me to handle all the errors. First, I created a module using
Rails’s <code>ActiveSupport::Concern</code> functionality:</p>

<div><pre><code><span># app/controllers/concerns/read_only_controller_support.rb</span>
<span>module</span> <span>ReadOnlyControllerSupport</span>
  <span>extend</span> <span>ActiveSupport</span><span>::</span><span>Concern</span>

  <span>included</span> <span>do</span>
    <span>if</span> <span>ENV</span><span>[</span><span>"DATABASE_URL_READ_ONLY"</span><span>].</span><span>present?</span>
      <span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
        <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
          <span>render</span><span>(</span>
            <span>status: :service_unavailable</span><span>,</span>
            <span>json: </span><span>{</span>
              <span>info: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
            <span>},</span>
          <span>)</span>
        <span>else</span>
          <span>raise</span> <span>error</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<p>When included, this module will use Rails’s <a href="https://api.rubyonrails.org/classes/ActiveSupport/Rescuable/ClassMethods.html#method-i-rescue_from"><code>rescue_from</code></a> method to capture
potentially relevant errors, and then we do a quick check within that block
to make sure we’re only capturing the relevant errors.</p>

<p>Note, the <code>rescue_from</code> logic is only enabled when the <code>DATABASE_URL_READ_ONLY</code>
is set, so we’re able to reuse the existence of that variable as a way to scope
this behavior.</p>

<p>I was then able to include that module in any relevant base controller:</p>

<div><pre><code><span># app/controllers/application_controller.rb</span>
<span>class</span> <span>ApplicationController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>

<span># app/controllers/api/base_controller.rb</span>
<span>class</span> <span>Api</span><span>::</span><span>BaseController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>
</code></pre></div>
<h2 id="non-api-error-handling">Non-API Error Handling</h2>

<p>My initial use case for this read-only mode only needed to support API requests,
but I could imagine extending it to HTML and form-based interfaces.</p>

<p>The first thing I would consider would be adding a sitewide banner that stated
that we were in a read-only maintenance mode to alert users to the current
status.</p>

<p>With that in place, I think we could extend the error handling in the
<code>ReadOnlyControllerSupport</code> module to redirect the user back and display a
relevant message:</p>

<div><pre><code><span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
  <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
    <span>respond_to</span> <span>do</span> <span>|</span><span>format</span><span>|</span>
      <span>format</span><span>.</span><span>json</span> <span>do</span>
        <span># JSON erorr message as shown above</span>
      <span>end</span>

      <span>format</span><span>.</span><span>html</span> <span>do</span>
        <span>redirect_back</span><span>(</span>
          <span>fallback_location: </span><span>root_path</span><span>,</span>
          <span>alert: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
        <span>)</span>
      <span>end</span>
    <span>end</span>
  <span>else</span>
    <span>raise</span> <span>error</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<h2 id="scheduler-and-background-jobs">Scheduler and Background Jobs</h2>

<p>One additional consideration here would be around background jobs and scheduler
processes. For background jobs things are relatively straightforward – we just
need to scale our worker pool down to zero for the read-only period.</p>

<p>Scheduler processes are a little trickier as I didn’t have a mechanism for
globally enabling or disabling them. With that in mind, I think the ideal
solution would be to only ever have scheduler processes enqueue jobs but not
actually do any work beyond that.</p>

<h2 id="migrations">Migrations</h2>

<p>The final sticking point we ran into was migrations. We have a <code>release</code> command
defined in our <code>Procfile</code> that was configured to run <code>rake db:migrate</code>.
Unfortunately, it turns out that even if no migrations run, Rails will still
attempt to write to the <code>ar_internal_metadata</code> table as part of the <code>db:migrate</code>
command, and Heroku will run the release command any time we change an env. In
my initial attempt, Heroku failed when I attempted to set the
<code>DATABASE_URL_READ_ONLY</code> as the associated release command hit the read-only
error when running <code>rake db:migrate</code>.</p>

<p>To work around this I wrote a small script that first checks if there
are any migrations that need to be run, and only if there are, then runs <code>rake
db:migrate</code>:</p>

<div><pre><code><span>#!/bin/bash</span>

<span>set</span> <span>-e</span>

<span>if </span>bin/rails db:migrate:status | <span>grep</span> <span>'^\s\+down\s'</span><span>;</span> <span>then
  </span>bin/rails db:migrate
<span>fi</span>
</code></pre></div>
<p>This script was added to the repo as <code>bin/migrate-if-needed</code>, and then we
replaced our call to <code>rake db:migrate</code> with <code>bin/migrate-if-needed</code></p>

<h2 id="update-oct-14-2020">Update (Oct 14, 2020)</h2>

<p>After sharing this post, <a href="https://news.ycombinator.com/item?id=24780033">a commenter on Hacker News</a> pointed out <a href="https://github.com/discourse/rails_failover">the
rails_failover gem</a> that their team at Discourse maintains. It seems to offer
similar functionality, but in a more robust and fully thought out way. Looks
like a great option to implement this sort of system.</p>



    </div></div>]]>
            </description>
            <link>https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778920</guid>
            <pubDate>Wed, 14 Oct 2020 17:03:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom Rolling Out End-to-End Encryption Offering]]>
            </title>
            <description>
<![CDATA[
Score 232 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24778490">thread link</a>) | @giuliomagnifico
<br/>
October 14, 2020 | https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/ | <a href="https://web.archive.org/web/*/https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              
              <div>
                <p><a href="https://blog.zoom.us/author/mkrohn/" title="Max Krohn">
                                            <img src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" alt="Max Krohn" title="Max Krohn">
                                      </a>
                </p>
                
            </div>
                          <p><img src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" alt="Zoom Rolling Out End-to-End Encryption Offering">
                                      </p>
                <!--?xml encoding="UTF-8" ?--><p>We’re excited to announce that starting next week, Zoom’s end-to-end encryption (E2EE) offering will be available as a technical preview, which means we’re proactively soliciting feedback from users for the first 30 days. Zoom users – free and paid – around the world can host up to 200 participants in an E2EE meeting on Zoom, providing increased privacy and security for your Zoom sessions.</p>



<p>We <a href="https://blog.zoom.us/zoom-acquires-keybase-and-announces-goal-of-developing-the-most-broadly-used-enterprise-end-to-end-encryption-offering/" target="_blank" rel="noreferrer noopener">announced in May</a> our plans to build an end-to-end-encrypted meeting option into our platform, on top of Zoom’s already strong encryption and advanced security features. We’re pleased to roll out Phase 1 of 4 of our E2EE offering, which provides robust protections to help prevent the interception of decryption keys that could be used to monitor meeting content.</p>



<h2>About E2EE</h2>



<p>To be clear, Zoom’s E2EE uses the same powerful GCM encryption you get now in a Zoom meeting. The only difference is where those encryption keys live.</p>



<p>In typical meetings, Zoom’s cloud generates encryption keys and distributes them to meeting participants using Zoom apps as they join. With Zoom’s E2EE, the meeting’s host generates encryption keys and uses public key cryptography to distribute these keys to the other meeting participants. Zoom’s servers become oblivious relays and never see the encryption keys required to decrypt the meeting contents.&nbsp;&nbsp;</p>



<p>“End-to-end encryption is another stride toward making Zoom the most secure communications platform in the world,” said Zoom CEO Eric S. Yuan. “This phase of our E2EE offering provides the same security as existing end-to-end-encrypted messaging platforms, but with the video quality and scale that has made Zoom the communications solution of choice for hundreds of millions of people and the world’s largest enterprises.”</p>



<p>Zoom’s E2EE will be available as a technical preview next week. To use it, customers must enable E2EE meetings at the account level and opt-in to E2EE on a per-meeting basis.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/t2TiiQUVghal7h8dVHrvTZL-14BVFCJELb7TtGg81kjh3EDA62hSNF-_vDucMMyjmLeyYhgGTQwBd214jVKbj4gfjq9o3wwshEo35R9XiijNxcbwl-I6kZzcrcshTDQ4XSo4UcDs"></figure><h2>FAQs</h2>



<p><strong>How does Zoom provide end-to-end encryption?</strong></p>



<p>Zoom’s E2EE offering uses public key cryptography. In short, the keys for each Zoom meeting are generated by participants’ machines, not by Zoom’s servers. Encrypted data relayed through Zoom’s servers is indecipherable by Zoom, since Zoom’s servers do not have the necessary decryption key. This key management strategy is similar to that used by most end-to-end encrypted messaging platforms today.</p>



<p><strong>How do I turn on E2EE?</strong></p>



<p>Hosts can enable the setting for E2EE at the account, group, and user level and can be locked at the account or group level. All participants must have the setting enabled to join an E2EE meeting. In Phase 1, all meeting participants must join from the Zoom desktop client, mobile app, or Zoom Rooms.</p>



<p><strong>When would I use E2EE?</strong></p>



<p>E2EE is best for when you want enhanced privacy and data protection for your meetings, and is an extra layer to mitigate risk and protect sensitive meeting content. While E2EE provides added security, some Zoom functionality is limited in this first E2EE version (more on that below). Individual Zoom users should determine whether they need these features before enabling this version of E2EE in their meetings.</p>



<p><strong>Do I have access to all the features of a regular Zoom meeting?</strong></p>



<p>Not right now. Enabling this version of Zoom’s E2EE in your meetings disables certain features, including join before host, cloud recording, streaming, live transcription, Breakout Rooms, polling, 1:1 private chat, and meeting reactions.</p>



<p><strong>Do free Zoom users have access to end-to-end encryption?</strong></p>



<p>Yes. Free and paid Zoom accounts joining from Zoom’s desktop client or mobile app, or from a Zoom Room, can host or join an E2EE meeting.</p>



<p><strong>How is this different from Zoom’s enhanced GCM encryption?</strong></p>



<p>Zoom meetings and webinars by default use AES 256-bit GCM encryption for audio, video, and application sharing (i.e., screen sharing, whiteboarding) in transit between Zoom applications, clients, and connectors. In a meeting without E2EE enabled, audio and video content flowing between users’ Zoom apps is not decrypted until it reaches the recipients’ devices. However, the encryption keys for each meeting are generated and managed by Zoom’s servers. In a meeting with E2EE enabled, nobody except each participant – not even Zoom’s servers – has access to the encryption keys being used to encrypt the meeting.</p>



<p><strong>How do I verify that my meeting is using end-to-end-encryption?</strong></p>



<p>Participants can look for a green shield logo in the upper left corner of their meeting screen with a padlock in the middle to indicate their meeting is using E2EE. It looks similar to our GCM encryption symbol, but the checkmark is replaced with a lock.</p>



<figure><img loading="lazy" alt="" width="325" height="324" data-src="https://lh3.googleusercontent.com/z-Qf8a0hn5w7dX4q7GAQjGc4iNM_b45r45Um6g7iai7jV9xtmHmcl8WI26vkdAtGfLZrzZTdrszHO6kpgAKspf8rGJ7XcSYrM6asib4EgPyEwFwQkOWmPQuwYI-WplnUflaStT3T"></figure><p>Participants will also see the meeting leader’s security code that they can use to verify the secure connection. The host can read this code out loud, and all participants can check that their clients display the same code.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/Mox0nHn2hmBZqje0OSqXI46iBlhD0YmFzqG0Cv04IIDhUgN76uvL2WCP9NPhZNtKcBV0QMGugkdsUxaeVjgTjnhMrF_DGZBxW7slPIPDYGDUrqYVEiSHFgu-pLAtyYJYgAJ0fJJQ"></figure><p><strong>How will you continue to provide a safe and secure platform?</strong></p>



<p>Zoom’s top priority is the trust and safety of our users, and our implementation of E2EE will allow us to continue to enhance safety on our platform. Free/Basic users seeking access to E2EE will participate in a one-time verification process that will prompt the user for additional pieces of information, such as verifying a phone number via text message. Many leading companies perform similar steps to reduce the mass creation of abusive accounts. We are confident that by implementing risk-based authentication, in combination with our current mix of tools — including our work with human rights and children’s safety organizations and our users’ ability to lock down a meeting, report abuse, and a myriad of other features made available as part of our security icon — we can continue to enhance the safety of our users.</p>



<p><strong>What is the rest of the timeline for E2EE?</strong></p>



<p>We plan to roll out better identity management and E2EE SSO integration as part of Phase 2, which is tentatively roadmapped for 2021.&nbsp;</p>



<p>To learn more about using end-to-end encryption and other security features for your Zoom meetings, visit <a href="https://zoom.us/security" target="_blank" rel="noreferrer noopener">Zoom’s security webpage</a>.</p>
                              
            </div></div>]]>
            </description>
            <link>https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778490</guid>
            <pubDate>Wed, 14 Oct 2020 16:29:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Truechimers and falsetickers: what it takes to synchronize your clocks]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24778348">thread link</a>) | @yminsky
<br/>
October 14, 2020 | https://signalsandthreads.com/clock-synchronization/ | <a href="https://web.archive.org/web/*/https://signalsandthreads.com/clock-synchronization/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<h2 id="000004">00:00:04</h2>

<div><p>Welcome to Signals And Threads, in-depth conversations about every layer of the tech stack from Jane Street. I’m Ron Minsky.</p><p>Today we’re going to talk about a deceptively simple topic: clock synchronization. I think there’s nothing like trying to write computer programs to manipulate time to convince you that time is an incredibly complicated thing, and it’s complicated in like 16 different ways, from time zones to leap seconds to all sorts of other crazy things, but one of the really interesting corners of this world is how do you get all of the clocks on your big computer network to roughly agree with each other? In other words, clock synchronization.</p><p>So we’re going to talk about that with Chris Perl, who’s a sysadmin, who’s worked at Jane Street since 2012. Chris is better than anyone I have ever worked with, at diving into the horrible details of complex systems and understanding how they work and how they can be made to work better, and he’s done a lot of work here, specifically on clock synchronization, and has, in the course of that, redone our entire system for doing clock synchronization, so he’s had an opportunity to really learn a lot about the topic. Chris, to get started, can you give us just a quick overview of how computer clocks work in the first place?</p></div>

<h2 id="000115">00:01:15</h2>

<p>So, I guess the rough gist is something like you have some oscillator, a little crystal effectively that’s inside the computer that is oscillating at some frequency, and that’s driving an interrupt that the operating system is going to handle in some level – there’s probably lots of details here that I’m just skipping over – but that’s driving an interrupt that’s going happen in the operating system. And the operating system is using that to derive its notion of time, and so if you have a really high-quality oscillator, and those timer interrupts happen at the right rate so that you’re tracking real-time that might just happen, and if your oscillator’s very good, and very stable you could actually just be pretty close to the correct time just by virtue of that. But the truth is that most computers come with fairly bad oscillators and they change their frequencies for various reasons like heat, so if you are using your computer to compile the Linux kernel or something like that, that could change the heat profile, change the frequency of the oscillator, and actually change how well you’re doing of keeping real time.</p>

<h2 id="000205">00:02:05</h2>

<p>When we naively think of clock synchronization as people, we think of it as like, “I’m going to go set my clock”. I’m going to look at what time it is and adjust my clock to match whatever real-time is, but you’re actually talking about a different thing here. You’re talking not just about setting what the right time is right now but keeping that time correct, essentially keeping the rate at which time is going forward in sync.</p>

<h2 id="000224">00:02:24</h2>

<p>Correct. You’d love it if you could get like a really, really high-quality oscillator for super cheap in all your computers and then you wouldn’t need a lot of adjustment to get them to keep the correct time, but that would be really expensive. You can buy such things, they just cost a lot of money.</p>

<h2 id="000237">00:02:37</h2>

<p>So, you say that heat and various other things that are going on in the computer will cause this rate at which time is appearing to march forward inside of your computer to drift around. How accurate are these? Can give me a kind of numerical sense of how far these things drift away?</p>

<h2 id="000253">00:02:53</h2>

<p>The stuff that we run, we capture some of these statistics, we see machines that have a frequency correction applied to them of, say, 50 parts per million, which is like microseconds per second, so that works out to roughly a couple seconds per day, is how you would wind up drifting off. But I’m sure that if you had a super old desktop under your desk, that you stole from your parents or something and you were trying to rebuild into a Linux box, you might have worse numbers than that. Like a sort of relatively current generation server from a well-known vendor, you’re talking somewhere around 50 to 100 microseconds per second that they can sort of walk-off out of alignment.</p>

<h2 id="000327">00:03:27</h2>

<p>Okay, so clock synchronization is the process of trying to get all of those clocks that you have across your whole data center and across multiple data centers to be in sync with each other. Is that the right way of thinking about it?</p>

<h2 id="000339">00:03:39</h2>

<p>I think so. “In sync”, is an interesting sort of thing to say, right? You kind of would like that if you were able to instantaneously ask two random servers on your network, what time it was at the same exact point in time, if you could somehow magically do that, that they would agree to some relatively small margin of error, and I think that that’s kind of what we mean by clock synchronization. That if you could somehow magically freeze time and go ask every single computer on your network, “Hey. What time do you think it is?” that they would all roughly agree to within some error bound that you can define.</p>

<h2 id="000413">00:04:13</h2>

<p>Right. And this basic model actually assumes that there is a well-defined notion of what it means to be instantaneously at the same time, which isn’t exactly true because of relativity and stuff like that, but we’re going to mostly ignore that. So, I guess one property that you’re highlighting here is having the clocks agree with each other, and that’s part of it, but there’s another piece, right, which is having the clocks agree with some external reference. There’s some notion of like, what does the world think the time is? So, where does that external reference come from?</p>

<h2 id="000435">00:04:35</h2>

<div><p>I’m not an expert on this stuff, but I’ll give you the sort of 10,000-foot view. You have various physics laboratories all over the world, like NPL in the UK, and other places across the world. They all have measurements of what they think time is, using things like hydrogen masers and sort of very accurate atomic methods. They contribute all of that stuff to a single source who kind of averages it, or does some sort of weighting, to come up with what the correct time is, and then you kind of magic that over to the Air Force, who then sends it up to the GPS constellation. And GPS has a mechanism for getting time from the GPS satellites down to GPS receivers, and so if you’re a person who runs a computer network and you’re interested in synchronizing your clocks to a relatively high degree of accuracy with something like UTC, which is effectively Greenwich Mean Time, it is just sort of the current time without time zones applied. </p><p>If you’re interested in doing that, what you can do is you can just go out to a vendor and you can buy a thing called a GPS appliance, which can hook up to a little antenna that goes onto the roof. It can receive this signal from the GPS constellation and basically gives you out time, and the accuracy there is something like maybe 100 nanoseconds or so. So you’ve got the sort of atomic measurements being fed up to a GPS constellation, down to GPS receivers that you, as an operator of a computer network, can buy.</p></div>

<h2 id="000557">00:05:57</h2>

<p>And for the purposes of this conversation, we’re going to treat those GPS receivers as the received wisdom as to what time it is, and our job is to figure out how, inside of a computer network, you make all of the different devices agree with each other and agree with that external reference.</p>

<h2 id="000611">00:06:11</h2>

<p>Correct.</p>

<h2 id="000612">00:06:12</h2>

<p>Why is it important? What does having synchronized clocks help you do?</p>

<h2 id="000622">00:06:22</h2>

<p>If you put yourself in the shoes of a financial regulatory authority, and you have all these different participants out there doing stuff with computer systems, and something weird happens, and you’d like to come up with a total ordering of events of what led to this crazy thing – or what led to this good thing, who knows – but you want to have a total ordering of events. If people don’t have good clock synchronization, to some external source, you can’t compare the timestamp from participant A to the timestamp from participant B, so if you were to decree everybody must have time that is within some error bound, you know if these timestamps are within that error bound, well, then I can’t be sure about the ordering, but if they’re farther away than that then I can be sure about the ordering. I can know which one came first and which one came second, and that can be very useful.</p>

<h2 id="000655">00:06:55</h2>

<p>So that’s the motivation that’s very specific to our industry, but don’t people in other industries care a lot about clock synchronization, too? I would have thought that there are other reasons that would drive you to want to synchronize the machines on the network.</p>

<h2 id="000706">00:07:06</h2>

<p>Oh, sure. There’s lots of different things. I mean, just like a general sysadmin topic, a lot of times you want to gather logs from all the systems on your computer network, and you want to analyze them for various reasons. Maybe it’s because you’re concerned about intruders. Or maybe it’s because you’re just trying to understand the way things are functioning, and if your clocks aren’t synchronized it’s very hard to kind of understand things that might have happened on system B and how they relate to system A because the two timestamps are just not – you just can’t compare them if they’re not synchronized.</p>

<h2 id="000733">00:07:33</h2>

<p>And I suppose there are also some distributed systems, algorithmic reasons to want clocks. Certainly, some kinds of distributed algorithms end up using clocks as ways of breaking ties between systems, and so that requires at least some reasonable level of synchronization.</p>

<h2 id="000745">00:07:45</h2>

<p>For sure. There’s also other network protocols that are widely used that require clock synchronization, but much less precise levels of clock synchronization. Kerberos is a widely used authentication protocol, and that requires that the clocks be synchronized to within five minutes, and the idea there is to thwart replay attacks, and stuff like that, making …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://signalsandthreads.com/clock-synchronization/">https://signalsandthreads.com/clock-synchronization/</a></em></p>]]>
            </description>
            <link>https://signalsandthreads.com/clock-synchronization/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778348</guid>
            <pubDate>Wed, 14 Oct 2020 16:19:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dockerfile Security Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 171 (<a href="https://news.ycombinator.com/item?id=24776771">thread link</a>) | @gbrindisi
<br/>
October 14, 2020 | https://cloudberry.engineering/article/dockerfile-security-best-practices/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/dockerfile-security-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p>Container security is a broad problem space and there are many low hanging fruits one can harvest to mitigate risks. A good starting point is to follow some rules when writing Dockerfiles.</p>

<p>I’ve compiled a list of common security issues and how to avoid them. For every issue I’ve also written an <a href="https://www.openpolicyagent.org/">Open Policy Agent</a> (OPA) rule ready to be used to statically analyze your Dockerfiles with <a href="https://conftest.dev/">conftest</a>. You can’t shift more left than this!</p>

<p>You can find the <code>.rego</code> rule set in <a href="https://github.com/gbrindisi/dockerfile-security">this repository</a>. I appreciate feedback and contributions.</p>

<h2 id="do-not-store-secrets-in-environment-variables">Do not store secrets in environment variables</h2>

<p>Secrets distribution is a hairy problem and it’s easy to do it wrong. For containerized  applications one can surface them either from the filesystem by mounting volumes or more handily through  environment variables.</p>

<p>Using <code>ENV</code> to store secrets is bad practice because Dockerfiles are usually distributed with the application, so there is no difference from hard coding secrets in code.</p>

<p>How to detect it:</p>

<pre><code>secrets_env = [
    "passwd",
    "password",
    "pass",
 #  "pwd", can't use this one   
    "secret",
    "key",
    "access",
    "api_key",
    "apikey",
    "token",
    "tkn"
]

deny[msg] {    
    input[i].Cmd == "env"
    val := input[i].Value
    contains(lower(val[_]), secrets_env[_])
    msg = sprintf("Line %d: Potential secret in ENV key found: %s", [i, val])
}
</code></pre>

<h2 id="only-use-trusted-base-images">Only use trusted base images</h2>

<p>Supply chain attacks for containerized application will also come from the hierarchy of layers used to build the container itself.</p>

<p>The main culprit is obviously the base image used. Untrusted base images are a high risk and whenever possible should be avoided.</p>

<p>Docker provides a <a href="https://docs.docker.com/docker-hub/official_images/">set of official base images</a> for most used operating systems and apps. By using them, we minimize risk of compromise by leveraging some sort of shared responsibility with Docker itself.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], "/")
    count(val) &gt; 1
    msg = sprintf("Line %d: use a trusted base image", [i])
}
</code></pre>

<p>This rule is tuned towards DockerHub’s official images. It’s very dumb since I’m only detecting the absence of a namespace.</p>

<p>The definition of trust depends on your context: change this rule accordingly.</p>

<h2 id="do-not-use-latest-tag-for-base-image">Do not use ‘latest’ tag for base image</h2>

<p>Pinning the version of your base images will give you some peace of mind with regards to the predictability of the containers you are building.</p>

<p>If you rely on latest you might silently inherit updated packages that in the best worst case might impact your application reliability, in the worst worst case might introduce a vulnerability.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], ":")
    contains(lower(val[1]), "latest"])
    msg = sprintf("Line %d: do not use 'latest' tag for base images", [i])
}
</code></pre>

<h2 id="avoid-curl-bashing">Avoid curl bashing</h2>

<p>Pulling stuff from internet and piping it into a shell is as bad as it could be. Unfortunately it’s a widespread solution to streamline installations of software.</p>

<pre><code>wget https://cloudberry.engineering/absolutely-trustworthy.sh | sh
</code></pre>

<p>The risk is the same framed for supply chain attacks and it <strong>boils down to trust</strong>. If you really have to curl bash, do it right:</p>

<ul>
<li>use a trusted source</li>
<li>use a secure connection</li>
<li>verify the authenticity and integrity of what you download</li>
</ul>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    matches := regex.find_n("(curl|wget)[^|^&gt;]*[|&gt;]", lower(val), -1)
    count(matches) &gt; 0
    msg = sprintf("Line %d: Avoid curl bashing", [i])
}
</code></pre>

<h2 id="do-not-upgrade-your-system-packages">Do not upgrade your system packages</h2>

<p>This might be a bit of a stretch but the reasoning is the following: you want to pin the version of your software dependencies, if you do <code>apt-get upgrade</code> you will effectively upgrade them all to the latest version.</p>

<p>If you do upgrade <strong>and</strong> you are using the <code>latest</code> tag for the base image, you amplify the unpredictability of your dependencies tree.</p>

<p>What you want to do is to pin the base image version and just <code>apt/apk update</code>.</p>

<p>How to detect it:</p>

<pre><code>upgrade_commands = [
    "apk upgrade",
    "apt-get upgrade",
    "dist-upgrade",
]

deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(val, upgrade_commands[_])
    msg = sprintf(“Line: %d: Do not upgrade your system packages", [i])
}
</code></pre>

<h2 id="do-not-use-add-if-possible">Do not use ADD if possible</h2>

<p>One little feature of the <code>ADD</code> command is that you can point it to a remote url and it will fetch the content at building time:</p>

<pre><code>ADD https://cloudberry.engineering/absolutely-trust-me.tar.gz
</code></pre>

<p>Ironically the official docs suggest to use curl bashing instead.</p>

<p>From a security perspective the same advice applies: don’t.
Get whatever content you need before, verify it and then <code>COPY</code>. But if you really have to, <strong>use trusted sources over secure connections</strong>.</p>

<p>Note: if you have a fancy build system that dynamically generate Dockerfiles, then <code>ADD</code> is effectively a sink asking to be exploited.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "add"
    msg = sprintf("Line %d: Use COPY instead of ADD", [i])
}
</code></pre>

<h2 id="do-not-root">Do not root</h2>

<p>Root in a container is the same root as on the host machine, but restricted by the docker daemon configuration. No matter the limitations, if an actor breaks out of the container he will still be able to find a way to get full access to the host.</p>

<p>Of course this is not ideal and your threat model can’t ignore the risk posed by running as root.</p>

<p>As such is best to always specify a user:</p>

<pre><code>USER hopefullynotroot
</code></pre>

<p>Note that explicitly setting a user in the Dockerfile is just one layer of defence and won’t solve the whole <a href="https://www.redhat.com/en/blog/understanding-root-inside-and-outside-container">running as root problem</a>.</p>

<p>Instead one can — and <em>should</em> — adopt a defence in depth approach and mitigate further across the whole stack: strictly configure the docker daemon or use a rootless container solution, restrict the runtime configuration (prohibit <code>--privileged</code> if possible, etc), and so on.</p>

<p>How to detect it:</p>

<pre><code>any_user {
    input[i].Cmd == "user"
 }

deny[msg] {
    not any_user
    msg = "Do not run as root, use USER instead"
}
</code></pre>

<h2 id="do-not-sudo">Do not sudo</h2>

<p>As a corollary to <code>do not root</code>, you shall not sudo either.</p>

<p>Even if you run as a user make sure the user is not in the <code>sudoers</code> club.</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(lower(val), "sudo")
    msg = sprintf("Line %d: Do not use 'sudo' command", [i])
}
</code></pre>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>This work has been inspired and is an iteration on <a href="https://blog.madhuakula.com/dockerfile-security-checks-using-opa-rego-policies-with-conftest-32ab2316172f">prior art</a> from <a href="https://blog.madhuakula.com/@madhuakula">Madhu Akula</a>.</p>
        </div>
        
    </div></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/dockerfile-security-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776771</guid>
            <pubDate>Wed, 14 Oct 2020 14:17:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unspoken Hard Bits of Bootstrapping a SaaS Product to Life]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24776605">thread link</a>) | @geoffroberts
<br/>
October 14, 2020 | https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping | <a href="https://web.archive.org/web/*/https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ec2306edd8f63db4e902"><div><p>The challenges that I’ve faced as a bootstrapped founder simply aren’t the ones that are commonly talked about</p><p>By <a href="https://twitter.com/GeoffTRoberts">Geoff Roberts</a> · 17 min read</p><p>The internet is littered with horror stories detailing the many challenges of entrepreneurship. We’ve all read the tales of founders wrestling for years to find <a href="https://www.outseta.com/posts/product-market-appetite">product market fit</a>, of co-founders squabbling over equity, of the CEO riddled by anxiety as he drains his infant daughter’s college fund to keep his start-up afloat for another month.</p><p>Cautionary tales? Sure. But while these circumstances may be relatively common, ultimately they gain notoriety in the tech media simply because they are alarmist and clickbait.&nbsp;</p><p>As I approach year four as a founder of a bootstrapped SaaS start-up, I can’t help but reflect on the hardships that I’ve encountered myself. As I have, I’ve had an overwhelming feeling—the majority of challenges that I’ve faced are by no means unique to me, but <em>nobody is talking about them</em>. This article is about surfacing those common entrepreneurial challenges that are gasping for some air.&nbsp;&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180654131_6032"><div><p>I’d go so far as to say most entrepreneurial challenges that we hear being bemoaned are a direct result of your chosen path being incompatible with your business idea or life circumstances. When these items are in harmony, entrepreneurship becomes vastly easier.</p><p>If you’re building SpaceX, your idea dictates that you go the VC route—it’s too big, too ambitious, and too capital intensive to bootstrap such a company into existence. This is an extreme example, but this is the lens through which we should be assessing our start-up ideas as we decide how to fund them.</p><p>Generally speaking, “smaller” products are better suited to bootstrapping. Building a slack notification tool? Great! You can probably launch something like this in less than a month, give the project the opportunity to gain some traction, then make the decision to proceed or not from there. You’d be crazy <em>not</em> to bootstrap such a company.&nbsp;&nbsp;&nbsp;</p><p>But if you’re building a bigger and more ambitious piece of software you need to look closely at the reality that it could take years to bring something of value to fruition. Can you afford a year without a paycheck? How about three years, or five?&nbsp;</p><p>It’s worth noting that this isn’t solely a financial decision or one of product scope, but also one that will impact your day-to-day life potentially for years to come. Did you recently sign a mortgage? Do you plan on having kids? The stresses that come with entrepreneurship and how you choose to fund your business will have trickle down effects on all aspects of your life.</p><p>The question is not do you prefer bootstrapping or venture capital. The question is which path is most compatible with the product you’re building… and your life.&nbsp;</p><p>Bringing this full circle to Outseta, in many ways Outseta is not an idea compatible with the idea of bootstrapping. Outseta is a very large and ambitious project that we’re executing on with a small team—it’s really three or four different software products rather than one. We knew this going in and openly talked about how it would take years for us to truly be able to deliver on our value proposition and start to grow revenue in a meaningful way. It took us two years to deliver a sellable product, and four years in now we’re just starting to scale.&nbsp;</p><p>But we had one major advantage—the idea that we chose to build was not one that needed “validating”—the categories of software that we offer (CRM, billing, email marketing, etc) have staying power and have been validated long ago. This gave us confidence that we could play the long game and allowed us to design all aspects of our business and lives so that we could survive long enough to see Outseta blossom into what it’s become today.&nbsp;</p><p>We didn’t choose an easy route, but we’re now finding that Outseta is massively defensible because very few teams would commit 4+ years just to bring an idea to life. You could do it much more quickly with venture capital, sure, but you’d never be able to serve the audience that we do at our price point.&nbsp;</p><h2>The “Doldrums” of SaaS</h2><p>One of the most common and least talked about hardships of bootstrapping a SaaS start-up is what I’ve started describing as “the doldrums of SaaS.” This occurs when your start-up hits an inflection point in sign-ups and support requests scale up dramatically to the extent that they all but take over your ability to focus on other aspects of your business, from marketing to building new features.</p><p>Ironically enough, this stage in a bootstrapped start-up’s growth initially became apparent to me because of one of our competitors. We started getting dozens of sign-ups from founders all singing the same tune.&nbsp;</p><p><em>“I was using CompetitorX—I loved their product initially, but they’re unresponsive and haven’t released any new features in months.”</em></p><p>Then earlier this spring, we went through a similar stage. On the back of a new partnership with <a href="https://www.outseta.com/webflow">Webflow</a>, all of a sudden the number of sign-ups for Outseta scaled up dramatically—and in tandem with that growth came an influx of support tickets from new users learning the platform.</p><p>My summer was spent focused almost entirely on technical support, while my time spent marketing Outseta fell off a cliff. Likewise, my Co-founders were pushing fixes and helping out with new Outseta implementations cutting into their ability to roll out new features.</p><p>Ultimately this is a stage in a bootstrapped start-up’s growth that doesn’t get much lip service because there’s little benefit to speaking about increased support levels and decreased capacity for building new features. But that’s unfortunate because this is a “good problem” that nearly every scaling company will encounter—yet there’s very little advice out there on how to best handle this stage of the entrepreneurial journey.</p><p>If you’re a VC backed company, it’s an easy problem to fix—throw some money at hiring additional support capacity, because you have the ability to run your company at a loss. But for a bootstrapper this stage can feel like your legs are stuck in quicksand.</p><p>I don’t have a solution here, aside from taking some degree of solace in the thought that time spent helping customers is the most single important thing that you can do to build your business. And rather than hiring support capacity, using your engineering resources to solve underlying issues that result in increased support requests will always pay off in the long run.</p><h2>The psychological toll of not feeling like you’re “all-in”</h2><p>It’s well documented that many entrepreneurs feel extreme levels of stress, anxiety, worry, and even depression—which most often is tied to financial instability and the regular peaks and valleys of building a company. But for me personally—and I suspect many others—one of the strongest psychological tolls I’ve felt is stress that comes from feeling like I’m not yet able to be “all-in” on my start-up.</p><p>Make no mistake about it—since the day we started Outseta, I’ve undoubtedly been “all-in.” I’ve rearranged almost all aspects of my life over four years in support of bringing this company into existence. But as part of our strategy to <a href="https://www.outseta.com/posts/marketing-strategies-for-bootstrappers">bootstrap the business</a>, our entire team began working on Outseta in a part-time capacity while consulting or working on other projects to pay the bills. We’ve gradually ramped up the time we’ve each invested in the business as our growth has permitted, as most bootstrappers do.</p><p>For me personally, this meant that for years, literally, there was always this nagging feeling that I could be doing more. I could be doing more or doing better for Outseta, and I could be doing more in terms of the other projects I was working on as well. For me, that feeling has been tough. It feels really good to be able to say that you unequivocally, without question, are giving something your all. But most bootstrappers have to wait quite a long period of time until their business can truly support every last scrap of their attention at work. That’s a long period of time to wait to shed that nagging feeling!</p><h2>SaaS <em>is</em> a torture chamber</h2><p>The wonders of SaaS as a business model are well known—the stability and predictability of recurring revenue, products that can scale to thousands of users, high valuations—the whole nine yards. But the fact of the matter is that for bootstrapped founders, SaaS <em>is</em> a torture chamber and a game of delayed gratification.</p><p>Don’t misunderstand me and immediately suppose that there’s some sort of self-inflicted pain behind this comment—I’m the biggest proponent of work/life balance and generally the principles outlined in Jason Fried and DHH’s <a href="https://www.amazon.com/Doesnt-Have-Be-Crazy-Work/dp/0062874780"><em>It Doesn’t Have To Be Crazy At Work</em></a> that you’ll ever find. This is solely a matter of the business model.</p><p>When you’re bootstrapping, you’re going to start off without a paycheck. Most of us work towards a point where the revenue of the business can eventually start to pay us something, then we scale up our own compensation until it reaches some semblance of a normal salary. The problem with SaaS and bootstrapping is you are hugely incentivized not to pay yourself—every dollar that you pay yourself is money that isn’t being reinvested in the growth of your business, so you’re intentionally slowing down your own growth.</p><p>Of course there are human, real world circumstances to consider and your own financial and emotional needs directly correlate to your ability to work on your business successfully. But the hard reality is the longer you can delay your own gratification, the greater your advantage.&nbsp;</p><p>I asked my Co-founder, Dimitris, to speak to his experience of the long, slow ramp of death that’s so prevalent in SaaS. Dimitris Co-founded <a href="https://www.buildium.com/">Buildium</a> back in 2004.</p><p>“It took us 2.5 years to get to 50 customers,” says Dimitris. “Then it took us another year to get to 400 customers, and a year after that we reached 1,000 customers. When we had 400 customers we made a conscious decision to defer paying ourselves more than a token $1,000 per month salary and instead hired our first two full-time …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</a></em></p>]]>
            </description>
            <link>https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776605</guid>
            <pubDate>Wed, 14 Oct 2020 14:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's start writing code in a simple, understandable way]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24776275">thread link</a>) | @sklivvz1971
<br/>
October 14, 2020 | https://sklivvz.com/posts/consider-using-simple-models-instead | <a href="https://web.archive.org/web/*/https://sklivvz.com/posts/consider-using-simple-models-instead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://imgur.com/vtdpk9t.png" alt=""></p>
<p>I want to share with you the pattern which I use very often to build classes in my web applications. It is different and relatively more straightforward in comparison to most enterprise patterns. I don't claim it's suitable for anyone but me -- I write web applications. It works exceptionally well for the cases I encounter, unlike the repository pattern, which is excellent if you have vast amounts of business logic, or command/query separation, which is very suitable for desktop-like experiences.</p>
<p>There are two guiding principles beyond it, which I find applicable generally:
simplicity, or the art of maximizing the work <em>not</em> done;
cohesion, keeping related code together to decrease the cognitive cost of coding.</p>
<p>First of all, remember that I build web applications. For me, a backend server either serves APIs or web pages and in most cases, the main business logic is a straight SQL query or a cache lookup.</p>
<p>I usually adopt an MVC pattern with ViewModels -- not the MVVM two-way binding monstrosity, ViewModels only serve as transport to get the data to the views. This is the main control flow for a typical request.</p>
<p><img src="https://imgur.com/560MwDF.png" alt=""></p>
<p>For most pages, business logic falls into two categories, either validation or simple database operations. The former is best implemented through a filter, middleware, or other <a href="https://en.wikipedia.org/wiki/Aspect-oriented_programming">aspect-oriented</a> language feature. This makes it testable. The latter runs on the database and can only be tested through an integration test. </p>
<p>As a side note, you might think that an ORM makes it possible to test these operations locally, and you would be wrong, I'm sorry to report. You would be validating the ORM and not the actual query that -- generated or not -- is what runs. In other words, you would be exercising a mock and no business logic. The sad fact is that databases (or caches) run a large part of the actual business logic for most web pages!</p>
<p>In other words, what you actually want to test is, in large part, locked away in a SQL query. This is why the repository pattern, or similar ways of decoupling "business logic" from "database calls" is not very useful in simple cases: the database calls <em>are</em> the business logic.</p>
<p>In these simple -- yet very pervasive -- cases, I use the following pattern. Start with a simple DTO:</p>
<pre><code>public class Widget
{
    public int? Id { get; private set; }
    public string Name { get; set; }
    public string PartNumber { get; set; }
    // ... other properties here
}
</code></pre>
<p>I kept the class mutable. This is because I plan to make this record updateable, and frankly, immutability gets in the way of keeping that as simple as possible. Only <code>Id</code> is kept immutable for reasons we'll see below.</p>
<p>Let's implement a simple CRUD, starting with getting a list of widgets.</p>
<pre><code>public class Widget
{
    // ... properties here
    public static List&lt;Widget&gt; All()
    {
        using (var conn = Common.GetConn())
        {
            return conn.Query&lt;Widget&gt;("Select * From Widgets");
        }
    }
}
</code></pre>
<p>As you can see, it's a straight <a href="https://github.com/StackExchange/Dapper">Dapper</a> query in a static method, right next to the properties that Dapper maps to. This is quite arguably the <em>simplest possible way</em> to get this data out of the database and into a class list. As such, it's my go-to coding solution, until an actual real, non-theoretical necessity emerges to do differently.</p>
<p>Single reads are implemented similarly.</p>
<pre><code>public class Widget
{
    // ... properties and other methods here
    public static Widget GetById(int id)
    {
        using (var conn = Common.GetConn())
        {
            return conn.QuerySingleOrDefault&lt;Widget&gt;("Select * From Widgets Where Id = @Id", id);
        }
    }
}
</code></pre>
<p>What about commands, i.e., Creates, Updates, and Deletes? Deletes are also static and take an <code>id</code> parameter -- generally, no one wants to pull a whole object out of the database just to delete it and if you do happen to have an instance already handy, passing the id is easy enough.</p>
<p>Creates and updates I usually merge into a single Save method. If a class has the <code>Id</code> property set, then we assume an update; if it is unset, then it is a new object to be inserted. Of course, the developer end-user cannot set the <code>Id</code> because of its private accessor, but Dapper can. Only classes that come from the actual database have an <code>Id</code> that will be used in the update.</p>
<p>This needs not to be a static method (although a static variant is always possible).</p>
<pre><code>public class Widget
{
    // ... properties and other methods here
    public void Save()
    {
        var sql = "";
        if (Id.HasValue())
            sql = "Update Widgets Set Name = @Name, PartNumber = @PartNumber /* other sets here */ Where Id = @Id; Select @Id";
        else
            sql = "Insert Into Widgets (Name, PartNumber /* etc */) Values (@Name, @PartNumber /* etc */); Select ScopeIdentity()";

        using (var conn = Common.GetConn())
        {
            this.Id = conn.QuerySingle&lt;int&gt;(sql, this);
        }
    }
}
</code></pre>
<p>This is the pattern. Further commands are likely to be implemented as property manipulation, followed by a <code>Save</code> call. Other queries depend on the size of the table in question, and they can be either custom SQL queries or perhaps LinqToObjects if the results of <code>All()</code> are cached in memory.</p>
<p>In conclusion, I've shown a simple way to implement Models as simple, self-contained entities that are perfectly adequate in large part of the use cases of web applications. I do not claim this way is the "one true way," but it works for me, and as any abstraction, please do not consider it a panacea.</p>
<p>Hopefully, whether you agree or less with me, you will spend some time reflecting on whether you really need that fat ORM-based, dependency-injected, data-mapped solution next time you write a simple model class.</p>
</div></div>]]>
            </description>
            <link>https://sklivvz.com/posts/consider-using-simple-models-instead</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776275</guid>
            <pubDate>Wed, 14 Oct 2020 13:28:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 CPU User Manual (2016)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24776115">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://zany80.github.io/documentation/Z80/UserManual.html | <a href="https://web.archive.org/web/*/https://zany80.github.io/documentation/Z80/UserManual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zany80.github.io/documentation/Z80/UserManual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776115</guid>
            <pubDate>Wed, 14 Oct 2020 13:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Shows the Germans How to Move Quickly]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24775556">thread link</a>) | @Tomte
<br/>
October 14, 2020 | https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;4f34f3e1-6c6f-4065-9ec6-3301690ac70f&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;011a50b0-5eca-4b9c-a93b-b9a3ce8c66a3&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg" srcset="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w520_r1.77_fpx76_fpy24.jpg 520w, https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg 948w" width="948" height="536" sizes="948px" title="Tesla founder Elon Musk: &quot;A ton of fun!&quot;" alt="Tesla founder Elon Musk: &quot;A ton of fun!&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Tesla founder Elon Musk:</strong> "A ton of fun!"</p>
<span>
Foto: <p>Julian Stähle / dpa</p>
</span>
</figcaption>
</figure>
</div><div>
<p>A large property map hangs in the mayor's office, right next to a display cabinet full of memorabilia accumulated over a long term in office. The coat of arms of the town of Grünheide on the map has faded, as has the writing: "Net settlement area of 300 hectares," it reads, if you look hard enough.</p>


<div>
<p>Arne Christiani's predecessor hung up the poster 20 years ago, back when BMW wanted to build a car manufacturing plant on the site, but then chose the city of Leipzig instead. "When I was first elected mayor in 2003, I left the map up," says Christiani. The pine forest on the edge of the town has remained his field of dreams for almost 17 years.</p><p>During that time, Grünheide has grown steadily, but its population has also aged. It's a place that's beautiful for people who appreciate peace and quiet, but not one that’s particularly tempting for the younger generation. Each year, Christiani has apologized to locals on International Volunteer Day for the fact that it had once again not been possible to attract high-quality industrial jobs to the area.</p>
</div>

<div>
<p>For some time now, though, two new maps have been hanging above the old one, with the parcel of land colored red. Christiani's dream could finally be coming true, with Tesla hoping to build electric cars on the site.</p><h3><strong>Dreams Threatened, Dreams Come True</strong></h3><p>If you leave Town Hall and walk a good 800 meters through a pine forest to the edge of the village, you reach a lake called Peetzsee. Christiani had been in office for two years when Johannes Curth and his family came to fulfil their dream here, swapping a rental apartment in Berlin’s Prenzlauer Berg neighborhood for a home of their own, surrounded by forests and lakes.</p>
</div>

<p>The Curths bought a plot of land just a few meters from the shore of the lake back when prices were still reasonable. They built a house with large windows and surrounded by a good-sized yard, in which stand two magnificent old trees in it.</p>

<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 39/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;640c6d43-536f-4a18-abc5-735accbca6fa&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>But now that Mayor Christiani's dream is coming true, Curth sees his own dream threatened. "We moved here because of the peace and quiet and the nature," he says. "What will happen if Tesla starts building cars here?" He fears for the quality of the water and air. And he worries about the extra traffic and what will happen to this sleepy community of 8,755 people when Tesla moves in.</p>

<div>
<p>Elon Musk, the entrepreneur behind the carmaker, is an uncompromising man whose ideas jump back and forth between California, Mars and Grünheide. The head of the world's largest electric car manufacturer builds rockets that ferry people into space and dreams of building a hyperloop tunnel for passenger transport. He is adored by his followers because, as an entrepreneur, he refuses to accept any limits.</p><h3><strong>Breathtaking Speed</strong></h3><p>Almost as a byproduct, Musk is now also changing not only the provincial state of Brandenburg, where he’s setting up his factory, but also Germany. The project just outside of Berlin is becoming symbolic for industrial policy in times of climate change. Whereas German companies tend to moan and dig in their heels when the government sets overly ambitious climate targets, as they did last week when the new European Union climate goals were announced, Tesla brings both together: sustainable manufacturing and speed. Breathtaking speed.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;7bfd7c90-7763-4bb3-ad45-ab17ec97c569&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;2ce6ae6b-8cd6-4df5-a9fe-c32f7c47f756&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" width="718" height="479" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" title="Tesla Gigafactory in Grünheide: Are the Germans fast enough?" alt="Tesla Gigafactory in Grünheide: Are the Germans fast enough?">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Tesla Gigafactory in Grünheide:</strong> Are the Germans fast enough?</p>
<span>
Foto: Robert Grahn&nbsp;/ euroluftbild.de / ullstein bild
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>Musk's Gigafactory will be built in a region where most structures tend to be single-family homes, if there are any at all. In the first stage of development, 12,000 people will work around the clock in three shifts. Once the factory is complete, more than 40,000 people could produce a good 2 million Tesla vehicles here. "Please work at Tesla Giga Berlin! It's going to be a ton of fun," Musk recently tweeted in German.</p><p>For quite some time, German car executives and politicians tended to make fun of Musk, notorious as he was for his outrageous personality on Twitter. When he outlined his visions at a 2014 lunch with Peter Altmaier - who was chief of staff of Angela Merkel's Chancellery at the time but is now economics minister – and raved about the advantages of electric propulsion, saying it could be used in all means of transportation except for rockets flying into space, Altmaier still thought he sounded a bit unhinged. "At the time," says Altmaier, "nobody thought this technology would be so successful." At least the German competition didn't.</p><p>As recently as 2018, when the California-based company was having troubles with the serial production of its Model 3, Volkswagen considered becoming a strategic investor in Tesla to teach Musk how to do mass production. But reality has long since overtaken that idea: Tesla is now worth five times as much as Volkswagen on the stock exchange.</p><p>The days when the billionaire had to ask politicians for an appointment are over. When he came to Germany in early September to visit his construction site, the reception he received was that of a pop star. Fans shared the latest movement data of his private jet and puzzled where he might pop up next. Leading politicians cleared their calendars at short notice.</p><p>This week, the Musk party is set to continue, and his name will once again appear in newspapers around the world. He has slated this Tuesday as "Battery Day,” when he plans to announce the progress Tesla has made in battery technology in addition to identifying the site of at least one new battery plant. There are many indications, including interviews with Musk, that Grünheide may be chosen as the site. If it is, giant tree-felling machines would again show up to wait for authorization to clear another 60 hectares (nearly 150 acres) of forest.</p><p>It would send an unmistakable message. Because one day later, on Wednesday, hearings are set to begin in the nearby town of Erkner on the 406 complaints against the factory that have been filed by environmental associations and residents. Construction, though, has already been underway for months, with Tesla deciding to move ahead at its own risk with preliminary permits.</p><h3><strong>Faster and Better</strong></h3><p>A recent visit to the construction site in Grünheide provided a glimpse of the degree to which Tesla's mantra has been internalized at Tesla, a mantra by which speed counts most. Evan Horetsky, who heads the roughly 100-member Tesla team in Grünheide, showed a number of interested journalists around the construction site.</p><p>The slim man in his mid-30s with a shaved head and carefully trimmed beard is one of the troubleshooters on Musk's team. He helped out with the Tesla factory in California before going to Reno, Nevada, to lead the creation of the company's first Gigafactory. That had hardly been finished by the time construction in Shanghai began. He says that he and his people have gotten "faster and better" each time. Now, Horetsky is moving things along in Brandenburg.</p><p>Just last fall, the site was covered with tall pine trees. Now, though, they have been replaced by dozens of white concrete pillars protruding from the levelled ground. In the rear section, the shell of the paint shop has been erected. "We gained experience during the construction of the first buildings that we could directly apply in the further development of the design," the American says. "It enabled us to save a couple of days."</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;557ddc99-4b15-46b4-871e-c4391a0edffd&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;c472a109-402d-4560-bace-2978897f5ba0&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg" srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" width="718" height="480" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" title="Mayor Arne Christiani: A field of dreams." alt="Mayor Arne Christiani: A field of dreams.">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Mayor Arne Christiani: </strong>A field of dreams.</p>
<span>
Foto: HC Plambeck / DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>The fact that final permission to build the factory has not yet been granted and that skeptical citizens must first be heard doesn't bother Horetsky. He says he takes their fears seriously. He notes that similarly complicated requirements had to be fulfilled when building the factory in Shanghai. "The difference to Germany is that here, the people who are directly affected can have their say," says Horetsky. "And who has more of a right to air their views than they do?"</p><p>It is, essentially, the concrete realization of what had been an abstract discussion. What price is society prepared to pay for the future? And are Germans capable of keeping up with the necessary pace?</p><p>The Gigafactory is set to be built in record time, with the first Y model electric SUVs slated for shipping as early as summer 2021. Plans call for 500,000 electric cars to be produced annually by the end of the first construction stage, a pace the <em>Wall Street Journal</em> has described as "breakneck."</p><p>And all this is taking place in Germany, a country where the length of approval procedures has almost doubled in the last 10 years. And in the state of Brandenburg, where construction of the Berlin-Brandenburg Airport (BER) has been marred by endless construction problems and is finally set to open its doors, fully nine years behind schedule.</p><h3><strong>Not Even Corona Has Slowed the Project</strong></h3><p>It sounded almost like a joke initially: An American high-tech car company with a volatile boss meets German environmental law, citizen participation and German bureaucracy. Now, though, it looks as though electric cars could start rolling off the assembly line in Grünheide even faster than they did in centrally steered China. And not even the coronavirus has thus far managed to slow down the project.</p><p>Somehow, the clichés didn't hold true. Tesla may be a tenacious, demanding company, but it also takes criticism seriously and tries to address it. In contrast to German companies, Musk uses every possibility that planning law avails him to accelerate construction, but he does so at his own risk. At the same time, the Brandenburg government has shown itself to be a skilful negotiator in the fight for the project. Since the contract was awarded, a task force of employees from the participating authorities has met weekly with Tesla representatives to discuss progress on the project.</p><p>Axel Vogel was one of the founding members of the Green Party in 1980. He worked …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775556</guid>
            <pubDate>Wed, 14 Oct 2020 11:59:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sega Master System Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24775305">thread link</a>) | @Parseus
<br/>
October 14, 2020 | https://www.copetti.org/projects/consoles/master-system/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/master-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The Master System comes from a long line of succession. What started as a collection of off-the-shelf components, has now gained a new identity thanks to Sega’s engineering.</p><hr><h2 id="models-and-variants">Models and variants</h2><p>I was a bit confused at first while reading about the different models that Sega ended up shipping, so here is a summary of the main models discussed to avoid further confusions:</p><ul><li><strong>Sega Mark III</strong>: The first console featuring this architecture, only released in Japan.</li><li><strong>Sega Master System</strong> (Europe and America): A rebranded Mark III with a new case, a BIOS ROM chip and a different cartridge slot.</li><li><strong>Sega Master System</strong> (Japan): An European/American Master system with the Mark III’s cartridge slot, a new FM chip and a jack port for ‘3D glasses’. However, it lacks the <code>RESET</code> button.</li></ul><p>From now one I’ll use the term ‘Master System’ or ‘SMS’ to refer to all of these, except when talking about exclusive features from a particular model.</p><hr><h2 id="cpu">CPU</h2><p>Sega decided on a fully-fledged <strong>Zilog Z80</strong> CPU running at <strong>~3.58 MHz</strong>. A popular choice by other machines like the ZX Spectrum and the Amstrad CPC. The Z80 has an instruction set compatible with the Intel 8080 but expanded with lots of more instructions.</p><p>The motherboard picture at the start of the article shows a NEC D780C-1 CPU, that’s just SEGA second-sourcing the chip to different manufacturers, other revisions even included the chip manufactured by Zilog. But for this article, it doesn’t matter who fabricated the CPU, as the internal features remain the same.</p><h4 id="memory-available">Memory available</h4><p>The Z80 has a 16-bit address bus, so the CPU can find up to 64 KB worth of memory. In the memory map you’ll find <strong>8 KB of RAM</strong> for general purpose use, this is mirrored in another 8 KB block. Finally, <strong>up to 48 KB of game ROM</strong> are mapped as well.</p><h4 id="accessing-the-rest-of-the-components">Accessing the rest of the components</h4><p>As you can read from the previous paragraph, only main RAM and some cartridge ROM is found on the address space, so how can the program access other components? Well, unlike Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/">Famicom/NES</a>, not all the hardware of the Master System is mapped using memory locations. Instead, some peripherals are found on the <strong>I/O space</strong>.</p><p>This is because the Z80 family contains an interesting feature called <strong>I/O ports</strong> which enables the CPU to communicate with other hardware without running out of memory addresses. For this, there’s a separate address space for ‘I/O devices’ called <strong>ports</strong> and both share the same data and address bus. The difference, however, is that ports are read and written using <code>IN</code> and <code>OUT</code> instructions, respectively - as opposed to the traditional load/store instruction (<code>LD</code>).</p><p>When an <code>IN</code> or <code>OUT</code> instruction is executed, the Z80 sets up the address lines pointing to the peripheral (which could be, for instance, a keyboard), flags its <code>IORQ</code> pin indicating that an I/O request has been initiated and also flags the <code>RD</code> pin or the <code>WR</code> pin whether it’s an <code>IN</code> or <code>OUT</code> instruction, respectively. The addressed peripheral must manually check for the address bus and the I/O pins and perform the required operation. In the case of an <code>IN</code> instruction, the CPU will store the received value on a pre-defined register.</p><div><a href="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png"><picture>
<img name="image_cover" alt="Image" width="944" height="315" src="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png" loading="auto"></picture></a><figcaption>SMS' Addressing layout</figcaption></div><p>The way SEGA interconnected the CPU with the rest of the components enables not only to access values, but also showing/hiding certain components from appearing in the memory map.</p><p>Curiously enough, the <a href="https://www.copetti.org/projects/consoles/game-boy/#cpu">Game Boy</a> had a Z80 ‘variant’ that completely omitted the I/O ports. Thus, it had to fit everything in the memory map.</p><h4 id="backwards-compatibility">Backwards compatibility</h4><p>The architecture of this console is very similar to its predecessor, the <strong>Sega SG-1000</strong>, so the Master System managed to gain backwards compatibility with the SG-1000. Although, this only applies to the Japanese variant since the others contain a different cartridge slot.</p><hr><h2 id="graphics">Graphics</h2><p>The drawings on the screen are produced by a proprietary chip called <strong>Video Display Processor</strong> or ‘VDP’. Internally, it has the same design of the Texas instrument TMS9918 (used in the SG-1000), but enhanced with more features which we will discuss in the following sections.</p><h4 id="organising-the-content">Organising the content</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/vdp.2930ab05e2b147c948d5134eeb66a701849c0a047bd649abd3cfd4b84d7cde21.png"><picture>
<img name="image_cover" alt="Image" width="1019" height="303" src="https://www.copetti.org/images/consoles/mastersystem/vdp.2930ab05e2b147c948d5134eeb66a701849c0a047bd649abd3cfd4b84d7cde21.png" loading="auto"></picture></a><figcaption>Memory architecture of the VDP</figcaption></div><p>Next to the VDP is connected <strong>16 KB of VRAM</strong> which only the VDP can access using a 16-bit data bus. If you look at the motherboard picture again, you’ll notice that both RAM and VRAM chips are roughly the same, except that VRAM uses the chip model ending in ‘20’ which has lower latency.</p><p>In the case of the Master System, VRAM houses everything the VDP will require for rendering (except Colour RAM). The CPU fills VRAM by writing on VDP’s registers, which will in turn forward the values to VRAM. Since the VDP is accessed using I/O ports, the CPU must use <code>IN</code> and <code>OUT</code> instructions.</p><h4 id="constructing-the-frame">Constructing the frame</h4><p>The VDP renders frames with a resolution of <strong>up to 256x192 pixels</strong>, further revision added support for 256x224 px and 256x240 px, however, to maintain compatibility with all models, developers held on to the standard resolution. This chip has the same <em>modus operandi</em> of Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/#constructing-the-frame">PPU</a>, in other words, graphics are rendered on-the-spot.</p><p>On the other side, the VDP has four different modes of operation which will alter the characteristics of the frame (colour depth and resolution):</p><ul><li><strong>Mode 0 to III</strong>: Inherited from the TMS9918 found on the SG-1000. Included for backwards compatibility, although any SMS game can use them.</li><li><strong>Mode IV</strong>: Native mode of the Master System, which enables access to all the state-of-the-art features of the VDP. For the analysis, we’ll focus on this one!</li></ul><p>Now let’s see how a frame is drawn step by step, for this, I’ll borrow <em>Sonic The Hedgehog</em>’s assets. Also, to make explanations easier, I’m going to focus on the standard memory layout that Sega suggest for organising the graphics content (just remember that the VDP is very flexible with this, so games are allowed to optimise it).</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-background-layer-link"><a href="#tab-2-2-background-layer">Background Layer</a></li><li id="tab-2-3-sprite-layer-link"><a href="#tab-2-3-sprite-layer">Sprite Layer</a></li><li id="tab-2-4-result-link"><a href="#tab-2-4-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><p>Mode IV is based on the <strong>tile system</strong>. To recall <a href="https://www.copetti.org/projects/consoles/nes/#tab-2-1-tiles">previous explanations</a> about tile engines, tiles are just <strong>8x8 pixel bitmaps</strong> which the renderer fetches to draw the game’s graphics. In the case of the VDP, the frame is composed of two planes, the background layer and the sprite layer.</p><p>Inside VRAM, there’s an area dedicated for tiles called <strong>Character generator</strong> (Sega calls ‘Characters’ to tiles) and it’s set to be <strong>14 KB long</strong>. Each tile occupies 32 bytes, so we can store up to 448 tiles.</p><p>There are 64 pixels defined on every tile, the VDP rules that each pixel must weight 4 bits, that means that up to <strong>16 colours can be chosen</strong>. Those bits reference a single entry on <strong>Colour RAM</strong> or ‘CRAM’. That area is found inside the VDP and stores the colour palettes. Colour palette systems help reduce the size of tiles in memory and allows programmers to alternate its colours without storing multiple copies.</p><p>Colour RAM stores <strong>two palettes of 16 colours each</strong>. Each entry is 6-bit wide and each 2-bit set defines one colour from the RGB model. This means that there are 64 colours available to choose from.</p></div><div id="tab-2-2-background-layer"><h4>Background Layer</h4><p>The background layer is a large plane where static tiles are drawn. To place something here, there’s another area on VRAM called <strong>Screen map</strong> that takes 1.75 KB.</p><p>This enables to build a layer of 896 tiles (32x28 tiles), but if we do the math we’ll see that this layer is larger than the display resolution of this console. The reality is, only 768 tiles (32x24 tiles) are visible, so the visible area is manually selected at the programmer’s will. Hence, by slowly alternating the X and Y coordinates of the selected area, a <strong>scrolling effect</strong> is accomplished.</p><p>Each entry of the map is 2 bytes wide (as wide as the VDP data-bus) and contains the address of the tile in the Character generator and the following attributes:</p><ul><li><strong>Horizontal and Vertical flip</strong>.</li><li>The <strong>priority bit</strong> (whether to draw some or all the tile in front of sprites).</li><li>The <strong>colour palette</strong> used.</li></ul><p>Curiously enough, there are 3 unused bits in the entry which the game can use for other purposes (i.e. extra flags to assist the game engine).</p></div><div id="tab-2-3-sprite-layer"><h4>Sprite Layer</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>Sprites are just tiles that move freely. The VDP can raster <strong>up to 64 sprites</strong> using a single tile (8x8 px) or two tiles stacked vertically (8x16 px).</p><p>The <strong>Sprite Attribute Table</strong> is a 256-byte area in VRAM that contains an array of all the sprites defined, its entries are similar to the background layer, except each sprite contain two additional values representing the X/Y coordinates.</p><p>The VDP is limited to <strong>up to eight sprites per horizontal scan-line</strong>. Also, if two sprites overlap, the last one in the list will be the one displayed.</p></div><div id="tab-2-4-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png" loading="auto"></picture></a><figcaption>Tada!</figcaption></div><p>The VDP automatically blends the two layers to form the final frame. The rendering process is done scan-line by scan-line, so the VDP doesn’t really know how the frame is going too look, that’s only seen by the user when the picture is constructed on the TV.</p><p>If you look at the example image, you may notice the frame has a vertical column at the left side. This is because the screen map is only tall enough to provide vertical scrolling without producing artefacts, <strong>but not wide enough for horizontal scrolling</strong>. So, the VDP can <strong>mask</strong> the left-most side with an 8 px column to protect the image from showing intermediate tiles.</p><p>To update the graphics for the next frame without breaking the image currently being displayed, the VDP sends two types of <strong>interrupts</strong> to the CPU. One which notifies that the CRT TV has finished beaming a chosen number of scan-lines (called <strong>horizontal interrupt</strong>) and another when the CRT finished drawing the last scan-line (called <strong>vertical interrupt</strong>) indicating the frame is finished. During those events, the CRT’s beam is re-allocating to draw the next scan-line (<strong>blanking interval</strong>), so any alteration of the VDP’s state won’t tear the image down. Horizontal blanking has a shorter time-frame than vertical blanking, yet it still allows to change, let’s say, the colour palette. This still can achieve some effects.</p></div></div></div><h4 id="secrets-and-limitation">Secrets and limitation</h4><p>At first glance, the VDP may seem like another chip with minimal functionality that we now take for …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/master-system/">https://www.copetti.org/projects/consoles/master-system/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/master-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775305</guid>
            <pubDate>Wed, 14 Oct 2020 11:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Cruip – Free landing page templates for startups]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24775182">thread link</a>) | @DavideP86
<br/>
October 14, 2020 | https://cruip.com/free-templates/ | <a href="https://web.archive.org/web/*/https://cruip.com/free-templates/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	<div id="primary">
		<div>

		<section>
			<div>
				
				<p>Beautifully designed HTML templates to help you easily build your startup landing page without hassles.</p>
                <div>
                    <ul>
                        <li>
                            <img src="https://cruip.com/wp-content/themes/cruip/dist/images/html5.svg" alt="HTML5 badge" width="50" height="50">
                        </li>                                   
                    </ul>
                </div>
            </div>
		</section>

		
			<section>

				
<div id="post-8738">
	
		<div>
			<p><img width="1400" height="1264" src="https://cruip.com/wp-content/uploads/2019/06/switch.png" alt="Switch HTML template" loading="lazy" srcset="https://cruip.com/wp-content/uploads/2019/06/switch.png 1400w, https://cruip.com/wp-content/uploads/2019/06/switch-300x271.png 300w, https://cruip.com/wp-content/uploads/2019/06/switch-768x693.png 768w, https://cruip.com/wp-content/uploads/2019/06/switch-1024x925.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></p><div>
				<div data-title="Switch">
											<p><a href="https://cruip.com/demos/switch/" target="_blank" rel="nofollow">Live demo</a>
					<a href="https://cruip.com/?download=8742" title="Download" rel="nofollow">Download</a>				</p></div>
			</div>
		</div>
		<div>
            <div>
                <h2><a href="https://cruip.com/switch/">Switch</a></h2>            <p><span>Built with</span> <span>Cruip CSS</span></p>
                    </div>
            <p>Available in <strong>HTML</strong>.</p>		</div>

	</div>

<div id="post-19713">
	
		<div>
			<p><img width="1400" height="1264" src="https://cruip.com/wp-content/uploads/2019/06/solid.png" alt="Solid HTML template" loading="lazy" srcset="https://cruip.com/wp-content/uploads/2019/06/solid.png 1400w, https://cruip.com/wp-content/uploads/2019/06/solid-300x271.png 300w, https://cruip.com/wp-content/uploads/2019/06/solid-768x693.png 768w, https://cruip.com/wp-content/uploads/2019/06/solid-1024x925.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></p><div>
				<div data-title="Solid">
											<p><a href="https://cruip.com/demos/solid/" target="_blank" rel="nofollow">Live demo</a>
					<a href="https://cruip.com/?download=19716" title="Download" rel="nofollow">Download</a>				</p></div>
			</div>
		</div>
		<div>
            <div>
                <h2><a href="https://cruip.com/solid/">Solid</a></h2>            <p><span>Built with</span> <span>Cruip CSS</span></p>
                    </div>
            <p>Available in <strong>HTML</strong>.</p>		</div>

	</div>

<div id="post-15021">
	
		<div>
			<p><img width="1400" height="1264" src="https://cruip.com/wp-content/uploads/2019/06/venus.png" alt="Venus HTML template" loading="lazy" srcset="https://cruip.com/wp-content/uploads/2019/06/venus.png 1400w, https://cruip.com/wp-content/uploads/2019/06/venus-300x271.png 300w, https://cruip.com/wp-content/uploads/2019/06/venus-768x693.png 768w, https://cruip.com/wp-content/uploads/2019/06/venus-1024x925.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></p><div>
				<div data-title="Venus">
											<p><a href="https://cruip.com/demos/venus/" target="_blank" rel="nofollow">Live demo</a>
					<a href="https://cruip.com/?download=15056" title="Download" rel="nofollow">Download</a>				</p></div>
			</div>
		</div>
		<div>
            <div>
                <h2><a href="https://cruip.com/venus/">Venus</a></h2>            <p><span>Built with</span> <span>Cruip CSS</span></p>
                    </div>
            <p>Available in <strong>HTML</strong>.</p>		</div>

	</div>

<div id="post-2924">
	
		<div>
			<p><img width="1400" height="1264" src="https://cruip.com/wp-content/uploads/2019/06/april.png" alt="April HTML template" loading="lazy" srcset="https://cruip.com/wp-content/uploads/2019/06/april.png 1400w, https://cruip.com/wp-content/uploads/2019/06/april-300x271.png 300w, https://cruip.com/wp-content/uploads/2019/06/april-768x693.png 768w, https://cruip.com/wp-content/uploads/2019/06/april-1024x925.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></p><div>
				<div data-title="April">
											<p><a href="https://cruip.com/demos/april/" target="_blank" rel="nofollow">Live demo</a>
					<a href="https://cruip.com/?download=2925" title="Download" rel="nofollow">Download</a>				</p></div>
			</div>
		</div>
		<div>
            <div>
                <h2><a href="https://cruip.com/april/">April</a></h2>            <p><span>Built with</span> <span>Cruip CSS</span></p>
                    </div>
            <p>Available in <strong>HTML</strong>.</p>		</div>

	</div>

<div id="post-4472">
	
		<div>
			<p><img width="1400" height="1264" src="https://cruip.com/wp-content/uploads/2019/06/laurel.png" alt="Laurel HTML template" loading="lazy" srcset="https://cruip.com/wp-content/uploads/2019/06/laurel.png 1400w, https://cruip.com/wp-content/uploads/2019/06/laurel-300x271.png 300w, https://cruip.com/wp-content/uploads/2019/06/laurel-768x693.png 768w, https://cruip.com/wp-content/uploads/2019/06/laurel-1024x925.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></p><div>
				<div data-title="Laurel">
											<p><a href="https://cruip.com/demos/laurel/" target="_blank" rel="nofollow">Live demo</a>
					<a href="https://cruip.com/?download=4489" title="Download" rel="nofollow">Download</a>				</p></div>
			</div>
		</div>
		<div>
            <div>
                <h2><a href="https://cruip.com/laurel/">Laurel</a></h2>            <p><span>Built with</span> <span>Cruip CSS</span></p>
                    </div>
            <p>Available in <strong>HTML</strong>.</p>		</div>

	</div>

<div id="post-49">
	
		<div>
			<p><img width="1400" height="1264" src="https://cruip.com/wp-content/uploads/2019/06/ellie.png" alt="Ellie HTML template" loading="lazy" srcset="https://cruip.com/wp-content/uploads/2019/06/ellie.png 1400w, https://cruip.com/wp-content/uploads/2019/06/ellie-300x271.png 300w, https://cruip.com/wp-content/uploads/2019/06/ellie-768x693.png 768w, https://cruip.com/wp-content/uploads/2019/06/ellie-1024x925.png 1024w" sizes="(max-width: 1400px) 100vw, 1400px"></p><div>
				<div data-title="Ellie">
											<p><a href="https://cruip.com/demos/ellie/" target="_blank" rel="nofollow">Live demo</a>
					<a href="https://cruip.com/?download=23" title="Download" rel="nofollow">Download</a>				</p></div>
			</div>
		</div>
		<div>
            <div>
                <h2><a href="https://cruip.com/ellie/">Ellie</a></h2>            <p><span>Built with</span> <span>Cruip CSS</span></p>
                    </div>
            <p>Available in <strong>HTML</strong>.</p>		</div>

	</div>

			</section>

			


		</div>
	</div><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://cruip.com/free-templates/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775182</guid>
            <pubDate>Wed, 14 Oct 2020 10:51:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[List of Side Projects]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24775020">thread link</a>) | @hanspagel
<br/>
October 14, 2020 | https://blog.ueber.io/post/list-of-side-projects/ | <a href="https://web.archive.org/web/*/https://blog.ueber.io/post/list-of-side-projects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>It’s been a year since we started to build side projects regularly. We planned to launch ten projects in 12 months. Let’s look at what we’ve got now. All projects are in chronological order.</p>
<h3 id="1-alldocs">#1 <a href="https://alldocs.app/" target="_blank" rel="nofollow noopener noreferrer">Alldocs</a></h3>
<p>We’ve never talked about that one, but it has been our first project. Alldocs is an online text converter that takes any text file and converts it to any text format.</p>
<p>Sure, there are many online converters already, but they all look like they want to steal my data. We wanted to make something looking more professional. We’re still working on it from time to time and hope to improve the search engine ranking. Currently, it has 1.500 page views/month, and the number grows slowly.</p>
<p>By the way, the code is public: <a href="https://github.com/ueberdosis/alldocs.app" target="_blank" rel="nofollow noopener noreferrer">github.com/ueberdosis/alldocs.app</a></p>
<h3 id="2-mouseless">#2 <a href="https://mouseless.app/" target="_blank" rel="nofollow noopener noreferrer">Mouseless</a></h3>
<p>Mouseless is a beautiful app to learn and look up keyboard shortcuts on your Mac, and it is our most significant success in many regards.</p>
<p>It has been sold more than 1,600 times and has more than $30,000 in revenue. It’s also part of the fantastic SetApp catalog.</p>
<p>We’re still maintaining it and publish an update from time to time.</p>
<p>And even this one is open source: <a href="https://github.com/ueberdosis/mouseless" target="_blank" rel="nofollow noopener noreferrer">github.com/ueberdosis/mouseless</a></p>
<h3 id="3-floatie">#3 <a href="https://floatie.app/" target="_blank" rel="nofollow noopener noreferrer">Floatie</a></h3>
<p>With Floatie, we’ve built a platform to publish metrics for our projects, including page views, tracked time, sales, revenue, and many more.</p>
<p>Around 20k people looked up our numbers, but only about 100 others showed interest in publishing their numbers on our platform. The project is on hold now.</p>
<h3 id="4-untitled-blogging-platform-killed">#4 Untitled Blogging Platform (killed)</h3>
<p>Yeah, that was a stupid one. We started to build our blogging platform and had a few ideas to grow it but were too afraid to try it. There are just too many blogging platforms out there. We’ve renamed and moved it to different domains a few times, and here is one fun fact: The blog you’re reading doesn’t use the platform, but its design.</p>
<h3 id="5-glyphfinder">#5 <a href="https://glyphfinder.com/" target="_blank" rel="nofollow noopener noreferrer">Glyphfinder</a></h3>
<p>After the success of Mouseless, we felt confident to try another macOS app and even wanted to bring it to Windows this time.</p>
<p>Long story short, less than 5 % of purchases were Windows users, but the development, testing, publishing, and support for the app was a tremendous time killer. We will probably never develop a Windows app again.</p>
<p>We still maintain the macOS version, release an update now and then, and love to use it ourselves.</p>
<p>Dig through the source code here: <a href="https://github.com/ueberdosis/glyphfinder" target="_blank" rel="nofollow noopener noreferrer">github.com/ueberdosis/glyphfinder</a></p>
<h3 id="6-fokus-paused">#6 Fokus (paused)</h3>
<p>We answered hundreds of support emails for our products and thought about building a lean support platform. We had a few ideas for it, designed the interface, and then stopped.</p>
<p>It’s a lot of development work, with many competitors, and we aren’t confident that our ideas are unique enough.</p>
<p>So that one is still on hold. I like the name, though. Maybe, we’ll start to work on it again someday, perhaps not.</p>
<h3 id="7-frontend-news-killed">#7 Frontend News (killed)</h3>
<p>After feeling stuck for a while, I’ve built Frontend News, which aggregated news from hundreds of blogs. I tried to make that very open but received only a little feedback, so I decided to kill it after a few days.</p>
<p>Also, that experiment showed me that I don’t want to work too public. It feels stressful to write about every tiny step and is demotivating when there’s not enough feedback. I prefer to work on something until I’m (mostly) happy and share it then.</p>
<h3 id="8-mattermd-paused">#8 <a href="https://matter.md/" target="_blank" rel="nofollow noopener noreferrer">matter.md</a> (paused)</h3>
<p>This project had a few names and took a few directions already. It started as an online text editor. Then we merged it with the untitled blogging platform, made it a macOS app, and tried to move it to the web again. None of that really worked, so <a href="https://blog.ueber.io/post/stopping-a-project/">we paused it in the end</a>.</p>
<h3 id="9-tiptap">#9 <a href="https://github.com/ueberdosis/tiptap" target="_blank" rel="nofollow noopener noreferrer">tiptap</a></h3>
<p>tiptap is a text editor we built a while ago, and <a href="https://blog.ueber.io/post/our-plan-for-tiptap-2/">we have big plans for version 2</a>.</p>
<p>We have no idea how to make money with it, but with millions of downloads, it’s the most successful project we’ve ever built. We enjoy working on it, so we follow that and see what it’ll bring us later.</p>
<h3 id="10-skara">#10 <a href="https://skara.io/" target="_blank" rel="nofollow noopener noreferrer">Skara</a></h3>
<p>Skara is a slick knowledge base for teams. It’s still in private beta and we will keep it like that for a while, but plan to invite new users on a regular basis soon.</p>
<p>This one is a little different though. We already started Skara a few years back, but as an endeavour separated from überdosis. It felt wrong, so it became officially a part of überdosis just a few weeks ago.</p>
<p>Oh, and there is also #11, but we’re not ready to talk about that one. :​-​) We learned a lot on our way, but I’ll keep that for a different post. If you have any questions about that, <a href="https://twitter.com/hanspagel" target="_blank" rel="nofollow noopener noreferrer">share it on Twitter</a> and I’ll answer them in one of the next posts.</p>
</section></div>]]>
            </description>
            <link>https://blog.ueber.io/post/list-of-side-projects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775020</guid>
            <pubDate>Wed, 14 Oct 2020 10:15:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visidata 2.0]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24774947">thread link</a>) | @polm23
<br/>
October 14, 2020 | https://www.visidata.org/blog/2020/v2.0/ | <a href="https://web.archive.org/web/*/https://www.visidata.org/blog/2020/v2.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="body">
        
<p>This is a major milestone. After almost 2 years of development, version 2.0 of VisiData is finally released. It's got several major improvements, a bunch of new loaders, and tons of new features and quality of life improvements. And, most importantly, an API specification for plugins.</p>
<h2>1. Licensing Changes</h2>
<p>[tl;dr: no more MIT vdtui; GPL3 for everything]</p>
<p>Previously, there was a core vdtui single-file library that I licensed as MIT, as I thought it might be a platform for a variety of apps like VisiData. Approximately no one showed interest in that though, and it became unwieldy to maintain, so over the course of developing VisiData 2.0, the vdtui library was thoroughly dismantled. It's now just the visidata module as a whole, which I'm releasing under GPL3. The last released version of vdtui.py under MIT was 1.5.2 if anyone wants to use that.</p>
<h2>2. Plugin API</h2>
<p>[tl;dr: "2.0" has a stable documented API; expect a growing ecosystem of plugins for a wide variety of use cases.]</p>
<p>To be honest, this is what held off the 2.0 release for so long. I knew I wanted to go through every function and decide whether I wanted to include it in the 2.0 API to be supported for the rest of the 2.x lifecycle, which might be years. (We don't intend to strictly adhere to "semver", but it's still important to try to maintain backwards compatibility within a major version number.) So now, we have an API spec with over 200 functions, which will be of interest if you want to customize VisiData, or create a plugin for it, or just to know more about its internal components.</p>
<p>Take a look at the actual API, at <a href="https://visidata.org/docs/api">visidata.org/docs/api</a>. It still needs a bit more polish, but the meat and bones are there.</p>
<h2>3. Undo and Redo</h2>
<p>This is a "game changer" according to @jsvine.</p>
<p>Undo and redo, along with the new <code>guard-sheet</code> command, make it much easier to rely on VisiData for data cleaning and data entry.</p>
<p>If you upgrade to 2.0 and learn nothing else about it, your life will be better for knowing Shift+U (undo) and Shift+R (redo).</p>
<h2>4. Deferred modifications</h2>
<p>[tl;dr: if you add/edit/delete rows on a few specific sheets, the changes won't take place right away; you'll have to press z Ctrl+S]</p>
<p>Certain sheets which know how to incrementally update their source--notably, the DirSheet and SqliteSheet--<strong>defer</strong> changes made to them, requiring an explicit save/commit step with commit-sheet (z Ctrl+S).</p>
<p>These changes are colorized on the screen and can be saved as data (or not saved, in the case of deletes) with save-sheet (Ctrl+S), even if they haven't been committed back to the original source with commit-sheet.</p>
<p>This means vd can work quite naturally as an interactive file manager, or as a sqlite database editor. I've been using it to manage my mp3 collection and my personal contacts database, which was a tsv file until I wanted to add a multiline "notes" field, so I saved it as a .json file and used that for a few months, and now I've been using it in an sqlite database. Of course they all look the same in VisiData so I can go back and forth without any friction.</p>
<h2>5. Split Window</h2>
<p>Press Shift+Z to split the terminal window into a top panel and bottom panel.</p>
<p>One panel contains the current/top sheet, the other panel contains the sheet "under" the top sheet. Press Tab or Ctrl+^ to go between them.</p>
<p>The fancy chooser (now the default for choosing aggregators or jointypes) uses this split window, and I have many other ideas for it as well.</p>
<p>It may not seem like much now, but I predict that this becomes a sleeper hit.</p>
<p>[previously blogged at: <a href="https://visidata.org/blog/2020/splitwin">visidata.org/blog/2020/splitwin</a>)]</p>
<h2>6. So many other features</h2>
<p>Here's curated list of highlights, the ones that seemed like people would be interested to know about:</p>
<ul>
<li>more visibility for long values, with "v" to toggle multi-line rows and and z+hjkl to adjust cell offset</li>
<li>[iota] the "i" family of commands to add an increment column</li>
<li>[unfurl] zM, which does row-wise expansion of iterables in a column (very useful with nested data)</li>
<li>[join] add "merge" jointype</li>
<li>[numeric binning] ranged binning for numeric columns</li>
<li>[cli] custom options parsing allows for per-sheet options</li>
<li>[cli] pipe and redirect to stdout; use as an interactive chooser</li>
<li>[input] Ctrl+Y paste from cell clipboard and other improvements</li>
<li>Alt+ as new keyboard layer for user keybindings</li>
</ul>
<p>And, as with every release, there are a bunch of new loaders, including MIME, recutils, vcard, imap, mysql, pdf, npy/npz, and more! See the new <a href="https://visidata.org/formats">/formats</a> page for a full list of supported formats, in tidy tabular form.</p>
<p>Then if you still haven't seen enough, you can see the <a href="https://github.com/saulpw/visidata/blob/stable/CHANGELOG.md#v2.0">CHANGELOG</a> for the complete list of bugfixes and changes.</p>
<p>Okay, that about wraps it up for this release. If anything I've written about here sounds interesting and you'd like me to cover it first, or more in-depth, let me know! Send me <a href="https://www.visidata.org/blog/2020/v2.0/vd@saul.pw">an email</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/twitter.com/VisiData">tweet @VisiData</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/github.com/saulpw/visidata/issues">open a github issue</a>, or chat with us on Freenode #visidata; however you want to get in touch, we'd love to hear from you.</p>

     </section></div>]]>
            </description>
            <link>https://www.visidata.org/blog/2020/v2.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24774947</guid>
            <pubDate>Wed, 14 Oct 2020 10:02:37 GMT</pubDate>
        </item>
    </channel>
</rss>
