<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 20 Sep 2020 04:24:19 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 20 Sep 2020 04:24:19 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Don't hate the book because you don't use it]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514953">thread link</a>) | @aseure
<br/>
September 18, 2020 | https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/ | <a href="https://web.archive.org/web/*/https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
<h3>
  18 September 2020
</h3>


  <p>In a few months, I‚Äôll celebrate my fifth year as a professional - understand paid - software engineer. I find this role to be a right balance of technical skills, human relationships and it fulfils my curiosity. As time goes by, I‚Äôm also starting to be disappointed by some of its negative aspects. While it doesn‚Äôt prevent me from sleeping, I think an effort could be made to challenge some lousy and short-sighted comments we see daily on social platforms.</p>
<p>Today, I‚Äôd like to talk about <a href="https://www.amazon.com/Design-Patterns-Object-Oriented-Addison-Wesley-Professional-ebook/dp/B000SEIBB8">Design Patterns: Elements of Reusable Object-Oriented Software</a>, a book written by Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides, famously known as the <em>Gang of Four</em>. If you never read it: this is a fundamental programming book describing programming abstractions published in 1994. The date is essential here, but we‚Äôll come to that later.</p>
<p>This book has recently been discussed by many, due to <a href="https://twitter.com/unclebobmartin/status/1306581616983183361">a recent tweet from Robert. C. Martin aka Uncle Bob</a>. Long story short, telling a massive audience that book X is great, and treating people who consider it outdated as ‚Äúfoolish‚Äù does not end well.</p>
<p>While I disagree with the tone here, I‚Äôd like to focus on the negative comments which followed, including but not limited to:</p>
<ul>
<li>the book is outdated</li>
<li>its concepts are outdated</li>
<li>its authors said it‚Äôs outdated</li>
<li>the book is only focused on mid-90s C++ developers</li>
<li>no one ever used the ‚Äúflyweight‚Äù design pattern</li>
<li>the book is not even readable</li>
<li>its abstractions make code unreadable</li>
</ul>
<p>First of all, let‚Äôs get back to 1994. I was two at the time. All Internet websites could probably fit on a floppy disk, Jeff Bezos founded Amazon, Rasmus Lerdorf was only starting to work on its <em>Personal Home Page/Forms Interpreter</em> CGI C program, and Larry Page and Sergey Brin would only start their research project for a web search engine two years later. The biggest technology companies were IBM, Hewlett-Packard, Motorola and Xerox, which mostly sat behind the oil, car, and food industries. Programming existed, but it wasn‚Äôt the same field as we know it today. Tech companies were a few, and I assume a lot of programmers were working in other industries. Being a professional in this sector was arguably more difficult then, and knowledge was not as easily accessible as it is today. This book was published in a world where programming started to spread in many industries. It surely was a very good resource, to try to apply its concepts, and see what works and what doesn‚Äôt. The authors were literally inventing the field at the time: Erich Gamma, for instance, teamed up with Kent Beck to create the Java JUnit test framework just a few years later, which hugely helped to popularise testing.</p>
<p>My point is: let‚Äôs remind ourselves we stand on the shoulders of many people who tried and experimented a lot at the time. We too often take for granted the knowledge and productivity we have today. On top of that, let‚Äôs not be disrespectful towards the previous generation. My father and my grandfather both work(ed) as electricians: never did my father complain about his father‚Äôs tools or habits before him. He learned them and perfected them with modern knowledge.</p>
<p>Now about the book in itself. While I agree with people saying that some design patterns are too abstract, I strongly disagree with the ones saying the whole book is outdated. Should you develop in a OO language today, such as Java, C++, Python or Ruby, or even more notably, develop a framework or a tool <em>for</em> developers, I think this book is still highly relevant today.</p>
<p>Here are my top picks from the book and why I chose them.</p>
<p><strong>Builder:</strong> because in OOP, objects often hold too much data in them, you need to control how to instantiate them properly. Even with overloaded constructors, data validation at instantiation can become messy. Do you like your testing framework using a <em>fluent interface</em> with method chaining (<code>assert(...).not().equalTo(...)</code>)? Guess what, it‚Äôs directly inspired by the builder design pattern.</p>
<p><strong>Prototype:</strong> I often hear people complaining about how complicated JavaScript is. While I don‚Äôt think this language makes it easy for the developer to write non error-prone code, I better understood the language via the lens of its prototype-based nature, precisely described by the prototype design pattern.</p>
<p><strong>Most of the structural patterns:</strong> While everyone is focused on the bad parts of OOP, namely inheritance, all those design patterns are focused on composability. If you want to be cool nowadays, you could say you prefer ‚Äúcomposition over inheritance‚Äù. Well, if you think composition is only about embedding objects in each other, you should read the part of structural design patterns. For instance, you probably know decorators from Python or annotations in Java/C#, they derive from the decorator design pattern.</p>
<p><strong>Chain of Responsibility:</strong> I think we can all agree on how great it is to use and implement a middleware in our modern web framework. Just use or write functions which take a <em>next</em> handler, a request object. Pass it to your web framework instance via a <code>.use(...)</code> method and you‚Äôre done. This is what the Chain of Responsibility pattern is all about. All Rails, Django, and Laravel developers knew that was NIH.</p>
<p><strong>Iterator:</strong> This one seems obvious now, perhaps not so much at a time where iterating on arrays with pointer arithmetic was common. Today, iterators are even buried behind standard libraries to implement even higher abstract functionalities, but they are still there. I don‚Äôt see a more universal way to implement, with the same public API, a traversal of an array, a tree, or a graph (they are better ways of iterating those last data structures though).</p>
<p><strong>Observer:</strong> For this last one, here is the verbatim definition from the book: ‚ÄúDefine a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically‚Äù. Now, if we take a look at some modern technologies, doesn‚Äôt this resonate with PubSub models or React hooks for instance?</p>
<p>To conclude, I‚Äôm not saying the book is not old, quite the opposite: you can feel it when it takes as examples from 90s user interfaces. I‚Äôm merely advocating that our industry and its workers have changed a lot in the last 30 years, dare I say even more than in any other industry. But this should not be an excuse to sweep away years of meticulous R&amp;D and documentation, on which our modern tools still rely on nowadays, and the people behind it.</p>
<p>Because a lot of people complained that they were never able to finish the book, here is an extract from the end, section ‚ÄúWhat to Expect from Design Patterns‚Äù, page 351:</p>
<blockquote>
<p>It‚Äôs possible to argue that this book hasn‚Äôt accomplished much. After all, it doesn‚Äôt present any algorithms or programming techniques that haven‚Äôt been used before. [‚Ä¶] it just documents existing designs. You could conclude that it makes a reasonable tutorial, perhaps, but it certainly can‚Äôt offer much to an experienced object-oriented designer.</p>
<p>We hope you think differently. Cataloging design patterns is important. It gives us standard names and definitions for the techniques we use. If we don‚Äôt study design patterns in software, we won‚Äôt be able to improve them, and it‚Äôll be harder to come up with new ones.</p>
<p>This book is only a start.</p>
</blockquote>

</div></div>]]>
            </description>
            <link>https://aseure.fr/articles/2020-09-18-dont-hate-the-book-because-you-dont-use-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514953</guid>
            <pubDate>Fri, 18 Sep 2020 10:14:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security Headlines: cURL special with Daniel Stenberg [audio]]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24514932">thread link</a>) | @devrustr
<br/>
September 18, 2020 | https://blog.firosolutions.com/2020/09/security-headlines-curl-special/ | <a href="https://web.archive.org/web/*/https://blog.firosolutions.com/2020/09/security-headlines-curl-special/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  





<p><img alt="curl security headlines podcast" src="https://blog.firosolutions.com/shcurl.png"></p><h3 id="summary">Summary:</h3>

<p>In this episode of Security Headlines, we jump into curl with<br>
its founder and maintainer Daniel Stenberg.<br>
We talk security, CI systems, creation of curl, Fuzzing, IRC bots<br>
and a lot more!</p>

<p>Relax, Tune in and enjoy this episode of Security Headlines:</p>







<p><a href="https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g">https://anchor.fm/firo-solutions/episodes/Curl-special-with-Daniel-Stenberg-ejqn0g</a></p>

<p>Few software developers never even get near to having one<br>
of their projects being picked up by a larger community.</p>

<p>A project that started as a currency plugin to an IRC bot.<br>
Spun off and ended up becoming bigger and bigger resulting in being
adopted by over 10 billion devices.  Well, this project is called<br>
curl!  Curl is known to be the stable swizz army knife that can<br>
be used for making various types of transfer requests.</p>

<p>Need to download a file? Curl is here for you<br>
Need to test a socks5 proxy? Curl is here for you<br>
Need to download an ezine over Gopher? Curl is here for you<br>
Need to test a unix socket? Curl is here for you</p>

<p>In this episode of Security Headlines, we are joined by Daniel<br>
Stenberg who is the founder and maintainer of Curl.<br>
He has even been awarded a gold medal by the Swedish king for<br>
his work with Curl.</p>



<p><img alt="curl Daniel stenberg King medal" src="https://blog.firosolutions.com/daniel-king.jpg"></p><p>The curl codebase is around 100 000 lines of C code, filled with<br>
hidden gems such as a libcurl code generator that creates a template<br>
based on the command line arguments you give it.</p>

<p>One of curl‚Äôs many features is the ‚Äìlibcurl option which<br>
takes the commmand you give curl and generate a C program that use<br>
libcurl with the same functionally, you can even port it to other<br>
programming languages with a similar syntax and use it with libcurl‚Äôs<br>
bindings.</p>

<pre><code>$ curl https://blog.firosolutions.com --libcurl example.c   
$ head example.c 
/********* Sample code generated by the curl command line tool **********
 * All curl_easy_setopt() options are documented at:
 * https://curl.haxx.se/libcurl/c/curl_easy_setopt.html
 ************************************************************************/
#include &lt;curl/curl.h&gt;

int main(int argc, char *argv[])
{
  CURLcode ret;
  CURL *hnd;

</code></pre>

<p>Even Google love Curl, having curl in over 100 devices.<br>
This leads us to Google‚Äôs fuzzing project, where they have<br>
an army of computers that feed automated generated data in order<br>
to find bugs.<br>
This has resulted in curl being more stable, secure, and mature.</p>

<p>The world is always moving and so is the technology evolution.<br>
Getting a bit dystopian here, but maybe we will move to a future<br>
where we are running everything in a browser.<br>
A world where everything runs ipv6 and http3.</p>

<p>In that world, I know one tool we can count on.</p>

<h3 id="external-links">External links:</h3>

<p><a href="https://curl.haxx.se/">https://curl.haxx.se/</a><br>
<a href="https://curl.haxx.se/docs/security.html">https://curl.haxx.se/docs/security.html</a><br>
<a href="https://en.wikipedia.org/wiki/CURL">https://en.wikipedia.org/wiki/CURL</a><br>
<a href="https://twitter.com/bagder">https://twitter.com/bagder</a><br>
<a href="https://www.wolfssl.com/">https://www.wolfssl.com/</a><br>
<a href="https://daniel.haxx.se/">https://daniel.haxx.se/</a><br>
<a href="https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl">https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:curl</a><br>
<a href="https://en.wikipedia.org/wiki/Gopher_%28protocol%29">https://en.wikipedia.org/wiki/Gopher_%28protocol%29</a><br>
<a href="https://curl.haxx.se/mail/">https://curl.haxx.se/mail/</a></p>

</div></div>]]>
            </description>
            <link>https://blog.firosolutions.com/2020/09/security-headlines-curl-special/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514932</guid>
            <pubDate>Fri, 18 Sep 2020 10:10:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardware Design of a 8088 based Chinese Typewriter made in the 1980s]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24514269">thread link</a>) | @tifan
<br/>
September 18, 2020 | https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/ | <a href="https://web.archive.org/web/*/https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <header id="banner">
      
    </header><!-- /#banner -->
    <!-- /#menu -->
<section id="content">
  <header>
    <h2>
      Stone MS-240x Typewriter (2): Hardware Design
    </h2> 
    
  </header>
  <!-- /.post-info -->
  <div>
    <p>In case you misseed it -- I talked about the backgrounds of the MS-240x typewriter in the <a href="https://tifan.net/blog/2020/09/09/revealing-a-forgotten-chinese-compute-history-stone-ms240x-chinese-typewritter-1-background/">previous article</a>. In this article, I'm going to discuss the hardware design of the legendary Stone MS-240x Chinese Typewriter (ÂõõÈÄö MS-240x ‰∏≠Ëã±ÊñáÊâìÂ≠óÊú∫) designed and sold in the mid-1980s.</p>
<p>Both the hardware and the BIOS was designed by ALPS Electric Co. ALPS provided a BIOS reference manual before the development began so that the developers in China could just write an emulator on the PC emulating the ALPS BIOS, and just focus on the development of the word processor.</p>
<div id="the-hardware">
<h2>The Hardware</h2>
<p><img alt="Stone MS-2401H ÂõõÈÄö MS-2401H ÊâìÂ≠óÊú∫" src="https://tifan.net/images/20200917-ms-2401h.jpg"></p><p>(<a href="https://www.lty.me/stone-ms-2401h/">Picture taken by @lty1993</a>)</p>
<p>As I mentioned in the previous article, the hardware is just a 8088 machine in its core. In the 80s, the Japanese engineer reverse engineered and implemented Japanese counterparts of almost all popular chips in the west. The ALPS motherboard is not an exception to that.</p>
<p>I bought the machine on Xianyu (Chinese eBay equivalent) and shipped it to @lty1993 in China for examination, disassembly, and ROM dumps. The machine is quite heavy -- shipping it to the west coast would probably cost 200 USD. Guess there won't be any Stone Chinese Typewriters in the US for a while!</p>
</div>
<div id="processor-nec-v20">
<h2>Processor: NEC V20</h2>
<p>Instead of using the actual 8088 processor, MS-240x series used the NEC V20 running at different clock frequencies. The original MS-2400 clocks at 4.9125 MHz, the upgraded MS-2401 runs at 8 MHz, and the later MS-2401H model runs at 10 MHz.</p>
<p>The V20 is 30% faster than the original 8088 running at the same clock speed, providing additional power for the heavy lifting work a Chinese Typewriters needs to do.</p>
</div>
<div id="memory-hard-wired-memory-map-with-page-control">
<h2>Memory: Hard-wired Memory Map with Page Control</h2>
<p>The RAM itself is not interesting at all. It's just a bunch of Japanese made SRAM connected to the address bus of the processor.</p>
<p>The BIOS is mapped at <cite>0xF8000</cite> to <cite>0xFFFF</cite>, and CPU will execute the instruction at <cite>0xFFFF0</cite> -- that's the convention for 8088. So naturally, the BIOS was hard wired at that address.</p>
<p>Remember we talked about the Chinese fonts? It's a mask ROM, and it is quite large -- larger than the address space of 8088 processor if we include high precision Chinese fonts at 24x24 dot (which is still pretty awful in today's standard). To solve this problem, all external ROMs were divided into 32KB pages. To access any page in the ROM, you would send a command to the ASIC to select the page first (bank switching) before reading memory from the hard wired memory location. Sounds like a MMU? Well, this <em>is</em> a poor man's MMU.</p>
<p>One thing worth noting is that all models have built in battery backup units. Newer models (such as MS-2401) can even operate with battery with up to 3 hours battery life -- it almost makes the typewritter a laptop with a built-in printer.</p>
<p>Here's the memory map for various models of the Chinese typewriter.</p>
<p><img alt="Memory Map for MS-2400" src="https://tifan.net/images/20200917-ms-2400-memory-map.png"></p><p>MS-2400 have the Chinese font mapped at <cite>0xA0000</cite> with 16 pages in total. It can support up to 3 Chinese IMEs (input methods, such as Pinyin, Wubi or Cangjie) -- a standard IME comes with the machine, up to 2 additional IMEs can be purchased as a EPROM chip inserted in the expansion ROM socket. As there's only 1 IME socket, regardless of how many IMEs would you purchase, you'll always get just one 64KB EPROM. The keyboards are mapped at <cite>0x90000</cite> and have up to 3 pages in total.</p>
<p>When the machine was designed, there's also an expansion socket at <cite>0xE8000</cite>. However, the expansion socket was never used.</p>
<p>As the only display device is a 240x64 LCD, the VRAM is just 2KB in size mapped at <cite>0x80000</cite>.</p>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-memory-map.png"></p><p>MS-2401 is significantly more capable with a bigger LCD display, larger RAM, and larger Chinese font ROM. To conserve mask ROM space, all font data in the mask ROM was compressed.</p>
<p><img alt="Memory Map for MS-2401H" src="https://tifan.net/images/20200917-ms-2401h-memory-map.png"></p><p>You might wonder what does "V-RAM (CRT Áî®)" in MS-2401H/01C mean. MS-2401H/01C is the top of the line model in MS-2401 series featuring ability to attach an external monitor. The graphics chip is <cite>MGP TM6066A</cite>, a Hercules clone, with MDA output.</p>
</div>
<div id="system-devices">
<h2>System Devices</h2>
<p>We all know the 8088 is not a very capable machine. ALPS custom made a few ASICs to connect system devices such as printers, keyboards and LCD monitors to the system. That's also what makes it extremely hard to write an emulator -- without knowing exactly how the ASIC works, it's close to impossible to emulate all devices and peripherals. Even with the original designer's help, we still can't be quite sure what is the exact IO address for each device, let alone determining what each command would do.</p>
<p>But anyway, we do have an rough idea of what the system is doing.</p>
<div id="external-storage-device">
<h3>External Storage Device</h3>
<p>The first model, MS-2400, have an audio cassette connector running at 1200bps. Each cassette can hold around 500KB of data, or 250k Chinese characters.</p>
<p>In 1986, when 3 1/2 inch disk just came out, Mr Jizhi Wang chose to use the very new technology in MS-2401. This is a killer function at that time, because digital documents could be finally archived relatively cheaply. Of course you could always use a computer, but that's a big upfront investment.</p>
</div>
<div id="keyboard">
<h3>Keyboard</h3>
<p><img alt="Memory Map for MS-2401" src="https://tifan.net/images/20200917-ms-2401-keyboard.jpg"></p><p>It's not a ANSI keyboard. The design seems to be inspired by JIS keyboard, and was fully translated into Chinese -- you can't even find "Ctrl" on the keyboard, instead, you'll see "ÊéßÂà∂" (lit. control). This flattens learning curve for the typewriter, as it doesn't feel foreign to the users. Just like we say "it's all Chinese to me" -- the Chinese users would say "it's all English to me" -- because it really is!</p>
<p>One interesting fact to point out is instead of commonly seem Esc, Tab, Caps Lock, Shift, Ctrl arrangement on the left, the keyboard is actually Âçä/ÂÖ® (half width / full width), Tab, Ctrl, Shift, Â∏∏Áî®Â≠ó (frequently used characters). Of course, it's a Chinese typewriter, Caps Lock isn't that important after all.</p>
</div>
<div id="printer">
<h3>Printer</h3>
<p>It sees that the printer only accepts low level commands -- or shall we say, the printer itself does not have a controller. According to the reference manual, the printer head and motor are directly controlled by the ASIC. It also needs a few dedicated timers.</p>
</div>
<div id="asic-and-fdd-controller">
<h3>ASIC and FDD Controller</h3>
<p>In MS-2401H, there are 2 ASICs, each of them contains around 8000 gates. the model is uPD91260GD-5BD and uPD91261GD-5BB.</p>
<p>The floppy controller for MS-2401 MS-2401H is UPD72067GC.</p>
</div>
</div>
<div id="conclusion">
<h2>Conclusion</h2>
<p>The MS series machines are classical examples of pushing the hardware to its limits. Most people would simply say it's impossible to use a 8088-equivalent to drive a Chinese typewriter, but the engineers did it. By abusing the system and designing chips around the 8088, they were even able to map memory larger than the actual address space of the machine! Hats off to the hardworking engineers both in Stone Company and ALPS Electric.</p>
<p>Another thing to point out is Stone Company wrote fabulous documentations. It's really pleasing to read, contains a lot of technical details, and in some occasions, it teaches you electrical engineering! It even contained the layout of the diagnostics program so that you can just disassemble them and add new functionalities should you need them.</p>
<p><img alt="manga illustration in technical document" src="https://tifan.net/images/20200917-stone-documentation-manga.png"></p><p>Plus, the manga illustration is pretty cute. Haven't seen them for a long long time.</p>
</div>


  </div><!-- /.entry-content -->
  

</section>
    <!-- /#contentinfo -->
    
    
  </div></div>]]>
            </description>
            <link>https://tifan.net/blog/2020/09/17/ms240x-chinese-typewriter-2-ms-2401h-hardware-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514269</guid>
            <pubDate>Fri, 18 Sep 2020 08:21:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an x86 bootloader in Rust that can launch vmlinux]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24514100">thread link</a>) | @lukastyrychtr
<br/>
September 18, 2020 | https://vmm.dev/en/rust/krabs.md | <a href="https://web.archive.org/web/*/https://vmm.dev/en/rust/krabs.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article id="contents">
<section>

<p>I've been developping an x86 bootloader in Rust that can use Linux boot protocol. In this article, I'd like to write about my motivation, features of this project, and issues. </p>
 
</section>
<section>
<h2>KRaBs - Kernel Reader and Booters</h2>
<p>KRaBs is a 4-stage chain loader for x86/x86_64 written in Rust.
<br>
 It can boot an ELF-formatted kernel placed on a FAT32 filesystem in the EFI System Partition. The ELF-formatted kernel is read from the filesystem and relocated, and then the kernel is booted. 
<br>
 It is all implemented in Rust. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/">GitHub - o8vm/krabs: An x86 bootloader written in Rust.</a> </p>
<p>It has the following features: </p>
<ol> <li> Currently, only legacy BIOS is supported.</li> <li> Both 64 bit and 32 bit system are supported.</li> <li> Both 64 bit long mode and 32 bit protected mode kernel are supported.</li> <li> GPT format partition table is supported.</li> <li> FAT32 file system support.</li> <li> The boot-time behavior can be controlled by CONFIG.TXT, which is placed on the FAT32 filesystem.</li> <li> Minimal x86/x86_64 Linux boot protocol is supported.</li> <li> kernel command line setting in CONFIG.TXT is supported.</li> <li> Some modules such as initramsfs/initrd are supported.</li> 10. The multi-boot specification is not supported. </ol> 
<p>An example of starting 64bit vmlinux with kernel command line and initrd is described in <a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/docs/linux-image-setup-64.md">this article</a>. </p>
<p>Just git clone the project and run a <code>cargo run</code> to experience after some preparation: </p>
<pre><code>
cargo run -- -we disk.img
</code></pre>
<p><a target="_blank" rel="noopener noreferrer" href="https://vmm.dev/en/rust/gogWCnI37-demo3.gif"><img src="https://vmm.dev/en/rust/gogWCnI37-demo3.gif" alt="demo3.gif"></a></p>
</section>
<section>
<h2>What motivated me to develop KRaBs?</h2>
<p>I thought that lower level programming below the OS stack could be also made more modern by using Rust. I wanted to extract the minimum essentials from the process of booting the Linux kernel and finally make up original bootloader where there is no black box for me.
<br>
 </p>
<p>In addition: </p>
<ul> <li>It's not easy for me to read the source code of an existing chain loader.</li> <li>Reading large amounts of assembly and C source code is tough for a beginner. It takes a lot of time and effort to read it. </li> <li>It is said that Rust binaries tend to be too big and not suitable for writing bootloaders, but I wondered if it is true.</li> </ul> 
<p>Based on the above, I've decided to write down the bootloader in Rust from scratch. </p>
</section>
<section>
<h2>How KRaBs Works</h2>
</section>
<section>
<h3>Linux kernel bootstrapping mechanism</h3>
<p>While it may be difficult to unravel the Linux kernel bootstrapping mechanism from the bzImage and GRUB bootloader sources, The mechanism itself is surprisingly simple.
<br>
 There are four basic things: Loading the ELF-formatted image from the file system, Relocating it according to the program headers, and initializing system and setting parameters according to The Linux/x86 Boot Protocol. That's all there is to it. </p>
<p>Specifically, the following four types of initialization are performed: </p>
<p><strong>Hardware initialization:</strong> </p><ul> <li>Setting the keyboard repeat rate.</li> <li>Disable interrupts and mask all interrupt levels.</li> <li>Setting Interrupt descriptor (IDT) and segment descriptor (GDT). As a result,</li> all selectors (CS, DS, ES, FS, GS) refer to the 4 Gbyte flat linear address space. <li>Change the address bus to 32 bits (Enable A20 line).</li> <li>Transition to protected mode.</li> <li>If the target is ELF64, set the 4G boot pagetable and transition to long mode.</li> </ul> 
<p><strong>Software initialization:</strong> </p><ul> <li>Get system memory by BIOS call.</li> </ul> 
<p><strong>Information transmission to the kernel:</strong> </p><ul> <li>KRaBs mount the FAT32 EFI System Partition and Reading the CONFIG.TXT.</li> <li>Setting <a target="_blank" rel="noopener noreferrer" href="https://www.kernel.org/doc/html/latest/x86/zero-page.html">Zero Page</a> of kernel parameters and transmit it to the OS.</li> </ul> 
<p><strong>Load items and Relocate the kernel:</strong> </p><ul> <li>Load kernel, initrd and command line according to CONFIG.TXT.</li> <li>The target is an ELF file, KRaBs do the ELF relocation.</li> </ul> 
<p>The format of CONFIG.TXT is a simple matrix-oriented text file that looks like this: </p>
<pre><code>
main.kernel sample-kernel
main.initrd sample-initrd
main.cmdlin sample command line clocksource=tsc net.ifnames=0
</code></pre>
<p>To perform the above process, KRaBs uses a program that is divided into four stages. </p>
</section>
<section>
<h3>Stages Overview</h3>
<ol> <li> stage1  </li> A 446 byte program written to the boot sector. The segment registers(CS, DS, ES, SS) are set to <code>0x07C0</code>, and the stack pointer (ESP) is initialized to <code>0xFFF0</code>. After that, stage2 is loaded to address <code>0x07C0:0x0200</code>, and jumps to address <code>0x07C0:0x0206</code>. In the latter half of stage1, there is an area for storing the sector position and length (in units of 512 bytes) of the stage2 program. <li> stage2  </li> Load stage3 and stage4, then jump to stage3. The stage3 program is loaded at address <code>0x07C0:0x6000</code>, the stage4 is loaded at address <code>0x0003_0000</code> in the extended memory area. The file is read from the disk using a 2K byte track buffer from address <code>0x07C0:0xEE00</code>, and further transferred to an appropriate address using <code>INT 15h</code> BIOS Function <code>0x87h</code>. A mechanism similar to this function is used in stage 4. When the loading of stage3 and stage4 is completed, jump to address <code>0x07C0:0x6000</code>.  <li> stage3  </li> Do hardware and software initialization which need BIOS calls. After a series of initialization, empty_zero_page information is prepared in <code>0x07C0:0x0000</code> to <code>0x07C0:0x0FFF</code>. Enable the A20 line, change the address bus to 32 bits, and shift to the protect mode. Then, jump to the Stage4. <li> stage4  </li> Mount the FAT32 EFI System Partition. Then, read and parse the CONFIG.TXT on that partition. Load ELF kernel image, initrd, and kernel command line according to CONFIG.TXT. Drop to real mode when executing I/O. Set Command line and image informations in empty_zero_page. ELF kernel image is stored to the extended memory address <code>0x100000</code> or later, and then the ELF32/ELF64 file is parsed and loaded. If the target is ELF64, set the 4G boot pagetable and transition to long mode. Finally, jump to the entry point to launch the kernel. At this time, put the physical address (<code>0x00007C00</code>) of the empty_zero_page information prepared in the low-order memory into the <code>ESI</code> or <code>RSI</code> register. <li> planktonü¶†  </li> library common to stage1 ~ stage4. </ol> 
</section>
<section>
<h3>How build KRaBs</h3>
<p>The directory structure of the KRaBs project is as follows: </p>
<pre><code>
$ cd /path/to
$ tree . -L 3
.
‚îú‚îÄ‚îÄ build.rs
‚îú‚îÄ‚îÄ Cargo.toml
‚îú‚îÄ‚îÄ rust-toolchain
‚îú‚îÄ‚îÄ src
‚îÇ   ‚îú‚îÄ‚îÄ bios
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ plankton
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_1st
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_2nd
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stage_3rd
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stage_4th
‚îÇ   ‚îú‚îÄ‚îÄ main.rs
‚îÇ   ‚îî‚îÄ‚îÄ uefi
...
</code></pre>
<p>All four stages that make up the bootloader for the legacy BIOS and a library called plankton are stored as a sub crate under a directory named <code>src/bios</code>.
<br>
 Under the <code>src/uefi</code> directory, we plan to store UEFI-compatible bootloader crates.
<br>
 All these sub-crates will be built by <code>build.rs</code> at <code>cargo build</code> time.
<br>
 </p>
<p><code>src/main.rs</code> is not the main body of the bootloader, <code>src/main.rs</code> is the CLI program that places KRaBs on the disk. This <code>main.rs</code> will write each stage of the KRaBs to the appropriate location on the disk. The <code>-w</code> option is used to write the stages to disk. </p>
<p>With this directory structure, just run <code>cargo buil</code> to build the CLI and the boot loader, and <code>cargo run -- -w disk.img</code> to burn the boot loader to disk. You can also test it with qemu by running <code>cargo run -- -e disk</code>. </p>
</section>
<section>
<h3>DISK Structure</h3>
<p>KRaBs supports disks that are partitioned in GPT format.
<br>
 The BIOS Boot Partition and the EFI System Partition are required. Place stage1 in the boot sector and stage2 ~ stage4 boot code for legacy BIOS in the BIOS Boot Partition. Place the CONFIG.TXT, Linux kernel, initrd on the FAT32 file system of the EFI System Partition. </p>
<p>Example: </p>
<pre><code>
$ gdisk -l disk.img 
...
Found valid GPT with protective MBR; using GPT.
Disk disk2.img: 204800 sectors, 100.0 MiB
Sector size (logical): 512 bytes
Disk identifier (GUID): 2A1F86BB-74EA-47C5-923A-7A3BAF83B5DF
Partition table holds up to 128 entries
Main partition table begins at sector 2 and ends at sector 33
First usable sector is 34, last usable sector is 204766
Partitions will be aligned on 2048-sector boundaries
Total free space is 2014 sectors (1007.0 KiB)

Number  Start (sector)    End (sector)  Size       Code  Name
   1            2048            4095   1024.0 KiB  EF02  BIOS boot partition
   2            4096          106495   50.0 MiB    EF00  EFI system partition
   3          106496          204766   48.0 MiB    8300  Linux filesystem
</code></pre>
</section>
<section>
<h3>Why use EFI System Partition?</h3>
<p>The reason for this is to make this project compatible with the UEFI environment in the future.
<br>
 I didn't support UEFI from the start because: </p>
<ul> <li>This bootloader was originally intended to be used on older PCs, such as the ThinkPad 600X.</li> <li>Currently, Legacy BIOS support works in a wider range system than UEFI.</li> <li>It is mainly intended to be used in the cloud environment except my PC. Legacy BIOS is the mainstream in x86 cloud environment, and there seems to be no merit to replace it with UEFI.</li> </ul> 
</section>
<section>
<h2>Is Rust good for writing a bootloader?</h2>
<p>I know there are pros and cons, but for me, Rust has been so much easier and better than writing C and assemblies. Personally, I think Rust is also pretty good for low-level programming, like bootloaders. </p>
<ol> <li> It's a great relief when the compilation is completed without problems   </li> When something goes wrong, most of the time I only need to suspect the unsafe part. This has made debugging a lot easier. I'm an amateur programmer, but thanks in part to this, I was able to complete my first prototype in a week. <li> Rust's build system is the best  </li> In Rust, you don't have to wonder which object file to link with which, like in C. <li> I can use my C experience</li> Since the chain loader is a rocket structure, we always have to code the unsafe parts in order to move to the next stage, and I thought it would be nice to be able to use the same techniques I often use in C for the unsafe parts.  <li> I think even the low-level code in no_std can be written in a modern way.</li> </ol> 
</section>
<section>
<h2>Issues</h2>
</section>
<section>
<h3>(RESOLVED) Setting Page Tables</h3>
<p>I tried to set up the page table with an alignment with a linker script or a struct attribute <a target="_blank" rel="noopener noreferrer" href="https://doc.rust-lang.org/reference/type-layout.html#representations">align</a>, but none of these things worked. It looked like the alignment settings were breaking other data structures. It's possible that I wasn't doing it right, but I didn't understand why and gave up debugging. In the end, I dealt with it by manually allocating the page table to the area where I wanted to set up. </p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/o8vm/krabs/blob/master/src/bios/stage_4th/src/svm/lm.rs#L44-L69">This code:</a> </p>
<pre><code>
fn setup_page_tables() {
    use plankton::layout::PGTABLE_START;
    use plankton::mem::MemoryRegion;
    let mut pg_table = ‚Ä¶</code></pre></section></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vmm.dev/en/rust/krabs.md">https://vmm.dev/en/rust/krabs.md</a></em></p>]]>
            </description>
            <link>https://vmm.dev/en/rust/krabs.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24514100</guid>
            <pubDate>Fri, 18 Sep 2020 07:54:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can we, as web professionals, help to make the web more energy efficient?]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 223 (<a href="https://news.ycombinator.com/item?id=24513427">thread link</a>) | @giuliomagnifico
<br/>
September 17, 2020 | https://cmhb.de/web-design-and-carbon-impact | <a href="https://web.archive.org/web/*/https://cmhb.de/web-design-and-carbon-impact">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
<section>
    <div><blockquote>
<p>How can we, as web professionals, help to make the web more energy efficient?</p>
</blockquote>
<p>From data centres to transmission networks to the devices that we hold in our hands, it is all consuming electricity, and in turn producing carbon emissions. According to recent estimates, the entire network already consumes 10% of global electricity production, with data traffic doubling roughly every two years. It‚Äôs probably something very few people think about, or are even aware of as being an issue. But the fact of the matter is that the Internet consumes a huge amount of electricity. And when it comes to web design, there is a lot that can be done to make the web far more energy efficient.</p>
<hr>
<h2>Attitudes</h2>
<p>Creating a website is a lot more accessible today, made simpler by the emergence of no-code site builders. But it might be asking a lot for your typical web user or amateur creator to be aware of the environmental impact of their site. This, however, shouldn‚Äôt really be the case for any digital professional. Naturally, web developers will be more conscious of the weight of their pages, given that they are fully immersed in the code and content management that serves what you see on a web page. But even then, many developers simply look for the quickest route to completing a project, rather than the best way to produce the quickest and most efficient site. </p>
<p>So they load a website with bulky Javascript and third-party tools to meet the visual specification of the client or designer. As long as it works, right? They probably don‚Äôt care. They‚Äôre probably happy with their site that loads quickly on their 500Mbps connection. Who cares if they‚Äôre wasting expensive data on mobile connections in other countries? ‚ÄúBut Carl, some of us don‚Äôt have the luxury of building super high-performance, lightweight, and optimised sites due to client budgets and deadlines.‚Äù Well, I think you need to work on your craft, change your attitude and your priorities, or find another profession.</p>
<p>When we talk about the energy efficiency of websites, it‚Äôs easy to assume that it‚Äôs a purely technical topic. However, efficiency can be improved before we even build a website. Design and content have a big impact on energy efficiency.</p>
<p>Therefore, some of the biggest contributors to heavy sites and large CO2 emissions, are <em>designers</em>. Large moving imagery, multiple web fonts, animation, sound, autoplaying video, and generally esoteric design is prevalent these days. We see showcase after showcase of the <em>best of the web</em>, where the only criteria is: ‚ÄúDoes it look well-designed?‚Äù Well, look under the hood. It‚Äôs pretty terrifying. And that‚Äôs not even getting into the many accessibility concerns. If only more designers would ask themselves, ‚ÄúWhen was the last time I considered page size when designing something? When was the last time I decided that page weight was more important than aesthetics?‚Äù </p>
<p>These are questions I have put to designers before, and the response quite often is, ‚ÄúI‚Äôm just experimenting with technologies and trying to improve my UI skills. What harm is there in that?‚Äù Well, <em>Site of the Day</em>, the harm is your energy usage, and the likelihood that nobody‚Äîbesides an echo chamber of fellow designers‚Äîgive a shit about your over-design. People just want to access content quickly, without distraction, without friction, and without it using a tonne of data. That‚Äôs not to say aesthetics aren‚Äôt important‚Äîthey certainly are. The visual design of a site can play a significant role in user experience, readability, and conversion, but as with most things, there is a balance to be achieved. And there is a responsibility to be shared.</p>
<hr>
<h2>Solutions</h2>
<p>Fortunately, there are a growing number of web professionals who do care about the impact sites have on the planet, and there are many solutions designers and developers alike can find to improve their sites without overly compromising their designs. Solutions that I am actively looking into to improve my own work.</p>
<p>So how can we be more energy efficient in web design? Well, the folks over at <a href="https://www.wholegraindigital.com/blog/website-energy-efficiency/">Wholegrain Digital</a> put together a comprehensive list, but here are some key considerations:</p>
<h3>Reduce Images</h3>
<p>The single largest contributors to page weight. The more images, the more data needs to be transferred and the more energy is used. A good starting point is to ask oneself:</p>
<ul>
<li>Does the image genuinely add value to the user?</li>
<li>Does it communicate useful information?</li>
<li>Could the same impact be achieved if the image was smaller?</li>
<li>Could we achieve the same effect with a vector graphic (or even CSS style) instead of a photo?</li>
</ul>
<h3>Optimise Images</h3>
<p>Some designs are focused almost entirely on imagery, in which case optimisation is vital to better performance. There are technical decisions that significantly affect the file size of images displayed on a page. These include:</p>
<ul>
<li>Load images at the correct scale instead of relying on CSS to resize them, so that you avoid loading images that are larger than the scale they will be displayed at.</li>
<li>Use image optimisation tools before you upload them to your site. I personally use <a href="https://imageoptim.com/mac">ImageOptim</a>.</li>
<li>Use the most efficient file format for each image, such as WebP instead of JPEG (although this is not supported by all browsers).</li>
<li>Use image processing tools to resize, crop, and enhance your images that are served. I use <a href="https://www.imgix.com/">imgimx</a> for this, which works well for image-heavy sites such as <a href="https://minimalissimo.com/">Minimalissimo</a>.</li>
</ul>
<h3>Reduce Video</h3>
<p>By far the most data intensive and processing intensive form of content. As with images, ask yourself if videos are really necessary. If they are, never autoplay a video. It creates a much higher load on the users CPU, resulting in vastly greater energy consumption. Plus, it‚Äôs annoying as hell. Let the user decide whether or not to play a video.</p>
<h3>Font Selection and Optimisation</h3>
<p>Web fonts can enhance the visual appeal of site designs, as well as improve readability, but they can add significant file weight to the sites on which they are used. A single font file could be as much as 250Kb, and that might only be for the standard weight. If you want bold, add another 250Kb! A couple of options worth considering:</p>
<ul>
<li>Use system fonts where possible.</li>
<li>Use fewer font variations.</li>
<li>Stick to modern web font file formats like WOFF and WOFF2.</li>
<li>Subset fonts to only include the characters needed on the site.</li>
</ul>
<h3>Write Clean Code</h3>
<p>Tidy and streamlined code is a fundamentally good thing. Keep code clean and simple, avoid duplication, and write efficient queries. The code behind the scenes should be a well oiled, lean machine. And I‚Äôll take this opportunity to share a controversial opinion: <em>all designers should learn to code.</em> At least if they want a website. No-code site builders can be very good, but if you‚Äôre not aware of the underlying code, then you‚Äôll be less aware of ways to optimise your site.</p>
<h3>Use Less Javascript</h3>
<p>JS impacts website efficiency in two ways: by adding file weight to the web page and by increasing the amount of processing required by the user‚Äôs device. The second of these is something that applies to JS much more than to other types of files. Look for ways to achieve front-end interactions, functionality, and animations using more efficient technologies like CSS, or at least use JS efficiently. A particular mention should be given here to tracking and advertising scripts that rarely offer any value to the user, but can add significant file weight. Don‚Äôt let advertising get in the way of craftsmanship.</p>
<h3>Use Server Caching</h3>
<p>Using caching technologies such as <a href="https://memcached.org/">Memcached</a> or <a href="https://varnish-cache.org/">Varnish</a> pre-generate static versions of each page so that the server overhead can be significantly reduced for most visitors. This significantly reduces server energy consumption and makes a big difference to page load times. </p>
<h3>SEO</h3>
<p>When optimising a site for search engines, we are helping people find the information they want quickly and easily. When SEO is successful, it results in people spending less time browsing the web looking for information, and visiting fewer pages that don‚Äôt meet their needs.</p>
<hr>
<p>No site is perfect, but appreciating that we have a responsibility to produce better digital design for the planet and for users is a good place to start. Web efficiency is an attitude and the result of a mindful approach to building for the web.</p>
<hr>
<h2>Useful Resources</h2>
<ul>
<li><a href="https://www.websitecarbon.com/">Website Carbon</a> (test your site‚Äôs carbon footprint)</li>
<li><a href="https://imageoptim.com/mac">ImageOptim</a> (image optimisation tool)</li>
<li><a href="https://www.imgix.com/">imgix</a> (image processing tool)</li>
<li><a href="https://developers.google.com/speed/pagespeed/insights/">Google PageSpeed Insights</a> (test your site‚Äôs performance)</li>
<li><a href="https://solar.lowtechmagazine.com/low-tech-solutions.html">Low-tech Solutions</a> (by Low-tech Magazine)</li>
</ul></div>
</section>
    </div></div>]]>
            </description>
            <link>https://cmhb.de/web-design-and-carbon-impact</link>
            <guid isPermaLink="false">hacker-news-small-sites-24513427</guid>
            <pubDate>Fri, 18 Sep 2020 06:02:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CCP announces plan to take control of China's private sector]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24511672">thread link</a>) | @apsec112
<br/>
September 17, 2020 | https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector | <a href="https://web.archive.org/web/*/https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        
        
      
        <h3>(ATF)√Ç&nbsp;Chinese President Xi Jinping and the Communist Party's Central Committee have laid out a plan for a √¢‚Ç¨Àúnew era√¢‚Ç¨‚Ñ¢ in which the party has better control over private business in China. </h3><p><a href="http://www.xinhuanet.com/fortune/2020-09/15/c_1126497384.htm">The plan</a> was detailed in a 5,000-word statement √¢‚Ç¨‚Äú and all regions and departments in the country have been told to follow the new guidelines.</p><p><span>This was the top story on Wednesday's CCTV Evening News √¢‚Ç¨‚Äú how the president had issued √¢‚Ç¨≈ìimportant instructions√¢‚Ç¨ÔøΩ.</span></p><p><span>It had a long-winded title: "Opinion on Strengthening the United Front Work of the Private Economy in the New Era".</span></p><p><span>The ultimate goal is for the party to have ideological leadership of private enterprise.</span></p><p><span>The statement seeks to improve CCP control over private enterprise and entrepreneurs through United Front Work √¢‚Ç¨≈ìto better focus the wisdom and strengthen of the private businesspeople on the goal and mission to realise the great rejuvenation of the Chinese nation.√¢‚Ç¨ÔøΩ</span></p><p><span>Xi's instructions were issued ahead of a conference today on this very topic.√Ç&nbsp;</span>The party wants to see a "united front" between private enterprise and government business.</p><h3><figure><iframe frameborder="0" scrolling="no" allow="accelerometer; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="" webkitallowfullscreen="" oallowfullscreen="" msallowfullscreen="" allowtransparency="true" src="//player.vimeo.com/video/459459469"></iframe></figure>100 ways to rein in the private sector</h3><p>Since the 18th National Congress in May, members of the party's Central Committee and Comrade Xi have proposed a series of new concepts and strategies, and adopted a series of major measures to guide and promote private economic 'united front' work. They say these moves have achieved "remarkable results". </p><p>As China√¢‚Ç¨‚Ñ¢s private economy has grown and diversified, the statement says "these measures will bring about a great rejuvenation of the Chinese nation under Xi Jinping thought".</p><p>Overall, there are more than 100 measures, including guidance on selection of personnel to implement the measures. </p><p>"We must also see that socialism with Chinese characteristics has entered a new era, [as] the scale of the private economy has continued to expand, risks and challenges have increased significantly, the values and interests of the private economy have become increasingly diverse, and the united front work of the private economy is facing new situations and tasks," the statement says.</p><p>"In order to thoroughly implement the major decisions and deployments of the Party Central Committee, to further strengthen the Party's leadership of the private economic united front work, and to better integrate the wisdom and strength of private economic personnel to the goal and task of achieving the great rejuvenation of the Chinese nation, the following opinions are hereby offered."</p><p>The primary stated significance of the measures is √¢‚Ç¨≈ìenhancement of the party√¢‚Ç¨‚Ñ¢s leadership over the private economy √¢‚Ç¨‚Äú private economic figures are to be more closely united around the party.√¢‚Ç¨ÔøΩ</p><h3>More CCP involvement in business</h3><p>This is quite a turnaround. Previously, private business was not considered very worthy for party membership or influence, but it has gradually entered the heart of the regime.</p><p>According to the new provisions, private firms will need a certain amount of CCP registered employees, which is already a long-term practise in large private firms but not smaller ones. </p><p>These cadres will make sure businesses follow the guiding ideology√Ç&nbsp;√¢‚Ç¨≈ìGuided by Xi Jinping√¢‚Ç¨‚Ñ¢s Thought on Socialism with Chinese Characteristics for a New Era.√¢‚Ç¨ÔøΩ </p><p>They will also guide private business people to enhance the latest CCP catchphrases √¢‚Ç¨‚Äú √¢‚Ç¨≈ìfour consciousnesses√¢‚Ç¨ÔøΩ, strengthen the √¢‚Ç¨≈ìfour self-confidences√¢‚Ç¨ÔøΩ, and achieve the √¢‚Ç¨≈ìtwo safeguards.√¢‚Ç¨ÔøΩ</p><p>Duties of cadres will include the duties of strengthening ideological guidance,√Ç&nbsp;guiding private economic figures to increase their awareness of self-discipline, build a strong line of ideological and moral defence, strictly regulate their own words and deeds, cultivate a healthy lifestyle, and create a good public image.√Ç&nbsp;</p><p>They will also need to continuously improve law abidance and moral standards of private citizens.√Ç&nbsp;</p><p>Communication channels will be set up between private business and the party to report back on progress and other matters.</p>
      
      
        <p>Tags:</p>
      
      </article></div>]]>
            </description>
            <link>https://www.asiatimesfinancial.com/ccp-announces-plan-to-take-control-of-chinas-private-sector</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511672</guid>
            <pubDate>Fri, 18 Sep 2020 00:33:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The End of the Arab-Israeli Conflict]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24511291">thread link</a>) | @brandonlc
<br/>
September 17, 2020 | https://ottomansandzionists.com/2020/09/17/the-end-of-the-arab-israeli-conflict/ | <a href="https://web.archive.org/web/*/https://ottomansandzionists.com/2020/09/17/the-end-of-the-arab-israeli-conflict/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

					
						<div>

							
<p>Tuesday‚Äôs ceremony on the White House lawn formalizing the normalization of relations between Israel and the United Arab Emirates, along with an agreement for Israel and Bahrain to do the same, marks the end of the Arab-Israeli conflict. The agreements do not create a new Middle East, as some have maintained, but cement that what had arrived haltingly and in fits and starts is here to stay. The Arab-Israeli conflict was already over in practice, and the Abraham Accord put a significant stamp on a process that had been underway for years. This does not lessen that it is something to be celebrated, and it should be clear to everyone without blinders on why Israelis are rightly happy. The Abraham Accord also brings with it another significant consequence, one that is perhaps unintended, in that the end of the Arab-Israeli conflict will put the focus on the Israeli-Palestinian conflict in an unavoidable way.</p>



<p>&nbsp;The Abraham Accord is a positive development for Israel, the UAE, and Bahrain, and nobody should pretend otherwise. Like nearly everything in foreign policy, it will bring some downsides along with it, but that doesn‚Äôt alter the cost-benefit analysis. It is a true Jared Kushner accomplishment, and credit should be given where credit is due. While Kushner and the Trump team‚Äôs vision for an ‚Äúultimate deal‚Äù when they took office was clearly intended to be one between Israelis and Palestinians, the decision to recognize Jerusalem as Israel‚Äôs capital without any reciprocal gesture toward the Palestinians and ‚Äì crucially ‚Äì the Palestinian reaction in the aftermath very obviously shifted their focus. Their vision ultimately became one of isolating and bypassing the Palestinians in order to craft agreements between Israel and Arab states and demonstrate to the Palestinians that they would not be able to exercise a veto over Israel‚Äôs place in the region writ large. Whether you agree with this approach or not ‚Äì and previous administrations did not ‚Äì the Trump administration succeeded in carrying it out.&nbsp;</p>



<p>&nbsp;While the way to the agreement was paved by the UAE publicly setting forth that normalization could not coexist with annexation, the text of the agreement itself demonstrates how well the Trump administration managed to divorce the Palestinian issue from the wider regional context. The agreement does not explicitly mention the Arab Peace Initiative or the 1967 lines, does not mention annexation, does not mention two states, does not mention past UN agreements, does not mention the Palestinians themselves, and the only reference to the conflict is an open-ended commitment to ‚Äúrealize a negotiated solution to‚Äù it ‚Äúthat meets the legitimate needs and aspirations of both people, and to advance comprehensive Middle East peace, stability and prosperity.‚Äù For anyone looking to demonstrate to the Palestinians just how little they matter in this new reality, you could not come up with a clearer statement of just that.</p>



<p>&nbsp;That Israel and Arab states have been moving closer together for years due to a confluence of shared interests and a desire to benefit economically, militarily, and technologically does not mean that Kushner‚Äôs success was accidental. He was able to come up with the right set of incentives for the UAE to formalize what had been informal, and was also able to make the case that any concerns about breaking the Arab Peace Initiative approach ‚Äì no normalization before an agreement with the Palestinians ‚Äì would not carry any real consequences for states willing to do so. For all of the years of talk about secret relations underneath the table, things are now out in the open, and that is indeed a big deal.</p>



<p>&nbsp;But just as it is hollow to argue that the Israel-UAE deal does not matter, it is also hollow to argue that it is the only thing that matters. In the past few weeks, there has been a strange phenomenon of simultaneously embarking on a new path while turning back the clock. In the decades after Israel‚Äôs founding, its battles for survival and struggle for acceptance were collectively known as the Arab-Israeli conflict, which accurately reflected the primary threats and challenges that Israel faced. Following repeated Israeli military victories against Egypt, Syria, Jordan, and others, and the subsequent acknowledgement of Israeli military superiority and permanence in the region, the Arab-Israeli conflict transformed into the Israeli-Palestinian conflict. That conflict remains, yet many this week want to pretend that we are back in Arab-Israeli conflict territory. Acting as if peace between Israel and Gulf states, and only peace between Israel and Gulf states, was the terminal goal all along is absurd. It does not detract from the actual accomplishment to describe it accurately and put it in the wider context, or to point out that this is an important and consequential deal but not the ultimate one that President Trump initially sought.</p>



<p>&nbsp;The fact that the Israeli-Palestinian conflict is what remains means that there will be a true return to it in a more crystallized and concentrated way. For some, that will make it even easier to ignore, because left on its own and severed from the prospect of it being the gateway to normal relations with other states, it will seem even less important and relevant. For others, it will mean even greater awareness, as it will be easier to see all of the ways in which it is different from past Israeli conflicts and how it is not going to disappear one day on its own. Whether or not one wants to minimize the Israeli-Palestinian conflict‚Äôs importance, it is far harder in the wake of the Israel-UAE accord ‚Äì one that does not explicitly recognize Israel as a Jewish state but does explicitly recognize Jews‚Äô place in the region and rebuts the charge that Israeli Jews are colonialist interlopers ‚Äì to maintain the posture that ‚Äúthey will always hate Jews and never accept Israel‚Äù and thus no deal can ever be struck. And if you argue that there is something qualitatively different about the Palestinians, it is also harder to simultaneously insist that they are not a distinct nationality and that they should be satisfied going to one of twenty two other Arab countries.</p>



<p>&nbsp;Most saliently, leaving the Arab-Israeli conflict behind while the Israeli-Palestinian conflict remains will create an ever starker contrast between a situation where Israeli actions and control do not have a direct impact on the parties across the table ‚Äì such as the Emiratis and the Bahrainis ‚Äì and the glaring situation with the Palestinians, where they do. This is also a Trump administration accomplishment, albeit an unintended one. When Arab states that were not directly impacted by Israeli actions in the West Bank would not engage with Israel, it was easy to criticize and point out the unfair standard involved and lump everyone together. With the Palestinians standing alone in every way, not only in how they relate to Israel but in how Israel relates to them, it is going to be ever clearer why and how the Israeli-Palestinian conflict is not the same as the Arab-Israeli conflict, why and how it cannot be reduced to economic or security interests, and why and how the Palestinians are not going to be overcome by U.S. inducements or the promise of access to Israeli benefits quite so easily.</p>
			
			
			
							
						</div>

					
					

				</div></div>]]>
            </description>
            <link>https://ottomansandzionists.com/2020/09/17/the-end-of-the-arab-israeli-conflict/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24511291</guid>
            <pubDate>Thu, 17 Sep 2020 23:41:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Universal flu vaccine finishes Phase 3 trial, results expected before December]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24510293">thread link</a>) | @apsec112
<br/>
September 17, 2020 | https://www.biondvax.com/2020/07/last-of-12400-participants-completes-final-visit-in-biondvaxs-m-001-universal-flu-vaccine-pivotal-phase-3-clinical-trial/ | <a href="https://web.archive.org/web/*/https://www.biondvax.com/2020/07/last-of-12400-participants-completes-final-visit-in-biondvaxs-m-001-universal-flu-vaccine-pivotal-phase-3-clinical-trial/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Jerusalem, Israel ‚Äì July 1, 2020 ‚Äì <strong>BiondVax Pharmaceuticals Ltd. (Nasdaq: BVXV)</strong> today announced that all participants in the placebo-controlled, blinded, pivotal, clinical efficacy, Phase 3 trial of BiondVax‚Äôs M‚Äë001 universal influenza vaccine candidate have now completed their site visits. In total, over 12,400 volunteers aged 50+ (with half aged 65+) were enrolled in the trial over the past two flu seasons in 83 sites across seven European countries. The purpose of the study is to assess M-001‚Äôs ability as a standalone non-adjuvanted vaccine to provide clinical protection from circulating influenza strains as measured by reduction of influenza illness rate (as a primary endpoint) and severity (as a secondary endpoint), as well as to assess M-001‚Äôs safety.</p>
<p>Seasonal influenza annually infects approximately <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5596521/">10-20% of the world‚Äôs population</a> resulting in up to about <a href="https://www.who.int/en/news-room/fact-sheets/detail/influenza-(seasonal)">five million cases of severe illness and 650,000 deaths</a>. In addition, pandemic influenza, such as the H1N1 Swine Flu pandemic of 2009, is a constant global threat. However, current influenza vaccines, which target frequently mutating parts of the flu virus and therefore must be updated annually in the hope they will match the next flu season‚Äôs circulating strains, achieve on average only about <a href="https://www.cdc.gov/flu/vaccines-work/effectiveness-studies.htm">40% vaccine effectiveness</a> in the general population and as low as <a href="https://www.cdc.gov/flu/vaccines-work/2018-2019.html">12% in older adults</a>.</p>
<p>BiondVax‚Äôs M-001 is a single recombinant protein of highly conserved influenza epitopes. Consequently:</p>
<ul>
<li>M-001 does not need to be updated and therefore can be manufactured and distributed year-round.</li>
<li>M-001 is designed to provide protection to both existing and future seasonal A and B strains, as well as emerging pandemic strains.</li>
</ul>
<p><a href="http://www.biondvax.com/about-us/management/tamar-ben-yedidia-cso/"><strong>Dr. Tamar Ben-Yedida</strong></a>, BiondVax‚Äôs Chief Scientist, commented, ‚Äú<em>We are pleased that despite the ongoing COVID-19 pandemic, and the challenge of conducting the trial across 83 sites and seven countries, thanks to all the people involved ‚Äì including the CRO, investigators, and thousands of participants ‚Äì we have maintained the planned timelines of our pivotal Phase 3 trial. In light of the ongoing COVID-19 pandemic, the need for improved influenza vaccines has arguably never been clearer. To better protect lives and economies, influenza vaccines must be more effective in reducing illness rates and severity. Needless to say, we are eagerly anticipating results of our trial by the end of this year.</em>‚Äù</p>
<p>Participants in the trial‚Äôs second cohort were enrolled prior to the 2019/20 flu season and monitored for influenza-like illness (ILI) symptoms throughout the flu season. Swabs samples were collected from those participants with ILI, and influenza confirmation is currently being conducted by a qualified laboratory. Analysis will continue in the coming months, and results are expected by the end of 2020.</p>
<p>As part of this Phase 3 study, cell-mediated immunogenicity markers of M-001 will be evaluated in a subset of participants. The recently completed clinical study report (CSR) of a U.S. National Institute of Allergy and Infectious Diseases (NIAID) supported Phase 2 clinical trial of M-001 concluded that, ‚Äú<em><a href="http://www.biondvax.com/2020/06/nih-report-on-phase-2-clinical-trial-of-biondvaxs-m-001-universal-influenza-vaccine-candidate-concludes-both-primary-endpoints-achieved/">M-001 induced significant polyfunctional T cell responses</a>.</em>‚Äù</p>
<p>In addition to the ongoing pivotal, clinical efficacy, Phase 3 trial, equipment installation and manufacturing process scale-up in BiondVax‚Äôs pilot facility in Jerusalem are in progress. The facility has planned annual capacity of up to between 10 and 20 million doses in bulk.</p>
<p><strong>About BiondVax </strong><br>
BiondVax (NASDAQ: BVXV) is a Phase 3 clinical stage biopharmaceutical company developing a universal flu vaccine. The vaccine candidate, called M-001, is designed to provide multi-strain and multi-season protection against current and future, seasonal and pandemic influenza. BiondVax‚Äôs proprietary technology utilizes a unique combination of conserved and common influenza virus peptides intended to stimulate both arms of the immune system for a cross-protecting and long-lasting effect. In a total of seven completed Phase 1/2 and Phase 2 clinical trials enrolling 818 participants, the vaccine has been shown to be safe, well-tolerated, and immunogenic. The ongoing pivotal Phase 3 clinical trial aims to assess safety and effectiveness of M-001 in reducing flu illness and severity. For more information, please visit <a href="http://www.biondvax.com/">www.biondvax.com</a>.</p>
<p><strong>Contact Details</strong><br>
Joshua E. Phillipson<strong> | </strong>+972 8 930 2529<strong> | </strong>j.phillipson@biondvax.com</p>
<p><strong>Forward Looking Statements</strong><br>
<em>This press release contains forward-looking statements within the meaning of the Private Litigation Reform Act of 1995. Words such as ‚Äúexpect,‚Äù ‚Äúbelieve,‚Äù ‚Äúintend,‚Äù ‚Äúplan,‚Äù ‚Äúcontinue,‚Äù ‚Äúmay,‚Äù ‚Äúwill,‚Äù ‚Äúanticipate,‚Äù and similar expressions are intended to identify forward-looking statements. These forward-looking statements reflect the management‚Äôs current views with respect to certain current and future events and are subject to various risks, uncertainties and assumptions that could cause the results to differ materially from those expected by the management of BiondVax Pharmaceuticals Ltd. Risks and uncertainties include, but are not limited to, risks relating to the COVID-19 (coronavirus) pandemic, including a risk of delay in the availability of the top line results from our pivotal clinical efficacy Phase 3 trial for M-001, the prosecution, timing and results of the ongoing Phase 2 and Phase 3 trials and any subsequent trials; timing of receipt of regulatory approval of our manufacturing facility in Jerusalem; ability to demonstrate the efficacy and safety of the vaccine; the timing of clinical trials and marketing approvals; the risk that drug development involves a lengthy and expensive process with uncertain outcome; the ability of the Company to maintain, preserve and defend its intellectual property and patents granted; whether our&nbsp; vaccine candidate will successfully advance through the clinical trial process on a timely basis, or at all, and receive approval from the U.S. Food and Drug Administration or equivalent foreign regulatory agencies; the adequacy of available cash resources and the ability to raise additional capital when needed. More detailed information about the risks and uncertainties affecting the Company is contained under the heading ‚ÄúRisk Factors‚Äù in our Annual Report on Form 20-F for the year ended December 31, 2019 filed with the U.S. Securities and Exchange Commission, or SEC, which is available on the SEC‚Äôs website, www.sec.gov. We undertake no obligation to revise or update any forward-looking statement for any reason.</em></p>
<p>###</p>
							</div></div>]]>
            </description>
            <link>https://www.biondvax.com/2020/07/last-of-12400-participants-completes-final-visit-in-biondvaxs-m-001-universal-flu-vaccine-pivotal-phase-3-clinical-trial/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24510293</guid>
            <pubDate>Thu, 17 Sep 2020 21:41:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Learning in Clojure with Fewer Parentheses Than Keras and Python]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24509374">thread link</a>) | @dragandj
<br/>
September 17, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-org5455e07">
<p>
How about the number of dreaded parentheses, <code>(</code> and <code>)</code>?
</p>

<table>


<colgroup>
<col>

<col>

<col>
</colgroup>
<thead>
<tr>
<th scope="col">&nbsp;</th>
<th scope="col">Python</th>
<th scope="col">Clojure</th>
</tr>
</thead>
<tbody>
<tr>
<td>( and )</td>
<td>48</td>
<td>28</td>
</tr>

<tr>
<td>(, ), [, and ]</td>
<td>50</td>
<td>48</td>
</tr>

<tr>
<td>Grouped (())</td>
<td>8</td>
<td>2</td>
</tr>

<tr>
<td>)))</td>
<td>2</td>
<td>1</td>
</tr>

<tr>
<td>,</td>
<td>17</td>
<td>0</td>
</tr>

<tr>
<td>model.add</td>
<td>8</td>
<td>0</td>
</tr>
</tbody>
</table>

<p>
As we can see from the table, on every punctuation metric that I could think
of, Deep Diamond and Clojure fare better than Keras &amp; Python.
</p>

<p>
Keras uses almost twice as much parentheses than Deep Diamond. Clojure uses <code>[]</code>
for vector literals, which Deep Diamond uses as tensor shapes. You will note that
there are more than a few of these, and argue that these are parentheses, too.
Fine. Add them up, and Clojure fares slightly better than Python!
</p>

<p>
A parenthesis here and there is not a problem, but there are horror tales of
<code>(((((((</code> and <code>)))))))</code> in Lisps. Not in Clojure. See that there is not a
single <code>((</code> in the Clojure example, and only two occurances of <code>))</code>.
In Python - there are 8.
</p>

<p>
Then we come to all additional assorted punctuation in Python: commas, dots, etc.
In Clojure, there are none, while in Python there are dozens.
</p>

<p>
Python is also riddled with redundant stuff such as <code>model.add()</code>.
</p>

<p>
Etc., etc. You get my point.
</p>
</div></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-Fewer-Parentheses-Python-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24509374</guid>
            <pubDate>Thu, 17 Sep 2020 20:11:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Algorithms discern our mood from what we write online]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24508610">thread link</a>) | @sinapticasblog
<br/>
September 17, 2020 | https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/ | <a href="https://web.archive.org/web/*/https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Researchers&nbsp;and companies are harnessing computers to identify the emotions behind our written words. While sentiment analysis is far from perfect, it manages to distill meaning from huge amounts of data ‚Äî and could one day even monitor mental health.</p>



<p>By Dana Mackenzie</p>



<p>9.14.2020</p>



<p>Many people have declared 2020 the worst year ever. While such a description may seem hopelessly subjective, according to one measure, it‚Äôs true.</p>



<p>That yardstick is the Hedonometer, a computerized way of assessing both our happiness and our despair. It runs day in and day out on computers at the University of Vermont (UVM), where it scrapes some 50 million tweets per day off Twitter and then gives a quick-and-dirty read of the public‚Äôs mood. According to the Hedonometer, 2020 has been by far the most horrible year since it began keeping track in 2008.</p>



<p>The <a rel="noreferrer noopener" href="http://hedonometer.org/timeseries/en_all/" target="_blank">Hedonometer</a> is a relatively recent incarnation of a task computer scientists have been working on for more than 50 years: using computers to assess words‚Äô emotional tone. To build the Hedonometer, UVM computer scientist Chris Danforth had to teach a machine to understand the emotions behind those tweets ‚Äî no human could possibly read them all. This process, called sentiment analysis, has made major advances in recent years and is finding more and more uses.</p>



<div><figure><img loading="lazy" data-attachment-id="2008" data-permalink="https://sinapticas.com/g-hedonometer/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png" data-orig-size="1179,600" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="g-hedonometer" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=300" data-large-file="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=672" src="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=1024" alt="" width="720" height="366" srcset="https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=1024 1024w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=720 720w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=150 150w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=300 300w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png?w=768 768w, https://sinapticas.files.wordpress.com/2020/09/g-hedonometer.png 1179w" sizes="(max-width: 720px) 100vw, 720px"><figcaption>The Hedonometer tracks the sentiments expressed in tweets, an effort underway since late 2008. This screenshot shows data from mid-August 2019 to the present and reveals a record low in early March of this year coinciding with the Covid-19 pandemic going global; that record was shattered in May after George Floyd‚Äôs killing. Portion of scale shown at right goes from 1 (extremely negative) to 9 (extremely positive). Gray at bottom shows total volume of Twitter posts.<br>CREDIT: COMPUTATIONAL STORY LAB AT THE UNIVERSITY OF VERMONT</figcaption></figure></div>



<p>In addition to taking Twitter user‚Äôs emotional temperature, researchers are employing sentiment analysis to gauge people‚Äôs perceptions of climate change and to test conventional wisdom such as, in music, whether a minor chord is sadder than a major chord (and by how much). Businesses who covet information about customers‚Äô feelings are harnessing sentiment analysis to assess reviews on platforms like Yelp. Some are using it to measure employees‚Äô moods on the internal social networks at work. The technique might also have medical applications, such as identifying depressed people in need of help.</p>



<p>Sentiment analysis is allowing researchers to examine a deluge of data that was previously time-consuming and difficult to collect, let alone study, says Danforth. ‚ÄúIn social science we tend to measure things that are easy, like gross domestic product. Happiness is an important thing that is hard to measure.‚Äù</p>



<h2>Deconstructing the ‚Äòword stew‚Äô</h2>



<p>You might think the first step in sentiment analysis would be teaching the computer to understand what humans are saying. But that‚Äôs one thing that computer scientists cannot do; understanding language is one of the most notoriously difficult problems in artificial intelligence. Yet there are abundant clues to the emotions behind a written text, which computers can recognize even without understanding the meaning of the words.</p>



<p>The earliest approach to sentiment analysis is word-counting. The idea is simple enough: Count the number of positive words and subtract the number of negative words. An even better measure can be obtained by weighting words: ‚ÄúExcellent,‚Äù for example, conveys a stronger sentiment than ‚Äúgood.‚Äù These weights are typically assigned by human experts and are part of creating the word-to-emotion dictionaries, called lexicons, that sentiment analyses often use.</p>



<p>But word-counting has inherent problems. One is that it ignores word order, treating a sentence as a sort of word stew. And word-counting can miss context-specific cues. Consider this product review: ‚ÄúI‚Äôm so happy that my iPhone is nothing like my old ugly Droid.‚Äù The sentence has three negative words (‚Äúnothing,‚Äù ‚Äúold,‚Äù ‚Äúugly‚Äù) and only one positive (‚Äúhappy‚Äù). While a human recognizes immediately that ‚Äúold‚Äù and ‚Äúugly‚Äù refer to a different phone, to the computer, it looks negative. And comparisons present additional difficulties: What does ‚Äúnothing like‚Äù mean? Does it mean the speaker is <em>not</em> comparing the iPhone with the Android? The English language can be so confusing.</p>



<p>To address such issues, computer scientists have increasingly turned to more sophisticated approaches that take humans out of the loop entirely. They are using machine learning algorithms that teach a computer program to recognize patterns, such as meaningful relationships between words. For example, the computer can learn that pairs of words such as ‚Äúbank‚Äù and ‚Äúriver‚Äù often occur together. These associations can give clues to meaning or to sentiment. If ‚Äúbank‚Äù and ‚Äúmoney‚Äù are in the same sentence, it is probably a different kind of bank.</p>



<div><figure><img data-attachment-id="2010" data-permalink="https://sinapticas.com/captura-de-pantalla-2020-09-17-a-las-15-44-31/" data-orig-file="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png" data-orig-size="577,396" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="captura-de-pantalla-2020-09-17-a-las-15.44.31" data-image-description="" data-medium-file="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=300" data-large-file="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=577" src="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=577" alt="" srcset="https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png 577w, https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=150 150w, https://sinapticas.files.wordpress.com/2020/09/captura-de-pantalla-2020-09-17-a-las-15.44.31.png?w=300 300w" sizes="(max-width: 577px) 100vw, 577px"><figcaption>A computer using a shallow neural network can easily be trained for the task of next-word prediction ‚Äî a familiar example is the suggested words featured while typing on a smartphone. Here, a neural network-trained language model calculates the probability that various words will follow ‚ÄúThou shalt.‚Äù Once the network is fully trained, it can be reverse-engineered to generate the mathematical constructs called ‚Äúword embeddings,‚Äù which link words that tend to go together. These, in turn, are used as an input to more difficult language-processing tasks, including sentiment analysis.</figcaption></figure></div>



<p>A major step in such methods came in 2013, when Tomas Mikolov of Google Brain applied machine learning to construct a tool called word embeddings. These convert each word into a list of 50 to 300 numbers, called a vector. The numbers are like a fingerprint that <a href="https://jalammar.github.io/illustrated-word2vec/" target="_blank" rel="noreferrer noopener">describes a word</a>, and particularly the other words it tends to hang out with.</p>



<p>To obtain these descriptors, Mikolov‚Äôs program looked at millions of words in newspaper articles and tried to predict the next word of text, given the previous words. Mikolov‚Äôs embeddings recognize synonyms: Words like ‚Äúmoney‚Äù and ‚Äúcash‚Äù have very similar vectors. More subtly, word embeddings capture elementary analogies ‚Äî that king is to queen as boy is to girl, for example ‚Äî even though it cannot define those words (a remarkable feat given that such analogies were part of how SAT exams assessed performance).</p>



<p>Mikolov‚Äôs word embeddings were generated by what‚Äôs called a neural network with one hidden layer. Neural networks, which are loosely modeled on the human brain, have <a href="https://www.knowablemagazine.org/article/technology/2020/why-some-artificial-intelligence-smart-until-its-dumb" target="_blank" rel="noreferrer noopener">enabled stunning advances in machine learning</a>, including AlphaGo (which learned to play the game of Go better than the world champion). Mikolov‚Äôs network was a deliberately shallower network, so it could be a useful for a variety of tasks, such as translation and topic analysis.</p>



<p><a href="https://www.knowablemagazine.org/article/technology/2020/synthetic-media-real-trouble-deepfakes" target="_blank" rel="noreferrer noopener">Deeper neural networks</a>, with more layers of ‚Äúcortex,‚Äù can extract even more information about a word‚Äôs sentiment in the context of a particular sentence or document. A common reference task is for the computer to read a movie review on the Internet Movie Database and predict whether the reviewer gave it a thumbs up or thumbs down. The earliest lexicon methods achieved about 74 percent accuracy. The most sophisticated ones got up to 87 percent. The very first neural nets, in 2011, scored 89 percent. Today they perform with upwards of 94 percent accuracy ‚Äî approaching that of a human. (Humor and sarcasm remain big stumbling blocks, because the written words may literally express the opposite of the intended sentiment.)</p>



<p><a href="https://www.knowablemagazine.org/collection/coronavirus-0" target="_blank" rel="noreferrer noopener">Explore&nbsp;<em>Knowable</em>‚Äôs coronavirus coverage</a></p>



<p>Despite the benefits of neural networks, lexicon-based methods are still popular; the Hedonometer, for instance, uses a lexicon, and Danforth has no intention to change it. While neural nets may be more accurate for some problems, they come at a cost. The training period alone is one of the most computationally intensive tasks you can ask a computer to do.</p>



<p>‚ÄúBasically, you‚Äôre limited by how much electricity you have,‚Äù says the Wharton School‚Äôs Robert Stine, who covers the <a href="https://www.annualreviews.org/doi/10.1146/annurev-statistics-030718-105242" target="_blank" rel="noreferrer noopener">evolution of sentiment analysis</a> in the 2019 <em>Annual Review of Statistics and Its Application</em>. ‚ÄúHow much electricity did Google use to train AlphaGo? The joke I heard was, enough to boil the ocean,‚Äù Stine says.</p>



<p>In addition to the electricity needs, neural nets require expensive hardware and technical expertise, and there‚Äôs a lack of transparency because the computer is figuring out how to tackle the task, rather than following a programmer‚Äôs explicit instructions. ‚ÄúIt‚Äôs easier to fix errors with a lexicon,‚Äù says Bing Liu of the University of Illinois at Chicago, one of the pioneers of sentiment analysis.</p>



<h2>Measuring mental health</h2>



<p>While sentiment analysis often falls under the purview of computer scientists, it has <a href="https://www.cs.cmu.edu/~ylataus/files/TausczikPennebaker2010.pdf" target="_blank" rel="noreferrer noopener">deep roots in psychology</a>. In 1962, Harvard psychologist Philip Stone developed the General Inquirer, the first computerized general purpose text analysis program for use in psychology; in the 1990s, social psychologist James Pennebaker developed an early program for sentiment analysis (the Linguistic Inquiry and Word Count) as a view into people‚Äôs psychological worlds. These earlier assessments revealed and confirmed patterns that experts had long-observed: Patients diagnosed with depression had distinct <a href="https://journals.sagepub.com/doi/abs/10.1177/0261927x09351676" target="_blank" rel="noreferrer noopener">writing styles</a>, such as using pronouns ‚ÄúI‚Äù and ‚Äúme‚Äù more often. They used more words with negative affect, and sometimes more death-related words.</p>



<p>Researchers are now probing mental health‚Äôs expression in speech and writing by <a rel="noreferrer noopener" href="https://www.annualreviews.org/doi/full/10.1146/annurev-biodatasci-030320-040844" target="_blank">analyzing social media posts</a>. Danforth and Harvard psychologist Andrew Reece, for example, analyzed the Twitter posts of people with formal diagnoses of depression or post-traumatic stress disorder that were written <em>prior</em> to the diagnosis (with consent of participants). <a rel="noreferrer noopener" href="https://www.nature.com/articles/s41598-017-12961-9" target="_blank">Signs of depression began to appear</a> as many as nine months earlier. And Facebook has an algorithm to detect users who seem to be at risk of suicide; human experts ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/">https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/</a></em></p>]]>
            </description>
            <link>https://sinapticas.com/2020/09/17/how-algorithms-discern-our-mood-from-what-we-write-online/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24508610</guid>
            <pubDate>Thu, 17 Sep 2020 19:03:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Marker ‚Äì open source hand-drawn illustrations]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24507433">thread link</a>) | @alokepillai
<br/>
September 17, 2020 | https://usepastel.com/marker-illustrations | <a href="https://web.archive.org/web/*/https://usepastel.com/marker-illustrations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://usepastel.com/marker-illustrations</link>
            <guid isPermaLink="false">hacker-news-small-sites-24507433</guid>
            <pubDate>Thu, 17 Sep 2020 17:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to Data Oriented Design with Rust]]>
            </title>
            <description>
<![CDATA[
Score 398 | Comments 134 (<a href="https://news.ycombinator.com/item?id=24506744">thread link</a>) | @headalgorithm
<br/>
September 17, 2020 | https://jamesmcm.github.io/blog/2020/07/25/intro-dod/ | <a href="https://web.archive.org/web/*/https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the post we will investigate the main concepts of <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented
Design</a> using Rust.</p>

<p>The source code for this example is <a href="https://github.com/jamesmcm/data-oriented-example">available on Github</a>.</p>

<!--more-->

<h2 id="what-is-data-oriented-design">What is data-oriented design?</h2>

<p>Data-oriented design is an approach to optimising programs by carefully
considering the memory layout of data structures, and their implications
for auto-vectorisation and use of the CPU cache. I highly recommend
watching Mike Acton‚Äôs <a href="https://www.youtube.com/watch?v=rX0ItVEVjHc">‚ÄúData-Oriented Design and C++‚Äù</a> talk
if you haven‚Äôt seen it already.</p>

<p>In this post we will cover 4 cases, using <a href="https://docs.rs/criterion/0.3.3/criterion/">criterion</a> for
benchmarking. The cases are:</p>

<ul>
  <li>Struct of arrays vs. array of structs</li>
  <li>The cost of branching inside a hot loop</li>
  <li>Linked List vs. Vector iteration</li>
  <li>The cost of dynamic dispatch vs. monomorphisation</li>
</ul>

<h2 id="struct-of-arrays-vs-array-of-structs">Struct of Arrays vs. Array of Structs</h2>

<p>The <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">Struct of Arrays vs. Array of Structs</a> 
refers to two contrasting ways of organising entity data to be operated
over.</p>

<p>For example, imagine we are writing a video game and we would like to
have a Player struct with the following fields:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>Player</span> <span>{</span>
    <span>name</span><span>:</span> <span>String</span><span>,</span>
    <span>health</span><span>:</span> <span>f64</span><span>,</span>
    <span>location</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>velocity</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
    <span>acceleration</span><span>:</span> <span>(</span><span>f64</span><span>,</span> <span>f64</span><span>),</span>
<span>}</span>
</code></pre></div></div>

<p>Then at each frame, we want to update the locations and velocities of all
Players. We could write something like:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_oop</span><span>(</span><span>players</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Vec</span><span>&lt;</span><span>Player</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>for</span> <span>player</span> <span>in</span> <span>players</span><span>.iter_mut</span><span>()</span> <span>{</span>
        <span>player</span><span>.location</span> <span>=</span> <span>(</span>
            <span>player</span><span>.location</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.location</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.velocity</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
        <span>player</span><span>.velocity</span> <span>=</span> <span>(</span>
            <span>player</span><span>.velocity</span><span>.</span><span>0</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>0</span><span>,</span>
            <span>player</span><span>.velocity</span><span>.</span><span>1</span> <span>+</span> <span>player</span><span>.acceleration</span><span>.</span><span>1</span><span>,</span>
        <span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This would be the usual object-oriented approach to this problem. The
issue here is that in memory the structs are stored as follows (assuming
no field re-ordering i.e. <code>#[repr(C)]</code>), on a 64-bit architecture each field will be 64
bits (8 bytes, so each Player is 64 bytes):</p>

<div><div><pre><code>-- Vec&lt;Player&gt;
name  (pointer to heap)  -- Player 1
health    
location0  (tuple split for clarity) 
location1
velocity0
velocity1
acceleration0
acceleration1
name  (pointer to heap)  -- Player 2
location0    
location1
velocity0
velocity1
acceleration0
acceleration1
...
</code></pre></div></div>

<p>Note the parts we want to operate on (locations, velocities and
accelerations) are not stored contiguously across different Players.
This prevents us from using vector operations to operate on multiple
players at once (since they cannot be loaded in the same CPU cache
line, usually ~64 bytes).</p>

<p>In contrast, the data-oriented approach is to design around this
limitation and optimise for auto-vectorisation. Instead of using a
struct per Player, we now use one struct for all Players and each Player
has their values stored at their index in the separate attribute Vectors:</p>

<div><div><pre><code><span>pub</span> <span>struct</span> <span>DOPlayers</span> <span>{</span>
    <span>names</span><span>:</span> <span>Vec</span><span>&lt;</span><span>String</span><span>&gt;</span><span>,</span>
    <span>health</span><span>:</span> <span>Vec</span><span>&lt;</span><span>f64</span><span>&gt;</span><span>,</span>
    <span>locations</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>velocities</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
    <span>acceleration</span><span>:</span> <span>Vec</span><span>&lt;</span><span>(</span><span>f64</span><span>,</span> <span>f64</span><span>)</span><span>&gt;</span><span>,</span>
<span>}</span>
</code></pre></div></div>

<p>Now we can do the same calculation as in the OOP case as follows:</p>

<div><div><pre><code><span>pub</span> <span>fn</span> <span>run_dop</span><span>(</span><span>world</span><span>:</span> <span>&amp;</span><span>mut</span> <span>DOPlayers</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>pos</span><span>,</span> <span>(</span><span>vel</span><span>,</span> <span>acc</span><span>))</span> <span>in</span> <span>world</span>
        <span>.locations</span>
        <span>.iter_mut</span><span>()</span>
        <span>.zip</span><span>(</span><span>world</span><span>.velocities</span><span>.iter_mut</span><span>()</span><span>.zip</span><span>(</span><span>world</span><span>.acceleration</span><span>.iter</span><span>()))</span>
    <span>{</span>
        <span>*</span><span>pos</span> <span>=</span> <span>(</span><span>pos</span><span>.</span><span>0</span> <span>+</span> <span>vel</span><span>.</span><span>0</span><span>,</span> <span>pos</span><span>.</span><span>1</span> <span>+</span> <span>vel</span><span>.</span><span>1</span><span>);</span>
        <span>*</span><span>vel</span> <span>=</span> <span>(</span><span>vel</span><span>.</span><span>0</span> <span>+</span> <span>acc</span><span>.</span><span>0</span><span>,</span> <span>vel</span><span>.</span><span>1</span> <span>+</span> <span>acc</span><span>.</span><span>1</span><span>);</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>In this case the memory layout is as follows:</p>
<div><div><pre><code>-- DOPlayers
name1    -- names
name2
...
health1    -- health
health2
...
location1    -- locations
location2
...
</code></pre></div></div>

<p>The relevant fields are now stored contiguously. Given that each
location tuple will be 16 bytes, we could now feasibly load 4 location
tuples on the same cache line to operate on them simultaneously with
SIMD instructions.</p>

<h3 id="benchmark">Benchmark</h3>

<p>Here are the results of the criterion benchmark for the above code (the
full code and benchmark code is available <a href="https://github.com/jamesmcm/data-oriented-example">in the Github repo</a>):</p>

<p><img src="https://jamesmcm.github.io/images/soa.svg" alt="AoS vs. SoA benchmark" title="AoS vs. SoA benchmark"></p>

<p>Overall, we see that the data-oriented approach finishes in half the
time. This would seem to be due to the data-oriented case operating on
two Players at a time - we can confirm this by reviewing the compiled
assembly.</p>

<p>Reviewing the <a href="https://godbolt.org/z/d8bjMb">output on Godbolt</a> we see the following:</p>

<pre><code>// Relevant OOP loop
.LBB0_2:
        movupd  xmm0, xmmword ptr [rax + rdx + 32]
        movupd  xmm1, xmmword ptr [rax + rdx + 48]
        movupd  xmm2, xmmword ptr [rax + rdx + 64]
        addpd   xmm0, xmm1
        movupd  xmmword ptr [rax + rdx + 32], xmm0
        addpd   xmm2, xmm1
        movupd  xmmword ptr [rax + rdx + 48], xmm2
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

// ...
// Relevant DOP loop
.LBB1_7:
        movupd  xmm0, xmmword ptr [rcx + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx - 16], xmm1
        movupd  xmm0, xmmword ptr [r9 + rdx - 16]
        movupd  xmm1, xmmword ptr [rax + rdx - 16]
        addpd   xmm1, xmm0
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmmword ptr [rax + rdx - 16], xmm1
        add     rdi, 2
        movupd  xmm1, xmmword ptr [rcx + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rcx + rdx], xmm1
        movupd  xmm0, xmmword ptr [rax + rdx]
        movupd  xmm1, xmmword ptr [r9 + rdx]
        addpd   xmm1, xmm0
        movupd  xmmword ptr [rax + rdx], xmm1
        add     rdx, 32
        cmp     rsi, rdi
        jne     .LBB1_7
        test    r8, r8
        je      .LBB1_5
</code></pre>

<p>We can see in the data-oriented case, the loop is unrolled to operate on
two elements at once - resulting in the 50% speed up overall!</p>

<p><strong>Addendum</strong>: As noted by <a href="https://www.reddit.com/r/rust/comments/hxqwom/an_introduction_to_data_oriented_design_with_rust/fz8lxcq/">/u/five9a2 on Reddit</a>
the above output is specifically for the default target, which is
misleading since <code>cargo bench</code> uses the native target by default (i.e.
all possible features on your CPU), so our benchmarks are not using the
above assembly code.</p>

<p>By setting the compiler flag to <code>-C target-cpu=skylake-avx512</code> to enable 
Skylake features, we get the <a href="https://godbolt.org/z/PEPdvn">following output</a>:</p>

<pre><code>// OOP loop
.LBB0_2:
        vmovupd ymm0, ymmword ptr [rax + rdx + 32]
        vaddpd  ymm0, ymm0, ymmword ptr [rax + rdx + 48]
        vmovupd ymmword ptr [rax + rdx + 32], ymm0
        add     rdx, 80
        cmp     rcx, rdx
        jne     .LBB0_2

...
// DOP loop
.LBB1_19:
        vmovupd zmm0, zmmword ptr [rsi + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax - 64]
        vmovupd zmmword ptr [rsi + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax - 64]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax - 64]
        vmovupd zmmword ptr [rcx + 4*rax - 64], zmm0
        vmovupd zmm0, zmmword ptr [rsi + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [rcx + 4*rax]
        vmovupd zmmword ptr [rsi + 4*rax], zmm0
        vmovupd zmm0, zmmword ptr [rcx + 4*rax]
        vaddpd  zmm0, zmm0, zmmword ptr [r10 + 4*rax]
        vmovupd zmmword ptr [rcx + 4*rax], zmm0
        add     r11, 8
        add     rax, 32
        add     rdi, 2
        jne     .LBB1_19
        test    r9, r9
        je      .LBB1_22
</code></pre>

<p>Here we see the OOP loop making use of the 256-bit ymm registers for the
position tuple and velocity tuple, and another for the velocity tuple
and acceleration tuple. This is possible because they are adjacent in
memory (due to the ordering of the fields). In the DOP loop,
the 512-bit zmm register is used.</p>

<p>It seems the performance differences comes from the bandwidth between
cache levels, since the performance is identical for the small examples.
This can be demonstrated further by removing the extra fields from the
struct - in this case we see only a 25% performance difference (<a href="https://godbolt.org/z/Th91Wa">godbolt
link</a>), and this
corresponds to Player struct now being 384 bits (and so 1/4 of the
512-bit read/write is unused).</p>

<p>This emphasises how important it is to consider your deployment target,
and if deploying performance-sensitive code, to consider setting the
target-cpu explicitly to benefit from all of its features.</p>

<p>It also demonstrates how the ordering of fields can be important to
performance. By default Rust will re-order fields automatically, but you can set
<code>#[repr(C)]</code> to disable this (necessary for C interoperability for
example).</p>

<h3 id="summary">Summary</h3>

<p>This example demonstrates the importance of considering memory layout
when aiming for performant code and auto-vectorisation.</p>

<p>Note that the same logic can also apply when working with arrays of
structs - making your struct smaller will allow you to load more
elements on the same cache line and possibly lead to autovectorisation.
<a href="https://github.com/Rene-007/flake_growth/blob/master/src/helpers.rs">Here is an example</a> of
a crate (which was shared on the <a href="https://www.reddit.com/r/rust/comments/hmqjvs/growing_gold_with_rust/">Rust subreddit</a>) that achieved a 40% performance
improvement by doing just that.</p>

<p>This particular re-organisation has a direct analogue in database design. A
major difference between databases aimed at transactional (OLTP)
workloads and analytical (OLAP) workloads is that the latter tend to use
columnar-based storage. Just like the case above, this means that
operations on one column can take advantage of the contiguous storage
and use vector operations, which tends to be the main access pattern for
analytical workloads (e.g. calculate the average purchase size across all rows,
rather than updating and retrieving entire, specific rows).</p>

<p>In the case of analytical databases this is actually a double win, since it also
applies to the serialisation of the data to disk, where compression can
now be applied along the column (where the data is guaranteed to be of the
same type) leading to much better compression ratios.</p>

<p>If you are working on a problem that might benefit from the struct of
arrays approach, and want to run a quick benchmark, you might be
interested in the <a href="https://github.com/lumol-org/soa-derive">soa-derive</a>
crate that will allow you to derive the struct of arrays from your
struct.</p>

<h2 id="branching-in-a-hot-loop">Branching in a hot loop</h2>

<p>Another optimisation tactic is to avoid branching in any ‚Äúhot‚Äù parts of
the code (i.e. any part that will be executed many, many times).</p>

<p>Branching can arise in subtle ways, often by trying to use one struct for many
different cases. For example, we might define some general Node type ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jamesmcm.github.io/blog/2020/07/25/intro-dod/">https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</a></em></p>]]>
            </description>
            <link>https://jamesmcm.github.io/blog/2020/07/25/intro-dod/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506744</guid>
            <pubDate>Thu, 17 Sep 2020 16:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speeding Tesla driver caught napping behind the wheel on Alberta highway]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24506649">thread link</a>) | @mtr
<br/>
September 17, 2020 | https://www.cbc.ca/news/canada/edmonton/tesla-driver-autopilot-alberta-ponoka-speeding-dangerous-driving-1.5727828 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/edmonton/tesla-driver-autopilot-alberta-ponoka-speeding-dangerous-driving-1.5727828">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>A 20-year-old B.C. motorist who who found reclining behind the wheel of a Tesla while the electric vehicle was on autopilot has been charged by the RCMP in Alberta with speeding.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5727840.1600356254!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/tesla-speeding-alberta.JPG"></p></div><figcaption>The 20-year-old B.C. driver of this Tesla Model S has been charged with speeding and dangerous driving, a criminal offence. The incident occurred on July 9 on Highway 2 near Ponoka, about 100 kilometres south of Edmonton.<!-- --> <!-- -->(Alberta RCMP)</figcaption></figure><p><span><p>The RCMP&nbsp;in Alberta have charged a&nbsp;20-year-old British Columbia man with&nbsp;speeding while he was asleep at the wheel of a Tesla electric car.</p>  <p>The RCMP&nbsp;received&nbsp;a call at about&nbsp;4 p.m. on July 9 concerning&nbsp;a 2019 Tesla Model S speeding south on Highway 2 near Ponoka, about 100&nbsp;kilometres south of Edmonton.</p>  <p>Both front seats were fully&nbsp;reclined, and both the driver and passenger&nbsp;appeared to be sound asleep, police say.&nbsp;</p>  <p>The car appeared to be driving on&nbsp;autopilot at more than 140 km/h, RCMP&nbsp;Sgt. Darrin Turnbull&nbsp;told CBC News on Thursday. The speed limit on that stretch of highway is 110 km/h.</p>  <p>"Nobody was looking out the windshield to see where the car was going," he&nbsp;said.&nbsp;</p>  <p>"I've been in policing for over 23 years&nbsp;and the&nbsp;majority of that in traffic&nbsp;law enforcement, and I'm speechless.</p>  <p>"I've never, ever seen anything like this before, but of course the technology wasn't there."&nbsp;</p>  <p>Tesla Model S sedans have autopilot functions, including auto-steer and "traffic-aware" cruise control, and both functions appeared to be activated.</p>  <p>"We believe the vehicle&nbsp;was operating on the autopilot system, which is really just an advanced driver safety system, a driver assist program. You still need to be driving the vehicle," Turnbull said.&nbsp;</p>  <p>"But of course, there are after-market things that can be done to a vehicle against the manufacturer's recommendations to change or circumvent the safety system."&nbsp;</p>  <p>After the responding officer activated emergency lights on their vehicle, the Tesla automatically began to accelerate, Turnbull said, even as those vehicles that were ahead of the Tesla on the highway moved out of the way.</p>  <p>"Nobody appeared to be in the car, but the vehicle sped up because the line was clear in front."</p>  <ul>  </ul>  <p>The responding officer obtained radar readings on the vehicle, confirming that it had automatically accelerated to exactly 150 km/h.</p>  <p>The RCMP charged the driver with speeding and issued a 24-hour licence suspension for fatigue.&nbsp;</p>  <p>After further investigation and consultation with the Crown, a Criminal Code charge of dangerous driving was laid against the driver, police said.</p>  <p>The driver was served with a summons for court in December.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/business/tesla-s-self-driving-autopilot-system-under-scrutiny-1.5413931" target="_blank">Tesla's self-driving Autopilot system under scrutiny after 3 deadly crashes</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/british-columbia/driverless-tesla-richmond-b-c-1.5349855" target="_blank">Driverless Tesla coasting along mall parking lot raises questions, causes confusion</a></strong></li>  </ul>  <p>Autonomous cars are in their early stages in much of Canada, with Ontario and Quebec approving pilot projects as long as a vigilant driver is present to take control of the vehicle when needed.</p>  <p>There have not been any reported self-driving car crashes in Canada, but several have been reported in the United States, putting Tesla's autopilot driving system functions&nbsp;under scrutiny.</p>  <p>On Dec. 29, 2019, a Tesla Model S sedan left a freeway in Gardena, Calif., at high speed, ran a red light and struck a Honda Civic, killing two people inside, police said. On the same day, a Tesla Model 3 hit a parked firetruck on an Indiana freeway, killing a passenger in the Tesla.</p>  <p>On Dec. 7, a Model 3 struck a police cruiser on a Connecticut highway, but&nbsp;no one was hurt.</p>  <p>Tesla's autopilot function is designed to keep a car in its lane and at a safe distance from other vehicles. Autopilot also can change lanes on its own.</p>  <ul>  </ul>  <h2>'It&nbsp;gives all of us a bad name'</h2>  <p>Angie Dean, president of the Tesla Owners Club of Alberta, said the incident is troubling for the 300 paying members of her group&nbsp;and the more than 1,000 active members of the club's online Facebook group.&nbsp;</p>  <p>Dean said the driver-assist functions in Tesla vehicles are designed to enhance safety, not detract from it.</p>  <p>"This type of story is sort of next to&nbsp;a worst-case scenario," she&nbsp;said. "The only thing that would be worse than this is if someone had got hurt.&nbsp;Everyone that I've spoken with is just so disappointed and so frustrated because it's abuse of the system.</p>  <p>"It&nbsp;gives all of us a bad name, and the vast majority of us would never do something like this. We bought these cars because we want to be safer."</p>  <p>The driver-assist program&nbsp;requires&nbsp;regular input from the driver to function,&nbsp;Dean said. If the driver's hands come off the wheel, warnings begin going off every 15 seconds, she said.</p>  <p>"It asks you to put your hands on the wheel&nbsp;and&nbsp;turn it a little bit so that it knows that your hands are on the wheel," Dean said.&nbsp;</p>  <p>"If you don't, it starts beeping at you. And if you still don't, it gets even louder. And&nbsp;if you still don't, it actually turns the hazard lights on, slows the vehicle down and it pulls it over. It turns the car off and autopilot will not engage for the rest of that drive."</p>  <p><strong><em>WATCH | Is the technology behind driverless cars ready for the road?</em></strong></p>  <p><span><span><span></span><span>The technology behind self-driving cars is available and in use, but there are examples showing it may not be fully ready for the real world.<!-- --> <!-- -->2:09</span></span></span></p>  <p>Despite the built-in safeguards, videos&nbsp;circulating online instruct drivers on ways to "hack" and override&nbsp;these systems, Dean&nbsp;said.</p>  <p>"There are a lot of systems that are in place that are really, really trying not to make this possible. But if there's a will, there's a way, I suppose. "&nbsp;</p>  <p>Just because some vehicles can drive themselves, it doesn't mean they should, the RCMP said.&nbsp;</p>  <p>&nbsp;"Although manufacturers of new vehicles have built in safeguards to prevent drivers from taking advantage of the new safety systems in vehicles, those systems are just that ‚Äî supplemental safety systems," said Supt. Gary Graham of Alberta RCMP Traffic Services.&nbsp;</p>  <p>"They are not self-driving systems, they still come with the responsibility of driving."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/edmonton/tesla-driver-autopilot-alberta-ponoka-speeding-dangerous-driving-1.5727828</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506649</guid>
            <pubDate>Thu, 17 Sep 2020 16:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Adding Auth to a Flask App with Azure Active Directory and Oso]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24506252">thread link</a>) | @todsacerdoti
<br/>
September 17, 2020 | https://www.osohq.com/post/oso-azure | <a href="https://web.archive.org/web/*/https://www.osohq.com/post/oso-azure">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Securing application resources usually consists of two security processes: authentication and authorization. <em>Authentication</em> determines the identity of a user, and is often accomplished by some kind of sign-in process. <em>Authorization</em> determines whether or not a user is allowed to access a resource, typically based on their authenticated identity but often based on other factors as well, like having a certain role, being in a group, having specific attributes or meeting other criteria relevant to the use case.</p>
<p>A common authentication pattern involves the application exchanging information with an <em>Identity Provider,</em> or "IdP", to confirm the identity of the user. Well-known IdPs include Facebook, Google, and GitHub.</p>
<p>This post will show how to add authentication and authorization to a simple Flask app, using Azure Active Directory B2C as an IdP, and oso's <code>oso-flask</code> library to authorize requests.</p>
<h3>Summary of what we'll cover:</h3>
<ul>
<li>Sign in users with Azure AD B2C</li>
<li>Use oso to restrict access to signed-in users</li>
<li>Add custom user attributes to our user profile</li>
<li>Write a policy to control access based on user attributes, like job title or team</li>
<li>Access Microsoft user data, like groups and managers, with the Graph API</li>
<li>Write an oso policy to implement role-based access control using Microsoft groups</li>
</ul>
<h3><strong>Background</strong></h3>
<p>This post uses an example application that's written in Python with Flask. You can find the source code <a href="https://github.com/osohq/oso-azure-ad-example">here</a>.</p>
<p><strong>Azure Active Directory</strong> ("AD") is Microsoft's cloud-based identity management service. We'll use it to sign in users and store user data. This example uses a newer variant of Active Directory called "<a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/overview">B2C</a>", which is designed for business-to-consumer apps to manage customer identities.</p>
<p><strong>oso</strong> is an open-source policy engine for authorization that is embedded in your application. We'll use oso to authorize user access to our application's resources. Since our example application uses Flask, we're using the <code>oso-flask</code> <a href="https://docs.osohq.com/using/frameworks/flask.html">integration</a>, which includes middleware for authorizing Flask requests.</p>
<p>The example we'll use in this post is a very simple application that stores and displays documents. Its authorization model is as follows:</p>
<ul>
<li>Users can always view documents that they are the owner of</li>
<li>Documents can belong to user groups</li>
<li>Public documents can be viewed by anyone</li>
<li>Private documents can only be viewed by users that belong to one of the document's groups</li>
</ul>
<h2>Authentication with Azure AD B2C</h2>
<p>We used a <a href="https://github.com/Azure-Samples/ms-identity-python-webapp">sample app</a> provided by Microsoft as the starting point for our example. Following Microsoft's <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-web-app-python?tabs=app-reg-ga">tutorial</a> on setting up authentication in their sample application will get you to the same starting point (you may have to complete a few prerequisite steps as well).</p>
<p>By the end of the tutorial, you should have <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-register-applications?tabs=app-reg-ga">registered the application</a> with your Azure AD <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-create-tenant">B2C tenant</a>. We've registered ours as "python-webapp":</p>
<p><img alt="Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled.png" src="https://images.osohq.com/oso-azure/Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled.png"></p>
<p>You should also have set up several <a href="https://docs.microsoft.com/en-us/azure/active-directory-b2c/tutorial-create-user-flows">User Flows</a> in the Azure portal for signing in, profile editing, and logging out:</p>
<p><img alt="Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%201.png" src="https://images.osohq.com/oso-azure/Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%201.png"></p>
<p>When you set up the user flows, make sure that you check the following boxes in "User Attributes" and "Application Claims":</p>
<ul>
<li>Email</li>
<li>Given name</li>
<li>Surname</li>
<li>Display Name</li>
<li>Job Title</li>
<li>Object ID (Application Claims only)</li>
</ul>
<p>Once you've reached the end of the tutorial, your app should be able to sign users in with an email and password, allow them to edit their profile, and log them out. Each of these user flows should return an <code>id_token</code> JWT to your app's redirect handler that stores the above attributes as claims. If you use Microsoft's provided JWT decoder, <a href="https://jwt.ms/">https://jwt.ms</a>, to test your user flow, you should see something like this:</p>
<p><img alt="Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%202.png" src="https://images.osohq.com/oso-azure/Adding%20auth%20to%20a%20Flask%20App%20with%20Azure%20Active%20Direc%20e4020384c5a348e499250ae95d24e0d1/Untitled%202.png"></p>
<p>Once you've completed the tutorial, the application can be run with the following command from the root directory:</p>
<pre><code>flask run --host localhost --port 5000
</code></pre>

<p>If you'd like to run our <a href="https://github.com/osohq/oso-azure-ad-example">sample application</a>, make sure to update the information in <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/app_config.py#L3-L17">app_config.py</a>:</p>
<pre><code># app_config.py

b2c_tenant = "your-tenant-name"
signupsignin_user_flow = "B2C_1_signupsignin1"
editprofile_user_flow = "B2C_1_profileediting1"
resetpassword_user_flow = "B2C_1_passwordreset1"
authority_template = (
    "https://{tenant}.b2clogin.com/{tenant}.onmicrosoft.com/{user_flow}"
)

CLIENT_ID = (
    "Enter_the_Application_Id_here"  # Application (client) ID of app registration
)

CLIENT_SECRET = (
    "Enter_the_Client_Secret_Here"  # Placeholder - for use ONLY during testing.
)
</code></pre>

<h3>Creating the User model</h3>
<p>Microsoft's sample app stores a raw dictionary of the <code>id_token</code> claims globally in <code>session["user"]</code>. In our app, we created a User <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/user.py#L13-L20">class</a> to store the user data, which we'll add to later on:</p>
<pre><code># user.py

class User:
    def __init__(self, id_token_claims):
        self.id = id_token_claims.get("oid")
        self.display_name = id_token_claims.get("name")
        self.first_name = id_token_claims.get("given_name")
        self.surname = id_token_claims.get("family_name")
        self.emails = id_token_claims.get("emails")
        self.job_title = id_token_claims.get("jobTitle")
</code></pre>

<p>In <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/app.py#L60-L61">our redirect handler</a>, we construct an instance of the current <code>User</code> from the <code>id_token_claims</code> dictionary, and store it on the <code>session</code> object:</p>
<pre><code># app.py

@app.route(app_config.REDIRECT_PATH)
def authorized():
    # ...
    user = User(id_token_result.get("id_token_claims"))
    session["user"] = user
</code></pre>

<p>We've successfully added authentication to our app. Now let's use oso to authorize our authenticated users' requests.</p>
<h2>Adding oso</h2>
<p>Since we're building a Flask app, we're going to use the <code>flask-oso</code> package to add oso to our application. <code>flask-oso</code> is an even lighter weight form of the <code>oso</code> package that provides convenient middleware for authorizing Flask requests. You can find a helpful guide to using <code>flask-oso</code> in our <a href="https://docs.osohq.com/using/frameworks/flask.html">docs</a>.</p>
<p>We followed three steps to add oso to the application:</p>
<ol>
<li>Create a <code>.polar</code> policy file</li>
<li>Initialize the global oso instance by loading the policy and registering relevant application classes</li>
<li>Add calls to <code>flask_oso.FlaskOso.authorize()</code> at authorization enforcement points</li>
</ol>
<h3>Writing a policy</h3>
<p>oso policies are written in a declarative policy language called Polar, and are stored in files with the <code>.polar</code> extension. Take a look at <a href="https://docs.osohq.com/getting-started/policies/index.html">Writing Policie</a>s for an overview of how to use oso policies.</p>
<p>The policy file in this example is called <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/authorization.polar#L1-L3">authorization.polar</a>. We started with a simple rule to allow any logged-in user to get a public document:</p>
<pre><code># authorization.polar

# allow anyone to get public documents
allow(_actor: User, "GET", doc: Document) if
    not doc.is_private;
</code></pre>

<p>This rule works by specializing the <code>_actor</code> on the <code>User</code> class, which means that only actors of type <code>User</code> are allowed to take any action on any resource. Since <code>get_current_user()</code>, which is used to get the default actor, returns <code>None</code> when the current user is not logged in, the rule only applies when the current user is authenticated. The <code>doc</code> argument is specialized on the <code>Document</code> class, which allows us to safely access the <code>is_private</code> field.</p>
<h3>Initializing oso</h3>
<p>We wrote a function called <code>init_oso()</code>, which we put in a file called <a href="https://github.com/osohq/oso-azure-ad-example/blob/master/oso_auth.py">oso_auth.py</a>:</p>
<pre><code># oso_auth.py

from oso import Oso
from flask_oso import FlaskOso

from document import Document
import user
from user import User

def init_oso(app):
    """ set up the `Oso` and `FlaskOso` objects, and add them to the global `app` instance."""
    oso = Oso()
    oso.register_class(Document)
    oso.register_class(User)
    oso.load_file("authorization.polar")

    flask_oso = FlaskOso(app=app, oso=oso)
    flask_oso.set_get_actor(user.get_current_user)

    app.oso = oso
    app.flask_oso = flask_oso
</code></pre>

<p>The <code>init_oso()</code> function creates an <code>Oso</code> instance, on which it registers the <code>User</code> class and the <code>Document</code> class that represents the app's document resources (registering Python classes with oso lets us reference them in our oso policies).</p>
<p>The function then uses the <code>Oso</code> instance to create the <code>FlaskOso</code> instance that we'll use to authorize requests. We call the <code>set_get_actor()</code> method to set the default actor to the current user. This default is used when we make calls to <code>flask_oso.authorize()</code> later on. The <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/user.py#L56-L57">method</a> we pass in, <code>get_current_user()</code> looks up the user on the session object:</p>
<pre><code># user.py

from flask import session

def get_current_user():
    return session.get("user")
</code></pre>

<h3>Authorizing requests</h3>
<p>We're now ready to use the oso library to authorize requests. In this example application, the resources we want to secure are documents, represented by the <code>Document</code> <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/document.py#L11-L46">class</a> in <code>document.py</code>:</p>
<pre><code># document.py

@dataclass
class Document:
    id: int
    owner_id: str
    groups: list
    is_private: bool
    content: str

def find_by_id(id):
    return DOCUMENTS.get(id)

DOCUMENTS = {
    1: Document(
        id=1,
        owner_id="5890e32a-c2ac-4aa0-902d-0717017d1bc3",
        groups=["engineering"],
        is_private=True,
        content="This is a private engineering doc.",
    ),
    2: Document(
        id=2,
        owner_id="273dd85f-0728-44c0-8588-c130f39c900b",
        groups=["marketing"],
        is_private=True,
        content="This is a private marketing doc.",
    ),
    3: Document(
        id=3,
        owner_id="273dd85f-0728-44c0-8588-c130f39c900b",
        groups=["admin"],
        is_private=False,
        content="This is a public admin doc.",
    ),
}
</code></pre>

<p>For this example we've simply hardcoded the document data, but this data would normally be stored in a database.</p>
<p><code>document.py</code> has a <a href="https://github.com/osohq/oso-azure-ad-example/blob/11aa2c113b7802b3136575e9900420511089834d/document.py#L55-L59">route</a> for viewing the documents, to which we've added a call to <code>flask_oso.FlaskOso.authorize()</code>:</p>
<pre><code># document.py

@bp.route("/docs/&lt;int:id&gt;", methods=["GET"])
def get_doc(id):
    doc = find_by_id(id)
    current_app.flask_oso.authorize(resource=doc)
    return str(doc)
</code></pre>

<p>The <code>authorize()</code> method accepts the same arguments as the <code>is_allowed()</code> method of the <code>oso</code> package (actor, action, and resource), but provides sensible defaults for working with Flask. With our call to <code>set_get_actor()</code>, we set the default actor to the current user. The action defaults to the method of the current request, <code>flask.request.method</code>. We have to provide the resource we want to authorize; in this case, we pass in the <code>Document</code> instance that is being ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.osohq.com/post/oso-azure">https://www.osohq.com/post/oso-azure</a></em></p>]]>
            </description>
            <link>https://www.osohq.com/post/oso-azure</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506252</guid>
            <pubDate>Thu, 17 Sep 2020 15:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking Clearly About Correlations and Causation (2018) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24506243">thread link</a>) | @Anon84
<br/>
September 17, 2020 | https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true | <a href="https://web.archive.org/web/*/https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dacemirror.sci-hub.tw/journal-article/7fe084d6885f9339910bf080b718c012/rohrer2018.pdf?download=true</link>
            <guid isPermaLink="false">hacker-news-small-sites-24506243</guid>
            <pubDate>Thu, 17 Sep 2020 15:58:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Favorite Rust Function Signature]]>
            </title>
            <description>
<![CDATA[
Score 234 | Comments 111 (<a href="https://news.ycombinator.com/item?id=24505436">thread link</a>) | @brundolf
<br/>
September 17, 2020 | https://www.brandonsmith.ninja/blog/favorite-rust-function | <a href="https://web.archive.org/web/*/https://www.brandonsmith.ninja/blog/favorite-rust-function">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemprop="articleBody">
      

      

      

      


      <p>I've gotten really into writing parsers lately, and Rust has turned out to be
        the perfect language for that. In the course of my adventures, I came up with
        the following:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>and it really deepened my appreciation for Rust.</p>
      <h2 id="what-does-this-function-do%3F">What does this function do? </h2>
      <p>For those not familiar with parsing, tokenization is the first step of the
        process. It takes a raw code string, like this:</p>
      <pre><code>let a = "foo";
</code></pre>
      <p>and turns it into a linear series of meaningful tokens, like so:</p>
      <pre><code>["let", "a", "=", "\"foo\"", ";"]
</code></pre>
      <p>This phase isn't terribly complicated, but it simplifies the mental model for
        the next pass: constructing an "abstract syntax tree". It removes whitespace
        from the equation, bundles up segments like strings and numbers, and just
        generally makes the code in the next pass cleaner.</p>
      <p>The downside is that, if you perform this as a separate pass, your parser now
        has to iterate over all of the source code <em>twice</em>. This may not be the end of
        the world: tokenizing isn't the most expensive operation. But it isn't ideal,
        so some parsers combine the two passes into a single one, saving cycles at the
        expense of readability.</p>
      <h2 id="what's-going-on-in-the-rust-version%3F">What's going on in the Rust version? </h2>
      <p>I'll copy the signature here again for reference:</p>
      <pre><code><span>fn</span> tokenize<span>&lt;</span><span>'a</span><span>&gt;</span><span>(</span>code<span>:</span> <span>&amp;</span><span>'a</span> str<span>)</span> <span>-&gt;</span> <span>impl</span> Iterator<span>&lt;</span>Item<span>=</span><span>&amp;</span><span>'a</span> str<span>&gt;</span> <span>{</span>
  <span>...</span>
<span>}</span>
</code></pre>
      <p>There are several things going on here.</p>
      <p><code>&amp;str</code>, in Rust, is a "string slice". It's effectively a character pointer and a
        length. The contents of the slice are guaranteed to be in valid, alive memory.
        <code>&amp;'a str</code> is a string slice <em>with a lifetime</em>. The lifetime <code>'a</code>, to be
        exact. This lifetime describes a limited span of time in which the
        reference (and the full contents of the slice) are guaranteed to be in valid,
        alive memory. More on this later.</p>
      <p><code>Iterator&lt;Item=&amp;'a str&gt;</code> is an iterator over elements of type <code>&amp;'a str</code>. This
        is a <em>trait</em>, though, not a concrete type. Rust needs a concrete type with a
        fixed size when you're defining something like a function, but luckily we can
        say <code>impl Iterator&lt;Item=&amp;'a str&gt;</code>, which tells Rust, "fill in some type that
        implements <code>Iterator&lt;Item=&amp;'a str&gt;</code>, to be inferred at compile-time". This is
        very helpful because in Rust there are lots and lots of different concrete types
        for <code>Iterator</code>; applying something like a <code>map()</code> or a <code>filter()</code> returns a whole
        new concrete type. So this way, we don't have to worry about keeping the
        function signature up to date as we work on the logic.</p>
      <h2 id="so-what's-so-great-about-all-this%3F">So what's so great about all this? </h2>
      <p>Okay, so we have a function that takes a reference to a string slice and returns
        an iterator over string slices. Why's that special? There are two reasons.</p>
      <h3 id="iterators-let-you-treat-one-pass-like-it's-two">Iterators let you treat one pass like it's two </h3>
      <p>Remember how I said you traditionally have to pick between doing a separate
        tokenization pass, and doing a single pass with all the logic interleaved? With
        an iterator, you can have the best of both worlds.</p>
      <p>When this function completes, it hasn't yet iterated over the string. It hasn't
        allocated any kind of collection in memory. It returns a structure that's
        <em>prepared</em> to iterate over the input string slice and produce a sequence of new
        slices. When this value later gets <code>map()</code>ed into something else, or
        <code>filter()</code>ed, or any other <code>Iterator</code> transformations get applied, the stages
        of the process get interleaved, and the "loops" effectively get folded into a
        single one. By doing this, we're able to get the clean abstraction of a
        tokenizing "pass" without the runtime overhead of a second loop!</p>
      <p>But other languages have iterators. Rust's may be extra powerful and ergonomic,
        but they aren't a totally unique feature. The next part is very much unique to
        Rust.</p>
      
      <p>The <code>tokenize()</code> function doesn't allocate any new memory for a collection of
        tokens. That's great. But what may be less obvious is that it <em>also</em> doesn't
        allocate any memory for the tokens themselves! Each string slice representing a
        token is a <em>direct pointer to part of the original string</em>.</p>
      <p>You can do this in C/C++, of course, but there's a danger: if those tokens are
        ever accessed after the original code string has been freed, you'll have a
        memory error.</p>
      <p>For example: let's say you open a file and load the source code from it, and
        store the result in a local variable. Then you <code>tokenize()</code> it and send the
        tokens on to somewhere else outside of the function where the original string
        lived. Voil√†, you've got a <a href="https://en.wikipedia.org/wiki/Dangling_pointer">use-after-free error</a>.</p>
      <p>One way to guard against this is by copying each string segment into a <em>new</em>
        string, allocated on the heap, which allows you to safely pass it on after the
        original string is gone. But this comes with a cost: creating, copying, and
        eventually disposing of each of those new strings takes time (and memory). Code
        down the line also has to be aware that it's responsible for de-allocating those
        strings, otherwise they'll leak.</p>
      <p>This is where the magic of lifetimes comes into play.</p>
      <p>Rust prevents the above situation entirely. Normally, though, to accomplish this
        a <code>&amp;str</code> coming into a function from elsewhere must be assumed to be <em>static</em>,
        or to be alive for the entire duration of the program's execution. This is the
        status assigned to, for example, a string literal that you've manually entered
        into your Rust code. Rust doesn't know, in the context of the function, how
        long that reference will be valid, so it must be pessimistic.</p>
      <p><strong>But.</strong> That little <code>'a</code> says: "these things all live for the same span of time". We
        can <em>assert</em> that the original source code string lives at least as long as the
        <em>tokens</em> that reference it. By doing so, Rust can reason about whether or not
        those resulting token references are valid at a given point, and therefore
        doesn't have to assume them to be static! We can do <em>whatever we want</em> with
        those tokens and the compiler will guarantee that they always point to something
        valid, even if the source code is loaded in dynamically at runtime (from a file
        or otherwise). If we find out later via a compiler error that they really do
        need to outlive the source string, then we can copy them ("take ownership") at
        that point. If the compiler doesn't force us to do so, we know we're safe,
        and we know we can continue using the most efficient possible approach,
        <em>fearlessly</em>.</p>
      <p>What we've effectively done is written the most optimistic possible function
        (in terms of memory safety), with no downsides, because the Rust compiler will
        tell us if we're misusing it and force us to then "step down" to whatever level
        of extra accommodation is needed.</p>
      <h2 id="conclusion">Conclusion </h2>
      <p>I've been using (and loving) Rust for about a year and a half now. And there are
        many things to love, but when I got this function working I immediately saw it
        as a microcosm of what really sets the language apart. This is something that
        you <strong>cannot do</strong> both a) this safely and b) this efficiently <strong>in any other
language</strong>. This is the power of Rust.</p>


    </article></div>]]>
            </description>
            <link>https://www.brandonsmith.ninja/blog/favorite-rust-function</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505436</guid>
            <pubDate>Thu, 17 Sep 2020 15:00:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shutting Down NavHere]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24505232">thread link</a>) | @jermaustin1
<br/>
September 17, 2020 | https://jeremyaboyd.com/post/shutting-down-navhere | <a href="https://web.archive.org/web/*/https://jeremyaboyd.com/post/shutting-down-navhere">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
            <div>
                <div>
                    <p>So over the last few weeks and months, I have made the not-so-easy decision to shut down NavHere. It was a product both birthed and killed by a change to GoDaddy's domain forwarding service.</p>
<p>GoDaddy, for all it's faults had a really decent domain/link forwarding and masking product, and best of all it was FREE. This all changed in 2018 with a series of changes that eventually broke domain forwarding. If you forwarded your domain, you would lose your path, if you had link forwarding enabled, you couldn't forward the domain, and if you had domain masking, you would again, lose the path.</p>
<p>I had multiple domains utilizing this, and my buddy's Austin's domain stopped forwarding to his university professor page.</p>
<p>When we realized what happened, we built NavHere, a "highly available" (failover-able with floating IP, but not balanced), vanity domain and link forwarding service. </p>
<p>I built out the infrastructure on Digital Ocean </p>
<ul>
<li>1 web application server (for the domain administration)</li>
<li>2 forwarding servers (1 primary - 1 failover with floating IP - and it was imaged so spinning up a new one took 30 seconds)</li>
<li>a 3-node cluster of database servers. </li>
</ul>
<p>All together it only cost about $55/mo to host, so figuring I only need 10 signups a month to cover the cost, I went off to the GoDaddy support forums where everyone was complaining to start letting people know... and got banned ALMOST immediately. A handful of people did see those posts, though and were the first to sign up. A couple of them even PAID! I just KNEW I was on my way to a million dollars in ARR. Then silence.</p>
<p>A couple of weeks after launching, I decided to reach out to a former manager and sell them on it. I knew they were paying around $15k per month for a similar service, and secured an "SMS of Intent" from my former manager stating they would switch over to us providing we gave them an API to manage their domains and links. </p>
<p><strong>Yes! Profitability here we come!</strong></p>
<p>In the couple of weeks from that initial enthusiasm to when I finally secured and exposed the internal API, my former manager left the company. There had been a series layoffs, budget freezes, and an emphases on outsourcing. So even though NavHere would have saved them $162k/year, there was no one there who would/could approve it. Again back to square one. With only a few paying customers, and still losing around $40/mo (a tiny rounding error, no doubt, but still, a loss).</p>
<p>By the end of  2018, we had hundreds of free-trial users, and were serving 100s of thousands of forwarding requests each day. But we had only converted a few paying customers (it was in the low 10s of paying customers), and most of those sales were VERY hands on. I was having to explain DNS to small business owners who all they know is their GoDaddy stopped working. It would some times take over a week from when they first contacted to when they had finally set up their DNS records, and another week before they would set up their DNS records <strong>correctly</strong>, and all of that for only $9/year. It wasn't sustainable. </p>
<p><strong>It wasn't fun.</strong></p>
<p>And then, <strong>as quickly as they broke it</strong>, in mid 2019, GoDaddy decided they were tired of people complaining and fixed/reverted/whatever the breaking changes they made, and since then, we have not had a single new paying customer sign up (rightly so, I feel). And now, all but a couple of paying customers have left - I hope back to GoDaddy's free domain forwarding.</p>
<p>So with that, I have decided to shut down NavHere effective 2020-10-31. </p>
<p>I know I said it wasn't fun, but <strong>that is a lie</strong>. Anytime you build something that is useful to someone, it <strong>IS</strong> fun. What becomes less fun is the after-building part of running the business.</p>
<p>It <strong>was</strong> fun; it <strong>was</strong> exciting; but NavHere is <strong>no longer needed</strong>. And that <strong>is</strong> sad.</p>

                </div>
            </div>
        </div>
    </article></div>]]>
            </description>
            <link>https://jeremyaboyd.com/post/shutting-down-navhere</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505232</guid>
            <pubDate>Thu, 17 Sep 2020 14:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SuperAnnotate Desktop: A better alternative to free annotation tools]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24505211">thread link</a>) | @tigranhakobian
<br/>
September 17, 2020 | https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools | <a href="https://web.archive.org/web/*/https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text">
<p><img src="https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=1200&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png" alt="SuperAnnotate OpenCV partnership-1" width="1200" srcset="https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=600&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 600w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=1200&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 1200w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=1800&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 1800w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=2400&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 2400w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=3000&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 3000w, https://blog.superannotate.com/hs-fs/hubfs/SuperAnnotate%20OpenCV%20partnership-1.png?width=3600&amp;name=SuperAnnotate%20OpenCV%20partnership-1.png 3600w" sizes="(max-width: 1200px) 100vw, 1200px"></p>

<h3><strong>As part of our partnership with OpenCV, we are launching the best free annotation tool for the computer vision community.</strong></h3>

<p><em>In this post, I will be introducing SuperAnnotate‚Äôs new free-to-use desktop app, discuss some of the reasons why we built it, and share more about many of the features which we feel will dramatically increase the speed, accuracy, and efficiency of annotation projects. There is a massive functionality gap between free and commercial image annotation tools. SuperAnnotate Desktop is closing this gap by providing the fastest all-inclusive software tool for computer vision engineers to complete their annotation tasks.&nbsp;</em></p>
<!--more-->
<h3><strong><span>Outline</span></strong></h3>
<ul>
<li>The world of free image annotation tools</li>
<li>Introducing SuperAnnotate Desktop‚Ää</li>
<li>Eight reasons why you should use SuperAnnotate Desktop‚Ää</li>
<li>Importing annotations from other platforms</li>
<li>The future of SuperAnnotate Desktop</li>
</ul>
<h2><strong>1. The World of Free Image Annotation Tools</strong></h2>
<p>Instead of writing a rather long introduction on the universe of free image annotation tools, I will quickly summarize many of the well-written articles, blogs, and websites covering the topic. Probably the most informative website discussing free tools is <a href="https://awesomeopensource.com/"><span>https://awesomeopensource.com/</span></a>, which ranks open source tools based on the number of&nbsp; GitHub stars each tool has received. The list for image annotation tools can be found<a href="https://awesomeopensource.com/projects/annotation-tool"> <span>here</span></a>. According to the list, it becomes apparent that CVAT (managed by Intel) and VOTT (managed by Microsoft) are among the most popular free tools for image annotation. There are several other interesting articles that include CVAT and VOTT among the best annotation tools available for free. Here are a few examples:<a href="https://bohemian.ai/blog/image-annotation-tools-which-one-pick-2020/"> <span>Bohemian.ai</span></a>,<a href="https://www.sicara.ai/blog/2019-09-01-top-five-open-source-annotation-tools-computer-vision"> <span>Sicara.ai</span></a>,<a href="https://en.wikipedia.org/wiki/List_of_manual_image_annotation_tools"> <span>Wikipedia</span></a>.</p>
<p>These articles are wonderful resources, and I strongly recommend reading them to learn about the different tools available and even try some of them if you have the time. However, what you soon start to realize is that free tools are lacking in many areas resulting in slow speeds, disjointed project management, and an overall non-intuitive user experience - especially when you consider what we‚Äôve come to expect from software today.&nbsp;</p>

<h2><strong>2. </strong><strong>Introducing SuperAnnotate Desktop‚Ää</strong><strong>‚Ää</strong></h2>
<p>The founding team of SuperAnnotate (my brother and I) were PhD students in biomedical imaging and computer vision, respectively. During the course of our PhDs, we spent a considerable amount of time working with images, particularly with annotations. In 2018, free annotation tools were as incredibly inconvenient as they are today, and it was quite painful using them. They were not only extremely slow and clunky, but also lacked many key annotation functionalities. These pains led us to launch SuperAnnotate.&nbsp;</p>
<p>Since founding SuperAnntotate, we have always been focused on releasing software that is lightning-fast, easy to use, and extremely functional for all types of computer vision tasks. Over the last two years, we‚Äôve worked hard to build what we think is the fastest and most efficient annotation platform for computer vision pipelines. And, as we came from academia, we also wanted to make a version of our platform easily installable and free for anyone, to help eliminate many of the pains my brother and I faced as PhD students.&nbsp;</p>
<p>Back in June we announced our partnership with OpenCV to bring a free annotation tool to the broader computer vision community that is a significant upgrade over the current free tools available.</p>
<p>A few days ago we released software for <strong>Mac</strong>, <strong>Windows</strong> and <strong>Linux</strong> users. Despite being the initial release, the software already provides multiple advanced features that will accelerate your labeling process by 3‚Äì5x.</p>
<p><!--HubSpot Call-to-Action Code --><span id="hs-cta-wrapper-d65647e7-d436-4d5f-831c-82dae9c73cef"><span id="hs-cta-d65647e7-d436-4d5f-831c-82dae9c73cef"><!--[if lte IE 8]><div id="hs-cta-ie-element"></div><![endif]--><a href="https://cta-redirect.hubspot.com/cta/redirect/7839526/d65647e7-d436-4d5f-831c-82dae9c73cef"><img id="hs-cta-img-d65647e7-d436-4d5f-831c-82dae9c73cef" src="https://no-cache.hubspot.com/cta/default/7839526/d65647e7-d436-4d5f-831c-82dae9c73cef.png" alt="Download SuperAnnotate Desktop"></a></span></span><!-- end HubSpot Call-to-Action Code --></p>
<p>We will keep updating our desktop app on a monthly basis and would love to get the community‚Äôs feedback on features you all like, as well as the ones that are missing. We‚Äôre excited to be a bigger part of the OpenCV community, and to help provide the best computer vision tools to its members.</p>

<p><img src="https://lh3.googleusercontent.com/yWBnNCxg3fqyUsM_kxoSPxZ2ELSDlAGx2q4y_xKmqHYZBBc2IceePuyJbsjzCXyYCDtVm8-66hTbIXoqCS01eJC8RiINmUJqolVcOyu2IBLmFCFPM6t2dG6WgtIzwt397BGsNv9i" width="624" height="391" alt="SuperAnnotate Desktop free annotation tool"></p>

<h2><strong>3. Eight reasons why you should use SuperAnnotate Desktop&nbsp;</strong></h2>
<p>In this section, I will do a deeper dive into some of the features that make our app unique compared to some of the most popular alternatives. As I mentioned above, the paid version of our platform is focused on delivering lightning-fast speed, robust workflows, and a delightful user experience. We tried to bring that focus (and a few of the features) into our desktop app. Here we go:&nbsp;</p>
<p><em>Note: I strongly recommend watching the video below which summarizes all these components.</em></p>

<div data-service="youtube" data-responsive="true"><div><p data-mce-style="position: relative; overflow: hidden; max-width: 100%; padding-bottom: 56.25%; margin: 0px;"><iframe width="480" height="270" src="https://www.youtube.com/embed/_wFYtQY3v14?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" xml="lang" data-mce-src="https://www.youtube.com/embed/_wFYtQY3v14?feature=oembed" data-mce-style="position: absolute; top: 0px; left: 0px; width: 100%; height: 100%; border: none;"></iframe></p></div></div>

<p><strong>3.1 Born out of SuperAnnotate‚Äôs Core Platform</strong>&nbsp;‚Äî‚Ää We‚Äôve spent the last two years and we have invested hundreds of thousands of engineering hours and millions of dollars on the core web version of SuperAnnotate, building what we feel is the fastest and most efficient annotation platform for computer vision. It incorporates feedback from annotators working hundreds of thousands of hours in the web version of our platform as well. This has allowed us to deliver our desktop editor with some of the designs, features, and refinements from our core product offering. We hope the result is a 100% free product that is delightful, feature-rich, and professional grade.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</p>
<p><strong>3.2 Advanced polygon tool‚Ää</strong>‚Äî‚ÄäPolygon annotation is often the most time-consuming annotation task. Anyone who has tried free annotation tooling knows how poor the experience can be. We made several additions to traditional polygon tools in order to make manual polygon creation and editing much faster. Some of these features include:</p>
<ul>
<li><em>Pen-polygon tool ‚Ää</em>‚Äî‚Ääuse the polygon as a pen making curved annotations much faster</li>
<li><em>Point addition/removal </em>‚Äî<em> Add</em> <em>and remove</em> polygon points with just a couple of clicks<strong>&nbsp;</strong></li>
<li><em>Edit polygon</em>‚Ää‚Äî‚Ää Substantially increase the speed of editing polygons with our pen polygon tool&nbsp;</li>
<li><em>Share polygon boundaries</em>‚Ää‚Äî‚Äädraw polygons with shared boundaries 2x faster than traditional tools</li>
<li><em>Polygon move</em><span>/group/delete ‚Äî‚Ääselect, drag, drop, or delete individual or groups of polygons wherever you want</span></li>
</ul>
These are just some of the features that allow us to reduce polygon annotation times by 20-60% while making polygon annotations significantly more accurate.&nbsp;
<p><strong>3.3 Filtering </strong>‚Ää‚Äî‚Ää Most annotation tools lack the ability to filter images. Yet we have found that class filtering has a dramatic impact on speeding up the annotation review process. Through SuperAnnotate‚Äôs filtering menu, users can display only images with certain classes they are interested in reviewing, avoiding the need to comb through all of the images and saving tremendous amounts of time.&nbsp;</p>
<p><strong>3.4 Tracking multiple objects between frames</strong>‚Ää‚Äî‚Ää Tracking multiple objects between consecutive frames can dramatically improve the annotation experience while also making annotating much faster. Our desktop app allows users to select multiple objects and perform operations such as move, delete, group, copy, paste, and duplicate. Users can copy and duplicate annotations in successive frames while keeping the same attribute ID so that a particular attribute can be tracked through multiple frames easily.&nbsp;</p>
<p><strong>3.5 Huge list of shortcuts</strong>‚Ää‚Äî Gamers and power users of tools like excel and photoshop know how a robust list of shortcuts can both improve the user experience and add considerable speed. That was why we made a huge list of shortcuts for actions like tool selection, on-screen navigation, copy/paste/group/ungroup objects, switching between frames, and others. All shortcuts take place on the left side of the keyboard (similar to gaming), so your right hand can stay focused on the mouse, and your left hand does not have to move while finding the right shortcut.&nbsp;</p>
<p><strong>3.6 Labeling Flexibility</strong> ‚Ää‚Äî‚ÄäCurrent platforms (both free and paid) limit you to one labeling workflow: you set the attributes and then draw the shapes. Oftentimes, it can be significantly more efficient to have different workflows such as drawing shapes first, or copying classes between instances. With SuperAnnotate, we allow for a wide range of labeling workflows, giving users the flexibility they need to be most efficient.</p>
<p><strong>3.7 Classes/attributes/point labels ‚Ää</strong>‚Äî‚ÄäCreating, adding, or deleting classes and attributes is made very simple in the SuperAnnotate desktop app. Users can easily import classes from previous projects saving the time needed to define projects. In addition, we allow users to annotate individual points with free text. This can have multiple uses such as, describing the object by a sentence, giving a tag to the object, or describing the specific point in the polygon (e.g. rear-right wheel).</p>
<p><strong>3.8 Leveling up your annotations</strong>‚Ää‚Äî‚ÄäAs your annotation needs increase, you will likely find yourself looking for things like increased automations, ML features, more robust project management, detailed quality assurance, team collaboration, and user roles. You might also find yourself needing outsourced annotation teams. At SuperAnnotate, we can satisfy all of these needs and much more via our core platform. <span>Our core platform leverages ML and workflow-based features to help computer vision teams increase annotation speed by up to 10x, while dramatically improving the quality of training data and increasing the efficiency of managing annotation projects. We also have integrated services on the platform, giving customers the ability to access thousands of professionally managed outsourced annotators armed with our lightning-fast tooling. If you are interested in learning more about our core platform and services, please fill out </span><a href="https://www.superannotate.com/contacts?utm_source=blog&amp;utm_medium=article&amp;utm_campaign=SuperAnnotate_Desktop_Launch" rel="noopener"><span>this form</span></a><span>.&nbsp;</span></p>

<h2><strong>4. Importing annotations from other platforms or open-source tools</strong></h2>
<p>Migrating to SuperAnnotate from other software is something important to our customers. This was a common request from our users as many of them wanted to use our platform to quality check their previous work and transition over from other tools. We‚Äôve made it super easy to import annotated data from other annotation tools using only a few lines of code, which I‚Äôve described below. Then, once in our platform, users can leverage features described above like filtering and advanced ‚Ä¶</p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools">https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools</a></em></p>]]>
            </description>
            <link>https://blog.superannotate.com/superannotate-desktop-a-better-alternative-to-free-annotation-tools</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505211</guid>
            <pubDate>Thu, 17 Sep 2020 14:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UK government‚Äôs plans to regulate the internet are a threat to free speech]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 176 (<a href="https://news.ycombinator.com/item?id=24505074">thread link</a>) | @timthorn
<br/>
September 17, 2020 | https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/ | <a href="https://web.archive.org/web/*/https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-17831" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div>

	
	<!-- .entry-header -->

	
	<div itemprop="text">

		
		
<p>Dr Radomir Tylecote</p>



<p>September 2020</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<figure><div>
<p><iframe title="How the Government‚Äôs plans to regulate the internet are a threat to free speech" width="1200" height="675" src="https://www.youtube.com/embed/CQac6mzC444?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
</div></figure>







<h3>The Government‚Äôs proposed new internet regulator will infringe free speech</h3>



<p>The Government published the Online Harms White Paper in April 2019 and intends to put a Bill before Parliament next year. The proposals aim to make the UK ‚Äúthe safest place in the world to go online‚Äù, but they will seriously infringe free speech.</p>



<p>Some of the harms the White Paper identifies are real, including distributing images of child abuse and online activities by terrorists. But these would be better dealt with by simpler legislation and more resources for law enforcement.</p>



<p>However, some of the harms the White Paper describes are vague, such as ‚Äúunacceptable content‚Äù and ‚Äúdisinformation‚Äù. These are not fixed but would be determined by a future regulator. This will lead to sweeping censorship. Online Harms does not even properly define ‚Äúharm‚Äù, so the definition risks being outsourced to activists and lobby groups.</p>



<p>A proposed new regulator will even have the power to censor lawful content: the government says new regulation should prohibit material ‚Äúthat may directly or indirectly cause harm‚Äù even if ‚Äúnot necessarily illegal‚Äù. The Government also singled out ‚Äúoffensive material‚Äù, as if giving offence is a harm the public should be protected from by the state.</p>



<h3>The proposals move the UK towards the internet laws of China, Russia and Belarus</h3>



<p>The Government‚Äôs proposals are partly inspired by Germany‚Äôs 2017 ‚ÄúNetzDG‚Äù internet law, but Human Rights Watch has called for Germany to scrap the law, saying it ‚Äúturns internet companies into censors‚Äù. President Lukashenko of Belarus, Vladimir Putin‚Äôs United Russia Party and the Venezuelan government have cited NetzDG as the model for their online laws.</p>



<p>Our government‚Äôs plans also bear a worrying similarity to Beijing‚Äôs internet censorship policies. Beijing censors ‚Äúrumours‚Äù because they cause ‚Äúsocial harms‚Äù. Our government‚Äôs proposals describe ‚Äúdisinformation‚Äù as ‚Äúharmful‚Äù, and will make ‚Äúcontent which has been disputed by reputable fact-checking services less visible to users‚Äù, forcing companies to promote ‚Äúauthoritative news sources‚Äù. This contradicts our government‚Äôs claim that ‚Äúthe regulator will not be responsible for policing truth and accuracy online‚Äù.</p>



<p>While the authors of the White Paper believe their proposals will mean more ‚Äútolerance‚Äù and less ‚Äúhate‚Äù, they will likely have the opposite effect, as people respond angrily to censorship and conspiracy theorists enjoy the cachet of being banned by the state.</p>



<p>In this briefing we outline the Government‚Äôs Online Harms plans and explain why they are a danger to freedom of speech. Later this year, the Free Speech Union will propose alternative regulation to protect the vulnerable without jeopardising free speech.</p>



<p><a href="https://freespeechunion.org/fsu-briefing-online-harms/">Full Report</a><br><a href="https://www.gofundme.com/f/the-free-speech-union-fighting-fund">GoFundMe appeal</a></p>



<p><em>FSU research papers are designed to promote discussion of free speech issues. As with all FSU publications, the views expressed are those of the author(s) and not those of the FSU, its directors, Advisory Councils or other senior staff.</em></p>

		
		
			</div><!-- .entry-content .clear -->
</div>

	
</article></div>]]>
            </description>
            <link>https://freespeechunion.org/why-the-governments-plans-to-regulate-the-internet-are-a-threat-to-free-speech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24505074</guid>
            <pubDate>Thu, 17 Sep 2020 14:31:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data-Oriented Programming in Python]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24504947">thread link</a>) | @jbredeche
<br/>
September 17, 2020 | https://www.moderndescartes.com/essays/data_oriented_python/ | <a href="https://web.archive.org/web/*/https://www.moderndescartes.com/essays/data_oriented_python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	

<p> Originally posted 2020-09-13</p>
<p> Tagged: <a href="https://www.moderndescartes.com/essays/tags/optimization">optimization</a>, <a href="https://www.moderndescartes.com/essays/tags/computer_science">computer_science</a>, <a href="https://www.moderndescartes.com/essays/tags/python">python</a></p>
<p> <em>Obligatory disclaimer: all opinions are mine and not of my employer </em></p>
<hr>

<p>Many users of Python deprioritize performance in favor of soft benefits like ergonomics, business value, and simplicity. Users who prioritize performance typically end up on faster compiled languages like C++ or Java.</p>
<p>One group of users is left behind, though. The scientific computing community has lots of raw data they need to process, and would very much like performance. Yet, they struggle to move away from Python, because of network effects, and because Python‚Äôs beginner-friendliness is appealing to scientists for whom programming is not a first language. So, how can Python users achieve some fraction of the performance that their C++ and Java friends enjoy?</p>
<p>In practice, scientific computing users rely on the NumPy family of libraries e.g.&nbsp;NumPy, SciPy, TensorFlow, PyTorch, CuPy, JAX, etc.. The sheer proliferation of these libraries suggests that the NumPy model is getting something right. In this essay, I‚Äôll talk about what makes NumPy so effective, and where the next generation of Python numerical computing libraries (e.g.&nbsp;TensorFlow, PyTorch, JAX) seems to be headed.</p>
<h2 id="data-good-pointers-bad">Data good, pointers bad</h2>
<p>A pesky fact of computing is that computers can compute far faster than we can deliver data to compute on. In particular, data transfer <em>latency</em> is the Achille‚Äôs heel of data devices (both RAM and storage). Manufacturers disguise this weakness by emphasizing improvements in data transfer <em>throughput</em>, but latency continues to stagnate. Ultimately, this means that any chained data access patterns, where one data retrieval must be completed before the next may proceed, are the worst case for computers.</p>
<p>These worst-case chained data access patterns are unfortunately quite common ‚Äì so common that they have a name you may be familiar with: a pointer.</p>
<p>Pointers have always been slow. In the ‚Äô80s and ‚Äô90s, our hard drives were essentially optimized record players, with a read head riding on top of a spinning platter. These hard drives had physical limitations: The disk could only spin so fast without shattering, and the read head was also mechanical, limiting its movement speed. Disk seeks were slow, and the programs that were most severely affected were databases. Some ways that databases dealt with these physical limitations are:</p>
<ul>
<li>Instead of using binary trees (requiring <span>\(\log_2 N\)</span> disk seeks), B-trees with a much higher branching factor <span>\(k\)</span> were used, only requiring <span>\(\log_k N\)</span> disk seeks.</li>
<li>Indices were used to query data without having to read the full contents of each row.</li>
<li>Vertically-oriented databases optimized for read-heavy workloads (e.g.&nbsp;summary statistics over one field, across entire datasets), by reorganizing from <a href="https://en.wikipedia.org/wiki/AoS_and_SoA">arrays of structs to structs of arrays</a>. This maximized effective disk throughput, since no extraneous data was loaded.</li>
</ul>
<p>Today, compute speed is roughly <span>\(10^5 - 10^6\)</span> times faster than in 1990. Today, RAM is roughly <span>\(10^5\)</span> times faster than HDDs from 1990. I was amused and unsurprised to find that Raymond Hettinger‚Äôs <a href="https://www.youtube.com/watch?v=npw4s1QTmPg">excellent talk on the evolution of Python‚Äôs in-memory <code>dict</code> implementation</a> plays out like a brief history of early database design. Time, rather than healing things, has only worsened the compute-memory imbalance.</p>
<h2 id="numpys-optimizations">NumPy‚Äôs optimizations</h2>
<h3 id="boxing-costs">Boxing costs</h3>
<p>In many higher-level languages, raw data comes in boxes containing metadata and a pointer to the actual data. In Python, the PyObject box holds reference counts, so that the garbage collector can operate generically on all Python entities.</p>
<p>Boxing creates two sources of inefficiency:</p>
<ul>
<li>The metadata bloats the data, reducing the data density of our expensive memory.</li>
<li>The pointer indirection creates another round trip of memory retrieval latency.</li>
</ul>
<p>A NumPy array can hold many raw data within a single PyObject box, <em>provided that all of those data are of the same type</em> (int32, float32, etc.). By doing this, NumPy amortizes the cost of boxing over multiple data.</p>
<p>In <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">my previous investigations into Monte Carlo tree search</a>, a naive UCT implementation performed poorly because it instantiated millions of UCTNode objects whose sole purpose was to hold a handful of float32 values. In the optimized UCT implementation, these nodes were replaced with NumPy arrays, reducing memory usage by a factor of 30.</p>
<h3 id="attribute-lookup-function-dispatch-costs">Attribute lookup / function dispatch costs</h3>
<p>Python‚Äôs language design forces an unusually large amount of pointer chasing. I mentioned boxing as one layer of pointer indirection, but really it‚Äôs just the tip of the iceberg.</p>
<p>Python has no problem handling the following code, even though each of these multiplications invokes a completely different implementation.</p>
<pre><code>&gt;&gt;&gt; mixed_list = [1, 1.0, 'foo', ('bar',)]
&gt;&gt;&gt; for obj in mixed_list:
...     print(obj * 2)

2
2.0
'foofoo'
('bar', 'bar')</code></pre>
<p>Python accomplishes this with a minimum of two layers of pointer indirection:</p>
<ol type="1">
<li>Look up the type of the object.</li>
<li>Look up and execute the <code>__mul__</code> function from that type‚Äôs operation registry.</li>
</ol>
<p>Additional layers of pointer indirection may be required if the <code>__mul__</code> method is defined on a superclass: the chain of superclasses must be traversed, one pointer at a time, until an implementation is found.</p>
<p>Attribute lookup is similarly fraught; <code>@property</code>, <code>__getattr__</code>, and <code>__getattribute__</code> provide users with flexibility that incurs pointer chasing overhead with something as simple as executing <code>a.b</code>. Access patterns like <code>a.b.c.d</code> create exactly the chained data access patterns that are a worst-case for data retrieval latency.</p>
<p>To top it all off, merely <em>resolving</em> the object is expensive: there‚Äôs a stack of lexical scopes (local, nonlocal, then global) that are checked in order to find the variable name. Each check requires a dictionary lookup, another source of pointer indirection.</p>
<p>As the saying goes: ‚ÄúWe can solve any problem by introducing an extra level of indirection‚Ä¶ except for the problem of too many levels of indirection‚Äù. The NumPy family of libraries deals with this indirection, not by removing it, but again by sharing its cost over multiple data.</p>
<pre><code>&gt;&gt;&gt; homogenous_array = np.arange(5, dtype=np.float32)
&gt;&gt;&gt; multiply_by_two = homogenous_array * 2
&gt;&gt;&gt; print(multiply_by_two)
array([ 0.,  2.,  4.,  6.,  8.], dtype=float32)</code></pre>
<p>Sharing a single box for multiple data allows NumPy to retain the expressiveness of Python while minimizing the cost of the dynamism. As before, this works because of the additional constraint that all data in a NumPy array must have identical type.</p>
<h2 id="the-frontier-jit">The Frontier: JIT</h2>
<p>So far, we‚Äôve seen that NumPy doesn‚Äôt solve any of Python‚Äôs fundamental problems when it comes to pointer overhead. Instead, it merely puts a bandaid on the problem by sharing those costs across multiple data. It‚Äôs a pretty successful strategy ‚Äì in my hands (<a href="https://www.moderndescartes.com/essays/vectorized_pagerank">1</a>, <a href="https://www.moderndescartes.com/essays/deep_dive_mcts">2</a>), I find that NumPy can typically achieve 30-60x speedups over pure Python solutions to dense numerical code. However, given that C code typically achieves <a href="https://www.moderndescartes.com/essays/data_oriented_python/(https://benchmarksgame-team.pages.debian.net/benchmarksgame/fastest/python3-gcc.html)">100-200x performance</a> over pure Python on dense numerical code (common in scientific computing), it would be nice if we could further reduce the Python overhead.</p>
<p>Tracing <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">JITs</a> promise to do exactly this. Roughly, the strategy is to trace the execution of the code and record the pointer chasing outcomes. Then, when you call the same code snippet, reuse the recorded outcomes! NumPy amortizes Python overhead over multiple data, and JIT amortizes Python overhead over multiple function calls.</p>
<p>(I should note that I‚Äôm most familiar with the tracing JITs used by TensorFlow and JAX. <a href="https://doc.pypy.org/en/latest/">PyPy</a> and <a href="https://numba.pydata.org/">Numba</a> are two alternate JIT implementations that have a longer history, but I don‚Äôt know enough about them to treat them fairly, so my apologies to readers.)</p>
<p>Tracing unlocks many wins typically reserved for compiled languages. For example, once you have the entire trace in one place, operations can be fused together (e.g., to make use of the <a href="https://en.wikipedia.org/wiki/FMA_instruction_set">fused multiply-add instructions</a> common to most modern computers), memory layouts can be optimized, and so on. TensorFlow‚Äôs <a href="https://www.tensorflow.org/guide/graph_optimization">Grappler</a> is one such implementation of this idea. Traces can also be <a href="https://en.wikipedia.org/wiki/Backpropagation">walked backwards</a> to automatically compute derivatives. Traces can be compiled for different hardware configurations, so that the same Python code executes on CPU, GPU, and TPU. JAX can <a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html#Auto-vectorization-with-vmap">autovectorize traces</a>, adding a batch dimension to all operations. Finally, a trace can be exported in a language-agnostic manner, allowing a program defined in Python to be executed in <a href="https://www.tensorflow.org/js">Javascript</a>, <a href="https://www.tensorflow.org/tfx/guide/serving">C++</a>, or more.</p>
<p>Unsurprisingly, there‚Äôs a catch to all this. NumPy can amortize Python overhead over multiple data, but only if that data is the same type. JIT can amortize Python overhead over multiple function calls, but only if the function calls would have resulted in the same pointer chasing outcomes. Retracing the function to verify this would defeat the purpose of JIT, so instead, TensorFlow/JAX JIT uses array shape and dtype to guess at whether a trace is reusable. This heuristic is necessarily conservative, rules out otherwise legal programs, often requires unnecessarily specific shape information, and doesn‚Äôt make any guarantees against mischievous tinkering. Furthermore, data-dependent tracing is a known issue (<a href="https://pytorch.org/docs/stable/generated/torch.jit.trace.html">1</a>, <a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#python-control-flow-+-JIT">2</a>). I worked on <a href="https://blog.tensorflow.org/2018/07/autograph-converts-python-into-tensorflow-graphs.html">AutoGraph</a>, a tool to address data-dependent tracing. Still, the engineering benefits of a shared tracing infrastructure are too good to pass up. I expect to see JIT-based systems flourish in the future and iron out their user experience.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The NumPy API‚Äôs specifically addresses Python‚Äôs performance problems for the kinds of programs that scientific computing users want to write. It encourages users to write code in ways that minimize pointer overhead. Coincidentally, this way of writing code is a fruitful abstraction for tracing JITs targeting vastly parallel computing architectures like GPU and TPU. (Some people argue that <a href="https://dl.acm.org/citation.cfm?id=3321441">machine learning is stuck in a rut</a> due to this NumPy monoculture.) In any case, tracing JITs built on top of ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moderndescartes.com/essays/data_oriented_python/">https://www.moderndescartes.com/essays/data_oriented_python/</a></em></p>]]>
            </description>
            <link>https://www.moderndescartes.com/essays/data_oriented_python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504947</guid>
            <pubDate>Thu, 17 Sep 2020 14:21:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deduplicating Decklists]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24504939">thread link</a>) | @umanwizard
<br/>
September 17, 2020 | http://justinjaffray.com/deduplicating-decklists/ | <a href="https://web.archive.org/web/*/http://justinjaffray.com/deduplicating-decklists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<p><small>17 Sep 2020</small></p><p>This is not going to be my normal kind of post, it‚Äôs not very focused, and
going to be a bit rambley, as I talk about a problem I thought about one day.</p>
<p>Magic: The Gathering is a card game where players construct decks, typically of
60 cards plus a 15 card sideboard, for 75 cards total.</p>
<p>Periodically, the company that makes the game,
Wizards of the Coast (WotC) publishes a
list of decks that did well recently.
Just recently they
<a href="https://magic.gg/news/esports-update-grand-finals-formats-decklist-hub-and-more">announced</a> that they were going to start doing this for their most recent digital offering of the game.
Stay with me! This isn‚Äôt a post about card games.
This list, however, is doctored: they want the data shown to be broad and not repetitive, so they perform some amount of deduplication on the data.
This means that if two ‚Äúsimilar‚Äù decks do well, only one will be shown in the dump.
The linked article outlines what is meant by ‚Äúsimilar:‚Äù</p>
<blockquote>
<p>We will be publishing lists from Standard Ranked, Traditional Standard Ranked, Historic Ranked, and Traditional Historic Ranked play queues. Like we do for Magic Online Leagues, we will be posting an example list for each category of deck that share a minimum number of cards: at least 55 of 75 cards (across main deck and sideboard) shared in Traditional (best of three games, or Bo3) or at least 45 of 60 main deck cards shared in best of one (Bo1). All lists published will have won at least six consecutive matches.</p>
</blockquote>
<p>This seemed to me like an interesting problem!
Given a raw set of decks that did well, how could we produce such a
deduplicated set of decks?</p>
<p>At a high level, we might envision the set of decks as a bunch of points in some
space, where points are closer together if the decks are more ‚Äúsimilar‚Äù (for some
meaning of ‚Äúsimilar‚Äù we haven‚Äôt made precise yet).</p>
<p><img src="http://justinjaffray.com/images/decks1.png">
</p>
<p>With a solution being a set of decks which ‚Äúcover‚Äù the set of all other decks
(for some meaning of ‚Äúcover‚Äù we haven‚Äôt made precise yet).</p>
<p><img src="http://justinjaffray.com/images/decks2.png">
</p>
<p>To be slightly more precise, given a set \(D\) of ‚Äúdecks,‚Äù we want to find a
minimal set \(D^\prime \subseteq D\) such that every \(d \in D\) is
‚Äúsufficiently close‚Äù to some \(d^\prime \in D^\prime\).</p>
<p>Let‚Äôs define what we mean by ‚Äúdeck‚Äù and ‚Äúsufficiently close.‚Äù We can represent
decks as maps from the set of cards \(C\) to some integer \(n \in \mathbb N\)
denoting how many copies of a given card are in the deck.
We might also think of this as an \(\mathbb N\) vector indexed by \(C\), which can be denoted \(\mathbb N ^ C\).
That‚Äôs all to say, you should think of one of these decks as just a sequence of numbers denoting how many of a given card were included,
where each index corresponds to a particular card:
\[
\langle
\ldots, 4 \ldots, 2, \ldots, 1, \ldots, 4, \ldots
\rangle
\]
The sequence is finite, since there‚Äôs a finite number of Magic cards (about twenty thousand).</p>
<p>For ‚Äúcloseness‚Äù of two decks, per the statement above from WotC we are interested in the <em>total number of different cards between them</em>.
That is, the distance between two decks \(a\) and \(b\) is the sum
of the absolute difference of the quantity of each card:
\[
|a - b| = \sum_{c \in C} \left| a_c - b_c \right|.
\]
This way of measuring distance is pretty natural, and satisfies some
nice properties:</p>
<ol>
<li>\(|a - b| = 0\) if and only if \(a = b\),</li>
<li>\(|a - b| = |b - a|\) (symmetry), and</li>
<li>\(|a - c| \le |a - b| + |b - c|\) (triangle inequality).</li>
</ol>
<p>A notion of distance that satisfies properties 1, 2, and 3 happens to be called a <em>metric</em>,
and a set combined with a metric on that set is called a <em>metric space</em>.
This particular metric we‚Äôve stumbled on is actually well known, and is called
the \(\ell_1\)-norm.</p>
<p>We‚Äôll be a little abstract here, but when you hear ‚Äúmetric‚Äù you should just
think ‚Äúway of thinking about distance.‚Äù
If you look at the three properties, they‚Äôre all pretty natural things you‚Äôd want from a measure of ‚Äúdistance:‚Äù</p>
<ol>
<li>says the only thing ‚Äúzero distant‚Äù from a thing is the thing itself,</li>
<li>says that \(a\) is exactly as far from \(b\) as \(b\) is from \(a\), and</li>
<li>says two things can‚Äôt be further away than the sum of their distances to a third thing.</li>
</ol>
<p>There are lots of metrics people use for various things.
Another one is the \(\ell_2\)-norm, which you might also know as Euclidean distance:
if you have two points in Euclidean space and draw a straight line between
them, their \(\ell_2\)-distance is the length of that line.
In two-dimensional space,
\[
|a - b| = \sqrt{(a_x - b_x)^2 + (a_y - b_y)^2}
\]
Which is just the Pythagorean theorem.
For our problem we‚Äôre concerned with the \(\ell_1\)-distance, as described above.</p>
<p>Why bother introducting this abstraction?
Well, mostly I just thought it was kind of neat, but
I think making this kind of hop upwards the abstraction hierarchy can be useful to understand problems sometimes,
because it lets us make concrete the link between our actual problem, \(\ell_1\)-distance of 20,000-dimensional \(\mathbb N\)-points, weird, scary, hard to visualize, to
a problem which is easier to conceptualize: \(\ell_2\)-distance of two-dimensional points.</p>
<p><img src="http://justinjaffray.com/images/decks2.png">
</p>
<p>Seen this way, this kind of picture isn‚Äôt just a helpful mental model,
but it actually has a real, quantifiable link to the original problem we were trying to solve.</p>
<p>When thinking about this problem, it‚Äôs not completely accurate, but it‚Äôs not
too bad to just imagine the \(\ell_2\) picture above.</p>
<p>Remember that the thing we‚Äôre primarily interested in is going to be
all the points ‚Äúsufficiently close‚Äù to a given point,
where ‚Äúsufficiently close‚Äù means ‚Äúhas distance less than some \(r\).‚Äù
It turns out this thing has a name, the <em>(closed) ball of radius \(r\) centered at \(p\)</em> is
the set of points \(x\) satisfying \(|x - p| \le r\).
A ‚Äúball‚Äù is basically what you expect in most contexts, in 2D space, under the \(\ell_2\)-norm (our diagram above)
a ball is a (filled in) circle.
In 3D it‚Äôs a sphere.
In ‚Äúdeck-space,‚Äù it‚Äôs the set of decks you can make from \(p\) by adding and removing at most \(r\) cards.</p>
<p>This lets us rephrase our problem a bit more generally.
Given a metric space \(M\), a finite set of points \(P \subseteq M\), and a radius \(r\),
we want to find a set \(P^\prime \subseteq P\) such that every \(p \in P\)
is within some ball of radius \(r\) centered at some \(p^\prime \in P^\prime\).</p>
<p>So, can we solve <em>this</em> problem, in a <em>general</em> metric space, efficiently?
It turns out we actually can‚Äôt!
Why did I bother going down this road of generalization if it was going to lead to a dead-end?
Well, it‚Äôs the road I took when thinking about this problem and it‚Äôs my blog,
and also it‚Äôs actually easy to show that the problem at this level of generality is NP-hard.
As a reminder, to show this is NP-hard for metric spaces in general, we must:</p>
<ol>
<li>Fix some metric space, and</li>
<li>show that computing the size of the cover is NP-hard by showing that an
efficient solution to <em>that</em> would allow us to solve some other NP-hard
problem.</li>
</ol>
<p>Consider a graph \(G\):</p>
<p><img src="http://justinjaffray.com/images/petersen.png">
</p>
<p>The <em>dominating set problem</em> is this:
given a graph \(G = (V, E)\), find a set \(V^\prime\) of vertices such that every \(v \in V\) is adjacent to some
\(v^\prime \in V^\prime\).
That is, we want to choose some set of vertices that ‚Äúcover‚Äù all other vertices: every other vertex is adjacent to one we chose.
Finding a minimum dominating set is a well known NP-complete problem,
and already smells similar to our problem!</p>
<p>If we define a binary function on the vertices of \(G\):
\[
d(a, b) = \text{the length of the shortest path between $a$ and $b$},
\]
it turns out \(d\) is a metric (check this yourself, it‚Äôs easy)!</p>
<p>If we take this metric and set \(r\) to 1, we‚Äôve exactly recreated the
dominating set problem, which, being NP-complete, means our problem
in a general metric space is also NP-complete.
While this doesn‚Äôt mean that our original problem about Magic decks is
NP-complete (though it‚Äôs evidence that suggests this might be the case),
it does mean that any algorithm that <em>only</em> uses the properties of a metric space
probably doesn‚Äôt have an efficient solution.</p>
<p>When asked about this, my friend <a href="https://www.its.caltech.edu/~fshinko/">Forte</a>
found a nice reduction from 3SAT to the deck problem if \(r\) is at least four.
The gist of it is this:</p>
<ul>
<li>Given an instance of 3SAT with \(n\) variables \(\{v_1, \ldots, v_n\}\), let your set of ‚Äúcards‚Äù be
\(\{x_1, \ldots, x_n\} \cup \{y_1, \ldots, y_n\}\).</li>
<li>For each clause \(a \vee b \vee c\), take the vector that is 1 at \(x_i\) for the variable for \(a\) if \(a\) is not negated, and -1 if it is, and the same for \(b\) and \(c\).</li>
<li>For each variable \(v_i\), add three vectors that are all 2 at \(y_i\), and -1, 0, and 1 at \(x_i\), respectively (the choice of the one at 1 or -1 will correspond to whether we take that variable to be true or not, and the 0 one is there to ensure you need to take at least one of them).</li>
<li>This set of decks has a cover of size \(n\) (for radius 4) if and only if the 3SAT instance was satisfiable (the numbers can be tweaked to support radii larger than 4).</li>
</ul>
<p>If \(r\) is one then there actually <em>is</em> an efficient solution,
because in this case the adjacency graph is bipartite, and a dominating set of a
bipartite graph can be found in polynomial time.
I don‚Äôt know if there‚Äôs an efficient solution when \(r\) is two or three.</p>
<p>Ok, well, we are probably not going to find an efficient solution then, how about an
inefficient solution?
Wizard of the Coast must have <em>some</em> way of doing that, since they regularly
publish such deduplicated decklists.
The likely answer, I‚Äôd guess, is that they don‚Äôt fret about finding the minimum cover,
and just do something like ‚Äúoutput uncovered decks until none remain.‚Äù
Or possibly there are just few enough decklists that they have an excel spreadsheet
or something that makes sure their stated invariants are upheld. Unsure!
If you work at WotC and somehow came across this post I‚Äôd be curious to learn the real answer.</p>
<p>I can‚Äôt say how they actually do it, but there are plenty of heuristic methods
for solving this kind of thing that they might employ if you‚Äôre actually
interested in finding a good solution.</p>
<p>Techniques like
<a href="http://justinjaffray.com/branch-and-bound/">Branch and Bound</a> or simulated</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://justinjaffray.com/deduplicating-decklists/">http://justinjaffray.com/deduplicating-decklists/</a></em></p>]]>
            </description>
            <link>http://justinjaffray.com/deduplicating-decklists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504939</guid>
            <pubDate>Thu, 17 Sep 2020 14:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Retro Unix Operating System]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24504891">thread link</a>) | @elvis70
<br/>
September 17, 2020 | https://www.singlix.com/runix | <a href="https://web.archive.org/web/*/https://www.singlix.com/runix">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="390">

            
<p>
<span lang="en-us"><span face="Arial" color="#003366" size="2">
Retro UNIX 8086 v1 operating system has been developed by Erdogan Tan as a 
special purposed derivation of original UNIX v1 (by Ken Thompson, 1970-1972).</span></span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Source code has 
been ported from PDP-11 Unix assembler syntax to Microsoft Macro Assembler 
(INTEL x86 real mode) syntax and original unix source code has been modified for 
IBM PC/AT compatibility with standard ROM BIOS functions, without 
dropping/removing original UNIX v1 multitasking (time-sharing) features.</span></span></p>

<p><span lang="en-us">
<span face="Arial" size="2" color="#003366">Retro UNIX 386 v1 is 32 bit (80386 
protected mode) version of Retro UNIX 8086 v1. Retro UNIX 386 v1 operating 
system kernel and binaries have been written in assembly language syntax of 
Netwide Assembler (NASM). </span>
</span></p>

<p>
<span face="Arial" color="#003366" size="2"><span lang="en-us">Retro UNIX is a 
predecessor to SINGLIX operating system project.<br>
&nbsp;</span></span></p>
            </div></div>]]>
            </description>
            <link>https://www.singlix.com/runix</link>
            <guid isPermaLink="false">hacker-news-small-sites-24504891</guid>
            <pubDate>Thu, 17 Sep 2020 14:16:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Introduction to LLVM LibFuzzer]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24503889">thread link</a>) | @fcambus
<br/>
September 17, 2020 | https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/ | <a href="https://web.archive.org/web/*/https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p>Fuzzing is a software testing method that involves passing malformed
data as input to the program and monitoring it for misbehavior.
Today, fuzzing is one of the most effective ways to find software security problems.
In 2014, Micha≈Ç Zalewski presented American Fuzzy Lop, the first coverage
guided fuzzer. This started the modern world of fuzzing solutions and
techniques on the market.</p>

<p>In this article, we will discuss libFuzzer, a LLVM utility that allows you to integrate fuzzing
methodology into your libraries, and briefly introduce techniques to maximize the effectiveness
of catching problems.</p>



<p><a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a>
is part of the <a href="https://llvm.org/">LLVM</a>
package. It allows you to integrate the
coverage-guided fuzzer logic into your C / C++ application. A crucial feature
of libFuzzer is its close integration with
<a href="https://clang.llvm.org/docs/SanitizerCoverage.html">Sanitizer Coverage</a>
and bug detecting sanitizers, namely:
<a href="https://clang.llvm.org/docs/AddressSanitizer.html">Address Sanitizer</a>,
<a href="https://clang.llvm.org/docs/LeakSanitizer.html">Leak Sanitizer</a>,
<a href="https://clang.llvm.org/docs/MemorySanitizer.html">Memory Sanitizer</a>,
<a href="https://clang.llvm.org/docs/ThreadSanitizer.html">Thread Sanitizer</a>
and <a href="https://clang.llvm.org/docs/UndefinedBehaviorSanitizer.html">Undefined Behavior Sanitizer</a>.
The use of these projects
ensures that a wide range of memory corruption bugs and undesired
application behavior are detected. A few examples of these are: Heap/Stack/Global Out Of Bounds,
Use After Free, Use After Return, Uninitialized Memory Reads, Memory Leaks
or Uninitialized Mutex Use.</p>

<p>Everything is provided with a relatively low performance and memory overhead.
The project requires merely a functional LLVM 5.0 toolchain or newer (release date: 07 Sep 2017).</p>



<p>AFL has been on the market since 2014 and has been able to detect
over 1000 different types of software errors.  When the development of
the <a href="https://github.com/google/AFL">original AFL repository</a> stalled for
a long time, the community created a fork called
<a href="https://github.com/AFLplusplus/AFLplusplus">AFL++</a> in 2018.
The development of Google hosted project was eventually resumed
by a different team of Google employees (as Micha≈Ç Zalewski changed
his workplace). Therefore, there are two independent versions of AFL
in active development today.</p>

<p>The design of AFL is primarily based on code coverage through tracing code path execution
(with SanitizerCoverage), then providing feedback to the fuzzer (again with SanitizerCoverage callbacks),
and then using genetic algorithms to craft new inputs
(using <a href="https://en.wikipedia.org/wiki/Standard_streams">standard input</a>) to widen the code coverage.
The <a href="https://github.com/google/AFL#2-the-afl-fuzz-approach">simplified algorithm of AFL</a> is as follows:</p>

<ol>
<li>Load user-supplied initial test cases into the queue,</li>
<li>Take the next input file from the queue,</li>
<li>Attempt to trim the test case to the smallest size that doesn‚Äôt alter the measured behavior of the program,</li>
<li>Repeatedly mutate the file using a balanced and well-researched variety of traditional fuzzing strategies,</li>
<li>If any of the generated mutations results in a transition to a new state recorded by the instrumentation, add mutated output as a new entry in the queue.</li>
<li>Go to point 2.</li>
</ol>

<p>The readers might ask, why create a new fuzzer?</p>

<p>First of all, AFL was incapable of handling different types of coverage, such as
tracking the evaluation of comparison instructions (in C <code>==</code>, <code>&gt;</code>, <code>&lt;</code>, <code>!=</code>, etc.).
Next, AFL was unaware of tracking the evaluation of standard (and non-standard)
functions that return certain values depending on the input, such as
the functions for comparing strings (in C <code>strcmp()</code>, <code>strncmp()</code>, etc.).
Finally, AFL was not sufficiently flexible to integrate in environments that
accept input from a different source than the <code>standard input</code>.</p>

<p>The Google employees created a new fuzzer to overcome all the mentioned limitations
and take advantage of the bug detecting features that were already present in LLVM.
The libFuzzer philosophy was to create a tool that operates
similarly to unit testing. We write a small fuzzing program (called the ‚Äúharness‚Äù)
and create programming environment to quickly integrate it into projects
that consists of callable set of functions, typically API of a library.
The fuzzer input is provided as parameters to a regular C function (instead of stdin),
and if possible the fuzzing process is run in persistent mode that
avoids respawning it for every input.</p>

<p>The simplest integration of libFuzzer is as follows:</p>

<pre><code>// fuzz_API.cpp
extern "C" int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) {
  DoSomethingWithMyAPI(Data, Size);
  return 0;
}
</code></pre>

<p>There are two arguments to the <code>LLVMFuzzerTestOneInput()</code> function, Data and Size.
This is the buffer of a fixed length that then has to be processed by our
unit testing-like program and passed on to our API.</p>

<p>That said, libFuzzer is tailored towards:</p>

<ul>
<li>Fuzzing libraries and their APIs, rather than standalone programs.</li>
<li>The behavior should be as deterministic as possible. The same input must result in the same output.</li>
<li>The called library should avoid exiting (by <code>exit()</code> or raising signals) for valid code paths.</li>
<li>It should avoid mutating the global state as otherwise it will confuse the fuzzer.</li>
<li>It should evaluate as quickly as possibly, returning to the fuzzer.</li>
<li>It may use threads, but all newly spawned threads should be joined before returning to libFuzzer.</li>
<li>Collecting diverse sources of coverage as productive as possible.</li>
</ul>

<p>AFL is better for one type of projects and libFuzzer for another one.
For example, projects that are not designed as libraries
are hard to integrate with libFuzzer, while entry barrier to AFL testing
can be lower. It is a matter of rebuilding the software and running the fuzzer as-is.</p>

<p>As we presented above libFuzzer operates entirely inside the memory while AFL
feeds the fuzzed program with specially crafted files and passed them to its input.</p>



<p>The fuzzing process begins with the construction of test corpora.
In the case of libFuzzer, this is not necessarily true - it
can generate entirely random input. Of course, this implies practically
no code coverage at the start, and many hours of work before the first
input passing initial integrity checks is produced. Therefore, it is
worth having even a few/odd test cases to start with.</p>

<p><img src="https://raw.githubusercontent.com/Moritz-Systems/moritz_staticDir/master/fuzzing_corpora.svg" alt="Fuzzing corpora"></p>

<p>The goal of minimizing the test files is to get as much code coverage as possible
with as small input file size as possible. The relation is simple:
the smaller the file, the more executions per second can be achieved. It is worth adding that
there is also a process of minimizing a single input file. This operation aims
to remove any redundant data from the test case causing the crash to capture
what exactly happened. According to the libFuzzer documentation, the minimum speed
at which it is worthwhile to start meaningful fuzzing with a prepared body is
1000 iterations per second.</p>

<p>Crash management usually boils down to deduplicating a set of test cases by
comparing the function call stack or a stack trace. Due to limited fuzzer
information during a crash, there are different approaches to solve the
problem here. libFuzzer does not have a module for managing test cases,
and every new fuzzing job is a ‚Äúclean card‚Äù for it. The user must automate
this process by writing the report parser himself/herself.</p>

<p>Readers are encouraged to create and maintain their test corpora - in
the long run, and this is much better than using the ‚Äúready-made‚Äù
ones found on the Internet or, as mentioned earlier, generating one from scratch.
It is worth categorizing the corpus per application (in case of a single
application) or per file type - if we test many different programs, using
the same file formats.</p>

<p>The more diverse the initial test data, the better. The corpus continuously
evolves during fuzzing: you find inputs that pass through previously unknown
paths in the code. During the operation, smaller files push large files
out of the corpus (if they provide equivalent code coverage). Of course,
you find test cases that cause the program to terminate. The process of
merging the corpus is nothing more than minimizing the sum of the sets:
the corpora that started fuzzing and the newly created test cases.</p>



<p>As mentioned earlier, to use libFuzzer in your projects, you need to prepare
a lightweight library entry code.</p>

<p>Let‚Äôs see at a real world example from the LLVM libFuzzer test-suite, an
example called
<a href="https://github.com/llvm/llvm-project/blob/master/compiler-rt/test/fuzzer/SingleStrcmpTest.cpp">SingleStrcmpTest.cpp</a></p>

<pre><code>// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

// Simple test for a fuzzer. The fuzzer must find a particular string.
#include &lt;cstdint&gt;
#include &lt;cstdio&gt;
#include &lt;cstdlib&gt;
#include &lt;cstring&gt;

extern "C" int LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) {
  if (Size &gt;= 7) {
    char Copy[7];
    memcpy(Copy, Data, 6);
    Copy[6] = 0;
    if (!strcmp(Copy, "qwerty")) {
      fprintf(stderr, "BINGO\n");
      exit(1);
    }
  }
  return 0;
}
</code></pre>

<p>In this example, we have two conditions for triggering the bug (in our case, calling <code>exit(2)</code> and exiting):</p>

<ul>
<li>Size of the input buffer is larger or equal to 7 bytes.</li>
<li>The first 6 bytes store the sequence <code>"qwerty"</code>, followed by <code>\0</code>.</li>
<li>The rest of the input buffer is ignored.</li>
</ul>

<p>We note that there is no <code>main()</code> function in the program, as it is provided directly by the
libFuzzer library. Besides that, the code contains SanCov instrumentation that feedbacks the fuzzer.</p>

<p>This fuzzer uses the <code>strcmp(3)</code> function interceptors that are integrated through Address Sanitizer
into the coverage reporting mechanism in libFuzzer. Thus, there are two ways of executing the program,
with Address Sanitizer enabled and without, and we can see the difference. This also illustrates that
even if the code path is relatively simple, AFL would be totally incapable of guessing code
to break <code>strcmp(3)</code> conditionals in the code and passing random inputs, possibly even never breaking
the program in a finite time.</p>

<p>This happens inside
<a href="https://github.com/llvm/llvm-project/blob/master/compiler-rt/lib/sanitizer_common/sanitizer_common_interceptors.inc">sanitizer_common_interceptors.inc</a>:</p>

<pre><code>DECLARE_WEAK_INTERCEPTOR_HOOK(__sanitizer_weak_hook_strcmp, uptr called_pc,
                              const char *s1, const char *s2, int result)

INTERCEPTOR(int, strcmp, const char *s1, const char *s2) {
  void *ctx;
  COMMON_INTERCEPTOR_ENTER(ctx, strcmp, s1, s2);
  unsigned char c1, c2;
  uptr i;
  for (i = 0;; i++) {
    c1 = (unsigned char)s1[i];
    c2 = (unsigned char)s2[i];</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/">https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/</a></em></p>]]>
            </description>
            <link>https://www.moritz.systems/blog/an-introduction-to-llvm-libfuzzer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503889</guid>
            <pubDate>Thu, 17 Sep 2020 12:42:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I think I want to drop modern Python packages into a single program]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24503292">thread link</a>) | @pcr910303
<br/>
September 17, 2020 | https://utcc.utoronto.ca/~cks/space/blog/python/PipDropInInstall | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/python/PipDropInInstall">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>How I think I want to drop modern Python packages into a single program</h2>

	<p><small>September 16, 2020</small></p>
</div><div><p>For reasons beyond the scope of this blog entry, I'm considering
augmenting <a href="https://github.com/siebenmann/exim-attachment-logger">our Python program to log email attachment information
for Exim</a> to
use <a href="https://github.com/decalage2/oletools">oletools</a> to peer
inside MS Office files for indications of bad things. Oletools is
not packaged by Ubuntu as far as I can see, and in any case it would
be an older version, so we would need to add the oletools Python
packages ourselves.</p>

<p>The official oletools install instructions talk about using either
pip or setup.py. As a general rule, we're very strongly against
installing anything system-wide except through Ubuntu's own package
management system, and the environment our Python program runs in
doesn't really have a home directory to use pip's --user option, so
the obvious and simple pip invocations are out. I've used a setup.py
approach to install a large Python package into a specific directory
hierarchy in the past (Django), and it was a big pain, so I'd like
not to do it again.</p>

<p>(Nor do we want to learn about how to build and maintain Python
virtual environments, and then convert how we run this Python program
to use one.)</p>

<p>After some looking at pip's help output I found the '<code>pip install
--target &lt;directory&gt;</code>' option and tested it a bit. This appears to
do more or less what I want, in that it installs oletools and all
of its dependencies into the target directory. The target directory
is also littered with various metadata, so we probably don't want
to make it where the program's normal source code lives. This means
we'll need to arrange to run the program so that <code>$PYTHONPATH</code> is
set to the target directory, but that's a solvable problem.</p>

<p>(This '<code>pip install</code>' invocation does write some additional pip
metadata to your <code>$HOME</code>. Fortunately it actually does respect the
value of the <code>$HOME</code> environment variable, so I can point that at
a junk directory and then delete it afterward. Or I can make <code>$HOME</code>
point to my target directory so everything is in one place.)</p>

<p>All of this is not quite as neat and simple as dropping an <code>oletools</code>
directory tree in the program's directory, <a href="https://utcc.utoronto.ca/~cks/space/blog/python/UpdatingToRarfile30">in the way that I could
deal with needing the rarfile module</a>, but then
again oletools has a bunch of dependencies and pip handles them all
for me. I could manually copy them all into place, but that would
actually create a sufficiently cluttered program directory that I
prefer a separate directory even if it needs a <code>$PYTHONPATH</code> step.</p>

<p>(Some people will say that setting <code>$PYTHONPATH</code> means that I should
go all the way to a virtual environment, but that would be a lot
more to learn and it would be more opaque. But looking into this
a bit did lead to me learning that <a href="https://docs.python.org/3/tutorial/venv.html">Python 3 now has standard
support for virtual environments</a>.)</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/python/PipDropInInstall</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503292</guid>
            <pubDate>Thu, 17 Sep 2020 11:24:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Toward a Technological Cage for the Masses]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24503179">thread link</a>) | @sT370ma2
<br/>
September 17, 2020 | https://cheapskatesguide.org/articles/techno-cage.html | <a href="https://web.archive.org/web/*/https://cheapskatesguide.org/articles/techno-cage.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cheapskatesguide.org/articles/techno-cage.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24503179</guid>
            <pubDate>Thu, 17 Sep 2020 11:05:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Become an Ultralearner ‚Äì Scott H. Young on the Artists of Data Science Podcast]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24502962">thread link</a>) | @harpreetsahota
<br/>
September 17, 2020 | https://theartistsofdatascience.fireside.fm/scott-h-young | <a href="https://web.archive.org/web/*/https://theartistsofdatascience.fireside.fm/scott-h-young">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

    <p>Scott H Young a writer, programmer, traveler and avid reader of interesting things. For the last ten years he's been experimenting to find out how to learn and think better. Today he swings by the show and talks to us about how we can master hard skills faster!</p>

<p><strong>QUOTES</strong><br>
"What you need is not just motivation, but you need some kind of system. You need some way to channel that initial burst of enthusiasm into creating structures for your life so that you will kind of consistently re-engage with it and consistently do what you need to do to learn things better." [00:07:37] </p>

<p>"The way that mental models become useful is when you really spent a lot of time thinking about them, not when you just heard their name and kind of written them down and understood a few sentences." [00:13:54] </p>

<p>"There is a certain type of person, I guess you could say that like they do need to stop reading, they need to actually start just taking action on things and implementing things." [00:24:23] </p>

<p>"The possibilities of learning are a lot more vast than you've maybe previously considered." [01:02:17]</p>

<p><strong>CONNECT WITH SCOTT</strong><br>
Website: <a href="https://www.scotthyoung.com/" rel="nofollow">https://www.scotthyoung.com/</a></p>

<p>Twitter: <a href="https://twitter.com/scotthyoung/" rel="nofollow">https://twitter.com/scotthyoung/</a></p>

<p>Facebook: <a href="https://www.facebook.com/AuthorScottYoung/" rel="nofollow">https://www.facebook.com/AuthorScottYoung/</a></p>

<p><strong>SHOW NOTES</strong></p>

<p>[00:01:27] Introduction for our guest</p>

<p>[00:02:42] Talk to us a bit about your journey. How did you get to where you are today?</p>

<p>[00:03:30] The struggles on the path to becoming an ultralearner</p>

<p>[00:06:22] The pitfalls of motivation</p>

<p>[00:08:25] A walk down the narrow path to success</p>

<p>[00:10:47] How to make sure you‚Äôre applying effort intelligently</p>

<p>[00:13:18] The benefits and limits of mental models</p>

<p>[00:16:32] The difference between knowing the name of a thing and knowing the thing</p>

<p>[00:18:54] Scott‚Äôs favorite mental model</p>

<p>[00:21:05] Scott talks about his doodles</p>

<p>[00:23:33] Is reading making you stupid?</p>

<p>[00:26:23] The danger of learning theories and not applying them</p>

<p>[00:27:37] You need to do more than just homework</p>

<p>[00:29:27] What to do when you‚Äôre stunned into inaction</p>

<p>[00:31:39] You can‚Äôt see your brain getting buff</p>

<p>[00:33:36] Luck to destiny</p>

<p>[00:39:14] What exactly is ultralearning?</p>

<p>[00:40:27] How can we use ultralearning to accelerate, transition, or rescue our careers?</p>

<p>[00:41:46] Why is it that we procrastinate?</p>

<p>[00:42:55] Mental habits to combat procrastination</p>

<p>[00:45:40] You‚Äôre more ready than you think you are</p>

<p>[00:49:32] How can we mitigate the distraction of our mind?</p>

<p>[00:51:18] Do you have any tips for our listeners for what they could start doing today to improve the quality of their focus?</p>

<p>[00:53:27] The principle of intuition</p>

<p>[00:59:47] Building expert intuition</p>

<p>[01:02:04] What's the one thing you want people to learn from your story?</p>

<p>[01:03:25] The random round</p>




      
      
  </div></div>]]>
            </description>
            <link>https://theartistsofdatascience.fireside.fm/scott-h-young</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502962</guid>
            <pubDate>Thu, 17 Sep 2020 10:34:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sixty second stories of exceptional founders, sent out every 10 days]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24502932">thread link</a>) | @plincoln8
<br/>
September 17, 2020 | http://tareksway.com/visionaries | <a href="https://web.archive.org/web/*/http://tareksway.com/visionaries">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">	
<section>
<article id="page-5046">
<section>
<div data-token="zSb1c"><div><div><div><div>
<div>
<div>
<p><img src="https://tareksway.com/wp-content/uploads/2020/08/visionaries-logo-250-03-copy.png" alt="" width="250" height="40"></p><h5>60-SECOND STORIES OF EXCEPTIONAL FOUNDERS</h5>
<p>1 STORY EVERY 10 DAYS</p>

<h5>‚¨áÔ∏é Read an example below ‚¨áÔ∏é</h5></div></div></div></div></div></div></div><div id="posts" data-token="5gLXL"><div><div><div><div><section>
<article id="post-5202">
<p><a href="https://tareksway.com/visionaries/sew-much-hope/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="600" height="444" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2020/09/Singer-image.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2020/09/Singer-image.jpg 600w, https://tareksway.com/wp-content/uploads/2020/09/Singer-image-300x222.jpg 300w" sizes="(max-width: 600px) 100vw, 600px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/sew-much-hope/" rel="bookmark" title="Permanent Link to Sew much hope">Sew much hope</a>
</h3>
<p><span>
<i></i><i></i>
<em>September 7, 2020</em>		</span></p><p><span>Reading time: 54 seconds</span></p>
<p>In 19th century America, less than 5% of US citizens had access to electricity and the average life expectancy was 45. Life was tough and opportunities were desperately needed.</p>
</div></article>
<article id="post-2525">
<p><a href="https://tareksway.com/visionaries/a-surprise-delivery-will-shu-deliveroo-story/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="780" height="597" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-780x597.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-780x597.jpg 780w, https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-300x230.jpg 300w, https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini-768x588.jpg 768w, https://tareksway.com/wp-content/uploads/2018/05/Will-Shu-Deliveroo-mini.jpg 900w" sizes="(max-width: 780px) 100vw, 780px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/a-surprise-delivery-will-shu-deliveroo-story/" rel="bookmark" title="Permanent Link to A surprise delivery">A surprise delivery</a>
</h3>
<p><span>
<i></i><i></i>
<em>May 22, 2018</em>		</span></p><p><span>Reading time: 60 seconds</span></p>
<p>It was 2001 and American Will Shu was fresh out of college with a shiny new job at Morgan Stanley, New York. The money was awesome but the 100-hour workweek‚Ä¶ not so much. </p>
</div></article>
<article id="post-2520">
<p><a href="https://tareksway.com/visionaries/from-grade-c-to-the-skies-fedex-story/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="780" height="417" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-780x417.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-780x417.jpg 780w, https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-300x161.jpg 300w, https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx-768x411.jpg 768w, https://tareksway.com/wp-content/uploads/2018/03/Frederick-Smith-FedEx.jpg 1000w" sizes="(max-width: 780px) 100vw, 780px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/from-grade-c-to-the-skies-fedex-story/" rel="bookmark" title="Permanent Link to From grade ‚ÄúC‚Äù to the skies">From grade ‚ÄúC‚Äù to the skies</a>
</h3>
<p><span>
<i></i><i></i>
<em>March 15, 2018</em>		</span></p><p><span>Reading time: 60 seconds</span></p>
<p>Frederick Smith wasn‚Äôt exactly in love with academics. He attended Yale in 1962 and was a solid ‚ÄúC‚Äù student. When one of his courses assigned a paper, he wrote one at the last minute. He later admitted that it likely also got him a ‚ÄúC‚Äù.</p>
</div></article>
<article id="post-2516">
<p><a href="https://tareksway.com/visionaries/when-the-stars-are-misaligned-instagram-story/"> <span><span><i></i></span></span> <img onload="Wpfcll.r(this,true);" src="https://tareksway.com/wp-content/plugins/wp-fastest-cache-premium/pro/images/blank.gif" width="780" height="569" data-wpfc-original-src="https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-780x569.jpg" alt="blank" data-wpfc-original-srcset="https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-780x569.jpg 780w, https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-300x219.jpg 300w, https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497-768x560.jpg 768w, https://tareksway.com/wp-content/uploads/2018/02/22639499_1454023074646352_7020349780203143168_n900px-2-e1517504855497.jpg 897w" sizes="(max-width: 780px) 100vw, 780px"> </a></p><div>
<h3>
<a href="https://tareksway.com/visionaries/when-the-stars-are-misaligned-instagram-story/" rel="bookmark" title="Permanent Link to When the stars are misaligned">When the stars are misaligned</a>
</h3>
<p><span>
<i></i><i></i>
<em>February 4, 2018</em>		</span></p><p><span>Reading time: 59 seconds</span></p>
<p>In 2009, Kevin Systrom was working full time at a travel startup but was learning to code at night. Smartphones had only recently become ‚Äúsmart‚Äù after acquiring a camera and location capabilities.</p>
</div></article></section></div></div></div></div></div></section>
</article>
</section>
</div></div>]]>
            </description>
            <link>http://tareksway.com/visionaries</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502932</guid>
            <pubDate>Thu, 17 Sep 2020 10:28:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Is 1 World Trade Center Missing from Spider-Man?]]>
            </title>
            <description>
<![CDATA[
Score 170 | Comments 114 (<a href="https://news.ycombinator.com/item?id=24502706">thread link</a>) | @tosh
<br/>
September 17, 2020 | https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman | <a href="https://web.archive.org/web/*/https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Like many people across the world, I‚Äôm using my quarantine effectively: by catching up on all the video games I wasn‚Äôt able to play while traveling. The game at the top of my list? <a href="https://en.wikipedia.org/wiki/Spider-Man_(2018_video_game)">Spider-Man</a>, which was widely recognized as one of the top games of 2018. The game is features an open-world, which means you can travel around the game map as you see fit. And since Spider-Man, canonically, lives in real-life New York City, this means you‚Äôll spend hours webbing around an incredibly detailed version of the city that never sleeps.</p>

<p>If you‚Äôve spent any appreciable amount of time in New York, the in-game world will immediately feel familiar. The developers nailed the look and feel of the city. I found myself using real-world landmarks to orient myself as I slinged (slunged?) across Manhattan. The game leans into this realism‚Äîit even includes a challenge where you can take photos of in-game landmarks. While some are unique to the Marvel universe, like Avengers Tower and Uncle Ben‚Äôs grave, many exist in the real world and are faithfully reproduced within the game: Williamsburg/Brooklyn/Manhattan/Queensboro Bridges all make an appearance, as does Grand Central, Madison Square Garden, Saint Patrick‚Äôs Cathedral, Columbus Circle, the High Line and many more points of reference. As you‚Äôre swinging through the city, you‚Äôre treated to great views of Manhattan‚Äôs skyline, anchored by the Empire State Building, Chrysler Building, and Freedom Tower. Except, it‚Äôs <em>not</em> the Freedom Tower, despite being located in the exact same location as its real-life counterpart. Why are equally famous buildings like the Empire State Building accurately depicted, but the Freedom Tower isn‚Äôt?</p>

<p>Here‚Äôs what the ‚ÄúFreedom Tower‚Äù looks like in the game:
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-1wtc.png" alt="In-Game 1WTC">
<em>(credit to Polygon because I was too lazy to get this off my PS4 myself)</em></p>

<p>Interestingly enough, the in-game design looks to be based on Libeskind‚Äôs original design for Freedom Tower (an interesting recap of the changes can be found <a href="https://www.newyorker.com/business/currency/daniel-libeskinds-world-trade-center-change-of-heart">here</a>), lending further credence to the theory that this building is supposed to be 1WTC.</p>

<p>My curiosity was further piqued when I learned that the <em>real</em> One World Trade Center was actually in the game during a demo at E3 in June of 2018, less than 4 months before the final game was set to be released to the public!</p>

<p><img src="https://www.stevenbuccini.com/assets/spiderman/1wtc_e3.png" alt="Real-life 1WTC in Spider-Man demo from E3 2018"></p>

<p>This deadline is even closer than it appears at first glance as the <a href="https://en.wikipedia.org/wiki/Software_release_life_cycle#RTM">‚Äúgold master‚Äù</a> is finalized weeks before release date so manufacturers have time to make and distribute the game to retailers. This change must have been implemented at the 11th hour.</p>

<p>And even after swapping the model out, they featured the building prominently on the home screen in the released version of the video game!
<img src="https://www.stevenbuccini.com/assets/spiderman/spiderman-start.png" alt="Start screen">
<em>(<a href="https://www.noobfeed.com/features/1119/marvel-s-spider-man-how-do-you-access-new-game-plus-and-ultimate-difficulty">credit</a>)</em></p>

<p>So <em>why</em> isn‚Äôt the real-life 1 WTC featured? At this point, we can eliminate time and budget constraints because we know the model already existed and was implemented before launch. We know that the designers thought this building was important as it‚Äôs the first thing you notice when starting the game.</p>

<p>I wish to briefly introduce <strong>Buccini‚Äôs razor</strong>‚Äîif something fun disappears unexpectedly, the cause is litigation (real or imagined).</p>

<p>It turns out that just like an author can copyright their book and a musician can copyright a song, an architect can copyright a building. Sure enough, here‚Äôs the copyright record for One World Trade Center:
<img src="https://www.stevenbuccini.com/assets/spiderman/copyright_record.png" alt="Record from [copyright.gov](https://www.copyright.gov/); can't deeplink the record but you can find it yourself by using the document record seen above"></p>

<p>At this point, I had a strong feeling copyright law was the reason for the change. The <a href="https://www.reddit.com/r/SpidermanPS4/comments/9grnr8/freedom_tower/">internet</a> <a href="https://www.reddit.com/r/SpidermanPS4/comments/9d3paw/the_real_reason_for_the_redesigned_freedom_tower/">seems</a> <a href="https://gamefaqs.gamespot.com/boards/191635-marvels-spider-man/76988485">to</a> <a href="https://www.neogaf.com/threads/one-world-trade-center-has-been-removed-from-spider-man-ps4.1465315/">agree</a>.</p>

<p>As luck<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> would have it, there was <a href="https://www.nexsenpruet.com/professionals/jeff-reichard">an expert in architectural copyright</a> right around the corner from my house here in Greensboro! Jeffrey was kind enough to spend a few minutes of his time thinking about this not-at-all-important question.</p>

<p>First, Jeffrey noted that <em>copyrights expire</em>. Just as music and books can pass into the public domain for anyone to replicate freely, you can also build an exact replica of the Empire State Building here in the United States if you so choose. Generally, any building constructed after December 1, 1990 is covered by the <a href="https://www.djc.com/news/ae/11151054.html">Architectural Works Copyright Protection Act</a>. This would explain why older structures are replicated faithfully but the Freedom Tower is not.</p>

<p>However, this doesn‚Äôt tell the full story. As Jeffrey noted, <a href="https://www.law.cornell.edu/uscode/text/17/120">17 U.S. Code ¬ß‚ÄØ120(a)</a> ‚Äúprovides an exception related to pictorial representations of of buildings that are visible from a public place. Therefore, I am not sure exactly why they changed it in the video game.‚Äù</p>

<p>The final piece of the puzzle lies at the <a href="https://www.youtube.com/watch?v=vo5A_fuDgtk&amp;feature=youtu.be&amp;t=2666">end of the credits</a>, where the creators of the game specifically thank the owners of certain famous buildings in New York, including the Empire State Building. I found this curious as the Empire State Building should be doubly safe: it was constructed long before 1990 so it is not covered under copyright law, and it is visible from a public place so it should be exempt from any potential copyrights. But look closer. You‚Äôll see that they are acknowledging the <em>trademark</em> holders, NOT the <em>copyright</em> holders.</p>

<p><a href="https://www.photosecrets.com/buildings-copyright-and-trademarks">As this page</a> helpfully explains, applying a trademark to the building limits how the building‚Äôs image can be used in the sale of goods and services (like video games)! The credits hint that the video game creators obtained limited licenses to use the trademark, i.e. the distinctive design and appearance of the building, for certain buildings such as the Flatiron Building.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>

<p>Therefore, the most likely answer is that the distinctive shape of 1 World Trade Center is either trademarked (although I could not find it within USPTO databases) or is so recognizable that it is easily defensible via a common law trademark and the game developers were unable to secure a license to use the trademark before their deadline.</p>

<p>However, <a href="https://www.youtube.com/watch?v=gHzuHo80U2M">Sony just announced</a> an expansion to the Spider-Man video game, so perhaps the additional time and the demonstrated popularity of the first installment will help resolve this issue for the upcoming title.</p>



  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://www.stevenbuccini.com/why-1wtc-isnt-in-spiderman</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502706</guid>
            <pubDate>Thu, 17 Sep 2020 09:38:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I overslept because iOS 14 disabled my alarm]]>
            </title>
            <description>
<![CDATA[
Score 474 | Comments 306 (<a href="https://news.ycombinator.com/item?id=24502697">thread link</a>) | @dewey
<br/>
September 17, 2020 | https://annoying.technology/posts/e82ff3bde8b225e6/ | <a href="https://web.archive.org/web/*/https://annoying.technology/posts/e82ff3bde8b225e6/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://d33wubrfki0l68.cloudfront.net/9261d105b12f5c6c5928c9532d1f8721b84005cd/62d1b/media/oversleeping.jpg"></p><p>I‚Äôm using the iOS <a href="https://support.apple.com/en-us/HT208655">Bedtime</a> feature for years now. With yesterday‚Äôs iOS 14 update the feature got moved from the Clock app to the Health app. Unfortunately the migration is done by disabling your existing alarm and showing a button to open the Health app to set it up again.</p><p>I woke up late and well rested today.</p></div></div>]]>
            </description>
            <link>https://annoying.technology/posts/e82ff3bde8b225e6/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24502697</guid>
            <pubDate>Thu, 17 Sep 2020 09:36:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Infosec Apocalypse]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 97 (<a href="https://news.ycombinator.com/item?id=24501803">thread link</a>) | @chillax
<br/>
September 16, 2020 | https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html | <a href="https://web.archive.org/web/*/https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The rise of tooling for vulnerability detection combined with pressure driven by Vendor Due Diligence is causing a massive enterprise freezeout for non-mainstream technologies across the board. Of particular concern is the impact this will have on the adoption of functional programming in enterprise and small business B2B development.</p>

<p>I see now that the last 10 years were ‚Äúeasy mode‚Äù for the growth of new programming tools and infrastructure, with many new breakthrough technologies seeing rapid adoption. Languages like Node, Go and to some degree Scala saw breakaway success, not to mention all of the new cloud tech, NoSQL tech, containerization and data processing platforms along with their custom query DSLs. Other languages like Haskell saw success in small companies and skunkworks style teams solving very difficult problems.</p>

<h3 id="the-rise-of-vulnerability-scanning">The Rise of Vulnerability Scanning</h3>

<p>Just this past year I‚Äôve come to see we‚Äôre in the middle of a massive change across the industry. There are new forces at play which will calcify current software stacks and make it extremely hard for existing or new entrants to see similar success without a massive coordinated push backed by big enterprise companies. This force is the rise of InfoSec and vulnerability detection tooling.</p>

<p>Tools like <a href="https://owasp.org/www-community/Source_Code_Analysis_Tools">Blackduck, WhiteSource, Checkmarx, Veracode</a> are exploding in popularity, there are too many to list and many variations on the same theme. In the wake of so many data leaks and hacking events enterprises no longer trust their developers and SREs to take care of security, and so protocols are being implemented top down. This isn‚Äôt just on the code scanning side, there is a similar set of things going on with network scanning as well which impacts programming languages less, but similarly will calcify server stacks.</p>

<p>These tools are quickly making their way into SOC2 and SDLC policies across industry, and if your language or new infrastructure tool isn‚Äôt supported by them there‚Äôs little chance you will get the previously already tenuous approval to use them. This sets the already high bar for adoption much higher. As you might expect, vendors will only implement support for languages that meet some threshold for profitability of their tools. Not only do you need to build a modern set of tools for your language to compete, now you also need support from external vendors.</p>

<h3 id="vendor-due-diligence">Vendor Due Diligence</h3>

<p>Maybe we just cede this territory to enterprise tools with big backers like Microsoft and Oracle, we never more than a few small inroads anyway. The use of these tools is arguably a good thing overall for software security. Unfortunately, the problem cannot be sidestepped so easily, and I‚Äôm afraid this is where things look very bleak. The biggest new trend is in enforcement of these tools through Vendor Due Diligence.</p>

<p>You may not be familiar with Vendor Due Diligence if you aren‚Äôt in a manager role. The basic idea is your customer will send you a long list of technical questions about your product which you must fill out to their satisfaction before they buy your product or service. In the B2B space where I work these lists are nothing new, but have been getting longer and longer over the last 10 years, now often numbering in the hundreds of questions.</p>

<p>Most recently I‚Äôve seen more and more invasive questions being asked, some even going into how teams are organized, but important to this article is that across the board they now all ask about vulnerability scanning and now often request specific outputs for well-known vulnerability scanning tools. The implication being that if you‚Äôre not scanning with these tools they won‚Äôt buy your software, and the list of supported languages is small.</p>

<p>Any experienced technology manager sees the natural tradeoff here. When it comes down to making money versus using cool tech, cool tech will lose every time. You‚Äôre just burning money if you‚Äôre building cool things with cool tech if you know no one will buy it.</p>

<h3 id="so-what-now">So What Now?</h3>

<p>Potentially we will see a resurgence of ‚Äúcompile-to‚Äù functional programming with mainstream language targets to sidestep the issue. I suppose though that the extra build complexity and problems debugging will prevent this from ever being mainstream, not to mention that the vulnerability tools look for specific patterns and likely won‚Äôt behave well on generated code.</p>

<p>There is some hope in the form of projects like SonarCube which enables users to come together and <a href="https://github.com/SonarSource/sonar-custom-plugin-example">build custom plugins</a>. Will functional programming communities come together to build and maintain such boring tech? I somewhat doubt it. This kind of work is not what most programmers would choose to do in their off time. Similarly, vulnerability detection is unlikely to be a good target to be advanced a little at a time with academic papers. It would take true functional programming fanatics to build companies or tools dedicated to the cause. If you are interested in helping out, pay attention to the <a href="https://owasp.org/www-project-top-ten/">OWASP Top 10</a> as this list drives focus for many infosec teams.</p>

<p>Where does this leave us? If our communities do nothing then smaller B2B software operations focused mom and pop shops or consumer focused web applications likely won‚Äôt see any impact unless static analysis makes it into data protection law. Beyond these use cases FP will be relegated to tiny boxes on the back end where vulnerabilities are much less of a concern and the mathematical skills of functional programmers can bring extreme amounts of value.</p>

<p>I know there are many deeper facets I didn‚Äôt cover here, if you want to continue the discussion <a href="https://twitter.com/rickasaurus/status/1300487826782420995">join the thread on twitter</a>.</p>


  </div></div>]]>
            </description>
            <link>https://blog.rickasaurus.com/2020/08/31/The-Infosec-Apocalypse.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24501803</guid>
            <pubDate>Thu, 17 Sep 2020 06:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hacking on Bug Bounties for Four Years]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24500198">thread link</a>) | @infosecau
<br/>
September 16, 2020 | https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <ul>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#intro">Intro &amp; Motivations</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#findings">Findings</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#analysis">Analysis</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#collaboration">Collaboration</a></li>
  <li><a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/#methodology">Methodology</a></li>
</ul>

<hr>





<p>I value transparency a lot, especially when it comes to the bug bounty space. Bug bounty hunters all around the world are submitting a range of reports where the issues found span across multiple domains, often leveraging numerous techniques and methodologies. However, if you‚Äôre not already an active bug bounty hunter who has a good understanding of what a bounty program expects, or will pay out for, you have a major disadvantage compared to someone who does have this knowledge. I hope through this blog post, I can demystify the sort of issues bug bounty programs pay for.</p>

<p>The last blog post I did in this series was around four years ago, <a href="https://shubs.io/high-frequency-security-bug-hunting-120-days-120-bugs/">120 days, 120 bugs</a>. In the last four years, a lot has happened. I moved to Europe for six months, I moved interstate in Australia twice, I won a <a href="https://www.youtube.com/watch?v=VojwIY4GL-4">live hacking event</a>, I co-founded a company and helped build an <a href="https://assetnote.io/">attack surface management platform</a> with a team of people I consider family.</p>

<p>Unlike my previous blog post, I did not set myself a goal to find a bug a day. Instead, I participated in bug bounties whenever time allowed. There were many months where I found nothing at all, which often terrified me when it came to evaluating my self worth as a hacker. I also admitted to myself, that I might be a good hacker, but there is always going to be a better hacker out there, and I‚Äôve made my peace with that as a hyper-competitve person.</p>

<p>If you don‚Äôt have an excellent understanding of fundamental application security <a href="http://projects.webappsec.org/w/page/13246978/Threat%20Classification">attacks and weaknesses</a> before you approach bug bounties, in my opinion, you are wasting your time. <a href="https://portswigger.net/web-security">Practice and learn more here</a>.</p>

<p>If you‚Äôre looking for a paid, more extensive resource, check out and practice with <a href="https://pentesterlab.com/">PentesterLab</a>.</p>

<p>Participating so heavily in bug bounties has given us the knowledge at Assetnote about what security teams <em>actually</em> care about. It‚Äôs the reason we can maintain high signal when we are continuously finding exposures.</p>

<p>My primary motivation for this blog post is to educate the masses on what bug bounty programs are paying out for.</p>

<p>For example, would you know that you could submit a dangling EC2 IP (subdomain pointing to an EC2 IP that is no longer owned by the company) as a bug report without reading the proof in the pudding below? I‚Äôve been paid for this by programs, so clearly they value this sort of information.</p>

<hr>




<p>Below are all of my findings for the last four years. I‚Äôve redacted information where necessary, but by reading the titles, it should give you a good understanding of what I was reporting to programs.</p>

<table data-order="[[ 0, &quot;desc&quot; ]]" id="bugs">
<thead><tr><th title="Field #1">Date</th>
<th title="Field #2">Bug</th>
<th title="Field #3">Payout</th>
</tr></thead>
<tbody><tr>
<td>2020-09-02 14:04:11 UTC</td>
<td>[redacted] Hosted Zone Takeover</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-07-16 18:39:22 UTC</td>
<td>Spring debugging endpoints exposed leading to disclosure of all secrets via heapdump on [redacted] &amp; Account takeover by Trace</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-06-30 22:54:07 UTC</td>
<td>Blind SSRF on [redacted] through invoicing API - access to internal hosts</td>
<td>$60.00</td>
</tr>
<tr>
<td>2020-06-10 13:53:43 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:24:10 UTC</td>
<td>Full Account takeover through subdomain takeover via [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-10 13:21:57 UTC</td>
<td>Full Account takeover through subdomain takeover via  [redacted]</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-06-08 14:28:05 UTC</td>
<td>Amazon S3 Subdomain Hijack - [redacted]</td>
<td>$256.00</td>
</tr>
<tr>
<td>2020-06-08 05:29:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-06-05 16:27:42 UTC</td>
<td>Admin panel for Cisco IP Conference Station CP-7937G exposed on the internet on [redacted] IP ranges</td>
<td>$400.00</td>
</tr>
<tr>
<td>2020-06-03 21:07:51 UTC</td>
<td>Pre-auth Blind MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-03 14:18:24 UTC</td>
<td>Pre-auth MSSQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:28:50 UTC</td>
<td>Pre-auth SQL Injection affecting [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:26:58 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-06-02 15:25:08 UTC</td>
<td>RCE via arbitrary file write and path traversal [redacted]</td>
<td>$1,024.00</td>
</tr>
<tr>
<td>2020-05-18 10:12:38 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:11:58 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:06:22 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-18 10:05:20 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-05-11 18:47:54 UTC</td>
<td>Route53 Hosted Zone Takeover of [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2020-05-11 14:59:23 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-11 14:31:18 UTC</td>
<td>Account takeover through Subdomain Takeover of [redacted] (Cookie Disclosure -&gt; Account Takeover)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-05-07 01:47:49 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:58:57 UTC</td>
<td>IDOR view all [redacted]</td>
<td>$4,000.00</td>
</tr>
<tr>
<td>2020-04-29 22:57:55 UTC</td>
<td>IDOR view the [redacted]</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2020-04-24 18:19:23 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-24 18:18:45 UTC</td>
<td>Subdomain takeover of [redacted] through Heroku</td>
<td>$300.00</td>
</tr>
<tr>
<td>2020-04-23 19:45:04 UTC</td>
<td>Ability to horizontal bruteforce [redacted] accounts by abusing [redacted] sign up flow</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:44:29 UTC</td>
<td>View all metadata for any [redacted] IDOR [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:51 UTC</td>
<td>IDOR view the [redacted] for any [redacted] for today [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-22 17:42:06 UTC</td>
<td>IDOR view all [redacted] for a [redacted] [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-04-06 19:13:19 UTC</td>
<td>Facebook - Payout For [redacted]</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2020-03-07 15:12:24 UTC</td>
<td>Accessing Querybuilder on [redacted] to gain access to secrets</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2020-02-25 15:02:20 UTC</td>
<td>Subdomain takeover of [redacted] via Amazon S3</td>
<td>$750.00</td>
</tr>
<tr>
<td>2020-02-20 23:01:58 UTC</td>
<td>HTML injection, DOS of email receipts and potentially template injection within [redacted] via "Expense Info" section</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-18 14:45:40 UTC</td>
<td>Admin account bruteforce via [redacted]/libs/granite/core/content/login.html</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-15 12:24:57 UTC</td>
<td>Blind XSS via registering on [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2020-02-04 03:45:38 UTC</td>
<td>HTML Injection in email when contributing to a [redacted]</td>
<td>$700.00</td>
</tr>
<tr>
<td>2020-01-21 17:13:58 UTC</td>
<td>Ability to attach malicious attachments (of any name and of any content type) to [redacted] support staff via [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2020-01-15 11:41:59 UTC</td>
<td>No authentication required to view and delete Terraform locks at [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-12-12 16:25:11 UTC</td>
<td>[redacted] Webhook URL + object leaked in JavaScript on [redacted]</td>
<td>$3,000.00</td>
</tr>
<tr>
<td>2019-11-21 22:15:20 UTC</td>
<td>AWS &amp; Screenhero JWT Credentials from [redacted] not rotated, still working</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-17 13:44:23 UTC</td>
<td>RCE on [redacted] via IBM Aspera exploit leading to compromise of secure file storage </td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-10-15 14:29:25 UTC</td>
<td>SSO bypass on [redacted] leading to access of internal documents and portals</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-10-11 18:07:51 UTC</td>
<td>Admin access to [redacted] via guessing credentials</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-10-11 18:06:15 UTC</td>
<td>3rd party subdomain hijack - EC2 IP of [redacted] is no longer controlled by [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-09-30 16:56:50 UTC</td>
<td>Multiple server-side issues affecting [redacted] (SSRF, admin panels)</td>
<td>$2,660.00</td>
</tr>
<tr>
<td>2019-09-25 22:10:00 UTC</td>
<td>Read any [redacted] details using UUID - IDOR in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-09-10 16:17:59 UTC</td>
<td>SSRF in [redacted]</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-09-03 15:28:36 UTC</td>
<td>SSRF in [redacted]</td>
<td>$17,900.00</td>
</tr>
<tr>
<td>2019-08-29 00:43:00 UTC</td>
<td>Bypassing email whitelists for organisation signup flows on [redacted]</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-08-09 05:15:44 UTC</td>
<td>[Pre-Submission] SSRF in [redacted] (Iframely)</td>
<td>$2,970.30</td>
</tr>
<tr>
<td>2019-07-29 16:32:59 UTC</td>
<td>[Bypass] SSRF via [redacted] leads to internal network access, ability to read internal JSON responses</td>
<td>$23,000.00</td>
</tr>
<tr>
<td>2019-07-24 02:52:42 UTC</td>
<td>PHPInfo exposed at [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-07-24 02:46:02 UTC</td>
<td>SSRF on [redacted] leading to AWS breach via security credentials</td>
<td>$5,000.00</td>
</tr>
<tr>
<td>2019-07-08 14:44:23 UTC</td>
<td>Remote command execution on production [redacted] (via tsi parameter) - CVE-2017-12611</td>
<td>$2,000.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:53 UTC</td>
<td>Username/Password for Aspera and other secrets leaked in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 17:42:08 UTC</td>
<td>SSO/Authorization bypass for APIs hosted on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-12 14:45:09 UTC</td>
<td>Remote Code Execution (many endpoints) - [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-06-10 17:29:35 UTC</td>
<td>Extract email, dob, full address, federal tax ID and other PII for all leads in [redacted]</td>
<td>$1,800.00</td>
</tr>
<tr>
<td>2019-06-10 16:53:22 UTC</td>
<td>Obtain email, mobile of customers of [redacted] by iterating through Lead IDs via the API</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-10 16:52:40 UTC</td>
<td>Ability to pull out all opportunities (IDOR) extract PII for customers of [redacted]</td>
<td>$12,600.00</td>
</tr>
<tr>
<td>2019-06-07 18:51:24 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$2,500.00</td>
</tr>
<tr>
<td>2019-06-07 18:17:31 UTC</td>
<td>Blind SSRF on [redacted] through RPC call to checkAvailableLivechatAgents</td>
<td>$62.50</td>
</tr>
<tr>
<td>2019-06-07 18:07:22 UTC</td>
<td>HTML injection in emails when adding a reviewer to [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 17:42:09 UTC</td>
<td>[IDOR] Impersonating an [redacted] employee via /api/readHandler on [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-06-07 15:33:31 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted]</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:36:01 UTC</td>
<td>Zendesk Ticket IDOR / Ability to enumerate  IDs via [redacted]</td>
<td>$125.00</td>
</tr>
<tr>
<td>2019-06-07 14:24:15 UTC</td>
<td>Extract mobile number and [redacted] using only an email address, for any [redacted] user</td>
<td>$750.00</td>
</tr>
<tr>
<td>2019-06-07 14:11:20 UTC</td>
<td>HTML Injection in [redacted] receipts if printed from [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-06-07 13:56:46 UTC</td>
<td>Ability to access the airwatch admin panels and APIs in [redacted]</td>
<td>$1,000.00</td>
</tr>
<tr>
<td>2019-06-07 13:21:31 UTC</td>
<td>IDOR on [redacted] allows you to access [redacted] information for any [redacted] user</td>
<td>$250.00</td>
</tr>
<tr>
<td>2019-06-07 10:13:20 UTC</td>
<td>[redacted][IDOR] - Accessing all accounts via regression / new attack vector by abusing [redacted] (regression?)</td>
<td>$15,000.00</td>
</tr>
<tr>
<td>2019-05-22 19:33:27 UTC</td>
<td>SQLi and Authentication Bypass in [redacted]</td>
<td>$4,500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:42 UTC</td>
<td>Reflected XSS in [redacted]</td>
<td>$500.00</td>
</tr>
<tr>
<td>2019-04-29 14:14:29 UTC</td>
<td>SSRF in [redacted]</td>
<td>$1,500.00</td>
</tr>
<tr>
<td>2019-04-25 07:33:22 UTC</td>
<td>Local file disclosure through Rails CVE-2019-5418 in [redacted]</td>
<td>$100.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:54 UTC</td>
<td>SSRF - [redacted]</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-04-19 02:28:35 UTC</td>
<td>SSRF at [redacted] via the 'url' parameter</td>
<td>$4,950.00</td>
</tr>
<tr>
<td>2019-03-29 11:23:14 UTC</td>
<td>AWS S3 secrets leaked in [redacted] meeting connector ‚Ä¶</td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/">https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/09/15/hacking-on-bug-bounties-for-four-years/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24500198</guid>
            <pubDate>Thu, 17 Sep 2020 01:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What happened to all the non-programmers? (2015)]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 118 (<a href="https://news.ycombinator.com/item?id=24497470">thread link</a>) | @harporoeder
<br/>
September 16, 2020 | https://www.benkuhn.net/nonprog/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/nonprog/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This week I found myself at yet another dinner party that mysteriously contained only two people who were not involved with the tech industry in some way.</p><p>As I looked around and realized for the hundredth time that I was surrounded by people exactly like me, something inside me snapped. I downloaded the latest <a href="http://www.census.gov/acs/www/data_documentation/public_use_microdata_sample/" target="_blank">American Community Survey microdata</a>, fired up R and started calculating feverishly.</p><p>It turns out that among people who</p><ul><li>are under 35</li><li>live in San Francisco, Berkeley or Oakland</li><li>and have at least a bachelor‚Äôs degree</li></ul><p>about 10% have a computer-related occupation. An additional 5% are employed in some other capacity by a strongly computer-related industry.</p><p>That‚Äôs not <em>nearly</em> large enough to explain how saturated with coders my social groups are. I have plenty of social circles that are (at least nominally) totally different from my work: contra dancers, people interested in effective altruism, folk musicians, friends from college, and so on. And yet I keep finding myself in the middle of a programmer monoculture. Why?</p><p>As <a href="http://xkcd.com/1480/" target="_blank">Randall Munroe recently suggested</a>, suggests, maybe taking up a sport would help expose me to a broader range of people. But which one? Obviously not football, since I‚Äôm barely 150 pounds and don‚Äôt like traumatic brain injuries. Preferably a more elegant sport that doesn‚Äôt require a bunch of awkward equipment. Maybe Ultimate or rock climbing‚Äì</p><p>Wait, crap.</p><p>Part of the problem is that my taste in hobbies is influenced by class lines and subculture in ways that I hadn‚Äôt realized before.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> It turns out that even when it‚Äôs totally up to me, most of the things I‚Äôm interested in are strongly associated with a very particular band of socioeconomic status‚Äîa much smaller band than the set of ‚Äúall bachelor‚Äôs degree holders‚Äù in my ACS analysis.</p><p>This stronger selection sneaks in when I try to pick a sport based on things like ‚Äúelegance,‚Äù instead of ‚Äúsize of community‚Äù or ‚Äúwhat I‚Äôve been playing since I was five years old‚Äù or whatever other things people might pick sports for. In fact, just the fact that I‚Äôm interested in doing sports for leisure is associated with class, since it‚Äôs not something that would be so easy for, say, manual laborers or shift workers.</p><p>But I don‚Äôt think socioeconomic selection explains all of it. My parents‚Äô friends were similarly selected, but they didn‚Äôt all have <em>literally the same job</em>, and the ones that did were usually coworkers‚Äînot people they had met socially who bizarrely all happened to work on the same stuff. My friends in other occupations with similar base rates‚Äîsay, school teachers‚Äîdon‚Äôt wonder where all the non-teachers are at social events. And I don‚Äôt even feel like I‚Äôm from a similar subculture to many programmers. What else could be going on?</p><ul><li><p>Maybe that crackpot-sounding stuff about the ‚Äúprogrammer‚Äôs brain‚Äù actually has something to it. Maybe programmers are all drawn to the same activities because those activities are friendly to the programmer‚Äôs innately logical, systematizing and abstract habits of thought.</p></li><li><p>Programmers could talk about programming too much, or smell bad, or something, so people from other professions are less likely to put up with them at social events.</p></li><li><p>Perhaps the various subcultures of programmers are closer together, and more distinct from other subcultures, than I perceive. Maybe ‚Äúprogrammer culture‚Äù is less analogous to other single professions and more analogous to ‚Äúacademic culture‚Äù or ‚Äúhippie culture,‚Äù where it would be more reasonable to have that be your entire social group.</p></li><li><p>Maybe I miscalculated from the ACS data and there are actually way more programmers than the 10% number suggests.</p></li></ul><p>Unless I‚Äôve miscalculated pretty badly, though, it‚Äôs clear that these social bubble effects are way stronger and more tenacious than I would have expected. And this is just one of the axes where it‚Äôs <em>obvious</em> that all the variance is being selected out. I wonder what more subtle facts are being selected for this strongly in my social groups?</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>When I lived in Boston, the people I associated with were determined mostly by my parents or my private high school/college, which is plenty enough to explain a monoculture without getting into class effects. <a href="#fnref:1" role="doc-backlink">‚Ü©Ô∏é</a></p></li></ol></section></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/nonprog/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24497470</guid>
            <pubDate>Wed, 16 Sep 2020 20:33:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rockset: 1B Events in a Day with 1-Second Data Latency]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24497202">thread link</a>) | @box2A1
<br/>
September 16, 2020 | https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/ | <a href="https://web.archive.org/web/*/https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3>YADB (Yet Another Database Benchmark)</h3>
<p>The world has a plethora of database benchmarks, starting with the <a href="http://pages.cs.wisc.edu/~dewitt/includes/benchmarking/vldb83.pdf">Wisconsin Benchmark</a> which is my favorite. Firstly, that benchmark was from Dr David Dewitt, who taught me Database Internals when I was a graduate student at University of Wisconsin. Secondly, it is probably the earliest conference paper (circa 1983) that I ever read. And thirdly, the results of this paper displeased Larry Ellison so much that he inserted a clause in newer Oracle releases to prevent researchers from benchmarking the Oracle database.</p>
<p>The Wisconsin paper clearly describes how a benchmark measures very specific features of databases, so it follows that as database capabilities evolve, new benchmarks are needed. If you have a database that has new behavior not found in existing databases, then it is clear that you need a new benchmark to measure this new behavior of the database.</p>
<p>Today, we are introducing a new benchmark, RockBench, that does just this. RockBench is designed to measure the most important characteristics of a real-time database.</p>
<h3>What Is a Real-Time Database?</h3>
<p>A real-time database is one that can sustain a high write rate of new incoming data, while at the same time allowing applications to make queries based on the freshest of data. It is different from a transactional database where the most significant characteristic is the ability to perform transactions, which is why TPC-C is the most cited benchmark for transactional databases.</p>
<p>In typical database ACID parlance, a real-time database provides Atomicity and Durability of updates just like most other databases. It supports an eventual Consistency model, where updates show up in query results as quickly as possible. This time lag is referred to as data latency.  A real-time database is one that is designed to minimize data latency.</p>
<p>Different applications need different data latencies, and the ability to measure data latency allows users to choose one real-time database configuration over another based on the needs of their application. RockBench is the only benchmark at present that measures the data latency of a database at varying write rates.</p>
<p>Data latency is different from query latency, which is what is typically used to benchmark transactional databases. We posit that one of the distinguishing factors that differentiates one real-time database from another is data latency. We designed a benchmark called <a href="https://github.com/rockset/rockbench">RockBench</a> that can measure the data latency of a real-time database.</p>
<h3>Why Is This Benchmark Relevant in the Real World?</h3>
<p><strong>Real-time analytics use cases.</strong> There are many decision-making systems that leverage large volumes of streaming data to make quick decisions. When a truck arrives at a loading dock, a fleet management system would need to produce a loading list for the truck by examining delivery deadlines, delay-charge estimates, weather forecasts and modeling of other trucks that are arriving in the near future. This type of decision-making system would use a real-time database. Similarly, a product team would look at product clickstreams and user feedback in real time to determine which feature flags to set in the product. The volume of incoming click logs is very high and the time to gather insights from this data is low. This is another use case for a real-time database. Such use cases are becoming the norm these days, which is why measuring the data latency of a real-time database is useful. It allows users to pick the right database for their needs based on how quickly they want to extract insights from their data streams.</p>
<p><strong>High write rates.</strong> The most critical measurement for a real-time database is the write rate it can sustain while supporting queries at the same time. The write rate could be bursty or periodic, depending on the time of the day or the day of the week. This behavior is like a streaming logging system that can take in large volumes of writes. However, one difference between a real-time database and a streaming logging system is that the database provides a query API that can perform random queries on the event stream. With writing and querying of data, there is always an inherent tradeoff between high write rates and the visibility of data in queries, and this is precisely what RockBench measures.</p>
<p><strong>Semi-structured data.</strong> Most of real-life decision-making data is in semi-structured form, e.g. JSON, XML or CSV. New fields get added to the schema and older fields are dropped. The same field can have multi-typed values. Some fields have deeply nested objects. Before the advent of real-time databases, a user would typically use a data pipeline to clean and homogenize all the fields, flatten nested fields, denormalize nested objects and then write it out it to a data warehouse like Redshift or Snowflake. The data warehouse is then used to gather insights from their data. These data pipelines add to data latency. On the other hand, a real-time database eliminates the need for some of these data pipelines and simultaneously offers lower data latency. This benchmark uses data in JSON format to simulate more of these types of real-life scenarios.</p>
<h3>Overview of RockBench</h3>
<p>RockBench comprises a Data Generator and a Data Latency Evaluator. The Data Generator simulates a real-life event workload, where every generated event is in JSON format and schemas can change frequently. The Data Generator produces events at various write rates and writes them to the database. The Data Latency Evaluator queries the database periodically and outputs a metric that measures the data latency at that instant.  A user can vary the write rate and measure the observed data latency of the system.</p>
<p><img src="https://images.ctfassets.net/1d31s1aajogl/4hh0BRpcquIlrm5cK2ivEf/20edd90be6b0660e2c1689b0da67965d/rockbench-database-test.png" alt="rockbench-database-test">
<em>Multiple instances of the benchmark connect to the database under test</em></p>
<p>The <a href="https://rockset.com/Evaluating_Data_Latency_for_Real_Time_Databases.pdf">Evaluating Data Latency for Real-Time Databases</a> white paper provides a detailed description of the benchmark. The size of an event is chosen to be around 1K bytes, which is what we found to be the sweet spot for many real-life systems. Each event has nested objects and arrays inside it. We looked at a lot of publicly available events streams like Twitter events, stock market events and online gaming events to pick these characteristics of the data that this benchmark uses.</p>
<h3>Results of Running RockBench on Rockset</h3>
<p>Before we analyze the results of the benchmark, let‚Äôs refresh our memory of Rockset‚Äôs <a href="https://rockset.com/blog/aggregator-leaf-tailer-an-architecture-for-live-analytics-on-event-streams/">Aggregator Leaf Tailer</a> (ALT) architecture. The ALT architecture allows Rockset to scale ingest compute and query compute separately. This benchmark measures the speed of indexing in Rockset‚Äôs <a href="https://rockset.com/blog/converged-indexing-the-secret-sauce-behind-rocksets-fast-queries/">Converged Index‚Ñ¢</a>, which maintains an inverted index, a columnar store and a record store on all fields. The benefit of building all indices is that queries are fast because it can leverage any of these pre-built indices. The data latency that we record in our benchmarking is a measure of how fast Rockset can index streaming data. Complete results can be found <a href="https://rockset.com/Evaluating_Data_Latency_for_Real_Time_Databases.pdf">here</a>.</p>
<p><img src="https://images.ctfassets.net/1d31s1aajogl/1q7BFjCAsnbWNb10jzBnlo/3c56104981e2e264b7a788c36962270c/rockbench-rockset-4xl-50.png" alt="rockbench-rockset-4xl-50">
<em>Rockset p50 and p95 data latency using a 4XLarge Virtual Instance at a batch size of 50</em></p>
<p>The first observation is that a Rockset 4XLarge Virtual Instance can support a billion events flowing in every day (approx. 12K events/sec) while keeping the data latency to under 1 second. This write rate is sufficient to support a variety of use cases, ranging from fleet management operations to handling events generated from sensors.</p>
<p>The second observation is that if you have to support a higher write rate, it is as simple as upgrading to the next higher Rockset Virtual Instance. Rockset is scalable, and depending on the amount of resources you dedicate, you can reduce your data latency or support higher write rates. Extrapolating from these benchmark results: an online gaming system that produces 40K events/sec and requires a data latency of 1 second may be satisfied with a Rockset 16XLarge Virtual Instance. Also, migrating from one Rockset Virtual Instance to another does not cause any downtime, which makes it easy for users to migrate from one instance to another.</p>
<p>The third observation is that if you are running on a fixed Rockset Virtual Instance and your write rate increases, the benchmark results show that there is a gradual and linear increase in the data latency until CPU resources are saturated. In all these cases, the compute resource on the leaf is the bottleneck, because this compute is the resource that makes recently written data queryable immediately. Rockset delegates compaction CPU to <a href="https://rockset.com/blog/remote-compactions-in-rocksdb-cloud">remote compactors</a>, but some minimum CPU is still needed on the leaves to copy files to and from cloud storage.</p>
<p>Rockset uses a specialized <a href="https://rockset.com/blog/optimizing-bulk-load-in-rocksdb/">bulk-load</a> mechanism to index stationary data and that can load data at terabytes/hour, but this benchmark is not to measure that functionality. This benchmark is purposely used to measure the data latency of high-velocity data when new data is arriving at a fast rate and needs to be immediately queried.</p>
<h3>Futures</h3>
<p>In its current form, the workload generator issues writes at a specified constant rate, but one of the improvements that users have requested is to make this benchmark simulate a bursty write rate. Another improvement is to add an overwrite feature that overwrites some documents that already exists in the database. Yet another requested feature is to vary the schema of some of the generated documents so that some fields are sparse.</p>
<p>RockBench is designed to be extensible, and we hope that developers in the database community would contribute code to make this benchmark run on other real-time databases as well.</p>
<p>I am thrilled to see the results of RockBench on Rockset. It demonstrates the value of real-time databases, like Rockset, in enabling real-time analytics by supporting streaming ingest of thousands of events per second while keeping data latencies in the low seconds. My hope is that RockBench will provide developers an essential tool for measuring data latency and selecting the appropriate real-time database configuration for their application requirements.</p>
<p><strong>Resources:</strong></p>
<ul>
<li><a href="https://github.com/rockset/rockbench">RockBench GitHub repository</a></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/">https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/</a></em></p>]]>
            </description>
            <link>https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24497202</guid>
            <pubDate>Wed, 16 Sep 2020 20:15:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I suspect many task deadlines are designed to force engineers to work for free]]>
            </title>
            <description>
<![CDATA[
Score 263 | Comments 186 (<a href="https://news.ycombinator.com/item?id=24496219">thread link</a>) | @sT370ma2
<br/>
September 16, 2020 | http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html | <a href="https://web.archive.org/web/*/http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://misc-stuff.terraaeon.com/articles/engineering-deadlines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24496219</guid>
            <pubDate>Wed, 16 Sep 2020 19:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[433% Keyboard]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24495046">thread link</a>) | @_salmon
<br/>
September 16, 2020 | https://relivesight.com/projects/433/ | <a href="https://web.archive.org/web/*/https://relivesight.com/projects/433/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

            <h2>433% Keyboard</h2>
            <p>‚Äî„Äå0X://Explanation„Äç<br>
            IT IS FINALLY (mostly) COMPLETED. If anyone has ever heard directly from God Himself, the conception of this keyboard was definitely the message. 450 keys of solid non-mx-browness and
            433% the size of a normal full size, what more could you ask for? This keyboard fits 2 (two) full football fields on it {diagram on page 9 of your textbooks}. and um yeah thats kinda it idk can you see it there isnt much to say.

            {and yes for anyone who is new, i know the images load slow, im using some jankery just bear with it plz and ty}
            </p>
            <p><a target="_blank" href="https://www.reddit.com/r/MechanicalKeyboards/comments/it7a0p/i_present_my_433_ortho_endgame_is_only_a_lie_if/">reddit post</a> - thanks for 13.1k upvotes and 58 awards &lt;3</p>
              <p><a id="back" href="https://relivesight.com/ongoing/">back a page</a></p>
              <p><img src="https://drive.google.com/uc?export=view&amp;id=1OKPmow5-rwRyFS-_zcOYHDpGRSjjKVej" width="500px"></p><p>Specs:</p>
        <ul>
          <li>PCB: ScrabblePad</li>
          <li>Microcontrollers: Teensy2.0++(x2)</li>
          <li>Switches: Gateron Yellows</li>
          <li>Keycaps: xda 9009 from kpreublic (98), dsa dark gray blanks (90), xda light grey blanks (12), cherry relegenadble keycaps (tipro rebrand) (120), dsa "retro beige" (26), cherry beige keycaps (52), dsa black blanks (38), and stroke and structure set keycaps (14)</li>
        </ul>
            
              
             <p>i've acquired all the materials, i intend to 3d print some "feet" for this board and maybe tent it a bit, here are the pcbs:</p>
             <p><img src="https://drive.google.com/uc?export=view&amp;id=1uWil1XZH2ctQViab6xnskC4BIYivAWeG" width="500px"></p><p>this one should be pretty straight forward, i just need some free time to build it. two "scrabblepads" by donutcables btw.</p>
             
             <p>the dautning task beings, and spoiler: i finish it all in one weekend (kinda). well you know what they say, show dont tell (and my hands ache from this build) so heres some pics of the board while i soldered the 450 diodes, switches, etc:</p>
             <p><img src="https://drive.google.com/uc?export=view&amp;id=1tlF20EdGLjFh_IJowFcZ7qy07jmj-w6s" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1ykB1evyrh2UrNnkfX7z3bR4keEpgLMhG" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1Ws5bUOHTzRmT6kGS_D4HoMzPZvrE81Hj" width="300px">
             <img src="https://drive.google.com/uc?export=view&amp;id=1pRKCnqxWew30dc5mC4INyfA1pUxMgCOr" width="300px"></p><p>wow! what only took you a couple seconds to look at took me a couple dozen hours, astonishing. well now the simple part (i so naively thought) choosing keycaps!
               lets just skip all of my indecsision and skip to what i finally settled on. a xda 9009 set, dsa dark gray blanks, xda light grey blanks, cherry relegenadble keycaps (tipro rebrand), dsa "retro beige", cherry beige keycaps, dsa black blanks, and stroke and structure set keycaps.
            
              </p>
               <p><img src="https://drive.google.com/uc?export=view&amp;id=1CYfMDgvnOXaQEQv89GwsMRd-nMT4Tl66" width="400px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1SxTfFaIz_Mv9gzYm4qFMZsB8LYYQCbD-" width="200px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1jSCz7vcr3Nc26TKKhYej4uAPvN6-HPih" width="500px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1h-45yK6HDq2VmC7mxl1NMAaWgQM8IGI_" width="500px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1q99gN9PK-m8a6wxMlPnEBEt9rFs3SRws" width="500px"></p><p>alot of cutting and frusturating placement of the paper (relegndable caps) later and its done! here's this board next to some other favorites of mine:</p>
               <p><img src="https://drive.google.com/uc?export=view&amp;id=1iRszdMNP3aFmEIkVCuBkOScToGBlz_Gd" width="300px">
               <img src="https://drive.google.com/uc?export=view&amp;id=1tkfGJU4lo1WCN7LOQSl1MJhVLyvJe55L" width="300px"></p><p>sadly i cant officially call this project done until i add the 3d printed feet and finish the qmk, tho fun fact: i typed this whole post on the board~
                 its honestly not as hard as i thought it would be to switch, its still 123897421987 times better than any staggered non split torture. anyway thanks for reading so far! its been fun~
               </p>

            

   <p><a id="back" href="https://relivesight.com/ongoing/">back a page</a></p>
   <p>‚îà ren ‚Äã‚ô°</p>


  </div></div>]]>
            </description>
            <link>https://relivesight.com/projects/433/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24495046</guid>
            <pubDate>Wed, 16 Sep 2020 17:36:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Large-scale Abuse of Contact Discovery in Mobile Messengers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 282 | Comments 84 (<a href="https://news.ycombinator.com/item?id=24494505">thread link</a>) | @sizzle
<br/>
September 16, 2020 | https://encrypto.de/papers/HWSDS21.pdf | <a href="https://web.archive.org/web/*/https://encrypto.de/papers/HWSDS21.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://encrypto.de/papers/HWSDS21.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24494505</guid>
            <pubDate>Wed, 16 Sep 2020 16:51:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BPF based live debugging for Go/C++/Rust in prod with no code changes]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24494486">thread link</a>) | @roopakv
<br/>
September 16, 2020 | https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/ | <a href="https://web.archive.org/web/*/https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>This is the first in a series of posts describing how we can debug applications in production using eBPF, without recompilation/redeployment. This post describes how to use <a href="https://github.com/iovisor/gobpf" target="_blank" rel="noopener noreferrer">gobpf</a> and uprobes to build a function argument tracer for Go applications. This technique is also extendable to other compiled languages such as C++, Rust, etc. The next sets of posts in this series will discuss using eBPF for tracing HTTP/gRPC data, SSL, etc.</p><p>When debugging, we are typically interested in capturing the state of a program. This allows us to examine what the application is doing and determine where the bug is located in our code. A simple way to observe state is to use a debugger to capture function arguments. For Go applications, we often use Delve or gdb.</p><p>Delve and gdb work well for debugging in a development environment, but they are not often used in production. The features that make these debuggers powerful can also make them undesirable to use in production systems. Debuggers can cause significant interruption to the program and even allow mutation of state which might lead to unexpected failures of production software.</p><p>To more cleanly capture function arguments, we will explore using enhanced BPF (<a href="https://ebpf.io/" target="_blank" rel="noopener noreferrer">eBPF</a>), which is available in Linux 4.x+, and the higher level Go library <a href="https://github.com/iovisor/gobpf" target="_blank" rel="noopener noreferrer">gobpf</a>.</p><p>Extended BPF (eBPF) is a kernel technology that is available in Linux 4.x+. You can think of it as a lightweight sandboxed VM that runs inside of the Linux kernel and can provide verified access to kernel memory.</p><p>As shown in the overview below, eBPF allows the kernel to run BPF bytecode. While the front-end language used can vary, it is often a restricted subset of C. Typically the C code is first compiled to the BPF bytecode using Clang, then the bytecode is verified to make sure it's safe to execute. These strict verifications guarantee that the machine code will not intentionally or accidentally compromise the Linux kernel, and that the BPF probe will execute in a bounded number of instructions every time it is triggered. These guarantees enable eBPF to be used in performance-critical workloads like packet filtering, networking monitoring, etc.</p><p>Functionally, eBPF allows you to run restricted C code upon some event (eg. timer, network event or a function call). When triggered on a function call we call these functions probes and they can be used to either run on a function call within the kernel (kprobes), or a function call in a userspace program (uprobes). This post focuses on using uprobes to allow dynamic tracing of function arguments.</p><p>Uprobes allow you to intercept a userspace program by inserting a debug trap instruction (<code>int3</code> on an x86) that triggers a soft-interrupt . This is also <a href="https://eli.thegreenplace.net/2011/01/27/how-debuggers-work-part-2-breakpoints" target="_blank" rel="noopener noreferrer">how debuggers work</a>. The flow for an uprobe is essentially the same as any other BPF program and is summarized in the diagram below. The compiled and verified BPF program is executed as part of a uprobe, and the results can be written into a buffer.</p><div><figure>
    <span>
      <span></span>
  <p><img alt="BPF for tracing (from Brendan Gregg)" title="BPF for tracing (from Brendan Gregg)" src="https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/073a0/bpf-tracing.jpg" srcset="https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/8356d/bpf-tracing.jpg 259w,https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/bc760/bpf-tracing.jpg 518w,https://blog.pixielabs.ai/static/a11d6d9cb78e055d59136a97665907d3/073a0/bpf-tracing.jpg 610w" sizes="(max-width: 610px) 100vw, 610px" loading="lazy"></p>
    </span>
    <figcaption>BPF for tracing (from Brendan Gregg)</figcaption>
  </figure></div><p>Let's see how uprobes actually function. To deploy uprobes and capture function arguments, we will be using <a href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/app.go" target="_blank" rel="noopener noreferrer">this</a> simple demo application. The relevant parts of this Go program are shown below.</p><p><code>main()</code> is a simple HTTP server that exposes a single <em>GET</em> endpoint on <em>/e</em>, which computes Euler's number (<strong>e</strong>) using an iterative approximation. <code>computeE</code> takes in a single query param(<em>iters</em>), which specifies the number of iterations to run for the approximation. The more iterations, the more accurate the approximation, at the cost of compute cycles. It's not essential to understand the math behind the function. We are just interested in tracing the arguments of any invocation of <code>computeE</code>.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>To understand how uprobes work, let's look at how symbols are tracked inside binaries. Since uprobes work by inserting a debug trap instruction, we need to get the address where the function is located. Go binaries on Linux use ELF to store debug info. This information is available, even in optimized binaries, unless debug data has been stripped. We can use the command <code>objdump</code> to examine the symbols in the binary:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>From the output, we know that the function <code>computeE</code> is located at address <code>0x6609a0</code>. To look at the instructions around it, we can ask <code>objdump</code> to disassemble to binary (done by adding <code>-d</code>). The disassembled code looks like:</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>From this we can see what happens when <code>computeE</code> is called. The first instruction is <code>mov 0x8(%rsp),%rax</code>. This moves the content offset <code>0x8</code> from the <code>rsp</code> register to the <code>rax</code> register. This is actually the input argument <code>iterations</code> above; Go's arguments are passed on the stack.</p><p>With this information in mind, we are now ready to dive in and write code to trace the arguments for <code>computeE</code>.</p><p>To capture the events, we need to register a uprobe function and have a userspace function that can read the output. A diagram of this is shown below. We will write a binary called <code>tracer</code> that is responsible for registering the BPF code and reading the results of the BPF code. As shown, the uprobe will simply write to a perf-buffer, a linux kernel data structure used for perf events.</p><div><figure><img src="https://blog.pixielabs.ai/static/9f8b26f88f9b132440ef1b9d48b5a341/app-tracer.svg"><figcaption>High-level overview showing the Tracer binary listening to perf events generated from the App</figcaption></figure></div><p>Now that we understand the pieces involved, let's look into the details of what happens when we add an uprobe. The diagram below shows how the binary is modified by the Linux kernel with an uprobe. The soft-interrupt instruction (<code>int3</code>) is inserted as the first instruction in <code>main.computeE</code>. This causes a soft-interrupt, allowing the Linux kernel to execute our BPF function. We then write the arguments to the perf-buffer, which is asynchronously read by the tracer.</p><div><figure><img src="https://blog.pixielabs.ai/static/87301c7282e8f8270fee2afb9fe85c81/app-trace.svg"><figcaption>Details of how a debug trap instruction is used call a BPF program</figcaption></figure></div><p>The BPF function for this is relatively simple; the C code is shown below. We register this function so that it's invoked every time <code>main.computeE</code> is called. Once it's called, we simply read the function argument and write that the perf buffer. Lots of boilerplate is required to set up the buffers, etc. and this can be found in the complete example <a href="https://github.com/pixie-labs/pixie/blob/main/demos/simple-gotracing/trace_example/trace.go" target="_blank" rel="noopener noreferrer">here</a>.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Now we have a fully functioning end-to-end argument tracer for the <code>main.computeE</code> function! The results of this are shown in the video clip below.</p><div><figure><img src="https://blog.pixielabs.ai/static/4de8713a5b05e1f9132350f333572174/e2e-demo.gif"><figcaption>End-to-End demo</figcaption></figure></div><p>One of the cool things is that we can actually use GDB to see the modifications made to the binary. Here we dump out the instructions at the <code>0x6609a0</code> address, before running our tracer binary.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Here it is after we run the tracer binary. We can clearly see that the first instruction is now <code>int3</code>.</p><pre><div><p><img src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIiIGhlaWdodD0iMzIiIHZpZXdCb3g9IjAgMCAzMiAzMiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZmlsbC1ydWxlPSJldmVub2RkIiBjbGlwLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0yMC4zMzYgNUg4LjA0OEM2LjkxNjQ4IDUgNiA1LjkxNjQ4IDYgNy4wNDhWMjEuMzg0SDguMDQ4VjcuMDQ4SDIwLjMzNlY1Wk0yMy40MDggOS4wOTZIMTIuMTQ0QzExLjAxMjUgOS4wOTYgMTAuMDk2IDEwLjAxMjUgMTAuMDk2IDExLjE0NFYyNS40OEMxMC4wOTYgMjYuNjExNSAxMS4wMTI1IDI3LjUyOCAxMi4xNDQgMjcuNTI4SDIzLjQwOEMyNC41Mzk1IDI3LjUyOCAyNS40NTYgMjYuNjExNSAyNS40NTYgMjUuNDhWMTEuMTQ0QzI1LjQ1NiAxMC4wMTI1IDI0LjUzOTUgOS4wOTYgMjMuNDA4IDkuMDk2Wk0xMi4xNDQgMjUuNDhIMjMuNDA4VjExLjE0NEgxMi4xNDRWMjUuNDhaIiBmaWxsPSIjNEE0QzRGIi8+Cjwvc3ZnPgo=" alt="" title="Copy to clipboard" aria-label="copy"></p></div></pre><p>Although we hardcoded the tracer for this particular example, it's possible to make this process generalizable. Many aspects of Go, such as nested pointers, interfaces, channels, etc. make this process challenging, but solving these problems allows for another instrumentation mode not available in existing systems. Also, since this process works at the binary level, it can be used with natively compiled binaries for other languages (C++, Rust, etc.). We just need to account for the differences in their respective ABI's.</p><p>BPF tracing using uprobes comes with its own set of pros and cons. It's beneficial to use BPF when we need observability into the binary state, even when running in environments where attaching a debugger will be problematic or harmful (ex. production binaries). The biggest downside is the code required to get even trivial visibility into the application state. While BPF code is relatively accessible, it's complex to write and maintain. Without substantial high-level tooling, it's unlikely this can be used for generic debugging.</p><div><figure><img src="https://blog.pixielabs.ai/static/12645e1cb582041085ede1877e97c812/wavingnaut.svg"><figcaption></figcaption></figure></div><p>Go dynamic logging is something we are working on at Pixie. You can checkout <a href="https://docs.pixielabs.ai/tutorials/simple-go-tracing/" target="_blank" rel="noopener noreferrer">this</a> to see how Pixie traces Go applications running on K8s clusters. If this post's contents are interesting, please give <a href="https://pixielabs.ai/" target="_blank" rel="noopener noreferrer">Pixie</a> a try, or check out our <a href="https://pixielabs.ai/career" target="_blank" rel="noopener noreferrer">open positions</a>.</p><h2>References</h2><ul><li><a href="https://github.com/iovisor/gobpf" target="_blank" rel="noopener noreferrer">iovisor/gobpf</a></li><li><a href="https://github.com/iovisor/bcc" target="_blank" rel="noopener noreferrer">iovisor/bcc</a></li><li>GoPoland Meetup <a href="https://www.youtube.com/watch?v=SlcBq3xDc7I" target="_blank" rel="noopener noreferrer">Video</a> + <a href="https://www.slideshare.net/ZainAsgar/go-logging-using-ebpf" target="_blank" rel="noopener noreferrer">Slides</a></li><li>GoBangalore Meetup <a href="https://www.youtube.com/watch?v=0mxUU_--dDM&amp;feature=youtu.be" target="_blank" rel="noopener noreferrer">Video</a>. Checkout Below:</li></ul><iframe width="560" height="315" src="https://www.youtube.com/embed/0mxUU_--dDM?start=15" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></div></div></div>]]>
            </description>
            <link>https://blog.pixielabs.ai/blog/ebpf-function-tracing/post/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24494486</guid>
            <pubDate>Wed, 16 Sep 2020 16:50:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern mindfulness meditation has lost its beating communal heart]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24494021">thread link</a>) | @canada_random1
<br/>
September 16, 2020 | https://psyche.co/ideas/modern-mindfulness-meditation-has-lost-its-beating-communal-heart | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/modern-mindfulness-meditation-has-lost-its-beating-communal-heart">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>In our tumultuous</strong> present, mindfulness and meditation can seem like attractive ways to process difficult feelings and emotions. Meditative practices have long been a support strategy for traditional cultures facing collective trauma, and a method for bringing individuals and communities into mutual solidarity. Tibetan refugees, who have lived through cultural genocide, use meditation and ritual to join with their spiritual ancestors. In this way, they experience their own suffering as a doorway into compassion for others.</p>
<p>Tibetan culture, through its resilience, kindness, intelligence and joy, has inspired millions of people in the West to take up meditation. But are the practices that many of us turn to the same in substance as the rituals that other communities have relied upon for centuries? In most cases, the answer is no: they have a profoundly different orientation and, significantly, they lack the crucial communal features that make traditional meditation so vital and nurturing for the brain and body. In fact, modern meditation can often work against us √¢‚Ç¨‚Äú reinforcing our separation from others, rather than strengthening the social bonds that are needed to overcome adversity and barriers to compassion.</p>
<p>The traditional and modern approaches to meditation are shaped by two distinct visions of the person. Those in traditional contemplative cultures typically understand persons to be constituted by their relationship to others, as the historian David McMahan <a href="https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195183276.001.0001/acprof-9780195183276">notes</a> in <em>The Making of Buddhist Modernism</em> (2008). As a consequence, practitioners first learn to experience themselves in meditation as empowered and supported by the care, compassion and wisdom of their spiritual ancestors and community. By contrast, citizens of the modern West often see persons as individual selves that exist prior to the community √¢‚Ç¨‚Äú atomistic individuals who choose whether or not to enter into relationships.</p>
<p>These different conceptions of the person have important consequences for meditation. In the modern view, practitioners tend to think of meditation as an autonomous project of self-help: through their own efforts, they try to foster beneficial states of mind. Socially conditioned in this way, Westerners enter into √¢‚Ç¨Àúlovingkindness meditation√¢‚Ç¨‚Ñ¢ (<em>metta</em>) as a way of summoning up a sense of love for themselves and those they feel close to; then, for those they√¢‚Ç¨‚Ñ¢re neutral towards; and, finally, for people they dislike.</p>
<p>For traditional Buddhist communities, any such meditation wouldn√¢‚Ç¨‚Ñ¢t begin with an atomistic self who is trying to generate a positive mindset from scratch. In such cultures, practitioners begin meditation with rituals and prayers that remind them that they are part of a connected community, blessed and supported by a lineage of spiritual ancestors that spans many generations. This starting point is shared by contemplative and ritual forms of Buddhism, Christianity, Confucianism, Hinduism, Islam, Judaism and many indigenous religions. In Tibetan Buddhism, for example, meditators envision a field of refuge that includes buddhas, bodhisattvas, spiritual teachers and other inspiring figures, who bless and sustain them and their world within qualities of unconditional love, compassion and wisdom. Practitioners√¢‚Ç¨‚Ñ¢ efforts to cultivate those same qualities begin not with self-help, but with the support and empowerment of their teachers and communities. In this way, the person meditating learns to become an extension of that field of love and compassion in which they are held, by progressively extending love and compassion to others.</p>
<p>Modern meditation and mindfulness, beginning with an atomistic sense of self, can reinforce an individual√¢‚Ç¨‚Ñ¢s sense of disconnection</p>
<p><strong>This kind of</strong> deeply supportive framework, found in all contemplative traditions, is mostly absent from modern meditation programmes. Because these communal dimensions of blessing and empowerment are embedded in premodern, ritualised cosmologies, they are often deemed an unneeded byproduct of √¢‚Ç¨Àúprimitive cultures√¢‚Ç¨‚Ñ¢, which can be jettisoned in order to √¢‚Ç¨Àúmodernise√¢‚Ç¨‚Ñ¢ the practice. However, these cosmologies serve a valuable function that maps directly onto attachment theory, one of the most influential approaches to developmental and social psychology.</p>
<p>Attachment theory is based on the idea that the care that children receive in infancy stays with them through their lifespan √¢‚Ç¨‚Äú for better or worse. Infants who receive sensitive and responsive care go on to develop a self that they feel is worthy of love. In turn, this supports their curiosity and courage to explore the world, because they trust that a source of security and support is available when needed. Sporadic or unreliable care, on the other hand, fosters insecurity and a distrust in support from others in times of need.</p>
<p>But the experience of security and insecurity is not locked in at infancy. Feelings of security and insecurity accrue throughout one√¢‚Ç¨‚Ñ¢s life from relationships with peers, mentors, romantic partners and so on. This means that we all have traces of security and insecurity in different relational contexts. Through the lens of attachment theory, the ritual and devotional practices of traditional contemplative cultures, which are repeated many thousands of times throughout a person√¢‚Ç¨‚Ñ¢s life, offer a powerful field of care in which practitioners experience themselves as recipients of love, compassion and wisdom. From this secure base, they are empowered to extend sustainable, inclusive and unconditional care to others.</p>
<p>From an evolutionary perspective, humans come prepared with capacities for care and compassion. But without the experience of actually receiving care, people can develop inner psychological blocks to compassion √¢‚Ç¨‚Äú including a lack of inner security, courage and confidence. Lack of security can foster aversion to others√¢‚Ç¨‚Ñ¢ suffering, a sense of isolation and biases against others. These psychological barriers interact with and are reinforced by systemic inequities such as racism, classism, sexism and homophobia.</p>
<p>Modern meditation and mindfulness, by beginning with an atomistic sense of self, can increase an individual√¢‚Ç¨‚Ñ¢s sense of disconnection. They can present meditation as a passive source of comfort for the self, instead of a practice that uses discomfort to create solidarity with other sufferers. In her <a href="https://yalebooks.yale.edu/book/9780300215809/american-dharma">book</a> <em>American Dharma</em> (2019), the Buddhist scholar Ann Gleig documents how communally oriented meditation can help people to become conscious of socially conditioned traumas, to heal internalised racism, and to tolerate the discomfort that conversations about race and privilege can generate.</p>
<p>Traditional cultures of compassion training strive to dismantle barriers to compassion by bringing to mind a field of care in which practitioners are held and supported, and from which they can learn to hold and support others. This relational starting point promotes resilience and connectivity, and bolsters the psychological and social resources we need today to confront systemic injustice. But how might secular people in modern individualistic cultures gain access to such communal benefits?</p>
<p>By reinhabiting moments of supportive caring connection, we can establish a core of inner safety that can be returned to again and again</p>
<p><strong>Research findings in psychology</strong> show that feelings of security can be temporarily increased, including among people who have predominantly insecure attachment histories. Social psychologists developed a method called <em>attachment security priming</em>, in which participants are asked to visualise a moment of receiving care from a loving figure, a trusted friend, or simply by thinking of words such as √¢‚Ç¨Àúlove√¢‚Ç¨‚Ñ¢, √¢‚Ç¨Àúsafety√¢‚Ç¨‚Ñ¢ or √¢‚Ç¨Àúcare√¢‚Ç¨‚Ñ¢ for a moment. These simple priming <a href="https://pubmed.ncbi.nlm.nih.gov/16351370/">exercises</a> temporarily increase feelings of security, safety and courage. In turn, participants are more likely to offer help to others, have more patience listening to others√¢‚Ç¨‚Ñ¢ difficult emotions, and possess less bias against other groups. This research suggests that attachment security priming could be integrated into meditation to recover the relational basis of the practice.</p>
<p>In an <a href="https://mindrxiv.org/dmxj7/">article</a> forthcoming in the journal <em>Perspectives on Psychological Science</em>, we introduce a relational starting point of support for meditation, derived from traditional Tibetan practice, and informed by research on attachment security priming. There are various ways to engage a relational starting point for meditation, depending on one√¢‚Ç¨‚Ñ¢s own life experience, background and worldview:</p><ul>
<li>You can recall a simple moment of supportive caring connection with another person, from any time in your life, and re-inhabit that caring moment as if it√¢‚Ç¨‚Ñ¢s happening now √¢‚Ç¨‚Äú evoking a rich experience of loving qualities and energies in mind and body. For example, Paul can call to mind playing cards with his loving grandmother at her kitchen counter, and John can recall a moment visiting a joyfully welcoming aunt as a young child.</li>
<li>A second option is to bring to mind someone to whom you feel grateful for their impact on your life, and experience the uplifting quality of imagining that person as present with you now.</li>
<li>A third option, if you practise in any spiritual tradition, is to bring to mind a saint, divine figure or field of spiritual ancestors, with whom you feel a deep connection.</li>
<li>If none of those options resonate, you might recall a time you spent somewhere special to you in the natural world √¢‚Ç¨‚Äú a place that felt deeply welcoming or peaceful. Or recall a loving moment with a pet. Or bring vividly to mind a moment when you were a loving presence to another person.</li>
</ul><p>According to <a href="https://www.frontiersin.org/research-topics/78/embodied-and-grounded-cognition#overview">theories</a> of embodied cognition, when we recall any such caring moment, it is simulated and re-enacted in multiple systems of the brain and body, including perceptual, motor, visual and affective systems. During the caring moment practice, we can visualise and simulate a felt sense of security, by experiencing that moment as if it were happening now, along with ‚Ä¶</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/modern-mindfulness-meditation-has-lost-its-beating-communal-heart">https://psyche.co/ideas/modern-mindfulness-meditation-has-lost-its-beating-communal-heart</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/modern-mindfulness-meditation-has-lost-its-beating-communal-heart</link>
            <guid isPermaLink="false">hacker-news-small-sites-24494021</guid>
            <pubDate>Wed, 16 Sep 2020 16:10:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Modern Web Applications Stability]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24493865">thread link</a>) | @blazeeboy
<br/>
September 16, 2020 | https://www.emadelsaid.com/on-modern-web-applications-stability/ | <a href="https://web.archive.org/web/*/https://www.emadelsaid.com/on-modern-web-applications-stability/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <div>
    <section dir="auto">
  


  

  <div dir="auto">
    <p>I don‚Äôt like how modern web applications are built. Many of the web applications
are too unstable, That you can‚Äôt imagine having the system running without a
team supporting it. The fact that we try to automate manual processes then the
automation needs manual intervention defies the purpose. Some companies has an
army of developers if they were to do the business by hand they would make a
better job than the programmed system. There are many reasons for this
situation. One of the reasons is the excessive use of third party dependencies.</p>

<p>Lets take a look on a basic modern web based system, There are several layers
on software running on the machine, starting from firmware to your business
logic.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_212438.jpg" alt="IMG_20200915_212438.jpg"></p>

<p>I don‚Äôt think this is very helpful to understand the gravity of the situation.
There are many actors that are not considered in this picture. Layers are also
missing because they are implicit in other layers. Lets expand these hidden
layers and actors. It will help us understand better why that small Nodejs or
RubyOnRails application we wrote isn‚Äôt just one layer in this picture.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_214548.jpg" alt="IMG_20200915_214548.jpg"></p>

<p>Here are the layers we added this time:</p>

<ul>
  <li>System core utilities</li>
  <li>Other processes your application depends on like ‚Äúmemcached, Redis, MySQL,
Postgres‚Ä¶etc‚Äù</li>
  <li>Third party code your application depends on an ORM, Template engine,
pagination library, a library that <a href="https://www.theregister.com/2016/03/23/npm_left_pad_chaos/">pads your string with
spaces</a> just
because.</li>
  <li>Server applications that sits in front of your code handling HTTP and response
compression‚Ä¶etc.</li>
</ul>

<p>For each of these layers there is <strong>at least</strong> one team responsible for
maintaining it.</p>

<p>Again, We missed other layers and people in this picture. Most of the
applications are using external SAAS providers for logs or monitoring or bug
reporting or provide parts of the system functionality that can take more time
to build by the company team. lets add them to the picture along with their
teams.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_221047.jpg" alt="IMG_20200915_221047.jpg"></p>

<p>This picture is for one application, I won‚Äôt expand it to a whole system with
different services and programs that is the reality of all companies.
Lets stick to one application for the sake of simplicity.</p>

<p>So here is the first point I want to make: With every service you use you‚Äôre not
just a user, This service is now part of your application, You are held
responsible for it‚Äôs behavior and misbehaving. You will inherit bugs in their
system. When this service team is affected by COVID-19 and get reduced to the
point where they can‚Äôt fix issues you will be affected too. When They get slower
your application will get slower too. When their service is down your
application will experience malfunction too, Your system and theirs is now
connected. So add external services integration cautiously. By adding an
external system you‚Äôre putting your trust in this service team and their ability
in delivering what the service is promising now <strong>and</strong> in the future. This is not
an easy decision and it should be treated as such.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_224907.jpg" alt="IMG_20200915_224907.jpg"></p>

<p>Now lets move to the direct dependencies of your application. If you‚Äôre using
any modern programming language it‚Äôll have a way to package code into reusable
format that could be reused by other applications. one package can use code from
other packages, these packages can use other packages and so on like a tree.</p>

<p><img src="https://www.emadelsaid.com/images/IMG_20200915_231326.jpg" alt="IMG_20200915_231326.jpg"></p>

<p>With every package in this tree we depend on the code inside this package and
the team that maintains it. A freshly generated rails project depends on 74
packages for ruby and <code>Yarn list</code> that lists JavaScript dependencies output 3102
lines, that‚Äôs 3176 packages with teams maintaining them and bugs and new
versions all the time.</p>

<p>This is wrong for many reasons. I will list some of them here for the sake of
clarity.</p>

<ul>
  <li>You have put your trust in at least 3176 other developers. You have never met
them, never talked to them, there are no guarantee they will continue to
maintain this package. There are no guarantee they won‚Äôt put code in their
package to show <a href="https://www.zdnet.com/article/npm-bans-terminal-ads/">ads in your
terminal</a> or <a href="https://www.trendmicro.com/vinfo/dk/security/news/cybercrime-and-digital-threats/hacker-infects-node-js-package-to-steal-from-bitcoin-wallets">code that
steals your bitcoin wallets
</a>.</li>
  <li>You are not really using all of this code. When someone is writing an open
source package it will suffer sooner or later from <a href="https://en.wikipedia.org/wiki/Feature_creep">feature
creeping</a> You are probably using
couple features of this package and don‚Äôt need the rest, but you wanted the
banana and got the whole forest now.</li>
  <li>With every package update you‚Äôre inventing unnecessary work for yourself. New
versions of packages are released all the time. Updating your project to <strong>get
the latest bug fixes and features</strong> is usually what people do. Most of the
time because of feature creeping these versions changes are not relevant to
you at all, but you won‚Äôt know until you read the change log. If it‚Äôs relevant
to your project you‚Äôll need to do an update. if something is deprecated or
changed you‚Äôll need to change your code. So suddenly someone somewhere is
telling you to change your code. That‚Äôs part of the control you have over your
code handed over to someone you never talked to or knew.</li>
  <li>When your programming language has a new release you can‚Äôt update unless all of
your dependencies are up to date. For ruby 2.7.0 for example some language syntax is
now deprecated and shows warning when you run your project. So to fix that you
either fix it in the package and open a PR with the change or wait for the
maintainer to update it.</li>
  <li>When you encounter a bug in a dependency you will have to understand this
package code, fork, branch, fix rinse and repeat. That requires a some
cooperation from the library maintainer which is most of the time isn‚Äôt
possible because most of the open source projects are voluntarily maintained.</li>
  <li>Developing new features or modifying existing features are ordre of magnitude
harder. You‚Äôll need to dig into the documentation of the dependencies looking
for support for this little feature you want to add. That is if there is any
documentation at all for that part of the code. Otherwise you‚Äôll have to dig
in to the library code.</li>
</ul>

<p>This is the second point I want to make: Using external library implies that you
trust the maintainer and you also inherit his decisions about using other
libraries and so forth. This decision should be weighed based on the benefit of
the library and how many of it‚Äôs features you‚Äôre going to use and other factors
like the maturity and how responsive is the maintainer, please don‚Äôt use GitHub
stars as a factor in your decision it‚Äôs misleading. And if the part you use from
the library isn‚Äôt too big I recommend using the library to save some time and
effort upfront but make sure you get rid of it and implement the part you need.
An example of that is a pagination library like rails ‚ÄúKaminari‚Äù if you‚Äôre using
it to save you some time then sure. But keep on your todo list a task to remove
it and implement the feature yourself. An example of libraries that‚Äôs hard to
get rid of it ‚ÄúOpenCV‚Äù This is something that reimplementing the part you need
probably will be a huge task so it can stay. You‚Äôll need to use your best
judgment to decide between these 2 sides of the spectrum.</p>

<p>I like to think of what I do as building an automated system, I would like this
system to run by itself, keep itself clean and healthy, doesn‚Äôt need manual
intervention. If the whole team disappeared out of existence I would like that
system to work for a very long time without any supervision.</p>

<p>More code means more bugs for me to fix, by extension more code that I didn‚Äôt write
means more bugs that I probably can‚Äôt solve. This is dangerous and shouldn‚Äôt be
taken lightly. Extending your code with external libraries or systems can cut
down effort hence the cost of development. But when this is taken lightly it
backfires badly.</p>

<p>HN comments: <a href="https://news.ycombinator.com/item?id=24493865">https://news.ycombinator.com/item?id=24493865</a></p>

  </div>
</section>

<hr>



    </div>
  </section></div>]]>
            </description>
            <link>https://www.emadelsaid.com/on-modern-web-applications-stability/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24493865</guid>
            <pubDate>Wed, 16 Sep 2020 15:56:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Challenging LR Parsing]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24492675">thread link</a>) | @dilap
<br/>
September 16, 2020 | https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Consider this incomplete snippet of Rust code:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre>1
2
3
4
5
</pre></td><td><pre><span>fn</span> <span>foo</span><span>(</span>

<span>struct</span> <span>S</span> <span>{</span>
   <span>f</span><span>:</span> <span>u32</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>I want to see an LR parser which produces the following syntax tree
(from <a href="https://rust-analyzer.github.io/manual.html#show-syntax-tree"><strong>Show Syntax Tree</strong></a> rust-analyzer command, with whitespace nodes elided for clarity):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre></td><td><pre>SOURCE_FILE@0..32
  FN@0..7
    FN_KW@0..2 "fn"
    NAME@3..6
      IDENT@3..6 "foo"
    PARAM_LIST@6..7
      L_PAREN@6..7 "("
  STRUCT@9..31
    STRUCT_KW@9..15 "struct"
    NAME@16..17
      IDENT@16..17 "S"
    RECORD_FIELD_LIST@18..31
      L_CURLY@18..19 "{"
      RECORD_FIELD@23..29
        NAME@23..24
          IDENT@23..24 "f"
        COLON@24..25 ":"
        PATH_TYPE@26..29
          PATH@26..29
            PATH_SEGMENT@26..29
              NAME_REF@26..29
                IDENT@26..29 "u32"
      R_CURLY@30..31 "}"
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The most error-resilient LR-style parser I know, <a href="https://github.com/tree-sitter/tree-sitter">tree sitter</a>, produces this instead (tree sitter is GLR, this is <strong>not</strong> the style of parsing advocated by the article):</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
</pre></td><td><pre>source_file [0, 0] - [5, 0])
  ERROR [0, 0] - [4, 1])
    identifier [0, 3] - [0, 6])
    struct_pattern [2, 0] - [4, 1])
      type: type_identifier [2, 0] - [2, 6])
      ERROR [2, 7] - [2, 8])
        identifier [2, 7] - [2, 8])
      field_pattern [3, 3] - [3, 9])
        name: field_identifier [3, 3] - [3, 4])
        pattern: identifier [3, 6] - [3, 9])
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Note two things about the rust-analyzer‚Äôs tree:</p>
<div>
<ul>
<li>
<p>There‚Äôs an (incomplete) ‚Äúfunction‚Äù node for <code>fn foo(</code>.
Unclosed parenthesis doesn‚Äôt preclude the parser from recognizing parameter list.</p>
</li>
<li>
<p>Incomplete function does not prevent struct definition from being recognized.</p>
</li>
</ul>
</div>
<p>These are important for IDE support.</p>
<p>For example, suppose that the cursor is just after <code>(</code>.
If we have rust-analyzer‚Äôs syntax tree, than we can figure out that we are completing a function parameter.
If we are to get fancy we might find the calls to the (not yet fully written) <code>foo</code>, run type inference to figure out the type of the first argument, and than suggest parameter name &amp; type based on that (not currently implemented‚Äâ‚Äî‚Äâthere‚Äôs soooooo much yet to be done in rust-analyzer).
And correctly recognizing <code>struct S</code> is important to not break type-inference in the code which uses <code>S</code>.</p>
<p>There‚Äôs a lot of literature about error recovery for LR parsers, how come academics haven‚Äôt figured this out already?
I have a bold claim to make: error-recovery research in academia is focusing on a problem irrelevant for IDEs.
Specifically, the research is focused on finding ‚Äúminimal cost repair sequence‚Äù:</p>
<div>
<ul>
<li>
<p>a set of edit operations is defined (skip, change or insert token),</p>
</li>
<li>
<p>a ‚Äúcost‚Äù metric is defined to distinguish big and small edits,</p>
</li>
<li>
<p>an algorithm is devised to find the smallest edit which makes the current text parse.</p>
</li>
</ul>
</div>
<p>This is a very academia-friendly problem‚Äâ‚Äî‚Äâthere‚Äôs a precise mathematical formulation, there‚Äôs an obvious brute force solution (try all edits), and there‚Äôs ample space for finding polynomial algorithm.</p>
<p>But IDEs don‚Äôt care about actually guessing &amp; repairing the text!
They just need to see as much of (possibly incomplete) syntax nodes in the existing text as possible.
When rust-analyzer‚Äôs parser produces</p>
<div>
<div>
<pre><code><table><tbody><tr><td><pre>1
2
3
</pre></td><td><pre>  PARAM_LIST@6..7
    L_PAREN@6..7 "("
STRUCT@9..31
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>it doesn‚Äôt think ‚ÄúOh, I need to insert <code>)</code> here to complete the list of parameters‚Äù.
Rather, it sees <code>struct</code> and thinks ‚ÄúOh wow, didn‚Äôt expect that! I guess I‚Äôll just stop parsing parameter list right here‚Äù.</p>
<p>So, here‚Äôs</p>
<div>
<table>
<tbody><tr>
<td>
<i title="Important"></i>
</td>
<td>
<p>First Challenge</p>
Design error <em>resilient</em> (and not just error <em>recovering</em>) LR parsing algorithm.
</td>
</tr>
</tbody></table>
</div>
<p>Note that error resilience is a topic orthogonal to error reporting.
I haven‚Äôt payed much attention to error reporting (in my experience, synchronous reporting of syntax errors in the editor compensates for bad syntax error messages), but it might be the case that MCRS are a good approach to there.</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/09/16/challeging-LR-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24492675</guid>
            <pubDate>Wed, 16 Sep 2020 13:48:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: 5 Kb Spreadsheet for the Web with copy paste]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24492647">thread link</a>) | @lecarore
<br/>
September 16, 2020 | https://renanlecaro.github.io/importabular/ | <a href="https://web.archive.org/web/*/https://renanlecaro.github.io/importabular/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"> <section> <div>  <ul> <li title="Once minified and gzipped">Under 5 Kb</li> <li title="Basic support, double tap a cell to edit it, not tried on iphone">Mobile friendly</li> <li title="Works from libre office, should work for other software">Copy / paste</li> <li>MIT License</li> </ul> </div>  </section> <section> <div> <h2>Usage</h2> <p>Install it from npm</p> <pre><code>npm install importabular</code></pre> <p>Instanciate it on a dom node</p>
<pre><code lang="javascript">import Importabular from 'importabular'
const sheet=new Importabular({
  node:document.getElementById('editorNode'),
})</code></pre> <p>Get the current data as a 2D array</p>
<pre><code lang="javascript">sheet.data.toArr()</code></pre> <p>Destroy it to remove event listeners</p>
<pre><code lang="javascript">sheet.destroy()</code></pre> </div> </section> <section> <div> <h2>Goals and limitations</h2> <p> I've created this lib because I was tired of having to remove 90% of the features offered by the very few open source libs for web spreadsheets. </p> <p> Some common use cases have options, for the rest you should just read <a href="https://github.com/renanlecaro/importabular">the source</a> and subclass it of fix the code. </p> <p> So for this reinventing the wheel to make sense, I should not add any extra features to this core. </p><ul> <li>No virtual rendering</li> <li>No sorting, pivot, formula, etc ..</li> <li>Only basic keyboard shortcuts</li> <li>Only strings as data type</li> <li>Only for recent browsers</li> </ul>  <p> The lib is fresh and not battle tested, probably has some bugs. Feel free to <a href="https://github.com/renanlecaro/importabular/issues/new"> create an issue</a> if you find a bug. </p> </div> <div> <pre><code lang="javascript">import Importabular from 'importabular'

const sheet=new Importabular({
  node:document.getElementById('editorNode'),

  // Prefill the table
  data:[['This','is','the','first','row']],

  // Called after each change to the table data
  onChange:data=&gt;console.log('new data : ',data),

  // Called every time the user changes selection,
  // useful for real time collaborative editing
  onSelectionChange:sel=&gt;console.log('new selection',sel),

  // Each cell is rendered as a TD with inside either
  // a div or an input. This will override the TD style
  cellStyle:(x,y,{selected,editing})=&gt;
    ({
      backgroundColor:!selected &amp;&amp; !editing &amp;&amp; y%2?
        '#fafafa':null
    }),

  // and this will override the style of the text
  // input or div.
  contentStyle:()=&gt;({fontFamily:'sherif'}),

  // Starting size of the grid on instanciation
  minWidth:5,
  minHeight:10,

  // Limits to the growth of the grid
  maxWidth:5,
  maxHeight:10,
})
</code></pre> </div>
</section> 
</div>]]>
            </description>
            <link>https://renanlecaro.github.io/importabular/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24492647</guid>
            <pubDate>Wed, 16 Sep 2020 13:44:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Direct sales for SaaS startups ‚Äì our experience and tips]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24492609">thread link</a>) | @pau_alcala
<br/>
September 16, 2020 | https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups | <a href="https://web.archive.org/web/*/https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p><em>By Pau Alcal√° - Co-founder of Palabra</em></p><p>While finding product-market fit for <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a>, our marketing strategy was exclusively organic and our first sales came from 1-1 conversations with potential users. After a month of difficult conversations and failed demos, I learned a very new and innovative approach to direct sales: actually listening to what people are saying. In this post I'll share my experience and some tips to listen to users, in the hopes of saving founders &amp; early startup teams some time and energy.</p><h2>What we mean by direct sales</h2><p>As the name suggest, direct sales means you talk directly to your prospect and try to sell them your solution via a 1-1 conversation. This conversation usually starts by reaching the prospect you think your product would work for, and sharing why you think your solution would be good for them.</p><p>Taking a direct approach is more common for B2B businesses, because the decision to purchase is strategical and the price is higher, which means you get a bigger return for each user you convert. But I think it's a good strategy to follow for any early stage SaaS, because it's an easy and direct way of learning about your users and implementing solutions that work for them.</p><p>The biggest challenges to direct sales is finding the right prospects and knowing how to show them value as quickly as possible. With direct conversations you'll probably get a higher conversion rate than self-served sales, but at a much slower rate.</p><h2>Why direct sales in a SaaS startup?</h2><p>When we launched <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a> we had no audience and not enough user data to understand who we should be targeting or how to convert them into paying users. We had two possible paths to follow:</p><ol><li>Awareness-first: Experimenting with low-budget ads or organic strategies in different channels, with different messages to see which stick better. This approach is the startup playbook, feeding the top of the funnel with as many prospects as possible assuming most of them will not end up buying, and learn how to convert them better later on.</li><li>Conversion-first: Spending almost no time to feed the top of the funnel (keep a low stream of leads and prospects) but improving that funnel to have better conversions. Leads would be scarce, but we'd learn how to qualify them and provide value so they are willing to buy and stay around.</li></ol><p>The first path was the riskier for us. First, because we had little experience with paid acquisition, and wouldn't know if our misses would be due to lack of experience or just wrong channels.</p><p>Second, we wanted to engage in deep conversations with users as soon as possible. We didn't really care about general trends, we wanted to actually understand what people were struggling with in email automation, and where to take our product so that it worked for them. That's why we decided to take the second path.</p><p>Our initial strategy was to ask a bunch of questions about people's current email automation strategies and try to turn the initial conversation into a sales pitch. We'd learn fast and get a few sales in the meantime.</p><p>Sounds easy, right? Well, it was not.</p><h2>What a failed sales conversation looks like</h2><p>After my first couple of calls I knew I was doing something wrong, but didn't know what it was. Sign ups were rarely because of my "sales" 1-1s, and every conversation left me with a sour feeling.</p><p>What usually happened was that I got to a call, asked the person a couple of questions about their strategies, and at some point I'd get nervous and start talking a lot. People are usually nice and would listen to what I had to say, but I could feel they weren't really interested, and felt like I was wasting time.</p><p>So what was I doing wrong?</p><p>After talking with my co-founder and a couple of friends in the SaaS industry, I found that I wasn't really paying attention to what prospects were saying. My team would ask questions about our prospects that I didn't know how to answer.</p><p>That meant I wasn't really selling, but I also wasn't learning about our users. I found I had to learn how to listen first, and sell later.</p><h2>How to talk less and sell more</h2><p>Listening to prospects is not at easy as it sounds when you are worried about selling them your solution. Specially if you're in early stage and don't have much experience selling software, it'll be hard to keep a clear mind and letting the user take the conversation where they want to.</p><p>But here's the thing: selling isn't about convincing people to try your product, it's about identifying how your product can solve a problem for them.</p><p>In a direct sales conversation, you should have two take outs:</p><ol><li>Identifying if the person you're talking to has a problem you could solve (the more details the better)</li><li>Communicating clearly how your product is a solution to their problem.</li></ol><p>If you fail at #1, you'll end up trying to convince people who don't actually have a problem you could help them with. Those are not your users, and there's nothing you can do today to make their life easier. Even if you somehow convince them to sign up, they'll probably cancel their subscription, making your churn go up.</p><p>Failing at #2 is usually connected to #1, because the only way of communicating a solution clearly is to understand the problem perfectly. You have to <strong>listen really carefully</strong> to understand what those problems are.</p><p>Most of your conversations with prospects should be about #1. Make a lot of questions. Listen closely and follow up on what isn't clear. Make the other person feel listened to. Worst case scenario, you end up with valuable insights about what problems people have. As an early stage startup, this information is crucial to find product-market fit.</p><p>Here are some lessons I learned while taking a direct sales approach to SaaS. Most of them came from reading <a href="http://momtestbook.com/">The Mom Test</a>, talking to awesome people and experimenting on my own.</p><h2>3 direct sales tips to listen to your users</h2><h3>Writing down what you want to get from the conversation</h3><p>This list should be really short. My initial conversation guide had 15+ questions to get to understand the problem, and then a short demo. It worked kinda fine, but I usually got lost by question 5, and then started thinking about what to ask next instead of listening to the answer.</p><p>The Mom Test suggests you should "prepare your list of 3". Three things you want to get from each conversation, depending on who you'll be talking to. And that was magic.</p><p>In early Palabra demos, when I asked to have a quick chat to someone in a startup, I usually had three different scenarios:</p><ul><li>The founder talked to me directly, who had no details about the email automation strategies his/her team was using but could provide context.</li><li>I talked to a marketer in the startup, who usually had many years of experience and had tried a bunch of other email automation tools.</li><li>I talked to a technical co-founder or dev, who had a lot of questions about technical aspects of Palabra and had tried different integrations before.</li></ul><p>I prepared three different notes to look at before each conversation, one for each "buyer" persona, and wrote down my list of three.</p><p>I started asking questions that came to mind from listening to what people were saying, and spend almost no time looking at my notes. If I ever felt I was starting to get lost, I just glanced to my list of three for that particular person to check if I was missing something. Freedom.</p><h3>Having a structured set of questions</h3><p>This advice came from a great friend and the <a href="http://sofandrade.com/">best UX designer I've met</a>. She knows all about user interviews, and since I was also trying to learn from our prospects, I knew it would help. Her advice was to divide my questions into chunks or topics I wanted to know about.</p><p>Having differentiated topics gives you flexibility to follow the conversation and not worry about what to ask after each answer. If you ask a question from the first topic and your user's answer goes to a slightly different topic, you can go to that part of your guide and then come back after that's done.</p><p>As an example, this was the structure I ended up using for each guide:</p><ul><li>About them/their job/their goals</li><li>About their emails, what they were using them from</li><li>About their email automation tools, what they were using and how</li><li>About their pains, what was missing from their current tools?</li></ul><p>What usually happened is that my email questions got answers related to tools. So I just moved over to the "tools" set of questions and then looked to see if I was missing something important at the end.</p><p>A smart move was to leave questions about pains for last. By then I usually had enough information about their problem and could offer a clear solution with <a href="https://www.palabra.io/?utm_medium=direct-sales-tips-startups&amp;utm_source=blog">Palabra</a>.</p><p>If we had a solution, I'd briefly tell people why I thought this would work, and offered to show them in a demo. By focusing on their specific solution in the demo, I only showed one feature and not the whole product, which was a much better use of everyone's time.</p><h3>Doing some background research - but still ask people</h3><p>You can't go into a sales pitch without knowing who you're talking to. For B2B sales you need to know about the company and the person you're actually going to talk to. The key here is to use that information wisely.</p><p>I used to start conversations on what I'd learned from their landing page, to let people know I had done my homework. But his was actually making me start with the wrong foot -by talking too much.</p><p>Asking about their company and what they do there gives you inside information you wouldn't get from LinkedIn or a landing page. And it also helps break the ice, since it's an easy answer for anyone.</p><p>My solution was full transparency. I started each conversation by saying I had done a bit of research about them but still wanted to hear from themselves. Then I would ask what they usually do.</p><p>This was incredibly effective. Being honest took away all of my nervousness and allowed me to relax into the conversation. I felt like I had no secrets, I was just telling the truth and asking questions. And I think this works both ways: the person you're talking to will probably trust you more if you're ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups">https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups</a></em></p>]]>
            </description>
            <link>https://blog.palabra.io/learning-to-listen-direct-sales-tips-for-early-stage-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24492609</guid>
            <pubDate>Wed, 16 Sep 2020 13:40:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Contravariant Functors Are Weird]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 22 (<a href="https://news.ycombinator.com/item?id=24491887">thread link</a>) | @gbrown_
<br/>
September 16, 2020 | https://sanj.ink/posts/2020-06-13-contravariant-functors-are-weird.html | <a href="https://web.archive.org/web/*/https://sanj.ink/posts/2020-06-13-contravariant-functors-are-weird.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
            <p>Just a note about nomenclature before we start; I‚Äôll use ‚Äúfunctor‚Äù to represent the <a href="https://bartoszmilewski.com/2015/01/20/functors/">categorical meaning</a> of the concept:</p>
<blockquote>
<p>A functor is a mapping between categories</p>
</blockquote>
<p>and <code>Functor</code> and <code>Contravariant</code> to specify the typeclass encodings of functors.</p>
<hr>
<p>Let‚Äôs begin!</p>
<p>Contravariant functors are odd aren‚Äôt they? Covariant functors (which are modelled by the <code>Functor</code> typeclass) are quite straightforward but <strong>contra</strong>variant functors as their name implies seem to be the complete opposite.</p>
<p>Before we get into what a contravariant functor is, it‚Äôs useful to look at the <code>Functor</code> <a href="https://wiki.haskell.org/Typeclassopedia">typeclass</a> which we know and love.</p>
<h2 id="functor">Functor</h2>
<p>A <code>Functor</code> is defined as:</p>
<div><pre><code><span>class</span> <span>Functor</span> f <span>where</span>
<span>  fmap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> f a <span>-&gt;</span> f b</code></pre></div>
<p>We often understand a <code>Functor</code> to be a ‚Äúcontainer‚Äù or a ‚Äúproducer‚Äù of some type, where the function supplied to <code>fmap</code> is applied to the elements that are ‚Äúcontained‚Äù or ‚Äúproduced‚Äù in some type constructor<a href="#type-constructor-1"><sup>1</sup></a> <code>f</code>.</p>
<p>A simple example would be the list (<code>[]</code>) type, that can represent zero or more values. Given a <code>[a]</code> we can turn it into a <code>[b]</code> when given a function <code>a -&gt; b</code>.</p>
<div><pre><code><span>data</span> [] a <span>=</span> [] <span>|</span> a <span>:</span> [a]  <span>-- an approximation of the [] data type</span>

<span>instance</span> <span>Functor</span> [] <span>where</span>
  fmap _ [] <span>=</span> []
  fmap f (x<span>:</span>xs) <span>=</span> f x <span>:</span> fmap f xs</code></pre></div>
<p>In the example below we convert a <code>[Int]</code> into a <code>[String]</code> given a function <code>Int -&gt; String</code>:</p>
<div><pre><code><span>import </span><span>Data.Semigroup</span> ((&lt;&gt;))

<span>myInts ::</span> [<span>Int</span>]
myInts <span>=</span> [<span>1</span> <span>..</span> <span>5</span>]

<span>emptyInts ::</span> [<span>Int</span>]
emptyInts <span>=</span> []

<span>intToString ::</span> <span>Int</span> <span>-&gt;</span> <span>String</span>
intToString n <span>=</span> (show n) <span>&lt;&gt;</span> <span>"!"</span>

<span>myStrings ::</span> [<span>String</span>]
myStrings <span>=</span> fmap intToString myInts <span>-- ["1!","2!","3!","4!","5!"]</span>

<span>myEmptyString ::</span> []
myEmptyString <span>=</span> fmap intToString emptyInts  <span>-- []</span></code></pre></div>
<p>Another example would the <code>Maybe</code> data type, that represents a value that may or may not exist.</p>
<div><pre><code><span>data</span> <span>Maybe</span> a <span>=</span> <span>Nothing</span> <span>|</span> <span>Just</span> a

<span>instance</span> <span>Functor</span> <span>Maybe</span> <span>where</span>
  fmap _ <span>Nothing</span> <span>=</span> <span>Nothing</span>
  fmap f (<span>Just</span> x) <span>=</span> <span>Just</span> (f x)</code></pre></div>
<p>In the example below we convert a <code>Maybe Int</code> into a <code>Maybe String</code> given a function <code>Int -&gt; String</code>:</p>
<div><pre><code><span>import </span><span>Data.Semigroup</span> ((&lt;&gt;))

<span>maybeInt ::</span> <span>Maybe</span> <span>Int</span>
maybeInt <span>=</span> <span>Just</span> <span>10</span>

<span>notInt ::</span> <span>Maybe</span> <span>Int</span>
notInt <span>=</span> <span>Nothing</span>

<span>intToString ::</span> <span>Int</span> <span>-&gt;</span> <span>String</span>
intToString n <span>=</span> (show n) <span>&lt;&gt;</span> <span>"!"</span>

<span>maybeString ::</span> <span>Maybe</span> <span>String</span>
maybeString <span>=</span> fmap intToString maybeInt <span>-- Just "10!"</span>

<span>notString ::</span> <span>Maybe</span> <span>String</span>
notString <span>=</span> fmap intToString notInt <span>-- Nothing</span></code></pre></div>
<p>The <code>Functor</code> typeclass has laws, that ensure <code>Functor</code> instances behave in a predictable way.</p>
<h3 id="laws">Laws</h3>
<h4 id="identity">Identity</h4>

<p>Essentially if you do nothing to the value of a <code>Functor</code>, you get the same <code>Functor</code> you started with.</p>
<h4 id="composition">Composition</h4>
<div><pre><code>fmap (f <span>.</span> g) <span>==</span> fmap f <span>.</span> fmap g</code></pre></div>
<p>If you convert the result of a Functor by <code>fmap</code>ing with a function <code>g</code> and then <code>fmap</code>ing that result with a subsequent function <code>f</code>, it‚Äôs the same as composing functions <code>g</code> and <code>f</code> (<code>f . g</code>) and then <code>fmap</code>ing once.</p>
<div>
<p><img src="https://sanj.ink/images/contravariant/functor-laws-ct.png" alt="Functor Laws"></p><p>Functor Laws</p>
</div>
<h3 id="the-wrong-type-of-fmap">The Wrong Type of fmap</h3>
<p>Now let‚Äôs look at something a little different. Let‚Äôs create a data type to wrap a predicate of some sort. A predicate is something that will evaluate to a <code>Bool</code>:</p>
<div><pre><code><span>newtype</span> <span>Predicate</span> a <span>=</span> <span>Predicate</span> {<span> getPredicate ::</span> a <span>-&gt;</span> <span>Bool</span> }</code></pre></div>
<p>An example of a Predicate is <code>greaterThanTen</code>:</p>
<div><pre><code><span>greaterThanTen ::</span> <span>Predicate</span> <span>Int</span>
greaterThanTen <span>=</span> <span>Predicate</span> (\n <span>-&gt;</span> n <span>&gt;</span> <span>10</span>)</code></pre></div>
<p>that tests whether a number is greater than ten.</p>
<p>We can run with it <code>getPredicate</code> and an <code>Int</code>:</p>
<div><pre><code>getPredicate greateThanTen <span>5</span>  <span>-- False</span>
getPredicate greateThanTen <span>11</span> <span>-- True</span></code></pre></div>
<p>It could be useful to define a <code>Functor</code> instance for Predicate - say if we have a <code>Predicate Int</code> and we want to convert it into a <code>Predicate String</code> when we have a <code>Int -&gt; String</code> function. Let‚Äôs try and implement that:</p>
<div><pre><code><span>instance</span> <span>Functor</span> <span>Predicate</span> <span>where</span>
  <span>-- fmap (a -&gt; b) -&gt; Predicate a -&gt; Predicate b</span>
  fmap f (<span>Predicate</span> p) <span>=</span> <span>Predicate</span> (\b <span>-&gt;</span> undefined)
  fmap f (<span>Predicate</span> (a <span>-&gt;</span> <span>Bool</span>)) <span>=</span> <span>Predicate</span> (\b <span>-&gt;</span> undefined)  <span>-- expanding p</span>
  fmap (a <span>-&gt;</span> b) (<span>Predicate</span> (a <span>-&gt;</span> <span>Bool</span>)) <span>=</span> <span>Predicate</span> (\b <span>-&gt;</span> undefined) <span>-- expanding f</span></code></pre></div>
<p>Now we‚Äôve run into a small problem:</p>
<blockquote>
<p>How do we compose (a -&gt; Bool) and (a -&gt; b) to give us a (b -&gt; Bool) ?</p>
</blockquote>
<p>We are given a <code>b</code> but we don‚Äôt have access to any functions that actually use a <code>b</code>.</p>
<p>The problem is that we can‚Äôt. It‚Äôs because of something called ‚Äúpolarity‚Äù of the type variable <code>a</code>. No <code>Functor</code> instance for you <code>Predicate</code>.</p>

<h2 id="polarity">Polarity</h2>
<p>Polarity is a way of representing <a href="https://en.wikipedia.org/wiki/Covariance_and_contravariance_(computer_science)">variance</a> using the position of type variables. Let‚Äôs take a simple function <code>a -&gt; b</code> as an example.</p>
<div>
<p><img src="https://sanj.ink/images/contravariant/function-polarity.png" alt="Function Polarity"></p><p>Function Polarity</p>
</div>
<p>If a type variable is in <strong>input</strong> position like <code>a</code> it is given a <strong>negative</strong> polarity. If it is in an <strong>output</strong> position like <code>b</code> then it is given a <strong>positive</strong> polarity.</p>
<p>These polarities map directly to variant types.</p>
<table>
<thead>
<tr>
<th>Polarity</th>
<th>Variance</th>
</tr>
</thead>
<tbody>
<tr>
<td>Positive</td>
<td>Covariant</td>
</tr>
<tr>
<td>Negative</td>
<td>Contravariant</td>
</tr>
<tr>
<td>Both</td>
<td>Invariant</td>
</tr>
</tbody>
</table>
<p>What this means is that <code>Functor</code>s (which are actually covariant functors) require a type constructor in a covariant position in order for you to define a <code>Functor</code> instance for that type.</p>
<p>Let‚Äôs look at a type that we know has a <code>Functor</code> instance like <code>Maybe</code>:</p>
<div>
<p><img src="https://sanj.ink/images/contravariant/maybe-polarity.png" alt="Polarity of the Maybe data type"></p><p>Polarity of the Maybe data type</p>
</div>
<p>We can see that the type variable <code>a</code> occurs in a covariant (or output) position within the definition of the <code>Just</code> constructor.</p>
<p>Now let‚Äôs look at the definition of <code>Predicate</code> data type:</p>
<div>
<p><img src="https://sanj.ink/images/contravariant/predicate-polarity.png" alt="Polarity of the Predicate data type"></p><p>Polarity of the Predicate data type</p>
</div>
<p>We can see that the type variable <code>a</code> occurs in a contravariant (or input) position. This indicates that we can‚Äôt create a (covariant) <code>Functor</code> instance for this data type.</p>
<p>But we want to map things! What do we do?</p>
<h2 id="contravariant">Contravariant</h2>
<p>Welcome the <code>Contravariant</code> typeclass to the stage! It‚Äôs defined as:</p>
<div><pre><code><span>class</span> <span>Contravariant</span> f <span>where</span>
<span>  contramap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> f b <span>-&gt;</span> f a</code></pre></div>
<p>Snazzy! <code>Contravariant</code> also takes some kind of type constructor <code>f</code> just like <code>Functor</code> but it has this weirdly named <code>contramap</code> function instead of <code>fmap</code>.</p>
<div><pre><code><span>     fmap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> f a <span>-&gt;</span> f b <span>-- Functor</span>
<span>contramap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> f b <span>-&gt;</span> f a <span>-- Contravariant</span>
                         <span>^^^</span></code></pre></div>
<p>If we read <code>fmap</code> as:</p>
<blockquote>
<p>If you have an <code>a</code> in some context and a function that takes that <code>a</code> and converts it to a <code>b</code>, I can give you a context with a <code>b</code> in it.</p>
</blockquote>
<p>we can then read <code>contramap</code> as:</p>
<blockquote>
<p>If you have a context that needs an <code>a</code> and a function that can convert <code>b</code>s to <code>a</code>s, I can give you a context that needs <code>b</code>s.</p>
</blockquote>
<p>But that probably doesn‚Äôt make much sense. So let‚Äôs try and look at this in terms of our non-<code>Functor</code>: <code>Predicate</code>. <code>Predicate</code> has a <strong>need</strong> for an <code>a</code>, which it then uses to tell if something about that <code>a</code> is True or False.</p>
<p>Let‚Äôs try and write a <code>Contravariant</code> instance for <code>Predicate</code> given that we know that the type <code>a</code> in <code>Predicate</code> occurs in an input position.</p>
<div><pre><code><span>instance</span> <span>Contravariant</span> <span>Predicate</span> <span>where</span>
  <span>-- contramp (a -&gt; b) -&gt; f b -&gt; f a</span>
  contramap (a <span>-&gt;</span> b) <span>-&gt;</span> <span>Predicate</span> b <span>-&gt;</span> <span>Predicate</span> a <span>-- substituting for `f` for Predicate</span>
  contramap aToB (<span>Predicate</span> bToBool) <span>=</span> <span>Predicate</span> (\a <span>-&gt;</span> undefined)</code></pre></div>
<p>Given that we have a function <code>a -&gt; b</code> and essentially a function of type <code>b -&gt; Bool</code> (wrapped inside a <code>Predicate b</code>), we can if given an <code>a</code>, convert it to a <code>b</code> using <code>aToB</code> and then give that <code>b</code> to <code>bToBool</code> to give us a <code>Bool</code>.</p>
<p>Here‚Äôs a slightly long-form implementation of the <code>Contravariant</code> instance for <code>Predicate</code>:</p>
<div><pre><code><span>instance</span> <span>Contravariant</span> <span>Predicate</span> <span>where</span>
<span>  contramap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> <span>Predicate</span> b <span>-&gt;</span> <span>Predicate</span> a
  contramap aToB (<span>Predicate</span> bToBool) <span>=</span>
    <span>Predicate</span> <span>$</span> \a <span>-&gt;</span>
      <span>let</span> b    <span>=</span> aToB a
          bool <span>=</span> bToBool b
      <span>in</span> bool</code></pre></div>
<div>
<p><img src="https://sanj.ink/images/contravariant/contramap-predicate.png" alt="contramap on Predicate"></p><p>contramap on Predicate</p>
</div>
<p>or more succinctly:</p>
<div><pre><code><span>instance</span> <span>Contravariant</span> <span>Predicate</span> <span>where</span>
<span>  contramap ::</span> (a <span>-&gt;</span> b) <span>-&gt;</span> <span>Predicate</span> b <span>-&gt;</span> <span>Predicate</span> a
  contramap f (<span>Predicate</span> b) <span>=</span> <span>Predicate</span> <span>$</span> b <span>.</span> f</code></pre></div>
<p>We can see from the definition of <code>Predicate a</code> that all we are doing is running the supplied function <code>f</code> <strong>before</strong> the function within <code>Predicate b</code>. The reason we do that is to adapt a new input type to match an existing input type to gain some functionality.</p>
<p>If we revisit the (covariant) <code>Functor</code> instance for <code>Maybe</code>:</p>
<div><pre><code><span>instance</span> <span>Functor</span> <span>Maybe</span> <span>where</span>
  fmap _ <span>Nothing</span> <span>=</span> <span>Nothing</span>
  fmap aToB (<span>Just</span> a) <span>=</span> <span>Just</span> (aToB a)</code></pre></div>
<p>we can see that the function <code>aToB</code> is run <strong>after</strong> we have a value of <code>a</code>. We do that to convert a result of some type to another type.</p>
<div>
<p><img src="https://sanj.ink/images/contravariant/fmap-maybe.png" alt="fmap on Maybe"></p><p>fmap on Maybe</p>
</div>
<p>These are the essential differences between covariant and contravariant functors:</p>
<table>
<thead>
<tr>
<th>Typeclass</th>
<th>Function runs</th>
<th>Purpose</th>
</tr>
</thead>
<tbody>
<tr>
<td>Functor</td>
<td>after</td>
<td>Convert results</td>
</tr>
<tr>
<td>Contravariant</td>
<td>before</td>
<td>Adapt inputs</td>
</tr>
</tbody>
</table>
<p>Now that we know the essential difference between <code>Functor</code> and <code>Contravariant</code>, let‚Äôs look at how we can use <code>contramap</code> with our <code>Predicate</code> class.</p>
<p>Given that we already have a <code>Predicate</code> that determines whether a number is greater than ten:</p>
<div><pre><code><span>numGreaterThanTen ::</span> <span>Predicate</span> <span>Int</span>
numGreaterThanTen <span>=</span> <span>Predicate</span> (\n <span>-&gt;</span> n <span>&gt;</span> <span>10</span>)</code></pre></div>
<p>say we want to write another <code>Predicate</code> that verifies that the length of String is greater than ten characters.</p>
<div><pre><code><span>strLengthGreaterThanTen ::</span> <span>Predicate</span> <span>String</span>
strLengthGreaterThanTen <span>=</span> <span>Predicate</span> (\s <span>-&gt;</span> (length s) <span>&gt;</span> <span>10</span>)</code></pre></div>
<p>Sure, that‚Äôs pretty contrived but bear with me. Let‚Äôs also say we have a <code>Person</code> data type and we want to know if a person‚Äôs name is over ten characters long - if so we consider that to be a long name.</p>
<div><pre><code><span>data</span> <span>Person</span> <span>=</span> <span>Person</span> {<span> personName ::</span> <span>String</span>,<span> personAge ::</span> <span>Int</span> }

<span>personLongName ::</span> <span>Predicate</span> <span>Person</span>
personLongName <span>=</span> <span>Predicate</span> (\p <span>-&gt;</span> (length <span>.</span> personName <span>$</span> p) <span>&gt;</span> <span>10</span>)</code></pre></div>
<p>And we can run these <code>Predicate</code>s as:</p>
<div><pre><code>getPredicate numGreaterThanTen <span>5</span> <span>-- False</span>
getPredicate numGreaterThanTen <span>20</span> <span>-- True</span>

getPredicate strLengthGreaterThanTen <span>"hello"</span>       <span>-- False</span>
getPredicate strLengthGreaterThanTen <span>"hello world"</span> <span>-- True</span>

getPredicate personLongName <span>$</span> <span>Person</span> <span>"John"</span> <span>30</span>        <span>-- False</span>
getPredicate personLongName <span>$</span> <span>Person</span> <span>"Bartholomew"</span> <span>30</span> <span>-- True</span></code></pre></div>
<p>And this is fine, but there‚Äôs some duplication across each of the <code>Predicate</code>s - namely the part where we compare a number to ten:</p>
<div><pre><code>(\n <span>-&gt;</span> n <span>&gt;</span> <span>10</span>)  <span>-- Int</span>
(\s <span>-&gt;</span> (length s) <span>&gt;</span> <span>10</span>) <span>-- String</span>
(\p <span>-&gt;</span> (length <span>.</span> personName <span>$</span> p) <span>&gt;</span> <span>10</span>) <span>-- Person</span></code></pre></div>
<p>It would be nice if we didn‚Äôt have to repeat ourselves.</p>
<p>If we look at the differences between <code>numGreaterThanTen</code>, <code>strLengthGreaterThanTen</code> and <code>personLongName</code> we can see that the only difference is that one works on an <code>Int</code> and the others work on <code>String</code> and <code>Person</code> respectively. <code>strLengthGreaterThanTen</code> and <code>personLongName</code> each convert their input types to an <code>Int</code> and then do the same comparison:</p>
<div><pre><code><span>Predicate</span> (\(<span>n ::</span> <span>Int</span>) <span>-&gt;</span>
  <span>let</span> num <span>=</span> id n
  <span>in</span> num <span>&gt;</span> <span>10</span> <span>-- (1)</span>
) <span>-- numGreaterThanTen</span>


<span>Predicate</span> (\(<span>s ::</span>‚Ä¶</code></pre></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sanj.ink/posts/2020-06-13-contravariant-functors-are-weird.html">https://sanj.ink/posts/2020-06-13-contravariant-functors-are-weird.html</a></em></p>]]>
            </description>
            <link>https://sanj.ink/posts/2020-06-13-contravariant-functors-are-weird.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24491887</guid>
            <pubDate>Wed, 16 Sep 2020 12:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[File Transfer with SSH, Tee, and Base64]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 61 (<a href="https://news.ycombinator.com/item?id=24491605">thread link</a>) | @susam
<br/>
September 16, 2020 | https://susam.in/blog/file-transfer-with-ssh-tee-and-base64/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/file-transfer-with-ssh-tee-and-base64/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 19 Nov 2019</p>
<p>
Computer servers deployed in a secure environment may allow SSH sessions
but forbid SCP, SFTP, and execution of remote commands without a login
shell. Such restricted access is typically enforced with SSH gateways
and firewalls. An SSH gateway provides controlled access to the remote
system. A firewall can ensure that only an SSH gateway can connect to
the remote system. Thus, users can be forced to connect to the remote
system only via the SSH gateway which can now control what is allowed
and what isn't.
</p>

<p>
Even if SCP, SFTP, and remote command execution without a login shell
are forbidden, as long as we get a login shell on our terminal and we
can print data on the terminal, we are already able to transfer data
from the remote system to our local system. The data is in the terminal.
It is now only a matter of figuring out how to copy that data to a file.
Assuming that both the remote and local systems are Unix-like, the
following steps show one way to achieve this:
</p>

<ol>
  <li>
    <p>
      Connect to the remote system with <code>ssh</code> and pipe the
      output to <code>tee</code> to write the entire session to a text
      file on the local system.
    </p>
    <pre><code>ssh <em>user</em>@<em>host</em> | tee ssh.txt</code></pre>
    <p>
      This type of pipeline works as intended even while connecting to a
      remote system via a jumphost or an SSH gateway.
    </p>
  </li>

  <li>
    <p>
      In the remote system, create a 10 MB file to serve as an example
      payload to be transferred.
    </p>
    <pre><code>head -c 10485760 /dev/urandom &gt; /tmp/payload</code></pre>
    <p>
       You probably already have a meaningful payload that you want to
       copy, so in that case, you would skip this step.
    </p>
  </li>

  <li>
    <p>
      Compute checksum on the file. This will be used later to verify
      that the entire file is transferred correctly.
    </p>
    <pre><code>sha1sum /tmp/payload</code></pre>
  </li>

  <li>
    <p>
      Print Base64 representation of the file.
    </p>
    <pre><code>base64 /tmp/payload</code></pre>
    <p>
      Depending on the Internet bandwidth, this can take a few seconds
      to a few minutes to complete.
    </p>
  </li>

  <li>
    <p>
      End the SSH session.
    </p>
    <pre><code>exit</code></pre>
  </li>

  <li>
    <p>
      On the local system, extract the Base64 encoded payload and decode
      it. Assuming the shell prompt on the remote system ends with the
      dollar sign (i.e., <code>$</code>), the following command does
      this.
    </p>
    <pre><code>sed '1,/$ base64/d;/$ exit/,$d' ssh.txt | base64 --decode &gt; payload</code></pre>
  </li>

  <li>
    <p>
      Extract the checksum computed on the original file.
    </p>
    <pre><code>grep -A 1 sha1sum ssh.txt</code></pre>
  </li>

  <li>
    <p>
      Compute checksum on the decoded payload.
    </p>
    <pre><code>sha1sum payload</code></pre>
    <p>
      Ensure that the checksum in this step matches the checksum in the
      previous step.
    </p>
  </li>
</ol>

<p>
  The steps above assume the use of the <code>sha1sum</code> command to
  compute checksum. If this command is unavailable, use
  <code>sha1</code>, <code>shasum</code>, or something else that serves
  this purpose well. If you are worried about collision attacks, you
  might want <code>sha256sum</code>, <code>sha256</code>, <code>shasum
  -a 256</code>, etc. instead.
</p>


</div></div>]]>
            </description>
            <link>https://susam.in/blog/file-transfer-with-ssh-tee-and-base64/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24491605</guid>
            <pubDate>Wed, 16 Sep 2020 11:36:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Signal.NotifyContext: context cancelation with Unix signals coming to Go 1.16]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24491205">thread link</a>) | @henvic
<br/>
September 16, 2020 | https://henvic.dev/posts/signal-notify-context/ | <a href="https://web.archive.org/web/*/https://henvic.dev/posts/signal-notify-context/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        
        
        <p>Posted in <time datetime="2020-09-16 00:00:00 +0000 UTC"></time>Wednesday, 16 September 2020.</p>
        
        <p>From Go 1.16 onwards, you‚Äôll be able to use</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>ctx</span>, <span>stop</span> <span>:=</span> <span>signal</span>.<span>NotifyContext</span>(<span>context</span>.<span>Background</span>(), <span>os</span>.<span>Interrupt</span>)
<span>defer</span> <span>stop</span>()
</code></pre></td></tr></tbody></table>
</div>
</div><p>to control context cancelation using Unix signals, simplifying handling operating system signals in Go for certain common cases. This is my first contribution to the Go standard library, and I am very excited!</p>
<h2 id="why">Why</h2>
<p>When writing <abbr title="command-line interface">CLI</abbr> code, I often needed to handle cancellation ‚Äì for instance, when a user presses CTRL+C producing an interrupt signal. Another possible use case is to handle graceful termination of HTTP servers using <code>http.*Server.Shutdown(ctx)</code>.</p>
<p>I had to write code using the signal package often and in multiple places. I didn‚Äôt want that, so I wrote the <a href="https://github.com/henvic/ctxsignal">ctxsignal</a> package to solve this common problem two years ago.</p>
<p>However, I kept finding it in other places and noticing people would often not handle proper termination correctly or at all, so I got motivated to submit a proposal and try to improve this situation.</p>
<h2 id="how-to-use">How to use</h2>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span></code></pre></td>
<td>
<pre><code data-lang="go"><span>// This example passes a context with a signal to tell a blocking function that
</span><span>// it should abandon its work after an operating system signal is notified.
</span><span></span><span>func</span> <span>main</span>() {
	<span>// Pass a context with a timeout to tell a blocking function that it
</span><span></span>	<span>// should abandon its work after the timeout elapses.
</span><span></span>	<span>ctx</span>, <span>stop</span> <span>:=</span> <span>signal</span>.<span>NotifyContext</span>(<span>context</span>.<span>Background</span>(), <span>os</span>.<span>Interrupt</span>)
	<span>defer</span> <span>stop</span>()

	<span>select</span> {
	<span>case</span> <span>&lt;-</span><span>time</span>.<span>After</span>(<span>10</span> <span>*</span> <span>time</span>.<span>Second</span>):
		<span>fmt</span>.<span>Println</span>(<span>"missed signal"</span>)
	<span>case</span> <span>&lt;-</span><span>ctx</span>.<span>Done</span>():
		<span>stop</span>()
		<span>fmt</span>.<span>Println</span>(<span>"signal received"</span>)
	}
}
</code></pre></td></tr></tbody></table>
</div>
</div><p>This program will print <code>"missed signal"</code> after 10 seconds or will print <code>"signal received"</code> when the user sends an interruption signal, such as by pressing CTRL+C on a keyboard.</p>
<p>Please note that the second returned value of the <code>signal.NotifyContext</code> function is a function called <code>stop</code> instead of <code>cancel</code>. Once you‚Äôre done handling a system signal, you should call <code>stop</code>. We call it <code>stop</code> instead of <code>cancel</code> because you need to call it to stop capturing any further system signal you registered with <code>NotifyContext</code>.</p>
<blockquote>
<p>The stop function unregisters the signal behavior, which, like signal.Reset, may restore the default behavior for a given signal.</p>
</blockquote>
<h2 id="timeline">Timeline</h2>
<ul>
<li>I submitted a <a href="https://github.com/golang/go/issues/37255">proposal</a> and <a href="https://golang.org/cl/219640">implementation</a> on 17 February (as WithContext in the signal package)</li>
<li>After some discussions, a somewhat modified proposal was accepted on 1 April as a WithCancelSignal in the context package</li>
<li>It was moved back to the proposal stage on 15 April after some concerns were presented about having it in the context package</li>
<li>After more discussions, it was accepted again on 20 May as NotifyContext in the signal package</li>
<li>A couple of days ago, I restarted working on it.</li>
<li>Today it got merged and is available in the tip</li>
<li><a href="https://tip.golang.org/doc/go1.16">Go 1.16</a> is expected to be released in February</li>
</ul>
<h2 id="other-points">Other points</h2>
<ul>
<li>I delayed working on it and missed the Go 1.15 release due to its <a href="https://github.com/golang/go/wiki/Go-Release-Cycle">code freeze window</a></li>
<li>Go uses <a href="https://www.gerritcodereview.com/">Gerrit</a> to track changes and code reviews.</li>
<li>I found Gerrit‚Äôs patchsets better over GitHub‚Äôs pull-requests to keep track of changes without losing context (pun intended).</li>
</ul>
<p>Thanks a lot to everyone who provided ideas, feedback, or code-reviewed my code. In particular, the Go team for the patience in helping me out.</p>

<p>If you click and buy any of these from Amazon after visiting the links above, I might get a commission from their <a href="https://affiliate-program.amazon.com/">Affiliate program</a>.</p>
<blockquote><p lang="en" dir="ltr">From Go 1.16 onwards, you‚Äôll be able to use context to handle operating system signals in Go for certain common cases. <a href="https://t.co/5H7P7QNWZq">https://t.co/5H7P7QNWZq</a><a href="https://twitter.com/hashtag/golang?src=hash&amp;ref_src=twsrc%5Etfw">#golang</a></p>‚Äî Henrique Vicente (@henriquev) <a href="https://twitter.com/henriquev/status/1306063440948137985?ref_src=twsrc%5Etfw">September 16, 2020</a></blockquote>



                
                        
</article></div>]]>
            </description>
            <link>https://henvic.dev/posts/signal-notify-context/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24491205</guid>
            <pubDate>Wed, 16 Sep 2020 10:09:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Form Design]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24490883">thread link</a>) | @mozillas
<br/>
September 16, 2020 | https://gerireid.com/forms.html | <a href="https://web.archive.org/web/*/https://gerireid.com/forms.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>



                <div>

                <div>
                    <h3>Here's my best practice guidelines for form design. </h3>
                    <p>Working on a design system for a bank has taught me a lot about forms. I've watched testing in our labs. I've worked alongside experts from specialist accessibility organisations. I've seen forms tested by disabled people and users of assistive technology. I've also read a lot of research.</p> 
                    <p>From all this learning I've formed my own forms best-practice guidelines. I thought it would be useful start recording it. Here's my work in progress. I do UI/UX so I'm coming at this from a designer's perspective.               
              
    </p><h2 id="principles"> First, some principles</h2>
                    
                    <hr>
					<p>It's important to start with with a set of principles. It's easy to become swayed by design trends and I have to bring myself back to the user.</p><p>I aspire to the <a href="https://inclusivedesignprinciples.org/">Inclusive Design Principles</a>. Designing forms for people experiencing permanent, temporary or situational disabilities improves the experience for everyone. I also look to the <a href="https://www.w3.org/WAI/WCAG21/Understanding/intro#understanding-the-four-principles-of-accessibility">WCAG</a> principles. Your website or app must be: </p>
	<ul>
	<li>perceivable</li>
	<li>operable</li>
	<li>understandable</li>
	<li>robust and compatible</li>

	</ul>
	<p>In summary, think of your user and keep things as simple and as functional as possible. But don't overvalue simplicity and style at the <a href="https://uxmyths.com/post/115783813605/myth-34-simple-minimal">cost of clarity</a>. In the words of Luke Wroblewski "<a href="https://aneventapart.com/news/post/obvious-always-wins-by-luke-wroblewski-aea-video">obvious always wins</a>".</p>

	
	
	<p><a href="#top">Back to top  ‚Üë</a></p><h2 id="text-input"> Text input</h2>

        <hr>
        <p>Simple input for a form. Easy to overcomplicate.</p>
		<div>        
        <h3>My guidelines</h3>  
        
        <ul>
        <li>Text input fields must have a visible label above the input box.</li>
        <li>Don't rely on placeholder text. It is not a substitute for a label.</li>
        <li>Place hint text under the form label.</li>
        <li>The size of the input box should reflect the intended input.</li>
        <li>Unless labelled otherwise, all fields in a form are required. Mark optional fields as 'optional'.</li>
        </ul>
         </div>  

 		<p><img src="https://gerireid.com/img/form-fields/text-input.png" alt="Graphic of a form input box"></p><h3>Research insights and sensible thinking</h3>
     
     	<h4>‚òû Placeholders</h4>
      	<ul>
      	<li><a href="https://www.w3.org/WAI/GL/low-vision-a11y-tf/wiki/Placeholder_Research">W3C Placeholder Research</a></li>
		<li><a href="https://www.uxmatters.com/mt/archives/2010/03/dont-put-hints-inside-text-boxes-in-web-forms.php">Don't Put Hints Inside Text Boxes in Web Forms</a> by Caroline Jarrett, UXmatters</li>
		<li><a href="https://www.nngroup.com/articles/form-design-placeholders/">Placeholders in Form Fields Are Harmful</a> by By Katie Sherwin, Nielsen Norman Group.</li>
				<li><a href="https://adamsilver.io/articles/placeholders-are-problematic/">Placeholders are problematic</a> by Adam Silver.</li>
		</ul>
		
		<h4>‚òû Labels</h4>
      	<ul>
      	<li><a href="https://www.uxmatters.com/mt/archives/2006/07/label-placement-in-forms.php">Label Placement in Forms</a> by Matteo Penzo, UXmatters.</li>
      	<li><a href="https://adamsilver.io/articles/always-use-a-label/">Always use a label</a> by Adam Silver.</li>
      	<li><a href="http://baymard.com/blog/mobile-forms-avoid-inline-labels">Mobile Form Usability: Never Use Inline Labels</a> by Baymard Institute.</li>
		<li><a href="https://bradfrost.com/blog/post/float-label-pattern/">Float label pattern</a> by Brad Frost.</li>
		<li><a href="https://webaim.org/techniques/forms/advanced#placeholder">Advanced Form Labelling</a> by WebAIM.</li>
		<li><a href="https://www.matsuko.ca/blog/stop-using-material-design-text-fields/?ref=uxlift.org">Stop using Material Design text fields!</a> by Matsuko Friedland.</li>
		<li><a href="http://preibusch.de/publications/Preibusch-Krol-Beresford__voluntary_over-disclosure.pdf"> The privacy economics of voluntary
over-disclosure in Web forms</a> by S√∂ren Preibusch, Kat Krol and Alastair R. Beresford, University of Cambridge Computer Laboratory. [See findings on options fields]</li>
		<li><a href="https://highlights.sawyerh.com/highlights/szZ8gGvk6MhIZNKSDpn2">Web Form Design</a> by Luke Wroblewski [Left-Aligned Labels snippet]</li>

		</ul>
 
      	<h4>‚òû Layout</h4>
      	<ul>
      	<li><a href="https://baymard.com/blog/avoid-multi-column-forms">Avoid Multi-Column Layouts</a> by Baymard Institute</li>
		</ul>    
     					
	<h3>Accessibility considerations for text input</h3>
		<ul>
		<li>Text needs a 4.5:1 contrast ratio against the background. <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/visual-audio-contrast-contrast.html">WCAG 1.4.3</a></li>
		<li>Input box outline needs a 3:1 contrast ratio against the background. <a href="https://www.w3.org/WAI/WCAG21/Understanding/non-text-contrast.html">WCAG 1.4.11</a></li>
		<li>Not all <a href="http://output.jsbin.com/vonesu/10/">screenreaders</a> read out placeholder text. See also <a href="https://www.w3.org/WAI/GL/low-vision-a11y-tf/wiki/Placeholder_Research">W3C placeholder research</a>.</li>
		<li>Not all <a href="https://caniuse.com/#feat=input-placeholder">browsers</a> support placeholder text.</li></ul>


	<h3>Text fields in the wild</h3>
        <ul>
		<li><a href="https://coop-design-system.herokuapp.com/pattern-library/foundations/input.html">Co-op Design Manual</a></li>
		<li><a href="https://design-system.barnardos.org.uk/components/forms/#text-input">Barnardos Design System</a></li>
		<li><a href="https://design-system.service.gov.uk/components/text-input/">Gov.uk Design System</a></li>
		<li><a href="https://service-manual.nhs.uk/design-system/components/text-input">NHS.UK Service Manual</a></li>
		</ul>

<p><a href="#top">Back to top  ‚Üë</a></p><h2 id="buttons"> Buttons</h2>

        <hr>
        <p>Buttons trigger an action or event such as continuing to the next stage or submitting a form. Use them purposely.</p>        
        
		<div>        
        	<h3>My guidelines</h3>  
        
       		 <ul>
        	<li>Button text should describe the action the button performs and be consistent through the journey.</li>
        	<li>Don't overload the user with choices. Use only one primary button on each page for the main action.</li>
        	<li>Place the submit button where users look for it. In a standard form journey this is usually to the left edge of the form, directly below the final field.</li>
        	<li>Make destructive buttons like cancel or previous harder for the user to find. A back button or link often works well above the form.</li>
        	<li>Avoid disabled buttons. They have poor contrast and can cause confusion.</li>
        	</ul>  

       		</div>


        <p><img src="https://gerireid.com/img/form-fields/button.png" alt="Graphic of a form field with a left aligned continue button"></p><h3>Research insights and sensible thinking</h3>
       <ul>
		<li><a href="https://medium.com/eightshapes-llc/buttons-in-design-systems-eac3acf7e23">Buttons in Design Systems</a> by Nathan Curtis.</li>
		<li><a href="https://www.lukew.com/ff/entry.asp?571">Primary &amp; Secondary Actions in Web Forms</a> by Luke Wroblewski.</li>
		<li><a href="http://www.effortmark.co.uk/seven-basic-best-practices-buttons/">Basic Best Practices for Buttons</a> by Caroline Jarrett.</li>
		<li><a href="https://adamsilver.io/articles/where-to-put-buttons-on-forms/">Where to put buttons on forms</a> by Adam Silver.</li>
		<li><a href="https://axesslab.com/disabled-buttons-suck/">Disabled buttons suck</a> by Hampus Sethfors, Axess Lab.</li>
		<li><a href="https://www.lukew.com/ff/entry.asp?740">Articles About Buttons</a> by Luke Wroblewski.</li>
		</ul>
					
	<h3>Accessibility considerations for buttons</h3>
        <ul>
		<li>Button text needs a 4.5:1 contrast ratio against the button container colour. <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/visual-audio-contrast-contrast.html">WCAG 1.4.3</a></li>
		<li>Button container needs a 3:1 contrast ratio against the background. <a href="https://www.w3.org/WAI/WCAG21/Understanding/non-text-contrast.html">WCAG 1.4.11</a></li>
		<li>When speccing out a button, remember to include a design for all the states; default, focus, hover, active. All states need sufficient colour contrast.</li>
		</ul>

	<h3>Buttons in the wild</h3>
        <ul>
        <li><a href="https://luna.sainsburys.co.uk/components/button">Sainsbury Luna Design System</a></li>
		<li><a href="https://design.bulb.co.uk/components/buttons">Bulb Solar Design System</a></li>	
		<li><a href="https://designsystem.gov.au/components/buttons/">Australian Government Design System</a></li>
		
		</ul>

<p><a href="#top">Back to top  ‚Üë</a></p><h2 id="radio-buttons"> Radio buttons</h2>

        <hr>
       <p>I like big radio buttons (and I cannot lie). They show all available choices upfront. Use a radio group when the user can only select one option from a list.  </p>
             
		<div>        
        	<h3>My guidelines</h3>  
        

       		 <ul>
		   	<li>Position radio buttons to the left of the label and stack options vertically.</li>
        	<li>Users can only select one option but don't assume that they will know this. </li>
        	<li>Once an option has been selected the user can't unselect it without refreshing their browser. Consider adding a 'none' option.</li>
        	<li>Order radios from most to least common options. If this will cause an unwanted bias, order options alphabetically.</li>
			<li>Place hint text under the form label.</li>  
			<li>Make radio buttons easy to tap, with a target height of at least 44 pixels.</li>
        	<li>Radio buttons must ALWAYS be round.</li>

        	</ul>  
       		
       		</div>
 
        <p><img src="https://gerireid.com/img/form-fields/radio-buttons.png" alt="Graphic of a form radio button group"></p><h3>Research insights and sensible thinking</h3>
        <ul>
       	<li>Max number of radio buttons? See <a href="https://lawsofux.com/millers-law">Millers Law</a>: The average person can only keep 7 items in their working memory.</li>
		<li><em>Contradicted by:</em> <a href="https://uxmyths.com/post/931925744/myth-23-choices-should-always-be-limited-to-seven">UX Myth #23:</a> Choices should always be limited to 7 :)</li>
		<li><a href="https://designnotes.blog.gov.uk/2016/11/30/weve-updated-the-radios-and-checkboxes-on-gov-uk/">We've updated the radios and checkboxes on GOV.UK</a> Government Digital Service.</li>		<li><a href="https://www.nngroup.com/articles/radio-buttons-default-selection/">Radio buttons: Select one by default or leave all unselected?</a> by Kara Pernice, Nielsen Norman Group.</li>
				<li><a href="https://technology.blog.gov.uk/2015/08/27/making-radio-buttons-and-checkboxes-easier-to-use/">Making radio buttons and checkboxes easier to use</a> by Robin Whittleton, GDS blog.</li>
<li><a href="https://design-system.service.gov.uk/get-started/labels-legends-headings/">Making labels and legends headings</a> Government Digital Service.</li>
				<li><a href="https://technology.blog.gov.uk/2015/08/27/making-radio-buttons-and-checkboxes-easier-to-use/">Making radio buttons and checkboxes easier to use</a> by Robin Whittleton, GDS blog.</li>
<li><a href="https://www.creativejuiz.fr/blog/en/tutorials/customize-checkbox-and-radio-button-with-css">Customize checkbox and radio button with CSS</a> by Geoffrey Crofte.</li>

		</ul>
					
	<h3>Accessibility considerations for radio buttons</h3>
        <ul>
		<li>Text needs a 4.5:1 contrast ratio against the background. <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/visual-audio-contrast-contrast.html">WCAG 1.4.3</a></li>
		<li>Radio button outline and fill needs a 3:1 contrast ratio against the background. <a href="https://www.w3.org/WAI/WCAG21/Understanding/non-text-contrast.html">WCAG 1.4.11</a></li>
		<li>For an accessible label, group radio buttons together in a <a href="https://www.w3.org/WAI/tutorials/forms/grouping/">field set</a> and legend that describes them.</li>
		<li>Selecting a radio button must not cause anything surprising to happen like submitting a form, significantly changing the content on the page, or moving the keyboard focus. <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/consistent-behavior-unpredictable-change.html">WCAG 3.2.2</a></li>

		</ul>

	<h3>Radio buttons in the wild</h3>
        <ul>
		<li><a href="https://design-system.service.gov.uk/components/radios/">Government Digital Service</a></li>
		<li><a href="https://service-manual.nhs.uk/design-system/components/radios">NHS Digital Service Manual</a></li>
		<li><a href="https://coop-design-system.herokuapp.com/pattern-library/foundations/checkboxes-and-radio-buttons.html">Co-op Design System</a>
		</li><li><a href="https://www.giffgaff.design/components/radio/">GiffGaff Design System</a></li>
		<li><a href="https://design-system.barnardos.org.uk/components/forms/#radio-buttons">Barnardos Design System</a></li>
		</ul>

<p><a href="#top">Back to top  ‚Üë</a></p><h2 id="checkboxes"> Checkboxes</h2>

        <hr>
        <p>Use a checkbox to select multiple items, they show all choices upfront. Users are generally familiar with the affordance of checking a box.  </p>

		<div>        
        	<h3>My guidelines</h3>  
        
       		 <ul>
		   	<li>Position checkboxes to the left of the label and stack options vertically.</li>
        	<li>Make it clear that the user can select multiple options.</li>
			<li>Place hint text under the form label.</li> 
			<li>Use a single checkbox where a user needs to indicate agreement (for example to terms and conditions).</li>
			<li>Make checkboxes easy to tap, with a target height of at least 44 pixels.</li>
			<li>Checkboxes must ALWAYS be square.</li>


        	</ul>  
       		
       		</div>
  
  <p><img src="https://gerireid.com/img/form-fields/check-boxes.png" alt="Graphic of a checkbox box"></p><h3>Research insights and sensible thinking</h3>
        <ul>
       	<li>Max number of radio buttons? See <a href="https://lawsofux.com/millers-law">Millers Law</a>: The average person can only keep 7 items in their working memory.</li>
		<li><em>Contradicted by:</em> <a href="https://uxmyths.com/post/931925744/myth-23-choices-should-always-be-limited-to-seven">UX Myth #23:</a> Choices should always be limited to 7 :)</li>
		<li><a href="https://designnotes.blog.gov.uk/2016/11/30/weve-updated-the-radios-and-checkboxes-on-gov-uk/">We've updated the radios and checkboxes on GOV.UK</a> Government Digital Service.</li>
		<li><a href="https://technology.blog.gov.uk/2015/08/27/making-radio-buttons-and-checkboxes-easier-to-use/">Making radio buttons and checkboxes easier to use</a> by Robin Whittleton, GDS blog.</li>
<li><a href="https://design-system.service.gov.uk/get-started/labels-legends-headings/">Making labels and legends headings</a> Government Digital Service.</li>
		</ul>
					
	<h3>Accessibility considerations for checkboxes</h3>
        <ul>
		<li>Text needs a 4.5:1 contrast ratio against the background. <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/visual-audio-contrast-contrast.html">WCAG 1.4.3</a></li>
		<li>Checkbox outline and checkmark needs a 3:1 contrast ratio against the background. <a href="https://www.w3.org/WAI/WCAG21/Understanding/non-text-contrast.html">WCAG 1.4.11</a></li>
        <li>For an accessible label, group checkboxes together in a <a href="https://www.w3.org/WAI/tutorials/forms/grouping/">field set</a> and legend that describes them.</li>
        <li>Checking a box must not cause anything surprising to happen like submitting a form, significantly changing the content on the page, or moving the keyboard focus. <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/consistent-behavior-unpredictable-change.html">WCAG 3.2.2</a></li>
		</ul>

	<h3>Checkboxes in the wild</h3>
        <ul>
		<li><a href="https://coop-design-system.herokuapp.com/pattern-library/foundations/checkboxes-and-radio-buttons.html">Co-op Design System</a>
		</li><li><a href="https://www.giffgaff.design/components/checkbox/">GiffGaff Design System</a></li>
		<li><a href="https://service-manual.nhs.uk/design-system/components/checkboxes">NHS Digital Service Manual</a></li>
		</ul>

<p><a href="#top">Back to top</a></p><h2 id="notifications"> Notifications</h2>

        <hr>
        <p>Notifications alert users to important information or changes on a page. Helpful ones attracts the user's attention without interrupting the flow of the task. They often appear at the top of a page following a submit action.</p>

		<div>        
        	<h3>My guidelines</h3>  
        
       		 <ul>
			<li>Notifications typically come in 4 flavours; Information, Warning, Success or Error.</li>
			<li>Users have a mental model for alert colours. Stick with Information=Blue, Warning=Orange, Positive=Green and Error=Red.</li>
			<li>Provide an additional indicator to colour, like an icon.</li>
			<li>Use notifications purposefully, keep text short and simple.</li>

        	</ul>  
       		
       		</div>
       		
       <p><img src="https://gerireid.com/img/form-fields/notifications.png" alt="Graphic of 4 notitications - warning, success, info and error"></p><h3>Research insights and sensible thinking</h3>
        <ul>
       	<li><a href="https://inclusive-components.design/notifications/">Inclusive Components: Notifications</a> by Heydon Pickering.</li>

		</ul>
					
	<h3>Accessibility considerations for notifications</h3>
        <ul>
		<li>Text needs a 4.5:1 contrast ratio against the background. Check coloured text on a tinted background. <a href="https://www.w3.org/TR/UNDERSTANDING-WCAG20/visual-audio-contrast-contrast.html">WCAG 1.4.3</a></li>
		<li>Icon needs a 3:1 contrast ratio against the background. <a href="https://www.w3.org/WAI/WCAG21/Understanding/non-text-contrast.html">WCAG 1.4.11</a></li>
        	<li>Consider users with colour vision deficiency. Test your alerts on a colour blind person, or use a free colour blind ‚Ä¶</li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gerireid.com/forms.html">https://gerireid.com/forms.html</a></em></p>]]>
            </description>
            <link>https://gerireid.com/forms.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490883</guid>
            <pubDate>Wed, 16 Sep 2020 09:09:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reveal 1.0: Read Eval Visualize Loop for Clojure]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24490363">thread link</a>) | @vlaaad
<br/>
September 16, 2020 | https://vlaaad.github.io/reveal/ | <a href="https://web.archive.org/web/*/https://vlaaad.github.io/reveal/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
      
      
      <p><img src="https://vlaaad.github.io/assets/reveal/demo.gif" alt="Demo"></p>



<ul id="markdown-toc">
  <li><a href="#rationale" id="markdown-toc-rationale">Rationale</a></li>
  <li><a href="#give-it-a-try" id="markdown-toc-give-it-a-try">Give it a try</a></li>
  <li><a href="#features" id="markdown-toc-features">Features</a>    <ul>
      <li><a href="#tap-support" id="markdown-toc-tap-support"><code>tap&gt;</code> support</a></li>
      <li><a href="#eval-on-selection" id="markdown-toc-eval-on-selection">Eval on selection</a></li>
      <li><a href="#inspect-object-fields-and-properties" id="markdown-toc-inspect-object-fields-and-properties">Inspect object fields and properties</a></li>
      <li><a href="#look-and-feel-customization" id="markdown-toc-look-and-feel-customization">Look and feel customization</a></li>
      <li><a href="#url-and-file-browser" id="markdown-toc-url-and-file-browser">URL and file browser</a></li>
      <li><a href="#doc-and-source" id="markdown-toc-doc-and-source">Doc and source</a></li>
      <li><a href="#ref-watchers" id="markdown-toc-ref-watchers">Ref watchers</a></li>
      <li><a href="#charts" id="markdown-toc-charts">Charts</a></li>
      <li><a href="#table-view" id="markdown-toc-table-view">Table view</a></li>
      <li><a href="#and-more" id="markdown-toc-and-more">‚Ä¶and more</a></li>
    </ul>
  </li>
  <li><a href="#using-reveal" id="markdown-toc-using-reveal">Using Reveal</a>    <ul>
      <li><a href="#ui-concepts-and-navigation" id="markdown-toc-ui-concepts-and-navigation">UI concepts and navigation</a></li>
      <li><a href="#customization" id="markdown-toc-customization">Customization</a></li>
      <li><a href="#user-api" id="markdown-toc-user-api">User API</a>        <ul>
          <li><a href="#repl" id="markdown-toc-repl"><code>repl</code></a></li>
          <li><a href="#io-prepl" id="markdown-toc-io-prepl"><code>io-prepl</code></a></li>
          <li><a href="#remote-prepl" id="markdown-toc-remote-prepl"><code>remote-prepl</code></a></li>
          <li><a href="#ui" id="markdown-toc-ui"><code>ui</code></a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#editor-integration" id="markdown-toc-editor-integration">Editor integration</a>    <ul>
      <li><a href="#cursive" id="markdown-toc-cursive">Cursive</a></li>
      <li><a href="#nrepl-based-editors" id="markdown-toc-nrepl-based-editors">Nrepl-based editors</a></li>
      <li><a href="#windows" id="markdown-toc-windows">Windows</a></li>
    </ul>
  </li>
  <li><a href="#extending-reveal" id="markdown-toc-extending-reveal">Extending reveal</a>    <ul>
      <li><a href="#formatters" id="markdown-toc-formatters">Formatters</a>        <ul>
          <li><a href="#low-level-text-emitting-sfs" id="markdown-toc-low-level-text-emitting-sfs">Low-level text emitting sfs</a></li>
          <li><a href="#delegating-sfs" id="markdown-toc-delegating-sfs">Delegating sfs</a></li>
          <li><a href="#overriding-sfs" id="markdown-toc-overriding-sfs">Overriding sfs</a></li>
        </ul>
      </li>
      <li><a href="#actions" id="markdown-toc-actions">Actions</a></li>
      <li><a href="#views" id="markdown-toc-views">Views</a>        <ul>
          <li><a href="#short-cljfx-intro" id="markdown-toc-short-cljfx-intro">Short cljfx intro</a></li>
          <li><a href="#built-in-components" id="markdown-toc-built-in-components">Built-in components</a></li>
          <li><a href="#pluggable-context-menu" id="markdown-toc-pluggable-context-menu">Pluggable context menu</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li><a href="#closing-thoughts" id="markdown-toc-closing-thoughts">Closing thoughts</a></li>
</ul>



<p>Repl is a great window into a running program, but the textual nature of its output limits developer‚Äôs ability to inspect the program: a text is not an object, and we are dealing with objects in the VM.</p>

<p>Reveal aims to solve this problem by creating an in-process repl output pane that makes inspecting values as easy as selecting an interesting datum. It recognizes the value of text as a universal interface, that‚Äôs why its output looks like a text: you can select it, copy it, save it into a file. Unlike text, reveal output holds references to printed values, making inspecting selected value a matter of opening a context menu.</p>

<p>Unlike datafy/nav based tools, Reveal does not enforce a particular data representation for any given object, making it an open set ‚Äî that includes datafy/nav as one of the available options. It does not use datafy/nav by default because in the absence of inter-process communication to datafy is to lose.</p>

<p>Not being limited to text, Reveal uses judicious syntax highlighting to aid in differentiating various objects: text <code>java.lang.Integer</code> looks differently depending on whether it was produced from a symbol or a class.</p>



<p>The easiest way to try it is to run a Reveal repl:</p>
<div><div><pre><code>clj <span>\</span>
<span>-Sdeps</span> <span>'{:deps {vlaaad/reveal {:mvn/version "1.0.130"}}}'</span> <span>\</span>
<span>-m</span> vlaaad.reveal repl
</code></pre></div></div>
<p>Executing this command will start a repl and open Reveal output window that will mirror the evaluations in the shell.</p>



<h2 id="tap-support"><code>tap&gt;</code> support</h2>

<p>Clojure 1.10 added <code>tap&gt;</code> function with the purpose similar to printing the value for debugging, but instead of characters you get the object. Reveal repls show tapped values in their output windows ‚Äî you won‚Äôt need <code>println</code> anymore!</p>

<p><img src="https://vlaaad.github.io/assets/reveal/tap.gif" alt="Tap demo"></p>

<h2 id="eval-on-selection">Eval on selection</h2>

<p>You can evaluate code on any selected value by using text input in the context menu. You can write either a single symbol of a function to call or a form where <code>*v</code> will be replaced with selected value.</p>

<p><img src="https://vlaaad.github.io/assets/reveal/eval-on-selection.gif" alt="Eval on selection demo"></p>

<h2 id="inspect-object-fields-and-properties">Inspect object fields and properties</h2>

<p>Any object in the JVM has class and fields, making them easily accessible for inspection is extremely important. With <code>java-bean</code> contextual action you get a debugger-like view of objects in the VM. Access to this information greatly improves the visibility of the VM and allows to explore it. For example, for any class you have on the classpath you can get the place where it‚Äôs coming from:</p>

<p><img src="https://vlaaad.github.io/assets/reveal/java-bean.gif" alt="Java bean demo">
I learned about it after implementing this feature :)</p>

<h2 id="look-and-feel-customization">Look and feel customization</h2>

<p>Reveal can be configured with <code>vlaaad.reveal.prefs</code> java property to use different font or theme:</p>

<p><img src="https://vlaaad.github.io/assets/reveal/light-theme.png" alt="Light theme"></p>

<h2 id="url-and-file-browser">URL and file browser</h2>

<p>You can open URL-like things and files: both internally in Reveal and externally using other applications in your OS e.g. file explorer, browser or text editor.</p>

<p><img src="https://vlaaad.github.io/assets/reveal/browse.gif" alt="Browse demo"></p>

<h2 id="doc-and-source">Doc and source</h2>

<p>Reveal can show you documentation and sources for various runtime values ‚Äî namespaces, vars, symbols, functions, keywords (if they define a spec). Like <a href="https://cljdoc.org/">cljdoc</a>, it supports <code>[[wikilink]]</code> syntax in docstrings to refer to other vars, making them accessible for further exploration.</p>

<p><img src="https://vlaaad.github.io/assets/reveal/doc-and-source.gif" alt="Doc and source demo"></p>

<h2 id="ref-watchers">Ref watchers</h2>
<p>Reveal can watch any object implementing <code>clojure.lang.IRef</code> (things like atoms, agents, vars, refs) and display it either automatically updated or as a log of successors.</p>

<p><img src="https://vlaaad.github.io/assets/reveal/watchers.gif" alt="Ref watchers demo"></p>

<h2 id="charts">Charts</h2>

<p>Reveal can show data of particular shapes as charts that are usually explorable: when you find an interesting data point on the chart, you can then further inspect the data in that data point.</p>

<p>The simplest shape is labeled numbers. Labeled means that those numbers exist in some collection that has a unique label for every number. For maps, keys are labels, for sequential collections, indices are labels and for sets, numbers themselves are labels.</p>

<p>A pie chart shows labeled numbers:</p>

<p><img src="https://vlaaad.github.io/assets/reveal/pie-chart.gif" alt="Pie chart demo"></p>

<p>Other charts support more flexible data shapes ‚Äî both because they can show more than one data series, and because they can be explored, where it might be useful to attach some metadata with the number. Since JVM numbers don‚Äôt allow metadata, you can instead use tuples where the first item is a number and second is the metadata. Bar charts can display labeled numbers (single data series) or labeled numbers that are themselves labeled (multiple data series):</p>

<p><img src="https://vlaaad.github.io/assets/reveal/bar-chart.gif" alt="Bar chart demo"></p>

<p>Line charts are useful to display progressions, so Reveal suggests them to display sequential numbers (and labeled sequential numbers):</p>

<p><img src="https://vlaaad.github.io/assets/reveal/line-chart.gif" alt="Line chart demo"></p>

<p>Finally, Reveal has scatter charts to display coordinates on a 2D plane. A coordinate is represented as a tuple of 2 numbers and as with numbers, you can use a tuple of coordinate and arbitrary value in the place of coordinate. Reveal will suggest scatter charts for collections of coordinates and labeled collections of coordinates.</p>

<p><img src="https://vlaaad.github.io/assets/reveal/scatter-chart.gif" alt="Scatter chart demo"></p>

<h2 id="table-view">Table view</h2>

<p>There are cases where it is better to make sense of the value when it is represented by a table: collections of homogeneous items where columns make it easier to compare corresponding parts of those items, and big deeply nested data structures where it‚Äôs easier to look at them layer by layer.</p>

<p><img src="https://vlaaad.github.io/assets/reveal/table.gif" alt="Table view demo"></p>

<h2 id="and-more">‚Ä¶and more</h2>

<p>Reveal was designed to be performant: it can stream syntax-highlighted output very fast. In addition to that, there are various helpers for data inspection:</p>
<ul>
  <li>text search that is triggered by <kbd>/</kbd> or <kbd>Ctrl F</kbd>;</li>
  <li>out of the box <a href="https://github.com/lambdaisland/deep-diff2">lambdaisland‚Äôs deep-diff</a> output highlighting: all you need to do is have it on the classpath;</li>
  <li>various contextual actions:
    <ul>
      <li>deref derefable things;</li>
      <li>get meta if a selected value has some meta;</li>
      <li>convert java array to vector;</li>
      <li>view the color of a thing that describes a color (like <code>"#fff"</code> or <code>:red</code>);</li>
    </ul>
  </li>
</ul>



<h2 id="ui-concepts-and-navigation">UI concepts and navigation</h2>

<p><img src="https://vlaaad.github.io/assets/reveal/concepts.png" alt="Concepts"></p>

<p>Reveal UI is made of 3 components:</p>
<ul>
  <li>output panel that contains data submitted to reveal window (e.g. repl output);</li>
  <li>a context menu that can invoke actions on selected values;</li>
  <li>results panel that has 1 or more tabs with action results produced from the context menu.</li>
</ul>

<p>Navigation:</p>
<ul>
  <li>Use <kbd>Space</kbd>, <kbd>Enter</kbd> or right mouse button to open a context menu on selection;</li>
  <li>Use <kbd>Tab</kbd> to switch focus between output and results panel;</li>
  <li>In results panel:
    <ul>
      <li>Use <kbd>Ctrl ‚Üê</kbd> and <kbd>Ctrl ‚Üí</kbd> to switch tabs in results panel;</li>
      <li>Use <kbd>Esc</kbd> to close the tab</li>
    </ul>
  </li>
  <li>In a context menu:
    <ul>
      <li>Use <kbd>‚Üë</kbd> and <kbd>‚Üì</kbd> to move focus between available actions and input text field;</li>
      <li>Use <kbd>Enter</kbd> to execute selected action or form written in the text field;</li>
      <li>Use <kbd>Esc</kbd> to close the context menu.</li>
    </ul>
  </li>
</ul>

<h2 id="customization">Customization</h2>

<p>Reveal can be customized using <code>vlaaad.reveal.prefs</code> java property that contains an edn map of UI preferences. Supported keys (all optional):</p>
<ul>
  <li><code>:theme</code> ‚Äî color theme, <code>:light</code> or <code>:dark</code>;</li>
  <li><code>:font-family</code> ‚Äî system font name (like <code>"Consolas"</code>) or URL (like <code>"file:/path/to/font.ttf"</code> or <code>"https://ff.static.1001fonts.net/u/b/ubuntu.mono.ttf"</code>) ‚Äî reveal only supports monospaced fonts;</li>
  <li><code>:font-size</code> ‚Äî font size, number.</li>
</ul>

<p>Example:</p>
<div><div><pre><code><span>$ </span>clj <span>-A</span>:reveal <span>\</span>
<span>-J-Dvlaaad</span>.reveal.prefs<span>=</span><span>'{:font-family "Consolas" :font-size 15}'</span> <span>\</span>
<span>-m</span> vlaaad.reveal repl
</code></pre></div></div>

<h2 id="user-api">User API</h2>

<p>The main entry point to Reveal is <code>vlaaad.reveal</code> ns that has various repls and lower-level functionality for data inspection.</p>

<h3 id="repl"><code>repl</code></h3>

<p>It is a repl wraps <code>clojure.main/repl</code> with additional support for <code>:repl/quit</code> and <code>tap&gt;</code>. It is as simple as it gets. I use it all the time. Example:</p>

<div><div><pre><code><span>$ </span>clj <span>-A</span>:reveal <span>-m</span> vlaaad.reveal repl
<span># Reveal window appears</span>
Clojure 1.10.1
<span>user</span><span>=&gt;</span>
</code></pre></div></div>

<h3 id="io-prepl"><code>io-prepl</code></h3>

<p>This prepl works like <code>clojure.core.server/io-prepl</code>. Its purpose is to be run in a process on your machine that you want to connect to using another prepl-aware tool. Example:</p>

<div><div><pre><code><span>$ </span>clj <span>-A</span>:reveal <span>\</span>
<span>-J-Dclojure</span>.server.reveal<span>=</span><span>'{:port 5555 :accept vlaaad.reveal/io-prepl}'</span>
</code></pre></div></div>
<p>Now you can connect to this process using any socket repl and it will show a Reveal window for every connection:</p>
<div><div><pre><code><span>$ </span>nc localhost 5555
<span># reveal window appears</span>
<span>(</span>+ 1 2 3<span>)</span> <span># input</span>
<span>{</span>:tag :ret, :val <span>"6"</span>, :ns <span>"user"</span>, :ms 1, :form <span>"(+ 1 2 3)"</span><span>}</span> <span># output</span>
</code></pre></div></div>

<h3 id="remote-prepl"><code>remote-prepl</code></h3>

<p>Reveal is the most useful when it runs in the process where the development happens. This prepl, unlike the previous two, is not like that: it connects to a remote process and shows a window for values that arrived from the network. It can‚Äôt benefit from easy access to printed references because these references are pointing to values deserialized from bytes, not values in the target VM. It‚Äôs still nice and performant repl, and it‚Äôs useful when you want to use Reveal to talk to another process that does not have Reveal on the classpath (e.g. production or ClojureScript prepl).</p>

<p>Example:</p>
<ol>
  <li>Start a prepl without Reveal on the classpath:
    <div><div><pre><code><span>$ </span> clj <span>\</span>
<span>-Sdeps</span> <span>'{:deps {org.clojure/clojurescript {:mvn/version "1.10.764"}}}'</span> <span>\</span>
<span>-J-Dclojure</span>.server.cljs-prepl<span>=</span><span>'{:port 50505 :accept cljs.server.browser/prepl}'</span>
</code></pre></div>    </div>
  </li>
  <li>Connect to that prepl using Reveal:
    <div><div><pre><code>$ clj -A:reveal -m vlaaad.reveal remote-prepl :port 50505
# at this point, 2 things happen:
# 1. Browser window with cljs prepl appears
# 2. Reveal window opens

# input
js/window

# output
{:tag :ret, 
 :val #object [Window [object Window]], 
 :ns "cljs.user", 
 :ms 25, 
 :form "js/window"}
</code></pre></div>    </div>
  </li>
</ol>

<h3 id="ui"><code>ui</code></h3>

<p>Calling this function will create and show a Reveal window. It returns a function that you can submit values to ‚Äî they will appear in the output panel. All built-in visual repls are thin wrappers of other repls that submit values to a window created by this generic function. You can use it to create custom Reveal-flavored repls, or, instead of using it as a repl, you can configure Reveal to only show tapped values.</p>

<p>Example:</p>
<div><div><pre><code><span>(</span><span>require</span><span> </span><span>'</span><span>[</span><span>vlaaad.reveal</span><span> </span><span>:as</span><span> </span><span>reveal</span><span>])</span><span>

</span><span>;; open a window that will show tapped values:</span><span>
</span><span>(</span><span>add-tap</span><span> </span><span>(</span><span>reveal/ui</span><span>))</span><span>

 </span><span>;; submit value to the window:</span><span>
</span>‚Ä¶</code></pre></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vlaaad.github.io/reveal/">https://vlaaad.github.io/reveal/</a></em></p>]]>
            </description>
            <link>https://vlaaad.github.io/reveal/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490363</guid>
            <pubDate>Wed, 16 Sep 2020 07:33:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why is Apple acting like an asshole?]]>
            </title>
            <description>
<![CDATA[
Score 560 | Comments 479 (<a href="https://news.ycombinator.com/item?id=24490326">thread link</a>) | @ig0r0
<br/>
September 16, 2020 | https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/ | <a href="https://web.archive.org/web/*/https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>Today Apple announced <a href="https://www.apple.com/apple-events/september-2020/">at their media event</a> that the final public release of iOS 14 ships tomorrow, which came as quite a shock to all third-party developers.</p>

<!--excerpt-->

<p>This unwelcome surprise comes against the backdrop of dozens of controversies around the App Store ‚Äî most recently <a href="https://www.theverge.com/2020/6/16/21293419/hey-apple-rejection-ios-app-store-dhh-gangsters-antitrust">Hey.com</a> and <a href="https://daringfireball.net/linked/2020/08/28/apple-terminates-epic-games-account">Epic</a>, but more generally its <a href="https://marco.org/2020/09/11/app-review-changes">painfully confusing</a> and <a href="https://inessential.com/2020/05/10/heads_up_to_rss_reader_authors">arbitrarily applied</a> rules, its incomprehensible <a href="https://mjtsai.com/blog/tag/rejection/">app rejections</a> and their often sudden retractions, app <a href="https://www.macrumors.com/2016/03/07/flexbright-adjust-display-temperature/">approvals followed by sudden removals</a> without explanation, and the general unequal treatment of developers where <a href="https://gizmodo.com/researchers-uber-s-ios-app-had-secret-permissions-that-1819177235">big companies</a> or favorites <a href="https://mjtsai.com/blog/2019/02/27/bbedit-12-6-to-return-to-the-mac-app-store/">get special treatment</a>. It leaves me wondering, what the hell is Apple‚Äôs strategy here? This is not a flurry of bad PR for the sake of it. There are serious problems here that need to be addressed ‚Äî in particular, Developer Relations.</p>

<div>
    
    <div>
        <figure>
            <img src="https://www.jessesquires.com/img/appholes.jpg" title="Appholes" alt="Appholes">
            <div>
                
            </div>
        </figure>
    </div>
    
</div>

<h4>* * *</h4>

<p>Historically, these events announce new hardware and the upcoming release of the next major version of iOS, which is typically made public a few days later or the following week. For as long as I can remember it goes something like this:</p>

<ul>
  <li>Apple hosts a media event on a Tuesday in September.</li>
  <li>Announcements include new iPhones, iPads, and Watches. Or, at least some combination of those. Maybe something about Apple TV.</li>
  <li>All of the new hardware will run the latest version of iOS (or watchOS, or tvOS).</li>
  <li>The next major release of iOS is announced to be shipping on Friday (in a few days) or sometime the following week, like the next Tuesday.</li>
</ul>

<p>But today, Apple announced that iOS 14 is shipping <strong>tomorrow</strong>. This was near the end of the event ‚Äî at roughly 11:00 AM Pacific time. This means West Coast developers have half a day to put the final touches on their app updates for iOS 14 <strong>AND</strong> get their apps submitted with the just-released Xcode 12 GM <strong>AND</strong> get through App Store review. None of those tasks are trivial, and no one familiar with them would agree that this is a sufficient amount of time to complete them. If you happen to be working on the East Coast, this means you were given just a few hours before the working day was over to get your app ready and submitted. And if you live in Europe or anywhere else in the world, well, go fuck yourself and good luck tomorrow!</p>

<p>On top of this, critical bugs still exist in the latest releases of the SDKs, Xcode 12, and iOS 14. It seems they will not be addressed.</p>

<h4>* * *</h4>

<p>Given the increasingly tenuous relationship that Apple has with developers, I do not understand how it could be in their interest to act like such an asshole right now. Not to mention, it is unlikely that they will even be able to review all of these app submissions in time. We already do not feel valued due to the aforementioned issues, and this is an outright negligent response to developer relationships the company has damaged over the past few years. Announcing that iOS 14 ships tomorrow with virtually no notice to developers is yet another breach of trust, another disappointment, and quite frankly feels like a big ‚Äòfuck you‚Äô to developers. What purpose does it serve to place this last-minute, unnecessary stress on third-party developers?</p>

<p>Who is in charge of iOS releases at Apple that thought this was a good idea? Who is the head of Developer Relations that thought this was a good idea?</p>

<p>To whomever made these decisions: <strong>y‚Äôall fucked up. Again.</strong></p>

    </div></div>]]>
            </description>
            <link>https://www.jessesquires.com/blog/2020/09/15/why-is-apple-acting-like-an-asshole/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490326</guid>
            <pubDate>Wed, 16 Sep 2020 07:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kontrast Is a Contrast Checker]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24490131">thread link</a>) | @_ZeD_
<br/>
September 15, 2020 | https://carlschwan.eu/2020/09/15/kontrast-1.0.html | <a href="https://web.archive.org/web/*/https://carlschwan.eu/2020/09/15/kontrast-1.0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <article>
  <header>
    
    
    <p>
      September 15, 2020
      
    </p>
    
  </header>
  <section><p>Kontrast is a contrast checker available for desktop and mobile devices. You can
use Kontrast to choose background and text color combinations for your website or
app that your users will find easy to read. Kontrast can help you improve the
accessibility for your site or app for people with vision problems.</p>

<p>Kontrast won‚Äôt catch all the problems, but it should still be very helpful to catch
many issues early on, when designing your interface.</p>

<p>I released the first version of Kontrast earlier this month.</p>

<p><img src="https://cdn.kde.org/screenshots/kontrast/kontrast.png" alt="Kontrast main page"></p>

<p>Another big feature of Kontrast is the possibility to generate random color
combinations with good contrast. These colors can be saved in the application itself,
so that you can keep a particularly good color combination for later use.</p>

<p>Kontrast is available for the Linux desktop, <a href="https://plasma-mobile.org/">Plasma Mobile</a> and
there is also a Beta version for Android.</p>

<p>This application is built using the excellent <a href="https://develop.kde.org/frameworks/kirigami">Kirigami</a>
framework.</p>

<p><img src="https://cdn.kde.org/screenshots/kontrast/kontrat_mobile.png" alt="Kontrast mobile view"></p>

<p>You can download and install Kontrast from <a href="https://flathub.org/apps/details/org.kde.kontrast">Flathub</a> and
a nightly build is also available <a href="https://binary-factory.kde.org/job/Kontrast_android/">in binary factory</a>.</p>

<p>The tarball is available <a href="https://download.kde.org/stable/kontrast/kontrast-1.0.2.tar.xz">here</a>
and is signed with my gpg key <a href="https://carlschwan.eu/gpg.html">14B0ED91B5783415D0AA1E0A06B35D38387B67BE</a>.</p>

<h2 id="future-improvements">Future Improvements</h2>

<p>Future plans include improving the Android build, possibly release a stable
build of the Android version and also create a QtQuick-based color picker
that is better integrated with the application.</p>
</section>
  

</article>

<!-- Post navigation -->


    </div></div>]]>
            </description>
            <link>https://carlschwan.eu/2020/09/15/kontrast-1.0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490131</guid>
            <pubDate>Wed, 16 Sep 2020 06:40:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Primitive binary functions]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24490108">thread link</a>) | @tekknolagi
<br/>
September 15, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-5/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-5/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> ‚Äì <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-4/">previous</a></em></p>

<p>Welcome back to the ‚ÄúCompiling a Lisp‚Äù series. Last time, we added some
primitive unary instructions like <code>add1</code> and <code>integer-&gt;char</code>. This time, we‚Äôre
going to add some primitive <em>binary</em> functions like <code>+</code> and <code>&lt;</code>. After this
post, we‚Äôll be able to compile programs like:</p>



<p>Note that these expressions may look like function calls but, like last
chapter, they are not opening new stack frames (which I‚Äôll explain more about
later). Instead, the compiler will recognize that the programmer is directly
applying the symbol <code>+</code> and generate special code. You can think about this
kind of like an inlined function call.</p>

<p>It‚Äôs important to remember that the compiler has a certain internal contract:
the result of any given compiled expression is stored in <code>rax</code>. This isn‚Äôt some
intrinsic property of all compilers, but it‚Äôs one we‚Äôve kept so far in this
series.</p>

<blockquote>
  <p>This is similar to but not the same as the calling convention that I
mentioned earlier, where function results are stored in <code>rax</code>. That calling
convention is for interacting with other people‚Äôs code. Within your own
generated code, there are no rules. So we could pick any other register,
really, for storing intermediate results.</p>
</blockquote>

<p>Now that we‚Äôre building primitive functions that can take two arguments, you
might notice a problem: our strategy of storing the result in <code>rax</code> won‚Äôt work
on its own. If we were to na√Øvely write something like the following to
implement <code>+</code>, then <code>rax</code> would get overwritten in the code generated by
compiling <code>operand1(args)</code>:</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"+"</span><span>))</span> <span>{</span>
      <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>operand2</span><span>(</span><span>args</span><span>)));</span>
      <span>// The result of this is stored in rax ^</span>
      <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>operand1</span><span>(</span><span>args</span><span>)));</span>
      <span>// Oops, we just overwrote rax ^</span>
      <span>Emit_add_something</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>kRax</span><span>));</span>
      <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>// ...</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>We could try and work around this by adding some kind of register allocation
algorithm and take advantage of <code>rcx</code>, <code>rdx</code>, etc. Or, simpler, we could decide
to allocate all intermediate values on the stack and move on with our lives. I
prefer the latter. It‚Äôs simpler.</p>

<h3 id="stack-background-info">Stack background info</h3>

<p>Since we can‚Äôt yet save our compiled programs to disk, there‚Äôs some amount of
setup that has to happen before they‚Äôre run. Right now, the C programs I‚Äôm
providing along with this series compile to binaries that just run the test
suites for the compiler. They don‚Äôt actually run full programs. For this
reason, there are already some call frames on the stack by the time our
generated code is run.</p>

<p>Let‚Äôs take a look at the stack at the moment we enter a compiled Lisp program:</p>

<div><div><pre><code>|                  | High addresses
+------------------+
|  main            |
+------------------+ |
|  ~ some data ~   | |
|  ~ some data ~   | |
+------------------+ |
|  compile_test    | |
+------------------+ |
|  ~ some data ~   | |
|  ~ some data ~   | v
+------------------+
|  Testing_exe...  | rsp (stack pointer)
+------------------+
|                  | &lt;-- Our frame!
|                  | Low addresses
</code></pre></div></div>

<p>In this diagram, we have the C program‚Äôs <code>main</code> function, which has its own
local variables and so on. Then the <code>main</code> function calls the <code>compile_test</code>
unit suite. This in turn calls this <code>Testing_execute_expr</code> function
(abbreviated in the diagram), which is responsible for calling into our
generated code. Every call stores the return address (some place to find the
next instruction to execute) on the stack and adjusts <code>rsp</code> down.</p>

<blockquote>
  <p>Refresher: the call stack grows <em>down</em>. Why? Check out this <a href="https://stackoverflow.com/a/54391533/569183">StackOverflow
answer</a> that quotes an architect
on the Intel 4004 and 8080 architectures. It‚Äôs stayed the same ever since.</p>
</blockquote>

<p>In this diagram, we have <code>rsp</code> pointing at a return address somewhere inside
the function <code>Testing_execute_expr</code>, since that‚Äôs what called our Lisp
entrypoint. We have some data ‚Äúabove‚Äù (higher addresses) <code>rsp</code> that we‚Äôre not
allowed to poke at, and we have this empty space ‚Äúbelow‚Äù (lower addresses)
<code>rsp</code> that is in our current <em>stack frame</em>. I say ‚Äúempty‚Äù because we haven‚Äôt
yet stored anything there, not because it‚Äôs necessarily zero-ed out.  I don‚Äôt
think there are any guarantees about the values in this stack frame.</p>

<p>We can use our stack frame to write and read values for our current Lisp
program. With every recursive subexpression, we can allocate a little more
stack space to keep track of the values. When I say ‚Äúallocate‚Äù, I mean
‚Äúsubtract from the stack pointer‚Äù, because the stack is already a contiguous
space in memory allocated for us. For example, here is how we can write to the
stack:</p>



<p>This puts the integer <code>4</code> at displacement <code>-8</code> from <code>rsp</code>. On the stack diagram
above, it would be at the slot labeled ‚ÄúOur frame‚Äù. It‚Äôs also possible to read
with a positive or zero displacement, but those point to previous stack frames
and the return address, respectively. So let‚Äôs avoid manipulating those.</p>

<blockquote>
  <p>Note that I used a multiple of 8. Not every store has to be a to an address
that is a multiple of 8, but it is natural and I think also <em>faster</em> to store
8-byte-sized things at aligned addresses.</p>
</blockquote>

<p>Let‚Äôs walk through a real example to get more hands-on experience with this
stack storage idea. We‚Äôll use the program <code>(+ 1 2)</code>. The compiled version of
that program should:</p>

<ul>
  <li>Move <code>compile(2)</code> to <code>rax</code></li>
  <li>Move <code>rax</code> into <code>[rsp-8]</code></li>
  <li>Move <code>compile(1)</code> to <code>rax</code></li>
  <li>Add <code>[rsp-8]</code> to <code>rax</code></li>
</ul>

<p>So after compiling that, the stack will look like this:</p>

<div><div><pre><code>|                  | High addresses
+------------------+
|  Testing_exe...  | RSP
+------------------+
|  0x8             | RSP-8 (result of compile(2))
|                  | Low addresses
</code></pre></div></div>

<p>And the result will be in <code>rax</code>, per our internal compiler contract.</p>

<p>This is all well and good, but at some point we‚Äôll need our compiled programs
to emit the <code>push</code> instruction or make function calls of their own. Both of
these modify the stack pointer. <code>push</code> writes to the stack and decrements
<code>rsp</code>. <code>call</code> is roughly equivalent to <code>push</code> followed by <code>jmp</code>.</p>

<p>For that reason, x86-64 comes with another register called <code>rbp</code> and it‚Äôs
designed to hold the Base Pointer. While the stack pointer is supposed to track
the ‚Äútop‚Äù (low address) of the stack, the base pointer is meant to keep a
pointer around to the ‚Äúbottom‚Äù (high address) of our current stack frame.</p>

<p>This is why in a lot of compiled code you see the following instructions
repeated<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code><span>myfunction:</span>
<span>push</span> <span>rbp</span>
<span>mov</span> <span>rbp</span><span>,</span> <span>rsp</span>
<span>sub</span> <span>rsp</span><span>,</span> <span>N</span>  <span>; optional; allocate stack space for locals</span>
<span>; ... function body ...</span>
<span>mov</span> <span>rsp</span><span>,</span> <span>rbp</span>  <span>; required if you subtracted from rsp above</span>
<span>pop</span> <span>rbp</span>
<span>ret</span>
</code></pre></div></div>

<p>The first three instructions, called the <em>prologue</em>, save <code>rbp</code> to the stack,
and then set <code>rbp</code> to the current stack pointer. Then it‚Äôs possible to maintain
steady references to variable locations on the stack even as <code>rsp</code> changes.
Yes, the compiler could adjust its internal table of references every time the
compiler emits code that modifies <code>rsp</code>, but that sounds much harder.</p>

<p>The last three instructions, called the <em>epilogue</em>, fetch the old <code>rbp</code> that we
saved to the stack, write it back into <code>rbp</code>, then exit the call.</p>

<p>To confirm this for yourself, check out this <a href="https://godbolt.org/z/qPM8Mh">sample compiled C
code</a>. Look at the disassembly following the
label <code>square</code>. Prologue, code, epilogue.</p>

<h3 id="stack-allocation-infrastructure">Stack allocation infrastructure</h3>

<p>Until now, we haven‚Äôt needed to keep track of much as we recursively traverse
expression trees. Now, in order to keep track of how much space on the stack
any given compiled code will need, we have to add more state to our compiler.
We‚Äôll call this state the <code>stack_index</code> ‚Äî Ghuloum calls it <code>si</code> ‚Äî and we‚Äôll
pass it around as a parameter. Whatever it‚Äôs called, it points to the first
writable (unused) index in the stack at any given point.</p>

<p>In compiled functions, the first writable index is <code>-kWordSize</code> (<code>-8</code>), since
the base pointers is already at <code>0</code>.</p>

<div><div><pre><code><span>int</span> <span>Compile_function</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>)</span> <span>{</span>
  <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kFunctionPrologue</span><span>,</span> <span>sizeof</span> <span>kFunctionPrologue</span><span>);</span>
  <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>node</span><span>,</span> <span>-</span><span>kWordSize</span><span>));</span>
  <span>Buffer_write_arr</span><span>(</span><span>buf</span><span>,</span> <span>kFunctionEpilogue</span><span>,</span> <span>sizeof</span> <span>kFunctionEpilogue</span><span>);</span>
  <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>I‚Äôve also gone ahead and added the prologue and epilogue. They‚Äôre stored in
static arrays. This makes them easier to modify, and also makes them accessible
to testing helpers. The testing helpers can use these arrays to make testing
easier for us ‚Äî we can check if our expected code is book-ended by this code.</p>

<div><div><pre><code><span>static</span> <span>const</span> <span>byte</span> <span>kFunctionPrologue</span><span>[]</span> <span>=</span> <span>{</span>
    <span>// push rbp</span>
    <span>0x55</span><span>,</span>
    <span>// mov rbp, rsp</span>
    <span>kRexPrefix</span><span>,</span> <span>0x89</span><span>,</span> <span>0xe5</span><span>,</span>
<span>};</span>

<span>static</span> <span>const</span> <span>byte</span> <span>kFunctionEpilogue</span><span>[]</span> <span>=</span> <span>{</span>
    <span>// pop rbp</span>
    <span>0x5d</span><span>,</span>
    <span>// ret</span>
    <span>0xc3</span><span>,</span>
<span>};</span>
</code></pre></div></div>

<p>For <code>Compile_expr</code>, we just pass this new stack index through.</p>

<div><div><pre><code><span>int</span> <span>Compile_expr</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>,</span> <span>word</span> <span>stack_index</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>if</span> <span>(</span><span>AST_is_pair</span><span>(</span><span>node</span><span>))</span> <span>{</span>
    <span>return</span> <span>Compile_call</span><span>(</span><span>buf</span><span>,</span> <span>AST_pair_car</span><span>(</span><span>node</span><span>),</span> <span>AST_pair_cdr</span><span>(</span><span>node</span><span>),</span>
                        <span>stack_index</span><span>);</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>And for <code>Compile_call</code>, we actually get to use it. Let‚Äôs look back at our stack
storage strategy for compiling <code>(+ 1 2)</code> (now replacing <code>rsp</code> with <code>rbp</code>):</p>

<ul>
  <li>Move <code>compile(2)</code> to <code>rax</code></li>
  <li>Move <code>rax</code> into <code>[rbp-8]</code></li>
  <li>Move <code>compile(1)</code> to <code>rax</code></li>
  <li>Add <code>[rbp-8]</code> to <code>rax</code></li>
</ul>

<p>For binary functions, this can be generalized to:</p>

<ul>
  <li>Compile <code>arg2</code> (stored in <code>rax</code>)</li>
  <li>Move <code>rax</code> to <code>stack_index</code></li>
  <li>Compile <code>arg1</code> (stored in <code>rax</code>)</li>
  <li>Do something with the results (in <code>[rbp-stack_index]</code> and <code>rax</code>)</li>
</ul>

<p>The key is this: for the first recursive call to <code>Compile_expr</code>, the compiler
is allowed to emit code that can use the current <code>stack_index</code> and anything
below that on the stack. For the <em>second</em> recursive call to <code>Compile_expr</code>, the
compiler has to bump <code>stack_index</code>, since we‚Äôve stored the result of the first
compiled call at <code>stack_index</code>.</p>

<p>Take a look at our implementation of binary add:</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>,</span>
                 <span>word</span> <span>stack_index</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"+"</span><span>))</span> <span>{</span>
      <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>operand2</span><span>(</span><span>args</span><span>),</span> <span>stack_index</span><span>));</span>
      <span>Emit_store_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>Ind</span><span>(</span>‚Ä¶</code></pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-5/">https://bernsteinbear.com/blog/compiling-a-lisp-5/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-5/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490108</guid>
            <pubDate>Wed, 16 Sep 2020 06:34:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bazel For Open-Source C/C++ Libraries Distribution]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 68 (<a href="https://news.ycombinator.com/item?id=24490089">thread link</a>) | @todsacerdoti
<br/>
September 15, 2020 | https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/ | <a href="https://web.archive.org/web/*/https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In the past a few days, I‚Äôve been experimenting with Bazel as a library distribution mechanism for <a href="https://github.com/liuliu/ccv">ccv</a>.</p>

<p>I am pretty familiar with hermetic build systems at this point. My main knowledge comes from Buck dating 8 years back. At that time, it never occurred to me such a build system could eventually be a library distribution mechanism. During the same 8 years, NPM has taken over the world. New language-dependent package managers such as Go module, Cargo and Swift Package Manager popularized the concept of using the public repositories (GitHub) as the dependency references. Languages prior to this period, mainly C / C++ are moving to this direction, slowly.</p>

<p><a href="https://github.com/liuliu/ccv">ccv</a> has a simple autoconf based feature detection / configuration system. You would expect the package to work when <code>./configure &amp;&amp; make</code>. However, it never made any serious attempt to be too smart. My initial experience with monorepos at companies strongly influenced the decision to have a simple build system. I fully expect that serious consumers will vendor the library into their monorepo using their own build systems.</p>

<p>This has been true for the past a few years. But as I am finishing up <a href="https://libnnc.org/">nnc</a> and increasingly using that for other closed-source personal projects, maintaining a closed-source <em>monorepo</em> setup for my personal projects while upstreaming fixes is quite an unpleasant experience. On the other hand, <a href="https://libnnc.org/">nnc</a> from the beginning meant to be a low-level implementation. I am expected to have high-level language bindings at some point. Given that I am doing more application-related development with <a href="https://libnnc.org/">nnc</a> in closed-source format now, it feels like the right time.</p>

<p>Although there is no one-true library distribution mechanism for C / C++, there are contenders. From the good-old apt / rpm, to Conan, which has gained some mind-share in the open-source world in recent years.</p>

<p>The choice of Bazel is not accidental. I‚Äôve been doing <a href="https://liuliu.me/eyes/migrating-ios-project-to-bazel-a-real-world-experience/">some Swift development with Bazel</a> and the experience has been positive. Moreover, the choice of high-level binding language for <a href="https://libnnc.org/">nnc</a>, I figured, would be Swift.</p>

<h2 id="configure">Configure</h2>

<p><a href="https://github.com/liuliu/ccv">ccv</a>‚Äôs build process, as much as I would rather not, is host-dependent. I use autoconf to detect system-wide libraries such as libjpeg and libpng, to configure proper compiler options. Although <a href="https://github.com/liuliu/ccv">ccv</a> can be used with zero dependency, in that configuration, it can sometimes be slow.</p>

<p>Coming from the monorepo background, Bazel doesn‚Äôt have many utilities that are as readily available as in autoconf. You can write automatic configurations in Starlark as <a href="https://docs.bazel.build/versions/master/skylark/repository_rules.html">repository rules</a>, but there is no good documentation on how to write robust ones.</p>

<p>I ended up <a href="https://github.com/liuliu/ccv/blob/unstable/WORKSPACE#L25">letting whoever use ccv to decide how they are going to enable certain features</a>. For things like CUDA, such configuration is not tenable. I ended up copying over <a href="https://github.com/liuliu/rules_cuda">TensorFlow‚Äôs CUDA rules</a>.</p>

<h2 id="dependencies">Dependencies</h2>

<p>Good old C / C++ libraries are notoriously indifferent to libraries dependencies v.s. toolchains. Autoconf detects both toolchain configurations as well as available libraries. These types of host dependencies make cross-compilation a skill in itself.</p>

<p>Bazel is excellent for in-tree dependencies. For out-tree dependencies however, there is no established mechanism. The popular way is to write a <a href="https://github.com/protocolbuffers/protobuf/blob/master/protobuf_deps.bzl#L5">repository rules to load relevant dependencies</a>.</p>

<p>This actually works well for me. It is versatile enough to handle cases that <a href="https://github.com/liuliu/ccv/blob/unstable/config/ccv.bzl#L103">have Bazel integrations</a> and <a href="https://github.com/liuliu/dflat/blob/unstable/deps.bzl#L17">have no Bazel integrations</a>.</p>

<h2 id="consume-bazel-dependencies">Consume Bazel Dependencies</h2>

<p>Consumption of the packaged Bazel dependencies then becomes as simple as adding <code>git_repository</code> to the <code>WORKSPACE</code> and call proper <code>&lt;your_library_name&gt;_deps()</code> repository rule.</p>

<p>After packaging <a href="https://libccv.org/">ccv</a> with Bazel, now <a href="https://github.com/liuliu/s4nnc/blob/main/WORKSPACE#L3">Swift for nnc can consume the packaged dependency</a>.</p>

<h2 id="semantic-versioning-challenges">Semantic Versioning Challenges</h2>

<p>While the Bazel-provided library distribution mechanism works well for my case, it is simplistic. For one, there is really no good way to do <a href="https://semver.org/">semantic versioning</a>. It is understandable. Coming from a monorepo culture, it is challenging for anyone to dive into dependency hells of library versioning. A <a href="https://donatstudios.com/Go-v2-Modules">slightly different story happened to Go</a> a while back as well.</p>

<p>It is messy if you want to pin a specific version of the library while your dependencies are not agreeing with you. This is going to be messy regardless in C / C++ world, unless you prelink these extremely carefully. Bazel‚Äôs philosophy from what I can see, seems largely on <em>keeping the trunk working</em> side. It is working so far, but one has to wonder whether this can scale if more libraries adopted Bazel as the distribution mechanism.</p>

<h2 id="closing-words">Closing Words</h2>

<p>The past a few months experience with Bazel has been delightful. While I would continue to use language specific tools (pip, Go modules, Cargo, NPM) when doing development in that particular language, Bazel is a capable choice for me when doing cross-language development. Concepts such as <code>workspace</code>, <code>git_repository</code>, <code>http_archive</code> fit well within the larger open-source ecosystem. And most surprisingly, it works for many-repo setup if you ever need to.</p>
</div></div>]]>
            </description>
            <link>https://liuliu.me/eyes/bazel-for-libraries-distribution-an-open-source-library-author-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24490089</guid>
            <pubDate>Wed, 16 Sep 2020 06:28:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Concurrency Cost Hierarchy]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24489829">thread link</a>) | @signa11
<br/>
September 15, 2020 | https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<!-- boilerplate 
page.assets: /assets/concurrency-costs
assetpath: /assets/concurrency-costs
tablepath: /misc/tables/concurrency-costs
-->

<h2 id="introduction">Introduction</h2>

<p>Concurrency is hard to get <em>correct</em>, at least for those of us unlucky enough to be writing in languages which expose directly the guts of concurrent hardware: threads and shared memory. Getting concurrency correct <em>and</em> fast is hard, too. Your knowledge about single-threaded optimization often won‚Äôt help you: at a micro (instruction) level we can‚Äôt simply apply the usual rules of Œºops, dependency chains, throughput limits, and so on. The rules are different.</p>

<p>If that first paragraph got your hopes up, this second one is here to dash them: I‚Äôm not actually going to do a deep dive into the very low level aspects of concurrent performance. There are a lot of things we just don‚Äôt know about how atomic instructions and fences execute, and we‚Äôll save that for another day.</p>

<p>Instead, I‚Äôm going to describe a higher level taxonomy that I use to think about concurrent performance. We‚Äôll group the performance of concurrent operations into six broad <em>levels</em> running from fast to slow, with each level differing from its neighbors by roughly an order of magnitude in performance.</p>

<p>I often find myself thinking in terms of these categories when I need high performance concurrency: what is the best level I can practically achieve for the given problem? Keeping the levels in mind is useful both during initial design (sometimes a small change in requirements or high level design can allow you to achieve a better level), and also while evaluating existing systems (to better understand existing performance and evaluate the path of least resistance to improvements).</p>

<h3 id="a-real-world-example">A ‚ÄúReal World‚Äù Example</h3>

<p>I don‚Äôt want this to be totally abstract, so we will use a real-world-if-you-squint<sup id="fnref:realworld" role="doc-noteref"><a href="#fn:realworld">1</a></sup> running example throughout: safely incrementing an integer counter across threads. By <em>safely</em> I mean without losing increments, producing out-of-thin air values, frying your RAM or making more than a minor rip in space-time.</p>

<h3 id="source-and-results">Source and Results</h3>

<p>The source for every benchmark here is <a href="https://github.com/travisdowns/concurrency-hierarchy-bench">available</a>, so you can follow along and even reproduce the results or run the benchmarks on your own hardware. All of the results discussed here (and more) are available in the same repository, and each plot includes a <code>[data table]</code> link to the specific subset used to generate the plot.</p>

<h3 id="hardware">Hardware</h3>

<p>All of the performance results are provided for several different hardware platforms: Intel Skylake, Ice Lake, Amazon Graviton and Graviton 2. However except when I explicitly mention other hardware, the prose refers to the results on Skylake. Although the specific numbers vary, most of the qualitative relationships hold for the hardware too, but <em>not always</em>. Not only does the hardware vary, but the OS and library implementations will vary as well.</p>

<p>It‚Äôs almost inevitable that this will be used to compare across hardware (‚Äúwow, Graviton 2 sure kicks Graviton 1‚Äôs ass‚Äù), but that‚Äôs not my goal here. The benchmarks are written primarily to tease apart the characteristics of the different levels, and <em>not</em> as a hardware shootout.</p>

<p>Find below the details of the hardware used:</p>

<table>
  <thead>
    <tr>
      <th>Micro-architecture</th>
      <th>ISA</th>
      <th>Model</th>
      <th>Tested Frequency</th>
      <th>Cores</th>
      <th>OS</th>
      <th>Instance Type</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Skylake</td>
      <td>x86</td>
      <td>i7-6700HQ</td>
      <td>2.6 GHz</td>
      <td>4</td>
      <td>Ubuntu 20.04</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Ice Lake</td>
      <td>x86</td>
      <td>i5-1035G4</td>
      <td>3.3 GHz</td>
      <td>4</td>
      <td>Ubuntu 19.10</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>Graviton</td>
      <td>AArch64</td>
      <td>Cortex-A72</td>
      <td>2.3 GHz</td>
      <td>16</td>
      <td>Ubuntu 20.04</td>
      <td>a1.4xlarge</td>
    </tr>
    <tr>
      <td>Graviton 2</td>
      <td>AArch64</td>
      <td>Neoverse N1</td>
      <td>2.5 GHz</td>
      <td>16<sup id="fnref:g2cores" role="doc-noteref"><a href="#fn:g2cores">2</a></sup></td>
      <td>Ubuntu 20.04</td>
      <td>c6g.4xlarge</td>
    </tr>
  </tbody>
</table>

<h2 id="level-2-contended-atomics">Level 2: Contended Atomics</h2>

<p>You‚Äôd probably expect this hierarchy to be introduced from fast to slow, or vice-versa, but we‚Äôre all about defying expectations here and we are going to start in the <em>middle</em> and work our way outwards. The middle (rounding down) turns out to be <em>level 2</em> and that‚Äôs where we will jump in.</p>

<p>The most elementary way to safely modify any shared object is to use a lock. It mostly <em>just works</em> for any type of object, no matter its structure or the nature of the modifications. Almost any mainstream CPU from the last thirty years has some type of locking<sup id="fnref:parisc" role="doc-noteref"><a href="#fn:parisc">3</a></sup> instruction accessible to userspace.</p>

<p>So our baseline increment implementation will use a simple mutex of type <code>T</code> to protect a plain integer variable:</p>

<div><div><pre><code><span>T</span> <span>lock</span><span>;</span>
<span>uint64_t</span> <span>counter</span><span>;</span>

<span>void</span> <span>bench</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>holder</span><span>(</span><span>lock</span><span>);</span>
        <span>counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>We‚Äôll call this implementation <em><abbr title="Uses a std::mutex and std::lock_guard to protect a plain integer counter.">mutex add</abbr></em>, and on my 4 CPU Skylake-S i7-6700HQ machine, when I use the vanilla <code>std::mutex</code> I get the following results for 2 to 4 threads:</p>



<p>The reported value is the median of all trials, and the vertical black error lines at the top of each bar indicate the <em>interdecile range</em>, i.e., the values at the 10th and 90th percentile. Where the error bars don‚Äôt show up, it means there is no difference between the p10 and p90 values at all, at least within the limits of the reporting resolution (100 picoseconds).</p>

<p>This shows that the baseline contended cost to modify an integer protected by a lock starts at about 125 nanoseconds for two threads, and grows somewhat with increasing thread count.</p>

<p>I can already hear someone saying: <em>If you are just modifying a single 64-bit integer, skip the lock and just directly use the atomic operations that most ISAs support!</em></p>

<p>Sure, let‚Äôs add a couple of variants that do that. The <code>std::atomic&lt;T&gt;</code> template makes this easy: we can wrap any type meeting some basic requirements and then manipulate it atomically. The easiest of all is to use <code>std::atomic&lt;uint64&gt;::operator++()</code><sup id="fnref:post" role="doc-noteref"><a href="#fn:post">4</a></sup> and this gives us <em><abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>atomic_counter</span><span>{};</span>

<span>void</span> <span>atomic_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>atomic_counter</span><span>++</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The other common approach would be to use <a href="https://en.wikipedia.org/wiki/Compare-and-swap">compare and swap (<abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr>)</a> to load the existing value, add one and then <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> it back if it hasn‚Äôt changed. If it <em>has</em> changed, the increment raced with another thread and we try again.</p>

<p>Note that even if you use increment at the source level, the assembly might actually end up using <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> if your hardware doesn‚Äôt support atomic increment<sup id="fnref:atomicsup" role="doc-noteref"><a href="#fn:atomicsup">5</a></sup>, or if your compiler or runtime just don‚Äôt take advantage of atomic operations even though they are available (e.g., see what even the newest version of <a href="https://godbolt.org/z/5h4K7y">icc does</a> for atomic increment, and what Java did for years<sup id="fnref:java" role="doc-noteref"><a href="#fn:java">6</a></sup>). This caveat doesn‚Äôt apply to any of our tested platforms, however.</p>

<p>Let‚Äôs add a counter implementation that uses <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> as described above, and we‚Äôll call it <em><abbr title="Uses a CAS loop to increment a single shared counter.">cas add</abbr></em>:</p>

<div><div><pre><code><span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>uint64_t</span><span>&gt;</span> <span>cas_counter</span><span>;</span>

<span>void</span> <span>cas_add</span><span>(</span><span>size_t</span> <span>iters</span><span>)</span> <span>{</span>
    <span>while</span> <span>(</span><span>iters</span><span>--</span><span>)</span> <span>{</span>
        <span>uint64_t</span> <span>v</span> <span>=</span> <span>cas_counter</span><span>.</span><span>load</span><span>();</span>
        <span>while</span> <span>(</span><span>!</span><span>cas_counter</span><span>.</span><span>compare_exchange_weak</span><span>(</span><span>v</span><span>,</span> <span>v</span> <span>+</span> <span>1</span><span>))</span>
            <span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Here‚Äôs what these look like alongside our existing <code>std::mutex</code> benchmark:</p>



<p>The first takeaway is that, at least in this <em>unrealistic maximum contention</em> benchmark, using <abbr title="Uses an atomic increment on a single shared counter.">atomic add</abbr> (<a href="https://www.felixcloutier.com/x86/xadd"><code>lock xadd</code></a> at the hardware level) is significantly better than <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr>. The second would be that <code>std::mutex</code> doesn‚Äôt come out looking all that bad on Skylake. It is only slightly worse than the <abbr title="Compare-and-swap: an atomic operation implemented on x86 and other CPUs.">CAS</abbr> approach at 2 cores and beats it at 3 and 4 cores. It is slower than the atomic increment approach, but less than three times as slow and seems to be scaling in a reasonable way.</p>

<p>All of these operations are belong to <em>level 2</em> in the hierarchy. The primary characteristic of level 2 is that they make a <em>contended access</em> to a shared variable. This means that at a minimum, the line containing the data needs to move out to the caching agent that manages coherency<sup id="fnref:l3" role="doc-noteref"><a href="#fn:l3">7</a></sup>, and then back up to the core that will receive ownership next. That‚Äôs about 70 cycles minimum just for that operation<sup id="fnref:inter" role="doc-noteref"><a href="#fn:inter">8</a></sup>.</p>

<p>Can it get slower? You bet it can. <em>Way</em> slower.</p>

<h3 id="level-3-system-calls">Level 3: System Calls</h3>

<p>The next level up (‚Äúup‚Äù is not good here‚Ä¶) is level 3. The key characteristic of implementations at this level is that they make a <em>system call on almost every operation</em>.</p>

<p>It is easy to write concurrency primitives that make a system call <em>unconditionally</em> (e.g., a lock which always tries to wake waiters via a <code>futex(2)</code> call, even if there aren‚Äôt any), but we won‚Äôt look at those here. Rather we‚Äôll take a look at a case where the fast path is written to avoid a system call, but the design or way it is used implies that such a call usually happens anyway.</p>

<p>Specifically, we are going to look at some <em>fair locks</em>. Fair locks allow threads into the critical section in the same order they began waiting. That is, when the critical section becomes available, the thread that has been waiting the longest is given the chance to take it.</p>

<p>Sounds like a good idea, right? Sometimes yes, but as we will see it can have significant performance implications.</p>

<p>On the menu are three different fair locks.</p>

<p>The first is a <a href="https://en.wikipedia.org/wiki/Ticket_lock">ticket lock</a> with a <code>sched_yield</code> in the spin loop. The idea of the yield is to give other threads which may hold the lock time to run. This <code>yield()</code> approach is publicly frowned upon by concurrency experts<sup id="fnref:notwhat" role="doc-noteref"><a href="#fn:notwhat">9</a></sup>, who then sometimes go right ahead and use it anyway.</p>

<p>We will call it <abbr title="A ticket lock that calls sched_yield in a spin loop while waiting for its turn.">ticket yield</abbr> and it looks like this:</p>



<div><div><pre><code><span>/**
 * A ticket lock which uses sched_yield() while waiting
 * for the ticket to be served.
 */</span>
<span>class</span> <span>ticket_yield</span> <span>{</span>
    <span>std</span><span>::</span><span>atomic</span><span>&lt;</span><span>size_t</span><span>&gt;</span> <span>dispenser</span><span>{},</span> <span>serving</span><span>{};</span>

<span>public:</span>
    <span>void</span> <span>lock</span><span>()</span> <span>{</span>
        <span>auto</span> <span>ticket</span> <span>=</span> <span>dispenser</span><span>.</span><span>fetch_add</span><span>(</span><span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_relaxed</span><span>);</span>

        <span>while</span> <span>(</span><span>ticket</span> <span>!=</span> <span>serving</span><span>.</span><span>load</span><span>(</span><span>std</span><span>::</span><span>memory_order_acquire</span><span>))</span>
            <span>sched_yield</span><span>();</span>
    <span>}</span>

    <span>void</span> <span>unlock</span><span>()</span> <span>{</span>
        <span>serving</span><span>.</span><span>store</span><span>(</span><span>serving</span><span>.</span><span>load</span><span>()</span> <span>+</span> <span>1</span><span>,</span> <span>std</span><span>::</span><span>memory_order_release</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre></div></div>

<p>Let‚Äôs plot the performance results for this lock alongside the existing approaches:</p>



<p>This is level 3 visualized: it is an order of magnitude slower than the level 2 approaches. The slowdown comes from the <code>sched_yield</code> call: this is a system call and these are generally on the order of 100s of nanoseconds<sup id="fnref:spectre" role="doc-noteref"><a href="#fn:spectre">10</a></sup>, and it shows in the results.</p>

<p>This lock <em>does</em> have a fast path where <code>sched_yield</code> isn‚Äôt called: if the lock is available, no spinning occurs and <code>sched_yield</code> is never called. However, the combination of being a <em>fair</em> lock and the high contention in this test means that a lock convoy quickly forms (we‚Äôll describe this in more detail later) and so the spin loop is entered basically ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html">https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2020/07/06/concurrency-costs.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489829</guid>
            <pubDate>Wed, 16 Sep 2020 05:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python's Innards: Introduction (2010)]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24489604">thread link</a>) | @johnsonjo
<br/>
September 15, 2020 | https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/ | <a href="https://web.archive.org/web/*/https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>A friend once said to me: <q>You know, to some people, C is just a bunch of macros that expand to assembly</q>. It‚Äôs been years ago (smartasses: it was also before <tt>llvm</tt>, ok?), but the sentence stuck with me. Do <em>Kernighan and Ritchie</em> really look at a C program and see assembly code? Does <em>Tim Berners-Lee</em> surf the Web any differently than you and me? And what on earth <em>did</em> <em>Keanu Reeves</em> see when he looked at all of that funky green gibberish soup, anyway? No, seriously, what the heck <em>did</em> he see there?! Uhm, back to the program. Anyway, what does Python look like in <em>Guido van Rossum</em>‚Äòs<sup>1</sup> eyes?</p>
<p>This post marks the beginning of what should develop to a <a href="https://tech.blog.aknin.name/tag/pythons-innards/">series</a> on Python‚Äôs internals, I‚Äôm writing it since I believe that explaining something is the best way to grok it, and I‚Äôd very much like to be able to visualize more of Python‚Äôs ‚Äòfunky green gibberish soup‚Äô as I read Python code. On the curriculum is mainly <em>CPython</em>, mainly <em>py3k</em>, mainly <em>bytecode evaluation</em> (I‚Äôm not a big compilation fan) ‚Äì but practically everything around executing Python and Python-like code (<em>Unladen Swallow</em>, <em>Jython</em>, <em>Cython</em>, etc) might turn out to be fair game in this series. For the sake of brevity and my sanity, when I say <em>Python</em>, I mean <em>CPython</em> unless noted otherwise. I also assume a POSIX-like OS or (if and where it matters) Linux, unless otherwise noted. You should read this if you want to know how Python works. You should read this if you want to contribute to CPython. You should read this to find all the mistakes I‚Äôll make and snicker at me behind me back or write snide comments. I realize it‚Äôs just <em>your</em> particular way to show affection.</p>
<p>I gather I‚Äôll glean pretty much everything I write about from Python‚Äôs source or, occasionally, other fine materials (documentation, especially <a href="http://docs.python.org/py3k/c-api/index.html">this</a> and <a href="http://docs.python.org/py3k/extending/index.html">that</a>, certain PyCon lectures, <a href="https://tech.blog.aknin.name/2010/05/07/searching-mailing-list-archives-offline/">searching</a> <a href="http://mail.python.org/mailman/listinfo/python-dev">python-dev</a>, etc). Everything is out there, but I do hope my efforts at putting it all in one place to which you can RSS-subscribe will make your journey easier. I assume the reader knows some C, some OS theory, a bit less than some assembly (any architecture), a bit more than some Python and has reasonable UNIX fitness (i.e., feels comfortable installing something from source). Don‚Äôt be afraid if you‚Äôre not reasonably conversant in one (or more) of these, but I can‚Äôt promise smooth sailing, either. Also, if you don‚Äôt have a working toolchain to do Python development, maybe you‚Äôd like to head over <a href="https://tech.blog.aknin.name/2010/04/08/contributing-to-python/">here</a> and do as it says on the second paragraph (and onwards, as relevant).</p>
<p>Let‚Äôs start with something which I assume you already know, but I think is important, at least to the main way I understand‚Ä¶ well, everything that I do understand. I look at it as if I‚Äôm looking at a machine. It‚Äôs easy in Python‚Äôs case, since Python relies on a Virtual Machine to do what it does (like many other interpreted languages). Be certain you understand ‚Äú<a href="http://en.wikipedia.org/wiki/Virtual_machine#Process_virtual_machines">Virtual Machine</a>‚Äù correctly in this context: think more like JVM and less like VirtualBox (very technically, they‚Äôre the same, but in the real world we usually differentiate these two kinds of VMs). I find it easiest to understand ‚ÄúVirtual Machine‚Äù literally ‚Äì it‚Äôs a machine built from software. Your CPU is just a complex electronic machine which receives all input (machine code, data), it has a state (registers), and based on the input and its state it will output stuff (to RAM or a Bus), right? Well, CPython is a machine built from software components that has a state and processes instructions (different implementations may use rather different instructions). This software machine operates in the process hosting the Python interpreter. Keep this in mind; I like the <a href="http://en.wikipedia.org/wiki/Turing_machine">machine</a> metaphor (as I explain in minute details <a href="https://tech.blog.aknin.name/2010/07/04/pythons-innards-for-my-wife/">here</a>).</p>
<p>That said, let‚Äôs start with a bird‚Äôs eye overview of what happens when you do this: <kbd>$ python -c 'print("Hello, world!")'</kbd>. Python‚Äôs binary is executed, the standard C library initialization which pretty much any process does happens and then the main function starts executing (see its source, <kbd>./Modules/python.c: main</kbd>, which soon calls <kbd>./Modules/main.c: Py_Main</kbd>). After some mundane initialization stuff (parse arguments, see if environment variables should affect behaviour, assess the situation of the standard streams and act accordingly, etc), <a href="http://docs.python.org/c-api/init.html#Py_Initialize">./Python/pythonrun.c: Py_Initialize</a> is called. In many ways, this function is what ‚Äòbuilds‚Äô and assembles together the pieces needed to run the CPython machine and makes ‚Äòa process‚Äô into ‚Äòa process with a Python interpreter in it‚Äô. Among other things, it creates two very important Python data-structures: the <strong>interpreter state</strong> and <strong>thread state</strong>. It also creates the built-in <strong>module</strong> <a href="http://docs.python.org/library/sys.html">sys</a> and the module which hosts all <a href="http://docs.python.org/library/functions.html#built-in-functions">builtins</a>. At a later post(s) we will cover all these in depth.</p>
<p>With these in place, Python will do one of several things based on how it was executed. Roughly, it will either execute a string (the <kbd>-c</kbd> option), execute a module as an executable (the <kbd>-m</kbd> option), or execute a file (passed explicitly on the commandline or passed by the kernel when used as an interpreter for a script) or run its <a href="http://en.wikipedia.org/wiki/Read-eval-print_loop">REPL</a> loop (this is more a special case of the file to execute being an interactive device). In the case we‚Äôre currently following, it will execute a single string, since we invoked it with <kbd>-c</kbd>. To execute this single string, <kbd>./Python/pythonrun.c: PyRun_SimpleStringFlags</kbd> is called. This function creates the <kbd>__main__</kbd> <strong>namespace</strong>, which is ‚Äòwhere‚Äô our string will be executed (if you run <kbd>$ python -c 'a=1; print(a)'</kbd>, where is <kbd>a</kbd> stored? in this namespace). After the namespace is created, the string is executed in it (or rather, interpreted or <em>evaluated</em> in it). To do that, you must first transform the string into something that machine can work on.</p>
<p>As I said, I‚Äôd rather not focus on the innards of Python‚Äôs parser/compiler at this time. I‚Äôm not a compilation expert, I‚Äôm not entirely interested in it, and as far as I know, Python doesn‚Äôt have significant Compiler-Fu beyond the basic CS compilation course. We‚Äôll do a (very) fast overview of what goes on here, and may return to it later only to inspect visible CPython behaviour (see the <a href="http://docs.python.org/reference/simple_stmts.html#the-global-statement">global</a> statement, which is said to affect parsing, for instance). So, the parser/compiler stage of <kbd>PyRun_SimpleStringFlags</kbd> goes largely like this: tokenize and create a <a href="http://en.wikipedia.org/wiki/Concrete_syntax_tree">Concrete Syntax Tree</a> (CST) from the code, transorm the CST into an <a href="http://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree</a> (AST) and finally compile the AST into a <strong>code object</strong> using <kbd>./Python/ast.c: PyAST_FromNode</kbd>. For now, think of the code object as a binary string of machine code that Python VM‚Äôs ‚Äòmachinary‚Äô can operate on ‚Äì so now we‚Äôre ready to do interpretation (again, <em>evaluation</em> in Python‚Äôs parlance).</p>
<p>We have an (almost) empty <kbd>__main__</kbd>, we have a code object, we want to evaluate it. Now what? Now this line: <kbd>Python/pythonrun.c: run_mod, v = PyEval_EvalCode(co, globals, locals);</kbd> does the trick. It receives a code object and a namespace for <strong>globals</strong> and for <strong>locals</strong> (in this case, both of them will be the newly created <kbd>__main__</kbd> namespace), creates a <strong>frame object</strong> from these and executes it. You remember previously that I mentioned that <kbd>Py_Initialize</kbd> creates a thread state, and that we‚Äôll talk about it later? Well, back to that for a bit: each Python thread is represented by its own thread state, which (among other things) points to the stack of currently executing frames. After the frame object is created and placed at the top of the thread state stack, it (or rather, the byte code pointed by it) is evaluated, opcode by opcode, by means of the (rather lengthy) <kbd>./Python/ceval.c: PyEval_EvalFrameEx</kbd>.</p>
<p><kbd>PyEval_EvalFrameEx</kbd> takes the frame, extracts opcode (and operands, if any, we‚Äôll get to that) after opcode, and executes a short piece of C code matching the opcode. Let‚Äôs take a closer look at what these ‚Äúopcodes‚Äù look like by disassembling a bit of compiled Python code:</p>
<pre title="">&gt;&gt;&gt; from dis import dis # ooh! a handy disassembly function!
&gt;&gt;&gt; co = compile("spam = eggs - 1", "&lt;string&gt;", "exec")
&gt;&gt;&gt; dis(co)
  1           0 LOAD_NAME                0 (eggs)
              3 LOAD_CONST               0 (1)
              6 BINARY_SUBTRACT     
              7 STORE_NAME               1 (spam)
             10 LOAD_CONST               1 (None)
             13 RETURN_VALUE        
&gt;&gt;&gt; 
</pre>
<p>‚Ä¶even without knowing much about Python‚Äôs bytecode, this is reasonably readable. You ‚Äúload‚Äù the name <kbd>eggs</kbd> (where do you load it from? where do you load it to? soon), and also load a constant value (<kbd>1</kbd>), then you do a ‚Äúbinary subtract‚Äù (what do you mean ‚Äòbinary‚Äô in this context? between which operands?), and so on and so forth. As you might have guessed, the names are ‚Äúloaded‚Äù from the <kbd>globals</kbd> and <kbd>locals</kbd> namespaces we‚Äôve seen earlier, and they‚Äôre loaded onto an operand stack (not to be confused with the stack of running frames), which is exactly where the binary subtract will pop them from, subtract one from the other, and put the result back on that stack. ‚ÄúBinary subtract‚Äù just means this is a subtraction opcode that has two operands (hence it is ‚Äúbinary‚Äù, this is not to say the operands are binary numbers made of ‚Äò0‚Äôs and ‚Äò1‚Äôs).</p>
<p>You can go look at <kbd>PyEval_EvalFrameEx</kbd> at <kbd>./Python/ceval.c</kbd> yourself, it‚Äôs not a small function by any means. For practical reasons I can‚Äôt paste too much code from there in here, but I will just paste the code that runs when a <kbd>BINARY_SUBTRACT</kbd> opcode is found, I think it really illustrates things:</p>
<pre title="">        TARGET(BINARY_SUBTRACT)
            w = POP();
            v = TOP();
            x = PyNumber_Subtract(v, w);
            Py_DECREF(v);
            Py_DECREF(w);
            SET_TOP(x);
            if (x != NULL) DISPATCH();
            break;
</pre>
<p>‚Ä¶pop something, take the top (of the operand stack), call a C function called PyNumber_Subtract() on these things, do something we still don‚Äôt understand (but will in due time) called ‚ÄúPy_DECREF‚Äù on both, set the top of the stack to the result of the subtraction (overwriting the previous top) and then do something else we don‚Äôt understand if x is not null, which is to do a ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/">https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/</a></em></p>]]>
            </description>
            <link>https://tech.blog.aknin.name/2010/04/02/pythons-innards-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489604</guid>
            <pubDate>Wed, 16 Sep 2020 04:43:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Short History of LED Lighting]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24489268">thread link</a>) | @blast
<br/>
September 15, 2020 | https://www.stet.build/ia/031 | <a href="https://web.archive.org/web/*/https://www.stet.build/ia/031">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
  <p><img src="https://blotcdn.com/blog_78585a67eddd4bfcb7936222fddae5c7/_image_cache/e294bb61-15a2-42d5-999c-b1d5c20f0429.svg" alt="In Abeyance Logo" width="900" height="150"></p>
<p><img src="https://blot.im/cdn/blog_78585a67eddd4bfcb7936222fddae5c7/_image_cache/8006e258-67aa-456f-be91-f47df313bcc6.png" alt="Issue 031" width="2048" height="2048"></p>

<h4>
By Khaled Abou Alfa ‚Ä¢ Published 29th of July, <span>2020
</span></h4>
<p>
In 1927, Oleg Losev, a Russian inventor and scientist would introduce the world to the light-emitting diode. This technology would remain dormant for decades. Progress was made in 1962 with the introduction of the first red <span>LED</span>. For the next 30 years, an industry would hunt for the elusive colour blue. Over time the risk of pouring resource and treasure into this pursuit increased - you were chasing the pot of gold at the end of a blue coloured rainbow.
</p>
<p>
These pursuits would continue with little success until the early 90s. Then the work of Shuji Nakamura, Isamu Akosaki and Hiroshi Amano unlocked the secrets of the blue <span>LED</span>. So significant was this discovery that in 2004, the trio would receive the Nobel price in Physics.
</p>
<p>
This work would be employed in diverse contexts, from the multitude of screens we depend upon to data communications. For the built environment, this discovery would transform artificial lighting across the world. The incandescent (and to a lesser extent the fluorescent) lamp illuminated the 20th century. Light for the 21st century would be ushered in by the <span>LED</span> lamp.
</p>
<h2 id="obsolete-lighting-law">Obsolete Lighting Law</h2>
<p>In 1999, <a href="http://www.haitzs-law.com/uploads/7/6/3/6/76362633/1999-_national_research_report__same_as_2000_sarndia_nrp_.pdf">Roland Haitz co-authored</a> a research report, on the future of <span>LED</span> lighting (which was renamed as solid state lighting). The paper included data collected over decades that plotted both the cost of lumens and the red light output per <span>LED</span> package since the 1970s. 20 years ago Haitz empirically predicted the world we are living in today and captured in a<span></span> <span>‚Äò</span>law‚Äô which states:</p>
<blockquote>
<p>Every decade, for a given wavelength of light, the cost per lumen falls by a factor of 10 and the amount of light generated per <span>LED</span> package increases by a factor of 20.<br>
‚Äî Haitz‚Äôs Law</p>
</blockquote>
<p>
A new report, which addressed the shortcomings and reviewed the impact of the earlier report, was published <a href="http://www.haitzs-law.com/uploads/7/6/3/6/76362633/2011-physica_-_haitz_r_2011_pssa.pdf">a decade later in 2010</a>. This paper predicted that within the decade (by 2020), we would have reached a point of diminishing returns. It acknowledged that Solid State Lighting (<span>SSL</span>) is limited in two areas. The conversion efficacy - converting electrical energy to luminous flux cannot exceed 100%. The actual need for increased flux range - just because you can produce it, doesn‚Äôt mean the market needs it. The paper provided indications of where the future after 2020 is likely to evolve:
</p>
<p><em><span>‚Äò</span>These include digital tuning of both the chromaticity and the temporal/spatial placement of light within the environment that is being lit.‚Äô</em></p>
<p><span>
27</span> years after the initial spark of the blue <span>LED</span> revolution, we are now entering a period of equilibrium of both the efficacy and flux of solid state lighting. The advances in lighting have now begun to shift into new territory, one of circadian rhythms, diurnal patterns and refined controllability.
</p>
<h2 id="controllability">Controllability</h2>
<p>Inline with the predictions from 10 years ago, the lighting industry has begun to focus its attention on how <span>SSL</span> can be controlled and manipulated. The technology available today would be considered both technically impossible and prohibitively expensive, compared with technology from only 15 years ago.</p>
<p>
The terms<span></span> <span>‚Äò</span>circadian lighting‚Äô or<span></span> <span>‚Äò</span>human centric lighting‚Äô have begun entering the lexicon as a means to enhance the wellbeing of everyone interacting with the built world. With the advent of <span>SSL</span> technology we are now able to control parameters such as colour spectrum, intensity and directionality. These systems offer control based on the exact location, the relationship to the outside world and what is happening outside in real time.
</p>
<p>
The main debate for the use of this type of lighting control is whether it actually works. Does it suppress the levels of Melatonin in the body? Does it make people more alert and therefore more responsive throughout the day? These are some of the questions that the industry will need to address for the technology to become more widespread.
</p>
<p>
<strong>In the last two decades, the lighting industry has experienced a revolution. This has led to an expanded scope of what is achievable with light in a manner unimaginable back in 1927. Incredibly these benefits have come at a greatly reduced level of energy consumption (typically 1/5th of previous technologies). The work is far from done, as incandecent lamp sources (amongst others) remain in wide use throughout the world (<a href="https://www.statista.com/statistics/246030/estimated-led-penetration-of-the-global-lighting-market/">global penetration of LEDs hovers around 61%</a>). We must wean ourselves both for our own wellbeing and that of the planet.</strong>
</p>

<h2 id="dysons-car">Dyson‚Äôs Car</h2>
<p><img src="https://blot.im/cdn/blog_78585a67eddd4bfcb7936222fddae5c7/_image_cache/da258a83-f760-46bc-8d61-23c8faa2a5e8.png" alt="Timber" width="900" height="596"></p>
<p>We now know what form factor Dyson had chosen for their <a href="https://www.autocar.co.uk/car-news/features/exclusive-inside-story-dyson-ev">now shelved electric vehicle</a>. Micromobility this is <em>not</em>.</p>
<p>
The Dyson‚Äôs interview demonstrates the tone deaf nature associated with cars. You may need a car for some activities, but for most of your mobility needs, you likely can get away with other methods. How different our cities would be if we could understand and embrace that reality together.
</p>
<p>
In adjacent news the guys over at Micromobility.io have been documenting our transition for a while. Just released is <a href="https://micromobility.io/landscape">version 2.0 of their Landscape document</a>. The document demonstrates the breadth that is on offer in this field.
</p>
<h2 id="wide-timber">Wide Timber</h2>
<p><img src="https://blot.im/cdn/blog_78585a67eddd4bfcb7936222fddae5c7/_image_cache/771a70fd-390a-4021-a8ee-e108b34d748e.jpg" alt="Timber" width="1800" height="650"></p>
<p>The 2020 Tokyo Olympics may have been postponed but that doesn‚Äôt mean we don‚Äôt get to marvel at some stunning timber architecture. As covered in <a href="https://www.stet.build/ia/007">issue 007</a>, the Japanese know a thing or two about building in timber. The completion of the <a href="https://www.designboom.com/architecture/nikken-sekkei-timber-gymnastics-center-tokyo-olympic-games-07-23-2020/">Ariake gymnastics center</a> is a wonderful extension of that history.</p>
<p><img src="https://blot.im/cdn/blog_78585a67eddd4bfcb7936222fddae5c7/_image_cache/a5fb78b8-d41f-4f9e-9bbe-ca1a8b265307.jpeg" alt="Timber" width="818" height="545"></p>

<h2 id="spoke-pens">Spoke Pens</h2>
<p><img src="https://blot.im/cdn/blog_78585a67eddd4bfcb7936222fddae5c7/_image_cache/59e3faa3-40df-46fe-98d7-bbf3cdd7d852.jpg" alt="Spoke Pens" width="680" height="680"></p>
<p>Over the past 5‚Äì10 years there has been an incredible industry of machined pens produced and sold on Kickstarter. I have found that the ergonomic design and available refill options to be under-represented. Rather than focusing on the utility of the pen itself, many focus on both the materials and aesthetic design instead.</p>
<blockquote>
<p>Most people make the mistake of thinking design is what it looks like. People think it‚Äôs this veneer‚Äâ‚Äî‚Äâthat the designers are handed this box and told,<span></span> <span>‚Äú</span>Make it look good!‚Äù That‚Äôs not what we think design is. It‚Äôs not just what it looks like and feels like. Design is how it works.<br>
‚Äî Steve Jobs</p>
</blockquote>
<p>
In this regard, the <a href="https://spokedesign.com/">Spoke pens and pencils</a> are different. The inside was considered first - even though the outside has a strong design language. The pen is primarily a wrap around the pen refill or pencil mechanism. The pens accept the standard Muji Gel ink refills or the Uni Signo <span>DX</span> refills (both come in a range of colours and go down to the 0.38mm range). While the pencil is based on the Pentel <span>P20</span># mechanical pencil mechanism. Both are highly recommended.
</p>
  <br>
      </div></div>]]>
            </description>
            <link>https://www.stet.build/ia/031</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489268</guid>
            <pubDate>Wed, 16 Sep 2020 03:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[North Pacific Logbook]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24489257">thread link</a>) | @blast
<br/>
September 15, 2020 | https://100r.co/site/north_pacific_logbook.html | <a href="https://web.archive.org/web/*/https://100r.co/site/north_pacific_logbook.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The passage from <b>Japan</b> (Shimoda) to <b>Canada</b> (Victoria) took <b>51 days</b>, and it was the hardest thing we've ever done. We decided to keep a logbook, to better remember it and so it can help others who wish to make this trip.</p><div>
	<!--  -->
	<tbody><tr><th colspan="3" id="week1">Week 1</th></tr>
	<tr>
		<td rowspan="6">June 9th</td>
		<td>0600</td>
		<td>We woke up early today, as we had little time to prepare before leaving Japan. Why so last minute? Because we only decided to leave yesterday morning. The reason we decided so late, was because we were waiting for a SIM card for our Iridium GO satellite phone, and we received it yesterday morning. As soon as we got it, we grabbed our passports and boat papers and hurried to the Immigration Office in Shizuoka to check out (a 4-5 hour train ride away). We were eager to leave on the 9th, as there was a good weather window, with moderate winds coming from a favourable direction. Because we weren't planning to leave until late yesterday morning, there were many tasks we had no yet done, or had not had time to do.<p>We're usually more organized than this, with only a few menial tasks to do, but not this time. Last minute departures is not our style, but we also wanted to take this window. We had to find a post box to send the pocket wifi we rented and to fill our water tanks ‚Äî this may not seem like much, but it was, as it piled up on top of other things we'd forgotten, like finding and installing the pot holders to the stovetop, installing the jack lines, taking out the tethers, putting key items back in the ditch bag plus a number of other last minute things that had escaped us at the time.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>0700</td>
		<td>We meet Shuhei, Thomas and Anja on the sailing vessel Robusta for coffee, turning down a cup as coffee, as it never sits right on the first day at sea. We use this opportunity to chat, meanwhile butterflies gather in my gut. I am nervous. I always am before a big trip and this time is no different, although this is our biggest passage yet, and will also likely be the most challenging. My gut has every right to twist itself into knots. We ask Shuhei to drop off our pocket wifi in a post box, he agrees ¬≠‚Äî ah, what a kind person. He came by this with his truck to help Robusta with some last minute tasks, like getting produce, gas etc. We had done most of that ahead of time.</td>
	</tr>
	<!--  -->
	<tr>
		<td>0800</td>
		<td>We push off our spot and head over to the Shimoda Boat Services pontoon to fill our water tanks. We tied up to it and began to ferry bins back and forth to empty them in our tank. We filled as many recipients as we could carry, as we don't know how long the trip will take. Once the tanks and jerry cans were full, we left the pontoon and headed outside of the breakwater. The Shimoda coastguard ship was lifting anchor at the time, it went past us, disappearing quickly as it was going much faster. Outside of the breakwater, we saw the lighthouse on our starboard side, the one we had difficulty rounding when we arrived here a week and a half ago due to 30-knot winds off our bow. Today, the seas were tame and the skies clear and blue. <p>We saw the Kurofune, a replica of Commodore Perry's black ship, taking tourists about the harbor. It was the first time we'd seen it on the water, as there weren't many tourists before due to concerns with the coronavirus. Now that the state of emergency's been lifted, people started traveling more around the country.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>The current is pushing us along, fast. We passed Oshima island at a ridiculous speed of 9.5 knots! The kuroshio, or <i>black current</i>, is very strong in this area, and even stronger between the islands as the water is forced through a narrow opening. We had no problem with ships, even with many heading to Tokyo. Our speed made it easy to work our way out of the main shipping channel. We are flying! Pino is happy to be moving again, and as are we.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1430</td>
		<td>We saw porpoises in the water! It's been too long! They came for a bow-riding session. We missed them. Winds are coming out of the SW, at a good speed of 12-15 knots. We're going at 8 knots. For lunch, we had inari pouches, a meal we'd purchased at MaxValue the night before. It's nice not having to cook on the first day. Neither of us are sea sick, but going below is still difficult and can easily trigger it. We stay outside instead, enjoying the good wind, weather and sun. <p>Devine is reading "The mushrooom at the end of the world", while I steer us east. We tried calling Robusta on the VHF, but got no answer, either they're too far or their radio isn't on.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1700</td>
		<td>Wind rises to 20 knots, we put on our foul weather gear as we don't want to wet our clothes. We won't be doing laundry in this trip, so keeping clothes dry is crucial.</td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="4">June 10th</td>
		<td>0800</td>
		<td>We download the weather, it is the same as yesterday, but it looks like the wind will increase this evening. Both of us are feeling sick and grumpy. We're experiencing the early symptoms of sea sickness, which usually means a headache, reduced appetite, morose view on things etc. This happens on every trip. Neither of us have ever vomited, thankfully.<p>Yesterday we sent Robusta an email and got a reply, they are ok and are southwest of us.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>We napped hard, then awoke and decided that we should try and cook something. Neither of us feel like eating rice balls, we regret getting so many as we aren't sure we can eat them. We have no appetite, but try to eat anyway.<p>We ate raw snap peas as a snack, the texture was weird in our mouths. Devine made spicy ramen, which were very, very spicy. I couldn't finish my bowl. We had a grapefruit for desert, and made a mess on deck trying to pry it apart. The deck had red on it for a while afterwards.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1700</td>
		<td>We check the weather again. We don't normally check it twice a day as it eats up data, but the weather was changing so fast...! We wanted to know what was going on. We're glad we looked, as the wind was set to increase by a lot. If we hadn't checked, we might not have set the second reef point in our main. The last thing we want in this ocean is to have too much canvas up.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1800</td>
		<td> We eat chips as a snack, as we are not hungry for a full dinner. Everything tastes weird? It's like our taste buds are going crazy. The only thing that goes down easy is salty foods.</td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="6">June 11th</td>
		<td>0200</td>
		<td>Saw a tanker ahead, but it wasn't moving? We passed its stern, wondering why it was idling out here.</td>
	</tr>
	<!--  -->
	<tr>
		<td>0900</td>
		<td>We've reduced the jib, as the wind is a strong and steady 27 knots. We are sailing east, although the current has pushed us higher than we wanted. We are at 36 degrees, and it is worrisome as we knew it was safer to stay under 35. The wind above that line tends to be stronger. Robusta was at 33 degrees, upon exiting Shimoda they took a more southerly route, I wish we'd done the same. We underestimated the strength of this current. We have peanut butter toast with slices of banana on top for breakfast.<p>Devine sent a happy birthday message to his sister.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1100</td>
		<td>The waves are getting bigger. We are worried about our fresh produce as we can't eat any of it. This has never happened to us before. The sun is warm and is hastening the rotting of some of the more sensitive vegetables, like broccoli. We had to throw away half a head overboard today. I hope we'll find our appetites again, I'd rather the food end up in our stomachs than in the ocean.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>Devine made a salad for lunch to try and use up some of our uglier produce. The wind is blowing food off of my fork as I eat, maybe not the best meal to have on a windy day. The wind is blowing 25-30 knots, generating big waves, but at least it is sunny.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1300</td>
		<td>We watched seabirds pirouetting in the distance, they've no problem in this wind. Their movements are sharp and fast. We don't know what kind of bird they are, they're brown with a white stomach.<p>We've noticed the automatic bilge pump keeps going off, we think there's a leak below the waterline, if so, that is worrisome. We tried to find where it was, but found nothing. None of the thru-hulls are leaking. I also checked the hose connections, nada! I suspect it may be the rudder post that is leaking, but for now it is impossible to look as I'd have to get into the cockpit locker, which is full of water bins and other heavy gear. For now, we try and check the bilge often, pumping the water out by hand every 2h or so. We have two manual bilge pumps, one in the cockpit and another in the cabin under the sink. The automatic bilge pump doesn't empty the bilge entirely, as it sits on a little stand above the lowest point, but the manual pump tube touches the bottom and does a better job of sucking up the majority of the water. If anything, the automatic pump serves as an alarm.</p></td>
	</tr>
	<!--  -->
	<tr>
		<td>1700</td>
		<td>Made spaghetti with eggplant and green peppers for dinner. It is still hard to finish food, so we started making smaller portions as to avoid waste. Both of us are still plagued with weird tastebuds. Sweet is too sweet, veggies are bland...</td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="2">June 12th</td>
		<td>0800</td>
		<td>Rain. All day. It won't stop. We've asked it to, but <i>it won't listen</i>.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1900</td>
		<td>The conditions out here are horrible. We are running with the waves and wind, we wished we'd put in the 3rd reef earlier. It is too late to do it now, as it is dark and stormy. Neither of us eat dinner, we're in sparta mode. </td>
	</tr>
	<!--  -->
	<tr>
		<td rowspan="4">June 13th</td>
		<td>0800</td>
		<td>It is still raining a lot, with winds gusting in the high 30's. This weather is demoralizing, but at least we are making good easting and getting further and further away from Japan. I never thought I'd be happy about getting away from Japan, it's my favorite place in the world...! The ocean around the country is mean, and another entity entirely, lingering here is dangerous. <i>Oh how much I wish the rain would stop</i>, everything would be more pleasant if the rain stopped.</td>
	</tr>
	<!--  -->
	<tr>
		<td>1200</td>
		<td>Devine made pasta with a mustard sauce for lunch, I ate half and left the bowl on the stove. It was delicious but I couldn't finish, I'll keep it as a snack for later. We had our usual ‚Ä¶</td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://100r.co/site/north_pacific_logbook.html">https://100r.co/site/north_pacific_logbook.html</a></em></p>]]>
            </description>
            <link>https://100r.co/site/north_pacific_logbook.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24489257</guid>
            <pubDate>Wed, 16 Sep 2020 03:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go‚Äôs Major Versioning Sucks ‚Äì From a Fanboy]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 162 (<a href="https://news.ycombinator.com/item?id=24488745">thread link</a>) | @lanecwagner
<br/>
September 15, 2020 | https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/ | <a href="https://web.archive.org/web/*/https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text">
			
<p>I‚Äôm normally a fan of the rigidity within the Go toolchain. In fact, we use Go on the <a href="https://app.qvault.io/dashboard/courses">front and backend at Qvault</a>. It‚Äôs wonderful to have standardized formatting, vetting, and testing across the entire language. The first real criticism I‚Äôve had is with the way Go modules handle major versions. It‚Äôs over-the-top opinionated and slows down development in a significant number of scenarios.</p>



<h2>Refresher on ‚ÄúGo Mod‚Äù</h2>



<p>Go modules, and the associated commands <code>go mod</code> and <code>go get</code> can be thought of as Go‚Äôs equivalents to NPM and Yarn. The Go toolchain provides a way to manage dependencies and lock the versions that a collection of code depends on.</p>



<p>One of the most common operations is to update a dependency in an existing module. For example:</p>



<pre><code lang="bash"># update all dependencies
go get -u ./...

# add missing and remove unused dependencies
go mod tidy

# save all dependency code in the project's "vendor" folder
go mod vendor</code></pre>



<h2>Semantic Versioning</h2>



<p>Go modules use git tags and semantic versioning to keep track of the versions of dependencies that are compatible with the module in question. Semantic versioning is a way to format version numbers and it looks like this: <code>v{MAJOR}.{MINOR}.{PATCH}</code>. For example, <code>v1.2.3</code>.</p>



<p>Each number is to be incremented according to the following standards:</p>



<pre><code lang="bash">MAJOR version when you make incompatible API changes,
MINOR version when you add functionality in a backwards compatible manner, and
PATCH version when you make backwards compatible bug fixes.</code></pre>



<h2>Package-Side Problems</h2>



<p>Go has decided that all versions beyond <code>v0</code> and <code>v1</code> are required to use the major version in the module path. There are two ways to accomplish this. </p>



<p><strong>The first and recommended way</strong> is laid out in an example on the <a rel="noreferrer noopener" href="https://blog.golang.org/v2-go-modules#TOC_4." target="_blank">Go Blog</a>:</p>



<blockquote><p>To start development on&nbsp;<code>v2</code>&nbsp;of&nbsp;<code>github.com/googleapis/gax-go</code>, we‚Äôll create a new&nbsp;<code>v2/</code>&nbsp;directory and copy our package into it.</p></blockquote>



<p>In other words, for every major version, we are encouraged to maintain a new copy of the entire codebase. This is also the only way to do it if you want pre-modules users to be able to use your package.</p>



<p><strong>The second way</strong> is to just change the name of your module in <code>go.mod</code>. Fore example, <code>module github.com/lane-c-wagner/go-tinydate</code> would become <code>module github.com/lane-c-wagner/go-tinydate/v2</code>. Besides this not working for older versions of Go, I also find it problematic because it breaks (in my mind) one of the most useful things about module names ‚Äì they reflect the file path.</p>



<h2>Package-Side Solutions</h2>



<p>Allow package maintainers to specify the major version simply by updating git tags, no module name changes required. There is no need for two sources of truth.</p>



<p>We can enforce safe updating by adding warnings or prompts to the <code>go get</code> CLI. We don‚Äôt have to add unnecessary time-consuming policies.</p>



<h2>Client-Side Problems</h2>



<p>When new versions of dependencies are released we have a simple command to get the newest stuff: <code>go get -u</code>. The problem is that this command has no way to automatically update to a new major version. It will only download new minor changes and patches. There isn‚Äôt even a console message to inform you that a new major version exists!</p>



<p>That said, the reason for not auto-updating is clear, and to be fair, well-founded:</p>



<blockquote><p>If an old package and a new package have the same import path, the new package must be backwards compatible with the old package.</p><cite><a href="https://research.swtch.com/vgo-import" rel="noopener">Import compatibility rule</a></cite></blockquote>



<p>In other words, we should only increment major versions when making breaking changes, and if breaking changes are made they can‚Äôt have the same import path. While this makes sense, I think a simple console warning would have been a better solution than forcing a cumbersome updating strategy on the community.</p>



<p><strong>Another problem </strong>on the client-side is that we don‚Äôt only need to update <code>go.mod</code>, but we actually need to <code>grep</code> through our codebase and change each import statement to point to the new major version:</p>



<blockquote><p>Users who wanted to use&nbsp;<code>v2</code>&nbsp;had to change their package imports and module requirements to&nbsp;<code>github.com/googleapis/gax-go/v2</code>.</p></blockquote>



<p>Instead of a few simple CLI commands to get the latest dependencies, we‚Äôre making changes to the code itself.</p>



<h3>A Caveat ‚Äì Diamond Imports</h3>



<p>Using different paths for different major versions makes more sense in situations where we may require two different versions of the same package, you know, <a aria-label="diamond imports (opens in a new tab)" href="https://research.swtch.com/vgo-import#dependency_story" target="_blank" rel="noreferrer noopener nofollow">diamond imports</a> and all that. This is the exception, not the rule, and it seems strange to tap dance around a problem that doesn‚Äôt exist in most codebases.</p>



<h2>Client-Side Solution</h2>



<p><code>go get -u</code> should have an additional command line flag to update major versions, and should default to showing a warning that there is a newer major version you don‚Äôt have yet.</p>



<p><em>Default</em> import paths should not change between major versions. If a module requires various versions, those <em>extra</em> versions could be flagged by having a different path.</p>



<h2>Why This Sucks For Me</h2>



<p>It is often the case that I want to build a package that has domain-specific logic and will only be used only in services at the small company I work for. For example, we have a repo that holds the <code>struct{}</code> definitions for common entities used across our system.</p>



<p>Occasionally we need to make backward-incompatible changes to those struct definitions. If it were an open-source library we wouldn‚Äôt make changes so often, but because it‚Äôs internal and we are aware of all the dependencies, we change the names of exported fields <em>regularly</em>. We aren‚Äôt changing names because we chose bad ones to begin with, we are usually changing names because requirements from the business change rapidly in a startup. </p>



<p>This means major version changes are a fairly regular occurrence. Some say that we should just stay on <code>v0</code>, and that‚Äôs a reasonable solution. The problem is these ARE production packages that are being used by a wide number of services. We WANT to Semver.</p>



<p>Go makes updating major versions so cumbersome that in the majority of cases, we have opted to just increment minor versions when we should increment major versions. We want to follow the proper versioning scheme, we just don‚Äôt want to add the unnecessary steps to our dev process.</p>



<h2>Hey ‚Äì I Get It</h2>



<p>I understand why these decisions were made ‚Äì and I even think in a lot of cases they were great decisions. For any open-source or public facing module this makes great sense. The Go toolchain is enforcing strict rules that encourage good API design.</p>



<p>In their effort to make public APIs great, they made it unnecessarily hard to have good ‚Äúlocal‚Äù package design.</p>



<p>There is an <a href="https://github.com/golang/go/issues/40323" rel="noopener">open issue on Github</a> that would make new major versions more discoverable from the CLI. Take a look at that if you are interested.</p>



<p>Go still has the best toolchain and ecosystem. NPM and PIP can suck it.</p>



<p>If you disagree, @ me on Twitter.</p>







<h2>Related Reading</h2>



<ul><li><a href="https://qvault.io/2020/08/15/optimize-for-simplicity-first/">Optimize for Simplicity First</a></li><li><a href="https://qvault.io/2019/10/21/golang-constant-maps-slices/">Constant Maps and Slices in Go</a></li><li><a href="https://qvault.io/2020/08/07/saving-a-third-of-our-memory-by-re-ordering-go-struct-fields/">Saving Memory by Re-ordering Go Structs</a></li></ul>
		</div></div>]]>
            </description>
            <link>https://qvault.io/2020/09/15/gos-major-version-handling-sucks-from-a-fanboy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24488745</guid>
            <pubDate>Wed, 16 Sep 2020 01:42:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When you browse Instagram and find Tony Abbott's passport number]]>
            </title>
            <description>
<![CDATA[
Score 2287 | Comments 331 (<a href="https://news.ycombinator.com/item?id=24488224">thread link</a>) | @michael_fine
<br/>
September 15, 2020 | https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram | <a href="https://web.archive.org/web/*/https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

    

    <div itemprop="articleBody">
        <hr>
        <p><img src="https://mango.pdf.zone/img/sunburnt-country/title.png" alt="title image what's up twitter-large"></p>



<p>So you know when you‚Äôre flopping about at home, minding your own business, drinking from your water bottle in a way that does not possess <em>any</em> intent to subvert the Commonwealth of Australia?</p>

<p>It‚Äôs a feeling I know all too well, and in which I was vigorously partaking when I got this message in ‚Äúthe group chat‚Äù<sup id="fnref:groupchat" role="doc-noteref"><a href="#fn:groupchat">1</a></sup>.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/groupchat.png" alt="Can you hack this man?|medium">
<em>A nice message from my friend, with a photo of a boarding pass üôÇ A good thing about messages from your friends is that they do not have any rippling consequences üôÇüôÇüôÇ</em></p>

<p>The man in question is <a href="https://en.wikipedia.org/wiki/Tony_Abbott">Tony Abbott</a>, one of Australia‚Äôs <em>many</em> former Prime Ministers.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/tony_abbott_wikipedia.png" alt="if u google tony abbott u get this|small">
<em>That‚Äôs him, officer</em></p>

<p>For security reasons, we try to change our Prime Minister every six months, and to never use the same Prime Minister on multiple websites.<sup id="fnref:kevin07" role="doc-noteref"><a href="#fn:kevin07">2</a></sup></p>

<h4 id="the-boarding-pass-photo">The boarding pass photo</h4>
<p>This particular former PM had just posted a picture of his boarding pass on Instagram (Instagram, in case you don‚Äôt know it, is an app you can open up on your phone any time to look at ads).</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/instagrampost.PNG" alt="Instagram post showing boarding pass|large">
<em>The since-deleted Instagram post showing the boarding pass and baggage receipt. The caption reads ‚Äúcoming back home from japan üòçüòç  looking forward to seeing everyone! climate change isn‚Äôt real üòå ok byeee‚Äù</em></p>

<h4 id="can-you-hack-this-man">‚ÄúCan you hack this man?‚Äù</h4>
<p>My friend<sup id="fnref:hoggemoade" role="doc-noteref"><a href="#fn:hoggemoade">3</a></sup> (who we will refer to by their group chat name, ùñçùñîùñåùñåùñä ùñíùñîùñÜùñâùñä) is asking<sup id="fnref:onbehalf" role="doc-noteref"><a href="#fn:onbehalf">4</a></sup> whether I can ‚Äúhack this man‚Äù not because I am the kind of person who regularly commits ùíÑùíöùíÉùíÜùíì ùíïùíìùíÜùíÇùíîùíêùíè on a whim, but because we‚Äôd recently been talking about boarding passes.</p>

<p>I‚Äôd said that people post pictures of their boarding passes all the time, not knowing that it can sometimes be used to get their passport number and stuff. They just post it being like ‚Äúomg going on holidayyyy üòçüòçüòç‚Äù, unaware that they‚Äôre posting cringe.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/instagramboardingpasses.png" alt="screenshot of #boardingpass on instagram|medium">
<em>People post their boarding passes all the time, because it‚Äôs not clear that they‚Äôre meant to be secret</em></p>

<p>Meanwhile, some hacker is rubbing their hands together, being all ‚Äúyumyum identity fraud üëÄ‚Äù in their dark web Discord, because this happens a <em>lot</em>.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/boardingpassposts.png" alt="screenshot of #boardingpass on instagram"></p>

<hr>

<p>So there I was, making intense and meaningful eye contact with this chat bubble, asking me if I could ‚Äúhack this man‚Äù.</p>

<h3 id="surely-you-wouldnt">Surely you wouldn‚Äôt</h3>
<p>Of course, my friend wasn‚Äôt <em>actually</em> asking me to hack the former Prime Minister.</p>



<p>However.</p>



<p>You <em>gotta</em>.</p>

<p>I mean‚Ä¶ what are you gonna do, <em>not</em> click it? Are you gonna let a <em>link</em> that‚Äôs like 50% advertising tracking ID tell you what to do? Wouldn‚Äôt you be <em>curious</em>?</p>

<p>The former Prime Minister had just posted his boarding pass. Was that <em>bad</em>? Was someone in danger? I didn‚Äôt know.</p>

<p>What I did know was: the <em>least</em> I could do<sup id="fnref:nocrime" role="doc-noteref"><a href="#fn:nocrime">5</a></sup> for my country would be to have a casual browse üëÄ</p>

<h2 id="investigating-the-boarding-pass-photo">Investigating the boarding pass photo</h2>
<h3 id="step-1-hubris">Step 1: Hubris</h3>

<p>So I had a bit of a casual browse, and got the picture of the boarding pass, and then‚Ä¶. I didn‚Äôt know what was supposed to happen after that.</p>

<p>Well, I‚Äôd heard that it‚Äôs bad to post your boarding pass online, because if you do, a bored 17 year-old Russian boy called ‚ÄúKatie-senpai‚Äù might somehow use it to commit identity fraud. But I don‚Äôt know anyone like that, so I just clumsily googled some stuff.</p>

<h4 id="googling-how-2-hakc-boarding-pass">Googling how 2 hakc boarding pass</h4>
<p><img src="https://mango.pdf.zone/img/sunburnt-country/uhhboardingpasshacking.png" alt="uhhh|small"></p>

<p>Eventually I found <a href="https://null-byte.wonderhowto.com/how-to/hackers-use-hidden-data-airline-boarding-passes-hack-flights-0180728/">a blog post</a> explaining that yes, pictures of boarding passes can indeed be used for Crimes. The part you wanna be looking at for all your criming needs is the barcode, because it‚Äôs got the ‚ÄúBooking Reference‚Äù (e.g. <code>H8JA2A</code>) in it.</p>

<p>Why do you want the booking reference? It‚Äôs one of the two things you need to log in to the airline website to manage your flight.</p>

<p>The second one is your‚Ä¶ last name. I was really hoping the second one would be like a password or something. But, no, it‚Äôs the booking reference the airline emails you and prints on your boarding pass. And it also lets you log in to the airline website?</p>

<p>That sounds suspiciously like a password to me, but like I‚Äôm still fine to pretend it‚Äôs not if you are.</p>

<h3 id="step-2-scan-the-barcode">Step 2: Scan the barcode</h3>
<p>I‚Äôve been practicing every morning at sunrise, but still can‚Äôt scan barcodes with my eyes. I had to settle for a barcode scanner app on my phone, but when I tried to scan the picture in the Instagram post, it didn‚Äôt work :((</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/boardingpass.png" alt="the boarding pass photo">
<em>Maybe I shouldn‚Äôt have blurred out the barcode first</em></p>

<h3 id="step-2-scan-the-barcode-but-more">Step 2: Scan the barcode, but more</h3>

<p>Well, maybe it wasn‚Äôt scanning because the picture was too blurry.</p>

<p>I spent around 15 minutes in an ‚Äúenhance, ENHANCE‚Äù montage, fiddling around with the image, increasing the contrast, and so on. Despite the montage taking up way too much of the 22 minute episode, I couldn‚Äôt even get the barcode to scan<sup id="fnref:step3" role="doc-noteref"><a href="#fn:step3">6</a></sup>.</p>

<h3 id="step-2-notice-that-the-booking-reference-is-printed-right-there-on-the-paper">Step 2: Notice that the Booking Reference is printed right there on the paper</h3>

<p>After staring at this image for 15 minutes, I noticed the Booking Reference is just‚Ä¶ printed on the baggage receipt.</p>

<p>I graduated university.</p>

<p>But it did not prepare me for this.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/bookingrefhighlighted.png" alt="Boarding pass with booking reference highlighted">
<em>askdjhaflajkshdflkh</em></p>

<h3 id="step-3-visit-the-airlines-website">Step 3: Visit the airline‚Äôs website</h3>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/bookinglogin2.png" alt="Manage booking login screen with empty fields-large"></p>

<p>After recovering from <em>that</em> emotional rollercoaster, I went to <a href="https://qantas.com.au/">qantas.com.au</a>, and clicked ‚ÄúManage Booking‚Äù. In case you don‚Äôt know it because you live in a country with fast internet, Qantas is the main airline here in Australia.</p>

<p>(I also very conveniently started recording my screen, which is gonna pay off <em>big time</em> in just a moment.)</p>

<h3 id="step-4-type-in-the-booking-reference">Step 4: Type in the Booking Reference</h3>

<p>Well, the login form was just‚Ä¶ <em>there</em>, and it was asking for a Booking Reference and a last name. I had just flawlessly read the Booking Reference from the boarding pass picture, and, well‚Ä¶ I knew the last name<sup id="fnref:lastname" role="doc-noteref"><a href="#fn:lastname">7</a></sup>.</p>

<p>I did hesitate for a split-second, but‚Ä¶ no, I had to know.</p>

<h3 id="step-5-crimes">Step 5: Crimes(?)</h3>

<video controls="" preload="auto">

    <source src="https://mango.pdf.zone/img/sunburnt-country/youngman.mp4" type="video/mp4">

<img src="https://mango.pdf.zone/img/sunburnt-country/summary.gif">
</video>
<p><em>youngman.mp4</em></p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/loggedin.png" alt="The logged in &quot;manage booking page&quot;">
<em>The ‚ÄúManage Booking‚Äù page, logged in as some guy called Anthony Abbott</em></p>

<h3 id="can-i-get-a-yikes-in-the-chat">Can I get a YIKES in the chat</h3>

<p>Leave a comment if you really felt that.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/yikes.png" alt="yikes"></p>

<p>I guess I was now logged the heck in as Tony Abbott? And for all I know, everyone else who saw his Instagram post was right there with me. It‚Äôs kinda wholesome, to imagine us all there together. But also probably suboptimal in a governmental sense.</p>

<h5 id="was-there-anything-secret-in-here">Was there anything secret in here?</h5>

<p>I then just incredibly browsed the page, browsed it so hard.</p>

<p>I saw Tony Abbott‚Äôs name<sup id="fnref:name" role="doc-noteref"><a href="#fn:name">8</a></sup>, flight times, and Frequent Flyer number, but not really anything <em>super</em> secret-looking. Not gonna be committing any cyber treason with a Frequent Flyer number. The flight was in the past, so I couldn‚Äôt change anything, either.</p>

<p>The page said the flight had been booked by a travel agent, so I guessed some information would be missing because of that.</p>

<p>I clicked around and scrolled a considerable length, but still didn‚Äôt find any government secrets.</p>

<p>Some people might give up here. But I, the Icarus of computers, was simply too dumb to know when to stop.</p>

<h3 id="were-not-done-just-because-a-web-page-says-were-done">We‚Äôre not done just because a <em>web page</em> says we‚Äôre done</h3>

<p>I wanted to see if there were juicy things hidden <em>inside</em> the page. To do it, I had to use the <em>only</em> hacker tool I know.</p>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/inspectelement.png" alt="Right click > Inspect-small">
<em>Right click &gt; Inspect Element, all you need to subvert the Commonwealth of Australia</em></p>

<p>Listen. This is the only part of the story that might be confused for highly elite computer skill. It‚Äôs not, though. Maybe later someone will show you this same thing to try and flex, acting like only <em>they</em> know how to do it. You will not go gently into that good night. You will refuse to acknowledge their flex, killing them instantly.</p>

<h5 id="how-does-inspect-element-work">How does ‚ÄúInspect Element‚Äù work?</h5>
<p>‚ÄúInspect Element‚Äù, as it‚Äôs called, is a feature of Google Chrome that lets you see the computer‚Äôs internal representation (HTML) of the page you‚Äôre looking at. Kinda like opening up a clock and looking at the cool cog party inside.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/6/67/Pocketwatch_cutaway_drawing.jpg" alt="cog party|small">
<em>Yeahhh go little cogs, look at ‚Äòem absolutely going off. Now imagine this but with like, JavaScript</em></p>

<p>Everything you see when you use ‚ÄúInspect Element‚Äù was already downloaded to your computer, you just hadn‚Äôt asked Chrome to show it to you yet. Just like how the cogs were already in the watch, you just hadn‚Äôt opened it up to look.</p>

<p>But let us dispense with frivolous cog talk. Cheap tricks such as ‚ÄúInspect Element‚Äù are used by programmers to try and understand how the website works. This is ultimately futile: Nobody can understand how websites work. Unfortunately, it kinda <em>looks</em> like hacking the first time you see it.</p>

<p>If you‚Äôd like to know more about it, I‚Äôve prepared a short video.</p>

<blockquote><p lang="en" dir="ltr">hey youtube welcome to my hacking tutorial, today we're gonna hack.... the nsa <a href="https://t.co/2Z35GJjSZE">pic.twitter.com/2Z35GJjSZE</a></p>‚Äî ‚ÄúAlex‚Äù (@mangopdf) <a href="https://twitter.com/mangopdf/status/1123400764926226432?ref_src=twsrc%5Etfw">May 1, 2019</a></blockquote>


<h3 id="browsing-the-manage-booking-pages-html">Browsing the ‚ÄúManage Booking‚Äù page‚Äôs HTML</h3>

<p>I scrolled around the page‚Äôs HTML, not really knowing what it meant, furiously trying to find anything that looked out of place or secret.</p>

<p>I eventually realised that manually reading HTML with my eyes was not an efficient way of defending my country, and Ctrl + F‚Äôd the HTML for ‚Äúpassport‚Äù.</p>

<h3 id="oh-no">oh no</h3>

<p><img src="https://mango.pdf.zone/img/sunburnt-country/passportjson.gif" alt="Blurred screenshot of close up &quot;passport&quot; number"></p>

<h3 id="oh-yes">Oh yes</h3>

<p>It‚Äôs just <em>there</em>.</p>

<p>At this point I was fairly sure I was looking at the <em>extremely</em> secret government-issued ID of the <em>28th Prime Minister of the Commonwealth of Australia, servant to her Majesty Queen Elizabeth II</em> and I was <em>kinda</em> worried that I was somehow doing something wrong, but like, not enough to stop.</p>

<h3 id="anything-else-in-this-page">‚Ä¶.anything <em>else</em> in this page?</h3>

<p>Well damn, if Tony Abbott‚Äôs passport number is in this treasure trove of computer spaghetti, maybe there‚Äôs wayyyyy more. Perhaps this HTML contains the lost launch codes to the Sydney Opera House, or Harold Holt<sup id="fnref:holt" role="doc-noteref"><a href="#fn:holt">9</a></sup>.</p>

<p>Maybe there‚Äôs a phone number?</p>

<p>Searching for <code>phone</code> and <code>number</code> didn‚Äôt get anywhere, so I searched for <code>614</code>, the first 3 digits of an Australian phone number, using my colossal and highly celestial galaxy brain.</p>

<h5 id="weird-uppercase-letters">Weird uppercase letters</h5>
<p>A weird pile of what I could only describe as extremely uppercase letters came up. It looked like this:</p>

<div><div><pre><code>RQST QF HK1 HNDSYD/03EN|FQTV QF HK1|CTCM QF HK1 614[phone number]|CKIN QF HN1 DO NOT SEAT ROW [row number] PLS SEAT LAST ROW OF [row letter] WINDOW
</code></pre></div></div>
<p>So, there‚Äôs a lot going on here. There is indeed a phone number in here. But what the heck is all this <em>other</em> stuff?</p>

<p>I realised this was like‚Ä¶ Qantas staff talking to eachother <em>about</em> Tony Abbott, but not <em>to</em> him?</p>

<p>In what is surely the subtweeting of the century, it has a ‚Ä¶</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram">https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram</a></em></p>]]>
            </description>
            <link>https://mango.pdf.zone/finding-former-australian-prime-minister-tony-abbotts-passport-number-on-instagram</link>
            <guid isPermaLink="false">hacker-news-small-sites-24488224</guid>
            <pubDate>Wed, 16 Sep 2020 00:16:13 GMT</pubDate>
        </item>
    </channel>
</rss>
